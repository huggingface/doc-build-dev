import{S as tzt,i as azt,s as nzt,e as a,k as l,w as F,t as o,M as szt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as lzt,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as Xot}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function izt($){let g,v,p,m,_,d,h,Eo,wi,Sf,nt,Ai,Li,WL,Rf,Oe,Qe,yi,Pn,HL,Bn,Nn,UL,xi,In,JL,$i,Pf,ka;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),wi=a("code"),Sf=o("model_type"),nt=o(" attribute is set to the same key you use when registering the config (here "),Ai=a("code"),Li=o('"new-model"'),WL=o(")."),Rf=l(),Oe=a("p"),Qe=o("Likewise, if your "),yi=a("code"),Pn=o("NewModel"),HL=o(" is a subclass of "),Bn=a("a"),Nn=o("PreTrainedModel"),UL=o(`, make sure its
`),xi=a("code"),In=o("config_class"),JL=o(` attribute is set to the same class you use when registering the model (here
`),$i=a("code"),Pf=o("NewModelConfig"),ka=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var LS=s(p);m=r(LS,"NewModelConfig"),LS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var ki=s(d);h=r(ki,"PretrainedConfig"),ki.forEach(t),Eo=r(Ae,`, make sure its
`),wi=n(Ae,"CODE",{});var yS=s(wi);Sf=r(yS,"model_type"),yS.forEach(t),nt=r(Ae," attribute is set to the same key you use when registering the config (here "),Ai=n(Ae,"CODE",{});var xS=s(Ai);Li=r(xS,'"new-model"'),xS.forEach(t),WL=r(Ae,")."),Ae.forEach(t),Rf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),yi=n(Co,"CODE",{});var Sa=s(yi);Pn=r(Sa,"NewModel"),Sa.forEach(t),HL=r(Co," is a subclass of "),Bn=n(Co,"A",{href:!0});var $S=s(Bn);Nn=r($S,"PreTrainedModel"),$S.forEach(t),UL=r(Co,`, make sure its
`),xi=n(Co,"CODE",{});var Bf=s(xi);In=r(Bf,"config_class"),Bf.forEach(t),JL=r(Co,` attribute is set to the same class you use when registering the model (here
`),$i=n(Co,"CODE",{});var kS=s($i);Pf=r(kS,"NewModelConfig"),kS.forEach(t),ka=r(Co,")."),Co.forEach(t),this.h()},h(){c(Bn,"href","/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,wi),e(wi,Sf),e(g,nt),e(g,Ai),e(Ai,Li),e(g,WL),b(We,Rf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,yi),e(yi,Pn),e(Oe,HL),e(Oe,Bn),e(Bn,Nn),e(Oe,UL),e(Oe,xi),e(xi,In),e(Oe,JL),e(Oe,$i),e($i,Pf),e(Oe,ka)},d(We){We&&t(g),We&&t(Rf),We&&t(Oe)}}}function dzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function czt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fzt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function mzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gzt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function hzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _zt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ezt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Czt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Azt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $zt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Szt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Izt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ozt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Qt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Qt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lWt($){let g,v,p,m,_,d,h,Eo,wi,Sf,nt,Ai,Li,WL,Rf,Oe,Qe,yi,Pn,HL,Bn,Nn,UL,xi,In,JL,$i,Pf,ka,We,Ae,LS,ki,yS,xS,Co,Sa,$S,Bf,kS,IWe,MVe,Si,Nf,iae,YL,qWe,dae,jWe,EVe,qn,DWe,cae,GWe,OWe,fae,VWe,XWe,CVe,KL,wVe,SS,zWe,AVe,If,LVe,Ri,qf,mae,ZL,QWe,gae,WWe,yVe,wo,ey,HWe,oy,UWe,RS,JWe,YWe,KWe,ry,ZWe,hae,eHe,oHe,rHe,Lr,ty,tHe,pae,aHe,nHe,Pi,sHe,_ae,lHe,iHe,uae,dHe,cHe,fHe,A,jf,bae,mHe,gHe,PS,hHe,pHe,_He,Df,vae,uHe,bHe,BS,vHe,FHe,THe,Gf,Fae,MHe,EHe,NS,CHe,wHe,AHe,Of,Tae,LHe,yHe,IS,xHe,$He,kHe,Vf,Mae,SHe,RHe,qS,PHe,BHe,NHe,Xf,Eae,IHe,qHe,jS,jHe,DHe,GHe,zf,Cae,OHe,VHe,DS,XHe,zHe,QHe,Qf,wae,WHe,HHe,GS,UHe,JHe,YHe,Wf,Aae,KHe,ZHe,OS,eUe,oUe,rUe,Hf,Lae,tUe,aUe,VS,nUe,sUe,lUe,Uf,yae,iUe,dUe,XS,cUe,fUe,mUe,Jf,xae,gUe,hUe,zS,pUe,_Ue,uUe,Yf,$ae,bUe,vUe,QS,FUe,TUe,MUe,Kf,kae,EUe,CUe,WS,wUe,AUe,LUe,Zf,Sae,yUe,xUe,HS,$Ue,kUe,SUe,em,Rae,RUe,PUe,US,BUe,NUe,IUe,om,Pae,qUe,jUe,JS,DUe,GUe,OUe,rm,Bae,VUe,XUe,YS,zUe,QUe,WUe,tm,Nae,HUe,UUe,KS,JUe,YUe,KUe,am,Iae,ZUe,eJe,ZS,oJe,rJe,tJe,nm,qae,aJe,nJe,eR,sJe,lJe,iJe,sm,jae,dJe,cJe,oR,fJe,mJe,gJe,lm,Dae,hJe,pJe,rR,_Je,uJe,bJe,im,Gae,vJe,FJe,tR,TJe,MJe,EJe,dm,Oae,CJe,wJe,aR,AJe,LJe,yJe,cm,Vae,xJe,$Je,nR,kJe,SJe,RJe,fm,Xae,PJe,BJe,sR,NJe,IJe,qJe,mm,zae,jJe,DJe,lR,GJe,OJe,VJe,gm,Qae,XJe,zJe,iR,QJe,WJe,HJe,hm,Wae,UJe,JJe,dR,YJe,KJe,ZJe,pm,Hae,eYe,oYe,cR,rYe,tYe,aYe,_m,Uae,nYe,sYe,fR,lYe,iYe,dYe,um,Jae,cYe,fYe,mR,mYe,gYe,hYe,bm,Yae,pYe,_Ye,gR,uYe,bYe,vYe,vm,Kae,FYe,TYe,hR,MYe,EYe,CYe,Fm,Zae,wYe,AYe,pR,LYe,yYe,xYe,Tm,ene,$Ye,kYe,_R,SYe,RYe,PYe,Mm,one,BYe,NYe,uR,IYe,qYe,jYe,Em,rne,DYe,GYe,bR,OYe,VYe,XYe,Cm,tne,zYe,QYe,vR,WYe,HYe,UYe,wm,ane,JYe,YYe,FR,KYe,ZYe,eKe,Am,nne,oKe,rKe,TR,tKe,aKe,nKe,Lm,sne,sKe,lKe,MR,iKe,dKe,cKe,ym,lne,fKe,mKe,ER,gKe,hKe,pKe,xm,ine,_Ke,uKe,CR,bKe,vKe,FKe,$m,dne,TKe,MKe,wR,EKe,CKe,wKe,km,cne,AKe,LKe,AR,yKe,xKe,$Ke,Sm,fne,kKe,SKe,LR,RKe,PKe,BKe,Rm,mne,NKe,IKe,yR,qKe,jKe,DKe,Pm,gne,GKe,OKe,xR,VKe,XKe,zKe,Bm,hne,QKe,WKe,$R,HKe,UKe,JKe,Nm,pne,YKe,KKe,kR,ZKe,eZe,oZe,Im,_ne,rZe,tZe,SR,aZe,nZe,sZe,qm,une,lZe,iZe,RR,dZe,cZe,fZe,jm,bne,mZe,gZe,PR,hZe,pZe,_Ze,Dm,vne,uZe,bZe,BR,vZe,FZe,TZe,Gm,Fne,MZe,EZe,NR,CZe,wZe,AZe,Om,Tne,LZe,yZe,IR,xZe,$Ze,kZe,Vm,Mne,SZe,RZe,qR,PZe,BZe,NZe,Xm,Ene,IZe,qZe,jR,jZe,DZe,GZe,zm,Cne,OZe,VZe,DR,XZe,zZe,QZe,Qm,wne,WZe,HZe,GR,UZe,JZe,YZe,Wm,Ane,KZe,ZZe,OR,eeo,oeo,reo,Hm,Lne,teo,aeo,VR,neo,seo,leo,Um,yne,ieo,deo,XR,ceo,feo,meo,Jm,xne,geo,heo,zR,peo,_eo,ueo,Ym,$ne,beo,veo,QR,Feo,Teo,Meo,Km,kne,Eeo,Ceo,WR,weo,Aeo,Leo,Zm,Sne,yeo,xeo,HR,$eo,keo,Seo,eg,Rne,Reo,Peo,UR,Beo,Neo,Ieo,og,Pne,qeo,jeo,JR,Deo,Geo,Oeo,rg,Bne,Veo,Xeo,YR,zeo,Qeo,Weo,tg,Nne,Heo,Ueo,KR,Jeo,Yeo,Keo,ag,Ine,Zeo,eoo,ZR,ooo,roo,too,ng,qne,aoo,noo,eP,soo,loo,ioo,sg,jne,doo,coo,oP,foo,moo,goo,lg,Dne,hoo,poo,rP,_oo,uoo,boo,ig,Gne,voo,Foo,tP,Too,Moo,Eoo,dg,One,Coo,woo,aP,Aoo,Loo,yoo,cg,Vne,xoo,$oo,nP,koo,Soo,Roo,fg,Xne,Poo,Boo,sP,Noo,Ioo,qoo,mg,zne,joo,Doo,lP,Goo,Ooo,Voo,gg,Qne,Xoo,zoo,iP,Qoo,Woo,Hoo,hg,Wne,Uoo,Joo,dP,Yoo,Koo,Zoo,pg,Hne,ero,oro,cP,rro,tro,aro,_g,Une,nro,sro,fP,lro,iro,dro,ug,Jne,cro,fro,mP,mro,gro,hro,bg,Yne,pro,_ro,gP,uro,bro,vro,vg,Kne,Fro,Tro,hP,Mro,Ero,Cro,Fg,Zne,wro,Aro,pP,Lro,yro,xro,Tg,ese,$ro,kro,_P,Sro,Rro,Pro,Mg,ose,Bro,Nro,uP,Iro,qro,jro,Eg,rse,Dro,Gro,bP,Oro,Vro,Xro,Cg,tse,zro,Qro,vP,Wro,Hro,Uro,wg,ase,Jro,Yro,FP,Kro,Zro,eto,Ag,nse,oto,rto,TP,tto,ato,nto,Lg,sse,sto,lto,MP,ito,dto,cto,yg,lse,fto,mto,EP,gto,hto,pto,xg,ise,_to,uto,CP,bto,vto,Fto,$g,dse,Tto,Mto,wP,Eto,Cto,wto,kg,cse,Ato,Lto,AP,yto,xto,$to,Sg,fse,kto,Sto,LP,Rto,Pto,Bto,Rg,mse,Nto,Ito,yP,qto,jto,Dto,Pg,gse,Gto,Oto,xP,Vto,Xto,zto,Bg,hse,Qto,Wto,$P,Hto,Uto,Jto,Ng,pse,Yto,Kto,kP,Zto,eao,oao,Ig,_se,rao,tao,SP,aao,nao,sao,qg,use,lao,iao,RP,dao,cao,fao,jg,bse,mao,gao,PP,hao,pao,_ao,Dg,vse,uao,bao,BP,vao,Fao,Tao,Gg,Fse,Mao,Eao,NP,Cao,wao,Aao,Og,Tse,Lao,yao,IP,xao,$ao,kao,Vg,Mse,Sao,Rao,qP,Pao,Bao,Nao,Xg,Ese,Iao,qao,jP,jao,Dao,Gao,zg,Cse,Oao,Vao,DP,Xao,zao,Qao,Qg,wse,Wao,Hao,GP,Uao,Jao,Yao,Wg,Ase,Kao,Zao,OP,eno,ono,rno,Hg,tno,Ug,ay,ano,Lse,nno,xVe,Bi,Jg,yse,ny,sno,xse,lno,$Ve,Ao,sy,ino,ly,dno,VP,cno,fno,mno,iy,gno,$se,hno,pno,_no,yr,dy,uno,kse,bno,vno,Ra,Fno,Sse,Tno,Mno,Rse,Eno,Cno,Pse,wno,Ano,Lno,k,jn,Bse,yno,xno,XP,$no,kno,zP,Sno,Rno,Pno,Dn,Nse,Bno,Nno,QP,Ino,qno,WP,jno,Dno,Gno,Gn,Ise,Ono,Vno,HP,Xno,zno,UP,Qno,Wno,Hno,Yg,qse,Uno,Jno,JP,Yno,Kno,Zno,On,jse,eso,oso,YP,rso,tso,KP,aso,nso,sso,Kg,Dse,lso,iso,ZP,dso,cso,fso,Zg,Gse,mso,gso,eB,hso,pso,_so,eh,Ose,uso,bso,oB,vso,Fso,Tso,Vn,Vse,Mso,Eso,rB,Cso,wso,tB,Aso,Lso,yso,Xn,Xse,xso,$so,aB,kso,Sso,nB,Rso,Pso,Bso,zn,zse,Nso,Iso,sB,qso,jso,lB,Dso,Gso,Oso,oh,Qse,Vso,Xso,iB,zso,Qso,Wso,rh,Wse,Hso,Uso,dB,Jso,Yso,Kso,th,Hse,Zso,elo,cB,olo,rlo,tlo,Qn,Use,alo,nlo,fB,slo,llo,mB,ilo,dlo,clo,ah,Jse,flo,mlo,gB,glo,hlo,plo,Wn,Yse,_lo,ulo,hB,blo,vlo,pB,Flo,Tlo,Mlo,Hn,Kse,Elo,Clo,_B,wlo,Alo,uB,Llo,ylo,xlo,Un,Zse,$lo,klo,bB,Slo,Rlo,vB,Plo,Blo,Nlo,Jn,ele,Ilo,qlo,FB,jlo,Dlo,TB,Glo,Olo,Vlo,nh,ole,Xlo,zlo,MB,Qlo,Wlo,Hlo,Yn,rle,Ulo,Jlo,EB,Ylo,Klo,CB,Zlo,eio,oio,Kn,tle,rio,tio,wB,aio,nio,AB,sio,lio,iio,Zn,ale,dio,cio,LB,fio,mio,yB,gio,hio,pio,es,nle,_io,uio,xB,bio,vio,$B,Fio,Tio,Mio,os,sle,Eio,Cio,kB,wio,Aio,SB,Lio,yio,xio,rs,lle,$io,kio,RB,Sio,Rio,PB,Pio,Bio,Nio,sh,ile,Iio,qio,BB,jio,Dio,Gio,ts,dle,Oio,Vio,NB,Xio,zio,IB,Qio,Wio,Hio,lh,cle,Uio,Jio,qB,Yio,Kio,Zio,as,fle,edo,odo,jB,rdo,tdo,DB,ado,ndo,sdo,ns,mle,ldo,ido,GB,ddo,cdo,OB,fdo,mdo,gdo,ss,gle,hdo,pdo,VB,_do,udo,XB,bdo,vdo,Fdo,ih,hle,Tdo,Mdo,zB,Edo,Cdo,wdo,ls,ple,Ado,Ldo,QB,ydo,xdo,WB,$do,kdo,Sdo,is,_le,Rdo,Pdo,HB,Bdo,Ndo,UB,Ido,qdo,jdo,ds,ule,Ddo,Gdo,JB,Odo,Vdo,YB,Xdo,zdo,Qdo,dh,ble,Wdo,Hdo,KB,Udo,Jdo,Ydo,cs,vle,Kdo,Zdo,ZB,eco,oco,eN,rco,tco,aco,fs,Fle,nco,sco,oN,lco,ico,rN,dco,cco,fco,ms,Tle,mco,gco,tN,hco,pco,aN,_co,uco,bco,gs,Mle,vco,Fco,nN,Tco,Mco,sN,Eco,Cco,wco,hs,Ele,Aco,Lco,lN,yco,xco,iN,$co,kco,Sco,ps,Cle,Rco,Pco,dN,Bco,Nco,cN,Ico,qco,jco,_s,wle,Dco,Gco,fN,Oco,Vco,mN,Xco,zco,Qco,us,Ale,Wco,Hco,gN,Uco,Jco,hN,Yco,Kco,Zco,ch,Lle,efo,ofo,pN,rfo,tfo,afo,bs,yle,nfo,sfo,_N,lfo,ifo,uN,dfo,cfo,ffo,fh,xle,mfo,gfo,bN,hfo,pfo,_fo,mh,$le,ufo,bfo,vN,vfo,Ffo,Tfo,vs,kle,Mfo,Efo,FN,Cfo,wfo,TN,Afo,Lfo,yfo,Fs,Sle,xfo,$fo,MN,kfo,Sfo,EN,Rfo,Pfo,Bfo,Ts,Rle,Nfo,Ifo,CN,qfo,jfo,wN,Dfo,Gfo,Ofo,gh,Ple,Vfo,Xfo,AN,zfo,Qfo,Wfo,Ms,Ble,Hfo,Ufo,LN,Jfo,Yfo,yN,Kfo,Zfo,emo,Es,Nle,omo,rmo,xN,tmo,amo,$N,nmo,smo,lmo,Cs,Ile,imo,dmo,kN,cmo,fmo,SN,mmo,gmo,hmo,ws,qle,pmo,_mo,RN,umo,bmo,PN,vmo,Fmo,Tmo,As,jle,Mmo,Emo,BN,Cmo,wmo,NN,Amo,Lmo,ymo,Ls,Dle,xmo,$mo,IN,kmo,Smo,qN,Rmo,Pmo,Bmo,ys,Gle,Nmo,Imo,jN,qmo,jmo,DN,Dmo,Gmo,Omo,hh,Ole,Vmo,Xmo,GN,zmo,Qmo,Wmo,xs,Vle,Hmo,Umo,ON,Jmo,Ymo,VN,Kmo,Zmo,ego,ph,Xle,ogo,rgo,XN,tgo,ago,ngo,_h,zle,sgo,lgo,zN,igo,dgo,cgo,uh,Qle,fgo,mgo,QN,ggo,hgo,pgo,bh,Wle,_go,ugo,WN,bgo,vgo,Fgo,$s,Hle,Tgo,Mgo,HN,Ego,Cgo,UN,wgo,Ago,Lgo,vh,Ule,ygo,xgo,JN,$go,kgo,Sgo,ks,Jle,Rgo,Pgo,YN,Bgo,Ngo,KN,Igo,qgo,jgo,Ss,Yle,Dgo,Ggo,ZN,Ogo,Vgo,eI,Xgo,zgo,Qgo,Rs,Kle,Wgo,Hgo,oI,Ugo,Jgo,rI,Ygo,Kgo,Zgo,Ps,Zle,eho,oho,tI,rho,tho,aI,aho,nho,sho,Bs,eie,lho,iho,nI,dho,cho,sI,fho,mho,gho,Ns,oie,hho,pho,lI,_ho,uho,iI,bho,vho,Fho,Fh,rie,Tho,Mho,dI,Eho,Cho,who,Th,tie,Aho,Lho,cI,yho,xho,$ho,Is,aie,kho,Sho,fI,Rho,Pho,mI,Bho,Nho,Iho,qs,nie,qho,jho,gI,Dho,Gho,hI,Oho,Vho,Xho,js,sie,zho,Qho,pI,Who,Hho,_I,Uho,Jho,Yho,Mh,lie,Kho,Zho,uI,epo,opo,rpo,Eh,iie,tpo,apo,bI,npo,spo,lpo,Ch,die,ipo,dpo,vI,cpo,fpo,mpo,Ds,cie,gpo,hpo,FI,ppo,_po,TI,upo,bpo,vpo,Gs,fie,Fpo,Tpo,MI,Mpo,Epo,EI,Cpo,wpo,Apo,wh,mie,Lpo,ypo,CI,xpo,$po,kpo,Ah,gie,Spo,Rpo,wI,Ppo,Bpo,Npo,Lh,hie,Ipo,qpo,AI,jpo,Dpo,Gpo,Os,pie,Opo,Vpo,LI,Xpo,zpo,yI,Qpo,Wpo,Hpo,yh,_ie,Upo,Jpo,xI,Ypo,Kpo,Zpo,xh,uie,e_o,o_o,$I,r_o,t_o,a_o,Vs,bie,n_o,s_o,kI,l_o,i_o,SI,d_o,c_o,f_o,Xs,vie,m_o,g_o,RI,h_o,p_o,PI,__o,u_o,b_o,zs,Fie,v_o,F_o,BI,T_o,M_o,NI,E_o,C_o,w_o,Qs,Tie,A_o,L_o,II,y_o,x_o,qI,$_o,k_o,S_o,$h,R_o,kh,cy,P_o,Mie,B_o,kVe,Ni,Sh,Eie,fy,N_o,Cie,I_o,SVe,Lo,my,q_o,gy,j_o,jI,D_o,G_o,O_o,hy,V_o,wie,X_o,z_o,Q_o,He,py,W_o,Aie,H_o,U_o,Pa,J_o,Lie,Y_o,K_o,yie,Z_o,euo,xie,ouo,ruo,tuo,Y,Rh,$ie,auo,nuo,DI,suo,luo,iuo,Ph,kie,duo,cuo,GI,fuo,muo,guo,Bh,Sie,huo,puo,OI,_uo,uuo,buo,Nh,Rie,vuo,Fuo,VI,Tuo,Muo,Euo,Ih,Pie,Cuo,wuo,XI,Auo,Luo,yuo,qh,Bie,xuo,$uo,zI,kuo,Suo,Ruo,jh,Nie,Puo,Buo,QI,Nuo,Iuo,quo,Dh,Iie,juo,Duo,WI,Guo,Ouo,Vuo,Gh,qie,Xuo,zuo,HI,Quo,Wuo,Huo,Oh,jie,Uuo,Juo,UI,Yuo,Kuo,Zuo,Vh,Die,e2o,o2o,JI,r2o,t2o,a2o,Xh,Gie,n2o,s2o,YI,l2o,i2o,d2o,zh,Oie,c2o,f2o,KI,m2o,g2o,h2o,Qh,Vie,p2o,_2o,ZI,u2o,b2o,v2o,Wh,Xie,F2o,T2o,eq,M2o,E2o,C2o,Hh,zie,w2o,A2o,oq,L2o,y2o,x2o,Uh,Qie,$2o,k2o,rq,S2o,R2o,P2o,Jh,Wie,B2o,N2o,tq,I2o,q2o,j2o,Yh,Hie,D2o,G2o,aq,O2o,V2o,X2o,Kh,Uie,z2o,Q2o,nq,W2o,H2o,U2o,Zh,Jie,J2o,Y2o,sq,K2o,Z2o,e1o,ep,Yie,o1o,r1o,lq,t1o,a1o,n1o,op,Kie,s1o,l1o,iq,i1o,d1o,c1o,rp,Zie,f1o,m1o,dq,g1o,h1o,p1o,tp,ede,_1o,u1o,cq,b1o,v1o,F1o,ap,ode,T1o,M1o,fq,E1o,C1o,w1o,np,rde,A1o,L1o,mq,y1o,x1o,$1o,sp,tde,k1o,S1o,gq,R1o,P1o,B1o,lp,ade,N1o,I1o,hq,q1o,j1o,D1o,ip,nde,G1o,O1o,pq,V1o,X1o,z1o,dp,sde,Q1o,W1o,_q,H1o,U1o,J1o,cp,lde,Y1o,K1o,uq,Z1o,e7o,o7o,fp,ide,r7o,t7o,bq,a7o,n7o,s7o,mp,l7o,gp,i7o,hp,_y,d7o,dde,c7o,RVe,Ii,pp,cde,uy,f7o,fde,m7o,PVe,yo,by,g7o,vy,h7o,vq,p7o,_7o,u7o,Fy,b7o,mde,v7o,F7o,T7o,Ue,Ty,M7o,gde,E7o,C7o,qi,w7o,hde,A7o,L7o,pde,y7o,x7o,$7o,he,_p,_de,k7o,S7o,Fq,R7o,P7o,B7o,up,ude,N7o,I7o,bde,q7o,j7o,D7o,bp,vde,G7o,O7o,Tq,V7o,X7o,z7o,vp,Fde,Q7o,W7o,Mq,H7o,U7o,J7o,Fp,Tde,Y7o,K7o,Eq,Z7o,e4o,o4o,Tp,Mde,r4o,t4o,Cq,a4o,n4o,s4o,Mp,Ede,l4o,i4o,wq,d4o,c4o,f4o,Ep,Cde,m4o,g4o,Aq,h4o,p4o,_4o,Cp,wde,u4o,b4o,Lq,v4o,F4o,T4o,wp,Ade,M4o,E4o,yq,C4o,w4o,A4o,Ap,Lde,L4o,y4o,xq,x4o,$4o,k4o,Lp,yde,S4o,R4o,$q,P4o,B4o,N4o,yp,xde,I4o,q4o,kq,j4o,D4o,G4o,xp,$de,O4o,V4o,Sq,X4o,z4o,Q4o,$p,kde,W4o,H4o,Rq,U4o,J4o,Y4o,kp,Sde,K4o,Z4o,Pq,ebo,obo,rbo,Sp,Rde,tbo,abo,Bq,nbo,sbo,lbo,Rp,Pde,ibo,dbo,Nq,cbo,fbo,mbo,Pp,gbo,Bp,hbo,Np,My,pbo,Bde,_bo,BVe,ji,Ip,Nde,Ey,ubo,Ide,bbo,NVe,xo,Cy,vbo,Di,Fbo,Iq,Tbo,Mbo,qq,Ebo,Cbo,wbo,wy,Abo,qde,Lbo,ybo,xbo,st,Ay,$bo,jde,kbo,Sbo,Gi,Rbo,Dde,Pbo,Bbo,jq,Nbo,Ibo,qbo,qp,jbo,Je,Ly,Dbo,Gde,Gbo,Obo,Ba,Vbo,Ode,Xbo,zbo,Vde,Qbo,Wbo,Xde,Hbo,Ubo,Jbo,y,jp,zde,Ybo,Kbo,Dq,Zbo,evo,ovo,Dp,Qde,rvo,tvo,Gq,avo,nvo,svo,Gp,Wde,lvo,ivo,Oq,dvo,cvo,fvo,Op,Hde,mvo,gvo,Vq,hvo,pvo,_vo,Vp,Ude,uvo,bvo,Xq,vvo,Fvo,Tvo,Xp,Jde,Mvo,Evo,zq,Cvo,wvo,Avo,zp,Yde,Lvo,yvo,Qq,xvo,$vo,kvo,Qp,Kde,Svo,Rvo,Wq,Pvo,Bvo,Nvo,Wp,Zde,Ivo,qvo,Hq,jvo,Dvo,Gvo,Hp,ece,Ovo,Vvo,Uq,Xvo,zvo,Qvo,Up,oce,Wvo,Hvo,Jq,Uvo,Jvo,Yvo,Jp,rce,Kvo,Zvo,Yq,eFo,oFo,rFo,Yp,tce,tFo,aFo,Kq,nFo,sFo,lFo,Kp,ace,iFo,dFo,Zq,cFo,fFo,mFo,Zp,nce,gFo,hFo,ej,pFo,_Fo,uFo,e_,sce,bFo,vFo,oj,FFo,TFo,MFo,o_,lce,EFo,CFo,rj,wFo,AFo,LFo,r_,ice,yFo,xFo,tj,$Fo,kFo,SFo,t_,dce,RFo,PFo,aj,BFo,NFo,IFo,a_,cce,qFo,jFo,nj,DFo,GFo,OFo,n_,fce,VFo,XFo,sj,zFo,QFo,WFo,s_,mce,HFo,UFo,lj,JFo,YFo,KFo,l_,gce,ZFo,eTo,ij,oTo,rTo,tTo,i_,hce,aTo,nTo,dj,sTo,lTo,iTo,d_,pce,dTo,cTo,cj,fTo,mTo,gTo,c_,_ce,hTo,pTo,fj,_To,uTo,bTo,f_,uce,vTo,FTo,mj,TTo,MTo,ETo,m_,bce,CTo,wTo,gj,ATo,LTo,yTo,g_,vce,xTo,$To,hj,kTo,STo,RTo,h_,Fce,PTo,BTo,pj,NTo,ITo,qTo,p_,Tce,jTo,DTo,_j,GTo,OTo,VTo,__,Mce,XTo,zTo,uj,QTo,WTo,HTo,u_,Ece,UTo,JTo,bj,YTo,KTo,ZTo,b_,Cce,eMo,oMo,vj,rMo,tMo,aMo,Ws,wce,nMo,sMo,Fj,lMo,iMo,Tj,dMo,cMo,fMo,v_,Ace,mMo,gMo,Mj,hMo,pMo,_Mo,F_,Lce,uMo,bMo,Ej,vMo,FMo,TMo,T_,yce,MMo,EMo,Cj,CMo,wMo,AMo,M_,xce,LMo,yMo,wj,xMo,$Mo,kMo,E_,$ce,SMo,RMo,Aj,PMo,BMo,NMo,C_,kce,IMo,qMo,Lj,jMo,DMo,GMo,w_,Sce,OMo,VMo,yj,XMo,zMo,QMo,A_,Rce,WMo,HMo,xj,UMo,JMo,YMo,L_,Pce,KMo,ZMo,$j,eEo,oEo,rEo,y_,Bce,tEo,aEo,kj,nEo,sEo,lEo,x_,Nce,iEo,dEo,Sj,cEo,fEo,mEo,$_,Ice,gEo,hEo,Rj,pEo,_Eo,uEo,k_,qce,bEo,vEo,Pj,FEo,TEo,MEo,S_,jce,EEo,CEo,Bj,wEo,AEo,LEo,R_,Dce,yEo,xEo,Nj,$Eo,kEo,SEo,P_,Gce,REo,PEo,Ij,BEo,NEo,IEo,B_,Oce,qEo,jEo,qj,DEo,GEo,OEo,N_,Vce,VEo,XEo,jj,zEo,QEo,WEo,I_,Xce,HEo,UEo,Dj,JEo,YEo,KEo,q_,zce,ZEo,eCo,Gj,oCo,rCo,tCo,j_,Qce,aCo,nCo,Oj,sCo,lCo,iCo,D_,Wce,dCo,cCo,Vj,fCo,mCo,gCo,G_,Hce,hCo,pCo,Xj,_Co,uCo,bCo,O_,Uce,vCo,FCo,zj,TCo,MCo,ECo,V_,Jce,CCo,wCo,Qj,ACo,LCo,yCo,X_,Yce,xCo,$Co,Wj,kCo,SCo,RCo,z_,Kce,PCo,BCo,Hj,NCo,ICo,qCo,Q_,Zce,jCo,DCo,Uj,GCo,OCo,VCo,W_,efe,XCo,zCo,Jj,QCo,WCo,HCo,H_,ofe,UCo,JCo,Yj,YCo,KCo,ZCo,U_,rfe,e3o,o3o,Kj,r3o,t3o,a3o,J_,tfe,n3o,s3o,Zj,l3o,i3o,d3o,Y_,afe,c3o,f3o,eD,m3o,g3o,h3o,K_,nfe,p3o,_3o,oD,u3o,b3o,v3o,Z_,sfe,F3o,T3o,rD,M3o,E3o,C3o,eu,lfe,w3o,A3o,tD,L3o,y3o,x3o,ou,ife,$3o,k3o,aD,S3o,R3o,P3o,ru,dfe,B3o,N3o,nD,I3o,q3o,j3o,tu,cfe,D3o,G3o,sD,O3o,V3o,X3o,au,ffe,z3o,Q3o,lD,W3o,H3o,U3o,nu,mfe,J3o,Y3o,iD,K3o,Z3o,e5o,su,gfe,o5o,r5o,dD,t5o,a5o,n5o,lu,hfe,s5o,l5o,cD,i5o,d5o,c5o,iu,pfe,f5o,m5o,fD,g5o,h5o,p5o,du,_fe,_5o,u5o,mD,b5o,v5o,F5o,cu,ufe,T5o,M5o,gD,E5o,C5o,w5o,fu,bfe,A5o,L5o,hD,y5o,x5o,$5o,mu,vfe,k5o,S5o,pD,R5o,P5o,B5o,gu,Ffe,N5o,I5o,_D,q5o,j5o,D5o,hu,Tfe,G5o,O5o,uD,V5o,X5o,z5o,pu,Mfe,Q5o,W5o,bD,H5o,U5o,J5o,_u,Efe,Y5o,K5o,vD,Z5o,e0o,o0o,uu,Cfe,r0o,t0o,FD,a0o,n0o,s0o,bu,wfe,l0o,i0o,TD,d0o,c0o,f0o,vu,Afe,m0o,g0o,MD,h0o,p0o,_0o,Fu,Lfe,u0o,b0o,ED,v0o,F0o,T0o,Tu,yfe,M0o,E0o,CD,C0o,w0o,A0o,Mu,xfe,L0o,y0o,wD,x0o,$0o,k0o,Eu,$fe,S0o,R0o,AD,P0o,B0o,N0o,Cu,kfe,I0o,q0o,LD,j0o,D0o,G0o,wu,Sfe,O0o,V0o,yD,X0o,z0o,Q0o,Au,Rfe,W0o,H0o,xD,U0o,J0o,Y0o,Lu,Pfe,K0o,Z0o,$D,ewo,owo,rwo,yu,Bfe,two,awo,kD,nwo,swo,lwo,xu,Nfe,iwo,dwo,SD,cwo,fwo,mwo,$u,Ife,gwo,hwo,RD,pwo,_wo,uwo,ku,qfe,bwo,vwo,PD,Fwo,Two,Mwo,Su,jfe,Ewo,Cwo,BD,wwo,Awo,Lwo,Ru,Dfe,ywo,xwo,ND,$wo,kwo,Swo,Pu,Gfe,Rwo,Pwo,ID,Bwo,Nwo,Iwo,Bu,Ofe,qwo,jwo,qD,Dwo,Gwo,Owo,Nu,Vfe,Vwo,Xwo,jD,zwo,Qwo,Wwo,Iu,Xfe,Hwo,Uwo,DD,Jwo,Ywo,Kwo,qu,zfe,Zwo,eAo,GD,oAo,rAo,tAo,ju,Qfe,aAo,nAo,OD,sAo,lAo,iAo,Du,dAo,Wfe,cAo,fAo,Hfe,mAo,gAo,Gu,IVe,Oi,Ou,Ufe,yy,hAo,Jfe,pAo,qVe,$o,xy,_Ao,Vi,uAo,VD,bAo,vAo,XD,FAo,TAo,MAo,$y,EAo,Yfe,CAo,wAo,AAo,lt,ky,LAo,Kfe,yAo,xAo,Xi,$Ao,Zfe,kAo,SAo,zD,RAo,PAo,BAo,Vu,NAo,Ye,Sy,IAo,eme,qAo,jAo,Na,DAo,ome,GAo,OAo,rme,VAo,XAo,tme,zAo,QAo,WAo,G,Xu,ame,HAo,UAo,QD,JAo,YAo,KAo,zu,nme,ZAo,e6o,WD,o6o,r6o,t6o,Qu,sme,a6o,n6o,HD,s6o,l6o,i6o,Wu,lme,d6o,c6o,UD,f6o,m6o,g6o,Hu,ime,h6o,p6o,JD,_6o,u6o,b6o,Uu,dme,v6o,F6o,YD,T6o,M6o,E6o,Ju,cme,C6o,w6o,KD,A6o,L6o,y6o,Yu,fme,x6o,$6o,ZD,k6o,S6o,R6o,Ku,mme,P6o,B6o,eG,N6o,I6o,q6o,Zu,gme,j6o,D6o,oG,G6o,O6o,V6o,e2,hme,X6o,z6o,rG,Q6o,W6o,H6o,o2,pme,U6o,J6o,tG,Y6o,K6o,Z6o,r2,_me,eLo,oLo,aG,rLo,tLo,aLo,t2,ume,nLo,sLo,nG,lLo,iLo,dLo,a2,bme,cLo,fLo,sG,mLo,gLo,hLo,n2,vme,pLo,_Lo,lG,uLo,bLo,vLo,s2,Fme,FLo,TLo,iG,MLo,ELo,CLo,l2,Tme,wLo,ALo,dG,LLo,yLo,xLo,i2,Mme,$Lo,kLo,cG,SLo,RLo,PLo,d2,Eme,BLo,NLo,fG,ILo,qLo,jLo,c2,Cme,DLo,GLo,mG,OLo,VLo,XLo,f2,wme,zLo,QLo,gG,WLo,HLo,ULo,m2,Ame,JLo,YLo,hG,KLo,ZLo,eyo,g2,Lme,oyo,ryo,pG,tyo,ayo,nyo,h2,yme,syo,lyo,_G,iyo,dyo,cyo,p2,xme,fyo,myo,uG,gyo,hyo,pyo,_2,$me,_yo,uyo,bG,byo,vyo,Fyo,u2,kme,Tyo,Myo,vG,Eyo,Cyo,wyo,b2,Sme,Ayo,Lyo,FG,yyo,xyo,$yo,v2,Rme,kyo,Syo,TG,Ryo,Pyo,Byo,F2,Pme,Nyo,Iyo,MG,qyo,jyo,Dyo,T2,Bme,Gyo,Oyo,EG,Vyo,Xyo,zyo,M2,Nme,Qyo,Wyo,CG,Hyo,Uyo,Jyo,E2,Ime,Yyo,Kyo,wG,Zyo,e8o,o8o,C2,qme,r8o,t8o,AG,a8o,n8o,s8o,w2,jme,l8o,i8o,LG,d8o,c8o,f8o,A2,Dme,m8o,g8o,yG,h8o,p8o,_8o,L2,Gme,u8o,b8o,xG,v8o,F8o,T8o,y2,Ome,M8o,E8o,$G,C8o,w8o,A8o,x2,Vme,L8o,y8o,kG,x8o,$8o,k8o,$2,Xme,S8o,R8o,SG,P8o,B8o,N8o,k2,zme,I8o,q8o,RG,j8o,D8o,G8o,S2,Qme,O8o,V8o,PG,X8o,z8o,Q8o,R2,Wme,W8o,H8o,BG,U8o,J8o,Y8o,P2,Hme,K8o,Z8o,NG,e9o,o9o,r9o,B2,t9o,Ume,a9o,n9o,Jme,s9o,l9o,N2,jVe,zi,I2,Yme,Ry,i9o,Kme,d9o,DVe,ko,Py,c9o,Qi,f9o,IG,m9o,g9o,qG,h9o,p9o,_9o,By,u9o,Zme,b9o,v9o,F9o,it,Ny,T9o,ege,M9o,E9o,Wi,C9o,oge,w9o,A9o,jG,L9o,y9o,x9o,q2,$9o,Ke,Iy,k9o,rge,S9o,R9o,Ia,P9o,tge,B9o,N9o,age,I9o,q9o,nge,j9o,D9o,G9o,z,j2,sge,O9o,V9o,DG,X9o,z9o,Q9o,D2,lge,W9o,H9o,GG,U9o,J9o,Y9o,G2,ige,K9o,Z9o,OG,exo,oxo,rxo,O2,dge,txo,axo,VG,nxo,sxo,lxo,V2,cge,ixo,dxo,XG,cxo,fxo,mxo,X2,fge,gxo,hxo,zG,pxo,_xo,uxo,z2,mge,bxo,vxo,QG,Fxo,Txo,Mxo,Q2,gge,Exo,Cxo,WG,wxo,Axo,Lxo,W2,hge,yxo,xxo,HG,$xo,kxo,Sxo,H2,pge,Rxo,Pxo,UG,Bxo,Nxo,Ixo,U2,_ge,qxo,jxo,JG,Dxo,Gxo,Oxo,J2,uge,Vxo,Xxo,YG,zxo,Qxo,Wxo,Y2,bge,Hxo,Uxo,KG,Jxo,Yxo,Kxo,K2,vge,Zxo,e$o,ZG,o$o,r$o,t$o,Z2,Fge,a$o,n$o,eO,s$o,l$o,i$o,e1,Tge,d$o,c$o,oO,f$o,m$o,g$o,o1,Mge,h$o,p$o,rO,_$o,u$o,b$o,r1,Ege,v$o,F$o,tO,T$o,M$o,E$o,t1,Cge,C$o,w$o,aO,A$o,L$o,y$o,a1,wge,x$o,$$o,nO,k$o,S$o,R$o,n1,Age,P$o,B$o,sO,N$o,I$o,q$o,s1,Lge,j$o,D$o,lO,G$o,O$o,V$o,l1,yge,X$o,z$o,iO,Q$o,W$o,H$o,i1,xge,U$o,J$o,dO,Y$o,K$o,Z$o,d1,$ge,eko,oko,cO,rko,tko,ako,c1,kge,nko,sko,fO,lko,iko,dko,f1,Sge,cko,fko,mO,mko,gko,hko,m1,Rge,pko,_ko,gO,uko,bko,vko,g1,Pge,Fko,Tko,hO,Mko,Eko,Cko,h1,Bge,wko,Ako,pO,Lko,yko,xko,p1,Nge,$ko,kko,_O,Sko,Rko,Pko,_1,Ige,Bko,Nko,uO,Iko,qko,jko,u1,qge,Dko,Gko,bO,Oko,Vko,Xko,b1,jge,zko,Qko,vO,Wko,Hko,Uko,v1,Dge,Jko,Yko,FO,Kko,Zko,eSo,F1,Gge,oSo,rSo,TO,tSo,aSo,nSo,T1,Oge,sSo,lSo,MO,iSo,dSo,cSo,M1,Vge,fSo,mSo,EO,gSo,hSo,pSo,E1,Xge,_So,uSo,CO,bSo,vSo,FSo,C1,zge,TSo,MSo,wO,ESo,CSo,wSo,w1,ASo,Qge,LSo,ySo,Wge,xSo,$So,A1,GVe,Hi,L1,Hge,qy,kSo,Uge,SSo,OVe,So,jy,RSo,Ui,PSo,AO,BSo,NSo,LO,ISo,qSo,jSo,Dy,DSo,Jge,GSo,OSo,VSo,dt,Gy,XSo,Yge,zSo,QSo,Ji,WSo,Kge,HSo,USo,yO,JSo,YSo,KSo,y1,ZSo,Ze,Oy,eRo,Zge,oRo,rRo,qa,tRo,ehe,aRo,nRo,ohe,sRo,lRo,rhe,iRo,dRo,cRo,W,x1,the,fRo,mRo,xO,gRo,hRo,pRo,$1,ahe,_Ro,uRo,$O,bRo,vRo,FRo,k1,nhe,TRo,MRo,kO,ERo,CRo,wRo,S1,she,ARo,LRo,SO,yRo,xRo,$Ro,R1,lhe,kRo,SRo,RO,RRo,PRo,BRo,P1,ihe,NRo,IRo,PO,qRo,jRo,DRo,B1,dhe,GRo,ORo,BO,VRo,XRo,zRo,N1,che,QRo,WRo,NO,HRo,URo,JRo,I1,fhe,YRo,KRo,IO,ZRo,ePo,oPo,q1,mhe,rPo,tPo,qO,aPo,nPo,sPo,j1,ghe,lPo,iPo,jO,dPo,cPo,fPo,D1,hhe,mPo,gPo,DO,hPo,pPo,_Po,G1,phe,uPo,bPo,GO,vPo,FPo,TPo,O1,_he,MPo,EPo,OO,CPo,wPo,APo,V1,uhe,LPo,yPo,VO,xPo,$Po,kPo,X1,bhe,SPo,RPo,XO,PPo,BPo,NPo,z1,vhe,IPo,qPo,zO,jPo,DPo,GPo,Q1,Fhe,OPo,VPo,QO,XPo,zPo,QPo,W1,The,WPo,HPo,WO,UPo,JPo,YPo,H1,Mhe,KPo,ZPo,HO,eBo,oBo,rBo,U1,Ehe,tBo,aBo,UO,nBo,sBo,lBo,J1,Che,iBo,dBo,JO,cBo,fBo,mBo,Y1,whe,gBo,hBo,YO,pBo,_Bo,uBo,K1,Ahe,bBo,vBo,KO,FBo,TBo,MBo,Z1,Lhe,EBo,CBo,ZO,wBo,ABo,LBo,e7,yhe,yBo,xBo,eV,$Bo,kBo,SBo,o7,xhe,RBo,PBo,oV,BBo,NBo,IBo,r7,$he,qBo,jBo,rV,DBo,GBo,OBo,t7,khe,VBo,XBo,tV,zBo,QBo,WBo,a7,She,HBo,UBo,aV,JBo,YBo,KBo,n7,Rhe,ZBo,eNo,nV,oNo,rNo,tNo,s7,Phe,aNo,nNo,sV,sNo,lNo,iNo,l7,Bhe,dNo,cNo,lV,fNo,mNo,gNo,i7,Nhe,hNo,pNo,Ihe,_No,uNo,bNo,d7,qhe,vNo,FNo,iV,TNo,MNo,ENo,c7,jhe,CNo,wNo,dV,ANo,LNo,yNo,f7,Dhe,xNo,$No,cV,kNo,SNo,RNo,m7,Ghe,PNo,BNo,fV,NNo,INo,qNo,g7,jNo,Ohe,DNo,GNo,Vhe,ONo,VNo,h7,VVe,Yi,p7,Xhe,Vy,XNo,zhe,zNo,XVe,Ro,Xy,QNo,Ki,WNo,mV,HNo,UNo,gV,JNo,YNo,KNo,zy,ZNo,Qhe,eIo,oIo,rIo,ct,Qy,tIo,Whe,aIo,nIo,Zi,sIo,Hhe,lIo,iIo,hV,dIo,cIo,fIo,_7,mIo,eo,Wy,gIo,Uhe,hIo,pIo,ja,_Io,Jhe,uIo,bIo,Yhe,vIo,FIo,Khe,TIo,MIo,EIo,pe,u7,Zhe,CIo,wIo,pV,AIo,LIo,yIo,b7,epe,xIo,$Io,_V,kIo,SIo,RIo,v7,ope,PIo,BIo,uV,NIo,IIo,qIo,F7,rpe,jIo,DIo,bV,GIo,OIo,VIo,T7,tpe,XIo,zIo,vV,QIo,WIo,HIo,M7,ape,UIo,JIo,FV,YIo,KIo,ZIo,E7,npe,eqo,oqo,TV,rqo,tqo,aqo,C7,spe,nqo,sqo,MV,lqo,iqo,dqo,w7,lpe,cqo,fqo,EV,mqo,gqo,hqo,A7,ipe,pqo,_qo,CV,uqo,bqo,vqo,L7,dpe,Fqo,Tqo,wV,Mqo,Eqo,Cqo,y7,cpe,wqo,Aqo,AV,Lqo,yqo,xqo,x7,fpe,$qo,kqo,LV,Sqo,Rqo,Pqo,$7,mpe,Bqo,Nqo,yV,Iqo,qqo,jqo,k7,gpe,Dqo,Gqo,xV,Oqo,Vqo,Xqo,S7,hpe,zqo,Qqo,$V,Wqo,Hqo,Uqo,R7,ppe,Jqo,Yqo,kV,Kqo,Zqo,ejo,P7,_pe,ojo,rjo,SV,tjo,ajo,njo,B7,sjo,upe,ljo,ijo,bpe,djo,cjo,N7,zVe,ed,I7,vpe,Hy,fjo,Fpe,mjo,QVe,Po,Uy,gjo,od,hjo,RV,pjo,_jo,PV,ujo,bjo,vjo,Jy,Fjo,Tpe,Tjo,Mjo,Ejo,ft,Yy,Cjo,Mpe,wjo,Ajo,rd,Ljo,Epe,yjo,xjo,BV,$jo,kjo,Sjo,q7,Rjo,oo,Ky,Pjo,Cpe,Bjo,Njo,Da,Ijo,wpe,qjo,jjo,Ape,Djo,Gjo,Lpe,Ojo,Vjo,Xjo,I,j7,ype,zjo,Qjo,NV,Wjo,Hjo,Ujo,D7,xpe,Jjo,Yjo,IV,Kjo,Zjo,eDo,G7,$pe,oDo,rDo,qV,tDo,aDo,nDo,O7,kpe,sDo,lDo,jV,iDo,dDo,cDo,V7,Spe,fDo,mDo,DV,gDo,hDo,pDo,X7,Rpe,_Do,uDo,GV,bDo,vDo,FDo,z7,Ppe,TDo,MDo,OV,EDo,CDo,wDo,Q7,Bpe,ADo,LDo,VV,yDo,xDo,$Do,W7,Npe,kDo,SDo,XV,RDo,PDo,BDo,H7,Ipe,NDo,IDo,zV,qDo,jDo,DDo,U7,qpe,GDo,ODo,QV,VDo,XDo,zDo,J7,jpe,QDo,WDo,WV,HDo,UDo,JDo,Y7,Dpe,YDo,KDo,HV,ZDo,eGo,oGo,K7,Gpe,rGo,tGo,UV,aGo,nGo,sGo,Z7,Ope,lGo,iGo,JV,dGo,cGo,fGo,e4,Vpe,mGo,gGo,YV,hGo,pGo,_Go,o4,Xpe,uGo,bGo,KV,vGo,FGo,TGo,r4,zpe,MGo,EGo,ZV,CGo,wGo,AGo,t4,Qpe,LGo,yGo,eX,xGo,$Go,kGo,a4,Wpe,SGo,RGo,oX,PGo,BGo,NGo,n4,Hpe,IGo,qGo,rX,jGo,DGo,GGo,s4,Upe,OGo,VGo,tX,XGo,zGo,QGo,l4,Jpe,WGo,HGo,aX,UGo,JGo,YGo,i4,Ype,KGo,ZGo,nX,eOo,oOo,rOo,d4,Kpe,tOo,aOo,sX,nOo,sOo,lOo,c4,Zpe,iOo,dOo,lX,cOo,fOo,mOo,f4,e_e,gOo,hOo,iX,pOo,_Oo,uOo,m4,o_e,bOo,vOo,dX,FOo,TOo,MOo,g4,r_e,EOo,COo,cX,wOo,AOo,LOo,h4,t_e,yOo,xOo,fX,$Oo,kOo,SOo,p4,a_e,ROo,POo,mX,BOo,NOo,IOo,_4,n_e,qOo,jOo,gX,DOo,GOo,OOo,u4,s_e,VOo,XOo,hX,zOo,QOo,WOo,b4,l_e,HOo,UOo,pX,JOo,YOo,KOo,v4,i_e,ZOo,eVo,_X,oVo,rVo,tVo,F4,d_e,aVo,nVo,uX,sVo,lVo,iVo,T4,c_e,dVo,cVo,bX,fVo,mVo,gVo,M4,f_e,hVo,pVo,vX,_Vo,uVo,bVo,E4,m_e,vVo,FVo,FX,TVo,MVo,EVo,C4,g_e,CVo,wVo,TX,AVo,LVo,yVo,w4,h_e,xVo,$Vo,MX,kVo,SVo,RVo,A4,p_e,PVo,BVo,EX,NVo,IVo,qVo,L4,__e,jVo,DVo,CX,GVo,OVo,VVo,y4,u_e,XVo,zVo,wX,QVo,WVo,HVo,x4,b_e,UVo,JVo,AX,YVo,KVo,ZVo,$4,v_e,eXo,oXo,LX,rXo,tXo,aXo,k4,F_e,nXo,sXo,yX,lXo,iXo,dXo,S4,T_e,cXo,fXo,xX,mXo,gXo,hXo,R4,M_e,pXo,_Xo,$X,uXo,bXo,vXo,P4,E_e,FXo,TXo,kX,MXo,EXo,CXo,B4,wXo,C_e,AXo,LXo,w_e,yXo,xXo,N4,WVe,td,I4,A_e,Zy,$Xo,L_e,kXo,HVe,Bo,e8,SXo,ad,RXo,SX,PXo,BXo,RX,NXo,IXo,qXo,o8,jXo,y_e,DXo,GXo,OXo,mt,r8,VXo,x_e,XXo,zXo,nd,QXo,$_e,WXo,HXo,PX,UXo,JXo,YXo,q4,KXo,ro,t8,ZXo,k_e,ezo,ozo,Ga,rzo,S_e,tzo,azo,R_e,nzo,szo,P_e,lzo,izo,dzo,Z,j4,B_e,czo,fzo,BX,mzo,gzo,hzo,D4,N_e,pzo,_zo,NX,uzo,bzo,vzo,G4,I_e,Fzo,Tzo,IX,Mzo,Ezo,Czo,O4,q_e,wzo,Azo,qX,Lzo,yzo,xzo,V4,j_e,$zo,kzo,jX,Szo,Rzo,Pzo,X4,D_e,Bzo,Nzo,DX,Izo,qzo,jzo,z4,G_e,Dzo,Gzo,GX,Ozo,Vzo,Xzo,Q4,O_e,zzo,Qzo,OX,Wzo,Hzo,Uzo,W4,V_e,Jzo,Yzo,VX,Kzo,Zzo,eQo,H4,X_e,oQo,rQo,XX,tQo,aQo,nQo,U4,z_e,sQo,lQo,zX,iQo,dQo,cQo,J4,Q_e,fQo,mQo,QX,gQo,hQo,pQo,Y4,W_e,_Qo,uQo,WX,bQo,vQo,FQo,K4,H_e,TQo,MQo,HX,EQo,CQo,wQo,Z4,U_e,AQo,LQo,UX,yQo,xQo,$Qo,eb,J_e,kQo,SQo,JX,RQo,PQo,BQo,ob,Y_e,NQo,IQo,YX,qQo,jQo,DQo,rb,K_e,GQo,OQo,KX,VQo,XQo,zQo,tb,Z_e,QQo,WQo,ZX,HQo,UQo,JQo,ab,eue,YQo,KQo,ez,ZQo,eWo,oWo,nb,oue,rWo,tWo,oz,aWo,nWo,sWo,sb,rue,lWo,iWo,rz,dWo,cWo,fWo,lb,tue,mWo,gWo,tz,hWo,pWo,_Wo,ib,aue,uWo,bWo,az,vWo,FWo,TWo,db,nue,MWo,EWo,nz,CWo,wWo,AWo,cb,sue,LWo,yWo,sz,xWo,$Wo,kWo,fb,lue,SWo,RWo,lz,PWo,BWo,NWo,mb,iue,IWo,qWo,iz,jWo,DWo,GWo,gb,due,OWo,VWo,dz,XWo,zWo,QWo,hb,cue,WWo,HWo,cz,UWo,JWo,YWo,pb,KWo,fue,ZWo,eHo,mue,oHo,rHo,_b,UVe,sd,ub,gue,a8,tHo,hue,aHo,JVe,No,n8,nHo,ld,sHo,fz,lHo,iHo,mz,dHo,cHo,fHo,s8,mHo,pue,gHo,hHo,pHo,gt,l8,_Ho,_ue,uHo,bHo,id,vHo,uue,FHo,THo,gz,MHo,EHo,CHo,bb,wHo,to,i8,AHo,bue,LHo,yHo,Oa,xHo,vue,$Ho,kHo,Fue,SHo,RHo,Tue,PHo,BHo,NHo,Io,vb,Mue,IHo,qHo,hz,jHo,DHo,GHo,Fb,Eue,OHo,VHo,pz,XHo,zHo,QHo,Tb,Cue,WHo,HHo,_z,UHo,JHo,YHo,Mb,wue,KHo,ZHo,uz,eUo,oUo,rUo,Eb,Aue,tUo,aUo,bz,nUo,sUo,lUo,Cb,Lue,iUo,dUo,vz,cUo,fUo,mUo,wb,gUo,yue,hUo,pUo,xue,_Uo,uUo,Ab,YVe,dd,Lb,$ue,d8,bUo,kue,vUo,KVe,qo,c8,FUo,cd,TUo,Fz,MUo,EUo,Tz,CUo,wUo,AUo,f8,LUo,Sue,yUo,xUo,$Uo,ht,m8,kUo,Rue,SUo,RUo,fd,PUo,Pue,BUo,NUo,Mz,IUo,qUo,jUo,yb,DUo,ao,g8,GUo,Bue,OUo,VUo,Va,XUo,Nue,zUo,QUo,Iue,WUo,HUo,que,UUo,JUo,YUo,U,xb,jue,KUo,ZUo,Ez,eJo,oJo,rJo,$b,Due,tJo,aJo,Cz,nJo,sJo,lJo,kb,Gue,iJo,dJo,wz,cJo,fJo,mJo,Sb,Oue,gJo,hJo,Az,pJo,_Jo,uJo,Rb,Vue,bJo,vJo,Lz,FJo,TJo,MJo,Pb,Xue,EJo,CJo,yz,wJo,AJo,LJo,Bb,zue,yJo,xJo,xz,$Jo,kJo,SJo,Nb,Que,RJo,PJo,$z,BJo,NJo,IJo,Ib,Wue,qJo,jJo,kz,DJo,GJo,OJo,qb,Hue,VJo,XJo,Sz,zJo,QJo,WJo,jb,Uue,HJo,UJo,Rz,JJo,YJo,KJo,Db,Jue,ZJo,eYo,Pz,oYo,rYo,tYo,Gb,Yue,aYo,nYo,Bz,sYo,lYo,iYo,Ob,Kue,dYo,cYo,Nz,fYo,mYo,gYo,Vb,Zue,hYo,pYo,Iz,_Yo,uYo,bYo,Xb,e2e,vYo,FYo,qz,TYo,MYo,EYo,zb,o2e,CYo,wYo,jz,AYo,LYo,yYo,Qb,r2e,xYo,$Yo,Dz,kYo,SYo,RYo,Wb,t2e,PYo,BYo,Gz,NYo,IYo,qYo,Hb,a2e,jYo,DYo,Oz,GYo,OYo,VYo,Ub,n2e,XYo,zYo,Vz,QYo,WYo,HYo,Jb,s2e,UYo,JYo,Xz,YYo,KYo,ZYo,Yb,l2e,eKo,oKo,zz,rKo,tKo,aKo,Kb,i2e,nKo,sKo,Qz,lKo,iKo,dKo,Zb,d2e,cKo,fKo,Wz,mKo,gKo,hKo,ev,c2e,pKo,_Ko,Hz,uKo,bKo,vKo,ov,f2e,FKo,TKo,Uz,MKo,EKo,CKo,rv,m2e,wKo,AKo,Jz,LKo,yKo,xKo,tv,g2e,$Ko,kKo,Yz,SKo,RKo,PKo,av,h2e,BKo,NKo,Kz,IKo,qKo,jKo,nv,p2e,DKo,GKo,Zz,OKo,VKo,XKo,sv,_2e,zKo,QKo,eQ,WKo,HKo,UKo,lv,u2e,JKo,YKo,oQ,KKo,ZKo,eZo,iv,b2e,oZo,rZo,rQ,tZo,aZo,nZo,dv,v2e,sZo,lZo,tQ,iZo,dZo,cZo,cv,F2e,fZo,mZo,aQ,gZo,hZo,pZo,fv,_Zo,T2e,uZo,bZo,M2e,vZo,FZo,mv,ZVe,md,gv,E2e,h8,TZo,C2e,MZo,eXe,jo,p8,EZo,gd,CZo,nQ,wZo,AZo,sQ,LZo,yZo,xZo,_8,$Zo,w2e,kZo,SZo,RZo,pt,u8,PZo,A2e,BZo,NZo,hd,IZo,L2e,qZo,jZo,lQ,DZo,GZo,OZo,hv,VZo,no,b8,XZo,y2e,zZo,QZo,Xa,WZo,x2e,HZo,UZo,$2e,JZo,YZo,k2e,KZo,ZZo,eer,V,pv,S2e,oer,rer,iQ,ter,aer,ner,_v,R2e,ser,ler,dQ,ier,der,cer,uv,P2e,fer,mer,cQ,ger,her,per,bv,B2e,_er,uer,fQ,ber,ver,Fer,vv,N2e,Ter,Mer,mQ,Eer,Cer,wer,Fv,I2e,Aer,Ler,gQ,yer,xer,$er,Tv,q2e,ker,Ser,hQ,Rer,Per,Ber,Mv,j2e,Ner,Ier,pQ,qer,jer,Der,Ev,D2e,Ger,Oer,_Q,Ver,Xer,zer,Cv,G2e,Qer,Wer,uQ,Her,Uer,Jer,wv,O2e,Yer,Ker,bQ,Zer,eor,oor,Av,V2e,ror,tor,vQ,aor,nor,sor,Lv,X2e,lor,ior,FQ,dor,cor,mor,yv,z2e,gor,hor,TQ,por,_or,uor,xv,Q2e,bor,vor,MQ,For,Tor,Mor,$v,W2e,Eor,Cor,EQ,wor,Aor,Lor,kv,H2e,yor,xor,CQ,$or,kor,Sor,Sv,U2e,Ror,Por,wQ,Bor,Nor,Ior,Rv,J2e,qor,jor,AQ,Dor,Gor,Oor,Pv,Y2e,Vor,Xor,LQ,zor,Qor,Wor,Bv,K2e,Hor,Uor,yQ,Jor,Yor,Kor,Nv,Z2e,Zor,err,xQ,orr,rrr,trr,Iv,e1e,arr,nrr,$Q,srr,lrr,irr,qv,o1e,drr,crr,kQ,frr,mrr,grr,jv,r1e,hrr,prr,SQ,_rr,urr,brr,Dv,t1e,vrr,Frr,RQ,Trr,Mrr,Err,Gv,a1e,Crr,wrr,PQ,Arr,Lrr,yrr,Ov,n1e,xrr,$rr,BQ,krr,Srr,Rrr,Vv,s1e,Prr,Brr,NQ,Nrr,Irr,qrr,Xv,l1e,jrr,Drr,IQ,Grr,Orr,Vrr,zv,i1e,Xrr,zrr,qQ,Qrr,Wrr,Hrr,Qv,d1e,Urr,Jrr,jQ,Yrr,Krr,Zrr,Wv,c1e,etr,otr,DQ,rtr,ttr,atr,Hv,f1e,ntr,str,GQ,ltr,itr,dtr,Uv,m1e,ctr,ftr,OQ,mtr,gtr,htr,Jv,g1e,ptr,_tr,VQ,utr,btr,vtr,Yv,h1e,Ftr,Ttr,XQ,Mtr,Etr,Ctr,Kv,p1e,wtr,Atr,zQ,Ltr,ytr,xtr,Zv,_1e,$tr,ktr,QQ,Str,Rtr,Ptr,eF,u1e,Btr,Ntr,WQ,Itr,qtr,jtr,oF,b1e,Dtr,Gtr,HQ,Otr,Vtr,Xtr,rF,v1e,ztr,Qtr,UQ,Wtr,Htr,Utr,tF,Jtr,F1e,Ytr,Ktr,T1e,Ztr,ear,aF,oXe,pd,nF,M1e,v8,oar,E1e,rar,rXe,Do,F8,tar,_d,aar,JQ,nar,sar,YQ,lar,iar,dar,T8,car,C1e,far,mar,gar,_t,M8,har,w1e,par,_ar,ud,uar,A1e,bar,Far,KQ,Tar,Mar,Ear,sF,Car,so,E8,war,L1e,Aar,Lar,za,yar,y1e,xar,$ar,x1e,kar,Sar,$1e,Rar,Par,Bar,k1e,lF,S1e,Nar,Iar,ZQ,qar,jar,Dar,iF,Gar,R1e,Oar,Var,P1e,Xar,zar,dF,tXe,bd,cF,B1e,C8,Qar,N1e,War,aXe,Go,w8,Har,vd,Uar,eW,Jar,Yar,oW,Kar,Zar,enr,A8,onr,I1e,rnr,tnr,anr,ut,L8,nnr,q1e,snr,lnr,Fd,inr,j1e,dnr,cnr,rW,fnr,mnr,gnr,fF,hnr,lo,y8,pnr,D1e,_nr,unr,Qa,bnr,G1e,vnr,Fnr,O1e,Tnr,Mnr,V1e,Enr,Cnr,wnr,Fe,mF,X1e,Anr,Lnr,tW,ynr,xnr,$nr,gF,z1e,knr,Snr,aW,Rnr,Pnr,Bnr,hF,Q1e,Nnr,Inr,nW,qnr,jnr,Dnr,pF,W1e,Gnr,Onr,sW,Vnr,Xnr,znr,Hs,H1e,Qnr,Wnr,lW,Hnr,Unr,iW,Jnr,Ynr,Knr,_F,U1e,Znr,esr,dW,osr,rsr,tsr,Us,J1e,asr,nsr,cW,ssr,lsr,fW,isr,dsr,csr,bt,Y1e,fsr,msr,mW,gsr,hsr,gW,psr,_sr,hW,usr,bsr,vsr,uF,K1e,Fsr,Tsr,pW,Msr,Esr,Csr,bF,Z1e,wsr,Asr,_W,Lsr,ysr,xsr,vF,e7e,$sr,ksr,uW,Ssr,Rsr,Psr,FF,o7e,Bsr,Nsr,bW,Isr,qsr,jsr,TF,r7e,Dsr,Gsr,vW,Osr,Vsr,Xsr,MF,t7e,zsr,Qsr,FW,Wsr,Hsr,Usr,EF,a7e,Jsr,Ysr,TW,Ksr,Zsr,elr,CF,olr,n7e,rlr,tlr,s7e,alr,nlr,wF,nXe,Td,AF,l7e,x8,slr,i7e,llr,sXe,Oo,$8,ilr,Md,dlr,MW,clr,flr,EW,mlr,glr,hlr,k8,plr,d7e,_lr,ulr,blr,vt,S8,vlr,c7e,Flr,Tlr,Ed,Mlr,f7e,Elr,Clr,CW,wlr,Alr,Llr,LF,ylr,io,R8,xlr,m7e,$lr,klr,Wa,Slr,g7e,Rlr,Plr,h7e,Blr,Nlr,p7e,Ilr,qlr,jlr,_7e,yF,u7e,Dlr,Glr,wW,Olr,Vlr,Xlr,xF,zlr,b7e,Qlr,Wlr,v7e,Hlr,Ulr,$F,lXe,Cd,kF,F7e,P8,Jlr,T7e,Ylr,iXe,Vo,B8,Klr,wd,Zlr,AW,eir,oir,LW,rir,tir,air,N8,nir,M7e,sir,lir,iir,Ft,I8,dir,E7e,cir,fir,Ad,mir,C7e,gir,hir,yW,pir,_ir,uir,SF,bir,co,q8,vir,w7e,Fir,Tir,Ha,Mir,A7e,Eir,Cir,L7e,wir,Air,y7e,Lir,yir,xir,x7e,RF,$7e,$ir,kir,xW,Sir,Rir,Pir,PF,Bir,k7e,Nir,Iir,S7e,qir,jir,BF,dXe,Ld,NF,R7e,j8,Dir,P7e,Gir,cXe,Xo,D8,Oir,yd,Vir,$W,Xir,zir,kW,Qir,Wir,Hir,G8,Uir,B7e,Jir,Yir,Kir,Tt,O8,Zir,N7e,edr,odr,xd,rdr,I7e,tdr,adr,SW,ndr,sdr,ldr,IF,idr,fo,V8,ddr,q7e,cdr,fdr,Ua,mdr,j7e,gdr,hdr,D7e,pdr,_dr,G7e,udr,bdr,vdr,Pe,qF,O7e,Fdr,Tdr,RW,Mdr,Edr,Cdr,jF,V7e,wdr,Adr,PW,Ldr,ydr,xdr,DF,X7e,$dr,kdr,BW,Sdr,Rdr,Pdr,GF,z7e,Bdr,Ndr,NW,Idr,qdr,jdr,OF,Q7e,Ddr,Gdr,IW,Odr,Vdr,Xdr,VF,W7e,zdr,Qdr,qW,Wdr,Hdr,Udr,XF,H7e,Jdr,Ydr,jW,Kdr,Zdr,ecr,zF,U7e,ocr,rcr,DW,tcr,acr,ncr,QF,J7e,scr,lcr,GW,icr,dcr,ccr,WF,fcr,Y7e,mcr,gcr,K7e,hcr,pcr,HF,fXe,$d,UF,Z7e,X8,_cr,e4e,ucr,mXe,zo,z8,bcr,kd,vcr,OW,Fcr,Tcr,VW,Mcr,Ecr,Ccr,Q8,wcr,o4e,Acr,Lcr,ycr,Mt,W8,xcr,r4e,$cr,kcr,Sd,Scr,t4e,Rcr,Pcr,XW,Bcr,Ncr,Icr,JF,qcr,mo,H8,jcr,a4e,Dcr,Gcr,Ja,Ocr,n4e,Vcr,Xcr,s4e,zcr,Qcr,l4e,Wcr,Hcr,Ucr,ot,YF,i4e,Jcr,Ycr,zW,Kcr,Zcr,efr,KF,d4e,ofr,rfr,QW,tfr,afr,nfr,ZF,c4e,sfr,lfr,WW,ifr,dfr,cfr,eT,f4e,ffr,mfr,HW,gfr,hfr,pfr,oT,m4e,_fr,ufr,UW,bfr,vfr,Ffr,rT,Tfr,g4e,Mfr,Efr,h4e,Cfr,wfr,tT,gXe,Rd,aT,p4e,U8,Afr,_4e,Lfr,hXe,Qo,J8,yfr,Pd,xfr,JW,$fr,kfr,YW,Sfr,Rfr,Pfr,Y8,Bfr,u4e,Nfr,Ifr,qfr,Et,K8,jfr,b4e,Dfr,Gfr,Bd,Ofr,v4e,Vfr,Xfr,KW,zfr,Qfr,Wfr,nT,Hfr,go,Z8,Ufr,F4e,Jfr,Yfr,Ya,Kfr,T4e,Zfr,emr,M4e,omr,rmr,E4e,tmr,amr,nmr,Le,sT,C4e,smr,lmr,ZW,imr,dmr,cmr,lT,w4e,fmr,mmr,eH,gmr,hmr,pmr,iT,A4e,_mr,umr,oH,bmr,vmr,Fmr,dT,L4e,Tmr,Mmr,rH,Emr,Cmr,wmr,cT,y4e,Amr,Lmr,tH,ymr,xmr,$mr,fT,x4e,kmr,Smr,aH,Rmr,Pmr,Bmr,mT,$4e,Nmr,Imr,nH,qmr,jmr,Dmr,gT,k4e,Gmr,Omr,sH,Vmr,Xmr,zmr,hT,S4e,Qmr,Wmr,lH,Hmr,Umr,Jmr,pT,R4e,Ymr,Kmr,iH,Zmr,egr,ogr,_T,rgr,P4e,tgr,agr,B4e,ngr,sgr,uT,pXe,Nd,bT,N4e,e9,lgr,I4e,igr,_Xe,Wo,o9,dgr,Id,cgr,dH,fgr,mgr,cH,ggr,hgr,pgr,r9,_gr,q4e,ugr,bgr,vgr,Ct,t9,Fgr,j4e,Tgr,Mgr,qd,Egr,D4e,Cgr,wgr,fH,Agr,Lgr,ygr,vT,xgr,ho,a9,$gr,G4e,kgr,Sgr,Ka,Rgr,O4e,Pgr,Bgr,V4e,Ngr,Igr,X4e,qgr,jgr,Dgr,n9,FT,z4e,Ggr,Ogr,mH,Vgr,Xgr,zgr,TT,Q4e,Qgr,Wgr,gH,Hgr,Ugr,Jgr,MT,Ygr,W4e,Kgr,Zgr,H4e,ehr,ohr,ET,uXe,jd,CT,U4e,s9,rhr,J4e,thr,bXe,Ho,l9,ahr,Dd,nhr,hH,shr,lhr,pH,ihr,dhr,chr,i9,fhr,Y4e,mhr,ghr,hhr,wt,d9,phr,K4e,_hr,uhr,Gd,bhr,Z4e,vhr,Fhr,_H,Thr,Mhr,Ehr,wT,Chr,po,c9,whr,ebe,Ahr,Lhr,Za,yhr,obe,xhr,$hr,rbe,khr,Shr,tbe,Rhr,Phr,Bhr,rt,AT,abe,Nhr,Ihr,uH,qhr,jhr,Dhr,LT,nbe,Ghr,Ohr,bH,Vhr,Xhr,zhr,yT,sbe,Qhr,Whr,vH,Hhr,Uhr,Jhr,xT,lbe,Yhr,Khr,FH,Zhr,epr,opr,$T,ibe,rpr,tpr,TH,apr,npr,spr,kT,lpr,dbe,ipr,dpr,cbe,cpr,fpr,ST,vXe,Od,RT,fbe,f9,mpr,mbe,gpr,FXe,Uo,m9,hpr,Vd,ppr,MH,_pr,upr,EH,bpr,vpr,Fpr,g9,Tpr,gbe,Mpr,Epr,Cpr,At,h9,wpr,hbe,Apr,Lpr,Xd,ypr,pbe,xpr,$pr,CH,kpr,Spr,Rpr,PT,Ppr,_o,p9,Bpr,_be,Npr,Ipr,en,qpr,ube,jpr,Dpr,bbe,Gpr,Opr,vbe,Vpr,Xpr,zpr,zd,BT,Fbe,Qpr,Wpr,wH,Hpr,Upr,Jpr,NT,Tbe,Ypr,Kpr,AH,Zpr,e_r,o_r,IT,Mbe,r_r,t_r,LH,a_r,n_r,s_r,qT,l_r,Ebe,i_r,d_r,Cbe,c_r,f_r,jT,TXe,Qd,DT,wbe,_9,m_r,Abe,g_r,MXe,Jo,u9,h_r,Wd,p_r,yH,__r,u_r,xH,b_r,v_r,F_r,b9,T_r,Lbe,M_r,E_r,C_r,Lt,v9,w_r,ybe,A_r,L_r,Hd,y_r,xbe,x_r,$_r,$H,k_r,S_r,R_r,GT,P_r,uo,F9,B_r,$be,N_r,I_r,on,q_r,kbe,j_r,D_r,Sbe,G_r,O_r,Rbe,V_r,X_r,z_r,T9,OT,Pbe,Q_r,W_r,kH,H_r,U_r,J_r,VT,Bbe,Y_r,K_r,SH,Z_r,eur,our,XT,rur,Nbe,tur,aur,Ibe,nur,sur,zT,EXe,Ud,QT,qbe,M9,lur,jbe,iur,CXe,Yo,E9,dur,Jd,cur,RH,fur,mur,PH,gur,hur,pur,C9,_ur,Dbe,uur,bur,vur,yt,w9,Fur,Gbe,Tur,Mur,Yd,Eur,Obe,Cur,wur,BH,Aur,Lur,yur,WT,xur,bo,A9,$ur,Vbe,kur,Sur,rn,Rur,Xbe,Pur,Bur,zbe,Nur,Iur,Qbe,qur,jur,Dur,Wbe,HT,Hbe,Gur,Our,NH,Vur,Xur,zur,UT,Qur,Ube,Wur,Hur,Jbe,Uur,Jur,JT,wXe,Kd,YT,Ybe,L9,Yur,Kbe,Kur,AXe,Ko,y9,Zur,Zd,e2r,IH,o2r,r2r,qH,t2r,a2r,n2r,x9,s2r,Zbe,l2r,i2r,d2r,xt,$9,c2r,eve,f2r,m2r,ec,g2r,ove,h2r,p2r,jH,_2r,u2r,b2r,KT,v2r,vo,k9,F2r,rve,T2r,M2r,tn,E2r,tve,C2r,w2r,ave,A2r,L2r,nve,y2r,x2r,$2r,an,ZT,sve,k2r,S2r,DH,R2r,P2r,B2r,eM,lve,N2r,I2r,GH,q2r,j2r,D2r,oM,ive,G2r,O2r,OH,V2r,X2r,z2r,rM,dve,Q2r,W2r,VH,H2r,U2r,J2r,tM,Y2r,cve,K2r,Z2r,fve,e1r,o1r,aM,LXe,oc,nM,mve,S9,r1r,gve,t1r,yXe,Zo,R9,a1r,rc,n1r,XH,s1r,l1r,zH,i1r,d1r,c1r,P9,f1r,hve,m1r,g1r,h1r,$t,B9,p1r,pve,_1r,u1r,tc,b1r,_ve,v1r,F1r,QH,T1r,M1r,E1r,sM,C1r,Fo,N9,w1r,uve,A1r,L1r,nn,y1r,bve,x1r,$1r,vve,k1r,S1r,Fve,R1r,P1r,B1r,Tve,lM,Mve,N1r,I1r,WH,q1r,j1r,D1r,iM,G1r,Eve,O1r,V1r,Cve,X1r,z1r,dM,xXe,ac,cM,wve,I9,Q1r,Ave,W1r,$Xe,er,q9,H1r,nc,U1r,HH,J1r,Y1r,UH,K1r,Z1r,e7r,j9,o7r,Lve,r7r,t7r,a7r,kt,D9,n7r,yve,s7r,l7r,sc,i7r,xve,d7r,c7r,JH,f7r,m7r,g7r,fM,h7r,xr,G9,p7r,$ve,_7r,u7r,sn,b7r,kve,v7r,F7r,Sve,T7r,M7r,Rve,E7r,C7r,w7r,q,mM,Pve,A7r,L7r,YH,y7r,x7r,$7r,gM,Bve,k7r,S7r,KH,R7r,P7r,B7r,hM,Nve,N7r,I7r,ZH,q7r,j7r,D7r,pM,Ive,G7r,O7r,eU,V7r,X7r,z7r,_M,qve,Q7r,W7r,oU,H7r,U7r,J7r,uM,jve,Y7r,K7r,rU,Z7r,e4r,o4r,bM,Dve,r4r,t4r,tU,a4r,n4r,s4r,vM,Gve,l4r,i4r,aU,d4r,c4r,f4r,FM,Ove,m4r,g4r,nU,h4r,p4r,_4r,TM,Vve,u4r,b4r,sU,v4r,F4r,T4r,MM,Xve,M4r,E4r,lU,C4r,w4r,A4r,EM,zve,L4r,y4r,iU,x4r,$4r,k4r,CM,Qve,S4r,R4r,dU,P4r,B4r,N4r,wM,Wve,I4r,q4r,cU,j4r,D4r,G4r,AM,Hve,O4r,V4r,fU,X4r,z4r,Q4r,LM,Uve,W4r,H4r,mU,U4r,J4r,Y4r,yM,Jve,K4r,Z4r,gU,ebr,obr,rbr,Js,Yve,tbr,abr,hU,nbr,sbr,pU,lbr,ibr,dbr,xM,Kve,cbr,fbr,_U,mbr,gbr,hbr,$M,Zve,pbr,_br,uU,ubr,bbr,vbr,kM,eFe,Fbr,Tbr,bU,Mbr,Ebr,Cbr,SM,oFe,wbr,Abr,vU,Lbr,ybr,xbr,RM,rFe,$br,kbr,FU,Sbr,Rbr,Pbr,PM,tFe,Bbr,Nbr,TU,Ibr,qbr,jbr,BM,aFe,Dbr,Gbr,MU,Obr,Vbr,Xbr,NM,nFe,zbr,Qbr,EU,Wbr,Hbr,Ubr,IM,sFe,Jbr,Ybr,CU,Kbr,Zbr,evr,qM,lFe,ovr,rvr,wU,tvr,avr,nvr,jM,iFe,svr,lvr,AU,ivr,dvr,cvr,DM,dFe,fvr,mvr,LU,gvr,hvr,pvr,GM,cFe,_vr,uvr,yU,bvr,vvr,Fvr,OM,fFe,Tvr,Mvr,xU,Evr,Cvr,wvr,VM,mFe,Avr,Lvr,$U,yvr,xvr,$vr,XM,gFe,kvr,Svr,kU,Rvr,Pvr,Bvr,zM,hFe,Nvr,Ivr,SU,qvr,jvr,Dvr,QM,pFe,Gvr,Ovr,RU,Vvr,Xvr,zvr,WM,_Fe,Qvr,Wvr,PU,Hvr,Uvr,Jvr,HM,uFe,Yvr,Kvr,BU,Zvr,eFr,oFr,UM,bFe,rFr,tFr,NU,aFr,nFr,sFr,JM,vFe,lFr,iFr,IU,dFr,cFr,fFr,YM,FFe,mFr,gFr,qU,hFr,pFr,_Fr,KM,TFe,uFr,bFr,jU,vFr,FFr,TFr,ZM,MFe,MFr,EFr,DU,CFr,wFr,AFr,eE,EFe,LFr,yFr,GU,xFr,$Fr,kFr,oE,CFe,SFr,RFr,OU,PFr,BFr,NFr,rE,wFe,IFr,qFr,VU,jFr,DFr,GFr,tE,AFe,OFr,VFr,XU,XFr,zFr,QFr,aE,LFe,WFr,HFr,zU,UFr,JFr,YFr,nE,yFe,KFr,ZFr,QU,eTr,oTr,rTr,sE,kXe,lc,lE,xFe,O9,tTr,$Fe,aTr,SXe,or,V9,nTr,ic,sTr,WU,lTr,iTr,HU,dTr,cTr,fTr,X9,mTr,kFe,gTr,hTr,pTr,St,z9,_Tr,SFe,uTr,bTr,dc,vTr,RFe,FTr,TTr,UU,MTr,ETr,CTr,iE,wTr,$r,Q9,ATr,PFe,LTr,yTr,ln,xTr,BFe,$Tr,kTr,NFe,STr,RTr,IFe,PTr,BTr,NTr,se,dE,qFe,ITr,qTr,JU,jTr,DTr,GTr,cE,jFe,OTr,VTr,YU,XTr,zTr,QTr,fE,DFe,WTr,HTr,KU,UTr,JTr,YTr,mE,GFe,KTr,ZTr,ZU,eMr,oMr,rMr,gE,OFe,tMr,aMr,eJ,nMr,sMr,lMr,hE,VFe,iMr,dMr,oJ,cMr,fMr,mMr,pE,XFe,gMr,hMr,rJ,pMr,_Mr,uMr,_E,zFe,bMr,vMr,tJ,FMr,TMr,MMr,uE,QFe,EMr,CMr,aJ,wMr,AMr,LMr,bE,WFe,yMr,xMr,nJ,$Mr,kMr,SMr,vE,HFe,RMr,PMr,sJ,BMr,NMr,IMr,FE,UFe,qMr,jMr,lJ,DMr,GMr,OMr,TE,JFe,VMr,XMr,iJ,zMr,QMr,WMr,ME,YFe,HMr,UMr,dJ,JMr,YMr,KMr,EE,KFe,ZMr,eEr,cJ,oEr,rEr,tEr,CE,ZFe,aEr,nEr,fJ,sEr,lEr,iEr,wE,eTe,dEr,cEr,mJ,fEr,mEr,gEr,AE,oTe,hEr,pEr,gJ,_Er,uEr,bEr,LE,rTe,vEr,FEr,hJ,TEr,MEr,EEr,yE,tTe,CEr,wEr,pJ,AEr,LEr,yEr,xE,aTe,xEr,$Er,_J,kEr,SEr,REr,$E,nTe,PEr,BEr,uJ,NEr,IEr,qEr,kE,sTe,jEr,DEr,bJ,GEr,OEr,VEr,SE,RXe,cc,RE,lTe,W9,XEr,iTe,zEr,PXe,rr,H9,QEr,fc,WEr,vJ,HEr,UEr,FJ,JEr,YEr,KEr,U9,ZEr,dTe,eCr,oCr,rCr,Rt,J9,tCr,cTe,aCr,nCr,mc,sCr,fTe,lCr,iCr,TJ,dCr,cCr,fCr,PE,mCr,kr,Y9,gCr,mTe,hCr,pCr,dn,_Cr,gTe,uCr,bCr,hTe,vCr,FCr,pTe,TCr,MCr,ECr,Me,BE,_Te,CCr,wCr,MJ,ACr,LCr,yCr,NE,uTe,xCr,$Cr,EJ,kCr,SCr,RCr,IE,bTe,PCr,BCr,CJ,NCr,ICr,qCr,qE,vTe,jCr,DCr,wJ,GCr,OCr,VCr,jE,FTe,XCr,zCr,AJ,QCr,WCr,HCr,DE,TTe,UCr,JCr,LJ,YCr,KCr,ZCr,GE,MTe,e3r,o3r,yJ,r3r,t3r,a3r,OE,ETe,n3r,s3r,xJ,l3r,i3r,d3r,VE,CTe,c3r,f3r,$J,m3r,g3r,h3r,XE,wTe,p3r,_3r,kJ,u3r,b3r,v3r,zE,ATe,F3r,T3r,SJ,M3r,E3r,C3r,QE,LTe,w3r,A3r,RJ,L3r,y3r,x3r,WE,yTe,$3r,k3r,PJ,S3r,R3r,P3r,HE,BXe,gc,UE,xTe,K9,B3r,$Te,N3r,NXe,tr,Z9,I3r,hc,q3r,BJ,j3r,D3r,NJ,G3r,O3r,V3r,ex,X3r,kTe,z3r,Q3r,W3r,Pt,ox,H3r,STe,U3r,J3r,pc,Y3r,RTe,K3r,Z3r,IJ,e5r,o5r,r5r,JE,t5r,Sr,rx,a5r,PTe,n5r,s5r,cn,l5r,BTe,i5r,d5r,NTe,c5r,f5r,ITe,m5r,g5r,h5r,ar,YE,qTe,p5r,_5r,qJ,u5r,b5r,v5r,KE,jTe,F5r,T5r,jJ,M5r,E5r,C5r,ZE,DTe,w5r,A5r,DJ,L5r,y5r,x5r,eC,GTe,$5r,k5r,GJ,S5r,R5r,P5r,oC,OTe,B5r,N5r,OJ,I5r,q5r,j5r,rC,VTe,D5r,G5r,VJ,O5r,V5r,X5r,tC,IXe,_c,aC,XTe,tx,z5r,zTe,Q5r,qXe,nr,ax,W5r,uc,H5r,XJ,U5r,J5r,zJ,Y5r,K5r,Z5r,nx,e0r,QTe,o0r,r0r,t0r,Bt,sx,a0r,WTe,n0r,s0r,bc,l0r,HTe,i0r,d0r,QJ,c0r,f0r,m0r,nC,g0r,Rr,lx,h0r,UTe,p0r,_0r,fn,u0r,JTe,b0r,v0r,YTe,F0r,T0r,KTe,M0r,E0r,C0r,ie,sC,ZTe,w0r,A0r,WJ,L0r,y0r,x0r,lC,eMe,$0r,k0r,HJ,S0r,R0r,P0r,iC,oMe,B0r,N0r,UJ,I0r,q0r,j0r,dC,rMe,D0r,G0r,JJ,O0r,V0r,X0r,cC,tMe,z0r,Q0r,YJ,W0r,H0r,U0r,fC,aMe,J0r,Y0r,KJ,K0r,Z0r,ewr,mC,nMe,owr,rwr,ZJ,twr,awr,nwr,gC,sMe,swr,lwr,eY,iwr,dwr,cwr,hC,lMe,fwr,mwr,oY,gwr,hwr,pwr,pC,iMe,_wr,uwr,rY,bwr,vwr,Fwr,_C,dMe,Twr,Mwr,tY,Ewr,Cwr,wwr,uC,cMe,Awr,Lwr,aY,ywr,xwr,$wr,bC,fMe,kwr,Swr,nY,Rwr,Pwr,Bwr,vC,mMe,Nwr,Iwr,sY,qwr,jwr,Dwr,FC,gMe,Gwr,Owr,lY,Vwr,Xwr,zwr,TC,hMe,Qwr,Wwr,iY,Hwr,Uwr,Jwr,MC,pMe,Ywr,Kwr,dY,Zwr,eAr,oAr,EC,_Me,rAr,tAr,cY,aAr,nAr,sAr,CC,uMe,lAr,iAr,fY,dAr,cAr,fAr,wC,bMe,mAr,gAr,mY,hAr,pAr,_Ar,AC,jXe,vc,LC,vMe,ix,uAr,FMe,bAr,DXe,sr,dx,vAr,Fc,FAr,gY,TAr,MAr,hY,EAr,CAr,wAr,cx,AAr,TMe,LAr,yAr,xAr,Nt,fx,$Ar,MMe,kAr,SAr,Tc,RAr,EMe,PAr,BAr,pY,NAr,IAr,qAr,yC,jAr,Pr,mx,DAr,CMe,GAr,OAr,mn,VAr,wMe,XAr,zAr,AMe,QAr,WAr,LMe,HAr,UAr,JAr,ye,xC,yMe,YAr,KAr,_Y,ZAr,e6r,o6r,$C,xMe,r6r,t6r,uY,a6r,n6r,s6r,kC,$Me,l6r,i6r,bY,d6r,c6r,f6r,SC,kMe,m6r,g6r,vY,h6r,p6r,_6r,RC,SMe,u6r,b6r,FY,v6r,F6r,T6r,PC,RMe,M6r,E6r,TY,C6r,w6r,A6r,BC,PMe,L6r,y6r,MY,x6r,$6r,k6r,NC,BMe,S6r,R6r,EY,P6r,B6r,N6r,IC,NMe,I6r,q6r,CY,j6r,D6r,G6r,qC,IMe,O6r,V6r,wY,X6r,z6r,Q6r,jC,GXe,Mc,DC,qMe,gx,W6r,jMe,H6r,OXe,lr,hx,U6r,Ec,J6r,AY,Y6r,K6r,LY,Z6r,eLr,oLr,px,rLr,DMe,tLr,aLr,nLr,It,_x,sLr,GMe,lLr,iLr,Cc,dLr,OMe,cLr,fLr,yY,mLr,gLr,hLr,GC,pLr,Br,ux,_Lr,VMe,uLr,bLr,gn,vLr,XMe,FLr,TLr,zMe,MLr,ELr,QMe,CLr,wLr,ALr,te,OC,WMe,LLr,yLr,xY,xLr,$Lr,kLr,VC,HMe,SLr,RLr,$Y,PLr,BLr,NLr,XC,UMe,ILr,qLr,kY,jLr,DLr,GLr,zC,JMe,OLr,VLr,SY,XLr,zLr,QLr,QC,YMe,WLr,HLr,RY,ULr,JLr,YLr,WC,KMe,KLr,ZLr,PY,eyr,oyr,ryr,HC,ZMe,tyr,ayr,BY,nyr,syr,lyr,UC,eEe,iyr,dyr,NY,cyr,fyr,myr,JC,oEe,gyr,hyr,IY,pyr,_yr,uyr,YC,rEe,byr,vyr,qY,Fyr,Tyr,Myr,KC,tEe,Eyr,Cyr,jY,wyr,Ayr,Lyr,ZC,aEe,yyr,xyr,DY,$yr,kyr,Syr,e3,nEe,Ryr,Pyr,GY,Byr,Nyr,Iyr,o3,sEe,qyr,jyr,OY,Dyr,Gyr,Oyr,r3,lEe,Vyr,Xyr,VY,zyr,Qyr,Wyr,t3,iEe,Hyr,Uyr,XY,Jyr,Yyr,Kyr,a3,dEe,Zyr,e8r,zY,o8r,r8r,t8r,n3,cEe,a8r,n8r,QY,s8r,l8r,i8r,s3,fEe,d8r,c8r,WY,f8r,m8r,g8r,l3,mEe,h8r,p8r,HY,_8r,u8r,b8r,i3,gEe,v8r,F8r,UY,T8r,M8r,E8r,d3,hEe,C8r,w8r,JY,A8r,L8r,y8r,c3,pEe,x8r,$8r,YY,k8r,S8r,R8r,f3,_Ee,P8r,B8r,KY,N8r,I8r,q8r,m3,uEe,j8r,D8r,ZY,G8r,O8r,V8r,g3,bEe,X8r,z8r,eK,Q8r,W8r,H8r,h3,VXe,wc,p3,vEe,bx,U8r,FEe,J8r,XXe,ir,vx,Y8r,Ac,K8r,oK,Z8r,e9r,rK,o9r,r9r,t9r,Fx,a9r,TEe,n9r,s9r,l9r,qt,Tx,i9r,MEe,d9r,c9r,Lc,f9r,EEe,m9r,g9r,tK,h9r,p9r,_9r,_3,u9r,Nr,Mx,b9r,CEe,v9r,F9r,hn,T9r,wEe,M9r,E9r,AEe,C9r,w9r,LEe,A9r,L9r,y9r,_e,u3,yEe,x9r,$9r,aK,k9r,S9r,R9r,b3,xEe,P9r,B9r,nK,N9r,I9r,q9r,v3,$Ee,j9r,D9r,sK,G9r,O9r,V9r,F3,kEe,X9r,z9r,lK,Q9r,W9r,H9r,T3,SEe,U9r,J9r,iK,Y9r,K9r,Z9r,M3,REe,exr,oxr,dK,rxr,txr,axr,E3,PEe,nxr,sxr,cK,lxr,ixr,dxr,C3,BEe,cxr,fxr,fK,mxr,gxr,hxr,w3,NEe,pxr,_xr,mK,uxr,bxr,vxr,A3,IEe,Fxr,Txr,gK,Mxr,Exr,Cxr,L3,qEe,wxr,Axr,hK,Lxr,yxr,xxr,y3,jEe,$xr,kxr,pK,Sxr,Rxr,Pxr,x3,DEe,Bxr,Nxr,_K,Ixr,qxr,jxr,$3,GEe,Dxr,Gxr,uK,Oxr,Vxr,Xxr,k3,OEe,zxr,Qxr,bK,Wxr,Hxr,Uxr,S3,VEe,Jxr,Yxr,vK,Kxr,Zxr,e$r,R3,XEe,o$r,r$r,FK,t$r,a$r,n$r,P3,zXe,yc,B3,zEe,Ex,s$r,QEe,l$r,QXe,dr,Cx,i$r,xc,d$r,TK,c$r,f$r,MK,m$r,g$r,h$r,wx,p$r,WEe,_$r,u$r,b$r,jt,Ax,v$r,HEe,F$r,T$r,$c,M$r,UEe,E$r,C$r,EK,w$r,A$r,L$r,N3,y$r,Ir,Lx,x$r,JEe,$$r,k$r,pn,S$r,YEe,R$r,P$r,KEe,B$r,N$r,ZEe,I$r,q$r,j$r,yx,I3,eCe,D$r,G$r,CK,O$r,V$r,X$r,q3,oCe,z$r,Q$r,wK,W$r,H$r,U$r,j3,WXe,kc,D3,rCe,xx,J$r,tCe,Y$r,HXe,cr,$x,K$r,Sc,Z$r,AK,ekr,okr,LK,rkr,tkr,akr,kx,nkr,aCe,skr,lkr,ikr,Dt,Sx,dkr,nCe,ckr,fkr,Rc,mkr,sCe,gkr,hkr,yK,pkr,_kr,ukr,G3,bkr,qr,Rx,vkr,lCe,Fkr,Tkr,_n,Mkr,iCe,Ekr,Ckr,dCe,wkr,Akr,cCe,Lkr,ykr,xkr,fCe,O3,mCe,$kr,kkr,xK,Skr,Rkr,Pkr,V3,UXe,Pc,X3,gCe,Px,Bkr,hCe,Nkr,JXe,fr,Bx,Ikr,Bc,qkr,$K,jkr,Dkr,kK,Gkr,Okr,Vkr,Nx,Xkr,pCe,zkr,Qkr,Wkr,Gt,Ix,Hkr,_Ce,Ukr,Jkr,Nc,Ykr,uCe,Kkr,Zkr,SK,eSr,oSr,rSr,z3,tSr,jr,qx,aSr,bCe,nSr,sSr,un,lSr,vCe,iSr,dSr,FCe,cSr,fSr,TCe,mSr,gSr,hSr,de,Q3,MCe,pSr,_Sr,RK,uSr,bSr,vSr,W3,ECe,FSr,TSr,PK,MSr,ESr,CSr,H3,CCe,wSr,ASr,BK,LSr,ySr,xSr,U3,wCe,$Sr,kSr,NK,SSr,RSr,PSr,J3,ACe,BSr,NSr,IK,ISr,qSr,jSr,Y3,LCe,DSr,GSr,qK,OSr,VSr,XSr,K3,yCe,zSr,QSr,jK,WSr,HSr,USr,Z3,xCe,JSr,YSr,DK,KSr,ZSr,eRr,e5,$Ce,oRr,rRr,GK,tRr,aRr,nRr,o5,kCe,sRr,lRr,OK,iRr,dRr,cRr,r5,SCe,fRr,mRr,VK,gRr,hRr,pRr,t5,RCe,_Rr,uRr,XK,bRr,vRr,FRr,a5,PCe,TRr,MRr,zK,ERr,CRr,wRr,n5,BCe,ARr,LRr,QK,yRr,xRr,$Rr,s5,NCe,kRr,SRr,WK,RRr,PRr,BRr,l5,ICe,NRr,IRr,HK,qRr,jRr,DRr,i5,qCe,GRr,ORr,UK,VRr,XRr,zRr,d5,jCe,QRr,WRr,JK,HRr,URr,JRr,c5,DCe,YRr,KRr,YK,ZRr,ePr,oPr,f5,GCe,rPr,tPr,KK,aPr,nPr,sPr,m5,YXe,Ic,g5,OCe,jx,lPr,VCe,iPr,KXe,mr,Dx,dPr,qc,cPr,ZK,fPr,mPr,eZ,gPr,hPr,pPr,Gx,_Pr,XCe,uPr,bPr,vPr,Ot,Ox,FPr,zCe,TPr,MPr,jc,EPr,QCe,CPr,wPr,oZ,APr,LPr,yPr,h5,xPr,Dr,Vx,$Pr,WCe,kPr,SPr,bn,RPr,HCe,PPr,BPr,UCe,NPr,IPr,JCe,qPr,jPr,DPr,ce,p5,YCe,GPr,OPr,rZ,VPr,XPr,zPr,_5,KCe,QPr,WPr,tZ,HPr,UPr,JPr,u5,ZCe,YPr,KPr,aZ,ZPr,eBr,oBr,b5,e3e,rBr,tBr,nZ,aBr,nBr,sBr,v5,o3e,lBr,iBr,sZ,dBr,cBr,fBr,F5,r3e,mBr,gBr,lZ,hBr,pBr,_Br,T5,t3e,uBr,bBr,iZ,vBr,FBr,TBr,M5,a3e,MBr,EBr,dZ,CBr,wBr,ABr,E5,n3e,LBr,yBr,cZ,xBr,$Br,kBr,C5,s3e,SBr,RBr,fZ,PBr,BBr,NBr,w5,l3e,IBr,qBr,mZ,jBr,DBr,GBr,A5,i3e,OBr,VBr,gZ,XBr,zBr,QBr,L5,d3e,WBr,HBr,hZ,UBr,JBr,YBr,y5,c3e,KBr,ZBr,pZ,eNr,oNr,rNr,x5,f3e,tNr,aNr,_Z,nNr,sNr,lNr,$5,m3e,iNr,dNr,uZ,cNr,fNr,mNr,k5,g3e,gNr,hNr,bZ,pNr,_Nr,uNr,S5,h3e,bNr,vNr,vZ,FNr,TNr,MNr,R5,p3e,ENr,CNr,FZ,wNr,ANr,LNr,P5,_3e,yNr,xNr,TZ,$Nr,kNr,SNr,B5,ZXe,Dc,N5,u3e,Xx,RNr,b3e,PNr,eze,gr,zx,BNr,Gc,NNr,MZ,INr,qNr,EZ,jNr,DNr,GNr,Qx,ONr,v3e,VNr,XNr,zNr,Vt,Wx,QNr,F3e,WNr,HNr,Oc,UNr,T3e,JNr,YNr,CZ,KNr,ZNr,eIr,I5,oIr,Gr,Hx,rIr,M3e,tIr,aIr,vn,nIr,E3e,sIr,lIr,C3e,iIr,dIr,w3e,cIr,fIr,mIr,A3e,q5,L3e,gIr,hIr,wZ,pIr,_Ir,uIr,j5,oze,Vc,D5,y3e,Ux,bIr,x3e,vIr,rze,hr,Jx,FIr,Xc,TIr,AZ,MIr,EIr,LZ,CIr,wIr,AIr,Yx,LIr,$3e,yIr,xIr,$Ir,Xt,Kx,kIr,k3e,SIr,RIr,zc,PIr,S3e,BIr,NIr,yZ,IIr,qIr,jIr,G5,DIr,Or,Zx,GIr,R3e,OIr,VIr,Fn,XIr,P3e,zIr,QIr,B3e,WIr,HIr,N3e,UIr,JIr,YIr,I3e,O5,q3e,KIr,ZIr,xZ,eqr,oqr,rqr,V5,tze,Qc,X5,j3e,e$,tqr,D3e,aqr,aze,pr,o$,nqr,Wc,sqr,$Z,lqr,iqr,kZ,dqr,cqr,fqr,r$,mqr,G3e,gqr,hqr,pqr,zt,t$,_qr,O3e,uqr,bqr,Hc,vqr,V3e,Fqr,Tqr,SZ,Mqr,Eqr,Cqr,z5,wqr,Vr,a$,Aqr,X3e,Lqr,yqr,Tn,xqr,z3e,$qr,kqr,Q3e,Sqr,Rqr,W3e,Pqr,Bqr,Nqr,oe,Q5,H3e,Iqr,qqr,RZ,jqr,Dqr,Gqr,W5,U3e,Oqr,Vqr,PZ,Xqr,zqr,Qqr,H5,J3e,Wqr,Hqr,BZ,Uqr,Jqr,Yqr,U5,Y3e,Kqr,Zqr,NZ,ejr,ojr,rjr,J5,K3e,tjr,ajr,IZ,njr,sjr,ljr,Y5,Z3e,ijr,djr,qZ,cjr,fjr,mjr,K5,e5e,gjr,hjr,jZ,pjr,_jr,ujr,Z5,o5e,bjr,vjr,DZ,Fjr,Tjr,Mjr,e0,r5e,Ejr,Cjr,GZ,wjr,Ajr,Ljr,o0,t5e,yjr,xjr,OZ,$jr,kjr,Sjr,r0,a5e,Rjr,Pjr,VZ,Bjr,Njr,Ijr,t0,n5e,qjr,jjr,XZ,Djr,Gjr,Ojr,a0,s5e,Vjr,Xjr,zZ,zjr,Qjr,Wjr,n0,l5e,Hjr,Ujr,QZ,Jjr,Yjr,Kjr,s0,i5e,Zjr,eDr,WZ,oDr,rDr,tDr,l0,d5e,aDr,nDr,HZ,sDr,lDr,iDr,i0,c5e,dDr,cDr,UZ,fDr,mDr,gDr,d0,f5e,hDr,pDr,JZ,_Dr,uDr,bDr,c0,m5e,vDr,FDr,YZ,TDr,MDr,EDr,f0,g5e,CDr,wDr,KZ,ADr,LDr,yDr,m0,h5e,xDr,$Dr,ZZ,kDr,SDr,RDr,g0,p5e,PDr,BDr,eee,NDr,IDr,qDr,h0,_5e,jDr,DDr,oee,GDr,ODr,VDr,p0,u5e,XDr,zDr,ree,QDr,WDr,HDr,_0,b5e,UDr,JDr,tee,YDr,KDr,ZDr,u0,v5e,eGr,oGr,aee,rGr,tGr,aGr,b0,F5e,nGr,sGr,nee,lGr,iGr,dGr,v0,nze,Uc,F0,T5e,n$,cGr,M5e,fGr,sze,_r,s$,mGr,Jc,gGr,see,hGr,pGr,lee,_Gr,uGr,bGr,l$,vGr,E5e,FGr,TGr,MGr,Qt,i$,EGr,C5e,CGr,wGr,Yc,AGr,w5e,LGr,yGr,iee,xGr,$Gr,kGr,T0,SGr,Xr,d$,RGr,A5e,PGr,BGr,Mn,NGr,L5e,IGr,qGr,y5e,jGr,DGr,x5e,GGr,OGr,VGr,xe,M0,$5e,XGr,zGr,dee,QGr,WGr,HGr,E0,k5e,UGr,JGr,cee,YGr,KGr,ZGr,C0,S5e,eOr,oOr,fee,rOr,tOr,aOr,w0,R5e,nOr,sOr,mee,lOr,iOr,dOr,A0,P5e,cOr,fOr,gee,mOr,gOr,hOr,L0,B5e,pOr,_Or,hee,uOr,bOr,vOr,y0,N5e,FOr,TOr,pee,MOr,EOr,COr,x0,I5e,wOr,AOr,_ee,LOr,yOr,xOr,$0,q5e,$Or,kOr,uee,SOr,ROr,POr,k0,j5e,BOr,NOr,bee,IOr,qOr,jOr,S0,lze,Kc,R0,D5e,c$,DOr,G5e,GOr,ize,ur,f$,OOr,Zc,VOr,vee,XOr,zOr,Fee,QOr,WOr,HOr,m$,UOr,O5e,JOr,YOr,KOr,Wt,g$,ZOr,V5e,eVr,oVr,ef,rVr,X5e,tVr,aVr,Tee,nVr,sVr,lVr,P0,iVr,zr,h$,dVr,z5e,cVr,fVr,En,mVr,Q5e,gVr,hVr,W5e,pVr,_Vr,H5e,uVr,bVr,vVr,Ee,B0,U5e,FVr,TVr,Mee,MVr,EVr,CVr,N0,J5e,wVr,AVr,Eee,LVr,yVr,xVr,I0,Y5e,$Vr,kVr,Cee,SVr,RVr,PVr,q0,K5e,BVr,NVr,wee,IVr,qVr,jVr,j0,Z5e,DVr,GVr,Aee,OVr,VVr,XVr,D0,e0e,zVr,QVr,Lee,WVr,HVr,UVr,G0,o0e,JVr,YVr,yee,KVr,ZVr,eXr,O0,r0e,oXr,rXr,xee,tXr,aXr,nXr,V0,t0e,sXr,lXr,$ee,iXr,dXr,cXr,X0,a0e,fXr,mXr,kee,gXr,hXr,pXr,z0,n0e,_Xr,uXr,See,bXr,vXr,FXr,Q0,s0e,TXr,MXr,Ree,EXr,CXr,wXr,W0,l0e,AXr,LXr,Pee,yXr,xXr,$Xr,H0,dze,of,U0,i0e,p$,kXr,d0e,SXr,cze,br,_$,RXr,rf,PXr,Bee,BXr,NXr,Nee,IXr,qXr,jXr,u$,DXr,c0e,GXr,OXr,VXr,Ht,b$,XXr,f0e,zXr,QXr,tf,WXr,m0e,HXr,UXr,Iee,JXr,YXr,KXr,J0,ZXr,Qr,v$,ezr,g0e,ozr,rzr,Cn,tzr,h0e,azr,nzr,p0e,szr,lzr,_0e,izr,dzr,czr,$e,Y0,u0e,fzr,mzr,qee,gzr,hzr,pzr,K0,b0e,_zr,uzr,jee,bzr,vzr,Fzr,Z0,v0e,Tzr,Mzr,Dee,Ezr,Czr,wzr,ew,F0e,Azr,Lzr,Gee,yzr,xzr,$zr,ow,T0e,kzr,Szr,Oee,Rzr,Pzr,Bzr,rw,M0e,Nzr,Izr,Vee,qzr,jzr,Dzr,tw,E0e,Gzr,Ozr,Xee,Vzr,Xzr,zzr,aw,C0e,Qzr,Wzr,zee,Hzr,Uzr,Jzr,nw,w0e,Yzr,Kzr,Qee,Zzr,eQr,oQr,sw,A0e,rQr,tQr,Wee,aQr,nQr,sQr,lw,fze,af,iw,L0e,F$,lQr,y0e,iQr,mze,vr,T$,dQr,nf,cQr,Hee,fQr,mQr,Uee,gQr,hQr,pQr,M$,_Qr,x0e,uQr,bQr,vQr,Ut,E$,FQr,$0e,TQr,MQr,sf,EQr,k0e,CQr,wQr,Jee,AQr,LQr,yQr,dw,xQr,Wr,C$,$Qr,S0e,kQr,SQr,wn,RQr,R0e,PQr,BQr,P0e,NQr,IQr,B0e,qQr,jQr,DQr,ke,cw,N0e,GQr,OQr,Yee,VQr,XQr,zQr,fw,I0e,QQr,WQr,Kee,HQr,UQr,JQr,mw,q0e,YQr,KQr,Zee,ZQr,eWr,oWr,gw,j0e,rWr,tWr,eoe,aWr,nWr,sWr,hw,D0e,lWr,iWr,ooe,dWr,cWr,fWr,pw,G0e,mWr,gWr,roe,hWr,pWr,_Wr,_w,O0e,uWr,bWr,toe,vWr,FWr,TWr,uw,V0e,MWr,EWr,aoe,CWr,wWr,AWr,bw,X0e,LWr,yWr,noe,xWr,$Wr,kWr,vw,z0e,SWr,RWr,soe,PWr,BWr,NWr,Fw,gze,lf,Tw,Q0e,w$,IWr,W0e,qWr,hze,Fr,A$,jWr,df,DWr,loe,GWr,OWr,ioe,VWr,XWr,zWr,L$,QWr,H0e,WWr,HWr,UWr,Jt,y$,JWr,U0e,YWr,KWr,cf,ZWr,J0e,eHr,oHr,doe,rHr,tHr,aHr,Mw,nHr,Hr,x$,sHr,Y0e,lHr,iHr,An,dHr,K0e,cHr,fHr,Z0e,mHr,gHr,ewe,hHr,pHr,_Hr,Se,Ew,owe,uHr,bHr,coe,vHr,FHr,THr,Cw,rwe,MHr,EHr,foe,CHr,wHr,AHr,ww,twe,LHr,yHr,moe,xHr,$Hr,kHr,Aw,awe,SHr,RHr,goe,PHr,BHr,NHr,Lw,nwe,IHr,qHr,hoe,jHr,DHr,GHr,yw,swe,OHr,VHr,poe,XHr,zHr,QHr,xw,lwe,WHr,HHr,_oe,UHr,JHr,YHr,$w,iwe,KHr,ZHr,uoe,eUr,oUr,rUr,kw,dwe,tUr,aUr,boe,nUr,sUr,lUr,Sw,cwe,iUr,dUr,voe,cUr,fUr,mUr,Rw,pze,ff,Pw,fwe,$$,gUr,mwe,hUr,_ze,Tr,k$,pUr,mf,_Ur,Foe,uUr,bUr,Toe,vUr,FUr,TUr,S$,MUr,gwe,EUr,CUr,wUr,Yt,R$,AUr,hwe,LUr,yUr,gf,xUr,pwe,$Ur,kUr,Moe,SUr,RUr,PUr,Bw,BUr,Ur,P$,NUr,_we,IUr,qUr,Ln,jUr,uwe,DUr,GUr,bwe,OUr,VUr,vwe,XUr,zUr,QUr,Re,Nw,Fwe,WUr,HUr,Eoe,UUr,JUr,YUr,Iw,Twe,KUr,ZUr,Coe,eJr,oJr,rJr,qw,Mwe,tJr,aJr,woe,nJr,sJr,lJr,jw,Ewe,iJr,dJr,Aoe,cJr,fJr,mJr,Dw,Cwe,gJr,hJr,Loe,pJr,_Jr,uJr,Gw,wwe,bJr,vJr,yoe,FJr,TJr,MJr,Ow,Awe,EJr,CJr,xoe,wJr,AJr,LJr,Vw,Lwe,yJr,xJr,$oe,$Jr,kJr,SJr,Xw,ywe,RJr,PJr,koe,BJr,NJr,IJr,zw,xwe,qJr,jJr,Soe,DJr,GJr,OJr,Qw,uze,hf,Ww,$we,B$,VJr,kwe,XJr,bze,Mr,N$,zJr,pf,QJr,Roe,WJr,HJr,Poe,UJr,JJr,YJr,I$,KJr,Swe,ZJr,eYr,oYr,Kt,q$,rYr,Rwe,tYr,aYr,_f,nYr,Pwe,sYr,lYr,Boe,iYr,dYr,cYr,Hw,fYr,Jr,j$,mYr,Bwe,gYr,hYr,yn,pYr,Nwe,_Yr,uYr,Iwe,bYr,vYr,qwe,FYr,TYr,MYr,Ve,Uw,jwe,EYr,CYr,Noe,wYr,AYr,LYr,Jw,Dwe,yYr,xYr,Ioe,$Yr,kYr,SYr,Yw,Gwe,RYr,PYr,qoe,BYr,NYr,IYr,Kw,Owe,qYr,jYr,joe,DYr,GYr,OYr,Zw,Vwe,VYr,XYr,Doe,zYr,QYr,WYr,eA,Xwe,HYr,UYr,Goe,JYr,YYr,KYr,oA,zwe,ZYr,eKr,Ooe,oKr,rKr,tKr,rA,Qwe,aKr,nKr,Voe,sKr,lKr,iKr,tA,vze,uf,aA,Wwe,D$,dKr,Hwe,cKr,Fze,Er,G$,fKr,bf,mKr,Xoe,gKr,hKr,zoe,pKr,_Kr,uKr,O$,bKr,Uwe,vKr,FKr,TKr,Zt,V$,MKr,Jwe,EKr,CKr,vf,wKr,Ywe,AKr,LKr,Qoe,yKr,xKr,$Kr,nA,kKr,Yr,X$,SKr,Kwe,RKr,PKr,xn,BKr,Zwe,NKr,IKr,eAe,qKr,jKr,oAe,DKr,GKr,OKr,Xe,sA,rAe,VKr,XKr,Woe,zKr,QKr,WKr,lA,tAe,HKr,UKr,Hoe,JKr,YKr,KKr,iA,aAe,ZKr,eZr,Uoe,oZr,rZr,tZr,dA,nAe,aZr,nZr,Joe,sZr,lZr,iZr,cA,sAe,dZr,cZr,Yoe,fZr,mZr,gZr,fA,lAe,hZr,pZr,Koe,_Zr,uZr,bZr,mA,iAe,vZr,FZr,Zoe,TZr,MZr,EZr,gA,dAe,CZr,wZr,ere,AZr,LZr,yZr,hA,Tze,Ff,pA,cAe,z$,xZr,fAe,$Zr,Mze,Cr,Q$,kZr,Tf,SZr,ore,RZr,PZr,rre,BZr,NZr,IZr,W$,qZr,mAe,jZr,DZr,GZr,ea,H$,OZr,gAe,VZr,XZr,Mf,zZr,hAe,QZr,WZr,tre,HZr,UZr,JZr,_A,YZr,Kr,U$,KZr,pAe,ZZr,eet,$n,oet,_Ae,ret,tet,uAe,aet,net,bAe,set,iet,det,vAe,uA,FAe,cet,fet,are,met,get,het,bA,Eze,Ef,vA,TAe,J$,pet,MAe,_et,Cze,wr,Y$,uet,Cf,bet,nre,vet,Fet,sre,Tet,Met,Eet,K$,Cet,EAe,wet,Aet,Let,oa,Z$,yet,CAe,xet,$et,wf,ket,wAe,Set,Ret,lre,Pet,Bet,Net,FA,Iet,Zr,ek,qet,AAe,jet,Det,kn,Get,LAe,Oet,Vet,yAe,Xet,zet,xAe,Qet,Wet,Het,ok,TA,$Ae,Uet,Jet,ire,Yet,Ket,Zet,MA,kAe,eot,oot,dre,rot,tot,aot,EA,wze,Af,CA,SAe,rk,not,RAe,sot,Aze,Ar,tk,lot,Lf,iot,cre,dot,cot,fre,fot,mot,got,ak,hot,PAe,pot,_ot,uot,ra,nk,bot,BAe,vot,Fot,yf,Tot,NAe,Mot,Eot,mre,Cot,wot,Aot,wA,Lot,et,sk,yot,IAe,xot,$ot,Sn,kot,qAe,Sot,Rot,jAe,Pot,Bot,DAe,Not,Iot,qot,GAe,AA,OAe,jot,Dot,gre,Got,Oot,Vot,LA,Lze;return d=new re({}),ka=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),YL=new re({}),KL=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),If=new Xot({props:{warning:!0,$$slots:{default:[izt]},$$scope:{ctx:$}}}),ZL=new re({}),ey=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/configuration_auto.py#L607"}}),ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/configuration_auto.py#L630"}}),Hg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[dzt]},$$scope:{ctx:$}}}),ay=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/configuration_auto.py#L753"}}),ny=new re({}),sy=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/tokenization_auto.py#L403"}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17427/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/tokenization_auto.py#L417"}}),$h=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[czt]},$$scope:{ctx:$}}}),cy=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/tokenization_auto.py#L616"}}),fy=new re({}),my=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/feature_extraction_auto.py#L194"}}),py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17427/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/feature_extraction_auto.py#L208"}}),mp=new Xot({props:{$$slots:{default:[fzt]},$$scope:{ctx:$}}}),gp=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[mzt]},$$scope:{ctx:$}}}),_y=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/feature_extraction_auto.py#L335"}}),uy=new re({}),by=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/processing_auto.py#L89"}}),Ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/processing_auto.py#L103"}}),Pp=new Xot({props:{$$slots:{default:[gzt]},$$scope:{ctx:$}}}),Bp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[hzt]},$$scope:{ctx:$}}}),My=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/processing_auto.py#L256"}}),Ey=new re({}),Cy=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L779"}}),Ay=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),qp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[pzt]},$$scope:{ctx:$}}}),Ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Gu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[_zt]},$$scope:{ctx:$}}}),yy=new re({}),xy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L786"}}),ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Vu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[uzt]},$$scope:{ctx:$}}}),Sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),N2=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[bzt]},$$scope:{ctx:$}}}),Ry=new re({}),Py=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L801"}}),Ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),q2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[vzt]},$$scope:{ctx:$}}}),Iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),A1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Fzt]},$$scope:{ctx:$}}}),qy=new re({}),jy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L808"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),y1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Tzt]},$$scope:{ctx:$}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),h7=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Mzt]},$$scope:{ctx:$}}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L815"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),_7=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Ezt]},$$scope:{ctx:$}}}),Wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),N7=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Czt]},$$scope:{ctx:$}}}),Hy=new re({}),Uy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L824"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[wzt]},$$scope:{ctx:$}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),N4=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Azt]},$$scope:{ctx:$}}}),Zy=new re({}),e8=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L869"}}),r8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),q4=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Lzt]},$$scope:{ctx:$}}}),t8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),_b=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[yzt]},$$scope:{ctx:$}}}),a8=new re({}),n8=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L876"}}),l8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),bb=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[xzt]},$$scope:{ctx:$}}}),i8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Ab=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[$zt]},$$scope:{ctx:$}}}),d8=new re({}),c8=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L862"}}),m8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),yb=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[kzt]},$$scope:{ctx:$}}}),g8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),mv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Szt]},$$scope:{ctx:$}}}),h8=new re({}),p8=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L833"}}),u8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),hv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Rzt]},$$scope:{ctx:$}}}),b8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),aF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Pzt]},$$scope:{ctx:$}}}),v8=new re({}),F8=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L840"}}),M8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),sF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Bzt]},$$scope:{ctx:$}}}),E8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),dF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Nzt]},$$scope:{ctx:$}}}),C8=new re({}),w8=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L885"}}),L8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),fF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Izt]},$$scope:{ctx:$}}}),y8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),wF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[qzt]},$$scope:{ctx:$}}}),x8=new re({}),$8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L924"}}),S8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),LF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[jzt]},$$scope:{ctx:$}}}),R8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),$F=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Dzt]},$$scope:{ctx:$}}}),P8=new re({}),B8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L851"}}),I8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),SF=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Gzt]},$$scope:{ctx:$}}}),q8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),BF=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Ozt]},$$scope:{ctx:$}}}),j8=new re({}),D8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L931"}}),O8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),IF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Vzt]},$$scope:{ctx:$}}}),V8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),HF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Xzt]},$$scope:{ctx:$}}}),X8=new re({}),z8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L954"}}),W8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),JF=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[zzt]},$$scope:{ctx:$}}}),H8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),tT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Qzt]},$$scope:{ctx:$}}}),U8=new re({}),J8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L938"}}),K8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),nT=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Wzt]},$$scope:{ctx:$}}}),Z8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),uT=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Hzt]},$$scope:{ctx:$}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L945"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),vT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Uzt]},$$scope:{ctx:$}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),ET=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Jzt]},$$scope:{ctx:$}}}),s9=new re({}),l9=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L963"}}),d9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),wT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Yzt]},$$scope:{ctx:$}}}),c9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),ST=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Kzt]},$$scope:{ctx:$}}}),f9=new re({}),m9=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L970"}}),h9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),PT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Zzt]},$$scope:{ctx:$}}}),p9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[eQt]},$$scope:{ctx:$}}}),_9=new re({}),u9=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L917"}}),v9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[oQt]},$$scope:{ctx:$}}}),F9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),zT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[rQt]},$$scope:{ctx:$}}}),M9=new re({}),E9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L892"}}),w9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),WT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[tQt]},$$scope:{ctx:$}}}),A9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),JT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[aQt]},$$scope:{ctx:$}}}),L9=new re({}),y9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L899"}}),$9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),KT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[nQt]},$$scope:{ctx:$}}}),k9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),aM=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[sQt]},$$scope:{ctx:$}}}),S9=new re({}),R9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_auto.py#L908"}}),B9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),sM=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[lQt]},$$scope:{ctx:$}}}),N9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),dM=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[iQt]},$$scope:{ctx:$}}}),I9=new re({}),q9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L410"}}),D9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),fM=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[dQt]},$$scope:{ctx:$}}}),G9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),sE=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[cQt]},$$scope:{ctx:$}}}),O9=new re({}),V9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L417"}}),z9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),iE=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[fQt]},$$scope:{ctx:$}}}),Q9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),SE=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[mQt]},$$scope:{ctx:$}}}),W9=new re({}),H9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),J9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),PE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[gQt]},$$scope:{ctx:$}}}),Y9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),HE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[hQt]},$$scope:{ctx:$}}}),K9=new re({}),Z9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),ox=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),JE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[pQt]},$$scope:{ctx:$}}}),rx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[_Qt]},$$scope:{ctx:$}}}),tx=new re({}),ax=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L473"}}),sx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[uQt]},$$scope:{ctx:$}}}),lx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),AC=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[bQt]},$$scope:{ctx:$}}}),ix=new re({}),dx=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),yC=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[vQt]},$$scope:{ctx:$}}}),mx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[FQt]},$$scope:{ctx:$}}}),gx=new re({}),hx=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L489"}}),_x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[TQt]},$$scope:{ctx:$}}}),ux=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),h3=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[MQt]},$$scope:{ctx:$}}}),bx=new re({}),vx=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L525"}}),Tx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),_3=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[EQt]},$$scope:{ctx:$}}}),Mx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),P3=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[CQt]},$$scope:{ctx:$}}}),Ex=new re({}),Cx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),Ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),N3=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[wQt]},$$scope:{ctx:$}}}),Lx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[AQt]},$$scope:{ctx:$}}}),xx=new re({}),$x=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L505"}}),Sx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),G3=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[LQt]},$$scope:{ctx:$}}}),Rx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),V3=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[yQt]},$$scope:{ctx:$}}}),Px=new re({}),Bx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L516"}}),Ix=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),z3=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[xQt]},$$scope:{ctx:$}}}),qx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[$Qt]},$$scope:{ctx:$}}}),jx=new re({}),Dx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L498"}}),Ox=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),h5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[kQt]},$$scope:{ctx:$}}}),Vx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),B5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[SQt]},$$scope:{ctx:$}}}),Xx=new re({}),zx=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),Wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),I5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[RQt]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),j5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[PQt]},$$scope:{ctx:$}}}),Ux=new re({}),Jx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_tf_auto.py#L541"}}),Kx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),G5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[BQt]},$$scope:{ctx:$}}}),Zx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),V5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[NQt]},$$scope:{ctx:$}}}),e$=new re({}),o$=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),t$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),z5=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[IQt]},$$scope:{ctx:$}}}),a$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),v0=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[qQt]},$$scope:{ctx:$}}}),n$=new re({}),s$=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),i$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),T0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[jQt]},$$scope:{ctx:$}}}),d$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),S0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[DQt]},$$scope:{ctx:$}}}),c$=new re({}),f$=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),g$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),P0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[GQt]},$$scope:{ctx:$}}}),h$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),H0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[OQt]},$$scope:{ctx:$}}}),p$=new re({}),_$=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),b$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),J0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[VQt]},$$scope:{ctx:$}}}),v$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),lw=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[XQt]},$$scope:{ctx:$}}}),F$=new re({}),T$=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),E$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),dw=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[zQt]},$$scope:{ctx:$}}}),C$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Fw=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[QQt]},$$scope:{ctx:$}}}),w$=new re({}),A$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),y$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Mw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[WQt]},$$scope:{ctx:$}}}),x$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Rw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[HQt]},$$scope:{ctx:$}}}),$$=new re({}),k$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),R$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Bw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UQt]},$$scope:{ctx:$}}}),P$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),Qw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JQt]},$$scope:{ctx:$}}}),B$=new re({}),N$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),q$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),Hw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[YQt]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),tA=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[KQt]},$$scope:{ctx:$}}}),D$=new re({}),G$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),V$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),nA=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[ZQt]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),hA=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[eWt]},$$scope:{ctx:$}}}),z$=new re({}),Q$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),H$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),_A=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[oWt]},$$scope:{ctx:$}}}),U$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),bA=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[rWt]},$$scope:{ctx:$}}}),J$=new re({}),Y$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),Z$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),FA=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[tWt]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),EA=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[aWt]},$$scope:{ctx:$}}}),rk=new re({}),tk=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),nk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L389"}}),wA=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[nWt]},$$scope:{ctx:$}}}),sk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17427/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17427/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17427/src/transformers/models/auto/auto_factory.py#L417"}}),LA=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[sWt]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),wi=o("Auto Classes"),Sf=l(),nt=a("p"),Ai=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Li=a("code"),WL=o("from_pretrained()"),Rf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),yi=o("Instantiating one of "),Pn=a("a"),HL=o("AutoConfig"),Bn=o(", "),Nn=a("a"),UL=o("AutoModel"),xi=o(`, and
`),In=a("a"),JL=o("AutoTokenizer"),$i=o(" will directly create a class of the relevant architecture. For instance"),Pf=l(),F(ka.$$.fragment),We=l(),Ae=a("p"),LS=o("will create a model that is an instance of "),ki=a("a"),yS=o("BertModel"),xS=o("."),Co=l(),Sa=a("p"),$S=o("There is one class of "),Bf=a("code"),kS=o("AutoModel"),IWe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),MVe=l(),Si=a("h2"),Nf=a("a"),iae=a("span"),F(YL.$$.fragment),qWe=l(),dae=a("span"),jWe=o("Extending the Auto Classes"),EVe=l(),qn=a("p"),DWe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),cae=a("code"),GWe=o("NewModel"),OWe=o(", make sure you have a "),fae=a("code"),VWe=o("NewModelConfig"),XWe=o(` then you can add those to the auto
classes like this:`),CVe=l(),F(KL.$$.fragment),wVe=l(),SS=a("p"),zWe=o("You will then be able to use the auto classes like you would usually do!"),AVe=l(),F(If.$$.fragment),LVe=l(),Ri=a("h2"),qf=a("a"),mae=a("span"),F(ZL.$$.fragment),QWe=l(),gae=a("span"),WWe=o("AutoConfig"),yVe=l(),wo=a("div"),F(ey.$$.fragment),HWe=l(),oy=a("p"),UWe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),RS=a("a"),JWe=o("from_pretrained()"),YWe=o(" class method."),KWe=l(),ry=a("p"),ZWe=o("This class cannot be instantiated directly using "),hae=a("code"),eHe=o("__init__()"),oHe=o(" (throws an error)."),rHe=l(),Lr=a("div"),F(ty.$$.fragment),tHe=l(),pae=a("p"),aHe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),nHe=l(),Pi=a("p"),sHe=o("The configuration class to instantiate is selected based on the "),_ae=a("code"),lHe=o("model_type"),iHe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),uae=a("code"),dHe=o("pretrained_model_name_or_path"),cHe=o(":"),fHe=l(),A=a("ul"),jf=a("li"),bae=a("strong"),mHe=o("albert"),gHe=o(" \u2014 "),PS=a("a"),hHe=o("AlbertConfig"),pHe=o(" (ALBERT model)"),_He=l(),Df=a("li"),vae=a("strong"),uHe=o("bart"),bHe=o(" \u2014 "),BS=a("a"),vHe=o("BartConfig"),FHe=o(" (BART model)"),THe=l(),Gf=a("li"),Fae=a("strong"),MHe=o("beit"),EHe=o(" \u2014 "),NS=a("a"),CHe=o("BeitConfig"),wHe=o(" (BEiT model)"),AHe=l(),Of=a("li"),Tae=a("strong"),LHe=o("bert"),yHe=o(" \u2014 "),IS=a("a"),xHe=o("BertConfig"),$He=o(" (BERT model)"),kHe=l(),Vf=a("li"),Mae=a("strong"),SHe=o("bert-generation"),RHe=o(" \u2014 "),qS=a("a"),PHe=o("BertGenerationConfig"),BHe=o(" (Bert Generation model)"),NHe=l(),Xf=a("li"),Eae=a("strong"),IHe=o("big_bird"),qHe=o(" \u2014 "),jS=a("a"),jHe=o("BigBirdConfig"),DHe=o(" (BigBird model)"),GHe=l(),zf=a("li"),Cae=a("strong"),OHe=o("bigbird_pegasus"),VHe=o(" \u2014 "),DS=a("a"),XHe=o("BigBirdPegasusConfig"),zHe=o(" (BigBird-Pegasus model)"),QHe=l(),Qf=a("li"),wae=a("strong"),WHe=o("blenderbot"),HHe=o(" \u2014 "),GS=a("a"),UHe=o("BlenderbotConfig"),JHe=o(" (Blenderbot model)"),YHe=l(),Wf=a("li"),Aae=a("strong"),KHe=o("blenderbot-small"),ZHe=o(" \u2014 "),OS=a("a"),eUe=o("BlenderbotSmallConfig"),oUe=o(" (BlenderbotSmall model)"),rUe=l(),Hf=a("li"),Lae=a("strong"),tUe=o("bloom"),aUe=o(" \u2014 "),VS=a("a"),nUe=o("BloomConfig"),sUe=o(" (BLOOM model)"),lUe=l(),Uf=a("li"),yae=a("strong"),iUe=o("camembert"),dUe=o(" \u2014 "),XS=a("a"),cUe=o("CamembertConfig"),fUe=o(" (CamemBERT model)"),mUe=l(),Jf=a("li"),xae=a("strong"),gUe=o("canine"),hUe=o(" \u2014 "),zS=a("a"),pUe=o("CanineConfig"),_Ue=o(" (CANINE model)"),uUe=l(),Yf=a("li"),$ae=a("strong"),bUe=o("clip"),vUe=o(" \u2014 "),QS=a("a"),FUe=o("CLIPConfig"),TUe=o(" (CLIP model)"),MUe=l(),Kf=a("li"),kae=a("strong"),EUe=o("codegen"),CUe=o(" \u2014 "),WS=a("a"),wUe=o("CodeGenConfig"),AUe=o(" (CodeGen model)"),LUe=l(),Zf=a("li"),Sae=a("strong"),yUe=o("convbert"),xUe=o(" \u2014 "),HS=a("a"),$Ue=o("ConvBertConfig"),kUe=o(" (ConvBERT model)"),SUe=l(),em=a("li"),Rae=a("strong"),RUe=o("convnext"),PUe=o(" \u2014 "),US=a("a"),BUe=o("ConvNextConfig"),NUe=o(" (ConvNeXT model)"),IUe=l(),om=a("li"),Pae=a("strong"),qUe=o("ctrl"),jUe=o(" \u2014 "),JS=a("a"),DUe=o("CTRLConfig"),GUe=o(" (CTRL model)"),OUe=l(),rm=a("li"),Bae=a("strong"),VUe=o("cvt"),XUe=o(" \u2014 "),YS=a("a"),zUe=o("CvtConfig"),QUe=o(" (CvT model)"),WUe=l(),tm=a("li"),Nae=a("strong"),HUe=o("data2vec-audio"),UUe=o(" \u2014 "),KS=a("a"),JUe=o("Data2VecAudioConfig"),YUe=o(" (Data2VecAudio model)"),KUe=l(),am=a("li"),Iae=a("strong"),ZUe=o("data2vec-text"),eJe=o(" \u2014 "),ZS=a("a"),oJe=o("Data2VecTextConfig"),rJe=o(" (Data2VecText model)"),tJe=l(),nm=a("li"),qae=a("strong"),aJe=o("data2vec-vision"),nJe=o(" \u2014 "),eR=a("a"),sJe=o("Data2VecVisionConfig"),lJe=o(" (Data2VecVision model)"),iJe=l(),sm=a("li"),jae=a("strong"),dJe=o("deberta"),cJe=o(" \u2014 "),oR=a("a"),fJe=o("DebertaConfig"),mJe=o(" (DeBERTa model)"),gJe=l(),lm=a("li"),Dae=a("strong"),hJe=o("deberta-v2"),pJe=o(" \u2014 "),rR=a("a"),_Je=o("DebertaV2Config"),uJe=o(" (DeBERTa-v2 model)"),bJe=l(),im=a("li"),Gae=a("strong"),vJe=o("decision_transformer"),FJe=o(" \u2014 "),tR=a("a"),TJe=o("DecisionTransformerConfig"),MJe=o(" (Decision Transformer model)"),EJe=l(),dm=a("li"),Oae=a("strong"),CJe=o("deit"),wJe=o(" \u2014 "),aR=a("a"),AJe=o("DeiTConfig"),LJe=o(" (DeiT model)"),yJe=l(),cm=a("li"),Vae=a("strong"),xJe=o("detr"),$Je=o(" \u2014 "),nR=a("a"),kJe=o("DetrConfig"),SJe=o(" (DETR model)"),RJe=l(),fm=a("li"),Xae=a("strong"),PJe=o("distilbert"),BJe=o(" \u2014 "),sR=a("a"),NJe=o("DistilBertConfig"),IJe=o(" (DistilBERT model)"),qJe=l(),mm=a("li"),zae=a("strong"),jJe=o("dpr"),DJe=o(" \u2014 "),lR=a("a"),GJe=o("DPRConfig"),OJe=o(" (DPR model)"),VJe=l(),gm=a("li"),Qae=a("strong"),XJe=o("dpt"),zJe=o(" \u2014 "),iR=a("a"),QJe=o("DPTConfig"),WJe=o(" (DPT model)"),HJe=l(),hm=a("li"),Wae=a("strong"),UJe=o("electra"),JJe=o(" \u2014 "),dR=a("a"),YJe=o("ElectraConfig"),KJe=o(" (ELECTRA model)"),ZJe=l(),pm=a("li"),Hae=a("strong"),eYe=o("encoder-decoder"),oYe=o(" \u2014 "),cR=a("a"),rYe=o("EncoderDecoderConfig"),tYe=o(" (Encoder decoder model)"),aYe=l(),_m=a("li"),Uae=a("strong"),nYe=o("flaubert"),sYe=o(" \u2014 "),fR=a("a"),lYe=o("FlaubertConfig"),iYe=o(" (FlauBERT model)"),dYe=l(),um=a("li"),Jae=a("strong"),cYe=o("flava"),fYe=o(" \u2014 "),mR=a("a"),mYe=o("FlavaConfig"),gYe=o(" (FLAVA model)"),hYe=l(),bm=a("li"),Yae=a("strong"),pYe=o("fnet"),_Ye=o(" \u2014 "),gR=a("a"),uYe=o("FNetConfig"),bYe=o(" (FNet model)"),vYe=l(),vm=a("li"),Kae=a("strong"),FYe=o("fsmt"),TYe=o(" \u2014 "),hR=a("a"),MYe=o("FSMTConfig"),EYe=o(" (FairSeq Machine-Translation model)"),CYe=l(),Fm=a("li"),Zae=a("strong"),wYe=o("funnel"),AYe=o(" \u2014 "),pR=a("a"),LYe=o("FunnelConfig"),yYe=o(" (Funnel Transformer model)"),xYe=l(),Tm=a("li"),ene=a("strong"),$Ye=o("glpn"),kYe=o(" \u2014 "),_R=a("a"),SYe=o("GLPNConfig"),RYe=o(" (GLPN model)"),PYe=l(),Mm=a("li"),one=a("strong"),BYe=o("gpt2"),NYe=o(" \u2014 "),uR=a("a"),IYe=o("GPT2Config"),qYe=o(" (OpenAI GPT-2 model)"),jYe=l(),Em=a("li"),rne=a("strong"),DYe=o("gpt_neo"),GYe=o(" \u2014 "),bR=a("a"),OYe=o("GPTNeoConfig"),VYe=o(" (GPT Neo model)"),XYe=l(),Cm=a("li"),tne=a("strong"),zYe=o("gpt_neox"),QYe=o(" \u2014 "),vR=a("a"),WYe=o("GPTNeoXConfig"),HYe=o(" (GPT NeoX model)"),UYe=l(),wm=a("li"),ane=a("strong"),JYe=o("gptj"),YYe=o(" \u2014 "),FR=a("a"),KYe=o("GPTJConfig"),ZYe=o(" (GPT-J model)"),eKe=l(),Am=a("li"),nne=a("strong"),oKe=o("groupvit"),rKe=o(" \u2014 "),TR=a("a"),tKe=o("GroupViTConfig"),aKe=o(" (GroupViT model)"),nKe=l(),Lm=a("li"),sne=a("strong"),sKe=o("hubert"),lKe=o(" \u2014 "),MR=a("a"),iKe=o("HubertConfig"),dKe=o(" (Hubert model)"),cKe=l(),ym=a("li"),lne=a("strong"),fKe=o("ibert"),mKe=o(" \u2014 "),ER=a("a"),gKe=o("IBertConfig"),hKe=o(" (I-BERT model)"),pKe=l(),xm=a("li"),ine=a("strong"),_Ke=o("imagegpt"),uKe=o(" \u2014 "),CR=a("a"),bKe=o("ImageGPTConfig"),vKe=o(" (ImageGPT model)"),FKe=l(),$m=a("li"),dne=a("strong"),TKe=o("layoutlm"),MKe=o(" \u2014 "),wR=a("a"),EKe=o("LayoutLMConfig"),CKe=o(" (LayoutLM model)"),wKe=l(),km=a("li"),cne=a("strong"),AKe=o("layoutlmv2"),LKe=o(" \u2014 "),AR=a("a"),yKe=o("LayoutLMv2Config"),xKe=o(" (LayoutLMv2 model)"),$Ke=l(),Sm=a("li"),fne=a("strong"),kKe=o("layoutlmv3"),SKe=o(" \u2014 "),LR=a("a"),RKe=o("LayoutLMv3Config"),PKe=o(" (LayoutLMv3 model)"),BKe=l(),Rm=a("li"),mne=a("strong"),NKe=o("led"),IKe=o(" \u2014 "),yR=a("a"),qKe=o("LEDConfig"),jKe=o(" (LED model)"),DKe=l(),Pm=a("li"),gne=a("strong"),GKe=o("levit"),OKe=o(" \u2014 "),xR=a("a"),VKe=o("LevitConfig"),XKe=o(" (LeViT model)"),zKe=l(),Bm=a("li"),hne=a("strong"),QKe=o("longformer"),WKe=o(" \u2014 "),$R=a("a"),HKe=o("LongformerConfig"),UKe=o(" (Longformer model)"),JKe=l(),Nm=a("li"),pne=a("strong"),YKe=o("longt5"),KKe=o(" \u2014 "),kR=a("a"),ZKe=o("LongT5Config"),eZe=o(" (LongT5 model)"),oZe=l(),Im=a("li"),_ne=a("strong"),rZe=o("luke"),tZe=o(" \u2014 "),SR=a("a"),aZe=o("LukeConfig"),nZe=o(" (LUKE model)"),sZe=l(),qm=a("li"),une=a("strong"),lZe=o("lxmert"),iZe=o(" \u2014 "),RR=a("a"),dZe=o("LxmertConfig"),cZe=o(" (LXMERT model)"),fZe=l(),jm=a("li"),bne=a("strong"),mZe=o("m2m_100"),gZe=o(" \u2014 "),PR=a("a"),hZe=o("M2M100Config"),pZe=o(" (M2M100 model)"),_Ze=l(),Dm=a("li"),vne=a("strong"),uZe=o("marian"),bZe=o(" \u2014 "),BR=a("a"),vZe=o("MarianConfig"),FZe=o(" (Marian model)"),TZe=l(),Gm=a("li"),Fne=a("strong"),MZe=o("maskformer"),EZe=o(" \u2014 "),NR=a("a"),CZe=o("MaskFormerConfig"),wZe=o(" (MaskFormer model)"),AZe=l(),Om=a("li"),Tne=a("strong"),LZe=o("mbart"),yZe=o(" \u2014 "),IR=a("a"),xZe=o("MBartConfig"),$Ze=o(" (mBART model)"),kZe=l(),Vm=a("li"),Mne=a("strong"),SZe=o("mctct"),RZe=o(" \u2014 "),qR=a("a"),PZe=o("MCTCTConfig"),BZe=o(" (M-CTC-T model)"),NZe=l(),Xm=a("li"),Ene=a("strong"),IZe=o("megatron-bert"),qZe=o(" \u2014 "),jR=a("a"),jZe=o("MegatronBertConfig"),DZe=o(" (Megatron-BERT model)"),GZe=l(),zm=a("li"),Cne=a("strong"),OZe=o("mobilebert"),VZe=o(" \u2014 "),DR=a("a"),XZe=o("MobileBertConfig"),zZe=o(" (MobileBERT model)"),QZe=l(),Qm=a("li"),wne=a("strong"),WZe=o("mpnet"),HZe=o(" \u2014 "),GR=a("a"),UZe=o("MPNetConfig"),JZe=o(" (MPNet model)"),YZe=l(),Wm=a("li"),Ane=a("strong"),KZe=o("mt5"),ZZe=o(" \u2014 "),OR=a("a"),eeo=o("MT5Config"),oeo=o(" (MT5 model)"),reo=l(),Hm=a("li"),Lne=a("strong"),teo=o("mvp"),aeo=o(" \u2014 "),VR=a("a"),neo=o("MvpConfig"),seo=o(" (MVP model)"),leo=l(),Um=a("li"),yne=a("strong"),ieo=o("nezha"),deo=o(" \u2014 "),XR=a("a"),ceo=o("NezhaConfig"),feo=o(" (Nezha model)"),meo=l(),Jm=a("li"),xne=a("strong"),geo=o("nystromformer"),heo=o(" \u2014 "),zR=a("a"),peo=o("NystromformerConfig"),_eo=o(" (Nystr\xF6mformer model)"),ueo=l(),Ym=a("li"),$ne=a("strong"),beo=o("openai-gpt"),veo=o(" \u2014 "),QR=a("a"),Feo=o("OpenAIGPTConfig"),Teo=o(" (OpenAI GPT model)"),Meo=l(),Km=a("li"),kne=a("strong"),Eeo=o("opt"),Ceo=o(" \u2014 "),WR=a("a"),weo=o("OPTConfig"),Aeo=o(" (OPT model)"),Leo=l(),Zm=a("li"),Sne=a("strong"),yeo=o("pegasus"),xeo=o(" \u2014 "),HR=a("a"),$eo=o("PegasusConfig"),keo=o(" (Pegasus model)"),Seo=l(),eg=a("li"),Rne=a("strong"),Reo=o("perceiver"),Peo=o(" \u2014 "),UR=a("a"),Beo=o("PerceiverConfig"),Neo=o(" (Perceiver model)"),Ieo=l(),og=a("li"),Pne=a("strong"),qeo=o("plbart"),jeo=o(" \u2014 "),JR=a("a"),Deo=o("PLBartConfig"),Geo=o(" (PLBart model)"),Oeo=l(),rg=a("li"),Bne=a("strong"),Veo=o("poolformer"),Xeo=o(" \u2014 "),YR=a("a"),zeo=o("PoolFormerConfig"),Qeo=o(" (PoolFormer model)"),Weo=l(),tg=a("li"),Nne=a("strong"),Heo=o("prophetnet"),Ueo=o(" \u2014 "),KR=a("a"),Jeo=o("ProphetNetConfig"),Yeo=o(" (ProphetNet model)"),Keo=l(),ag=a("li"),Ine=a("strong"),Zeo=o("qdqbert"),eoo=o(" \u2014 "),ZR=a("a"),ooo=o("QDQBertConfig"),roo=o(" (QDQBert model)"),too=l(),ng=a("li"),qne=a("strong"),aoo=o("rag"),noo=o(" \u2014 "),eP=a("a"),soo=o("RagConfig"),loo=o(" (RAG model)"),ioo=l(),sg=a("li"),jne=a("strong"),doo=o("realm"),coo=o(" \u2014 "),oP=a("a"),foo=o("RealmConfig"),moo=o(" (REALM model)"),goo=l(),lg=a("li"),Dne=a("strong"),hoo=o("reformer"),poo=o(" \u2014 "),rP=a("a"),_oo=o("ReformerConfig"),uoo=o(" (Reformer model)"),boo=l(),ig=a("li"),Gne=a("strong"),voo=o("regnet"),Foo=o(" \u2014 "),tP=a("a"),Too=o("RegNetConfig"),Moo=o(" (RegNet model)"),Eoo=l(),dg=a("li"),One=a("strong"),Coo=o("rembert"),woo=o(" \u2014 "),aP=a("a"),Aoo=o("RemBertConfig"),Loo=o(" (RemBERT model)"),yoo=l(),cg=a("li"),Vne=a("strong"),xoo=o("resnet"),$oo=o(" \u2014 "),nP=a("a"),koo=o("ResNetConfig"),Soo=o(" (ResNet model)"),Roo=l(),fg=a("li"),Xne=a("strong"),Poo=o("retribert"),Boo=o(" \u2014 "),sP=a("a"),Noo=o("RetriBertConfig"),Ioo=o(" (RetriBERT model)"),qoo=l(),mg=a("li"),zne=a("strong"),joo=o("roberta"),Doo=o(" \u2014 "),lP=a("a"),Goo=o("RobertaConfig"),Ooo=o(" (RoBERTa model)"),Voo=l(),gg=a("li"),Qne=a("strong"),Xoo=o("roformer"),zoo=o(" \u2014 "),iP=a("a"),Qoo=o("RoFormerConfig"),Woo=o(" (RoFormer model)"),Hoo=l(),hg=a("li"),Wne=a("strong"),Uoo=o("segformer"),Joo=o(" \u2014 "),dP=a("a"),Yoo=o("SegformerConfig"),Koo=o(" (SegFormer model)"),Zoo=l(),pg=a("li"),Hne=a("strong"),ero=o("sew"),oro=o(" \u2014 "),cP=a("a"),rro=o("SEWConfig"),tro=o(" (SEW model)"),aro=l(),_g=a("li"),Une=a("strong"),nro=o("sew-d"),sro=o(" \u2014 "),fP=a("a"),lro=o("SEWDConfig"),iro=o(" (SEW-D model)"),dro=l(),ug=a("li"),Jne=a("strong"),cro=o("speech-encoder-decoder"),fro=o(" \u2014 "),mP=a("a"),mro=o("SpeechEncoderDecoderConfig"),gro=o(" (Speech Encoder decoder model)"),hro=l(),bg=a("li"),Yne=a("strong"),pro=o("speech_to_text"),_ro=o(" \u2014 "),gP=a("a"),uro=o("Speech2TextConfig"),bro=o(" (Speech2Text model)"),vro=l(),vg=a("li"),Kne=a("strong"),Fro=o("speech_to_text_2"),Tro=o(" \u2014 "),hP=a("a"),Mro=o("Speech2Text2Config"),Ero=o(" (Speech2Text2 model)"),Cro=l(),Fg=a("li"),Zne=a("strong"),wro=o("splinter"),Aro=o(" \u2014 "),pP=a("a"),Lro=o("SplinterConfig"),yro=o(" (Splinter model)"),xro=l(),Tg=a("li"),ese=a("strong"),$ro=o("squeezebert"),kro=o(" \u2014 "),_P=a("a"),Sro=o("SqueezeBertConfig"),Rro=o(" (SqueezeBERT model)"),Pro=l(),Mg=a("li"),ose=a("strong"),Bro=o("swin"),Nro=o(" \u2014 "),uP=a("a"),Iro=o("SwinConfig"),qro=o(" (Swin Transformer model)"),jro=l(),Eg=a("li"),rse=a("strong"),Dro=o("t5"),Gro=o(" \u2014 "),bP=a("a"),Oro=o("T5Config"),Vro=o(" (T5 model)"),Xro=l(),Cg=a("li"),tse=a("strong"),zro=o("tapas"),Qro=o(" \u2014 "),vP=a("a"),Wro=o("TapasConfig"),Hro=o(" (TAPAS model)"),Uro=l(),wg=a("li"),ase=a("strong"),Jro=o("trajectory_transformer"),Yro=o(" \u2014 "),FP=a("a"),Kro=o("TrajectoryTransformerConfig"),Zro=o(" (Trajectory Transformer model)"),eto=l(),Ag=a("li"),nse=a("strong"),oto=o("transfo-xl"),rto=o(" \u2014 "),TP=a("a"),tto=o("TransfoXLConfig"),ato=o(" (Transformer-XL model)"),nto=l(),Lg=a("li"),sse=a("strong"),sto=o("trocr"),lto=o(" \u2014 "),MP=a("a"),ito=o("TrOCRConfig"),dto=o(" (TrOCR model)"),cto=l(),yg=a("li"),lse=a("strong"),fto=o("unispeech"),mto=o(" \u2014 "),EP=a("a"),gto=o("UniSpeechConfig"),hto=o(" (UniSpeech model)"),pto=l(),xg=a("li"),ise=a("strong"),_to=o("unispeech-sat"),uto=o(" \u2014 "),CP=a("a"),bto=o("UniSpeechSatConfig"),vto=o(" (UniSpeechSat model)"),Fto=l(),$g=a("li"),dse=a("strong"),Tto=o("van"),Mto=o(" \u2014 "),wP=a("a"),Eto=o("VanConfig"),Cto=o(" (VAN model)"),wto=l(),kg=a("li"),cse=a("strong"),Ato=o("vilt"),Lto=o(" \u2014 "),AP=a("a"),yto=o("ViltConfig"),xto=o(" (ViLT model)"),$to=l(),Sg=a("li"),fse=a("strong"),kto=o("vision-encoder-decoder"),Sto=o(" \u2014 "),LP=a("a"),Rto=o("VisionEncoderDecoderConfig"),Pto=o(" (Vision Encoder decoder model)"),Bto=l(),Rg=a("li"),mse=a("strong"),Nto=o("vision-text-dual-encoder"),Ito=o(" \u2014 "),yP=a("a"),qto=o("VisionTextDualEncoderConfig"),jto=o(" (VisionTextDualEncoder model)"),Dto=l(),Pg=a("li"),gse=a("strong"),Gto=o("visual_bert"),Oto=o(" \u2014 "),xP=a("a"),Vto=o("VisualBertConfig"),Xto=o(" (VisualBERT model)"),zto=l(),Bg=a("li"),hse=a("strong"),Qto=o("vit"),Wto=o(" \u2014 "),$P=a("a"),Hto=o("ViTConfig"),Uto=o(" (ViT model)"),Jto=l(),Ng=a("li"),pse=a("strong"),Yto=o("vit_mae"),Kto=o(" \u2014 "),kP=a("a"),Zto=o("ViTMAEConfig"),eao=o(" (ViTMAE model)"),oao=l(),Ig=a("li"),_se=a("strong"),rao=o("wav2vec2"),tao=o(" \u2014 "),SP=a("a"),aao=o("Wav2Vec2Config"),nao=o(" (Wav2Vec2 model)"),sao=l(),qg=a("li"),use=a("strong"),lao=o("wav2vec2-conformer"),iao=o(" \u2014 "),RP=a("a"),dao=o("Wav2Vec2ConformerConfig"),cao=o(" (Wav2Vec2-Conformer model)"),fao=l(),jg=a("li"),bse=a("strong"),mao=o("wavlm"),gao=o(" \u2014 "),PP=a("a"),hao=o("WavLMConfig"),pao=o(" (WavLM model)"),_ao=l(),Dg=a("li"),vse=a("strong"),uao=o("xglm"),bao=o(" \u2014 "),BP=a("a"),vao=o("XGLMConfig"),Fao=o(" (XGLM model)"),Tao=l(),Gg=a("li"),Fse=a("strong"),Mao=o("xlm"),Eao=o(" \u2014 "),NP=a("a"),Cao=o("XLMConfig"),wao=o(" (XLM model)"),Aao=l(),Og=a("li"),Tse=a("strong"),Lao=o("xlm-prophetnet"),yao=o(" \u2014 "),IP=a("a"),xao=o("XLMProphetNetConfig"),$ao=o(" (XLM-ProphetNet model)"),kao=l(),Vg=a("li"),Mse=a("strong"),Sao=o("xlm-roberta"),Rao=o(" \u2014 "),qP=a("a"),Pao=o("XLMRobertaConfig"),Bao=o(" (XLM-RoBERTa model)"),Nao=l(),Xg=a("li"),Ese=a("strong"),Iao=o("xlm-roberta-xl"),qao=o(" \u2014 "),jP=a("a"),jao=o("XLMRobertaXLConfig"),Dao=o(" (XLM-RoBERTa-XL model)"),Gao=l(),zg=a("li"),Cse=a("strong"),Oao=o("xlnet"),Vao=o(" \u2014 "),DP=a("a"),Xao=o("XLNetConfig"),zao=o(" (XLNet model)"),Qao=l(),Qg=a("li"),wse=a("strong"),Wao=o("yolos"),Hao=o(" \u2014 "),GP=a("a"),Uao=o("YolosConfig"),Jao=o(" (YOLOS model)"),Yao=l(),Wg=a("li"),Ase=a("strong"),Kao=o("yoso"),Zao=o(" \u2014 "),OP=a("a"),eno=o("YosoConfig"),ono=o(" (YOSO model)"),rno=l(),F(Hg.$$.fragment),tno=l(),Ug=a("div"),F(ay.$$.fragment),ano=l(),Lse=a("p"),nno=o("Register a new configuration for this class."),xVe=l(),Bi=a("h2"),Jg=a("a"),yse=a("span"),F(ny.$$.fragment),sno=l(),xse=a("span"),lno=o("AutoTokenizer"),$Ve=l(),Ao=a("div"),F(sy.$$.fragment),ino=l(),ly=a("p"),dno=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),VP=a("a"),cno=o("AutoTokenizer.from_pretrained()"),fno=o(" class method."),mno=l(),iy=a("p"),gno=o("This class cannot be instantiated directly using "),$se=a("code"),hno=o("__init__()"),pno=o(" (throws an error)."),_no=l(),yr=a("div"),F(dy.$$.fragment),uno=l(),kse=a("p"),bno=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),vno=l(),Ra=a("p"),Fno=o("The tokenizer class to instantiate is selected based on the "),Sse=a("code"),Tno=o("model_type"),Mno=o(` property of the config object (either
passed as an argument or loaded from `),Rse=a("code"),Eno=o("pretrained_model_name_or_path"),Cno=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pse=a("code"),wno=o("pretrained_model_name_or_path"),Ano=o(":"),Lno=l(),k=a("ul"),jn=a("li"),Bse=a("strong"),yno=o("albert"),xno=o(" \u2014 "),XP=a("a"),$no=o("AlbertTokenizer"),kno=o(" or "),zP=a("a"),Sno=o("AlbertTokenizerFast"),Rno=o(" (ALBERT model)"),Pno=l(),Dn=a("li"),Nse=a("strong"),Bno=o("bart"),Nno=o(" \u2014 "),QP=a("a"),Ino=o("BartTokenizer"),qno=o(" or "),WP=a("a"),jno=o("BartTokenizerFast"),Dno=o(" (BART model)"),Gno=l(),Gn=a("li"),Ise=a("strong"),Ono=o("barthez"),Vno=o(" \u2014 "),HP=a("a"),Xno=o("BarthezTokenizer"),zno=o(" or "),UP=a("a"),Qno=o("BarthezTokenizerFast"),Wno=o(" (BARThez model)"),Hno=l(),Yg=a("li"),qse=a("strong"),Uno=o("bartpho"),Jno=o(" \u2014 "),JP=a("a"),Yno=o("BartphoTokenizer"),Kno=o(" (BARTpho model)"),Zno=l(),On=a("li"),jse=a("strong"),eso=o("bert"),oso=o(" \u2014 "),YP=a("a"),rso=o("BertTokenizer"),tso=o(" or "),KP=a("a"),aso=o("BertTokenizerFast"),nso=o(" (BERT model)"),sso=l(),Kg=a("li"),Dse=a("strong"),lso=o("bert-generation"),iso=o(" \u2014 "),ZP=a("a"),dso=o("BertGenerationTokenizer"),cso=o(" (Bert Generation model)"),fso=l(),Zg=a("li"),Gse=a("strong"),mso=o("bert-japanese"),gso=o(" \u2014 "),eB=a("a"),hso=o("BertJapaneseTokenizer"),pso=o(" (BertJapanese model)"),_so=l(),eh=a("li"),Ose=a("strong"),uso=o("bertweet"),bso=o(" \u2014 "),oB=a("a"),vso=o("BertweetTokenizer"),Fso=o(" (BERTweet model)"),Tso=l(),Vn=a("li"),Vse=a("strong"),Mso=o("big_bird"),Eso=o(" \u2014 "),rB=a("a"),Cso=o("BigBirdTokenizer"),wso=o(" or "),tB=a("a"),Aso=o("BigBirdTokenizerFast"),Lso=o(" (BigBird model)"),yso=l(),Xn=a("li"),Xse=a("strong"),xso=o("bigbird_pegasus"),$so=o(" \u2014 "),aB=a("a"),kso=o("PegasusTokenizer"),Sso=o(" or "),nB=a("a"),Rso=o("PegasusTokenizerFast"),Pso=o(" (BigBird-Pegasus model)"),Bso=l(),zn=a("li"),zse=a("strong"),Nso=o("blenderbot"),Iso=o(" \u2014 "),sB=a("a"),qso=o("BlenderbotTokenizer"),jso=o(" or "),lB=a("a"),Dso=o("BlenderbotTokenizerFast"),Gso=o(" (Blenderbot model)"),Oso=l(),oh=a("li"),Qse=a("strong"),Vso=o("blenderbot-small"),Xso=o(" \u2014 "),iB=a("a"),zso=o("BlenderbotSmallTokenizer"),Qso=o(" (BlenderbotSmall model)"),Wso=l(),rh=a("li"),Wse=a("strong"),Hso=o("bloom"),Uso=o(" \u2014 "),dB=a("a"),Jso=o("BloomTokenizerFast"),Yso=o(" (BLOOM model)"),Kso=l(),th=a("li"),Hse=a("strong"),Zso=o("byt5"),elo=o(" \u2014 "),cB=a("a"),olo=o("ByT5Tokenizer"),rlo=o(" (ByT5 model)"),tlo=l(),Qn=a("li"),Use=a("strong"),alo=o("camembert"),nlo=o(" \u2014 "),fB=a("a"),slo=o("CamembertTokenizer"),llo=o(" or "),mB=a("a"),ilo=o("CamembertTokenizerFast"),dlo=o(" (CamemBERT model)"),clo=l(),ah=a("li"),Jse=a("strong"),flo=o("canine"),mlo=o(" \u2014 "),gB=a("a"),glo=o("CanineTokenizer"),hlo=o(" (CANINE model)"),plo=l(),Wn=a("li"),Yse=a("strong"),_lo=o("clip"),ulo=o(" \u2014 "),hB=a("a"),blo=o("CLIPTokenizer"),vlo=o(" or "),pB=a("a"),Flo=o("CLIPTokenizerFast"),Tlo=o(" (CLIP model)"),Mlo=l(),Hn=a("li"),Kse=a("strong"),Elo=o("codegen"),Clo=o(" \u2014 "),_B=a("a"),wlo=o("CodeGenTokenizer"),Alo=o(" or "),uB=a("a"),Llo=o("CodeGenTokenizerFast"),ylo=o(" (CodeGen model)"),xlo=l(),Un=a("li"),Zse=a("strong"),$lo=o("convbert"),klo=o(" \u2014 "),bB=a("a"),Slo=o("ConvBertTokenizer"),Rlo=o(" or "),vB=a("a"),Plo=o("ConvBertTokenizerFast"),Blo=o(" (ConvBERT model)"),Nlo=l(),Jn=a("li"),ele=a("strong"),Ilo=o("cpm"),qlo=o(" \u2014 "),FB=a("a"),jlo=o("CpmTokenizer"),Dlo=o(" or "),TB=a("a"),Glo=o("CpmTokenizerFast"),Olo=o(" (CPM model)"),Vlo=l(),nh=a("li"),ole=a("strong"),Xlo=o("ctrl"),zlo=o(" \u2014 "),MB=a("a"),Qlo=o("CTRLTokenizer"),Wlo=o(" (CTRL model)"),Hlo=l(),Yn=a("li"),rle=a("strong"),Ulo=o("data2vec-text"),Jlo=o(" \u2014 "),EB=a("a"),Ylo=o("RobertaTokenizer"),Klo=o(" or "),CB=a("a"),Zlo=o("RobertaTokenizerFast"),eio=o(" (Data2VecText model)"),oio=l(),Kn=a("li"),tle=a("strong"),rio=o("deberta"),tio=o(" \u2014 "),wB=a("a"),aio=o("DebertaTokenizer"),nio=o(" or "),AB=a("a"),sio=o("DebertaTokenizerFast"),lio=o(" (DeBERTa model)"),iio=l(),Zn=a("li"),ale=a("strong"),dio=o("deberta-v2"),cio=o(" \u2014 "),LB=a("a"),fio=o("DebertaV2Tokenizer"),mio=o(" or "),yB=a("a"),gio=o("DebertaV2TokenizerFast"),hio=o(" (DeBERTa-v2 model)"),pio=l(),es=a("li"),nle=a("strong"),_io=o("distilbert"),uio=o(" \u2014 "),xB=a("a"),bio=o("DistilBertTokenizer"),vio=o(" or "),$B=a("a"),Fio=o("DistilBertTokenizerFast"),Tio=o(" (DistilBERT model)"),Mio=l(),os=a("li"),sle=a("strong"),Eio=o("dpr"),Cio=o(" \u2014 "),kB=a("a"),wio=o("DPRQuestionEncoderTokenizer"),Aio=o(" or "),SB=a("a"),Lio=o("DPRQuestionEncoderTokenizerFast"),yio=o(" (DPR model)"),xio=l(),rs=a("li"),lle=a("strong"),$io=o("electra"),kio=o(" \u2014 "),RB=a("a"),Sio=o("ElectraTokenizer"),Rio=o(" or "),PB=a("a"),Pio=o("ElectraTokenizerFast"),Bio=o(" (ELECTRA model)"),Nio=l(),sh=a("li"),ile=a("strong"),Iio=o("flaubert"),qio=o(" \u2014 "),BB=a("a"),jio=o("FlaubertTokenizer"),Dio=o(" (FlauBERT model)"),Gio=l(),ts=a("li"),dle=a("strong"),Oio=o("fnet"),Vio=o(" \u2014 "),NB=a("a"),Xio=o("FNetTokenizer"),zio=o(" or "),IB=a("a"),Qio=o("FNetTokenizerFast"),Wio=o(" (FNet model)"),Hio=l(),lh=a("li"),cle=a("strong"),Uio=o("fsmt"),Jio=o(" \u2014 "),qB=a("a"),Yio=o("FSMTTokenizer"),Kio=o(" (FairSeq Machine-Translation model)"),Zio=l(),as=a("li"),fle=a("strong"),edo=o("funnel"),odo=o(" \u2014 "),jB=a("a"),rdo=o("FunnelTokenizer"),tdo=o(" or "),DB=a("a"),ado=o("FunnelTokenizerFast"),ndo=o(" (Funnel Transformer model)"),sdo=l(),ns=a("li"),mle=a("strong"),ldo=o("gpt2"),ido=o(" \u2014 "),GB=a("a"),ddo=o("GPT2Tokenizer"),cdo=o(" or "),OB=a("a"),fdo=o("GPT2TokenizerFast"),mdo=o(" (OpenAI GPT-2 model)"),gdo=l(),ss=a("li"),gle=a("strong"),hdo=o("gpt_neo"),pdo=o(" \u2014 "),VB=a("a"),_do=o("GPT2Tokenizer"),udo=o(" or "),XB=a("a"),bdo=o("GPT2TokenizerFast"),vdo=o(" (GPT Neo model)"),Fdo=l(),ih=a("li"),hle=a("strong"),Tdo=o("gpt_neox"),Mdo=o(" \u2014 "),zB=a("a"),Edo=o("GPTNeoXTokenizerFast"),Cdo=o(" (GPT NeoX model)"),wdo=l(),ls=a("li"),ple=a("strong"),Ado=o("gptj"),Ldo=o(" \u2014 "),QB=a("a"),ydo=o("GPT2Tokenizer"),xdo=o(" or "),WB=a("a"),$do=o("GPT2TokenizerFast"),kdo=o(" (GPT-J model)"),Sdo=l(),is=a("li"),_le=a("strong"),Rdo=o("groupvit"),Pdo=o(" \u2014 "),HB=a("a"),Bdo=o("CLIPTokenizer"),Ndo=o(" or "),UB=a("a"),Ido=o("CLIPTokenizerFast"),qdo=o(" (GroupViT model)"),jdo=l(),ds=a("li"),ule=a("strong"),Ddo=o("herbert"),Gdo=o(" \u2014 "),JB=a("a"),Odo=o("HerbertTokenizer"),Vdo=o(" or "),YB=a("a"),Xdo=o("HerbertTokenizerFast"),zdo=o(" (HerBERT model)"),Qdo=l(),dh=a("li"),ble=a("strong"),Wdo=o("hubert"),Hdo=o(" \u2014 "),KB=a("a"),Udo=o("Wav2Vec2CTCTokenizer"),Jdo=o(" (Hubert model)"),Ydo=l(),cs=a("li"),vle=a("strong"),Kdo=o("ibert"),Zdo=o(" \u2014 "),ZB=a("a"),eco=o("RobertaTokenizer"),oco=o(" or "),eN=a("a"),rco=o("RobertaTokenizerFast"),tco=o(" (I-BERT model)"),aco=l(),fs=a("li"),Fle=a("strong"),nco=o("layoutlm"),sco=o(" \u2014 "),oN=a("a"),lco=o("LayoutLMTokenizer"),ico=o(" or "),rN=a("a"),dco=o("LayoutLMTokenizerFast"),cco=o(" (LayoutLM model)"),fco=l(),ms=a("li"),Tle=a("strong"),mco=o("layoutlmv2"),gco=o(" \u2014 "),tN=a("a"),hco=o("LayoutLMv2Tokenizer"),pco=o(" or "),aN=a("a"),_co=o("LayoutLMv2TokenizerFast"),uco=o(" (LayoutLMv2 model)"),bco=l(),gs=a("li"),Mle=a("strong"),vco=o("layoutlmv3"),Fco=o(" \u2014 "),nN=a("a"),Tco=o("LayoutLMv3Tokenizer"),Mco=o(" or "),sN=a("a"),Eco=o("LayoutLMv3TokenizerFast"),Cco=o(" (LayoutLMv3 model)"),wco=l(),hs=a("li"),Ele=a("strong"),Aco=o("layoutxlm"),Lco=o(" \u2014 "),lN=a("a"),yco=o("LayoutXLMTokenizer"),xco=o(" or "),iN=a("a"),$co=o("LayoutXLMTokenizerFast"),kco=o(" (LayoutXLM model)"),Sco=l(),ps=a("li"),Cle=a("strong"),Rco=o("led"),Pco=o(" \u2014 "),dN=a("a"),Bco=o("LEDTokenizer"),Nco=o(" or "),cN=a("a"),Ico=o("LEDTokenizerFast"),qco=o(" (LED model)"),jco=l(),_s=a("li"),wle=a("strong"),Dco=o("longformer"),Gco=o(" \u2014 "),fN=a("a"),Oco=o("LongformerTokenizer"),Vco=o(" or "),mN=a("a"),Xco=o("LongformerTokenizerFast"),zco=o(" (Longformer model)"),Qco=l(),us=a("li"),Ale=a("strong"),Wco=o("longt5"),Hco=o(" \u2014 "),gN=a("a"),Uco=o("T5Tokenizer"),Jco=o(" or "),hN=a("a"),Yco=o("T5TokenizerFast"),Kco=o(" (LongT5 model)"),Zco=l(),ch=a("li"),Lle=a("strong"),efo=o("luke"),ofo=o(" \u2014 "),pN=a("a"),rfo=o("LukeTokenizer"),tfo=o(" (LUKE model)"),afo=l(),bs=a("li"),yle=a("strong"),nfo=o("lxmert"),sfo=o(" \u2014 "),_N=a("a"),lfo=o("LxmertTokenizer"),ifo=o(" or "),uN=a("a"),dfo=o("LxmertTokenizerFast"),cfo=o(" (LXMERT model)"),ffo=l(),fh=a("li"),xle=a("strong"),mfo=o("m2m_100"),gfo=o(" \u2014 "),bN=a("a"),hfo=o("M2M100Tokenizer"),pfo=o(" (M2M100 model)"),_fo=l(),mh=a("li"),$le=a("strong"),ufo=o("marian"),bfo=o(" \u2014 "),vN=a("a"),vfo=o("MarianTokenizer"),Ffo=o(" (Marian model)"),Tfo=l(),vs=a("li"),kle=a("strong"),Mfo=o("mbart"),Efo=o(" \u2014 "),FN=a("a"),Cfo=o("MBartTokenizer"),wfo=o(" or "),TN=a("a"),Afo=o("MBartTokenizerFast"),Lfo=o(" (mBART model)"),yfo=l(),Fs=a("li"),Sle=a("strong"),xfo=o("mbart50"),$fo=o(" \u2014 "),MN=a("a"),kfo=o("MBart50Tokenizer"),Sfo=o(" or "),EN=a("a"),Rfo=o("MBart50TokenizerFast"),Pfo=o(" (mBART-50 model)"),Bfo=l(),Ts=a("li"),Rle=a("strong"),Nfo=o("megatron-bert"),Ifo=o(" \u2014 "),CN=a("a"),qfo=o("BertTokenizer"),jfo=o(" or "),wN=a("a"),Dfo=o("BertTokenizerFast"),Gfo=o(" (Megatron-BERT model)"),Ofo=l(),gh=a("li"),Ple=a("strong"),Vfo=o("mluke"),Xfo=o(" \u2014 "),AN=a("a"),zfo=o("MLukeTokenizer"),Qfo=o(" (mLUKE model)"),Wfo=l(),Ms=a("li"),Ble=a("strong"),Hfo=o("mobilebert"),Ufo=o(" \u2014 "),LN=a("a"),Jfo=o("MobileBertTokenizer"),Yfo=o(" or "),yN=a("a"),Kfo=o("MobileBertTokenizerFast"),Zfo=o(" (MobileBERT model)"),emo=l(),Es=a("li"),Nle=a("strong"),omo=o("mpnet"),rmo=o(" \u2014 "),xN=a("a"),tmo=o("MPNetTokenizer"),amo=o(" or "),$N=a("a"),nmo=o("MPNetTokenizerFast"),smo=o(" (MPNet model)"),lmo=l(),Cs=a("li"),Ile=a("strong"),imo=o("mt5"),dmo=o(" \u2014 "),kN=a("a"),cmo=o("MT5Tokenizer"),fmo=o(" or "),SN=a("a"),mmo=o("MT5TokenizerFast"),gmo=o(" (MT5 model)"),hmo=l(),ws=a("li"),qle=a("strong"),pmo=o("mvp"),_mo=o(" \u2014 "),RN=a("a"),umo=o("MvpTokenizer"),bmo=o(" or "),PN=a("a"),vmo=o("MvpTokenizerFast"),Fmo=o(" (MVP model)"),Tmo=l(),As=a("li"),jle=a("strong"),Mmo=o("nezha"),Emo=o(" \u2014 "),BN=a("a"),Cmo=o("BertTokenizer"),wmo=o(" or "),NN=a("a"),Amo=o("BertTokenizerFast"),Lmo=o(" (Nezha model)"),ymo=l(),Ls=a("li"),Dle=a("strong"),xmo=o("nystromformer"),$mo=o(" \u2014 "),IN=a("a"),kmo=o("AlbertTokenizer"),Smo=o(" or "),qN=a("a"),Rmo=o("AlbertTokenizerFast"),Pmo=o(" (Nystr\xF6mformer model)"),Bmo=l(),ys=a("li"),Gle=a("strong"),Nmo=o("openai-gpt"),Imo=o(" \u2014 "),jN=a("a"),qmo=o("OpenAIGPTTokenizer"),jmo=o(" or "),DN=a("a"),Dmo=o("OpenAIGPTTokenizerFast"),Gmo=o(" (OpenAI GPT model)"),Omo=l(),hh=a("li"),Ole=a("strong"),Vmo=o("opt"),Xmo=o(" \u2014 "),GN=a("a"),zmo=o("GPT2Tokenizer"),Qmo=o(" (OPT model)"),Wmo=l(),xs=a("li"),Vle=a("strong"),Hmo=o("pegasus"),Umo=o(" \u2014 "),ON=a("a"),Jmo=o("PegasusTokenizer"),Ymo=o(" or "),VN=a("a"),Kmo=o("PegasusTokenizerFast"),Zmo=o(" (Pegasus model)"),ego=l(),ph=a("li"),Xle=a("strong"),ogo=o("perceiver"),rgo=o(" \u2014 "),XN=a("a"),tgo=o("PerceiverTokenizer"),ago=o(" (Perceiver model)"),ngo=l(),_h=a("li"),zle=a("strong"),sgo=o("phobert"),lgo=o(" \u2014 "),zN=a("a"),igo=o("PhobertTokenizer"),dgo=o(" (PhoBERT model)"),cgo=l(),uh=a("li"),Qle=a("strong"),fgo=o("plbart"),mgo=o(" \u2014 "),QN=a("a"),ggo=o("PLBartTokenizer"),hgo=o(" (PLBart model)"),pgo=l(),bh=a("li"),Wle=a("strong"),_go=o("prophetnet"),ugo=o(" \u2014 "),WN=a("a"),bgo=o("ProphetNetTokenizer"),vgo=o(" (ProphetNet model)"),Fgo=l(),$s=a("li"),Hle=a("strong"),Tgo=o("qdqbert"),Mgo=o(" \u2014 "),HN=a("a"),Ego=o("BertTokenizer"),Cgo=o(" or "),UN=a("a"),wgo=o("BertTokenizerFast"),Ago=o(" (QDQBert model)"),Lgo=l(),vh=a("li"),Ule=a("strong"),ygo=o("rag"),xgo=o(" \u2014 "),JN=a("a"),$go=o("RagTokenizer"),kgo=o(" (RAG model)"),Sgo=l(),ks=a("li"),Jle=a("strong"),Rgo=o("realm"),Pgo=o(" \u2014 "),YN=a("a"),Bgo=o("RealmTokenizer"),Ngo=o(" or "),KN=a("a"),Igo=o("RealmTokenizerFast"),qgo=o(" (REALM model)"),jgo=l(),Ss=a("li"),Yle=a("strong"),Dgo=o("reformer"),Ggo=o(" \u2014 "),ZN=a("a"),Ogo=o("ReformerTokenizer"),Vgo=o(" or "),eI=a("a"),Xgo=o("ReformerTokenizerFast"),zgo=o(" (Reformer model)"),Qgo=l(),Rs=a("li"),Kle=a("strong"),Wgo=o("rembert"),Hgo=o(" \u2014 "),oI=a("a"),Ugo=o("RemBertTokenizer"),Jgo=o(" or "),rI=a("a"),Ygo=o("RemBertTokenizerFast"),Kgo=o(" (RemBERT model)"),Zgo=l(),Ps=a("li"),Zle=a("strong"),eho=o("retribert"),oho=o(" \u2014 "),tI=a("a"),rho=o("RetriBertTokenizer"),tho=o(" or "),aI=a("a"),aho=o("RetriBertTokenizerFast"),nho=o(" (RetriBERT model)"),sho=l(),Bs=a("li"),eie=a("strong"),lho=o("roberta"),iho=o(" \u2014 "),nI=a("a"),dho=o("RobertaTokenizer"),cho=o(" or "),sI=a("a"),fho=o("RobertaTokenizerFast"),mho=o(" (RoBERTa model)"),gho=l(),Ns=a("li"),oie=a("strong"),hho=o("roformer"),pho=o(" \u2014 "),lI=a("a"),_ho=o("RoFormerTokenizer"),uho=o(" or "),iI=a("a"),bho=o("RoFormerTokenizerFast"),vho=o(" (RoFormer model)"),Fho=l(),Fh=a("li"),rie=a("strong"),Tho=o("speech_to_text"),Mho=o(" \u2014 "),dI=a("a"),Eho=o("Speech2TextTokenizer"),Cho=o(" (Speech2Text model)"),who=l(),Th=a("li"),tie=a("strong"),Aho=o("speech_to_text_2"),Lho=o(" \u2014 "),cI=a("a"),yho=o("Speech2Text2Tokenizer"),xho=o(" (Speech2Text2 model)"),$ho=l(),Is=a("li"),aie=a("strong"),kho=o("splinter"),Sho=o(" \u2014 "),fI=a("a"),Rho=o("SplinterTokenizer"),Pho=o(" or "),mI=a("a"),Bho=o("SplinterTokenizerFast"),Nho=o(" (Splinter model)"),Iho=l(),qs=a("li"),nie=a("strong"),qho=o("squeezebert"),jho=o(" \u2014 "),gI=a("a"),Dho=o("SqueezeBertTokenizer"),Gho=o(" or "),hI=a("a"),Oho=o("SqueezeBertTokenizerFast"),Vho=o(" (SqueezeBERT model)"),Xho=l(),js=a("li"),sie=a("strong"),zho=o("t5"),Qho=o(" \u2014 "),pI=a("a"),Who=o("T5Tokenizer"),Hho=o(" or "),_I=a("a"),Uho=o("T5TokenizerFast"),Jho=o(" (T5 model)"),Yho=l(),Mh=a("li"),lie=a("strong"),Kho=o("tapas"),Zho=o(" \u2014 "),uI=a("a"),epo=o("TapasTokenizer"),opo=o(" (TAPAS model)"),rpo=l(),Eh=a("li"),iie=a("strong"),tpo=o("tapex"),apo=o(" \u2014 "),bI=a("a"),npo=o("TapexTokenizer"),spo=o(" (TAPEX model)"),lpo=l(),Ch=a("li"),die=a("strong"),ipo=o("transfo-xl"),dpo=o(" \u2014 "),vI=a("a"),cpo=o("TransfoXLTokenizer"),fpo=o(" (Transformer-XL model)"),mpo=l(),Ds=a("li"),cie=a("strong"),gpo=o("vilt"),hpo=o(" \u2014 "),FI=a("a"),ppo=o("BertTokenizer"),_po=o(" or "),TI=a("a"),upo=o("BertTokenizerFast"),bpo=o(" (ViLT model)"),vpo=l(),Gs=a("li"),fie=a("strong"),Fpo=o("visual_bert"),Tpo=o(" \u2014 "),MI=a("a"),Mpo=o("BertTokenizer"),Epo=o(" or "),EI=a("a"),Cpo=o("BertTokenizerFast"),wpo=o(" (VisualBERT model)"),Apo=l(),wh=a("li"),mie=a("strong"),Lpo=o("wav2vec2"),ypo=o(" \u2014 "),CI=a("a"),xpo=o("Wav2Vec2CTCTokenizer"),$po=o(" (Wav2Vec2 model)"),kpo=l(),Ah=a("li"),gie=a("strong"),Spo=o("wav2vec2-conformer"),Rpo=o(" \u2014 "),wI=a("a"),Ppo=o("Wav2Vec2CTCTokenizer"),Bpo=o(" (Wav2Vec2-Conformer model)"),Npo=l(),Lh=a("li"),hie=a("strong"),Ipo=o("wav2vec2_phoneme"),qpo=o(" \u2014 "),AI=a("a"),jpo=o("Wav2Vec2PhonemeCTCTokenizer"),Dpo=o(" (Wav2Vec2Phoneme model)"),Gpo=l(),Os=a("li"),pie=a("strong"),Opo=o("xglm"),Vpo=o(" \u2014 "),LI=a("a"),Xpo=o("XGLMTokenizer"),zpo=o(" or "),yI=a("a"),Qpo=o("XGLMTokenizerFast"),Wpo=o(" (XGLM model)"),Hpo=l(),yh=a("li"),_ie=a("strong"),Upo=o("xlm"),Jpo=o(" \u2014 "),xI=a("a"),Ypo=o("XLMTokenizer"),Kpo=o(" (XLM model)"),Zpo=l(),xh=a("li"),uie=a("strong"),e_o=o("xlm-prophetnet"),o_o=o(" \u2014 "),$I=a("a"),r_o=o("XLMProphetNetTokenizer"),t_o=o(" (XLM-ProphetNet model)"),a_o=l(),Vs=a("li"),bie=a("strong"),n_o=o("xlm-roberta"),s_o=o(" \u2014 "),kI=a("a"),l_o=o("XLMRobertaTokenizer"),i_o=o(" or "),SI=a("a"),d_o=o("XLMRobertaTokenizerFast"),c_o=o(" (XLM-RoBERTa model)"),f_o=l(),Xs=a("li"),vie=a("strong"),m_o=o("xlm-roberta-xl"),g_o=o(" \u2014 "),RI=a("a"),h_o=o("RobertaTokenizer"),p_o=o(" or "),PI=a("a"),__o=o("RobertaTokenizerFast"),u_o=o(" (XLM-RoBERTa-XL model)"),b_o=l(),zs=a("li"),Fie=a("strong"),v_o=o("xlnet"),F_o=o(" \u2014 "),BI=a("a"),T_o=o("XLNetTokenizer"),M_o=o(" or "),NI=a("a"),E_o=o("XLNetTokenizerFast"),C_o=o(" (XLNet model)"),w_o=l(),Qs=a("li"),Tie=a("strong"),A_o=o("yoso"),L_o=o(" \u2014 "),II=a("a"),y_o=o("AlbertTokenizer"),x_o=o(" or "),qI=a("a"),$_o=o("AlbertTokenizerFast"),k_o=o(" (YOSO model)"),S_o=l(),F($h.$$.fragment),R_o=l(),kh=a("div"),F(cy.$$.fragment),P_o=l(),Mie=a("p"),B_o=o("Register a new tokenizer in this mapping."),kVe=l(),Ni=a("h2"),Sh=a("a"),Eie=a("span"),F(fy.$$.fragment),N_o=l(),Cie=a("span"),I_o=o("AutoFeatureExtractor"),SVe=l(),Lo=a("div"),F(my.$$.fragment),q_o=l(),gy=a("p"),j_o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),jI=a("a"),D_o=o("AutoFeatureExtractor.from_pretrained()"),G_o=o(" class method."),O_o=l(),hy=a("p"),V_o=o("This class cannot be instantiated directly using "),wie=a("code"),X_o=o("__init__()"),z_o=o(" (throws an error)."),Q_o=l(),He=a("div"),F(py.$$.fragment),W_o=l(),Aie=a("p"),H_o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),U_o=l(),Pa=a("p"),J_o=o("The feature extractor class to instantiate is selected based on the "),Lie=a("code"),Y_o=o("model_type"),K_o=o(` property of the config object
(either passed as an argument or loaded from `),yie=a("code"),Z_o=o("pretrained_model_name_or_path"),euo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),xie=a("code"),ouo=o("pretrained_model_name_or_path"),ruo=o(":"),tuo=l(),Y=a("ul"),Rh=a("li"),$ie=a("strong"),auo=o("beit"),nuo=o(" \u2014 "),DI=a("a"),suo=o("BeitFeatureExtractor"),luo=o(" (BEiT model)"),iuo=l(),Ph=a("li"),kie=a("strong"),duo=o("clip"),cuo=o(" \u2014 "),GI=a("a"),fuo=o("CLIPFeatureExtractor"),muo=o(" (CLIP model)"),guo=l(),Bh=a("li"),Sie=a("strong"),huo=o("convnext"),puo=o(" \u2014 "),OI=a("a"),_uo=o("ConvNextFeatureExtractor"),uuo=o(" (ConvNeXT model)"),buo=l(),Nh=a("li"),Rie=a("strong"),vuo=o("cvt"),Fuo=o(" \u2014 "),VI=a("a"),Tuo=o("ConvNextFeatureExtractor"),Muo=o(" (CvT model)"),Euo=l(),Ih=a("li"),Pie=a("strong"),Cuo=o("data2vec-audio"),wuo=o(" \u2014 "),XI=a("a"),Auo=o("Wav2Vec2FeatureExtractor"),Luo=o(" (Data2VecAudio model)"),yuo=l(),qh=a("li"),Bie=a("strong"),xuo=o("data2vec-vision"),$uo=o(" \u2014 "),zI=a("a"),kuo=o("BeitFeatureExtractor"),Suo=o(" (Data2VecVision model)"),Ruo=l(),jh=a("li"),Nie=a("strong"),Puo=o("deit"),Buo=o(" \u2014 "),QI=a("a"),Nuo=o("DeiTFeatureExtractor"),Iuo=o(" (DeiT model)"),quo=l(),Dh=a("li"),Iie=a("strong"),juo=o("detr"),Duo=o(" \u2014 "),WI=a("a"),Guo=o("DetrFeatureExtractor"),Ouo=o(" (DETR model)"),Vuo=l(),Gh=a("li"),qie=a("strong"),Xuo=o("dpt"),zuo=o(" \u2014 "),HI=a("a"),Quo=o("DPTFeatureExtractor"),Wuo=o(" (DPT model)"),Huo=l(),Oh=a("li"),jie=a("strong"),Uuo=o("flava"),Juo=o(" \u2014 "),UI=a("a"),Yuo=o("FlavaFeatureExtractor"),Kuo=o(" (FLAVA model)"),Zuo=l(),Vh=a("li"),Die=a("strong"),e2o=o("glpn"),o2o=o(" \u2014 "),JI=a("a"),r2o=o("GLPNFeatureExtractor"),t2o=o(" (GLPN model)"),a2o=l(),Xh=a("li"),Gie=a("strong"),n2o=o("groupvit"),s2o=o(" \u2014 "),YI=a("a"),l2o=o("CLIPFeatureExtractor"),i2o=o(" (GroupViT model)"),d2o=l(),zh=a("li"),Oie=a("strong"),c2o=o("hubert"),f2o=o(" \u2014 "),KI=a("a"),m2o=o("Wav2Vec2FeatureExtractor"),g2o=o(" (Hubert model)"),h2o=l(),Qh=a("li"),Vie=a("strong"),p2o=o("imagegpt"),_2o=o(" \u2014 "),ZI=a("a"),u2o=o("ImageGPTFeatureExtractor"),b2o=o(" (ImageGPT model)"),v2o=l(),Wh=a("li"),Xie=a("strong"),F2o=o("layoutlmv2"),T2o=o(" \u2014 "),eq=a("a"),M2o=o("LayoutLMv2FeatureExtractor"),E2o=o(" (LayoutLMv2 model)"),C2o=l(),Hh=a("li"),zie=a("strong"),w2o=o("layoutlmv3"),A2o=o(" \u2014 "),oq=a("a"),L2o=o("LayoutLMv3FeatureExtractor"),y2o=o(" (LayoutLMv3 model)"),x2o=l(),Uh=a("li"),Qie=a("strong"),$2o=o("levit"),k2o=o(" \u2014 "),rq=a("a"),S2o=o("LevitFeatureExtractor"),R2o=o(" (LeViT model)"),P2o=l(),Jh=a("li"),Wie=a("strong"),B2o=o("maskformer"),N2o=o(" \u2014 "),tq=a("a"),I2o=o("MaskFormerFeatureExtractor"),q2o=o(" (MaskFormer model)"),j2o=l(),Yh=a("li"),Hie=a("strong"),D2o=o("mctct"),G2o=o(" \u2014 "),aq=a("a"),O2o=o("MCTCTFeatureExtractor"),V2o=o(" (M-CTC-T model)"),X2o=l(),Kh=a("li"),Uie=a("strong"),z2o=o("perceiver"),Q2o=o(" \u2014 "),nq=a("a"),W2o=o("PerceiverFeatureExtractor"),H2o=o(" (Perceiver model)"),U2o=l(),Zh=a("li"),Jie=a("strong"),J2o=o("poolformer"),Y2o=o(" \u2014 "),sq=a("a"),K2o=o("PoolFormerFeatureExtractor"),Z2o=o(" (PoolFormer model)"),e1o=l(),ep=a("li"),Yie=a("strong"),o1o=o("regnet"),r1o=o(" \u2014 "),lq=a("a"),t1o=o("ConvNextFeatureExtractor"),a1o=o(" (RegNet model)"),n1o=l(),op=a("li"),Kie=a("strong"),s1o=o("resnet"),l1o=o(" \u2014 "),iq=a("a"),i1o=o("ConvNextFeatureExtractor"),d1o=o(" (ResNet model)"),c1o=l(),rp=a("li"),Zie=a("strong"),f1o=o("segformer"),m1o=o(" \u2014 "),dq=a("a"),g1o=o("SegformerFeatureExtractor"),h1o=o(" (SegFormer model)"),p1o=l(),tp=a("li"),ede=a("strong"),_1o=o("speech_to_text"),u1o=o(" \u2014 "),cq=a("a"),b1o=o("Speech2TextFeatureExtractor"),v1o=o(" (Speech2Text model)"),F1o=l(),ap=a("li"),ode=a("strong"),T1o=o("swin"),M1o=o(" \u2014 "),fq=a("a"),E1o=o("ViTFeatureExtractor"),C1o=o(" (Swin Transformer model)"),w1o=l(),np=a("li"),rde=a("strong"),A1o=o("van"),L1o=o(" \u2014 "),mq=a("a"),y1o=o("ConvNextFeatureExtractor"),x1o=o(" (VAN model)"),$1o=l(),sp=a("li"),tde=a("strong"),k1o=o("vilt"),S1o=o(" \u2014 "),gq=a("a"),R1o=o("ViltFeatureExtractor"),P1o=o(" (ViLT model)"),B1o=l(),lp=a("li"),ade=a("strong"),N1o=o("vit"),I1o=o(" \u2014 "),hq=a("a"),q1o=o("ViTFeatureExtractor"),j1o=o(" (ViT model)"),D1o=l(),ip=a("li"),nde=a("strong"),G1o=o("vit_mae"),O1o=o(" \u2014 "),pq=a("a"),V1o=o("ViTFeatureExtractor"),X1o=o(" (ViTMAE model)"),z1o=l(),dp=a("li"),sde=a("strong"),Q1o=o("wav2vec2"),W1o=o(" \u2014 "),_q=a("a"),H1o=o("Wav2Vec2FeatureExtractor"),U1o=o(" (Wav2Vec2 model)"),J1o=l(),cp=a("li"),lde=a("strong"),Y1o=o("wav2vec2-conformer"),K1o=o(" \u2014 "),uq=a("a"),Z1o=o("Wav2Vec2FeatureExtractor"),e7o=o(" (Wav2Vec2-Conformer model)"),o7o=l(),fp=a("li"),ide=a("strong"),r7o=o("yolos"),t7o=o(" \u2014 "),bq=a("a"),a7o=o("YolosFeatureExtractor"),n7o=o(" (YOLOS model)"),s7o=l(),F(mp.$$.fragment),l7o=l(),F(gp.$$.fragment),i7o=l(),hp=a("div"),F(_y.$$.fragment),d7o=l(),dde=a("p"),c7o=o("Register a new feature extractor for this class."),RVe=l(),Ii=a("h2"),pp=a("a"),cde=a("span"),F(uy.$$.fragment),f7o=l(),fde=a("span"),m7o=o("AutoProcessor"),PVe=l(),yo=a("div"),F(by.$$.fragment),g7o=l(),vy=a("p"),h7o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),vq=a("a"),p7o=o("AutoProcessor.from_pretrained()"),_7o=o(" class method."),u7o=l(),Fy=a("p"),b7o=o("This class cannot be instantiated directly using "),mde=a("code"),v7o=o("__init__()"),F7o=o(" (throws an error)."),T7o=l(),Ue=a("div"),F(Ty.$$.fragment),M7o=l(),gde=a("p"),E7o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),C7o=l(),qi=a("p"),w7o=o("The processor class to instantiate is selected based on the "),hde=a("code"),A7o=o("model_type"),L7o=o(` property of the config object (either
passed as an argument or loaded from `),pde=a("code"),y7o=o("pretrained_model_name_or_path"),x7o=o(" if possible):"),$7o=l(),he=a("ul"),_p=a("li"),_de=a("strong"),k7o=o("clip"),S7o=o(" \u2014 "),Fq=a("a"),R7o=o("CLIPProcessor"),P7o=o(" (CLIP model)"),B7o=l(),up=a("li"),ude=a("strong"),N7o=o("flava"),I7o=o(" \u2014 "),bde=a("code"),q7o=o("FLAVAProcessor"),j7o=o(" (FLAVA model)"),D7o=l(),bp=a("li"),vde=a("strong"),G7o=o("groupvit"),O7o=o(" \u2014 "),Tq=a("a"),V7o=o("CLIPProcessor"),X7o=o(" (GroupViT model)"),z7o=l(),vp=a("li"),Fde=a("strong"),Q7o=o("layoutlmv2"),W7o=o(" \u2014 "),Mq=a("a"),H7o=o("LayoutLMv2Processor"),U7o=o(" (LayoutLMv2 model)"),J7o=l(),Fp=a("li"),Tde=a("strong"),Y7o=o("layoutlmv3"),K7o=o(" \u2014 "),Eq=a("a"),Z7o=o("LayoutLMv3Processor"),e4o=o(" (LayoutLMv3 model)"),o4o=l(),Tp=a("li"),Mde=a("strong"),r4o=o("layoutxlm"),t4o=o(" \u2014 "),Cq=a("a"),a4o=o("LayoutXLMProcessor"),n4o=o(" (LayoutXLM model)"),s4o=l(),Mp=a("li"),Ede=a("strong"),l4o=o("sew"),i4o=o(" \u2014 "),wq=a("a"),d4o=o("Wav2Vec2Processor"),c4o=o(" (SEW model)"),f4o=l(),Ep=a("li"),Cde=a("strong"),m4o=o("sew-d"),g4o=o(" \u2014 "),Aq=a("a"),h4o=o("Wav2Vec2Processor"),p4o=o(" (SEW-D model)"),_4o=l(),Cp=a("li"),wde=a("strong"),u4o=o("speech_to_text"),b4o=o(" \u2014 "),Lq=a("a"),v4o=o("Speech2TextProcessor"),F4o=o(" (Speech2Text model)"),T4o=l(),wp=a("li"),Ade=a("strong"),M4o=o("speech_to_text_2"),E4o=o(" \u2014 "),yq=a("a"),C4o=o("Speech2Text2Processor"),w4o=o(" (Speech2Text2 model)"),A4o=l(),Ap=a("li"),Lde=a("strong"),L4o=o("trocr"),y4o=o(" \u2014 "),xq=a("a"),x4o=o("TrOCRProcessor"),$4o=o(" (TrOCR model)"),k4o=l(),Lp=a("li"),yde=a("strong"),S4o=o("unispeech"),R4o=o(" \u2014 "),$q=a("a"),P4o=o("Wav2Vec2Processor"),B4o=o(" (UniSpeech model)"),N4o=l(),yp=a("li"),xde=a("strong"),I4o=o("unispeech-sat"),q4o=o(" \u2014 "),kq=a("a"),j4o=o("Wav2Vec2Processor"),D4o=o(" (UniSpeechSat model)"),G4o=l(),xp=a("li"),$de=a("strong"),O4o=o("vilt"),V4o=o(" \u2014 "),Sq=a("a"),X4o=o("ViltProcessor"),z4o=o(" (ViLT model)"),Q4o=l(),$p=a("li"),kde=a("strong"),W4o=o("vision-text-dual-encoder"),H4o=o(" \u2014 "),Rq=a("a"),U4o=o("VisionTextDualEncoderProcessor"),J4o=o(" (VisionTextDualEncoder model)"),Y4o=l(),kp=a("li"),Sde=a("strong"),K4o=o("wav2vec2"),Z4o=o(" \u2014 "),Pq=a("a"),ebo=o("Wav2Vec2Processor"),obo=o(" (Wav2Vec2 model)"),rbo=l(),Sp=a("li"),Rde=a("strong"),tbo=o("wav2vec2-conformer"),abo=o(" \u2014 "),Bq=a("a"),nbo=o("Wav2Vec2Processor"),sbo=o(" (Wav2Vec2-Conformer model)"),lbo=l(),Rp=a("li"),Pde=a("strong"),ibo=o("wavlm"),dbo=o(" \u2014 "),Nq=a("a"),cbo=o("Wav2Vec2Processor"),fbo=o(" (WavLM model)"),mbo=l(),F(Pp.$$.fragment),gbo=l(),F(Bp.$$.fragment),hbo=l(),Np=a("div"),F(My.$$.fragment),pbo=l(),Bde=a("p"),_bo=o("Register a new processor for this class."),BVe=l(),ji=a("h2"),Ip=a("a"),Nde=a("span"),F(Ey.$$.fragment),ubo=l(),Ide=a("span"),bbo=o("AutoModel"),NVe=l(),xo=a("div"),F(Cy.$$.fragment),vbo=l(),Di=a("p"),Fbo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Iq=a("a"),Tbo=o("from_pretrained()"),Mbo=o(" class method or the "),qq=a("a"),Ebo=o("from_config()"),Cbo=o(` class
method.`),wbo=l(),wy=a("p"),Abo=o("This class cannot be instantiated directly using "),qde=a("code"),Lbo=o("__init__()"),ybo=o(" (throws an error)."),xbo=l(),st=a("div"),F(Ay.$$.fragment),$bo=l(),jde=a("p"),kbo=o("Instantiates one of the base model classes of the library from a configuration."),Sbo=l(),Gi=a("p"),Rbo=o(`Note:
Loading a model from its configuration file does `),Dde=a("strong"),Pbo=o("not"),Bbo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jq=a("a"),Nbo=o("from_pretrained()"),Ibo=o(" to load the model weights."),qbo=l(),F(qp.$$.fragment),jbo=l(),Je=a("div"),F(Ly.$$.fragment),Dbo=l(),Gde=a("p"),Gbo=o("Instantiate one of the base model classes of the library from a pretrained model."),Obo=l(),Ba=a("p"),Vbo=o("The model class to instantiate is selected based on the "),Ode=a("code"),Xbo=o("model_type"),zbo=o(` property of the config object (either
passed as an argument or loaded from `),Vde=a("code"),Qbo=o("pretrained_model_name_or_path"),Wbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xde=a("code"),Hbo=o("pretrained_model_name_or_path"),Ubo=o(":"),Jbo=l(),y=a("ul"),jp=a("li"),zde=a("strong"),Ybo=o("albert"),Kbo=o(" \u2014 "),Dq=a("a"),Zbo=o("AlbertModel"),evo=o(" (ALBERT model)"),ovo=l(),Dp=a("li"),Qde=a("strong"),rvo=o("bart"),tvo=o(" \u2014 "),Gq=a("a"),avo=o("BartModel"),nvo=o(" (BART model)"),svo=l(),Gp=a("li"),Wde=a("strong"),lvo=o("beit"),ivo=o(" \u2014 "),Oq=a("a"),dvo=o("BeitModel"),cvo=o(" (BEiT model)"),fvo=l(),Op=a("li"),Hde=a("strong"),mvo=o("bert"),gvo=o(" \u2014 "),Vq=a("a"),hvo=o("BertModel"),pvo=o(" (BERT model)"),_vo=l(),Vp=a("li"),Ude=a("strong"),uvo=o("bert-generation"),bvo=o(" \u2014 "),Xq=a("a"),vvo=o("BertGenerationEncoder"),Fvo=o(" (Bert Generation model)"),Tvo=l(),Xp=a("li"),Jde=a("strong"),Mvo=o("big_bird"),Evo=o(" \u2014 "),zq=a("a"),Cvo=o("BigBirdModel"),wvo=o(" (BigBird model)"),Avo=l(),zp=a("li"),Yde=a("strong"),Lvo=o("bigbird_pegasus"),yvo=o(" \u2014 "),Qq=a("a"),xvo=o("BigBirdPegasusModel"),$vo=o(" (BigBird-Pegasus model)"),kvo=l(),Qp=a("li"),Kde=a("strong"),Svo=o("blenderbot"),Rvo=o(" \u2014 "),Wq=a("a"),Pvo=o("BlenderbotModel"),Bvo=o(" (Blenderbot model)"),Nvo=l(),Wp=a("li"),Zde=a("strong"),Ivo=o("blenderbot-small"),qvo=o(" \u2014 "),Hq=a("a"),jvo=o("BlenderbotSmallModel"),Dvo=o(" (BlenderbotSmall model)"),Gvo=l(),Hp=a("li"),ece=a("strong"),Ovo=o("bloom"),Vvo=o(" \u2014 "),Uq=a("a"),Xvo=o("BloomModel"),zvo=o(" (BLOOM model)"),Qvo=l(),Up=a("li"),oce=a("strong"),Wvo=o("camembert"),Hvo=o(" \u2014 "),Jq=a("a"),Uvo=o("CamembertModel"),Jvo=o(" (CamemBERT model)"),Yvo=l(),Jp=a("li"),rce=a("strong"),Kvo=o("canine"),Zvo=o(" \u2014 "),Yq=a("a"),eFo=o("CanineModel"),oFo=o(" (CANINE model)"),rFo=l(),Yp=a("li"),tce=a("strong"),tFo=o("clip"),aFo=o(" \u2014 "),Kq=a("a"),nFo=o("CLIPModel"),sFo=o(" (CLIP model)"),lFo=l(),Kp=a("li"),ace=a("strong"),iFo=o("codegen"),dFo=o(" \u2014 "),Zq=a("a"),cFo=o("CodeGenModel"),fFo=o(" (CodeGen model)"),mFo=l(),Zp=a("li"),nce=a("strong"),gFo=o("convbert"),hFo=o(" \u2014 "),ej=a("a"),pFo=o("ConvBertModel"),_Fo=o(" (ConvBERT model)"),uFo=l(),e_=a("li"),sce=a("strong"),bFo=o("convnext"),vFo=o(" \u2014 "),oj=a("a"),FFo=o("ConvNextModel"),TFo=o(" (ConvNeXT model)"),MFo=l(),o_=a("li"),lce=a("strong"),EFo=o("ctrl"),CFo=o(" \u2014 "),rj=a("a"),wFo=o("CTRLModel"),AFo=o(" (CTRL model)"),LFo=l(),r_=a("li"),ice=a("strong"),yFo=o("cvt"),xFo=o(" \u2014 "),tj=a("a"),$Fo=o("CvtModel"),kFo=o(" (CvT model)"),SFo=l(),t_=a("li"),dce=a("strong"),RFo=o("data2vec-audio"),PFo=o(" \u2014 "),aj=a("a"),BFo=o("Data2VecAudioModel"),NFo=o(" (Data2VecAudio model)"),IFo=l(),a_=a("li"),cce=a("strong"),qFo=o("data2vec-text"),jFo=o(" \u2014 "),nj=a("a"),DFo=o("Data2VecTextModel"),GFo=o(" (Data2VecText model)"),OFo=l(),n_=a("li"),fce=a("strong"),VFo=o("data2vec-vision"),XFo=o(" \u2014 "),sj=a("a"),zFo=o("Data2VecVisionModel"),QFo=o(" (Data2VecVision model)"),WFo=l(),s_=a("li"),mce=a("strong"),HFo=o("deberta"),UFo=o(" \u2014 "),lj=a("a"),JFo=o("DebertaModel"),YFo=o(" (DeBERTa model)"),KFo=l(),l_=a("li"),gce=a("strong"),ZFo=o("deberta-v2"),eTo=o(" \u2014 "),ij=a("a"),oTo=o("DebertaV2Model"),rTo=o(" (DeBERTa-v2 model)"),tTo=l(),i_=a("li"),hce=a("strong"),aTo=o("decision_transformer"),nTo=o(" \u2014 "),dj=a("a"),sTo=o("DecisionTransformerModel"),lTo=o(" (Decision Transformer model)"),iTo=l(),d_=a("li"),pce=a("strong"),dTo=o("deit"),cTo=o(" \u2014 "),cj=a("a"),fTo=o("DeiTModel"),mTo=o(" (DeiT model)"),gTo=l(),c_=a("li"),_ce=a("strong"),hTo=o("detr"),pTo=o(" \u2014 "),fj=a("a"),_To=o("DetrModel"),uTo=o(" (DETR model)"),bTo=l(),f_=a("li"),uce=a("strong"),vTo=o("distilbert"),FTo=o(" \u2014 "),mj=a("a"),TTo=o("DistilBertModel"),MTo=o(" (DistilBERT model)"),ETo=l(),m_=a("li"),bce=a("strong"),CTo=o("dpr"),wTo=o(" \u2014 "),gj=a("a"),ATo=o("DPRQuestionEncoder"),LTo=o(" (DPR model)"),yTo=l(),g_=a("li"),vce=a("strong"),xTo=o("dpt"),$To=o(" \u2014 "),hj=a("a"),kTo=o("DPTModel"),STo=o(" (DPT model)"),RTo=l(),h_=a("li"),Fce=a("strong"),PTo=o("electra"),BTo=o(" \u2014 "),pj=a("a"),NTo=o("ElectraModel"),ITo=o(" (ELECTRA model)"),qTo=l(),p_=a("li"),Tce=a("strong"),jTo=o("flaubert"),DTo=o(" \u2014 "),_j=a("a"),GTo=o("FlaubertModel"),OTo=o(" (FlauBERT model)"),VTo=l(),__=a("li"),Mce=a("strong"),XTo=o("flava"),zTo=o(" \u2014 "),uj=a("a"),QTo=o("FlavaModel"),WTo=o(" (FLAVA model)"),HTo=l(),u_=a("li"),Ece=a("strong"),UTo=o("fnet"),JTo=o(" \u2014 "),bj=a("a"),YTo=o("FNetModel"),KTo=o(" (FNet model)"),ZTo=l(),b_=a("li"),Cce=a("strong"),eMo=o("fsmt"),oMo=o(" \u2014 "),vj=a("a"),rMo=o("FSMTModel"),tMo=o(" (FairSeq Machine-Translation model)"),aMo=l(),Ws=a("li"),wce=a("strong"),nMo=o("funnel"),sMo=o(" \u2014 "),Fj=a("a"),lMo=o("FunnelModel"),iMo=o(" or "),Tj=a("a"),dMo=o("FunnelBaseModel"),cMo=o(" (Funnel Transformer model)"),fMo=l(),v_=a("li"),Ace=a("strong"),mMo=o("glpn"),gMo=o(" \u2014 "),Mj=a("a"),hMo=o("GLPNModel"),pMo=o(" (GLPN model)"),_Mo=l(),F_=a("li"),Lce=a("strong"),uMo=o("gpt2"),bMo=o(" \u2014 "),Ej=a("a"),vMo=o("GPT2Model"),FMo=o(" (OpenAI GPT-2 model)"),TMo=l(),T_=a("li"),yce=a("strong"),MMo=o("gpt_neo"),EMo=o(" \u2014 "),Cj=a("a"),CMo=o("GPTNeoModel"),wMo=o(" (GPT Neo model)"),AMo=l(),M_=a("li"),xce=a("strong"),LMo=o("gpt_neox"),yMo=o(" \u2014 "),wj=a("a"),xMo=o("GPTNeoXModel"),$Mo=o(" (GPT NeoX model)"),kMo=l(),E_=a("li"),$ce=a("strong"),SMo=o("gptj"),RMo=o(" \u2014 "),Aj=a("a"),PMo=o("GPTJModel"),BMo=o(" (GPT-J model)"),NMo=l(),C_=a("li"),kce=a("strong"),IMo=o("groupvit"),qMo=o(" \u2014 "),Lj=a("a"),jMo=o("GroupViTModel"),DMo=o(" (GroupViT model)"),GMo=l(),w_=a("li"),Sce=a("strong"),OMo=o("hubert"),VMo=o(" \u2014 "),yj=a("a"),XMo=o("HubertModel"),zMo=o(" (Hubert model)"),QMo=l(),A_=a("li"),Rce=a("strong"),WMo=o("ibert"),HMo=o(" \u2014 "),xj=a("a"),UMo=o("IBertModel"),JMo=o(" (I-BERT model)"),YMo=l(),L_=a("li"),Pce=a("strong"),KMo=o("imagegpt"),ZMo=o(" \u2014 "),$j=a("a"),eEo=o("ImageGPTModel"),oEo=o(" (ImageGPT model)"),rEo=l(),y_=a("li"),Bce=a("strong"),tEo=o("layoutlm"),aEo=o(" \u2014 "),kj=a("a"),nEo=o("LayoutLMModel"),sEo=o(" (LayoutLM model)"),lEo=l(),x_=a("li"),Nce=a("strong"),iEo=o("layoutlmv2"),dEo=o(" \u2014 "),Sj=a("a"),cEo=o("LayoutLMv2Model"),fEo=o(" (LayoutLMv2 model)"),mEo=l(),$_=a("li"),Ice=a("strong"),gEo=o("layoutlmv3"),hEo=o(" \u2014 "),Rj=a("a"),pEo=o("LayoutLMv3Model"),_Eo=o(" (LayoutLMv3 model)"),uEo=l(),k_=a("li"),qce=a("strong"),bEo=o("led"),vEo=o(" \u2014 "),Pj=a("a"),FEo=o("LEDModel"),TEo=o(" (LED model)"),MEo=l(),S_=a("li"),jce=a("strong"),EEo=o("levit"),CEo=o(" \u2014 "),Bj=a("a"),wEo=o("LevitModel"),AEo=o(" (LeViT model)"),LEo=l(),R_=a("li"),Dce=a("strong"),yEo=o("longformer"),xEo=o(" \u2014 "),Nj=a("a"),$Eo=o("LongformerModel"),kEo=o(" (Longformer model)"),SEo=l(),P_=a("li"),Gce=a("strong"),REo=o("longt5"),PEo=o(" \u2014 "),Ij=a("a"),BEo=o("LongT5Model"),NEo=o(" (LongT5 model)"),IEo=l(),B_=a("li"),Oce=a("strong"),qEo=o("luke"),jEo=o(" \u2014 "),qj=a("a"),DEo=o("LukeModel"),GEo=o(" (LUKE model)"),OEo=l(),N_=a("li"),Vce=a("strong"),VEo=o("lxmert"),XEo=o(" \u2014 "),jj=a("a"),zEo=o("LxmertModel"),QEo=o(" (LXMERT model)"),WEo=l(),I_=a("li"),Xce=a("strong"),HEo=o("m2m_100"),UEo=o(" \u2014 "),Dj=a("a"),JEo=o("M2M100Model"),YEo=o(" (M2M100 model)"),KEo=l(),q_=a("li"),zce=a("strong"),ZEo=o("marian"),eCo=o(" \u2014 "),Gj=a("a"),oCo=o("MarianModel"),rCo=o(" (Marian model)"),tCo=l(),j_=a("li"),Qce=a("strong"),aCo=o("maskformer"),nCo=o(" \u2014 "),Oj=a("a"),sCo=o("MaskFormerModel"),lCo=o(" (MaskFormer model)"),iCo=l(),D_=a("li"),Wce=a("strong"),dCo=o("mbart"),cCo=o(" \u2014 "),Vj=a("a"),fCo=o("MBartModel"),mCo=o(" (mBART model)"),gCo=l(),G_=a("li"),Hce=a("strong"),hCo=o("mctct"),pCo=o(" \u2014 "),Xj=a("a"),_Co=o("MCTCTModel"),uCo=o(" (M-CTC-T model)"),bCo=l(),O_=a("li"),Uce=a("strong"),vCo=o("megatron-bert"),FCo=o(" \u2014 "),zj=a("a"),TCo=o("MegatronBertModel"),MCo=o(" (Megatron-BERT model)"),ECo=l(),V_=a("li"),Jce=a("strong"),CCo=o("mobilebert"),wCo=o(" \u2014 "),Qj=a("a"),ACo=o("MobileBertModel"),LCo=o(" (MobileBERT model)"),yCo=l(),X_=a("li"),Yce=a("strong"),xCo=o("mpnet"),$Co=o(" \u2014 "),Wj=a("a"),kCo=o("MPNetModel"),SCo=o(" (MPNet model)"),RCo=l(),z_=a("li"),Kce=a("strong"),PCo=o("mt5"),BCo=o(" \u2014 "),Hj=a("a"),NCo=o("MT5Model"),ICo=o(" (MT5 model)"),qCo=l(),Q_=a("li"),Zce=a("strong"),jCo=o("mvp"),DCo=o(" \u2014 "),Uj=a("a"),GCo=o("MvpModel"),OCo=o(" (MVP model)"),VCo=l(),W_=a("li"),efe=a("strong"),XCo=o("nezha"),zCo=o(" \u2014 "),Jj=a("a"),QCo=o("NezhaModel"),WCo=o(" (Nezha model)"),HCo=l(),H_=a("li"),ofe=a("strong"),UCo=o("nystromformer"),JCo=o(" \u2014 "),Yj=a("a"),YCo=o("NystromformerModel"),KCo=o(" (Nystr\xF6mformer model)"),ZCo=l(),U_=a("li"),rfe=a("strong"),e3o=o("openai-gpt"),o3o=o(" \u2014 "),Kj=a("a"),r3o=o("OpenAIGPTModel"),t3o=o(" (OpenAI GPT model)"),a3o=l(),J_=a("li"),tfe=a("strong"),n3o=o("opt"),s3o=o(" \u2014 "),Zj=a("a"),l3o=o("OPTModel"),i3o=o(" (OPT model)"),d3o=l(),Y_=a("li"),afe=a("strong"),c3o=o("pegasus"),f3o=o(" \u2014 "),eD=a("a"),m3o=o("PegasusModel"),g3o=o(" (Pegasus model)"),h3o=l(),K_=a("li"),nfe=a("strong"),p3o=o("perceiver"),_3o=o(" \u2014 "),oD=a("a"),u3o=o("PerceiverModel"),b3o=o(" (Perceiver model)"),v3o=l(),Z_=a("li"),sfe=a("strong"),F3o=o("plbart"),T3o=o(" \u2014 "),rD=a("a"),M3o=o("PLBartModel"),E3o=o(" (PLBart model)"),C3o=l(),eu=a("li"),lfe=a("strong"),w3o=o("poolformer"),A3o=o(" \u2014 "),tD=a("a"),L3o=o("PoolFormerModel"),y3o=o(" (PoolFormer model)"),x3o=l(),ou=a("li"),ife=a("strong"),$3o=o("prophetnet"),k3o=o(" \u2014 "),aD=a("a"),S3o=o("ProphetNetModel"),R3o=o(" (ProphetNet model)"),P3o=l(),ru=a("li"),dfe=a("strong"),B3o=o("qdqbert"),N3o=o(" \u2014 "),nD=a("a"),I3o=o("QDQBertModel"),q3o=o(" (QDQBert model)"),j3o=l(),tu=a("li"),cfe=a("strong"),D3o=o("reformer"),G3o=o(" \u2014 "),sD=a("a"),O3o=o("ReformerModel"),V3o=o(" (Reformer model)"),X3o=l(),au=a("li"),ffe=a("strong"),z3o=o("regnet"),Q3o=o(" \u2014 "),lD=a("a"),W3o=o("RegNetModel"),H3o=o(" (RegNet model)"),U3o=l(),nu=a("li"),mfe=a("strong"),J3o=o("rembert"),Y3o=o(" \u2014 "),iD=a("a"),K3o=o("RemBertModel"),Z3o=o(" (RemBERT model)"),e5o=l(),su=a("li"),gfe=a("strong"),o5o=o("resnet"),r5o=o(" \u2014 "),dD=a("a"),t5o=o("ResNetModel"),a5o=o(" (ResNet model)"),n5o=l(),lu=a("li"),hfe=a("strong"),s5o=o("retribert"),l5o=o(" \u2014 "),cD=a("a"),i5o=o("RetriBertModel"),d5o=o(" (RetriBERT model)"),c5o=l(),iu=a("li"),pfe=a("strong"),f5o=o("roberta"),m5o=o(" \u2014 "),fD=a("a"),g5o=o("RobertaModel"),h5o=o(" (RoBERTa model)"),p5o=l(),du=a("li"),_fe=a("strong"),_5o=o("roformer"),u5o=o(" \u2014 "),mD=a("a"),b5o=o("RoFormerModel"),v5o=o(" (RoFormer model)"),F5o=l(),cu=a("li"),ufe=a("strong"),T5o=o("segformer"),M5o=o(" \u2014 "),gD=a("a"),E5o=o("SegformerModel"),C5o=o(" (SegFormer model)"),w5o=l(),fu=a("li"),bfe=a("strong"),A5o=o("sew"),L5o=o(" \u2014 "),hD=a("a"),y5o=o("SEWModel"),x5o=o(" (SEW model)"),$5o=l(),mu=a("li"),vfe=a("strong"),k5o=o("sew-d"),S5o=o(" \u2014 "),pD=a("a"),R5o=o("SEWDModel"),P5o=o(" (SEW-D model)"),B5o=l(),gu=a("li"),Ffe=a("strong"),N5o=o("speech_to_text"),I5o=o(" \u2014 "),_D=a("a"),q5o=o("Speech2TextModel"),j5o=o(" (Speech2Text model)"),D5o=l(),hu=a("li"),Tfe=a("strong"),G5o=o("splinter"),O5o=o(" \u2014 "),uD=a("a"),V5o=o("SplinterModel"),X5o=o(" (Splinter model)"),z5o=l(),pu=a("li"),Mfe=a("strong"),Q5o=o("squeezebert"),W5o=o(" \u2014 "),bD=a("a"),H5o=o("SqueezeBertModel"),U5o=o(" (SqueezeBERT model)"),J5o=l(),_u=a("li"),Efe=a("strong"),Y5o=o("swin"),K5o=o(" \u2014 "),vD=a("a"),Z5o=o("SwinModel"),e0o=o(" (Swin Transformer model)"),o0o=l(),uu=a("li"),Cfe=a("strong"),r0o=o("t5"),t0o=o(" \u2014 "),FD=a("a"),a0o=o("T5Model"),n0o=o(" (T5 model)"),s0o=l(),bu=a("li"),wfe=a("strong"),l0o=o("tapas"),i0o=o(" \u2014 "),TD=a("a"),d0o=o("TapasModel"),c0o=o(" (TAPAS model)"),f0o=l(),vu=a("li"),Afe=a("strong"),m0o=o("trajectory_transformer"),g0o=o(" \u2014 "),MD=a("a"),h0o=o("TrajectoryTransformerModel"),p0o=o(" (Trajectory Transformer model)"),_0o=l(),Fu=a("li"),Lfe=a("strong"),u0o=o("transfo-xl"),b0o=o(" \u2014 "),ED=a("a"),v0o=o("TransfoXLModel"),F0o=o(" (Transformer-XL model)"),T0o=l(),Tu=a("li"),yfe=a("strong"),M0o=o("unispeech"),E0o=o(" \u2014 "),CD=a("a"),C0o=o("UniSpeechModel"),w0o=o(" (UniSpeech model)"),A0o=l(),Mu=a("li"),xfe=a("strong"),L0o=o("unispeech-sat"),y0o=o(" \u2014 "),wD=a("a"),x0o=o("UniSpeechSatModel"),$0o=o(" (UniSpeechSat model)"),k0o=l(),Eu=a("li"),$fe=a("strong"),S0o=o("van"),R0o=o(" \u2014 "),AD=a("a"),P0o=o("VanModel"),B0o=o(" (VAN model)"),N0o=l(),Cu=a("li"),kfe=a("strong"),I0o=o("vilt"),q0o=o(" \u2014 "),LD=a("a"),j0o=o("ViltModel"),D0o=o(" (ViLT model)"),G0o=l(),wu=a("li"),Sfe=a("strong"),O0o=o("vision-text-dual-encoder"),V0o=o(" \u2014 "),yD=a("a"),X0o=o("VisionTextDualEncoderModel"),z0o=o(" (VisionTextDualEncoder model)"),Q0o=l(),Au=a("li"),Rfe=a("strong"),W0o=o("visual_bert"),H0o=o(" \u2014 "),xD=a("a"),U0o=o("VisualBertModel"),J0o=o(" (VisualBERT model)"),Y0o=l(),Lu=a("li"),Pfe=a("strong"),K0o=o("vit"),Z0o=o(" \u2014 "),$D=a("a"),ewo=o("ViTModel"),owo=o(" (ViT model)"),rwo=l(),yu=a("li"),Bfe=a("strong"),two=o("vit_mae"),awo=o(" \u2014 "),kD=a("a"),nwo=o("ViTMAEModel"),swo=o(" (ViTMAE model)"),lwo=l(),xu=a("li"),Nfe=a("strong"),iwo=o("wav2vec2"),dwo=o(" \u2014 "),SD=a("a"),cwo=o("Wav2Vec2Model"),fwo=o(" (Wav2Vec2 model)"),mwo=l(),$u=a("li"),Ife=a("strong"),gwo=o("wav2vec2-conformer"),hwo=o(" \u2014 "),RD=a("a"),pwo=o("Wav2Vec2ConformerModel"),_wo=o(" (Wav2Vec2-Conformer model)"),uwo=l(),ku=a("li"),qfe=a("strong"),bwo=o("wavlm"),vwo=o(" \u2014 "),PD=a("a"),Fwo=o("WavLMModel"),Two=o(" (WavLM model)"),Mwo=l(),Su=a("li"),jfe=a("strong"),Ewo=o("xglm"),Cwo=o(" \u2014 "),BD=a("a"),wwo=o("XGLMModel"),Awo=o(" (XGLM model)"),Lwo=l(),Ru=a("li"),Dfe=a("strong"),ywo=o("xlm"),xwo=o(" \u2014 "),ND=a("a"),$wo=o("XLMModel"),kwo=o(" (XLM model)"),Swo=l(),Pu=a("li"),Gfe=a("strong"),Rwo=o("xlm-prophetnet"),Pwo=o(" \u2014 "),ID=a("a"),Bwo=o("XLMProphetNetModel"),Nwo=o(" (XLM-ProphetNet model)"),Iwo=l(),Bu=a("li"),Ofe=a("strong"),qwo=o("xlm-roberta"),jwo=o(" \u2014 "),qD=a("a"),Dwo=o("XLMRobertaModel"),Gwo=o(" (XLM-RoBERTa model)"),Owo=l(),Nu=a("li"),Vfe=a("strong"),Vwo=o("xlm-roberta-xl"),Xwo=o(" \u2014 "),jD=a("a"),zwo=o("XLMRobertaXLModel"),Qwo=o(" (XLM-RoBERTa-XL model)"),Wwo=l(),Iu=a("li"),Xfe=a("strong"),Hwo=o("xlnet"),Uwo=o(" \u2014 "),DD=a("a"),Jwo=o("XLNetModel"),Ywo=o(" (XLNet model)"),Kwo=l(),qu=a("li"),zfe=a("strong"),Zwo=o("yolos"),eAo=o(" \u2014 "),GD=a("a"),oAo=o("YolosModel"),rAo=o(" (YOLOS model)"),tAo=l(),ju=a("li"),Qfe=a("strong"),aAo=o("yoso"),nAo=o(" \u2014 "),OD=a("a"),sAo=o("YosoModel"),lAo=o(" (YOSO model)"),iAo=l(),Du=a("p"),dAo=o("The model is set in evaluation mode by default using "),Wfe=a("code"),cAo=o("model.eval()"),fAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hfe=a("code"),mAo=o("model.train()"),gAo=l(),F(Gu.$$.fragment),IVe=l(),Oi=a("h2"),Ou=a("a"),Ufe=a("span"),F(yy.$$.fragment),hAo=l(),Jfe=a("span"),pAo=o("AutoModelForPreTraining"),qVe=l(),$o=a("div"),F(xy.$$.fragment),_Ao=l(),Vi=a("p"),uAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VD=a("a"),bAo=o("from_pretrained()"),vAo=o(" class method or the "),XD=a("a"),FAo=o("from_config()"),TAo=o(` class
method.`),MAo=l(),$y=a("p"),EAo=o("This class cannot be instantiated directly using "),Yfe=a("code"),CAo=o("__init__()"),wAo=o(" (throws an error)."),AAo=l(),lt=a("div"),F(ky.$$.fragment),LAo=l(),Kfe=a("p"),yAo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),xAo=l(),Xi=a("p"),$Ao=o(`Note:
Loading a model from its configuration file does `),Zfe=a("strong"),kAo=o("not"),SAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zD=a("a"),RAo=o("from_pretrained()"),PAo=o(" to load the model weights."),BAo=l(),F(Vu.$$.fragment),NAo=l(),Ye=a("div"),F(Sy.$$.fragment),IAo=l(),eme=a("p"),qAo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),jAo=l(),Na=a("p"),DAo=o("The model class to instantiate is selected based on the "),ome=a("code"),GAo=o("model_type"),OAo=o(` property of the config object (either
passed as an argument or loaded from `),rme=a("code"),VAo=o("pretrained_model_name_or_path"),XAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tme=a("code"),zAo=o("pretrained_model_name_or_path"),QAo=o(":"),WAo=l(),G=a("ul"),Xu=a("li"),ame=a("strong"),HAo=o("albert"),UAo=o(" \u2014 "),QD=a("a"),JAo=o("AlbertForPreTraining"),YAo=o(" (ALBERT model)"),KAo=l(),zu=a("li"),nme=a("strong"),ZAo=o("bart"),e6o=o(" \u2014 "),WD=a("a"),o6o=o("BartForConditionalGeneration"),r6o=o(" (BART model)"),t6o=l(),Qu=a("li"),sme=a("strong"),a6o=o("bert"),n6o=o(" \u2014 "),HD=a("a"),s6o=o("BertForPreTraining"),l6o=o(" (BERT model)"),i6o=l(),Wu=a("li"),lme=a("strong"),d6o=o("big_bird"),c6o=o(" \u2014 "),UD=a("a"),f6o=o("BigBirdForPreTraining"),m6o=o(" (BigBird model)"),g6o=l(),Hu=a("li"),ime=a("strong"),h6o=o("bloom"),p6o=o(" \u2014 "),JD=a("a"),_6o=o("BloomForCausalLM"),u6o=o(" (BLOOM model)"),b6o=l(),Uu=a("li"),dme=a("strong"),v6o=o("camembert"),F6o=o(" \u2014 "),YD=a("a"),T6o=o("CamembertForMaskedLM"),M6o=o(" (CamemBERT model)"),E6o=l(),Ju=a("li"),cme=a("strong"),C6o=o("ctrl"),w6o=o(" \u2014 "),KD=a("a"),A6o=o("CTRLLMHeadModel"),L6o=o(" (CTRL model)"),y6o=l(),Yu=a("li"),fme=a("strong"),x6o=o("data2vec-text"),$6o=o(" \u2014 "),ZD=a("a"),k6o=o("Data2VecTextForMaskedLM"),S6o=o(" (Data2VecText model)"),R6o=l(),Ku=a("li"),mme=a("strong"),P6o=o("deberta"),B6o=o(" \u2014 "),eG=a("a"),N6o=o("DebertaForMaskedLM"),I6o=o(" (DeBERTa model)"),q6o=l(),Zu=a("li"),gme=a("strong"),j6o=o("deberta-v2"),D6o=o(" \u2014 "),oG=a("a"),G6o=o("DebertaV2ForMaskedLM"),O6o=o(" (DeBERTa-v2 model)"),V6o=l(),e2=a("li"),hme=a("strong"),X6o=o("distilbert"),z6o=o(" \u2014 "),rG=a("a"),Q6o=o("DistilBertForMaskedLM"),W6o=o(" (DistilBERT model)"),H6o=l(),o2=a("li"),pme=a("strong"),U6o=o("electra"),J6o=o(" \u2014 "),tG=a("a"),Y6o=o("ElectraForPreTraining"),K6o=o(" (ELECTRA model)"),Z6o=l(),r2=a("li"),_me=a("strong"),eLo=o("flaubert"),oLo=o(" \u2014 "),aG=a("a"),rLo=o("FlaubertWithLMHeadModel"),tLo=o(" (FlauBERT model)"),aLo=l(),t2=a("li"),ume=a("strong"),nLo=o("flava"),sLo=o(" \u2014 "),nG=a("a"),lLo=o("FlavaForPreTraining"),iLo=o(" (FLAVA model)"),dLo=l(),a2=a("li"),bme=a("strong"),cLo=o("fnet"),fLo=o(" \u2014 "),sG=a("a"),mLo=o("FNetForPreTraining"),gLo=o(" (FNet model)"),hLo=l(),n2=a("li"),vme=a("strong"),pLo=o("fsmt"),_Lo=o(" \u2014 "),lG=a("a"),uLo=o("FSMTForConditionalGeneration"),bLo=o(" (FairSeq Machine-Translation model)"),vLo=l(),s2=a("li"),Fme=a("strong"),FLo=o("funnel"),TLo=o(" \u2014 "),iG=a("a"),MLo=o("FunnelForPreTraining"),ELo=o(" (Funnel Transformer model)"),CLo=l(),l2=a("li"),Tme=a("strong"),wLo=o("gpt2"),ALo=o(" \u2014 "),dG=a("a"),LLo=o("GPT2LMHeadModel"),yLo=o(" (OpenAI GPT-2 model)"),xLo=l(),i2=a("li"),Mme=a("strong"),$Lo=o("ibert"),kLo=o(" \u2014 "),cG=a("a"),SLo=o("IBertForMaskedLM"),RLo=o(" (I-BERT model)"),PLo=l(),d2=a("li"),Eme=a("strong"),BLo=o("layoutlm"),NLo=o(" \u2014 "),fG=a("a"),ILo=o("LayoutLMForMaskedLM"),qLo=o(" (LayoutLM model)"),jLo=l(),c2=a("li"),Cme=a("strong"),DLo=o("longformer"),GLo=o(" \u2014 "),mG=a("a"),OLo=o("LongformerForMaskedLM"),VLo=o(" (Longformer model)"),XLo=l(),f2=a("li"),wme=a("strong"),zLo=o("lxmert"),QLo=o(" \u2014 "),gG=a("a"),WLo=o("LxmertForPreTraining"),HLo=o(" (LXMERT model)"),ULo=l(),m2=a("li"),Ame=a("strong"),JLo=o("megatron-bert"),YLo=o(" \u2014 "),hG=a("a"),KLo=o("MegatronBertForPreTraining"),ZLo=o(" (Megatron-BERT model)"),eyo=l(),g2=a("li"),Lme=a("strong"),oyo=o("mobilebert"),ryo=o(" \u2014 "),pG=a("a"),tyo=o("MobileBertForPreTraining"),ayo=o(" (MobileBERT model)"),nyo=l(),h2=a("li"),yme=a("strong"),syo=o("mpnet"),lyo=o(" \u2014 "),_G=a("a"),iyo=o("MPNetForMaskedLM"),dyo=o(" (MPNet model)"),cyo=l(),p2=a("li"),xme=a("strong"),fyo=o("mvp"),myo=o(" \u2014 "),uG=a("a"),gyo=o("MvpForConditionalGeneration"),hyo=o(" (MVP model)"),pyo=l(),_2=a("li"),$me=a("strong"),_yo=o("nezha"),uyo=o(" \u2014 "),bG=a("a"),byo=o("NezhaForPreTraining"),vyo=o(" (Nezha model)"),Fyo=l(),u2=a("li"),kme=a("strong"),Tyo=o("openai-gpt"),Myo=o(" \u2014 "),vG=a("a"),Eyo=o("OpenAIGPTLMHeadModel"),Cyo=o(" (OpenAI GPT model)"),wyo=l(),b2=a("li"),Sme=a("strong"),Ayo=o("retribert"),Lyo=o(" \u2014 "),FG=a("a"),yyo=o("RetriBertModel"),xyo=o(" (RetriBERT model)"),$yo=l(),v2=a("li"),Rme=a("strong"),kyo=o("roberta"),Syo=o(" \u2014 "),TG=a("a"),Ryo=o("RobertaForMaskedLM"),Pyo=o(" (RoBERTa model)"),Byo=l(),F2=a("li"),Pme=a("strong"),Nyo=o("splinter"),Iyo=o(" \u2014 "),MG=a("a"),qyo=o("SplinterForPreTraining"),jyo=o(" (Splinter model)"),Dyo=l(),T2=a("li"),Bme=a("strong"),Gyo=o("squeezebert"),Oyo=o(" \u2014 "),EG=a("a"),Vyo=o("SqueezeBertForMaskedLM"),Xyo=o(" (SqueezeBERT model)"),zyo=l(),M2=a("li"),Nme=a("strong"),Qyo=o("t5"),Wyo=o(" \u2014 "),CG=a("a"),Hyo=o("T5ForConditionalGeneration"),Uyo=o(" (T5 model)"),Jyo=l(),E2=a("li"),Ime=a("strong"),Yyo=o("tapas"),Kyo=o(" \u2014 "),wG=a("a"),Zyo=o("TapasForMaskedLM"),e8o=o(" (TAPAS model)"),o8o=l(),C2=a("li"),qme=a("strong"),r8o=o("transfo-xl"),t8o=o(" \u2014 "),AG=a("a"),a8o=o("TransfoXLLMHeadModel"),n8o=o(" (Transformer-XL model)"),s8o=l(),w2=a("li"),jme=a("strong"),l8o=o("unispeech"),i8o=o(" \u2014 "),LG=a("a"),d8o=o("UniSpeechForPreTraining"),c8o=o(" (UniSpeech model)"),f8o=l(),A2=a("li"),Dme=a("strong"),m8o=o("unispeech-sat"),g8o=o(" \u2014 "),yG=a("a"),h8o=o("UniSpeechSatForPreTraining"),p8o=o(" (UniSpeechSat model)"),_8o=l(),L2=a("li"),Gme=a("strong"),u8o=o("visual_bert"),b8o=o(" \u2014 "),xG=a("a"),v8o=o("VisualBertForPreTraining"),F8o=o(" (VisualBERT model)"),T8o=l(),y2=a("li"),Ome=a("strong"),M8o=o("vit_mae"),E8o=o(" \u2014 "),$G=a("a"),C8o=o("ViTMAEForPreTraining"),w8o=o(" (ViTMAE model)"),A8o=l(),x2=a("li"),Vme=a("strong"),L8o=o("wav2vec2"),y8o=o(" \u2014 "),kG=a("a"),x8o=o("Wav2Vec2ForPreTraining"),$8o=o(" (Wav2Vec2 model)"),k8o=l(),$2=a("li"),Xme=a("strong"),S8o=o("wav2vec2-conformer"),R8o=o(" \u2014 "),SG=a("a"),P8o=o("Wav2Vec2ConformerForPreTraining"),B8o=o(" (Wav2Vec2-Conformer model)"),N8o=l(),k2=a("li"),zme=a("strong"),I8o=o("xlm"),q8o=o(" \u2014 "),RG=a("a"),j8o=o("XLMWithLMHeadModel"),D8o=o(" (XLM model)"),G8o=l(),S2=a("li"),Qme=a("strong"),O8o=o("xlm-roberta"),V8o=o(" \u2014 "),PG=a("a"),X8o=o("XLMRobertaForMaskedLM"),z8o=o(" (XLM-RoBERTa model)"),Q8o=l(),R2=a("li"),Wme=a("strong"),W8o=o("xlm-roberta-xl"),H8o=o(" \u2014 "),BG=a("a"),U8o=o("XLMRobertaXLForMaskedLM"),J8o=o(" (XLM-RoBERTa-XL model)"),Y8o=l(),P2=a("li"),Hme=a("strong"),K8o=o("xlnet"),Z8o=o(" \u2014 "),NG=a("a"),e9o=o("XLNetLMHeadModel"),o9o=o(" (XLNet model)"),r9o=l(),B2=a("p"),t9o=o("The model is set in evaluation mode by default using "),Ume=a("code"),a9o=o("model.eval()"),n9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jme=a("code"),s9o=o("model.train()"),l9o=l(),F(N2.$$.fragment),jVe=l(),zi=a("h2"),I2=a("a"),Yme=a("span"),F(Ry.$$.fragment),i9o=l(),Kme=a("span"),d9o=o("AutoModelForCausalLM"),DVe=l(),ko=a("div"),F(Py.$$.fragment),c9o=l(),Qi=a("p"),f9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),IG=a("a"),m9o=o("from_pretrained()"),g9o=o(" class method or the "),qG=a("a"),h9o=o("from_config()"),p9o=o(` class
method.`),_9o=l(),By=a("p"),u9o=o("This class cannot be instantiated directly using "),Zme=a("code"),b9o=o("__init__()"),v9o=o(" (throws an error)."),F9o=l(),it=a("div"),F(Ny.$$.fragment),T9o=l(),ege=a("p"),M9o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),E9o=l(),Wi=a("p"),C9o=o(`Note:
Loading a model from its configuration file does `),oge=a("strong"),w9o=o("not"),A9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jG=a("a"),L9o=o("from_pretrained()"),y9o=o(" to load the model weights."),x9o=l(),F(q2.$$.fragment),$9o=l(),Ke=a("div"),F(Iy.$$.fragment),k9o=l(),rge=a("p"),S9o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),R9o=l(),Ia=a("p"),P9o=o("The model class to instantiate is selected based on the "),tge=a("code"),B9o=o("model_type"),N9o=o(` property of the config object (either
passed as an argument or loaded from `),age=a("code"),I9o=o("pretrained_model_name_or_path"),q9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nge=a("code"),j9o=o("pretrained_model_name_or_path"),D9o=o(":"),G9o=l(),z=a("ul"),j2=a("li"),sge=a("strong"),O9o=o("bart"),V9o=o(" \u2014 "),DG=a("a"),X9o=o("BartForCausalLM"),z9o=o(" (BART model)"),Q9o=l(),D2=a("li"),lge=a("strong"),W9o=o("bert"),H9o=o(" \u2014 "),GG=a("a"),U9o=o("BertLMHeadModel"),J9o=o(" (BERT model)"),Y9o=l(),G2=a("li"),ige=a("strong"),K9o=o("bert-generation"),Z9o=o(" \u2014 "),OG=a("a"),exo=o("BertGenerationDecoder"),oxo=o(" (Bert Generation model)"),rxo=l(),O2=a("li"),dge=a("strong"),txo=o("big_bird"),axo=o(" \u2014 "),VG=a("a"),nxo=o("BigBirdForCausalLM"),sxo=o(" (BigBird model)"),lxo=l(),V2=a("li"),cge=a("strong"),ixo=o("bigbird_pegasus"),dxo=o(" \u2014 "),XG=a("a"),cxo=o("BigBirdPegasusForCausalLM"),fxo=o(" (BigBird-Pegasus model)"),mxo=l(),X2=a("li"),fge=a("strong"),gxo=o("blenderbot"),hxo=o(" \u2014 "),zG=a("a"),pxo=o("BlenderbotForCausalLM"),_xo=o(" (Blenderbot model)"),uxo=l(),z2=a("li"),mge=a("strong"),bxo=o("blenderbot-small"),vxo=o(" \u2014 "),QG=a("a"),Fxo=o("BlenderbotSmallForCausalLM"),Txo=o(" (BlenderbotSmall model)"),Mxo=l(),Q2=a("li"),gge=a("strong"),Exo=o("bloom"),Cxo=o(" \u2014 "),WG=a("a"),wxo=o("BloomForCausalLM"),Axo=o(" (BLOOM model)"),Lxo=l(),W2=a("li"),hge=a("strong"),yxo=o("camembert"),xxo=o(" \u2014 "),HG=a("a"),$xo=o("CamembertForCausalLM"),kxo=o(" (CamemBERT model)"),Sxo=l(),H2=a("li"),pge=a("strong"),Rxo=o("codegen"),Pxo=o(" \u2014 "),UG=a("a"),Bxo=o("CodeGenForCausalLM"),Nxo=o(" (CodeGen model)"),Ixo=l(),U2=a("li"),_ge=a("strong"),qxo=o("ctrl"),jxo=o(" \u2014 "),JG=a("a"),Dxo=o("CTRLLMHeadModel"),Gxo=o(" (CTRL model)"),Oxo=l(),J2=a("li"),uge=a("strong"),Vxo=o("data2vec-text"),Xxo=o(" \u2014 "),YG=a("a"),zxo=o("Data2VecTextForCausalLM"),Qxo=o(" (Data2VecText model)"),Wxo=l(),Y2=a("li"),bge=a("strong"),Hxo=o("electra"),Uxo=o(" \u2014 "),KG=a("a"),Jxo=o("ElectraForCausalLM"),Yxo=o(" (ELECTRA model)"),Kxo=l(),K2=a("li"),vge=a("strong"),Zxo=o("gpt2"),e$o=o(" \u2014 "),ZG=a("a"),o$o=o("GPT2LMHeadModel"),r$o=o(" (OpenAI GPT-2 model)"),t$o=l(),Z2=a("li"),Fge=a("strong"),a$o=o("gpt_neo"),n$o=o(" \u2014 "),eO=a("a"),s$o=o("GPTNeoForCausalLM"),l$o=o(" (GPT Neo model)"),i$o=l(),e1=a("li"),Tge=a("strong"),d$o=o("gpt_neox"),c$o=o(" \u2014 "),oO=a("a"),f$o=o("GPTNeoXForCausalLM"),m$o=o(" (GPT NeoX model)"),g$o=l(),o1=a("li"),Mge=a("strong"),h$o=o("gptj"),p$o=o(" \u2014 "),rO=a("a"),_$o=o("GPTJForCausalLM"),u$o=o(" (GPT-J model)"),b$o=l(),r1=a("li"),Ege=a("strong"),v$o=o("marian"),F$o=o(" \u2014 "),tO=a("a"),T$o=o("MarianForCausalLM"),M$o=o(" (Marian model)"),E$o=l(),t1=a("li"),Cge=a("strong"),C$o=o("mbart"),w$o=o(" \u2014 "),aO=a("a"),A$o=o("MBartForCausalLM"),L$o=o(" (mBART model)"),y$o=l(),a1=a("li"),wge=a("strong"),x$o=o("megatron-bert"),$$o=o(" \u2014 "),nO=a("a"),k$o=o("MegatronBertForCausalLM"),S$o=o(" (Megatron-BERT model)"),R$o=l(),n1=a("li"),Age=a("strong"),P$o=o("mvp"),B$o=o(" \u2014 "),sO=a("a"),N$o=o("MvpForCausalLM"),I$o=o(" (MVP model)"),q$o=l(),s1=a("li"),Lge=a("strong"),j$o=o("openai-gpt"),D$o=o(" \u2014 "),lO=a("a"),G$o=o("OpenAIGPTLMHeadModel"),O$o=o(" (OpenAI GPT model)"),V$o=l(),l1=a("li"),yge=a("strong"),X$o=o("opt"),z$o=o(" \u2014 "),iO=a("a"),Q$o=o("OPTForCausalLM"),W$o=o(" (OPT model)"),H$o=l(),i1=a("li"),xge=a("strong"),U$o=o("pegasus"),J$o=o(" \u2014 "),dO=a("a"),Y$o=o("PegasusForCausalLM"),K$o=o(" (Pegasus model)"),Z$o=l(),d1=a("li"),$ge=a("strong"),eko=o("plbart"),oko=o(" \u2014 "),cO=a("a"),rko=o("PLBartForCausalLM"),tko=o(" (PLBart model)"),ako=l(),c1=a("li"),kge=a("strong"),nko=o("prophetnet"),sko=o(" \u2014 "),fO=a("a"),lko=o("ProphetNetForCausalLM"),iko=o(" (ProphetNet model)"),dko=l(),f1=a("li"),Sge=a("strong"),cko=o("qdqbert"),fko=o(" \u2014 "),mO=a("a"),mko=o("QDQBertLMHeadModel"),gko=o(" (QDQBert model)"),hko=l(),m1=a("li"),Rge=a("strong"),pko=o("reformer"),_ko=o(" \u2014 "),gO=a("a"),uko=o("ReformerModelWithLMHead"),bko=o(" (Reformer model)"),vko=l(),g1=a("li"),Pge=a("strong"),Fko=o("rembert"),Tko=o(" \u2014 "),hO=a("a"),Mko=o("RemBertForCausalLM"),Eko=o(" (RemBERT model)"),Cko=l(),h1=a("li"),Bge=a("strong"),wko=o("roberta"),Ako=o(" \u2014 "),pO=a("a"),Lko=o("RobertaForCausalLM"),yko=o(" (RoBERTa model)"),xko=l(),p1=a("li"),Nge=a("strong"),$ko=o("roformer"),kko=o(" \u2014 "),_O=a("a"),Sko=o("RoFormerForCausalLM"),Rko=o(" (RoFormer model)"),Pko=l(),_1=a("li"),Ige=a("strong"),Bko=o("speech_to_text_2"),Nko=o(" \u2014 "),uO=a("a"),Iko=o("Speech2Text2ForCausalLM"),qko=o(" (Speech2Text2 model)"),jko=l(),u1=a("li"),qge=a("strong"),Dko=o("transfo-xl"),Gko=o(" \u2014 "),bO=a("a"),Oko=o("TransfoXLLMHeadModel"),Vko=o(" (Transformer-XL model)"),Xko=l(),b1=a("li"),jge=a("strong"),zko=o("trocr"),Qko=o(" \u2014 "),vO=a("a"),Wko=o("TrOCRForCausalLM"),Hko=o(" (TrOCR model)"),Uko=l(),v1=a("li"),Dge=a("strong"),Jko=o("xglm"),Yko=o(" \u2014 "),FO=a("a"),Kko=o("XGLMForCausalLM"),Zko=o(" (XGLM model)"),eSo=l(),F1=a("li"),Gge=a("strong"),oSo=o("xlm"),rSo=o(" \u2014 "),TO=a("a"),tSo=o("XLMWithLMHeadModel"),aSo=o(" (XLM model)"),nSo=l(),T1=a("li"),Oge=a("strong"),sSo=o("xlm-prophetnet"),lSo=o(" \u2014 "),MO=a("a"),iSo=o("XLMProphetNetForCausalLM"),dSo=o(" (XLM-ProphetNet model)"),cSo=l(),M1=a("li"),Vge=a("strong"),fSo=o("xlm-roberta"),mSo=o(" \u2014 "),EO=a("a"),gSo=o("XLMRobertaForCausalLM"),hSo=o(" (XLM-RoBERTa model)"),pSo=l(),E1=a("li"),Xge=a("strong"),_So=o("xlm-roberta-xl"),uSo=o(" \u2014 "),CO=a("a"),bSo=o("XLMRobertaXLForCausalLM"),vSo=o(" (XLM-RoBERTa-XL model)"),FSo=l(),C1=a("li"),zge=a("strong"),TSo=o("xlnet"),MSo=o(" \u2014 "),wO=a("a"),ESo=o("XLNetLMHeadModel"),CSo=o(" (XLNet model)"),wSo=l(),w1=a("p"),ASo=o("The model is set in evaluation mode by default using "),Qge=a("code"),LSo=o("model.eval()"),ySo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wge=a("code"),xSo=o("model.train()"),$So=l(),F(A1.$$.fragment),GVe=l(),Hi=a("h2"),L1=a("a"),Hge=a("span"),F(qy.$$.fragment),kSo=l(),Uge=a("span"),SSo=o("AutoModelForMaskedLM"),OVe=l(),So=a("div"),F(jy.$$.fragment),RSo=l(),Ui=a("p"),PSo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),AO=a("a"),BSo=o("from_pretrained()"),NSo=o(" class method or the "),LO=a("a"),ISo=o("from_config()"),qSo=o(` class
method.`),jSo=l(),Dy=a("p"),DSo=o("This class cannot be instantiated directly using "),Jge=a("code"),GSo=o("__init__()"),OSo=o(" (throws an error)."),VSo=l(),dt=a("div"),F(Gy.$$.fragment),XSo=l(),Yge=a("p"),zSo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),QSo=l(),Ji=a("p"),WSo=o(`Note:
Loading a model from its configuration file does `),Kge=a("strong"),HSo=o("not"),USo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yO=a("a"),JSo=o("from_pretrained()"),YSo=o(" to load the model weights."),KSo=l(),F(y1.$$.fragment),ZSo=l(),Ze=a("div"),F(Oy.$$.fragment),eRo=l(),Zge=a("p"),oRo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),rRo=l(),qa=a("p"),tRo=o("The model class to instantiate is selected based on the "),ehe=a("code"),aRo=o("model_type"),nRo=o(` property of the config object (either
passed as an argument or loaded from `),ohe=a("code"),sRo=o("pretrained_model_name_or_path"),lRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rhe=a("code"),iRo=o("pretrained_model_name_or_path"),dRo=o(":"),cRo=l(),W=a("ul"),x1=a("li"),the=a("strong"),fRo=o("albert"),mRo=o(" \u2014 "),xO=a("a"),gRo=o("AlbertForMaskedLM"),hRo=o(" (ALBERT model)"),pRo=l(),$1=a("li"),ahe=a("strong"),_Ro=o("bart"),uRo=o(" \u2014 "),$O=a("a"),bRo=o("BartForConditionalGeneration"),vRo=o(" (BART model)"),FRo=l(),k1=a("li"),nhe=a("strong"),TRo=o("bert"),MRo=o(" \u2014 "),kO=a("a"),ERo=o("BertForMaskedLM"),CRo=o(" (BERT model)"),wRo=l(),S1=a("li"),she=a("strong"),ARo=o("big_bird"),LRo=o(" \u2014 "),SO=a("a"),yRo=o("BigBirdForMaskedLM"),xRo=o(" (BigBird model)"),$Ro=l(),R1=a("li"),lhe=a("strong"),kRo=o("camembert"),SRo=o(" \u2014 "),RO=a("a"),RRo=o("CamembertForMaskedLM"),PRo=o(" (CamemBERT model)"),BRo=l(),P1=a("li"),ihe=a("strong"),NRo=o("convbert"),IRo=o(" \u2014 "),PO=a("a"),qRo=o("ConvBertForMaskedLM"),jRo=o(" (ConvBERT model)"),DRo=l(),B1=a("li"),dhe=a("strong"),GRo=o("data2vec-text"),ORo=o(" \u2014 "),BO=a("a"),VRo=o("Data2VecTextForMaskedLM"),XRo=o(" (Data2VecText model)"),zRo=l(),N1=a("li"),che=a("strong"),QRo=o("deberta"),WRo=o(" \u2014 "),NO=a("a"),HRo=o("DebertaForMaskedLM"),URo=o(" (DeBERTa model)"),JRo=l(),I1=a("li"),fhe=a("strong"),YRo=o("deberta-v2"),KRo=o(" \u2014 "),IO=a("a"),ZRo=o("DebertaV2ForMaskedLM"),ePo=o(" (DeBERTa-v2 model)"),oPo=l(),q1=a("li"),mhe=a("strong"),rPo=o("distilbert"),tPo=o(" \u2014 "),qO=a("a"),aPo=o("DistilBertForMaskedLM"),nPo=o(" (DistilBERT model)"),sPo=l(),j1=a("li"),ghe=a("strong"),lPo=o("electra"),iPo=o(" \u2014 "),jO=a("a"),dPo=o("ElectraForMaskedLM"),cPo=o(" (ELECTRA model)"),fPo=l(),D1=a("li"),hhe=a("strong"),mPo=o("flaubert"),gPo=o(" \u2014 "),DO=a("a"),hPo=o("FlaubertWithLMHeadModel"),pPo=o(" (FlauBERT model)"),_Po=l(),G1=a("li"),phe=a("strong"),uPo=o("fnet"),bPo=o(" \u2014 "),GO=a("a"),vPo=o("FNetForMaskedLM"),FPo=o(" (FNet model)"),TPo=l(),O1=a("li"),_he=a("strong"),MPo=o("funnel"),EPo=o(" \u2014 "),OO=a("a"),CPo=o("FunnelForMaskedLM"),wPo=o(" (Funnel Transformer model)"),APo=l(),V1=a("li"),uhe=a("strong"),LPo=o("ibert"),yPo=o(" \u2014 "),VO=a("a"),xPo=o("IBertForMaskedLM"),$Po=o(" (I-BERT model)"),kPo=l(),X1=a("li"),bhe=a("strong"),SPo=o("layoutlm"),RPo=o(" \u2014 "),XO=a("a"),PPo=o("LayoutLMForMaskedLM"),BPo=o(" (LayoutLM model)"),NPo=l(),z1=a("li"),vhe=a("strong"),IPo=o("longformer"),qPo=o(" \u2014 "),zO=a("a"),jPo=o("LongformerForMaskedLM"),DPo=o(" (Longformer model)"),GPo=l(),Q1=a("li"),Fhe=a("strong"),OPo=o("luke"),VPo=o(" \u2014 "),QO=a("a"),XPo=o("LukeForMaskedLM"),zPo=o(" (LUKE model)"),QPo=l(),W1=a("li"),The=a("strong"),WPo=o("mbart"),HPo=o(" \u2014 "),WO=a("a"),UPo=o("MBartForConditionalGeneration"),JPo=o(" (mBART model)"),YPo=l(),H1=a("li"),Mhe=a("strong"),KPo=o("megatron-bert"),ZPo=o(" \u2014 "),HO=a("a"),eBo=o("MegatronBertForMaskedLM"),oBo=o(" (Megatron-BERT model)"),rBo=l(),U1=a("li"),Ehe=a("strong"),tBo=o("mobilebert"),aBo=o(" \u2014 "),UO=a("a"),nBo=o("MobileBertForMaskedLM"),sBo=o(" (MobileBERT model)"),lBo=l(),J1=a("li"),Che=a("strong"),iBo=o("mpnet"),dBo=o(" \u2014 "),JO=a("a"),cBo=o("MPNetForMaskedLM"),fBo=o(" (MPNet model)"),mBo=l(),Y1=a("li"),whe=a("strong"),gBo=o("mvp"),hBo=o(" \u2014 "),YO=a("a"),pBo=o("MvpForConditionalGeneration"),_Bo=o(" (MVP model)"),uBo=l(),K1=a("li"),Ahe=a("strong"),bBo=o("nezha"),vBo=o(" \u2014 "),KO=a("a"),FBo=o("NezhaForMaskedLM"),TBo=o(" (Nezha model)"),MBo=l(),Z1=a("li"),Lhe=a("strong"),EBo=o("nystromformer"),CBo=o(" \u2014 "),ZO=a("a"),wBo=o("NystromformerForMaskedLM"),ABo=o(" (Nystr\xF6mformer model)"),LBo=l(),e7=a("li"),yhe=a("strong"),yBo=o("perceiver"),xBo=o(" \u2014 "),eV=a("a"),$Bo=o("PerceiverForMaskedLM"),kBo=o(" (Perceiver model)"),SBo=l(),o7=a("li"),xhe=a("strong"),RBo=o("qdqbert"),PBo=o(" \u2014 "),oV=a("a"),BBo=o("QDQBertForMaskedLM"),NBo=o(" (QDQBert model)"),IBo=l(),r7=a("li"),$he=a("strong"),qBo=o("reformer"),jBo=o(" \u2014 "),rV=a("a"),DBo=o("ReformerForMaskedLM"),GBo=o(" (Reformer model)"),OBo=l(),t7=a("li"),khe=a("strong"),VBo=o("rembert"),XBo=o(" \u2014 "),tV=a("a"),zBo=o("RemBertForMaskedLM"),QBo=o(" (RemBERT model)"),WBo=l(),a7=a("li"),She=a("strong"),HBo=o("roberta"),UBo=o(" \u2014 "),aV=a("a"),JBo=o("RobertaForMaskedLM"),YBo=o(" (RoBERTa model)"),KBo=l(),n7=a("li"),Rhe=a("strong"),ZBo=o("roformer"),eNo=o(" \u2014 "),nV=a("a"),oNo=o("RoFormerForMaskedLM"),rNo=o(" (RoFormer model)"),tNo=l(),s7=a("li"),Phe=a("strong"),aNo=o("squeezebert"),nNo=o(" \u2014 "),sV=a("a"),sNo=o("SqueezeBertForMaskedLM"),lNo=o(" (SqueezeBERT model)"),iNo=l(),l7=a("li"),Bhe=a("strong"),dNo=o("tapas"),cNo=o(" \u2014 "),lV=a("a"),fNo=o("TapasForMaskedLM"),mNo=o(" (TAPAS model)"),gNo=l(),i7=a("li"),Nhe=a("strong"),hNo=o("wav2vec2"),pNo=o(" \u2014 "),Ihe=a("code"),_No=o("Wav2Vec2ForMaskedLM"),uNo=o(" (Wav2Vec2 model)"),bNo=l(),d7=a("li"),qhe=a("strong"),vNo=o("xlm"),FNo=o(" \u2014 "),iV=a("a"),TNo=o("XLMWithLMHeadModel"),MNo=o(" (XLM model)"),ENo=l(),c7=a("li"),jhe=a("strong"),CNo=o("xlm-roberta"),wNo=o(" \u2014 "),dV=a("a"),ANo=o("XLMRobertaForMaskedLM"),LNo=o(" (XLM-RoBERTa model)"),yNo=l(),f7=a("li"),Dhe=a("strong"),xNo=o("xlm-roberta-xl"),$No=o(" \u2014 "),cV=a("a"),kNo=o("XLMRobertaXLForMaskedLM"),SNo=o(" (XLM-RoBERTa-XL model)"),RNo=l(),m7=a("li"),Ghe=a("strong"),PNo=o("yoso"),BNo=o(" \u2014 "),fV=a("a"),NNo=o("YosoForMaskedLM"),INo=o(" (YOSO model)"),qNo=l(),g7=a("p"),jNo=o("The model is set in evaluation mode by default using "),Ohe=a("code"),DNo=o("model.eval()"),GNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vhe=a("code"),ONo=o("model.train()"),VNo=l(),F(h7.$$.fragment),VVe=l(),Yi=a("h2"),p7=a("a"),Xhe=a("span"),F(Vy.$$.fragment),XNo=l(),zhe=a("span"),zNo=o("AutoModelForSeq2SeqLM"),XVe=l(),Ro=a("div"),F(Xy.$$.fragment),QNo=l(),Ki=a("p"),WNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),mV=a("a"),HNo=o("from_pretrained()"),UNo=o(" class method or the "),gV=a("a"),JNo=o("from_config()"),YNo=o(` class
method.`),KNo=l(),zy=a("p"),ZNo=o("This class cannot be instantiated directly using "),Qhe=a("code"),eIo=o("__init__()"),oIo=o(" (throws an error)."),rIo=l(),ct=a("div"),F(Qy.$$.fragment),tIo=l(),Whe=a("p"),aIo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),nIo=l(),Zi=a("p"),sIo=o(`Note:
Loading a model from its configuration file does `),Hhe=a("strong"),lIo=o("not"),iIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hV=a("a"),dIo=o("from_pretrained()"),cIo=o(" to load the model weights."),fIo=l(),F(_7.$$.fragment),mIo=l(),eo=a("div"),F(Wy.$$.fragment),gIo=l(),Uhe=a("p"),hIo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),pIo=l(),ja=a("p"),_Io=o("The model class to instantiate is selected based on the "),Jhe=a("code"),uIo=o("model_type"),bIo=o(` property of the config object (either
passed as an argument or loaded from `),Yhe=a("code"),vIo=o("pretrained_model_name_or_path"),FIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Khe=a("code"),TIo=o("pretrained_model_name_or_path"),MIo=o(":"),EIo=l(),pe=a("ul"),u7=a("li"),Zhe=a("strong"),CIo=o("bart"),wIo=o(" \u2014 "),pV=a("a"),AIo=o("BartForConditionalGeneration"),LIo=o(" (BART model)"),yIo=l(),b7=a("li"),epe=a("strong"),xIo=o("bigbird_pegasus"),$Io=o(" \u2014 "),_V=a("a"),kIo=o("BigBirdPegasusForConditionalGeneration"),SIo=o(" (BigBird-Pegasus model)"),RIo=l(),v7=a("li"),ope=a("strong"),PIo=o("blenderbot"),BIo=o(" \u2014 "),uV=a("a"),NIo=o("BlenderbotForConditionalGeneration"),IIo=o(" (Blenderbot model)"),qIo=l(),F7=a("li"),rpe=a("strong"),jIo=o("blenderbot-small"),DIo=o(" \u2014 "),bV=a("a"),GIo=o("BlenderbotSmallForConditionalGeneration"),OIo=o(" (BlenderbotSmall model)"),VIo=l(),T7=a("li"),tpe=a("strong"),XIo=o("encoder-decoder"),zIo=o(" \u2014 "),vV=a("a"),QIo=o("EncoderDecoderModel"),WIo=o(" (Encoder decoder model)"),HIo=l(),M7=a("li"),ape=a("strong"),UIo=o("fsmt"),JIo=o(" \u2014 "),FV=a("a"),YIo=o("FSMTForConditionalGeneration"),KIo=o(" (FairSeq Machine-Translation model)"),ZIo=l(),E7=a("li"),npe=a("strong"),eqo=o("led"),oqo=o(" \u2014 "),TV=a("a"),rqo=o("LEDForConditionalGeneration"),tqo=o(" (LED model)"),aqo=l(),C7=a("li"),spe=a("strong"),nqo=o("longt5"),sqo=o(" \u2014 "),MV=a("a"),lqo=o("LongT5ForConditionalGeneration"),iqo=o(" (LongT5 model)"),dqo=l(),w7=a("li"),lpe=a("strong"),cqo=o("m2m_100"),fqo=o(" \u2014 "),EV=a("a"),mqo=o("M2M100ForConditionalGeneration"),gqo=o(" (M2M100 model)"),hqo=l(),A7=a("li"),ipe=a("strong"),pqo=o("marian"),_qo=o(" \u2014 "),CV=a("a"),uqo=o("MarianMTModel"),bqo=o(" (Marian model)"),vqo=l(),L7=a("li"),dpe=a("strong"),Fqo=o("mbart"),Tqo=o(" \u2014 "),wV=a("a"),Mqo=o("MBartForConditionalGeneration"),Eqo=o(" (mBART model)"),Cqo=l(),y7=a("li"),cpe=a("strong"),wqo=o("mt5"),Aqo=o(" \u2014 "),AV=a("a"),Lqo=o("MT5ForConditionalGeneration"),yqo=o(" (MT5 model)"),xqo=l(),x7=a("li"),fpe=a("strong"),$qo=o("mvp"),kqo=o(" \u2014 "),LV=a("a"),Sqo=o("MvpForConditionalGeneration"),Rqo=o(" (MVP model)"),Pqo=l(),$7=a("li"),mpe=a("strong"),Bqo=o("pegasus"),Nqo=o(" \u2014 "),yV=a("a"),Iqo=o("PegasusForConditionalGeneration"),qqo=o(" (Pegasus model)"),jqo=l(),k7=a("li"),gpe=a("strong"),Dqo=o("plbart"),Gqo=o(" \u2014 "),xV=a("a"),Oqo=o("PLBartForConditionalGeneration"),Vqo=o(" (PLBart model)"),Xqo=l(),S7=a("li"),hpe=a("strong"),zqo=o("prophetnet"),Qqo=o(" \u2014 "),$V=a("a"),Wqo=o("ProphetNetForConditionalGeneration"),Hqo=o(" (ProphetNet model)"),Uqo=l(),R7=a("li"),ppe=a("strong"),Jqo=o("t5"),Yqo=o(" \u2014 "),kV=a("a"),Kqo=o("T5ForConditionalGeneration"),Zqo=o(" (T5 model)"),ejo=l(),P7=a("li"),_pe=a("strong"),ojo=o("xlm-prophetnet"),rjo=o(" \u2014 "),SV=a("a"),tjo=o("XLMProphetNetForConditionalGeneration"),ajo=o(" (XLM-ProphetNet model)"),njo=l(),B7=a("p"),sjo=o("The model is set in evaluation mode by default using "),upe=a("code"),ljo=o("model.eval()"),ijo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bpe=a("code"),djo=o("model.train()"),cjo=l(),F(N7.$$.fragment),zVe=l(),ed=a("h2"),I7=a("a"),vpe=a("span"),F(Hy.$$.fragment),fjo=l(),Fpe=a("span"),mjo=o("AutoModelForSequenceClassification"),QVe=l(),Po=a("div"),F(Uy.$$.fragment),gjo=l(),od=a("p"),hjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),RV=a("a"),pjo=o("from_pretrained()"),_jo=o(" class method or the "),PV=a("a"),ujo=o("from_config()"),bjo=o(` class
method.`),vjo=l(),Jy=a("p"),Fjo=o("This class cannot be instantiated directly using "),Tpe=a("code"),Tjo=o("__init__()"),Mjo=o(" (throws an error)."),Ejo=l(),ft=a("div"),F(Yy.$$.fragment),Cjo=l(),Mpe=a("p"),wjo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Ajo=l(),rd=a("p"),Ljo=o(`Note:
Loading a model from its configuration file does `),Epe=a("strong"),yjo=o("not"),xjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=a("a"),$jo=o("from_pretrained()"),kjo=o(" to load the model weights."),Sjo=l(),F(q7.$$.fragment),Rjo=l(),oo=a("div"),F(Ky.$$.fragment),Pjo=l(),Cpe=a("p"),Bjo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Njo=l(),Da=a("p"),Ijo=o("The model class to instantiate is selected based on the "),wpe=a("code"),qjo=o("model_type"),jjo=o(` property of the config object (either
passed as an argument or loaded from `),Ape=a("code"),Djo=o("pretrained_model_name_or_path"),Gjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lpe=a("code"),Ojo=o("pretrained_model_name_or_path"),Vjo=o(":"),Xjo=l(),I=a("ul"),j7=a("li"),ype=a("strong"),zjo=o("albert"),Qjo=o(" \u2014 "),NV=a("a"),Wjo=o("AlbertForSequenceClassification"),Hjo=o(" (ALBERT model)"),Ujo=l(),D7=a("li"),xpe=a("strong"),Jjo=o("bart"),Yjo=o(" \u2014 "),IV=a("a"),Kjo=o("BartForSequenceClassification"),Zjo=o(" (BART model)"),eDo=l(),G7=a("li"),$pe=a("strong"),oDo=o("bert"),rDo=o(" \u2014 "),qV=a("a"),tDo=o("BertForSequenceClassification"),aDo=o(" (BERT model)"),nDo=l(),O7=a("li"),kpe=a("strong"),sDo=o("big_bird"),lDo=o(" \u2014 "),jV=a("a"),iDo=o("BigBirdForSequenceClassification"),dDo=o(" (BigBird model)"),cDo=l(),V7=a("li"),Spe=a("strong"),fDo=o("bigbird_pegasus"),mDo=o(" \u2014 "),DV=a("a"),gDo=o("BigBirdPegasusForSequenceClassification"),hDo=o(" (BigBird-Pegasus model)"),pDo=l(),X7=a("li"),Rpe=a("strong"),_Do=o("bloom"),uDo=o(" \u2014 "),GV=a("a"),bDo=o("BloomForSequenceClassification"),vDo=o(" (BLOOM model)"),FDo=l(),z7=a("li"),Ppe=a("strong"),TDo=o("camembert"),MDo=o(" \u2014 "),OV=a("a"),EDo=o("CamembertForSequenceClassification"),CDo=o(" (CamemBERT model)"),wDo=l(),Q7=a("li"),Bpe=a("strong"),ADo=o("canine"),LDo=o(" \u2014 "),VV=a("a"),yDo=o("CanineForSequenceClassification"),xDo=o(" (CANINE model)"),$Do=l(),W7=a("li"),Npe=a("strong"),kDo=o("convbert"),SDo=o(" \u2014 "),XV=a("a"),RDo=o("ConvBertForSequenceClassification"),PDo=o(" (ConvBERT model)"),BDo=l(),H7=a("li"),Ipe=a("strong"),NDo=o("ctrl"),IDo=o(" \u2014 "),zV=a("a"),qDo=o("CTRLForSequenceClassification"),jDo=o(" (CTRL model)"),DDo=l(),U7=a("li"),qpe=a("strong"),GDo=o("data2vec-text"),ODo=o(" \u2014 "),QV=a("a"),VDo=o("Data2VecTextForSequenceClassification"),XDo=o(" (Data2VecText model)"),zDo=l(),J7=a("li"),jpe=a("strong"),QDo=o("deberta"),WDo=o(" \u2014 "),WV=a("a"),HDo=o("DebertaForSequenceClassification"),UDo=o(" (DeBERTa model)"),JDo=l(),Y7=a("li"),Dpe=a("strong"),YDo=o("deberta-v2"),KDo=o(" \u2014 "),HV=a("a"),ZDo=o("DebertaV2ForSequenceClassification"),eGo=o(" (DeBERTa-v2 model)"),oGo=l(),K7=a("li"),Gpe=a("strong"),rGo=o("distilbert"),tGo=o(" \u2014 "),UV=a("a"),aGo=o("DistilBertForSequenceClassification"),nGo=o(" (DistilBERT model)"),sGo=l(),Z7=a("li"),Ope=a("strong"),lGo=o("electra"),iGo=o(" \u2014 "),JV=a("a"),dGo=o("ElectraForSequenceClassification"),cGo=o(" (ELECTRA model)"),fGo=l(),e4=a("li"),Vpe=a("strong"),mGo=o("flaubert"),gGo=o(" \u2014 "),YV=a("a"),hGo=o("FlaubertForSequenceClassification"),pGo=o(" (FlauBERT model)"),_Go=l(),o4=a("li"),Xpe=a("strong"),uGo=o("fnet"),bGo=o(" \u2014 "),KV=a("a"),vGo=o("FNetForSequenceClassification"),FGo=o(" (FNet model)"),TGo=l(),r4=a("li"),zpe=a("strong"),MGo=o("funnel"),EGo=o(" \u2014 "),ZV=a("a"),CGo=o("FunnelForSequenceClassification"),wGo=o(" (Funnel Transformer model)"),AGo=l(),t4=a("li"),Qpe=a("strong"),LGo=o("gpt2"),yGo=o(" \u2014 "),eX=a("a"),xGo=o("GPT2ForSequenceClassification"),$Go=o(" (OpenAI GPT-2 model)"),kGo=l(),a4=a("li"),Wpe=a("strong"),SGo=o("gpt_neo"),RGo=o(" \u2014 "),oX=a("a"),PGo=o("GPTNeoForSequenceClassification"),BGo=o(" (GPT Neo model)"),NGo=l(),n4=a("li"),Hpe=a("strong"),IGo=o("gptj"),qGo=o(" \u2014 "),rX=a("a"),jGo=o("GPTJForSequenceClassification"),DGo=o(" (GPT-J model)"),GGo=l(),s4=a("li"),Upe=a("strong"),OGo=o("ibert"),VGo=o(" \u2014 "),tX=a("a"),XGo=o("IBertForSequenceClassification"),zGo=o(" (I-BERT model)"),QGo=l(),l4=a("li"),Jpe=a("strong"),WGo=o("layoutlm"),HGo=o(" \u2014 "),aX=a("a"),UGo=o("LayoutLMForSequenceClassification"),JGo=o(" (LayoutLM model)"),YGo=l(),i4=a("li"),Ype=a("strong"),KGo=o("layoutlmv2"),ZGo=o(" \u2014 "),nX=a("a"),eOo=o("LayoutLMv2ForSequenceClassification"),oOo=o(" (LayoutLMv2 model)"),rOo=l(),d4=a("li"),Kpe=a("strong"),tOo=o("layoutlmv3"),aOo=o(" \u2014 "),sX=a("a"),nOo=o("LayoutLMv3ForSequenceClassification"),sOo=o(" (LayoutLMv3 model)"),lOo=l(),c4=a("li"),Zpe=a("strong"),iOo=o("led"),dOo=o(" \u2014 "),lX=a("a"),cOo=o("LEDForSequenceClassification"),fOo=o(" (LED model)"),mOo=l(),f4=a("li"),e_e=a("strong"),gOo=o("longformer"),hOo=o(" \u2014 "),iX=a("a"),pOo=o("LongformerForSequenceClassification"),_Oo=o(" (Longformer model)"),uOo=l(),m4=a("li"),o_e=a("strong"),bOo=o("mbart"),vOo=o(" \u2014 "),dX=a("a"),FOo=o("MBartForSequenceClassification"),TOo=o(" (mBART model)"),MOo=l(),g4=a("li"),r_e=a("strong"),EOo=o("megatron-bert"),COo=o(" \u2014 "),cX=a("a"),wOo=o("MegatronBertForSequenceClassification"),AOo=o(" (Megatron-BERT model)"),LOo=l(),h4=a("li"),t_e=a("strong"),yOo=o("mobilebert"),xOo=o(" \u2014 "),fX=a("a"),$Oo=o("MobileBertForSequenceClassification"),kOo=o(" (MobileBERT model)"),SOo=l(),p4=a("li"),a_e=a("strong"),ROo=o("mpnet"),POo=o(" \u2014 "),mX=a("a"),BOo=o("MPNetForSequenceClassification"),NOo=o(" (MPNet model)"),IOo=l(),_4=a("li"),n_e=a("strong"),qOo=o("mvp"),jOo=o(" \u2014 "),gX=a("a"),DOo=o("MvpForSequenceClassification"),GOo=o(" (MVP model)"),OOo=l(),u4=a("li"),s_e=a("strong"),VOo=o("nezha"),XOo=o(" \u2014 "),hX=a("a"),zOo=o("NezhaForSequenceClassification"),QOo=o(" (Nezha model)"),WOo=l(),b4=a("li"),l_e=a("strong"),HOo=o("nystromformer"),UOo=o(" \u2014 "),pX=a("a"),JOo=o("NystromformerForSequenceClassification"),YOo=o(" (Nystr\xF6mformer model)"),KOo=l(),v4=a("li"),i_e=a("strong"),ZOo=o("openai-gpt"),eVo=o(" \u2014 "),_X=a("a"),oVo=o("OpenAIGPTForSequenceClassification"),rVo=o(" (OpenAI GPT model)"),tVo=l(),F4=a("li"),d_e=a("strong"),aVo=o("perceiver"),nVo=o(" \u2014 "),uX=a("a"),sVo=o("PerceiverForSequenceClassification"),lVo=o(" (Perceiver model)"),iVo=l(),T4=a("li"),c_e=a("strong"),dVo=o("plbart"),cVo=o(" \u2014 "),bX=a("a"),fVo=o("PLBartForSequenceClassification"),mVo=o(" (PLBart model)"),gVo=l(),M4=a("li"),f_e=a("strong"),hVo=o("qdqbert"),pVo=o(" \u2014 "),vX=a("a"),_Vo=o("QDQBertForSequenceClassification"),uVo=o(" (QDQBert model)"),bVo=l(),E4=a("li"),m_e=a("strong"),vVo=o("reformer"),FVo=o(" \u2014 "),FX=a("a"),TVo=o("ReformerForSequenceClassification"),MVo=o(" (Reformer model)"),EVo=l(),C4=a("li"),g_e=a("strong"),CVo=o("rembert"),wVo=o(" \u2014 "),TX=a("a"),AVo=o("RemBertForSequenceClassification"),LVo=o(" (RemBERT model)"),yVo=l(),w4=a("li"),h_e=a("strong"),xVo=o("roberta"),$Vo=o(" \u2014 "),MX=a("a"),kVo=o("RobertaForSequenceClassification"),SVo=o(" (RoBERTa model)"),RVo=l(),A4=a("li"),p_e=a("strong"),PVo=o("roformer"),BVo=o(" \u2014 "),EX=a("a"),NVo=o("RoFormerForSequenceClassification"),IVo=o(" (RoFormer model)"),qVo=l(),L4=a("li"),__e=a("strong"),jVo=o("squeezebert"),DVo=o(" \u2014 "),CX=a("a"),GVo=o("SqueezeBertForSequenceClassification"),OVo=o(" (SqueezeBERT model)"),VVo=l(),y4=a("li"),u_e=a("strong"),XVo=o("tapas"),zVo=o(" \u2014 "),wX=a("a"),QVo=o("TapasForSequenceClassification"),WVo=o(" (TAPAS model)"),HVo=l(),x4=a("li"),b_e=a("strong"),UVo=o("transfo-xl"),JVo=o(" \u2014 "),AX=a("a"),YVo=o("TransfoXLForSequenceClassification"),KVo=o(" (Transformer-XL model)"),ZVo=l(),$4=a("li"),v_e=a("strong"),eXo=o("xlm"),oXo=o(" \u2014 "),LX=a("a"),rXo=o("XLMForSequenceClassification"),tXo=o(" (XLM model)"),aXo=l(),k4=a("li"),F_e=a("strong"),nXo=o("xlm-roberta"),sXo=o(" \u2014 "),yX=a("a"),lXo=o("XLMRobertaForSequenceClassification"),iXo=o(" (XLM-RoBERTa model)"),dXo=l(),S4=a("li"),T_e=a("strong"),cXo=o("xlm-roberta-xl"),fXo=o(" \u2014 "),xX=a("a"),mXo=o("XLMRobertaXLForSequenceClassification"),gXo=o(" (XLM-RoBERTa-XL model)"),hXo=l(),R4=a("li"),M_e=a("strong"),pXo=o("xlnet"),_Xo=o(" \u2014 "),$X=a("a"),uXo=o("XLNetForSequenceClassification"),bXo=o(" (XLNet model)"),vXo=l(),P4=a("li"),E_e=a("strong"),FXo=o("yoso"),TXo=o(" \u2014 "),kX=a("a"),MXo=o("YosoForSequenceClassification"),EXo=o(" (YOSO model)"),CXo=l(),B4=a("p"),wXo=o("The model is set in evaluation mode by default using "),C_e=a("code"),AXo=o("model.eval()"),LXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w_e=a("code"),yXo=o("model.train()"),xXo=l(),F(N4.$$.fragment),WVe=l(),td=a("h2"),I4=a("a"),A_e=a("span"),F(Zy.$$.fragment),$Xo=l(),L_e=a("span"),kXo=o("AutoModelForMultipleChoice"),HVe=l(),Bo=a("div"),F(e8.$$.fragment),SXo=l(),ad=a("p"),RXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),SX=a("a"),PXo=o("from_pretrained()"),BXo=o(" class method or the "),RX=a("a"),NXo=o("from_config()"),IXo=o(` class
method.`),qXo=l(),o8=a("p"),jXo=o("This class cannot be instantiated directly using "),y_e=a("code"),DXo=o("__init__()"),GXo=o(" (throws an error)."),OXo=l(),mt=a("div"),F(r8.$$.fragment),VXo=l(),x_e=a("p"),XXo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),zXo=l(),nd=a("p"),QXo=o(`Note:
Loading a model from its configuration file does `),$_e=a("strong"),WXo=o("not"),HXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PX=a("a"),UXo=o("from_pretrained()"),JXo=o(" to load the model weights."),YXo=l(),F(q4.$$.fragment),KXo=l(),ro=a("div"),F(t8.$$.fragment),ZXo=l(),k_e=a("p"),ezo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ozo=l(),Ga=a("p"),rzo=o("The model class to instantiate is selected based on the "),S_e=a("code"),tzo=o("model_type"),azo=o(` property of the config object (either
passed as an argument or loaded from `),R_e=a("code"),nzo=o("pretrained_model_name_or_path"),szo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P_e=a("code"),lzo=o("pretrained_model_name_or_path"),izo=o(":"),dzo=l(),Z=a("ul"),j4=a("li"),B_e=a("strong"),czo=o("albert"),fzo=o(" \u2014 "),BX=a("a"),mzo=o("AlbertForMultipleChoice"),gzo=o(" (ALBERT model)"),hzo=l(),D4=a("li"),N_e=a("strong"),pzo=o("bert"),_zo=o(" \u2014 "),NX=a("a"),uzo=o("BertForMultipleChoice"),bzo=o(" (BERT model)"),vzo=l(),G4=a("li"),I_e=a("strong"),Fzo=o("big_bird"),Tzo=o(" \u2014 "),IX=a("a"),Mzo=o("BigBirdForMultipleChoice"),Ezo=o(" (BigBird model)"),Czo=l(),O4=a("li"),q_e=a("strong"),wzo=o("camembert"),Azo=o(" \u2014 "),qX=a("a"),Lzo=o("CamembertForMultipleChoice"),yzo=o(" (CamemBERT model)"),xzo=l(),V4=a("li"),j_e=a("strong"),$zo=o("canine"),kzo=o(" \u2014 "),jX=a("a"),Szo=o("CanineForMultipleChoice"),Rzo=o(" (CANINE model)"),Pzo=l(),X4=a("li"),D_e=a("strong"),Bzo=o("convbert"),Nzo=o(" \u2014 "),DX=a("a"),Izo=o("ConvBertForMultipleChoice"),qzo=o(" (ConvBERT model)"),jzo=l(),z4=a("li"),G_e=a("strong"),Dzo=o("data2vec-text"),Gzo=o(" \u2014 "),GX=a("a"),Ozo=o("Data2VecTextForMultipleChoice"),Vzo=o(" (Data2VecText model)"),Xzo=l(),Q4=a("li"),O_e=a("strong"),zzo=o("deberta-v2"),Qzo=o(" \u2014 "),OX=a("a"),Wzo=o("DebertaV2ForMultipleChoice"),Hzo=o(" (DeBERTa-v2 model)"),Uzo=l(),W4=a("li"),V_e=a("strong"),Jzo=o("distilbert"),Yzo=o(" \u2014 "),VX=a("a"),Kzo=o("DistilBertForMultipleChoice"),Zzo=o(" (DistilBERT model)"),eQo=l(),H4=a("li"),X_e=a("strong"),oQo=o("electra"),rQo=o(" \u2014 "),XX=a("a"),tQo=o("ElectraForMultipleChoice"),aQo=o(" (ELECTRA model)"),nQo=l(),U4=a("li"),z_e=a("strong"),sQo=o("flaubert"),lQo=o(" \u2014 "),zX=a("a"),iQo=o("FlaubertForMultipleChoice"),dQo=o(" (FlauBERT model)"),cQo=l(),J4=a("li"),Q_e=a("strong"),fQo=o("fnet"),mQo=o(" \u2014 "),QX=a("a"),gQo=o("FNetForMultipleChoice"),hQo=o(" (FNet model)"),pQo=l(),Y4=a("li"),W_e=a("strong"),_Qo=o("funnel"),uQo=o(" \u2014 "),WX=a("a"),bQo=o("FunnelForMultipleChoice"),vQo=o(" (Funnel Transformer model)"),FQo=l(),K4=a("li"),H_e=a("strong"),TQo=o("ibert"),MQo=o(" \u2014 "),HX=a("a"),EQo=o("IBertForMultipleChoice"),CQo=o(" (I-BERT model)"),wQo=l(),Z4=a("li"),U_e=a("strong"),AQo=o("longformer"),LQo=o(" \u2014 "),UX=a("a"),yQo=o("LongformerForMultipleChoice"),xQo=o(" (Longformer model)"),$Qo=l(),eb=a("li"),J_e=a("strong"),kQo=o("megatron-bert"),SQo=o(" \u2014 "),JX=a("a"),RQo=o("MegatronBertForMultipleChoice"),PQo=o(" (Megatron-BERT model)"),BQo=l(),ob=a("li"),Y_e=a("strong"),NQo=o("mobilebert"),IQo=o(" \u2014 "),YX=a("a"),qQo=o("MobileBertForMultipleChoice"),jQo=o(" (MobileBERT model)"),DQo=l(),rb=a("li"),K_e=a("strong"),GQo=o("mpnet"),OQo=o(" \u2014 "),KX=a("a"),VQo=o("MPNetForMultipleChoice"),XQo=o(" (MPNet model)"),zQo=l(),tb=a("li"),Z_e=a("strong"),QQo=o("nezha"),WQo=o(" \u2014 "),ZX=a("a"),HQo=o("NezhaForMultipleChoice"),UQo=o(" (Nezha model)"),JQo=l(),ab=a("li"),eue=a("strong"),YQo=o("nystromformer"),KQo=o(" \u2014 "),ez=a("a"),ZQo=o("NystromformerForMultipleChoice"),eWo=o(" (Nystr\xF6mformer model)"),oWo=l(),nb=a("li"),oue=a("strong"),rWo=o("qdqbert"),tWo=o(" \u2014 "),oz=a("a"),aWo=o("QDQBertForMultipleChoice"),nWo=o(" (QDQBert model)"),sWo=l(),sb=a("li"),rue=a("strong"),lWo=o("rembert"),iWo=o(" \u2014 "),rz=a("a"),dWo=o("RemBertForMultipleChoice"),cWo=o(" (RemBERT model)"),fWo=l(),lb=a("li"),tue=a("strong"),mWo=o("roberta"),gWo=o(" \u2014 "),tz=a("a"),hWo=o("RobertaForMultipleChoice"),pWo=o(" (RoBERTa model)"),_Wo=l(),ib=a("li"),aue=a("strong"),uWo=o("roformer"),bWo=o(" \u2014 "),az=a("a"),vWo=o("RoFormerForMultipleChoice"),FWo=o(" (RoFormer model)"),TWo=l(),db=a("li"),nue=a("strong"),MWo=o("squeezebert"),EWo=o(" \u2014 "),nz=a("a"),CWo=o("SqueezeBertForMultipleChoice"),wWo=o(" (SqueezeBERT model)"),AWo=l(),cb=a("li"),sue=a("strong"),LWo=o("xlm"),yWo=o(" \u2014 "),sz=a("a"),xWo=o("XLMForMultipleChoice"),$Wo=o(" (XLM model)"),kWo=l(),fb=a("li"),lue=a("strong"),SWo=o("xlm-roberta"),RWo=o(" \u2014 "),lz=a("a"),PWo=o("XLMRobertaForMultipleChoice"),BWo=o(" (XLM-RoBERTa model)"),NWo=l(),mb=a("li"),iue=a("strong"),IWo=o("xlm-roberta-xl"),qWo=o(" \u2014 "),iz=a("a"),jWo=o("XLMRobertaXLForMultipleChoice"),DWo=o(" (XLM-RoBERTa-XL model)"),GWo=l(),gb=a("li"),due=a("strong"),OWo=o("xlnet"),VWo=o(" \u2014 "),dz=a("a"),XWo=o("XLNetForMultipleChoice"),zWo=o(" (XLNet model)"),QWo=l(),hb=a("li"),cue=a("strong"),WWo=o("yoso"),HWo=o(" \u2014 "),cz=a("a"),UWo=o("YosoForMultipleChoice"),JWo=o(" (YOSO model)"),YWo=l(),pb=a("p"),KWo=o("The model is set in evaluation mode by default using "),fue=a("code"),ZWo=o("model.eval()"),eHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mue=a("code"),oHo=o("model.train()"),rHo=l(),F(_b.$$.fragment),UVe=l(),sd=a("h2"),ub=a("a"),gue=a("span"),F(a8.$$.fragment),tHo=l(),hue=a("span"),aHo=o("AutoModelForNextSentencePrediction"),JVe=l(),No=a("div"),F(n8.$$.fragment),nHo=l(),ld=a("p"),sHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fz=a("a"),lHo=o("from_pretrained()"),iHo=o(" class method or the "),mz=a("a"),dHo=o("from_config()"),cHo=o(` class
method.`),fHo=l(),s8=a("p"),mHo=o("This class cannot be instantiated directly using "),pue=a("code"),gHo=o("__init__()"),hHo=o(" (throws an error)."),pHo=l(),gt=a("div"),F(l8.$$.fragment),_Ho=l(),_ue=a("p"),uHo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bHo=l(),id=a("p"),vHo=o(`Note:
Loading a model from its configuration file does `),uue=a("strong"),FHo=o("not"),THo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gz=a("a"),MHo=o("from_pretrained()"),EHo=o(" to load the model weights."),CHo=l(),F(bb.$$.fragment),wHo=l(),to=a("div"),F(i8.$$.fragment),AHo=l(),bue=a("p"),LHo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),yHo=l(),Oa=a("p"),xHo=o("The model class to instantiate is selected based on the "),vue=a("code"),$Ho=o("model_type"),kHo=o(` property of the config object (either
passed as an argument or loaded from `),Fue=a("code"),SHo=o("pretrained_model_name_or_path"),RHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tue=a("code"),PHo=o("pretrained_model_name_or_path"),BHo=o(":"),NHo=l(),Io=a("ul"),vb=a("li"),Mue=a("strong"),IHo=o("bert"),qHo=o(" \u2014 "),hz=a("a"),jHo=o("BertForNextSentencePrediction"),DHo=o(" (BERT model)"),GHo=l(),Fb=a("li"),Eue=a("strong"),OHo=o("fnet"),VHo=o(" \u2014 "),pz=a("a"),XHo=o("FNetForNextSentencePrediction"),zHo=o(" (FNet model)"),QHo=l(),Tb=a("li"),Cue=a("strong"),WHo=o("megatron-bert"),HHo=o(" \u2014 "),_z=a("a"),UHo=o("MegatronBertForNextSentencePrediction"),JHo=o(" (Megatron-BERT model)"),YHo=l(),Mb=a("li"),wue=a("strong"),KHo=o("mobilebert"),ZHo=o(" \u2014 "),uz=a("a"),eUo=o("MobileBertForNextSentencePrediction"),oUo=o(" (MobileBERT model)"),rUo=l(),Eb=a("li"),Aue=a("strong"),tUo=o("nezha"),aUo=o(" \u2014 "),bz=a("a"),nUo=o("NezhaForNextSentencePrediction"),sUo=o(" (Nezha model)"),lUo=l(),Cb=a("li"),Lue=a("strong"),iUo=o("qdqbert"),dUo=o(" \u2014 "),vz=a("a"),cUo=o("QDQBertForNextSentencePrediction"),fUo=o(" (QDQBert model)"),mUo=l(),wb=a("p"),gUo=o("The model is set in evaluation mode by default using "),yue=a("code"),hUo=o("model.eval()"),pUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xue=a("code"),_Uo=o("model.train()"),uUo=l(),F(Ab.$$.fragment),YVe=l(),dd=a("h2"),Lb=a("a"),$ue=a("span"),F(d8.$$.fragment),bUo=l(),kue=a("span"),vUo=o("AutoModelForTokenClassification"),KVe=l(),qo=a("div"),F(c8.$$.fragment),FUo=l(),cd=a("p"),TUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fz=a("a"),MUo=o("from_pretrained()"),EUo=o(" class method or the "),Tz=a("a"),CUo=o("from_config()"),wUo=o(` class
method.`),AUo=l(),f8=a("p"),LUo=o("This class cannot be instantiated directly using "),Sue=a("code"),yUo=o("__init__()"),xUo=o(" (throws an error)."),$Uo=l(),ht=a("div"),F(m8.$$.fragment),kUo=l(),Rue=a("p"),SUo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),RUo=l(),fd=a("p"),PUo=o(`Note:
Loading a model from its configuration file does `),Pue=a("strong"),BUo=o("not"),NUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mz=a("a"),IUo=o("from_pretrained()"),qUo=o(" to load the model weights."),jUo=l(),F(yb.$$.fragment),DUo=l(),ao=a("div"),F(g8.$$.fragment),GUo=l(),Bue=a("p"),OUo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VUo=l(),Va=a("p"),XUo=o("The model class to instantiate is selected based on the "),Nue=a("code"),zUo=o("model_type"),QUo=o(` property of the config object (either
passed as an argument or loaded from `),Iue=a("code"),WUo=o("pretrained_model_name_or_path"),HUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),que=a("code"),UUo=o("pretrained_model_name_or_path"),JUo=o(":"),YUo=l(),U=a("ul"),xb=a("li"),jue=a("strong"),KUo=o("albert"),ZUo=o(" \u2014 "),Ez=a("a"),eJo=o("AlbertForTokenClassification"),oJo=o(" (ALBERT model)"),rJo=l(),$b=a("li"),Due=a("strong"),tJo=o("bert"),aJo=o(" \u2014 "),Cz=a("a"),nJo=o("BertForTokenClassification"),sJo=o(" (BERT model)"),lJo=l(),kb=a("li"),Gue=a("strong"),iJo=o("big_bird"),dJo=o(" \u2014 "),wz=a("a"),cJo=o("BigBirdForTokenClassification"),fJo=o(" (BigBird model)"),mJo=l(),Sb=a("li"),Oue=a("strong"),gJo=o("bloom"),hJo=o(" \u2014 "),Az=a("a"),pJo=o("BloomForTokenClassification"),_Jo=o(" (BLOOM model)"),uJo=l(),Rb=a("li"),Vue=a("strong"),bJo=o("camembert"),vJo=o(" \u2014 "),Lz=a("a"),FJo=o("CamembertForTokenClassification"),TJo=o(" (CamemBERT model)"),MJo=l(),Pb=a("li"),Xue=a("strong"),EJo=o("canine"),CJo=o(" \u2014 "),yz=a("a"),wJo=o("CanineForTokenClassification"),AJo=o(" (CANINE model)"),LJo=l(),Bb=a("li"),zue=a("strong"),yJo=o("convbert"),xJo=o(" \u2014 "),xz=a("a"),$Jo=o("ConvBertForTokenClassification"),kJo=o(" (ConvBERT model)"),SJo=l(),Nb=a("li"),Que=a("strong"),RJo=o("data2vec-text"),PJo=o(" \u2014 "),$z=a("a"),BJo=o("Data2VecTextForTokenClassification"),NJo=o(" (Data2VecText model)"),IJo=l(),Ib=a("li"),Wue=a("strong"),qJo=o("deberta"),jJo=o(" \u2014 "),kz=a("a"),DJo=o("DebertaForTokenClassification"),GJo=o(" (DeBERTa model)"),OJo=l(),qb=a("li"),Hue=a("strong"),VJo=o("deberta-v2"),XJo=o(" \u2014 "),Sz=a("a"),zJo=o("DebertaV2ForTokenClassification"),QJo=o(" (DeBERTa-v2 model)"),WJo=l(),jb=a("li"),Uue=a("strong"),HJo=o("distilbert"),UJo=o(" \u2014 "),Rz=a("a"),JJo=o("DistilBertForTokenClassification"),YJo=o(" (DistilBERT model)"),KJo=l(),Db=a("li"),Jue=a("strong"),ZJo=o("electra"),eYo=o(" \u2014 "),Pz=a("a"),oYo=o("ElectraForTokenClassification"),rYo=o(" (ELECTRA model)"),tYo=l(),Gb=a("li"),Yue=a("strong"),aYo=o("flaubert"),nYo=o(" \u2014 "),Bz=a("a"),sYo=o("FlaubertForTokenClassification"),lYo=o(" (FlauBERT model)"),iYo=l(),Ob=a("li"),Kue=a("strong"),dYo=o("fnet"),cYo=o(" \u2014 "),Nz=a("a"),fYo=o("FNetForTokenClassification"),mYo=o(" (FNet model)"),gYo=l(),Vb=a("li"),Zue=a("strong"),hYo=o("funnel"),pYo=o(" \u2014 "),Iz=a("a"),_Yo=o("FunnelForTokenClassification"),uYo=o(" (Funnel Transformer model)"),bYo=l(),Xb=a("li"),e2e=a("strong"),vYo=o("gpt2"),FYo=o(" \u2014 "),qz=a("a"),TYo=o("GPT2ForTokenClassification"),MYo=o(" (OpenAI GPT-2 model)"),EYo=l(),zb=a("li"),o2e=a("strong"),CYo=o("ibert"),wYo=o(" \u2014 "),jz=a("a"),AYo=o("IBertForTokenClassification"),LYo=o(" (I-BERT model)"),yYo=l(),Qb=a("li"),r2e=a("strong"),xYo=o("layoutlm"),$Yo=o(" \u2014 "),Dz=a("a"),kYo=o("LayoutLMForTokenClassification"),SYo=o(" (LayoutLM model)"),RYo=l(),Wb=a("li"),t2e=a("strong"),PYo=o("layoutlmv2"),BYo=o(" \u2014 "),Gz=a("a"),NYo=o("LayoutLMv2ForTokenClassification"),IYo=o(" (LayoutLMv2 model)"),qYo=l(),Hb=a("li"),a2e=a("strong"),jYo=o("layoutlmv3"),DYo=o(" \u2014 "),Oz=a("a"),GYo=o("LayoutLMv3ForTokenClassification"),OYo=o(" (LayoutLMv3 model)"),VYo=l(),Ub=a("li"),n2e=a("strong"),XYo=o("longformer"),zYo=o(" \u2014 "),Vz=a("a"),QYo=o("LongformerForTokenClassification"),WYo=o(" (Longformer model)"),HYo=l(),Jb=a("li"),s2e=a("strong"),UYo=o("megatron-bert"),JYo=o(" \u2014 "),Xz=a("a"),YYo=o("MegatronBertForTokenClassification"),KYo=o(" (Megatron-BERT model)"),ZYo=l(),Yb=a("li"),l2e=a("strong"),eKo=o("mobilebert"),oKo=o(" \u2014 "),zz=a("a"),rKo=o("MobileBertForTokenClassification"),tKo=o(" (MobileBERT model)"),aKo=l(),Kb=a("li"),i2e=a("strong"),nKo=o("mpnet"),sKo=o(" \u2014 "),Qz=a("a"),lKo=o("MPNetForTokenClassification"),iKo=o(" (MPNet model)"),dKo=l(),Zb=a("li"),d2e=a("strong"),cKo=o("nezha"),fKo=o(" \u2014 "),Wz=a("a"),mKo=o("NezhaForTokenClassification"),gKo=o(" (Nezha model)"),hKo=l(),ev=a("li"),c2e=a("strong"),pKo=o("nystromformer"),_Ko=o(" \u2014 "),Hz=a("a"),uKo=o("NystromformerForTokenClassification"),bKo=o(" (Nystr\xF6mformer model)"),vKo=l(),ov=a("li"),f2e=a("strong"),FKo=o("qdqbert"),TKo=o(" \u2014 "),Uz=a("a"),MKo=o("QDQBertForTokenClassification"),EKo=o(" (QDQBert model)"),CKo=l(),rv=a("li"),m2e=a("strong"),wKo=o("rembert"),AKo=o(" \u2014 "),Jz=a("a"),LKo=o("RemBertForTokenClassification"),yKo=o(" (RemBERT model)"),xKo=l(),tv=a("li"),g2e=a("strong"),$Ko=o("roberta"),kKo=o(" \u2014 "),Yz=a("a"),SKo=o("RobertaForTokenClassification"),RKo=o(" (RoBERTa model)"),PKo=l(),av=a("li"),h2e=a("strong"),BKo=o("roformer"),NKo=o(" \u2014 "),Kz=a("a"),IKo=o("RoFormerForTokenClassification"),qKo=o(" (RoFormer model)"),jKo=l(),nv=a("li"),p2e=a("strong"),DKo=o("squeezebert"),GKo=o(" \u2014 "),Zz=a("a"),OKo=o("SqueezeBertForTokenClassification"),VKo=o(" (SqueezeBERT model)"),XKo=l(),sv=a("li"),_2e=a("strong"),zKo=o("xlm"),QKo=o(" \u2014 "),eQ=a("a"),WKo=o("XLMForTokenClassification"),HKo=o(" (XLM model)"),UKo=l(),lv=a("li"),u2e=a("strong"),JKo=o("xlm-roberta"),YKo=o(" \u2014 "),oQ=a("a"),KKo=o("XLMRobertaForTokenClassification"),ZKo=o(" (XLM-RoBERTa model)"),eZo=l(),iv=a("li"),b2e=a("strong"),oZo=o("xlm-roberta-xl"),rZo=o(" \u2014 "),rQ=a("a"),tZo=o("XLMRobertaXLForTokenClassification"),aZo=o(" (XLM-RoBERTa-XL model)"),nZo=l(),dv=a("li"),v2e=a("strong"),sZo=o("xlnet"),lZo=o(" \u2014 "),tQ=a("a"),iZo=o("XLNetForTokenClassification"),dZo=o(" (XLNet model)"),cZo=l(),cv=a("li"),F2e=a("strong"),fZo=o("yoso"),mZo=o(" \u2014 "),aQ=a("a"),gZo=o("YosoForTokenClassification"),hZo=o(" (YOSO model)"),pZo=l(),fv=a("p"),_Zo=o("The model is set in evaluation mode by default using "),T2e=a("code"),uZo=o("model.eval()"),bZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M2e=a("code"),vZo=o("model.train()"),FZo=l(),F(mv.$$.fragment),ZVe=l(),md=a("h2"),gv=a("a"),E2e=a("span"),F(h8.$$.fragment),TZo=l(),C2e=a("span"),MZo=o("AutoModelForQuestionAnswering"),eXe=l(),jo=a("div"),F(p8.$$.fragment),EZo=l(),gd=a("p"),CZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nQ=a("a"),wZo=o("from_pretrained()"),AZo=o(" class method or the "),sQ=a("a"),LZo=o("from_config()"),yZo=o(` class
method.`),xZo=l(),_8=a("p"),$Zo=o("This class cannot be instantiated directly using "),w2e=a("code"),kZo=o("__init__()"),SZo=o(" (throws an error)."),RZo=l(),pt=a("div"),F(u8.$$.fragment),PZo=l(),A2e=a("p"),BZo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),NZo=l(),hd=a("p"),IZo=o(`Note:
Loading a model from its configuration file does `),L2e=a("strong"),qZo=o("not"),jZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lQ=a("a"),DZo=o("from_pretrained()"),GZo=o(" to load the model weights."),OZo=l(),F(hv.$$.fragment),VZo=l(),no=a("div"),F(b8.$$.fragment),XZo=l(),y2e=a("p"),zZo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),QZo=l(),Xa=a("p"),WZo=o("The model class to instantiate is selected based on the "),x2e=a("code"),HZo=o("model_type"),UZo=o(` property of the config object (either
passed as an argument or loaded from `),$2e=a("code"),JZo=o("pretrained_model_name_or_path"),YZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k2e=a("code"),KZo=o("pretrained_model_name_or_path"),ZZo=o(":"),eer=l(),V=a("ul"),pv=a("li"),S2e=a("strong"),oer=o("albert"),rer=o(" \u2014 "),iQ=a("a"),ter=o("AlbertForQuestionAnswering"),aer=o(" (ALBERT model)"),ner=l(),_v=a("li"),R2e=a("strong"),ser=o("bart"),ler=o(" \u2014 "),dQ=a("a"),ier=o("BartForQuestionAnswering"),der=o(" (BART model)"),cer=l(),uv=a("li"),P2e=a("strong"),fer=o("bert"),mer=o(" \u2014 "),cQ=a("a"),ger=o("BertForQuestionAnswering"),her=o(" (BERT model)"),per=l(),bv=a("li"),B2e=a("strong"),_er=o("big_bird"),uer=o(" \u2014 "),fQ=a("a"),ber=o("BigBirdForQuestionAnswering"),ver=o(" (BigBird model)"),Fer=l(),vv=a("li"),N2e=a("strong"),Ter=o("bigbird_pegasus"),Mer=o(" \u2014 "),mQ=a("a"),Eer=o("BigBirdPegasusForQuestionAnswering"),Cer=o(" (BigBird-Pegasus model)"),wer=l(),Fv=a("li"),I2e=a("strong"),Aer=o("camembert"),Ler=o(" \u2014 "),gQ=a("a"),yer=o("CamembertForQuestionAnswering"),xer=o(" (CamemBERT model)"),$er=l(),Tv=a("li"),q2e=a("strong"),ker=o("canine"),Ser=o(" \u2014 "),hQ=a("a"),Rer=o("CanineForQuestionAnswering"),Per=o(" (CANINE model)"),Ber=l(),Mv=a("li"),j2e=a("strong"),Ner=o("convbert"),Ier=o(" \u2014 "),pQ=a("a"),qer=o("ConvBertForQuestionAnswering"),jer=o(" (ConvBERT model)"),Der=l(),Ev=a("li"),D2e=a("strong"),Ger=o("data2vec-text"),Oer=o(" \u2014 "),_Q=a("a"),Ver=o("Data2VecTextForQuestionAnswering"),Xer=o(" (Data2VecText model)"),zer=l(),Cv=a("li"),G2e=a("strong"),Qer=o("deberta"),Wer=o(" \u2014 "),uQ=a("a"),Her=o("DebertaForQuestionAnswering"),Uer=o(" (DeBERTa model)"),Jer=l(),wv=a("li"),O2e=a("strong"),Yer=o("deberta-v2"),Ker=o(" \u2014 "),bQ=a("a"),Zer=o("DebertaV2ForQuestionAnswering"),eor=o(" (DeBERTa-v2 model)"),oor=l(),Av=a("li"),V2e=a("strong"),ror=o("distilbert"),tor=o(" \u2014 "),vQ=a("a"),aor=o("DistilBertForQuestionAnswering"),nor=o(" (DistilBERT model)"),sor=l(),Lv=a("li"),X2e=a("strong"),lor=o("electra"),ior=o(" \u2014 "),FQ=a("a"),dor=o("ElectraForQuestionAnswering"),cor=o(" (ELECTRA model)"),mor=l(),yv=a("li"),z2e=a("strong"),gor=o("flaubert"),hor=o(" \u2014 "),TQ=a("a"),por=o("FlaubertForQuestionAnsweringSimple"),_or=o(" (FlauBERT model)"),uor=l(),xv=a("li"),Q2e=a("strong"),bor=o("fnet"),vor=o(" \u2014 "),MQ=a("a"),For=o("FNetForQuestionAnswering"),Tor=o(" (FNet model)"),Mor=l(),$v=a("li"),W2e=a("strong"),Eor=o("funnel"),Cor=o(" \u2014 "),EQ=a("a"),wor=o("FunnelForQuestionAnswering"),Aor=o(" (Funnel Transformer model)"),Lor=l(),kv=a("li"),H2e=a("strong"),yor=o("gptj"),xor=o(" \u2014 "),CQ=a("a"),$or=o("GPTJForQuestionAnswering"),kor=o(" (GPT-J model)"),Sor=l(),Sv=a("li"),U2e=a("strong"),Ror=o("ibert"),Por=o(" \u2014 "),wQ=a("a"),Bor=o("IBertForQuestionAnswering"),Nor=o(" (I-BERT model)"),Ior=l(),Rv=a("li"),J2e=a("strong"),qor=o("layoutlmv2"),jor=o(" \u2014 "),AQ=a("a"),Dor=o("LayoutLMv2ForQuestionAnswering"),Gor=o(" (LayoutLMv2 model)"),Oor=l(),Pv=a("li"),Y2e=a("strong"),Vor=o("layoutlmv3"),Xor=o(" \u2014 "),LQ=a("a"),zor=o("LayoutLMv3ForQuestionAnswering"),Qor=o(" (LayoutLMv3 model)"),Wor=l(),Bv=a("li"),K2e=a("strong"),Hor=o("led"),Uor=o(" \u2014 "),yQ=a("a"),Jor=o("LEDForQuestionAnswering"),Yor=o(" (LED model)"),Kor=l(),Nv=a("li"),Z2e=a("strong"),Zor=o("longformer"),err=o(" \u2014 "),xQ=a("a"),orr=o("LongformerForQuestionAnswering"),rrr=o(" (Longformer model)"),trr=l(),Iv=a("li"),e1e=a("strong"),arr=o("lxmert"),nrr=o(" \u2014 "),$Q=a("a"),srr=o("LxmertForQuestionAnswering"),lrr=o(" (LXMERT model)"),irr=l(),qv=a("li"),o1e=a("strong"),drr=o("mbart"),crr=o(" \u2014 "),kQ=a("a"),frr=o("MBartForQuestionAnswering"),mrr=o(" (mBART model)"),grr=l(),jv=a("li"),r1e=a("strong"),hrr=o("megatron-bert"),prr=o(" \u2014 "),SQ=a("a"),_rr=o("MegatronBertForQuestionAnswering"),urr=o(" (Megatron-BERT model)"),brr=l(),Dv=a("li"),t1e=a("strong"),vrr=o("mobilebert"),Frr=o(" \u2014 "),RQ=a("a"),Trr=o("MobileBertForQuestionAnswering"),Mrr=o(" (MobileBERT model)"),Err=l(),Gv=a("li"),a1e=a("strong"),Crr=o("mpnet"),wrr=o(" \u2014 "),PQ=a("a"),Arr=o("MPNetForQuestionAnswering"),Lrr=o(" (MPNet model)"),yrr=l(),Ov=a("li"),n1e=a("strong"),xrr=o("mvp"),$rr=o(" \u2014 "),BQ=a("a"),krr=o("MvpForQuestionAnswering"),Srr=o(" (MVP model)"),Rrr=l(),Vv=a("li"),s1e=a("strong"),Prr=o("nezha"),Brr=o(" \u2014 "),NQ=a("a"),Nrr=o("NezhaForQuestionAnswering"),Irr=o(" (Nezha model)"),qrr=l(),Xv=a("li"),l1e=a("strong"),jrr=o("nystromformer"),Drr=o(" \u2014 "),IQ=a("a"),Grr=o("NystromformerForQuestionAnswering"),Orr=o(" (Nystr\xF6mformer model)"),Vrr=l(),zv=a("li"),i1e=a("strong"),Xrr=o("qdqbert"),zrr=o(" \u2014 "),qQ=a("a"),Qrr=o("QDQBertForQuestionAnswering"),Wrr=o(" (QDQBert model)"),Hrr=l(),Qv=a("li"),d1e=a("strong"),Urr=o("reformer"),Jrr=o(" \u2014 "),jQ=a("a"),Yrr=o("ReformerForQuestionAnswering"),Krr=o(" (Reformer model)"),Zrr=l(),Wv=a("li"),c1e=a("strong"),etr=o("rembert"),otr=o(" \u2014 "),DQ=a("a"),rtr=o("RemBertForQuestionAnswering"),ttr=o(" (RemBERT model)"),atr=l(),Hv=a("li"),f1e=a("strong"),ntr=o("roberta"),str=o(" \u2014 "),GQ=a("a"),ltr=o("RobertaForQuestionAnswering"),itr=o(" (RoBERTa model)"),dtr=l(),Uv=a("li"),m1e=a("strong"),ctr=o("roformer"),ftr=o(" \u2014 "),OQ=a("a"),mtr=o("RoFormerForQuestionAnswering"),gtr=o(" (RoFormer model)"),htr=l(),Jv=a("li"),g1e=a("strong"),ptr=o("splinter"),_tr=o(" \u2014 "),VQ=a("a"),utr=o("SplinterForQuestionAnswering"),btr=o(" (Splinter model)"),vtr=l(),Yv=a("li"),h1e=a("strong"),Ftr=o("squeezebert"),Ttr=o(" \u2014 "),XQ=a("a"),Mtr=o("SqueezeBertForQuestionAnswering"),Etr=o(" (SqueezeBERT model)"),Ctr=l(),Kv=a("li"),p1e=a("strong"),wtr=o("xlm"),Atr=o(" \u2014 "),zQ=a("a"),Ltr=o("XLMForQuestionAnsweringSimple"),ytr=o(" (XLM model)"),xtr=l(),Zv=a("li"),_1e=a("strong"),$tr=o("xlm-roberta"),ktr=o(" \u2014 "),QQ=a("a"),Str=o("XLMRobertaForQuestionAnswering"),Rtr=o(" (XLM-RoBERTa model)"),Ptr=l(),eF=a("li"),u1e=a("strong"),Btr=o("xlm-roberta-xl"),Ntr=o(" \u2014 "),WQ=a("a"),Itr=o("XLMRobertaXLForQuestionAnswering"),qtr=o(" (XLM-RoBERTa-XL model)"),jtr=l(),oF=a("li"),b1e=a("strong"),Dtr=o("xlnet"),Gtr=o(" \u2014 "),HQ=a("a"),Otr=o("XLNetForQuestionAnsweringSimple"),Vtr=o(" (XLNet model)"),Xtr=l(),rF=a("li"),v1e=a("strong"),ztr=o("yoso"),Qtr=o(" \u2014 "),UQ=a("a"),Wtr=o("YosoForQuestionAnswering"),Htr=o(" (YOSO model)"),Utr=l(),tF=a("p"),Jtr=o("The model is set in evaluation mode by default using "),F1e=a("code"),Ytr=o("model.eval()"),Ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T1e=a("code"),Ztr=o("model.train()"),ear=l(),F(aF.$$.fragment),oXe=l(),pd=a("h2"),nF=a("a"),M1e=a("span"),F(v8.$$.fragment),oar=l(),E1e=a("span"),rar=o("AutoModelForTableQuestionAnswering"),rXe=l(),Do=a("div"),F(F8.$$.fragment),tar=l(),_d=a("p"),aar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),JQ=a("a"),nar=o("from_pretrained()"),sar=o(" class method or the "),YQ=a("a"),lar=o("from_config()"),iar=o(` class
method.`),dar=l(),T8=a("p"),car=o("This class cannot be instantiated directly using "),C1e=a("code"),far=o("__init__()"),mar=o(" (throws an error)."),gar=l(),_t=a("div"),F(M8.$$.fragment),har=l(),w1e=a("p"),par=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),_ar=l(),ud=a("p"),uar=o(`Note:
Loading a model from its configuration file does `),A1e=a("strong"),bar=o("not"),Far=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=a("a"),Tar=o("from_pretrained()"),Mar=o(" to load the model weights."),Ear=l(),F(sF.$$.fragment),Car=l(),so=a("div"),F(E8.$$.fragment),war=l(),L1e=a("p"),Aar=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Lar=l(),za=a("p"),yar=o("The model class to instantiate is selected based on the "),y1e=a("code"),xar=o("model_type"),$ar=o(` property of the config object (either
passed as an argument or loaded from `),x1e=a("code"),kar=o("pretrained_model_name_or_path"),Sar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$1e=a("code"),Rar=o("pretrained_model_name_or_path"),Par=o(":"),Bar=l(),k1e=a("ul"),lF=a("li"),S1e=a("strong"),Nar=o("tapas"),Iar=o(" \u2014 "),ZQ=a("a"),qar=o("TapasForQuestionAnswering"),jar=o(" (TAPAS model)"),Dar=l(),iF=a("p"),Gar=o("The model is set in evaluation mode by default using "),R1e=a("code"),Oar=o("model.eval()"),Var=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P1e=a("code"),Xar=o("model.train()"),zar=l(),F(dF.$$.fragment),tXe=l(),bd=a("h2"),cF=a("a"),B1e=a("span"),F(C8.$$.fragment),Qar=l(),N1e=a("span"),War=o("AutoModelForImageClassification"),aXe=l(),Go=a("div"),F(w8.$$.fragment),Har=l(),vd=a("p"),Uar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eW=a("a"),Jar=o("from_pretrained()"),Yar=o(" class method or the "),oW=a("a"),Kar=o("from_config()"),Zar=o(` class
method.`),enr=l(),A8=a("p"),onr=o("This class cannot be instantiated directly using "),I1e=a("code"),rnr=o("__init__()"),tnr=o(" (throws an error)."),anr=l(),ut=a("div"),F(L8.$$.fragment),nnr=l(),q1e=a("p"),snr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),lnr=l(),Fd=a("p"),inr=o(`Note:
Loading a model from its configuration file does `),j1e=a("strong"),dnr=o("not"),cnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),fnr=o("from_pretrained()"),mnr=o(" to load the model weights."),gnr=l(),F(fF.$$.fragment),hnr=l(),lo=a("div"),F(y8.$$.fragment),pnr=l(),D1e=a("p"),_nr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),unr=l(),Qa=a("p"),bnr=o("The model class to instantiate is selected based on the "),G1e=a("code"),vnr=o("model_type"),Fnr=o(` property of the config object (either
passed as an argument or loaded from `),O1e=a("code"),Tnr=o("pretrained_model_name_or_path"),Mnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V1e=a("code"),Enr=o("pretrained_model_name_or_path"),Cnr=o(":"),wnr=l(),Fe=a("ul"),mF=a("li"),X1e=a("strong"),Anr=o("beit"),Lnr=o(" \u2014 "),tW=a("a"),ynr=o("BeitForImageClassification"),xnr=o(" (BEiT model)"),$nr=l(),gF=a("li"),z1e=a("strong"),knr=o("convnext"),Snr=o(" \u2014 "),aW=a("a"),Rnr=o("ConvNextForImageClassification"),Pnr=o(" (ConvNeXT model)"),Bnr=l(),hF=a("li"),Q1e=a("strong"),Nnr=o("cvt"),Inr=o(" \u2014 "),nW=a("a"),qnr=o("CvtForImageClassification"),jnr=o(" (CvT model)"),Dnr=l(),pF=a("li"),W1e=a("strong"),Gnr=o("data2vec-vision"),Onr=o(" \u2014 "),sW=a("a"),Vnr=o("Data2VecVisionForImageClassification"),Xnr=o(" (Data2VecVision model)"),znr=l(),Hs=a("li"),H1e=a("strong"),Qnr=o("deit"),Wnr=o(" \u2014 "),lW=a("a"),Hnr=o("DeiTForImageClassification"),Unr=o(" or "),iW=a("a"),Jnr=o("DeiTForImageClassificationWithTeacher"),Ynr=o(" (DeiT model)"),Knr=l(),_F=a("li"),U1e=a("strong"),Znr=o("imagegpt"),esr=o(" \u2014 "),dW=a("a"),osr=o("ImageGPTForImageClassification"),rsr=o(" (ImageGPT model)"),tsr=l(),Us=a("li"),J1e=a("strong"),asr=o("levit"),nsr=o(" \u2014 "),cW=a("a"),ssr=o("LevitForImageClassification"),lsr=o(" or "),fW=a("a"),isr=o("LevitForImageClassificationWithTeacher"),dsr=o(" (LeViT model)"),csr=l(),bt=a("li"),Y1e=a("strong"),fsr=o("perceiver"),msr=o(" \u2014 "),mW=a("a"),gsr=o("PerceiverForImageClassificationLearned"),hsr=o(" or "),gW=a("a"),psr=o("PerceiverForImageClassificationFourier"),_sr=o(" or "),hW=a("a"),usr=o("PerceiverForImageClassificationConvProcessing"),bsr=o(" (Perceiver model)"),vsr=l(),uF=a("li"),K1e=a("strong"),Fsr=o("poolformer"),Tsr=o(" \u2014 "),pW=a("a"),Msr=o("PoolFormerForImageClassification"),Esr=o(" (PoolFormer model)"),Csr=l(),bF=a("li"),Z1e=a("strong"),wsr=o("regnet"),Asr=o(" \u2014 "),_W=a("a"),Lsr=o("RegNetForImageClassification"),ysr=o(" (RegNet model)"),xsr=l(),vF=a("li"),e7e=a("strong"),$sr=o("resnet"),ksr=o(" \u2014 "),uW=a("a"),Ssr=o("ResNetForImageClassification"),Rsr=o(" (ResNet model)"),Psr=l(),FF=a("li"),o7e=a("strong"),Bsr=o("segformer"),Nsr=o(" \u2014 "),bW=a("a"),Isr=o("SegformerForImageClassification"),qsr=o(" (SegFormer model)"),jsr=l(),TF=a("li"),r7e=a("strong"),Dsr=o("swin"),Gsr=o(" \u2014 "),vW=a("a"),Osr=o("SwinForImageClassification"),Vsr=o(" (Swin Transformer model)"),Xsr=l(),MF=a("li"),t7e=a("strong"),zsr=o("van"),Qsr=o(" \u2014 "),FW=a("a"),Wsr=o("VanForImageClassification"),Hsr=o(" (VAN model)"),Usr=l(),EF=a("li"),a7e=a("strong"),Jsr=o("vit"),Ysr=o(" \u2014 "),TW=a("a"),Ksr=o("ViTForImageClassification"),Zsr=o(" (ViT model)"),elr=l(),CF=a("p"),olr=o("The model is set in evaluation mode by default using "),n7e=a("code"),rlr=o("model.eval()"),tlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s7e=a("code"),alr=o("model.train()"),nlr=l(),F(wF.$$.fragment),nXe=l(),Td=a("h2"),AF=a("a"),l7e=a("span"),F(x8.$$.fragment),slr=l(),i7e=a("span"),llr=o("AutoModelForVision2Seq"),sXe=l(),Oo=a("div"),F($8.$$.fragment),ilr=l(),Md=a("p"),dlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),MW=a("a"),clr=o("from_pretrained()"),flr=o(" class method or the "),EW=a("a"),mlr=o("from_config()"),glr=o(` class
method.`),hlr=l(),k8=a("p"),plr=o("This class cannot be instantiated directly using "),d7e=a("code"),_lr=o("__init__()"),ulr=o(" (throws an error)."),blr=l(),vt=a("div"),F(S8.$$.fragment),vlr=l(),c7e=a("p"),Flr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Tlr=l(),Ed=a("p"),Mlr=o(`Note:
Loading a model from its configuration file does `),f7e=a("strong"),Elr=o("not"),Clr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),wlr=o("from_pretrained()"),Alr=o(" to load the model weights."),Llr=l(),F(LF.$$.fragment),ylr=l(),io=a("div"),F(R8.$$.fragment),xlr=l(),m7e=a("p"),$lr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),klr=l(),Wa=a("p"),Slr=o("The model class to instantiate is selected based on the "),g7e=a("code"),Rlr=o("model_type"),Plr=o(` property of the config object (either
passed as an argument or loaded from `),h7e=a("code"),Blr=o("pretrained_model_name_or_path"),Nlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p7e=a("code"),Ilr=o("pretrained_model_name_or_path"),qlr=o(":"),jlr=l(),_7e=a("ul"),yF=a("li"),u7e=a("strong"),Dlr=o("vision-encoder-decoder"),Glr=o(" \u2014 "),wW=a("a"),Olr=o("VisionEncoderDecoderModel"),Vlr=o(" (Vision Encoder decoder model)"),Xlr=l(),xF=a("p"),zlr=o("The model is set in evaluation mode by default using "),b7e=a("code"),Qlr=o("model.eval()"),Wlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v7e=a("code"),Hlr=o("model.train()"),Ulr=l(),F($F.$$.fragment),lXe=l(),Cd=a("h2"),kF=a("a"),F7e=a("span"),F(P8.$$.fragment),Jlr=l(),T7e=a("span"),Ylr=o("AutoModelForVisualQuestionAnswering"),iXe=l(),Vo=a("div"),F(B8.$$.fragment),Klr=l(),wd=a("p"),Zlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),AW=a("a"),eir=o("from_pretrained()"),oir=o(" class method or the "),LW=a("a"),rir=o("from_config()"),tir=o(` class
method.`),air=l(),N8=a("p"),nir=o("This class cannot be instantiated directly using "),M7e=a("code"),sir=o("__init__()"),lir=o(" (throws an error)."),iir=l(),Ft=a("div"),F(I8.$$.fragment),dir=l(),E7e=a("p"),cir=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),fir=l(),Ad=a("p"),mir=o(`Note:
Loading a model from its configuration file does `),C7e=a("strong"),gir=o("not"),hir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yW=a("a"),pir=o("from_pretrained()"),_ir=o(" to load the model weights."),uir=l(),F(SF.$$.fragment),bir=l(),co=a("div"),F(q8.$$.fragment),vir=l(),w7e=a("p"),Fir=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Tir=l(),Ha=a("p"),Mir=o("The model class to instantiate is selected based on the "),A7e=a("code"),Eir=o("model_type"),Cir=o(` property of the config object (either
passed as an argument or loaded from `),L7e=a("code"),wir=o("pretrained_model_name_or_path"),Air=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y7e=a("code"),Lir=o("pretrained_model_name_or_path"),yir=o(":"),xir=l(),x7e=a("ul"),RF=a("li"),$7e=a("strong"),$ir=o("vilt"),kir=o(" \u2014 "),xW=a("a"),Sir=o("ViltForQuestionAnswering"),Rir=o(" (ViLT model)"),Pir=l(),PF=a("p"),Bir=o("The model is set in evaluation mode by default using "),k7e=a("code"),Nir=o("model.eval()"),Iir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S7e=a("code"),qir=o("model.train()"),jir=l(),F(BF.$$.fragment),dXe=l(),Ld=a("h2"),NF=a("a"),R7e=a("span"),F(j8.$$.fragment),Dir=l(),P7e=a("span"),Gir=o("AutoModelForAudioClassification"),cXe=l(),Xo=a("div"),F(D8.$$.fragment),Oir=l(),yd=a("p"),Vir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),$W=a("a"),Xir=o("from_pretrained()"),zir=o(" class method or the "),kW=a("a"),Qir=o("from_config()"),Wir=o(` class
method.`),Hir=l(),G8=a("p"),Uir=o("This class cannot be instantiated directly using "),B7e=a("code"),Jir=o("__init__()"),Yir=o(" (throws an error)."),Kir=l(),Tt=a("div"),F(O8.$$.fragment),Zir=l(),N7e=a("p"),edr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),odr=l(),xd=a("p"),rdr=o(`Note:
Loading a model from its configuration file does `),I7e=a("strong"),tdr=o("not"),adr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),ndr=o("from_pretrained()"),sdr=o(" to load the model weights."),ldr=l(),F(IF.$$.fragment),idr=l(),fo=a("div"),F(V8.$$.fragment),ddr=l(),q7e=a("p"),cdr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),fdr=l(),Ua=a("p"),mdr=o("The model class to instantiate is selected based on the "),j7e=a("code"),gdr=o("model_type"),hdr=o(` property of the config object (either
passed as an argument or loaded from `),D7e=a("code"),pdr=o("pretrained_model_name_or_path"),_dr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G7e=a("code"),udr=o("pretrained_model_name_or_path"),bdr=o(":"),vdr=l(),Pe=a("ul"),qF=a("li"),O7e=a("strong"),Fdr=o("data2vec-audio"),Tdr=o(" \u2014 "),RW=a("a"),Mdr=o("Data2VecAudioForSequenceClassification"),Edr=o(" (Data2VecAudio model)"),Cdr=l(),jF=a("li"),V7e=a("strong"),wdr=o("hubert"),Adr=o(" \u2014 "),PW=a("a"),Ldr=o("HubertForSequenceClassification"),ydr=o(" (Hubert model)"),xdr=l(),DF=a("li"),X7e=a("strong"),$dr=o("sew"),kdr=o(" \u2014 "),BW=a("a"),Sdr=o("SEWForSequenceClassification"),Rdr=o(" (SEW model)"),Pdr=l(),GF=a("li"),z7e=a("strong"),Bdr=o("sew-d"),Ndr=o(" \u2014 "),NW=a("a"),Idr=o("SEWDForSequenceClassification"),qdr=o(" (SEW-D model)"),jdr=l(),OF=a("li"),Q7e=a("strong"),Ddr=o("unispeech"),Gdr=o(" \u2014 "),IW=a("a"),Odr=o("UniSpeechForSequenceClassification"),Vdr=o(" (UniSpeech model)"),Xdr=l(),VF=a("li"),W7e=a("strong"),zdr=o("unispeech-sat"),Qdr=o(" \u2014 "),qW=a("a"),Wdr=o("UniSpeechSatForSequenceClassification"),Hdr=o(" (UniSpeechSat model)"),Udr=l(),XF=a("li"),H7e=a("strong"),Jdr=o("wav2vec2"),Ydr=o(" \u2014 "),jW=a("a"),Kdr=o("Wav2Vec2ForSequenceClassification"),Zdr=o(" (Wav2Vec2 model)"),ecr=l(),zF=a("li"),U7e=a("strong"),ocr=o("wav2vec2-conformer"),rcr=o(" \u2014 "),DW=a("a"),tcr=o("Wav2Vec2ConformerForSequenceClassification"),acr=o(" (Wav2Vec2-Conformer model)"),ncr=l(),QF=a("li"),J7e=a("strong"),scr=o("wavlm"),lcr=o(" \u2014 "),GW=a("a"),icr=o("WavLMForSequenceClassification"),dcr=o(" (WavLM model)"),ccr=l(),WF=a("p"),fcr=o("The model is set in evaluation mode by default using "),Y7e=a("code"),mcr=o("model.eval()"),gcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K7e=a("code"),hcr=o("model.train()"),pcr=l(),F(HF.$$.fragment),fXe=l(),$d=a("h2"),UF=a("a"),Z7e=a("span"),F(X8.$$.fragment),_cr=l(),e4e=a("span"),ucr=o("AutoModelForAudioFrameClassification"),mXe=l(),zo=a("div"),F(z8.$$.fragment),bcr=l(),kd=a("p"),vcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),OW=a("a"),Fcr=o("from_pretrained()"),Tcr=o(" class method or the "),VW=a("a"),Mcr=o("from_config()"),Ecr=o(` class
method.`),Ccr=l(),Q8=a("p"),wcr=o("This class cannot be instantiated directly using "),o4e=a("code"),Acr=o("__init__()"),Lcr=o(" (throws an error)."),ycr=l(),Mt=a("div"),F(W8.$$.fragment),xcr=l(),r4e=a("p"),$cr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),kcr=l(),Sd=a("p"),Scr=o(`Note:
Loading a model from its configuration file does `),t4e=a("strong"),Rcr=o("not"),Pcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XW=a("a"),Bcr=o("from_pretrained()"),Ncr=o(" to load the model weights."),Icr=l(),F(JF.$$.fragment),qcr=l(),mo=a("div"),F(H8.$$.fragment),jcr=l(),a4e=a("p"),Dcr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Gcr=l(),Ja=a("p"),Ocr=o("The model class to instantiate is selected based on the "),n4e=a("code"),Vcr=o("model_type"),Xcr=o(` property of the config object (either
passed as an argument or loaded from `),s4e=a("code"),zcr=o("pretrained_model_name_or_path"),Qcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l4e=a("code"),Wcr=o("pretrained_model_name_or_path"),Hcr=o(":"),Ucr=l(),ot=a("ul"),YF=a("li"),i4e=a("strong"),Jcr=o("data2vec-audio"),Ycr=o(" \u2014 "),zW=a("a"),Kcr=o("Data2VecAudioForAudioFrameClassification"),Zcr=o(" (Data2VecAudio model)"),efr=l(),KF=a("li"),d4e=a("strong"),ofr=o("unispeech-sat"),rfr=o(" \u2014 "),QW=a("a"),tfr=o("UniSpeechSatForAudioFrameClassification"),afr=o(" (UniSpeechSat model)"),nfr=l(),ZF=a("li"),c4e=a("strong"),sfr=o("wav2vec2"),lfr=o(" \u2014 "),WW=a("a"),ifr=o("Wav2Vec2ForAudioFrameClassification"),dfr=o(" (Wav2Vec2 model)"),cfr=l(),eT=a("li"),f4e=a("strong"),ffr=o("wav2vec2-conformer"),mfr=o(" \u2014 "),HW=a("a"),gfr=o("Wav2Vec2ConformerForAudioFrameClassification"),hfr=o(" (Wav2Vec2-Conformer model)"),pfr=l(),oT=a("li"),m4e=a("strong"),_fr=o("wavlm"),ufr=o(" \u2014 "),UW=a("a"),bfr=o("WavLMForAudioFrameClassification"),vfr=o(" (WavLM model)"),Ffr=l(),rT=a("p"),Tfr=o("The model is set in evaluation mode by default using "),g4e=a("code"),Mfr=o("model.eval()"),Efr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h4e=a("code"),Cfr=o("model.train()"),wfr=l(),F(tT.$$.fragment),gXe=l(),Rd=a("h2"),aT=a("a"),p4e=a("span"),F(U8.$$.fragment),Afr=l(),_4e=a("span"),Lfr=o("AutoModelForCTC"),hXe=l(),Qo=a("div"),F(J8.$$.fragment),yfr=l(),Pd=a("p"),xfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),JW=a("a"),$fr=o("from_pretrained()"),kfr=o(" class method or the "),YW=a("a"),Sfr=o("from_config()"),Rfr=o(` class
method.`),Pfr=l(),Y8=a("p"),Bfr=o("This class cannot be instantiated directly using "),u4e=a("code"),Nfr=o("__init__()"),Ifr=o(" (throws an error)."),qfr=l(),Et=a("div"),F(K8.$$.fragment),jfr=l(),b4e=a("p"),Dfr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Gfr=l(),Bd=a("p"),Ofr=o(`Note:
Loading a model from its configuration file does `),v4e=a("strong"),Vfr=o("not"),Xfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KW=a("a"),zfr=o("from_pretrained()"),Qfr=o(" to load the model weights."),Wfr=l(),F(nT.$$.fragment),Hfr=l(),go=a("div"),F(Z8.$$.fragment),Ufr=l(),F4e=a("p"),Jfr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Yfr=l(),Ya=a("p"),Kfr=o("The model class to instantiate is selected based on the "),T4e=a("code"),Zfr=o("model_type"),emr=o(` property of the config object (either
passed as an argument or loaded from `),M4e=a("code"),omr=o("pretrained_model_name_or_path"),rmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E4e=a("code"),tmr=o("pretrained_model_name_or_path"),amr=o(":"),nmr=l(),Le=a("ul"),sT=a("li"),C4e=a("strong"),smr=o("data2vec-audio"),lmr=o(" \u2014 "),ZW=a("a"),imr=o("Data2VecAudioForCTC"),dmr=o(" (Data2VecAudio model)"),cmr=l(),lT=a("li"),w4e=a("strong"),fmr=o("hubert"),mmr=o(" \u2014 "),eH=a("a"),gmr=o("HubertForCTC"),hmr=o(" (Hubert model)"),pmr=l(),iT=a("li"),A4e=a("strong"),_mr=o("mctct"),umr=o(" \u2014 "),oH=a("a"),bmr=o("MCTCTForCTC"),vmr=o(" (M-CTC-T model)"),Fmr=l(),dT=a("li"),L4e=a("strong"),Tmr=o("sew"),Mmr=o(" \u2014 "),rH=a("a"),Emr=o("SEWForCTC"),Cmr=o(" (SEW model)"),wmr=l(),cT=a("li"),y4e=a("strong"),Amr=o("sew-d"),Lmr=o(" \u2014 "),tH=a("a"),ymr=o("SEWDForCTC"),xmr=o(" (SEW-D model)"),$mr=l(),fT=a("li"),x4e=a("strong"),kmr=o("unispeech"),Smr=o(" \u2014 "),aH=a("a"),Rmr=o("UniSpeechForCTC"),Pmr=o(" (UniSpeech model)"),Bmr=l(),mT=a("li"),$4e=a("strong"),Nmr=o("unispeech-sat"),Imr=o(" \u2014 "),nH=a("a"),qmr=o("UniSpeechSatForCTC"),jmr=o(" (UniSpeechSat model)"),Dmr=l(),gT=a("li"),k4e=a("strong"),Gmr=o("wav2vec2"),Omr=o(" \u2014 "),sH=a("a"),Vmr=o("Wav2Vec2ForCTC"),Xmr=o(" (Wav2Vec2 model)"),zmr=l(),hT=a("li"),S4e=a("strong"),Qmr=o("wav2vec2-conformer"),Wmr=o(" \u2014 "),lH=a("a"),Hmr=o("Wav2Vec2ConformerForCTC"),Umr=o(" (Wav2Vec2-Conformer model)"),Jmr=l(),pT=a("li"),R4e=a("strong"),Ymr=o("wavlm"),Kmr=o(" \u2014 "),iH=a("a"),Zmr=o("WavLMForCTC"),egr=o(" (WavLM model)"),ogr=l(),_T=a("p"),rgr=o("The model is set in evaluation mode by default using "),P4e=a("code"),tgr=o("model.eval()"),agr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B4e=a("code"),ngr=o("model.train()"),sgr=l(),F(uT.$$.fragment),pXe=l(),Nd=a("h2"),bT=a("a"),N4e=a("span"),F(e9.$$.fragment),lgr=l(),I4e=a("span"),igr=o("AutoModelForSpeechSeq2Seq"),_Xe=l(),Wo=a("div"),F(o9.$$.fragment),dgr=l(),Id=a("p"),cgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),dH=a("a"),fgr=o("from_pretrained()"),mgr=o(" class method or the "),cH=a("a"),ggr=o("from_config()"),hgr=o(` class
method.`),pgr=l(),r9=a("p"),_gr=o("This class cannot be instantiated directly using "),q4e=a("code"),ugr=o("__init__()"),bgr=o(" (throws an error)."),vgr=l(),Ct=a("div"),F(t9.$$.fragment),Fgr=l(),j4e=a("p"),Tgr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Mgr=l(),qd=a("p"),Egr=o(`Note:
Loading a model from its configuration file does `),D4e=a("strong"),Cgr=o("not"),wgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fH=a("a"),Agr=o("from_pretrained()"),Lgr=o(" to load the model weights."),ygr=l(),F(vT.$$.fragment),xgr=l(),ho=a("div"),F(a9.$$.fragment),$gr=l(),G4e=a("p"),kgr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Sgr=l(),Ka=a("p"),Rgr=o("The model class to instantiate is selected based on the "),O4e=a("code"),Pgr=o("model_type"),Bgr=o(` property of the config object (either
passed as an argument or loaded from `),V4e=a("code"),Ngr=o("pretrained_model_name_or_path"),Igr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X4e=a("code"),qgr=o("pretrained_model_name_or_path"),jgr=o(":"),Dgr=l(),n9=a("ul"),FT=a("li"),z4e=a("strong"),Ggr=o("speech-encoder-decoder"),Ogr=o(" \u2014 "),mH=a("a"),Vgr=o("SpeechEncoderDecoderModel"),Xgr=o(" (Speech Encoder decoder model)"),zgr=l(),TT=a("li"),Q4e=a("strong"),Qgr=o("speech_to_text"),Wgr=o(" \u2014 "),gH=a("a"),Hgr=o("Speech2TextForConditionalGeneration"),Ugr=o(" (Speech2Text model)"),Jgr=l(),MT=a("p"),Ygr=o("The model is set in evaluation mode by default using "),W4e=a("code"),Kgr=o("model.eval()"),Zgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H4e=a("code"),ehr=o("model.train()"),ohr=l(),F(ET.$$.fragment),uXe=l(),jd=a("h2"),CT=a("a"),U4e=a("span"),F(s9.$$.fragment),rhr=l(),J4e=a("span"),thr=o("AutoModelForAudioXVector"),bXe=l(),Ho=a("div"),F(l9.$$.fragment),ahr=l(),Dd=a("p"),nhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),hH=a("a"),shr=o("from_pretrained()"),lhr=o(" class method or the "),pH=a("a"),ihr=o("from_config()"),dhr=o(` class
method.`),chr=l(),i9=a("p"),fhr=o("This class cannot be instantiated directly using "),Y4e=a("code"),mhr=o("__init__()"),ghr=o(" (throws an error)."),hhr=l(),wt=a("div"),F(d9.$$.fragment),phr=l(),K4e=a("p"),_hr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),uhr=l(),Gd=a("p"),bhr=o(`Note:
Loading a model from its configuration file does `),Z4e=a("strong"),vhr=o("not"),Fhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_H=a("a"),Thr=o("from_pretrained()"),Mhr=o(" to load the model weights."),Ehr=l(),F(wT.$$.fragment),Chr=l(),po=a("div"),F(c9.$$.fragment),whr=l(),ebe=a("p"),Ahr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Lhr=l(),Za=a("p"),yhr=o("The model class to instantiate is selected based on the "),obe=a("code"),xhr=o("model_type"),$hr=o(` property of the config object (either
passed as an argument or loaded from `),rbe=a("code"),khr=o("pretrained_model_name_or_path"),Shr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tbe=a("code"),Rhr=o("pretrained_model_name_or_path"),Phr=o(":"),Bhr=l(),rt=a("ul"),AT=a("li"),abe=a("strong"),Nhr=o("data2vec-audio"),Ihr=o(" \u2014 "),uH=a("a"),qhr=o("Data2VecAudioForXVector"),jhr=o(" (Data2VecAudio model)"),Dhr=l(),LT=a("li"),nbe=a("strong"),Ghr=o("unispeech-sat"),Ohr=o(" \u2014 "),bH=a("a"),Vhr=o("UniSpeechSatForXVector"),Xhr=o(" (UniSpeechSat model)"),zhr=l(),yT=a("li"),sbe=a("strong"),Qhr=o("wav2vec2"),Whr=o(" \u2014 "),vH=a("a"),Hhr=o("Wav2Vec2ForXVector"),Uhr=o(" (Wav2Vec2 model)"),Jhr=l(),xT=a("li"),lbe=a("strong"),Yhr=o("wav2vec2-conformer"),Khr=o(" \u2014 "),FH=a("a"),Zhr=o("Wav2Vec2ConformerForXVector"),epr=o(" (Wav2Vec2-Conformer model)"),opr=l(),$T=a("li"),ibe=a("strong"),rpr=o("wavlm"),tpr=o(" \u2014 "),TH=a("a"),apr=o("WavLMForXVector"),npr=o(" (WavLM model)"),spr=l(),kT=a("p"),lpr=o("The model is set in evaluation mode by default using "),dbe=a("code"),ipr=o("model.eval()"),dpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cbe=a("code"),cpr=o("model.train()"),fpr=l(),F(ST.$$.fragment),vXe=l(),Od=a("h2"),RT=a("a"),fbe=a("span"),F(f9.$$.fragment),mpr=l(),mbe=a("span"),gpr=o("AutoModelForMaskedImageModeling"),FXe=l(),Uo=a("div"),F(m9.$$.fragment),hpr=l(),Vd=a("p"),ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),MH=a("a"),_pr=o("from_pretrained()"),upr=o(" class method or the "),EH=a("a"),bpr=o("from_config()"),vpr=o(` class
method.`),Fpr=l(),g9=a("p"),Tpr=o("This class cannot be instantiated directly using "),gbe=a("code"),Mpr=o("__init__()"),Epr=o(" (throws an error)."),Cpr=l(),At=a("div"),F(h9.$$.fragment),wpr=l(),hbe=a("p"),Apr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Lpr=l(),Xd=a("p"),ypr=o(`Note:
Loading a model from its configuration file does `),pbe=a("strong"),xpr=o("not"),$pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CH=a("a"),kpr=o("from_pretrained()"),Spr=o(" to load the model weights."),Rpr=l(),F(PT.$$.fragment),Ppr=l(),_o=a("div"),F(p9.$$.fragment),Bpr=l(),_be=a("p"),Npr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Ipr=l(),en=a("p"),qpr=o("The model class to instantiate is selected based on the "),ube=a("code"),jpr=o("model_type"),Dpr=o(` property of the config object (either
passed as an argument or loaded from `),bbe=a("code"),Gpr=o("pretrained_model_name_or_path"),Opr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vbe=a("code"),Vpr=o("pretrained_model_name_or_path"),Xpr=o(":"),zpr=l(),zd=a("ul"),BT=a("li"),Fbe=a("strong"),Qpr=o("deit"),Wpr=o(" \u2014 "),wH=a("a"),Hpr=o("DeiTForMaskedImageModeling"),Upr=o(" (DeiT model)"),Jpr=l(),NT=a("li"),Tbe=a("strong"),Ypr=o("swin"),Kpr=o(" \u2014 "),AH=a("a"),Zpr=o("SwinForMaskedImageModeling"),e_r=o(" (Swin Transformer model)"),o_r=l(),IT=a("li"),Mbe=a("strong"),r_r=o("vit"),t_r=o(" \u2014 "),LH=a("a"),a_r=o("ViTForMaskedImageModeling"),n_r=o(" (ViT model)"),s_r=l(),qT=a("p"),l_r=o("The model is set in evaluation mode by default using "),Ebe=a("code"),i_r=o("model.eval()"),d_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cbe=a("code"),c_r=o("model.train()"),f_r=l(),F(jT.$$.fragment),TXe=l(),Qd=a("h2"),DT=a("a"),wbe=a("span"),F(_9.$$.fragment),m_r=l(),Abe=a("span"),g_r=o("AutoModelForObjectDetection"),MXe=l(),Jo=a("div"),F(u9.$$.fragment),h_r=l(),Wd=a("p"),p_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),yH=a("a"),__r=o("from_pretrained()"),u_r=o(" class method or the "),xH=a("a"),b_r=o("from_config()"),v_r=o(` class
method.`),F_r=l(),b9=a("p"),T_r=o("This class cannot be instantiated directly using "),Lbe=a("code"),M_r=o("__init__()"),E_r=o(" (throws an error)."),C_r=l(),Lt=a("div"),F(v9.$$.fragment),w_r=l(),ybe=a("p"),A_r=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),L_r=l(),Hd=a("p"),y_r=o(`Note:
Loading a model from its configuration file does `),xbe=a("strong"),x_r=o("not"),$_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=a("a"),k_r=o("from_pretrained()"),S_r=o(" to load the model weights."),R_r=l(),F(GT.$$.fragment),P_r=l(),uo=a("div"),F(F9.$$.fragment),B_r=l(),$be=a("p"),N_r=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),I_r=l(),on=a("p"),q_r=o("The model class to instantiate is selected based on the "),kbe=a("code"),j_r=o("model_type"),D_r=o(` property of the config object (either
passed as an argument or loaded from `),Sbe=a("code"),G_r=o("pretrained_model_name_or_path"),O_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rbe=a("code"),V_r=o("pretrained_model_name_or_path"),X_r=o(":"),z_r=l(),T9=a("ul"),OT=a("li"),Pbe=a("strong"),Q_r=o("detr"),W_r=o(" \u2014 "),kH=a("a"),H_r=o("DetrForObjectDetection"),U_r=o(" (DETR model)"),J_r=l(),VT=a("li"),Bbe=a("strong"),Y_r=o("yolos"),K_r=o(" \u2014 "),SH=a("a"),Z_r=o("YolosForObjectDetection"),eur=o(" (YOLOS model)"),our=l(),XT=a("p"),rur=o("The model is set in evaluation mode by default using "),Nbe=a("code"),tur=o("model.eval()"),aur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=a("code"),nur=o("model.train()"),sur=l(),F(zT.$$.fragment),EXe=l(),Ud=a("h2"),QT=a("a"),qbe=a("span"),F(M9.$$.fragment),lur=l(),jbe=a("span"),iur=o("AutoModelForImageSegmentation"),CXe=l(),Yo=a("div"),F(E9.$$.fragment),dur=l(),Jd=a("p"),cur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),RH=a("a"),fur=o("from_pretrained()"),mur=o(" class method or the "),PH=a("a"),gur=o("from_config()"),hur=o(` class
method.`),pur=l(),C9=a("p"),_ur=o("This class cannot be instantiated directly using "),Dbe=a("code"),uur=o("__init__()"),bur=o(" (throws an error)."),vur=l(),yt=a("div"),F(w9.$$.fragment),Fur=l(),Gbe=a("p"),Tur=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Mur=l(),Yd=a("p"),Eur=o(`Note:
Loading a model from its configuration file does `),Obe=a("strong"),Cur=o("not"),wur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BH=a("a"),Aur=o("from_pretrained()"),Lur=o(" to load the model weights."),yur=l(),F(WT.$$.fragment),xur=l(),bo=a("div"),F(A9.$$.fragment),$ur=l(),Vbe=a("p"),kur=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Sur=l(),rn=a("p"),Rur=o("The model class to instantiate is selected based on the "),Xbe=a("code"),Pur=o("model_type"),Bur=o(` property of the config object (either
passed as an argument or loaded from `),zbe=a("code"),Nur=o("pretrained_model_name_or_path"),Iur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qbe=a("code"),qur=o("pretrained_model_name_or_path"),jur=o(":"),Dur=l(),Wbe=a("ul"),HT=a("li"),Hbe=a("strong"),Gur=o("detr"),Our=o(" \u2014 "),NH=a("a"),Vur=o("DetrForSegmentation"),Xur=o(" (DETR model)"),zur=l(),UT=a("p"),Qur=o("The model is set in evaluation mode by default using "),Ube=a("code"),Wur=o("model.eval()"),Hur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=a("code"),Uur=o("model.train()"),Jur=l(),F(JT.$$.fragment),wXe=l(),Kd=a("h2"),YT=a("a"),Ybe=a("span"),F(L9.$$.fragment),Yur=l(),Kbe=a("span"),Kur=o("AutoModelForSemanticSegmentation"),AXe=l(),Ko=a("div"),F(y9.$$.fragment),Zur=l(),Zd=a("p"),e2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),IH=a("a"),o2r=o("from_pretrained()"),r2r=o(" class method or the "),qH=a("a"),t2r=o("from_config()"),a2r=o(` class
method.`),n2r=l(),x9=a("p"),s2r=o("This class cannot be instantiated directly using "),Zbe=a("code"),l2r=o("__init__()"),i2r=o(" (throws an error)."),d2r=l(),xt=a("div"),F($9.$$.fragment),c2r=l(),eve=a("p"),f2r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),m2r=l(),ec=a("p"),g2r=o(`Note:
Loading a model from its configuration file does `),ove=a("strong"),h2r=o("not"),p2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=a("a"),_2r=o("from_pretrained()"),u2r=o(" to load the model weights."),b2r=l(),F(KT.$$.fragment),v2r=l(),vo=a("div"),F(k9.$$.fragment),F2r=l(),rve=a("p"),T2r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),M2r=l(),tn=a("p"),E2r=o("The model class to instantiate is selected based on the "),tve=a("code"),C2r=o("model_type"),w2r=o(` property of the config object (either
passed as an argument or loaded from `),ave=a("code"),A2r=o("pretrained_model_name_or_path"),L2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=a("code"),y2r=o("pretrained_model_name_or_path"),x2r=o(":"),$2r=l(),an=a("ul"),ZT=a("li"),sve=a("strong"),k2r=o("beit"),S2r=o(" \u2014 "),DH=a("a"),R2r=o("BeitForSemanticSegmentation"),P2r=o(" (BEiT model)"),B2r=l(),eM=a("li"),lve=a("strong"),N2r=o("data2vec-vision"),I2r=o(" \u2014 "),GH=a("a"),q2r=o("Data2VecVisionForSemanticSegmentation"),j2r=o(" (Data2VecVision model)"),D2r=l(),oM=a("li"),ive=a("strong"),G2r=o("dpt"),O2r=o(" \u2014 "),OH=a("a"),V2r=o("DPTForSemanticSegmentation"),X2r=o(" (DPT model)"),z2r=l(),rM=a("li"),dve=a("strong"),Q2r=o("segformer"),W2r=o(" \u2014 "),VH=a("a"),H2r=o("SegformerForSemanticSegmentation"),U2r=o(" (SegFormer model)"),J2r=l(),tM=a("p"),Y2r=o("The model is set in evaluation mode by default using "),cve=a("code"),K2r=o("model.eval()"),Z2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fve=a("code"),e1r=o("model.train()"),o1r=l(),F(aM.$$.fragment),LXe=l(),oc=a("h2"),nM=a("a"),mve=a("span"),F(S9.$$.fragment),r1r=l(),gve=a("span"),t1r=o("AutoModelForInstanceSegmentation"),yXe=l(),Zo=a("div"),F(R9.$$.fragment),a1r=l(),rc=a("p"),n1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),XH=a("a"),s1r=o("from_pretrained()"),l1r=o(" class method or the "),zH=a("a"),i1r=o("from_config()"),d1r=o(` class
method.`),c1r=l(),P9=a("p"),f1r=o("This class cannot be instantiated directly using "),hve=a("code"),m1r=o("__init__()"),g1r=o(" (throws an error)."),h1r=l(),$t=a("div"),F(B9.$$.fragment),p1r=l(),pve=a("p"),_1r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),u1r=l(),tc=a("p"),b1r=o(`Note:
Loading a model from its configuration file does `),_ve=a("strong"),v1r=o("not"),F1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QH=a("a"),T1r=o("from_pretrained()"),M1r=o(" to load the model weights."),E1r=l(),F(sM.$$.fragment),C1r=l(),Fo=a("div"),F(N9.$$.fragment),w1r=l(),uve=a("p"),A1r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),L1r=l(),nn=a("p"),y1r=o("The model class to instantiate is selected based on the "),bve=a("code"),x1r=o("model_type"),$1r=o(` property of the config object (either
passed as an argument or loaded from `),vve=a("code"),k1r=o("pretrained_model_name_or_path"),S1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fve=a("code"),R1r=o("pretrained_model_name_or_path"),P1r=o(":"),B1r=l(),Tve=a("ul"),lM=a("li"),Mve=a("strong"),N1r=o("maskformer"),I1r=o(" \u2014 "),WH=a("a"),q1r=o("MaskFormerForInstanceSegmentation"),j1r=o(" (MaskFormer model)"),D1r=l(),iM=a("p"),G1r=o("The model is set in evaluation mode by default using "),Eve=a("code"),O1r=o("model.eval()"),V1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cve=a("code"),X1r=o("model.train()"),z1r=l(),F(dM.$$.fragment),xXe=l(),ac=a("h2"),cM=a("a"),wve=a("span"),F(I9.$$.fragment),Q1r=l(),Ave=a("span"),W1r=o("TFAutoModel"),$Xe=l(),er=a("div"),F(q9.$$.fragment),H1r=l(),nc=a("p"),U1r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),HH=a("a"),J1r=o("from_pretrained()"),Y1r=o(" class method or the "),UH=a("a"),K1r=o("from_config()"),Z1r=o(` class
method.`),e7r=l(),j9=a("p"),o7r=o("This class cannot be instantiated directly using "),Lve=a("code"),r7r=o("__init__()"),t7r=o(" (throws an error)."),a7r=l(),kt=a("div"),F(D9.$$.fragment),n7r=l(),yve=a("p"),s7r=o("Instantiates one of the base model classes of the library from a configuration."),l7r=l(),sc=a("p"),i7r=o(`Note:
Loading a model from its configuration file does `),xve=a("strong"),d7r=o("not"),c7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JH=a("a"),f7r=o("from_pretrained()"),m7r=o(" to load the model weights."),g7r=l(),F(fM.$$.fragment),h7r=l(),xr=a("div"),F(G9.$$.fragment),p7r=l(),$ve=a("p"),_7r=o("Instantiate one of the base model classes of the library from a pretrained model."),u7r=l(),sn=a("p"),b7r=o("The model class to instantiate is selected based on the "),kve=a("code"),v7r=o("model_type"),F7r=o(` property of the config object (either
passed as an argument or loaded from `),Sve=a("code"),T7r=o("pretrained_model_name_or_path"),M7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rve=a("code"),E7r=o("pretrained_model_name_or_path"),C7r=o(":"),w7r=l(),q=a("ul"),mM=a("li"),Pve=a("strong"),A7r=o("albert"),L7r=o(" \u2014 "),YH=a("a"),y7r=o("TFAlbertModel"),x7r=o(" (ALBERT model)"),$7r=l(),gM=a("li"),Bve=a("strong"),k7r=o("bart"),S7r=o(" \u2014 "),KH=a("a"),R7r=o("TFBartModel"),P7r=o(" (BART model)"),B7r=l(),hM=a("li"),Nve=a("strong"),N7r=o("bert"),I7r=o(" \u2014 "),ZH=a("a"),q7r=o("TFBertModel"),j7r=o(" (BERT model)"),D7r=l(),pM=a("li"),Ive=a("strong"),G7r=o("blenderbot"),O7r=o(" \u2014 "),eU=a("a"),V7r=o("TFBlenderbotModel"),X7r=o(" (Blenderbot model)"),z7r=l(),_M=a("li"),qve=a("strong"),Q7r=o("blenderbot-small"),W7r=o(" \u2014 "),oU=a("a"),H7r=o("TFBlenderbotSmallModel"),U7r=o(" (BlenderbotSmall model)"),J7r=l(),uM=a("li"),jve=a("strong"),Y7r=o("camembert"),K7r=o(" \u2014 "),rU=a("a"),Z7r=o("TFCamembertModel"),e4r=o(" (CamemBERT model)"),o4r=l(),bM=a("li"),Dve=a("strong"),r4r=o("clip"),t4r=o(" \u2014 "),tU=a("a"),a4r=o("TFCLIPModel"),n4r=o(" (CLIP model)"),s4r=l(),vM=a("li"),Gve=a("strong"),l4r=o("convbert"),i4r=o(" \u2014 "),aU=a("a"),d4r=o("TFConvBertModel"),c4r=o(" (ConvBERT model)"),f4r=l(),FM=a("li"),Ove=a("strong"),m4r=o("convnext"),g4r=o(" \u2014 "),nU=a("a"),h4r=o("TFConvNextModel"),p4r=o(" (ConvNeXT model)"),_4r=l(),TM=a("li"),Vve=a("strong"),u4r=o("ctrl"),b4r=o(" \u2014 "),sU=a("a"),v4r=o("TFCTRLModel"),F4r=o(" (CTRL model)"),T4r=l(),MM=a("li"),Xve=a("strong"),M4r=o("data2vec-vision"),E4r=o(" \u2014 "),lU=a("a"),C4r=o("TFData2VecVisionModel"),w4r=o(" (Data2VecVision model)"),A4r=l(),EM=a("li"),zve=a("strong"),L4r=o("deberta"),y4r=o(" \u2014 "),iU=a("a"),x4r=o("TFDebertaModel"),$4r=o(" (DeBERTa model)"),k4r=l(),CM=a("li"),Qve=a("strong"),S4r=o("deberta-v2"),R4r=o(" \u2014 "),dU=a("a"),P4r=o("TFDebertaV2Model"),B4r=o(" (DeBERTa-v2 model)"),N4r=l(),wM=a("li"),Wve=a("strong"),I4r=o("distilbert"),q4r=o(" \u2014 "),cU=a("a"),j4r=o("TFDistilBertModel"),D4r=o(" (DistilBERT model)"),G4r=l(),AM=a("li"),Hve=a("strong"),O4r=o("dpr"),V4r=o(" \u2014 "),fU=a("a"),X4r=o("TFDPRQuestionEncoder"),z4r=o(" (DPR model)"),Q4r=l(),LM=a("li"),Uve=a("strong"),W4r=o("electra"),H4r=o(" \u2014 "),mU=a("a"),U4r=o("TFElectraModel"),J4r=o(" (ELECTRA model)"),Y4r=l(),yM=a("li"),Jve=a("strong"),K4r=o("flaubert"),Z4r=o(" \u2014 "),gU=a("a"),ebr=o("TFFlaubertModel"),obr=o(" (FlauBERT model)"),rbr=l(),Js=a("li"),Yve=a("strong"),tbr=o("funnel"),abr=o(" \u2014 "),hU=a("a"),nbr=o("TFFunnelModel"),sbr=o(" or "),pU=a("a"),lbr=o("TFFunnelBaseModel"),ibr=o(" (Funnel Transformer model)"),dbr=l(),xM=a("li"),Kve=a("strong"),cbr=o("gpt2"),fbr=o(" \u2014 "),_U=a("a"),mbr=o("TFGPT2Model"),gbr=o(" (OpenAI GPT-2 model)"),hbr=l(),$M=a("li"),Zve=a("strong"),pbr=o("gptj"),_br=o(" \u2014 "),uU=a("a"),ubr=o("TFGPTJModel"),bbr=o(" (GPT-J model)"),vbr=l(),kM=a("li"),eFe=a("strong"),Fbr=o("hubert"),Tbr=o(" \u2014 "),bU=a("a"),Mbr=o("TFHubertModel"),Ebr=o(" (Hubert model)"),Cbr=l(),SM=a("li"),oFe=a("strong"),wbr=o("layoutlm"),Abr=o(" \u2014 "),vU=a("a"),Lbr=o("TFLayoutLMModel"),ybr=o(" (LayoutLM model)"),xbr=l(),RM=a("li"),rFe=a("strong"),$br=o("led"),kbr=o(" \u2014 "),FU=a("a"),Sbr=o("TFLEDModel"),Rbr=o(" (LED model)"),Pbr=l(),PM=a("li"),tFe=a("strong"),Bbr=o("longformer"),Nbr=o(" \u2014 "),TU=a("a"),Ibr=o("TFLongformerModel"),qbr=o(" (Longformer model)"),jbr=l(),BM=a("li"),aFe=a("strong"),Dbr=o("lxmert"),Gbr=o(" \u2014 "),MU=a("a"),Obr=o("TFLxmertModel"),Vbr=o(" (LXMERT model)"),Xbr=l(),NM=a("li"),nFe=a("strong"),zbr=o("marian"),Qbr=o(" \u2014 "),EU=a("a"),Wbr=o("TFMarianModel"),Hbr=o(" (Marian model)"),Ubr=l(),IM=a("li"),sFe=a("strong"),Jbr=o("mbart"),Ybr=o(" \u2014 "),CU=a("a"),Kbr=o("TFMBartModel"),Zbr=o(" (mBART model)"),evr=l(),qM=a("li"),lFe=a("strong"),ovr=o("mobilebert"),rvr=o(" \u2014 "),wU=a("a"),tvr=o("TFMobileBertModel"),avr=o(" (MobileBERT model)"),nvr=l(),jM=a("li"),iFe=a("strong"),svr=o("mpnet"),lvr=o(" \u2014 "),AU=a("a"),ivr=o("TFMPNetModel"),dvr=o(" (MPNet model)"),cvr=l(),DM=a("li"),dFe=a("strong"),fvr=o("mt5"),mvr=o(" \u2014 "),LU=a("a"),gvr=o("TFMT5Model"),hvr=o(" (MT5 model)"),pvr=l(),GM=a("li"),cFe=a("strong"),_vr=o("openai-gpt"),uvr=o(" \u2014 "),yU=a("a"),bvr=o("TFOpenAIGPTModel"),vvr=o(" (OpenAI GPT model)"),Fvr=l(),OM=a("li"),fFe=a("strong"),Tvr=o("opt"),Mvr=o(" \u2014 "),xU=a("a"),Evr=o("TFOPTModel"),Cvr=o(" (OPT model)"),wvr=l(),VM=a("li"),mFe=a("strong"),Avr=o("pegasus"),Lvr=o(" \u2014 "),$U=a("a"),yvr=o("TFPegasusModel"),xvr=o(" (Pegasus model)"),$vr=l(),XM=a("li"),gFe=a("strong"),kvr=o("regnet"),Svr=o(" \u2014 "),kU=a("a"),Rvr=o("TFRegNetModel"),Pvr=o(" (RegNet model)"),Bvr=l(),zM=a("li"),hFe=a("strong"),Nvr=o("rembert"),Ivr=o(" \u2014 "),SU=a("a"),qvr=o("TFRemBertModel"),jvr=o(" (RemBERT model)"),Dvr=l(),QM=a("li"),pFe=a("strong"),Gvr=o("resnet"),Ovr=o(" \u2014 "),RU=a("a"),Vvr=o("TFResNetModel"),Xvr=o(" (ResNet model)"),zvr=l(),WM=a("li"),_Fe=a("strong"),Qvr=o("roberta"),Wvr=o(" \u2014 "),PU=a("a"),Hvr=o("TFRobertaModel"),Uvr=o(" (RoBERTa model)"),Jvr=l(),HM=a("li"),uFe=a("strong"),Yvr=o("roformer"),Kvr=o(" \u2014 "),BU=a("a"),Zvr=o("TFRoFormerModel"),eFr=o(" (RoFormer model)"),oFr=l(),UM=a("li"),bFe=a("strong"),rFr=o("speech_to_text"),tFr=o(" \u2014 "),NU=a("a"),aFr=o("TFSpeech2TextModel"),nFr=o(" (Speech2Text model)"),sFr=l(),JM=a("li"),vFe=a("strong"),lFr=o("swin"),iFr=o(" \u2014 "),IU=a("a"),dFr=o("TFSwinModel"),cFr=o(" (Swin Transformer model)"),fFr=l(),YM=a("li"),FFe=a("strong"),mFr=o("t5"),gFr=o(" \u2014 "),qU=a("a"),hFr=o("TFT5Model"),pFr=o(" (T5 model)"),_Fr=l(),KM=a("li"),TFe=a("strong"),uFr=o("tapas"),bFr=o(" \u2014 "),jU=a("a"),vFr=o("TFTapasModel"),FFr=o(" (TAPAS model)"),TFr=l(),ZM=a("li"),MFe=a("strong"),MFr=o("transfo-xl"),EFr=o(" \u2014 "),DU=a("a"),CFr=o("TFTransfoXLModel"),wFr=o(" (Transformer-XL model)"),AFr=l(),eE=a("li"),EFe=a("strong"),LFr=o("vit"),yFr=o(" \u2014 "),GU=a("a"),xFr=o("TFViTModel"),$Fr=o(" (ViT model)"),kFr=l(),oE=a("li"),CFe=a("strong"),SFr=o("vit_mae"),RFr=o(" \u2014 "),OU=a("a"),PFr=o("TFViTMAEModel"),BFr=o(" (ViTMAE model)"),NFr=l(),rE=a("li"),wFe=a("strong"),IFr=o("wav2vec2"),qFr=o(" \u2014 "),VU=a("a"),jFr=o("TFWav2Vec2Model"),DFr=o(" (Wav2Vec2 model)"),GFr=l(),tE=a("li"),AFe=a("strong"),OFr=o("xlm"),VFr=o(" \u2014 "),XU=a("a"),XFr=o("TFXLMModel"),zFr=o(" (XLM model)"),QFr=l(),aE=a("li"),LFe=a("strong"),WFr=o("xlm-roberta"),HFr=o(" \u2014 "),zU=a("a"),UFr=o("TFXLMRobertaModel"),JFr=o(" (XLM-RoBERTa model)"),YFr=l(),nE=a("li"),yFe=a("strong"),KFr=o("xlnet"),ZFr=o(" \u2014 "),QU=a("a"),eTr=o("TFXLNetModel"),oTr=o(" (XLNet model)"),rTr=l(),F(sE.$$.fragment),kXe=l(),lc=a("h2"),lE=a("a"),xFe=a("span"),F(O9.$$.fragment),tTr=l(),$Fe=a("span"),aTr=o("TFAutoModelForPreTraining"),SXe=l(),or=a("div"),F(V9.$$.fragment),nTr=l(),ic=a("p"),sTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),WU=a("a"),lTr=o("from_pretrained()"),iTr=o(" class method or the "),HU=a("a"),dTr=o("from_config()"),cTr=o(` class
method.`),fTr=l(),X9=a("p"),mTr=o("This class cannot be instantiated directly using "),kFe=a("code"),gTr=o("__init__()"),hTr=o(" (throws an error)."),pTr=l(),St=a("div"),F(z9.$$.fragment),_Tr=l(),SFe=a("p"),uTr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),bTr=l(),dc=a("p"),vTr=o(`Note:
Loading a model from its configuration file does `),RFe=a("strong"),FTr=o("not"),TTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UU=a("a"),MTr=o("from_pretrained()"),ETr=o(" to load the model weights."),CTr=l(),F(iE.$$.fragment),wTr=l(),$r=a("div"),F(Q9.$$.fragment),ATr=l(),PFe=a("p"),LTr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),yTr=l(),ln=a("p"),xTr=o("The model class to instantiate is selected based on the "),BFe=a("code"),$Tr=o("model_type"),kTr=o(` property of the config object (either
passed as an argument or loaded from `),NFe=a("code"),STr=o("pretrained_model_name_or_path"),RTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IFe=a("code"),PTr=o("pretrained_model_name_or_path"),BTr=o(":"),NTr=l(),se=a("ul"),dE=a("li"),qFe=a("strong"),ITr=o("albert"),qTr=o(" \u2014 "),JU=a("a"),jTr=o("TFAlbertForPreTraining"),DTr=o(" (ALBERT model)"),GTr=l(),cE=a("li"),jFe=a("strong"),OTr=o("bart"),VTr=o(" \u2014 "),YU=a("a"),XTr=o("TFBartForConditionalGeneration"),zTr=o(" (BART model)"),QTr=l(),fE=a("li"),DFe=a("strong"),WTr=o("bert"),HTr=o(" \u2014 "),KU=a("a"),UTr=o("TFBertForPreTraining"),JTr=o(" (BERT model)"),YTr=l(),mE=a("li"),GFe=a("strong"),KTr=o("camembert"),ZTr=o(" \u2014 "),ZU=a("a"),eMr=o("TFCamembertForMaskedLM"),oMr=o(" (CamemBERT model)"),rMr=l(),gE=a("li"),OFe=a("strong"),tMr=o("ctrl"),aMr=o(" \u2014 "),eJ=a("a"),nMr=o("TFCTRLLMHeadModel"),sMr=o(" (CTRL model)"),lMr=l(),hE=a("li"),VFe=a("strong"),iMr=o("distilbert"),dMr=o(" \u2014 "),oJ=a("a"),cMr=o("TFDistilBertForMaskedLM"),fMr=o(" (DistilBERT model)"),mMr=l(),pE=a("li"),XFe=a("strong"),gMr=o("electra"),hMr=o(" \u2014 "),rJ=a("a"),pMr=o("TFElectraForPreTraining"),_Mr=o(" (ELECTRA model)"),uMr=l(),_E=a("li"),zFe=a("strong"),bMr=o("flaubert"),vMr=o(" \u2014 "),tJ=a("a"),FMr=o("TFFlaubertWithLMHeadModel"),TMr=o(" (FlauBERT model)"),MMr=l(),uE=a("li"),QFe=a("strong"),EMr=o("funnel"),CMr=o(" \u2014 "),aJ=a("a"),wMr=o("TFFunnelForPreTraining"),AMr=o(" (Funnel Transformer model)"),LMr=l(),bE=a("li"),WFe=a("strong"),yMr=o("gpt2"),xMr=o(" \u2014 "),nJ=a("a"),$Mr=o("TFGPT2LMHeadModel"),kMr=o(" (OpenAI GPT-2 model)"),SMr=l(),vE=a("li"),HFe=a("strong"),RMr=o("layoutlm"),PMr=o(" \u2014 "),sJ=a("a"),BMr=o("TFLayoutLMForMaskedLM"),NMr=o(" (LayoutLM model)"),IMr=l(),FE=a("li"),UFe=a("strong"),qMr=o("lxmert"),jMr=o(" \u2014 "),lJ=a("a"),DMr=o("TFLxmertForPreTraining"),GMr=o(" (LXMERT model)"),OMr=l(),TE=a("li"),JFe=a("strong"),VMr=o("mobilebert"),XMr=o(" \u2014 "),iJ=a("a"),zMr=o("TFMobileBertForPreTraining"),QMr=o(" (MobileBERT model)"),WMr=l(),ME=a("li"),YFe=a("strong"),HMr=o("mpnet"),UMr=o(" \u2014 "),dJ=a("a"),JMr=o("TFMPNetForMaskedLM"),YMr=o(" (MPNet model)"),KMr=l(),EE=a("li"),KFe=a("strong"),ZMr=o("openai-gpt"),eEr=o(" \u2014 "),cJ=a("a"),oEr=o("TFOpenAIGPTLMHeadModel"),rEr=o(" (OpenAI GPT model)"),tEr=l(),CE=a("li"),ZFe=a("strong"),aEr=o("roberta"),nEr=o(" \u2014 "),fJ=a("a"),sEr=o("TFRobertaForMaskedLM"),lEr=o(" (RoBERTa model)"),iEr=l(),wE=a("li"),eTe=a("strong"),dEr=o("t5"),cEr=o(" \u2014 "),mJ=a("a"),fEr=o("TFT5ForConditionalGeneration"),mEr=o(" (T5 model)"),gEr=l(),AE=a("li"),oTe=a("strong"),hEr=o("tapas"),pEr=o(" \u2014 "),gJ=a("a"),_Er=o("TFTapasForMaskedLM"),uEr=o(" (TAPAS model)"),bEr=l(),LE=a("li"),rTe=a("strong"),vEr=o("transfo-xl"),FEr=o(" \u2014 "),hJ=a("a"),TEr=o("TFTransfoXLLMHeadModel"),MEr=o(" (Transformer-XL model)"),EEr=l(),yE=a("li"),tTe=a("strong"),CEr=o("vit_mae"),wEr=o(" \u2014 "),pJ=a("a"),AEr=o("TFViTMAEForPreTraining"),LEr=o(" (ViTMAE model)"),yEr=l(),xE=a("li"),aTe=a("strong"),xEr=o("xlm"),$Er=o(" \u2014 "),_J=a("a"),kEr=o("TFXLMWithLMHeadModel"),SEr=o(" (XLM model)"),REr=l(),$E=a("li"),nTe=a("strong"),PEr=o("xlm-roberta"),BEr=o(" \u2014 "),uJ=a("a"),NEr=o("TFXLMRobertaForMaskedLM"),IEr=o(" (XLM-RoBERTa model)"),qEr=l(),kE=a("li"),sTe=a("strong"),jEr=o("xlnet"),DEr=o(" \u2014 "),bJ=a("a"),GEr=o("TFXLNetLMHeadModel"),OEr=o(" (XLNet model)"),VEr=l(),F(SE.$$.fragment),RXe=l(),cc=a("h2"),RE=a("a"),lTe=a("span"),F(W9.$$.fragment),XEr=l(),iTe=a("span"),zEr=o("TFAutoModelForCausalLM"),PXe=l(),rr=a("div"),F(H9.$$.fragment),QEr=l(),fc=a("p"),WEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vJ=a("a"),HEr=o("from_pretrained()"),UEr=o(" class method or the "),FJ=a("a"),JEr=o("from_config()"),YEr=o(` class
method.`),KEr=l(),U9=a("p"),ZEr=o("This class cannot be instantiated directly using "),dTe=a("code"),eCr=o("__init__()"),oCr=o(" (throws an error)."),rCr=l(),Rt=a("div"),F(J9.$$.fragment),tCr=l(),cTe=a("p"),aCr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),nCr=l(),mc=a("p"),sCr=o(`Note:
Loading a model from its configuration file does `),fTe=a("strong"),lCr=o("not"),iCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TJ=a("a"),dCr=o("from_pretrained()"),cCr=o(" to load the model weights."),fCr=l(),F(PE.$$.fragment),mCr=l(),kr=a("div"),F(Y9.$$.fragment),gCr=l(),mTe=a("p"),hCr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),pCr=l(),dn=a("p"),_Cr=o("The model class to instantiate is selected based on the "),gTe=a("code"),uCr=o("model_type"),bCr=o(` property of the config object (either
passed as an argument or loaded from `),hTe=a("code"),vCr=o("pretrained_model_name_or_path"),FCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=a("code"),TCr=o("pretrained_model_name_or_path"),MCr=o(":"),ECr=l(),Me=a("ul"),BE=a("li"),_Te=a("strong"),CCr=o("bert"),wCr=o(" \u2014 "),MJ=a("a"),ACr=o("TFBertLMHeadModel"),LCr=o(" (BERT model)"),yCr=l(),NE=a("li"),uTe=a("strong"),xCr=o("camembert"),$Cr=o(" \u2014 "),EJ=a("a"),kCr=o("TFCamembertForCausalLM"),SCr=o(" (CamemBERT model)"),RCr=l(),IE=a("li"),bTe=a("strong"),PCr=o("ctrl"),BCr=o(" \u2014 "),CJ=a("a"),NCr=o("TFCTRLLMHeadModel"),ICr=o(" (CTRL model)"),qCr=l(),qE=a("li"),vTe=a("strong"),jCr=o("gpt2"),DCr=o(" \u2014 "),wJ=a("a"),GCr=o("TFGPT2LMHeadModel"),OCr=o(" (OpenAI GPT-2 model)"),VCr=l(),jE=a("li"),FTe=a("strong"),XCr=o("gptj"),zCr=o(" \u2014 "),AJ=a("a"),QCr=o("TFGPTJForCausalLM"),WCr=o(" (GPT-J model)"),HCr=l(),DE=a("li"),TTe=a("strong"),UCr=o("openai-gpt"),JCr=o(" \u2014 "),LJ=a("a"),YCr=o("TFOpenAIGPTLMHeadModel"),KCr=o(" (OpenAI GPT model)"),ZCr=l(),GE=a("li"),MTe=a("strong"),e3r=o("opt"),o3r=o(" \u2014 "),yJ=a("a"),r3r=o("TFOPTForCausalLM"),t3r=o(" (OPT model)"),a3r=l(),OE=a("li"),ETe=a("strong"),n3r=o("rembert"),s3r=o(" \u2014 "),xJ=a("a"),l3r=o("TFRemBertForCausalLM"),i3r=o(" (RemBERT model)"),d3r=l(),VE=a("li"),CTe=a("strong"),c3r=o("roberta"),f3r=o(" \u2014 "),$J=a("a"),m3r=o("TFRobertaForCausalLM"),g3r=o(" (RoBERTa model)"),h3r=l(),XE=a("li"),wTe=a("strong"),p3r=o("roformer"),_3r=o(" \u2014 "),kJ=a("a"),u3r=o("TFRoFormerForCausalLM"),b3r=o(" (RoFormer model)"),v3r=l(),zE=a("li"),ATe=a("strong"),F3r=o("transfo-xl"),T3r=o(" \u2014 "),SJ=a("a"),M3r=o("TFTransfoXLLMHeadModel"),E3r=o(" (Transformer-XL model)"),C3r=l(),QE=a("li"),LTe=a("strong"),w3r=o("xlm"),A3r=o(" \u2014 "),RJ=a("a"),L3r=o("TFXLMWithLMHeadModel"),y3r=o(" (XLM model)"),x3r=l(),WE=a("li"),yTe=a("strong"),$3r=o("xlnet"),k3r=o(" \u2014 "),PJ=a("a"),S3r=o("TFXLNetLMHeadModel"),R3r=o(" (XLNet model)"),P3r=l(),F(HE.$$.fragment),BXe=l(),gc=a("h2"),UE=a("a"),xTe=a("span"),F(K9.$$.fragment),B3r=l(),$Te=a("span"),N3r=o("TFAutoModelForImageClassification"),NXe=l(),tr=a("div"),F(Z9.$$.fragment),I3r=l(),hc=a("p"),q3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),BJ=a("a"),j3r=o("from_pretrained()"),D3r=o(" class method or the "),NJ=a("a"),G3r=o("from_config()"),O3r=o(` class
method.`),V3r=l(),ex=a("p"),X3r=o("This class cannot be instantiated directly using "),kTe=a("code"),z3r=o("__init__()"),Q3r=o(" (throws an error)."),W3r=l(),Pt=a("div"),F(ox.$$.fragment),H3r=l(),STe=a("p"),U3r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),J3r=l(),pc=a("p"),Y3r=o(`Note:
Loading a model from its configuration file does `),RTe=a("strong"),K3r=o("not"),Z3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=a("a"),e5r=o("from_pretrained()"),o5r=o(" to load the model weights."),r5r=l(),F(JE.$$.fragment),t5r=l(),Sr=a("div"),F(rx.$$.fragment),a5r=l(),PTe=a("p"),n5r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),s5r=l(),cn=a("p"),l5r=o("The model class to instantiate is selected based on the "),BTe=a("code"),i5r=o("model_type"),d5r=o(` property of the config object (either
passed as an argument or loaded from `),NTe=a("code"),c5r=o("pretrained_model_name_or_path"),f5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ITe=a("code"),m5r=o("pretrained_model_name_or_path"),g5r=o(":"),h5r=l(),ar=a("ul"),YE=a("li"),qTe=a("strong"),p5r=o("convnext"),_5r=o(" \u2014 "),qJ=a("a"),u5r=o("TFConvNextForImageClassification"),b5r=o(" (ConvNeXT model)"),v5r=l(),KE=a("li"),jTe=a("strong"),F5r=o("data2vec-vision"),T5r=o(" \u2014 "),jJ=a("a"),M5r=o("TFData2VecVisionForImageClassification"),E5r=o(" (Data2VecVision model)"),C5r=l(),ZE=a("li"),DTe=a("strong"),w5r=o("regnet"),A5r=o(" \u2014 "),DJ=a("a"),L5r=o("TFRegNetForImageClassification"),y5r=o(" (RegNet model)"),x5r=l(),eC=a("li"),GTe=a("strong"),$5r=o("resnet"),k5r=o(" \u2014 "),GJ=a("a"),S5r=o("TFResNetForImageClassification"),R5r=o(" (ResNet model)"),P5r=l(),oC=a("li"),OTe=a("strong"),B5r=o("swin"),N5r=o(" \u2014 "),OJ=a("a"),I5r=o("TFSwinForImageClassification"),q5r=o(" (Swin Transformer model)"),j5r=l(),rC=a("li"),VTe=a("strong"),D5r=o("vit"),G5r=o(" \u2014 "),VJ=a("a"),O5r=o("TFViTForImageClassification"),V5r=o(" (ViT model)"),X5r=l(),F(tC.$$.fragment),IXe=l(),_c=a("h2"),aC=a("a"),XTe=a("span"),F(tx.$$.fragment),z5r=l(),zTe=a("span"),Q5r=o("TFAutoModelForMaskedLM"),qXe=l(),nr=a("div"),F(ax.$$.fragment),W5r=l(),uc=a("p"),H5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),XJ=a("a"),U5r=o("from_pretrained()"),J5r=o(" class method or the "),zJ=a("a"),Y5r=o("from_config()"),K5r=o(` class
method.`),Z5r=l(),nx=a("p"),e0r=o("This class cannot be instantiated directly using "),QTe=a("code"),o0r=o("__init__()"),r0r=o(" (throws an error)."),t0r=l(),Bt=a("div"),F(sx.$$.fragment),a0r=l(),WTe=a("p"),n0r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),s0r=l(),bc=a("p"),l0r=o(`Note:
Loading a model from its configuration file does `),HTe=a("strong"),i0r=o("not"),d0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),c0r=o("from_pretrained()"),f0r=o(" to load the model weights."),m0r=l(),F(nC.$$.fragment),g0r=l(),Rr=a("div"),F(lx.$$.fragment),h0r=l(),UTe=a("p"),p0r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_0r=l(),fn=a("p"),u0r=o("The model class to instantiate is selected based on the "),JTe=a("code"),b0r=o("model_type"),v0r=o(` property of the config object (either
passed as an argument or loaded from `),YTe=a("code"),F0r=o("pretrained_model_name_or_path"),T0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KTe=a("code"),M0r=o("pretrained_model_name_or_path"),E0r=o(":"),C0r=l(),ie=a("ul"),sC=a("li"),ZTe=a("strong"),w0r=o("albert"),A0r=o(" \u2014 "),WJ=a("a"),L0r=o("TFAlbertForMaskedLM"),y0r=o(" (ALBERT model)"),x0r=l(),lC=a("li"),eMe=a("strong"),$0r=o("bert"),k0r=o(" \u2014 "),HJ=a("a"),S0r=o("TFBertForMaskedLM"),R0r=o(" (BERT model)"),P0r=l(),iC=a("li"),oMe=a("strong"),B0r=o("camembert"),N0r=o(" \u2014 "),UJ=a("a"),I0r=o("TFCamembertForMaskedLM"),q0r=o(" (CamemBERT model)"),j0r=l(),dC=a("li"),rMe=a("strong"),D0r=o("convbert"),G0r=o(" \u2014 "),JJ=a("a"),O0r=o("TFConvBertForMaskedLM"),V0r=o(" (ConvBERT model)"),X0r=l(),cC=a("li"),tMe=a("strong"),z0r=o("deberta"),Q0r=o(" \u2014 "),YJ=a("a"),W0r=o("TFDebertaForMaskedLM"),H0r=o(" (DeBERTa model)"),U0r=l(),fC=a("li"),aMe=a("strong"),J0r=o("deberta-v2"),Y0r=o(" \u2014 "),KJ=a("a"),K0r=o("TFDebertaV2ForMaskedLM"),Z0r=o(" (DeBERTa-v2 model)"),ewr=l(),mC=a("li"),nMe=a("strong"),owr=o("distilbert"),rwr=o(" \u2014 "),ZJ=a("a"),twr=o("TFDistilBertForMaskedLM"),awr=o(" (DistilBERT model)"),nwr=l(),gC=a("li"),sMe=a("strong"),swr=o("electra"),lwr=o(" \u2014 "),eY=a("a"),iwr=o("TFElectraForMaskedLM"),dwr=o(" (ELECTRA model)"),cwr=l(),hC=a("li"),lMe=a("strong"),fwr=o("flaubert"),mwr=o(" \u2014 "),oY=a("a"),gwr=o("TFFlaubertWithLMHeadModel"),hwr=o(" (FlauBERT model)"),pwr=l(),pC=a("li"),iMe=a("strong"),_wr=o("funnel"),uwr=o(" \u2014 "),rY=a("a"),bwr=o("TFFunnelForMaskedLM"),vwr=o(" (Funnel Transformer model)"),Fwr=l(),_C=a("li"),dMe=a("strong"),Twr=o("layoutlm"),Mwr=o(" \u2014 "),tY=a("a"),Ewr=o("TFLayoutLMForMaskedLM"),Cwr=o(" (LayoutLM model)"),wwr=l(),uC=a("li"),cMe=a("strong"),Awr=o("longformer"),Lwr=o(" \u2014 "),aY=a("a"),ywr=o("TFLongformerForMaskedLM"),xwr=o(" (Longformer model)"),$wr=l(),bC=a("li"),fMe=a("strong"),kwr=o("mobilebert"),Swr=o(" \u2014 "),nY=a("a"),Rwr=o("TFMobileBertForMaskedLM"),Pwr=o(" (MobileBERT model)"),Bwr=l(),vC=a("li"),mMe=a("strong"),Nwr=o("mpnet"),Iwr=o(" \u2014 "),sY=a("a"),qwr=o("TFMPNetForMaskedLM"),jwr=o(" (MPNet model)"),Dwr=l(),FC=a("li"),gMe=a("strong"),Gwr=o("rembert"),Owr=o(" \u2014 "),lY=a("a"),Vwr=o("TFRemBertForMaskedLM"),Xwr=o(" (RemBERT model)"),zwr=l(),TC=a("li"),hMe=a("strong"),Qwr=o("roberta"),Wwr=o(" \u2014 "),iY=a("a"),Hwr=o("TFRobertaForMaskedLM"),Uwr=o(" (RoBERTa model)"),Jwr=l(),MC=a("li"),pMe=a("strong"),Ywr=o("roformer"),Kwr=o(" \u2014 "),dY=a("a"),Zwr=o("TFRoFormerForMaskedLM"),eAr=o(" (RoFormer model)"),oAr=l(),EC=a("li"),_Me=a("strong"),rAr=o("tapas"),tAr=o(" \u2014 "),cY=a("a"),aAr=o("TFTapasForMaskedLM"),nAr=o(" (TAPAS model)"),sAr=l(),CC=a("li"),uMe=a("strong"),lAr=o("xlm"),iAr=o(" \u2014 "),fY=a("a"),dAr=o("TFXLMWithLMHeadModel"),cAr=o(" (XLM model)"),fAr=l(),wC=a("li"),bMe=a("strong"),mAr=o("xlm-roberta"),gAr=o(" \u2014 "),mY=a("a"),hAr=o("TFXLMRobertaForMaskedLM"),pAr=o(" (XLM-RoBERTa model)"),_Ar=l(),F(AC.$$.fragment),jXe=l(),vc=a("h2"),LC=a("a"),vMe=a("span"),F(ix.$$.fragment),uAr=l(),FMe=a("span"),bAr=o("TFAutoModelForSeq2SeqLM"),DXe=l(),sr=a("div"),F(dx.$$.fragment),vAr=l(),Fc=a("p"),FAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gY=a("a"),TAr=o("from_pretrained()"),MAr=o(" class method or the "),hY=a("a"),EAr=o("from_config()"),CAr=o(` class
method.`),wAr=l(),cx=a("p"),AAr=o("This class cannot be instantiated directly using "),TMe=a("code"),LAr=o("__init__()"),yAr=o(" (throws an error)."),xAr=l(),Nt=a("div"),F(fx.$$.fragment),$Ar=l(),MMe=a("p"),kAr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),SAr=l(),Tc=a("p"),RAr=o(`Note:
Loading a model from its configuration file does `),EMe=a("strong"),PAr=o("not"),BAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pY=a("a"),NAr=o("from_pretrained()"),IAr=o(" to load the model weights."),qAr=l(),F(yC.$$.fragment),jAr=l(),Pr=a("div"),F(mx.$$.fragment),DAr=l(),CMe=a("p"),GAr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),OAr=l(),mn=a("p"),VAr=o("The model class to instantiate is selected based on the "),wMe=a("code"),XAr=o("model_type"),zAr=o(` property of the config object (either
passed as an argument or loaded from `),AMe=a("code"),QAr=o("pretrained_model_name_or_path"),WAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LMe=a("code"),HAr=o("pretrained_model_name_or_path"),UAr=o(":"),JAr=l(),ye=a("ul"),xC=a("li"),yMe=a("strong"),YAr=o("bart"),KAr=o(" \u2014 "),_Y=a("a"),ZAr=o("TFBartForConditionalGeneration"),e6r=o(" (BART model)"),o6r=l(),$C=a("li"),xMe=a("strong"),r6r=o("blenderbot"),t6r=o(" \u2014 "),uY=a("a"),a6r=o("TFBlenderbotForConditionalGeneration"),n6r=o(" (Blenderbot model)"),s6r=l(),kC=a("li"),$Me=a("strong"),l6r=o("blenderbot-small"),i6r=o(" \u2014 "),bY=a("a"),d6r=o("TFBlenderbotSmallForConditionalGeneration"),c6r=o(" (BlenderbotSmall model)"),f6r=l(),SC=a("li"),kMe=a("strong"),m6r=o("encoder-decoder"),g6r=o(" \u2014 "),vY=a("a"),h6r=o("TFEncoderDecoderModel"),p6r=o(" (Encoder decoder model)"),_6r=l(),RC=a("li"),SMe=a("strong"),u6r=o("led"),b6r=o(" \u2014 "),FY=a("a"),v6r=o("TFLEDForConditionalGeneration"),F6r=o(" (LED model)"),T6r=l(),PC=a("li"),RMe=a("strong"),M6r=o("marian"),E6r=o(" \u2014 "),TY=a("a"),C6r=o("TFMarianMTModel"),w6r=o(" (Marian model)"),A6r=l(),BC=a("li"),PMe=a("strong"),L6r=o("mbart"),y6r=o(" \u2014 "),MY=a("a"),x6r=o("TFMBartForConditionalGeneration"),$6r=o(" (mBART model)"),k6r=l(),NC=a("li"),BMe=a("strong"),S6r=o("mt5"),R6r=o(" \u2014 "),EY=a("a"),P6r=o("TFMT5ForConditionalGeneration"),B6r=o(" (MT5 model)"),N6r=l(),IC=a("li"),NMe=a("strong"),I6r=o("pegasus"),q6r=o(" \u2014 "),CY=a("a"),j6r=o("TFPegasusForConditionalGeneration"),D6r=o(" (Pegasus model)"),G6r=l(),qC=a("li"),IMe=a("strong"),O6r=o("t5"),V6r=o(" \u2014 "),wY=a("a"),X6r=o("TFT5ForConditionalGeneration"),z6r=o(" (T5 model)"),Q6r=l(),F(jC.$$.fragment),GXe=l(),Mc=a("h2"),DC=a("a"),qMe=a("span"),F(gx.$$.fragment),W6r=l(),jMe=a("span"),H6r=o("TFAutoModelForSequenceClassification"),OXe=l(),lr=a("div"),F(hx.$$.fragment),U6r=l(),Ec=a("p"),J6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),AY=a("a"),Y6r=o("from_pretrained()"),K6r=o(" class method or the "),LY=a("a"),Z6r=o("from_config()"),eLr=o(` class
method.`),oLr=l(),px=a("p"),rLr=o("This class cannot be instantiated directly using "),DMe=a("code"),tLr=o("__init__()"),aLr=o(" (throws an error)."),nLr=l(),It=a("div"),F(_x.$$.fragment),sLr=l(),GMe=a("p"),lLr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),iLr=l(),Cc=a("p"),dLr=o(`Note:
Loading a model from its configuration file does `),OMe=a("strong"),cLr=o("not"),fLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=a("a"),mLr=o("from_pretrained()"),gLr=o(" to load the model weights."),hLr=l(),F(GC.$$.fragment),pLr=l(),Br=a("div"),F(ux.$$.fragment),_Lr=l(),VMe=a("p"),uLr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),bLr=l(),gn=a("p"),vLr=o("The model class to instantiate is selected based on the "),XMe=a("code"),FLr=o("model_type"),TLr=o(` property of the config object (either
passed as an argument or loaded from `),zMe=a("code"),MLr=o("pretrained_model_name_or_path"),ELr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QMe=a("code"),CLr=o("pretrained_model_name_or_path"),wLr=o(":"),ALr=l(),te=a("ul"),OC=a("li"),WMe=a("strong"),LLr=o("albert"),yLr=o(" \u2014 "),xY=a("a"),xLr=o("TFAlbertForSequenceClassification"),$Lr=o(" (ALBERT model)"),kLr=l(),VC=a("li"),HMe=a("strong"),SLr=o("bert"),RLr=o(" \u2014 "),$Y=a("a"),PLr=o("TFBertForSequenceClassification"),BLr=o(" (BERT model)"),NLr=l(),XC=a("li"),UMe=a("strong"),ILr=o("camembert"),qLr=o(" \u2014 "),kY=a("a"),jLr=o("TFCamembertForSequenceClassification"),DLr=o(" (CamemBERT model)"),GLr=l(),zC=a("li"),JMe=a("strong"),OLr=o("convbert"),VLr=o(" \u2014 "),SY=a("a"),XLr=o("TFConvBertForSequenceClassification"),zLr=o(" (ConvBERT model)"),QLr=l(),QC=a("li"),YMe=a("strong"),WLr=o("ctrl"),HLr=o(" \u2014 "),RY=a("a"),ULr=o("TFCTRLForSequenceClassification"),JLr=o(" (CTRL model)"),YLr=l(),WC=a("li"),KMe=a("strong"),KLr=o("deberta"),ZLr=o(" \u2014 "),PY=a("a"),eyr=o("TFDebertaForSequenceClassification"),oyr=o(" (DeBERTa model)"),ryr=l(),HC=a("li"),ZMe=a("strong"),tyr=o("deberta-v2"),ayr=o(" \u2014 "),BY=a("a"),nyr=o("TFDebertaV2ForSequenceClassification"),syr=o(" (DeBERTa-v2 model)"),lyr=l(),UC=a("li"),eEe=a("strong"),iyr=o("distilbert"),dyr=o(" \u2014 "),NY=a("a"),cyr=o("TFDistilBertForSequenceClassification"),fyr=o(" (DistilBERT model)"),myr=l(),JC=a("li"),oEe=a("strong"),gyr=o("electra"),hyr=o(" \u2014 "),IY=a("a"),pyr=o("TFElectraForSequenceClassification"),_yr=o(" (ELECTRA model)"),uyr=l(),YC=a("li"),rEe=a("strong"),byr=o("flaubert"),vyr=o(" \u2014 "),qY=a("a"),Fyr=o("TFFlaubertForSequenceClassification"),Tyr=o(" (FlauBERT model)"),Myr=l(),KC=a("li"),tEe=a("strong"),Eyr=o("funnel"),Cyr=o(" \u2014 "),jY=a("a"),wyr=o("TFFunnelForSequenceClassification"),Ayr=o(" (Funnel Transformer model)"),Lyr=l(),ZC=a("li"),aEe=a("strong"),yyr=o("gpt2"),xyr=o(" \u2014 "),DY=a("a"),$yr=o("TFGPT2ForSequenceClassification"),kyr=o(" (OpenAI GPT-2 model)"),Syr=l(),e3=a("li"),nEe=a("strong"),Ryr=o("gptj"),Pyr=o(" \u2014 "),GY=a("a"),Byr=o("TFGPTJForSequenceClassification"),Nyr=o(" (GPT-J model)"),Iyr=l(),o3=a("li"),sEe=a("strong"),qyr=o("layoutlm"),jyr=o(" \u2014 "),OY=a("a"),Dyr=o("TFLayoutLMForSequenceClassification"),Gyr=o(" (LayoutLM model)"),Oyr=l(),r3=a("li"),lEe=a("strong"),Vyr=o("longformer"),Xyr=o(" \u2014 "),VY=a("a"),zyr=o("TFLongformerForSequenceClassification"),Qyr=o(" (Longformer model)"),Wyr=l(),t3=a("li"),iEe=a("strong"),Hyr=o("mobilebert"),Uyr=o(" \u2014 "),XY=a("a"),Jyr=o("TFMobileBertForSequenceClassification"),Yyr=o(" (MobileBERT model)"),Kyr=l(),a3=a("li"),dEe=a("strong"),Zyr=o("mpnet"),e8r=o(" \u2014 "),zY=a("a"),o8r=o("TFMPNetForSequenceClassification"),r8r=o(" (MPNet model)"),t8r=l(),n3=a("li"),cEe=a("strong"),a8r=o("openai-gpt"),n8r=o(" \u2014 "),QY=a("a"),s8r=o("TFOpenAIGPTForSequenceClassification"),l8r=o(" (OpenAI GPT model)"),i8r=l(),s3=a("li"),fEe=a("strong"),d8r=o("rembert"),c8r=o(" \u2014 "),WY=a("a"),f8r=o("TFRemBertForSequenceClassification"),m8r=o(" (RemBERT model)"),g8r=l(),l3=a("li"),mEe=a("strong"),h8r=o("roberta"),p8r=o(" \u2014 "),HY=a("a"),_8r=o("TFRobertaForSequenceClassification"),u8r=o(" (RoBERTa model)"),b8r=l(),i3=a("li"),gEe=a("strong"),v8r=o("roformer"),F8r=o(" \u2014 "),UY=a("a"),T8r=o("TFRoFormerForSequenceClassification"),M8r=o(" (RoFormer model)"),E8r=l(),d3=a("li"),hEe=a("strong"),C8r=o("tapas"),w8r=o(" \u2014 "),JY=a("a"),A8r=o("TFTapasForSequenceClassification"),L8r=o(" (TAPAS model)"),y8r=l(),c3=a("li"),pEe=a("strong"),x8r=o("transfo-xl"),$8r=o(" \u2014 "),YY=a("a"),k8r=o("TFTransfoXLForSequenceClassification"),S8r=o(" (Transformer-XL model)"),R8r=l(),f3=a("li"),_Ee=a("strong"),P8r=o("xlm"),B8r=o(" \u2014 "),KY=a("a"),N8r=o("TFXLMForSequenceClassification"),I8r=o(" (XLM model)"),q8r=l(),m3=a("li"),uEe=a("strong"),j8r=o("xlm-roberta"),D8r=o(" \u2014 "),ZY=a("a"),G8r=o("TFXLMRobertaForSequenceClassification"),O8r=o(" (XLM-RoBERTa model)"),V8r=l(),g3=a("li"),bEe=a("strong"),X8r=o("xlnet"),z8r=o(" \u2014 "),eK=a("a"),Q8r=o("TFXLNetForSequenceClassification"),W8r=o(" (XLNet model)"),H8r=l(),F(h3.$$.fragment),VXe=l(),wc=a("h2"),p3=a("a"),vEe=a("span"),F(bx.$$.fragment),U8r=l(),FEe=a("span"),J8r=o("TFAutoModelForMultipleChoice"),XXe=l(),ir=a("div"),F(vx.$$.fragment),Y8r=l(),Ac=a("p"),K8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),oK=a("a"),Z8r=o("from_pretrained()"),e9r=o(" class method or the "),rK=a("a"),o9r=o("from_config()"),r9r=o(` class
method.`),t9r=l(),Fx=a("p"),a9r=o("This class cannot be instantiated directly using "),TEe=a("code"),n9r=o("__init__()"),s9r=o(" (throws an error)."),l9r=l(),qt=a("div"),F(Tx.$$.fragment),i9r=l(),MEe=a("p"),d9r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),c9r=l(),Lc=a("p"),f9r=o(`Note:
Loading a model from its configuration file does `),EEe=a("strong"),m9r=o("not"),g9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=a("a"),h9r=o("from_pretrained()"),p9r=o(" to load the model weights."),_9r=l(),F(_3.$$.fragment),u9r=l(),Nr=a("div"),F(Mx.$$.fragment),b9r=l(),CEe=a("p"),v9r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),F9r=l(),hn=a("p"),T9r=o("The model class to instantiate is selected based on the "),wEe=a("code"),M9r=o("model_type"),E9r=o(` property of the config object (either
passed as an argument or loaded from `),AEe=a("code"),C9r=o("pretrained_model_name_or_path"),w9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=a("code"),A9r=o("pretrained_model_name_or_path"),L9r=o(":"),y9r=l(),_e=a("ul"),u3=a("li"),yEe=a("strong"),x9r=o("albert"),$9r=o(" \u2014 "),aK=a("a"),k9r=o("TFAlbertForMultipleChoice"),S9r=o(" (ALBERT model)"),R9r=l(),b3=a("li"),xEe=a("strong"),P9r=o("bert"),B9r=o(" \u2014 "),nK=a("a"),N9r=o("TFBertForMultipleChoice"),I9r=o(" (BERT model)"),q9r=l(),v3=a("li"),$Ee=a("strong"),j9r=o("camembert"),D9r=o(" \u2014 "),sK=a("a"),G9r=o("TFCamembertForMultipleChoice"),O9r=o(" (CamemBERT model)"),V9r=l(),F3=a("li"),kEe=a("strong"),X9r=o("convbert"),z9r=o(" \u2014 "),lK=a("a"),Q9r=o("TFConvBertForMultipleChoice"),W9r=o(" (ConvBERT model)"),H9r=l(),T3=a("li"),SEe=a("strong"),U9r=o("distilbert"),J9r=o(" \u2014 "),iK=a("a"),Y9r=o("TFDistilBertForMultipleChoice"),K9r=o(" (DistilBERT model)"),Z9r=l(),M3=a("li"),REe=a("strong"),exr=o("electra"),oxr=o(" \u2014 "),dK=a("a"),rxr=o("TFElectraForMultipleChoice"),txr=o(" (ELECTRA model)"),axr=l(),E3=a("li"),PEe=a("strong"),nxr=o("flaubert"),sxr=o(" \u2014 "),cK=a("a"),lxr=o("TFFlaubertForMultipleChoice"),ixr=o(" (FlauBERT model)"),dxr=l(),C3=a("li"),BEe=a("strong"),cxr=o("funnel"),fxr=o(" \u2014 "),fK=a("a"),mxr=o("TFFunnelForMultipleChoice"),gxr=o(" (Funnel Transformer model)"),hxr=l(),w3=a("li"),NEe=a("strong"),pxr=o("longformer"),_xr=o(" \u2014 "),mK=a("a"),uxr=o("TFLongformerForMultipleChoice"),bxr=o(" (Longformer model)"),vxr=l(),A3=a("li"),IEe=a("strong"),Fxr=o("mobilebert"),Txr=o(" \u2014 "),gK=a("a"),Mxr=o("TFMobileBertForMultipleChoice"),Exr=o(" (MobileBERT model)"),Cxr=l(),L3=a("li"),qEe=a("strong"),wxr=o("mpnet"),Axr=o(" \u2014 "),hK=a("a"),Lxr=o("TFMPNetForMultipleChoice"),yxr=o(" (MPNet model)"),xxr=l(),y3=a("li"),jEe=a("strong"),$xr=o("rembert"),kxr=o(" \u2014 "),pK=a("a"),Sxr=o("TFRemBertForMultipleChoice"),Rxr=o(" (RemBERT model)"),Pxr=l(),x3=a("li"),DEe=a("strong"),Bxr=o("roberta"),Nxr=o(" \u2014 "),_K=a("a"),Ixr=o("TFRobertaForMultipleChoice"),qxr=o(" (RoBERTa model)"),jxr=l(),$3=a("li"),GEe=a("strong"),Dxr=o("roformer"),Gxr=o(" \u2014 "),uK=a("a"),Oxr=o("TFRoFormerForMultipleChoice"),Vxr=o(" (RoFormer model)"),Xxr=l(),k3=a("li"),OEe=a("strong"),zxr=o("xlm"),Qxr=o(" \u2014 "),bK=a("a"),Wxr=o("TFXLMForMultipleChoice"),Hxr=o(" (XLM model)"),Uxr=l(),S3=a("li"),VEe=a("strong"),Jxr=o("xlm-roberta"),Yxr=o(" \u2014 "),vK=a("a"),Kxr=o("TFXLMRobertaForMultipleChoice"),Zxr=o(" (XLM-RoBERTa model)"),e$r=l(),R3=a("li"),XEe=a("strong"),o$r=o("xlnet"),r$r=o(" \u2014 "),FK=a("a"),t$r=o("TFXLNetForMultipleChoice"),a$r=o(" (XLNet model)"),n$r=l(),F(P3.$$.fragment),zXe=l(),yc=a("h2"),B3=a("a"),zEe=a("span"),F(Ex.$$.fragment),s$r=l(),QEe=a("span"),l$r=o("TFAutoModelForNextSentencePrediction"),QXe=l(),dr=a("div"),F(Cx.$$.fragment),i$r=l(),xc=a("p"),d$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),TK=a("a"),c$r=o("from_pretrained()"),f$r=o(" class method or the "),MK=a("a"),m$r=o("from_config()"),g$r=o(` class
method.`),h$r=l(),wx=a("p"),p$r=o("This class cannot be instantiated directly using "),WEe=a("code"),_$r=o("__init__()"),u$r=o(" (throws an error)."),b$r=l(),jt=a("div"),F(Ax.$$.fragment),v$r=l(),HEe=a("p"),F$r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),T$r=l(),$c=a("p"),M$r=o(`Note:
Loading a model from its configuration file does `),UEe=a("strong"),E$r=o("not"),C$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=a("a"),w$r=o("from_pretrained()"),A$r=o(" to load the model weights."),L$r=l(),F(N3.$$.fragment),y$r=l(),Ir=a("div"),F(Lx.$$.fragment),x$r=l(),JEe=a("p"),$$r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),k$r=l(),pn=a("p"),S$r=o("The model class to instantiate is selected based on the "),YEe=a("code"),R$r=o("model_type"),P$r=o(` property of the config object (either
passed as an argument or loaded from `),KEe=a("code"),B$r=o("pretrained_model_name_or_path"),N$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZEe=a("code"),I$r=o("pretrained_model_name_or_path"),q$r=o(":"),j$r=l(),yx=a("ul"),I3=a("li"),eCe=a("strong"),D$r=o("bert"),G$r=o(" \u2014 "),CK=a("a"),O$r=o("TFBertForNextSentencePrediction"),V$r=o(" (BERT model)"),X$r=l(),q3=a("li"),oCe=a("strong"),z$r=o("mobilebert"),Q$r=o(" \u2014 "),wK=a("a"),W$r=o("TFMobileBertForNextSentencePrediction"),H$r=o(" (MobileBERT model)"),U$r=l(),F(j3.$$.fragment),WXe=l(),kc=a("h2"),D3=a("a"),rCe=a("span"),F(xx.$$.fragment),J$r=l(),tCe=a("span"),Y$r=o("TFAutoModelForTableQuestionAnswering"),HXe=l(),cr=a("div"),F($x.$$.fragment),K$r=l(),Sc=a("p"),Z$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),AK=a("a"),ekr=o("from_pretrained()"),okr=o(" class method or the "),LK=a("a"),rkr=o("from_config()"),tkr=o(` class
method.`),akr=l(),kx=a("p"),nkr=o("This class cannot be instantiated directly using "),aCe=a("code"),skr=o("__init__()"),lkr=o(" (throws an error)."),ikr=l(),Dt=a("div"),F(Sx.$$.fragment),dkr=l(),nCe=a("p"),ckr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),fkr=l(),Rc=a("p"),mkr=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),gkr=o("not"),hkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),pkr=o("from_pretrained()"),_kr=o(" to load the model weights."),ukr=l(),F(G3.$$.fragment),bkr=l(),qr=a("div"),F(Rx.$$.fragment),vkr=l(),lCe=a("p"),Fkr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Tkr=l(),_n=a("p"),Mkr=o("The model class to instantiate is selected based on the "),iCe=a("code"),Ekr=o("model_type"),Ckr=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),wkr=o("pretrained_model_name_or_path"),Akr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=a("code"),Lkr=o("pretrained_model_name_or_path"),ykr=o(":"),xkr=l(),fCe=a("ul"),O3=a("li"),mCe=a("strong"),$kr=o("tapas"),kkr=o(" \u2014 "),xK=a("a"),Skr=o("TFTapasForQuestionAnswering"),Rkr=o(" (TAPAS model)"),Pkr=l(),F(V3.$$.fragment),UXe=l(),Pc=a("h2"),X3=a("a"),gCe=a("span"),F(Px.$$.fragment),Bkr=l(),hCe=a("span"),Nkr=o("TFAutoModelForTokenClassification"),JXe=l(),fr=a("div"),F(Bx.$$.fragment),Ikr=l(),Bc=a("p"),qkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$K=a("a"),jkr=o("from_pretrained()"),Dkr=o(" class method or the "),kK=a("a"),Gkr=o("from_config()"),Okr=o(` class
method.`),Vkr=l(),Nx=a("p"),Xkr=o("This class cannot be instantiated directly using "),pCe=a("code"),zkr=o("__init__()"),Qkr=o(" (throws an error)."),Wkr=l(),Gt=a("div"),F(Ix.$$.fragment),Hkr=l(),_Ce=a("p"),Ukr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Jkr=l(),Nc=a("p"),Ykr=o(`Note:
Loading a model from its configuration file does `),uCe=a("strong"),Kkr=o("not"),Zkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),eSr=o("from_pretrained()"),oSr=o(" to load the model weights."),rSr=l(),F(z3.$$.fragment),tSr=l(),jr=a("div"),F(qx.$$.fragment),aSr=l(),bCe=a("p"),nSr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),sSr=l(),un=a("p"),lSr=o("The model class to instantiate is selected based on the "),vCe=a("code"),iSr=o("model_type"),dSr=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),cSr=o("pretrained_model_name_or_path"),fSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),mSr=o("pretrained_model_name_or_path"),gSr=o(":"),hSr=l(),de=a("ul"),Q3=a("li"),MCe=a("strong"),pSr=o("albert"),_Sr=o(" \u2014 "),RK=a("a"),uSr=o("TFAlbertForTokenClassification"),bSr=o(" (ALBERT model)"),vSr=l(),W3=a("li"),ECe=a("strong"),FSr=o("bert"),TSr=o(" \u2014 "),PK=a("a"),MSr=o("TFBertForTokenClassification"),ESr=o(" (BERT model)"),CSr=l(),H3=a("li"),CCe=a("strong"),wSr=o("camembert"),ASr=o(" \u2014 "),BK=a("a"),LSr=o("TFCamembertForTokenClassification"),ySr=o(" (CamemBERT model)"),xSr=l(),U3=a("li"),wCe=a("strong"),$Sr=o("convbert"),kSr=o(" \u2014 "),NK=a("a"),SSr=o("TFConvBertForTokenClassification"),RSr=o(" (ConvBERT model)"),PSr=l(),J3=a("li"),ACe=a("strong"),BSr=o("deberta"),NSr=o(" \u2014 "),IK=a("a"),ISr=o("TFDebertaForTokenClassification"),qSr=o(" (DeBERTa model)"),jSr=l(),Y3=a("li"),LCe=a("strong"),DSr=o("deberta-v2"),GSr=o(" \u2014 "),qK=a("a"),OSr=o("TFDebertaV2ForTokenClassification"),VSr=o(" (DeBERTa-v2 model)"),XSr=l(),K3=a("li"),yCe=a("strong"),zSr=o("distilbert"),QSr=o(" \u2014 "),jK=a("a"),WSr=o("TFDistilBertForTokenClassification"),HSr=o(" (DistilBERT model)"),USr=l(),Z3=a("li"),xCe=a("strong"),JSr=o("electra"),YSr=o(" \u2014 "),DK=a("a"),KSr=o("TFElectraForTokenClassification"),ZSr=o(" (ELECTRA model)"),eRr=l(),e5=a("li"),$Ce=a("strong"),oRr=o("flaubert"),rRr=o(" \u2014 "),GK=a("a"),tRr=o("TFFlaubertForTokenClassification"),aRr=o(" (FlauBERT model)"),nRr=l(),o5=a("li"),kCe=a("strong"),sRr=o("funnel"),lRr=o(" \u2014 "),OK=a("a"),iRr=o("TFFunnelForTokenClassification"),dRr=o(" (Funnel Transformer model)"),cRr=l(),r5=a("li"),SCe=a("strong"),fRr=o("layoutlm"),mRr=o(" \u2014 "),VK=a("a"),gRr=o("TFLayoutLMForTokenClassification"),hRr=o(" (LayoutLM model)"),pRr=l(),t5=a("li"),RCe=a("strong"),_Rr=o("longformer"),uRr=o(" \u2014 "),XK=a("a"),bRr=o("TFLongformerForTokenClassification"),vRr=o(" (Longformer model)"),FRr=l(),a5=a("li"),PCe=a("strong"),TRr=o("mobilebert"),MRr=o(" \u2014 "),zK=a("a"),ERr=o("TFMobileBertForTokenClassification"),CRr=o(" (MobileBERT model)"),wRr=l(),n5=a("li"),BCe=a("strong"),ARr=o("mpnet"),LRr=o(" \u2014 "),QK=a("a"),yRr=o("TFMPNetForTokenClassification"),xRr=o(" (MPNet model)"),$Rr=l(),s5=a("li"),NCe=a("strong"),kRr=o("rembert"),SRr=o(" \u2014 "),WK=a("a"),RRr=o("TFRemBertForTokenClassification"),PRr=o(" (RemBERT model)"),BRr=l(),l5=a("li"),ICe=a("strong"),NRr=o("roberta"),IRr=o(" \u2014 "),HK=a("a"),qRr=o("TFRobertaForTokenClassification"),jRr=o(" (RoBERTa model)"),DRr=l(),i5=a("li"),qCe=a("strong"),GRr=o("roformer"),ORr=o(" \u2014 "),UK=a("a"),VRr=o("TFRoFormerForTokenClassification"),XRr=o(" (RoFormer model)"),zRr=l(),d5=a("li"),jCe=a("strong"),QRr=o("xlm"),WRr=o(" \u2014 "),JK=a("a"),HRr=o("TFXLMForTokenClassification"),URr=o(" (XLM model)"),JRr=l(),c5=a("li"),DCe=a("strong"),YRr=o("xlm-roberta"),KRr=o(" \u2014 "),YK=a("a"),ZRr=o("TFXLMRobertaForTokenClassification"),ePr=o(" (XLM-RoBERTa model)"),oPr=l(),f5=a("li"),GCe=a("strong"),rPr=o("xlnet"),tPr=o(" \u2014 "),KK=a("a"),aPr=o("TFXLNetForTokenClassification"),nPr=o(" (XLNet model)"),sPr=l(),F(m5.$$.fragment),YXe=l(),Ic=a("h2"),g5=a("a"),OCe=a("span"),F(jx.$$.fragment),lPr=l(),VCe=a("span"),iPr=o("TFAutoModelForQuestionAnswering"),KXe=l(),mr=a("div"),F(Dx.$$.fragment),dPr=l(),qc=a("p"),cPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ZK=a("a"),fPr=o("from_pretrained()"),mPr=o(" class method or the "),eZ=a("a"),gPr=o("from_config()"),hPr=o(` class
method.`),pPr=l(),Gx=a("p"),_Pr=o("This class cannot be instantiated directly using "),XCe=a("code"),uPr=o("__init__()"),bPr=o(" (throws an error)."),vPr=l(),Ot=a("div"),F(Ox.$$.fragment),FPr=l(),zCe=a("p"),TPr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),MPr=l(),jc=a("p"),EPr=o(`Note:
Loading a model from its configuration file does `),QCe=a("strong"),CPr=o("not"),wPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),APr=o("from_pretrained()"),LPr=o(" to load the model weights."),yPr=l(),F(h5.$$.fragment),xPr=l(),Dr=a("div"),F(Vx.$$.fragment),$Pr=l(),WCe=a("p"),kPr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),SPr=l(),bn=a("p"),RPr=o("The model class to instantiate is selected based on the "),HCe=a("code"),PPr=o("model_type"),BPr=o(` property of the config object (either
passed as an argument or loaded from `),UCe=a("code"),NPr=o("pretrained_model_name_or_path"),IPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=a("code"),qPr=o("pretrained_model_name_or_path"),jPr=o(":"),DPr=l(),ce=a("ul"),p5=a("li"),YCe=a("strong"),GPr=o("albert"),OPr=o(" \u2014 "),rZ=a("a"),VPr=o("TFAlbertForQuestionAnswering"),XPr=o(" (ALBERT model)"),zPr=l(),_5=a("li"),KCe=a("strong"),QPr=o("bert"),WPr=o(" \u2014 "),tZ=a("a"),HPr=o("TFBertForQuestionAnswering"),UPr=o(" (BERT model)"),JPr=l(),u5=a("li"),ZCe=a("strong"),YPr=o("camembert"),KPr=o(" \u2014 "),aZ=a("a"),ZPr=o("TFCamembertForQuestionAnswering"),eBr=o(" (CamemBERT model)"),oBr=l(),b5=a("li"),e3e=a("strong"),rBr=o("convbert"),tBr=o(" \u2014 "),nZ=a("a"),aBr=o("TFConvBertForQuestionAnswering"),nBr=o(" (ConvBERT model)"),sBr=l(),v5=a("li"),o3e=a("strong"),lBr=o("deberta"),iBr=o(" \u2014 "),sZ=a("a"),dBr=o("TFDebertaForQuestionAnswering"),cBr=o(" (DeBERTa model)"),fBr=l(),F5=a("li"),r3e=a("strong"),mBr=o("deberta-v2"),gBr=o(" \u2014 "),lZ=a("a"),hBr=o("TFDebertaV2ForQuestionAnswering"),pBr=o(" (DeBERTa-v2 model)"),_Br=l(),T5=a("li"),t3e=a("strong"),uBr=o("distilbert"),bBr=o(" \u2014 "),iZ=a("a"),vBr=o("TFDistilBertForQuestionAnswering"),FBr=o(" (DistilBERT model)"),TBr=l(),M5=a("li"),a3e=a("strong"),MBr=o("electra"),EBr=o(" \u2014 "),dZ=a("a"),CBr=o("TFElectraForQuestionAnswering"),wBr=o(" (ELECTRA model)"),ABr=l(),E5=a("li"),n3e=a("strong"),LBr=o("flaubert"),yBr=o(" \u2014 "),cZ=a("a"),xBr=o("TFFlaubertForQuestionAnsweringSimple"),$Br=o(" (FlauBERT model)"),kBr=l(),C5=a("li"),s3e=a("strong"),SBr=o("funnel"),RBr=o(" \u2014 "),fZ=a("a"),PBr=o("TFFunnelForQuestionAnswering"),BBr=o(" (Funnel Transformer model)"),NBr=l(),w5=a("li"),l3e=a("strong"),IBr=o("gptj"),qBr=o(" \u2014 "),mZ=a("a"),jBr=o("TFGPTJForQuestionAnswering"),DBr=o(" (GPT-J model)"),GBr=l(),A5=a("li"),i3e=a("strong"),OBr=o("longformer"),VBr=o(" \u2014 "),gZ=a("a"),XBr=o("TFLongformerForQuestionAnswering"),zBr=o(" (Longformer model)"),QBr=l(),L5=a("li"),d3e=a("strong"),WBr=o("mobilebert"),HBr=o(" \u2014 "),hZ=a("a"),UBr=o("TFMobileBertForQuestionAnswering"),JBr=o(" (MobileBERT model)"),YBr=l(),y5=a("li"),c3e=a("strong"),KBr=o("mpnet"),ZBr=o(" \u2014 "),pZ=a("a"),eNr=o("TFMPNetForQuestionAnswering"),oNr=o(" (MPNet model)"),rNr=l(),x5=a("li"),f3e=a("strong"),tNr=o("rembert"),aNr=o(" \u2014 "),_Z=a("a"),nNr=o("TFRemBertForQuestionAnswering"),sNr=o(" (RemBERT model)"),lNr=l(),$5=a("li"),m3e=a("strong"),iNr=o("roberta"),dNr=o(" \u2014 "),uZ=a("a"),cNr=o("TFRobertaForQuestionAnswering"),fNr=o(" (RoBERTa model)"),mNr=l(),k5=a("li"),g3e=a("strong"),gNr=o("roformer"),hNr=o(" \u2014 "),bZ=a("a"),pNr=o("TFRoFormerForQuestionAnswering"),_Nr=o(" (RoFormer model)"),uNr=l(),S5=a("li"),h3e=a("strong"),bNr=o("xlm"),vNr=o(" \u2014 "),vZ=a("a"),FNr=o("TFXLMForQuestionAnsweringSimple"),TNr=o(" (XLM model)"),MNr=l(),R5=a("li"),p3e=a("strong"),ENr=o("xlm-roberta"),CNr=o(" \u2014 "),FZ=a("a"),wNr=o("TFXLMRobertaForQuestionAnswering"),ANr=o(" (XLM-RoBERTa model)"),LNr=l(),P5=a("li"),_3e=a("strong"),yNr=o("xlnet"),xNr=o(" \u2014 "),TZ=a("a"),$Nr=o("TFXLNetForQuestionAnsweringSimple"),kNr=o(" (XLNet model)"),SNr=l(),F(B5.$$.fragment),ZXe=l(),Dc=a("h2"),N5=a("a"),u3e=a("span"),F(Xx.$$.fragment),RNr=l(),b3e=a("span"),PNr=o("TFAutoModelForVision2Seq"),eze=l(),gr=a("div"),F(zx.$$.fragment),BNr=l(),Gc=a("p"),NNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),MZ=a("a"),INr=o("from_pretrained()"),qNr=o(" class method or the "),EZ=a("a"),jNr=o("from_config()"),DNr=o(` class
method.`),GNr=l(),Qx=a("p"),ONr=o("This class cannot be instantiated directly using "),v3e=a("code"),VNr=o("__init__()"),XNr=o(" (throws an error)."),zNr=l(),Vt=a("div"),F(Wx.$$.fragment),QNr=l(),F3e=a("p"),WNr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),HNr=l(),Oc=a("p"),UNr=o(`Note:
Loading a model from its configuration file does `),T3e=a("strong"),JNr=o("not"),YNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CZ=a("a"),KNr=o("from_pretrained()"),ZNr=o(" to load the model weights."),eIr=l(),F(I5.$$.fragment),oIr=l(),Gr=a("div"),F(Hx.$$.fragment),rIr=l(),M3e=a("p"),tIr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),aIr=l(),vn=a("p"),nIr=o("The model class to instantiate is selected based on the "),E3e=a("code"),sIr=o("model_type"),lIr=o(` property of the config object (either
passed as an argument or loaded from `),C3e=a("code"),iIr=o("pretrained_model_name_or_path"),dIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w3e=a("code"),cIr=o("pretrained_model_name_or_path"),fIr=o(":"),mIr=l(),A3e=a("ul"),q5=a("li"),L3e=a("strong"),gIr=o("vision-encoder-decoder"),hIr=o(" \u2014 "),wZ=a("a"),pIr=o("TFVisionEncoderDecoderModel"),_Ir=o(" (Vision Encoder decoder model)"),uIr=l(),F(j5.$$.fragment),oze=l(),Vc=a("h2"),D5=a("a"),y3e=a("span"),F(Ux.$$.fragment),bIr=l(),x3e=a("span"),vIr=o("TFAutoModelForSpeechSeq2Seq"),rze=l(),hr=a("div"),F(Jx.$$.fragment),FIr=l(),Xc=a("p"),TIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),AZ=a("a"),MIr=o("from_pretrained()"),EIr=o(" class method or the "),LZ=a("a"),CIr=o("from_config()"),wIr=o(` class
method.`),AIr=l(),Yx=a("p"),LIr=o("This class cannot be instantiated directly using "),$3e=a("code"),yIr=o("__init__()"),xIr=o(" (throws an error)."),$Ir=l(),Xt=a("div"),F(Kx.$$.fragment),kIr=l(),k3e=a("p"),SIr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),RIr=l(),zc=a("p"),PIr=o(`Note:
Loading a model from its configuration file does `),S3e=a("strong"),BIr=o("not"),NIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yZ=a("a"),IIr=o("from_pretrained()"),qIr=o(" to load the model weights."),jIr=l(),F(G5.$$.fragment),DIr=l(),Or=a("div"),F(Zx.$$.fragment),GIr=l(),R3e=a("p"),OIr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),VIr=l(),Fn=a("p"),XIr=o("The model class to instantiate is selected based on the "),P3e=a("code"),zIr=o("model_type"),QIr=o(` property of the config object (either
passed as an argument or loaded from `),B3e=a("code"),WIr=o("pretrained_model_name_or_path"),HIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N3e=a("code"),UIr=o("pretrained_model_name_or_path"),JIr=o(":"),YIr=l(),I3e=a("ul"),O5=a("li"),q3e=a("strong"),KIr=o("speech_to_text"),ZIr=o(" \u2014 "),xZ=a("a"),eqr=o("TFSpeech2TextForConditionalGeneration"),oqr=o(" (Speech2Text model)"),rqr=l(),F(V5.$$.fragment),tze=l(),Qc=a("h2"),X5=a("a"),j3e=a("span"),F(e$.$$.fragment),tqr=l(),D3e=a("span"),aqr=o("FlaxAutoModel"),aze=l(),pr=a("div"),F(o$.$$.fragment),nqr=l(),Wc=a("p"),sqr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),$Z=a("a"),lqr=o("from_pretrained()"),iqr=o(" class method or the "),kZ=a("a"),dqr=o("from_config()"),cqr=o(` class
method.`),fqr=l(),r$=a("p"),mqr=o("This class cannot be instantiated directly using "),G3e=a("code"),gqr=o("__init__()"),hqr=o(" (throws an error)."),pqr=l(),zt=a("div"),F(t$.$$.fragment),_qr=l(),O3e=a("p"),uqr=o("Instantiates one of the base model classes of the library from a configuration."),bqr=l(),Hc=a("p"),vqr=o(`Note:
Loading a model from its configuration file does `),V3e=a("strong"),Fqr=o("not"),Tqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SZ=a("a"),Mqr=o("from_pretrained()"),Eqr=o(" to load the model weights."),Cqr=l(),F(z5.$$.fragment),wqr=l(),Vr=a("div"),F(a$.$$.fragment),Aqr=l(),X3e=a("p"),Lqr=o("Instantiate one of the base model classes of the library from a pretrained model."),yqr=l(),Tn=a("p"),xqr=o("The model class to instantiate is selected based on the "),z3e=a("code"),$qr=o("model_type"),kqr=o(` property of the config object (either
passed as an argument or loaded from `),Q3e=a("code"),Sqr=o("pretrained_model_name_or_path"),Rqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W3e=a("code"),Pqr=o("pretrained_model_name_or_path"),Bqr=o(":"),Nqr=l(),oe=a("ul"),Q5=a("li"),H3e=a("strong"),Iqr=o("albert"),qqr=o(" \u2014 "),RZ=a("a"),jqr=o("FlaxAlbertModel"),Dqr=o(" (ALBERT model)"),Gqr=l(),W5=a("li"),U3e=a("strong"),Oqr=o("bart"),Vqr=o(" \u2014 "),PZ=a("a"),Xqr=o("FlaxBartModel"),zqr=o(" (BART model)"),Qqr=l(),H5=a("li"),J3e=a("strong"),Wqr=o("beit"),Hqr=o(" \u2014 "),BZ=a("a"),Uqr=o("FlaxBeitModel"),Jqr=o(" (BEiT model)"),Yqr=l(),U5=a("li"),Y3e=a("strong"),Kqr=o("bert"),Zqr=o(" \u2014 "),NZ=a("a"),ejr=o("FlaxBertModel"),ojr=o(" (BERT model)"),rjr=l(),J5=a("li"),K3e=a("strong"),tjr=o("big_bird"),ajr=o(" \u2014 "),IZ=a("a"),njr=o("FlaxBigBirdModel"),sjr=o(" (BigBird model)"),ljr=l(),Y5=a("li"),Z3e=a("strong"),ijr=o("blenderbot"),djr=o(" \u2014 "),qZ=a("a"),cjr=o("FlaxBlenderbotModel"),fjr=o(" (Blenderbot model)"),mjr=l(),K5=a("li"),e5e=a("strong"),gjr=o("blenderbot-small"),hjr=o(" \u2014 "),jZ=a("a"),pjr=o("FlaxBlenderbotSmallModel"),_jr=o(" (BlenderbotSmall model)"),ujr=l(),Z5=a("li"),o5e=a("strong"),bjr=o("clip"),vjr=o(" \u2014 "),DZ=a("a"),Fjr=o("FlaxCLIPModel"),Tjr=o(" (CLIP model)"),Mjr=l(),e0=a("li"),r5e=a("strong"),Ejr=o("distilbert"),Cjr=o(" \u2014 "),GZ=a("a"),wjr=o("FlaxDistilBertModel"),Ajr=o(" (DistilBERT model)"),Ljr=l(),o0=a("li"),t5e=a("strong"),yjr=o("electra"),xjr=o(" \u2014 "),OZ=a("a"),$jr=o("FlaxElectraModel"),kjr=o(" (ELECTRA model)"),Sjr=l(),r0=a("li"),a5e=a("strong"),Rjr=o("gpt2"),Pjr=o(" \u2014 "),VZ=a("a"),Bjr=o("FlaxGPT2Model"),Njr=o(" (OpenAI GPT-2 model)"),Ijr=l(),t0=a("li"),n5e=a("strong"),qjr=o("gpt_neo"),jjr=o(" \u2014 "),XZ=a("a"),Djr=o("FlaxGPTNeoModel"),Gjr=o(" (GPT Neo model)"),Ojr=l(),a0=a("li"),s5e=a("strong"),Vjr=o("gptj"),Xjr=o(" \u2014 "),zZ=a("a"),zjr=o("FlaxGPTJModel"),Qjr=o(" (GPT-J model)"),Wjr=l(),n0=a("li"),l5e=a("strong"),Hjr=o("longt5"),Ujr=o(" \u2014 "),QZ=a("a"),Jjr=o("FlaxLongT5Model"),Yjr=o(" (LongT5 model)"),Kjr=l(),s0=a("li"),i5e=a("strong"),Zjr=o("marian"),eDr=o(" \u2014 "),WZ=a("a"),oDr=o("FlaxMarianModel"),rDr=o(" (Marian model)"),tDr=l(),l0=a("li"),d5e=a("strong"),aDr=o("mbart"),nDr=o(" \u2014 "),HZ=a("a"),sDr=o("FlaxMBartModel"),lDr=o(" (mBART model)"),iDr=l(),i0=a("li"),c5e=a("strong"),dDr=o("mt5"),cDr=o(" \u2014 "),UZ=a("a"),fDr=o("FlaxMT5Model"),mDr=o(" (MT5 model)"),gDr=l(),d0=a("li"),f5e=a("strong"),hDr=o("opt"),pDr=o(" \u2014 "),JZ=a("a"),_Dr=o("FlaxOPTModel"),uDr=o(" (OPT model)"),bDr=l(),c0=a("li"),m5e=a("strong"),vDr=o("pegasus"),FDr=o(" \u2014 "),YZ=a("a"),TDr=o("FlaxPegasusModel"),MDr=o(" (Pegasus model)"),EDr=l(),f0=a("li"),g5e=a("strong"),CDr=o("roberta"),wDr=o(" \u2014 "),KZ=a("a"),ADr=o("FlaxRobertaModel"),LDr=o(" (RoBERTa model)"),yDr=l(),m0=a("li"),h5e=a("strong"),xDr=o("roformer"),$Dr=o(" \u2014 "),ZZ=a("a"),kDr=o("FlaxRoFormerModel"),SDr=o(" (RoFormer model)"),RDr=l(),g0=a("li"),p5e=a("strong"),PDr=o("t5"),BDr=o(" \u2014 "),eee=a("a"),NDr=o("FlaxT5Model"),IDr=o(" (T5 model)"),qDr=l(),h0=a("li"),_5e=a("strong"),jDr=o("vision-text-dual-encoder"),DDr=o(" \u2014 "),oee=a("a"),GDr=o("FlaxVisionTextDualEncoderModel"),ODr=o(" (VisionTextDualEncoder model)"),VDr=l(),p0=a("li"),u5e=a("strong"),XDr=o("vit"),zDr=o(" \u2014 "),ree=a("a"),QDr=o("FlaxViTModel"),WDr=o(" (ViT model)"),HDr=l(),_0=a("li"),b5e=a("strong"),UDr=o("wav2vec2"),JDr=o(" \u2014 "),tee=a("a"),YDr=o("FlaxWav2Vec2Model"),KDr=o(" (Wav2Vec2 model)"),ZDr=l(),u0=a("li"),v5e=a("strong"),eGr=o("xglm"),oGr=o(" \u2014 "),aee=a("a"),rGr=o("FlaxXGLMModel"),tGr=o(" (XGLM model)"),aGr=l(),b0=a("li"),F5e=a("strong"),nGr=o("xlm-roberta"),sGr=o(" \u2014 "),nee=a("a"),lGr=o("FlaxXLMRobertaModel"),iGr=o(" (XLM-RoBERTa model)"),dGr=l(),F(v0.$$.fragment),nze=l(),Uc=a("h2"),F0=a("a"),T5e=a("span"),F(n$.$$.fragment),cGr=l(),M5e=a("span"),fGr=o("FlaxAutoModelForCausalLM"),sze=l(),_r=a("div"),F(s$.$$.fragment),mGr=l(),Jc=a("p"),gGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),see=a("a"),hGr=o("from_pretrained()"),pGr=o(" class method or the "),lee=a("a"),_Gr=o("from_config()"),uGr=o(` class
method.`),bGr=l(),l$=a("p"),vGr=o("This class cannot be instantiated directly using "),E5e=a("code"),FGr=o("__init__()"),TGr=o(" (throws an error)."),MGr=l(),Qt=a("div"),F(i$.$$.fragment),EGr=l(),C5e=a("p"),CGr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),wGr=l(),Yc=a("p"),AGr=o(`Note:
Loading a model from its configuration file does `),w5e=a("strong"),LGr=o("not"),yGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iee=a("a"),xGr=o("from_pretrained()"),$Gr=o(" to load the model weights."),kGr=l(),F(T0.$$.fragment),SGr=l(),Xr=a("div"),F(d$.$$.fragment),RGr=l(),A5e=a("p"),PGr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),BGr=l(),Mn=a("p"),NGr=o("The model class to instantiate is selected based on the "),L5e=a("code"),IGr=o("model_type"),qGr=o(` property of the config object (either
passed as an argument or loaded from `),y5e=a("code"),jGr=o("pretrained_model_name_or_path"),DGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=a("code"),GGr=o("pretrained_model_name_or_path"),OGr=o(":"),VGr=l(),xe=a("ul"),M0=a("li"),$5e=a("strong"),XGr=o("bart"),zGr=o(" \u2014 "),dee=a("a"),QGr=o("FlaxBartForCausalLM"),WGr=o(" (BART model)"),HGr=l(),E0=a("li"),k5e=a("strong"),UGr=o("bert"),JGr=o(" \u2014 "),cee=a("a"),YGr=o("FlaxBertForCausalLM"),KGr=o(" (BERT model)"),ZGr=l(),C0=a("li"),S5e=a("strong"),eOr=o("big_bird"),oOr=o(" \u2014 "),fee=a("a"),rOr=o("FlaxBigBirdForCausalLM"),tOr=o(" (BigBird model)"),aOr=l(),w0=a("li"),R5e=a("strong"),nOr=o("electra"),sOr=o(" \u2014 "),mee=a("a"),lOr=o("FlaxElectraForCausalLM"),iOr=o(" (ELECTRA model)"),dOr=l(),A0=a("li"),P5e=a("strong"),cOr=o("gpt2"),fOr=o(" \u2014 "),gee=a("a"),mOr=o("FlaxGPT2LMHeadModel"),gOr=o(" (OpenAI GPT-2 model)"),hOr=l(),L0=a("li"),B5e=a("strong"),pOr=o("gpt_neo"),_Or=o(" \u2014 "),hee=a("a"),uOr=o("FlaxGPTNeoForCausalLM"),bOr=o(" (GPT Neo model)"),vOr=l(),y0=a("li"),N5e=a("strong"),FOr=o("gptj"),TOr=o(" \u2014 "),pee=a("a"),MOr=o("FlaxGPTJForCausalLM"),EOr=o(" (GPT-J model)"),COr=l(),x0=a("li"),I5e=a("strong"),wOr=o("opt"),AOr=o(" \u2014 "),_ee=a("a"),LOr=o("FlaxOPTForCausalLM"),yOr=o(" (OPT model)"),xOr=l(),$0=a("li"),q5e=a("strong"),$Or=o("roberta"),kOr=o(" \u2014 "),uee=a("a"),SOr=o("FlaxRobertaForCausalLM"),ROr=o(" (RoBERTa model)"),POr=l(),k0=a("li"),j5e=a("strong"),BOr=o("xglm"),NOr=o(" \u2014 "),bee=a("a"),IOr=o("FlaxXGLMForCausalLM"),qOr=o(" (XGLM model)"),jOr=l(),F(S0.$$.fragment),lze=l(),Kc=a("h2"),R0=a("a"),D5e=a("span"),F(c$.$$.fragment),DOr=l(),G5e=a("span"),GOr=o("FlaxAutoModelForPreTraining"),ize=l(),ur=a("div"),F(f$.$$.fragment),OOr=l(),Zc=a("p"),VOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),vee=a("a"),XOr=o("from_pretrained()"),zOr=o(" class method or the "),Fee=a("a"),QOr=o("from_config()"),WOr=o(` class
method.`),HOr=l(),m$=a("p"),UOr=o("This class cannot be instantiated directly using "),O5e=a("code"),JOr=o("__init__()"),YOr=o(" (throws an error)."),KOr=l(),Wt=a("div"),F(g$.$$.fragment),ZOr=l(),V5e=a("p"),eVr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),oVr=l(),ef=a("p"),rVr=o(`Note:
Loading a model from its configuration file does `),X5e=a("strong"),tVr=o("not"),aVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tee=a("a"),nVr=o("from_pretrained()"),sVr=o(" to load the model weights."),lVr=l(),F(P0.$$.fragment),iVr=l(),zr=a("div"),F(h$.$$.fragment),dVr=l(),z5e=a("p"),cVr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),fVr=l(),En=a("p"),mVr=o("The model class to instantiate is selected based on the "),Q5e=a("code"),gVr=o("model_type"),hVr=o(` property of the config object (either
passed as an argument or loaded from `),W5e=a("code"),pVr=o("pretrained_model_name_or_path"),_Vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H5e=a("code"),uVr=o("pretrained_model_name_or_path"),bVr=o(":"),vVr=l(),Ee=a("ul"),B0=a("li"),U5e=a("strong"),FVr=o("albert"),TVr=o(" \u2014 "),Mee=a("a"),MVr=o("FlaxAlbertForPreTraining"),EVr=o(" (ALBERT model)"),CVr=l(),N0=a("li"),J5e=a("strong"),wVr=o("bart"),AVr=o(" \u2014 "),Eee=a("a"),LVr=o("FlaxBartForConditionalGeneration"),yVr=o(" (BART model)"),xVr=l(),I0=a("li"),Y5e=a("strong"),$Vr=o("bert"),kVr=o(" \u2014 "),Cee=a("a"),SVr=o("FlaxBertForPreTraining"),RVr=o(" (BERT model)"),PVr=l(),q0=a("li"),K5e=a("strong"),BVr=o("big_bird"),NVr=o(" \u2014 "),wee=a("a"),IVr=o("FlaxBigBirdForPreTraining"),qVr=o(" (BigBird model)"),jVr=l(),j0=a("li"),Z5e=a("strong"),DVr=o("electra"),GVr=o(" \u2014 "),Aee=a("a"),OVr=o("FlaxElectraForPreTraining"),VVr=o(" (ELECTRA model)"),XVr=l(),D0=a("li"),e0e=a("strong"),zVr=o("longt5"),QVr=o(" \u2014 "),Lee=a("a"),WVr=o("FlaxLongT5ForConditionalGeneration"),HVr=o(" (LongT5 model)"),UVr=l(),G0=a("li"),o0e=a("strong"),JVr=o("mbart"),YVr=o(" \u2014 "),yee=a("a"),KVr=o("FlaxMBartForConditionalGeneration"),ZVr=o(" (mBART model)"),eXr=l(),O0=a("li"),r0e=a("strong"),oXr=o("mt5"),rXr=o(" \u2014 "),xee=a("a"),tXr=o("FlaxMT5ForConditionalGeneration"),aXr=o(" (MT5 model)"),nXr=l(),V0=a("li"),t0e=a("strong"),sXr=o("roberta"),lXr=o(" \u2014 "),$ee=a("a"),iXr=o("FlaxRobertaForMaskedLM"),dXr=o(" (RoBERTa model)"),cXr=l(),X0=a("li"),a0e=a("strong"),fXr=o("roformer"),mXr=o(" \u2014 "),kee=a("a"),gXr=o("FlaxRoFormerForMaskedLM"),hXr=o(" (RoFormer model)"),pXr=l(),z0=a("li"),n0e=a("strong"),_Xr=o("t5"),uXr=o(" \u2014 "),See=a("a"),bXr=o("FlaxT5ForConditionalGeneration"),vXr=o(" (T5 model)"),FXr=l(),Q0=a("li"),s0e=a("strong"),TXr=o("wav2vec2"),MXr=o(" \u2014 "),Ree=a("a"),EXr=o("FlaxWav2Vec2ForPreTraining"),CXr=o(" (Wav2Vec2 model)"),wXr=l(),W0=a("li"),l0e=a("strong"),AXr=o("xlm-roberta"),LXr=o(" \u2014 "),Pee=a("a"),yXr=o("FlaxXLMRobertaForMaskedLM"),xXr=o(" (XLM-RoBERTa model)"),$Xr=l(),F(H0.$$.fragment),dze=l(),of=a("h2"),U0=a("a"),i0e=a("span"),F(p$.$$.fragment),kXr=l(),d0e=a("span"),SXr=o("FlaxAutoModelForMaskedLM"),cze=l(),br=a("div"),F(_$.$$.fragment),RXr=l(),rf=a("p"),PXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Bee=a("a"),BXr=o("from_pretrained()"),NXr=o(" class method or the "),Nee=a("a"),IXr=o("from_config()"),qXr=o(` class
method.`),jXr=l(),u$=a("p"),DXr=o("This class cannot be instantiated directly using "),c0e=a("code"),GXr=o("__init__()"),OXr=o(" (throws an error)."),VXr=l(),Ht=a("div"),F(b$.$$.fragment),XXr=l(),f0e=a("p"),zXr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),QXr=l(),tf=a("p"),WXr=o(`Note:
Loading a model from its configuration file does `),m0e=a("strong"),HXr=o("not"),UXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=a("a"),JXr=o("from_pretrained()"),YXr=o(" to load the model weights."),KXr=l(),F(J0.$$.fragment),ZXr=l(),Qr=a("div"),F(v$.$$.fragment),ezr=l(),g0e=a("p"),ozr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),rzr=l(),Cn=a("p"),tzr=o("The model class to instantiate is selected based on the "),h0e=a("code"),azr=o("model_type"),nzr=o(` property of the config object (either
passed as an argument or loaded from `),p0e=a("code"),szr=o("pretrained_model_name_or_path"),lzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=a("code"),izr=o("pretrained_model_name_or_path"),dzr=o(":"),czr=l(),$e=a("ul"),Y0=a("li"),u0e=a("strong"),fzr=o("albert"),mzr=o(" \u2014 "),qee=a("a"),gzr=o("FlaxAlbertForMaskedLM"),hzr=o(" (ALBERT model)"),pzr=l(),K0=a("li"),b0e=a("strong"),_zr=o("bart"),uzr=o(" \u2014 "),jee=a("a"),bzr=o("FlaxBartForConditionalGeneration"),vzr=o(" (BART model)"),Fzr=l(),Z0=a("li"),v0e=a("strong"),Tzr=o("bert"),Mzr=o(" \u2014 "),Dee=a("a"),Ezr=o("FlaxBertForMaskedLM"),Czr=o(" (BERT model)"),wzr=l(),ew=a("li"),F0e=a("strong"),Azr=o("big_bird"),Lzr=o(" \u2014 "),Gee=a("a"),yzr=o("FlaxBigBirdForMaskedLM"),xzr=o(" (BigBird model)"),$zr=l(),ow=a("li"),T0e=a("strong"),kzr=o("distilbert"),Szr=o(" \u2014 "),Oee=a("a"),Rzr=o("FlaxDistilBertForMaskedLM"),Pzr=o(" (DistilBERT model)"),Bzr=l(),rw=a("li"),M0e=a("strong"),Nzr=o("electra"),Izr=o(" \u2014 "),Vee=a("a"),qzr=o("FlaxElectraForMaskedLM"),jzr=o(" (ELECTRA model)"),Dzr=l(),tw=a("li"),E0e=a("strong"),Gzr=o("mbart"),Ozr=o(" \u2014 "),Xee=a("a"),Vzr=o("FlaxMBartForConditionalGeneration"),Xzr=o(" (mBART model)"),zzr=l(),aw=a("li"),C0e=a("strong"),Qzr=o("roberta"),Wzr=o(" \u2014 "),zee=a("a"),Hzr=o("FlaxRobertaForMaskedLM"),Uzr=o(" (RoBERTa model)"),Jzr=l(),nw=a("li"),w0e=a("strong"),Yzr=o("roformer"),Kzr=o(" \u2014 "),Qee=a("a"),Zzr=o("FlaxRoFormerForMaskedLM"),eQr=o(" (RoFormer model)"),oQr=l(),sw=a("li"),A0e=a("strong"),rQr=o("xlm-roberta"),tQr=o(" \u2014 "),Wee=a("a"),aQr=o("FlaxXLMRobertaForMaskedLM"),nQr=o(" (XLM-RoBERTa model)"),sQr=l(),F(lw.$$.fragment),fze=l(),af=a("h2"),iw=a("a"),L0e=a("span"),F(F$.$$.fragment),lQr=l(),y0e=a("span"),iQr=o("FlaxAutoModelForSeq2SeqLM"),mze=l(),vr=a("div"),F(T$.$$.fragment),dQr=l(),nf=a("p"),cQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Hee=a("a"),fQr=o("from_pretrained()"),mQr=o(" class method or the "),Uee=a("a"),gQr=o("from_config()"),hQr=o(` class
method.`),pQr=l(),M$=a("p"),_Qr=o("This class cannot be instantiated directly using "),x0e=a("code"),uQr=o("__init__()"),bQr=o(" (throws an error)."),vQr=l(),Ut=a("div"),F(E$.$$.fragment),FQr=l(),$0e=a("p"),TQr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),MQr=l(),sf=a("p"),EQr=o(`Note:
Loading a model from its configuration file does `),k0e=a("strong"),CQr=o("not"),wQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),AQr=o("from_pretrained()"),LQr=o(" to load the model weights."),yQr=l(),F(dw.$$.fragment),xQr=l(),Wr=a("div"),F(C$.$$.fragment),$Qr=l(),S0e=a("p"),kQr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),SQr=l(),wn=a("p"),RQr=o("The model class to instantiate is selected based on the "),R0e=a("code"),PQr=o("model_type"),BQr=o(` property of the config object (either
passed as an argument or loaded from `),P0e=a("code"),NQr=o("pretrained_model_name_or_path"),IQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B0e=a("code"),qQr=o("pretrained_model_name_or_path"),jQr=o(":"),DQr=l(),ke=a("ul"),cw=a("li"),N0e=a("strong"),GQr=o("bart"),OQr=o(" \u2014 "),Yee=a("a"),VQr=o("FlaxBartForConditionalGeneration"),XQr=o(" (BART model)"),zQr=l(),fw=a("li"),I0e=a("strong"),QQr=o("blenderbot"),WQr=o(" \u2014 "),Kee=a("a"),HQr=o("FlaxBlenderbotForConditionalGeneration"),UQr=o(" (Blenderbot model)"),JQr=l(),mw=a("li"),q0e=a("strong"),YQr=o("blenderbot-small"),KQr=o(" \u2014 "),Zee=a("a"),ZQr=o("FlaxBlenderbotSmallForConditionalGeneration"),eWr=o(" (BlenderbotSmall model)"),oWr=l(),gw=a("li"),j0e=a("strong"),rWr=o("encoder-decoder"),tWr=o(" \u2014 "),eoe=a("a"),aWr=o("FlaxEncoderDecoderModel"),nWr=o(" (Encoder decoder model)"),sWr=l(),hw=a("li"),D0e=a("strong"),lWr=o("longt5"),iWr=o(" \u2014 "),ooe=a("a"),dWr=o("FlaxLongT5ForConditionalGeneration"),cWr=o(" (LongT5 model)"),fWr=l(),pw=a("li"),G0e=a("strong"),mWr=o("marian"),gWr=o(" \u2014 "),roe=a("a"),hWr=o("FlaxMarianMTModel"),pWr=o(" (Marian model)"),_Wr=l(),_w=a("li"),O0e=a("strong"),uWr=o("mbart"),bWr=o(" \u2014 "),toe=a("a"),vWr=o("FlaxMBartForConditionalGeneration"),FWr=o(" (mBART model)"),TWr=l(),uw=a("li"),V0e=a("strong"),MWr=o("mt5"),EWr=o(" \u2014 "),aoe=a("a"),CWr=o("FlaxMT5ForConditionalGeneration"),wWr=o(" (MT5 model)"),AWr=l(),bw=a("li"),X0e=a("strong"),LWr=o("pegasus"),yWr=o(" \u2014 "),noe=a("a"),xWr=o("FlaxPegasusForConditionalGeneration"),$Wr=o(" (Pegasus model)"),kWr=l(),vw=a("li"),z0e=a("strong"),SWr=o("t5"),RWr=o(" \u2014 "),soe=a("a"),PWr=o("FlaxT5ForConditionalGeneration"),BWr=o(" (T5 model)"),NWr=l(),F(Fw.$$.fragment),gze=l(),lf=a("h2"),Tw=a("a"),Q0e=a("span"),F(w$.$$.fragment),IWr=l(),W0e=a("span"),qWr=o("FlaxAutoModelForSequenceClassification"),hze=l(),Fr=a("div"),F(A$.$$.fragment),jWr=l(),df=a("p"),DWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),loe=a("a"),GWr=o("from_pretrained()"),OWr=o(" class method or the "),ioe=a("a"),VWr=o("from_config()"),XWr=o(` class
method.`),zWr=l(),L$=a("p"),QWr=o("This class cannot be instantiated directly using "),H0e=a("code"),WWr=o("__init__()"),HWr=o(" (throws an error)."),UWr=l(),Jt=a("div"),F(y$.$$.fragment),JWr=l(),U0e=a("p"),YWr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),KWr=l(),cf=a("p"),ZWr=o(`Note:
Loading a model from its configuration file does `),J0e=a("strong"),eHr=o("not"),oHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=a("a"),rHr=o("from_pretrained()"),tHr=o(" to load the model weights."),aHr=l(),F(Mw.$$.fragment),nHr=l(),Hr=a("div"),F(x$.$$.fragment),sHr=l(),Y0e=a("p"),lHr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),iHr=l(),An=a("p"),dHr=o("The model class to instantiate is selected based on the "),K0e=a("code"),cHr=o("model_type"),fHr=o(` property of the config object (either
passed as an argument or loaded from `),Z0e=a("code"),mHr=o("pretrained_model_name_or_path"),gHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=a("code"),hHr=o("pretrained_model_name_or_path"),pHr=o(":"),_Hr=l(),Se=a("ul"),Ew=a("li"),owe=a("strong"),uHr=o("albert"),bHr=o(" \u2014 "),coe=a("a"),vHr=o("FlaxAlbertForSequenceClassification"),FHr=o(" (ALBERT model)"),THr=l(),Cw=a("li"),rwe=a("strong"),MHr=o("bart"),EHr=o(" \u2014 "),foe=a("a"),CHr=o("FlaxBartForSequenceClassification"),wHr=o(" (BART model)"),AHr=l(),ww=a("li"),twe=a("strong"),LHr=o("bert"),yHr=o(" \u2014 "),moe=a("a"),xHr=o("FlaxBertForSequenceClassification"),$Hr=o(" (BERT model)"),kHr=l(),Aw=a("li"),awe=a("strong"),SHr=o("big_bird"),RHr=o(" \u2014 "),goe=a("a"),PHr=o("FlaxBigBirdForSequenceClassification"),BHr=o(" (BigBird model)"),NHr=l(),Lw=a("li"),nwe=a("strong"),IHr=o("distilbert"),qHr=o(" \u2014 "),hoe=a("a"),jHr=o("FlaxDistilBertForSequenceClassification"),DHr=o(" (DistilBERT model)"),GHr=l(),yw=a("li"),swe=a("strong"),OHr=o("electra"),VHr=o(" \u2014 "),poe=a("a"),XHr=o("FlaxElectraForSequenceClassification"),zHr=o(" (ELECTRA model)"),QHr=l(),xw=a("li"),lwe=a("strong"),WHr=o("mbart"),HHr=o(" \u2014 "),_oe=a("a"),UHr=o("FlaxMBartForSequenceClassification"),JHr=o(" (mBART model)"),YHr=l(),$w=a("li"),iwe=a("strong"),KHr=o("roberta"),ZHr=o(" \u2014 "),uoe=a("a"),eUr=o("FlaxRobertaForSequenceClassification"),oUr=o(" (RoBERTa model)"),rUr=l(),kw=a("li"),dwe=a("strong"),tUr=o("roformer"),aUr=o(" \u2014 "),boe=a("a"),nUr=o("FlaxRoFormerForSequenceClassification"),sUr=o(" (RoFormer model)"),lUr=l(),Sw=a("li"),cwe=a("strong"),iUr=o("xlm-roberta"),dUr=o(" \u2014 "),voe=a("a"),cUr=o("FlaxXLMRobertaForSequenceClassification"),fUr=o(" (XLM-RoBERTa model)"),mUr=l(),F(Rw.$$.fragment),pze=l(),ff=a("h2"),Pw=a("a"),fwe=a("span"),F($$.$$.fragment),gUr=l(),mwe=a("span"),hUr=o("FlaxAutoModelForQuestionAnswering"),_ze=l(),Tr=a("div"),F(k$.$$.fragment),pUr=l(),mf=a("p"),_Ur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Foe=a("a"),uUr=o("from_pretrained()"),bUr=o(" class method or the "),Toe=a("a"),vUr=o("from_config()"),FUr=o(` class
method.`),TUr=l(),S$=a("p"),MUr=o("This class cannot be instantiated directly using "),gwe=a("code"),EUr=o("__init__()"),CUr=o(" (throws an error)."),wUr=l(),Yt=a("div"),F(R$.$$.fragment),AUr=l(),hwe=a("p"),LUr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),yUr=l(),gf=a("p"),xUr=o(`Note:
Loading a model from its configuration file does `),pwe=a("strong"),$Ur=o("not"),kUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Moe=a("a"),SUr=o("from_pretrained()"),RUr=o(" to load the model weights."),PUr=l(),F(Bw.$$.fragment),BUr=l(),Ur=a("div"),F(P$.$$.fragment),NUr=l(),_we=a("p"),IUr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),qUr=l(),Ln=a("p"),jUr=o("The model class to instantiate is selected based on the "),uwe=a("code"),DUr=o("model_type"),GUr=o(` property of the config object (either
passed as an argument or loaded from `),bwe=a("code"),OUr=o("pretrained_model_name_or_path"),VUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vwe=a("code"),XUr=o("pretrained_model_name_or_path"),zUr=o(":"),QUr=l(),Re=a("ul"),Nw=a("li"),Fwe=a("strong"),WUr=o("albert"),HUr=o(" \u2014 "),Eoe=a("a"),UUr=o("FlaxAlbertForQuestionAnswering"),JUr=o(" (ALBERT model)"),YUr=l(),Iw=a("li"),Twe=a("strong"),KUr=o("bart"),ZUr=o(" \u2014 "),Coe=a("a"),eJr=o("FlaxBartForQuestionAnswering"),oJr=o(" (BART model)"),rJr=l(),qw=a("li"),Mwe=a("strong"),tJr=o("bert"),aJr=o(" \u2014 "),woe=a("a"),nJr=o("FlaxBertForQuestionAnswering"),sJr=o(" (BERT model)"),lJr=l(),jw=a("li"),Ewe=a("strong"),iJr=o("big_bird"),dJr=o(" \u2014 "),Aoe=a("a"),cJr=o("FlaxBigBirdForQuestionAnswering"),fJr=o(" (BigBird model)"),mJr=l(),Dw=a("li"),Cwe=a("strong"),gJr=o("distilbert"),hJr=o(" \u2014 "),Loe=a("a"),pJr=o("FlaxDistilBertForQuestionAnswering"),_Jr=o(" (DistilBERT model)"),uJr=l(),Gw=a("li"),wwe=a("strong"),bJr=o("electra"),vJr=o(" \u2014 "),yoe=a("a"),FJr=o("FlaxElectraForQuestionAnswering"),TJr=o(" (ELECTRA model)"),MJr=l(),Ow=a("li"),Awe=a("strong"),EJr=o("mbart"),CJr=o(" \u2014 "),xoe=a("a"),wJr=o("FlaxMBartForQuestionAnswering"),AJr=o(" (mBART model)"),LJr=l(),Vw=a("li"),Lwe=a("strong"),yJr=o("roberta"),xJr=o(" \u2014 "),$oe=a("a"),$Jr=o("FlaxRobertaForQuestionAnswering"),kJr=o(" (RoBERTa model)"),SJr=l(),Xw=a("li"),ywe=a("strong"),RJr=o("roformer"),PJr=o(" \u2014 "),koe=a("a"),BJr=o("FlaxRoFormerForQuestionAnswering"),NJr=o(" (RoFormer model)"),IJr=l(),zw=a("li"),xwe=a("strong"),qJr=o("xlm-roberta"),jJr=o(" \u2014 "),Soe=a("a"),DJr=o("FlaxXLMRobertaForQuestionAnswering"),GJr=o(" (XLM-RoBERTa model)"),OJr=l(),F(Qw.$$.fragment),uze=l(),hf=a("h2"),Ww=a("a"),$we=a("span"),F(B$.$$.fragment),VJr=l(),kwe=a("span"),XJr=o("FlaxAutoModelForTokenClassification"),bze=l(),Mr=a("div"),F(N$.$$.fragment),zJr=l(),pf=a("p"),QJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Roe=a("a"),WJr=o("from_pretrained()"),HJr=o(" class method or the "),Poe=a("a"),UJr=o("from_config()"),JJr=o(` class
method.`),YJr=l(),I$=a("p"),KJr=o("This class cannot be instantiated directly using "),Swe=a("code"),ZJr=o("__init__()"),eYr=o(" (throws an error)."),oYr=l(),Kt=a("div"),F(q$.$$.fragment),rYr=l(),Rwe=a("p"),tYr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),aYr=l(),_f=a("p"),nYr=o(`Note:
Loading a model from its configuration file does `),Pwe=a("strong"),sYr=o("not"),lYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Boe=a("a"),iYr=o("from_pretrained()"),dYr=o(" to load the model weights."),cYr=l(),F(Hw.$$.fragment),fYr=l(),Jr=a("div"),F(j$.$$.fragment),mYr=l(),Bwe=a("p"),gYr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),hYr=l(),yn=a("p"),pYr=o("The model class to instantiate is selected based on the "),Nwe=a("code"),_Yr=o("model_type"),uYr=o(` property of the config object (either
passed as an argument or loaded from `),Iwe=a("code"),bYr=o("pretrained_model_name_or_path"),vYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qwe=a("code"),FYr=o("pretrained_model_name_or_path"),TYr=o(":"),MYr=l(),Ve=a("ul"),Uw=a("li"),jwe=a("strong"),EYr=o("albert"),CYr=o(" \u2014 "),Noe=a("a"),wYr=o("FlaxAlbertForTokenClassification"),AYr=o(" (ALBERT model)"),LYr=l(),Jw=a("li"),Dwe=a("strong"),yYr=o("bert"),xYr=o(" \u2014 "),Ioe=a("a"),$Yr=o("FlaxBertForTokenClassification"),kYr=o(" (BERT model)"),SYr=l(),Yw=a("li"),Gwe=a("strong"),RYr=o("big_bird"),PYr=o(" \u2014 "),qoe=a("a"),BYr=o("FlaxBigBirdForTokenClassification"),NYr=o(" (BigBird model)"),IYr=l(),Kw=a("li"),Owe=a("strong"),qYr=o("distilbert"),jYr=o(" \u2014 "),joe=a("a"),DYr=o("FlaxDistilBertForTokenClassification"),GYr=o(" (DistilBERT model)"),OYr=l(),Zw=a("li"),Vwe=a("strong"),VYr=o("electra"),XYr=o(" \u2014 "),Doe=a("a"),zYr=o("FlaxElectraForTokenClassification"),QYr=o(" (ELECTRA model)"),WYr=l(),eA=a("li"),Xwe=a("strong"),HYr=o("roberta"),UYr=o(" \u2014 "),Goe=a("a"),JYr=o("FlaxRobertaForTokenClassification"),YYr=o(" (RoBERTa model)"),KYr=l(),oA=a("li"),zwe=a("strong"),ZYr=o("roformer"),eKr=o(" \u2014 "),Ooe=a("a"),oKr=o("FlaxRoFormerForTokenClassification"),rKr=o(" (RoFormer model)"),tKr=l(),rA=a("li"),Qwe=a("strong"),aKr=o("xlm-roberta"),nKr=o(" \u2014 "),Voe=a("a"),sKr=o("FlaxXLMRobertaForTokenClassification"),lKr=o(" (XLM-RoBERTa model)"),iKr=l(),F(tA.$$.fragment),vze=l(),uf=a("h2"),aA=a("a"),Wwe=a("span"),F(D$.$$.fragment),dKr=l(),Hwe=a("span"),cKr=o("FlaxAutoModelForMultipleChoice"),Fze=l(),Er=a("div"),F(G$.$$.fragment),fKr=l(),bf=a("p"),mKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Xoe=a("a"),gKr=o("from_pretrained()"),hKr=o(" class method or the "),zoe=a("a"),pKr=o("from_config()"),_Kr=o(` class
method.`),uKr=l(),O$=a("p"),bKr=o("This class cannot be instantiated directly using "),Uwe=a("code"),vKr=o("__init__()"),FKr=o(" (throws an error)."),TKr=l(),Zt=a("div"),F(V$.$$.fragment),MKr=l(),Jwe=a("p"),EKr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),CKr=l(),vf=a("p"),wKr=o(`Note:
Loading a model from its configuration file does `),Ywe=a("strong"),AKr=o("not"),LKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qoe=a("a"),yKr=o("from_pretrained()"),xKr=o(" to load the model weights."),$Kr=l(),F(nA.$$.fragment),kKr=l(),Yr=a("div"),F(X$.$$.fragment),SKr=l(),Kwe=a("p"),RKr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),PKr=l(),xn=a("p"),BKr=o("The model class to instantiate is selected based on the "),Zwe=a("code"),NKr=o("model_type"),IKr=o(` property of the config object (either
passed as an argument or loaded from `),eAe=a("code"),qKr=o("pretrained_model_name_or_path"),jKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oAe=a("code"),DKr=o("pretrained_model_name_or_path"),GKr=o(":"),OKr=l(),Xe=a("ul"),sA=a("li"),rAe=a("strong"),VKr=o("albert"),XKr=o(" \u2014 "),Woe=a("a"),zKr=o("FlaxAlbertForMultipleChoice"),QKr=o(" (ALBERT model)"),WKr=l(),lA=a("li"),tAe=a("strong"),HKr=o("bert"),UKr=o(" \u2014 "),Hoe=a("a"),JKr=o("FlaxBertForMultipleChoice"),YKr=o(" (BERT model)"),KKr=l(),iA=a("li"),aAe=a("strong"),ZKr=o("big_bird"),eZr=o(" \u2014 "),Uoe=a("a"),oZr=o("FlaxBigBirdForMultipleChoice"),rZr=o(" (BigBird model)"),tZr=l(),dA=a("li"),nAe=a("strong"),aZr=o("distilbert"),nZr=o(" \u2014 "),Joe=a("a"),sZr=o("FlaxDistilBertForMultipleChoice"),lZr=o(" (DistilBERT model)"),iZr=l(),cA=a("li"),sAe=a("strong"),dZr=o("electra"),cZr=o(" \u2014 "),Yoe=a("a"),fZr=o("FlaxElectraForMultipleChoice"),mZr=o(" (ELECTRA model)"),gZr=l(),fA=a("li"),lAe=a("strong"),hZr=o("roberta"),pZr=o(" \u2014 "),Koe=a("a"),_Zr=o("FlaxRobertaForMultipleChoice"),uZr=o(" (RoBERTa model)"),bZr=l(),mA=a("li"),iAe=a("strong"),vZr=o("roformer"),FZr=o(" \u2014 "),Zoe=a("a"),TZr=o("FlaxRoFormerForMultipleChoice"),MZr=o(" (RoFormer model)"),EZr=l(),gA=a("li"),dAe=a("strong"),CZr=o("xlm-roberta"),wZr=o(" \u2014 "),ere=a("a"),AZr=o("FlaxXLMRobertaForMultipleChoice"),LZr=o(" (XLM-RoBERTa model)"),yZr=l(),F(hA.$$.fragment),Tze=l(),Ff=a("h2"),pA=a("a"),cAe=a("span"),F(z$.$$.fragment),xZr=l(),fAe=a("span"),$Zr=o("FlaxAutoModelForNextSentencePrediction"),Mze=l(),Cr=a("div"),F(Q$.$$.fragment),kZr=l(),Tf=a("p"),SZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ore=a("a"),RZr=o("from_pretrained()"),PZr=o(" class method or the "),rre=a("a"),BZr=o("from_config()"),NZr=o(` class
method.`),IZr=l(),W$=a("p"),qZr=o("This class cannot be instantiated directly using "),mAe=a("code"),jZr=o("__init__()"),DZr=o(" (throws an error)."),GZr=l(),ea=a("div"),F(H$.$$.fragment),OZr=l(),gAe=a("p"),VZr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),XZr=l(),Mf=a("p"),zZr=o(`Note:
Loading a model from its configuration file does `),hAe=a("strong"),QZr=o("not"),WZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=a("a"),HZr=o("from_pretrained()"),UZr=o(" to load the model weights."),JZr=l(),F(_A.$$.fragment),YZr=l(),Kr=a("div"),F(U$.$$.fragment),KZr=l(),pAe=a("p"),ZZr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eet=l(),$n=a("p"),oet=o("The model class to instantiate is selected based on the "),_Ae=a("code"),ret=o("model_type"),tet=o(` property of the config object (either
passed as an argument or loaded from `),uAe=a("code"),aet=o("pretrained_model_name_or_path"),net=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bAe=a("code"),set=o("pretrained_model_name_or_path"),iet=o(":"),det=l(),vAe=a("ul"),uA=a("li"),FAe=a("strong"),cet=o("bert"),fet=o(" \u2014 "),are=a("a"),met=o("FlaxBertForNextSentencePrediction"),get=o(" (BERT model)"),het=l(),F(bA.$$.fragment),Eze=l(),Ef=a("h2"),vA=a("a"),TAe=a("span"),F(J$.$$.fragment),pet=l(),MAe=a("span"),_et=o("FlaxAutoModelForImageClassification"),Cze=l(),wr=a("div"),F(Y$.$$.fragment),uet=l(),Cf=a("p"),bet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),nre=a("a"),vet=o("from_pretrained()"),Fet=o(" class method or the "),sre=a("a"),Tet=o("from_config()"),Met=o(` class
method.`),Eet=l(),K$=a("p"),Cet=o("This class cannot be instantiated directly using "),EAe=a("code"),wet=o("__init__()"),Aet=o(" (throws an error)."),Let=l(),oa=a("div"),F(Z$.$$.fragment),yet=l(),CAe=a("p"),xet=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$et=l(),wf=a("p"),ket=o(`Note:
Loading a model from its configuration file does `),wAe=a("strong"),Set=o("not"),Ret=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=a("a"),Pet=o("from_pretrained()"),Bet=o(" to load the model weights."),Net=l(),F(FA.$$.fragment),Iet=l(),Zr=a("div"),F(ek.$$.fragment),qet=l(),AAe=a("p"),jet=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Det=l(),kn=a("p"),Get=o("The model class to instantiate is selected based on the "),LAe=a("code"),Oet=o("model_type"),Vet=o(` property of the config object (either
passed as an argument or loaded from `),yAe=a("code"),Xet=o("pretrained_model_name_or_path"),zet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=a("code"),Qet=o("pretrained_model_name_or_path"),Wet=o(":"),Het=l(),ok=a("ul"),TA=a("li"),$Ae=a("strong"),Uet=o("beit"),Jet=o(" \u2014 "),ire=a("a"),Yet=o("FlaxBeitForImageClassification"),Ket=o(" (BEiT model)"),Zet=l(),MA=a("li"),kAe=a("strong"),eot=o("vit"),oot=o(" \u2014 "),dre=a("a"),rot=o("FlaxViTForImageClassification"),tot=o(" (ViT model)"),aot=l(),F(EA.$$.fragment),wze=l(),Af=a("h2"),CA=a("a"),SAe=a("span"),F(rk.$$.fragment),not=l(),RAe=a("span"),sot=o("FlaxAutoModelForVision2Seq"),Aze=l(),Ar=a("div"),F(tk.$$.fragment),lot=l(),Lf=a("p"),iot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cre=a("a"),dot=o("from_pretrained()"),cot=o(" class method or the "),fre=a("a"),fot=o("from_config()"),mot=o(` class
method.`),got=l(),ak=a("p"),hot=o("This class cannot be instantiated directly using "),PAe=a("code"),pot=o("__init__()"),_ot=o(" (throws an error)."),uot=l(),ra=a("div"),F(nk.$$.fragment),bot=l(),BAe=a("p"),vot=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Fot=l(),yf=a("p"),Tot=o(`Note:
Loading a model from its configuration file does `),NAe=a("strong"),Mot=o("not"),Eot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mre=a("a"),Cot=o("from_pretrained()"),wot=o(" to load the model weights."),Aot=l(),F(wA.$$.fragment),Lot=l(),et=a("div"),F(sk.$$.fragment),yot=l(),IAe=a("p"),xot=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),$ot=l(),Sn=a("p"),kot=o("The model class to instantiate is selected based on the "),qAe=a("code"),Sot=o("model_type"),Rot=o(` property of the config object (either
passed as an argument or loaded from `),jAe=a("code"),Pot=o("pretrained_model_name_or_path"),Bot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DAe=a("code"),Not=o("pretrained_model_name_or_path"),Iot=o(":"),qot=l(),GAe=a("ul"),AA=a("li"),OAe=a("strong"),jot=o("vision-encoder-decoder"),Dot=o(" \u2014 "),gre=a("a"),Got=o("FlaxVisionEncoderDecoderModel"),Oot=o(" (Vision Encoder decoder model)"),Vot=l(),F(LA.$$.fragment),this.h()},l(f){const u=szt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var lk=s(p);m=n(lk,"A",{id:!0,class:!0,href:!0});var VAe=s(m);_=n(VAe,"SPAN",{});var XAe=s(_);T(d.$$.fragment,XAe),XAe.forEach(t),VAe.forEach(t),h=i(lk),Eo=n(lk,"SPAN",{});var zAe=s(Eo);wi=r(zAe,"Auto Classes"),zAe.forEach(t),lk.forEach(t),Sf=i(f),nt=n(f,"P",{});var ik=s(nt);Ai=r(ik,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Li=n(ik,"CODE",{});var QAe=s(Li);WL=r(QAe,"from_pretrained()"),QAe.forEach(t),Rf=r(ik,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),ik.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Rn=s(Qe);yi=r(Rn,"Instantiating one of "),Pn=n(Rn,"A",{href:!0});var WAe=s(Pn);HL=r(WAe,"AutoConfig"),WAe.forEach(t),Bn=r(Rn,", "),Nn=n(Rn,"A",{href:!0});var HAe=s(Nn);UL=r(HAe,"AutoModel"),HAe.forEach(t),xi=r(Rn,`, and
`),In=n(Rn,"A",{href:!0});var UAe=s(In);JL=r(UAe,"AutoTokenizer"),UAe.forEach(t),$i=r(Rn," will directly create a class of the relevant architecture. For instance"),Rn.forEach(t),Pf=i(f),T(ka.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var dk=s(Ae);LS=r(dk,"will create a model that is an instance of "),ki=n(dk,"A",{href:!0});var JAe=s(ki);yS=r(JAe,"BertModel"),JAe.forEach(t),xS=r(dk,"."),dk.forEach(t),Co=i(f),Sa=n(f,"P",{});var ck=s(Sa);$S=r(ck,"There is one class of "),Bf=n(ck,"CODE",{});var YAe=s(Bf);kS=r(YAe,"AutoModel"),YAe.forEach(t),IWe=r(ck," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ck.forEach(t),MVe=i(f),Si=n(f,"H2",{class:!0});var fk=s(Si);Nf=n(fk,"A",{id:!0,class:!0,href:!0});var KAe=s(Nf);iae=n(KAe,"SPAN",{});var ZAe=s(iae);T(YL.$$.fragment,ZAe),ZAe.forEach(t),KAe.forEach(t),qWe=i(fk),dae=n(fk,"SPAN",{});var e6e=s(dae);jWe=r(e6e,"Extending the Auto Classes"),e6e.forEach(t),fk.forEach(t),EVe=i(f),qn=n(f,"P",{});var xf=s(qn);DWe=r(xf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),cae=n(xf,"CODE",{});var o6e=s(cae);GWe=r(o6e,"NewModel"),o6e.forEach(t),OWe=r(xf,", make sure you have a "),fae=n(xf,"CODE",{});var r6e=s(fae);VWe=r(r6e,"NewModelConfig"),r6e.forEach(t),XWe=r(xf,` then you can add those to the auto
classes like this:`),xf.forEach(t),CVe=i(f),T(KL.$$.fragment,f),wVe=i(f),SS=n(f,"P",{});var t6e=s(SS);zWe=r(t6e,"You will then be able to use the auto classes like you would usually do!"),t6e.forEach(t),AVe=i(f),T(If.$$.fragment,f),LVe=i(f),Ri=n(f,"H2",{class:!0});var mk=s(Ri);qf=n(mk,"A",{id:!0,class:!0,href:!0});var a6e=s(qf);mae=n(a6e,"SPAN",{});var n6e=s(mae);T(ZL.$$.fragment,n6e),n6e.forEach(t),a6e.forEach(t),QWe=i(mk),gae=n(mk,"SPAN",{});var s6e=s(gae);WWe=r(s6e,"AutoConfig"),s6e.forEach(t),mk.forEach(t),yVe=i(f),wo=n(f,"DIV",{class:!0});var tt=s(wo);T(ey.$$.fragment,tt),HWe=i(tt),oy=n(tt,"P",{});var gk=s(oy);UWe=r(gk,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),RS=n(gk,"A",{href:!0});var l6e=s(RS);JWe=r(l6e,"from_pretrained()"),l6e.forEach(t),YWe=r(gk," class method."),gk.forEach(t),KWe=i(tt),ry=n(tt,"P",{});var hk=s(ry);ZWe=r(hk,"This class cannot be instantiated directly using "),hae=n(hk,"CODE",{});var i6e=s(hae);eHe=r(i6e,"__init__()"),i6e.forEach(t),oHe=r(hk," (throws an error)."),hk.forEach(t),rHe=i(tt),Lr=n(tt,"DIV",{class:!0});var at=s(Lr);T(ty.$$.fragment,at),tHe=i(at),pae=n(at,"P",{});var d6e=s(pae);aHe=r(d6e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),d6e.forEach(t),nHe=i(at),Pi=n(at,"P",{});var $f=s(Pi);sHe=r($f,"The configuration class to instantiate is selected based on the "),_ae=n($f,"CODE",{});var c6e=s(_ae);lHe=r(c6e,"model_type"),c6e.forEach(t),iHe=r($f,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),uae=n($f,"CODE",{});var f6e=s(uae);dHe=r(f6e,"pretrained_model_name_or_path"),f6e.forEach(t),cHe=r($f,":"),$f.forEach(t),fHe=i(at),A=n(at,"UL",{});var L=s(A);jf=n(L,"LI",{});var yA=s(jf);bae=n(yA,"STRONG",{});var m6e=s(bae);mHe=r(m6e,"albert"),m6e.forEach(t),gHe=r(yA," \u2014 "),PS=n(yA,"A",{href:!0});var g6e=s(PS);hHe=r(g6e,"AlbertConfig"),g6e.forEach(t),pHe=r(yA," (ALBERT model)"),yA.forEach(t),_He=i(L),Df=n(L,"LI",{});var xA=s(Df);vae=n(xA,"STRONG",{});var h6e=s(vae);uHe=r(h6e,"bart"),h6e.forEach(t),bHe=r(xA," \u2014 "),BS=n(xA,"A",{href:!0});var p6e=s(BS);vHe=r(p6e,"BartConfig"),p6e.forEach(t),FHe=r(xA," (BART model)"),xA.forEach(t),THe=i(L),Gf=n(L,"LI",{});var $A=s(Gf);Fae=n($A,"STRONG",{});var _6e=s(Fae);MHe=r(_6e,"beit"),_6e.forEach(t),EHe=r($A," \u2014 "),NS=n($A,"A",{href:!0});var u6e=s(NS);CHe=r(u6e,"BeitConfig"),u6e.forEach(t),wHe=r($A," (BEiT model)"),$A.forEach(t),AHe=i(L),Of=n(L,"LI",{});var kA=s(Of);Tae=n(kA,"STRONG",{});var b6e=s(Tae);LHe=r(b6e,"bert"),b6e.forEach(t),yHe=r(kA," \u2014 "),IS=n(kA,"A",{href:!0});var v6e=s(IS);xHe=r(v6e,"BertConfig"),v6e.forEach(t),$He=r(kA," (BERT model)"),kA.forEach(t),kHe=i(L),Vf=n(L,"LI",{});var SA=s(Vf);Mae=n(SA,"STRONG",{});var F6e=s(Mae);SHe=r(F6e,"bert-generation"),F6e.forEach(t),RHe=r(SA," \u2014 "),qS=n(SA,"A",{href:!0});var T6e=s(qS);PHe=r(T6e,"BertGenerationConfig"),T6e.forEach(t),BHe=r(SA," (Bert Generation model)"),SA.forEach(t),NHe=i(L),Xf=n(L,"LI",{});var RA=s(Xf);Eae=n(RA,"STRONG",{});var M6e=s(Eae);IHe=r(M6e,"big_bird"),M6e.forEach(t),qHe=r(RA," \u2014 "),jS=n(RA,"A",{href:!0});var E6e=s(jS);jHe=r(E6e,"BigBirdConfig"),E6e.forEach(t),DHe=r(RA," (BigBird model)"),RA.forEach(t),GHe=i(L),zf=n(L,"LI",{});var PA=s(zf);Cae=n(PA,"STRONG",{});var C6e=s(Cae);OHe=r(C6e,"bigbird_pegasus"),C6e.forEach(t),VHe=r(PA," \u2014 "),DS=n(PA,"A",{href:!0});var w6e=s(DS);XHe=r(w6e,"BigBirdPegasusConfig"),w6e.forEach(t),zHe=r(PA," (BigBird-Pegasus model)"),PA.forEach(t),QHe=i(L),Qf=n(L,"LI",{});var BA=s(Qf);wae=n(BA,"STRONG",{});var A6e=s(wae);WHe=r(A6e,"blenderbot"),A6e.forEach(t),HHe=r(BA," \u2014 "),GS=n(BA,"A",{href:!0});var L6e=s(GS);UHe=r(L6e,"BlenderbotConfig"),L6e.forEach(t),JHe=r(BA," (Blenderbot model)"),BA.forEach(t),YHe=i(L),Wf=n(L,"LI",{});var NA=s(Wf);Aae=n(NA,"STRONG",{});var y6e=s(Aae);KHe=r(y6e,"blenderbot-small"),y6e.forEach(t),ZHe=r(NA," \u2014 "),OS=n(NA,"A",{href:!0});var x6e=s(OS);eUe=r(x6e,"BlenderbotSmallConfig"),x6e.forEach(t),oUe=r(NA," (BlenderbotSmall model)"),NA.forEach(t),rUe=i(L),Hf=n(L,"LI",{});var IA=s(Hf);Lae=n(IA,"STRONG",{});var $6e=s(Lae);tUe=r($6e,"bloom"),$6e.forEach(t),aUe=r(IA," \u2014 "),VS=n(IA,"A",{href:!0});var k6e=s(VS);nUe=r(k6e,"BloomConfig"),k6e.forEach(t),sUe=r(IA," (BLOOM model)"),IA.forEach(t),lUe=i(L),Uf=n(L,"LI",{});var qA=s(Uf);yae=n(qA,"STRONG",{});var S6e=s(yae);iUe=r(S6e,"camembert"),S6e.forEach(t),dUe=r(qA," \u2014 "),XS=n(qA,"A",{href:!0});var R6e=s(XS);cUe=r(R6e,"CamembertConfig"),R6e.forEach(t),fUe=r(qA," (CamemBERT model)"),qA.forEach(t),mUe=i(L),Jf=n(L,"LI",{});var jA=s(Jf);xae=n(jA,"STRONG",{});var P6e=s(xae);gUe=r(P6e,"canine"),P6e.forEach(t),hUe=r(jA," \u2014 "),zS=n(jA,"A",{href:!0});var B6e=s(zS);pUe=r(B6e,"CanineConfig"),B6e.forEach(t),_Ue=r(jA," (CANINE model)"),jA.forEach(t),uUe=i(L),Yf=n(L,"LI",{});var DA=s(Yf);$ae=n(DA,"STRONG",{});var N6e=s($ae);bUe=r(N6e,"clip"),N6e.forEach(t),vUe=r(DA," \u2014 "),QS=n(DA,"A",{href:!0});var I6e=s(QS);FUe=r(I6e,"CLIPConfig"),I6e.forEach(t),TUe=r(DA," (CLIP model)"),DA.forEach(t),MUe=i(L),Kf=n(L,"LI",{});var GA=s(Kf);kae=n(GA,"STRONG",{});var q6e=s(kae);EUe=r(q6e,"codegen"),q6e.forEach(t),CUe=r(GA," \u2014 "),WS=n(GA,"A",{href:!0});var j6e=s(WS);wUe=r(j6e,"CodeGenConfig"),j6e.forEach(t),AUe=r(GA," (CodeGen model)"),GA.forEach(t),LUe=i(L),Zf=n(L,"LI",{});var OA=s(Zf);Sae=n(OA,"STRONG",{});var D6e=s(Sae);yUe=r(D6e,"convbert"),D6e.forEach(t),xUe=r(OA," \u2014 "),HS=n(OA,"A",{href:!0});var G6e=s(HS);$Ue=r(G6e,"ConvBertConfig"),G6e.forEach(t),kUe=r(OA," (ConvBERT model)"),OA.forEach(t),SUe=i(L),em=n(L,"LI",{});var VA=s(em);Rae=n(VA,"STRONG",{});var O6e=s(Rae);RUe=r(O6e,"convnext"),O6e.forEach(t),PUe=r(VA," \u2014 "),US=n(VA,"A",{href:!0});var V6e=s(US);BUe=r(V6e,"ConvNextConfig"),V6e.forEach(t),NUe=r(VA," (ConvNeXT model)"),VA.forEach(t),IUe=i(L),om=n(L,"LI",{});var XA=s(om);Pae=n(XA,"STRONG",{});var X6e=s(Pae);qUe=r(X6e,"ctrl"),X6e.forEach(t),jUe=r(XA," \u2014 "),JS=n(XA,"A",{href:!0});var z6e=s(JS);DUe=r(z6e,"CTRLConfig"),z6e.forEach(t),GUe=r(XA," (CTRL model)"),XA.forEach(t),OUe=i(L),rm=n(L,"LI",{});var zA=s(rm);Bae=n(zA,"STRONG",{});var Q6e=s(Bae);VUe=r(Q6e,"cvt"),Q6e.forEach(t),XUe=r(zA," \u2014 "),YS=n(zA,"A",{href:!0});var W6e=s(YS);zUe=r(W6e,"CvtConfig"),W6e.forEach(t),QUe=r(zA," (CvT model)"),zA.forEach(t),WUe=i(L),tm=n(L,"LI",{});var QA=s(tm);Nae=n(QA,"STRONG",{});var H6e=s(Nae);HUe=r(H6e,"data2vec-audio"),H6e.forEach(t),UUe=r(QA," \u2014 "),KS=n(QA,"A",{href:!0});var U6e=s(KS);JUe=r(U6e,"Data2VecAudioConfig"),U6e.forEach(t),YUe=r(QA," (Data2VecAudio model)"),QA.forEach(t),KUe=i(L),am=n(L,"LI",{});var WA=s(am);Iae=n(WA,"STRONG",{});var J6e=s(Iae);ZUe=r(J6e,"data2vec-text"),J6e.forEach(t),eJe=r(WA," \u2014 "),ZS=n(WA,"A",{href:!0});var Y6e=s(ZS);oJe=r(Y6e,"Data2VecTextConfig"),Y6e.forEach(t),rJe=r(WA," (Data2VecText model)"),WA.forEach(t),tJe=i(L),nm=n(L,"LI",{});var HA=s(nm);qae=n(HA,"STRONG",{});var K6e=s(qae);aJe=r(K6e,"data2vec-vision"),K6e.forEach(t),nJe=r(HA," \u2014 "),eR=n(HA,"A",{href:!0});var Z6e=s(eR);sJe=r(Z6e,"Data2VecVisionConfig"),Z6e.forEach(t),lJe=r(HA," (Data2VecVision model)"),HA.forEach(t),iJe=i(L),sm=n(L,"LI",{});var UA=s(sm);jae=n(UA,"STRONG",{});var eLe=s(jae);dJe=r(eLe,"deberta"),eLe.forEach(t),cJe=r(UA," \u2014 "),oR=n(UA,"A",{href:!0});var oLe=s(oR);fJe=r(oLe,"DebertaConfig"),oLe.forEach(t),mJe=r(UA," (DeBERTa model)"),UA.forEach(t),gJe=i(L),lm=n(L,"LI",{});var JA=s(lm);Dae=n(JA,"STRONG",{});var rLe=s(Dae);hJe=r(rLe,"deberta-v2"),rLe.forEach(t),pJe=r(JA," \u2014 "),rR=n(JA,"A",{href:!0});var tLe=s(rR);_Je=r(tLe,"DebertaV2Config"),tLe.forEach(t),uJe=r(JA," (DeBERTa-v2 model)"),JA.forEach(t),bJe=i(L),im=n(L,"LI",{});var YA=s(im);Gae=n(YA,"STRONG",{});var zot=s(Gae);vJe=r(zot,"decision_transformer"),zot.forEach(t),FJe=r(YA," \u2014 "),tR=n(YA,"A",{href:!0});var Qot=s(tR);TJe=r(Qot,"DecisionTransformerConfig"),Qot.forEach(t),MJe=r(YA," (Decision Transformer model)"),YA.forEach(t),EJe=i(L),dm=n(L,"LI",{});var aLe=s(dm);Oae=n(aLe,"STRONG",{});var Wot=s(Oae);CJe=r(Wot,"deit"),Wot.forEach(t),wJe=r(aLe," \u2014 "),aR=n(aLe,"A",{href:!0});var Hot=s(aR);AJe=r(Hot,"DeiTConfig"),Hot.forEach(t),LJe=r(aLe," (DeiT model)"),aLe.forEach(t),yJe=i(L),cm=n(L,"LI",{});var nLe=s(cm);Vae=n(nLe,"STRONG",{});var Uot=s(Vae);xJe=r(Uot,"detr"),Uot.forEach(t),$Je=r(nLe," \u2014 "),nR=n(nLe,"A",{href:!0});var Jot=s(nR);kJe=r(Jot,"DetrConfig"),Jot.forEach(t),SJe=r(nLe," (DETR model)"),nLe.forEach(t),RJe=i(L),fm=n(L,"LI",{});var sLe=s(fm);Xae=n(sLe,"STRONG",{});var Yot=s(Xae);PJe=r(Yot,"distilbert"),Yot.forEach(t),BJe=r(sLe," \u2014 "),sR=n(sLe,"A",{href:!0});var Kot=s(sR);NJe=r(Kot,"DistilBertConfig"),Kot.forEach(t),IJe=r(sLe," (DistilBERT model)"),sLe.forEach(t),qJe=i(L),mm=n(L,"LI",{});var lLe=s(mm);zae=n(lLe,"STRONG",{});var Zot=s(zae);jJe=r(Zot,"dpr"),Zot.forEach(t),DJe=r(lLe," \u2014 "),lR=n(lLe,"A",{href:!0});var ert=s(lR);GJe=r(ert,"DPRConfig"),ert.forEach(t),OJe=r(lLe," (DPR model)"),lLe.forEach(t),VJe=i(L),gm=n(L,"LI",{});var iLe=s(gm);Qae=n(iLe,"STRONG",{});var ort=s(Qae);XJe=r(ort,"dpt"),ort.forEach(t),zJe=r(iLe," \u2014 "),iR=n(iLe,"A",{href:!0});var rrt=s(iR);QJe=r(rrt,"DPTConfig"),rrt.forEach(t),WJe=r(iLe," (DPT model)"),iLe.forEach(t),HJe=i(L),hm=n(L,"LI",{});var dLe=s(hm);Wae=n(dLe,"STRONG",{});var trt=s(Wae);UJe=r(trt,"electra"),trt.forEach(t),JJe=r(dLe," \u2014 "),dR=n(dLe,"A",{href:!0});var art=s(dR);YJe=r(art,"ElectraConfig"),art.forEach(t),KJe=r(dLe," (ELECTRA model)"),dLe.forEach(t),ZJe=i(L),pm=n(L,"LI",{});var cLe=s(pm);Hae=n(cLe,"STRONG",{});var nrt=s(Hae);eYe=r(nrt,"encoder-decoder"),nrt.forEach(t),oYe=r(cLe," \u2014 "),cR=n(cLe,"A",{href:!0});var srt=s(cR);rYe=r(srt,"EncoderDecoderConfig"),srt.forEach(t),tYe=r(cLe," (Encoder decoder model)"),cLe.forEach(t),aYe=i(L),_m=n(L,"LI",{});var fLe=s(_m);Uae=n(fLe,"STRONG",{});var lrt=s(Uae);nYe=r(lrt,"flaubert"),lrt.forEach(t),sYe=r(fLe," \u2014 "),fR=n(fLe,"A",{href:!0});var irt=s(fR);lYe=r(irt,"FlaubertConfig"),irt.forEach(t),iYe=r(fLe," (FlauBERT model)"),fLe.forEach(t),dYe=i(L),um=n(L,"LI",{});var mLe=s(um);Jae=n(mLe,"STRONG",{});var drt=s(Jae);cYe=r(drt,"flava"),drt.forEach(t),fYe=r(mLe," \u2014 "),mR=n(mLe,"A",{href:!0});var crt=s(mR);mYe=r(crt,"FlavaConfig"),crt.forEach(t),gYe=r(mLe," (FLAVA model)"),mLe.forEach(t),hYe=i(L),bm=n(L,"LI",{});var gLe=s(bm);Yae=n(gLe,"STRONG",{});var frt=s(Yae);pYe=r(frt,"fnet"),frt.forEach(t),_Ye=r(gLe," \u2014 "),gR=n(gLe,"A",{href:!0});var mrt=s(gR);uYe=r(mrt,"FNetConfig"),mrt.forEach(t),bYe=r(gLe," (FNet model)"),gLe.forEach(t),vYe=i(L),vm=n(L,"LI",{});var hLe=s(vm);Kae=n(hLe,"STRONG",{});var grt=s(Kae);FYe=r(grt,"fsmt"),grt.forEach(t),TYe=r(hLe," \u2014 "),hR=n(hLe,"A",{href:!0});var hrt=s(hR);MYe=r(hrt,"FSMTConfig"),hrt.forEach(t),EYe=r(hLe," (FairSeq Machine-Translation model)"),hLe.forEach(t),CYe=i(L),Fm=n(L,"LI",{});var pLe=s(Fm);Zae=n(pLe,"STRONG",{});var prt=s(Zae);wYe=r(prt,"funnel"),prt.forEach(t),AYe=r(pLe," \u2014 "),pR=n(pLe,"A",{href:!0});var _rt=s(pR);LYe=r(_rt,"FunnelConfig"),_rt.forEach(t),yYe=r(pLe," (Funnel Transformer model)"),pLe.forEach(t),xYe=i(L),Tm=n(L,"LI",{});var _Le=s(Tm);ene=n(_Le,"STRONG",{});var urt=s(ene);$Ye=r(urt,"glpn"),urt.forEach(t),kYe=r(_Le," \u2014 "),_R=n(_Le,"A",{href:!0});var brt=s(_R);SYe=r(brt,"GLPNConfig"),brt.forEach(t),RYe=r(_Le," (GLPN model)"),_Le.forEach(t),PYe=i(L),Mm=n(L,"LI",{});var uLe=s(Mm);one=n(uLe,"STRONG",{});var vrt=s(one);BYe=r(vrt,"gpt2"),vrt.forEach(t),NYe=r(uLe," \u2014 "),uR=n(uLe,"A",{href:!0});var Frt=s(uR);IYe=r(Frt,"GPT2Config"),Frt.forEach(t),qYe=r(uLe," (OpenAI GPT-2 model)"),uLe.forEach(t),jYe=i(L),Em=n(L,"LI",{});var bLe=s(Em);rne=n(bLe,"STRONG",{});var Trt=s(rne);DYe=r(Trt,"gpt_neo"),Trt.forEach(t),GYe=r(bLe," \u2014 "),bR=n(bLe,"A",{href:!0});var Mrt=s(bR);OYe=r(Mrt,"GPTNeoConfig"),Mrt.forEach(t),VYe=r(bLe," (GPT Neo model)"),bLe.forEach(t),XYe=i(L),Cm=n(L,"LI",{});var vLe=s(Cm);tne=n(vLe,"STRONG",{});var Ert=s(tne);zYe=r(Ert,"gpt_neox"),Ert.forEach(t),QYe=r(vLe," \u2014 "),vR=n(vLe,"A",{href:!0});var Crt=s(vR);WYe=r(Crt,"GPTNeoXConfig"),Crt.forEach(t),HYe=r(vLe," (GPT NeoX model)"),vLe.forEach(t),UYe=i(L),wm=n(L,"LI",{});var FLe=s(wm);ane=n(FLe,"STRONG",{});var wrt=s(ane);JYe=r(wrt,"gptj"),wrt.forEach(t),YYe=r(FLe," \u2014 "),FR=n(FLe,"A",{href:!0});var Art=s(FR);KYe=r(Art,"GPTJConfig"),Art.forEach(t),ZYe=r(FLe," (GPT-J model)"),FLe.forEach(t),eKe=i(L),Am=n(L,"LI",{});var TLe=s(Am);nne=n(TLe,"STRONG",{});var Lrt=s(nne);oKe=r(Lrt,"groupvit"),Lrt.forEach(t),rKe=r(TLe," \u2014 "),TR=n(TLe,"A",{href:!0});var yrt=s(TR);tKe=r(yrt,"GroupViTConfig"),yrt.forEach(t),aKe=r(TLe," (GroupViT model)"),TLe.forEach(t),nKe=i(L),Lm=n(L,"LI",{});var MLe=s(Lm);sne=n(MLe,"STRONG",{});var xrt=s(sne);sKe=r(xrt,"hubert"),xrt.forEach(t),lKe=r(MLe," \u2014 "),MR=n(MLe,"A",{href:!0});var $rt=s(MR);iKe=r($rt,"HubertConfig"),$rt.forEach(t),dKe=r(MLe," (Hubert model)"),MLe.forEach(t),cKe=i(L),ym=n(L,"LI",{});var ELe=s(ym);lne=n(ELe,"STRONG",{});var krt=s(lne);fKe=r(krt,"ibert"),krt.forEach(t),mKe=r(ELe," \u2014 "),ER=n(ELe,"A",{href:!0});var Srt=s(ER);gKe=r(Srt,"IBertConfig"),Srt.forEach(t),hKe=r(ELe," (I-BERT model)"),ELe.forEach(t),pKe=i(L),xm=n(L,"LI",{});var CLe=s(xm);ine=n(CLe,"STRONG",{});var Rrt=s(ine);_Ke=r(Rrt,"imagegpt"),Rrt.forEach(t),uKe=r(CLe," \u2014 "),CR=n(CLe,"A",{href:!0});var Prt=s(CR);bKe=r(Prt,"ImageGPTConfig"),Prt.forEach(t),vKe=r(CLe," (ImageGPT model)"),CLe.forEach(t),FKe=i(L),$m=n(L,"LI",{});var wLe=s($m);dne=n(wLe,"STRONG",{});var Brt=s(dne);TKe=r(Brt,"layoutlm"),Brt.forEach(t),MKe=r(wLe," \u2014 "),wR=n(wLe,"A",{href:!0});var Nrt=s(wR);EKe=r(Nrt,"LayoutLMConfig"),Nrt.forEach(t),CKe=r(wLe," (LayoutLM model)"),wLe.forEach(t),wKe=i(L),km=n(L,"LI",{});var ALe=s(km);cne=n(ALe,"STRONG",{});var Irt=s(cne);AKe=r(Irt,"layoutlmv2"),Irt.forEach(t),LKe=r(ALe," \u2014 "),AR=n(ALe,"A",{href:!0});var qrt=s(AR);yKe=r(qrt,"LayoutLMv2Config"),qrt.forEach(t),xKe=r(ALe," (LayoutLMv2 model)"),ALe.forEach(t),$Ke=i(L),Sm=n(L,"LI",{});var LLe=s(Sm);fne=n(LLe,"STRONG",{});var jrt=s(fne);kKe=r(jrt,"layoutlmv3"),jrt.forEach(t),SKe=r(LLe," \u2014 "),LR=n(LLe,"A",{href:!0});var Drt=s(LR);RKe=r(Drt,"LayoutLMv3Config"),Drt.forEach(t),PKe=r(LLe," (LayoutLMv3 model)"),LLe.forEach(t),BKe=i(L),Rm=n(L,"LI",{});var yLe=s(Rm);mne=n(yLe,"STRONG",{});var Grt=s(mne);NKe=r(Grt,"led"),Grt.forEach(t),IKe=r(yLe," \u2014 "),yR=n(yLe,"A",{href:!0});var Ort=s(yR);qKe=r(Ort,"LEDConfig"),Ort.forEach(t),jKe=r(yLe," (LED model)"),yLe.forEach(t),DKe=i(L),Pm=n(L,"LI",{});var xLe=s(Pm);gne=n(xLe,"STRONG",{});var Vrt=s(gne);GKe=r(Vrt,"levit"),Vrt.forEach(t),OKe=r(xLe," \u2014 "),xR=n(xLe,"A",{href:!0});var Xrt=s(xR);VKe=r(Xrt,"LevitConfig"),Xrt.forEach(t),XKe=r(xLe," (LeViT model)"),xLe.forEach(t),zKe=i(L),Bm=n(L,"LI",{});var $Le=s(Bm);hne=n($Le,"STRONG",{});var zrt=s(hne);QKe=r(zrt,"longformer"),zrt.forEach(t),WKe=r($Le," \u2014 "),$R=n($Le,"A",{href:!0});var Qrt=s($R);HKe=r(Qrt,"LongformerConfig"),Qrt.forEach(t),UKe=r($Le," (Longformer model)"),$Le.forEach(t),JKe=i(L),Nm=n(L,"LI",{});var kLe=s(Nm);pne=n(kLe,"STRONG",{});var Wrt=s(pne);YKe=r(Wrt,"longt5"),Wrt.forEach(t),KKe=r(kLe," \u2014 "),kR=n(kLe,"A",{href:!0});var Hrt=s(kR);ZKe=r(Hrt,"LongT5Config"),Hrt.forEach(t),eZe=r(kLe," (LongT5 model)"),kLe.forEach(t),oZe=i(L),Im=n(L,"LI",{});var SLe=s(Im);_ne=n(SLe,"STRONG",{});var Urt=s(_ne);rZe=r(Urt,"luke"),Urt.forEach(t),tZe=r(SLe," \u2014 "),SR=n(SLe,"A",{href:!0});var Jrt=s(SR);aZe=r(Jrt,"LukeConfig"),Jrt.forEach(t),nZe=r(SLe," (LUKE model)"),SLe.forEach(t),sZe=i(L),qm=n(L,"LI",{});var RLe=s(qm);une=n(RLe,"STRONG",{});var Yrt=s(une);lZe=r(Yrt,"lxmert"),Yrt.forEach(t),iZe=r(RLe," \u2014 "),RR=n(RLe,"A",{href:!0});var Krt=s(RR);dZe=r(Krt,"LxmertConfig"),Krt.forEach(t),cZe=r(RLe," (LXMERT model)"),RLe.forEach(t),fZe=i(L),jm=n(L,"LI",{});var PLe=s(jm);bne=n(PLe,"STRONG",{});var Zrt=s(bne);mZe=r(Zrt,"m2m_100"),Zrt.forEach(t),gZe=r(PLe," \u2014 "),PR=n(PLe,"A",{href:!0});var ett=s(PR);hZe=r(ett,"M2M100Config"),ett.forEach(t),pZe=r(PLe," (M2M100 model)"),PLe.forEach(t),_Ze=i(L),Dm=n(L,"LI",{});var BLe=s(Dm);vne=n(BLe,"STRONG",{});var ott=s(vne);uZe=r(ott,"marian"),ott.forEach(t),bZe=r(BLe," \u2014 "),BR=n(BLe,"A",{href:!0});var rtt=s(BR);vZe=r(rtt,"MarianConfig"),rtt.forEach(t),FZe=r(BLe," (Marian model)"),BLe.forEach(t),TZe=i(L),Gm=n(L,"LI",{});var NLe=s(Gm);Fne=n(NLe,"STRONG",{});var ttt=s(Fne);MZe=r(ttt,"maskformer"),ttt.forEach(t),EZe=r(NLe," \u2014 "),NR=n(NLe,"A",{href:!0});var att=s(NR);CZe=r(att,"MaskFormerConfig"),att.forEach(t),wZe=r(NLe," (MaskFormer model)"),NLe.forEach(t),AZe=i(L),Om=n(L,"LI",{});var ILe=s(Om);Tne=n(ILe,"STRONG",{});var ntt=s(Tne);LZe=r(ntt,"mbart"),ntt.forEach(t),yZe=r(ILe," \u2014 "),IR=n(ILe,"A",{href:!0});var stt=s(IR);xZe=r(stt,"MBartConfig"),stt.forEach(t),$Ze=r(ILe," (mBART model)"),ILe.forEach(t),kZe=i(L),Vm=n(L,"LI",{});var qLe=s(Vm);Mne=n(qLe,"STRONG",{});var ltt=s(Mne);SZe=r(ltt,"mctct"),ltt.forEach(t),RZe=r(qLe," \u2014 "),qR=n(qLe,"A",{href:!0});var itt=s(qR);PZe=r(itt,"MCTCTConfig"),itt.forEach(t),BZe=r(qLe," (M-CTC-T model)"),qLe.forEach(t),NZe=i(L),Xm=n(L,"LI",{});var jLe=s(Xm);Ene=n(jLe,"STRONG",{});var dtt=s(Ene);IZe=r(dtt,"megatron-bert"),dtt.forEach(t),qZe=r(jLe," \u2014 "),jR=n(jLe,"A",{href:!0});var ctt=s(jR);jZe=r(ctt,"MegatronBertConfig"),ctt.forEach(t),DZe=r(jLe," (Megatron-BERT model)"),jLe.forEach(t),GZe=i(L),zm=n(L,"LI",{});var DLe=s(zm);Cne=n(DLe,"STRONG",{});var ftt=s(Cne);OZe=r(ftt,"mobilebert"),ftt.forEach(t),VZe=r(DLe," \u2014 "),DR=n(DLe,"A",{href:!0});var mtt=s(DR);XZe=r(mtt,"MobileBertConfig"),mtt.forEach(t),zZe=r(DLe," (MobileBERT model)"),DLe.forEach(t),QZe=i(L),Qm=n(L,"LI",{});var GLe=s(Qm);wne=n(GLe,"STRONG",{});var gtt=s(wne);WZe=r(gtt,"mpnet"),gtt.forEach(t),HZe=r(GLe," \u2014 "),GR=n(GLe,"A",{href:!0});var htt=s(GR);UZe=r(htt,"MPNetConfig"),htt.forEach(t),JZe=r(GLe," (MPNet model)"),GLe.forEach(t),YZe=i(L),Wm=n(L,"LI",{});var OLe=s(Wm);Ane=n(OLe,"STRONG",{});var ptt=s(Ane);KZe=r(ptt,"mt5"),ptt.forEach(t),ZZe=r(OLe," \u2014 "),OR=n(OLe,"A",{href:!0});var _tt=s(OR);eeo=r(_tt,"MT5Config"),_tt.forEach(t),oeo=r(OLe," (MT5 model)"),OLe.forEach(t),reo=i(L),Hm=n(L,"LI",{});var VLe=s(Hm);Lne=n(VLe,"STRONG",{});var utt=s(Lne);teo=r(utt,"mvp"),utt.forEach(t),aeo=r(VLe," \u2014 "),VR=n(VLe,"A",{href:!0});var btt=s(VR);neo=r(btt,"MvpConfig"),btt.forEach(t),seo=r(VLe," (MVP model)"),VLe.forEach(t),leo=i(L),Um=n(L,"LI",{});var XLe=s(Um);yne=n(XLe,"STRONG",{});var vtt=s(yne);ieo=r(vtt,"nezha"),vtt.forEach(t),deo=r(XLe," \u2014 "),XR=n(XLe,"A",{href:!0});var Ftt=s(XR);ceo=r(Ftt,"NezhaConfig"),Ftt.forEach(t),feo=r(XLe," (Nezha model)"),XLe.forEach(t),meo=i(L),Jm=n(L,"LI",{});var zLe=s(Jm);xne=n(zLe,"STRONG",{});var Ttt=s(xne);geo=r(Ttt,"nystromformer"),Ttt.forEach(t),heo=r(zLe," \u2014 "),zR=n(zLe,"A",{href:!0});var Mtt=s(zR);peo=r(Mtt,"NystromformerConfig"),Mtt.forEach(t),_eo=r(zLe," (Nystr\xF6mformer model)"),zLe.forEach(t),ueo=i(L),Ym=n(L,"LI",{});var QLe=s(Ym);$ne=n(QLe,"STRONG",{});var Ett=s($ne);beo=r(Ett,"openai-gpt"),Ett.forEach(t),veo=r(QLe," \u2014 "),QR=n(QLe,"A",{href:!0});var Ctt=s(QR);Feo=r(Ctt,"OpenAIGPTConfig"),Ctt.forEach(t),Teo=r(QLe," (OpenAI GPT model)"),QLe.forEach(t),Meo=i(L),Km=n(L,"LI",{});var WLe=s(Km);kne=n(WLe,"STRONG",{});var wtt=s(kne);Eeo=r(wtt,"opt"),wtt.forEach(t),Ceo=r(WLe," \u2014 "),WR=n(WLe,"A",{href:!0});var Att=s(WR);weo=r(Att,"OPTConfig"),Att.forEach(t),Aeo=r(WLe," (OPT model)"),WLe.forEach(t),Leo=i(L),Zm=n(L,"LI",{});var HLe=s(Zm);Sne=n(HLe,"STRONG",{});var Ltt=s(Sne);yeo=r(Ltt,"pegasus"),Ltt.forEach(t),xeo=r(HLe," \u2014 "),HR=n(HLe,"A",{href:!0});var ytt=s(HR);$eo=r(ytt,"PegasusConfig"),ytt.forEach(t),keo=r(HLe," (Pegasus model)"),HLe.forEach(t),Seo=i(L),eg=n(L,"LI",{});var ULe=s(eg);Rne=n(ULe,"STRONG",{});var xtt=s(Rne);Reo=r(xtt,"perceiver"),xtt.forEach(t),Peo=r(ULe," \u2014 "),UR=n(ULe,"A",{href:!0});var $tt=s(UR);Beo=r($tt,"PerceiverConfig"),$tt.forEach(t),Neo=r(ULe," (Perceiver model)"),ULe.forEach(t),Ieo=i(L),og=n(L,"LI",{});var JLe=s(og);Pne=n(JLe,"STRONG",{});var ktt=s(Pne);qeo=r(ktt,"plbart"),ktt.forEach(t),jeo=r(JLe," \u2014 "),JR=n(JLe,"A",{href:!0});var Stt=s(JR);Deo=r(Stt,"PLBartConfig"),Stt.forEach(t),Geo=r(JLe," (PLBart model)"),JLe.forEach(t),Oeo=i(L),rg=n(L,"LI",{});var YLe=s(rg);Bne=n(YLe,"STRONG",{});var Rtt=s(Bne);Veo=r(Rtt,"poolformer"),Rtt.forEach(t),Xeo=r(YLe," \u2014 "),YR=n(YLe,"A",{href:!0});var Ptt=s(YR);zeo=r(Ptt,"PoolFormerConfig"),Ptt.forEach(t),Qeo=r(YLe," (PoolFormer model)"),YLe.forEach(t),Weo=i(L),tg=n(L,"LI",{});var KLe=s(tg);Nne=n(KLe,"STRONG",{});var Btt=s(Nne);Heo=r(Btt,"prophetnet"),Btt.forEach(t),Ueo=r(KLe," \u2014 "),KR=n(KLe,"A",{href:!0});var Ntt=s(KR);Jeo=r(Ntt,"ProphetNetConfig"),Ntt.forEach(t),Yeo=r(KLe," (ProphetNet model)"),KLe.forEach(t),Keo=i(L),ag=n(L,"LI",{});var ZLe=s(ag);Ine=n(ZLe,"STRONG",{});var Itt=s(Ine);Zeo=r(Itt,"qdqbert"),Itt.forEach(t),eoo=r(ZLe," \u2014 "),ZR=n(ZLe,"A",{href:!0});var qtt=s(ZR);ooo=r(qtt,"QDQBertConfig"),qtt.forEach(t),roo=r(ZLe," (QDQBert model)"),ZLe.forEach(t),too=i(L),ng=n(L,"LI",{});var eye=s(ng);qne=n(eye,"STRONG",{});var jtt=s(qne);aoo=r(jtt,"rag"),jtt.forEach(t),noo=r(eye," \u2014 "),eP=n(eye,"A",{href:!0});var Dtt=s(eP);soo=r(Dtt,"RagConfig"),Dtt.forEach(t),loo=r(eye," (RAG model)"),eye.forEach(t),ioo=i(L),sg=n(L,"LI",{});var oye=s(sg);jne=n(oye,"STRONG",{});var Gtt=s(jne);doo=r(Gtt,"realm"),Gtt.forEach(t),coo=r(oye," \u2014 "),oP=n(oye,"A",{href:!0});var Ott=s(oP);foo=r(Ott,"RealmConfig"),Ott.forEach(t),moo=r(oye," (REALM model)"),oye.forEach(t),goo=i(L),lg=n(L,"LI",{});var rye=s(lg);Dne=n(rye,"STRONG",{});var Vtt=s(Dne);hoo=r(Vtt,"reformer"),Vtt.forEach(t),poo=r(rye," \u2014 "),rP=n(rye,"A",{href:!0});var Xtt=s(rP);_oo=r(Xtt,"ReformerConfig"),Xtt.forEach(t),uoo=r(rye," (Reformer model)"),rye.forEach(t),boo=i(L),ig=n(L,"LI",{});var tye=s(ig);Gne=n(tye,"STRONG",{});var ztt=s(Gne);voo=r(ztt,"regnet"),ztt.forEach(t),Foo=r(tye," \u2014 "),tP=n(tye,"A",{href:!0});var Qtt=s(tP);Too=r(Qtt,"RegNetConfig"),Qtt.forEach(t),Moo=r(tye," (RegNet model)"),tye.forEach(t),Eoo=i(L),dg=n(L,"LI",{});var aye=s(dg);One=n(aye,"STRONG",{});var Wtt=s(One);Coo=r(Wtt,"rembert"),Wtt.forEach(t),woo=r(aye," \u2014 "),aP=n(aye,"A",{href:!0});var Htt=s(aP);Aoo=r(Htt,"RemBertConfig"),Htt.forEach(t),Loo=r(aye," (RemBERT model)"),aye.forEach(t),yoo=i(L),cg=n(L,"LI",{});var nye=s(cg);Vne=n(nye,"STRONG",{});var Utt=s(Vne);xoo=r(Utt,"resnet"),Utt.forEach(t),$oo=r(nye," \u2014 "),nP=n(nye,"A",{href:!0});var Jtt=s(nP);koo=r(Jtt,"ResNetConfig"),Jtt.forEach(t),Soo=r(nye," (ResNet model)"),nye.forEach(t),Roo=i(L),fg=n(L,"LI",{});var sye=s(fg);Xne=n(sye,"STRONG",{});var Ytt=s(Xne);Poo=r(Ytt,"retribert"),Ytt.forEach(t),Boo=r(sye," \u2014 "),sP=n(sye,"A",{href:!0});var Ktt=s(sP);Noo=r(Ktt,"RetriBertConfig"),Ktt.forEach(t),Ioo=r(sye," (RetriBERT model)"),sye.forEach(t),qoo=i(L),mg=n(L,"LI",{});var lye=s(mg);zne=n(lye,"STRONG",{});var Ztt=s(zne);joo=r(Ztt,"roberta"),Ztt.forEach(t),Doo=r(lye," \u2014 "),lP=n(lye,"A",{href:!0});var eat=s(lP);Goo=r(eat,"RobertaConfig"),eat.forEach(t),Ooo=r(lye," (RoBERTa model)"),lye.forEach(t),Voo=i(L),gg=n(L,"LI",{});var iye=s(gg);Qne=n(iye,"STRONG",{});var oat=s(Qne);Xoo=r(oat,"roformer"),oat.forEach(t),zoo=r(iye," \u2014 "),iP=n(iye,"A",{href:!0});var rat=s(iP);Qoo=r(rat,"RoFormerConfig"),rat.forEach(t),Woo=r(iye," (RoFormer model)"),iye.forEach(t),Hoo=i(L),hg=n(L,"LI",{});var dye=s(hg);Wne=n(dye,"STRONG",{});var tat=s(Wne);Uoo=r(tat,"segformer"),tat.forEach(t),Joo=r(dye," \u2014 "),dP=n(dye,"A",{href:!0});var aat=s(dP);Yoo=r(aat,"SegformerConfig"),aat.forEach(t),Koo=r(dye," (SegFormer model)"),dye.forEach(t),Zoo=i(L),pg=n(L,"LI",{});var cye=s(pg);Hne=n(cye,"STRONG",{});var nat=s(Hne);ero=r(nat,"sew"),nat.forEach(t),oro=r(cye," \u2014 "),cP=n(cye,"A",{href:!0});var sat=s(cP);rro=r(sat,"SEWConfig"),sat.forEach(t),tro=r(cye," (SEW model)"),cye.forEach(t),aro=i(L),_g=n(L,"LI",{});var fye=s(_g);Une=n(fye,"STRONG",{});var lat=s(Une);nro=r(lat,"sew-d"),lat.forEach(t),sro=r(fye," \u2014 "),fP=n(fye,"A",{href:!0});var iat=s(fP);lro=r(iat,"SEWDConfig"),iat.forEach(t),iro=r(fye," (SEW-D model)"),fye.forEach(t),dro=i(L),ug=n(L,"LI",{});var mye=s(ug);Jne=n(mye,"STRONG",{});var dat=s(Jne);cro=r(dat,"speech-encoder-decoder"),dat.forEach(t),fro=r(mye," \u2014 "),mP=n(mye,"A",{href:!0});var cat=s(mP);mro=r(cat,"SpeechEncoderDecoderConfig"),cat.forEach(t),gro=r(mye," (Speech Encoder decoder model)"),mye.forEach(t),hro=i(L),bg=n(L,"LI",{});var gye=s(bg);Yne=n(gye,"STRONG",{});var fat=s(Yne);pro=r(fat,"speech_to_text"),fat.forEach(t),_ro=r(gye," \u2014 "),gP=n(gye,"A",{href:!0});var mat=s(gP);uro=r(mat,"Speech2TextConfig"),mat.forEach(t),bro=r(gye," (Speech2Text model)"),gye.forEach(t),vro=i(L),vg=n(L,"LI",{});var hye=s(vg);Kne=n(hye,"STRONG",{});var gat=s(Kne);Fro=r(gat,"speech_to_text_2"),gat.forEach(t),Tro=r(hye," \u2014 "),hP=n(hye,"A",{href:!0});var hat=s(hP);Mro=r(hat,"Speech2Text2Config"),hat.forEach(t),Ero=r(hye," (Speech2Text2 model)"),hye.forEach(t),Cro=i(L),Fg=n(L,"LI",{});var pye=s(Fg);Zne=n(pye,"STRONG",{});var pat=s(Zne);wro=r(pat,"splinter"),pat.forEach(t),Aro=r(pye," \u2014 "),pP=n(pye,"A",{href:!0});var _at=s(pP);Lro=r(_at,"SplinterConfig"),_at.forEach(t),yro=r(pye," (Splinter model)"),pye.forEach(t),xro=i(L),Tg=n(L,"LI",{});var _ye=s(Tg);ese=n(_ye,"STRONG",{});var uat=s(ese);$ro=r(uat,"squeezebert"),uat.forEach(t),kro=r(_ye," \u2014 "),_P=n(_ye,"A",{href:!0});var bat=s(_P);Sro=r(bat,"SqueezeBertConfig"),bat.forEach(t),Rro=r(_ye," (SqueezeBERT model)"),_ye.forEach(t),Pro=i(L),Mg=n(L,"LI",{});var uye=s(Mg);ose=n(uye,"STRONG",{});var vat=s(ose);Bro=r(vat,"swin"),vat.forEach(t),Nro=r(uye," \u2014 "),uP=n(uye,"A",{href:!0});var Fat=s(uP);Iro=r(Fat,"SwinConfig"),Fat.forEach(t),qro=r(uye," (Swin Transformer model)"),uye.forEach(t),jro=i(L),Eg=n(L,"LI",{});var bye=s(Eg);rse=n(bye,"STRONG",{});var Tat=s(rse);Dro=r(Tat,"t5"),Tat.forEach(t),Gro=r(bye," \u2014 "),bP=n(bye,"A",{href:!0});var Mat=s(bP);Oro=r(Mat,"T5Config"),Mat.forEach(t),Vro=r(bye," (T5 model)"),bye.forEach(t),Xro=i(L),Cg=n(L,"LI",{});var vye=s(Cg);tse=n(vye,"STRONG",{});var Eat=s(tse);zro=r(Eat,"tapas"),Eat.forEach(t),Qro=r(vye," \u2014 "),vP=n(vye,"A",{href:!0});var Cat=s(vP);Wro=r(Cat,"TapasConfig"),Cat.forEach(t),Hro=r(vye," (TAPAS model)"),vye.forEach(t),Uro=i(L),wg=n(L,"LI",{});var Fye=s(wg);ase=n(Fye,"STRONG",{});var wat=s(ase);Jro=r(wat,"trajectory_transformer"),wat.forEach(t),Yro=r(Fye," \u2014 "),FP=n(Fye,"A",{href:!0});var Aat=s(FP);Kro=r(Aat,"TrajectoryTransformerConfig"),Aat.forEach(t),Zro=r(Fye," (Trajectory Transformer model)"),Fye.forEach(t),eto=i(L),Ag=n(L,"LI",{});var Tye=s(Ag);nse=n(Tye,"STRONG",{});var Lat=s(nse);oto=r(Lat,"transfo-xl"),Lat.forEach(t),rto=r(Tye," \u2014 "),TP=n(Tye,"A",{href:!0});var yat=s(TP);tto=r(yat,"TransfoXLConfig"),yat.forEach(t),ato=r(Tye," (Transformer-XL model)"),Tye.forEach(t),nto=i(L),Lg=n(L,"LI",{});var Mye=s(Lg);sse=n(Mye,"STRONG",{});var xat=s(sse);sto=r(xat,"trocr"),xat.forEach(t),lto=r(Mye," \u2014 "),MP=n(Mye,"A",{href:!0});var $at=s(MP);ito=r($at,"TrOCRConfig"),$at.forEach(t),dto=r(Mye," (TrOCR model)"),Mye.forEach(t),cto=i(L),yg=n(L,"LI",{});var Eye=s(yg);lse=n(Eye,"STRONG",{});var kat=s(lse);fto=r(kat,"unispeech"),kat.forEach(t),mto=r(Eye," \u2014 "),EP=n(Eye,"A",{href:!0});var Sat=s(EP);gto=r(Sat,"UniSpeechConfig"),Sat.forEach(t),hto=r(Eye," (UniSpeech model)"),Eye.forEach(t),pto=i(L),xg=n(L,"LI",{});var Cye=s(xg);ise=n(Cye,"STRONG",{});var Rat=s(ise);_to=r(Rat,"unispeech-sat"),Rat.forEach(t),uto=r(Cye," \u2014 "),CP=n(Cye,"A",{href:!0});var Pat=s(CP);bto=r(Pat,"UniSpeechSatConfig"),Pat.forEach(t),vto=r(Cye," (UniSpeechSat model)"),Cye.forEach(t),Fto=i(L),$g=n(L,"LI",{});var wye=s($g);dse=n(wye,"STRONG",{});var Bat=s(dse);Tto=r(Bat,"van"),Bat.forEach(t),Mto=r(wye," \u2014 "),wP=n(wye,"A",{href:!0});var Nat=s(wP);Eto=r(Nat,"VanConfig"),Nat.forEach(t),Cto=r(wye," (VAN model)"),wye.forEach(t),wto=i(L),kg=n(L,"LI",{});var Aye=s(kg);cse=n(Aye,"STRONG",{});var Iat=s(cse);Ato=r(Iat,"vilt"),Iat.forEach(t),Lto=r(Aye," \u2014 "),AP=n(Aye,"A",{href:!0});var qat=s(AP);yto=r(qat,"ViltConfig"),qat.forEach(t),xto=r(Aye," (ViLT model)"),Aye.forEach(t),$to=i(L),Sg=n(L,"LI",{});var Lye=s(Sg);fse=n(Lye,"STRONG",{});var jat=s(fse);kto=r(jat,"vision-encoder-decoder"),jat.forEach(t),Sto=r(Lye," \u2014 "),LP=n(Lye,"A",{href:!0});var Dat=s(LP);Rto=r(Dat,"VisionEncoderDecoderConfig"),Dat.forEach(t),Pto=r(Lye," (Vision Encoder decoder model)"),Lye.forEach(t),Bto=i(L),Rg=n(L,"LI",{});var yye=s(Rg);mse=n(yye,"STRONG",{});var Gat=s(mse);Nto=r(Gat,"vision-text-dual-encoder"),Gat.forEach(t),Ito=r(yye," \u2014 "),yP=n(yye,"A",{href:!0});var Oat=s(yP);qto=r(Oat,"VisionTextDualEncoderConfig"),Oat.forEach(t),jto=r(yye," (VisionTextDualEncoder model)"),yye.forEach(t),Dto=i(L),Pg=n(L,"LI",{});var xye=s(Pg);gse=n(xye,"STRONG",{});var Vat=s(gse);Gto=r(Vat,"visual_bert"),Vat.forEach(t),Oto=r(xye," \u2014 "),xP=n(xye,"A",{href:!0});var Xat=s(xP);Vto=r(Xat,"VisualBertConfig"),Xat.forEach(t),Xto=r(xye," (VisualBERT model)"),xye.forEach(t),zto=i(L),Bg=n(L,"LI",{});var $ye=s(Bg);hse=n($ye,"STRONG",{});var zat=s(hse);Qto=r(zat,"vit"),zat.forEach(t),Wto=r($ye," \u2014 "),$P=n($ye,"A",{href:!0});var Qat=s($P);Hto=r(Qat,"ViTConfig"),Qat.forEach(t),Uto=r($ye," (ViT model)"),$ye.forEach(t),Jto=i(L),Ng=n(L,"LI",{});var kye=s(Ng);pse=n(kye,"STRONG",{});var Wat=s(pse);Yto=r(Wat,"vit_mae"),Wat.forEach(t),Kto=r(kye," \u2014 "),kP=n(kye,"A",{href:!0});var Hat=s(kP);Zto=r(Hat,"ViTMAEConfig"),Hat.forEach(t),eao=r(kye," (ViTMAE model)"),kye.forEach(t),oao=i(L),Ig=n(L,"LI",{});var Sye=s(Ig);_se=n(Sye,"STRONG",{});var Uat=s(_se);rao=r(Uat,"wav2vec2"),Uat.forEach(t),tao=r(Sye," \u2014 "),SP=n(Sye,"A",{href:!0});var Jat=s(SP);aao=r(Jat,"Wav2Vec2Config"),Jat.forEach(t),nao=r(Sye," (Wav2Vec2 model)"),Sye.forEach(t),sao=i(L),qg=n(L,"LI",{});var Rye=s(qg);use=n(Rye,"STRONG",{});var Yat=s(use);lao=r(Yat,"wav2vec2-conformer"),Yat.forEach(t),iao=r(Rye," \u2014 "),RP=n(Rye,"A",{href:!0});var Kat=s(RP);dao=r(Kat,"Wav2Vec2ConformerConfig"),Kat.forEach(t),cao=r(Rye," (Wav2Vec2-Conformer model)"),Rye.forEach(t),fao=i(L),jg=n(L,"LI",{});var Pye=s(jg);bse=n(Pye,"STRONG",{});var Zat=s(bse);mao=r(Zat,"wavlm"),Zat.forEach(t),gao=r(Pye," \u2014 "),PP=n(Pye,"A",{href:!0});var ent=s(PP);hao=r(ent,"WavLMConfig"),ent.forEach(t),pao=r(Pye," (WavLM model)"),Pye.forEach(t),_ao=i(L),Dg=n(L,"LI",{});var Bye=s(Dg);vse=n(Bye,"STRONG",{});var ont=s(vse);uao=r(ont,"xglm"),ont.forEach(t),bao=r(Bye," \u2014 "),BP=n(Bye,"A",{href:!0});var rnt=s(BP);vao=r(rnt,"XGLMConfig"),rnt.forEach(t),Fao=r(Bye," (XGLM model)"),Bye.forEach(t),Tao=i(L),Gg=n(L,"LI",{});var Nye=s(Gg);Fse=n(Nye,"STRONG",{});var tnt=s(Fse);Mao=r(tnt,"xlm"),tnt.forEach(t),Eao=r(Nye," \u2014 "),NP=n(Nye,"A",{href:!0});var ant=s(NP);Cao=r(ant,"XLMConfig"),ant.forEach(t),wao=r(Nye," (XLM model)"),Nye.forEach(t),Aao=i(L),Og=n(L,"LI",{});var Iye=s(Og);Tse=n(Iye,"STRONG",{});var nnt=s(Tse);Lao=r(nnt,"xlm-prophetnet"),nnt.forEach(t),yao=r(Iye," \u2014 "),IP=n(Iye,"A",{href:!0});var snt=s(IP);xao=r(snt,"XLMProphetNetConfig"),snt.forEach(t),$ao=r(Iye," (XLM-ProphetNet model)"),Iye.forEach(t),kao=i(L),Vg=n(L,"LI",{});var qye=s(Vg);Mse=n(qye,"STRONG",{});var lnt=s(Mse);Sao=r(lnt,"xlm-roberta"),lnt.forEach(t),Rao=r(qye," \u2014 "),qP=n(qye,"A",{href:!0});var int=s(qP);Pao=r(int,"XLMRobertaConfig"),int.forEach(t),Bao=r(qye," (XLM-RoBERTa model)"),qye.forEach(t),Nao=i(L),Xg=n(L,"LI",{});var jye=s(Xg);Ese=n(jye,"STRONG",{});var dnt=s(Ese);Iao=r(dnt,"xlm-roberta-xl"),dnt.forEach(t),qao=r(jye," \u2014 "),jP=n(jye,"A",{href:!0});var cnt=s(jP);jao=r(cnt,"XLMRobertaXLConfig"),cnt.forEach(t),Dao=r(jye," (XLM-RoBERTa-XL model)"),jye.forEach(t),Gao=i(L),zg=n(L,"LI",{});var Dye=s(zg);Cse=n(Dye,"STRONG",{});var fnt=s(Cse);Oao=r(fnt,"xlnet"),fnt.forEach(t),Vao=r(Dye," \u2014 "),DP=n(Dye,"A",{href:!0});var mnt=s(DP);Xao=r(mnt,"XLNetConfig"),mnt.forEach(t),zao=r(Dye," (XLNet model)"),Dye.forEach(t),Qao=i(L),Qg=n(L,"LI",{});var Gye=s(Qg);wse=n(Gye,"STRONG",{});var gnt=s(wse);Wao=r(gnt,"yolos"),gnt.forEach(t),Hao=r(Gye," \u2014 "),GP=n(Gye,"A",{href:!0});var hnt=s(GP);Uao=r(hnt,"YolosConfig"),hnt.forEach(t),Jao=r(Gye," (YOLOS model)"),Gye.forEach(t),Yao=i(L),Wg=n(L,"LI",{});var Oye=s(Wg);Ase=n(Oye,"STRONG",{});var pnt=s(Ase);Kao=r(pnt,"yoso"),pnt.forEach(t),Zao=r(Oye," \u2014 "),OP=n(Oye,"A",{href:!0});var _nt=s(OP);eno=r(_nt,"YosoConfig"),_nt.forEach(t),ono=r(Oye," (YOSO model)"),Oye.forEach(t),L.forEach(t),rno=i(at),T(Hg.$$.fragment,at),at.forEach(t),tno=i(tt),Ug=n(tt,"DIV",{class:!0});var yze=s(Ug);T(ay.$$.fragment,yze),ano=i(yze),Lse=n(yze,"P",{});var unt=s(Lse);nno=r(unt,"Register a new configuration for this class."),unt.forEach(t),yze.forEach(t),tt.forEach(t),xVe=i(f),Bi=n(f,"H2",{class:!0});var xze=s(Bi);Jg=n(xze,"A",{id:!0,class:!0,href:!0});var bnt=s(Jg);yse=n(bnt,"SPAN",{});var vnt=s(yse);T(ny.$$.fragment,vnt),vnt.forEach(t),bnt.forEach(t),sno=i(xze),xse=n(xze,"SPAN",{});var Fnt=s(xse);lno=r(Fnt,"AutoTokenizer"),Fnt.forEach(t),xze.forEach(t),$Ve=i(f),Ao=n(f,"DIV",{class:!0});var Ys=s(Ao);T(sy.$$.fragment,Ys),ino=i(Ys),ly=n(Ys,"P",{});var $ze=s(ly);dno=r($ze,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),VP=n($ze,"A",{href:!0});var Tnt=s(VP);cno=r(Tnt,"AutoTokenizer.from_pretrained()"),Tnt.forEach(t),fno=r($ze," class method."),$ze.forEach(t),mno=i(Ys),iy=n(Ys,"P",{});var kze=s(iy);gno=r(kze,"This class cannot be instantiated directly using "),$se=n(kze,"CODE",{});var Mnt=s($se);hno=r(Mnt,"__init__()"),Mnt.forEach(t),pno=r(kze," (throws an error)."),kze.forEach(t),_no=i(Ys),yr=n(Ys,"DIV",{class:!0});var Ks=s(yr);T(dy.$$.fragment,Ks),uno=i(Ks),kse=n(Ks,"P",{});var Ent=s(kse);bno=r(Ent,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Ent.forEach(t),vno=i(Ks),Ra=n(Ks,"P",{});var KA=s(Ra);Fno=r(KA,"The tokenizer class to instantiate is selected based on the "),Sse=n(KA,"CODE",{});var Cnt=s(Sse);Tno=r(Cnt,"model_type"),Cnt.forEach(t),Mno=r(KA,` property of the config object (either
passed as an argument or loaded from `),Rse=n(KA,"CODE",{});var wnt=s(Rse);Eno=r(wnt,"pretrained_model_name_or_path"),wnt.forEach(t),Cno=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pse=n(KA,"CODE",{});var Ant=s(Pse);wno=r(Ant,"pretrained_model_name_or_path"),Ant.forEach(t),Ano=r(KA,":"),KA.forEach(t),Lno=i(Ks),k=n(Ks,"UL",{});var S=s(k);jn=n(S,"LI",{});var pk=s(jn);Bse=n(pk,"STRONG",{});var Lnt=s(Bse);yno=r(Lnt,"albert"),Lnt.forEach(t),xno=r(pk," \u2014 "),XP=n(pk,"A",{href:!0});var ynt=s(XP);$no=r(ynt,"AlbertTokenizer"),ynt.forEach(t),kno=r(pk," or "),zP=n(pk,"A",{href:!0});var xnt=s(zP);Sno=r(xnt,"AlbertTokenizerFast"),xnt.forEach(t),Rno=r(pk," (ALBERT model)"),pk.forEach(t),Pno=i(S),Dn=n(S,"LI",{});var _k=s(Dn);Nse=n(_k,"STRONG",{});var $nt=s(Nse);Bno=r($nt,"bart"),$nt.forEach(t),Nno=r(_k," \u2014 "),QP=n(_k,"A",{href:!0});var knt=s(QP);Ino=r(knt,"BartTokenizer"),knt.forEach(t),qno=r(_k," or "),WP=n(_k,"A",{href:!0});var Snt=s(WP);jno=r(Snt,"BartTokenizerFast"),Snt.forEach(t),Dno=r(_k," (BART model)"),_k.forEach(t),Gno=i(S),Gn=n(S,"LI",{});var uk=s(Gn);Ise=n(uk,"STRONG",{});var Rnt=s(Ise);Ono=r(Rnt,"barthez"),Rnt.forEach(t),Vno=r(uk," \u2014 "),HP=n(uk,"A",{href:!0});var Pnt=s(HP);Xno=r(Pnt,"BarthezTokenizer"),Pnt.forEach(t),zno=r(uk," or "),UP=n(uk,"A",{href:!0});var Bnt=s(UP);Qno=r(Bnt,"BarthezTokenizerFast"),Bnt.forEach(t),Wno=r(uk," (BARThez model)"),uk.forEach(t),Hno=i(S),Yg=n(S,"LI",{});var Vye=s(Yg);qse=n(Vye,"STRONG",{});var Nnt=s(qse);Uno=r(Nnt,"bartpho"),Nnt.forEach(t),Jno=r(Vye," \u2014 "),JP=n(Vye,"A",{href:!0});var Int=s(JP);Yno=r(Int,"BartphoTokenizer"),Int.forEach(t),Kno=r(Vye," (BARTpho model)"),Vye.forEach(t),Zno=i(S),On=n(S,"LI",{});var bk=s(On);jse=n(bk,"STRONG",{});var qnt=s(jse);eso=r(qnt,"bert"),qnt.forEach(t),oso=r(bk," \u2014 "),YP=n(bk,"A",{href:!0});var jnt=s(YP);rso=r(jnt,"BertTokenizer"),jnt.forEach(t),tso=r(bk," or "),KP=n(bk,"A",{href:!0});var Dnt=s(KP);aso=r(Dnt,"BertTokenizerFast"),Dnt.forEach(t),nso=r(bk," (BERT model)"),bk.forEach(t),sso=i(S),Kg=n(S,"LI",{});var Xye=s(Kg);Dse=n(Xye,"STRONG",{});var Gnt=s(Dse);lso=r(Gnt,"bert-generation"),Gnt.forEach(t),iso=r(Xye," \u2014 "),ZP=n(Xye,"A",{href:!0});var Ont=s(ZP);dso=r(Ont,"BertGenerationTokenizer"),Ont.forEach(t),cso=r(Xye," (Bert Generation model)"),Xye.forEach(t),fso=i(S),Zg=n(S,"LI",{});var zye=s(Zg);Gse=n(zye,"STRONG",{});var Vnt=s(Gse);mso=r(Vnt,"bert-japanese"),Vnt.forEach(t),gso=r(zye," \u2014 "),eB=n(zye,"A",{href:!0});var Xnt=s(eB);hso=r(Xnt,"BertJapaneseTokenizer"),Xnt.forEach(t),pso=r(zye," (BertJapanese model)"),zye.forEach(t),_so=i(S),eh=n(S,"LI",{});var Qye=s(eh);Ose=n(Qye,"STRONG",{});var znt=s(Ose);uso=r(znt,"bertweet"),znt.forEach(t),bso=r(Qye," \u2014 "),oB=n(Qye,"A",{href:!0});var Qnt=s(oB);vso=r(Qnt,"BertweetTokenizer"),Qnt.forEach(t),Fso=r(Qye," (BERTweet model)"),Qye.forEach(t),Tso=i(S),Vn=n(S,"LI",{});var vk=s(Vn);Vse=n(vk,"STRONG",{});var Wnt=s(Vse);Mso=r(Wnt,"big_bird"),Wnt.forEach(t),Eso=r(vk," \u2014 "),rB=n(vk,"A",{href:!0});var Hnt=s(rB);Cso=r(Hnt,"BigBirdTokenizer"),Hnt.forEach(t),wso=r(vk," or "),tB=n(vk,"A",{href:!0});var Unt=s(tB);Aso=r(Unt,"BigBirdTokenizerFast"),Unt.forEach(t),Lso=r(vk," (BigBird model)"),vk.forEach(t),yso=i(S),Xn=n(S,"LI",{});var Fk=s(Xn);Xse=n(Fk,"STRONG",{});var Jnt=s(Xse);xso=r(Jnt,"bigbird_pegasus"),Jnt.forEach(t),$so=r(Fk," \u2014 "),aB=n(Fk,"A",{href:!0});var Ynt=s(aB);kso=r(Ynt,"PegasusTokenizer"),Ynt.forEach(t),Sso=r(Fk," or "),nB=n(Fk,"A",{href:!0});var Knt=s(nB);Rso=r(Knt,"PegasusTokenizerFast"),Knt.forEach(t),Pso=r(Fk," (BigBird-Pegasus model)"),Fk.forEach(t),Bso=i(S),zn=n(S,"LI",{});var Tk=s(zn);zse=n(Tk,"STRONG",{});var Znt=s(zse);Nso=r(Znt,"blenderbot"),Znt.forEach(t),Iso=r(Tk," \u2014 "),sB=n(Tk,"A",{href:!0});var est=s(sB);qso=r(est,"BlenderbotTokenizer"),est.forEach(t),jso=r(Tk," or "),lB=n(Tk,"A",{href:!0});var ost=s(lB);Dso=r(ost,"BlenderbotTokenizerFast"),ost.forEach(t),Gso=r(Tk," (Blenderbot model)"),Tk.forEach(t),Oso=i(S),oh=n(S,"LI",{});var Wye=s(oh);Qse=n(Wye,"STRONG",{});var rst=s(Qse);Vso=r(rst,"blenderbot-small"),rst.forEach(t),Xso=r(Wye," \u2014 "),iB=n(Wye,"A",{href:!0});var tst=s(iB);zso=r(tst,"BlenderbotSmallTokenizer"),tst.forEach(t),Qso=r(Wye," (BlenderbotSmall model)"),Wye.forEach(t),Wso=i(S),rh=n(S,"LI",{});var Hye=s(rh);Wse=n(Hye,"STRONG",{});var ast=s(Wse);Hso=r(ast,"bloom"),ast.forEach(t),Uso=r(Hye," \u2014 "),dB=n(Hye,"A",{href:!0});var nst=s(dB);Jso=r(nst,"BloomTokenizerFast"),nst.forEach(t),Yso=r(Hye," (BLOOM model)"),Hye.forEach(t),Kso=i(S),th=n(S,"LI",{});var Uye=s(th);Hse=n(Uye,"STRONG",{});var sst=s(Hse);Zso=r(sst,"byt5"),sst.forEach(t),elo=r(Uye," \u2014 "),cB=n(Uye,"A",{href:!0});var lst=s(cB);olo=r(lst,"ByT5Tokenizer"),lst.forEach(t),rlo=r(Uye," (ByT5 model)"),Uye.forEach(t),tlo=i(S),Qn=n(S,"LI",{});var Mk=s(Qn);Use=n(Mk,"STRONG",{});var ist=s(Use);alo=r(ist,"camembert"),ist.forEach(t),nlo=r(Mk," \u2014 "),fB=n(Mk,"A",{href:!0});var dst=s(fB);slo=r(dst,"CamembertTokenizer"),dst.forEach(t),llo=r(Mk," or "),mB=n(Mk,"A",{href:!0});var cst=s(mB);ilo=r(cst,"CamembertTokenizerFast"),cst.forEach(t),dlo=r(Mk," (CamemBERT model)"),Mk.forEach(t),clo=i(S),ah=n(S,"LI",{});var Jye=s(ah);Jse=n(Jye,"STRONG",{});var fst=s(Jse);flo=r(fst,"canine"),fst.forEach(t),mlo=r(Jye," \u2014 "),gB=n(Jye,"A",{href:!0});var mst=s(gB);glo=r(mst,"CanineTokenizer"),mst.forEach(t),hlo=r(Jye," (CANINE model)"),Jye.forEach(t),plo=i(S),Wn=n(S,"LI",{});var Ek=s(Wn);Yse=n(Ek,"STRONG",{});var gst=s(Yse);_lo=r(gst,"clip"),gst.forEach(t),ulo=r(Ek," \u2014 "),hB=n(Ek,"A",{href:!0});var hst=s(hB);blo=r(hst,"CLIPTokenizer"),hst.forEach(t),vlo=r(Ek," or "),pB=n(Ek,"A",{href:!0});var pst=s(pB);Flo=r(pst,"CLIPTokenizerFast"),pst.forEach(t),Tlo=r(Ek," (CLIP model)"),Ek.forEach(t),Mlo=i(S),Hn=n(S,"LI",{});var Ck=s(Hn);Kse=n(Ck,"STRONG",{});var _st=s(Kse);Elo=r(_st,"codegen"),_st.forEach(t),Clo=r(Ck," \u2014 "),_B=n(Ck,"A",{href:!0});var ust=s(_B);wlo=r(ust,"CodeGenTokenizer"),ust.forEach(t),Alo=r(Ck," or "),uB=n(Ck,"A",{href:!0});var bst=s(uB);Llo=r(bst,"CodeGenTokenizerFast"),bst.forEach(t),ylo=r(Ck," (CodeGen model)"),Ck.forEach(t),xlo=i(S),Un=n(S,"LI",{});var wk=s(Un);Zse=n(wk,"STRONG",{});var vst=s(Zse);$lo=r(vst,"convbert"),vst.forEach(t),klo=r(wk," \u2014 "),bB=n(wk,"A",{href:!0});var Fst=s(bB);Slo=r(Fst,"ConvBertTokenizer"),Fst.forEach(t),Rlo=r(wk," or "),vB=n(wk,"A",{href:!0});var Tst=s(vB);Plo=r(Tst,"ConvBertTokenizerFast"),Tst.forEach(t),Blo=r(wk," (ConvBERT model)"),wk.forEach(t),Nlo=i(S),Jn=n(S,"LI",{});var Ak=s(Jn);ele=n(Ak,"STRONG",{});var Mst=s(ele);Ilo=r(Mst,"cpm"),Mst.forEach(t),qlo=r(Ak," \u2014 "),FB=n(Ak,"A",{href:!0});var Est=s(FB);jlo=r(Est,"CpmTokenizer"),Est.forEach(t),Dlo=r(Ak," or "),TB=n(Ak,"A",{href:!0});var Cst=s(TB);Glo=r(Cst,"CpmTokenizerFast"),Cst.forEach(t),Olo=r(Ak," (CPM model)"),Ak.forEach(t),Vlo=i(S),nh=n(S,"LI",{});var Yye=s(nh);ole=n(Yye,"STRONG",{});var wst=s(ole);Xlo=r(wst,"ctrl"),wst.forEach(t),zlo=r(Yye," \u2014 "),MB=n(Yye,"A",{href:!0});var Ast=s(MB);Qlo=r(Ast,"CTRLTokenizer"),Ast.forEach(t),Wlo=r(Yye," (CTRL model)"),Yye.forEach(t),Hlo=i(S),Yn=n(S,"LI",{});var Lk=s(Yn);rle=n(Lk,"STRONG",{});var Lst=s(rle);Ulo=r(Lst,"data2vec-text"),Lst.forEach(t),Jlo=r(Lk," \u2014 "),EB=n(Lk,"A",{href:!0});var yst=s(EB);Ylo=r(yst,"RobertaTokenizer"),yst.forEach(t),Klo=r(Lk," or "),CB=n(Lk,"A",{href:!0});var xst=s(CB);Zlo=r(xst,"RobertaTokenizerFast"),xst.forEach(t),eio=r(Lk," (Data2VecText model)"),Lk.forEach(t),oio=i(S),Kn=n(S,"LI",{});var yk=s(Kn);tle=n(yk,"STRONG",{});var $st=s(tle);rio=r($st,"deberta"),$st.forEach(t),tio=r(yk," \u2014 "),wB=n(yk,"A",{href:!0});var kst=s(wB);aio=r(kst,"DebertaTokenizer"),kst.forEach(t),nio=r(yk," or "),AB=n(yk,"A",{href:!0});var Sst=s(AB);sio=r(Sst,"DebertaTokenizerFast"),Sst.forEach(t),lio=r(yk," (DeBERTa model)"),yk.forEach(t),iio=i(S),Zn=n(S,"LI",{});var xk=s(Zn);ale=n(xk,"STRONG",{});var Rst=s(ale);dio=r(Rst,"deberta-v2"),Rst.forEach(t),cio=r(xk," \u2014 "),LB=n(xk,"A",{href:!0});var Pst=s(LB);fio=r(Pst,"DebertaV2Tokenizer"),Pst.forEach(t),mio=r(xk," or "),yB=n(xk,"A",{href:!0});var Bst=s(yB);gio=r(Bst,"DebertaV2TokenizerFast"),Bst.forEach(t),hio=r(xk," (DeBERTa-v2 model)"),xk.forEach(t),pio=i(S),es=n(S,"LI",{});var $k=s(es);nle=n($k,"STRONG",{});var Nst=s(nle);_io=r(Nst,"distilbert"),Nst.forEach(t),uio=r($k," \u2014 "),xB=n($k,"A",{href:!0});var Ist=s(xB);bio=r(Ist,"DistilBertTokenizer"),Ist.forEach(t),vio=r($k," or "),$B=n($k,"A",{href:!0});var qst=s($B);Fio=r(qst,"DistilBertTokenizerFast"),qst.forEach(t),Tio=r($k," (DistilBERT model)"),$k.forEach(t),Mio=i(S),os=n(S,"LI",{});var kk=s(os);sle=n(kk,"STRONG",{});var jst=s(sle);Eio=r(jst,"dpr"),jst.forEach(t),Cio=r(kk," \u2014 "),kB=n(kk,"A",{href:!0});var Dst=s(kB);wio=r(Dst,"DPRQuestionEncoderTokenizer"),Dst.forEach(t),Aio=r(kk," or "),SB=n(kk,"A",{href:!0});var Gst=s(SB);Lio=r(Gst,"DPRQuestionEncoderTokenizerFast"),Gst.forEach(t),yio=r(kk," (DPR model)"),kk.forEach(t),xio=i(S),rs=n(S,"LI",{});var Sk=s(rs);lle=n(Sk,"STRONG",{});var Ost=s(lle);$io=r(Ost,"electra"),Ost.forEach(t),kio=r(Sk," \u2014 "),RB=n(Sk,"A",{href:!0});var Vst=s(RB);Sio=r(Vst,"ElectraTokenizer"),Vst.forEach(t),Rio=r(Sk," or "),PB=n(Sk,"A",{href:!0});var Xst=s(PB);Pio=r(Xst,"ElectraTokenizerFast"),Xst.forEach(t),Bio=r(Sk," (ELECTRA model)"),Sk.forEach(t),Nio=i(S),sh=n(S,"LI",{});var Kye=s(sh);ile=n(Kye,"STRONG",{});var zst=s(ile);Iio=r(zst,"flaubert"),zst.forEach(t),qio=r(Kye," \u2014 "),BB=n(Kye,"A",{href:!0});var Qst=s(BB);jio=r(Qst,"FlaubertTokenizer"),Qst.forEach(t),Dio=r(Kye," (FlauBERT model)"),Kye.forEach(t),Gio=i(S),ts=n(S,"LI",{});var Rk=s(ts);dle=n(Rk,"STRONG",{});var Wst=s(dle);Oio=r(Wst,"fnet"),Wst.forEach(t),Vio=r(Rk," \u2014 "),NB=n(Rk,"A",{href:!0});var Hst=s(NB);Xio=r(Hst,"FNetTokenizer"),Hst.forEach(t),zio=r(Rk," or "),IB=n(Rk,"A",{href:!0});var Ust=s(IB);Qio=r(Ust,"FNetTokenizerFast"),Ust.forEach(t),Wio=r(Rk," (FNet model)"),Rk.forEach(t),Hio=i(S),lh=n(S,"LI",{});var Zye=s(lh);cle=n(Zye,"STRONG",{});var Jst=s(cle);Uio=r(Jst,"fsmt"),Jst.forEach(t),Jio=r(Zye," \u2014 "),qB=n(Zye,"A",{href:!0});var Yst=s(qB);Yio=r(Yst,"FSMTTokenizer"),Yst.forEach(t),Kio=r(Zye," (FairSeq Machine-Translation model)"),Zye.forEach(t),Zio=i(S),as=n(S,"LI",{});var Pk=s(as);fle=n(Pk,"STRONG",{});var Kst=s(fle);edo=r(Kst,"funnel"),Kst.forEach(t),odo=r(Pk," \u2014 "),jB=n(Pk,"A",{href:!0});var Zst=s(jB);rdo=r(Zst,"FunnelTokenizer"),Zst.forEach(t),tdo=r(Pk," or "),DB=n(Pk,"A",{href:!0});var elt=s(DB);ado=r(elt,"FunnelTokenizerFast"),elt.forEach(t),ndo=r(Pk," (Funnel Transformer model)"),Pk.forEach(t),sdo=i(S),ns=n(S,"LI",{});var Bk=s(ns);mle=n(Bk,"STRONG",{});var olt=s(mle);ldo=r(olt,"gpt2"),olt.forEach(t),ido=r(Bk," \u2014 "),GB=n(Bk,"A",{href:!0});var rlt=s(GB);ddo=r(rlt,"GPT2Tokenizer"),rlt.forEach(t),cdo=r(Bk," or "),OB=n(Bk,"A",{href:!0});var tlt=s(OB);fdo=r(tlt,"GPT2TokenizerFast"),tlt.forEach(t),mdo=r(Bk," (OpenAI GPT-2 model)"),Bk.forEach(t),gdo=i(S),ss=n(S,"LI",{});var Nk=s(ss);gle=n(Nk,"STRONG",{});var alt=s(gle);hdo=r(alt,"gpt_neo"),alt.forEach(t),pdo=r(Nk," \u2014 "),VB=n(Nk,"A",{href:!0});var nlt=s(VB);_do=r(nlt,"GPT2Tokenizer"),nlt.forEach(t),udo=r(Nk," or "),XB=n(Nk,"A",{href:!0});var slt=s(XB);bdo=r(slt,"GPT2TokenizerFast"),slt.forEach(t),vdo=r(Nk," (GPT Neo model)"),Nk.forEach(t),Fdo=i(S),ih=n(S,"LI",{});var e8e=s(ih);hle=n(e8e,"STRONG",{});var llt=s(hle);Tdo=r(llt,"gpt_neox"),llt.forEach(t),Mdo=r(e8e," \u2014 "),zB=n(e8e,"A",{href:!0});var ilt=s(zB);Edo=r(ilt,"GPTNeoXTokenizerFast"),ilt.forEach(t),Cdo=r(e8e," (GPT NeoX model)"),e8e.forEach(t),wdo=i(S),ls=n(S,"LI",{});var Ik=s(ls);ple=n(Ik,"STRONG",{});var dlt=s(ple);Ado=r(dlt,"gptj"),dlt.forEach(t),Ldo=r(Ik," \u2014 "),QB=n(Ik,"A",{href:!0});var clt=s(QB);ydo=r(clt,"GPT2Tokenizer"),clt.forEach(t),xdo=r(Ik," or "),WB=n(Ik,"A",{href:!0});var flt=s(WB);$do=r(flt,"GPT2TokenizerFast"),flt.forEach(t),kdo=r(Ik," (GPT-J model)"),Ik.forEach(t),Sdo=i(S),is=n(S,"LI",{});var qk=s(is);_le=n(qk,"STRONG",{});var mlt=s(_le);Rdo=r(mlt,"groupvit"),mlt.forEach(t),Pdo=r(qk," \u2014 "),HB=n(qk,"A",{href:!0});var glt=s(HB);Bdo=r(glt,"CLIPTokenizer"),glt.forEach(t),Ndo=r(qk," or "),UB=n(qk,"A",{href:!0});var hlt=s(UB);Ido=r(hlt,"CLIPTokenizerFast"),hlt.forEach(t),qdo=r(qk," (GroupViT model)"),qk.forEach(t),jdo=i(S),ds=n(S,"LI",{});var jk=s(ds);ule=n(jk,"STRONG",{});var plt=s(ule);Ddo=r(plt,"herbert"),plt.forEach(t),Gdo=r(jk," \u2014 "),JB=n(jk,"A",{href:!0});var _lt=s(JB);Odo=r(_lt,"HerbertTokenizer"),_lt.forEach(t),Vdo=r(jk," or "),YB=n(jk,"A",{href:!0});var ult=s(YB);Xdo=r(ult,"HerbertTokenizerFast"),ult.forEach(t),zdo=r(jk," (HerBERT model)"),jk.forEach(t),Qdo=i(S),dh=n(S,"LI",{});var o8e=s(dh);ble=n(o8e,"STRONG",{});var blt=s(ble);Wdo=r(blt,"hubert"),blt.forEach(t),Hdo=r(o8e," \u2014 "),KB=n(o8e,"A",{href:!0});var vlt=s(KB);Udo=r(vlt,"Wav2Vec2CTCTokenizer"),vlt.forEach(t),Jdo=r(o8e," (Hubert model)"),o8e.forEach(t),Ydo=i(S),cs=n(S,"LI",{});var Dk=s(cs);vle=n(Dk,"STRONG",{});var Flt=s(vle);Kdo=r(Flt,"ibert"),Flt.forEach(t),Zdo=r(Dk," \u2014 "),ZB=n(Dk,"A",{href:!0});var Tlt=s(ZB);eco=r(Tlt,"RobertaTokenizer"),Tlt.forEach(t),oco=r(Dk," or "),eN=n(Dk,"A",{href:!0});var Mlt=s(eN);rco=r(Mlt,"RobertaTokenizerFast"),Mlt.forEach(t),tco=r(Dk," (I-BERT model)"),Dk.forEach(t),aco=i(S),fs=n(S,"LI",{});var Gk=s(fs);Fle=n(Gk,"STRONG",{});var Elt=s(Fle);nco=r(Elt,"layoutlm"),Elt.forEach(t),sco=r(Gk," \u2014 "),oN=n(Gk,"A",{href:!0});var Clt=s(oN);lco=r(Clt,"LayoutLMTokenizer"),Clt.forEach(t),ico=r(Gk," or "),rN=n(Gk,"A",{href:!0});var wlt=s(rN);dco=r(wlt,"LayoutLMTokenizerFast"),wlt.forEach(t),cco=r(Gk," (LayoutLM model)"),Gk.forEach(t),fco=i(S),ms=n(S,"LI",{});var Ok=s(ms);Tle=n(Ok,"STRONG",{});var Alt=s(Tle);mco=r(Alt,"layoutlmv2"),Alt.forEach(t),gco=r(Ok," \u2014 "),tN=n(Ok,"A",{href:!0});var Llt=s(tN);hco=r(Llt,"LayoutLMv2Tokenizer"),Llt.forEach(t),pco=r(Ok," or "),aN=n(Ok,"A",{href:!0});var ylt=s(aN);_co=r(ylt,"LayoutLMv2TokenizerFast"),ylt.forEach(t),uco=r(Ok," (LayoutLMv2 model)"),Ok.forEach(t),bco=i(S),gs=n(S,"LI",{});var Vk=s(gs);Mle=n(Vk,"STRONG",{});var xlt=s(Mle);vco=r(xlt,"layoutlmv3"),xlt.forEach(t),Fco=r(Vk," \u2014 "),nN=n(Vk,"A",{href:!0});var $lt=s(nN);Tco=r($lt,"LayoutLMv3Tokenizer"),$lt.forEach(t),Mco=r(Vk," or "),sN=n(Vk,"A",{href:!0});var klt=s(sN);Eco=r(klt,"LayoutLMv3TokenizerFast"),klt.forEach(t),Cco=r(Vk," (LayoutLMv3 model)"),Vk.forEach(t),wco=i(S),hs=n(S,"LI",{});var Xk=s(hs);Ele=n(Xk,"STRONG",{});var Slt=s(Ele);Aco=r(Slt,"layoutxlm"),Slt.forEach(t),Lco=r(Xk," \u2014 "),lN=n(Xk,"A",{href:!0});var Rlt=s(lN);yco=r(Rlt,"LayoutXLMTokenizer"),Rlt.forEach(t),xco=r(Xk," or "),iN=n(Xk,"A",{href:!0});var Plt=s(iN);$co=r(Plt,"LayoutXLMTokenizerFast"),Plt.forEach(t),kco=r(Xk," (LayoutXLM model)"),Xk.forEach(t),Sco=i(S),ps=n(S,"LI",{});var zk=s(ps);Cle=n(zk,"STRONG",{});var Blt=s(Cle);Rco=r(Blt,"led"),Blt.forEach(t),Pco=r(zk," \u2014 "),dN=n(zk,"A",{href:!0});var Nlt=s(dN);Bco=r(Nlt,"LEDTokenizer"),Nlt.forEach(t),Nco=r(zk," or "),cN=n(zk,"A",{href:!0});var Ilt=s(cN);Ico=r(Ilt,"LEDTokenizerFast"),Ilt.forEach(t),qco=r(zk," (LED model)"),zk.forEach(t),jco=i(S),_s=n(S,"LI",{});var Qk=s(_s);wle=n(Qk,"STRONG",{});var qlt=s(wle);Dco=r(qlt,"longformer"),qlt.forEach(t),Gco=r(Qk," \u2014 "),fN=n(Qk,"A",{href:!0});var jlt=s(fN);Oco=r(jlt,"LongformerTokenizer"),jlt.forEach(t),Vco=r(Qk," or "),mN=n(Qk,"A",{href:!0});var Dlt=s(mN);Xco=r(Dlt,"LongformerTokenizerFast"),Dlt.forEach(t),zco=r(Qk," (Longformer model)"),Qk.forEach(t),Qco=i(S),us=n(S,"LI",{});var Wk=s(us);Ale=n(Wk,"STRONG",{});var Glt=s(Ale);Wco=r(Glt,"longt5"),Glt.forEach(t),Hco=r(Wk," \u2014 "),gN=n(Wk,"A",{href:!0});var Olt=s(gN);Uco=r(Olt,"T5Tokenizer"),Olt.forEach(t),Jco=r(Wk," or "),hN=n(Wk,"A",{href:!0});var Vlt=s(hN);Yco=r(Vlt,"T5TokenizerFast"),Vlt.forEach(t),Kco=r(Wk," (LongT5 model)"),Wk.forEach(t),Zco=i(S),ch=n(S,"LI",{});var r8e=s(ch);Lle=n(r8e,"STRONG",{});var Xlt=s(Lle);efo=r(Xlt,"luke"),Xlt.forEach(t),ofo=r(r8e," \u2014 "),pN=n(r8e,"A",{href:!0});var zlt=s(pN);rfo=r(zlt,"LukeTokenizer"),zlt.forEach(t),tfo=r(r8e," (LUKE model)"),r8e.forEach(t),afo=i(S),bs=n(S,"LI",{});var Hk=s(bs);yle=n(Hk,"STRONG",{});var Qlt=s(yle);nfo=r(Qlt,"lxmert"),Qlt.forEach(t),sfo=r(Hk," \u2014 "),_N=n(Hk,"A",{href:!0});var Wlt=s(_N);lfo=r(Wlt,"LxmertTokenizer"),Wlt.forEach(t),ifo=r(Hk," or "),uN=n(Hk,"A",{href:!0});var Hlt=s(uN);dfo=r(Hlt,"LxmertTokenizerFast"),Hlt.forEach(t),cfo=r(Hk," (LXMERT model)"),Hk.forEach(t),ffo=i(S),fh=n(S,"LI",{});var t8e=s(fh);xle=n(t8e,"STRONG",{});var Ult=s(xle);mfo=r(Ult,"m2m_100"),Ult.forEach(t),gfo=r(t8e," \u2014 "),bN=n(t8e,"A",{href:!0});var Jlt=s(bN);hfo=r(Jlt,"M2M100Tokenizer"),Jlt.forEach(t),pfo=r(t8e," (M2M100 model)"),t8e.forEach(t),_fo=i(S),mh=n(S,"LI",{});var a8e=s(mh);$le=n(a8e,"STRONG",{});var Ylt=s($le);ufo=r(Ylt,"marian"),Ylt.forEach(t),bfo=r(a8e," \u2014 "),vN=n(a8e,"A",{href:!0});var Klt=s(vN);vfo=r(Klt,"MarianTokenizer"),Klt.forEach(t),Ffo=r(a8e," (Marian model)"),a8e.forEach(t),Tfo=i(S),vs=n(S,"LI",{});var Uk=s(vs);kle=n(Uk,"STRONG",{});var Zlt=s(kle);Mfo=r(Zlt,"mbart"),Zlt.forEach(t),Efo=r(Uk," \u2014 "),FN=n(Uk,"A",{href:!0});var eit=s(FN);Cfo=r(eit,"MBartTokenizer"),eit.forEach(t),wfo=r(Uk," or "),TN=n(Uk,"A",{href:!0});var oit=s(TN);Afo=r(oit,"MBartTokenizerFast"),oit.forEach(t),Lfo=r(Uk," (mBART model)"),Uk.forEach(t),yfo=i(S),Fs=n(S,"LI",{});var Jk=s(Fs);Sle=n(Jk,"STRONG",{});var rit=s(Sle);xfo=r(rit,"mbart50"),rit.forEach(t),$fo=r(Jk," \u2014 "),MN=n(Jk,"A",{href:!0});var tit=s(MN);kfo=r(tit,"MBart50Tokenizer"),tit.forEach(t),Sfo=r(Jk," or "),EN=n(Jk,"A",{href:!0});var ait=s(EN);Rfo=r(ait,"MBart50TokenizerFast"),ait.forEach(t),Pfo=r(Jk," (mBART-50 model)"),Jk.forEach(t),Bfo=i(S),Ts=n(S,"LI",{});var Yk=s(Ts);Rle=n(Yk,"STRONG",{});var nit=s(Rle);Nfo=r(nit,"megatron-bert"),nit.forEach(t),Ifo=r(Yk," \u2014 "),CN=n(Yk,"A",{href:!0});var sit=s(CN);qfo=r(sit,"BertTokenizer"),sit.forEach(t),jfo=r(Yk," or "),wN=n(Yk,"A",{href:!0});var lit=s(wN);Dfo=r(lit,"BertTokenizerFast"),lit.forEach(t),Gfo=r(Yk," (Megatron-BERT model)"),Yk.forEach(t),Ofo=i(S),gh=n(S,"LI",{});var n8e=s(gh);Ple=n(n8e,"STRONG",{});var iit=s(Ple);Vfo=r(iit,"mluke"),iit.forEach(t),Xfo=r(n8e," \u2014 "),AN=n(n8e,"A",{href:!0});var dit=s(AN);zfo=r(dit,"MLukeTokenizer"),dit.forEach(t),Qfo=r(n8e," (mLUKE model)"),n8e.forEach(t),Wfo=i(S),Ms=n(S,"LI",{});var Kk=s(Ms);Ble=n(Kk,"STRONG",{});var cit=s(Ble);Hfo=r(cit,"mobilebert"),cit.forEach(t),Ufo=r(Kk," \u2014 "),LN=n(Kk,"A",{href:!0});var fit=s(LN);Jfo=r(fit,"MobileBertTokenizer"),fit.forEach(t),Yfo=r(Kk," or "),yN=n(Kk,"A",{href:!0});var mit=s(yN);Kfo=r(mit,"MobileBertTokenizerFast"),mit.forEach(t),Zfo=r(Kk," (MobileBERT model)"),Kk.forEach(t),emo=i(S),Es=n(S,"LI",{});var Zk=s(Es);Nle=n(Zk,"STRONG",{});var git=s(Nle);omo=r(git,"mpnet"),git.forEach(t),rmo=r(Zk," \u2014 "),xN=n(Zk,"A",{href:!0});var hit=s(xN);tmo=r(hit,"MPNetTokenizer"),hit.forEach(t),amo=r(Zk," or "),$N=n(Zk,"A",{href:!0});var pit=s($N);nmo=r(pit,"MPNetTokenizerFast"),pit.forEach(t),smo=r(Zk," (MPNet model)"),Zk.forEach(t),lmo=i(S),Cs=n(S,"LI",{});var eS=s(Cs);Ile=n(eS,"STRONG",{});var _it=s(Ile);imo=r(_it,"mt5"),_it.forEach(t),dmo=r(eS," \u2014 "),kN=n(eS,"A",{href:!0});var uit=s(kN);cmo=r(uit,"MT5Tokenizer"),uit.forEach(t),fmo=r(eS," or "),SN=n(eS,"A",{href:!0});var bit=s(SN);mmo=r(bit,"MT5TokenizerFast"),bit.forEach(t),gmo=r(eS," (MT5 model)"),eS.forEach(t),hmo=i(S),ws=n(S,"LI",{});var oS=s(ws);qle=n(oS,"STRONG",{});var vit=s(qle);pmo=r(vit,"mvp"),vit.forEach(t),_mo=r(oS," \u2014 "),RN=n(oS,"A",{href:!0});var Fit=s(RN);umo=r(Fit,"MvpTokenizer"),Fit.forEach(t),bmo=r(oS," or "),PN=n(oS,"A",{href:!0});var Tit=s(PN);vmo=r(Tit,"MvpTokenizerFast"),Tit.forEach(t),Fmo=r(oS," (MVP model)"),oS.forEach(t),Tmo=i(S),As=n(S,"LI",{});var rS=s(As);jle=n(rS,"STRONG",{});var Mit=s(jle);Mmo=r(Mit,"nezha"),Mit.forEach(t),Emo=r(rS," \u2014 "),BN=n(rS,"A",{href:!0});var Eit=s(BN);Cmo=r(Eit,"BertTokenizer"),Eit.forEach(t),wmo=r(rS," or "),NN=n(rS,"A",{href:!0});var Cit=s(NN);Amo=r(Cit,"BertTokenizerFast"),Cit.forEach(t),Lmo=r(rS," (Nezha model)"),rS.forEach(t),ymo=i(S),Ls=n(S,"LI",{});var tS=s(Ls);Dle=n(tS,"STRONG",{});var wit=s(Dle);xmo=r(wit,"nystromformer"),wit.forEach(t),$mo=r(tS," \u2014 "),IN=n(tS,"A",{href:!0});var Ait=s(IN);kmo=r(Ait,"AlbertTokenizer"),Ait.forEach(t),Smo=r(tS," or "),qN=n(tS,"A",{href:!0});var Lit=s(qN);Rmo=r(Lit,"AlbertTokenizerFast"),Lit.forEach(t),Pmo=r(tS," (Nystr\xF6mformer model)"),tS.forEach(t),Bmo=i(S),ys=n(S,"LI",{});var aS=s(ys);Gle=n(aS,"STRONG",{});var yit=s(Gle);Nmo=r(yit,"openai-gpt"),yit.forEach(t),Imo=r(aS," \u2014 "),jN=n(aS,"A",{href:!0});var xit=s(jN);qmo=r(xit,"OpenAIGPTTokenizer"),xit.forEach(t),jmo=r(aS," or "),DN=n(aS,"A",{href:!0});var $it=s(DN);Dmo=r($it,"OpenAIGPTTokenizerFast"),$it.forEach(t),Gmo=r(aS," (OpenAI GPT model)"),aS.forEach(t),Omo=i(S),hh=n(S,"LI",{});var s8e=s(hh);Ole=n(s8e,"STRONG",{});var kit=s(Ole);Vmo=r(kit,"opt"),kit.forEach(t),Xmo=r(s8e," \u2014 "),GN=n(s8e,"A",{href:!0});var Sit=s(GN);zmo=r(Sit,"GPT2Tokenizer"),Sit.forEach(t),Qmo=r(s8e," (OPT model)"),s8e.forEach(t),Wmo=i(S),xs=n(S,"LI",{});var nS=s(xs);Vle=n(nS,"STRONG",{});var Rit=s(Vle);Hmo=r(Rit,"pegasus"),Rit.forEach(t),Umo=r(nS," \u2014 "),ON=n(nS,"A",{href:!0});var Pit=s(ON);Jmo=r(Pit,"PegasusTokenizer"),Pit.forEach(t),Ymo=r(nS," or "),VN=n(nS,"A",{href:!0});var Bit=s(VN);Kmo=r(Bit,"PegasusTokenizerFast"),Bit.forEach(t),Zmo=r(nS," (Pegasus model)"),nS.forEach(t),ego=i(S),ph=n(S,"LI",{});var l8e=s(ph);Xle=n(l8e,"STRONG",{});var Nit=s(Xle);ogo=r(Nit,"perceiver"),Nit.forEach(t),rgo=r(l8e," \u2014 "),XN=n(l8e,"A",{href:!0});var Iit=s(XN);tgo=r(Iit,"PerceiverTokenizer"),Iit.forEach(t),ago=r(l8e," (Perceiver model)"),l8e.forEach(t),ngo=i(S),_h=n(S,"LI",{});var i8e=s(_h);zle=n(i8e,"STRONG",{});var qit=s(zle);sgo=r(qit,"phobert"),qit.forEach(t),lgo=r(i8e," \u2014 "),zN=n(i8e,"A",{href:!0});var jit=s(zN);igo=r(jit,"PhobertTokenizer"),jit.forEach(t),dgo=r(i8e," (PhoBERT model)"),i8e.forEach(t),cgo=i(S),uh=n(S,"LI",{});var d8e=s(uh);Qle=n(d8e,"STRONG",{});var Dit=s(Qle);fgo=r(Dit,"plbart"),Dit.forEach(t),mgo=r(d8e," \u2014 "),QN=n(d8e,"A",{href:!0});var Git=s(QN);ggo=r(Git,"PLBartTokenizer"),Git.forEach(t),hgo=r(d8e," (PLBart model)"),d8e.forEach(t),pgo=i(S),bh=n(S,"LI",{});var c8e=s(bh);Wle=n(c8e,"STRONG",{});var Oit=s(Wle);_go=r(Oit,"prophetnet"),Oit.forEach(t),ugo=r(c8e," \u2014 "),WN=n(c8e,"A",{href:!0});var Vit=s(WN);bgo=r(Vit,"ProphetNetTokenizer"),Vit.forEach(t),vgo=r(c8e," (ProphetNet model)"),c8e.forEach(t),Fgo=i(S),$s=n(S,"LI",{});var sS=s($s);Hle=n(sS,"STRONG",{});var Xit=s(Hle);Tgo=r(Xit,"qdqbert"),Xit.forEach(t),Mgo=r(sS," \u2014 "),HN=n(sS,"A",{href:!0});var zit=s(HN);Ego=r(zit,"BertTokenizer"),zit.forEach(t),Cgo=r(sS," or "),UN=n(sS,"A",{href:!0});var Qit=s(UN);wgo=r(Qit,"BertTokenizerFast"),Qit.forEach(t),Ago=r(sS," (QDQBert model)"),sS.forEach(t),Lgo=i(S),vh=n(S,"LI",{});var f8e=s(vh);Ule=n(f8e,"STRONG",{});var Wit=s(Ule);ygo=r(Wit,"rag"),Wit.forEach(t),xgo=r(f8e," \u2014 "),JN=n(f8e,"A",{href:!0});var Hit=s(JN);$go=r(Hit,"RagTokenizer"),Hit.forEach(t),kgo=r(f8e," (RAG model)"),f8e.forEach(t),Sgo=i(S),ks=n(S,"LI",{});var lS=s(ks);Jle=n(lS,"STRONG",{});var Uit=s(Jle);Rgo=r(Uit,"realm"),Uit.forEach(t),Pgo=r(lS," \u2014 "),YN=n(lS,"A",{href:!0});var Jit=s(YN);Bgo=r(Jit,"RealmTokenizer"),Jit.forEach(t),Ngo=r(lS," or "),KN=n(lS,"A",{href:!0});var Yit=s(KN);Igo=r(Yit,"RealmTokenizerFast"),Yit.forEach(t),qgo=r(lS," (REALM model)"),lS.forEach(t),jgo=i(S),Ss=n(S,"LI",{});var iS=s(Ss);Yle=n(iS,"STRONG",{});var Kit=s(Yle);Dgo=r(Kit,"reformer"),Kit.forEach(t),Ggo=r(iS," \u2014 "),ZN=n(iS,"A",{href:!0});var Zit=s(ZN);Ogo=r(Zit,"ReformerTokenizer"),Zit.forEach(t),Vgo=r(iS," or "),eI=n(iS,"A",{href:!0});var edt=s(eI);Xgo=r(edt,"ReformerTokenizerFast"),edt.forEach(t),zgo=r(iS," (Reformer model)"),iS.forEach(t),Qgo=i(S),Rs=n(S,"LI",{});var dS=s(Rs);Kle=n(dS,"STRONG",{});var odt=s(Kle);Wgo=r(odt,"rembert"),odt.forEach(t),Hgo=r(dS," \u2014 "),oI=n(dS,"A",{href:!0});var rdt=s(oI);Ugo=r(rdt,"RemBertTokenizer"),rdt.forEach(t),Jgo=r(dS," or "),rI=n(dS,"A",{href:!0});var tdt=s(rI);Ygo=r(tdt,"RemBertTokenizerFast"),tdt.forEach(t),Kgo=r(dS," (RemBERT model)"),dS.forEach(t),Zgo=i(S),Ps=n(S,"LI",{});var cS=s(Ps);Zle=n(cS,"STRONG",{});var adt=s(Zle);eho=r(adt,"retribert"),adt.forEach(t),oho=r(cS," \u2014 "),tI=n(cS,"A",{href:!0});var ndt=s(tI);rho=r(ndt,"RetriBertTokenizer"),ndt.forEach(t),tho=r(cS," or "),aI=n(cS,"A",{href:!0});var sdt=s(aI);aho=r(sdt,"RetriBertTokenizerFast"),sdt.forEach(t),nho=r(cS," (RetriBERT model)"),cS.forEach(t),sho=i(S),Bs=n(S,"LI",{});var fS=s(Bs);eie=n(fS,"STRONG",{});var ldt=s(eie);lho=r(ldt,"roberta"),ldt.forEach(t),iho=r(fS," \u2014 "),nI=n(fS,"A",{href:!0});var idt=s(nI);dho=r(idt,"RobertaTokenizer"),idt.forEach(t),cho=r(fS," or "),sI=n(fS,"A",{href:!0});var ddt=s(sI);fho=r(ddt,"RobertaTokenizerFast"),ddt.forEach(t),mho=r(fS," (RoBERTa model)"),fS.forEach(t),gho=i(S),Ns=n(S,"LI",{});var mS=s(Ns);oie=n(mS,"STRONG",{});var cdt=s(oie);hho=r(cdt,"roformer"),cdt.forEach(t),pho=r(mS," \u2014 "),lI=n(mS,"A",{href:!0});var fdt=s(lI);_ho=r(fdt,"RoFormerTokenizer"),fdt.forEach(t),uho=r(mS," or "),iI=n(mS,"A",{href:!0});var mdt=s(iI);bho=r(mdt,"RoFormerTokenizerFast"),mdt.forEach(t),vho=r(mS," (RoFormer model)"),mS.forEach(t),Fho=i(S),Fh=n(S,"LI",{});var m8e=s(Fh);rie=n(m8e,"STRONG",{});var gdt=s(rie);Tho=r(gdt,"speech_to_text"),gdt.forEach(t),Mho=r(m8e," \u2014 "),dI=n(m8e,"A",{href:!0});var hdt=s(dI);Eho=r(hdt,"Speech2TextTokenizer"),hdt.forEach(t),Cho=r(m8e," (Speech2Text model)"),m8e.forEach(t),who=i(S),Th=n(S,"LI",{});var g8e=s(Th);tie=n(g8e,"STRONG",{});var pdt=s(tie);Aho=r(pdt,"speech_to_text_2"),pdt.forEach(t),Lho=r(g8e," \u2014 "),cI=n(g8e,"A",{href:!0});var _dt=s(cI);yho=r(_dt,"Speech2Text2Tokenizer"),_dt.forEach(t),xho=r(g8e," (Speech2Text2 model)"),g8e.forEach(t),$ho=i(S),Is=n(S,"LI",{});var gS=s(Is);aie=n(gS,"STRONG",{});var udt=s(aie);kho=r(udt,"splinter"),udt.forEach(t),Sho=r(gS," \u2014 "),fI=n(gS,"A",{href:!0});var bdt=s(fI);Rho=r(bdt,"SplinterTokenizer"),bdt.forEach(t),Pho=r(gS," or "),mI=n(gS,"A",{href:!0});var vdt=s(mI);Bho=r(vdt,"SplinterTokenizerFast"),vdt.forEach(t),Nho=r(gS," (Splinter model)"),gS.forEach(t),Iho=i(S),qs=n(S,"LI",{});var hS=s(qs);nie=n(hS,"STRONG",{});var Fdt=s(nie);qho=r(Fdt,"squeezebert"),Fdt.forEach(t),jho=r(hS," \u2014 "),gI=n(hS,"A",{href:!0});var Tdt=s(gI);Dho=r(Tdt,"SqueezeBertTokenizer"),Tdt.forEach(t),Gho=r(hS," or "),hI=n(hS,"A",{href:!0});var Mdt=s(hI);Oho=r(Mdt,"SqueezeBertTokenizerFast"),Mdt.forEach(t),Vho=r(hS," (SqueezeBERT model)"),hS.forEach(t),Xho=i(S),js=n(S,"LI",{});var pS=s(js);sie=n(pS,"STRONG",{});var Edt=s(sie);zho=r(Edt,"t5"),Edt.forEach(t),Qho=r(pS," \u2014 "),pI=n(pS,"A",{href:!0});var Cdt=s(pI);Who=r(Cdt,"T5Tokenizer"),Cdt.forEach(t),Hho=r(pS," or "),_I=n(pS,"A",{href:!0});var wdt=s(_I);Uho=r(wdt,"T5TokenizerFast"),wdt.forEach(t),Jho=r(pS," (T5 model)"),pS.forEach(t),Yho=i(S),Mh=n(S,"LI",{});var h8e=s(Mh);lie=n(h8e,"STRONG",{});var Adt=s(lie);Kho=r(Adt,"tapas"),Adt.forEach(t),Zho=r(h8e," \u2014 "),uI=n(h8e,"A",{href:!0});var Ldt=s(uI);epo=r(Ldt,"TapasTokenizer"),Ldt.forEach(t),opo=r(h8e," (TAPAS model)"),h8e.forEach(t),rpo=i(S),Eh=n(S,"LI",{});var p8e=s(Eh);iie=n(p8e,"STRONG",{});var ydt=s(iie);tpo=r(ydt,"tapex"),ydt.forEach(t),apo=r(p8e," \u2014 "),bI=n(p8e,"A",{href:!0});var xdt=s(bI);npo=r(xdt,"TapexTokenizer"),xdt.forEach(t),spo=r(p8e," (TAPEX model)"),p8e.forEach(t),lpo=i(S),Ch=n(S,"LI",{});var _8e=s(Ch);die=n(_8e,"STRONG",{});var $dt=s(die);ipo=r($dt,"transfo-xl"),$dt.forEach(t),dpo=r(_8e," \u2014 "),vI=n(_8e,"A",{href:!0});var kdt=s(vI);cpo=r(kdt,"TransfoXLTokenizer"),kdt.forEach(t),fpo=r(_8e," (Transformer-XL model)"),_8e.forEach(t),mpo=i(S),Ds=n(S,"LI",{});var _S=s(Ds);cie=n(_S,"STRONG",{});var Sdt=s(cie);gpo=r(Sdt,"vilt"),Sdt.forEach(t),hpo=r(_S," \u2014 "),FI=n(_S,"A",{href:!0});var Rdt=s(FI);ppo=r(Rdt,"BertTokenizer"),Rdt.forEach(t),_po=r(_S," or "),TI=n(_S,"A",{href:!0});var Pdt=s(TI);upo=r(Pdt,"BertTokenizerFast"),Pdt.forEach(t),bpo=r(_S," (ViLT model)"),_S.forEach(t),vpo=i(S),Gs=n(S,"LI",{});var uS=s(Gs);fie=n(uS,"STRONG",{});var Bdt=s(fie);Fpo=r(Bdt,"visual_bert"),Bdt.forEach(t),Tpo=r(uS," \u2014 "),MI=n(uS,"A",{href:!0});var Ndt=s(MI);Mpo=r(Ndt,"BertTokenizer"),Ndt.forEach(t),Epo=r(uS," or "),EI=n(uS,"A",{href:!0});var Idt=s(EI);Cpo=r(Idt,"BertTokenizerFast"),Idt.forEach(t),wpo=r(uS," (VisualBERT model)"),uS.forEach(t),Apo=i(S),wh=n(S,"LI",{});var u8e=s(wh);mie=n(u8e,"STRONG",{});var qdt=s(mie);Lpo=r(qdt,"wav2vec2"),qdt.forEach(t),ypo=r(u8e," \u2014 "),CI=n(u8e,"A",{href:!0});var jdt=s(CI);xpo=r(jdt,"Wav2Vec2CTCTokenizer"),jdt.forEach(t),$po=r(u8e," (Wav2Vec2 model)"),u8e.forEach(t),kpo=i(S),Ah=n(S,"LI",{});var b8e=s(Ah);gie=n(b8e,"STRONG",{});var Ddt=s(gie);Spo=r(Ddt,"wav2vec2-conformer"),Ddt.forEach(t),Rpo=r(b8e," \u2014 "),wI=n(b8e,"A",{href:!0});var Gdt=s(wI);Ppo=r(Gdt,"Wav2Vec2CTCTokenizer"),Gdt.forEach(t),Bpo=r(b8e," (Wav2Vec2-Conformer model)"),b8e.forEach(t),Npo=i(S),Lh=n(S,"LI",{});var v8e=s(Lh);hie=n(v8e,"STRONG",{});var Odt=s(hie);Ipo=r(Odt,"wav2vec2_phoneme"),Odt.forEach(t),qpo=r(v8e," \u2014 "),AI=n(v8e,"A",{href:!0});var Vdt=s(AI);jpo=r(Vdt,"Wav2Vec2PhonemeCTCTokenizer"),Vdt.forEach(t),Dpo=r(v8e," (Wav2Vec2Phoneme model)"),v8e.forEach(t),Gpo=i(S),Os=n(S,"LI",{});var bS=s(Os);pie=n(bS,"STRONG",{});var Xdt=s(pie);Opo=r(Xdt,"xglm"),Xdt.forEach(t),Vpo=r(bS," \u2014 "),LI=n(bS,"A",{href:!0});var zdt=s(LI);Xpo=r(zdt,"XGLMTokenizer"),zdt.forEach(t),zpo=r(bS," or "),yI=n(bS,"A",{href:!0});var Qdt=s(yI);Qpo=r(Qdt,"XGLMTokenizerFast"),Qdt.forEach(t),Wpo=r(bS," (XGLM model)"),bS.forEach(t),Hpo=i(S),yh=n(S,"LI",{});var F8e=s(yh);_ie=n(F8e,"STRONG",{});var Wdt=s(_ie);Upo=r(Wdt,"xlm"),Wdt.forEach(t),Jpo=r(F8e," \u2014 "),xI=n(F8e,"A",{href:!0});var Hdt=s(xI);Ypo=r(Hdt,"XLMTokenizer"),Hdt.forEach(t),Kpo=r(F8e," (XLM model)"),F8e.forEach(t),Zpo=i(S),xh=n(S,"LI",{});var T8e=s(xh);uie=n(T8e,"STRONG",{});var Udt=s(uie);e_o=r(Udt,"xlm-prophetnet"),Udt.forEach(t),o_o=r(T8e," \u2014 "),$I=n(T8e,"A",{href:!0});var Jdt=s($I);r_o=r(Jdt,"XLMProphetNetTokenizer"),Jdt.forEach(t),t_o=r(T8e," (XLM-ProphetNet model)"),T8e.forEach(t),a_o=i(S),Vs=n(S,"LI",{});var vS=s(Vs);bie=n(vS,"STRONG",{});var Ydt=s(bie);n_o=r(Ydt,"xlm-roberta"),Ydt.forEach(t),s_o=r(vS," \u2014 "),kI=n(vS,"A",{href:!0});var Kdt=s(kI);l_o=r(Kdt,"XLMRobertaTokenizer"),Kdt.forEach(t),i_o=r(vS," or "),SI=n(vS,"A",{href:!0});var Zdt=s(SI);d_o=r(Zdt,"XLMRobertaTokenizerFast"),Zdt.forEach(t),c_o=r(vS," (XLM-RoBERTa model)"),vS.forEach(t),f_o=i(S),Xs=n(S,"LI",{});var FS=s(Xs);vie=n(FS,"STRONG",{});var ect=s(vie);m_o=r(ect,"xlm-roberta-xl"),ect.forEach(t),g_o=r(FS," \u2014 "),RI=n(FS,"A",{href:!0});var oct=s(RI);h_o=r(oct,"RobertaTokenizer"),oct.forEach(t),p_o=r(FS," or "),PI=n(FS,"A",{href:!0});var rct=s(PI);__o=r(rct,"RobertaTokenizerFast"),rct.forEach(t),u_o=r(FS," (XLM-RoBERTa-XL model)"),FS.forEach(t),b_o=i(S),zs=n(S,"LI",{});var TS=s(zs);Fie=n(TS,"STRONG",{});var tct=s(Fie);v_o=r(tct,"xlnet"),tct.forEach(t),F_o=r(TS," \u2014 "),BI=n(TS,"A",{href:!0});var act=s(BI);T_o=r(act,"XLNetTokenizer"),act.forEach(t),M_o=r(TS," or "),NI=n(TS,"A",{href:!0});var nct=s(NI);E_o=r(nct,"XLNetTokenizerFast"),nct.forEach(t),C_o=r(TS," (XLNet model)"),TS.forEach(t),w_o=i(S),Qs=n(S,"LI",{});var MS=s(Qs);Tie=n(MS,"STRONG",{});var sct=s(Tie);A_o=r(sct,"yoso"),sct.forEach(t),L_o=r(MS," \u2014 "),II=n(MS,"A",{href:!0});var lct=s(II);y_o=r(lct,"AlbertTokenizer"),lct.forEach(t),x_o=r(MS," or "),qI=n(MS,"A",{href:!0});var ict=s(qI);$_o=r(ict,"AlbertTokenizerFast"),ict.forEach(t),k_o=r(MS," (YOSO model)"),MS.forEach(t),S.forEach(t),S_o=i(Ks),T($h.$$.fragment,Ks),Ks.forEach(t),R_o=i(Ys),kh=n(Ys,"DIV",{class:!0});var Sze=s(kh);T(cy.$$.fragment,Sze),P_o=i(Sze),Mie=n(Sze,"P",{});var dct=s(Mie);B_o=r(dct,"Register a new tokenizer in this mapping."),dct.forEach(t),Sze.forEach(t),Ys.forEach(t),kVe=i(f),Ni=n(f,"H2",{class:!0});var Rze=s(Ni);Sh=n(Rze,"A",{id:!0,class:!0,href:!0});var cct=s(Sh);Eie=n(cct,"SPAN",{});var fct=s(Eie);T(fy.$$.fragment,fct),fct.forEach(t),cct.forEach(t),N_o=i(Rze),Cie=n(Rze,"SPAN",{});var mct=s(Cie);I_o=r(mct,"AutoFeatureExtractor"),mct.forEach(t),Rze.forEach(t),SVe=i(f),Lo=n(f,"DIV",{class:!0});var Zs=s(Lo);T(my.$$.fragment,Zs),q_o=i(Zs),gy=n(Zs,"P",{});var Pze=s(gy);j_o=r(Pze,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),jI=n(Pze,"A",{href:!0});var gct=s(jI);D_o=r(gct,"AutoFeatureExtractor.from_pretrained()"),gct.forEach(t),G_o=r(Pze," class method."),Pze.forEach(t),O_o=i(Zs),hy=n(Zs,"P",{});var Bze=s(hy);V_o=r(Bze,"This class cannot be instantiated directly using "),wie=n(Bze,"CODE",{});var hct=s(wie);X_o=r(hct,"__init__()"),hct.forEach(t),z_o=r(Bze," (throws an error)."),Bze.forEach(t),Q_o=i(Zs),He=n(Zs,"DIV",{class:!0});var ta=s(He);T(py.$$.fragment,ta),W_o=i(ta),Aie=n(ta,"P",{});var pct=s(Aie);H_o=r(pct,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),pct.forEach(t),U_o=i(ta),Pa=n(ta,"P",{});var ZA=s(Pa);J_o=r(ZA,"The feature extractor class to instantiate is selected based on the "),Lie=n(ZA,"CODE",{});var _ct=s(Lie);Y_o=r(_ct,"model_type"),_ct.forEach(t),K_o=r(ZA,` property of the config object
(either passed as an argument or loaded from `),yie=n(ZA,"CODE",{});var uct=s(yie);Z_o=r(uct,"pretrained_model_name_or_path"),uct.forEach(t),euo=r(ZA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),xie=n(ZA,"CODE",{});var bct=s(xie);ouo=r(bct,"pretrained_model_name_or_path"),bct.forEach(t),ruo=r(ZA,":"),ZA.forEach(t),tuo=i(ta),Y=n(ta,"UL",{});var K=s(Y);Rh=n(K,"LI",{});var M8e=s(Rh);$ie=n(M8e,"STRONG",{});var vct=s($ie);auo=r(vct,"beit"),vct.forEach(t),nuo=r(M8e," \u2014 "),DI=n(M8e,"A",{href:!0});var Fct=s(DI);suo=r(Fct,"BeitFeatureExtractor"),Fct.forEach(t),luo=r(M8e," (BEiT model)"),M8e.forEach(t),iuo=i(K),Ph=n(K,"LI",{});var E8e=s(Ph);kie=n(E8e,"STRONG",{});var Tct=s(kie);duo=r(Tct,"clip"),Tct.forEach(t),cuo=r(E8e," \u2014 "),GI=n(E8e,"A",{href:!0});var Mct=s(GI);fuo=r(Mct,"CLIPFeatureExtractor"),Mct.forEach(t),muo=r(E8e," (CLIP model)"),E8e.forEach(t),guo=i(K),Bh=n(K,"LI",{});var C8e=s(Bh);Sie=n(C8e,"STRONG",{});var Ect=s(Sie);huo=r(Ect,"convnext"),Ect.forEach(t),puo=r(C8e," \u2014 "),OI=n(C8e,"A",{href:!0});var Cct=s(OI);_uo=r(Cct,"ConvNextFeatureExtractor"),Cct.forEach(t),uuo=r(C8e," (ConvNeXT model)"),C8e.forEach(t),buo=i(K),Nh=n(K,"LI",{});var w8e=s(Nh);Rie=n(w8e,"STRONG",{});var wct=s(Rie);vuo=r(wct,"cvt"),wct.forEach(t),Fuo=r(w8e," \u2014 "),VI=n(w8e,"A",{href:!0});var Act=s(VI);Tuo=r(Act,"ConvNextFeatureExtractor"),Act.forEach(t),Muo=r(w8e," (CvT model)"),w8e.forEach(t),Euo=i(K),Ih=n(K,"LI",{});var A8e=s(Ih);Pie=n(A8e,"STRONG",{});var Lct=s(Pie);Cuo=r(Lct,"data2vec-audio"),Lct.forEach(t),wuo=r(A8e," \u2014 "),XI=n(A8e,"A",{href:!0});var yct=s(XI);Auo=r(yct,"Wav2Vec2FeatureExtractor"),yct.forEach(t),Luo=r(A8e," (Data2VecAudio model)"),A8e.forEach(t),yuo=i(K),qh=n(K,"LI",{});var L8e=s(qh);Bie=n(L8e,"STRONG",{});var xct=s(Bie);xuo=r(xct,"data2vec-vision"),xct.forEach(t),$uo=r(L8e," \u2014 "),zI=n(L8e,"A",{href:!0});var $ct=s(zI);kuo=r($ct,"BeitFeatureExtractor"),$ct.forEach(t),Suo=r(L8e," (Data2VecVision model)"),L8e.forEach(t),Ruo=i(K),jh=n(K,"LI",{});var y8e=s(jh);Nie=n(y8e,"STRONG",{});var kct=s(Nie);Puo=r(kct,"deit"),kct.forEach(t),Buo=r(y8e," \u2014 "),QI=n(y8e,"A",{href:!0});var Sct=s(QI);Nuo=r(Sct,"DeiTFeatureExtractor"),Sct.forEach(t),Iuo=r(y8e," (DeiT model)"),y8e.forEach(t),quo=i(K),Dh=n(K,"LI",{});var x8e=s(Dh);Iie=n(x8e,"STRONG",{});var Rct=s(Iie);juo=r(Rct,"detr"),Rct.forEach(t),Duo=r(x8e," \u2014 "),WI=n(x8e,"A",{href:!0});var Pct=s(WI);Guo=r(Pct,"DetrFeatureExtractor"),Pct.forEach(t),Ouo=r(x8e," (DETR model)"),x8e.forEach(t),Vuo=i(K),Gh=n(K,"LI",{});var $8e=s(Gh);qie=n($8e,"STRONG",{});var Bct=s(qie);Xuo=r(Bct,"dpt"),Bct.forEach(t),zuo=r($8e," \u2014 "),HI=n($8e,"A",{href:!0});var Nct=s(HI);Quo=r(Nct,"DPTFeatureExtractor"),Nct.forEach(t),Wuo=r($8e," (DPT model)"),$8e.forEach(t),Huo=i(K),Oh=n(K,"LI",{});var k8e=s(Oh);jie=n(k8e,"STRONG",{});var Ict=s(jie);Uuo=r(Ict,"flava"),Ict.forEach(t),Juo=r(k8e," \u2014 "),UI=n(k8e,"A",{href:!0});var qct=s(UI);Yuo=r(qct,"FlavaFeatureExtractor"),qct.forEach(t),Kuo=r(k8e," (FLAVA model)"),k8e.forEach(t),Zuo=i(K),Vh=n(K,"LI",{});var S8e=s(Vh);Die=n(S8e,"STRONG",{});var jct=s(Die);e2o=r(jct,"glpn"),jct.forEach(t),o2o=r(S8e," \u2014 "),JI=n(S8e,"A",{href:!0});var Dct=s(JI);r2o=r(Dct,"GLPNFeatureExtractor"),Dct.forEach(t),t2o=r(S8e," (GLPN model)"),S8e.forEach(t),a2o=i(K),Xh=n(K,"LI",{});var R8e=s(Xh);Gie=n(R8e,"STRONG",{});var Gct=s(Gie);n2o=r(Gct,"groupvit"),Gct.forEach(t),s2o=r(R8e," \u2014 "),YI=n(R8e,"A",{href:!0});var Oct=s(YI);l2o=r(Oct,"CLIPFeatureExtractor"),Oct.forEach(t),i2o=r(R8e," (GroupViT model)"),R8e.forEach(t),d2o=i(K),zh=n(K,"LI",{});var P8e=s(zh);Oie=n(P8e,"STRONG",{});var Vct=s(Oie);c2o=r(Vct,"hubert"),Vct.forEach(t),f2o=r(P8e," \u2014 "),KI=n(P8e,"A",{href:!0});var Xct=s(KI);m2o=r(Xct,"Wav2Vec2FeatureExtractor"),Xct.forEach(t),g2o=r(P8e," (Hubert model)"),P8e.forEach(t),h2o=i(K),Qh=n(K,"LI",{});var B8e=s(Qh);Vie=n(B8e,"STRONG",{});var zct=s(Vie);p2o=r(zct,"imagegpt"),zct.forEach(t),_2o=r(B8e," \u2014 "),ZI=n(B8e,"A",{href:!0});var Qct=s(ZI);u2o=r(Qct,"ImageGPTFeatureExtractor"),Qct.forEach(t),b2o=r(B8e," (ImageGPT model)"),B8e.forEach(t),v2o=i(K),Wh=n(K,"LI",{});var N8e=s(Wh);Xie=n(N8e,"STRONG",{});var Wct=s(Xie);F2o=r(Wct,"layoutlmv2"),Wct.forEach(t),T2o=r(N8e," \u2014 "),eq=n(N8e,"A",{href:!0});var Hct=s(eq);M2o=r(Hct,"LayoutLMv2FeatureExtractor"),Hct.forEach(t),E2o=r(N8e," (LayoutLMv2 model)"),N8e.forEach(t),C2o=i(K),Hh=n(K,"LI",{});var I8e=s(Hh);zie=n(I8e,"STRONG",{});var Uct=s(zie);w2o=r(Uct,"layoutlmv3"),Uct.forEach(t),A2o=r(I8e," \u2014 "),oq=n(I8e,"A",{href:!0});var Jct=s(oq);L2o=r(Jct,"LayoutLMv3FeatureExtractor"),Jct.forEach(t),y2o=r(I8e," (LayoutLMv3 model)"),I8e.forEach(t),x2o=i(K),Uh=n(K,"LI",{});var q8e=s(Uh);Qie=n(q8e,"STRONG",{});var Yct=s(Qie);$2o=r(Yct,"levit"),Yct.forEach(t),k2o=r(q8e," \u2014 "),rq=n(q8e,"A",{href:!0});var Kct=s(rq);S2o=r(Kct,"LevitFeatureExtractor"),Kct.forEach(t),R2o=r(q8e," (LeViT model)"),q8e.forEach(t),P2o=i(K),Jh=n(K,"LI",{});var j8e=s(Jh);Wie=n(j8e,"STRONG",{});var Zct=s(Wie);B2o=r(Zct,"maskformer"),Zct.forEach(t),N2o=r(j8e," \u2014 "),tq=n(j8e,"A",{href:!0});var eft=s(tq);I2o=r(eft,"MaskFormerFeatureExtractor"),eft.forEach(t),q2o=r(j8e," (MaskFormer model)"),j8e.forEach(t),j2o=i(K),Yh=n(K,"LI",{});var D8e=s(Yh);Hie=n(D8e,"STRONG",{});var oft=s(Hie);D2o=r(oft,"mctct"),oft.forEach(t),G2o=r(D8e," \u2014 "),aq=n(D8e,"A",{href:!0});var rft=s(aq);O2o=r(rft,"MCTCTFeatureExtractor"),rft.forEach(t),V2o=r(D8e," (M-CTC-T model)"),D8e.forEach(t),X2o=i(K),Kh=n(K,"LI",{});var G8e=s(Kh);Uie=n(G8e,"STRONG",{});var tft=s(Uie);z2o=r(tft,"perceiver"),tft.forEach(t),Q2o=r(G8e," \u2014 "),nq=n(G8e,"A",{href:!0});var aft=s(nq);W2o=r(aft,"PerceiverFeatureExtractor"),aft.forEach(t),H2o=r(G8e," (Perceiver model)"),G8e.forEach(t),U2o=i(K),Zh=n(K,"LI",{});var O8e=s(Zh);Jie=n(O8e,"STRONG",{});var nft=s(Jie);J2o=r(nft,"poolformer"),nft.forEach(t),Y2o=r(O8e," \u2014 "),sq=n(O8e,"A",{href:!0});var sft=s(sq);K2o=r(sft,"PoolFormerFeatureExtractor"),sft.forEach(t),Z2o=r(O8e," (PoolFormer model)"),O8e.forEach(t),e1o=i(K),ep=n(K,"LI",{});var V8e=s(ep);Yie=n(V8e,"STRONG",{});var lft=s(Yie);o1o=r(lft,"regnet"),lft.forEach(t),r1o=r(V8e," \u2014 "),lq=n(V8e,"A",{href:!0});var ift=s(lq);t1o=r(ift,"ConvNextFeatureExtractor"),ift.forEach(t),a1o=r(V8e," (RegNet model)"),V8e.forEach(t),n1o=i(K),op=n(K,"LI",{});var X8e=s(op);Kie=n(X8e,"STRONG",{});var dft=s(Kie);s1o=r(dft,"resnet"),dft.forEach(t),l1o=r(X8e," \u2014 "),iq=n(X8e,"A",{href:!0});var cft=s(iq);i1o=r(cft,"ConvNextFeatureExtractor"),cft.forEach(t),d1o=r(X8e," (ResNet model)"),X8e.forEach(t),c1o=i(K),rp=n(K,"LI",{});var z8e=s(rp);Zie=n(z8e,"STRONG",{});var fft=s(Zie);f1o=r(fft,"segformer"),fft.forEach(t),m1o=r(z8e," \u2014 "),dq=n(z8e,"A",{href:!0});var mft=s(dq);g1o=r(mft,"SegformerFeatureExtractor"),mft.forEach(t),h1o=r(z8e," (SegFormer model)"),z8e.forEach(t),p1o=i(K),tp=n(K,"LI",{});var Q8e=s(tp);ede=n(Q8e,"STRONG",{});var gft=s(ede);_1o=r(gft,"speech_to_text"),gft.forEach(t),u1o=r(Q8e," \u2014 "),cq=n(Q8e,"A",{href:!0});var hft=s(cq);b1o=r(hft,"Speech2TextFeatureExtractor"),hft.forEach(t),v1o=r(Q8e," (Speech2Text model)"),Q8e.forEach(t),F1o=i(K),ap=n(K,"LI",{});var W8e=s(ap);ode=n(W8e,"STRONG",{});var pft=s(ode);T1o=r(pft,"swin"),pft.forEach(t),M1o=r(W8e," \u2014 "),fq=n(W8e,"A",{href:!0});var _ft=s(fq);E1o=r(_ft,"ViTFeatureExtractor"),_ft.forEach(t),C1o=r(W8e," (Swin Transformer model)"),W8e.forEach(t),w1o=i(K),np=n(K,"LI",{});var H8e=s(np);rde=n(H8e,"STRONG",{});var uft=s(rde);A1o=r(uft,"van"),uft.forEach(t),L1o=r(H8e," \u2014 "),mq=n(H8e,"A",{href:!0});var bft=s(mq);y1o=r(bft,"ConvNextFeatureExtractor"),bft.forEach(t),x1o=r(H8e," (VAN model)"),H8e.forEach(t),$1o=i(K),sp=n(K,"LI",{});var U8e=s(sp);tde=n(U8e,"STRONG",{});var vft=s(tde);k1o=r(vft,"vilt"),vft.forEach(t),S1o=r(U8e," \u2014 "),gq=n(U8e,"A",{href:!0});var Fft=s(gq);R1o=r(Fft,"ViltFeatureExtractor"),Fft.forEach(t),P1o=r(U8e," (ViLT model)"),U8e.forEach(t),B1o=i(K),lp=n(K,"LI",{});var J8e=s(lp);ade=n(J8e,"STRONG",{});var Tft=s(ade);N1o=r(Tft,"vit"),Tft.forEach(t),I1o=r(J8e," \u2014 "),hq=n(J8e,"A",{href:!0});var Mft=s(hq);q1o=r(Mft,"ViTFeatureExtractor"),Mft.forEach(t),j1o=r(J8e," (ViT model)"),J8e.forEach(t),D1o=i(K),ip=n(K,"LI",{});var Y8e=s(ip);nde=n(Y8e,"STRONG",{});var Eft=s(nde);G1o=r(Eft,"vit_mae"),Eft.forEach(t),O1o=r(Y8e," \u2014 "),pq=n(Y8e,"A",{href:!0});var Cft=s(pq);V1o=r(Cft,"ViTFeatureExtractor"),Cft.forEach(t),X1o=r(Y8e," (ViTMAE model)"),Y8e.forEach(t),z1o=i(K),dp=n(K,"LI",{});var K8e=s(dp);sde=n(K8e,"STRONG",{});var wft=s(sde);Q1o=r(wft,"wav2vec2"),wft.forEach(t),W1o=r(K8e," \u2014 "),_q=n(K8e,"A",{href:!0});var Aft=s(_q);H1o=r(Aft,"Wav2Vec2FeatureExtractor"),Aft.forEach(t),U1o=r(K8e," (Wav2Vec2 model)"),K8e.forEach(t),J1o=i(K),cp=n(K,"LI",{});var Z8e=s(cp);lde=n(Z8e,"STRONG",{});var Lft=s(lde);Y1o=r(Lft,"wav2vec2-conformer"),Lft.forEach(t),K1o=r(Z8e," \u2014 "),uq=n(Z8e,"A",{href:!0});var yft=s(uq);Z1o=r(yft,"Wav2Vec2FeatureExtractor"),yft.forEach(t),e7o=r(Z8e," (Wav2Vec2-Conformer model)"),Z8e.forEach(t),o7o=i(K),fp=n(K,"LI",{});var e9e=s(fp);ide=n(e9e,"STRONG",{});var xft=s(ide);r7o=r(xft,"yolos"),xft.forEach(t),t7o=r(e9e," \u2014 "),bq=n(e9e,"A",{href:!0});var $ft=s(bq);a7o=r($ft,"YolosFeatureExtractor"),$ft.forEach(t),n7o=r(e9e," (YOLOS model)"),e9e.forEach(t),K.forEach(t),s7o=i(ta),T(mp.$$.fragment,ta),l7o=i(ta),T(gp.$$.fragment,ta),ta.forEach(t),i7o=i(Zs),hp=n(Zs,"DIV",{class:!0});var Nze=s(hp);T(_y.$$.fragment,Nze),d7o=i(Nze),dde=n(Nze,"P",{});var kft=s(dde);c7o=r(kft,"Register a new feature extractor for this class."),kft.forEach(t),Nze.forEach(t),Zs.forEach(t),RVe=i(f),Ii=n(f,"H2",{class:!0});var Ize=s(Ii);pp=n(Ize,"A",{id:!0,class:!0,href:!0});var Sft=s(pp);cde=n(Sft,"SPAN",{});var Rft=s(cde);T(uy.$$.fragment,Rft),Rft.forEach(t),Sft.forEach(t),f7o=i(Ize),fde=n(Ize,"SPAN",{});var Pft=s(fde);m7o=r(Pft,"AutoProcessor"),Pft.forEach(t),Ize.forEach(t),PVe=i(f),yo=n(f,"DIV",{class:!0});var el=s(yo);T(by.$$.fragment,el),g7o=i(el),vy=n(el,"P",{});var qze=s(vy);h7o=r(qze,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),vq=n(qze,"A",{href:!0});var Bft=s(vq);p7o=r(Bft,"AutoProcessor.from_pretrained()"),Bft.forEach(t),_7o=r(qze," class method."),qze.forEach(t),u7o=i(el),Fy=n(el,"P",{});var jze=s(Fy);b7o=r(jze,"This class cannot be instantiated directly using "),mde=n(jze,"CODE",{});var Nft=s(mde);v7o=r(Nft,"__init__()"),Nft.forEach(t),F7o=r(jze," (throws an error)."),jze.forEach(t),T7o=i(el),Ue=n(el,"DIV",{class:!0});var aa=s(Ue);T(Ty.$$.fragment,aa),M7o=i(aa),gde=n(aa,"P",{});var Ift=s(gde);E7o=r(Ift,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Ift.forEach(t),C7o=i(aa),qi=n(aa,"P",{});var hre=s(qi);w7o=r(hre,"The processor class to instantiate is selected based on the "),hde=n(hre,"CODE",{});var qft=s(hde);A7o=r(qft,"model_type"),qft.forEach(t),L7o=r(hre,` property of the config object (either
passed as an argument or loaded from `),pde=n(hre,"CODE",{});var jft=s(pde);y7o=r(jft,"pretrained_model_name_or_path"),jft.forEach(t),x7o=r(hre," if possible):"),hre.forEach(t),$7o=i(aa),he=n(aa,"UL",{});var ue=s(he);_p=n(ue,"LI",{});var o9e=s(_p);_de=n(o9e,"STRONG",{});var Dft=s(_de);k7o=r(Dft,"clip"),Dft.forEach(t),S7o=r(o9e," \u2014 "),Fq=n(o9e,"A",{href:!0});var Gft=s(Fq);R7o=r(Gft,"CLIPProcessor"),Gft.forEach(t),P7o=r(o9e," (CLIP model)"),o9e.forEach(t),B7o=i(ue),up=n(ue,"LI",{});var r9e=s(up);ude=n(r9e,"STRONG",{});var Oft=s(ude);N7o=r(Oft,"flava"),Oft.forEach(t),I7o=r(r9e," \u2014 "),bde=n(r9e,"CODE",{});var Vft=s(bde);q7o=r(Vft,"FLAVAProcessor"),Vft.forEach(t),j7o=r(r9e," (FLAVA model)"),r9e.forEach(t),D7o=i(ue),bp=n(ue,"LI",{});var t9e=s(bp);vde=n(t9e,"STRONG",{});var Xft=s(vde);G7o=r(Xft,"groupvit"),Xft.forEach(t),O7o=r(t9e," \u2014 "),Tq=n(t9e,"A",{href:!0});var zft=s(Tq);V7o=r(zft,"CLIPProcessor"),zft.forEach(t),X7o=r(t9e," (GroupViT model)"),t9e.forEach(t),z7o=i(ue),vp=n(ue,"LI",{});var a9e=s(vp);Fde=n(a9e,"STRONG",{});var Qft=s(Fde);Q7o=r(Qft,"layoutlmv2"),Qft.forEach(t),W7o=r(a9e," \u2014 "),Mq=n(a9e,"A",{href:!0});var Wft=s(Mq);H7o=r(Wft,"LayoutLMv2Processor"),Wft.forEach(t),U7o=r(a9e," (LayoutLMv2 model)"),a9e.forEach(t),J7o=i(ue),Fp=n(ue,"LI",{});var n9e=s(Fp);Tde=n(n9e,"STRONG",{});var Hft=s(Tde);Y7o=r(Hft,"layoutlmv3"),Hft.forEach(t),K7o=r(n9e," \u2014 "),Eq=n(n9e,"A",{href:!0});var Uft=s(Eq);Z7o=r(Uft,"LayoutLMv3Processor"),Uft.forEach(t),e4o=r(n9e," (LayoutLMv3 model)"),n9e.forEach(t),o4o=i(ue),Tp=n(ue,"LI",{});var s9e=s(Tp);Mde=n(s9e,"STRONG",{});var Jft=s(Mde);r4o=r(Jft,"layoutxlm"),Jft.forEach(t),t4o=r(s9e," \u2014 "),Cq=n(s9e,"A",{href:!0});var Yft=s(Cq);a4o=r(Yft,"LayoutXLMProcessor"),Yft.forEach(t),n4o=r(s9e," (LayoutXLM model)"),s9e.forEach(t),s4o=i(ue),Mp=n(ue,"LI",{});var l9e=s(Mp);Ede=n(l9e,"STRONG",{});var Kft=s(Ede);l4o=r(Kft,"sew"),Kft.forEach(t),i4o=r(l9e," \u2014 "),wq=n(l9e,"A",{href:!0});var Zft=s(wq);d4o=r(Zft,"Wav2Vec2Processor"),Zft.forEach(t),c4o=r(l9e," (SEW model)"),l9e.forEach(t),f4o=i(ue),Ep=n(ue,"LI",{});var i9e=s(Ep);Cde=n(i9e,"STRONG",{});var emt=s(Cde);m4o=r(emt,"sew-d"),emt.forEach(t),g4o=r(i9e," \u2014 "),Aq=n(i9e,"A",{href:!0});var omt=s(Aq);h4o=r(omt,"Wav2Vec2Processor"),omt.forEach(t),p4o=r(i9e," (SEW-D model)"),i9e.forEach(t),_4o=i(ue),Cp=n(ue,"LI",{});var d9e=s(Cp);wde=n(d9e,"STRONG",{});var rmt=s(wde);u4o=r(rmt,"speech_to_text"),rmt.forEach(t),b4o=r(d9e," \u2014 "),Lq=n(d9e,"A",{href:!0});var tmt=s(Lq);v4o=r(tmt,"Speech2TextProcessor"),tmt.forEach(t),F4o=r(d9e," (Speech2Text model)"),d9e.forEach(t),T4o=i(ue),wp=n(ue,"LI",{});var c9e=s(wp);Ade=n(c9e,"STRONG",{});var amt=s(Ade);M4o=r(amt,"speech_to_text_2"),amt.forEach(t),E4o=r(c9e," \u2014 "),yq=n(c9e,"A",{href:!0});var nmt=s(yq);C4o=r(nmt,"Speech2Text2Processor"),nmt.forEach(t),w4o=r(c9e," (Speech2Text2 model)"),c9e.forEach(t),A4o=i(ue),Ap=n(ue,"LI",{});var f9e=s(Ap);Lde=n(f9e,"STRONG",{});var smt=s(Lde);L4o=r(smt,"trocr"),smt.forEach(t),y4o=r(f9e," \u2014 "),xq=n(f9e,"A",{href:!0});var lmt=s(xq);x4o=r(lmt,"TrOCRProcessor"),lmt.forEach(t),$4o=r(f9e," (TrOCR model)"),f9e.forEach(t),k4o=i(ue),Lp=n(ue,"LI",{});var m9e=s(Lp);yde=n(m9e,"STRONG",{});var imt=s(yde);S4o=r(imt,"unispeech"),imt.forEach(t),R4o=r(m9e," \u2014 "),$q=n(m9e,"A",{href:!0});var dmt=s($q);P4o=r(dmt,"Wav2Vec2Processor"),dmt.forEach(t),B4o=r(m9e," (UniSpeech model)"),m9e.forEach(t),N4o=i(ue),yp=n(ue,"LI",{});var g9e=s(yp);xde=n(g9e,"STRONG",{});var cmt=s(xde);I4o=r(cmt,"unispeech-sat"),cmt.forEach(t),q4o=r(g9e," \u2014 "),kq=n(g9e,"A",{href:!0});var fmt=s(kq);j4o=r(fmt,"Wav2Vec2Processor"),fmt.forEach(t),D4o=r(g9e," (UniSpeechSat model)"),g9e.forEach(t),G4o=i(ue),xp=n(ue,"LI",{});var h9e=s(xp);$de=n(h9e,"STRONG",{});var mmt=s($de);O4o=r(mmt,"vilt"),mmt.forEach(t),V4o=r(h9e," \u2014 "),Sq=n(h9e,"A",{href:!0});var gmt=s(Sq);X4o=r(gmt,"ViltProcessor"),gmt.forEach(t),z4o=r(h9e," (ViLT model)"),h9e.forEach(t),Q4o=i(ue),$p=n(ue,"LI",{});var p9e=s($p);kde=n(p9e,"STRONG",{});var hmt=s(kde);W4o=r(hmt,"vision-text-dual-encoder"),hmt.forEach(t),H4o=r(p9e," \u2014 "),Rq=n(p9e,"A",{href:!0});var pmt=s(Rq);U4o=r(pmt,"VisionTextDualEncoderProcessor"),pmt.forEach(t),J4o=r(p9e," (VisionTextDualEncoder model)"),p9e.forEach(t),Y4o=i(ue),kp=n(ue,"LI",{});var _9e=s(kp);Sde=n(_9e,"STRONG",{});var _mt=s(Sde);K4o=r(_mt,"wav2vec2"),_mt.forEach(t),Z4o=r(_9e," \u2014 "),Pq=n(_9e,"A",{href:!0});var umt=s(Pq);ebo=r(umt,"Wav2Vec2Processor"),umt.forEach(t),obo=r(_9e," (Wav2Vec2 model)"),_9e.forEach(t),rbo=i(ue),Sp=n(ue,"LI",{});var u9e=s(Sp);Rde=n(u9e,"STRONG",{});var bmt=s(Rde);tbo=r(bmt,"wav2vec2-conformer"),bmt.forEach(t),abo=r(u9e," \u2014 "),Bq=n(u9e,"A",{href:!0});var vmt=s(Bq);nbo=r(vmt,"Wav2Vec2Processor"),vmt.forEach(t),sbo=r(u9e," (Wav2Vec2-Conformer model)"),u9e.forEach(t),lbo=i(ue),Rp=n(ue,"LI",{});var b9e=s(Rp);Pde=n(b9e,"STRONG",{});var Fmt=s(Pde);ibo=r(Fmt,"wavlm"),Fmt.forEach(t),dbo=r(b9e," \u2014 "),Nq=n(b9e,"A",{href:!0});var Tmt=s(Nq);cbo=r(Tmt,"Wav2Vec2Processor"),Tmt.forEach(t),fbo=r(b9e," (WavLM model)"),b9e.forEach(t),ue.forEach(t),mbo=i(aa),T(Pp.$$.fragment,aa),gbo=i(aa),T(Bp.$$.fragment,aa),aa.forEach(t),hbo=i(el),Np=n(el,"DIV",{class:!0});var Dze=s(Np);T(My.$$.fragment,Dze),pbo=i(Dze),Bde=n(Dze,"P",{});var Mmt=s(Bde);_bo=r(Mmt,"Register a new processor for this class."),Mmt.forEach(t),Dze.forEach(t),el.forEach(t),BVe=i(f),ji=n(f,"H2",{class:!0});var Gze=s(ji);Ip=n(Gze,"A",{id:!0,class:!0,href:!0});var Emt=s(Ip);Nde=n(Emt,"SPAN",{});var Cmt=s(Nde);T(Ey.$$.fragment,Cmt),Cmt.forEach(t),Emt.forEach(t),ubo=i(Gze),Ide=n(Gze,"SPAN",{});var wmt=s(Ide);bbo=r(wmt,"AutoModel"),wmt.forEach(t),Gze.forEach(t),NVe=i(f),xo=n(f,"DIV",{class:!0});var ol=s(xo);T(Cy.$$.fragment,ol),vbo=i(ol),Di=n(ol,"P",{});var pre=s(Di);Fbo=r(pre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Iq=n(pre,"A",{href:!0});var Amt=s(Iq);Tbo=r(Amt,"from_pretrained()"),Amt.forEach(t),Mbo=r(pre," class method or the "),qq=n(pre,"A",{href:!0});var Lmt=s(qq);Ebo=r(Lmt,"from_config()"),Lmt.forEach(t),Cbo=r(pre,` class
method.`),pre.forEach(t),wbo=i(ol),wy=n(ol,"P",{});var Oze=s(wy);Abo=r(Oze,"This class cannot be instantiated directly using "),qde=n(Oze,"CODE",{});var ymt=s(qde);Lbo=r(ymt,"__init__()"),ymt.forEach(t),ybo=r(Oze," (throws an error)."),Oze.forEach(t),xbo=i(ol),st=n(ol,"DIV",{class:!0});var e6=s(st);T(Ay.$$.fragment,e6),$bo=i(e6),jde=n(e6,"P",{});var xmt=s(jde);kbo=r(xmt,"Instantiates one of the base model classes of the library from a configuration."),xmt.forEach(t),Sbo=i(e6),Gi=n(e6,"P",{});var _re=s(Gi);Rbo=r(_re,`Note:
Loading a model from its configuration file does `),Dde=n(_re,"STRONG",{});var $mt=s(Dde);Pbo=r($mt,"not"),$mt.forEach(t),Bbo=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),jq=n(_re,"A",{href:!0});var kmt=s(jq);Nbo=r(kmt,"from_pretrained()"),kmt.forEach(t),Ibo=r(_re," to load the model weights."),_re.forEach(t),qbo=i(e6),T(qp.$$.fragment,e6),e6.forEach(t),jbo=i(ol),Je=n(ol,"DIV",{class:!0});var na=s(Je);T(Ly.$$.fragment,na),Dbo=i(na),Gde=n(na,"P",{});var Smt=s(Gde);Gbo=r(Smt,"Instantiate one of the base model classes of the library from a pretrained model."),Smt.forEach(t),Obo=i(na),Ba=n(na,"P",{});var o6=s(Ba);Vbo=r(o6,"The model class to instantiate is selected based on the "),Ode=n(o6,"CODE",{});var Rmt=s(Ode);Xbo=r(Rmt,"model_type"),Rmt.forEach(t),zbo=r(o6,` property of the config object (either
passed as an argument or loaded from `),Vde=n(o6,"CODE",{});var Pmt=s(Vde);Qbo=r(Pmt,"pretrained_model_name_or_path"),Pmt.forEach(t),Wbo=r(o6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xde=n(o6,"CODE",{});var Bmt=s(Xde);Hbo=r(Bmt,"pretrained_model_name_or_path"),Bmt.forEach(t),Ubo=r(o6,":"),o6.forEach(t),Jbo=i(na),y=n(na,"UL",{});var x=s(y);jp=n(x,"LI",{});var v9e=s(jp);zde=n(v9e,"STRONG",{});var Nmt=s(zde);Ybo=r(Nmt,"albert"),Nmt.forEach(t),Kbo=r(v9e," \u2014 "),Dq=n(v9e,"A",{href:!0});var Imt=s(Dq);Zbo=r(Imt,"AlbertModel"),Imt.forEach(t),evo=r(v9e," (ALBERT model)"),v9e.forEach(t),ovo=i(x),Dp=n(x,"LI",{});var F9e=s(Dp);Qde=n(F9e,"STRONG",{});var qmt=s(Qde);rvo=r(qmt,"bart"),qmt.forEach(t),tvo=r(F9e," \u2014 "),Gq=n(F9e,"A",{href:!0});var jmt=s(Gq);avo=r(jmt,"BartModel"),jmt.forEach(t),nvo=r(F9e," (BART model)"),F9e.forEach(t),svo=i(x),Gp=n(x,"LI",{});var T9e=s(Gp);Wde=n(T9e,"STRONG",{});var Dmt=s(Wde);lvo=r(Dmt,"beit"),Dmt.forEach(t),ivo=r(T9e," \u2014 "),Oq=n(T9e,"A",{href:!0});var Gmt=s(Oq);dvo=r(Gmt,"BeitModel"),Gmt.forEach(t),cvo=r(T9e," (BEiT model)"),T9e.forEach(t),fvo=i(x),Op=n(x,"LI",{});var M9e=s(Op);Hde=n(M9e,"STRONG",{});var Omt=s(Hde);mvo=r(Omt,"bert"),Omt.forEach(t),gvo=r(M9e," \u2014 "),Vq=n(M9e,"A",{href:!0});var Vmt=s(Vq);hvo=r(Vmt,"BertModel"),Vmt.forEach(t),pvo=r(M9e," (BERT model)"),M9e.forEach(t),_vo=i(x),Vp=n(x,"LI",{});var E9e=s(Vp);Ude=n(E9e,"STRONG",{});var Xmt=s(Ude);uvo=r(Xmt,"bert-generation"),Xmt.forEach(t),bvo=r(E9e," \u2014 "),Xq=n(E9e,"A",{href:!0});var zmt=s(Xq);vvo=r(zmt,"BertGenerationEncoder"),zmt.forEach(t),Fvo=r(E9e," (Bert Generation model)"),E9e.forEach(t),Tvo=i(x),Xp=n(x,"LI",{});var C9e=s(Xp);Jde=n(C9e,"STRONG",{});var Qmt=s(Jde);Mvo=r(Qmt,"big_bird"),Qmt.forEach(t),Evo=r(C9e," \u2014 "),zq=n(C9e,"A",{href:!0});var Wmt=s(zq);Cvo=r(Wmt,"BigBirdModel"),Wmt.forEach(t),wvo=r(C9e," (BigBird model)"),C9e.forEach(t),Avo=i(x),zp=n(x,"LI",{});var w9e=s(zp);Yde=n(w9e,"STRONG",{});var Hmt=s(Yde);Lvo=r(Hmt,"bigbird_pegasus"),Hmt.forEach(t),yvo=r(w9e," \u2014 "),Qq=n(w9e,"A",{href:!0});var Umt=s(Qq);xvo=r(Umt,"BigBirdPegasusModel"),Umt.forEach(t),$vo=r(w9e," (BigBird-Pegasus model)"),w9e.forEach(t),kvo=i(x),Qp=n(x,"LI",{});var A9e=s(Qp);Kde=n(A9e,"STRONG",{});var Jmt=s(Kde);Svo=r(Jmt,"blenderbot"),Jmt.forEach(t),Rvo=r(A9e," \u2014 "),Wq=n(A9e,"A",{href:!0});var Ymt=s(Wq);Pvo=r(Ymt,"BlenderbotModel"),Ymt.forEach(t),Bvo=r(A9e," (Blenderbot model)"),A9e.forEach(t),Nvo=i(x),Wp=n(x,"LI",{});var L9e=s(Wp);Zde=n(L9e,"STRONG",{});var Kmt=s(Zde);Ivo=r(Kmt,"blenderbot-small"),Kmt.forEach(t),qvo=r(L9e," \u2014 "),Hq=n(L9e,"A",{href:!0});var Zmt=s(Hq);jvo=r(Zmt,"BlenderbotSmallModel"),Zmt.forEach(t),Dvo=r(L9e," (BlenderbotSmall model)"),L9e.forEach(t),Gvo=i(x),Hp=n(x,"LI",{});var y9e=s(Hp);ece=n(y9e,"STRONG",{});var egt=s(ece);Ovo=r(egt,"bloom"),egt.forEach(t),Vvo=r(y9e," \u2014 "),Uq=n(y9e,"A",{href:!0});var ogt=s(Uq);Xvo=r(ogt,"BloomModel"),ogt.forEach(t),zvo=r(y9e," (BLOOM model)"),y9e.forEach(t),Qvo=i(x),Up=n(x,"LI",{});var x9e=s(Up);oce=n(x9e,"STRONG",{});var rgt=s(oce);Wvo=r(rgt,"camembert"),rgt.forEach(t),Hvo=r(x9e," \u2014 "),Jq=n(x9e,"A",{href:!0});var tgt=s(Jq);Uvo=r(tgt,"CamembertModel"),tgt.forEach(t),Jvo=r(x9e," (CamemBERT model)"),x9e.forEach(t),Yvo=i(x),Jp=n(x,"LI",{});var $9e=s(Jp);rce=n($9e,"STRONG",{});var agt=s(rce);Kvo=r(agt,"canine"),agt.forEach(t),Zvo=r($9e," \u2014 "),Yq=n($9e,"A",{href:!0});var ngt=s(Yq);eFo=r(ngt,"CanineModel"),ngt.forEach(t),oFo=r($9e," (CANINE model)"),$9e.forEach(t),rFo=i(x),Yp=n(x,"LI",{});var k9e=s(Yp);tce=n(k9e,"STRONG",{});var sgt=s(tce);tFo=r(sgt,"clip"),sgt.forEach(t),aFo=r(k9e," \u2014 "),Kq=n(k9e,"A",{href:!0});var lgt=s(Kq);nFo=r(lgt,"CLIPModel"),lgt.forEach(t),sFo=r(k9e," (CLIP model)"),k9e.forEach(t),lFo=i(x),Kp=n(x,"LI",{});var S9e=s(Kp);ace=n(S9e,"STRONG",{});var igt=s(ace);iFo=r(igt,"codegen"),igt.forEach(t),dFo=r(S9e," \u2014 "),Zq=n(S9e,"A",{href:!0});var dgt=s(Zq);cFo=r(dgt,"CodeGenModel"),dgt.forEach(t),fFo=r(S9e," (CodeGen model)"),S9e.forEach(t),mFo=i(x),Zp=n(x,"LI",{});var R9e=s(Zp);nce=n(R9e,"STRONG",{});var cgt=s(nce);gFo=r(cgt,"convbert"),cgt.forEach(t),hFo=r(R9e," \u2014 "),ej=n(R9e,"A",{href:!0});var fgt=s(ej);pFo=r(fgt,"ConvBertModel"),fgt.forEach(t),_Fo=r(R9e," (ConvBERT model)"),R9e.forEach(t),uFo=i(x),e_=n(x,"LI",{});var P9e=s(e_);sce=n(P9e,"STRONG",{});var mgt=s(sce);bFo=r(mgt,"convnext"),mgt.forEach(t),vFo=r(P9e," \u2014 "),oj=n(P9e,"A",{href:!0});var ggt=s(oj);FFo=r(ggt,"ConvNextModel"),ggt.forEach(t),TFo=r(P9e," (ConvNeXT model)"),P9e.forEach(t),MFo=i(x),o_=n(x,"LI",{});var B9e=s(o_);lce=n(B9e,"STRONG",{});var hgt=s(lce);EFo=r(hgt,"ctrl"),hgt.forEach(t),CFo=r(B9e," \u2014 "),rj=n(B9e,"A",{href:!0});var pgt=s(rj);wFo=r(pgt,"CTRLModel"),pgt.forEach(t),AFo=r(B9e," (CTRL model)"),B9e.forEach(t),LFo=i(x),r_=n(x,"LI",{});var N9e=s(r_);ice=n(N9e,"STRONG",{});var _gt=s(ice);yFo=r(_gt,"cvt"),_gt.forEach(t),xFo=r(N9e," \u2014 "),tj=n(N9e,"A",{href:!0});var ugt=s(tj);$Fo=r(ugt,"CvtModel"),ugt.forEach(t),kFo=r(N9e," (CvT model)"),N9e.forEach(t),SFo=i(x),t_=n(x,"LI",{});var I9e=s(t_);dce=n(I9e,"STRONG",{});var bgt=s(dce);RFo=r(bgt,"data2vec-audio"),bgt.forEach(t),PFo=r(I9e," \u2014 "),aj=n(I9e,"A",{href:!0});var vgt=s(aj);BFo=r(vgt,"Data2VecAudioModel"),vgt.forEach(t),NFo=r(I9e," (Data2VecAudio model)"),I9e.forEach(t),IFo=i(x),a_=n(x,"LI",{});var q9e=s(a_);cce=n(q9e,"STRONG",{});var Fgt=s(cce);qFo=r(Fgt,"data2vec-text"),Fgt.forEach(t),jFo=r(q9e," \u2014 "),nj=n(q9e,"A",{href:!0});var Tgt=s(nj);DFo=r(Tgt,"Data2VecTextModel"),Tgt.forEach(t),GFo=r(q9e," (Data2VecText model)"),q9e.forEach(t),OFo=i(x),n_=n(x,"LI",{});var j9e=s(n_);fce=n(j9e,"STRONG",{});var Mgt=s(fce);VFo=r(Mgt,"data2vec-vision"),Mgt.forEach(t),XFo=r(j9e," \u2014 "),sj=n(j9e,"A",{href:!0});var Egt=s(sj);zFo=r(Egt,"Data2VecVisionModel"),Egt.forEach(t),QFo=r(j9e," (Data2VecVision model)"),j9e.forEach(t),WFo=i(x),s_=n(x,"LI",{});var D9e=s(s_);mce=n(D9e,"STRONG",{});var Cgt=s(mce);HFo=r(Cgt,"deberta"),Cgt.forEach(t),UFo=r(D9e," \u2014 "),lj=n(D9e,"A",{href:!0});var wgt=s(lj);JFo=r(wgt,"DebertaModel"),wgt.forEach(t),YFo=r(D9e," (DeBERTa model)"),D9e.forEach(t),KFo=i(x),l_=n(x,"LI",{});var G9e=s(l_);gce=n(G9e,"STRONG",{});var Agt=s(gce);ZFo=r(Agt,"deberta-v2"),Agt.forEach(t),eTo=r(G9e," \u2014 "),ij=n(G9e,"A",{href:!0});var Lgt=s(ij);oTo=r(Lgt,"DebertaV2Model"),Lgt.forEach(t),rTo=r(G9e," (DeBERTa-v2 model)"),G9e.forEach(t),tTo=i(x),i_=n(x,"LI",{});var O9e=s(i_);hce=n(O9e,"STRONG",{});var ygt=s(hce);aTo=r(ygt,"decision_transformer"),ygt.forEach(t),nTo=r(O9e," \u2014 "),dj=n(O9e,"A",{href:!0});var xgt=s(dj);sTo=r(xgt,"DecisionTransformerModel"),xgt.forEach(t),lTo=r(O9e," (Decision Transformer model)"),O9e.forEach(t),iTo=i(x),d_=n(x,"LI",{});var V9e=s(d_);pce=n(V9e,"STRONG",{});var $gt=s(pce);dTo=r($gt,"deit"),$gt.forEach(t),cTo=r(V9e," \u2014 "),cj=n(V9e,"A",{href:!0});var kgt=s(cj);fTo=r(kgt,"DeiTModel"),kgt.forEach(t),mTo=r(V9e," (DeiT model)"),V9e.forEach(t),gTo=i(x),c_=n(x,"LI",{});var X9e=s(c_);_ce=n(X9e,"STRONG",{});var Sgt=s(_ce);hTo=r(Sgt,"detr"),Sgt.forEach(t),pTo=r(X9e," \u2014 "),fj=n(X9e,"A",{href:!0});var Rgt=s(fj);_To=r(Rgt,"DetrModel"),Rgt.forEach(t),uTo=r(X9e," (DETR model)"),X9e.forEach(t),bTo=i(x),f_=n(x,"LI",{});var z9e=s(f_);uce=n(z9e,"STRONG",{});var Pgt=s(uce);vTo=r(Pgt,"distilbert"),Pgt.forEach(t),FTo=r(z9e," \u2014 "),mj=n(z9e,"A",{href:!0});var Bgt=s(mj);TTo=r(Bgt,"DistilBertModel"),Bgt.forEach(t),MTo=r(z9e," (DistilBERT model)"),z9e.forEach(t),ETo=i(x),m_=n(x,"LI",{});var Q9e=s(m_);bce=n(Q9e,"STRONG",{});var Ngt=s(bce);CTo=r(Ngt,"dpr"),Ngt.forEach(t),wTo=r(Q9e," \u2014 "),gj=n(Q9e,"A",{href:!0});var Igt=s(gj);ATo=r(Igt,"DPRQuestionEncoder"),Igt.forEach(t),LTo=r(Q9e," (DPR model)"),Q9e.forEach(t),yTo=i(x),g_=n(x,"LI",{});var W9e=s(g_);vce=n(W9e,"STRONG",{});var qgt=s(vce);xTo=r(qgt,"dpt"),qgt.forEach(t),$To=r(W9e," \u2014 "),hj=n(W9e,"A",{href:!0});var jgt=s(hj);kTo=r(jgt,"DPTModel"),jgt.forEach(t),STo=r(W9e," (DPT model)"),W9e.forEach(t),RTo=i(x),h_=n(x,"LI",{});var H9e=s(h_);Fce=n(H9e,"STRONG",{});var Dgt=s(Fce);PTo=r(Dgt,"electra"),Dgt.forEach(t),BTo=r(H9e," \u2014 "),pj=n(H9e,"A",{href:!0});var Ggt=s(pj);NTo=r(Ggt,"ElectraModel"),Ggt.forEach(t),ITo=r(H9e," (ELECTRA model)"),H9e.forEach(t),qTo=i(x),p_=n(x,"LI",{});var U9e=s(p_);Tce=n(U9e,"STRONG",{});var Ogt=s(Tce);jTo=r(Ogt,"flaubert"),Ogt.forEach(t),DTo=r(U9e," \u2014 "),_j=n(U9e,"A",{href:!0});var Vgt=s(_j);GTo=r(Vgt,"FlaubertModel"),Vgt.forEach(t),OTo=r(U9e," (FlauBERT model)"),U9e.forEach(t),VTo=i(x),__=n(x,"LI",{});var J9e=s(__);Mce=n(J9e,"STRONG",{});var Xgt=s(Mce);XTo=r(Xgt,"flava"),Xgt.forEach(t),zTo=r(J9e," \u2014 "),uj=n(J9e,"A",{href:!0});var zgt=s(uj);QTo=r(zgt,"FlavaModel"),zgt.forEach(t),WTo=r(J9e," (FLAVA model)"),J9e.forEach(t),HTo=i(x),u_=n(x,"LI",{});var Y9e=s(u_);Ece=n(Y9e,"STRONG",{});var Qgt=s(Ece);UTo=r(Qgt,"fnet"),Qgt.forEach(t),JTo=r(Y9e," \u2014 "),bj=n(Y9e,"A",{href:!0});var Wgt=s(bj);YTo=r(Wgt,"FNetModel"),Wgt.forEach(t),KTo=r(Y9e," (FNet model)"),Y9e.forEach(t),ZTo=i(x),b_=n(x,"LI",{});var K9e=s(b_);Cce=n(K9e,"STRONG",{});var Hgt=s(Cce);eMo=r(Hgt,"fsmt"),Hgt.forEach(t),oMo=r(K9e," \u2014 "),vj=n(K9e,"A",{href:!0});var Ugt=s(vj);rMo=r(Ugt,"FSMTModel"),Ugt.forEach(t),tMo=r(K9e," (FairSeq Machine-Translation model)"),K9e.forEach(t),aMo=i(x),Ws=n(x,"LI",{});var ES=s(Ws);wce=n(ES,"STRONG",{});var Jgt=s(wce);nMo=r(Jgt,"funnel"),Jgt.forEach(t),sMo=r(ES," \u2014 "),Fj=n(ES,"A",{href:!0});var Ygt=s(Fj);lMo=r(Ygt,"FunnelModel"),Ygt.forEach(t),iMo=r(ES," or "),Tj=n(ES,"A",{href:!0});var Kgt=s(Tj);dMo=r(Kgt,"FunnelBaseModel"),Kgt.forEach(t),cMo=r(ES," (Funnel Transformer model)"),ES.forEach(t),fMo=i(x),v_=n(x,"LI",{});var Z9e=s(v_);Ace=n(Z9e,"STRONG",{});var Zgt=s(Ace);mMo=r(Zgt,"glpn"),Zgt.forEach(t),gMo=r(Z9e," \u2014 "),Mj=n(Z9e,"A",{href:!0});var eht=s(Mj);hMo=r(eht,"GLPNModel"),eht.forEach(t),pMo=r(Z9e," (GLPN model)"),Z9e.forEach(t),_Mo=i(x),F_=n(x,"LI",{});var exe=s(F_);Lce=n(exe,"STRONG",{});var oht=s(Lce);uMo=r(oht,"gpt2"),oht.forEach(t),bMo=r(exe," \u2014 "),Ej=n(exe,"A",{href:!0});var rht=s(Ej);vMo=r(rht,"GPT2Model"),rht.forEach(t),FMo=r(exe," (OpenAI GPT-2 model)"),exe.forEach(t),TMo=i(x),T_=n(x,"LI",{});var oxe=s(T_);yce=n(oxe,"STRONG",{});var tht=s(yce);MMo=r(tht,"gpt_neo"),tht.forEach(t),EMo=r(oxe," \u2014 "),Cj=n(oxe,"A",{href:!0});var aht=s(Cj);CMo=r(aht,"GPTNeoModel"),aht.forEach(t),wMo=r(oxe," (GPT Neo model)"),oxe.forEach(t),AMo=i(x),M_=n(x,"LI",{});var rxe=s(M_);xce=n(rxe,"STRONG",{});var nht=s(xce);LMo=r(nht,"gpt_neox"),nht.forEach(t),yMo=r(rxe," \u2014 "),wj=n(rxe,"A",{href:!0});var sht=s(wj);xMo=r(sht,"GPTNeoXModel"),sht.forEach(t),$Mo=r(rxe," (GPT NeoX model)"),rxe.forEach(t),kMo=i(x),E_=n(x,"LI",{});var txe=s(E_);$ce=n(txe,"STRONG",{});var lht=s($ce);SMo=r(lht,"gptj"),lht.forEach(t),RMo=r(txe," \u2014 "),Aj=n(txe,"A",{href:!0});var iht=s(Aj);PMo=r(iht,"GPTJModel"),iht.forEach(t),BMo=r(txe," (GPT-J model)"),txe.forEach(t),NMo=i(x),C_=n(x,"LI",{});var axe=s(C_);kce=n(axe,"STRONG",{});var dht=s(kce);IMo=r(dht,"groupvit"),dht.forEach(t),qMo=r(axe," \u2014 "),Lj=n(axe,"A",{href:!0});var cht=s(Lj);jMo=r(cht,"GroupViTModel"),cht.forEach(t),DMo=r(axe," (GroupViT model)"),axe.forEach(t),GMo=i(x),w_=n(x,"LI",{});var nxe=s(w_);Sce=n(nxe,"STRONG",{});var fht=s(Sce);OMo=r(fht,"hubert"),fht.forEach(t),VMo=r(nxe," \u2014 "),yj=n(nxe,"A",{href:!0});var mht=s(yj);XMo=r(mht,"HubertModel"),mht.forEach(t),zMo=r(nxe," (Hubert model)"),nxe.forEach(t),QMo=i(x),A_=n(x,"LI",{});var sxe=s(A_);Rce=n(sxe,"STRONG",{});var ght=s(Rce);WMo=r(ght,"ibert"),ght.forEach(t),HMo=r(sxe," \u2014 "),xj=n(sxe,"A",{href:!0});var hht=s(xj);UMo=r(hht,"IBertModel"),hht.forEach(t),JMo=r(sxe," (I-BERT model)"),sxe.forEach(t),YMo=i(x),L_=n(x,"LI",{});var lxe=s(L_);Pce=n(lxe,"STRONG",{});var pht=s(Pce);KMo=r(pht,"imagegpt"),pht.forEach(t),ZMo=r(lxe," \u2014 "),$j=n(lxe,"A",{href:!0});var _ht=s($j);eEo=r(_ht,"ImageGPTModel"),_ht.forEach(t),oEo=r(lxe," (ImageGPT model)"),lxe.forEach(t),rEo=i(x),y_=n(x,"LI",{});var ixe=s(y_);Bce=n(ixe,"STRONG",{});var uht=s(Bce);tEo=r(uht,"layoutlm"),uht.forEach(t),aEo=r(ixe," \u2014 "),kj=n(ixe,"A",{href:!0});var bht=s(kj);nEo=r(bht,"LayoutLMModel"),bht.forEach(t),sEo=r(ixe," (LayoutLM model)"),ixe.forEach(t),lEo=i(x),x_=n(x,"LI",{});var dxe=s(x_);Nce=n(dxe,"STRONG",{});var vht=s(Nce);iEo=r(vht,"layoutlmv2"),vht.forEach(t),dEo=r(dxe," \u2014 "),Sj=n(dxe,"A",{href:!0});var Fht=s(Sj);cEo=r(Fht,"LayoutLMv2Model"),Fht.forEach(t),fEo=r(dxe," (LayoutLMv2 model)"),dxe.forEach(t),mEo=i(x),$_=n(x,"LI",{});var cxe=s($_);Ice=n(cxe,"STRONG",{});var Tht=s(Ice);gEo=r(Tht,"layoutlmv3"),Tht.forEach(t),hEo=r(cxe," \u2014 "),Rj=n(cxe,"A",{href:!0});var Mht=s(Rj);pEo=r(Mht,"LayoutLMv3Model"),Mht.forEach(t),_Eo=r(cxe," (LayoutLMv3 model)"),cxe.forEach(t),uEo=i(x),k_=n(x,"LI",{});var fxe=s(k_);qce=n(fxe,"STRONG",{});var Eht=s(qce);bEo=r(Eht,"led"),Eht.forEach(t),vEo=r(fxe," \u2014 "),Pj=n(fxe,"A",{href:!0});var Cht=s(Pj);FEo=r(Cht,"LEDModel"),Cht.forEach(t),TEo=r(fxe," (LED model)"),fxe.forEach(t),MEo=i(x),S_=n(x,"LI",{});var mxe=s(S_);jce=n(mxe,"STRONG",{});var wht=s(jce);EEo=r(wht,"levit"),wht.forEach(t),CEo=r(mxe," \u2014 "),Bj=n(mxe,"A",{href:!0});var Aht=s(Bj);wEo=r(Aht,"LevitModel"),Aht.forEach(t),AEo=r(mxe," (LeViT model)"),mxe.forEach(t),LEo=i(x),R_=n(x,"LI",{});var gxe=s(R_);Dce=n(gxe,"STRONG",{});var Lht=s(Dce);yEo=r(Lht,"longformer"),Lht.forEach(t),xEo=r(gxe," \u2014 "),Nj=n(gxe,"A",{href:!0});var yht=s(Nj);$Eo=r(yht,"LongformerModel"),yht.forEach(t),kEo=r(gxe," (Longformer model)"),gxe.forEach(t),SEo=i(x),P_=n(x,"LI",{});var hxe=s(P_);Gce=n(hxe,"STRONG",{});var xht=s(Gce);REo=r(xht,"longt5"),xht.forEach(t),PEo=r(hxe," \u2014 "),Ij=n(hxe,"A",{href:!0});var $ht=s(Ij);BEo=r($ht,"LongT5Model"),$ht.forEach(t),NEo=r(hxe," (LongT5 model)"),hxe.forEach(t),IEo=i(x),B_=n(x,"LI",{});var pxe=s(B_);Oce=n(pxe,"STRONG",{});var kht=s(Oce);qEo=r(kht,"luke"),kht.forEach(t),jEo=r(pxe," \u2014 "),qj=n(pxe,"A",{href:!0});var Sht=s(qj);DEo=r(Sht,"LukeModel"),Sht.forEach(t),GEo=r(pxe," (LUKE model)"),pxe.forEach(t),OEo=i(x),N_=n(x,"LI",{});var _xe=s(N_);Vce=n(_xe,"STRONG",{});var Rht=s(Vce);VEo=r(Rht,"lxmert"),Rht.forEach(t),XEo=r(_xe," \u2014 "),jj=n(_xe,"A",{href:!0});var Pht=s(jj);zEo=r(Pht,"LxmertModel"),Pht.forEach(t),QEo=r(_xe," (LXMERT model)"),_xe.forEach(t),WEo=i(x),I_=n(x,"LI",{});var uxe=s(I_);Xce=n(uxe,"STRONG",{});var Bht=s(Xce);HEo=r(Bht,"m2m_100"),Bht.forEach(t),UEo=r(uxe," \u2014 "),Dj=n(uxe,"A",{href:!0});var Nht=s(Dj);JEo=r(Nht,"M2M100Model"),Nht.forEach(t),YEo=r(uxe," (M2M100 model)"),uxe.forEach(t),KEo=i(x),q_=n(x,"LI",{});var bxe=s(q_);zce=n(bxe,"STRONG",{});var Iht=s(zce);ZEo=r(Iht,"marian"),Iht.forEach(t),eCo=r(bxe," \u2014 "),Gj=n(bxe,"A",{href:!0});var qht=s(Gj);oCo=r(qht,"MarianModel"),qht.forEach(t),rCo=r(bxe," (Marian model)"),bxe.forEach(t),tCo=i(x),j_=n(x,"LI",{});var vxe=s(j_);Qce=n(vxe,"STRONG",{});var jht=s(Qce);aCo=r(jht,"maskformer"),jht.forEach(t),nCo=r(vxe," \u2014 "),Oj=n(vxe,"A",{href:!0});var Dht=s(Oj);sCo=r(Dht,"MaskFormerModel"),Dht.forEach(t),lCo=r(vxe," (MaskFormer model)"),vxe.forEach(t),iCo=i(x),D_=n(x,"LI",{});var Fxe=s(D_);Wce=n(Fxe,"STRONG",{});var Ght=s(Wce);dCo=r(Ght,"mbart"),Ght.forEach(t),cCo=r(Fxe," \u2014 "),Vj=n(Fxe,"A",{href:!0});var Oht=s(Vj);fCo=r(Oht,"MBartModel"),Oht.forEach(t),mCo=r(Fxe," (mBART model)"),Fxe.forEach(t),gCo=i(x),G_=n(x,"LI",{});var Txe=s(G_);Hce=n(Txe,"STRONG",{});var Vht=s(Hce);hCo=r(Vht,"mctct"),Vht.forEach(t),pCo=r(Txe," \u2014 "),Xj=n(Txe,"A",{href:!0});var Xht=s(Xj);_Co=r(Xht,"MCTCTModel"),Xht.forEach(t),uCo=r(Txe," (M-CTC-T model)"),Txe.forEach(t),bCo=i(x),O_=n(x,"LI",{});var Mxe=s(O_);Uce=n(Mxe,"STRONG",{});var zht=s(Uce);vCo=r(zht,"megatron-bert"),zht.forEach(t),FCo=r(Mxe," \u2014 "),zj=n(Mxe,"A",{href:!0});var Qht=s(zj);TCo=r(Qht,"MegatronBertModel"),Qht.forEach(t),MCo=r(Mxe," (Megatron-BERT model)"),Mxe.forEach(t),ECo=i(x),V_=n(x,"LI",{});var Exe=s(V_);Jce=n(Exe,"STRONG",{});var Wht=s(Jce);CCo=r(Wht,"mobilebert"),Wht.forEach(t),wCo=r(Exe," \u2014 "),Qj=n(Exe,"A",{href:!0});var Hht=s(Qj);ACo=r(Hht,"MobileBertModel"),Hht.forEach(t),LCo=r(Exe," (MobileBERT model)"),Exe.forEach(t),yCo=i(x),X_=n(x,"LI",{});var Cxe=s(X_);Yce=n(Cxe,"STRONG",{});var Uht=s(Yce);xCo=r(Uht,"mpnet"),Uht.forEach(t),$Co=r(Cxe," \u2014 "),Wj=n(Cxe,"A",{href:!0});var Jht=s(Wj);kCo=r(Jht,"MPNetModel"),Jht.forEach(t),SCo=r(Cxe," (MPNet model)"),Cxe.forEach(t),RCo=i(x),z_=n(x,"LI",{});var wxe=s(z_);Kce=n(wxe,"STRONG",{});var Yht=s(Kce);PCo=r(Yht,"mt5"),Yht.forEach(t),BCo=r(wxe," \u2014 "),Hj=n(wxe,"A",{href:!0});var Kht=s(Hj);NCo=r(Kht,"MT5Model"),Kht.forEach(t),ICo=r(wxe," (MT5 model)"),wxe.forEach(t),qCo=i(x),Q_=n(x,"LI",{});var Axe=s(Q_);Zce=n(Axe,"STRONG",{});var Zht=s(Zce);jCo=r(Zht,"mvp"),Zht.forEach(t),DCo=r(Axe," \u2014 "),Uj=n(Axe,"A",{href:!0});var ept=s(Uj);GCo=r(ept,"MvpModel"),ept.forEach(t),OCo=r(Axe," (MVP model)"),Axe.forEach(t),VCo=i(x),W_=n(x,"LI",{});var Lxe=s(W_);efe=n(Lxe,"STRONG",{});var opt=s(efe);XCo=r(opt,"nezha"),opt.forEach(t),zCo=r(Lxe," \u2014 "),Jj=n(Lxe,"A",{href:!0});var rpt=s(Jj);QCo=r(rpt,"NezhaModel"),rpt.forEach(t),WCo=r(Lxe," (Nezha model)"),Lxe.forEach(t),HCo=i(x),H_=n(x,"LI",{});var yxe=s(H_);ofe=n(yxe,"STRONG",{});var tpt=s(ofe);UCo=r(tpt,"nystromformer"),tpt.forEach(t),JCo=r(yxe," \u2014 "),Yj=n(yxe,"A",{href:!0});var apt=s(Yj);YCo=r(apt,"NystromformerModel"),apt.forEach(t),KCo=r(yxe," (Nystr\xF6mformer model)"),yxe.forEach(t),ZCo=i(x),U_=n(x,"LI",{});var xxe=s(U_);rfe=n(xxe,"STRONG",{});var npt=s(rfe);e3o=r(npt,"openai-gpt"),npt.forEach(t),o3o=r(xxe," \u2014 "),Kj=n(xxe,"A",{href:!0});var spt=s(Kj);r3o=r(spt,"OpenAIGPTModel"),spt.forEach(t),t3o=r(xxe," (OpenAI GPT model)"),xxe.forEach(t),a3o=i(x),J_=n(x,"LI",{});var $xe=s(J_);tfe=n($xe,"STRONG",{});var lpt=s(tfe);n3o=r(lpt,"opt"),lpt.forEach(t),s3o=r($xe," \u2014 "),Zj=n($xe,"A",{href:!0});var ipt=s(Zj);l3o=r(ipt,"OPTModel"),ipt.forEach(t),i3o=r($xe," (OPT model)"),$xe.forEach(t),d3o=i(x),Y_=n(x,"LI",{});var kxe=s(Y_);afe=n(kxe,"STRONG",{});var dpt=s(afe);c3o=r(dpt,"pegasus"),dpt.forEach(t),f3o=r(kxe," \u2014 "),eD=n(kxe,"A",{href:!0});var cpt=s(eD);m3o=r(cpt,"PegasusModel"),cpt.forEach(t),g3o=r(kxe," (Pegasus model)"),kxe.forEach(t),h3o=i(x),K_=n(x,"LI",{});var Sxe=s(K_);nfe=n(Sxe,"STRONG",{});var fpt=s(nfe);p3o=r(fpt,"perceiver"),fpt.forEach(t),_3o=r(Sxe," \u2014 "),oD=n(Sxe,"A",{href:!0});var mpt=s(oD);u3o=r(mpt,"PerceiverModel"),mpt.forEach(t),b3o=r(Sxe," (Perceiver model)"),Sxe.forEach(t),v3o=i(x),Z_=n(x,"LI",{});var Rxe=s(Z_);sfe=n(Rxe,"STRONG",{});var gpt=s(sfe);F3o=r(gpt,"plbart"),gpt.forEach(t),T3o=r(Rxe," \u2014 "),rD=n(Rxe,"A",{href:!0});var hpt=s(rD);M3o=r(hpt,"PLBartModel"),hpt.forEach(t),E3o=r(Rxe," (PLBart model)"),Rxe.forEach(t),C3o=i(x),eu=n(x,"LI",{});var Pxe=s(eu);lfe=n(Pxe,"STRONG",{});var ppt=s(lfe);w3o=r(ppt,"poolformer"),ppt.forEach(t),A3o=r(Pxe," \u2014 "),tD=n(Pxe,"A",{href:!0});var _pt=s(tD);L3o=r(_pt,"PoolFormerModel"),_pt.forEach(t),y3o=r(Pxe," (PoolFormer model)"),Pxe.forEach(t),x3o=i(x),ou=n(x,"LI",{});var Bxe=s(ou);ife=n(Bxe,"STRONG",{});var upt=s(ife);$3o=r(upt,"prophetnet"),upt.forEach(t),k3o=r(Bxe," \u2014 "),aD=n(Bxe,"A",{href:!0});var bpt=s(aD);S3o=r(bpt,"ProphetNetModel"),bpt.forEach(t),R3o=r(Bxe," (ProphetNet model)"),Bxe.forEach(t),P3o=i(x),ru=n(x,"LI",{});var Nxe=s(ru);dfe=n(Nxe,"STRONG",{});var vpt=s(dfe);B3o=r(vpt,"qdqbert"),vpt.forEach(t),N3o=r(Nxe," \u2014 "),nD=n(Nxe,"A",{href:!0});var Fpt=s(nD);I3o=r(Fpt,"QDQBertModel"),Fpt.forEach(t),q3o=r(Nxe," (QDQBert model)"),Nxe.forEach(t),j3o=i(x),tu=n(x,"LI",{});var Ixe=s(tu);cfe=n(Ixe,"STRONG",{});var Tpt=s(cfe);D3o=r(Tpt,"reformer"),Tpt.forEach(t),G3o=r(Ixe," \u2014 "),sD=n(Ixe,"A",{href:!0});var Mpt=s(sD);O3o=r(Mpt,"ReformerModel"),Mpt.forEach(t),V3o=r(Ixe," (Reformer model)"),Ixe.forEach(t),X3o=i(x),au=n(x,"LI",{});var qxe=s(au);ffe=n(qxe,"STRONG",{});var Ept=s(ffe);z3o=r(Ept,"regnet"),Ept.forEach(t),Q3o=r(qxe," \u2014 "),lD=n(qxe,"A",{href:!0});var Cpt=s(lD);W3o=r(Cpt,"RegNetModel"),Cpt.forEach(t),H3o=r(qxe," (RegNet model)"),qxe.forEach(t),U3o=i(x),nu=n(x,"LI",{});var jxe=s(nu);mfe=n(jxe,"STRONG",{});var wpt=s(mfe);J3o=r(wpt,"rembert"),wpt.forEach(t),Y3o=r(jxe," \u2014 "),iD=n(jxe,"A",{href:!0});var Apt=s(iD);K3o=r(Apt,"RemBertModel"),Apt.forEach(t),Z3o=r(jxe," (RemBERT model)"),jxe.forEach(t),e5o=i(x),su=n(x,"LI",{});var Dxe=s(su);gfe=n(Dxe,"STRONG",{});var Lpt=s(gfe);o5o=r(Lpt,"resnet"),Lpt.forEach(t),r5o=r(Dxe," \u2014 "),dD=n(Dxe,"A",{href:!0});var ypt=s(dD);t5o=r(ypt,"ResNetModel"),ypt.forEach(t),a5o=r(Dxe," (ResNet model)"),Dxe.forEach(t),n5o=i(x),lu=n(x,"LI",{});var Gxe=s(lu);hfe=n(Gxe,"STRONG",{});var xpt=s(hfe);s5o=r(xpt,"retribert"),xpt.forEach(t),l5o=r(Gxe," \u2014 "),cD=n(Gxe,"A",{href:!0});var $pt=s(cD);i5o=r($pt,"RetriBertModel"),$pt.forEach(t),d5o=r(Gxe," (RetriBERT model)"),Gxe.forEach(t),c5o=i(x),iu=n(x,"LI",{});var Oxe=s(iu);pfe=n(Oxe,"STRONG",{});var kpt=s(pfe);f5o=r(kpt,"roberta"),kpt.forEach(t),m5o=r(Oxe," \u2014 "),fD=n(Oxe,"A",{href:!0});var Spt=s(fD);g5o=r(Spt,"RobertaModel"),Spt.forEach(t),h5o=r(Oxe," (RoBERTa model)"),Oxe.forEach(t),p5o=i(x),du=n(x,"LI",{});var Vxe=s(du);_fe=n(Vxe,"STRONG",{});var Rpt=s(_fe);_5o=r(Rpt,"roformer"),Rpt.forEach(t),u5o=r(Vxe," \u2014 "),mD=n(Vxe,"A",{href:!0});var Ppt=s(mD);b5o=r(Ppt,"RoFormerModel"),Ppt.forEach(t),v5o=r(Vxe," (RoFormer model)"),Vxe.forEach(t),F5o=i(x),cu=n(x,"LI",{});var Xxe=s(cu);ufe=n(Xxe,"STRONG",{});var Bpt=s(ufe);T5o=r(Bpt,"segformer"),Bpt.forEach(t),M5o=r(Xxe," \u2014 "),gD=n(Xxe,"A",{href:!0});var Npt=s(gD);E5o=r(Npt,"SegformerModel"),Npt.forEach(t),C5o=r(Xxe," (SegFormer model)"),Xxe.forEach(t),w5o=i(x),fu=n(x,"LI",{});var zxe=s(fu);bfe=n(zxe,"STRONG",{});var Ipt=s(bfe);A5o=r(Ipt,"sew"),Ipt.forEach(t),L5o=r(zxe," \u2014 "),hD=n(zxe,"A",{href:!0});var qpt=s(hD);y5o=r(qpt,"SEWModel"),qpt.forEach(t),x5o=r(zxe," (SEW model)"),zxe.forEach(t),$5o=i(x),mu=n(x,"LI",{});var Qxe=s(mu);vfe=n(Qxe,"STRONG",{});var jpt=s(vfe);k5o=r(jpt,"sew-d"),jpt.forEach(t),S5o=r(Qxe," \u2014 "),pD=n(Qxe,"A",{href:!0});var Dpt=s(pD);R5o=r(Dpt,"SEWDModel"),Dpt.forEach(t),P5o=r(Qxe," (SEW-D model)"),Qxe.forEach(t),B5o=i(x),gu=n(x,"LI",{});var Wxe=s(gu);Ffe=n(Wxe,"STRONG",{});var Gpt=s(Ffe);N5o=r(Gpt,"speech_to_text"),Gpt.forEach(t),I5o=r(Wxe," \u2014 "),_D=n(Wxe,"A",{href:!0});var Opt=s(_D);q5o=r(Opt,"Speech2TextModel"),Opt.forEach(t),j5o=r(Wxe," (Speech2Text model)"),Wxe.forEach(t),D5o=i(x),hu=n(x,"LI",{});var Hxe=s(hu);Tfe=n(Hxe,"STRONG",{});var Vpt=s(Tfe);G5o=r(Vpt,"splinter"),Vpt.forEach(t),O5o=r(Hxe," \u2014 "),uD=n(Hxe,"A",{href:!0});var Xpt=s(uD);V5o=r(Xpt,"SplinterModel"),Xpt.forEach(t),X5o=r(Hxe," (Splinter model)"),Hxe.forEach(t),z5o=i(x),pu=n(x,"LI",{});var Uxe=s(pu);Mfe=n(Uxe,"STRONG",{});var zpt=s(Mfe);Q5o=r(zpt,"squeezebert"),zpt.forEach(t),W5o=r(Uxe," \u2014 "),bD=n(Uxe,"A",{href:!0});var Qpt=s(bD);H5o=r(Qpt,"SqueezeBertModel"),Qpt.forEach(t),U5o=r(Uxe," (SqueezeBERT model)"),Uxe.forEach(t),J5o=i(x),_u=n(x,"LI",{});var Jxe=s(_u);Efe=n(Jxe,"STRONG",{});var Wpt=s(Efe);Y5o=r(Wpt,"swin"),Wpt.forEach(t),K5o=r(Jxe," \u2014 "),vD=n(Jxe,"A",{href:!0});var Hpt=s(vD);Z5o=r(Hpt,"SwinModel"),Hpt.forEach(t),e0o=r(Jxe," (Swin Transformer model)"),Jxe.forEach(t),o0o=i(x),uu=n(x,"LI",{});var Yxe=s(uu);Cfe=n(Yxe,"STRONG",{});var Upt=s(Cfe);r0o=r(Upt,"t5"),Upt.forEach(t),t0o=r(Yxe," \u2014 "),FD=n(Yxe,"A",{href:!0});var Jpt=s(FD);a0o=r(Jpt,"T5Model"),Jpt.forEach(t),n0o=r(Yxe," (T5 model)"),Yxe.forEach(t),s0o=i(x),bu=n(x,"LI",{});var Kxe=s(bu);wfe=n(Kxe,"STRONG",{});var Ypt=s(wfe);l0o=r(Ypt,"tapas"),Ypt.forEach(t),i0o=r(Kxe," \u2014 "),TD=n(Kxe,"A",{href:!0});var Kpt=s(TD);d0o=r(Kpt,"TapasModel"),Kpt.forEach(t),c0o=r(Kxe," (TAPAS model)"),Kxe.forEach(t),f0o=i(x),vu=n(x,"LI",{});var Zxe=s(vu);Afe=n(Zxe,"STRONG",{});var Zpt=s(Afe);m0o=r(Zpt,"trajectory_transformer"),Zpt.forEach(t),g0o=r(Zxe," \u2014 "),MD=n(Zxe,"A",{href:!0});var e_t=s(MD);h0o=r(e_t,"TrajectoryTransformerModel"),e_t.forEach(t),p0o=r(Zxe," (Trajectory Transformer model)"),Zxe.forEach(t),_0o=i(x),Fu=n(x,"LI",{});var e$e=s(Fu);Lfe=n(e$e,"STRONG",{});var o_t=s(Lfe);u0o=r(o_t,"transfo-xl"),o_t.forEach(t),b0o=r(e$e," \u2014 "),ED=n(e$e,"A",{href:!0});var r_t=s(ED);v0o=r(r_t,"TransfoXLModel"),r_t.forEach(t),F0o=r(e$e," (Transformer-XL model)"),e$e.forEach(t),T0o=i(x),Tu=n(x,"LI",{});var o$e=s(Tu);yfe=n(o$e,"STRONG",{});var t_t=s(yfe);M0o=r(t_t,"unispeech"),t_t.forEach(t),E0o=r(o$e," \u2014 "),CD=n(o$e,"A",{href:!0});var a_t=s(CD);C0o=r(a_t,"UniSpeechModel"),a_t.forEach(t),w0o=r(o$e," (UniSpeech model)"),o$e.forEach(t),A0o=i(x),Mu=n(x,"LI",{});var r$e=s(Mu);xfe=n(r$e,"STRONG",{});var n_t=s(xfe);L0o=r(n_t,"unispeech-sat"),n_t.forEach(t),y0o=r(r$e," \u2014 "),wD=n(r$e,"A",{href:!0});var s_t=s(wD);x0o=r(s_t,"UniSpeechSatModel"),s_t.forEach(t),$0o=r(r$e," (UniSpeechSat model)"),r$e.forEach(t),k0o=i(x),Eu=n(x,"LI",{});var t$e=s(Eu);$fe=n(t$e,"STRONG",{});var l_t=s($fe);S0o=r(l_t,"van"),l_t.forEach(t),R0o=r(t$e," \u2014 "),AD=n(t$e,"A",{href:!0});var i_t=s(AD);P0o=r(i_t,"VanModel"),i_t.forEach(t),B0o=r(t$e," (VAN model)"),t$e.forEach(t),N0o=i(x),Cu=n(x,"LI",{});var a$e=s(Cu);kfe=n(a$e,"STRONG",{});var d_t=s(kfe);I0o=r(d_t,"vilt"),d_t.forEach(t),q0o=r(a$e," \u2014 "),LD=n(a$e,"A",{href:!0});var c_t=s(LD);j0o=r(c_t,"ViltModel"),c_t.forEach(t),D0o=r(a$e," (ViLT model)"),a$e.forEach(t),G0o=i(x),wu=n(x,"LI",{});var n$e=s(wu);Sfe=n(n$e,"STRONG",{});var f_t=s(Sfe);O0o=r(f_t,"vision-text-dual-encoder"),f_t.forEach(t),V0o=r(n$e," \u2014 "),yD=n(n$e,"A",{href:!0});var m_t=s(yD);X0o=r(m_t,"VisionTextDualEncoderModel"),m_t.forEach(t),z0o=r(n$e," (VisionTextDualEncoder model)"),n$e.forEach(t),Q0o=i(x),Au=n(x,"LI",{});var s$e=s(Au);Rfe=n(s$e,"STRONG",{});var g_t=s(Rfe);W0o=r(g_t,"visual_bert"),g_t.forEach(t),H0o=r(s$e," \u2014 "),xD=n(s$e,"A",{href:!0});var h_t=s(xD);U0o=r(h_t,"VisualBertModel"),h_t.forEach(t),J0o=r(s$e," (VisualBERT model)"),s$e.forEach(t),Y0o=i(x),Lu=n(x,"LI",{});var l$e=s(Lu);Pfe=n(l$e,"STRONG",{});var p_t=s(Pfe);K0o=r(p_t,"vit"),p_t.forEach(t),Z0o=r(l$e," \u2014 "),$D=n(l$e,"A",{href:!0});var __t=s($D);ewo=r(__t,"ViTModel"),__t.forEach(t),owo=r(l$e," (ViT model)"),l$e.forEach(t),rwo=i(x),yu=n(x,"LI",{});var i$e=s(yu);Bfe=n(i$e,"STRONG",{});var u_t=s(Bfe);two=r(u_t,"vit_mae"),u_t.forEach(t),awo=r(i$e," \u2014 "),kD=n(i$e,"A",{href:!0});var b_t=s(kD);nwo=r(b_t,"ViTMAEModel"),b_t.forEach(t),swo=r(i$e," (ViTMAE model)"),i$e.forEach(t),lwo=i(x),xu=n(x,"LI",{});var d$e=s(xu);Nfe=n(d$e,"STRONG",{});var v_t=s(Nfe);iwo=r(v_t,"wav2vec2"),v_t.forEach(t),dwo=r(d$e," \u2014 "),SD=n(d$e,"A",{href:!0});var F_t=s(SD);cwo=r(F_t,"Wav2Vec2Model"),F_t.forEach(t),fwo=r(d$e," (Wav2Vec2 model)"),d$e.forEach(t),mwo=i(x),$u=n(x,"LI",{});var c$e=s($u);Ife=n(c$e,"STRONG",{});var T_t=s(Ife);gwo=r(T_t,"wav2vec2-conformer"),T_t.forEach(t),hwo=r(c$e," \u2014 "),RD=n(c$e,"A",{href:!0});var M_t=s(RD);pwo=r(M_t,"Wav2Vec2ConformerModel"),M_t.forEach(t),_wo=r(c$e," (Wav2Vec2-Conformer model)"),c$e.forEach(t),uwo=i(x),ku=n(x,"LI",{});var f$e=s(ku);qfe=n(f$e,"STRONG",{});var E_t=s(qfe);bwo=r(E_t,"wavlm"),E_t.forEach(t),vwo=r(f$e," \u2014 "),PD=n(f$e,"A",{href:!0});var C_t=s(PD);Fwo=r(C_t,"WavLMModel"),C_t.forEach(t),Two=r(f$e," (WavLM model)"),f$e.forEach(t),Mwo=i(x),Su=n(x,"LI",{});var m$e=s(Su);jfe=n(m$e,"STRONG",{});var w_t=s(jfe);Ewo=r(w_t,"xglm"),w_t.forEach(t),Cwo=r(m$e," \u2014 "),BD=n(m$e,"A",{href:!0});var A_t=s(BD);wwo=r(A_t,"XGLMModel"),A_t.forEach(t),Awo=r(m$e," (XGLM model)"),m$e.forEach(t),Lwo=i(x),Ru=n(x,"LI",{});var g$e=s(Ru);Dfe=n(g$e,"STRONG",{});var L_t=s(Dfe);ywo=r(L_t,"xlm"),L_t.forEach(t),xwo=r(g$e," \u2014 "),ND=n(g$e,"A",{href:!0});var y_t=s(ND);$wo=r(y_t,"XLMModel"),y_t.forEach(t),kwo=r(g$e," (XLM model)"),g$e.forEach(t),Swo=i(x),Pu=n(x,"LI",{});var h$e=s(Pu);Gfe=n(h$e,"STRONG",{});var x_t=s(Gfe);Rwo=r(x_t,"xlm-prophetnet"),x_t.forEach(t),Pwo=r(h$e," \u2014 "),ID=n(h$e,"A",{href:!0});var $_t=s(ID);Bwo=r($_t,"XLMProphetNetModel"),$_t.forEach(t),Nwo=r(h$e," (XLM-ProphetNet model)"),h$e.forEach(t),Iwo=i(x),Bu=n(x,"LI",{});var p$e=s(Bu);Ofe=n(p$e,"STRONG",{});var k_t=s(Ofe);qwo=r(k_t,"xlm-roberta"),k_t.forEach(t),jwo=r(p$e," \u2014 "),qD=n(p$e,"A",{href:!0});var S_t=s(qD);Dwo=r(S_t,"XLMRobertaModel"),S_t.forEach(t),Gwo=r(p$e," (XLM-RoBERTa model)"),p$e.forEach(t),Owo=i(x),Nu=n(x,"LI",{});var _$e=s(Nu);Vfe=n(_$e,"STRONG",{});var R_t=s(Vfe);Vwo=r(R_t,"xlm-roberta-xl"),R_t.forEach(t),Xwo=r(_$e," \u2014 "),jD=n(_$e,"A",{href:!0});var P_t=s(jD);zwo=r(P_t,"XLMRobertaXLModel"),P_t.forEach(t),Qwo=r(_$e," (XLM-RoBERTa-XL model)"),_$e.forEach(t),Wwo=i(x),Iu=n(x,"LI",{});var u$e=s(Iu);Xfe=n(u$e,"STRONG",{});var B_t=s(Xfe);Hwo=r(B_t,"xlnet"),B_t.forEach(t),Uwo=r(u$e," \u2014 "),DD=n(u$e,"A",{href:!0});var N_t=s(DD);Jwo=r(N_t,"XLNetModel"),N_t.forEach(t),Ywo=r(u$e," (XLNet model)"),u$e.forEach(t),Kwo=i(x),qu=n(x,"LI",{});var b$e=s(qu);zfe=n(b$e,"STRONG",{});var I_t=s(zfe);Zwo=r(I_t,"yolos"),I_t.forEach(t),eAo=r(b$e," \u2014 "),GD=n(b$e,"A",{href:!0});var q_t=s(GD);oAo=r(q_t,"YolosModel"),q_t.forEach(t),rAo=r(b$e," (YOLOS model)"),b$e.forEach(t),tAo=i(x),ju=n(x,"LI",{});var v$e=s(ju);Qfe=n(v$e,"STRONG",{});var j_t=s(Qfe);aAo=r(j_t,"yoso"),j_t.forEach(t),nAo=r(v$e," \u2014 "),OD=n(v$e,"A",{href:!0});var D_t=s(OD);sAo=r(D_t,"YosoModel"),D_t.forEach(t),lAo=r(v$e," (YOSO model)"),v$e.forEach(t),x.forEach(t),iAo=i(na),Du=n(na,"P",{});var F$e=s(Du);dAo=r(F$e,"The model is set in evaluation mode by default using "),Wfe=n(F$e,"CODE",{});var G_t=s(Wfe);cAo=r(G_t,"model.eval()"),G_t.forEach(t),fAo=r(F$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hfe=n(F$e,"CODE",{});var O_t=s(Hfe);mAo=r(O_t,"model.train()"),O_t.forEach(t),F$e.forEach(t),gAo=i(na),T(Gu.$$.fragment,na),na.forEach(t),ol.forEach(t),IVe=i(f),Oi=n(f,"H2",{class:!0});var Vze=s(Oi);Ou=n(Vze,"A",{id:!0,class:!0,href:!0});var V_t=s(Ou);Ufe=n(V_t,"SPAN",{});var X_t=s(Ufe);T(yy.$$.fragment,X_t),X_t.forEach(t),V_t.forEach(t),hAo=i(Vze),Jfe=n(Vze,"SPAN",{});var z_t=s(Jfe);pAo=r(z_t,"AutoModelForPreTraining"),z_t.forEach(t),Vze.forEach(t),qVe=i(f),$o=n(f,"DIV",{class:!0});var rl=s($o);T(xy.$$.fragment,rl),_Ao=i(rl),Vi=n(rl,"P",{});var ure=s(Vi);uAo=r(ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),VD=n(ure,"A",{href:!0});var Q_t=s(VD);bAo=r(Q_t,"from_pretrained()"),Q_t.forEach(t),vAo=r(ure," class method or the "),XD=n(ure,"A",{href:!0});var W_t=s(XD);FAo=r(W_t,"from_config()"),W_t.forEach(t),TAo=r(ure,` class
method.`),ure.forEach(t),MAo=i(rl),$y=n(rl,"P",{});var Xze=s($y);EAo=r(Xze,"This class cannot be instantiated directly using "),Yfe=n(Xze,"CODE",{});var H_t=s(Yfe);CAo=r(H_t,"__init__()"),H_t.forEach(t),wAo=r(Xze," (throws an error)."),Xze.forEach(t),AAo=i(rl),lt=n(rl,"DIV",{class:!0});var r6=s(lt);T(ky.$$.fragment,r6),LAo=i(r6),Kfe=n(r6,"P",{});var U_t=s(Kfe);yAo=r(U_t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),U_t.forEach(t),xAo=i(r6),Xi=n(r6,"P",{});var bre=s(Xi);$Ao=r(bre,`Note:
Loading a model from its configuration file does `),Zfe=n(bre,"STRONG",{});var J_t=s(Zfe);kAo=r(J_t,"not"),J_t.forEach(t),SAo=r(bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),zD=n(bre,"A",{href:!0});var Y_t=s(zD);RAo=r(Y_t,"from_pretrained()"),Y_t.forEach(t),PAo=r(bre," to load the model weights."),bre.forEach(t),BAo=i(r6),T(Vu.$$.fragment,r6),r6.forEach(t),NAo=i(rl),Ye=n(rl,"DIV",{class:!0});var sa=s(Ye);T(Sy.$$.fragment,sa),IAo=i(sa),eme=n(sa,"P",{});var K_t=s(eme);qAo=r(K_t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),K_t.forEach(t),jAo=i(sa),Na=n(sa,"P",{});var t6=s(Na);DAo=r(t6,"The model class to instantiate is selected based on the "),ome=n(t6,"CODE",{});var Z_t=s(ome);GAo=r(Z_t,"model_type"),Z_t.forEach(t),OAo=r(t6,` property of the config object (either
passed as an argument or loaded from `),rme=n(t6,"CODE",{});var eut=s(rme);VAo=r(eut,"pretrained_model_name_or_path"),eut.forEach(t),XAo=r(t6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tme=n(t6,"CODE",{});var out=s(tme);zAo=r(out,"pretrained_model_name_or_path"),out.forEach(t),QAo=r(t6,":"),t6.forEach(t),WAo=i(sa),G=n(sa,"UL",{});var O=s(G);Xu=n(O,"LI",{});var T$e=s(Xu);ame=n(T$e,"STRONG",{});var rut=s(ame);HAo=r(rut,"albert"),rut.forEach(t),UAo=r(T$e," \u2014 "),QD=n(T$e,"A",{href:!0});var tut=s(QD);JAo=r(tut,"AlbertForPreTraining"),tut.forEach(t),YAo=r(T$e," (ALBERT model)"),T$e.forEach(t),KAo=i(O),zu=n(O,"LI",{});var M$e=s(zu);nme=n(M$e,"STRONG",{});var aut=s(nme);ZAo=r(aut,"bart"),aut.forEach(t),e6o=r(M$e," \u2014 "),WD=n(M$e,"A",{href:!0});var nut=s(WD);o6o=r(nut,"BartForConditionalGeneration"),nut.forEach(t),r6o=r(M$e," (BART model)"),M$e.forEach(t),t6o=i(O),Qu=n(O,"LI",{});var E$e=s(Qu);sme=n(E$e,"STRONG",{});var sut=s(sme);a6o=r(sut,"bert"),sut.forEach(t),n6o=r(E$e," \u2014 "),HD=n(E$e,"A",{href:!0});var lut=s(HD);s6o=r(lut,"BertForPreTraining"),lut.forEach(t),l6o=r(E$e," (BERT model)"),E$e.forEach(t),i6o=i(O),Wu=n(O,"LI",{});var C$e=s(Wu);lme=n(C$e,"STRONG",{});var iut=s(lme);d6o=r(iut,"big_bird"),iut.forEach(t),c6o=r(C$e," \u2014 "),UD=n(C$e,"A",{href:!0});var dut=s(UD);f6o=r(dut,"BigBirdForPreTraining"),dut.forEach(t),m6o=r(C$e," (BigBird model)"),C$e.forEach(t),g6o=i(O),Hu=n(O,"LI",{});var w$e=s(Hu);ime=n(w$e,"STRONG",{});var cut=s(ime);h6o=r(cut,"bloom"),cut.forEach(t),p6o=r(w$e," \u2014 "),JD=n(w$e,"A",{href:!0});var fut=s(JD);_6o=r(fut,"BloomForCausalLM"),fut.forEach(t),u6o=r(w$e," (BLOOM model)"),w$e.forEach(t),b6o=i(O),Uu=n(O,"LI",{});var A$e=s(Uu);dme=n(A$e,"STRONG",{});var mut=s(dme);v6o=r(mut,"camembert"),mut.forEach(t),F6o=r(A$e," \u2014 "),YD=n(A$e,"A",{href:!0});var gut=s(YD);T6o=r(gut,"CamembertForMaskedLM"),gut.forEach(t),M6o=r(A$e," (CamemBERT model)"),A$e.forEach(t),E6o=i(O),Ju=n(O,"LI",{});var L$e=s(Ju);cme=n(L$e,"STRONG",{});var hut=s(cme);C6o=r(hut,"ctrl"),hut.forEach(t),w6o=r(L$e," \u2014 "),KD=n(L$e,"A",{href:!0});var put=s(KD);A6o=r(put,"CTRLLMHeadModel"),put.forEach(t),L6o=r(L$e," (CTRL model)"),L$e.forEach(t),y6o=i(O),Yu=n(O,"LI",{});var y$e=s(Yu);fme=n(y$e,"STRONG",{});var _ut=s(fme);x6o=r(_ut,"data2vec-text"),_ut.forEach(t),$6o=r(y$e," \u2014 "),ZD=n(y$e,"A",{href:!0});var uut=s(ZD);k6o=r(uut,"Data2VecTextForMaskedLM"),uut.forEach(t),S6o=r(y$e," (Data2VecText model)"),y$e.forEach(t),R6o=i(O),Ku=n(O,"LI",{});var x$e=s(Ku);mme=n(x$e,"STRONG",{});var but=s(mme);P6o=r(but,"deberta"),but.forEach(t),B6o=r(x$e," \u2014 "),eG=n(x$e,"A",{href:!0});var vut=s(eG);N6o=r(vut,"DebertaForMaskedLM"),vut.forEach(t),I6o=r(x$e," (DeBERTa model)"),x$e.forEach(t),q6o=i(O),Zu=n(O,"LI",{});var $$e=s(Zu);gme=n($$e,"STRONG",{});var Fut=s(gme);j6o=r(Fut,"deberta-v2"),Fut.forEach(t),D6o=r($$e," \u2014 "),oG=n($$e,"A",{href:!0});var Tut=s(oG);G6o=r(Tut,"DebertaV2ForMaskedLM"),Tut.forEach(t),O6o=r($$e," (DeBERTa-v2 model)"),$$e.forEach(t),V6o=i(O),e2=n(O,"LI",{});var k$e=s(e2);hme=n(k$e,"STRONG",{});var Mut=s(hme);X6o=r(Mut,"distilbert"),Mut.forEach(t),z6o=r(k$e," \u2014 "),rG=n(k$e,"A",{href:!0});var Eut=s(rG);Q6o=r(Eut,"DistilBertForMaskedLM"),Eut.forEach(t),W6o=r(k$e," (DistilBERT model)"),k$e.forEach(t),H6o=i(O),o2=n(O,"LI",{});var S$e=s(o2);pme=n(S$e,"STRONG",{});var Cut=s(pme);U6o=r(Cut,"electra"),Cut.forEach(t),J6o=r(S$e," \u2014 "),tG=n(S$e,"A",{href:!0});var wut=s(tG);Y6o=r(wut,"ElectraForPreTraining"),wut.forEach(t),K6o=r(S$e," (ELECTRA model)"),S$e.forEach(t),Z6o=i(O),r2=n(O,"LI",{});var R$e=s(r2);_me=n(R$e,"STRONG",{});var Aut=s(_me);eLo=r(Aut,"flaubert"),Aut.forEach(t),oLo=r(R$e," \u2014 "),aG=n(R$e,"A",{href:!0});var Lut=s(aG);rLo=r(Lut,"FlaubertWithLMHeadModel"),Lut.forEach(t),tLo=r(R$e," (FlauBERT model)"),R$e.forEach(t),aLo=i(O),t2=n(O,"LI",{});var P$e=s(t2);ume=n(P$e,"STRONG",{});var yut=s(ume);nLo=r(yut,"flava"),yut.forEach(t),sLo=r(P$e," \u2014 "),nG=n(P$e,"A",{href:!0});var xut=s(nG);lLo=r(xut,"FlavaForPreTraining"),xut.forEach(t),iLo=r(P$e," (FLAVA model)"),P$e.forEach(t),dLo=i(O),a2=n(O,"LI",{});var B$e=s(a2);bme=n(B$e,"STRONG",{});var $ut=s(bme);cLo=r($ut,"fnet"),$ut.forEach(t),fLo=r(B$e," \u2014 "),sG=n(B$e,"A",{href:!0});var kut=s(sG);mLo=r(kut,"FNetForPreTraining"),kut.forEach(t),gLo=r(B$e," (FNet model)"),B$e.forEach(t),hLo=i(O),n2=n(O,"LI",{});var N$e=s(n2);vme=n(N$e,"STRONG",{});var Sut=s(vme);pLo=r(Sut,"fsmt"),Sut.forEach(t),_Lo=r(N$e," \u2014 "),lG=n(N$e,"A",{href:!0});var Rut=s(lG);uLo=r(Rut,"FSMTForConditionalGeneration"),Rut.forEach(t),bLo=r(N$e," (FairSeq Machine-Translation model)"),N$e.forEach(t),vLo=i(O),s2=n(O,"LI",{});var I$e=s(s2);Fme=n(I$e,"STRONG",{});var Put=s(Fme);FLo=r(Put,"funnel"),Put.forEach(t),TLo=r(I$e," \u2014 "),iG=n(I$e,"A",{href:!0});var But=s(iG);MLo=r(But,"FunnelForPreTraining"),But.forEach(t),ELo=r(I$e," (Funnel Transformer model)"),I$e.forEach(t),CLo=i(O),l2=n(O,"LI",{});var q$e=s(l2);Tme=n(q$e,"STRONG",{});var Nut=s(Tme);wLo=r(Nut,"gpt2"),Nut.forEach(t),ALo=r(q$e," \u2014 "),dG=n(q$e,"A",{href:!0});var Iut=s(dG);LLo=r(Iut,"GPT2LMHeadModel"),Iut.forEach(t),yLo=r(q$e," (OpenAI GPT-2 model)"),q$e.forEach(t),xLo=i(O),i2=n(O,"LI",{});var j$e=s(i2);Mme=n(j$e,"STRONG",{});var qut=s(Mme);$Lo=r(qut,"ibert"),qut.forEach(t),kLo=r(j$e," \u2014 "),cG=n(j$e,"A",{href:!0});var jut=s(cG);SLo=r(jut,"IBertForMaskedLM"),jut.forEach(t),RLo=r(j$e," (I-BERT model)"),j$e.forEach(t),PLo=i(O),d2=n(O,"LI",{});var D$e=s(d2);Eme=n(D$e,"STRONG",{});var Dut=s(Eme);BLo=r(Dut,"layoutlm"),Dut.forEach(t),NLo=r(D$e," \u2014 "),fG=n(D$e,"A",{href:!0});var Gut=s(fG);ILo=r(Gut,"LayoutLMForMaskedLM"),Gut.forEach(t),qLo=r(D$e," (LayoutLM model)"),D$e.forEach(t),jLo=i(O),c2=n(O,"LI",{});var G$e=s(c2);Cme=n(G$e,"STRONG",{});var Out=s(Cme);DLo=r(Out,"longformer"),Out.forEach(t),GLo=r(G$e," \u2014 "),mG=n(G$e,"A",{href:!0});var Vut=s(mG);OLo=r(Vut,"LongformerForMaskedLM"),Vut.forEach(t),VLo=r(G$e," (Longformer model)"),G$e.forEach(t),XLo=i(O),f2=n(O,"LI",{});var O$e=s(f2);wme=n(O$e,"STRONG",{});var Xut=s(wme);zLo=r(Xut,"lxmert"),Xut.forEach(t),QLo=r(O$e," \u2014 "),gG=n(O$e,"A",{href:!0});var zut=s(gG);WLo=r(zut,"LxmertForPreTraining"),zut.forEach(t),HLo=r(O$e," (LXMERT model)"),O$e.forEach(t),ULo=i(O),m2=n(O,"LI",{});var V$e=s(m2);Ame=n(V$e,"STRONG",{});var Qut=s(Ame);JLo=r(Qut,"megatron-bert"),Qut.forEach(t),YLo=r(V$e," \u2014 "),hG=n(V$e,"A",{href:!0});var Wut=s(hG);KLo=r(Wut,"MegatronBertForPreTraining"),Wut.forEach(t),ZLo=r(V$e," (Megatron-BERT model)"),V$e.forEach(t),eyo=i(O),g2=n(O,"LI",{});var X$e=s(g2);Lme=n(X$e,"STRONG",{});var Hut=s(Lme);oyo=r(Hut,"mobilebert"),Hut.forEach(t),ryo=r(X$e," \u2014 "),pG=n(X$e,"A",{href:!0});var Uut=s(pG);tyo=r(Uut,"MobileBertForPreTraining"),Uut.forEach(t),ayo=r(X$e," (MobileBERT model)"),X$e.forEach(t),nyo=i(O),h2=n(O,"LI",{});var z$e=s(h2);yme=n(z$e,"STRONG",{});var Jut=s(yme);syo=r(Jut,"mpnet"),Jut.forEach(t),lyo=r(z$e," \u2014 "),_G=n(z$e,"A",{href:!0});var Yut=s(_G);iyo=r(Yut,"MPNetForMaskedLM"),Yut.forEach(t),dyo=r(z$e," (MPNet model)"),z$e.forEach(t),cyo=i(O),p2=n(O,"LI",{});var Q$e=s(p2);xme=n(Q$e,"STRONG",{});var Kut=s(xme);fyo=r(Kut,"mvp"),Kut.forEach(t),myo=r(Q$e," \u2014 "),uG=n(Q$e,"A",{href:!0});var Zut=s(uG);gyo=r(Zut,"MvpForConditionalGeneration"),Zut.forEach(t),hyo=r(Q$e," (MVP model)"),Q$e.forEach(t),pyo=i(O),_2=n(O,"LI",{});var W$e=s(_2);$me=n(W$e,"STRONG",{});var e2t=s($me);_yo=r(e2t,"nezha"),e2t.forEach(t),uyo=r(W$e," \u2014 "),bG=n(W$e,"A",{href:!0});var o2t=s(bG);byo=r(o2t,"NezhaForPreTraining"),o2t.forEach(t),vyo=r(W$e," (Nezha model)"),W$e.forEach(t),Fyo=i(O),u2=n(O,"LI",{});var H$e=s(u2);kme=n(H$e,"STRONG",{});var r2t=s(kme);Tyo=r(r2t,"openai-gpt"),r2t.forEach(t),Myo=r(H$e," \u2014 "),vG=n(H$e,"A",{href:!0});var t2t=s(vG);Eyo=r(t2t,"OpenAIGPTLMHeadModel"),t2t.forEach(t),Cyo=r(H$e," (OpenAI GPT model)"),H$e.forEach(t),wyo=i(O),b2=n(O,"LI",{});var U$e=s(b2);Sme=n(U$e,"STRONG",{});var a2t=s(Sme);Ayo=r(a2t,"retribert"),a2t.forEach(t),Lyo=r(U$e," \u2014 "),FG=n(U$e,"A",{href:!0});var n2t=s(FG);yyo=r(n2t,"RetriBertModel"),n2t.forEach(t),xyo=r(U$e," (RetriBERT model)"),U$e.forEach(t),$yo=i(O),v2=n(O,"LI",{});var J$e=s(v2);Rme=n(J$e,"STRONG",{});var s2t=s(Rme);kyo=r(s2t,"roberta"),s2t.forEach(t),Syo=r(J$e," \u2014 "),TG=n(J$e,"A",{href:!0});var l2t=s(TG);Ryo=r(l2t,"RobertaForMaskedLM"),l2t.forEach(t),Pyo=r(J$e," (RoBERTa model)"),J$e.forEach(t),Byo=i(O),F2=n(O,"LI",{});var Y$e=s(F2);Pme=n(Y$e,"STRONG",{});var i2t=s(Pme);Nyo=r(i2t,"splinter"),i2t.forEach(t),Iyo=r(Y$e," \u2014 "),MG=n(Y$e,"A",{href:!0});var d2t=s(MG);qyo=r(d2t,"SplinterForPreTraining"),d2t.forEach(t),jyo=r(Y$e," (Splinter model)"),Y$e.forEach(t),Dyo=i(O),T2=n(O,"LI",{});var K$e=s(T2);Bme=n(K$e,"STRONG",{});var c2t=s(Bme);Gyo=r(c2t,"squeezebert"),c2t.forEach(t),Oyo=r(K$e," \u2014 "),EG=n(K$e,"A",{href:!0});var f2t=s(EG);Vyo=r(f2t,"SqueezeBertForMaskedLM"),f2t.forEach(t),Xyo=r(K$e," (SqueezeBERT model)"),K$e.forEach(t),zyo=i(O),M2=n(O,"LI",{});var Z$e=s(M2);Nme=n(Z$e,"STRONG",{});var m2t=s(Nme);Qyo=r(m2t,"t5"),m2t.forEach(t),Wyo=r(Z$e," \u2014 "),CG=n(Z$e,"A",{href:!0});var g2t=s(CG);Hyo=r(g2t,"T5ForConditionalGeneration"),g2t.forEach(t),Uyo=r(Z$e," (T5 model)"),Z$e.forEach(t),Jyo=i(O),E2=n(O,"LI",{});var eke=s(E2);Ime=n(eke,"STRONG",{});var h2t=s(Ime);Yyo=r(h2t,"tapas"),h2t.forEach(t),Kyo=r(eke," \u2014 "),wG=n(eke,"A",{href:!0});var p2t=s(wG);Zyo=r(p2t,"TapasForMaskedLM"),p2t.forEach(t),e8o=r(eke," (TAPAS model)"),eke.forEach(t),o8o=i(O),C2=n(O,"LI",{});var oke=s(C2);qme=n(oke,"STRONG",{});var _2t=s(qme);r8o=r(_2t,"transfo-xl"),_2t.forEach(t),t8o=r(oke," \u2014 "),AG=n(oke,"A",{href:!0});var u2t=s(AG);a8o=r(u2t,"TransfoXLLMHeadModel"),u2t.forEach(t),n8o=r(oke," (Transformer-XL model)"),oke.forEach(t),s8o=i(O),w2=n(O,"LI",{});var rke=s(w2);jme=n(rke,"STRONG",{});var b2t=s(jme);l8o=r(b2t,"unispeech"),b2t.forEach(t),i8o=r(rke," \u2014 "),LG=n(rke,"A",{href:!0});var v2t=s(LG);d8o=r(v2t,"UniSpeechForPreTraining"),v2t.forEach(t),c8o=r(rke," (UniSpeech model)"),rke.forEach(t),f8o=i(O),A2=n(O,"LI",{});var tke=s(A2);Dme=n(tke,"STRONG",{});var F2t=s(Dme);m8o=r(F2t,"unispeech-sat"),F2t.forEach(t),g8o=r(tke," \u2014 "),yG=n(tke,"A",{href:!0});var T2t=s(yG);h8o=r(T2t,"UniSpeechSatForPreTraining"),T2t.forEach(t),p8o=r(tke," (UniSpeechSat model)"),tke.forEach(t),_8o=i(O),L2=n(O,"LI",{});var ake=s(L2);Gme=n(ake,"STRONG",{});var M2t=s(Gme);u8o=r(M2t,"visual_bert"),M2t.forEach(t),b8o=r(ake," \u2014 "),xG=n(ake,"A",{href:!0});var E2t=s(xG);v8o=r(E2t,"VisualBertForPreTraining"),E2t.forEach(t),F8o=r(ake," (VisualBERT model)"),ake.forEach(t),T8o=i(O),y2=n(O,"LI",{});var nke=s(y2);Ome=n(nke,"STRONG",{});var C2t=s(Ome);M8o=r(C2t,"vit_mae"),C2t.forEach(t),E8o=r(nke," \u2014 "),$G=n(nke,"A",{href:!0});var w2t=s($G);C8o=r(w2t,"ViTMAEForPreTraining"),w2t.forEach(t),w8o=r(nke," (ViTMAE model)"),nke.forEach(t),A8o=i(O),x2=n(O,"LI",{});var ske=s(x2);Vme=n(ske,"STRONG",{});var A2t=s(Vme);L8o=r(A2t,"wav2vec2"),A2t.forEach(t),y8o=r(ske," \u2014 "),kG=n(ske,"A",{href:!0});var L2t=s(kG);x8o=r(L2t,"Wav2Vec2ForPreTraining"),L2t.forEach(t),$8o=r(ske," (Wav2Vec2 model)"),ske.forEach(t),k8o=i(O),$2=n(O,"LI",{});var lke=s($2);Xme=n(lke,"STRONG",{});var y2t=s(Xme);S8o=r(y2t,"wav2vec2-conformer"),y2t.forEach(t),R8o=r(lke," \u2014 "),SG=n(lke,"A",{href:!0});var x2t=s(SG);P8o=r(x2t,"Wav2Vec2ConformerForPreTraining"),x2t.forEach(t),B8o=r(lke," (Wav2Vec2-Conformer model)"),lke.forEach(t),N8o=i(O),k2=n(O,"LI",{});var ike=s(k2);zme=n(ike,"STRONG",{});var $2t=s(zme);I8o=r($2t,"xlm"),$2t.forEach(t),q8o=r(ike," \u2014 "),RG=n(ike,"A",{href:!0});var k2t=s(RG);j8o=r(k2t,"XLMWithLMHeadModel"),k2t.forEach(t),D8o=r(ike," (XLM model)"),ike.forEach(t),G8o=i(O),S2=n(O,"LI",{});var dke=s(S2);Qme=n(dke,"STRONG",{});var S2t=s(Qme);O8o=r(S2t,"xlm-roberta"),S2t.forEach(t),V8o=r(dke," \u2014 "),PG=n(dke,"A",{href:!0});var R2t=s(PG);X8o=r(R2t,"XLMRobertaForMaskedLM"),R2t.forEach(t),z8o=r(dke," (XLM-RoBERTa model)"),dke.forEach(t),Q8o=i(O),R2=n(O,"LI",{});var cke=s(R2);Wme=n(cke,"STRONG",{});var P2t=s(Wme);W8o=r(P2t,"xlm-roberta-xl"),P2t.forEach(t),H8o=r(cke," \u2014 "),BG=n(cke,"A",{href:!0});var B2t=s(BG);U8o=r(B2t,"XLMRobertaXLForMaskedLM"),B2t.forEach(t),J8o=r(cke," (XLM-RoBERTa-XL model)"),cke.forEach(t),Y8o=i(O),P2=n(O,"LI",{});var fke=s(P2);Hme=n(fke,"STRONG",{});var N2t=s(Hme);K8o=r(N2t,"xlnet"),N2t.forEach(t),Z8o=r(fke," \u2014 "),NG=n(fke,"A",{href:!0});var I2t=s(NG);e9o=r(I2t,"XLNetLMHeadModel"),I2t.forEach(t),o9o=r(fke," (XLNet model)"),fke.forEach(t),O.forEach(t),r9o=i(sa),B2=n(sa,"P",{});var mke=s(B2);t9o=r(mke,"The model is set in evaluation mode by default using "),Ume=n(mke,"CODE",{});var q2t=s(Ume);a9o=r(q2t,"model.eval()"),q2t.forEach(t),n9o=r(mke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jme=n(mke,"CODE",{});var j2t=s(Jme);s9o=r(j2t,"model.train()"),j2t.forEach(t),mke.forEach(t),l9o=i(sa),T(N2.$$.fragment,sa),sa.forEach(t),rl.forEach(t),jVe=i(f),zi=n(f,"H2",{class:!0});var zze=s(zi);I2=n(zze,"A",{id:!0,class:!0,href:!0});var D2t=s(I2);Yme=n(D2t,"SPAN",{});var G2t=s(Yme);T(Ry.$$.fragment,G2t),G2t.forEach(t),D2t.forEach(t),i9o=i(zze),Kme=n(zze,"SPAN",{});var O2t=s(Kme);d9o=r(O2t,"AutoModelForCausalLM"),O2t.forEach(t),zze.forEach(t),DVe=i(f),ko=n(f,"DIV",{class:!0});var tl=s(ko);T(Py.$$.fragment,tl),c9o=i(tl),Qi=n(tl,"P",{});var vre=s(Qi);f9o=r(vre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),IG=n(vre,"A",{href:!0});var V2t=s(IG);m9o=r(V2t,"from_pretrained()"),V2t.forEach(t),g9o=r(vre," class method or the "),qG=n(vre,"A",{href:!0});var X2t=s(qG);h9o=r(X2t,"from_config()"),X2t.forEach(t),p9o=r(vre,` class
method.`),vre.forEach(t),_9o=i(tl),By=n(tl,"P",{});var Qze=s(By);u9o=r(Qze,"This class cannot be instantiated directly using "),Zme=n(Qze,"CODE",{});var z2t=s(Zme);b9o=r(z2t,"__init__()"),z2t.forEach(t),v9o=r(Qze," (throws an error)."),Qze.forEach(t),F9o=i(tl),it=n(tl,"DIV",{class:!0});var a6=s(it);T(Ny.$$.fragment,a6),T9o=i(a6),ege=n(a6,"P",{});var Q2t=s(ege);M9o=r(Q2t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Q2t.forEach(t),E9o=i(a6),Wi=n(a6,"P",{});var Fre=s(Wi);C9o=r(Fre,`Note:
Loading a model from its configuration file does `),oge=n(Fre,"STRONG",{});var W2t=s(oge);w9o=r(W2t,"not"),W2t.forEach(t),A9o=r(Fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),jG=n(Fre,"A",{href:!0});var H2t=s(jG);L9o=r(H2t,"from_pretrained()"),H2t.forEach(t),y9o=r(Fre," to load the model weights."),Fre.forEach(t),x9o=i(a6),T(q2.$$.fragment,a6),a6.forEach(t),$9o=i(tl),Ke=n(tl,"DIV",{class:!0});var la=s(Ke);T(Iy.$$.fragment,la),k9o=i(la),rge=n(la,"P",{});var U2t=s(rge);S9o=r(U2t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),U2t.forEach(t),R9o=i(la),Ia=n(la,"P",{});var n6=s(Ia);P9o=r(n6,"The model class to instantiate is selected based on the "),tge=n(n6,"CODE",{});var J2t=s(tge);B9o=r(J2t,"model_type"),J2t.forEach(t),N9o=r(n6,` property of the config object (either
passed as an argument or loaded from `),age=n(n6,"CODE",{});var Y2t=s(age);I9o=r(Y2t,"pretrained_model_name_or_path"),Y2t.forEach(t),q9o=r(n6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nge=n(n6,"CODE",{});var K2t=s(nge);j9o=r(K2t,"pretrained_model_name_or_path"),K2t.forEach(t),D9o=r(n6,":"),n6.forEach(t),G9o=i(la),z=n(la,"UL",{});var Q=s(z);j2=n(Q,"LI",{});var gke=s(j2);sge=n(gke,"STRONG",{});var Z2t=s(sge);O9o=r(Z2t,"bart"),Z2t.forEach(t),V9o=r(gke," \u2014 "),DG=n(gke,"A",{href:!0});var e1t=s(DG);X9o=r(e1t,"BartForCausalLM"),e1t.forEach(t),z9o=r(gke," (BART model)"),gke.forEach(t),Q9o=i(Q),D2=n(Q,"LI",{});var hke=s(D2);lge=n(hke,"STRONG",{});var o1t=s(lge);W9o=r(o1t,"bert"),o1t.forEach(t),H9o=r(hke," \u2014 "),GG=n(hke,"A",{href:!0});var r1t=s(GG);U9o=r(r1t,"BertLMHeadModel"),r1t.forEach(t),J9o=r(hke," (BERT model)"),hke.forEach(t),Y9o=i(Q),G2=n(Q,"LI",{});var pke=s(G2);ige=n(pke,"STRONG",{});var t1t=s(ige);K9o=r(t1t,"bert-generation"),t1t.forEach(t),Z9o=r(pke," \u2014 "),OG=n(pke,"A",{href:!0});var a1t=s(OG);exo=r(a1t,"BertGenerationDecoder"),a1t.forEach(t),oxo=r(pke," (Bert Generation model)"),pke.forEach(t),rxo=i(Q),O2=n(Q,"LI",{});var _ke=s(O2);dge=n(_ke,"STRONG",{});var n1t=s(dge);txo=r(n1t,"big_bird"),n1t.forEach(t),axo=r(_ke," \u2014 "),VG=n(_ke,"A",{href:!0});var s1t=s(VG);nxo=r(s1t,"BigBirdForCausalLM"),s1t.forEach(t),sxo=r(_ke," (BigBird model)"),_ke.forEach(t),lxo=i(Q),V2=n(Q,"LI",{});var uke=s(V2);cge=n(uke,"STRONG",{});var l1t=s(cge);ixo=r(l1t,"bigbird_pegasus"),l1t.forEach(t),dxo=r(uke," \u2014 "),XG=n(uke,"A",{href:!0});var i1t=s(XG);cxo=r(i1t,"BigBirdPegasusForCausalLM"),i1t.forEach(t),fxo=r(uke," (BigBird-Pegasus model)"),uke.forEach(t),mxo=i(Q),X2=n(Q,"LI",{});var bke=s(X2);fge=n(bke,"STRONG",{});var d1t=s(fge);gxo=r(d1t,"blenderbot"),d1t.forEach(t),hxo=r(bke," \u2014 "),zG=n(bke,"A",{href:!0});var c1t=s(zG);pxo=r(c1t,"BlenderbotForCausalLM"),c1t.forEach(t),_xo=r(bke," (Blenderbot model)"),bke.forEach(t),uxo=i(Q),z2=n(Q,"LI",{});var vke=s(z2);mge=n(vke,"STRONG",{});var f1t=s(mge);bxo=r(f1t,"blenderbot-small"),f1t.forEach(t),vxo=r(vke," \u2014 "),QG=n(vke,"A",{href:!0});var m1t=s(QG);Fxo=r(m1t,"BlenderbotSmallForCausalLM"),m1t.forEach(t),Txo=r(vke," (BlenderbotSmall model)"),vke.forEach(t),Mxo=i(Q),Q2=n(Q,"LI",{});var Fke=s(Q2);gge=n(Fke,"STRONG",{});var g1t=s(gge);Exo=r(g1t,"bloom"),g1t.forEach(t),Cxo=r(Fke," \u2014 "),WG=n(Fke,"A",{href:!0});var h1t=s(WG);wxo=r(h1t,"BloomForCausalLM"),h1t.forEach(t),Axo=r(Fke," (BLOOM model)"),Fke.forEach(t),Lxo=i(Q),W2=n(Q,"LI",{});var Tke=s(W2);hge=n(Tke,"STRONG",{});var p1t=s(hge);yxo=r(p1t,"camembert"),p1t.forEach(t),xxo=r(Tke," \u2014 "),HG=n(Tke,"A",{href:!0});var _1t=s(HG);$xo=r(_1t,"CamembertForCausalLM"),_1t.forEach(t),kxo=r(Tke," (CamemBERT model)"),Tke.forEach(t),Sxo=i(Q),H2=n(Q,"LI",{});var Mke=s(H2);pge=n(Mke,"STRONG",{});var u1t=s(pge);Rxo=r(u1t,"codegen"),u1t.forEach(t),Pxo=r(Mke," \u2014 "),UG=n(Mke,"A",{href:!0});var b1t=s(UG);Bxo=r(b1t,"CodeGenForCausalLM"),b1t.forEach(t),Nxo=r(Mke," (CodeGen model)"),Mke.forEach(t),Ixo=i(Q),U2=n(Q,"LI",{});var Eke=s(U2);_ge=n(Eke,"STRONG",{});var v1t=s(_ge);qxo=r(v1t,"ctrl"),v1t.forEach(t),jxo=r(Eke," \u2014 "),JG=n(Eke,"A",{href:!0});var F1t=s(JG);Dxo=r(F1t,"CTRLLMHeadModel"),F1t.forEach(t),Gxo=r(Eke," (CTRL model)"),Eke.forEach(t),Oxo=i(Q),J2=n(Q,"LI",{});var Cke=s(J2);uge=n(Cke,"STRONG",{});var T1t=s(uge);Vxo=r(T1t,"data2vec-text"),T1t.forEach(t),Xxo=r(Cke," \u2014 "),YG=n(Cke,"A",{href:!0});var M1t=s(YG);zxo=r(M1t,"Data2VecTextForCausalLM"),M1t.forEach(t),Qxo=r(Cke," (Data2VecText model)"),Cke.forEach(t),Wxo=i(Q),Y2=n(Q,"LI",{});var wke=s(Y2);bge=n(wke,"STRONG",{});var E1t=s(bge);Hxo=r(E1t,"electra"),E1t.forEach(t),Uxo=r(wke," \u2014 "),KG=n(wke,"A",{href:!0});var C1t=s(KG);Jxo=r(C1t,"ElectraForCausalLM"),C1t.forEach(t),Yxo=r(wke," (ELECTRA model)"),wke.forEach(t),Kxo=i(Q),K2=n(Q,"LI",{});var Ake=s(K2);vge=n(Ake,"STRONG",{});var w1t=s(vge);Zxo=r(w1t,"gpt2"),w1t.forEach(t),e$o=r(Ake," \u2014 "),ZG=n(Ake,"A",{href:!0});var A1t=s(ZG);o$o=r(A1t,"GPT2LMHeadModel"),A1t.forEach(t),r$o=r(Ake," (OpenAI GPT-2 model)"),Ake.forEach(t),t$o=i(Q),Z2=n(Q,"LI",{});var Lke=s(Z2);Fge=n(Lke,"STRONG",{});var L1t=s(Fge);a$o=r(L1t,"gpt_neo"),L1t.forEach(t),n$o=r(Lke," \u2014 "),eO=n(Lke,"A",{href:!0});var y1t=s(eO);s$o=r(y1t,"GPTNeoForCausalLM"),y1t.forEach(t),l$o=r(Lke," (GPT Neo model)"),Lke.forEach(t),i$o=i(Q),e1=n(Q,"LI",{});var yke=s(e1);Tge=n(yke,"STRONG",{});var x1t=s(Tge);d$o=r(x1t,"gpt_neox"),x1t.forEach(t),c$o=r(yke," \u2014 "),oO=n(yke,"A",{href:!0});var $1t=s(oO);f$o=r($1t,"GPTNeoXForCausalLM"),$1t.forEach(t),m$o=r(yke," (GPT NeoX model)"),yke.forEach(t),g$o=i(Q),o1=n(Q,"LI",{});var xke=s(o1);Mge=n(xke,"STRONG",{});var k1t=s(Mge);h$o=r(k1t,"gptj"),k1t.forEach(t),p$o=r(xke," \u2014 "),rO=n(xke,"A",{href:!0});var S1t=s(rO);_$o=r(S1t,"GPTJForCausalLM"),S1t.forEach(t),u$o=r(xke," (GPT-J model)"),xke.forEach(t),b$o=i(Q),r1=n(Q,"LI",{});var $ke=s(r1);Ege=n($ke,"STRONG",{});var R1t=s(Ege);v$o=r(R1t,"marian"),R1t.forEach(t),F$o=r($ke," \u2014 "),tO=n($ke,"A",{href:!0});var P1t=s(tO);T$o=r(P1t,"MarianForCausalLM"),P1t.forEach(t),M$o=r($ke," (Marian model)"),$ke.forEach(t),E$o=i(Q),t1=n(Q,"LI",{});var kke=s(t1);Cge=n(kke,"STRONG",{});var B1t=s(Cge);C$o=r(B1t,"mbart"),B1t.forEach(t),w$o=r(kke," \u2014 "),aO=n(kke,"A",{href:!0});var N1t=s(aO);A$o=r(N1t,"MBartForCausalLM"),N1t.forEach(t),L$o=r(kke," (mBART model)"),kke.forEach(t),y$o=i(Q),a1=n(Q,"LI",{});var Ske=s(a1);wge=n(Ske,"STRONG",{});var I1t=s(wge);x$o=r(I1t,"megatron-bert"),I1t.forEach(t),$$o=r(Ske," \u2014 "),nO=n(Ske,"A",{href:!0});var q1t=s(nO);k$o=r(q1t,"MegatronBertForCausalLM"),q1t.forEach(t),S$o=r(Ske," (Megatron-BERT model)"),Ske.forEach(t),R$o=i(Q),n1=n(Q,"LI",{});var Rke=s(n1);Age=n(Rke,"STRONG",{});var j1t=s(Age);P$o=r(j1t,"mvp"),j1t.forEach(t),B$o=r(Rke," \u2014 "),sO=n(Rke,"A",{href:!0});var D1t=s(sO);N$o=r(D1t,"MvpForCausalLM"),D1t.forEach(t),I$o=r(Rke," (MVP model)"),Rke.forEach(t),q$o=i(Q),s1=n(Q,"LI",{});var Pke=s(s1);Lge=n(Pke,"STRONG",{});var G1t=s(Lge);j$o=r(G1t,"openai-gpt"),G1t.forEach(t),D$o=r(Pke," \u2014 "),lO=n(Pke,"A",{href:!0});var O1t=s(lO);G$o=r(O1t,"OpenAIGPTLMHeadModel"),O1t.forEach(t),O$o=r(Pke," (OpenAI GPT model)"),Pke.forEach(t),V$o=i(Q),l1=n(Q,"LI",{});var Bke=s(l1);yge=n(Bke,"STRONG",{});var V1t=s(yge);X$o=r(V1t,"opt"),V1t.forEach(t),z$o=r(Bke," \u2014 "),iO=n(Bke,"A",{href:!0});var X1t=s(iO);Q$o=r(X1t,"OPTForCausalLM"),X1t.forEach(t),W$o=r(Bke," (OPT model)"),Bke.forEach(t),H$o=i(Q),i1=n(Q,"LI",{});var Nke=s(i1);xge=n(Nke,"STRONG",{});var z1t=s(xge);U$o=r(z1t,"pegasus"),z1t.forEach(t),J$o=r(Nke," \u2014 "),dO=n(Nke,"A",{href:!0});var Q1t=s(dO);Y$o=r(Q1t,"PegasusForCausalLM"),Q1t.forEach(t),K$o=r(Nke," (Pegasus model)"),Nke.forEach(t),Z$o=i(Q),d1=n(Q,"LI",{});var Ike=s(d1);$ge=n(Ike,"STRONG",{});var W1t=s($ge);eko=r(W1t,"plbart"),W1t.forEach(t),oko=r(Ike," \u2014 "),cO=n(Ike,"A",{href:!0});var H1t=s(cO);rko=r(H1t,"PLBartForCausalLM"),H1t.forEach(t),tko=r(Ike," (PLBart model)"),Ike.forEach(t),ako=i(Q),c1=n(Q,"LI",{});var qke=s(c1);kge=n(qke,"STRONG",{});var U1t=s(kge);nko=r(U1t,"prophetnet"),U1t.forEach(t),sko=r(qke," \u2014 "),fO=n(qke,"A",{href:!0});var J1t=s(fO);lko=r(J1t,"ProphetNetForCausalLM"),J1t.forEach(t),iko=r(qke," (ProphetNet model)"),qke.forEach(t),dko=i(Q),f1=n(Q,"LI",{});var jke=s(f1);Sge=n(jke,"STRONG",{});var Y1t=s(Sge);cko=r(Y1t,"qdqbert"),Y1t.forEach(t),fko=r(jke," \u2014 "),mO=n(jke,"A",{href:!0});var K1t=s(mO);mko=r(K1t,"QDQBertLMHeadModel"),K1t.forEach(t),gko=r(jke," (QDQBert model)"),jke.forEach(t),hko=i(Q),m1=n(Q,"LI",{});var Dke=s(m1);Rge=n(Dke,"STRONG",{});var Z1t=s(Rge);pko=r(Z1t,"reformer"),Z1t.forEach(t),_ko=r(Dke," \u2014 "),gO=n(Dke,"A",{href:!0});var e7t=s(gO);uko=r(e7t,"ReformerModelWithLMHead"),e7t.forEach(t),bko=r(Dke," (Reformer model)"),Dke.forEach(t),vko=i(Q),g1=n(Q,"LI",{});var Gke=s(g1);Pge=n(Gke,"STRONG",{});var o7t=s(Pge);Fko=r(o7t,"rembert"),o7t.forEach(t),Tko=r(Gke," \u2014 "),hO=n(Gke,"A",{href:!0});var r7t=s(hO);Mko=r(r7t,"RemBertForCausalLM"),r7t.forEach(t),Eko=r(Gke," (RemBERT model)"),Gke.forEach(t),Cko=i(Q),h1=n(Q,"LI",{});var Oke=s(h1);Bge=n(Oke,"STRONG",{});var t7t=s(Bge);wko=r(t7t,"roberta"),t7t.forEach(t),Ako=r(Oke," \u2014 "),pO=n(Oke,"A",{href:!0});var a7t=s(pO);Lko=r(a7t,"RobertaForCausalLM"),a7t.forEach(t),yko=r(Oke," (RoBERTa model)"),Oke.forEach(t),xko=i(Q),p1=n(Q,"LI",{});var Vke=s(p1);Nge=n(Vke,"STRONG",{});var n7t=s(Nge);$ko=r(n7t,"roformer"),n7t.forEach(t),kko=r(Vke," \u2014 "),_O=n(Vke,"A",{href:!0});var s7t=s(_O);Sko=r(s7t,"RoFormerForCausalLM"),s7t.forEach(t),Rko=r(Vke," (RoFormer model)"),Vke.forEach(t),Pko=i(Q),_1=n(Q,"LI",{});var Xke=s(_1);Ige=n(Xke,"STRONG",{});var l7t=s(Ige);Bko=r(l7t,"speech_to_text_2"),l7t.forEach(t),Nko=r(Xke," \u2014 "),uO=n(Xke,"A",{href:!0});var i7t=s(uO);Iko=r(i7t,"Speech2Text2ForCausalLM"),i7t.forEach(t),qko=r(Xke," (Speech2Text2 model)"),Xke.forEach(t),jko=i(Q),u1=n(Q,"LI",{});var zke=s(u1);qge=n(zke,"STRONG",{});var d7t=s(qge);Dko=r(d7t,"transfo-xl"),d7t.forEach(t),Gko=r(zke," \u2014 "),bO=n(zke,"A",{href:!0});var c7t=s(bO);Oko=r(c7t,"TransfoXLLMHeadModel"),c7t.forEach(t),Vko=r(zke," (Transformer-XL model)"),zke.forEach(t),Xko=i(Q),b1=n(Q,"LI",{});var Qke=s(b1);jge=n(Qke,"STRONG",{});var f7t=s(jge);zko=r(f7t,"trocr"),f7t.forEach(t),Qko=r(Qke," \u2014 "),vO=n(Qke,"A",{href:!0});var m7t=s(vO);Wko=r(m7t,"TrOCRForCausalLM"),m7t.forEach(t),Hko=r(Qke," (TrOCR model)"),Qke.forEach(t),Uko=i(Q),v1=n(Q,"LI",{});var Wke=s(v1);Dge=n(Wke,"STRONG",{});var g7t=s(Dge);Jko=r(g7t,"xglm"),g7t.forEach(t),Yko=r(Wke," \u2014 "),FO=n(Wke,"A",{href:!0});var h7t=s(FO);Kko=r(h7t,"XGLMForCausalLM"),h7t.forEach(t),Zko=r(Wke," (XGLM model)"),Wke.forEach(t),eSo=i(Q),F1=n(Q,"LI",{});var Hke=s(F1);Gge=n(Hke,"STRONG",{});var p7t=s(Gge);oSo=r(p7t,"xlm"),p7t.forEach(t),rSo=r(Hke," \u2014 "),TO=n(Hke,"A",{href:!0});var _7t=s(TO);tSo=r(_7t,"XLMWithLMHeadModel"),_7t.forEach(t),aSo=r(Hke," (XLM model)"),Hke.forEach(t),nSo=i(Q),T1=n(Q,"LI",{});var Uke=s(T1);Oge=n(Uke,"STRONG",{});var u7t=s(Oge);sSo=r(u7t,"xlm-prophetnet"),u7t.forEach(t),lSo=r(Uke," \u2014 "),MO=n(Uke,"A",{href:!0});var b7t=s(MO);iSo=r(b7t,"XLMProphetNetForCausalLM"),b7t.forEach(t),dSo=r(Uke," (XLM-ProphetNet model)"),Uke.forEach(t),cSo=i(Q),M1=n(Q,"LI",{});var Jke=s(M1);Vge=n(Jke,"STRONG",{});var v7t=s(Vge);fSo=r(v7t,"xlm-roberta"),v7t.forEach(t),mSo=r(Jke," \u2014 "),EO=n(Jke,"A",{href:!0});var F7t=s(EO);gSo=r(F7t,"XLMRobertaForCausalLM"),F7t.forEach(t),hSo=r(Jke," (XLM-RoBERTa model)"),Jke.forEach(t),pSo=i(Q),E1=n(Q,"LI",{});var Yke=s(E1);Xge=n(Yke,"STRONG",{});var T7t=s(Xge);_So=r(T7t,"xlm-roberta-xl"),T7t.forEach(t),uSo=r(Yke," \u2014 "),CO=n(Yke,"A",{href:!0});var M7t=s(CO);bSo=r(M7t,"XLMRobertaXLForCausalLM"),M7t.forEach(t),vSo=r(Yke," (XLM-RoBERTa-XL model)"),Yke.forEach(t),FSo=i(Q),C1=n(Q,"LI",{});var Kke=s(C1);zge=n(Kke,"STRONG",{});var E7t=s(zge);TSo=r(E7t,"xlnet"),E7t.forEach(t),MSo=r(Kke," \u2014 "),wO=n(Kke,"A",{href:!0});var C7t=s(wO);ESo=r(C7t,"XLNetLMHeadModel"),C7t.forEach(t),CSo=r(Kke," (XLNet model)"),Kke.forEach(t),Q.forEach(t),wSo=i(la),w1=n(la,"P",{});var Zke=s(w1);ASo=r(Zke,"The model is set in evaluation mode by default using "),Qge=n(Zke,"CODE",{});var w7t=s(Qge);LSo=r(w7t,"model.eval()"),w7t.forEach(t),ySo=r(Zke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wge=n(Zke,"CODE",{});var A7t=s(Wge);xSo=r(A7t,"model.train()"),A7t.forEach(t),Zke.forEach(t),$So=i(la),T(A1.$$.fragment,la),la.forEach(t),tl.forEach(t),GVe=i(f),Hi=n(f,"H2",{class:!0});var Wze=s(Hi);L1=n(Wze,"A",{id:!0,class:!0,href:!0});var L7t=s(L1);Hge=n(L7t,"SPAN",{});var y7t=s(Hge);T(qy.$$.fragment,y7t),y7t.forEach(t),L7t.forEach(t),kSo=i(Wze),Uge=n(Wze,"SPAN",{});var x7t=s(Uge);SSo=r(x7t,"AutoModelForMaskedLM"),x7t.forEach(t),Wze.forEach(t),OVe=i(f),So=n(f,"DIV",{class:!0});var al=s(So);T(jy.$$.fragment,al),RSo=i(al),Ui=n(al,"P",{});var Tre=s(Ui);PSo=r(Tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),AO=n(Tre,"A",{href:!0});var $7t=s(AO);BSo=r($7t,"from_pretrained()"),$7t.forEach(t),NSo=r(Tre," class method or the "),LO=n(Tre,"A",{href:!0});var k7t=s(LO);ISo=r(k7t,"from_config()"),k7t.forEach(t),qSo=r(Tre,` class
method.`),Tre.forEach(t),jSo=i(al),Dy=n(al,"P",{});var Hze=s(Dy);DSo=r(Hze,"This class cannot be instantiated directly using "),Jge=n(Hze,"CODE",{});var S7t=s(Jge);GSo=r(S7t,"__init__()"),S7t.forEach(t),OSo=r(Hze," (throws an error)."),Hze.forEach(t),VSo=i(al),dt=n(al,"DIV",{class:!0});var s6=s(dt);T(Gy.$$.fragment,s6),XSo=i(s6),Yge=n(s6,"P",{});var R7t=s(Yge);zSo=r(R7t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),R7t.forEach(t),QSo=i(s6),Ji=n(s6,"P",{});var Mre=s(Ji);WSo=r(Mre,`Note:
Loading a model from its configuration file does `),Kge=n(Mre,"STRONG",{});var P7t=s(Kge);HSo=r(P7t,"not"),P7t.forEach(t),USo=r(Mre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yO=n(Mre,"A",{href:!0});var B7t=s(yO);JSo=r(B7t,"from_pretrained()"),B7t.forEach(t),YSo=r(Mre," to load the model weights."),Mre.forEach(t),KSo=i(s6),T(y1.$$.fragment,s6),s6.forEach(t),ZSo=i(al),Ze=n(al,"DIV",{class:!0});var ia=s(Ze);T(Oy.$$.fragment,ia),eRo=i(ia),Zge=n(ia,"P",{});var N7t=s(Zge);oRo=r(N7t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),N7t.forEach(t),rRo=i(ia),qa=n(ia,"P",{});var l6=s(qa);tRo=r(l6,"The model class to instantiate is selected based on the "),ehe=n(l6,"CODE",{});var I7t=s(ehe);aRo=r(I7t,"model_type"),I7t.forEach(t),nRo=r(l6,` property of the config object (either
passed as an argument or loaded from `),ohe=n(l6,"CODE",{});var q7t=s(ohe);sRo=r(q7t,"pretrained_model_name_or_path"),q7t.forEach(t),lRo=r(l6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rhe=n(l6,"CODE",{});var j7t=s(rhe);iRo=r(j7t,"pretrained_model_name_or_path"),j7t.forEach(t),dRo=r(l6,":"),l6.forEach(t),cRo=i(ia),W=n(ia,"UL",{});var H=s(W);x1=n(H,"LI",{});var eSe=s(x1);the=n(eSe,"STRONG",{});var D7t=s(the);fRo=r(D7t,"albert"),D7t.forEach(t),mRo=r(eSe," \u2014 "),xO=n(eSe,"A",{href:!0});var G7t=s(xO);gRo=r(G7t,"AlbertForMaskedLM"),G7t.forEach(t),hRo=r(eSe," (ALBERT model)"),eSe.forEach(t),pRo=i(H),$1=n(H,"LI",{});var oSe=s($1);ahe=n(oSe,"STRONG",{});var O7t=s(ahe);_Ro=r(O7t,"bart"),O7t.forEach(t),uRo=r(oSe," \u2014 "),$O=n(oSe,"A",{href:!0});var V7t=s($O);bRo=r(V7t,"BartForConditionalGeneration"),V7t.forEach(t),vRo=r(oSe," (BART model)"),oSe.forEach(t),FRo=i(H),k1=n(H,"LI",{});var rSe=s(k1);nhe=n(rSe,"STRONG",{});var X7t=s(nhe);TRo=r(X7t,"bert"),X7t.forEach(t),MRo=r(rSe," \u2014 "),kO=n(rSe,"A",{href:!0});var z7t=s(kO);ERo=r(z7t,"BertForMaskedLM"),z7t.forEach(t),CRo=r(rSe," (BERT model)"),rSe.forEach(t),wRo=i(H),S1=n(H,"LI",{});var tSe=s(S1);she=n(tSe,"STRONG",{});var Q7t=s(she);ARo=r(Q7t,"big_bird"),Q7t.forEach(t),LRo=r(tSe," \u2014 "),SO=n(tSe,"A",{href:!0});var W7t=s(SO);yRo=r(W7t,"BigBirdForMaskedLM"),W7t.forEach(t),xRo=r(tSe," (BigBird model)"),tSe.forEach(t),$Ro=i(H),R1=n(H,"LI",{});var aSe=s(R1);lhe=n(aSe,"STRONG",{});var H7t=s(lhe);kRo=r(H7t,"camembert"),H7t.forEach(t),SRo=r(aSe," \u2014 "),RO=n(aSe,"A",{href:!0});var U7t=s(RO);RRo=r(U7t,"CamembertForMaskedLM"),U7t.forEach(t),PRo=r(aSe," (CamemBERT model)"),aSe.forEach(t),BRo=i(H),P1=n(H,"LI",{});var nSe=s(P1);ihe=n(nSe,"STRONG",{});var J7t=s(ihe);NRo=r(J7t,"convbert"),J7t.forEach(t),IRo=r(nSe," \u2014 "),PO=n(nSe,"A",{href:!0});var Y7t=s(PO);qRo=r(Y7t,"ConvBertForMaskedLM"),Y7t.forEach(t),jRo=r(nSe," (ConvBERT model)"),nSe.forEach(t),DRo=i(H),B1=n(H,"LI",{});var sSe=s(B1);dhe=n(sSe,"STRONG",{});var K7t=s(dhe);GRo=r(K7t,"data2vec-text"),K7t.forEach(t),ORo=r(sSe," \u2014 "),BO=n(sSe,"A",{href:!0});var Z7t=s(BO);VRo=r(Z7t,"Data2VecTextForMaskedLM"),Z7t.forEach(t),XRo=r(sSe," (Data2VecText model)"),sSe.forEach(t),zRo=i(H),N1=n(H,"LI",{});var lSe=s(N1);che=n(lSe,"STRONG",{});var e4t=s(che);QRo=r(e4t,"deberta"),e4t.forEach(t),WRo=r(lSe," \u2014 "),NO=n(lSe,"A",{href:!0});var o4t=s(NO);HRo=r(o4t,"DebertaForMaskedLM"),o4t.forEach(t),URo=r(lSe," (DeBERTa model)"),lSe.forEach(t),JRo=i(H),I1=n(H,"LI",{});var iSe=s(I1);fhe=n(iSe,"STRONG",{});var r4t=s(fhe);YRo=r(r4t,"deberta-v2"),r4t.forEach(t),KRo=r(iSe," \u2014 "),IO=n(iSe,"A",{href:!0});var t4t=s(IO);ZRo=r(t4t,"DebertaV2ForMaskedLM"),t4t.forEach(t),ePo=r(iSe," (DeBERTa-v2 model)"),iSe.forEach(t),oPo=i(H),q1=n(H,"LI",{});var dSe=s(q1);mhe=n(dSe,"STRONG",{});var a4t=s(mhe);rPo=r(a4t,"distilbert"),a4t.forEach(t),tPo=r(dSe," \u2014 "),qO=n(dSe,"A",{href:!0});var n4t=s(qO);aPo=r(n4t,"DistilBertForMaskedLM"),n4t.forEach(t),nPo=r(dSe," (DistilBERT model)"),dSe.forEach(t),sPo=i(H),j1=n(H,"LI",{});var cSe=s(j1);ghe=n(cSe,"STRONG",{});var s4t=s(ghe);lPo=r(s4t,"electra"),s4t.forEach(t),iPo=r(cSe," \u2014 "),jO=n(cSe,"A",{href:!0});var l4t=s(jO);dPo=r(l4t,"ElectraForMaskedLM"),l4t.forEach(t),cPo=r(cSe," (ELECTRA model)"),cSe.forEach(t),fPo=i(H),D1=n(H,"LI",{});var fSe=s(D1);hhe=n(fSe,"STRONG",{});var i4t=s(hhe);mPo=r(i4t,"flaubert"),i4t.forEach(t),gPo=r(fSe," \u2014 "),DO=n(fSe,"A",{href:!0});var d4t=s(DO);hPo=r(d4t,"FlaubertWithLMHeadModel"),d4t.forEach(t),pPo=r(fSe," (FlauBERT model)"),fSe.forEach(t),_Po=i(H),G1=n(H,"LI",{});var mSe=s(G1);phe=n(mSe,"STRONG",{});var c4t=s(phe);uPo=r(c4t,"fnet"),c4t.forEach(t),bPo=r(mSe," \u2014 "),GO=n(mSe,"A",{href:!0});var f4t=s(GO);vPo=r(f4t,"FNetForMaskedLM"),f4t.forEach(t),FPo=r(mSe," (FNet model)"),mSe.forEach(t),TPo=i(H),O1=n(H,"LI",{});var gSe=s(O1);_he=n(gSe,"STRONG",{});var m4t=s(_he);MPo=r(m4t,"funnel"),m4t.forEach(t),EPo=r(gSe," \u2014 "),OO=n(gSe,"A",{href:!0});var g4t=s(OO);CPo=r(g4t,"FunnelForMaskedLM"),g4t.forEach(t),wPo=r(gSe," (Funnel Transformer model)"),gSe.forEach(t),APo=i(H),V1=n(H,"LI",{});var hSe=s(V1);uhe=n(hSe,"STRONG",{});var h4t=s(uhe);LPo=r(h4t,"ibert"),h4t.forEach(t),yPo=r(hSe," \u2014 "),VO=n(hSe,"A",{href:!0});var p4t=s(VO);xPo=r(p4t,"IBertForMaskedLM"),p4t.forEach(t),$Po=r(hSe," (I-BERT model)"),hSe.forEach(t),kPo=i(H),X1=n(H,"LI",{});var pSe=s(X1);bhe=n(pSe,"STRONG",{});var _4t=s(bhe);SPo=r(_4t,"layoutlm"),_4t.forEach(t),RPo=r(pSe," \u2014 "),XO=n(pSe,"A",{href:!0});var u4t=s(XO);PPo=r(u4t,"LayoutLMForMaskedLM"),u4t.forEach(t),BPo=r(pSe," (LayoutLM model)"),pSe.forEach(t),NPo=i(H),z1=n(H,"LI",{});var _Se=s(z1);vhe=n(_Se,"STRONG",{});var b4t=s(vhe);IPo=r(b4t,"longformer"),b4t.forEach(t),qPo=r(_Se," \u2014 "),zO=n(_Se,"A",{href:!0});var v4t=s(zO);jPo=r(v4t,"LongformerForMaskedLM"),v4t.forEach(t),DPo=r(_Se," (Longformer model)"),_Se.forEach(t),GPo=i(H),Q1=n(H,"LI",{});var uSe=s(Q1);Fhe=n(uSe,"STRONG",{});var F4t=s(Fhe);OPo=r(F4t,"luke"),F4t.forEach(t),VPo=r(uSe," \u2014 "),QO=n(uSe,"A",{href:!0});var T4t=s(QO);XPo=r(T4t,"LukeForMaskedLM"),T4t.forEach(t),zPo=r(uSe," (LUKE model)"),uSe.forEach(t),QPo=i(H),W1=n(H,"LI",{});var bSe=s(W1);The=n(bSe,"STRONG",{});var M4t=s(The);WPo=r(M4t,"mbart"),M4t.forEach(t),HPo=r(bSe," \u2014 "),WO=n(bSe,"A",{href:!0});var E4t=s(WO);UPo=r(E4t,"MBartForConditionalGeneration"),E4t.forEach(t),JPo=r(bSe," (mBART model)"),bSe.forEach(t),YPo=i(H),H1=n(H,"LI",{});var vSe=s(H1);Mhe=n(vSe,"STRONG",{});var C4t=s(Mhe);KPo=r(C4t,"megatron-bert"),C4t.forEach(t),ZPo=r(vSe," \u2014 "),HO=n(vSe,"A",{href:!0});var w4t=s(HO);eBo=r(w4t,"MegatronBertForMaskedLM"),w4t.forEach(t),oBo=r(vSe," (Megatron-BERT model)"),vSe.forEach(t),rBo=i(H),U1=n(H,"LI",{});var FSe=s(U1);Ehe=n(FSe,"STRONG",{});var A4t=s(Ehe);tBo=r(A4t,"mobilebert"),A4t.forEach(t),aBo=r(FSe," \u2014 "),UO=n(FSe,"A",{href:!0});var L4t=s(UO);nBo=r(L4t,"MobileBertForMaskedLM"),L4t.forEach(t),sBo=r(FSe," (MobileBERT model)"),FSe.forEach(t),lBo=i(H),J1=n(H,"LI",{});var TSe=s(J1);Che=n(TSe,"STRONG",{});var y4t=s(Che);iBo=r(y4t,"mpnet"),y4t.forEach(t),dBo=r(TSe," \u2014 "),JO=n(TSe,"A",{href:!0});var x4t=s(JO);cBo=r(x4t,"MPNetForMaskedLM"),x4t.forEach(t),fBo=r(TSe," (MPNet model)"),TSe.forEach(t),mBo=i(H),Y1=n(H,"LI",{});var MSe=s(Y1);whe=n(MSe,"STRONG",{});var $4t=s(whe);gBo=r($4t,"mvp"),$4t.forEach(t),hBo=r(MSe," \u2014 "),YO=n(MSe,"A",{href:!0});var k4t=s(YO);pBo=r(k4t,"MvpForConditionalGeneration"),k4t.forEach(t),_Bo=r(MSe," (MVP model)"),MSe.forEach(t),uBo=i(H),K1=n(H,"LI",{});var ESe=s(K1);Ahe=n(ESe,"STRONG",{});var S4t=s(Ahe);bBo=r(S4t,"nezha"),S4t.forEach(t),vBo=r(ESe," \u2014 "),KO=n(ESe,"A",{href:!0});var R4t=s(KO);FBo=r(R4t,"NezhaForMaskedLM"),R4t.forEach(t),TBo=r(ESe," (Nezha model)"),ESe.forEach(t),MBo=i(H),Z1=n(H,"LI",{});var CSe=s(Z1);Lhe=n(CSe,"STRONG",{});var P4t=s(Lhe);EBo=r(P4t,"nystromformer"),P4t.forEach(t),CBo=r(CSe," \u2014 "),ZO=n(CSe,"A",{href:!0});var B4t=s(ZO);wBo=r(B4t,"NystromformerForMaskedLM"),B4t.forEach(t),ABo=r(CSe," (Nystr\xF6mformer model)"),CSe.forEach(t),LBo=i(H),e7=n(H,"LI",{});var wSe=s(e7);yhe=n(wSe,"STRONG",{});var N4t=s(yhe);yBo=r(N4t,"perceiver"),N4t.forEach(t),xBo=r(wSe," \u2014 "),eV=n(wSe,"A",{href:!0});var I4t=s(eV);$Bo=r(I4t,"PerceiverForMaskedLM"),I4t.forEach(t),kBo=r(wSe," (Perceiver model)"),wSe.forEach(t),SBo=i(H),o7=n(H,"LI",{});var ASe=s(o7);xhe=n(ASe,"STRONG",{});var q4t=s(xhe);RBo=r(q4t,"qdqbert"),q4t.forEach(t),PBo=r(ASe," \u2014 "),oV=n(ASe,"A",{href:!0});var j4t=s(oV);BBo=r(j4t,"QDQBertForMaskedLM"),j4t.forEach(t),NBo=r(ASe," (QDQBert model)"),ASe.forEach(t),IBo=i(H),r7=n(H,"LI",{});var LSe=s(r7);$he=n(LSe,"STRONG",{});var D4t=s($he);qBo=r(D4t,"reformer"),D4t.forEach(t),jBo=r(LSe," \u2014 "),rV=n(LSe,"A",{href:!0});var G4t=s(rV);DBo=r(G4t,"ReformerForMaskedLM"),G4t.forEach(t),GBo=r(LSe," (Reformer model)"),LSe.forEach(t),OBo=i(H),t7=n(H,"LI",{});var ySe=s(t7);khe=n(ySe,"STRONG",{});var O4t=s(khe);VBo=r(O4t,"rembert"),O4t.forEach(t),XBo=r(ySe," \u2014 "),tV=n(ySe,"A",{href:!0});var V4t=s(tV);zBo=r(V4t,"RemBertForMaskedLM"),V4t.forEach(t),QBo=r(ySe," (RemBERT model)"),ySe.forEach(t),WBo=i(H),a7=n(H,"LI",{});var xSe=s(a7);She=n(xSe,"STRONG",{});var X4t=s(She);HBo=r(X4t,"roberta"),X4t.forEach(t),UBo=r(xSe," \u2014 "),aV=n(xSe,"A",{href:!0});var z4t=s(aV);JBo=r(z4t,"RobertaForMaskedLM"),z4t.forEach(t),YBo=r(xSe," (RoBERTa model)"),xSe.forEach(t),KBo=i(H),n7=n(H,"LI",{});var $Se=s(n7);Rhe=n($Se,"STRONG",{});var Q4t=s(Rhe);ZBo=r(Q4t,"roformer"),Q4t.forEach(t),eNo=r($Se," \u2014 "),nV=n($Se,"A",{href:!0});var W4t=s(nV);oNo=r(W4t,"RoFormerForMaskedLM"),W4t.forEach(t),rNo=r($Se," (RoFormer model)"),$Se.forEach(t),tNo=i(H),s7=n(H,"LI",{});var kSe=s(s7);Phe=n(kSe,"STRONG",{});var H4t=s(Phe);aNo=r(H4t,"squeezebert"),H4t.forEach(t),nNo=r(kSe," \u2014 "),sV=n(kSe,"A",{href:!0});var U4t=s(sV);sNo=r(U4t,"SqueezeBertForMaskedLM"),U4t.forEach(t),lNo=r(kSe," (SqueezeBERT model)"),kSe.forEach(t),iNo=i(H),l7=n(H,"LI",{});var SSe=s(l7);Bhe=n(SSe,"STRONG",{});var J4t=s(Bhe);dNo=r(J4t,"tapas"),J4t.forEach(t),cNo=r(SSe," \u2014 "),lV=n(SSe,"A",{href:!0});var Y4t=s(lV);fNo=r(Y4t,"TapasForMaskedLM"),Y4t.forEach(t),mNo=r(SSe," (TAPAS model)"),SSe.forEach(t),gNo=i(H),i7=n(H,"LI",{});var RSe=s(i7);Nhe=n(RSe,"STRONG",{});var K4t=s(Nhe);hNo=r(K4t,"wav2vec2"),K4t.forEach(t),pNo=r(RSe," \u2014 "),Ihe=n(RSe,"CODE",{});var Z4t=s(Ihe);_No=r(Z4t,"Wav2Vec2ForMaskedLM"),Z4t.forEach(t),uNo=r(RSe," (Wav2Vec2 model)"),RSe.forEach(t),bNo=i(H),d7=n(H,"LI",{});var PSe=s(d7);qhe=n(PSe,"STRONG",{});var ebt=s(qhe);vNo=r(ebt,"xlm"),ebt.forEach(t),FNo=r(PSe," \u2014 "),iV=n(PSe,"A",{href:!0});var obt=s(iV);TNo=r(obt,"XLMWithLMHeadModel"),obt.forEach(t),MNo=r(PSe," (XLM model)"),PSe.forEach(t),ENo=i(H),c7=n(H,"LI",{});var BSe=s(c7);jhe=n(BSe,"STRONG",{});var rbt=s(jhe);CNo=r(rbt,"xlm-roberta"),rbt.forEach(t),wNo=r(BSe," \u2014 "),dV=n(BSe,"A",{href:!0});var tbt=s(dV);ANo=r(tbt,"XLMRobertaForMaskedLM"),tbt.forEach(t),LNo=r(BSe," (XLM-RoBERTa model)"),BSe.forEach(t),yNo=i(H),f7=n(H,"LI",{});var NSe=s(f7);Dhe=n(NSe,"STRONG",{});var abt=s(Dhe);xNo=r(abt,"xlm-roberta-xl"),abt.forEach(t),$No=r(NSe," \u2014 "),cV=n(NSe,"A",{href:!0});var nbt=s(cV);kNo=r(nbt,"XLMRobertaXLForMaskedLM"),nbt.forEach(t),SNo=r(NSe," (XLM-RoBERTa-XL model)"),NSe.forEach(t),RNo=i(H),m7=n(H,"LI",{});var ISe=s(m7);Ghe=n(ISe,"STRONG",{});var sbt=s(Ghe);PNo=r(sbt,"yoso"),sbt.forEach(t),BNo=r(ISe," \u2014 "),fV=n(ISe,"A",{href:!0});var lbt=s(fV);NNo=r(lbt,"YosoForMaskedLM"),lbt.forEach(t),INo=r(ISe," (YOSO model)"),ISe.forEach(t),H.forEach(t),qNo=i(ia),g7=n(ia,"P",{});var qSe=s(g7);jNo=r(qSe,"The model is set in evaluation mode by default using "),Ohe=n(qSe,"CODE",{});var ibt=s(Ohe);DNo=r(ibt,"model.eval()"),ibt.forEach(t),GNo=r(qSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Vhe=n(qSe,"CODE",{});var dbt=s(Vhe);ONo=r(dbt,"model.train()"),dbt.forEach(t),qSe.forEach(t),VNo=i(ia),T(h7.$$.fragment,ia),ia.forEach(t),al.forEach(t),VVe=i(f),Yi=n(f,"H2",{class:!0});var Uze=s(Yi);p7=n(Uze,"A",{id:!0,class:!0,href:!0});var cbt=s(p7);Xhe=n(cbt,"SPAN",{});var fbt=s(Xhe);T(Vy.$$.fragment,fbt),fbt.forEach(t),cbt.forEach(t),XNo=i(Uze),zhe=n(Uze,"SPAN",{});var mbt=s(zhe);zNo=r(mbt,"AutoModelForSeq2SeqLM"),mbt.forEach(t),Uze.forEach(t),XVe=i(f),Ro=n(f,"DIV",{class:!0});var nl=s(Ro);T(Xy.$$.fragment,nl),QNo=i(nl),Ki=n(nl,"P",{});var Ere=s(Ki);WNo=r(Ere,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),mV=n(Ere,"A",{href:!0});var gbt=s(mV);HNo=r(gbt,"from_pretrained()"),gbt.forEach(t),UNo=r(Ere," class method or the "),gV=n(Ere,"A",{href:!0});var hbt=s(gV);JNo=r(hbt,"from_config()"),hbt.forEach(t),YNo=r(Ere,` class
method.`),Ere.forEach(t),KNo=i(nl),zy=n(nl,"P",{});var Jze=s(zy);ZNo=r(Jze,"This class cannot be instantiated directly using "),Qhe=n(Jze,"CODE",{});var pbt=s(Qhe);eIo=r(pbt,"__init__()"),pbt.forEach(t),oIo=r(Jze," (throws an error)."),Jze.forEach(t),rIo=i(nl),ct=n(nl,"DIV",{class:!0});var i6=s(ct);T(Qy.$$.fragment,i6),tIo=i(i6),Whe=n(i6,"P",{});var _bt=s(Whe);aIo=r(_bt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_bt.forEach(t),nIo=i(i6),Zi=n(i6,"P",{});var Cre=s(Zi);sIo=r(Cre,`Note:
Loading a model from its configuration file does `),Hhe=n(Cre,"STRONG",{});var ubt=s(Hhe);lIo=r(ubt,"not"),ubt.forEach(t),iIo=r(Cre,` load the model weights. It only affects the
model\u2019s configuration. Use `),hV=n(Cre,"A",{href:!0});var bbt=s(hV);dIo=r(bbt,"from_pretrained()"),bbt.forEach(t),cIo=r(Cre," to load the model weights."),Cre.forEach(t),fIo=i(i6),T(_7.$$.fragment,i6),i6.forEach(t),mIo=i(nl),eo=n(nl,"DIV",{class:!0});var da=s(eo);T(Wy.$$.fragment,da),gIo=i(da),Uhe=n(da,"P",{});var vbt=s(Uhe);hIo=r(vbt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),vbt.forEach(t),pIo=i(da),ja=n(da,"P",{});var d6=s(ja);_Io=r(d6,"The model class to instantiate is selected based on the "),Jhe=n(d6,"CODE",{});var Fbt=s(Jhe);uIo=r(Fbt,"model_type"),Fbt.forEach(t),bIo=r(d6,` property of the config object (either
passed as an argument or loaded from `),Yhe=n(d6,"CODE",{});var Tbt=s(Yhe);vIo=r(Tbt,"pretrained_model_name_or_path"),Tbt.forEach(t),FIo=r(d6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Khe=n(d6,"CODE",{});var Mbt=s(Khe);TIo=r(Mbt,"pretrained_model_name_or_path"),Mbt.forEach(t),MIo=r(d6,":"),d6.forEach(t),EIo=i(da),pe=n(da,"UL",{});var be=s(pe);u7=n(be,"LI",{});var jSe=s(u7);Zhe=n(jSe,"STRONG",{});var Ebt=s(Zhe);CIo=r(Ebt,"bart"),Ebt.forEach(t),wIo=r(jSe," \u2014 "),pV=n(jSe,"A",{href:!0});var Cbt=s(pV);AIo=r(Cbt,"BartForConditionalGeneration"),Cbt.forEach(t),LIo=r(jSe," (BART model)"),jSe.forEach(t),yIo=i(be),b7=n(be,"LI",{});var DSe=s(b7);epe=n(DSe,"STRONG",{});var wbt=s(epe);xIo=r(wbt,"bigbird_pegasus"),wbt.forEach(t),$Io=r(DSe," \u2014 "),_V=n(DSe,"A",{href:!0});var Abt=s(_V);kIo=r(Abt,"BigBirdPegasusForConditionalGeneration"),Abt.forEach(t),SIo=r(DSe," (BigBird-Pegasus model)"),DSe.forEach(t),RIo=i(be),v7=n(be,"LI",{});var GSe=s(v7);ope=n(GSe,"STRONG",{});var Lbt=s(ope);PIo=r(Lbt,"blenderbot"),Lbt.forEach(t),BIo=r(GSe," \u2014 "),uV=n(GSe,"A",{href:!0});var ybt=s(uV);NIo=r(ybt,"BlenderbotForConditionalGeneration"),ybt.forEach(t),IIo=r(GSe," (Blenderbot model)"),GSe.forEach(t),qIo=i(be),F7=n(be,"LI",{});var OSe=s(F7);rpe=n(OSe,"STRONG",{});var xbt=s(rpe);jIo=r(xbt,"blenderbot-small"),xbt.forEach(t),DIo=r(OSe," \u2014 "),bV=n(OSe,"A",{href:!0});var $bt=s(bV);GIo=r($bt,"BlenderbotSmallForConditionalGeneration"),$bt.forEach(t),OIo=r(OSe," (BlenderbotSmall model)"),OSe.forEach(t),VIo=i(be),T7=n(be,"LI",{});var VSe=s(T7);tpe=n(VSe,"STRONG",{});var kbt=s(tpe);XIo=r(kbt,"encoder-decoder"),kbt.forEach(t),zIo=r(VSe," \u2014 "),vV=n(VSe,"A",{href:!0});var Sbt=s(vV);QIo=r(Sbt,"EncoderDecoderModel"),Sbt.forEach(t),WIo=r(VSe," (Encoder decoder model)"),VSe.forEach(t),HIo=i(be),M7=n(be,"LI",{});var XSe=s(M7);ape=n(XSe,"STRONG",{});var Rbt=s(ape);UIo=r(Rbt,"fsmt"),Rbt.forEach(t),JIo=r(XSe," \u2014 "),FV=n(XSe,"A",{href:!0});var Pbt=s(FV);YIo=r(Pbt,"FSMTForConditionalGeneration"),Pbt.forEach(t),KIo=r(XSe," (FairSeq Machine-Translation model)"),XSe.forEach(t),ZIo=i(be),E7=n(be,"LI",{});var zSe=s(E7);npe=n(zSe,"STRONG",{});var Bbt=s(npe);eqo=r(Bbt,"led"),Bbt.forEach(t),oqo=r(zSe," \u2014 "),TV=n(zSe,"A",{href:!0});var Nbt=s(TV);rqo=r(Nbt,"LEDForConditionalGeneration"),Nbt.forEach(t),tqo=r(zSe," (LED model)"),zSe.forEach(t),aqo=i(be),C7=n(be,"LI",{});var QSe=s(C7);spe=n(QSe,"STRONG",{});var Ibt=s(spe);nqo=r(Ibt,"longt5"),Ibt.forEach(t),sqo=r(QSe," \u2014 "),MV=n(QSe,"A",{href:!0});var qbt=s(MV);lqo=r(qbt,"LongT5ForConditionalGeneration"),qbt.forEach(t),iqo=r(QSe," (LongT5 model)"),QSe.forEach(t),dqo=i(be),w7=n(be,"LI",{});var WSe=s(w7);lpe=n(WSe,"STRONG",{});var jbt=s(lpe);cqo=r(jbt,"m2m_100"),jbt.forEach(t),fqo=r(WSe," \u2014 "),EV=n(WSe,"A",{href:!0});var Dbt=s(EV);mqo=r(Dbt,"M2M100ForConditionalGeneration"),Dbt.forEach(t),gqo=r(WSe," (M2M100 model)"),WSe.forEach(t),hqo=i(be),A7=n(be,"LI",{});var HSe=s(A7);ipe=n(HSe,"STRONG",{});var Gbt=s(ipe);pqo=r(Gbt,"marian"),Gbt.forEach(t),_qo=r(HSe," \u2014 "),CV=n(HSe,"A",{href:!0});var Obt=s(CV);uqo=r(Obt,"MarianMTModel"),Obt.forEach(t),bqo=r(HSe," (Marian model)"),HSe.forEach(t),vqo=i(be),L7=n(be,"LI",{});var USe=s(L7);dpe=n(USe,"STRONG",{});var Vbt=s(dpe);Fqo=r(Vbt,"mbart"),Vbt.forEach(t),Tqo=r(USe," \u2014 "),wV=n(USe,"A",{href:!0});var Xbt=s(wV);Mqo=r(Xbt,"MBartForConditionalGeneration"),Xbt.forEach(t),Eqo=r(USe," (mBART model)"),USe.forEach(t),Cqo=i(be),y7=n(be,"LI",{});var JSe=s(y7);cpe=n(JSe,"STRONG",{});var zbt=s(cpe);wqo=r(zbt,"mt5"),zbt.forEach(t),Aqo=r(JSe," \u2014 "),AV=n(JSe,"A",{href:!0});var Qbt=s(AV);Lqo=r(Qbt,"MT5ForConditionalGeneration"),Qbt.forEach(t),yqo=r(JSe," (MT5 model)"),JSe.forEach(t),xqo=i(be),x7=n(be,"LI",{});var YSe=s(x7);fpe=n(YSe,"STRONG",{});var Wbt=s(fpe);$qo=r(Wbt,"mvp"),Wbt.forEach(t),kqo=r(YSe," \u2014 "),LV=n(YSe,"A",{href:!0});var Hbt=s(LV);Sqo=r(Hbt,"MvpForConditionalGeneration"),Hbt.forEach(t),Rqo=r(YSe," (MVP model)"),YSe.forEach(t),Pqo=i(be),$7=n(be,"LI",{});var KSe=s($7);mpe=n(KSe,"STRONG",{});var Ubt=s(mpe);Bqo=r(Ubt,"pegasus"),Ubt.forEach(t),Nqo=r(KSe," \u2014 "),yV=n(KSe,"A",{href:!0});var Jbt=s(yV);Iqo=r(Jbt,"PegasusForConditionalGeneration"),Jbt.forEach(t),qqo=r(KSe," (Pegasus model)"),KSe.forEach(t),jqo=i(be),k7=n(be,"LI",{});var ZSe=s(k7);gpe=n(ZSe,"STRONG",{});var Ybt=s(gpe);Dqo=r(Ybt,"plbart"),Ybt.forEach(t),Gqo=r(ZSe," \u2014 "),xV=n(ZSe,"A",{href:!0});var Kbt=s(xV);Oqo=r(Kbt,"PLBartForConditionalGeneration"),Kbt.forEach(t),Vqo=r(ZSe," (PLBart model)"),ZSe.forEach(t),Xqo=i(be),S7=n(be,"LI",{});var eRe=s(S7);hpe=n(eRe,"STRONG",{});var Zbt=s(hpe);zqo=r(Zbt,"prophetnet"),Zbt.forEach(t),Qqo=r(eRe," \u2014 "),$V=n(eRe,"A",{href:!0});var evt=s($V);Wqo=r(evt,"ProphetNetForConditionalGeneration"),evt.forEach(t),Hqo=r(eRe," (ProphetNet model)"),eRe.forEach(t),Uqo=i(be),R7=n(be,"LI",{});var oRe=s(R7);ppe=n(oRe,"STRONG",{});var ovt=s(ppe);Jqo=r(ovt,"t5"),ovt.forEach(t),Yqo=r(oRe," \u2014 "),kV=n(oRe,"A",{href:!0});var rvt=s(kV);Kqo=r(rvt,"T5ForConditionalGeneration"),rvt.forEach(t),Zqo=r(oRe," (T5 model)"),oRe.forEach(t),ejo=i(be),P7=n(be,"LI",{});var rRe=s(P7);_pe=n(rRe,"STRONG",{});var tvt=s(_pe);ojo=r(tvt,"xlm-prophetnet"),tvt.forEach(t),rjo=r(rRe," \u2014 "),SV=n(rRe,"A",{href:!0});var avt=s(SV);tjo=r(avt,"XLMProphetNetForConditionalGeneration"),avt.forEach(t),ajo=r(rRe," (XLM-ProphetNet model)"),rRe.forEach(t),be.forEach(t),njo=i(da),B7=n(da,"P",{});var tRe=s(B7);sjo=r(tRe,"The model is set in evaluation mode by default using "),upe=n(tRe,"CODE",{});var nvt=s(upe);ljo=r(nvt,"model.eval()"),nvt.forEach(t),ijo=r(tRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bpe=n(tRe,"CODE",{});var svt=s(bpe);djo=r(svt,"model.train()"),svt.forEach(t),tRe.forEach(t),cjo=i(da),T(N7.$$.fragment,da),da.forEach(t),nl.forEach(t),zVe=i(f),ed=n(f,"H2",{class:!0});var Yze=s(ed);I7=n(Yze,"A",{id:!0,class:!0,href:!0});var lvt=s(I7);vpe=n(lvt,"SPAN",{});var ivt=s(vpe);T(Hy.$$.fragment,ivt),ivt.forEach(t),lvt.forEach(t),fjo=i(Yze),Fpe=n(Yze,"SPAN",{});var dvt=s(Fpe);mjo=r(dvt,"AutoModelForSequenceClassification"),dvt.forEach(t),Yze.forEach(t),QVe=i(f),Po=n(f,"DIV",{class:!0});var sl=s(Po);T(Uy.$$.fragment,sl),gjo=i(sl),od=n(sl,"P",{});var wre=s(od);hjo=r(wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),RV=n(wre,"A",{href:!0});var cvt=s(RV);pjo=r(cvt,"from_pretrained()"),cvt.forEach(t),_jo=r(wre," class method or the "),PV=n(wre,"A",{href:!0});var fvt=s(PV);ujo=r(fvt,"from_config()"),fvt.forEach(t),bjo=r(wre,` class
method.`),wre.forEach(t),vjo=i(sl),Jy=n(sl,"P",{});var Kze=s(Jy);Fjo=r(Kze,"This class cannot be instantiated directly using "),Tpe=n(Kze,"CODE",{});var mvt=s(Tpe);Tjo=r(mvt,"__init__()"),mvt.forEach(t),Mjo=r(Kze," (throws an error)."),Kze.forEach(t),Ejo=i(sl),ft=n(sl,"DIV",{class:!0});var c6=s(ft);T(Yy.$$.fragment,c6),Cjo=i(c6),Mpe=n(c6,"P",{});var gvt=s(Mpe);wjo=r(gvt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),gvt.forEach(t),Ajo=i(c6),rd=n(c6,"P",{});var Are=s(rd);Ljo=r(Are,`Note:
Loading a model from its configuration file does `),Epe=n(Are,"STRONG",{});var hvt=s(Epe);yjo=r(hvt,"not"),hvt.forEach(t),xjo=r(Are,` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=n(Are,"A",{href:!0});var pvt=s(BV);$jo=r(pvt,"from_pretrained()"),pvt.forEach(t),kjo=r(Are," to load the model weights."),Are.forEach(t),Sjo=i(c6),T(q7.$$.fragment,c6),c6.forEach(t),Rjo=i(sl),oo=n(sl,"DIV",{class:!0});var ca=s(oo);T(Ky.$$.fragment,ca),Pjo=i(ca),Cpe=n(ca,"P",{});var _vt=s(Cpe);Bjo=r(_vt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_vt.forEach(t),Njo=i(ca),Da=n(ca,"P",{});var f6=s(Da);Ijo=r(f6,"The model class to instantiate is selected based on the "),wpe=n(f6,"CODE",{});var uvt=s(wpe);qjo=r(uvt,"model_type"),uvt.forEach(t),jjo=r(f6,` property of the config object (either
passed as an argument or loaded from `),Ape=n(f6,"CODE",{});var bvt=s(Ape);Djo=r(bvt,"pretrained_model_name_or_path"),bvt.forEach(t),Gjo=r(f6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lpe=n(f6,"CODE",{});var vvt=s(Lpe);Ojo=r(vvt,"pretrained_model_name_or_path"),vvt.forEach(t),Vjo=r(f6,":"),f6.forEach(t),Xjo=i(ca),I=n(ca,"UL",{});var j=s(I);j7=n(j,"LI",{});var aRe=s(j7);ype=n(aRe,"STRONG",{});var Fvt=s(ype);zjo=r(Fvt,"albert"),Fvt.forEach(t),Qjo=r(aRe," \u2014 "),NV=n(aRe,"A",{href:!0});var Tvt=s(NV);Wjo=r(Tvt,"AlbertForSequenceClassification"),Tvt.forEach(t),Hjo=r(aRe," (ALBERT model)"),aRe.forEach(t),Ujo=i(j),D7=n(j,"LI",{});var nRe=s(D7);xpe=n(nRe,"STRONG",{});var Mvt=s(xpe);Jjo=r(Mvt,"bart"),Mvt.forEach(t),Yjo=r(nRe," \u2014 "),IV=n(nRe,"A",{href:!0});var Evt=s(IV);Kjo=r(Evt,"BartForSequenceClassification"),Evt.forEach(t),Zjo=r(nRe," (BART model)"),nRe.forEach(t),eDo=i(j),G7=n(j,"LI",{});var sRe=s(G7);$pe=n(sRe,"STRONG",{});var Cvt=s($pe);oDo=r(Cvt,"bert"),Cvt.forEach(t),rDo=r(sRe," \u2014 "),qV=n(sRe,"A",{href:!0});var wvt=s(qV);tDo=r(wvt,"BertForSequenceClassification"),wvt.forEach(t),aDo=r(sRe," (BERT model)"),sRe.forEach(t),nDo=i(j),O7=n(j,"LI",{});var lRe=s(O7);kpe=n(lRe,"STRONG",{});var Avt=s(kpe);sDo=r(Avt,"big_bird"),Avt.forEach(t),lDo=r(lRe," \u2014 "),jV=n(lRe,"A",{href:!0});var Lvt=s(jV);iDo=r(Lvt,"BigBirdForSequenceClassification"),Lvt.forEach(t),dDo=r(lRe," (BigBird model)"),lRe.forEach(t),cDo=i(j),V7=n(j,"LI",{});var iRe=s(V7);Spe=n(iRe,"STRONG",{});var yvt=s(Spe);fDo=r(yvt,"bigbird_pegasus"),yvt.forEach(t),mDo=r(iRe," \u2014 "),DV=n(iRe,"A",{href:!0});var xvt=s(DV);gDo=r(xvt,"BigBirdPegasusForSequenceClassification"),xvt.forEach(t),hDo=r(iRe," (BigBird-Pegasus model)"),iRe.forEach(t),pDo=i(j),X7=n(j,"LI",{});var dRe=s(X7);Rpe=n(dRe,"STRONG",{});var $vt=s(Rpe);_Do=r($vt,"bloom"),$vt.forEach(t),uDo=r(dRe," \u2014 "),GV=n(dRe,"A",{href:!0});var kvt=s(GV);bDo=r(kvt,"BloomForSequenceClassification"),kvt.forEach(t),vDo=r(dRe," (BLOOM model)"),dRe.forEach(t),FDo=i(j),z7=n(j,"LI",{});var cRe=s(z7);Ppe=n(cRe,"STRONG",{});var Svt=s(Ppe);TDo=r(Svt,"camembert"),Svt.forEach(t),MDo=r(cRe," \u2014 "),OV=n(cRe,"A",{href:!0});var Rvt=s(OV);EDo=r(Rvt,"CamembertForSequenceClassification"),Rvt.forEach(t),CDo=r(cRe," (CamemBERT model)"),cRe.forEach(t),wDo=i(j),Q7=n(j,"LI",{});var fRe=s(Q7);Bpe=n(fRe,"STRONG",{});var Pvt=s(Bpe);ADo=r(Pvt,"canine"),Pvt.forEach(t),LDo=r(fRe," \u2014 "),VV=n(fRe,"A",{href:!0});var Bvt=s(VV);yDo=r(Bvt,"CanineForSequenceClassification"),Bvt.forEach(t),xDo=r(fRe," (CANINE model)"),fRe.forEach(t),$Do=i(j),W7=n(j,"LI",{});var mRe=s(W7);Npe=n(mRe,"STRONG",{});var Nvt=s(Npe);kDo=r(Nvt,"convbert"),Nvt.forEach(t),SDo=r(mRe," \u2014 "),XV=n(mRe,"A",{href:!0});var Ivt=s(XV);RDo=r(Ivt,"ConvBertForSequenceClassification"),Ivt.forEach(t),PDo=r(mRe," (ConvBERT model)"),mRe.forEach(t),BDo=i(j),H7=n(j,"LI",{});var gRe=s(H7);Ipe=n(gRe,"STRONG",{});var qvt=s(Ipe);NDo=r(qvt,"ctrl"),qvt.forEach(t),IDo=r(gRe," \u2014 "),zV=n(gRe,"A",{href:!0});var jvt=s(zV);qDo=r(jvt,"CTRLForSequenceClassification"),jvt.forEach(t),jDo=r(gRe," (CTRL model)"),gRe.forEach(t),DDo=i(j),U7=n(j,"LI",{});var hRe=s(U7);qpe=n(hRe,"STRONG",{});var Dvt=s(qpe);GDo=r(Dvt,"data2vec-text"),Dvt.forEach(t),ODo=r(hRe," \u2014 "),QV=n(hRe,"A",{href:!0});var Gvt=s(QV);VDo=r(Gvt,"Data2VecTextForSequenceClassification"),Gvt.forEach(t),XDo=r(hRe," (Data2VecText model)"),hRe.forEach(t),zDo=i(j),J7=n(j,"LI",{});var pRe=s(J7);jpe=n(pRe,"STRONG",{});var Ovt=s(jpe);QDo=r(Ovt,"deberta"),Ovt.forEach(t),WDo=r(pRe," \u2014 "),WV=n(pRe,"A",{href:!0});var Vvt=s(WV);HDo=r(Vvt,"DebertaForSequenceClassification"),Vvt.forEach(t),UDo=r(pRe," (DeBERTa model)"),pRe.forEach(t),JDo=i(j),Y7=n(j,"LI",{});var _Re=s(Y7);Dpe=n(_Re,"STRONG",{});var Xvt=s(Dpe);YDo=r(Xvt,"deberta-v2"),Xvt.forEach(t),KDo=r(_Re," \u2014 "),HV=n(_Re,"A",{href:!0});var zvt=s(HV);ZDo=r(zvt,"DebertaV2ForSequenceClassification"),zvt.forEach(t),eGo=r(_Re," (DeBERTa-v2 model)"),_Re.forEach(t),oGo=i(j),K7=n(j,"LI",{});var uRe=s(K7);Gpe=n(uRe,"STRONG",{});var Qvt=s(Gpe);rGo=r(Qvt,"distilbert"),Qvt.forEach(t),tGo=r(uRe," \u2014 "),UV=n(uRe,"A",{href:!0});var Wvt=s(UV);aGo=r(Wvt,"DistilBertForSequenceClassification"),Wvt.forEach(t),nGo=r(uRe," (DistilBERT model)"),uRe.forEach(t),sGo=i(j),Z7=n(j,"LI",{});var bRe=s(Z7);Ope=n(bRe,"STRONG",{});var Hvt=s(Ope);lGo=r(Hvt,"electra"),Hvt.forEach(t),iGo=r(bRe," \u2014 "),JV=n(bRe,"A",{href:!0});var Uvt=s(JV);dGo=r(Uvt,"ElectraForSequenceClassification"),Uvt.forEach(t),cGo=r(bRe," (ELECTRA model)"),bRe.forEach(t),fGo=i(j),e4=n(j,"LI",{});var vRe=s(e4);Vpe=n(vRe,"STRONG",{});var Jvt=s(Vpe);mGo=r(Jvt,"flaubert"),Jvt.forEach(t),gGo=r(vRe," \u2014 "),YV=n(vRe,"A",{href:!0});var Yvt=s(YV);hGo=r(Yvt,"FlaubertForSequenceClassification"),Yvt.forEach(t),pGo=r(vRe," (FlauBERT model)"),vRe.forEach(t),_Go=i(j),o4=n(j,"LI",{});var FRe=s(o4);Xpe=n(FRe,"STRONG",{});var Kvt=s(Xpe);uGo=r(Kvt,"fnet"),Kvt.forEach(t),bGo=r(FRe," \u2014 "),KV=n(FRe,"A",{href:!0});var Zvt=s(KV);vGo=r(Zvt,"FNetForSequenceClassification"),Zvt.forEach(t),FGo=r(FRe," (FNet model)"),FRe.forEach(t),TGo=i(j),r4=n(j,"LI",{});var TRe=s(r4);zpe=n(TRe,"STRONG",{});var eFt=s(zpe);MGo=r(eFt,"funnel"),eFt.forEach(t),EGo=r(TRe," \u2014 "),ZV=n(TRe,"A",{href:!0});var oFt=s(ZV);CGo=r(oFt,"FunnelForSequenceClassification"),oFt.forEach(t),wGo=r(TRe," (Funnel Transformer model)"),TRe.forEach(t),AGo=i(j),t4=n(j,"LI",{});var MRe=s(t4);Qpe=n(MRe,"STRONG",{});var rFt=s(Qpe);LGo=r(rFt,"gpt2"),rFt.forEach(t),yGo=r(MRe," \u2014 "),eX=n(MRe,"A",{href:!0});var tFt=s(eX);xGo=r(tFt,"GPT2ForSequenceClassification"),tFt.forEach(t),$Go=r(MRe," (OpenAI GPT-2 model)"),MRe.forEach(t),kGo=i(j),a4=n(j,"LI",{});var ERe=s(a4);Wpe=n(ERe,"STRONG",{});var aFt=s(Wpe);SGo=r(aFt,"gpt_neo"),aFt.forEach(t),RGo=r(ERe," \u2014 "),oX=n(ERe,"A",{href:!0});var nFt=s(oX);PGo=r(nFt,"GPTNeoForSequenceClassification"),nFt.forEach(t),BGo=r(ERe," (GPT Neo model)"),ERe.forEach(t),NGo=i(j),n4=n(j,"LI",{});var CRe=s(n4);Hpe=n(CRe,"STRONG",{});var sFt=s(Hpe);IGo=r(sFt,"gptj"),sFt.forEach(t),qGo=r(CRe," \u2014 "),rX=n(CRe,"A",{href:!0});var lFt=s(rX);jGo=r(lFt,"GPTJForSequenceClassification"),lFt.forEach(t),DGo=r(CRe," (GPT-J model)"),CRe.forEach(t),GGo=i(j),s4=n(j,"LI",{});var wRe=s(s4);Upe=n(wRe,"STRONG",{});var iFt=s(Upe);OGo=r(iFt,"ibert"),iFt.forEach(t),VGo=r(wRe," \u2014 "),tX=n(wRe,"A",{href:!0});var dFt=s(tX);XGo=r(dFt,"IBertForSequenceClassification"),dFt.forEach(t),zGo=r(wRe," (I-BERT model)"),wRe.forEach(t),QGo=i(j),l4=n(j,"LI",{});var ARe=s(l4);Jpe=n(ARe,"STRONG",{});var cFt=s(Jpe);WGo=r(cFt,"layoutlm"),cFt.forEach(t),HGo=r(ARe," \u2014 "),aX=n(ARe,"A",{href:!0});var fFt=s(aX);UGo=r(fFt,"LayoutLMForSequenceClassification"),fFt.forEach(t),JGo=r(ARe," (LayoutLM model)"),ARe.forEach(t),YGo=i(j),i4=n(j,"LI",{});var LRe=s(i4);Ype=n(LRe,"STRONG",{});var mFt=s(Ype);KGo=r(mFt,"layoutlmv2"),mFt.forEach(t),ZGo=r(LRe," \u2014 "),nX=n(LRe,"A",{href:!0});var gFt=s(nX);eOo=r(gFt,"LayoutLMv2ForSequenceClassification"),gFt.forEach(t),oOo=r(LRe," (LayoutLMv2 model)"),LRe.forEach(t),rOo=i(j),d4=n(j,"LI",{});var yRe=s(d4);Kpe=n(yRe,"STRONG",{});var hFt=s(Kpe);tOo=r(hFt,"layoutlmv3"),hFt.forEach(t),aOo=r(yRe," \u2014 "),sX=n(yRe,"A",{href:!0});var pFt=s(sX);nOo=r(pFt,"LayoutLMv3ForSequenceClassification"),pFt.forEach(t),sOo=r(yRe," (LayoutLMv3 model)"),yRe.forEach(t),lOo=i(j),c4=n(j,"LI",{});var xRe=s(c4);Zpe=n(xRe,"STRONG",{});var _Ft=s(Zpe);iOo=r(_Ft,"led"),_Ft.forEach(t),dOo=r(xRe," \u2014 "),lX=n(xRe,"A",{href:!0});var uFt=s(lX);cOo=r(uFt,"LEDForSequenceClassification"),uFt.forEach(t),fOo=r(xRe," (LED model)"),xRe.forEach(t),mOo=i(j),f4=n(j,"LI",{});var $Re=s(f4);e_e=n($Re,"STRONG",{});var bFt=s(e_e);gOo=r(bFt,"longformer"),bFt.forEach(t),hOo=r($Re," \u2014 "),iX=n($Re,"A",{href:!0});var vFt=s(iX);pOo=r(vFt,"LongformerForSequenceClassification"),vFt.forEach(t),_Oo=r($Re," (Longformer model)"),$Re.forEach(t),uOo=i(j),m4=n(j,"LI",{});var kRe=s(m4);o_e=n(kRe,"STRONG",{});var FFt=s(o_e);bOo=r(FFt,"mbart"),FFt.forEach(t),vOo=r(kRe," \u2014 "),dX=n(kRe,"A",{href:!0});var TFt=s(dX);FOo=r(TFt,"MBartForSequenceClassification"),TFt.forEach(t),TOo=r(kRe," (mBART model)"),kRe.forEach(t),MOo=i(j),g4=n(j,"LI",{});var SRe=s(g4);r_e=n(SRe,"STRONG",{});var MFt=s(r_e);EOo=r(MFt,"megatron-bert"),MFt.forEach(t),COo=r(SRe," \u2014 "),cX=n(SRe,"A",{href:!0});var EFt=s(cX);wOo=r(EFt,"MegatronBertForSequenceClassification"),EFt.forEach(t),AOo=r(SRe," (Megatron-BERT model)"),SRe.forEach(t),LOo=i(j),h4=n(j,"LI",{});var RRe=s(h4);t_e=n(RRe,"STRONG",{});var CFt=s(t_e);yOo=r(CFt,"mobilebert"),CFt.forEach(t),xOo=r(RRe," \u2014 "),fX=n(RRe,"A",{href:!0});var wFt=s(fX);$Oo=r(wFt,"MobileBertForSequenceClassification"),wFt.forEach(t),kOo=r(RRe," (MobileBERT model)"),RRe.forEach(t),SOo=i(j),p4=n(j,"LI",{});var PRe=s(p4);a_e=n(PRe,"STRONG",{});var AFt=s(a_e);ROo=r(AFt,"mpnet"),AFt.forEach(t),POo=r(PRe," \u2014 "),mX=n(PRe,"A",{href:!0});var LFt=s(mX);BOo=r(LFt,"MPNetForSequenceClassification"),LFt.forEach(t),NOo=r(PRe," (MPNet model)"),PRe.forEach(t),IOo=i(j),_4=n(j,"LI",{});var BRe=s(_4);n_e=n(BRe,"STRONG",{});var yFt=s(n_e);qOo=r(yFt,"mvp"),yFt.forEach(t),jOo=r(BRe," \u2014 "),gX=n(BRe,"A",{href:!0});var xFt=s(gX);DOo=r(xFt,"MvpForSequenceClassification"),xFt.forEach(t),GOo=r(BRe," (MVP model)"),BRe.forEach(t),OOo=i(j),u4=n(j,"LI",{});var NRe=s(u4);s_e=n(NRe,"STRONG",{});var $Ft=s(s_e);VOo=r($Ft,"nezha"),$Ft.forEach(t),XOo=r(NRe," \u2014 "),hX=n(NRe,"A",{href:!0});var kFt=s(hX);zOo=r(kFt,"NezhaForSequenceClassification"),kFt.forEach(t),QOo=r(NRe," (Nezha model)"),NRe.forEach(t),WOo=i(j),b4=n(j,"LI",{});var IRe=s(b4);l_e=n(IRe,"STRONG",{});var SFt=s(l_e);HOo=r(SFt,"nystromformer"),SFt.forEach(t),UOo=r(IRe," \u2014 "),pX=n(IRe,"A",{href:!0});var RFt=s(pX);JOo=r(RFt,"NystromformerForSequenceClassification"),RFt.forEach(t),YOo=r(IRe," (Nystr\xF6mformer model)"),IRe.forEach(t),KOo=i(j),v4=n(j,"LI",{});var qRe=s(v4);i_e=n(qRe,"STRONG",{});var PFt=s(i_e);ZOo=r(PFt,"openai-gpt"),PFt.forEach(t),eVo=r(qRe," \u2014 "),_X=n(qRe,"A",{href:!0});var BFt=s(_X);oVo=r(BFt,"OpenAIGPTForSequenceClassification"),BFt.forEach(t),rVo=r(qRe," (OpenAI GPT model)"),qRe.forEach(t),tVo=i(j),F4=n(j,"LI",{});var jRe=s(F4);d_e=n(jRe,"STRONG",{});var NFt=s(d_e);aVo=r(NFt,"perceiver"),NFt.forEach(t),nVo=r(jRe," \u2014 "),uX=n(jRe,"A",{href:!0});var IFt=s(uX);sVo=r(IFt,"PerceiverForSequenceClassification"),IFt.forEach(t),lVo=r(jRe," (Perceiver model)"),jRe.forEach(t),iVo=i(j),T4=n(j,"LI",{});var DRe=s(T4);c_e=n(DRe,"STRONG",{});var qFt=s(c_e);dVo=r(qFt,"plbart"),qFt.forEach(t),cVo=r(DRe," \u2014 "),bX=n(DRe,"A",{href:!0});var jFt=s(bX);fVo=r(jFt,"PLBartForSequenceClassification"),jFt.forEach(t),mVo=r(DRe," (PLBart model)"),DRe.forEach(t),gVo=i(j),M4=n(j,"LI",{});var GRe=s(M4);f_e=n(GRe,"STRONG",{});var DFt=s(f_e);hVo=r(DFt,"qdqbert"),DFt.forEach(t),pVo=r(GRe," \u2014 "),vX=n(GRe,"A",{href:!0});var GFt=s(vX);_Vo=r(GFt,"QDQBertForSequenceClassification"),GFt.forEach(t),uVo=r(GRe," (QDQBert model)"),GRe.forEach(t),bVo=i(j),E4=n(j,"LI",{});var ORe=s(E4);m_e=n(ORe,"STRONG",{});var OFt=s(m_e);vVo=r(OFt,"reformer"),OFt.forEach(t),FVo=r(ORe," \u2014 "),FX=n(ORe,"A",{href:!0});var VFt=s(FX);TVo=r(VFt,"ReformerForSequenceClassification"),VFt.forEach(t),MVo=r(ORe," (Reformer model)"),ORe.forEach(t),EVo=i(j),C4=n(j,"LI",{});var VRe=s(C4);g_e=n(VRe,"STRONG",{});var XFt=s(g_e);CVo=r(XFt,"rembert"),XFt.forEach(t),wVo=r(VRe," \u2014 "),TX=n(VRe,"A",{href:!0});var zFt=s(TX);AVo=r(zFt,"RemBertForSequenceClassification"),zFt.forEach(t),LVo=r(VRe," (RemBERT model)"),VRe.forEach(t),yVo=i(j),w4=n(j,"LI",{});var XRe=s(w4);h_e=n(XRe,"STRONG",{});var QFt=s(h_e);xVo=r(QFt,"roberta"),QFt.forEach(t),$Vo=r(XRe," \u2014 "),MX=n(XRe,"A",{href:!0});var WFt=s(MX);kVo=r(WFt,"RobertaForSequenceClassification"),WFt.forEach(t),SVo=r(XRe," (RoBERTa model)"),XRe.forEach(t),RVo=i(j),A4=n(j,"LI",{});var zRe=s(A4);p_e=n(zRe,"STRONG",{});var HFt=s(p_e);PVo=r(HFt,"roformer"),HFt.forEach(t),BVo=r(zRe," \u2014 "),EX=n(zRe,"A",{href:!0});var UFt=s(EX);NVo=r(UFt,"RoFormerForSequenceClassification"),UFt.forEach(t),IVo=r(zRe," (RoFormer model)"),zRe.forEach(t),qVo=i(j),L4=n(j,"LI",{});var QRe=s(L4);__e=n(QRe,"STRONG",{});var JFt=s(__e);jVo=r(JFt,"squeezebert"),JFt.forEach(t),DVo=r(QRe," \u2014 "),CX=n(QRe,"A",{href:!0});var YFt=s(CX);GVo=r(YFt,"SqueezeBertForSequenceClassification"),YFt.forEach(t),OVo=r(QRe," (SqueezeBERT model)"),QRe.forEach(t),VVo=i(j),y4=n(j,"LI",{});var WRe=s(y4);u_e=n(WRe,"STRONG",{});var KFt=s(u_e);XVo=r(KFt,"tapas"),KFt.forEach(t),zVo=r(WRe," \u2014 "),wX=n(WRe,"A",{href:!0});var ZFt=s(wX);QVo=r(ZFt,"TapasForSequenceClassification"),ZFt.forEach(t),WVo=r(WRe," (TAPAS model)"),WRe.forEach(t),HVo=i(j),x4=n(j,"LI",{});var HRe=s(x4);b_e=n(HRe,"STRONG",{});var eTt=s(b_e);UVo=r(eTt,"transfo-xl"),eTt.forEach(t),JVo=r(HRe," \u2014 "),AX=n(HRe,"A",{href:!0});var oTt=s(AX);YVo=r(oTt,"TransfoXLForSequenceClassification"),oTt.forEach(t),KVo=r(HRe," (Transformer-XL model)"),HRe.forEach(t),ZVo=i(j),$4=n(j,"LI",{});var URe=s($4);v_e=n(URe,"STRONG",{});var rTt=s(v_e);eXo=r(rTt,"xlm"),rTt.forEach(t),oXo=r(URe," \u2014 "),LX=n(URe,"A",{href:!0});var tTt=s(LX);rXo=r(tTt,"XLMForSequenceClassification"),tTt.forEach(t),tXo=r(URe," (XLM model)"),URe.forEach(t),aXo=i(j),k4=n(j,"LI",{});var JRe=s(k4);F_e=n(JRe,"STRONG",{});var aTt=s(F_e);nXo=r(aTt,"xlm-roberta"),aTt.forEach(t),sXo=r(JRe," \u2014 "),yX=n(JRe,"A",{href:!0});var nTt=s(yX);lXo=r(nTt,"XLMRobertaForSequenceClassification"),nTt.forEach(t),iXo=r(JRe," (XLM-RoBERTa model)"),JRe.forEach(t),dXo=i(j),S4=n(j,"LI",{});var YRe=s(S4);T_e=n(YRe,"STRONG",{});var sTt=s(T_e);cXo=r(sTt,"xlm-roberta-xl"),sTt.forEach(t),fXo=r(YRe," \u2014 "),xX=n(YRe,"A",{href:!0});var lTt=s(xX);mXo=r(lTt,"XLMRobertaXLForSequenceClassification"),lTt.forEach(t),gXo=r(YRe," (XLM-RoBERTa-XL model)"),YRe.forEach(t),hXo=i(j),R4=n(j,"LI",{});var KRe=s(R4);M_e=n(KRe,"STRONG",{});var iTt=s(M_e);pXo=r(iTt,"xlnet"),iTt.forEach(t),_Xo=r(KRe," \u2014 "),$X=n(KRe,"A",{href:!0});var dTt=s($X);uXo=r(dTt,"XLNetForSequenceClassification"),dTt.forEach(t),bXo=r(KRe," (XLNet model)"),KRe.forEach(t),vXo=i(j),P4=n(j,"LI",{});var ZRe=s(P4);E_e=n(ZRe,"STRONG",{});var cTt=s(E_e);FXo=r(cTt,"yoso"),cTt.forEach(t),TXo=r(ZRe," \u2014 "),kX=n(ZRe,"A",{href:!0});var fTt=s(kX);MXo=r(fTt,"YosoForSequenceClassification"),fTt.forEach(t),EXo=r(ZRe," (YOSO model)"),ZRe.forEach(t),j.forEach(t),CXo=i(ca),B4=n(ca,"P",{});var ePe=s(B4);wXo=r(ePe,"The model is set in evaluation mode by default using "),C_e=n(ePe,"CODE",{});var mTt=s(C_e);AXo=r(mTt,"model.eval()"),mTt.forEach(t),LXo=r(ePe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w_e=n(ePe,"CODE",{});var gTt=s(w_e);yXo=r(gTt,"model.train()"),gTt.forEach(t),ePe.forEach(t),xXo=i(ca),T(N4.$$.fragment,ca),ca.forEach(t),sl.forEach(t),WVe=i(f),td=n(f,"H2",{class:!0});var Zze=s(td);I4=n(Zze,"A",{id:!0,class:!0,href:!0});var hTt=s(I4);A_e=n(hTt,"SPAN",{});var pTt=s(A_e);T(Zy.$$.fragment,pTt),pTt.forEach(t),hTt.forEach(t),$Xo=i(Zze),L_e=n(Zze,"SPAN",{});var _Tt=s(L_e);kXo=r(_Tt,"AutoModelForMultipleChoice"),_Tt.forEach(t),Zze.forEach(t),HVe=i(f),Bo=n(f,"DIV",{class:!0});var ll=s(Bo);T(e8.$$.fragment,ll),SXo=i(ll),ad=n(ll,"P",{});var Lre=s(ad);RXo=r(Lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),SX=n(Lre,"A",{href:!0});var uTt=s(SX);PXo=r(uTt,"from_pretrained()"),uTt.forEach(t),BXo=r(Lre," class method or the "),RX=n(Lre,"A",{href:!0});var bTt=s(RX);NXo=r(bTt,"from_config()"),bTt.forEach(t),IXo=r(Lre,` class
method.`),Lre.forEach(t),qXo=i(ll),o8=n(ll,"P",{});var eQe=s(o8);jXo=r(eQe,"This class cannot be instantiated directly using "),y_e=n(eQe,"CODE",{});var vTt=s(y_e);DXo=r(vTt,"__init__()"),vTt.forEach(t),GXo=r(eQe," (throws an error)."),eQe.forEach(t),OXo=i(ll),mt=n(ll,"DIV",{class:!0});var m6=s(mt);T(r8.$$.fragment,m6),VXo=i(m6),x_e=n(m6,"P",{});var FTt=s(x_e);XXo=r(FTt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),FTt.forEach(t),zXo=i(m6),nd=n(m6,"P",{});var yre=s(nd);QXo=r(yre,`Note:
Loading a model from its configuration file does `),$_e=n(yre,"STRONG",{});var TTt=s($_e);WXo=r(TTt,"not"),TTt.forEach(t),HXo=r(yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),PX=n(yre,"A",{href:!0});var MTt=s(PX);UXo=r(MTt,"from_pretrained()"),MTt.forEach(t),JXo=r(yre," to load the model weights."),yre.forEach(t),YXo=i(m6),T(q4.$$.fragment,m6),m6.forEach(t),KXo=i(ll),ro=n(ll,"DIV",{class:!0});var fa=s(ro);T(t8.$$.fragment,fa),ZXo=i(fa),k_e=n(fa,"P",{});var ETt=s(k_e);ezo=r(ETt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ETt.forEach(t),ozo=i(fa),Ga=n(fa,"P",{});var g6=s(Ga);rzo=r(g6,"The model class to instantiate is selected based on the "),S_e=n(g6,"CODE",{});var CTt=s(S_e);tzo=r(CTt,"model_type"),CTt.forEach(t),azo=r(g6,` property of the config object (either
passed as an argument or loaded from `),R_e=n(g6,"CODE",{});var wTt=s(R_e);nzo=r(wTt,"pretrained_model_name_or_path"),wTt.forEach(t),szo=r(g6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P_e=n(g6,"CODE",{});var ATt=s(P_e);lzo=r(ATt,"pretrained_model_name_or_path"),ATt.forEach(t),izo=r(g6,":"),g6.forEach(t),dzo=i(fa),Z=n(fa,"UL",{});var ee=s(Z);j4=n(ee,"LI",{});var oPe=s(j4);B_e=n(oPe,"STRONG",{});var LTt=s(B_e);czo=r(LTt,"albert"),LTt.forEach(t),fzo=r(oPe," \u2014 "),BX=n(oPe,"A",{href:!0});var yTt=s(BX);mzo=r(yTt,"AlbertForMultipleChoice"),yTt.forEach(t),gzo=r(oPe," (ALBERT model)"),oPe.forEach(t),hzo=i(ee),D4=n(ee,"LI",{});var rPe=s(D4);N_e=n(rPe,"STRONG",{});var xTt=s(N_e);pzo=r(xTt,"bert"),xTt.forEach(t),_zo=r(rPe," \u2014 "),NX=n(rPe,"A",{href:!0});var $Tt=s(NX);uzo=r($Tt,"BertForMultipleChoice"),$Tt.forEach(t),bzo=r(rPe," (BERT model)"),rPe.forEach(t),vzo=i(ee),G4=n(ee,"LI",{});var tPe=s(G4);I_e=n(tPe,"STRONG",{});var kTt=s(I_e);Fzo=r(kTt,"big_bird"),kTt.forEach(t),Tzo=r(tPe," \u2014 "),IX=n(tPe,"A",{href:!0});var STt=s(IX);Mzo=r(STt,"BigBirdForMultipleChoice"),STt.forEach(t),Ezo=r(tPe," (BigBird model)"),tPe.forEach(t),Czo=i(ee),O4=n(ee,"LI",{});var aPe=s(O4);q_e=n(aPe,"STRONG",{});var RTt=s(q_e);wzo=r(RTt,"camembert"),RTt.forEach(t),Azo=r(aPe," \u2014 "),qX=n(aPe,"A",{href:!0});var PTt=s(qX);Lzo=r(PTt,"CamembertForMultipleChoice"),PTt.forEach(t),yzo=r(aPe," (CamemBERT model)"),aPe.forEach(t),xzo=i(ee),V4=n(ee,"LI",{});var nPe=s(V4);j_e=n(nPe,"STRONG",{});var BTt=s(j_e);$zo=r(BTt,"canine"),BTt.forEach(t),kzo=r(nPe," \u2014 "),jX=n(nPe,"A",{href:!0});var NTt=s(jX);Szo=r(NTt,"CanineForMultipleChoice"),NTt.forEach(t),Rzo=r(nPe," (CANINE model)"),nPe.forEach(t),Pzo=i(ee),X4=n(ee,"LI",{});var sPe=s(X4);D_e=n(sPe,"STRONG",{});var ITt=s(D_e);Bzo=r(ITt,"convbert"),ITt.forEach(t),Nzo=r(sPe," \u2014 "),DX=n(sPe,"A",{href:!0});var qTt=s(DX);Izo=r(qTt,"ConvBertForMultipleChoice"),qTt.forEach(t),qzo=r(sPe," (ConvBERT model)"),sPe.forEach(t),jzo=i(ee),z4=n(ee,"LI",{});var lPe=s(z4);G_e=n(lPe,"STRONG",{});var jTt=s(G_e);Dzo=r(jTt,"data2vec-text"),jTt.forEach(t),Gzo=r(lPe," \u2014 "),GX=n(lPe,"A",{href:!0});var DTt=s(GX);Ozo=r(DTt,"Data2VecTextForMultipleChoice"),DTt.forEach(t),Vzo=r(lPe," (Data2VecText model)"),lPe.forEach(t),Xzo=i(ee),Q4=n(ee,"LI",{});var iPe=s(Q4);O_e=n(iPe,"STRONG",{});var GTt=s(O_e);zzo=r(GTt,"deberta-v2"),GTt.forEach(t),Qzo=r(iPe," \u2014 "),OX=n(iPe,"A",{href:!0});var OTt=s(OX);Wzo=r(OTt,"DebertaV2ForMultipleChoice"),OTt.forEach(t),Hzo=r(iPe," (DeBERTa-v2 model)"),iPe.forEach(t),Uzo=i(ee),W4=n(ee,"LI",{});var dPe=s(W4);V_e=n(dPe,"STRONG",{});var VTt=s(V_e);Jzo=r(VTt,"distilbert"),VTt.forEach(t),Yzo=r(dPe," \u2014 "),VX=n(dPe,"A",{href:!0});var XTt=s(VX);Kzo=r(XTt,"DistilBertForMultipleChoice"),XTt.forEach(t),Zzo=r(dPe," (DistilBERT model)"),dPe.forEach(t),eQo=i(ee),H4=n(ee,"LI",{});var cPe=s(H4);X_e=n(cPe,"STRONG",{});var zTt=s(X_e);oQo=r(zTt,"electra"),zTt.forEach(t),rQo=r(cPe," \u2014 "),XX=n(cPe,"A",{href:!0});var QTt=s(XX);tQo=r(QTt,"ElectraForMultipleChoice"),QTt.forEach(t),aQo=r(cPe," (ELECTRA model)"),cPe.forEach(t),nQo=i(ee),U4=n(ee,"LI",{});var fPe=s(U4);z_e=n(fPe,"STRONG",{});var WTt=s(z_e);sQo=r(WTt,"flaubert"),WTt.forEach(t),lQo=r(fPe," \u2014 "),zX=n(fPe,"A",{href:!0});var HTt=s(zX);iQo=r(HTt,"FlaubertForMultipleChoice"),HTt.forEach(t),dQo=r(fPe," (FlauBERT model)"),fPe.forEach(t),cQo=i(ee),J4=n(ee,"LI",{});var mPe=s(J4);Q_e=n(mPe,"STRONG",{});var UTt=s(Q_e);fQo=r(UTt,"fnet"),UTt.forEach(t),mQo=r(mPe," \u2014 "),QX=n(mPe,"A",{href:!0});var JTt=s(QX);gQo=r(JTt,"FNetForMultipleChoice"),JTt.forEach(t),hQo=r(mPe," (FNet model)"),mPe.forEach(t),pQo=i(ee),Y4=n(ee,"LI",{});var gPe=s(Y4);W_e=n(gPe,"STRONG",{});var YTt=s(W_e);_Qo=r(YTt,"funnel"),YTt.forEach(t),uQo=r(gPe," \u2014 "),WX=n(gPe,"A",{href:!0});var KTt=s(WX);bQo=r(KTt,"FunnelForMultipleChoice"),KTt.forEach(t),vQo=r(gPe," (Funnel Transformer model)"),gPe.forEach(t),FQo=i(ee),K4=n(ee,"LI",{});var hPe=s(K4);H_e=n(hPe,"STRONG",{});var ZTt=s(H_e);TQo=r(ZTt,"ibert"),ZTt.forEach(t),MQo=r(hPe," \u2014 "),HX=n(hPe,"A",{href:!0});var eMt=s(HX);EQo=r(eMt,"IBertForMultipleChoice"),eMt.forEach(t),CQo=r(hPe," (I-BERT model)"),hPe.forEach(t),wQo=i(ee),Z4=n(ee,"LI",{});var pPe=s(Z4);U_e=n(pPe,"STRONG",{});var oMt=s(U_e);AQo=r(oMt,"longformer"),oMt.forEach(t),LQo=r(pPe," \u2014 "),UX=n(pPe,"A",{href:!0});var rMt=s(UX);yQo=r(rMt,"LongformerForMultipleChoice"),rMt.forEach(t),xQo=r(pPe," (Longformer model)"),pPe.forEach(t),$Qo=i(ee),eb=n(ee,"LI",{});var _Pe=s(eb);J_e=n(_Pe,"STRONG",{});var tMt=s(J_e);kQo=r(tMt,"megatron-bert"),tMt.forEach(t),SQo=r(_Pe," \u2014 "),JX=n(_Pe,"A",{href:!0});var aMt=s(JX);RQo=r(aMt,"MegatronBertForMultipleChoice"),aMt.forEach(t),PQo=r(_Pe," (Megatron-BERT model)"),_Pe.forEach(t),BQo=i(ee),ob=n(ee,"LI",{});var uPe=s(ob);Y_e=n(uPe,"STRONG",{});var nMt=s(Y_e);NQo=r(nMt,"mobilebert"),nMt.forEach(t),IQo=r(uPe," \u2014 "),YX=n(uPe,"A",{href:!0});var sMt=s(YX);qQo=r(sMt,"MobileBertForMultipleChoice"),sMt.forEach(t),jQo=r(uPe," (MobileBERT model)"),uPe.forEach(t),DQo=i(ee),rb=n(ee,"LI",{});var bPe=s(rb);K_e=n(bPe,"STRONG",{});var lMt=s(K_e);GQo=r(lMt,"mpnet"),lMt.forEach(t),OQo=r(bPe," \u2014 "),KX=n(bPe,"A",{href:!0});var iMt=s(KX);VQo=r(iMt,"MPNetForMultipleChoice"),iMt.forEach(t),XQo=r(bPe," (MPNet model)"),bPe.forEach(t),zQo=i(ee),tb=n(ee,"LI",{});var vPe=s(tb);Z_e=n(vPe,"STRONG",{});var dMt=s(Z_e);QQo=r(dMt,"nezha"),dMt.forEach(t),WQo=r(vPe," \u2014 "),ZX=n(vPe,"A",{href:!0});var cMt=s(ZX);HQo=r(cMt,"NezhaForMultipleChoice"),cMt.forEach(t),UQo=r(vPe," (Nezha model)"),vPe.forEach(t),JQo=i(ee),ab=n(ee,"LI",{});var FPe=s(ab);eue=n(FPe,"STRONG",{});var fMt=s(eue);YQo=r(fMt,"nystromformer"),fMt.forEach(t),KQo=r(FPe," \u2014 "),ez=n(FPe,"A",{href:!0});var mMt=s(ez);ZQo=r(mMt,"NystromformerForMultipleChoice"),mMt.forEach(t),eWo=r(FPe," (Nystr\xF6mformer model)"),FPe.forEach(t),oWo=i(ee),nb=n(ee,"LI",{});var TPe=s(nb);oue=n(TPe,"STRONG",{});var gMt=s(oue);rWo=r(gMt,"qdqbert"),gMt.forEach(t),tWo=r(TPe," \u2014 "),oz=n(TPe,"A",{href:!0});var hMt=s(oz);aWo=r(hMt,"QDQBertForMultipleChoice"),hMt.forEach(t),nWo=r(TPe," (QDQBert model)"),TPe.forEach(t),sWo=i(ee),sb=n(ee,"LI",{});var MPe=s(sb);rue=n(MPe,"STRONG",{});var pMt=s(rue);lWo=r(pMt,"rembert"),pMt.forEach(t),iWo=r(MPe," \u2014 "),rz=n(MPe,"A",{href:!0});var _Mt=s(rz);dWo=r(_Mt,"RemBertForMultipleChoice"),_Mt.forEach(t),cWo=r(MPe," (RemBERT model)"),MPe.forEach(t),fWo=i(ee),lb=n(ee,"LI",{});var EPe=s(lb);tue=n(EPe,"STRONG",{});var uMt=s(tue);mWo=r(uMt,"roberta"),uMt.forEach(t),gWo=r(EPe," \u2014 "),tz=n(EPe,"A",{href:!0});var bMt=s(tz);hWo=r(bMt,"RobertaForMultipleChoice"),bMt.forEach(t),pWo=r(EPe," (RoBERTa model)"),EPe.forEach(t),_Wo=i(ee),ib=n(ee,"LI",{});var CPe=s(ib);aue=n(CPe,"STRONG",{});var vMt=s(aue);uWo=r(vMt,"roformer"),vMt.forEach(t),bWo=r(CPe," \u2014 "),az=n(CPe,"A",{href:!0});var FMt=s(az);vWo=r(FMt,"RoFormerForMultipleChoice"),FMt.forEach(t),FWo=r(CPe," (RoFormer model)"),CPe.forEach(t),TWo=i(ee),db=n(ee,"LI",{});var wPe=s(db);nue=n(wPe,"STRONG",{});var TMt=s(nue);MWo=r(TMt,"squeezebert"),TMt.forEach(t),EWo=r(wPe," \u2014 "),nz=n(wPe,"A",{href:!0});var MMt=s(nz);CWo=r(MMt,"SqueezeBertForMultipleChoice"),MMt.forEach(t),wWo=r(wPe," (SqueezeBERT model)"),wPe.forEach(t),AWo=i(ee),cb=n(ee,"LI",{});var APe=s(cb);sue=n(APe,"STRONG",{});var EMt=s(sue);LWo=r(EMt,"xlm"),EMt.forEach(t),yWo=r(APe," \u2014 "),sz=n(APe,"A",{href:!0});var CMt=s(sz);xWo=r(CMt,"XLMForMultipleChoice"),CMt.forEach(t),$Wo=r(APe," (XLM model)"),APe.forEach(t),kWo=i(ee),fb=n(ee,"LI",{});var LPe=s(fb);lue=n(LPe,"STRONG",{});var wMt=s(lue);SWo=r(wMt,"xlm-roberta"),wMt.forEach(t),RWo=r(LPe," \u2014 "),lz=n(LPe,"A",{href:!0});var AMt=s(lz);PWo=r(AMt,"XLMRobertaForMultipleChoice"),AMt.forEach(t),BWo=r(LPe," (XLM-RoBERTa model)"),LPe.forEach(t),NWo=i(ee),mb=n(ee,"LI",{});var yPe=s(mb);iue=n(yPe,"STRONG",{});var LMt=s(iue);IWo=r(LMt,"xlm-roberta-xl"),LMt.forEach(t),qWo=r(yPe," \u2014 "),iz=n(yPe,"A",{href:!0});var yMt=s(iz);jWo=r(yMt,"XLMRobertaXLForMultipleChoice"),yMt.forEach(t),DWo=r(yPe," (XLM-RoBERTa-XL model)"),yPe.forEach(t),GWo=i(ee),gb=n(ee,"LI",{});var xPe=s(gb);due=n(xPe,"STRONG",{});var xMt=s(due);OWo=r(xMt,"xlnet"),xMt.forEach(t),VWo=r(xPe," \u2014 "),dz=n(xPe,"A",{href:!0});var $Mt=s(dz);XWo=r($Mt,"XLNetForMultipleChoice"),$Mt.forEach(t),zWo=r(xPe," (XLNet model)"),xPe.forEach(t),QWo=i(ee),hb=n(ee,"LI",{});var $Pe=s(hb);cue=n($Pe,"STRONG",{});var kMt=s(cue);WWo=r(kMt,"yoso"),kMt.forEach(t),HWo=r($Pe," \u2014 "),cz=n($Pe,"A",{href:!0});var SMt=s(cz);UWo=r(SMt,"YosoForMultipleChoice"),SMt.forEach(t),JWo=r($Pe," (YOSO model)"),$Pe.forEach(t),ee.forEach(t),YWo=i(fa),pb=n(fa,"P",{});var kPe=s(pb);KWo=r(kPe,"The model is set in evaluation mode by default using "),fue=n(kPe,"CODE",{});var RMt=s(fue);ZWo=r(RMt,"model.eval()"),RMt.forEach(t),eHo=r(kPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mue=n(kPe,"CODE",{});var PMt=s(mue);oHo=r(PMt,"model.train()"),PMt.forEach(t),kPe.forEach(t),rHo=i(fa),T(_b.$$.fragment,fa),fa.forEach(t),ll.forEach(t),UVe=i(f),sd=n(f,"H2",{class:!0});var oQe=s(sd);ub=n(oQe,"A",{id:!0,class:!0,href:!0});var BMt=s(ub);gue=n(BMt,"SPAN",{});var NMt=s(gue);T(a8.$$.fragment,NMt),NMt.forEach(t),BMt.forEach(t),tHo=i(oQe),hue=n(oQe,"SPAN",{});var IMt=s(hue);aHo=r(IMt,"AutoModelForNextSentencePrediction"),IMt.forEach(t),oQe.forEach(t),JVe=i(f),No=n(f,"DIV",{class:!0});var il=s(No);T(n8.$$.fragment,il),nHo=i(il),ld=n(il,"P",{});var xre=s(ld);sHo=r(xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fz=n(xre,"A",{href:!0});var qMt=s(fz);lHo=r(qMt,"from_pretrained()"),qMt.forEach(t),iHo=r(xre," class method or the "),mz=n(xre,"A",{href:!0});var jMt=s(mz);dHo=r(jMt,"from_config()"),jMt.forEach(t),cHo=r(xre,` class
method.`),xre.forEach(t),fHo=i(il),s8=n(il,"P",{});var rQe=s(s8);mHo=r(rQe,"This class cannot be instantiated directly using "),pue=n(rQe,"CODE",{});var DMt=s(pue);gHo=r(DMt,"__init__()"),DMt.forEach(t),hHo=r(rQe," (throws an error)."),rQe.forEach(t),pHo=i(il),gt=n(il,"DIV",{class:!0});var h6=s(gt);T(l8.$$.fragment,h6),_Ho=i(h6),_ue=n(h6,"P",{});var GMt=s(_ue);uHo=r(GMt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),GMt.forEach(t),bHo=i(h6),id=n(h6,"P",{});var $re=s(id);vHo=r($re,`Note:
Loading a model from its configuration file does `),uue=n($re,"STRONG",{});var OMt=s(uue);FHo=r(OMt,"not"),OMt.forEach(t),THo=r($re,` load the model weights. It only affects the
model\u2019s configuration. Use `),gz=n($re,"A",{href:!0});var VMt=s(gz);MHo=r(VMt,"from_pretrained()"),VMt.forEach(t),EHo=r($re," to load the model weights."),$re.forEach(t),CHo=i(h6),T(bb.$$.fragment,h6),h6.forEach(t),wHo=i(il),to=n(il,"DIV",{class:!0});var ma=s(to);T(i8.$$.fragment,ma),AHo=i(ma),bue=n(ma,"P",{});var XMt=s(bue);LHo=r(XMt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),XMt.forEach(t),yHo=i(ma),Oa=n(ma,"P",{});var p6=s(Oa);xHo=r(p6,"The model class to instantiate is selected based on the "),vue=n(p6,"CODE",{});var zMt=s(vue);$Ho=r(zMt,"model_type"),zMt.forEach(t),kHo=r(p6,` property of the config object (either
passed as an argument or loaded from `),Fue=n(p6,"CODE",{});var QMt=s(Fue);SHo=r(QMt,"pretrained_model_name_or_path"),QMt.forEach(t),RHo=r(p6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tue=n(p6,"CODE",{});var WMt=s(Tue);PHo=r(WMt,"pretrained_model_name_or_path"),WMt.forEach(t),BHo=r(p6,":"),p6.forEach(t),NHo=i(ma),Io=n(ma,"UL",{});var ga=s(Io);vb=n(ga,"LI",{});var SPe=s(vb);Mue=n(SPe,"STRONG",{});var HMt=s(Mue);IHo=r(HMt,"bert"),HMt.forEach(t),qHo=r(SPe," \u2014 "),hz=n(SPe,"A",{href:!0});var UMt=s(hz);jHo=r(UMt,"BertForNextSentencePrediction"),UMt.forEach(t),DHo=r(SPe," (BERT model)"),SPe.forEach(t),GHo=i(ga),Fb=n(ga,"LI",{});var RPe=s(Fb);Eue=n(RPe,"STRONG",{});var JMt=s(Eue);OHo=r(JMt,"fnet"),JMt.forEach(t),VHo=r(RPe," \u2014 "),pz=n(RPe,"A",{href:!0});var YMt=s(pz);XHo=r(YMt,"FNetForNextSentencePrediction"),YMt.forEach(t),zHo=r(RPe," (FNet model)"),RPe.forEach(t),QHo=i(ga),Tb=n(ga,"LI",{});var PPe=s(Tb);Cue=n(PPe,"STRONG",{});var KMt=s(Cue);WHo=r(KMt,"megatron-bert"),KMt.forEach(t),HHo=r(PPe," \u2014 "),_z=n(PPe,"A",{href:!0});var ZMt=s(_z);UHo=r(ZMt,"MegatronBertForNextSentencePrediction"),ZMt.forEach(t),JHo=r(PPe," (Megatron-BERT model)"),PPe.forEach(t),YHo=i(ga),Mb=n(ga,"LI",{});var BPe=s(Mb);wue=n(BPe,"STRONG",{});var eEt=s(wue);KHo=r(eEt,"mobilebert"),eEt.forEach(t),ZHo=r(BPe," \u2014 "),uz=n(BPe,"A",{href:!0});var oEt=s(uz);eUo=r(oEt,"MobileBertForNextSentencePrediction"),oEt.forEach(t),oUo=r(BPe," (MobileBERT model)"),BPe.forEach(t),rUo=i(ga),Eb=n(ga,"LI",{});var NPe=s(Eb);Aue=n(NPe,"STRONG",{});var rEt=s(Aue);tUo=r(rEt,"nezha"),rEt.forEach(t),aUo=r(NPe," \u2014 "),bz=n(NPe,"A",{href:!0});var tEt=s(bz);nUo=r(tEt,"NezhaForNextSentencePrediction"),tEt.forEach(t),sUo=r(NPe," (Nezha model)"),NPe.forEach(t),lUo=i(ga),Cb=n(ga,"LI",{});var IPe=s(Cb);Lue=n(IPe,"STRONG",{});var aEt=s(Lue);iUo=r(aEt,"qdqbert"),aEt.forEach(t),dUo=r(IPe," \u2014 "),vz=n(IPe,"A",{href:!0});var nEt=s(vz);cUo=r(nEt,"QDQBertForNextSentencePrediction"),nEt.forEach(t),fUo=r(IPe," (QDQBert model)"),IPe.forEach(t),ga.forEach(t),mUo=i(ma),wb=n(ma,"P",{});var qPe=s(wb);gUo=r(qPe,"The model is set in evaluation mode by default using "),yue=n(qPe,"CODE",{});var sEt=s(yue);hUo=r(sEt,"model.eval()"),sEt.forEach(t),pUo=r(qPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xue=n(qPe,"CODE",{});var lEt=s(xue);_Uo=r(lEt,"model.train()"),lEt.forEach(t),qPe.forEach(t),uUo=i(ma),T(Ab.$$.fragment,ma),ma.forEach(t),il.forEach(t),YVe=i(f),dd=n(f,"H2",{class:!0});var tQe=s(dd);Lb=n(tQe,"A",{id:!0,class:!0,href:!0});var iEt=s(Lb);$ue=n(iEt,"SPAN",{});var dEt=s($ue);T(d8.$$.fragment,dEt),dEt.forEach(t),iEt.forEach(t),bUo=i(tQe),kue=n(tQe,"SPAN",{});var cEt=s(kue);vUo=r(cEt,"AutoModelForTokenClassification"),cEt.forEach(t),tQe.forEach(t),KVe=i(f),qo=n(f,"DIV",{class:!0});var dl=s(qo);T(c8.$$.fragment,dl),FUo=i(dl),cd=n(dl,"P",{});var kre=s(cd);TUo=r(kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fz=n(kre,"A",{href:!0});var fEt=s(Fz);MUo=r(fEt,"from_pretrained()"),fEt.forEach(t),EUo=r(kre," class method or the "),Tz=n(kre,"A",{href:!0});var mEt=s(Tz);CUo=r(mEt,"from_config()"),mEt.forEach(t),wUo=r(kre,` class
method.`),kre.forEach(t),AUo=i(dl),f8=n(dl,"P",{});var aQe=s(f8);LUo=r(aQe,"This class cannot be instantiated directly using "),Sue=n(aQe,"CODE",{});var gEt=s(Sue);yUo=r(gEt,"__init__()"),gEt.forEach(t),xUo=r(aQe," (throws an error)."),aQe.forEach(t),$Uo=i(dl),ht=n(dl,"DIV",{class:!0});var _6=s(ht);T(m8.$$.fragment,_6),kUo=i(_6),Rue=n(_6,"P",{});var hEt=s(Rue);SUo=r(hEt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),hEt.forEach(t),RUo=i(_6),fd=n(_6,"P",{});var Sre=s(fd);PUo=r(Sre,`Note:
Loading a model from its configuration file does `),Pue=n(Sre,"STRONG",{});var pEt=s(Pue);BUo=r(pEt,"not"),pEt.forEach(t),NUo=r(Sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mz=n(Sre,"A",{href:!0});var _Et=s(Mz);IUo=r(_Et,"from_pretrained()"),_Et.forEach(t),qUo=r(Sre," to load the model weights."),Sre.forEach(t),jUo=i(_6),T(yb.$$.fragment,_6),_6.forEach(t),DUo=i(dl),ao=n(dl,"DIV",{class:!0});var ha=s(ao);T(g8.$$.fragment,ha),GUo=i(ha),Bue=n(ha,"P",{});var uEt=s(Bue);OUo=r(uEt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),uEt.forEach(t),VUo=i(ha),Va=n(ha,"P",{});var u6=s(Va);XUo=r(u6,"The model class to instantiate is selected based on the "),Nue=n(u6,"CODE",{});var bEt=s(Nue);zUo=r(bEt,"model_type"),bEt.forEach(t),QUo=r(u6,` property of the config object (either
passed as an argument or loaded from `),Iue=n(u6,"CODE",{});var vEt=s(Iue);WUo=r(vEt,"pretrained_model_name_or_path"),vEt.forEach(t),HUo=r(u6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),que=n(u6,"CODE",{});var FEt=s(que);UUo=r(FEt,"pretrained_model_name_or_path"),FEt.forEach(t),JUo=r(u6,":"),u6.forEach(t),YUo=i(ha),U=n(ha,"UL",{});var J=s(U);xb=n(J,"LI",{});var jPe=s(xb);jue=n(jPe,"STRONG",{});var TEt=s(jue);KUo=r(TEt,"albert"),TEt.forEach(t),ZUo=r(jPe," \u2014 "),Ez=n(jPe,"A",{href:!0});var MEt=s(Ez);eJo=r(MEt,"AlbertForTokenClassification"),MEt.forEach(t),oJo=r(jPe," (ALBERT model)"),jPe.forEach(t),rJo=i(J),$b=n(J,"LI",{});var DPe=s($b);Due=n(DPe,"STRONG",{});var EEt=s(Due);tJo=r(EEt,"bert"),EEt.forEach(t),aJo=r(DPe," \u2014 "),Cz=n(DPe,"A",{href:!0});var CEt=s(Cz);nJo=r(CEt,"BertForTokenClassification"),CEt.forEach(t),sJo=r(DPe," (BERT model)"),DPe.forEach(t),lJo=i(J),kb=n(J,"LI",{});var GPe=s(kb);Gue=n(GPe,"STRONG",{});var wEt=s(Gue);iJo=r(wEt,"big_bird"),wEt.forEach(t),dJo=r(GPe," \u2014 "),wz=n(GPe,"A",{href:!0});var AEt=s(wz);cJo=r(AEt,"BigBirdForTokenClassification"),AEt.forEach(t),fJo=r(GPe," (BigBird model)"),GPe.forEach(t),mJo=i(J),Sb=n(J,"LI",{});var OPe=s(Sb);Oue=n(OPe,"STRONG",{});var LEt=s(Oue);gJo=r(LEt,"bloom"),LEt.forEach(t),hJo=r(OPe," \u2014 "),Az=n(OPe,"A",{href:!0});var yEt=s(Az);pJo=r(yEt,"BloomForTokenClassification"),yEt.forEach(t),_Jo=r(OPe," (BLOOM model)"),OPe.forEach(t),uJo=i(J),Rb=n(J,"LI",{});var VPe=s(Rb);Vue=n(VPe,"STRONG",{});var xEt=s(Vue);bJo=r(xEt,"camembert"),xEt.forEach(t),vJo=r(VPe," \u2014 "),Lz=n(VPe,"A",{href:!0});var $Et=s(Lz);FJo=r($Et,"CamembertForTokenClassification"),$Et.forEach(t),TJo=r(VPe," (CamemBERT model)"),VPe.forEach(t),MJo=i(J),Pb=n(J,"LI",{});var XPe=s(Pb);Xue=n(XPe,"STRONG",{});var kEt=s(Xue);EJo=r(kEt,"canine"),kEt.forEach(t),CJo=r(XPe," \u2014 "),yz=n(XPe,"A",{href:!0});var SEt=s(yz);wJo=r(SEt,"CanineForTokenClassification"),SEt.forEach(t),AJo=r(XPe," (CANINE model)"),XPe.forEach(t),LJo=i(J),Bb=n(J,"LI",{});var zPe=s(Bb);zue=n(zPe,"STRONG",{});var REt=s(zue);yJo=r(REt,"convbert"),REt.forEach(t),xJo=r(zPe," \u2014 "),xz=n(zPe,"A",{href:!0});var PEt=s(xz);$Jo=r(PEt,"ConvBertForTokenClassification"),PEt.forEach(t),kJo=r(zPe," (ConvBERT model)"),zPe.forEach(t),SJo=i(J),Nb=n(J,"LI",{});var QPe=s(Nb);Que=n(QPe,"STRONG",{});var BEt=s(Que);RJo=r(BEt,"data2vec-text"),BEt.forEach(t),PJo=r(QPe," \u2014 "),$z=n(QPe,"A",{href:!0});var NEt=s($z);BJo=r(NEt,"Data2VecTextForTokenClassification"),NEt.forEach(t),NJo=r(QPe," (Data2VecText model)"),QPe.forEach(t),IJo=i(J),Ib=n(J,"LI",{});var WPe=s(Ib);Wue=n(WPe,"STRONG",{});var IEt=s(Wue);qJo=r(IEt,"deberta"),IEt.forEach(t),jJo=r(WPe," \u2014 "),kz=n(WPe,"A",{href:!0});var qEt=s(kz);DJo=r(qEt,"DebertaForTokenClassification"),qEt.forEach(t),GJo=r(WPe," (DeBERTa model)"),WPe.forEach(t),OJo=i(J),qb=n(J,"LI",{});var HPe=s(qb);Hue=n(HPe,"STRONG",{});var jEt=s(Hue);VJo=r(jEt,"deberta-v2"),jEt.forEach(t),XJo=r(HPe," \u2014 "),Sz=n(HPe,"A",{href:!0});var DEt=s(Sz);zJo=r(DEt,"DebertaV2ForTokenClassification"),DEt.forEach(t),QJo=r(HPe," (DeBERTa-v2 model)"),HPe.forEach(t),WJo=i(J),jb=n(J,"LI",{});var UPe=s(jb);Uue=n(UPe,"STRONG",{});var GEt=s(Uue);HJo=r(GEt,"distilbert"),GEt.forEach(t),UJo=r(UPe," \u2014 "),Rz=n(UPe,"A",{href:!0});var OEt=s(Rz);JJo=r(OEt,"DistilBertForTokenClassification"),OEt.forEach(t),YJo=r(UPe," (DistilBERT model)"),UPe.forEach(t),KJo=i(J),Db=n(J,"LI",{});var JPe=s(Db);Jue=n(JPe,"STRONG",{});var VEt=s(Jue);ZJo=r(VEt,"electra"),VEt.forEach(t),eYo=r(JPe," \u2014 "),Pz=n(JPe,"A",{href:!0});var XEt=s(Pz);oYo=r(XEt,"ElectraForTokenClassification"),XEt.forEach(t),rYo=r(JPe," (ELECTRA model)"),JPe.forEach(t),tYo=i(J),Gb=n(J,"LI",{});var YPe=s(Gb);Yue=n(YPe,"STRONG",{});var zEt=s(Yue);aYo=r(zEt,"flaubert"),zEt.forEach(t),nYo=r(YPe," \u2014 "),Bz=n(YPe,"A",{href:!0});var QEt=s(Bz);sYo=r(QEt,"FlaubertForTokenClassification"),QEt.forEach(t),lYo=r(YPe," (FlauBERT model)"),YPe.forEach(t),iYo=i(J),Ob=n(J,"LI",{});var KPe=s(Ob);Kue=n(KPe,"STRONG",{});var WEt=s(Kue);dYo=r(WEt,"fnet"),WEt.forEach(t),cYo=r(KPe," \u2014 "),Nz=n(KPe,"A",{href:!0});var HEt=s(Nz);fYo=r(HEt,"FNetForTokenClassification"),HEt.forEach(t),mYo=r(KPe," (FNet model)"),KPe.forEach(t),gYo=i(J),Vb=n(J,"LI",{});var ZPe=s(Vb);Zue=n(ZPe,"STRONG",{});var UEt=s(Zue);hYo=r(UEt,"funnel"),UEt.forEach(t),pYo=r(ZPe," \u2014 "),Iz=n(ZPe,"A",{href:!0});var JEt=s(Iz);_Yo=r(JEt,"FunnelForTokenClassification"),JEt.forEach(t),uYo=r(ZPe," (Funnel Transformer model)"),ZPe.forEach(t),bYo=i(J),Xb=n(J,"LI",{});var eBe=s(Xb);e2e=n(eBe,"STRONG",{});var YEt=s(e2e);vYo=r(YEt,"gpt2"),YEt.forEach(t),FYo=r(eBe," \u2014 "),qz=n(eBe,"A",{href:!0});var KEt=s(qz);TYo=r(KEt,"GPT2ForTokenClassification"),KEt.forEach(t),MYo=r(eBe," (OpenAI GPT-2 model)"),eBe.forEach(t),EYo=i(J),zb=n(J,"LI",{});var oBe=s(zb);o2e=n(oBe,"STRONG",{});var ZEt=s(o2e);CYo=r(ZEt,"ibert"),ZEt.forEach(t),wYo=r(oBe," \u2014 "),jz=n(oBe,"A",{href:!0});var eCt=s(jz);AYo=r(eCt,"IBertForTokenClassification"),eCt.forEach(t),LYo=r(oBe," (I-BERT model)"),oBe.forEach(t),yYo=i(J),Qb=n(J,"LI",{});var rBe=s(Qb);r2e=n(rBe,"STRONG",{});var oCt=s(r2e);xYo=r(oCt,"layoutlm"),oCt.forEach(t),$Yo=r(rBe," \u2014 "),Dz=n(rBe,"A",{href:!0});var rCt=s(Dz);kYo=r(rCt,"LayoutLMForTokenClassification"),rCt.forEach(t),SYo=r(rBe," (LayoutLM model)"),rBe.forEach(t),RYo=i(J),Wb=n(J,"LI",{});var tBe=s(Wb);t2e=n(tBe,"STRONG",{});var tCt=s(t2e);PYo=r(tCt,"layoutlmv2"),tCt.forEach(t),BYo=r(tBe," \u2014 "),Gz=n(tBe,"A",{href:!0});var aCt=s(Gz);NYo=r(aCt,"LayoutLMv2ForTokenClassification"),aCt.forEach(t),IYo=r(tBe," (LayoutLMv2 model)"),tBe.forEach(t),qYo=i(J),Hb=n(J,"LI",{});var aBe=s(Hb);a2e=n(aBe,"STRONG",{});var nCt=s(a2e);jYo=r(nCt,"layoutlmv3"),nCt.forEach(t),DYo=r(aBe," \u2014 "),Oz=n(aBe,"A",{href:!0});var sCt=s(Oz);GYo=r(sCt,"LayoutLMv3ForTokenClassification"),sCt.forEach(t),OYo=r(aBe," (LayoutLMv3 model)"),aBe.forEach(t),VYo=i(J),Ub=n(J,"LI",{});var nBe=s(Ub);n2e=n(nBe,"STRONG",{});var lCt=s(n2e);XYo=r(lCt,"longformer"),lCt.forEach(t),zYo=r(nBe," \u2014 "),Vz=n(nBe,"A",{href:!0});var iCt=s(Vz);QYo=r(iCt,"LongformerForTokenClassification"),iCt.forEach(t),WYo=r(nBe," (Longformer model)"),nBe.forEach(t),HYo=i(J),Jb=n(J,"LI",{});var sBe=s(Jb);s2e=n(sBe,"STRONG",{});var dCt=s(s2e);UYo=r(dCt,"megatron-bert"),dCt.forEach(t),JYo=r(sBe," \u2014 "),Xz=n(sBe,"A",{href:!0});var cCt=s(Xz);YYo=r(cCt,"MegatronBertForTokenClassification"),cCt.forEach(t),KYo=r(sBe," (Megatron-BERT model)"),sBe.forEach(t),ZYo=i(J),Yb=n(J,"LI",{});var lBe=s(Yb);l2e=n(lBe,"STRONG",{});var fCt=s(l2e);eKo=r(fCt,"mobilebert"),fCt.forEach(t),oKo=r(lBe," \u2014 "),zz=n(lBe,"A",{href:!0});var mCt=s(zz);rKo=r(mCt,"MobileBertForTokenClassification"),mCt.forEach(t),tKo=r(lBe," (MobileBERT model)"),lBe.forEach(t),aKo=i(J),Kb=n(J,"LI",{});var iBe=s(Kb);i2e=n(iBe,"STRONG",{});var gCt=s(i2e);nKo=r(gCt,"mpnet"),gCt.forEach(t),sKo=r(iBe," \u2014 "),Qz=n(iBe,"A",{href:!0});var hCt=s(Qz);lKo=r(hCt,"MPNetForTokenClassification"),hCt.forEach(t),iKo=r(iBe," (MPNet model)"),iBe.forEach(t),dKo=i(J),Zb=n(J,"LI",{});var dBe=s(Zb);d2e=n(dBe,"STRONG",{});var pCt=s(d2e);cKo=r(pCt,"nezha"),pCt.forEach(t),fKo=r(dBe," \u2014 "),Wz=n(dBe,"A",{href:!0});var _Ct=s(Wz);mKo=r(_Ct,"NezhaForTokenClassification"),_Ct.forEach(t),gKo=r(dBe," (Nezha model)"),dBe.forEach(t),hKo=i(J),ev=n(J,"LI",{});var cBe=s(ev);c2e=n(cBe,"STRONG",{});var uCt=s(c2e);pKo=r(uCt,"nystromformer"),uCt.forEach(t),_Ko=r(cBe," \u2014 "),Hz=n(cBe,"A",{href:!0});var bCt=s(Hz);uKo=r(bCt,"NystromformerForTokenClassification"),bCt.forEach(t),bKo=r(cBe," (Nystr\xF6mformer model)"),cBe.forEach(t),vKo=i(J),ov=n(J,"LI",{});var fBe=s(ov);f2e=n(fBe,"STRONG",{});var vCt=s(f2e);FKo=r(vCt,"qdqbert"),vCt.forEach(t),TKo=r(fBe," \u2014 "),Uz=n(fBe,"A",{href:!0});var FCt=s(Uz);MKo=r(FCt,"QDQBertForTokenClassification"),FCt.forEach(t),EKo=r(fBe," (QDQBert model)"),fBe.forEach(t),CKo=i(J),rv=n(J,"LI",{});var mBe=s(rv);m2e=n(mBe,"STRONG",{});var TCt=s(m2e);wKo=r(TCt,"rembert"),TCt.forEach(t),AKo=r(mBe," \u2014 "),Jz=n(mBe,"A",{href:!0});var MCt=s(Jz);LKo=r(MCt,"RemBertForTokenClassification"),MCt.forEach(t),yKo=r(mBe," (RemBERT model)"),mBe.forEach(t),xKo=i(J),tv=n(J,"LI",{});var gBe=s(tv);g2e=n(gBe,"STRONG",{});var ECt=s(g2e);$Ko=r(ECt,"roberta"),ECt.forEach(t),kKo=r(gBe," \u2014 "),Yz=n(gBe,"A",{href:!0});var CCt=s(Yz);SKo=r(CCt,"RobertaForTokenClassification"),CCt.forEach(t),RKo=r(gBe," (RoBERTa model)"),gBe.forEach(t),PKo=i(J),av=n(J,"LI",{});var hBe=s(av);h2e=n(hBe,"STRONG",{});var wCt=s(h2e);BKo=r(wCt,"roformer"),wCt.forEach(t),NKo=r(hBe," \u2014 "),Kz=n(hBe,"A",{href:!0});var ACt=s(Kz);IKo=r(ACt,"RoFormerForTokenClassification"),ACt.forEach(t),qKo=r(hBe," (RoFormer model)"),hBe.forEach(t),jKo=i(J),nv=n(J,"LI",{});var pBe=s(nv);p2e=n(pBe,"STRONG",{});var LCt=s(p2e);DKo=r(LCt,"squeezebert"),LCt.forEach(t),GKo=r(pBe," \u2014 "),Zz=n(pBe,"A",{href:!0});var yCt=s(Zz);OKo=r(yCt,"SqueezeBertForTokenClassification"),yCt.forEach(t),VKo=r(pBe," (SqueezeBERT model)"),pBe.forEach(t),XKo=i(J),sv=n(J,"LI",{});var _Be=s(sv);_2e=n(_Be,"STRONG",{});var xCt=s(_2e);zKo=r(xCt,"xlm"),xCt.forEach(t),QKo=r(_Be," \u2014 "),eQ=n(_Be,"A",{href:!0});var $Ct=s(eQ);WKo=r($Ct,"XLMForTokenClassification"),$Ct.forEach(t),HKo=r(_Be," (XLM model)"),_Be.forEach(t),UKo=i(J),lv=n(J,"LI",{});var uBe=s(lv);u2e=n(uBe,"STRONG",{});var kCt=s(u2e);JKo=r(kCt,"xlm-roberta"),kCt.forEach(t),YKo=r(uBe," \u2014 "),oQ=n(uBe,"A",{href:!0});var SCt=s(oQ);KKo=r(SCt,"XLMRobertaForTokenClassification"),SCt.forEach(t),ZKo=r(uBe," (XLM-RoBERTa model)"),uBe.forEach(t),eZo=i(J),iv=n(J,"LI",{});var bBe=s(iv);b2e=n(bBe,"STRONG",{});var RCt=s(b2e);oZo=r(RCt,"xlm-roberta-xl"),RCt.forEach(t),rZo=r(bBe," \u2014 "),rQ=n(bBe,"A",{href:!0});var PCt=s(rQ);tZo=r(PCt,"XLMRobertaXLForTokenClassification"),PCt.forEach(t),aZo=r(bBe," (XLM-RoBERTa-XL model)"),bBe.forEach(t),nZo=i(J),dv=n(J,"LI",{});var vBe=s(dv);v2e=n(vBe,"STRONG",{});var BCt=s(v2e);sZo=r(BCt,"xlnet"),BCt.forEach(t),lZo=r(vBe," \u2014 "),tQ=n(vBe,"A",{href:!0});var NCt=s(tQ);iZo=r(NCt,"XLNetForTokenClassification"),NCt.forEach(t),dZo=r(vBe," (XLNet model)"),vBe.forEach(t),cZo=i(J),cv=n(J,"LI",{});var FBe=s(cv);F2e=n(FBe,"STRONG",{});var ICt=s(F2e);fZo=r(ICt,"yoso"),ICt.forEach(t),mZo=r(FBe," \u2014 "),aQ=n(FBe,"A",{href:!0});var qCt=s(aQ);gZo=r(qCt,"YosoForTokenClassification"),qCt.forEach(t),hZo=r(FBe," (YOSO model)"),FBe.forEach(t),J.forEach(t),pZo=i(ha),fv=n(ha,"P",{});var TBe=s(fv);_Zo=r(TBe,"The model is set in evaluation mode by default using "),T2e=n(TBe,"CODE",{});var jCt=s(T2e);uZo=r(jCt,"model.eval()"),jCt.forEach(t),bZo=r(TBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M2e=n(TBe,"CODE",{});var DCt=s(M2e);vZo=r(DCt,"model.train()"),DCt.forEach(t),TBe.forEach(t),FZo=i(ha),T(mv.$$.fragment,ha),ha.forEach(t),dl.forEach(t),ZVe=i(f),md=n(f,"H2",{class:!0});var nQe=s(md);gv=n(nQe,"A",{id:!0,class:!0,href:!0});var GCt=s(gv);E2e=n(GCt,"SPAN",{});var OCt=s(E2e);T(h8.$$.fragment,OCt),OCt.forEach(t),GCt.forEach(t),TZo=i(nQe),C2e=n(nQe,"SPAN",{});var VCt=s(C2e);MZo=r(VCt,"AutoModelForQuestionAnswering"),VCt.forEach(t),nQe.forEach(t),eXe=i(f),jo=n(f,"DIV",{class:!0});var cl=s(jo);T(p8.$$.fragment,cl),EZo=i(cl),gd=n(cl,"P",{});var Rre=s(gd);CZo=r(Rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nQ=n(Rre,"A",{href:!0});var XCt=s(nQ);wZo=r(XCt,"from_pretrained()"),XCt.forEach(t),AZo=r(Rre," class method or the "),sQ=n(Rre,"A",{href:!0});var zCt=s(sQ);LZo=r(zCt,"from_config()"),zCt.forEach(t),yZo=r(Rre,` class
method.`),Rre.forEach(t),xZo=i(cl),_8=n(cl,"P",{});var sQe=s(_8);$Zo=r(sQe,"This class cannot be instantiated directly using "),w2e=n(sQe,"CODE",{});var QCt=s(w2e);kZo=r(QCt,"__init__()"),QCt.forEach(t),SZo=r(sQe," (throws an error)."),sQe.forEach(t),RZo=i(cl),pt=n(cl,"DIV",{class:!0});var b6=s(pt);T(u8.$$.fragment,b6),PZo=i(b6),A2e=n(b6,"P",{});var WCt=s(A2e);BZo=r(WCt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WCt.forEach(t),NZo=i(b6),hd=n(b6,"P",{});var Pre=s(hd);IZo=r(Pre,`Note:
Loading a model from its configuration file does `),L2e=n(Pre,"STRONG",{});var HCt=s(L2e);qZo=r(HCt,"not"),HCt.forEach(t),jZo=r(Pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),lQ=n(Pre,"A",{href:!0});var UCt=s(lQ);DZo=r(UCt,"from_pretrained()"),UCt.forEach(t),GZo=r(Pre," to load the model weights."),Pre.forEach(t),OZo=i(b6),T(hv.$$.fragment,b6),b6.forEach(t),VZo=i(cl),no=n(cl,"DIV",{class:!0});var pa=s(no);T(b8.$$.fragment,pa),XZo=i(pa),y2e=n(pa,"P",{});var JCt=s(y2e);zZo=r(JCt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JCt.forEach(t),QZo=i(pa),Xa=n(pa,"P",{});var v6=s(Xa);WZo=r(v6,"The model class to instantiate is selected based on the "),x2e=n(v6,"CODE",{});var YCt=s(x2e);HZo=r(YCt,"model_type"),YCt.forEach(t),UZo=r(v6,` property of the config object (either
passed as an argument or loaded from `),$2e=n(v6,"CODE",{});var KCt=s($2e);JZo=r(KCt,"pretrained_model_name_or_path"),KCt.forEach(t),YZo=r(v6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k2e=n(v6,"CODE",{});var ZCt=s(k2e);KZo=r(ZCt,"pretrained_model_name_or_path"),ZCt.forEach(t),ZZo=r(v6,":"),v6.forEach(t),eer=i(pa),V=n(pa,"UL",{});var X=s(V);pv=n(X,"LI",{});var MBe=s(pv);S2e=n(MBe,"STRONG",{});var e3t=s(S2e);oer=r(e3t,"albert"),e3t.forEach(t),rer=r(MBe," \u2014 "),iQ=n(MBe,"A",{href:!0});var o3t=s(iQ);ter=r(o3t,"AlbertForQuestionAnswering"),o3t.forEach(t),aer=r(MBe," (ALBERT model)"),MBe.forEach(t),ner=i(X),_v=n(X,"LI",{});var EBe=s(_v);R2e=n(EBe,"STRONG",{});var r3t=s(R2e);ser=r(r3t,"bart"),r3t.forEach(t),ler=r(EBe," \u2014 "),dQ=n(EBe,"A",{href:!0});var t3t=s(dQ);ier=r(t3t,"BartForQuestionAnswering"),t3t.forEach(t),der=r(EBe," (BART model)"),EBe.forEach(t),cer=i(X),uv=n(X,"LI",{});var CBe=s(uv);P2e=n(CBe,"STRONG",{});var a3t=s(P2e);fer=r(a3t,"bert"),a3t.forEach(t),mer=r(CBe," \u2014 "),cQ=n(CBe,"A",{href:!0});var n3t=s(cQ);ger=r(n3t,"BertForQuestionAnswering"),n3t.forEach(t),her=r(CBe," (BERT model)"),CBe.forEach(t),per=i(X),bv=n(X,"LI",{});var wBe=s(bv);B2e=n(wBe,"STRONG",{});var s3t=s(B2e);_er=r(s3t,"big_bird"),s3t.forEach(t),uer=r(wBe," \u2014 "),fQ=n(wBe,"A",{href:!0});var l3t=s(fQ);ber=r(l3t,"BigBirdForQuestionAnswering"),l3t.forEach(t),ver=r(wBe," (BigBird model)"),wBe.forEach(t),Fer=i(X),vv=n(X,"LI",{});var ABe=s(vv);N2e=n(ABe,"STRONG",{});var i3t=s(N2e);Ter=r(i3t,"bigbird_pegasus"),i3t.forEach(t),Mer=r(ABe," \u2014 "),mQ=n(ABe,"A",{href:!0});var d3t=s(mQ);Eer=r(d3t,"BigBirdPegasusForQuestionAnswering"),d3t.forEach(t),Cer=r(ABe," (BigBird-Pegasus model)"),ABe.forEach(t),wer=i(X),Fv=n(X,"LI",{});var LBe=s(Fv);I2e=n(LBe,"STRONG",{});var c3t=s(I2e);Aer=r(c3t,"camembert"),c3t.forEach(t),Ler=r(LBe," \u2014 "),gQ=n(LBe,"A",{href:!0});var f3t=s(gQ);yer=r(f3t,"CamembertForQuestionAnswering"),f3t.forEach(t),xer=r(LBe," (CamemBERT model)"),LBe.forEach(t),$er=i(X),Tv=n(X,"LI",{});var yBe=s(Tv);q2e=n(yBe,"STRONG",{});var m3t=s(q2e);ker=r(m3t,"canine"),m3t.forEach(t),Ser=r(yBe," \u2014 "),hQ=n(yBe,"A",{href:!0});var g3t=s(hQ);Rer=r(g3t,"CanineForQuestionAnswering"),g3t.forEach(t),Per=r(yBe," (CANINE model)"),yBe.forEach(t),Ber=i(X),Mv=n(X,"LI",{});var xBe=s(Mv);j2e=n(xBe,"STRONG",{});var h3t=s(j2e);Ner=r(h3t,"convbert"),h3t.forEach(t),Ier=r(xBe," \u2014 "),pQ=n(xBe,"A",{href:!0});var p3t=s(pQ);qer=r(p3t,"ConvBertForQuestionAnswering"),p3t.forEach(t),jer=r(xBe," (ConvBERT model)"),xBe.forEach(t),Der=i(X),Ev=n(X,"LI",{});var $Be=s(Ev);D2e=n($Be,"STRONG",{});var _3t=s(D2e);Ger=r(_3t,"data2vec-text"),_3t.forEach(t),Oer=r($Be," \u2014 "),_Q=n($Be,"A",{href:!0});var u3t=s(_Q);Ver=r(u3t,"Data2VecTextForQuestionAnswering"),u3t.forEach(t),Xer=r($Be," (Data2VecText model)"),$Be.forEach(t),zer=i(X),Cv=n(X,"LI",{});var kBe=s(Cv);G2e=n(kBe,"STRONG",{});var b3t=s(G2e);Qer=r(b3t,"deberta"),b3t.forEach(t),Wer=r(kBe," \u2014 "),uQ=n(kBe,"A",{href:!0});var v3t=s(uQ);Her=r(v3t,"DebertaForQuestionAnswering"),v3t.forEach(t),Uer=r(kBe," (DeBERTa model)"),kBe.forEach(t),Jer=i(X),wv=n(X,"LI",{});var SBe=s(wv);O2e=n(SBe,"STRONG",{});var F3t=s(O2e);Yer=r(F3t,"deberta-v2"),F3t.forEach(t),Ker=r(SBe," \u2014 "),bQ=n(SBe,"A",{href:!0});var T3t=s(bQ);Zer=r(T3t,"DebertaV2ForQuestionAnswering"),T3t.forEach(t),eor=r(SBe," (DeBERTa-v2 model)"),SBe.forEach(t),oor=i(X),Av=n(X,"LI",{});var RBe=s(Av);V2e=n(RBe,"STRONG",{});var M3t=s(V2e);ror=r(M3t,"distilbert"),M3t.forEach(t),tor=r(RBe," \u2014 "),vQ=n(RBe,"A",{href:!0});var E3t=s(vQ);aor=r(E3t,"DistilBertForQuestionAnswering"),E3t.forEach(t),nor=r(RBe," (DistilBERT model)"),RBe.forEach(t),sor=i(X),Lv=n(X,"LI",{});var PBe=s(Lv);X2e=n(PBe,"STRONG",{});var C3t=s(X2e);lor=r(C3t,"electra"),C3t.forEach(t),ior=r(PBe," \u2014 "),FQ=n(PBe,"A",{href:!0});var w3t=s(FQ);dor=r(w3t,"ElectraForQuestionAnswering"),w3t.forEach(t),cor=r(PBe," (ELECTRA model)"),PBe.forEach(t),mor=i(X),yv=n(X,"LI",{});var BBe=s(yv);z2e=n(BBe,"STRONG",{});var A3t=s(z2e);gor=r(A3t,"flaubert"),A3t.forEach(t),hor=r(BBe," \u2014 "),TQ=n(BBe,"A",{href:!0});var L3t=s(TQ);por=r(L3t,"FlaubertForQuestionAnsweringSimple"),L3t.forEach(t),_or=r(BBe," (FlauBERT model)"),BBe.forEach(t),uor=i(X),xv=n(X,"LI",{});var NBe=s(xv);Q2e=n(NBe,"STRONG",{});var y3t=s(Q2e);bor=r(y3t,"fnet"),y3t.forEach(t),vor=r(NBe," \u2014 "),MQ=n(NBe,"A",{href:!0});var x3t=s(MQ);For=r(x3t,"FNetForQuestionAnswering"),x3t.forEach(t),Tor=r(NBe," (FNet model)"),NBe.forEach(t),Mor=i(X),$v=n(X,"LI",{});var IBe=s($v);W2e=n(IBe,"STRONG",{});var $3t=s(W2e);Eor=r($3t,"funnel"),$3t.forEach(t),Cor=r(IBe," \u2014 "),EQ=n(IBe,"A",{href:!0});var k3t=s(EQ);wor=r(k3t,"FunnelForQuestionAnswering"),k3t.forEach(t),Aor=r(IBe," (Funnel Transformer model)"),IBe.forEach(t),Lor=i(X),kv=n(X,"LI",{});var qBe=s(kv);H2e=n(qBe,"STRONG",{});var S3t=s(H2e);yor=r(S3t,"gptj"),S3t.forEach(t),xor=r(qBe," \u2014 "),CQ=n(qBe,"A",{href:!0});var R3t=s(CQ);$or=r(R3t,"GPTJForQuestionAnswering"),R3t.forEach(t),kor=r(qBe," (GPT-J model)"),qBe.forEach(t),Sor=i(X),Sv=n(X,"LI",{});var jBe=s(Sv);U2e=n(jBe,"STRONG",{});var P3t=s(U2e);Ror=r(P3t,"ibert"),P3t.forEach(t),Por=r(jBe," \u2014 "),wQ=n(jBe,"A",{href:!0});var B3t=s(wQ);Bor=r(B3t,"IBertForQuestionAnswering"),B3t.forEach(t),Nor=r(jBe," (I-BERT model)"),jBe.forEach(t),Ior=i(X),Rv=n(X,"LI",{});var DBe=s(Rv);J2e=n(DBe,"STRONG",{});var N3t=s(J2e);qor=r(N3t,"layoutlmv2"),N3t.forEach(t),jor=r(DBe," \u2014 "),AQ=n(DBe,"A",{href:!0});var I3t=s(AQ);Dor=r(I3t,"LayoutLMv2ForQuestionAnswering"),I3t.forEach(t),Gor=r(DBe," (LayoutLMv2 model)"),DBe.forEach(t),Oor=i(X),Pv=n(X,"LI",{});var GBe=s(Pv);Y2e=n(GBe,"STRONG",{});var q3t=s(Y2e);Vor=r(q3t,"layoutlmv3"),q3t.forEach(t),Xor=r(GBe," \u2014 "),LQ=n(GBe,"A",{href:!0});var j3t=s(LQ);zor=r(j3t,"LayoutLMv3ForQuestionAnswering"),j3t.forEach(t),Qor=r(GBe," (LayoutLMv3 model)"),GBe.forEach(t),Wor=i(X),Bv=n(X,"LI",{});var OBe=s(Bv);K2e=n(OBe,"STRONG",{});var D3t=s(K2e);Hor=r(D3t,"led"),D3t.forEach(t),Uor=r(OBe," \u2014 "),yQ=n(OBe,"A",{href:!0});var G3t=s(yQ);Jor=r(G3t,"LEDForQuestionAnswering"),G3t.forEach(t),Yor=r(OBe," (LED model)"),OBe.forEach(t),Kor=i(X),Nv=n(X,"LI",{});var VBe=s(Nv);Z2e=n(VBe,"STRONG",{});var O3t=s(Z2e);Zor=r(O3t,"longformer"),O3t.forEach(t),err=r(VBe," \u2014 "),xQ=n(VBe,"A",{href:!0});var V3t=s(xQ);orr=r(V3t,"LongformerForQuestionAnswering"),V3t.forEach(t),rrr=r(VBe," (Longformer model)"),VBe.forEach(t),trr=i(X),Iv=n(X,"LI",{});var XBe=s(Iv);e1e=n(XBe,"STRONG",{});var X3t=s(e1e);arr=r(X3t,"lxmert"),X3t.forEach(t),nrr=r(XBe," \u2014 "),$Q=n(XBe,"A",{href:!0});var z3t=s($Q);srr=r(z3t,"LxmertForQuestionAnswering"),z3t.forEach(t),lrr=r(XBe," (LXMERT model)"),XBe.forEach(t),irr=i(X),qv=n(X,"LI",{});var zBe=s(qv);o1e=n(zBe,"STRONG",{});var Q3t=s(o1e);drr=r(Q3t,"mbart"),Q3t.forEach(t),crr=r(zBe," \u2014 "),kQ=n(zBe,"A",{href:!0});var W3t=s(kQ);frr=r(W3t,"MBartForQuestionAnswering"),W3t.forEach(t),mrr=r(zBe," (mBART model)"),zBe.forEach(t),grr=i(X),jv=n(X,"LI",{});var QBe=s(jv);r1e=n(QBe,"STRONG",{});var H3t=s(r1e);hrr=r(H3t,"megatron-bert"),H3t.forEach(t),prr=r(QBe," \u2014 "),SQ=n(QBe,"A",{href:!0});var U3t=s(SQ);_rr=r(U3t,"MegatronBertForQuestionAnswering"),U3t.forEach(t),urr=r(QBe," (Megatron-BERT model)"),QBe.forEach(t),brr=i(X),Dv=n(X,"LI",{});var WBe=s(Dv);t1e=n(WBe,"STRONG",{});var J3t=s(t1e);vrr=r(J3t,"mobilebert"),J3t.forEach(t),Frr=r(WBe," \u2014 "),RQ=n(WBe,"A",{href:!0});var Y3t=s(RQ);Trr=r(Y3t,"MobileBertForQuestionAnswering"),Y3t.forEach(t),Mrr=r(WBe," (MobileBERT model)"),WBe.forEach(t),Err=i(X),Gv=n(X,"LI",{});var HBe=s(Gv);a1e=n(HBe,"STRONG",{});var K3t=s(a1e);Crr=r(K3t,"mpnet"),K3t.forEach(t),wrr=r(HBe," \u2014 "),PQ=n(HBe,"A",{href:!0});var Z3t=s(PQ);Arr=r(Z3t,"MPNetForQuestionAnswering"),Z3t.forEach(t),Lrr=r(HBe," (MPNet model)"),HBe.forEach(t),yrr=i(X),Ov=n(X,"LI",{});var UBe=s(Ov);n1e=n(UBe,"STRONG",{});var e5t=s(n1e);xrr=r(e5t,"mvp"),e5t.forEach(t),$rr=r(UBe," \u2014 "),BQ=n(UBe,"A",{href:!0});var o5t=s(BQ);krr=r(o5t,"MvpForQuestionAnswering"),o5t.forEach(t),Srr=r(UBe," (MVP model)"),UBe.forEach(t),Rrr=i(X),Vv=n(X,"LI",{});var JBe=s(Vv);s1e=n(JBe,"STRONG",{});var r5t=s(s1e);Prr=r(r5t,"nezha"),r5t.forEach(t),Brr=r(JBe," \u2014 "),NQ=n(JBe,"A",{href:!0});var t5t=s(NQ);Nrr=r(t5t,"NezhaForQuestionAnswering"),t5t.forEach(t),Irr=r(JBe," (Nezha model)"),JBe.forEach(t),qrr=i(X),Xv=n(X,"LI",{});var YBe=s(Xv);l1e=n(YBe,"STRONG",{});var a5t=s(l1e);jrr=r(a5t,"nystromformer"),a5t.forEach(t),Drr=r(YBe," \u2014 "),IQ=n(YBe,"A",{href:!0});var n5t=s(IQ);Grr=r(n5t,"NystromformerForQuestionAnswering"),n5t.forEach(t),Orr=r(YBe," (Nystr\xF6mformer model)"),YBe.forEach(t),Vrr=i(X),zv=n(X,"LI",{});var KBe=s(zv);i1e=n(KBe,"STRONG",{});var s5t=s(i1e);Xrr=r(s5t,"qdqbert"),s5t.forEach(t),zrr=r(KBe," \u2014 "),qQ=n(KBe,"A",{href:!0});var l5t=s(qQ);Qrr=r(l5t,"QDQBertForQuestionAnswering"),l5t.forEach(t),Wrr=r(KBe," (QDQBert model)"),KBe.forEach(t),Hrr=i(X),Qv=n(X,"LI",{});var ZBe=s(Qv);d1e=n(ZBe,"STRONG",{});var i5t=s(d1e);Urr=r(i5t,"reformer"),i5t.forEach(t),Jrr=r(ZBe," \u2014 "),jQ=n(ZBe,"A",{href:!0});var d5t=s(jQ);Yrr=r(d5t,"ReformerForQuestionAnswering"),d5t.forEach(t),Krr=r(ZBe," (Reformer model)"),ZBe.forEach(t),Zrr=i(X),Wv=n(X,"LI",{});var eNe=s(Wv);c1e=n(eNe,"STRONG",{});var c5t=s(c1e);etr=r(c5t,"rembert"),c5t.forEach(t),otr=r(eNe," \u2014 "),DQ=n(eNe,"A",{href:!0});var f5t=s(DQ);rtr=r(f5t,"RemBertForQuestionAnswering"),f5t.forEach(t),ttr=r(eNe," (RemBERT model)"),eNe.forEach(t),atr=i(X),Hv=n(X,"LI",{});var oNe=s(Hv);f1e=n(oNe,"STRONG",{});var m5t=s(f1e);ntr=r(m5t,"roberta"),m5t.forEach(t),str=r(oNe," \u2014 "),GQ=n(oNe,"A",{href:!0});var g5t=s(GQ);ltr=r(g5t,"RobertaForQuestionAnswering"),g5t.forEach(t),itr=r(oNe," (RoBERTa model)"),oNe.forEach(t),dtr=i(X),Uv=n(X,"LI",{});var rNe=s(Uv);m1e=n(rNe,"STRONG",{});var h5t=s(m1e);ctr=r(h5t,"roformer"),h5t.forEach(t),ftr=r(rNe," \u2014 "),OQ=n(rNe,"A",{href:!0});var p5t=s(OQ);mtr=r(p5t,"RoFormerForQuestionAnswering"),p5t.forEach(t),gtr=r(rNe," (RoFormer model)"),rNe.forEach(t),htr=i(X),Jv=n(X,"LI",{});var tNe=s(Jv);g1e=n(tNe,"STRONG",{});var _5t=s(g1e);ptr=r(_5t,"splinter"),_5t.forEach(t),_tr=r(tNe," \u2014 "),VQ=n(tNe,"A",{href:!0});var u5t=s(VQ);utr=r(u5t,"SplinterForQuestionAnswering"),u5t.forEach(t),btr=r(tNe," (Splinter model)"),tNe.forEach(t),vtr=i(X),Yv=n(X,"LI",{});var aNe=s(Yv);h1e=n(aNe,"STRONG",{});var b5t=s(h1e);Ftr=r(b5t,"squeezebert"),b5t.forEach(t),Ttr=r(aNe," \u2014 "),XQ=n(aNe,"A",{href:!0});var v5t=s(XQ);Mtr=r(v5t,"SqueezeBertForQuestionAnswering"),v5t.forEach(t),Etr=r(aNe," (SqueezeBERT model)"),aNe.forEach(t),Ctr=i(X),Kv=n(X,"LI",{});var nNe=s(Kv);p1e=n(nNe,"STRONG",{});var F5t=s(p1e);wtr=r(F5t,"xlm"),F5t.forEach(t),Atr=r(nNe," \u2014 "),zQ=n(nNe,"A",{href:!0});var T5t=s(zQ);Ltr=r(T5t,"XLMForQuestionAnsweringSimple"),T5t.forEach(t),ytr=r(nNe," (XLM model)"),nNe.forEach(t),xtr=i(X),Zv=n(X,"LI",{});var sNe=s(Zv);_1e=n(sNe,"STRONG",{});var M5t=s(_1e);$tr=r(M5t,"xlm-roberta"),M5t.forEach(t),ktr=r(sNe," \u2014 "),QQ=n(sNe,"A",{href:!0});var E5t=s(QQ);Str=r(E5t,"XLMRobertaForQuestionAnswering"),E5t.forEach(t),Rtr=r(sNe," (XLM-RoBERTa model)"),sNe.forEach(t),Ptr=i(X),eF=n(X,"LI",{});var lNe=s(eF);u1e=n(lNe,"STRONG",{});var C5t=s(u1e);Btr=r(C5t,"xlm-roberta-xl"),C5t.forEach(t),Ntr=r(lNe," \u2014 "),WQ=n(lNe,"A",{href:!0});var w5t=s(WQ);Itr=r(w5t,"XLMRobertaXLForQuestionAnswering"),w5t.forEach(t),qtr=r(lNe," (XLM-RoBERTa-XL model)"),lNe.forEach(t),jtr=i(X),oF=n(X,"LI",{});var iNe=s(oF);b1e=n(iNe,"STRONG",{});var A5t=s(b1e);Dtr=r(A5t,"xlnet"),A5t.forEach(t),Gtr=r(iNe," \u2014 "),HQ=n(iNe,"A",{href:!0});var L5t=s(HQ);Otr=r(L5t,"XLNetForQuestionAnsweringSimple"),L5t.forEach(t),Vtr=r(iNe," (XLNet model)"),iNe.forEach(t),Xtr=i(X),rF=n(X,"LI",{});var dNe=s(rF);v1e=n(dNe,"STRONG",{});var y5t=s(v1e);ztr=r(y5t,"yoso"),y5t.forEach(t),Qtr=r(dNe," \u2014 "),UQ=n(dNe,"A",{href:!0});var x5t=s(UQ);Wtr=r(x5t,"YosoForQuestionAnswering"),x5t.forEach(t),Htr=r(dNe," (YOSO model)"),dNe.forEach(t),X.forEach(t),Utr=i(pa),tF=n(pa,"P",{});var cNe=s(tF);Jtr=r(cNe,"The model is set in evaluation mode by default using "),F1e=n(cNe,"CODE",{});var $5t=s(F1e);Ytr=r($5t,"model.eval()"),$5t.forEach(t),Ktr=r(cNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T1e=n(cNe,"CODE",{});var k5t=s(T1e);Ztr=r(k5t,"model.train()"),k5t.forEach(t),cNe.forEach(t),ear=i(pa),T(aF.$$.fragment,pa),pa.forEach(t),cl.forEach(t),oXe=i(f),pd=n(f,"H2",{class:!0});var lQe=s(pd);nF=n(lQe,"A",{id:!0,class:!0,href:!0});var S5t=s(nF);M1e=n(S5t,"SPAN",{});var R5t=s(M1e);T(v8.$$.fragment,R5t),R5t.forEach(t),S5t.forEach(t),oar=i(lQe),E1e=n(lQe,"SPAN",{});var P5t=s(E1e);rar=r(P5t,"AutoModelForTableQuestionAnswering"),P5t.forEach(t),lQe.forEach(t),rXe=i(f),Do=n(f,"DIV",{class:!0});var fl=s(Do);T(F8.$$.fragment,fl),tar=i(fl),_d=n(fl,"P",{});var Bre=s(_d);aar=r(Bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),JQ=n(Bre,"A",{href:!0});var B5t=s(JQ);nar=r(B5t,"from_pretrained()"),B5t.forEach(t),sar=r(Bre," class method or the "),YQ=n(Bre,"A",{href:!0});var N5t=s(YQ);lar=r(N5t,"from_config()"),N5t.forEach(t),iar=r(Bre,` class
method.`),Bre.forEach(t),dar=i(fl),T8=n(fl,"P",{});var iQe=s(T8);car=r(iQe,"This class cannot be instantiated directly using "),C1e=n(iQe,"CODE",{});var I5t=s(C1e);far=r(I5t,"__init__()"),I5t.forEach(t),mar=r(iQe," (throws an error)."),iQe.forEach(t),gar=i(fl),_t=n(fl,"DIV",{class:!0});var F6=s(_t);T(M8.$$.fragment,F6),har=i(F6),w1e=n(F6,"P",{});var q5t=s(w1e);par=r(q5t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),q5t.forEach(t),_ar=i(F6),ud=n(F6,"P",{});var Nre=s(ud);uar=r(Nre,`Note:
Loading a model from its configuration file does `),A1e=n(Nre,"STRONG",{});var j5t=s(A1e);bar=r(j5t,"not"),j5t.forEach(t),Far=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=n(Nre,"A",{href:!0});var D5t=s(KQ);Tar=r(D5t,"from_pretrained()"),D5t.forEach(t),Mar=r(Nre," to load the model weights."),Nre.forEach(t),Ear=i(F6),T(sF.$$.fragment,F6),F6.forEach(t),Car=i(fl),so=n(fl,"DIV",{class:!0});var _a=s(so);T(E8.$$.fragment,_a),war=i(_a),L1e=n(_a,"P",{});var G5t=s(L1e);Aar=r(G5t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),G5t.forEach(t),Lar=i(_a),za=n(_a,"P",{});var T6=s(za);yar=r(T6,"The model class to instantiate is selected based on the "),y1e=n(T6,"CODE",{});var O5t=s(y1e);xar=r(O5t,"model_type"),O5t.forEach(t),$ar=r(T6,` property of the config object (either
passed as an argument or loaded from `),x1e=n(T6,"CODE",{});var V5t=s(x1e);kar=r(V5t,"pretrained_model_name_or_path"),V5t.forEach(t),Sar=r(T6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$1e=n(T6,"CODE",{});var X5t=s($1e);Rar=r(X5t,"pretrained_model_name_or_path"),X5t.forEach(t),Par=r(T6,":"),T6.forEach(t),Bar=i(_a),k1e=n(_a,"UL",{});var z5t=s(k1e);lF=n(z5t,"LI",{});var fNe=s(lF);S1e=n(fNe,"STRONG",{});var Q5t=s(S1e);Nar=r(Q5t,"tapas"),Q5t.forEach(t),Iar=r(fNe," \u2014 "),ZQ=n(fNe,"A",{href:!0});var W5t=s(ZQ);qar=r(W5t,"TapasForQuestionAnswering"),W5t.forEach(t),jar=r(fNe," (TAPAS model)"),fNe.forEach(t),z5t.forEach(t),Dar=i(_a),iF=n(_a,"P",{});var mNe=s(iF);Gar=r(mNe,"The model is set in evaluation mode by default using "),R1e=n(mNe,"CODE",{});var H5t=s(R1e);Oar=r(H5t,"model.eval()"),H5t.forEach(t),Var=r(mNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P1e=n(mNe,"CODE",{});var U5t=s(P1e);Xar=r(U5t,"model.train()"),U5t.forEach(t),mNe.forEach(t),zar=i(_a),T(dF.$$.fragment,_a),_a.forEach(t),fl.forEach(t),tXe=i(f),bd=n(f,"H2",{class:!0});var dQe=s(bd);cF=n(dQe,"A",{id:!0,class:!0,href:!0});var J5t=s(cF);B1e=n(J5t,"SPAN",{});var Y5t=s(B1e);T(C8.$$.fragment,Y5t),Y5t.forEach(t),J5t.forEach(t),Qar=i(dQe),N1e=n(dQe,"SPAN",{});var K5t=s(N1e);War=r(K5t,"AutoModelForImageClassification"),K5t.forEach(t),dQe.forEach(t),aXe=i(f),Go=n(f,"DIV",{class:!0});var ml=s(Go);T(w8.$$.fragment,ml),Har=i(ml),vd=n(ml,"P",{});var Ire=s(vd);Uar=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eW=n(Ire,"A",{href:!0});var Z5t=s(eW);Jar=r(Z5t,"from_pretrained()"),Z5t.forEach(t),Yar=r(Ire," class method or the "),oW=n(Ire,"A",{href:!0});var e0t=s(oW);Kar=r(e0t,"from_config()"),e0t.forEach(t),Zar=r(Ire,` class
method.`),Ire.forEach(t),enr=i(ml),A8=n(ml,"P",{});var cQe=s(A8);onr=r(cQe,"This class cannot be instantiated directly using "),I1e=n(cQe,"CODE",{});var o0t=s(I1e);rnr=r(o0t,"__init__()"),o0t.forEach(t),tnr=r(cQe," (throws an error)."),cQe.forEach(t),anr=i(ml),ut=n(ml,"DIV",{class:!0});var M6=s(ut);T(L8.$$.fragment,M6),nnr=i(M6),q1e=n(M6,"P",{});var r0t=s(q1e);snr=r(r0t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),r0t.forEach(t),lnr=i(M6),Fd=n(M6,"P",{});var qre=s(Fd);inr=r(qre,`Note:
Loading a model from its configuration file does `),j1e=n(qre,"STRONG",{});var t0t=s(j1e);dnr=r(t0t,"not"),t0t.forEach(t),cnr=r(qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(qre,"A",{href:!0});var a0t=s(rW);fnr=r(a0t,"from_pretrained()"),a0t.forEach(t),mnr=r(qre," to load the model weights."),qre.forEach(t),gnr=i(M6),T(fF.$$.fragment,M6),M6.forEach(t),hnr=i(ml),lo=n(ml,"DIV",{class:!0});var ua=s(lo);T(y8.$$.fragment,ua),pnr=i(ua),D1e=n(ua,"P",{});var n0t=s(D1e);_nr=r(n0t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),n0t.forEach(t),unr=i(ua),Qa=n(ua,"P",{});var E6=s(Qa);bnr=r(E6,"The model class to instantiate is selected based on the "),G1e=n(E6,"CODE",{});var s0t=s(G1e);vnr=r(s0t,"model_type"),s0t.forEach(t),Fnr=r(E6,` property of the config object (either
passed as an argument or loaded from `),O1e=n(E6,"CODE",{});var l0t=s(O1e);Tnr=r(l0t,"pretrained_model_name_or_path"),l0t.forEach(t),Mnr=r(E6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V1e=n(E6,"CODE",{});var i0t=s(V1e);Enr=r(i0t,"pretrained_model_name_or_path"),i0t.forEach(t),Cnr=r(E6,":"),E6.forEach(t),wnr=i(ua),Fe=n(ua,"UL",{});var Te=s(Fe);mF=n(Te,"LI",{});var gNe=s(mF);X1e=n(gNe,"STRONG",{});var d0t=s(X1e);Anr=r(d0t,"beit"),d0t.forEach(t),Lnr=r(gNe," \u2014 "),tW=n(gNe,"A",{href:!0});var c0t=s(tW);ynr=r(c0t,"BeitForImageClassification"),c0t.forEach(t),xnr=r(gNe," (BEiT model)"),gNe.forEach(t),$nr=i(Te),gF=n(Te,"LI",{});var hNe=s(gF);z1e=n(hNe,"STRONG",{});var f0t=s(z1e);knr=r(f0t,"convnext"),f0t.forEach(t),Snr=r(hNe," \u2014 "),aW=n(hNe,"A",{href:!0});var m0t=s(aW);Rnr=r(m0t,"ConvNextForImageClassification"),m0t.forEach(t),Pnr=r(hNe," (ConvNeXT model)"),hNe.forEach(t),Bnr=i(Te),hF=n(Te,"LI",{});var pNe=s(hF);Q1e=n(pNe,"STRONG",{});var g0t=s(Q1e);Nnr=r(g0t,"cvt"),g0t.forEach(t),Inr=r(pNe," \u2014 "),nW=n(pNe,"A",{href:!0});var h0t=s(nW);qnr=r(h0t,"CvtForImageClassification"),h0t.forEach(t),jnr=r(pNe," (CvT model)"),pNe.forEach(t),Dnr=i(Te),pF=n(Te,"LI",{});var _Ne=s(pF);W1e=n(_Ne,"STRONG",{});var p0t=s(W1e);Gnr=r(p0t,"data2vec-vision"),p0t.forEach(t),Onr=r(_Ne," \u2014 "),sW=n(_Ne,"A",{href:!0});var _0t=s(sW);Vnr=r(_0t,"Data2VecVisionForImageClassification"),_0t.forEach(t),Xnr=r(_Ne," (Data2VecVision model)"),_Ne.forEach(t),znr=i(Te),Hs=n(Te,"LI",{});var CS=s(Hs);H1e=n(CS,"STRONG",{});var u0t=s(H1e);Qnr=r(u0t,"deit"),u0t.forEach(t),Wnr=r(CS," \u2014 "),lW=n(CS,"A",{href:!0});var b0t=s(lW);Hnr=r(b0t,"DeiTForImageClassification"),b0t.forEach(t),Unr=r(CS," or "),iW=n(CS,"A",{href:!0});var v0t=s(iW);Jnr=r(v0t,"DeiTForImageClassificationWithTeacher"),v0t.forEach(t),Ynr=r(CS," (DeiT model)"),CS.forEach(t),Knr=i(Te),_F=n(Te,"LI",{});var uNe=s(_F);U1e=n(uNe,"STRONG",{});var F0t=s(U1e);Znr=r(F0t,"imagegpt"),F0t.forEach(t),esr=r(uNe," \u2014 "),dW=n(uNe,"A",{href:!0});var T0t=s(dW);osr=r(T0t,"ImageGPTForImageClassification"),T0t.forEach(t),rsr=r(uNe," (ImageGPT model)"),uNe.forEach(t),tsr=i(Te),Us=n(Te,"LI",{});var wS=s(Us);J1e=n(wS,"STRONG",{});var M0t=s(J1e);asr=r(M0t,"levit"),M0t.forEach(t),nsr=r(wS," \u2014 "),cW=n(wS,"A",{href:!0});var E0t=s(cW);ssr=r(E0t,"LevitForImageClassification"),E0t.forEach(t),lsr=r(wS," or "),fW=n(wS,"A",{href:!0});var C0t=s(fW);isr=r(C0t,"LevitForImageClassificationWithTeacher"),C0t.forEach(t),dsr=r(wS," (LeViT model)"),wS.forEach(t),csr=i(Te),bt=n(Te,"LI",{});var kf=s(bt);Y1e=n(kf,"STRONG",{});var w0t=s(Y1e);fsr=r(w0t,"perceiver"),w0t.forEach(t),msr=r(kf," \u2014 "),mW=n(kf,"A",{href:!0});var A0t=s(mW);gsr=r(A0t,"PerceiverForImageClassificationLearned"),A0t.forEach(t),hsr=r(kf," or "),gW=n(kf,"A",{href:!0});var L0t=s(gW);psr=r(L0t,"PerceiverForImageClassificationFourier"),L0t.forEach(t),_sr=r(kf," or "),hW=n(kf,"A",{href:!0});var y0t=s(hW);usr=r(y0t,"PerceiverForImageClassificationConvProcessing"),y0t.forEach(t),bsr=r(kf," (Perceiver model)"),kf.forEach(t),vsr=i(Te),uF=n(Te,"LI",{});var bNe=s(uF);K1e=n(bNe,"STRONG",{});var x0t=s(K1e);Fsr=r(x0t,"poolformer"),x0t.forEach(t),Tsr=r(bNe," \u2014 "),pW=n(bNe,"A",{href:!0});var $0t=s(pW);Msr=r($0t,"PoolFormerForImageClassification"),$0t.forEach(t),Esr=r(bNe," (PoolFormer model)"),bNe.forEach(t),Csr=i(Te),bF=n(Te,"LI",{});var vNe=s(bF);Z1e=n(vNe,"STRONG",{});var k0t=s(Z1e);wsr=r(k0t,"regnet"),k0t.forEach(t),Asr=r(vNe," \u2014 "),_W=n(vNe,"A",{href:!0});var S0t=s(_W);Lsr=r(S0t,"RegNetForImageClassification"),S0t.forEach(t),ysr=r(vNe," (RegNet model)"),vNe.forEach(t),xsr=i(Te),vF=n(Te,"LI",{});var FNe=s(vF);e7e=n(FNe,"STRONG",{});var R0t=s(e7e);$sr=r(R0t,"resnet"),R0t.forEach(t),ksr=r(FNe," \u2014 "),uW=n(FNe,"A",{href:!0});var P0t=s(uW);Ssr=r(P0t,"ResNetForImageClassification"),P0t.forEach(t),Rsr=r(FNe," (ResNet model)"),FNe.forEach(t),Psr=i(Te),FF=n(Te,"LI",{});var TNe=s(FF);o7e=n(TNe,"STRONG",{});var B0t=s(o7e);Bsr=r(B0t,"segformer"),B0t.forEach(t),Nsr=r(TNe," \u2014 "),bW=n(TNe,"A",{href:!0});var N0t=s(bW);Isr=r(N0t,"SegformerForImageClassification"),N0t.forEach(t),qsr=r(TNe," (SegFormer model)"),TNe.forEach(t),jsr=i(Te),TF=n(Te,"LI",{});var MNe=s(TF);r7e=n(MNe,"STRONG",{});var I0t=s(r7e);Dsr=r(I0t,"swin"),I0t.forEach(t),Gsr=r(MNe," \u2014 "),vW=n(MNe,"A",{href:!0});var q0t=s(vW);Osr=r(q0t,"SwinForImageClassification"),q0t.forEach(t),Vsr=r(MNe," (Swin Transformer model)"),MNe.forEach(t),Xsr=i(Te),MF=n(Te,"LI",{});var ENe=s(MF);t7e=n(ENe,"STRONG",{});var j0t=s(t7e);zsr=r(j0t,"van"),j0t.forEach(t),Qsr=r(ENe," \u2014 "),FW=n(ENe,"A",{href:!0});var D0t=s(FW);Wsr=r(D0t,"VanForImageClassification"),D0t.forEach(t),Hsr=r(ENe," (VAN model)"),ENe.forEach(t),Usr=i(Te),EF=n(Te,"LI",{});var CNe=s(EF);a7e=n(CNe,"STRONG",{});var G0t=s(a7e);Jsr=r(G0t,"vit"),G0t.forEach(t),Ysr=r(CNe," \u2014 "),TW=n(CNe,"A",{href:!0});var O0t=s(TW);Ksr=r(O0t,"ViTForImageClassification"),O0t.forEach(t),Zsr=r(CNe," (ViT model)"),CNe.forEach(t),Te.forEach(t),elr=i(ua),CF=n(ua,"P",{});var wNe=s(CF);olr=r(wNe,"The model is set in evaluation mode by default using "),n7e=n(wNe,"CODE",{});var V0t=s(n7e);rlr=r(V0t,"model.eval()"),V0t.forEach(t),tlr=r(wNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s7e=n(wNe,"CODE",{});var X0t=s(s7e);alr=r(X0t,"model.train()"),X0t.forEach(t),wNe.forEach(t),nlr=i(ua),T(wF.$$.fragment,ua),ua.forEach(t),ml.forEach(t),nXe=i(f),Td=n(f,"H2",{class:!0});var fQe=s(Td);AF=n(fQe,"A",{id:!0,class:!0,href:!0});var z0t=s(AF);l7e=n(z0t,"SPAN",{});var Q0t=s(l7e);T(x8.$$.fragment,Q0t),Q0t.forEach(t),z0t.forEach(t),slr=i(fQe),i7e=n(fQe,"SPAN",{});var W0t=s(i7e);llr=r(W0t,"AutoModelForVision2Seq"),W0t.forEach(t),fQe.forEach(t),sXe=i(f),Oo=n(f,"DIV",{class:!0});var gl=s(Oo);T($8.$$.fragment,gl),ilr=i(gl),Md=n(gl,"P",{});var jre=s(Md);dlr=r(jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),MW=n(jre,"A",{href:!0});var H0t=s(MW);clr=r(H0t,"from_pretrained()"),H0t.forEach(t),flr=r(jre," class method or the "),EW=n(jre,"A",{href:!0});var U0t=s(EW);mlr=r(U0t,"from_config()"),U0t.forEach(t),glr=r(jre,` class
method.`),jre.forEach(t),hlr=i(gl),k8=n(gl,"P",{});var mQe=s(k8);plr=r(mQe,"This class cannot be instantiated directly using "),d7e=n(mQe,"CODE",{});var J0t=s(d7e);_lr=r(J0t,"__init__()"),J0t.forEach(t),ulr=r(mQe," (throws an error)."),mQe.forEach(t),blr=i(gl),vt=n(gl,"DIV",{class:!0});var C6=s(vt);T(S8.$$.fragment,C6),vlr=i(C6),c7e=n(C6,"P",{});var Y0t=s(c7e);Flr=r(Y0t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Y0t.forEach(t),Tlr=i(C6),Ed=n(C6,"P",{});var Dre=s(Ed);Mlr=r(Dre,`Note:
Loading a model from its configuration file does `),f7e=n(Dre,"STRONG",{});var K0t=s(f7e);Elr=r(K0t,"not"),K0t.forEach(t),Clr=r(Dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(Dre,"A",{href:!0});var Z0t=s(CW);wlr=r(Z0t,"from_pretrained()"),Z0t.forEach(t),Alr=r(Dre," to load the model weights."),Dre.forEach(t),Llr=i(C6),T(LF.$$.fragment,C6),C6.forEach(t),ylr=i(gl),io=n(gl,"DIV",{class:!0});var ba=s(io);T(R8.$$.fragment,ba),xlr=i(ba),m7e=n(ba,"P",{});var ewt=s(m7e);$lr=r(ewt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ewt.forEach(t),klr=i(ba),Wa=n(ba,"P",{});var w6=s(Wa);Slr=r(w6,"The model class to instantiate is selected based on the "),g7e=n(w6,"CODE",{});var owt=s(g7e);Rlr=r(owt,"model_type"),owt.forEach(t),Plr=r(w6,` property of the config object (either
passed as an argument or loaded from `),h7e=n(w6,"CODE",{});var rwt=s(h7e);Blr=r(rwt,"pretrained_model_name_or_path"),rwt.forEach(t),Nlr=r(w6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p7e=n(w6,"CODE",{});var twt=s(p7e);Ilr=r(twt,"pretrained_model_name_or_path"),twt.forEach(t),qlr=r(w6,":"),w6.forEach(t),jlr=i(ba),_7e=n(ba,"UL",{});var awt=s(_7e);yF=n(awt,"LI",{});var ANe=s(yF);u7e=n(ANe,"STRONG",{});var nwt=s(u7e);Dlr=r(nwt,"vision-encoder-decoder"),nwt.forEach(t),Glr=r(ANe," \u2014 "),wW=n(ANe,"A",{href:!0});var swt=s(wW);Olr=r(swt,"VisionEncoderDecoderModel"),swt.forEach(t),Vlr=r(ANe," (Vision Encoder decoder model)"),ANe.forEach(t),awt.forEach(t),Xlr=i(ba),xF=n(ba,"P",{});var LNe=s(xF);zlr=r(LNe,"The model is set in evaluation mode by default using "),b7e=n(LNe,"CODE",{});var lwt=s(b7e);Qlr=r(lwt,"model.eval()"),lwt.forEach(t),Wlr=r(LNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v7e=n(LNe,"CODE",{});var iwt=s(v7e);Hlr=r(iwt,"model.train()"),iwt.forEach(t),LNe.forEach(t),Ulr=i(ba),T($F.$$.fragment,ba),ba.forEach(t),gl.forEach(t),lXe=i(f),Cd=n(f,"H2",{class:!0});var gQe=s(Cd);kF=n(gQe,"A",{id:!0,class:!0,href:!0});var dwt=s(kF);F7e=n(dwt,"SPAN",{});var cwt=s(F7e);T(P8.$$.fragment,cwt),cwt.forEach(t),dwt.forEach(t),Jlr=i(gQe),T7e=n(gQe,"SPAN",{});var fwt=s(T7e);Ylr=r(fwt,"AutoModelForVisualQuestionAnswering"),fwt.forEach(t),gQe.forEach(t),iXe=i(f),Vo=n(f,"DIV",{class:!0});var hl=s(Vo);T(B8.$$.fragment,hl),Klr=i(hl),wd=n(hl,"P",{});var Gre=s(wd);Zlr=r(Gre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),AW=n(Gre,"A",{href:!0});var mwt=s(AW);eir=r(mwt,"from_pretrained()"),mwt.forEach(t),oir=r(Gre," class method or the "),LW=n(Gre,"A",{href:!0});var gwt=s(LW);rir=r(gwt,"from_config()"),gwt.forEach(t),tir=r(Gre,` class
method.`),Gre.forEach(t),air=i(hl),N8=n(hl,"P",{});var hQe=s(N8);nir=r(hQe,"This class cannot be instantiated directly using "),M7e=n(hQe,"CODE",{});var hwt=s(M7e);sir=r(hwt,"__init__()"),hwt.forEach(t),lir=r(hQe," (throws an error)."),hQe.forEach(t),iir=i(hl),Ft=n(hl,"DIV",{class:!0});var A6=s(Ft);T(I8.$$.fragment,A6),dir=i(A6),E7e=n(A6,"P",{});var pwt=s(E7e);cir=r(pwt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),pwt.forEach(t),fir=i(A6),Ad=n(A6,"P",{});var Ore=s(Ad);mir=r(Ore,`Note:
Loading a model from its configuration file does `),C7e=n(Ore,"STRONG",{});var _wt=s(C7e);gir=r(_wt,"not"),_wt.forEach(t),hir=r(Ore,` load the model weights. It only affects the
model\u2019s configuration. Use `),yW=n(Ore,"A",{href:!0});var uwt=s(yW);pir=r(uwt,"from_pretrained()"),uwt.forEach(t),_ir=r(Ore," to load the model weights."),Ore.forEach(t),uir=i(A6),T(SF.$$.fragment,A6),A6.forEach(t),bir=i(hl),co=n(hl,"DIV",{class:!0});var va=s(co);T(q8.$$.fragment,va),vir=i(va),w7e=n(va,"P",{});var bwt=s(w7e);Fir=r(bwt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),bwt.forEach(t),Tir=i(va),Ha=n(va,"P",{});var L6=s(Ha);Mir=r(L6,"The model class to instantiate is selected based on the "),A7e=n(L6,"CODE",{});var vwt=s(A7e);Eir=r(vwt,"model_type"),vwt.forEach(t),Cir=r(L6,` property of the config object (either
passed as an argument or loaded from `),L7e=n(L6,"CODE",{});var Fwt=s(L7e);wir=r(Fwt,"pretrained_model_name_or_path"),Fwt.forEach(t),Air=r(L6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y7e=n(L6,"CODE",{});var Twt=s(y7e);Lir=r(Twt,"pretrained_model_name_or_path"),Twt.forEach(t),yir=r(L6,":"),L6.forEach(t),xir=i(va),x7e=n(va,"UL",{});var Mwt=s(x7e);RF=n(Mwt,"LI",{});var yNe=s(RF);$7e=n(yNe,"STRONG",{});var Ewt=s($7e);$ir=r(Ewt,"vilt"),Ewt.forEach(t),kir=r(yNe," \u2014 "),xW=n(yNe,"A",{href:!0});var Cwt=s(xW);Sir=r(Cwt,"ViltForQuestionAnswering"),Cwt.forEach(t),Rir=r(yNe," (ViLT model)"),yNe.forEach(t),Mwt.forEach(t),Pir=i(va),PF=n(va,"P",{});var xNe=s(PF);Bir=r(xNe,"The model is set in evaluation mode by default using "),k7e=n(xNe,"CODE",{});var wwt=s(k7e);Nir=r(wwt,"model.eval()"),wwt.forEach(t),Iir=r(xNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S7e=n(xNe,"CODE",{});var Awt=s(S7e);qir=r(Awt,"model.train()"),Awt.forEach(t),xNe.forEach(t),jir=i(va),T(BF.$$.fragment,va),va.forEach(t),hl.forEach(t),dXe=i(f),Ld=n(f,"H2",{class:!0});var pQe=s(Ld);NF=n(pQe,"A",{id:!0,class:!0,href:!0});var Lwt=s(NF);R7e=n(Lwt,"SPAN",{});var ywt=s(R7e);T(j8.$$.fragment,ywt),ywt.forEach(t),Lwt.forEach(t),Dir=i(pQe),P7e=n(pQe,"SPAN",{});var xwt=s(P7e);Gir=r(xwt,"AutoModelForAudioClassification"),xwt.forEach(t),pQe.forEach(t),cXe=i(f),Xo=n(f,"DIV",{class:!0});var pl=s(Xo);T(D8.$$.fragment,pl),Oir=i(pl),yd=n(pl,"P",{});var Vre=s(yd);Vir=r(Vre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),$W=n(Vre,"A",{href:!0});var $wt=s($W);Xir=r($wt,"from_pretrained()"),$wt.forEach(t),zir=r(Vre," class method or the "),kW=n(Vre,"A",{href:!0});var kwt=s(kW);Qir=r(kwt,"from_config()"),kwt.forEach(t),Wir=r(Vre,` class
method.`),Vre.forEach(t),Hir=i(pl),G8=n(pl,"P",{});var _Qe=s(G8);Uir=r(_Qe,"This class cannot be instantiated directly using "),B7e=n(_Qe,"CODE",{});var Swt=s(B7e);Jir=r(Swt,"__init__()"),Swt.forEach(t),Yir=r(_Qe," (throws an error)."),_Qe.forEach(t),Kir=i(pl),Tt=n(pl,"DIV",{class:!0});var y6=s(Tt);T(O8.$$.fragment,y6),Zir=i(y6),N7e=n(y6,"P",{});var Rwt=s(N7e);edr=r(Rwt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Rwt.forEach(t),odr=i(y6),xd=n(y6,"P",{});var Xre=s(xd);rdr=r(Xre,`Note:
Loading a model from its configuration file does `),I7e=n(Xre,"STRONG",{});var Pwt=s(I7e);tdr=r(Pwt,"not"),Pwt.forEach(t),adr=r(Xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(Xre,"A",{href:!0});var Bwt=s(SW);ndr=r(Bwt,"from_pretrained()"),Bwt.forEach(t),sdr=r(Xre," to load the model weights."),Xre.forEach(t),ldr=i(y6),T(IF.$$.fragment,y6),y6.forEach(t),idr=i(pl),fo=n(pl,"DIV",{class:!0});var Fa=s(fo);T(V8.$$.fragment,Fa),ddr=i(Fa),q7e=n(Fa,"P",{});var Nwt=s(q7e);cdr=r(Nwt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Nwt.forEach(t),fdr=i(Fa),Ua=n(Fa,"P",{});var x6=s(Ua);mdr=r(x6,"The model class to instantiate is selected based on the "),j7e=n(x6,"CODE",{});var Iwt=s(j7e);gdr=r(Iwt,"model_type"),Iwt.forEach(t),hdr=r(x6,` property of the config object (either
passed as an argument or loaded from `),D7e=n(x6,"CODE",{});var qwt=s(D7e);pdr=r(qwt,"pretrained_model_name_or_path"),qwt.forEach(t),_dr=r(x6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G7e=n(x6,"CODE",{});var jwt=s(G7e);udr=r(jwt,"pretrained_model_name_or_path"),jwt.forEach(t),bdr=r(x6,":"),x6.forEach(t),vdr=i(Fa),Pe=n(Fa,"UL",{});var ze=s(Pe);qF=n(ze,"LI",{});var $Ne=s(qF);O7e=n($Ne,"STRONG",{});var Dwt=s(O7e);Fdr=r(Dwt,"data2vec-audio"),Dwt.forEach(t),Tdr=r($Ne," \u2014 "),RW=n($Ne,"A",{href:!0});var Gwt=s(RW);Mdr=r(Gwt,"Data2VecAudioForSequenceClassification"),Gwt.forEach(t),Edr=r($Ne," (Data2VecAudio model)"),$Ne.forEach(t),Cdr=i(ze),jF=n(ze,"LI",{});var kNe=s(jF);V7e=n(kNe,"STRONG",{});var Owt=s(V7e);wdr=r(Owt,"hubert"),Owt.forEach(t),Adr=r(kNe," \u2014 "),PW=n(kNe,"A",{href:!0});var Vwt=s(PW);Ldr=r(Vwt,"HubertForSequenceClassification"),Vwt.forEach(t),ydr=r(kNe," (Hubert model)"),kNe.forEach(t),xdr=i(ze),DF=n(ze,"LI",{});var SNe=s(DF);X7e=n(SNe,"STRONG",{});var Xwt=s(X7e);$dr=r(Xwt,"sew"),Xwt.forEach(t),kdr=r(SNe," \u2014 "),BW=n(SNe,"A",{href:!0});var zwt=s(BW);Sdr=r(zwt,"SEWForSequenceClassification"),zwt.forEach(t),Rdr=r(SNe," (SEW model)"),SNe.forEach(t),Pdr=i(ze),GF=n(ze,"LI",{});var RNe=s(GF);z7e=n(RNe,"STRONG",{});var Qwt=s(z7e);Bdr=r(Qwt,"sew-d"),Qwt.forEach(t),Ndr=r(RNe," \u2014 "),NW=n(RNe,"A",{href:!0});var Wwt=s(NW);Idr=r(Wwt,"SEWDForSequenceClassification"),Wwt.forEach(t),qdr=r(RNe," (SEW-D model)"),RNe.forEach(t),jdr=i(ze),OF=n(ze,"LI",{});var PNe=s(OF);Q7e=n(PNe,"STRONG",{});var Hwt=s(Q7e);Ddr=r(Hwt,"unispeech"),Hwt.forEach(t),Gdr=r(PNe," \u2014 "),IW=n(PNe,"A",{href:!0});var Uwt=s(IW);Odr=r(Uwt,"UniSpeechForSequenceClassification"),Uwt.forEach(t),Vdr=r(PNe," (UniSpeech model)"),PNe.forEach(t),Xdr=i(ze),VF=n(ze,"LI",{});var BNe=s(VF);W7e=n(BNe,"STRONG",{});var Jwt=s(W7e);zdr=r(Jwt,"unispeech-sat"),Jwt.forEach(t),Qdr=r(BNe," \u2014 "),qW=n(BNe,"A",{href:!0});var Ywt=s(qW);Wdr=r(Ywt,"UniSpeechSatForSequenceClassification"),Ywt.forEach(t),Hdr=r(BNe," (UniSpeechSat model)"),BNe.forEach(t),Udr=i(ze),XF=n(ze,"LI",{});var NNe=s(XF);H7e=n(NNe,"STRONG",{});var Kwt=s(H7e);Jdr=r(Kwt,"wav2vec2"),Kwt.forEach(t),Ydr=r(NNe," \u2014 "),jW=n(NNe,"A",{href:!0});var Zwt=s(jW);Kdr=r(Zwt,"Wav2Vec2ForSequenceClassification"),Zwt.forEach(t),Zdr=r(NNe," (Wav2Vec2 model)"),NNe.forEach(t),ecr=i(ze),zF=n(ze,"LI",{});var INe=s(zF);U7e=n(INe,"STRONG",{});var eAt=s(U7e);ocr=r(eAt,"wav2vec2-conformer"),eAt.forEach(t),rcr=r(INe," \u2014 "),DW=n(INe,"A",{href:!0});var oAt=s(DW);tcr=r(oAt,"Wav2Vec2ConformerForSequenceClassification"),oAt.forEach(t),acr=r(INe," (Wav2Vec2-Conformer model)"),INe.forEach(t),ncr=i(ze),QF=n(ze,"LI",{});var qNe=s(QF);J7e=n(qNe,"STRONG",{});var rAt=s(J7e);scr=r(rAt,"wavlm"),rAt.forEach(t),lcr=r(qNe," \u2014 "),GW=n(qNe,"A",{href:!0});var tAt=s(GW);icr=r(tAt,"WavLMForSequenceClassification"),tAt.forEach(t),dcr=r(qNe," (WavLM model)"),qNe.forEach(t),ze.forEach(t),ccr=i(Fa),WF=n(Fa,"P",{});var jNe=s(WF);fcr=r(jNe,"The model is set in evaluation mode by default using "),Y7e=n(jNe,"CODE",{});var aAt=s(Y7e);mcr=r(aAt,"model.eval()"),aAt.forEach(t),gcr=r(jNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K7e=n(jNe,"CODE",{});var nAt=s(K7e);hcr=r(nAt,"model.train()"),nAt.forEach(t),jNe.forEach(t),pcr=i(Fa),T(HF.$$.fragment,Fa),Fa.forEach(t),pl.forEach(t),fXe=i(f),$d=n(f,"H2",{class:!0});var uQe=s($d);UF=n(uQe,"A",{id:!0,class:!0,href:!0});var sAt=s(UF);Z7e=n(sAt,"SPAN",{});var lAt=s(Z7e);T(X8.$$.fragment,lAt),lAt.forEach(t),sAt.forEach(t),_cr=i(uQe),e4e=n(uQe,"SPAN",{});var iAt=s(e4e);ucr=r(iAt,"AutoModelForAudioFrameClassification"),iAt.forEach(t),uQe.forEach(t),mXe=i(f),zo=n(f,"DIV",{class:!0});var _l=s(zo);T(z8.$$.fragment,_l),bcr=i(_l),kd=n(_l,"P",{});var zre=s(kd);vcr=r(zre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),OW=n(zre,"A",{href:!0});var dAt=s(OW);Fcr=r(dAt,"from_pretrained()"),dAt.forEach(t),Tcr=r(zre," class method or the "),VW=n(zre,"A",{href:!0});var cAt=s(VW);Mcr=r(cAt,"from_config()"),cAt.forEach(t),Ecr=r(zre,` class
method.`),zre.forEach(t),Ccr=i(_l),Q8=n(_l,"P",{});var bQe=s(Q8);wcr=r(bQe,"This class cannot be instantiated directly using "),o4e=n(bQe,"CODE",{});var fAt=s(o4e);Acr=r(fAt,"__init__()"),fAt.forEach(t),Lcr=r(bQe," (throws an error)."),bQe.forEach(t),ycr=i(_l),Mt=n(_l,"DIV",{class:!0});var $6=s(Mt);T(W8.$$.fragment,$6),xcr=i($6),r4e=n($6,"P",{});var mAt=s(r4e);$cr=r(mAt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),mAt.forEach(t),kcr=i($6),Sd=n($6,"P",{});var Qre=s(Sd);Scr=r(Qre,`Note:
Loading a model from its configuration file does `),t4e=n(Qre,"STRONG",{});var gAt=s(t4e);Rcr=r(gAt,"not"),gAt.forEach(t),Pcr=r(Qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),XW=n(Qre,"A",{href:!0});var hAt=s(XW);Bcr=r(hAt,"from_pretrained()"),hAt.forEach(t),Ncr=r(Qre," to load the model weights."),Qre.forEach(t),Icr=i($6),T(JF.$$.fragment,$6),$6.forEach(t),qcr=i(_l),mo=n(_l,"DIV",{class:!0});var Ta=s(mo);T(H8.$$.fragment,Ta),jcr=i(Ta),a4e=n(Ta,"P",{});var pAt=s(a4e);Dcr=r(pAt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),pAt.forEach(t),Gcr=i(Ta),Ja=n(Ta,"P",{});var k6=s(Ja);Ocr=r(k6,"The model class to instantiate is selected based on the "),n4e=n(k6,"CODE",{});var _At=s(n4e);Vcr=r(_At,"model_type"),_At.forEach(t),Xcr=r(k6,` property of the config object (either
passed as an argument or loaded from `),s4e=n(k6,"CODE",{});var uAt=s(s4e);zcr=r(uAt,"pretrained_model_name_or_path"),uAt.forEach(t),Qcr=r(k6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l4e=n(k6,"CODE",{});var bAt=s(l4e);Wcr=r(bAt,"pretrained_model_name_or_path"),bAt.forEach(t),Hcr=r(k6,":"),k6.forEach(t),Ucr=i(Ta),ot=n(Ta,"UL",{});var ul=s(ot);YF=n(ul,"LI",{});var DNe=s(YF);i4e=n(DNe,"STRONG",{});var vAt=s(i4e);Jcr=r(vAt,"data2vec-audio"),vAt.forEach(t),Ycr=r(DNe," \u2014 "),zW=n(DNe,"A",{href:!0});var FAt=s(zW);Kcr=r(FAt,"Data2VecAudioForAudioFrameClassification"),FAt.forEach(t),Zcr=r(DNe," (Data2VecAudio model)"),DNe.forEach(t),efr=i(ul),KF=n(ul,"LI",{});var GNe=s(KF);d4e=n(GNe,"STRONG",{});var TAt=s(d4e);ofr=r(TAt,"unispeech-sat"),TAt.forEach(t),rfr=r(GNe," \u2014 "),QW=n(GNe,"A",{href:!0});var MAt=s(QW);tfr=r(MAt,"UniSpeechSatForAudioFrameClassification"),MAt.forEach(t),afr=r(GNe," (UniSpeechSat model)"),GNe.forEach(t),nfr=i(ul),ZF=n(ul,"LI",{});var ONe=s(ZF);c4e=n(ONe,"STRONG",{});var EAt=s(c4e);sfr=r(EAt,"wav2vec2"),EAt.forEach(t),lfr=r(ONe," \u2014 "),WW=n(ONe,"A",{href:!0});var CAt=s(WW);ifr=r(CAt,"Wav2Vec2ForAudioFrameClassification"),CAt.forEach(t),dfr=r(ONe," (Wav2Vec2 model)"),ONe.forEach(t),cfr=i(ul),eT=n(ul,"LI",{});var VNe=s(eT);f4e=n(VNe,"STRONG",{});var wAt=s(f4e);ffr=r(wAt,"wav2vec2-conformer"),wAt.forEach(t),mfr=r(VNe," \u2014 "),HW=n(VNe,"A",{href:!0});var AAt=s(HW);gfr=r(AAt,"Wav2Vec2ConformerForAudioFrameClassification"),AAt.forEach(t),hfr=r(VNe," (Wav2Vec2-Conformer model)"),VNe.forEach(t),pfr=i(ul),oT=n(ul,"LI",{});var XNe=s(oT);m4e=n(XNe,"STRONG",{});var LAt=s(m4e);_fr=r(LAt,"wavlm"),LAt.forEach(t),ufr=r(XNe," \u2014 "),UW=n(XNe,"A",{href:!0});var yAt=s(UW);bfr=r(yAt,"WavLMForAudioFrameClassification"),yAt.forEach(t),vfr=r(XNe," (WavLM model)"),XNe.forEach(t),ul.forEach(t),Ffr=i(Ta),rT=n(Ta,"P",{});var zNe=s(rT);Tfr=r(zNe,"The model is set in evaluation mode by default using "),g4e=n(zNe,"CODE",{});var xAt=s(g4e);Mfr=r(xAt,"model.eval()"),xAt.forEach(t),Efr=r(zNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h4e=n(zNe,"CODE",{});var $At=s(h4e);Cfr=r($At,"model.train()"),$At.forEach(t),zNe.forEach(t),wfr=i(Ta),T(tT.$$.fragment,Ta),Ta.forEach(t),_l.forEach(t),gXe=i(f),Rd=n(f,"H2",{class:!0});var vQe=s(Rd);aT=n(vQe,"A",{id:!0,class:!0,href:!0});var kAt=s(aT);p4e=n(kAt,"SPAN",{});var SAt=s(p4e);T(U8.$$.fragment,SAt),SAt.forEach(t),kAt.forEach(t),Afr=i(vQe),_4e=n(vQe,"SPAN",{});var RAt=s(_4e);Lfr=r(RAt,"AutoModelForCTC"),RAt.forEach(t),vQe.forEach(t),hXe=i(f),Qo=n(f,"DIV",{class:!0});var bl=s(Qo);T(J8.$$.fragment,bl),yfr=i(bl),Pd=n(bl,"P",{});var Wre=s(Pd);xfr=r(Wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),JW=n(Wre,"A",{href:!0});var PAt=s(JW);$fr=r(PAt,"from_pretrained()"),PAt.forEach(t),kfr=r(Wre," class method or the "),YW=n(Wre,"A",{href:!0});var BAt=s(YW);Sfr=r(BAt,"from_config()"),BAt.forEach(t),Rfr=r(Wre,` class
method.`),Wre.forEach(t),Pfr=i(bl),Y8=n(bl,"P",{});var FQe=s(Y8);Bfr=r(FQe,"This class cannot be instantiated directly using "),u4e=n(FQe,"CODE",{});var NAt=s(u4e);Nfr=r(NAt,"__init__()"),NAt.forEach(t),Ifr=r(FQe," (throws an error)."),FQe.forEach(t),qfr=i(bl),Et=n(bl,"DIV",{class:!0});var S6=s(Et);T(K8.$$.fragment,S6),jfr=i(S6),b4e=n(S6,"P",{});var IAt=s(b4e);Dfr=r(IAt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),IAt.forEach(t),Gfr=i(S6),Bd=n(S6,"P",{});var Hre=s(Bd);Ofr=r(Hre,`Note:
Loading a model from its configuration file does `),v4e=n(Hre,"STRONG",{});var qAt=s(v4e);Vfr=r(qAt,"not"),qAt.forEach(t),Xfr=r(Hre,` load the model weights. It only affects the
model\u2019s configuration. Use `),KW=n(Hre,"A",{href:!0});var jAt=s(KW);zfr=r(jAt,"from_pretrained()"),jAt.forEach(t),Qfr=r(Hre," to load the model weights."),Hre.forEach(t),Wfr=i(S6),T(nT.$$.fragment,S6),S6.forEach(t),Hfr=i(bl),go=n(bl,"DIV",{class:!0});var Ma=s(go);T(Z8.$$.fragment,Ma),Ufr=i(Ma),F4e=n(Ma,"P",{});var DAt=s(F4e);Jfr=r(DAt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),DAt.forEach(t),Yfr=i(Ma),Ya=n(Ma,"P",{});var R6=s(Ya);Kfr=r(R6,"The model class to instantiate is selected based on the "),T4e=n(R6,"CODE",{});var GAt=s(T4e);Zfr=r(GAt,"model_type"),GAt.forEach(t),emr=r(R6,` property of the config object (either
passed as an argument or loaded from `),M4e=n(R6,"CODE",{});var OAt=s(M4e);omr=r(OAt,"pretrained_model_name_or_path"),OAt.forEach(t),rmr=r(R6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E4e=n(R6,"CODE",{});var VAt=s(E4e);tmr=r(VAt,"pretrained_model_name_or_path"),VAt.forEach(t),amr=r(R6,":"),R6.forEach(t),nmr=i(Ma),Le=n(Ma,"UL",{});var Be=s(Le);sT=n(Be,"LI",{});var QNe=s(sT);C4e=n(QNe,"STRONG",{});var XAt=s(C4e);smr=r(XAt,"data2vec-audio"),XAt.forEach(t),lmr=r(QNe," \u2014 "),ZW=n(QNe,"A",{href:!0});var zAt=s(ZW);imr=r(zAt,"Data2VecAudioForCTC"),zAt.forEach(t),dmr=r(QNe," (Data2VecAudio model)"),QNe.forEach(t),cmr=i(Be),lT=n(Be,"LI",{});var WNe=s(lT);w4e=n(WNe,"STRONG",{});var QAt=s(w4e);fmr=r(QAt,"hubert"),QAt.forEach(t),mmr=r(WNe," \u2014 "),eH=n(WNe,"A",{href:!0});var WAt=s(eH);gmr=r(WAt,"HubertForCTC"),WAt.forEach(t),hmr=r(WNe," (Hubert model)"),WNe.forEach(t),pmr=i(Be),iT=n(Be,"LI",{});var HNe=s(iT);A4e=n(HNe,"STRONG",{});var HAt=s(A4e);_mr=r(HAt,"mctct"),HAt.forEach(t),umr=r(HNe," \u2014 "),oH=n(HNe,"A",{href:!0});var UAt=s(oH);bmr=r(UAt,"MCTCTForCTC"),UAt.forEach(t),vmr=r(HNe," (M-CTC-T model)"),HNe.forEach(t),Fmr=i(Be),dT=n(Be,"LI",{});var UNe=s(dT);L4e=n(UNe,"STRONG",{});var JAt=s(L4e);Tmr=r(JAt,"sew"),JAt.forEach(t),Mmr=r(UNe," \u2014 "),rH=n(UNe,"A",{href:!0});var YAt=s(rH);Emr=r(YAt,"SEWForCTC"),YAt.forEach(t),Cmr=r(UNe," (SEW model)"),UNe.forEach(t),wmr=i(Be),cT=n(Be,"LI",{});var JNe=s(cT);y4e=n(JNe,"STRONG",{});var KAt=s(y4e);Amr=r(KAt,"sew-d"),KAt.forEach(t),Lmr=r(JNe," \u2014 "),tH=n(JNe,"A",{href:!0});var ZAt=s(tH);ymr=r(ZAt,"SEWDForCTC"),ZAt.forEach(t),xmr=r(JNe," (SEW-D model)"),JNe.forEach(t),$mr=i(Be),fT=n(Be,"LI",{});var YNe=s(fT);x4e=n(YNe,"STRONG",{});var e6t=s(x4e);kmr=r(e6t,"unispeech"),e6t.forEach(t),Smr=r(YNe," \u2014 "),aH=n(YNe,"A",{href:!0});var o6t=s(aH);Rmr=r(o6t,"UniSpeechForCTC"),o6t.forEach(t),Pmr=r(YNe," (UniSpeech model)"),YNe.forEach(t),Bmr=i(Be),mT=n(Be,"LI",{});var KNe=s(mT);$4e=n(KNe,"STRONG",{});var r6t=s($4e);Nmr=r(r6t,"unispeech-sat"),r6t.forEach(t),Imr=r(KNe," \u2014 "),nH=n(KNe,"A",{href:!0});var t6t=s(nH);qmr=r(t6t,"UniSpeechSatForCTC"),t6t.forEach(t),jmr=r(KNe," (UniSpeechSat model)"),KNe.forEach(t),Dmr=i(Be),gT=n(Be,"LI",{});var ZNe=s(gT);k4e=n(ZNe,"STRONG",{});var a6t=s(k4e);Gmr=r(a6t,"wav2vec2"),a6t.forEach(t),Omr=r(ZNe," \u2014 "),sH=n(ZNe,"A",{href:!0});var n6t=s(sH);Vmr=r(n6t,"Wav2Vec2ForCTC"),n6t.forEach(t),Xmr=r(ZNe," (Wav2Vec2 model)"),ZNe.forEach(t),zmr=i(Be),hT=n(Be,"LI",{});var eIe=s(hT);S4e=n(eIe,"STRONG",{});var s6t=s(S4e);Qmr=r(s6t,"wav2vec2-conformer"),s6t.forEach(t),Wmr=r(eIe," \u2014 "),lH=n(eIe,"A",{href:!0});var l6t=s(lH);Hmr=r(l6t,"Wav2Vec2ConformerForCTC"),l6t.forEach(t),Umr=r(eIe," (Wav2Vec2-Conformer model)"),eIe.forEach(t),Jmr=i(Be),pT=n(Be,"LI",{});var oIe=s(pT);R4e=n(oIe,"STRONG",{});var i6t=s(R4e);Ymr=r(i6t,"wavlm"),i6t.forEach(t),Kmr=r(oIe," \u2014 "),iH=n(oIe,"A",{href:!0});var d6t=s(iH);Zmr=r(d6t,"WavLMForCTC"),d6t.forEach(t),egr=r(oIe," (WavLM model)"),oIe.forEach(t),Be.forEach(t),ogr=i(Ma),_T=n(Ma,"P",{});var rIe=s(_T);rgr=r(rIe,"The model is set in evaluation mode by default using "),P4e=n(rIe,"CODE",{});var c6t=s(P4e);tgr=r(c6t,"model.eval()"),c6t.forEach(t),agr=r(rIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),B4e=n(rIe,"CODE",{});var f6t=s(B4e);ngr=r(f6t,"model.train()"),f6t.forEach(t),rIe.forEach(t),sgr=i(Ma),T(uT.$$.fragment,Ma),Ma.forEach(t),bl.forEach(t),pXe=i(f),Nd=n(f,"H2",{class:!0});var TQe=s(Nd);bT=n(TQe,"A",{id:!0,class:!0,href:!0});var m6t=s(bT);N4e=n(m6t,"SPAN",{});var g6t=s(N4e);T(e9.$$.fragment,g6t),g6t.forEach(t),m6t.forEach(t),lgr=i(TQe),I4e=n(TQe,"SPAN",{});var h6t=s(I4e);igr=r(h6t,"AutoModelForSpeechSeq2Seq"),h6t.forEach(t),TQe.forEach(t),_Xe=i(f),Wo=n(f,"DIV",{class:!0});var vl=s(Wo);T(o9.$$.fragment,vl),dgr=i(vl),Id=n(vl,"P",{});var Ure=s(Id);cgr=r(Ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),dH=n(Ure,"A",{href:!0});var p6t=s(dH);fgr=r(p6t,"from_pretrained()"),p6t.forEach(t),mgr=r(Ure," class method or the "),cH=n(Ure,"A",{href:!0});var _6t=s(cH);ggr=r(_6t,"from_config()"),_6t.forEach(t),hgr=r(Ure,` class
method.`),Ure.forEach(t),pgr=i(vl),r9=n(vl,"P",{});var MQe=s(r9);_gr=r(MQe,"This class cannot be instantiated directly using "),q4e=n(MQe,"CODE",{});var u6t=s(q4e);ugr=r(u6t,"__init__()"),u6t.forEach(t),bgr=r(MQe," (throws an error)."),MQe.forEach(t),vgr=i(vl),Ct=n(vl,"DIV",{class:!0});var P6=s(Ct);T(t9.$$.fragment,P6),Fgr=i(P6),j4e=n(P6,"P",{});var b6t=s(j4e);Tgr=r(b6t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),b6t.forEach(t),Mgr=i(P6),qd=n(P6,"P",{});var Jre=s(qd);Egr=r(Jre,`Note:
Loading a model from its configuration file does `),D4e=n(Jre,"STRONG",{});var v6t=s(D4e);Cgr=r(v6t,"not"),v6t.forEach(t),wgr=r(Jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),fH=n(Jre,"A",{href:!0});var F6t=s(fH);Agr=r(F6t,"from_pretrained()"),F6t.forEach(t),Lgr=r(Jre," to load the model weights."),Jre.forEach(t),ygr=i(P6),T(vT.$$.fragment,P6),P6.forEach(t),xgr=i(vl),ho=n(vl,"DIV",{class:!0});var Ea=s(ho);T(a9.$$.fragment,Ea),$gr=i(Ea),G4e=n(Ea,"P",{});var T6t=s(G4e);kgr=r(T6t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),T6t.forEach(t),Sgr=i(Ea),Ka=n(Ea,"P",{});var B6=s(Ka);Rgr=r(B6,"The model class to instantiate is selected based on the "),O4e=n(B6,"CODE",{});var M6t=s(O4e);Pgr=r(M6t,"model_type"),M6t.forEach(t),Bgr=r(B6,` property of the config object (either
passed as an argument or loaded from `),V4e=n(B6,"CODE",{});var E6t=s(V4e);Ngr=r(E6t,"pretrained_model_name_or_path"),E6t.forEach(t),Igr=r(B6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),X4e=n(B6,"CODE",{});var C6t=s(X4e);qgr=r(C6t,"pretrained_model_name_or_path"),C6t.forEach(t),jgr=r(B6,":"),B6.forEach(t),Dgr=i(Ea),n9=n(Ea,"UL",{});var EQe=s(n9);FT=n(EQe,"LI",{});var tIe=s(FT);z4e=n(tIe,"STRONG",{});var w6t=s(z4e);Ggr=r(w6t,"speech-encoder-decoder"),w6t.forEach(t),Ogr=r(tIe," \u2014 "),mH=n(tIe,"A",{href:!0});var A6t=s(mH);Vgr=r(A6t,"SpeechEncoderDecoderModel"),A6t.forEach(t),Xgr=r(tIe," (Speech Encoder decoder model)"),tIe.forEach(t),zgr=i(EQe),TT=n(EQe,"LI",{});var aIe=s(TT);Q4e=n(aIe,"STRONG",{});var L6t=s(Q4e);Qgr=r(L6t,"speech_to_text"),L6t.forEach(t),Wgr=r(aIe," \u2014 "),gH=n(aIe,"A",{href:!0});var y6t=s(gH);Hgr=r(y6t,"Speech2TextForConditionalGeneration"),y6t.forEach(t),Ugr=r(aIe," (Speech2Text model)"),aIe.forEach(t),EQe.forEach(t),Jgr=i(Ea),MT=n(Ea,"P",{});var nIe=s(MT);Ygr=r(nIe,"The model is set in evaluation mode by default using "),W4e=n(nIe,"CODE",{});var x6t=s(W4e);Kgr=r(x6t,"model.eval()"),x6t.forEach(t),Zgr=r(nIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H4e=n(nIe,"CODE",{});var $6t=s(H4e);ehr=r($6t,"model.train()"),$6t.forEach(t),nIe.forEach(t),ohr=i(Ea),T(ET.$$.fragment,Ea),Ea.forEach(t),vl.forEach(t),uXe=i(f),jd=n(f,"H2",{class:!0});var CQe=s(jd);CT=n(CQe,"A",{id:!0,class:!0,href:!0});var k6t=s(CT);U4e=n(k6t,"SPAN",{});var S6t=s(U4e);T(s9.$$.fragment,S6t),S6t.forEach(t),k6t.forEach(t),rhr=i(CQe),J4e=n(CQe,"SPAN",{});var R6t=s(J4e);thr=r(R6t,"AutoModelForAudioXVector"),R6t.forEach(t),CQe.forEach(t),bXe=i(f),Ho=n(f,"DIV",{class:!0});var Fl=s(Ho);T(l9.$$.fragment,Fl),ahr=i(Fl),Dd=n(Fl,"P",{});var Yre=s(Dd);nhr=r(Yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),hH=n(Yre,"A",{href:!0});var P6t=s(hH);shr=r(P6t,"from_pretrained()"),P6t.forEach(t),lhr=r(Yre," class method or the "),pH=n(Yre,"A",{href:!0});var B6t=s(pH);ihr=r(B6t,"from_config()"),B6t.forEach(t),dhr=r(Yre,` class
method.`),Yre.forEach(t),chr=i(Fl),i9=n(Fl,"P",{});var wQe=s(i9);fhr=r(wQe,"This class cannot be instantiated directly using "),Y4e=n(wQe,"CODE",{});var N6t=s(Y4e);mhr=r(N6t,"__init__()"),N6t.forEach(t),ghr=r(wQe," (throws an error)."),wQe.forEach(t),hhr=i(Fl),wt=n(Fl,"DIV",{class:!0});var N6=s(wt);T(d9.$$.fragment,N6),phr=i(N6),K4e=n(N6,"P",{});var I6t=s(K4e);_hr=r(I6t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),I6t.forEach(t),uhr=i(N6),Gd=n(N6,"P",{});var Kre=s(Gd);bhr=r(Kre,`Note:
Loading a model from its configuration file does `),Z4e=n(Kre,"STRONG",{});var q6t=s(Z4e);vhr=r(q6t,"not"),q6t.forEach(t),Fhr=r(Kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),_H=n(Kre,"A",{href:!0});var j6t=s(_H);Thr=r(j6t,"from_pretrained()"),j6t.forEach(t),Mhr=r(Kre," to load the model weights."),Kre.forEach(t),Ehr=i(N6),T(wT.$$.fragment,N6),N6.forEach(t),Chr=i(Fl),po=n(Fl,"DIV",{class:!0});var Ca=s(po);T(c9.$$.fragment,Ca),whr=i(Ca),ebe=n(Ca,"P",{});var D6t=s(ebe);Ahr=r(D6t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),D6t.forEach(t),Lhr=i(Ca),Za=n(Ca,"P",{});var I6=s(Za);yhr=r(I6,"The model class to instantiate is selected based on the "),obe=n(I6,"CODE",{});var G6t=s(obe);xhr=r(G6t,"model_type"),G6t.forEach(t),$hr=r(I6,` property of the config object (either
passed as an argument or loaded from `),rbe=n(I6,"CODE",{});var O6t=s(rbe);khr=r(O6t,"pretrained_model_name_or_path"),O6t.forEach(t),Shr=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tbe=n(I6,"CODE",{});var V6t=s(tbe);Rhr=r(V6t,"pretrained_model_name_or_path"),V6t.forEach(t),Phr=r(I6,":"),I6.forEach(t),Bhr=i(Ca),rt=n(Ca,"UL",{});var Tl=s(rt);AT=n(Tl,"LI",{});var sIe=s(AT);abe=n(sIe,"STRONG",{});var X6t=s(abe);Nhr=r(X6t,"data2vec-audio"),X6t.forEach(t),Ihr=r(sIe," \u2014 "),uH=n(sIe,"A",{href:!0});var z6t=s(uH);qhr=r(z6t,"Data2VecAudioForXVector"),z6t.forEach(t),jhr=r(sIe," (Data2VecAudio model)"),sIe.forEach(t),Dhr=i(Tl),LT=n(Tl,"LI",{});var lIe=s(LT);nbe=n(lIe,"STRONG",{});var Q6t=s(nbe);Ghr=r(Q6t,"unispeech-sat"),Q6t.forEach(t),Ohr=r(lIe," \u2014 "),bH=n(lIe,"A",{href:!0});var W6t=s(bH);Vhr=r(W6t,"UniSpeechSatForXVector"),W6t.forEach(t),Xhr=r(lIe," (UniSpeechSat model)"),lIe.forEach(t),zhr=i(Tl),yT=n(Tl,"LI",{});var iIe=s(yT);sbe=n(iIe,"STRONG",{});var H6t=s(sbe);Qhr=r(H6t,"wav2vec2"),H6t.forEach(t),Whr=r(iIe," \u2014 "),vH=n(iIe,"A",{href:!0});var U6t=s(vH);Hhr=r(U6t,"Wav2Vec2ForXVector"),U6t.forEach(t),Uhr=r(iIe," (Wav2Vec2 model)"),iIe.forEach(t),Jhr=i(Tl),xT=n(Tl,"LI",{});var dIe=s(xT);lbe=n(dIe,"STRONG",{});var J6t=s(lbe);Yhr=r(J6t,"wav2vec2-conformer"),J6t.forEach(t),Khr=r(dIe," \u2014 "),FH=n(dIe,"A",{href:!0});var Y6t=s(FH);Zhr=r(Y6t,"Wav2Vec2ConformerForXVector"),Y6t.forEach(t),epr=r(dIe," (Wav2Vec2-Conformer model)"),dIe.forEach(t),opr=i(Tl),$T=n(Tl,"LI",{});var cIe=s($T);ibe=n(cIe,"STRONG",{});var K6t=s(ibe);rpr=r(K6t,"wavlm"),K6t.forEach(t),tpr=r(cIe," \u2014 "),TH=n(cIe,"A",{href:!0});var Z6t=s(TH);apr=r(Z6t,"WavLMForXVector"),Z6t.forEach(t),npr=r(cIe," (WavLM model)"),cIe.forEach(t),Tl.forEach(t),spr=i(Ca),kT=n(Ca,"P",{});var fIe=s(kT);lpr=r(fIe,"The model is set in evaluation mode by default using "),dbe=n(fIe,"CODE",{});var eLt=s(dbe);ipr=r(eLt,"model.eval()"),eLt.forEach(t),dpr=r(fIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cbe=n(fIe,"CODE",{});var oLt=s(cbe);cpr=r(oLt,"model.train()"),oLt.forEach(t),fIe.forEach(t),fpr=i(Ca),T(ST.$$.fragment,Ca),Ca.forEach(t),Fl.forEach(t),vXe=i(f),Od=n(f,"H2",{class:!0});var AQe=s(Od);RT=n(AQe,"A",{id:!0,class:!0,href:!0});var rLt=s(RT);fbe=n(rLt,"SPAN",{});var tLt=s(fbe);T(f9.$$.fragment,tLt),tLt.forEach(t),rLt.forEach(t),mpr=i(AQe),mbe=n(AQe,"SPAN",{});var aLt=s(mbe);gpr=r(aLt,"AutoModelForMaskedImageModeling"),aLt.forEach(t),AQe.forEach(t),FXe=i(f),Uo=n(f,"DIV",{class:!0});var Ml=s(Uo);T(m9.$$.fragment,Ml),hpr=i(Ml),Vd=n(Ml,"P",{});var Zre=s(Vd);ppr=r(Zre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),MH=n(Zre,"A",{href:!0});var nLt=s(MH);_pr=r(nLt,"from_pretrained()"),nLt.forEach(t),upr=r(Zre," class method or the "),EH=n(Zre,"A",{href:!0});var sLt=s(EH);bpr=r(sLt,"from_config()"),sLt.forEach(t),vpr=r(Zre,` class
method.`),Zre.forEach(t),Fpr=i(Ml),g9=n(Ml,"P",{});var LQe=s(g9);Tpr=r(LQe,"This class cannot be instantiated directly using "),gbe=n(LQe,"CODE",{});var lLt=s(gbe);Mpr=r(lLt,"__init__()"),lLt.forEach(t),Epr=r(LQe," (throws an error)."),LQe.forEach(t),Cpr=i(Ml),At=n(Ml,"DIV",{class:!0});var q6=s(At);T(h9.$$.fragment,q6),wpr=i(q6),hbe=n(q6,"P",{});var iLt=s(hbe);Apr=r(iLt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),iLt.forEach(t),Lpr=i(q6),Xd=n(q6,"P",{});var ete=s(Xd);ypr=r(ete,`Note:
Loading a model from its configuration file does `),pbe=n(ete,"STRONG",{});var dLt=s(pbe);xpr=r(dLt,"not"),dLt.forEach(t),$pr=r(ete,` load the model weights. It only affects the
model\u2019s configuration. Use `),CH=n(ete,"A",{href:!0});var cLt=s(CH);kpr=r(cLt,"from_pretrained()"),cLt.forEach(t),Spr=r(ete," to load the model weights."),ete.forEach(t),Rpr=i(q6),T(PT.$$.fragment,q6),q6.forEach(t),Ppr=i(Ml),_o=n(Ml,"DIV",{class:!0});var wa=s(_o);T(p9.$$.fragment,wa),Bpr=i(wa),_be=n(wa,"P",{});var fLt=s(_be);Npr=r(fLt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),fLt.forEach(t),Ipr=i(wa),en=n(wa,"P",{});var j6=s(en);qpr=r(j6,"The model class to instantiate is selected based on the "),ube=n(j6,"CODE",{});var mLt=s(ube);jpr=r(mLt,"model_type"),mLt.forEach(t),Dpr=r(j6,` property of the config object (either
passed as an argument or loaded from `),bbe=n(j6,"CODE",{});var gLt=s(bbe);Gpr=r(gLt,"pretrained_model_name_or_path"),gLt.forEach(t),Opr=r(j6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vbe=n(j6,"CODE",{});var hLt=s(vbe);Vpr=r(hLt,"pretrained_model_name_or_path"),hLt.forEach(t),Xpr=r(j6,":"),j6.forEach(t),zpr=i(wa),zd=n(wa,"UL",{});var ote=s(zd);BT=n(ote,"LI",{});var mIe=s(BT);Fbe=n(mIe,"STRONG",{});var pLt=s(Fbe);Qpr=r(pLt,"deit"),pLt.forEach(t),Wpr=r(mIe," \u2014 "),wH=n(mIe,"A",{href:!0});var _Lt=s(wH);Hpr=r(_Lt,"DeiTForMaskedImageModeling"),_Lt.forEach(t),Upr=r(mIe," (DeiT model)"),mIe.forEach(t),Jpr=i(ote),NT=n(ote,"LI",{});var gIe=s(NT);Tbe=n(gIe,"STRONG",{});var uLt=s(Tbe);Ypr=r(uLt,"swin"),uLt.forEach(t),Kpr=r(gIe," \u2014 "),AH=n(gIe,"A",{href:!0});var bLt=s(AH);Zpr=r(bLt,"SwinForMaskedImageModeling"),bLt.forEach(t),e_r=r(gIe," (Swin Transformer model)"),gIe.forEach(t),o_r=i(ote),IT=n(ote,"LI",{});var hIe=s(IT);Mbe=n(hIe,"STRONG",{});var vLt=s(Mbe);r_r=r(vLt,"vit"),vLt.forEach(t),t_r=r(hIe," \u2014 "),LH=n(hIe,"A",{href:!0});var FLt=s(LH);a_r=r(FLt,"ViTForMaskedImageModeling"),FLt.forEach(t),n_r=r(hIe," (ViT model)"),hIe.forEach(t),ote.forEach(t),s_r=i(wa),qT=n(wa,"P",{});var pIe=s(qT);l_r=r(pIe,"The model is set in evaluation mode by default using "),Ebe=n(pIe,"CODE",{});var TLt=s(Ebe);i_r=r(TLt,"model.eval()"),TLt.forEach(t),d_r=r(pIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cbe=n(pIe,"CODE",{});var MLt=s(Cbe);c_r=r(MLt,"model.train()"),MLt.forEach(t),pIe.forEach(t),f_r=i(wa),T(jT.$$.fragment,wa),wa.forEach(t),Ml.forEach(t),TXe=i(f),Qd=n(f,"H2",{class:!0});var yQe=s(Qd);DT=n(yQe,"A",{id:!0,class:!0,href:!0});var ELt=s(DT);wbe=n(ELt,"SPAN",{});var CLt=s(wbe);T(_9.$$.fragment,CLt),CLt.forEach(t),ELt.forEach(t),m_r=i(yQe),Abe=n(yQe,"SPAN",{});var wLt=s(Abe);g_r=r(wLt,"AutoModelForObjectDetection"),wLt.forEach(t),yQe.forEach(t),MXe=i(f),Jo=n(f,"DIV",{class:!0});var El=s(Jo);T(u9.$$.fragment,El),h_r=i(El),Wd=n(El,"P",{});var rte=s(Wd);p_r=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),yH=n(rte,"A",{href:!0});var ALt=s(yH);__r=r(ALt,"from_pretrained()"),ALt.forEach(t),u_r=r(rte," class method or the "),xH=n(rte,"A",{href:!0});var LLt=s(xH);b_r=r(LLt,"from_config()"),LLt.forEach(t),v_r=r(rte,` class
method.`),rte.forEach(t),F_r=i(El),b9=n(El,"P",{});var xQe=s(b9);T_r=r(xQe,"This class cannot be instantiated directly using "),Lbe=n(xQe,"CODE",{});var yLt=s(Lbe);M_r=r(yLt,"__init__()"),yLt.forEach(t),E_r=r(xQe," (throws an error)."),xQe.forEach(t),C_r=i(El),Lt=n(El,"DIV",{class:!0});var D6=s(Lt);T(v9.$$.fragment,D6),w_r=i(D6),ybe=n(D6,"P",{});var xLt=s(ybe);A_r=r(xLt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),xLt.forEach(t),L_r=i(D6),Hd=n(D6,"P",{});var tte=s(Hd);y_r=r(tte,`Note:
Loading a model from its configuration file does `),xbe=n(tte,"STRONG",{});var $Lt=s(xbe);x_r=r($Lt,"not"),$Lt.forEach(t),$_r=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=n(tte,"A",{href:!0});var kLt=s($H);k_r=r(kLt,"from_pretrained()"),kLt.forEach(t),S_r=r(tte," to load the model weights."),tte.forEach(t),R_r=i(D6),T(GT.$$.fragment,D6),D6.forEach(t),P_r=i(El),uo=n(El,"DIV",{class:!0});var Aa=s(uo);T(F9.$$.fragment,Aa),B_r=i(Aa),$be=n(Aa,"P",{});var SLt=s($be);N_r=r(SLt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),SLt.forEach(t),I_r=i(Aa),on=n(Aa,"P",{});var G6=s(on);q_r=r(G6,"The model class to instantiate is selected based on the "),kbe=n(G6,"CODE",{});var RLt=s(kbe);j_r=r(RLt,"model_type"),RLt.forEach(t),D_r=r(G6,` property of the config object (either
passed as an argument or loaded from `),Sbe=n(G6,"CODE",{});var PLt=s(Sbe);G_r=r(PLt,"pretrained_model_name_or_path"),PLt.forEach(t),O_r=r(G6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rbe=n(G6,"CODE",{});var BLt=s(Rbe);V_r=r(BLt,"pretrained_model_name_or_path"),BLt.forEach(t),X_r=r(G6,":"),G6.forEach(t),z_r=i(Aa),T9=n(Aa,"UL",{});var $Qe=s(T9);OT=n($Qe,"LI",{});var _Ie=s(OT);Pbe=n(_Ie,"STRONG",{});var NLt=s(Pbe);Q_r=r(NLt,"detr"),NLt.forEach(t),W_r=r(_Ie," \u2014 "),kH=n(_Ie,"A",{href:!0});var ILt=s(kH);H_r=r(ILt,"DetrForObjectDetection"),ILt.forEach(t),U_r=r(_Ie," (DETR model)"),_Ie.forEach(t),J_r=i($Qe),VT=n($Qe,"LI",{});var uIe=s(VT);Bbe=n(uIe,"STRONG",{});var qLt=s(Bbe);Y_r=r(qLt,"yolos"),qLt.forEach(t),K_r=r(uIe," \u2014 "),SH=n(uIe,"A",{href:!0});var jLt=s(SH);Z_r=r(jLt,"YolosForObjectDetection"),jLt.forEach(t),eur=r(uIe," (YOLOS model)"),uIe.forEach(t),$Qe.forEach(t),our=i(Aa),XT=n(Aa,"P",{});var bIe=s(XT);rur=r(bIe,"The model is set in evaluation mode by default using "),Nbe=n(bIe,"CODE",{});var DLt=s(Nbe);tur=r(DLt,"model.eval()"),DLt.forEach(t),aur=r(bIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=n(bIe,"CODE",{});var GLt=s(Ibe);nur=r(GLt,"model.train()"),GLt.forEach(t),bIe.forEach(t),sur=i(Aa),T(zT.$$.fragment,Aa),Aa.forEach(t),El.forEach(t),EXe=i(f),Ud=n(f,"H2",{class:!0});var kQe=s(Ud);QT=n(kQe,"A",{id:!0,class:!0,href:!0});var OLt=s(QT);qbe=n(OLt,"SPAN",{});var VLt=s(qbe);T(M9.$$.fragment,VLt),VLt.forEach(t),OLt.forEach(t),lur=i(kQe),jbe=n(kQe,"SPAN",{});var XLt=s(jbe);iur=r(XLt,"AutoModelForImageSegmentation"),XLt.forEach(t),kQe.forEach(t),CXe=i(f),Yo=n(f,"DIV",{class:!0});var Cl=s(Yo);T(E9.$$.fragment,Cl),dur=i(Cl),Jd=n(Cl,"P",{});var ate=s(Jd);cur=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),RH=n(ate,"A",{href:!0});var zLt=s(RH);fur=r(zLt,"from_pretrained()"),zLt.forEach(t),mur=r(ate," class method or the "),PH=n(ate,"A",{href:!0});var QLt=s(PH);gur=r(QLt,"from_config()"),QLt.forEach(t),hur=r(ate,` class
method.`),ate.forEach(t),pur=i(Cl),C9=n(Cl,"P",{});var SQe=s(C9);_ur=r(SQe,"This class cannot be instantiated directly using "),Dbe=n(SQe,"CODE",{});var WLt=s(Dbe);uur=r(WLt,"__init__()"),WLt.forEach(t),bur=r(SQe," (throws an error)."),SQe.forEach(t),vur=i(Cl),yt=n(Cl,"DIV",{class:!0});var O6=s(yt);T(w9.$$.fragment,O6),Fur=i(O6),Gbe=n(O6,"P",{});var HLt=s(Gbe);Tur=r(HLt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),HLt.forEach(t),Mur=i(O6),Yd=n(O6,"P",{});var nte=s(Yd);Eur=r(nte,`Note:
Loading a model from its configuration file does `),Obe=n(nte,"STRONG",{});var ULt=s(Obe);Cur=r(ULt,"not"),ULt.forEach(t),wur=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),BH=n(nte,"A",{href:!0});var JLt=s(BH);Aur=r(JLt,"from_pretrained()"),JLt.forEach(t),Lur=r(nte," to load the model weights."),nte.forEach(t),yur=i(O6),T(WT.$$.fragment,O6),O6.forEach(t),xur=i(Cl),bo=n(Cl,"DIV",{class:!0});var La=s(bo);T(A9.$$.fragment,La),$ur=i(La),Vbe=n(La,"P",{});var YLt=s(Vbe);kur=r(YLt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),YLt.forEach(t),Sur=i(La),rn=n(La,"P",{});var V6=s(rn);Rur=r(V6,"The model class to instantiate is selected based on the "),Xbe=n(V6,"CODE",{});var KLt=s(Xbe);Pur=r(KLt,"model_type"),KLt.forEach(t),Bur=r(V6,` property of the config object (either
passed as an argument or loaded from `),zbe=n(V6,"CODE",{});var ZLt=s(zbe);Nur=r(ZLt,"pretrained_model_name_or_path"),ZLt.forEach(t),Iur=r(V6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qbe=n(V6,"CODE",{});var eyt=s(Qbe);qur=r(eyt,"pretrained_model_name_or_path"),eyt.forEach(t),jur=r(V6,":"),V6.forEach(t),Dur=i(La),Wbe=n(La,"UL",{});var oyt=s(Wbe);HT=n(oyt,"LI",{});var vIe=s(HT);Hbe=n(vIe,"STRONG",{});var ryt=s(Hbe);Gur=r(ryt,"detr"),ryt.forEach(t),Our=r(vIe," \u2014 "),NH=n(vIe,"A",{href:!0});var tyt=s(NH);Vur=r(tyt,"DetrForSegmentation"),tyt.forEach(t),Xur=r(vIe," (DETR model)"),vIe.forEach(t),oyt.forEach(t),zur=i(La),UT=n(La,"P",{});var FIe=s(UT);Qur=r(FIe,"The model is set in evaluation mode by default using "),Ube=n(FIe,"CODE",{});var ayt=s(Ube);Wur=r(ayt,"model.eval()"),ayt.forEach(t),Hur=r(FIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=n(FIe,"CODE",{});var nyt=s(Jbe);Uur=r(nyt,"model.train()"),nyt.forEach(t),FIe.forEach(t),Jur=i(La),T(JT.$$.fragment,La),La.forEach(t),Cl.forEach(t),wXe=i(f),Kd=n(f,"H2",{class:!0});var RQe=s(Kd);YT=n(RQe,"A",{id:!0,class:!0,href:!0});var syt=s(YT);Ybe=n(syt,"SPAN",{});var lyt=s(Ybe);T(L9.$$.fragment,lyt),lyt.forEach(t),syt.forEach(t),Yur=i(RQe),Kbe=n(RQe,"SPAN",{});var iyt=s(Kbe);Kur=r(iyt,"AutoModelForSemanticSegmentation"),iyt.forEach(t),RQe.forEach(t),AXe=i(f),Ko=n(f,"DIV",{class:!0});var wl=s(Ko);T(y9.$$.fragment,wl),Zur=i(wl),Zd=n(wl,"P",{});var ste=s(Zd);e2r=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),IH=n(ste,"A",{href:!0});var dyt=s(IH);o2r=r(dyt,"from_pretrained()"),dyt.forEach(t),r2r=r(ste," class method or the "),qH=n(ste,"A",{href:!0});var cyt=s(qH);t2r=r(cyt,"from_config()"),cyt.forEach(t),a2r=r(ste,` class
method.`),ste.forEach(t),n2r=i(wl),x9=n(wl,"P",{});var PQe=s(x9);s2r=r(PQe,"This class cannot be instantiated directly using "),Zbe=n(PQe,"CODE",{});var fyt=s(Zbe);l2r=r(fyt,"__init__()"),fyt.forEach(t),i2r=r(PQe," (throws an error)."),PQe.forEach(t),d2r=i(wl),xt=n(wl,"DIV",{class:!0});var X6=s(xt);T($9.$$.fragment,X6),c2r=i(X6),eve=n(X6,"P",{});var myt=s(eve);f2r=r(myt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),myt.forEach(t),m2r=i(X6),ec=n(X6,"P",{});var lte=s(ec);g2r=r(lte,`Note:
Loading a model from its configuration file does `),ove=n(lte,"STRONG",{});var gyt=s(ove);h2r=r(gyt,"not"),gyt.forEach(t),p2r=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=n(lte,"A",{href:!0});var hyt=s(jH);_2r=r(hyt,"from_pretrained()"),hyt.forEach(t),u2r=r(lte," to load the model weights."),lte.forEach(t),b2r=i(X6),T(KT.$$.fragment,X6),X6.forEach(t),v2r=i(wl),vo=n(wl,"DIV",{class:!0});var ya=s(vo);T(k9.$$.fragment,ya),F2r=i(ya),rve=n(ya,"P",{});var pyt=s(rve);T2r=r(pyt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),pyt.forEach(t),M2r=i(ya),tn=n(ya,"P",{});var z6=s(tn);E2r=r(z6,"The model class to instantiate is selected based on the "),tve=n(z6,"CODE",{});var _yt=s(tve);C2r=r(_yt,"model_type"),_yt.forEach(t),w2r=r(z6,` property of the config object (either
passed as an argument or loaded from `),ave=n(z6,"CODE",{});var uyt=s(ave);A2r=r(uyt,"pretrained_model_name_or_path"),uyt.forEach(t),L2r=r(z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=n(z6,"CODE",{});var byt=s(nve);y2r=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),x2r=r(z6,":"),z6.forEach(t),$2r=i(ya),an=n(ya,"UL",{});var Q6=s(an);ZT=n(Q6,"LI",{});var TIe=s(ZT);sve=n(TIe,"STRONG",{});var vyt=s(sve);k2r=r(vyt,"beit"),vyt.forEach(t),S2r=r(TIe," \u2014 "),DH=n(TIe,"A",{href:!0});var Fyt=s(DH);R2r=r(Fyt,"BeitForSemanticSegmentation"),Fyt.forEach(t),P2r=r(TIe," (BEiT model)"),TIe.forEach(t),B2r=i(Q6),eM=n(Q6,"LI",{});var MIe=s(eM);lve=n(MIe,"STRONG",{});var Tyt=s(lve);N2r=r(Tyt,"data2vec-vision"),Tyt.forEach(t),I2r=r(MIe," \u2014 "),GH=n(MIe,"A",{href:!0});var Myt=s(GH);q2r=r(Myt,"Data2VecVisionForSemanticSegmentation"),Myt.forEach(t),j2r=r(MIe," (Data2VecVision model)"),MIe.forEach(t),D2r=i(Q6),oM=n(Q6,"LI",{});var EIe=s(oM);ive=n(EIe,"STRONG",{});var Eyt=s(ive);G2r=r(Eyt,"dpt"),Eyt.forEach(t),O2r=r(EIe," \u2014 "),OH=n(EIe,"A",{href:!0});var Cyt=s(OH);V2r=r(Cyt,"DPTForSemanticSegmentation"),Cyt.forEach(t),X2r=r(EIe," (DPT model)"),EIe.forEach(t),z2r=i(Q6),rM=n(Q6,"LI",{});var CIe=s(rM);dve=n(CIe,"STRONG",{});var wyt=s(dve);Q2r=r(wyt,"segformer"),wyt.forEach(t),W2r=r(CIe," \u2014 "),VH=n(CIe,"A",{href:!0});var Ayt=s(VH);H2r=r(Ayt,"SegformerForSemanticSegmentation"),Ayt.forEach(t),U2r=r(CIe," (SegFormer model)"),CIe.forEach(t),Q6.forEach(t),J2r=i(ya),tM=n(ya,"P",{});var wIe=s(tM);Y2r=r(wIe,"The model is set in evaluation mode by default using "),cve=n(wIe,"CODE",{});var Lyt=s(cve);K2r=r(Lyt,"model.eval()"),Lyt.forEach(t),Z2r=r(wIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fve=n(wIe,"CODE",{});var yyt=s(fve);e1r=r(yyt,"model.train()"),yyt.forEach(t),wIe.forEach(t),o1r=i(ya),T(aM.$$.fragment,ya),ya.forEach(t),wl.forEach(t),LXe=i(f),oc=n(f,"H2",{class:!0});var BQe=s(oc);nM=n(BQe,"A",{id:!0,class:!0,href:!0});var xyt=s(nM);mve=n(xyt,"SPAN",{});var $yt=s(mve);T(S9.$$.fragment,$yt),$yt.forEach(t),xyt.forEach(t),r1r=i(BQe),gve=n(BQe,"SPAN",{});var kyt=s(gve);t1r=r(kyt,"AutoModelForInstanceSegmentation"),kyt.forEach(t),BQe.forEach(t),yXe=i(f),Zo=n(f,"DIV",{class:!0});var Al=s(Zo);T(R9.$$.fragment,Al),a1r=i(Al),rc=n(Al,"P",{});var ite=s(rc);n1r=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),XH=n(ite,"A",{href:!0});var Syt=s(XH);s1r=r(Syt,"from_pretrained()"),Syt.forEach(t),l1r=r(ite," class method or the "),zH=n(ite,"A",{href:!0});var Ryt=s(zH);i1r=r(Ryt,"from_config()"),Ryt.forEach(t),d1r=r(ite,` class
method.`),ite.forEach(t),c1r=i(Al),P9=n(Al,"P",{});var NQe=s(P9);f1r=r(NQe,"This class cannot be instantiated directly using "),hve=n(NQe,"CODE",{});var Pyt=s(hve);m1r=r(Pyt,"__init__()"),Pyt.forEach(t),g1r=r(NQe," (throws an error)."),NQe.forEach(t),h1r=i(Al),$t=n(Al,"DIV",{class:!0});var W6=s($t);T(B9.$$.fragment,W6),p1r=i(W6),pve=n(W6,"P",{});var Byt=s(pve);_1r=r(Byt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Byt.forEach(t),u1r=i(W6),tc=n(W6,"P",{});var dte=s(tc);b1r=r(dte,`Note:
Loading a model from its configuration file does `),_ve=n(dte,"STRONG",{});var Nyt=s(_ve);v1r=r(Nyt,"not"),Nyt.forEach(t),F1r=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),QH=n(dte,"A",{href:!0});var Iyt=s(QH);T1r=r(Iyt,"from_pretrained()"),Iyt.forEach(t),M1r=r(dte," to load the model weights."),dte.forEach(t),E1r=i(W6),T(sM.$$.fragment,W6),W6.forEach(t),C1r=i(Al),Fo=n(Al,"DIV",{class:!0});var xa=s(Fo);T(N9.$$.fragment,xa),w1r=i(xa),uve=n(xa,"P",{});var qyt=s(uve);A1r=r(qyt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),qyt.forEach(t),L1r=i(xa),nn=n(xa,"P",{});var H6=s(nn);y1r=r(H6,"The model class to instantiate is selected based on the "),bve=n(H6,"CODE",{});var jyt=s(bve);x1r=r(jyt,"model_type"),jyt.forEach(t),$1r=r(H6,` property of the config object (either
passed as an argument or loaded from `),vve=n(H6,"CODE",{});var Dyt=s(vve);k1r=r(Dyt,"pretrained_model_name_or_path"),Dyt.forEach(t),S1r=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fve=n(H6,"CODE",{});var Gyt=s(Fve);R1r=r(Gyt,"pretrained_model_name_or_path"),Gyt.forEach(t),P1r=r(H6,":"),H6.forEach(t),B1r=i(xa),Tve=n(xa,"UL",{});var Oyt=s(Tve);lM=n(Oyt,"LI",{});var AIe=s(lM);Mve=n(AIe,"STRONG",{});var Vyt=s(Mve);N1r=r(Vyt,"maskformer"),Vyt.forEach(t),I1r=r(AIe," \u2014 "),WH=n(AIe,"A",{href:!0});var Xyt=s(WH);q1r=r(Xyt,"MaskFormerForInstanceSegmentation"),Xyt.forEach(t),j1r=r(AIe," (MaskFormer model)"),AIe.forEach(t),Oyt.forEach(t),D1r=i(xa),iM=n(xa,"P",{});var LIe=s(iM);G1r=r(LIe,"The model is set in evaluation mode by default using "),Eve=n(LIe,"CODE",{});var zyt=s(Eve);O1r=r(zyt,"model.eval()"),zyt.forEach(t),V1r=r(LIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cve=n(LIe,"CODE",{});var Qyt=s(Cve);X1r=r(Qyt,"model.train()"),Qyt.forEach(t),LIe.forEach(t),z1r=i(xa),T(dM.$$.fragment,xa),xa.forEach(t),Al.forEach(t),xXe=i(f),ac=n(f,"H2",{class:!0});var IQe=s(ac);cM=n(IQe,"A",{id:!0,class:!0,href:!0});var Wyt=s(cM);wve=n(Wyt,"SPAN",{});var Hyt=s(wve);T(I9.$$.fragment,Hyt),Hyt.forEach(t),Wyt.forEach(t),Q1r=i(IQe),Ave=n(IQe,"SPAN",{});var Uyt=s(Ave);W1r=r(Uyt,"TFAutoModel"),Uyt.forEach(t),IQe.forEach(t),$Xe=i(f),er=n(f,"DIV",{class:!0});var Ll=s(er);T(q9.$$.fragment,Ll),H1r=i(Ll),nc=n(Ll,"P",{});var cte=s(nc);U1r=r(cte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),HH=n(cte,"A",{href:!0});var Jyt=s(HH);J1r=r(Jyt,"from_pretrained()"),Jyt.forEach(t),Y1r=r(cte," class method or the "),UH=n(cte,"A",{href:!0});var Yyt=s(UH);K1r=r(Yyt,"from_config()"),Yyt.forEach(t),Z1r=r(cte,` class
method.`),cte.forEach(t),e7r=i(Ll),j9=n(Ll,"P",{});var qQe=s(j9);o7r=r(qQe,"This class cannot be instantiated directly using "),Lve=n(qQe,"CODE",{});var Kyt=s(Lve);r7r=r(Kyt,"__init__()"),Kyt.forEach(t),t7r=r(qQe," (throws an error)."),qQe.forEach(t),a7r=i(Ll),kt=n(Ll,"DIV",{class:!0});var U6=s(kt);T(D9.$$.fragment,U6),n7r=i(U6),yve=n(U6,"P",{});var Zyt=s(yve);s7r=r(Zyt,"Instantiates one of the base model classes of the library from a configuration."),Zyt.forEach(t),l7r=i(U6),sc=n(U6,"P",{});var fte=s(sc);i7r=r(fte,`Note:
Loading a model from its configuration file does `),xve=n(fte,"STRONG",{});var e8t=s(xve);d7r=r(e8t,"not"),e8t.forEach(t),c7r=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),JH=n(fte,"A",{href:!0});var o8t=s(JH);f7r=r(o8t,"from_pretrained()"),o8t.forEach(t),m7r=r(fte," to load the model weights."),fte.forEach(t),g7r=i(U6),T(fM.$$.fragment,U6),U6.forEach(t),h7r=i(Ll),xr=n(Ll,"DIV",{class:!0});var yl=s(xr);T(G9.$$.fragment,yl),p7r=i(yl),$ve=n(yl,"P",{});var r8t=s($ve);_7r=r(r8t,"Instantiate one of the base model classes of the library from a pretrained model."),r8t.forEach(t),u7r=i(yl),sn=n(yl,"P",{});var J6=s(sn);b7r=r(J6,"The model class to instantiate is selected based on the "),kve=n(J6,"CODE",{});var t8t=s(kve);v7r=r(t8t,"model_type"),t8t.forEach(t),F7r=r(J6,` property of the config object (either
passed as an argument or loaded from `),Sve=n(J6,"CODE",{});var a8t=s(Sve);T7r=r(a8t,"pretrained_model_name_or_path"),a8t.forEach(t),M7r=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rve=n(J6,"CODE",{});var n8t=s(Rve);E7r=r(n8t,"pretrained_model_name_or_path"),n8t.forEach(t),C7r=r(J6,":"),J6.forEach(t),w7r=i(yl),q=n(yl,"UL",{});var D=s(q);mM=n(D,"LI",{});var yIe=s(mM);Pve=n(yIe,"STRONG",{});var s8t=s(Pve);A7r=r(s8t,"albert"),s8t.forEach(t),L7r=r(yIe," \u2014 "),YH=n(yIe,"A",{href:!0});var l8t=s(YH);y7r=r(l8t,"TFAlbertModel"),l8t.forEach(t),x7r=r(yIe," (ALBERT model)"),yIe.forEach(t),$7r=i(D),gM=n(D,"LI",{});var xIe=s(gM);Bve=n(xIe,"STRONG",{});var i8t=s(Bve);k7r=r(i8t,"bart"),i8t.forEach(t),S7r=r(xIe," \u2014 "),KH=n(xIe,"A",{href:!0});var d8t=s(KH);R7r=r(d8t,"TFBartModel"),d8t.forEach(t),P7r=r(xIe," (BART model)"),xIe.forEach(t),B7r=i(D),hM=n(D,"LI",{});var $Ie=s(hM);Nve=n($Ie,"STRONG",{});var c8t=s(Nve);N7r=r(c8t,"bert"),c8t.forEach(t),I7r=r($Ie," \u2014 "),ZH=n($Ie,"A",{href:!0});var f8t=s(ZH);q7r=r(f8t,"TFBertModel"),f8t.forEach(t),j7r=r($Ie," (BERT model)"),$Ie.forEach(t),D7r=i(D),pM=n(D,"LI",{});var kIe=s(pM);Ive=n(kIe,"STRONG",{});var m8t=s(Ive);G7r=r(m8t,"blenderbot"),m8t.forEach(t),O7r=r(kIe," \u2014 "),eU=n(kIe,"A",{href:!0});var g8t=s(eU);V7r=r(g8t,"TFBlenderbotModel"),g8t.forEach(t),X7r=r(kIe," (Blenderbot model)"),kIe.forEach(t),z7r=i(D),_M=n(D,"LI",{});var SIe=s(_M);qve=n(SIe,"STRONG",{});var h8t=s(qve);Q7r=r(h8t,"blenderbot-small"),h8t.forEach(t),W7r=r(SIe," \u2014 "),oU=n(SIe,"A",{href:!0});var p8t=s(oU);H7r=r(p8t,"TFBlenderbotSmallModel"),p8t.forEach(t),U7r=r(SIe," (BlenderbotSmall model)"),SIe.forEach(t),J7r=i(D),uM=n(D,"LI",{});var RIe=s(uM);jve=n(RIe,"STRONG",{});var _8t=s(jve);Y7r=r(_8t,"camembert"),_8t.forEach(t),K7r=r(RIe," \u2014 "),rU=n(RIe,"A",{href:!0});var u8t=s(rU);Z7r=r(u8t,"TFCamembertModel"),u8t.forEach(t),e4r=r(RIe," (CamemBERT model)"),RIe.forEach(t),o4r=i(D),bM=n(D,"LI",{});var PIe=s(bM);Dve=n(PIe,"STRONG",{});var b8t=s(Dve);r4r=r(b8t,"clip"),b8t.forEach(t),t4r=r(PIe," \u2014 "),tU=n(PIe,"A",{href:!0});var v8t=s(tU);a4r=r(v8t,"TFCLIPModel"),v8t.forEach(t),n4r=r(PIe," (CLIP model)"),PIe.forEach(t),s4r=i(D),vM=n(D,"LI",{});var BIe=s(vM);Gve=n(BIe,"STRONG",{});var F8t=s(Gve);l4r=r(F8t,"convbert"),F8t.forEach(t),i4r=r(BIe," \u2014 "),aU=n(BIe,"A",{href:!0});var T8t=s(aU);d4r=r(T8t,"TFConvBertModel"),T8t.forEach(t),c4r=r(BIe," (ConvBERT model)"),BIe.forEach(t),f4r=i(D),FM=n(D,"LI",{});var NIe=s(FM);Ove=n(NIe,"STRONG",{});var M8t=s(Ove);m4r=r(M8t,"convnext"),M8t.forEach(t),g4r=r(NIe," \u2014 "),nU=n(NIe,"A",{href:!0});var E8t=s(nU);h4r=r(E8t,"TFConvNextModel"),E8t.forEach(t),p4r=r(NIe," (ConvNeXT model)"),NIe.forEach(t),_4r=i(D),TM=n(D,"LI",{});var IIe=s(TM);Vve=n(IIe,"STRONG",{});var C8t=s(Vve);u4r=r(C8t,"ctrl"),C8t.forEach(t),b4r=r(IIe," \u2014 "),sU=n(IIe,"A",{href:!0});var w8t=s(sU);v4r=r(w8t,"TFCTRLModel"),w8t.forEach(t),F4r=r(IIe," (CTRL model)"),IIe.forEach(t),T4r=i(D),MM=n(D,"LI",{});var qIe=s(MM);Xve=n(qIe,"STRONG",{});var A8t=s(Xve);M4r=r(A8t,"data2vec-vision"),A8t.forEach(t),E4r=r(qIe," \u2014 "),lU=n(qIe,"A",{href:!0});var L8t=s(lU);C4r=r(L8t,"TFData2VecVisionModel"),L8t.forEach(t),w4r=r(qIe," (Data2VecVision model)"),qIe.forEach(t),A4r=i(D),EM=n(D,"LI",{});var jIe=s(EM);zve=n(jIe,"STRONG",{});var y8t=s(zve);L4r=r(y8t,"deberta"),y8t.forEach(t),y4r=r(jIe," \u2014 "),iU=n(jIe,"A",{href:!0});var x8t=s(iU);x4r=r(x8t,"TFDebertaModel"),x8t.forEach(t),$4r=r(jIe," (DeBERTa model)"),jIe.forEach(t),k4r=i(D),CM=n(D,"LI",{});var DIe=s(CM);Qve=n(DIe,"STRONG",{});var $8t=s(Qve);S4r=r($8t,"deberta-v2"),$8t.forEach(t),R4r=r(DIe," \u2014 "),dU=n(DIe,"A",{href:!0});var k8t=s(dU);P4r=r(k8t,"TFDebertaV2Model"),k8t.forEach(t),B4r=r(DIe," (DeBERTa-v2 model)"),DIe.forEach(t),N4r=i(D),wM=n(D,"LI",{});var GIe=s(wM);Wve=n(GIe,"STRONG",{});var S8t=s(Wve);I4r=r(S8t,"distilbert"),S8t.forEach(t),q4r=r(GIe," \u2014 "),cU=n(GIe,"A",{href:!0});var R8t=s(cU);j4r=r(R8t,"TFDistilBertModel"),R8t.forEach(t),D4r=r(GIe," (DistilBERT model)"),GIe.forEach(t),G4r=i(D),AM=n(D,"LI",{});var OIe=s(AM);Hve=n(OIe,"STRONG",{});var P8t=s(Hve);O4r=r(P8t,"dpr"),P8t.forEach(t),V4r=r(OIe," \u2014 "),fU=n(OIe,"A",{href:!0});var B8t=s(fU);X4r=r(B8t,"TFDPRQuestionEncoder"),B8t.forEach(t),z4r=r(OIe," (DPR model)"),OIe.forEach(t),Q4r=i(D),LM=n(D,"LI",{});var VIe=s(LM);Uve=n(VIe,"STRONG",{});var N8t=s(Uve);W4r=r(N8t,"electra"),N8t.forEach(t),H4r=r(VIe," \u2014 "),mU=n(VIe,"A",{href:!0});var I8t=s(mU);U4r=r(I8t,"TFElectraModel"),I8t.forEach(t),J4r=r(VIe," (ELECTRA model)"),VIe.forEach(t),Y4r=i(D),yM=n(D,"LI",{});var XIe=s(yM);Jve=n(XIe,"STRONG",{});var q8t=s(Jve);K4r=r(q8t,"flaubert"),q8t.forEach(t),Z4r=r(XIe," \u2014 "),gU=n(XIe,"A",{href:!0});var j8t=s(gU);ebr=r(j8t,"TFFlaubertModel"),j8t.forEach(t),obr=r(XIe," (FlauBERT model)"),XIe.forEach(t),rbr=i(D),Js=n(D,"LI",{});var AS=s(Js);Yve=n(AS,"STRONG",{});var D8t=s(Yve);tbr=r(D8t,"funnel"),D8t.forEach(t),abr=r(AS," \u2014 "),hU=n(AS,"A",{href:!0});var G8t=s(hU);nbr=r(G8t,"TFFunnelModel"),G8t.forEach(t),sbr=r(AS," or "),pU=n(AS,"A",{href:!0});var O8t=s(pU);lbr=r(O8t,"TFFunnelBaseModel"),O8t.forEach(t),ibr=r(AS," (Funnel Transformer model)"),AS.forEach(t),dbr=i(D),xM=n(D,"LI",{});var zIe=s(xM);Kve=n(zIe,"STRONG",{});var V8t=s(Kve);cbr=r(V8t,"gpt2"),V8t.forEach(t),fbr=r(zIe," \u2014 "),_U=n(zIe,"A",{href:!0});var X8t=s(_U);mbr=r(X8t,"TFGPT2Model"),X8t.forEach(t),gbr=r(zIe," (OpenAI GPT-2 model)"),zIe.forEach(t),hbr=i(D),$M=n(D,"LI",{});var QIe=s($M);Zve=n(QIe,"STRONG",{});var z8t=s(Zve);pbr=r(z8t,"gptj"),z8t.forEach(t),_br=r(QIe," \u2014 "),uU=n(QIe,"A",{href:!0});var Q8t=s(uU);ubr=r(Q8t,"TFGPTJModel"),Q8t.forEach(t),bbr=r(QIe," (GPT-J model)"),QIe.forEach(t),vbr=i(D),kM=n(D,"LI",{});var WIe=s(kM);eFe=n(WIe,"STRONG",{});var W8t=s(eFe);Fbr=r(W8t,"hubert"),W8t.forEach(t),Tbr=r(WIe," \u2014 "),bU=n(WIe,"A",{href:!0});var H8t=s(bU);Mbr=r(H8t,"TFHubertModel"),H8t.forEach(t),Ebr=r(WIe," (Hubert model)"),WIe.forEach(t),Cbr=i(D),SM=n(D,"LI",{});var HIe=s(SM);oFe=n(HIe,"STRONG",{});var U8t=s(oFe);wbr=r(U8t,"layoutlm"),U8t.forEach(t),Abr=r(HIe," \u2014 "),vU=n(HIe,"A",{href:!0});var J8t=s(vU);Lbr=r(J8t,"TFLayoutLMModel"),J8t.forEach(t),ybr=r(HIe," (LayoutLM model)"),HIe.forEach(t),xbr=i(D),RM=n(D,"LI",{});var UIe=s(RM);rFe=n(UIe,"STRONG",{});var Y8t=s(rFe);$br=r(Y8t,"led"),Y8t.forEach(t),kbr=r(UIe," \u2014 "),FU=n(UIe,"A",{href:!0});var K8t=s(FU);Sbr=r(K8t,"TFLEDModel"),K8t.forEach(t),Rbr=r(UIe," (LED model)"),UIe.forEach(t),Pbr=i(D),PM=n(D,"LI",{});var JIe=s(PM);tFe=n(JIe,"STRONG",{});var Z8t=s(tFe);Bbr=r(Z8t,"longformer"),Z8t.forEach(t),Nbr=r(JIe," \u2014 "),TU=n(JIe,"A",{href:!0});var e9t=s(TU);Ibr=r(e9t,"TFLongformerModel"),e9t.forEach(t),qbr=r(JIe," (Longformer model)"),JIe.forEach(t),jbr=i(D),BM=n(D,"LI",{});var YIe=s(BM);aFe=n(YIe,"STRONG",{});var o9t=s(aFe);Dbr=r(o9t,"lxmert"),o9t.forEach(t),Gbr=r(YIe," \u2014 "),MU=n(YIe,"A",{href:!0});var r9t=s(MU);Obr=r(r9t,"TFLxmertModel"),r9t.forEach(t),Vbr=r(YIe," (LXMERT model)"),YIe.forEach(t),Xbr=i(D),NM=n(D,"LI",{});var KIe=s(NM);nFe=n(KIe,"STRONG",{});var t9t=s(nFe);zbr=r(t9t,"marian"),t9t.forEach(t),Qbr=r(KIe," \u2014 "),EU=n(KIe,"A",{href:!0});var a9t=s(EU);Wbr=r(a9t,"TFMarianModel"),a9t.forEach(t),Hbr=r(KIe," (Marian model)"),KIe.forEach(t),Ubr=i(D),IM=n(D,"LI",{});var ZIe=s(IM);sFe=n(ZIe,"STRONG",{});var n9t=s(sFe);Jbr=r(n9t,"mbart"),n9t.forEach(t),Ybr=r(ZIe," \u2014 "),CU=n(ZIe,"A",{href:!0});var s9t=s(CU);Kbr=r(s9t,"TFMBartModel"),s9t.forEach(t),Zbr=r(ZIe," (mBART model)"),ZIe.forEach(t),evr=i(D),qM=n(D,"LI",{});var eqe=s(qM);lFe=n(eqe,"STRONG",{});var l9t=s(lFe);ovr=r(l9t,"mobilebert"),l9t.forEach(t),rvr=r(eqe," \u2014 "),wU=n(eqe,"A",{href:!0});var i9t=s(wU);tvr=r(i9t,"TFMobileBertModel"),i9t.forEach(t),avr=r(eqe," (MobileBERT model)"),eqe.forEach(t),nvr=i(D),jM=n(D,"LI",{});var oqe=s(jM);iFe=n(oqe,"STRONG",{});var d9t=s(iFe);svr=r(d9t,"mpnet"),d9t.forEach(t),lvr=r(oqe," \u2014 "),AU=n(oqe,"A",{href:!0});var c9t=s(AU);ivr=r(c9t,"TFMPNetModel"),c9t.forEach(t),dvr=r(oqe," (MPNet model)"),oqe.forEach(t),cvr=i(D),DM=n(D,"LI",{});var rqe=s(DM);dFe=n(rqe,"STRONG",{});var f9t=s(dFe);fvr=r(f9t,"mt5"),f9t.forEach(t),mvr=r(rqe," \u2014 "),LU=n(rqe,"A",{href:!0});var m9t=s(LU);gvr=r(m9t,"TFMT5Model"),m9t.forEach(t),hvr=r(rqe," (MT5 model)"),rqe.forEach(t),pvr=i(D),GM=n(D,"LI",{});var tqe=s(GM);cFe=n(tqe,"STRONG",{});var g9t=s(cFe);_vr=r(g9t,"openai-gpt"),g9t.forEach(t),uvr=r(tqe," \u2014 "),yU=n(tqe,"A",{href:!0});var h9t=s(yU);bvr=r(h9t,"TFOpenAIGPTModel"),h9t.forEach(t),vvr=r(tqe," (OpenAI GPT model)"),tqe.forEach(t),Fvr=i(D),OM=n(D,"LI",{});var aqe=s(OM);fFe=n(aqe,"STRONG",{});var p9t=s(fFe);Tvr=r(p9t,"opt"),p9t.forEach(t),Mvr=r(aqe," \u2014 "),xU=n(aqe,"A",{href:!0});var _9t=s(xU);Evr=r(_9t,"TFOPTModel"),_9t.forEach(t),Cvr=r(aqe," (OPT model)"),aqe.forEach(t),wvr=i(D),VM=n(D,"LI",{});var nqe=s(VM);mFe=n(nqe,"STRONG",{});var u9t=s(mFe);Avr=r(u9t,"pegasus"),u9t.forEach(t),Lvr=r(nqe," \u2014 "),$U=n(nqe,"A",{href:!0});var b9t=s($U);yvr=r(b9t,"TFPegasusModel"),b9t.forEach(t),xvr=r(nqe," (Pegasus model)"),nqe.forEach(t),$vr=i(D),XM=n(D,"LI",{});var sqe=s(XM);gFe=n(sqe,"STRONG",{});var v9t=s(gFe);kvr=r(v9t,"regnet"),v9t.forEach(t),Svr=r(sqe," \u2014 "),kU=n(sqe,"A",{href:!0});var F9t=s(kU);Rvr=r(F9t,"TFRegNetModel"),F9t.forEach(t),Pvr=r(sqe," (RegNet model)"),sqe.forEach(t),Bvr=i(D),zM=n(D,"LI",{});var lqe=s(zM);hFe=n(lqe,"STRONG",{});var T9t=s(hFe);Nvr=r(T9t,"rembert"),T9t.forEach(t),Ivr=r(lqe," \u2014 "),SU=n(lqe,"A",{href:!0});var M9t=s(SU);qvr=r(M9t,"TFRemBertModel"),M9t.forEach(t),jvr=r(lqe," (RemBERT model)"),lqe.forEach(t),Dvr=i(D),QM=n(D,"LI",{});var iqe=s(QM);pFe=n(iqe,"STRONG",{});var E9t=s(pFe);Gvr=r(E9t,"resnet"),E9t.forEach(t),Ovr=r(iqe," \u2014 "),RU=n(iqe,"A",{href:!0});var C9t=s(RU);Vvr=r(C9t,"TFResNetModel"),C9t.forEach(t),Xvr=r(iqe," (ResNet model)"),iqe.forEach(t),zvr=i(D),WM=n(D,"LI",{});var dqe=s(WM);_Fe=n(dqe,"STRONG",{});var w9t=s(_Fe);Qvr=r(w9t,"roberta"),w9t.forEach(t),Wvr=r(dqe," \u2014 "),PU=n(dqe,"A",{href:!0});var A9t=s(PU);Hvr=r(A9t,"TFRobertaModel"),A9t.forEach(t),Uvr=r(dqe," (RoBERTa model)"),dqe.forEach(t),Jvr=i(D),HM=n(D,"LI",{});var cqe=s(HM);uFe=n(cqe,"STRONG",{});var L9t=s(uFe);Yvr=r(L9t,"roformer"),L9t.forEach(t),Kvr=r(cqe," \u2014 "),BU=n(cqe,"A",{href:!0});var y9t=s(BU);Zvr=r(y9t,"TFRoFormerModel"),y9t.forEach(t),eFr=r(cqe," (RoFormer model)"),cqe.forEach(t),oFr=i(D),UM=n(D,"LI",{});var fqe=s(UM);bFe=n(fqe,"STRONG",{});var x9t=s(bFe);rFr=r(x9t,"speech_to_text"),x9t.forEach(t),tFr=r(fqe," \u2014 "),NU=n(fqe,"A",{href:!0});var $9t=s(NU);aFr=r($9t,"TFSpeech2TextModel"),$9t.forEach(t),nFr=r(fqe," (Speech2Text model)"),fqe.forEach(t),sFr=i(D),JM=n(D,"LI",{});var mqe=s(JM);vFe=n(mqe,"STRONG",{});var k9t=s(vFe);lFr=r(k9t,"swin"),k9t.forEach(t),iFr=r(mqe," \u2014 "),IU=n(mqe,"A",{href:!0});var S9t=s(IU);dFr=r(S9t,"TFSwinModel"),S9t.forEach(t),cFr=r(mqe," (Swin Transformer model)"),mqe.forEach(t),fFr=i(D),YM=n(D,"LI",{});var gqe=s(YM);FFe=n(gqe,"STRONG",{});var R9t=s(FFe);mFr=r(R9t,"t5"),R9t.forEach(t),gFr=r(gqe," \u2014 "),qU=n(gqe,"A",{href:!0});var P9t=s(qU);hFr=r(P9t,"TFT5Model"),P9t.forEach(t),pFr=r(gqe," (T5 model)"),gqe.forEach(t),_Fr=i(D),KM=n(D,"LI",{});var hqe=s(KM);TFe=n(hqe,"STRONG",{});var B9t=s(TFe);uFr=r(B9t,"tapas"),B9t.forEach(t),bFr=r(hqe," \u2014 "),jU=n(hqe,"A",{href:!0});var N9t=s(jU);vFr=r(N9t,"TFTapasModel"),N9t.forEach(t),FFr=r(hqe," (TAPAS model)"),hqe.forEach(t),TFr=i(D),ZM=n(D,"LI",{});var pqe=s(ZM);MFe=n(pqe,"STRONG",{});var I9t=s(MFe);MFr=r(I9t,"transfo-xl"),I9t.forEach(t),EFr=r(pqe," \u2014 "),DU=n(pqe,"A",{href:!0});var q9t=s(DU);CFr=r(q9t,"TFTransfoXLModel"),q9t.forEach(t),wFr=r(pqe," (Transformer-XL model)"),pqe.forEach(t),AFr=i(D),eE=n(D,"LI",{});var _qe=s(eE);EFe=n(_qe,"STRONG",{});var j9t=s(EFe);LFr=r(j9t,"vit"),j9t.forEach(t),yFr=r(_qe," \u2014 "),GU=n(_qe,"A",{href:!0});var D9t=s(GU);xFr=r(D9t,"TFViTModel"),D9t.forEach(t),$Fr=r(_qe," (ViT model)"),_qe.forEach(t),kFr=i(D),oE=n(D,"LI",{});var uqe=s(oE);CFe=n(uqe,"STRONG",{});var G9t=s(CFe);SFr=r(G9t,"vit_mae"),G9t.forEach(t),RFr=r(uqe," \u2014 "),OU=n(uqe,"A",{href:!0});var O9t=s(OU);PFr=r(O9t,"TFViTMAEModel"),O9t.forEach(t),BFr=r(uqe," (ViTMAE model)"),uqe.forEach(t),NFr=i(D),rE=n(D,"LI",{});var bqe=s(rE);wFe=n(bqe,"STRONG",{});var V9t=s(wFe);IFr=r(V9t,"wav2vec2"),V9t.forEach(t),qFr=r(bqe," \u2014 "),VU=n(bqe,"A",{href:!0});var X9t=s(VU);jFr=r(X9t,"TFWav2Vec2Model"),X9t.forEach(t),DFr=r(bqe," (Wav2Vec2 model)"),bqe.forEach(t),GFr=i(D),tE=n(D,"LI",{});var vqe=s(tE);AFe=n(vqe,"STRONG",{});var z9t=s(AFe);OFr=r(z9t,"xlm"),z9t.forEach(t),VFr=r(vqe," \u2014 "),XU=n(vqe,"A",{href:!0});var Q9t=s(XU);XFr=r(Q9t,"TFXLMModel"),Q9t.forEach(t),zFr=r(vqe," (XLM model)"),vqe.forEach(t),QFr=i(D),aE=n(D,"LI",{});var Fqe=s(aE);LFe=n(Fqe,"STRONG",{});var W9t=s(LFe);WFr=r(W9t,"xlm-roberta"),W9t.forEach(t),HFr=r(Fqe," \u2014 "),zU=n(Fqe,"A",{href:!0});var H9t=s(zU);UFr=r(H9t,"TFXLMRobertaModel"),H9t.forEach(t),JFr=r(Fqe," (XLM-RoBERTa model)"),Fqe.forEach(t),YFr=i(D),nE=n(D,"LI",{});var Tqe=s(nE);yFe=n(Tqe,"STRONG",{});var U9t=s(yFe);KFr=r(U9t,"xlnet"),U9t.forEach(t),ZFr=r(Tqe," \u2014 "),QU=n(Tqe,"A",{href:!0});var J9t=s(QU);eTr=r(J9t,"TFXLNetModel"),J9t.forEach(t),oTr=r(Tqe," (XLNet model)"),Tqe.forEach(t),D.forEach(t),rTr=i(yl),T(sE.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),kXe=i(f),lc=n(f,"H2",{class:!0});var jQe=s(lc);lE=n(jQe,"A",{id:!0,class:!0,href:!0});var Y9t=s(lE);xFe=n(Y9t,"SPAN",{});var K9t=s(xFe);T(O9.$$.fragment,K9t),K9t.forEach(t),Y9t.forEach(t),tTr=i(jQe),$Fe=n(jQe,"SPAN",{});var Z9t=s($Fe);aTr=r(Z9t,"TFAutoModelForPreTraining"),Z9t.forEach(t),jQe.forEach(t),SXe=i(f),or=n(f,"DIV",{class:!0});var xl=s(or);T(V9.$$.fragment,xl),nTr=i(xl),ic=n(xl,"P",{});var mte=s(ic);sTr=r(mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),WU=n(mte,"A",{href:!0});var ext=s(WU);lTr=r(ext,"from_pretrained()"),ext.forEach(t),iTr=r(mte," class method or the "),HU=n(mte,"A",{href:!0});var oxt=s(HU);dTr=r(oxt,"from_config()"),oxt.forEach(t),cTr=r(mte,` class
method.`),mte.forEach(t),fTr=i(xl),X9=n(xl,"P",{});var DQe=s(X9);mTr=r(DQe,"This class cannot be instantiated directly using "),kFe=n(DQe,"CODE",{});var rxt=s(kFe);gTr=r(rxt,"__init__()"),rxt.forEach(t),hTr=r(DQe," (throws an error)."),DQe.forEach(t),pTr=i(xl),St=n(xl,"DIV",{class:!0});var Y6=s(St);T(z9.$$.fragment,Y6),_Tr=i(Y6),SFe=n(Y6,"P",{});var txt=s(SFe);uTr=r(txt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),txt.forEach(t),bTr=i(Y6),dc=n(Y6,"P",{});var gte=s(dc);vTr=r(gte,`Note:
Loading a model from its configuration file does `),RFe=n(gte,"STRONG",{});var axt=s(RFe);FTr=r(axt,"not"),axt.forEach(t),TTr=r(gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),UU=n(gte,"A",{href:!0});var nxt=s(UU);MTr=r(nxt,"from_pretrained()"),nxt.forEach(t),ETr=r(gte," to load the model weights."),gte.forEach(t),CTr=i(Y6),T(iE.$$.fragment,Y6),Y6.forEach(t),wTr=i(xl),$r=n(xl,"DIV",{class:!0});var $l=s($r);T(Q9.$$.fragment,$l),ATr=i($l),PFe=n($l,"P",{});var sxt=s(PFe);LTr=r(sxt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),sxt.forEach(t),yTr=i($l),ln=n($l,"P",{});var K6=s(ln);xTr=r(K6,"The model class to instantiate is selected based on the "),BFe=n(K6,"CODE",{});var lxt=s(BFe);$Tr=r(lxt,"model_type"),lxt.forEach(t),kTr=r(K6,` property of the config object (either
passed as an argument or loaded from `),NFe=n(K6,"CODE",{});var ixt=s(NFe);STr=r(ixt,"pretrained_model_name_or_path"),ixt.forEach(t),RTr=r(K6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IFe=n(K6,"CODE",{});var dxt=s(IFe);PTr=r(dxt,"pretrained_model_name_or_path"),dxt.forEach(t),BTr=r(K6,":"),K6.forEach(t),NTr=i($l),se=n($l,"UL",{});var le=s(se);dE=n(le,"LI",{});var Mqe=s(dE);qFe=n(Mqe,"STRONG",{});var cxt=s(qFe);ITr=r(cxt,"albert"),cxt.forEach(t),qTr=r(Mqe," \u2014 "),JU=n(Mqe,"A",{href:!0});var fxt=s(JU);jTr=r(fxt,"TFAlbertForPreTraining"),fxt.forEach(t),DTr=r(Mqe," (ALBERT model)"),Mqe.forEach(t),GTr=i(le),cE=n(le,"LI",{});var Eqe=s(cE);jFe=n(Eqe,"STRONG",{});var mxt=s(jFe);OTr=r(mxt,"bart"),mxt.forEach(t),VTr=r(Eqe," \u2014 "),YU=n(Eqe,"A",{href:!0});var gxt=s(YU);XTr=r(gxt,"TFBartForConditionalGeneration"),gxt.forEach(t),zTr=r(Eqe," (BART model)"),Eqe.forEach(t),QTr=i(le),fE=n(le,"LI",{});var Cqe=s(fE);DFe=n(Cqe,"STRONG",{});var hxt=s(DFe);WTr=r(hxt,"bert"),hxt.forEach(t),HTr=r(Cqe," \u2014 "),KU=n(Cqe,"A",{href:!0});var pxt=s(KU);UTr=r(pxt,"TFBertForPreTraining"),pxt.forEach(t),JTr=r(Cqe," (BERT model)"),Cqe.forEach(t),YTr=i(le),mE=n(le,"LI",{});var wqe=s(mE);GFe=n(wqe,"STRONG",{});var _xt=s(GFe);KTr=r(_xt,"camembert"),_xt.forEach(t),ZTr=r(wqe," \u2014 "),ZU=n(wqe,"A",{href:!0});var uxt=s(ZU);eMr=r(uxt,"TFCamembertForMaskedLM"),uxt.forEach(t),oMr=r(wqe," (CamemBERT model)"),wqe.forEach(t),rMr=i(le),gE=n(le,"LI",{});var Aqe=s(gE);OFe=n(Aqe,"STRONG",{});var bxt=s(OFe);tMr=r(bxt,"ctrl"),bxt.forEach(t),aMr=r(Aqe," \u2014 "),eJ=n(Aqe,"A",{href:!0});var vxt=s(eJ);nMr=r(vxt,"TFCTRLLMHeadModel"),vxt.forEach(t),sMr=r(Aqe," (CTRL model)"),Aqe.forEach(t),lMr=i(le),hE=n(le,"LI",{});var Lqe=s(hE);VFe=n(Lqe,"STRONG",{});var Fxt=s(VFe);iMr=r(Fxt,"distilbert"),Fxt.forEach(t),dMr=r(Lqe," \u2014 "),oJ=n(Lqe,"A",{href:!0});var Txt=s(oJ);cMr=r(Txt,"TFDistilBertForMaskedLM"),Txt.forEach(t),fMr=r(Lqe," (DistilBERT model)"),Lqe.forEach(t),mMr=i(le),pE=n(le,"LI",{});var yqe=s(pE);XFe=n(yqe,"STRONG",{});var Mxt=s(XFe);gMr=r(Mxt,"electra"),Mxt.forEach(t),hMr=r(yqe," \u2014 "),rJ=n(yqe,"A",{href:!0});var Ext=s(rJ);pMr=r(Ext,"TFElectraForPreTraining"),Ext.forEach(t),_Mr=r(yqe," (ELECTRA model)"),yqe.forEach(t),uMr=i(le),_E=n(le,"LI",{});var xqe=s(_E);zFe=n(xqe,"STRONG",{});var Cxt=s(zFe);bMr=r(Cxt,"flaubert"),Cxt.forEach(t),vMr=r(xqe," \u2014 "),tJ=n(xqe,"A",{href:!0});var wxt=s(tJ);FMr=r(wxt,"TFFlaubertWithLMHeadModel"),wxt.forEach(t),TMr=r(xqe," (FlauBERT model)"),xqe.forEach(t),MMr=i(le),uE=n(le,"LI",{});var $qe=s(uE);QFe=n($qe,"STRONG",{});var Axt=s(QFe);EMr=r(Axt,"funnel"),Axt.forEach(t),CMr=r($qe," \u2014 "),aJ=n($qe,"A",{href:!0});var Lxt=s(aJ);wMr=r(Lxt,"TFFunnelForPreTraining"),Lxt.forEach(t),AMr=r($qe," (Funnel Transformer model)"),$qe.forEach(t),LMr=i(le),bE=n(le,"LI",{});var kqe=s(bE);WFe=n(kqe,"STRONG",{});var yxt=s(WFe);yMr=r(yxt,"gpt2"),yxt.forEach(t),xMr=r(kqe," \u2014 "),nJ=n(kqe,"A",{href:!0});var xxt=s(nJ);$Mr=r(xxt,"TFGPT2LMHeadModel"),xxt.forEach(t),kMr=r(kqe," (OpenAI GPT-2 model)"),kqe.forEach(t),SMr=i(le),vE=n(le,"LI",{});var Sqe=s(vE);HFe=n(Sqe,"STRONG",{});var $xt=s(HFe);RMr=r($xt,"layoutlm"),$xt.forEach(t),PMr=r(Sqe," \u2014 "),sJ=n(Sqe,"A",{href:!0});var kxt=s(sJ);BMr=r(kxt,"TFLayoutLMForMaskedLM"),kxt.forEach(t),NMr=r(Sqe," (LayoutLM model)"),Sqe.forEach(t),IMr=i(le),FE=n(le,"LI",{});var Rqe=s(FE);UFe=n(Rqe,"STRONG",{});var Sxt=s(UFe);qMr=r(Sxt,"lxmert"),Sxt.forEach(t),jMr=r(Rqe," \u2014 "),lJ=n(Rqe,"A",{href:!0});var Rxt=s(lJ);DMr=r(Rxt,"TFLxmertForPreTraining"),Rxt.forEach(t),GMr=r(Rqe," (LXMERT model)"),Rqe.forEach(t),OMr=i(le),TE=n(le,"LI",{});var Pqe=s(TE);JFe=n(Pqe,"STRONG",{});var Pxt=s(JFe);VMr=r(Pxt,"mobilebert"),Pxt.forEach(t),XMr=r(Pqe," \u2014 "),iJ=n(Pqe,"A",{href:!0});var Bxt=s(iJ);zMr=r(Bxt,"TFMobileBertForPreTraining"),Bxt.forEach(t),QMr=r(Pqe," (MobileBERT model)"),Pqe.forEach(t),WMr=i(le),ME=n(le,"LI",{});var Bqe=s(ME);YFe=n(Bqe,"STRONG",{});var Nxt=s(YFe);HMr=r(Nxt,"mpnet"),Nxt.forEach(t),UMr=r(Bqe," \u2014 "),dJ=n(Bqe,"A",{href:!0});var Ixt=s(dJ);JMr=r(Ixt,"TFMPNetForMaskedLM"),Ixt.forEach(t),YMr=r(Bqe," (MPNet model)"),Bqe.forEach(t),KMr=i(le),EE=n(le,"LI",{});var Nqe=s(EE);KFe=n(Nqe,"STRONG",{});var qxt=s(KFe);ZMr=r(qxt,"openai-gpt"),qxt.forEach(t),eEr=r(Nqe," \u2014 "),cJ=n(Nqe,"A",{href:!0});var jxt=s(cJ);oEr=r(jxt,"TFOpenAIGPTLMHeadModel"),jxt.forEach(t),rEr=r(Nqe," (OpenAI GPT model)"),Nqe.forEach(t),tEr=i(le),CE=n(le,"LI",{});var Iqe=s(CE);ZFe=n(Iqe,"STRONG",{});var Dxt=s(ZFe);aEr=r(Dxt,"roberta"),Dxt.forEach(t),nEr=r(Iqe," \u2014 "),fJ=n(Iqe,"A",{href:!0});var Gxt=s(fJ);sEr=r(Gxt,"TFRobertaForMaskedLM"),Gxt.forEach(t),lEr=r(Iqe," (RoBERTa model)"),Iqe.forEach(t),iEr=i(le),wE=n(le,"LI",{});var qqe=s(wE);eTe=n(qqe,"STRONG",{});var Oxt=s(eTe);dEr=r(Oxt,"t5"),Oxt.forEach(t),cEr=r(qqe," \u2014 "),mJ=n(qqe,"A",{href:!0});var Vxt=s(mJ);fEr=r(Vxt,"TFT5ForConditionalGeneration"),Vxt.forEach(t),mEr=r(qqe," (T5 model)"),qqe.forEach(t),gEr=i(le),AE=n(le,"LI",{});var jqe=s(AE);oTe=n(jqe,"STRONG",{});var Xxt=s(oTe);hEr=r(Xxt,"tapas"),Xxt.forEach(t),pEr=r(jqe," \u2014 "),gJ=n(jqe,"A",{href:!0});var zxt=s(gJ);_Er=r(zxt,"TFTapasForMaskedLM"),zxt.forEach(t),uEr=r(jqe," (TAPAS model)"),jqe.forEach(t),bEr=i(le),LE=n(le,"LI",{});var Dqe=s(LE);rTe=n(Dqe,"STRONG",{});var Qxt=s(rTe);vEr=r(Qxt,"transfo-xl"),Qxt.forEach(t),FEr=r(Dqe," \u2014 "),hJ=n(Dqe,"A",{href:!0});var Wxt=s(hJ);TEr=r(Wxt,"TFTransfoXLLMHeadModel"),Wxt.forEach(t),MEr=r(Dqe," (Transformer-XL model)"),Dqe.forEach(t),EEr=i(le),yE=n(le,"LI",{});var Gqe=s(yE);tTe=n(Gqe,"STRONG",{});var Hxt=s(tTe);CEr=r(Hxt,"vit_mae"),Hxt.forEach(t),wEr=r(Gqe," \u2014 "),pJ=n(Gqe,"A",{href:!0});var Uxt=s(pJ);AEr=r(Uxt,"TFViTMAEForPreTraining"),Uxt.forEach(t),LEr=r(Gqe," (ViTMAE model)"),Gqe.forEach(t),yEr=i(le),xE=n(le,"LI",{});var Oqe=s(xE);aTe=n(Oqe,"STRONG",{});var Jxt=s(aTe);xEr=r(Jxt,"xlm"),Jxt.forEach(t),$Er=r(Oqe," \u2014 "),_J=n(Oqe,"A",{href:!0});var Yxt=s(_J);kEr=r(Yxt,"TFXLMWithLMHeadModel"),Yxt.forEach(t),SEr=r(Oqe," (XLM model)"),Oqe.forEach(t),REr=i(le),$E=n(le,"LI",{});var Vqe=s($E);nTe=n(Vqe,"STRONG",{});var Kxt=s(nTe);PEr=r(Kxt,"xlm-roberta"),Kxt.forEach(t),BEr=r(Vqe," \u2014 "),uJ=n(Vqe,"A",{href:!0});var Zxt=s(uJ);NEr=r(Zxt,"TFXLMRobertaForMaskedLM"),Zxt.forEach(t),IEr=r(Vqe," (XLM-RoBERTa model)"),Vqe.forEach(t),qEr=i(le),kE=n(le,"LI",{});var Xqe=s(kE);sTe=n(Xqe,"STRONG",{});var e$t=s(sTe);jEr=r(e$t,"xlnet"),e$t.forEach(t),DEr=r(Xqe," \u2014 "),bJ=n(Xqe,"A",{href:!0});var o$t=s(bJ);GEr=r(o$t,"TFXLNetLMHeadModel"),o$t.forEach(t),OEr=r(Xqe," (XLNet model)"),Xqe.forEach(t),le.forEach(t),VEr=i($l),T(SE.$$.fragment,$l),$l.forEach(t),xl.forEach(t),RXe=i(f),cc=n(f,"H2",{class:!0});var GQe=s(cc);RE=n(GQe,"A",{id:!0,class:!0,href:!0});var r$t=s(RE);lTe=n(r$t,"SPAN",{});var t$t=s(lTe);T(W9.$$.fragment,t$t),t$t.forEach(t),r$t.forEach(t),XEr=i(GQe),iTe=n(GQe,"SPAN",{});var a$t=s(iTe);zEr=r(a$t,"TFAutoModelForCausalLM"),a$t.forEach(t),GQe.forEach(t),PXe=i(f),rr=n(f,"DIV",{class:!0});var kl=s(rr);T(H9.$$.fragment,kl),QEr=i(kl),fc=n(kl,"P",{});var hte=s(fc);WEr=r(hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vJ=n(hte,"A",{href:!0});var n$t=s(vJ);HEr=r(n$t,"from_pretrained()"),n$t.forEach(t),UEr=r(hte," class method or the "),FJ=n(hte,"A",{href:!0});var s$t=s(FJ);JEr=r(s$t,"from_config()"),s$t.forEach(t),YEr=r(hte,` class
method.`),hte.forEach(t),KEr=i(kl),U9=n(kl,"P",{});var OQe=s(U9);ZEr=r(OQe,"This class cannot be instantiated directly using "),dTe=n(OQe,"CODE",{});var l$t=s(dTe);eCr=r(l$t,"__init__()"),l$t.forEach(t),oCr=r(OQe," (throws an error)."),OQe.forEach(t),rCr=i(kl),Rt=n(kl,"DIV",{class:!0});var Z6=s(Rt);T(J9.$$.fragment,Z6),tCr=i(Z6),cTe=n(Z6,"P",{});var i$t=s(cTe);aCr=r(i$t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),i$t.forEach(t),nCr=i(Z6),mc=n(Z6,"P",{});var pte=s(mc);sCr=r(pte,`Note:
Loading a model from its configuration file does `),fTe=n(pte,"STRONG",{});var d$t=s(fTe);lCr=r(d$t,"not"),d$t.forEach(t),iCr=r(pte,` load the model weights. It only affects the
model\u2019s configuration. Use `),TJ=n(pte,"A",{href:!0});var c$t=s(TJ);dCr=r(c$t,"from_pretrained()"),c$t.forEach(t),cCr=r(pte," to load the model weights."),pte.forEach(t),fCr=i(Z6),T(PE.$$.fragment,Z6),Z6.forEach(t),mCr=i(kl),kr=n(kl,"DIV",{class:!0});var Sl=s(kr);T(Y9.$$.fragment,Sl),gCr=i(Sl),mTe=n(Sl,"P",{});var f$t=s(mTe);hCr=r(f$t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),f$t.forEach(t),pCr=i(Sl),dn=n(Sl,"P",{});var eL=s(dn);_Cr=r(eL,"The model class to instantiate is selected based on the "),gTe=n(eL,"CODE",{});var m$t=s(gTe);uCr=r(m$t,"model_type"),m$t.forEach(t),bCr=r(eL,` property of the config object (either
passed as an argument or loaded from `),hTe=n(eL,"CODE",{});var g$t=s(hTe);vCr=r(g$t,"pretrained_model_name_or_path"),g$t.forEach(t),FCr=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=n(eL,"CODE",{});var h$t=s(pTe);TCr=r(h$t,"pretrained_model_name_or_path"),h$t.forEach(t),MCr=r(eL,":"),eL.forEach(t),ECr=i(Sl),Me=n(Sl,"UL",{});var Ce=s(Me);BE=n(Ce,"LI",{});var zqe=s(BE);_Te=n(zqe,"STRONG",{});var p$t=s(_Te);CCr=r(p$t,"bert"),p$t.forEach(t),wCr=r(zqe," \u2014 "),MJ=n(zqe,"A",{href:!0});var _$t=s(MJ);ACr=r(_$t,"TFBertLMHeadModel"),_$t.forEach(t),LCr=r(zqe," (BERT model)"),zqe.forEach(t),yCr=i(Ce),NE=n(Ce,"LI",{});var Qqe=s(NE);uTe=n(Qqe,"STRONG",{});var u$t=s(uTe);xCr=r(u$t,"camembert"),u$t.forEach(t),$Cr=r(Qqe," \u2014 "),EJ=n(Qqe,"A",{href:!0});var b$t=s(EJ);kCr=r(b$t,"TFCamembertForCausalLM"),b$t.forEach(t),SCr=r(Qqe," (CamemBERT model)"),Qqe.forEach(t),RCr=i(Ce),IE=n(Ce,"LI",{});var Wqe=s(IE);bTe=n(Wqe,"STRONG",{});var v$t=s(bTe);PCr=r(v$t,"ctrl"),v$t.forEach(t),BCr=r(Wqe," \u2014 "),CJ=n(Wqe,"A",{href:!0});var F$t=s(CJ);NCr=r(F$t,"TFCTRLLMHeadModel"),F$t.forEach(t),ICr=r(Wqe," (CTRL model)"),Wqe.forEach(t),qCr=i(Ce),qE=n(Ce,"LI",{});var Hqe=s(qE);vTe=n(Hqe,"STRONG",{});var T$t=s(vTe);jCr=r(T$t,"gpt2"),T$t.forEach(t),DCr=r(Hqe," \u2014 "),wJ=n(Hqe,"A",{href:!0});var M$t=s(wJ);GCr=r(M$t,"TFGPT2LMHeadModel"),M$t.forEach(t),OCr=r(Hqe," (OpenAI GPT-2 model)"),Hqe.forEach(t),VCr=i(Ce),jE=n(Ce,"LI",{});var Uqe=s(jE);FTe=n(Uqe,"STRONG",{});var E$t=s(FTe);XCr=r(E$t,"gptj"),E$t.forEach(t),zCr=r(Uqe," \u2014 "),AJ=n(Uqe,"A",{href:!0});var C$t=s(AJ);QCr=r(C$t,"TFGPTJForCausalLM"),C$t.forEach(t),WCr=r(Uqe," (GPT-J model)"),Uqe.forEach(t),HCr=i(Ce),DE=n(Ce,"LI",{});var Jqe=s(DE);TTe=n(Jqe,"STRONG",{});var w$t=s(TTe);UCr=r(w$t,"openai-gpt"),w$t.forEach(t),JCr=r(Jqe," \u2014 "),LJ=n(Jqe,"A",{href:!0});var A$t=s(LJ);YCr=r(A$t,"TFOpenAIGPTLMHeadModel"),A$t.forEach(t),KCr=r(Jqe," (OpenAI GPT model)"),Jqe.forEach(t),ZCr=i(Ce),GE=n(Ce,"LI",{});var Yqe=s(GE);MTe=n(Yqe,"STRONG",{});var L$t=s(MTe);e3r=r(L$t,"opt"),L$t.forEach(t),o3r=r(Yqe," \u2014 "),yJ=n(Yqe,"A",{href:!0});var y$t=s(yJ);r3r=r(y$t,"TFOPTForCausalLM"),y$t.forEach(t),t3r=r(Yqe," (OPT model)"),Yqe.forEach(t),a3r=i(Ce),OE=n(Ce,"LI",{});var Kqe=s(OE);ETe=n(Kqe,"STRONG",{});var x$t=s(ETe);n3r=r(x$t,"rembert"),x$t.forEach(t),s3r=r(Kqe," \u2014 "),xJ=n(Kqe,"A",{href:!0});var $$t=s(xJ);l3r=r($$t,"TFRemBertForCausalLM"),$$t.forEach(t),i3r=r(Kqe," (RemBERT model)"),Kqe.forEach(t),d3r=i(Ce),VE=n(Ce,"LI",{});var Zqe=s(VE);CTe=n(Zqe,"STRONG",{});var k$t=s(CTe);c3r=r(k$t,"roberta"),k$t.forEach(t),f3r=r(Zqe," \u2014 "),$J=n(Zqe,"A",{href:!0});var S$t=s($J);m3r=r(S$t,"TFRobertaForCausalLM"),S$t.forEach(t),g3r=r(Zqe," (RoBERTa model)"),Zqe.forEach(t),h3r=i(Ce),XE=n(Ce,"LI",{});var eje=s(XE);wTe=n(eje,"STRONG",{});var R$t=s(wTe);p3r=r(R$t,"roformer"),R$t.forEach(t),_3r=r(eje," \u2014 "),kJ=n(eje,"A",{href:!0});var P$t=s(kJ);u3r=r(P$t,"TFRoFormerForCausalLM"),P$t.forEach(t),b3r=r(eje," (RoFormer model)"),eje.forEach(t),v3r=i(Ce),zE=n(Ce,"LI",{});var oje=s(zE);ATe=n(oje,"STRONG",{});var B$t=s(ATe);F3r=r(B$t,"transfo-xl"),B$t.forEach(t),T3r=r(oje," \u2014 "),SJ=n(oje,"A",{href:!0});var N$t=s(SJ);M3r=r(N$t,"TFTransfoXLLMHeadModel"),N$t.forEach(t),E3r=r(oje," (Transformer-XL model)"),oje.forEach(t),C3r=i(Ce),QE=n(Ce,"LI",{});var rje=s(QE);LTe=n(rje,"STRONG",{});var I$t=s(LTe);w3r=r(I$t,"xlm"),I$t.forEach(t),A3r=r(rje," \u2014 "),RJ=n(rje,"A",{href:!0});var q$t=s(RJ);L3r=r(q$t,"TFXLMWithLMHeadModel"),q$t.forEach(t),y3r=r(rje," (XLM model)"),rje.forEach(t),x3r=i(Ce),WE=n(Ce,"LI",{});var tje=s(WE);yTe=n(tje,"STRONG",{});var j$t=s(yTe);$3r=r(j$t,"xlnet"),j$t.forEach(t),k3r=r(tje," \u2014 "),PJ=n(tje,"A",{href:!0});var D$t=s(PJ);S3r=r(D$t,"TFXLNetLMHeadModel"),D$t.forEach(t),R3r=r(tje," (XLNet model)"),tje.forEach(t),Ce.forEach(t),P3r=i(Sl),T(HE.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),BXe=i(f),gc=n(f,"H2",{class:!0});var VQe=s(gc);UE=n(VQe,"A",{id:!0,class:!0,href:!0});var G$t=s(UE);xTe=n(G$t,"SPAN",{});var O$t=s(xTe);T(K9.$$.fragment,O$t),O$t.forEach(t),G$t.forEach(t),B3r=i(VQe),$Te=n(VQe,"SPAN",{});var V$t=s($Te);N3r=r(V$t,"TFAutoModelForImageClassification"),V$t.forEach(t),VQe.forEach(t),NXe=i(f),tr=n(f,"DIV",{class:!0});var Rl=s(tr);T(Z9.$$.fragment,Rl),I3r=i(Rl),hc=n(Rl,"P",{});var _te=s(hc);q3r=r(_te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),BJ=n(_te,"A",{href:!0});var X$t=s(BJ);j3r=r(X$t,"from_pretrained()"),X$t.forEach(t),D3r=r(_te," class method or the "),NJ=n(_te,"A",{href:!0});var z$t=s(NJ);G3r=r(z$t,"from_config()"),z$t.forEach(t),O3r=r(_te,` class
method.`),_te.forEach(t),V3r=i(Rl),ex=n(Rl,"P",{});var XQe=s(ex);X3r=r(XQe,"This class cannot be instantiated directly using "),kTe=n(XQe,"CODE",{});var Q$t=s(kTe);z3r=r(Q$t,"__init__()"),Q$t.forEach(t),Q3r=r(XQe," (throws an error)."),XQe.forEach(t),W3r=i(Rl),Pt=n(Rl,"DIV",{class:!0});var oL=s(Pt);T(ox.$$.fragment,oL),H3r=i(oL),STe=n(oL,"P",{});var W$t=s(STe);U3r=r(W$t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),W$t.forEach(t),J3r=i(oL),pc=n(oL,"P",{});var ute=s(pc);Y3r=r(ute,`Note:
Loading a model from its configuration file does `),RTe=n(ute,"STRONG",{});var H$t=s(RTe);K3r=r(H$t,"not"),H$t.forEach(t),Z3r=r(ute,` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=n(ute,"A",{href:!0});var U$t=s(IJ);e5r=r(U$t,"from_pretrained()"),U$t.forEach(t),o5r=r(ute," to load the model weights."),ute.forEach(t),r5r=i(oL),T(JE.$$.fragment,oL),oL.forEach(t),t5r=i(Rl),Sr=n(Rl,"DIV",{class:!0});var Pl=s(Sr);T(rx.$$.fragment,Pl),a5r=i(Pl),PTe=n(Pl,"P",{});var J$t=s(PTe);n5r=r(J$t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),J$t.forEach(t),s5r=i(Pl),cn=n(Pl,"P",{});var rL=s(cn);l5r=r(rL,"The model class to instantiate is selected based on the "),BTe=n(rL,"CODE",{});var Y$t=s(BTe);i5r=r(Y$t,"model_type"),Y$t.forEach(t),d5r=r(rL,` property of the config object (either
passed as an argument or loaded from `),NTe=n(rL,"CODE",{});var K$t=s(NTe);c5r=r(K$t,"pretrained_model_name_or_path"),K$t.forEach(t),f5r=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ITe=n(rL,"CODE",{});var Z$t=s(ITe);m5r=r(Z$t,"pretrained_model_name_or_path"),Z$t.forEach(t),g5r=r(rL,":"),rL.forEach(t),h5r=i(Pl),ar=n(Pl,"UL",{});var $a=s(ar);YE=n($a,"LI",{});var aje=s(YE);qTe=n(aje,"STRONG",{});var ekt=s(qTe);p5r=r(ekt,"convnext"),ekt.forEach(t),_5r=r(aje," \u2014 "),qJ=n(aje,"A",{href:!0});var okt=s(qJ);u5r=r(okt,"TFConvNextForImageClassification"),okt.forEach(t),b5r=r(aje," (ConvNeXT model)"),aje.forEach(t),v5r=i($a),KE=n($a,"LI",{});var nje=s(KE);jTe=n(nje,"STRONG",{});var rkt=s(jTe);F5r=r(rkt,"data2vec-vision"),rkt.forEach(t),T5r=r(nje," \u2014 "),jJ=n(nje,"A",{href:!0});var tkt=s(jJ);M5r=r(tkt,"TFData2VecVisionForImageClassification"),tkt.forEach(t),E5r=r(nje," (Data2VecVision model)"),nje.forEach(t),C5r=i($a),ZE=n($a,"LI",{});var sje=s(ZE);DTe=n(sje,"STRONG",{});var akt=s(DTe);w5r=r(akt,"regnet"),akt.forEach(t),A5r=r(sje," \u2014 "),DJ=n(sje,"A",{href:!0});var nkt=s(DJ);L5r=r(nkt,"TFRegNetForImageClassification"),nkt.forEach(t),y5r=r(sje," (RegNet model)"),sje.forEach(t),x5r=i($a),eC=n($a,"LI",{});var lje=s(eC);GTe=n(lje,"STRONG",{});var skt=s(GTe);$5r=r(skt,"resnet"),skt.forEach(t),k5r=r(lje," \u2014 "),GJ=n(lje,"A",{href:!0});var lkt=s(GJ);S5r=r(lkt,"TFResNetForImageClassification"),lkt.forEach(t),R5r=r(lje," (ResNet model)"),lje.forEach(t),P5r=i($a),oC=n($a,"LI",{});var ije=s(oC);OTe=n(ije,"STRONG",{});var ikt=s(OTe);B5r=r(ikt,"swin"),ikt.forEach(t),N5r=r(ije," \u2014 "),OJ=n(ije,"A",{href:!0});var dkt=s(OJ);I5r=r(dkt,"TFSwinForImageClassification"),dkt.forEach(t),q5r=r(ije," (Swin Transformer model)"),ije.forEach(t),j5r=i($a),rC=n($a,"LI",{});var dje=s(rC);VTe=n(dje,"STRONG",{});var ckt=s(VTe);D5r=r(ckt,"vit"),ckt.forEach(t),G5r=r(dje," \u2014 "),VJ=n(dje,"A",{href:!0});var fkt=s(VJ);O5r=r(fkt,"TFViTForImageClassification"),fkt.forEach(t),V5r=r(dje," (ViT model)"),dje.forEach(t),$a.forEach(t),X5r=i(Pl),T(tC.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),IXe=i(f),_c=n(f,"H2",{class:!0});var zQe=s(_c);aC=n(zQe,"A",{id:!0,class:!0,href:!0});var mkt=s(aC);XTe=n(mkt,"SPAN",{});var gkt=s(XTe);T(tx.$$.fragment,gkt),gkt.forEach(t),mkt.forEach(t),z5r=i(zQe),zTe=n(zQe,"SPAN",{});var hkt=s(zTe);Q5r=r(hkt,"TFAutoModelForMaskedLM"),hkt.forEach(t),zQe.forEach(t),qXe=i(f),nr=n(f,"DIV",{class:!0});var Bl=s(nr);T(ax.$$.fragment,Bl),W5r=i(Bl),uc=n(Bl,"P",{});var bte=s(uc);H5r=r(bte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),XJ=n(bte,"A",{href:!0});var pkt=s(XJ);U5r=r(pkt,"from_pretrained()"),pkt.forEach(t),J5r=r(bte," class method or the "),zJ=n(bte,"A",{href:!0});var _kt=s(zJ);Y5r=r(_kt,"from_config()"),_kt.forEach(t),K5r=r(bte,` class
method.`),bte.forEach(t),Z5r=i(Bl),nx=n(Bl,"P",{});var QQe=s(nx);e0r=r(QQe,"This class cannot be instantiated directly using "),QTe=n(QQe,"CODE",{});var ukt=s(QTe);o0r=r(ukt,"__init__()"),ukt.forEach(t),r0r=r(QQe," (throws an error)."),QQe.forEach(t),t0r=i(Bl),Bt=n(Bl,"DIV",{class:!0});var tL=s(Bt);T(sx.$$.fragment,tL),a0r=i(tL),WTe=n(tL,"P",{});var bkt=s(WTe);n0r=r(bkt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),bkt.forEach(t),s0r=i(tL),bc=n(tL,"P",{});var vte=s(bc);l0r=r(vte,`Note:
Loading a model from its configuration file does `),HTe=n(vte,"STRONG",{});var vkt=s(HTe);i0r=r(vkt,"not"),vkt.forEach(t),d0r=r(vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(vte,"A",{href:!0});var Fkt=s(QJ);c0r=r(Fkt,"from_pretrained()"),Fkt.forEach(t),f0r=r(vte," to load the model weights."),vte.forEach(t),m0r=i(tL),T(nC.$$.fragment,tL),tL.forEach(t),g0r=i(Bl),Rr=n(Bl,"DIV",{class:!0});var Nl=s(Rr);T(lx.$$.fragment,Nl),h0r=i(Nl),UTe=n(Nl,"P",{});var Tkt=s(UTe);p0r=r(Tkt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Tkt.forEach(t),_0r=i(Nl),fn=n(Nl,"P",{});var aL=s(fn);u0r=r(aL,"The model class to instantiate is selected based on the "),JTe=n(aL,"CODE",{});var Mkt=s(JTe);b0r=r(Mkt,"model_type"),Mkt.forEach(t),v0r=r(aL,` property of the config object (either
passed as an argument or loaded from `),YTe=n(aL,"CODE",{});var Ekt=s(YTe);F0r=r(Ekt,"pretrained_model_name_or_path"),Ekt.forEach(t),T0r=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KTe=n(aL,"CODE",{});var Ckt=s(KTe);M0r=r(Ckt,"pretrained_model_name_or_path"),Ckt.forEach(t),E0r=r(aL,":"),aL.forEach(t),C0r=i(Nl),ie=n(Nl,"UL",{});var fe=s(ie);sC=n(fe,"LI",{});var cje=s(sC);ZTe=n(cje,"STRONG",{});var wkt=s(ZTe);w0r=r(wkt,"albert"),wkt.forEach(t),A0r=r(cje," \u2014 "),WJ=n(cje,"A",{href:!0});var Akt=s(WJ);L0r=r(Akt,"TFAlbertForMaskedLM"),Akt.forEach(t),y0r=r(cje," (ALBERT model)"),cje.forEach(t),x0r=i(fe),lC=n(fe,"LI",{});var fje=s(lC);eMe=n(fje,"STRONG",{});var Lkt=s(eMe);$0r=r(Lkt,"bert"),Lkt.forEach(t),k0r=r(fje," \u2014 "),HJ=n(fje,"A",{href:!0});var ykt=s(HJ);S0r=r(ykt,"TFBertForMaskedLM"),ykt.forEach(t),R0r=r(fje," (BERT model)"),fje.forEach(t),P0r=i(fe),iC=n(fe,"LI",{});var mje=s(iC);oMe=n(mje,"STRONG",{});var xkt=s(oMe);B0r=r(xkt,"camembert"),xkt.forEach(t),N0r=r(mje," \u2014 "),UJ=n(mje,"A",{href:!0});var $kt=s(UJ);I0r=r($kt,"TFCamembertForMaskedLM"),$kt.forEach(t),q0r=r(mje," (CamemBERT model)"),mje.forEach(t),j0r=i(fe),dC=n(fe,"LI",{});var gje=s(dC);rMe=n(gje,"STRONG",{});var kkt=s(rMe);D0r=r(kkt,"convbert"),kkt.forEach(t),G0r=r(gje," \u2014 "),JJ=n(gje,"A",{href:!0});var Skt=s(JJ);O0r=r(Skt,"TFConvBertForMaskedLM"),Skt.forEach(t),V0r=r(gje," (ConvBERT model)"),gje.forEach(t),X0r=i(fe),cC=n(fe,"LI",{});var hje=s(cC);tMe=n(hje,"STRONG",{});var Rkt=s(tMe);z0r=r(Rkt,"deberta"),Rkt.forEach(t),Q0r=r(hje," \u2014 "),YJ=n(hje,"A",{href:!0});var Pkt=s(YJ);W0r=r(Pkt,"TFDebertaForMaskedLM"),Pkt.forEach(t),H0r=r(hje," (DeBERTa model)"),hje.forEach(t),U0r=i(fe),fC=n(fe,"LI",{});var pje=s(fC);aMe=n(pje,"STRONG",{});var Bkt=s(aMe);J0r=r(Bkt,"deberta-v2"),Bkt.forEach(t),Y0r=r(pje," \u2014 "),KJ=n(pje,"A",{href:!0});var Nkt=s(KJ);K0r=r(Nkt,"TFDebertaV2ForMaskedLM"),Nkt.forEach(t),Z0r=r(pje," (DeBERTa-v2 model)"),pje.forEach(t),ewr=i(fe),mC=n(fe,"LI",{});var _je=s(mC);nMe=n(_je,"STRONG",{});var Ikt=s(nMe);owr=r(Ikt,"distilbert"),Ikt.forEach(t),rwr=r(_je," \u2014 "),ZJ=n(_je,"A",{href:!0});var qkt=s(ZJ);twr=r(qkt,"TFDistilBertForMaskedLM"),qkt.forEach(t),awr=r(_je," (DistilBERT model)"),_je.forEach(t),nwr=i(fe),gC=n(fe,"LI",{});var uje=s(gC);sMe=n(uje,"STRONG",{});var jkt=s(sMe);swr=r(jkt,"electra"),jkt.forEach(t),lwr=r(uje," \u2014 "),eY=n(uje,"A",{href:!0});var Dkt=s(eY);iwr=r(Dkt,"TFElectraForMaskedLM"),Dkt.forEach(t),dwr=r(uje," (ELECTRA model)"),uje.forEach(t),cwr=i(fe),hC=n(fe,"LI",{});var bje=s(hC);lMe=n(bje,"STRONG",{});var Gkt=s(lMe);fwr=r(Gkt,"flaubert"),Gkt.forEach(t),mwr=r(bje," \u2014 "),oY=n(bje,"A",{href:!0});var Okt=s(oY);gwr=r(Okt,"TFFlaubertWithLMHeadModel"),Okt.forEach(t),hwr=r(bje," (FlauBERT model)"),bje.forEach(t),pwr=i(fe),pC=n(fe,"LI",{});var vje=s(pC);iMe=n(vje,"STRONG",{});var Vkt=s(iMe);_wr=r(Vkt,"funnel"),Vkt.forEach(t),uwr=r(vje," \u2014 "),rY=n(vje,"A",{href:!0});var Xkt=s(rY);bwr=r(Xkt,"TFFunnelForMaskedLM"),Xkt.forEach(t),vwr=r(vje," (Funnel Transformer model)"),vje.forEach(t),Fwr=i(fe),_C=n(fe,"LI",{});var Fje=s(_C);dMe=n(Fje,"STRONG",{});var zkt=s(dMe);Twr=r(zkt,"layoutlm"),zkt.forEach(t),Mwr=r(Fje," \u2014 "),tY=n(Fje,"A",{href:!0});var Qkt=s(tY);Ewr=r(Qkt,"TFLayoutLMForMaskedLM"),Qkt.forEach(t),Cwr=r(Fje," (LayoutLM model)"),Fje.forEach(t),wwr=i(fe),uC=n(fe,"LI",{});var Tje=s(uC);cMe=n(Tje,"STRONG",{});var Wkt=s(cMe);Awr=r(Wkt,"longformer"),Wkt.forEach(t),Lwr=r(Tje," \u2014 "),aY=n(Tje,"A",{href:!0});var Hkt=s(aY);ywr=r(Hkt,"TFLongformerForMaskedLM"),Hkt.forEach(t),xwr=r(Tje," (Longformer model)"),Tje.forEach(t),$wr=i(fe),bC=n(fe,"LI",{});var Mje=s(bC);fMe=n(Mje,"STRONG",{});var Ukt=s(fMe);kwr=r(Ukt,"mobilebert"),Ukt.forEach(t),Swr=r(Mje," \u2014 "),nY=n(Mje,"A",{href:!0});var Jkt=s(nY);Rwr=r(Jkt,"TFMobileBertForMaskedLM"),Jkt.forEach(t),Pwr=r(Mje," (MobileBERT model)"),Mje.forEach(t),Bwr=i(fe),vC=n(fe,"LI",{});var Eje=s(vC);mMe=n(Eje,"STRONG",{});var Ykt=s(mMe);Nwr=r(Ykt,"mpnet"),Ykt.forEach(t),Iwr=r(Eje," \u2014 "),sY=n(Eje,"A",{href:!0});var Kkt=s(sY);qwr=r(Kkt,"TFMPNetForMaskedLM"),Kkt.forEach(t),jwr=r(Eje," (MPNet model)"),Eje.forEach(t),Dwr=i(fe),FC=n(fe,"LI",{});var Cje=s(FC);gMe=n(Cje,"STRONG",{});var Zkt=s(gMe);Gwr=r(Zkt,"rembert"),Zkt.forEach(t),Owr=r(Cje," \u2014 "),lY=n(Cje,"A",{href:!0});var eSt=s(lY);Vwr=r(eSt,"TFRemBertForMaskedLM"),eSt.forEach(t),Xwr=r(Cje," (RemBERT model)"),Cje.forEach(t),zwr=i(fe),TC=n(fe,"LI",{});var wje=s(TC);hMe=n(wje,"STRONG",{});var oSt=s(hMe);Qwr=r(oSt,"roberta"),oSt.forEach(t),Wwr=r(wje," \u2014 "),iY=n(wje,"A",{href:!0});var rSt=s(iY);Hwr=r(rSt,"TFRobertaForMaskedLM"),rSt.forEach(t),Uwr=r(wje," (RoBERTa model)"),wje.forEach(t),Jwr=i(fe),MC=n(fe,"LI",{});var Aje=s(MC);pMe=n(Aje,"STRONG",{});var tSt=s(pMe);Ywr=r(tSt,"roformer"),tSt.forEach(t),Kwr=r(Aje," \u2014 "),dY=n(Aje,"A",{href:!0});var aSt=s(dY);Zwr=r(aSt,"TFRoFormerForMaskedLM"),aSt.forEach(t),eAr=r(Aje," (RoFormer model)"),Aje.forEach(t),oAr=i(fe),EC=n(fe,"LI",{});var Lje=s(EC);_Me=n(Lje,"STRONG",{});var nSt=s(_Me);rAr=r(nSt,"tapas"),nSt.forEach(t),tAr=r(Lje," \u2014 "),cY=n(Lje,"A",{href:!0});var sSt=s(cY);aAr=r(sSt,"TFTapasForMaskedLM"),sSt.forEach(t),nAr=r(Lje," (TAPAS model)"),Lje.forEach(t),sAr=i(fe),CC=n(fe,"LI",{});var yje=s(CC);uMe=n(yje,"STRONG",{});var lSt=s(uMe);lAr=r(lSt,"xlm"),lSt.forEach(t),iAr=r(yje," \u2014 "),fY=n(yje,"A",{href:!0});var iSt=s(fY);dAr=r(iSt,"TFXLMWithLMHeadModel"),iSt.forEach(t),cAr=r(yje," (XLM model)"),yje.forEach(t),fAr=i(fe),wC=n(fe,"LI",{});var xje=s(wC);bMe=n(xje,"STRONG",{});var dSt=s(bMe);mAr=r(dSt,"xlm-roberta"),dSt.forEach(t),gAr=r(xje," \u2014 "),mY=n(xje,"A",{href:!0});var cSt=s(mY);hAr=r(cSt,"TFXLMRobertaForMaskedLM"),cSt.forEach(t),pAr=r(xje," (XLM-RoBERTa model)"),xje.forEach(t),fe.forEach(t),_Ar=i(Nl),T(AC.$$.fragment,Nl),Nl.forEach(t),Bl.forEach(t),jXe=i(f),vc=n(f,"H2",{class:!0});var WQe=s(vc);LC=n(WQe,"A",{id:!0,class:!0,href:!0});var fSt=s(LC);vMe=n(fSt,"SPAN",{});var mSt=s(vMe);T(ix.$$.fragment,mSt),mSt.forEach(t),fSt.forEach(t),uAr=i(WQe),FMe=n(WQe,"SPAN",{});var gSt=s(FMe);bAr=r(gSt,"TFAutoModelForSeq2SeqLM"),gSt.forEach(t),WQe.forEach(t),DXe=i(f),sr=n(f,"DIV",{class:!0});var Il=s(sr);T(dx.$$.fragment,Il),vAr=i(Il),Fc=n(Il,"P",{});var Fte=s(Fc);FAr=r(Fte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gY=n(Fte,"A",{href:!0});var hSt=s(gY);TAr=r(hSt,"from_pretrained()"),hSt.forEach(t),MAr=r(Fte," class method or the "),hY=n(Fte,"A",{href:!0});var pSt=s(hY);EAr=r(pSt,"from_config()"),pSt.forEach(t),CAr=r(Fte,` class
method.`),Fte.forEach(t),wAr=i(Il),cx=n(Il,"P",{});var HQe=s(cx);AAr=r(HQe,"This class cannot be instantiated directly using "),TMe=n(HQe,"CODE",{});var _St=s(TMe);LAr=r(_St,"__init__()"),_St.forEach(t),yAr=r(HQe," (throws an error)."),HQe.forEach(t),xAr=i(Il),Nt=n(Il,"DIV",{class:!0});var nL=s(Nt);T(fx.$$.fragment,nL),$Ar=i(nL),MMe=n(nL,"P",{});var uSt=s(MMe);kAr=r(uSt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),uSt.forEach(t),SAr=i(nL),Tc=n(nL,"P",{});var Tte=s(Tc);RAr=r(Tte,`Note:
Loading a model from its configuration file does `),EMe=n(Tte,"STRONG",{});var bSt=s(EMe);PAr=r(bSt,"not"),bSt.forEach(t),BAr=r(Tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),pY=n(Tte,"A",{href:!0});var vSt=s(pY);NAr=r(vSt,"from_pretrained()"),vSt.forEach(t),IAr=r(Tte," to load the model weights."),Tte.forEach(t),qAr=i(nL),T(yC.$$.fragment,nL),nL.forEach(t),jAr=i(Il),Pr=n(Il,"DIV",{class:!0});var ql=s(Pr);T(mx.$$.fragment,ql),DAr=i(ql),CMe=n(ql,"P",{});var FSt=s(CMe);GAr=r(FSt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),FSt.forEach(t),OAr=i(ql),mn=n(ql,"P",{});var sL=s(mn);VAr=r(sL,"The model class to instantiate is selected based on the "),wMe=n(sL,"CODE",{});var TSt=s(wMe);XAr=r(TSt,"model_type"),TSt.forEach(t),zAr=r(sL,` property of the config object (either
passed as an argument or loaded from `),AMe=n(sL,"CODE",{});var MSt=s(AMe);QAr=r(MSt,"pretrained_model_name_or_path"),MSt.forEach(t),WAr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LMe=n(sL,"CODE",{});var ESt=s(LMe);HAr=r(ESt,"pretrained_model_name_or_path"),ESt.forEach(t),UAr=r(sL,":"),sL.forEach(t),JAr=i(ql),ye=n(ql,"UL",{});var Ne=s(ye);xC=n(Ne,"LI",{});var $je=s(xC);yMe=n($je,"STRONG",{});var CSt=s(yMe);YAr=r(CSt,"bart"),CSt.forEach(t),KAr=r($je," \u2014 "),_Y=n($je,"A",{href:!0});var wSt=s(_Y);ZAr=r(wSt,"TFBartForConditionalGeneration"),wSt.forEach(t),e6r=r($je," (BART model)"),$je.forEach(t),o6r=i(Ne),$C=n(Ne,"LI",{});var kje=s($C);xMe=n(kje,"STRONG",{});var ASt=s(xMe);r6r=r(ASt,"blenderbot"),ASt.forEach(t),t6r=r(kje," \u2014 "),uY=n(kje,"A",{href:!0});var LSt=s(uY);a6r=r(LSt,"TFBlenderbotForConditionalGeneration"),LSt.forEach(t),n6r=r(kje," (Blenderbot model)"),kje.forEach(t),s6r=i(Ne),kC=n(Ne,"LI",{});var Sje=s(kC);$Me=n(Sje,"STRONG",{});var ySt=s($Me);l6r=r(ySt,"blenderbot-small"),ySt.forEach(t),i6r=r(Sje," \u2014 "),bY=n(Sje,"A",{href:!0});var xSt=s(bY);d6r=r(xSt,"TFBlenderbotSmallForConditionalGeneration"),xSt.forEach(t),c6r=r(Sje," (BlenderbotSmall model)"),Sje.forEach(t),f6r=i(Ne),SC=n(Ne,"LI",{});var Rje=s(SC);kMe=n(Rje,"STRONG",{});var $St=s(kMe);m6r=r($St,"encoder-decoder"),$St.forEach(t),g6r=r(Rje," \u2014 "),vY=n(Rje,"A",{href:!0});var kSt=s(vY);h6r=r(kSt,"TFEncoderDecoderModel"),kSt.forEach(t),p6r=r(Rje," (Encoder decoder model)"),Rje.forEach(t),_6r=i(Ne),RC=n(Ne,"LI",{});var Pje=s(RC);SMe=n(Pje,"STRONG",{});var SSt=s(SMe);u6r=r(SSt,"led"),SSt.forEach(t),b6r=r(Pje," \u2014 "),FY=n(Pje,"A",{href:!0});var RSt=s(FY);v6r=r(RSt,"TFLEDForConditionalGeneration"),RSt.forEach(t),F6r=r(Pje," (LED model)"),Pje.forEach(t),T6r=i(Ne),PC=n(Ne,"LI",{});var Bje=s(PC);RMe=n(Bje,"STRONG",{});var PSt=s(RMe);M6r=r(PSt,"marian"),PSt.forEach(t),E6r=r(Bje," \u2014 "),TY=n(Bje,"A",{href:!0});var BSt=s(TY);C6r=r(BSt,"TFMarianMTModel"),BSt.forEach(t),w6r=r(Bje," (Marian model)"),Bje.forEach(t),A6r=i(Ne),BC=n(Ne,"LI",{});var Nje=s(BC);PMe=n(Nje,"STRONG",{});var NSt=s(PMe);L6r=r(NSt,"mbart"),NSt.forEach(t),y6r=r(Nje," \u2014 "),MY=n(Nje,"A",{href:!0});var ISt=s(MY);x6r=r(ISt,"TFMBartForConditionalGeneration"),ISt.forEach(t),$6r=r(Nje," (mBART model)"),Nje.forEach(t),k6r=i(Ne),NC=n(Ne,"LI",{});var Ije=s(NC);BMe=n(Ije,"STRONG",{});var qSt=s(BMe);S6r=r(qSt,"mt5"),qSt.forEach(t),R6r=r(Ije," \u2014 "),EY=n(Ije,"A",{href:!0});var jSt=s(EY);P6r=r(jSt,"TFMT5ForConditionalGeneration"),jSt.forEach(t),B6r=r(Ije," (MT5 model)"),Ije.forEach(t),N6r=i(Ne),IC=n(Ne,"LI",{});var qje=s(IC);NMe=n(qje,"STRONG",{});var DSt=s(NMe);I6r=r(DSt,"pegasus"),DSt.forEach(t),q6r=r(qje," \u2014 "),CY=n(qje,"A",{href:!0});var GSt=s(CY);j6r=r(GSt,"TFPegasusForConditionalGeneration"),GSt.forEach(t),D6r=r(qje," (Pegasus model)"),qje.forEach(t),G6r=i(Ne),qC=n(Ne,"LI",{});var jje=s(qC);IMe=n(jje,"STRONG",{});var OSt=s(IMe);O6r=r(OSt,"t5"),OSt.forEach(t),V6r=r(jje," \u2014 "),wY=n(jje,"A",{href:!0});var VSt=s(wY);X6r=r(VSt,"TFT5ForConditionalGeneration"),VSt.forEach(t),z6r=r(jje," (T5 model)"),jje.forEach(t),Ne.forEach(t),Q6r=i(ql),T(jC.$$.fragment,ql),ql.forEach(t),Il.forEach(t),GXe=i(f),Mc=n(f,"H2",{class:!0});var UQe=s(Mc);DC=n(UQe,"A",{id:!0,class:!0,href:!0});var XSt=s(DC);qMe=n(XSt,"SPAN",{});var zSt=s(qMe);T(gx.$$.fragment,zSt),zSt.forEach(t),XSt.forEach(t),W6r=i(UQe),jMe=n(UQe,"SPAN",{});var QSt=s(jMe);H6r=r(QSt,"TFAutoModelForSequenceClassification"),QSt.forEach(t),UQe.forEach(t),OXe=i(f),lr=n(f,"DIV",{class:!0});var jl=s(lr);T(hx.$$.fragment,jl),U6r=i(jl),Ec=n(jl,"P",{});var Mte=s(Ec);J6r=r(Mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),AY=n(Mte,"A",{href:!0});var WSt=s(AY);Y6r=r(WSt,"from_pretrained()"),WSt.forEach(t),K6r=r(Mte," class method or the "),LY=n(Mte,"A",{href:!0});var HSt=s(LY);Z6r=r(HSt,"from_config()"),HSt.forEach(t),eLr=r(Mte,` class
method.`),Mte.forEach(t),oLr=i(jl),px=n(jl,"P",{});var JQe=s(px);rLr=r(JQe,"This class cannot be instantiated directly using "),DMe=n(JQe,"CODE",{});var USt=s(DMe);tLr=r(USt,"__init__()"),USt.forEach(t),aLr=r(JQe," (throws an error)."),JQe.forEach(t),nLr=i(jl),It=n(jl,"DIV",{class:!0});var lL=s(It);T(_x.$$.fragment,lL),sLr=i(lL),GMe=n(lL,"P",{});var JSt=s(GMe);lLr=r(JSt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),JSt.forEach(t),iLr=i(lL),Cc=n(lL,"P",{});var Ete=s(Cc);dLr=r(Ete,`Note:
Loading a model from its configuration file does `),OMe=n(Ete,"STRONG",{});var YSt=s(OMe);cLr=r(YSt,"not"),YSt.forEach(t),fLr=r(Ete,` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=n(Ete,"A",{href:!0});var KSt=s(yY);mLr=r(KSt,"from_pretrained()"),KSt.forEach(t),gLr=r(Ete," to load the model weights."),Ete.forEach(t),hLr=i(lL),T(GC.$$.fragment,lL),lL.forEach(t),pLr=i(jl),Br=n(jl,"DIV",{class:!0});var Dl=s(Br);T(ux.$$.fragment,Dl),_Lr=i(Dl),VMe=n(Dl,"P",{});var ZSt=s(VMe);uLr=r(ZSt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ZSt.forEach(t),bLr=i(Dl),gn=n(Dl,"P",{});var iL=s(gn);vLr=r(iL,"The model class to instantiate is selected based on the "),XMe=n(iL,"CODE",{});var eRt=s(XMe);FLr=r(eRt,"model_type"),eRt.forEach(t),TLr=r(iL,` property of the config object (either
passed as an argument or loaded from `),zMe=n(iL,"CODE",{});var oRt=s(zMe);MLr=r(oRt,"pretrained_model_name_or_path"),oRt.forEach(t),ELr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QMe=n(iL,"CODE",{});var rRt=s(QMe);CLr=r(rRt,"pretrained_model_name_or_path"),rRt.forEach(t),wLr=r(iL,":"),iL.forEach(t),ALr=i(Dl),te=n(Dl,"UL",{});var ne=s(te);OC=n(ne,"LI",{});var Dje=s(OC);WMe=n(Dje,"STRONG",{});var tRt=s(WMe);LLr=r(tRt,"albert"),tRt.forEach(t),yLr=r(Dje," \u2014 "),xY=n(Dje,"A",{href:!0});var aRt=s(xY);xLr=r(aRt,"TFAlbertForSequenceClassification"),aRt.forEach(t),$Lr=r(Dje," (ALBERT model)"),Dje.forEach(t),kLr=i(ne),VC=n(ne,"LI",{});var Gje=s(VC);HMe=n(Gje,"STRONG",{});var nRt=s(HMe);SLr=r(nRt,"bert"),nRt.forEach(t),RLr=r(Gje," \u2014 "),$Y=n(Gje,"A",{href:!0});var sRt=s($Y);PLr=r(sRt,"TFBertForSequenceClassification"),sRt.forEach(t),BLr=r(Gje," (BERT model)"),Gje.forEach(t),NLr=i(ne),XC=n(ne,"LI",{});var Oje=s(XC);UMe=n(Oje,"STRONG",{});var lRt=s(UMe);ILr=r(lRt,"camembert"),lRt.forEach(t),qLr=r(Oje," \u2014 "),kY=n(Oje,"A",{href:!0});var iRt=s(kY);jLr=r(iRt,"TFCamembertForSequenceClassification"),iRt.forEach(t),DLr=r(Oje," (CamemBERT model)"),Oje.forEach(t),GLr=i(ne),zC=n(ne,"LI",{});var Vje=s(zC);JMe=n(Vje,"STRONG",{});var dRt=s(JMe);OLr=r(dRt,"convbert"),dRt.forEach(t),VLr=r(Vje," \u2014 "),SY=n(Vje,"A",{href:!0});var cRt=s(SY);XLr=r(cRt,"TFConvBertForSequenceClassification"),cRt.forEach(t),zLr=r(Vje," (ConvBERT model)"),Vje.forEach(t),QLr=i(ne),QC=n(ne,"LI",{});var Xje=s(QC);YMe=n(Xje,"STRONG",{});var fRt=s(YMe);WLr=r(fRt,"ctrl"),fRt.forEach(t),HLr=r(Xje," \u2014 "),RY=n(Xje,"A",{href:!0});var mRt=s(RY);ULr=r(mRt,"TFCTRLForSequenceClassification"),mRt.forEach(t),JLr=r(Xje," (CTRL model)"),Xje.forEach(t),YLr=i(ne),WC=n(ne,"LI",{});var zje=s(WC);KMe=n(zje,"STRONG",{});var gRt=s(KMe);KLr=r(gRt,"deberta"),gRt.forEach(t),ZLr=r(zje," \u2014 "),PY=n(zje,"A",{href:!0});var hRt=s(PY);eyr=r(hRt,"TFDebertaForSequenceClassification"),hRt.forEach(t),oyr=r(zje," (DeBERTa model)"),zje.forEach(t),ryr=i(ne),HC=n(ne,"LI",{});var Qje=s(HC);ZMe=n(Qje,"STRONG",{});var pRt=s(ZMe);tyr=r(pRt,"deberta-v2"),pRt.forEach(t),ayr=r(Qje," \u2014 "),BY=n(Qje,"A",{href:!0});var _Rt=s(BY);nyr=r(_Rt,"TFDebertaV2ForSequenceClassification"),_Rt.forEach(t),syr=r(Qje," (DeBERTa-v2 model)"),Qje.forEach(t),lyr=i(ne),UC=n(ne,"LI",{});var Wje=s(UC);eEe=n(Wje,"STRONG",{});var uRt=s(eEe);iyr=r(uRt,"distilbert"),uRt.forEach(t),dyr=r(Wje," \u2014 "),NY=n(Wje,"A",{href:!0});var bRt=s(NY);cyr=r(bRt,"TFDistilBertForSequenceClassification"),bRt.forEach(t),fyr=r(Wje," (DistilBERT model)"),Wje.forEach(t),myr=i(ne),JC=n(ne,"LI",{});var Hje=s(JC);oEe=n(Hje,"STRONG",{});var vRt=s(oEe);gyr=r(vRt,"electra"),vRt.forEach(t),hyr=r(Hje," \u2014 "),IY=n(Hje,"A",{href:!0});var FRt=s(IY);pyr=r(FRt,"TFElectraForSequenceClassification"),FRt.forEach(t),_yr=r(Hje," (ELECTRA model)"),Hje.forEach(t),uyr=i(ne),YC=n(ne,"LI",{});var Uje=s(YC);rEe=n(Uje,"STRONG",{});var TRt=s(rEe);byr=r(TRt,"flaubert"),TRt.forEach(t),vyr=r(Uje," \u2014 "),qY=n(Uje,"A",{href:!0});var MRt=s(qY);Fyr=r(MRt,"TFFlaubertForSequenceClassification"),MRt.forEach(t),Tyr=r(Uje," (FlauBERT model)"),Uje.forEach(t),Myr=i(ne),KC=n(ne,"LI",{});var Jje=s(KC);tEe=n(Jje,"STRONG",{});var ERt=s(tEe);Eyr=r(ERt,"funnel"),ERt.forEach(t),Cyr=r(Jje," \u2014 "),jY=n(Jje,"A",{href:!0});var CRt=s(jY);wyr=r(CRt,"TFFunnelForSequenceClassification"),CRt.forEach(t),Ayr=r(Jje," (Funnel Transformer model)"),Jje.forEach(t),Lyr=i(ne),ZC=n(ne,"LI",{});var Yje=s(ZC);aEe=n(Yje,"STRONG",{});var wRt=s(aEe);yyr=r(wRt,"gpt2"),wRt.forEach(t),xyr=r(Yje," \u2014 "),DY=n(Yje,"A",{href:!0});var ARt=s(DY);$yr=r(ARt,"TFGPT2ForSequenceClassification"),ARt.forEach(t),kyr=r(Yje," (OpenAI GPT-2 model)"),Yje.forEach(t),Syr=i(ne),e3=n(ne,"LI",{});var Kje=s(e3);nEe=n(Kje,"STRONG",{});var LRt=s(nEe);Ryr=r(LRt,"gptj"),LRt.forEach(t),Pyr=r(Kje," \u2014 "),GY=n(Kje,"A",{href:!0});var yRt=s(GY);Byr=r(yRt,"TFGPTJForSequenceClassification"),yRt.forEach(t),Nyr=r(Kje," (GPT-J model)"),Kje.forEach(t),Iyr=i(ne),o3=n(ne,"LI",{});var Zje=s(o3);sEe=n(Zje,"STRONG",{});var xRt=s(sEe);qyr=r(xRt,"layoutlm"),xRt.forEach(t),jyr=r(Zje," \u2014 "),OY=n(Zje,"A",{href:!0});var $Rt=s(OY);Dyr=r($Rt,"TFLayoutLMForSequenceClassification"),$Rt.forEach(t),Gyr=r(Zje," (LayoutLM model)"),Zje.forEach(t),Oyr=i(ne),r3=n(ne,"LI",{});var eDe=s(r3);lEe=n(eDe,"STRONG",{});var kRt=s(lEe);Vyr=r(kRt,"longformer"),kRt.forEach(t),Xyr=r(eDe," \u2014 "),VY=n(eDe,"A",{href:!0});var SRt=s(VY);zyr=r(SRt,"TFLongformerForSequenceClassification"),SRt.forEach(t),Qyr=r(eDe," (Longformer model)"),eDe.forEach(t),Wyr=i(ne),t3=n(ne,"LI",{});var oDe=s(t3);iEe=n(oDe,"STRONG",{});var RRt=s(iEe);Hyr=r(RRt,"mobilebert"),RRt.forEach(t),Uyr=r(oDe," \u2014 "),XY=n(oDe,"A",{href:!0});var PRt=s(XY);Jyr=r(PRt,"TFMobileBertForSequenceClassification"),PRt.forEach(t),Yyr=r(oDe," (MobileBERT model)"),oDe.forEach(t),Kyr=i(ne),a3=n(ne,"LI",{});var rDe=s(a3);dEe=n(rDe,"STRONG",{});var BRt=s(dEe);Zyr=r(BRt,"mpnet"),BRt.forEach(t),e8r=r(rDe," \u2014 "),zY=n(rDe,"A",{href:!0});var NRt=s(zY);o8r=r(NRt,"TFMPNetForSequenceClassification"),NRt.forEach(t),r8r=r(rDe," (MPNet model)"),rDe.forEach(t),t8r=i(ne),n3=n(ne,"LI",{});var tDe=s(n3);cEe=n(tDe,"STRONG",{});var IRt=s(cEe);a8r=r(IRt,"openai-gpt"),IRt.forEach(t),n8r=r(tDe," \u2014 "),QY=n(tDe,"A",{href:!0});var qRt=s(QY);s8r=r(qRt,"TFOpenAIGPTForSequenceClassification"),qRt.forEach(t),l8r=r(tDe," (OpenAI GPT model)"),tDe.forEach(t),i8r=i(ne),s3=n(ne,"LI",{});var aDe=s(s3);fEe=n(aDe,"STRONG",{});var jRt=s(fEe);d8r=r(jRt,"rembert"),jRt.forEach(t),c8r=r(aDe," \u2014 "),WY=n(aDe,"A",{href:!0});var DRt=s(WY);f8r=r(DRt,"TFRemBertForSequenceClassification"),DRt.forEach(t),m8r=r(aDe," (RemBERT model)"),aDe.forEach(t),g8r=i(ne),l3=n(ne,"LI",{});var nDe=s(l3);mEe=n(nDe,"STRONG",{});var GRt=s(mEe);h8r=r(GRt,"roberta"),GRt.forEach(t),p8r=r(nDe," \u2014 "),HY=n(nDe,"A",{href:!0});var ORt=s(HY);_8r=r(ORt,"TFRobertaForSequenceClassification"),ORt.forEach(t),u8r=r(nDe," (RoBERTa model)"),nDe.forEach(t),b8r=i(ne),i3=n(ne,"LI",{});var sDe=s(i3);gEe=n(sDe,"STRONG",{});var VRt=s(gEe);v8r=r(VRt,"roformer"),VRt.forEach(t),F8r=r(sDe," \u2014 "),UY=n(sDe,"A",{href:!0});var XRt=s(UY);T8r=r(XRt,"TFRoFormerForSequenceClassification"),XRt.forEach(t),M8r=r(sDe," (RoFormer model)"),sDe.forEach(t),E8r=i(ne),d3=n(ne,"LI",{});var lDe=s(d3);hEe=n(lDe,"STRONG",{});var zRt=s(hEe);C8r=r(zRt,"tapas"),zRt.forEach(t),w8r=r(lDe," \u2014 "),JY=n(lDe,"A",{href:!0});var QRt=s(JY);A8r=r(QRt,"TFTapasForSequenceClassification"),QRt.forEach(t),L8r=r(lDe," (TAPAS model)"),lDe.forEach(t),y8r=i(ne),c3=n(ne,"LI",{});var iDe=s(c3);pEe=n(iDe,"STRONG",{});var WRt=s(pEe);x8r=r(WRt,"transfo-xl"),WRt.forEach(t),$8r=r(iDe," \u2014 "),YY=n(iDe,"A",{href:!0});var HRt=s(YY);k8r=r(HRt,"TFTransfoXLForSequenceClassification"),HRt.forEach(t),S8r=r(iDe," (Transformer-XL model)"),iDe.forEach(t),R8r=i(ne),f3=n(ne,"LI",{});var dDe=s(f3);_Ee=n(dDe,"STRONG",{});var URt=s(_Ee);P8r=r(URt,"xlm"),URt.forEach(t),B8r=r(dDe," \u2014 "),KY=n(dDe,"A",{href:!0});var JRt=s(KY);N8r=r(JRt,"TFXLMForSequenceClassification"),JRt.forEach(t),I8r=r(dDe," (XLM model)"),dDe.forEach(t),q8r=i(ne),m3=n(ne,"LI",{});var cDe=s(m3);uEe=n(cDe,"STRONG",{});var YRt=s(uEe);j8r=r(YRt,"xlm-roberta"),YRt.forEach(t),D8r=r(cDe," \u2014 "),ZY=n(cDe,"A",{href:!0});var KRt=s(ZY);G8r=r(KRt,"TFXLMRobertaForSequenceClassification"),KRt.forEach(t),O8r=r(cDe," (XLM-RoBERTa model)"),cDe.forEach(t),V8r=i(ne),g3=n(ne,"LI",{});var fDe=s(g3);bEe=n(fDe,"STRONG",{});var ZRt=s(bEe);X8r=r(ZRt,"xlnet"),ZRt.forEach(t),z8r=r(fDe," \u2014 "),eK=n(fDe,"A",{href:!0});var ePt=s(eK);Q8r=r(ePt,"TFXLNetForSequenceClassification"),ePt.forEach(t),W8r=r(fDe," (XLNet model)"),fDe.forEach(t),ne.forEach(t),H8r=i(Dl),T(h3.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),VXe=i(f),wc=n(f,"H2",{class:!0});var YQe=s(wc);p3=n(YQe,"A",{id:!0,class:!0,href:!0});var oPt=s(p3);vEe=n(oPt,"SPAN",{});var rPt=s(vEe);T(bx.$$.fragment,rPt),rPt.forEach(t),oPt.forEach(t),U8r=i(YQe),FEe=n(YQe,"SPAN",{});var tPt=s(FEe);J8r=r(tPt,"TFAutoModelForMultipleChoice"),tPt.forEach(t),YQe.forEach(t),XXe=i(f),ir=n(f,"DIV",{class:!0});var Gl=s(ir);T(vx.$$.fragment,Gl),Y8r=i(Gl),Ac=n(Gl,"P",{});var Cte=s(Ac);K8r=r(Cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),oK=n(Cte,"A",{href:!0});var aPt=s(oK);Z8r=r(aPt,"from_pretrained()"),aPt.forEach(t),e9r=r(Cte," class method or the "),rK=n(Cte,"A",{href:!0});var nPt=s(rK);o9r=r(nPt,"from_config()"),nPt.forEach(t),r9r=r(Cte,` class
method.`),Cte.forEach(t),t9r=i(Gl),Fx=n(Gl,"P",{});var KQe=s(Fx);a9r=r(KQe,"This class cannot be instantiated directly using "),TEe=n(KQe,"CODE",{});var sPt=s(TEe);n9r=r(sPt,"__init__()"),sPt.forEach(t),s9r=r(KQe," (throws an error)."),KQe.forEach(t),l9r=i(Gl),qt=n(Gl,"DIV",{class:!0});var dL=s(qt);T(Tx.$$.fragment,dL),i9r=i(dL),MEe=n(dL,"P",{});var lPt=s(MEe);d9r=r(lPt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),lPt.forEach(t),c9r=i(dL),Lc=n(dL,"P",{});var wte=s(Lc);f9r=r(wte,`Note:
Loading a model from its configuration file does `),EEe=n(wte,"STRONG",{});var iPt=s(EEe);m9r=r(iPt,"not"),iPt.forEach(t),g9r=r(wte,` load the model weights. It only affects the
model\u2019s configuration. Use `),tK=n(wte,"A",{href:!0});var dPt=s(tK);h9r=r(dPt,"from_pretrained()"),dPt.forEach(t),p9r=r(wte," to load the model weights."),wte.forEach(t),_9r=i(dL),T(_3.$$.fragment,dL),dL.forEach(t),u9r=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(Mx.$$.fragment,Ol),b9r=i(Ol),CEe=n(Ol,"P",{});var cPt=s(CEe);v9r=r(cPt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),cPt.forEach(t),F9r=i(Ol),hn=n(Ol,"P",{});var cL=s(hn);T9r=r(cL,"The model class to instantiate is selected based on the "),wEe=n(cL,"CODE",{});var fPt=s(wEe);M9r=r(fPt,"model_type"),fPt.forEach(t),E9r=r(cL,` property of the config object (either
passed as an argument or loaded from `),AEe=n(cL,"CODE",{});var mPt=s(AEe);C9r=r(mPt,"pretrained_model_name_or_path"),mPt.forEach(t),w9r=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LEe=n(cL,"CODE",{});var gPt=s(LEe);A9r=r(gPt,"pretrained_model_name_or_path"),gPt.forEach(t),L9r=r(cL,":"),cL.forEach(t),y9r=i(Ol),_e=n(Ol,"UL",{});var ve=s(_e);u3=n(ve,"LI",{});var mDe=s(u3);yEe=n(mDe,"STRONG",{});var hPt=s(yEe);x9r=r(hPt,"albert"),hPt.forEach(t),$9r=r(mDe," \u2014 "),aK=n(mDe,"A",{href:!0});var pPt=s(aK);k9r=r(pPt,"TFAlbertForMultipleChoice"),pPt.forEach(t),S9r=r(mDe," (ALBERT model)"),mDe.forEach(t),R9r=i(ve),b3=n(ve,"LI",{});var gDe=s(b3);xEe=n(gDe,"STRONG",{});var _Pt=s(xEe);P9r=r(_Pt,"bert"),_Pt.forEach(t),B9r=r(gDe," \u2014 "),nK=n(gDe,"A",{href:!0});var uPt=s(nK);N9r=r(uPt,"TFBertForMultipleChoice"),uPt.forEach(t),I9r=r(gDe," (BERT model)"),gDe.forEach(t),q9r=i(ve),v3=n(ve,"LI",{});var hDe=s(v3);$Ee=n(hDe,"STRONG",{});var bPt=s($Ee);j9r=r(bPt,"camembert"),bPt.forEach(t),D9r=r(hDe," \u2014 "),sK=n(hDe,"A",{href:!0});var vPt=s(sK);G9r=r(vPt,"TFCamembertForMultipleChoice"),vPt.forEach(t),O9r=r(hDe," (CamemBERT model)"),hDe.forEach(t),V9r=i(ve),F3=n(ve,"LI",{});var pDe=s(F3);kEe=n(pDe,"STRONG",{});var FPt=s(kEe);X9r=r(FPt,"convbert"),FPt.forEach(t),z9r=r(pDe," \u2014 "),lK=n(pDe,"A",{href:!0});var TPt=s(lK);Q9r=r(TPt,"TFConvBertForMultipleChoice"),TPt.forEach(t),W9r=r(pDe," (ConvBERT model)"),pDe.forEach(t),H9r=i(ve),T3=n(ve,"LI",{});var _De=s(T3);SEe=n(_De,"STRONG",{});var MPt=s(SEe);U9r=r(MPt,"distilbert"),MPt.forEach(t),J9r=r(_De," \u2014 "),iK=n(_De,"A",{href:!0});var EPt=s(iK);Y9r=r(EPt,"TFDistilBertForMultipleChoice"),EPt.forEach(t),K9r=r(_De," (DistilBERT model)"),_De.forEach(t),Z9r=i(ve),M3=n(ve,"LI",{});var uDe=s(M3);REe=n(uDe,"STRONG",{});var CPt=s(REe);exr=r(CPt,"electra"),CPt.forEach(t),oxr=r(uDe," \u2014 "),dK=n(uDe,"A",{href:!0});var wPt=s(dK);rxr=r(wPt,"TFElectraForMultipleChoice"),wPt.forEach(t),txr=r(uDe," (ELECTRA model)"),uDe.forEach(t),axr=i(ve),E3=n(ve,"LI",{});var bDe=s(E3);PEe=n(bDe,"STRONG",{});var APt=s(PEe);nxr=r(APt,"flaubert"),APt.forEach(t),sxr=r(bDe," \u2014 "),cK=n(bDe,"A",{href:!0});var LPt=s(cK);lxr=r(LPt,"TFFlaubertForMultipleChoice"),LPt.forEach(t),ixr=r(bDe," (FlauBERT model)"),bDe.forEach(t),dxr=i(ve),C3=n(ve,"LI",{});var vDe=s(C3);BEe=n(vDe,"STRONG",{});var yPt=s(BEe);cxr=r(yPt,"funnel"),yPt.forEach(t),fxr=r(vDe," \u2014 "),fK=n(vDe,"A",{href:!0});var xPt=s(fK);mxr=r(xPt,"TFFunnelForMultipleChoice"),xPt.forEach(t),gxr=r(vDe," (Funnel Transformer model)"),vDe.forEach(t),hxr=i(ve),w3=n(ve,"LI",{});var FDe=s(w3);NEe=n(FDe,"STRONG",{});var $Pt=s(NEe);pxr=r($Pt,"longformer"),$Pt.forEach(t),_xr=r(FDe," \u2014 "),mK=n(FDe,"A",{href:!0});var kPt=s(mK);uxr=r(kPt,"TFLongformerForMultipleChoice"),kPt.forEach(t),bxr=r(FDe," (Longformer model)"),FDe.forEach(t),vxr=i(ve),A3=n(ve,"LI",{});var TDe=s(A3);IEe=n(TDe,"STRONG",{});var SPt=s(IEe);Fxr=r(SPt,"mobilebert"),SPt.forEach(t),Txr=r(TDe," \u2014 "),gK=n(TDe,"A",{href:!0});var RPt=s(gK);Mxr=r(RPt,"TFMobileBertForMultipleChoice"),RPt.forEach(t),Exr=r(TDe," (MobileBERT model)"),TDe.forEach(t),Cxr=i(ve),L3=n(ve,"LI",{});var MDe=s(L3);qEe=n(MDe,"STRONG",{});var PPt=s(qEe);wxr=r(PPt,"mpnet"),PPt.forEach(t),Axr=r(MDe," \u2014 "),hK=n(MDe,"A",{href:!0});var BPt=s(hK);Lxr=r(BPt,"TFMPNetForMultipleChoice"),BPt.forEach(t),yxr=r(MDe," (MPNet model)"),MDe.forEach(t),xxr=i(ve),y3=n(ve,"LI",{});var EDe=s(y3);jEe=n(EDe,"STRONG",{});var NPt=s(jEe);$xr=r(NPt,"rembert"),NPt.forEach(t),kxr=r(EDe," \u2014 "),pK=n(EDe,"A",{href:!0});var IPt=s(pK);Sxr=r(IPt,"TFRemBertForMultipleChoice"),IPt.forEach(t),Rxr=r(EDe," (RemBERT model)"),EDe.forEach(t),Pxr=i(ve),x3=n(ve,"LI",{});var CDe=s(x3);DEe=n(CDe,"STRONG",{});var qPt=s(DEe);Bxr=r(qPt,"roberta"),qPt.forEach(t),Nxr=r(CDe," \u2014 "),_K=n(CDe,"A",{href:!0});var jPt=s(_K);Ixr=r(jPt,"TFRobertaForMultipleChoice"),jPt.forEach(t),qxr=r(CDe," (RoBERTa model)"),CDe.forEach(t),jxr=i(ve),$3=n(ve,"LI",{});var wDe=s($3);GEe=n(wDe,"STRONG",{});var DPt=s(GEe);Dxr=r(DPt,"roformer"),DPt.forEach(t),Gxr=r(wDe," \u2014 "),uK=n(wDe,"A",{href:!0});var GPt=s(uK);Oxr=r(GPt,"TFRoFormerForMultipleChoice"),GPt.forEach(t),Vxr=r(wDe," (RoFormer model)"),wDe.forEach(t),Xxr=i(ve),k3=n(ve,"LI",{});var ADe=s(k3);OEe=n(ADe,"STRONG",{});var OPt=s(OEe);zxr=r(OPt,"xlm"),OPt.forEach(t),Qxr=r(ADe," \u2014 "),bK=n(ADe,"A",{href:!0});var VPt=s(bK);Wxr=r(VPt,"TFXLMForMultipleChoice"),VPt.forEach(t),Hxr=r(ADe," (XLM model)"),ADe.forEach(t),Uxr=i(ve),S3=n(ve,"LI",{});var LDe=s(S3);VEe=n(LDe,"STRONG",{});var XPt=s(VEe);Jxr=r(XPt,"xlm-roberta"),XPt.forEach(t),Yxr=r(LDe," \u2014 "),vK=n(LDe,"A",{href:!0});var zPt=s(vK);Kxr=r(zPt,"TFXLMRobertaForMultipleChoice"),zPt.forEach(t),Zxr=r(LDe," (XLM-RoBERTa model)"),LDe.forEach(t),e$r=i(ve),R3=n(ve,"LI",{});var yDe=s(R3);XEe=n(yDe,"STRONG",{});var QPt=s(XEe);o$r=r(QPt,"xlnet"),QPt.forEach(t),r$r=r(yDe," \u2014 "),FK=n(yDe,"A",{href:!0});var WPt=s(FK);t$r=r(WPt,"TFXLNetForMultipleChoice"),WPt.forEach(t),a$r=r(yDe," (XLNet model)"),yDe.forEach(t),ve.forEach(t),n$r=i(Ol),T(P3.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),zXe=i(f),yc=n(f,"H2",{class:!0});var ZQe=s(yc);B3=n(ZQe,"A",{id:!0,class:!0,href:!0});var HPt=s(B3);zEe=n(HPt,"SPAN",{});var UPt=s(zEe);T(Ex.$$.fragment,UPt),UPt.forEach(t),HPt.forEach(t),s$r=i(ZQe),QEe=n(ZQe,"SPAN",{});var JPt=s(QEe);l$r=r(JPt,"TFAutoModelForNextSentencePrediction"),JPt.forEach(t),ZQe.forEach(t),QXe=i(f),dr=n(f,"DIV",{class:!0});var Vl=s(dr);T(Cx.$$.fragment,Vl),i$r=i(Vl),xc=n(Vl,"P",{});var Ate=s(xc);d$r=r(Ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),TK=n(Ate,"A",{href:!0});var YPt=s(TK);c$r=r(YPt,"from_pretrained()"),YPt.forEach(t),f$r=r(Ate," class method or the "),MK=n(Ate,"A",{href:!0});var KPt=s(MK);m$r=r(KPt,"from_config()"),KPt.forEach(t),g$r=r(Ate,` class
method.`),Ate.forEach(t),h$r=i(Vl),wx=n(Vl,"P",{});var eWe=s(wx);p$r=r(eWe,"This class cannot be instantiated directly using "),WEe=n(eWe,"CODE",{});var ZPt=s(WEe);_$r=r(ZPt,"__init__()"),ZPt.forEach(t),u$r=r(eWe," (throws an error)."),eWe.forEach(t),b$r=i(Vl),jt=n(Vl,"DIV",{class:!0});var fL=s(jt);T(Ax.$$.fragment,fL),v$r=i(fL),HEe=n(fL,"P",{});var eBt=s(HEe);F$r=r(eBt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),eBt.forEach(t),T$r=i(fL),$c=n(fL,"P",{});var Lte=s($c);M$r=r(Lte,`Note:
Loading a model from its configuration file does `),UEe=n(Lte,"STRONG",{});var oBt=s(UEe);E$r=r(oBt,"not"),oBt.forEach(t),C$r=r(Lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=n(Lte,"A",{href:!0});var rBt=s(EK);w$r=r(rBt,"from_pretrained()"),rBt.forEach(t),A$r=r(Lte," to load the model weights."),Lte.forEach(t),L$r=i(fL),T(N3.$$.fragment,fL),fL.forEach(t),y$r=i(Vl),Ir=n(Vl,"DIV",{class:!0});var Xl=s(Ir);T(Lx.$$.fragment,Xl),x$r=i(Xl),JEe=n(Xl,"P",{});var tBt=s(JEe);$$r=r(tBt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),tBt.forEach(t),k$r=i(Xl),pn=n(Xl,"P",{});var mL=s(pn);S$r=r(mL,"The model class to instantiate is selected based on the "),YEe=n(mL,"CODE",{});var aBt=s(YEe);R$r=r(aBt,"model_type"),aBt.forEach(t),P$r=r(mL,` property of the config object (either
passed as an argument or loaded from `),KEe=n(mL,"CODE",{});var nBt=s(KEe);B$r=r(nBt,"pretrained_model_name_or_path"),nBt.forEach(t),N$r=r(mL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZEe=n(mL,"CODE",{});var sBt=s(ZEe);I$r=r(sBt,"pretrained_model_name_or_path"),sBt.forEach(t),q$r=r(mL,":"),mL.forEach(t),j$r=i(Xl),yx=n(Xl,"UL",{});var oWe=s(yx);I3=n(oWe,"LI",{});var xDe=s(I3);eCe=n(xDe,"STRONG",{});var lBt=s(eCe);D$r=r(lBt,"bert"),lBt.forEach(t),G$r=r(xDe," \u2014 "),CK=n(xDe,"A",{href:!0});var iBt=s(CK);O$r=r(iBt,"TFBertForNextSentencePrediction"),iBt.forEach(t),V$r=r(xDe," (BERT model)"),xDe.forEach(t),X$r=i(oWe),q3=n(oWe,"LI",{});var $De=s(q3);oCe=n($De,"STRONG",{});var dBt=s(oCe);z$r=r(dBt,"mobilebert"),dBt.forEach(t),Q$r=r($De," \u2014 "),wK=n($De,"A",{href:!0});var cBt=s(wK);W$r=r(cBt,"TFMobileBertForNextSentencePrediction"),cBt.forEach(t),H$r=r($De," (MobileBERT model)"),$De.forEach(t),oWe.forEach(t),U$r=i(Xl),T(j3.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),WXe=i(f),kc=n(f,"H2",{class:!0});var rWe=s(kc);D3=n(rWe,"A",{id:!0,class:!0,href:!0});var fBt=s(D3);rCe=n(fBt,"SPAN",{});var mBt=s(rCe);T(xx.$$.fragment,mBt),mBt.forEach(t),fBt.forEach(t),J$r=i(rWe),tCe=n(rWe,"SPAN",{});var gBt=s(tCe);Y$r=r(gBt,"TFAutoModelForTableQuestionAnswering"),gBt.forEach(t),rWe.forEach(t),HXe=i(f),cr=n(f,"DIV",{class:!0});var zl=s(cr);T($x.$$.fragment,zl),K$r=i(zl),Sc=n(zl,"P",{});var yte=s(Sc);Z$r=r(yte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),AK=n(yte,"A",{href:!0});var hBt=s(AK);ekr=r(hBt,"from_pretrained()"),hBt.forEach(t),okr=r(yte," class method or the "),LK=n(yte,"A",{href:!0});var pBt=s(LK);rkr=r(pBt,"from_config()"),pBt.forEach(t),tkr=r(yte,` class
method.`),yte.forEach(t),akr=i(zl),kx=n(zl,"P",{});var tWe=s(kx);nkr=r(tWe,"This class cannot be instantiated directly using "),aCe=n(tWe,"CODE",{});var _Bt=s(aCe);skr=r(_Bt,"__init__()"),_Bt.forEach(t),lkr=r(tWe," (throws an error)."),tWe.forEach(t),ikr=i(zl),Dt=n(zl,"DIV",{class:!0});var gL=s(Dt);T(Sx.$$.fragment,gL),dkr=i(gL),nCe=n(gL,"P",{});var uBt=s(nCe);ckr=r(uBt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),uBt.forEach(t),fkr=i(gL),Rc=n(gL,"P",{});var xte=s(Rc);mkr=r(xte,`Note:
Loading a model from its configuration file does `),sCe=n(xte,"STRONG",{});var bBt=s(sCe);gkr=r(bBt,"not"),bBt.forEach(t),hkr=r(xte,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(xte,"A",{href:!0});var vBt=s(yK);pkr=r(vBt,"from_pretrained()"),vBt.forEach(t),_kr=r(xte," to load the model weights."),xte.forEach(t),ukr=i(gL),T(G3.$$.fragment,gL),gL.forEach(t),bkr=i(zl),qr=n(zl,"DIV",{class:!0});var Ql=s(qr);T(Rx.$$.fragment,Ql),vkr=i(Ql),lCe=n(Ql,"P",{});var FBt=s(lCe);Fkr=r(FBt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),FBt.forEach(t),Tkr=i(Ql),_n=n(Ql,"P",{});var hL=s(_n);Mkr=r(hL,"The model class to instantiate is selected based on the "),iCe=n(hL,"CODE",{});var TBt=s(iCe);Ekr=r(TBt,"model_type"),TBt.forEach(t),Ckr=r(hL,` property of the config object (either
passed as an argument or loaded from `),dCe=n(hL,"CODE",{});var MBt=s(dCe);wkr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),Akr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=n(hL,"CODE",{});var EBt=s(cCe);Lkr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),ykr=r(hL,":"),hL.forEach(t),xkr=i(Ql),fCe=n(Ql,"UL",{});var CBt=s(fCe);O3=n(CBt,"LI",{});var kDe=s(O3);mCe=n(kDe,"STRONG",{});var wBt=s(mCe);$kr=r(wBt,"tapas"),wBt.forEach(t),kkr=r(kDe," \u2014 "),xK=n(kDe,"A",{href:!0});var ABt=s(xK);Skr=r(ABt,"TFTapasForQuestionAnswering"),ABt.forEach(t),Rkr=r(kDe," (TAPAS model)"),kDe.forEach(t),CBt.forEach(t),Pkr=i(Ql),T(V3.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),UXe=i(f),Pc=n(f,"H2",{class:!0});var aWe=s(Pc);X3=n(aWe,"A",{id:!0,class:!0,href:!0});var LBt=s(X3);gCe=n(LBt,"SPAN",{});var yBt=s(gCe);T(Px.$$.fragment,yBt),yBt.forEach(t),LBt.forEach(t),Bkr=i(aWe),hCe=n(aWe,"SPAN",{});var xBt=s(hCe);Nkr=r(xBt,"TFAutoModelForTokenClassification"),xBt.forEach(t),aWe.forEach(t),JXe=i(f),fr=n(f,"DIV",{class:!0});var Wl=s(fr);T(Bx.$$.fragment,Wl),Ikr=i(Wl),Bc=n(Wl,"P",{});var $te=s(Bc);qkr=r($te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$K=n($te,"A",{href:!0});var $Bt=s($K);jkr=r($Bt,"from_pretrained()"),$Bt.forEach(t),Dkr=r($te," class method or the "),kK=n($te,"A",{href:!0});var kBt=s(kK);Gkr=r(kBt,"from_config()"),kBt.forEach(t),Okr=r($te,` class
method.`),$te.forEach(t),Vkr=i(Wl),Nx=n(Wl,"P",{});var nWe=s(Nx);Xkr=r(nWe,"This class cannot be instantiated directly using "),pCe=n(nWe,"CODE",{});var SBt=s(pCe);zkr=r(SBt,"__init__()"),SBt.forEach(t),Qkr=r(nWe," (throws an error)."),nWe.forEach(t),Wkr=i(Wl),Gt=n(Wl,"DIV",{class:!0});var pL=s(Gt);T(Ix.$$.fragment,pL),Hkr=i(pL),_Ce=n(pL,"P",{});var RBt=s(_Ce);Ukr=r(RBt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),RBt.forEach(t),Jkr=i(pL),Nc=n(pL,"P",{});var kte=s(Nc);Ykr=r(kte,`Note:
Loading a model from its configuration file does `),uCe=n(kte,"STRONG",{});var PBt=s(uCe);Kkr=r(PBt,"not"),PBt.forEach(t),Zkr=r(kte,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(kte,"A",{href:!0});var BBt=s(SK);eSr=r(BBt,"from_pretrained()"),BBt.forEach(t),oSr=r(kte," to load the model weights."),kte.forEach(t),rSr=i(pL),T(z3.$$.fragment,pL),pL.forEach(t),tSr=i(Wl),jr=n(Wl,"DIV",{class:!0});var Hl=s(jr);T(qx.$$.fragment,Hl),aSr=i(Hl),bCe=n(Hl,"P",{});var NBt=s(bCe);nSr=r(NBt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),NBt.forEach(t),sSr=i(Hl),un=n(Hl,"P",{});var _L=s(un);lSr=r(_L,"The model class to instantiate is selected based on the "),vCe=n(_L,"CODE",{});var IBt=s(vCe);iSr=r(IBt,"model_type"),IBt.forEach(t),dSr=r(_L,` property of the config object (either
passed as an argument or loaded from `),FCe=n(_L,"CODE",{});var qBt=s(FCe);cSr=r(qBt,"pretrained_model_name_or_path"),qBt.forEach(t),fSr=r(_L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(_L,"CODE",{});var jBt=s(TCe);mSr=r(jBt,"pretrained_model_name_or_path"),jBt.forEach(t),gSr=r(_L,":"),_L.forEach(t),hSr=i(Hl),de=n(Hl,"UL",{});var me=s(de);Q3=n(me,"LI",{});var SDe=s(Q3);MCe=n(SDe,"STRONG",{});var DBt=s(MCe);pSr=r(DBt,"albert"),DBt.forEach(t),_Sr=r(SDe," \u2014 "),RK=n(SDe,"A",{href:!0});var GBt=s(RK);uSr=r(GBt,"TFAlbertForTokenClassification"),GBt.forEach(t),bSr=r(SDe," (ALBERT model)"),SDe.forEach(t),vSr=i(me),W3=n(me,"LI",{});var RDe=s(W3);ECe=n(RDe,"STRONG",{});var OBt=s(ECe);FSr=r(OBt,"bert"),OBt.forEach(t),TSr=r(RDe," \u2014 "),PK=n(RDe,"A",{href:!0});var VBt=s(PK);MSr=r(VBt,"TFBertForTokenClassification"),VBt.forEach(t),ESr=r(RDe," (BERT model)"),RDe.forEach(t),CSr=i(me),H3=n(me,"LI",{});var PDe=s(H3);CCe=n(PDe,"STRONG",{});var XBt=s(CCe);wSr=r(XBt,"camembert"),XBt.forEach(t),ASr=r(PDe," \u2014 "),BK=n(PDe,"A",{href:!0});var zBt=s(BK);LSr=r(zBt,"TFCamembertForTokenClassification"),zBt.forEach(t),ySr=r(PDe," (CamemBERT model)"),PDe.forEach(t),xSr=i(me),U3=n(me,"LI",{});var BDe=s(U3);wCe=n(BDe,"STRONG",{});var QBt=s(wCe);$Sr=r(QBt,"convbert"),QBt.forEach(t),kSr=r(BDe," \u2014 "),NK=n(BDe,"A",{href:!0});var WBt=s(NK);SSr=r(WBt,"TFConvBertForTokenClassification"),WBt.forEach(t),RSr=r(BDe," (ConvBERT model)"),BDe.forEach(t),PSr=i(me),J3=n(me,"LI",{});var NDe=s(J3);ACe=n(NDe,"STRONG",{});var HBt=s(ACe);BSr=r(HBt,"deberta"),HBt.forEach(t),NSr=r(NDe," \u2014 "),IK=n(NDe,"A",{href:!0});var UBt=s(IK);ISr=r(UBt,"TFDebertaForTokenClassification"),UBt.forEach(t),qSr=r(NDe," (DeBERTa model)"),NDe.forEach(t),jSr=i(me),Y3=n(me,"LI",{});var IDe=s(Y3);LCe=n(IDe,"STRONG",{});var JBt=s(LCe);DSr=r(JBt,"deberta-v2"),JBt.forEach(t),GSr=r(IDe," \u2014 "),qK=n(IDe,"A",{href:!0});var YBt=s(qK);OSr=r(YBt,"TFDebertaV2ForTokenClassification"),YBt.forEach(t),VSr=r(IDe," (DeBERTa-v2 model)"),IDe.forEach(t),XSr=i(me),K3=n(me,"LI",{});var qDe=s(K3);yCe=n(qDe,"STRONG",{});var KBt=s(yCe);zSr=r(KBt,"distilbert"),KBt.forEach(t),QSr=r(qDe," \u2014 "),jK=n(qDe,"A",{href:!0});var ZBt=s(jK);WSr=r(ZBt,"TFDistilBertForTokenClassification"),ZBt.forEach(t),HSr=r(qDe," (DistilBERT model)"),qDe.forEach(t),USr=i(me),Z3=n(me,"LI",{});var jDe=s(Z3);xCe=n(jDe,"STRONG",{});var eNt=s(xCe);JSr=r(eNt,"electra"),eNt.forEach(t),YSr=r(jDe," \u2014 "),DK=n(jDe,"A",{href:!0});var oNt=s(DK);KSr=r(oNt,"TFElectraForTokenClassification"),oNt.forEach(t),ZSr=r(jDe," (ELECTRA model)"),jDe.forEach(t),eRr=i(me),e5=n(me,"LI",{});var DDe=s(e5);$Ce=n(DDe,"STRONG",{});var rNt=s($Ce);oRr=r(rNt,"flaubert"),rNt.forEach(t),rRr=r(DDe," \u2014 "),GK=n(DDe,"A",{href:!0});var tNt=s(GK);tRr=r(tNt,"TFFlaubertForTokenClassification"),tNt.forEach(t),aRr=r(DDe," (FlauBERT model)"),DDe.forEach(t),nRr=i(me),o5=n(me,"LI",{});var GDe=s(o5);kCe=n(GDe,"STRONG",{});var aNt=s(kCe);sRr=r(aNt,"funnel"),aNt.forEach(t),lRr=r(GDe," \u2014 "),OK=n(GDe,"A",{href:!0});var nNt=s(OK);iRr=r(nNt,"TFFunnelForTokenClassification"),nNt.forEach(t),dRr=r(GDe," (Funnel Transformer model)"),GDe.forEach(t),cRr=i(me),r5=n(me,"LI",{});var ODe=s(r5);SCe=n(ODe,"STRONG",{});var sNt=s(SCe);fRr=r(sNt,"layoutlm"),sNt.forEach(t),mRr=r(ODe," \u2014 "),VK=n(ODe,"A",{href:!0});var lNt=s(VK);gRr=r(lNt,"TFLayoutLMForTokenClassification"),lNt.forEach(t),hRr=r(ODe," (LayoutLM model)"),ODe.forEach(t),pRr=i(me),t5=n(me,"LI",{});var VDe=s(t5);RCe=n(VDe,"STRONG",{});var iNt=s(RCe);_Rr=r(iNt,"longformer"),iNt.forEach(t),uRr=r(VDe," \u2014 "),XK=n(VDe,"A",{href:!0});var dNt=s(XK);bRr=r(dNt,"TFLongformerForTokenClassification"),dNt.forEach(t),vRr=r(VDe," (Longformer model)"),VDe.forEach(t),FRr=i(me),a5=n(me,"LI",{});var XDe=s(a5);PCe=n(XDe,"STRONG",{});var cNt=s(PCe);TRr=r(cNt,"mobilebert"),cNt.forEach(t),MRr=r(XDe," \u2014 "),zK=n(XDe,"A",{href:!0});var fNt=s(zK);ERr=r(fNt,"TFMobileBertForTokenClassification"),fNt.forEach(t),CRr=r(XDe," (MobileBERT model)"),XDe.forEach(t),wRr=i(me),n5=n(me,"LI",{});var zDe=s(n5);BCe=n(zDe,"STRONG",{});var mNt=s(BCe);ARr=r(mNt,"mpnet"),mNt.forEach(t),LRr=r(zDe," \u2014 "),QK=n(zDe,"A",{href:!0});var gNt=s(QK);yRr=r(gNt,"TFMPNetForTokenClassification"),gNt.forEach(t),xRr=r(zDe," (MPNet model)"),zDe.forEach(t),$Rr=i(me),s5=n(me,"LI",{});var QDe=s(s5);NCe=n(QDe,"STRONG",{});var hNt=s(NCe);kRr=r(hNt,"rembert"),hNt.forEach(t),SRr=r(QDe," \u2014 "),WK=n(QDe,"A",{href:!0});var pNt=s(WK);RRr=r(pNt,"TFRemBertForTokenClassification"),pNt.forEach(t),PRr=r(QDe," (RemBERT model)"),QDe.forEach(t),BRr=i(me),l5=n(me,"LI",{});var WDe=s(l5);ICe=n(WDe,"STRONG",{});var _Nt=s(ICe);NRr=r(_Nt,"roberta"),_Nt.forEach(t),IRr=r(WDe," \u2014 "),HK=n(WDe,"A",{href:!0});var uNt=s(HK);qRr=r(uNt,"TFRobertaForTokenClassification"),uNt.forEach(t),jRr=r(WDe," (RoBERTa model)"),WDe.forEach(t),DRr=i(me),i5=n(me,"LI",{});var HDe=s(i5);qCe=n(HDe,"STRONG",{});var bNt=s(qCe);GRr=r(bNt,"roformer"),bNt.forEach(t),ORr=r(HDe," \u2014 "),UK=n(HDe,"A",{href:!0});var vNt=s(UK);VRr=r(vNt,"TFRoFormerForTokenClassification"),vNt.forEach(t),XRr=r(HDe," (RoFormer model)"),HDe.forEach(t),zRr=i(me),d5=n(me,"LI",{});var UDe=s(d5);jCe=n(UDe,"STRONG",{});var FNt=s(jCe);QRr=r(FNt,"xlm"),FNt.forEach(t),WRr=r(UDe," \u2014 "),JK=n(UDe,"A",{href:!0});var TNt=s(JK);HRr=r(TNt,"TFXLMForTokenClassification"),TNt.forEach(t),URr=r(UDe," (XLM model)"),UDe.forEach(t),JRr=i(me),c5=n(me,"LI",{});var JDe=s(c5);DCe=n(JDe,"STRONG",{});var MNt=s(DCe);YRr=r(MNt,"xlm-roberta"),MNt.forEach(t),KRr=r(JDe," \u2014 "),YK=n(JDe,"A",{href:!0});var ENt=s(YK);ZRr=r(ENt,"TFXLMRobertaForTokenClassification"),ENt.forEach(t),ePr=r(JDe," (XLM-RoBERTa model)"),JDe.forEach(t),oPr=i(me),f5=n(me,"LI",{});var YDe=s(f5);GCe=n(YDe,"STRONG",{});var CNt=s(GCe);rPr=r(CNt,"xlnet"),CNt.forEach(t),tPr=r(YDe," \u2014 "),KK=n(YDe,"A",{href:!0});var wNt=s(KK);aPr=r(wNt,"TFXLNetForTokenClassification"),wNt.forEach(t),nPr=r(YDe," (XLNet model)"),YDe.forEach(t),me.forEach(t),sPr=i(Hl),T(m5.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),YXe=i(f),Ic=n(f,"H2",{class:!0});var sWe=s(Ic);g5=n(sWe,"A",{id:!0,class:!0,href:!0});var ANt=s(g5);OCe=n(ANt,"SPAN",{});var LNt=s(OCe);T(jx.$$.fragment,LNt),LNt.forEach(t),ANt.forEach(t),lPr=i(sWe),VCe=n(sWe,"SPAN",{});var yNt=s(VCe);iPr=r(yNt,"TFAutoModelForQuestionAnswering"),yNt.forEach(t),sWe.forEach(t),KXe=i(f),mr=n(f,"DIV",{class:!0});var Ul=s(mr);T(Dx.$$.fragment,Ul),dPr=i(Ul),qc=n(Ul,"P",{});var Ste=s(qc);cPr=r(Ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ZK=n(Ste,"A",{href:!0});var xNt=s(ZK);fPr=r(xNt,"from_pretrained()"),xNt.forEach(t),mPr=r(Ste," class method or the "),eZ=n(Ste,"A",{href:!0});var $Nt=s(eZ);gPr=r($Nt,"from_config()"),$Nt.forEach(t),hPr=r(Ste,` class
method.`),Ste.forEach(t),pPr=i(Ul),Gx=n(Ul,"P",{});var lWe=s(Gx);_Pr=r(lWe,"This class cannot be instantiated directly using "),XCe=n(lWe,"CODE",{});var kNt=s(XCe);uPr=r(kNt,"__init__()"),kNt.forEach(t),bPr=r(lWe," (throws an error)."),lWe.forEach(t),vPr=i(Ul),Ot=n(Ul,"DIV",{class:!0});var uL=s(Ot);T(Ox.$$.fragment,uL),FPr=i(uL),zCe=n(uL,"P",{});var SNt=s(zCe);TPr=r(SNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),SNt.forEach(t),MPr=i(uL),jc=n(uL,"P",{});var Rte=s(jc);EPr=r(Rte,`Note:
Loading a model from its configuration file does `),QCe=n(Rte,"STRONG",{});var RNt=s(QCe);CPr=r(RNt,"not"),RNt.forEach(t),wPr=r(Rte,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(Rte,"A",{href:!0});var PNt=s(oZ);APr=r(PNt,"from_pretrained()"),PNt.forEach(t),LPr=r(Rte," to load the model weights."),Rte.forEach(t),yPr=i(uL),T(h5.$$.fragment,uL),uL.forEach(t),xPr=i(Ul),Dr=n(Ul,"DIV",{class:!0});var Jl=s(Dr);T(Vx.$$.fragment,Jl),$Pr=i(Jl),WCe=n(Jl,"P",{});var BNt=s(WCe);kPr=r(BNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),BNt.forEach(t),SPr=i(Jl),bn=n(Jl,"P",{});var bL=s(bn);RPr=r(bL,"The model class to instantiate is selected based on the "),HCe=n(bL,"CODE",{});var NNt=s(HCe);PPr=r(NNt,"model_type"),NNt.forEach(t),BPr=r(bL,` property of the config object (either
passed as an argument or loaded from `),UCe=n(bL,"CODE",{});var INt=s(UCe);NPr=r(INt,"pretrained_model_name_or_path"),INt.forEach(t),IPr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JCe=n(bL,"CODE",{});var qNt=s(JCe);qPr=r(qNt,"pretrained_model_name_or_path"),qNt.forEach(t),jPr=r(bL,":"),bL.forEach(t),DPr=i(Jl),ce=n(Jl,"UL",{});var ge=s(ce);p5=n(ge,"LI",{});var KDe=s(p5);YCe=n(KDe,"STRONG",{});var jNt=s(YCe);GPr=r(jNt,"albert"),jNt.forEach(t),OPr=r(KDe," \u2014 "),rZ=n(KDe,"A",{href:!0});var DNt=s(rZ);VPr=r(DNt,"TFAlbertForQuestionAnswering"),DNt.forEach(t),XPr=r(KDe," (ALBERT model)"),KDe.forEach(t),zPr=i(ge),_5=n(ge,"LI",{});var ZDe=s(_5);KCe=n(ZDe,"STRONG",{});var GNt=s(KCe);QPr=r(GNt,"bert"),GNt.forEach(t),WPr=r(ZDe," \u2014 "),tZ=n(ZDe,"A",{href:!0});var ONt=s(tZ);HPr=r(ONt,"TFBertForQuestionAnswering"),ONt.forEach(t),UPr=r(ZDe," (BERT model)"),ZDe.forEach(t),JPr=i(ge),u5=n(ge,"LI",{});var eGe=s(u5);ZCe=n(eGe,"STRONG",{});var VNt=s(ZCe);YPr=r(VNt,"camembert"),VNt.forEach(t),KPr=r(eGe," \u2014 "),aZ=n(eGe,"A",{href:!0});var XNt=s(aZ);ZPr=r(XNt,"TFCamembertForQuestionAnswering"),XNt.forEach(t),eBr=r(eGe," (CamemBERT model)"),eGe.forEach(t),oBr=i(ge),b5=n(ge,"LI",{});var oGe=s(b5);e3e=n(oGe,"STRONG",{});var zNt=s(e3e);rBr=r(zNt,"convbert"),zNt.forEach(t),tBr=r(oGe," \u2014 "),nZ=n(oGe,"A",{href:!0});var QNt=s(nZ);aBr=r(QNt,"TFConvBertForQuestionAnswering"),QNt.forEach(t),nBr=r(oGe," (ConvBERT model)"),oGe.forEach(t),sBr=i(ge),v5=n(ge,"LI",{});var rGe=s(v5);o3e=n(rGe,"STRONG",{});var WNt=s(o3e);lBr=r(WNt,"deberta"),WNt.forEach(t),iBr=r(rGe," \u2014 "),sZ=n(rGe,"A",{href:!0});var HNt=s(sZ);dBr=r(HNt,"TFDebertaForQuestionAnswering"),HNt.forEach(t),cBr=r(rGe," (DeBERTa model)"),rGe.forEach(t),fBr=i(ge),F5=n(ge,"LI",{});var tGe=s(F5);r3e=n(tGe,"STRONG",{});var UNt=s(r3e);mBr=r(UNt,"deberta-v2"),UNt.forEach(t),gBr=r(tGe," \u2014 "),lZ=n(tGe,"A",{href:!0});var JNt=s(lZ);hBr=r(JNt,"TFDebertaV2ForQuestionAnswering"),JNt.forEach(t),pBr=r(tGe," (DeBERTa-v2 model)"),tGe.forEach(t),_Br=i(ge),T5=n(ge,"LI",{});var aGe=s(T5);t3e=n(aGe,"STRONG",{});var YNt=s(t3e);uBr=r(YNt,"distilbert"),YNt.forEach(t),bBr=r(aGe," \u2014 "),iZ=n(aGe,"A",{href:!0});var KNt=s(iZ);vBr=r(KNt,"TFDistilBertForQuestionAnswering"),KNt.forEach(t),FBr=r(aGe," (DistilBERT model)"),aGe.forEach(t),TBr=i(ge),M5=n(ge,"LI",{});var nGe=s(M5);a3e=n(nGe,"STRONG",{});var ZNt=s(a3e);MBr=r(ZNt,"electra"),ZNt.forEach(t),EBr=r(nGe," \u2014 "),dZ=n(nGe,"A",{href:!0});var eIt=s(dZ);CBr=r(eIt,"TFElectraForQuestionAnswering"),eIt.forEach(t),wBr=r(nGe," (ELECTRA model)"),nGe.forEach(t),ABr=i(ge),E5=n(ge,"LI",{});var sGe=s(E5);n3e=n(sGe,"STRONG",{});var oIt=s(n3e);LBr=r(oIt,"flaubert"),oIt.forEach(t),yBr=r(sGe," \u2014 "),cZ=n(sGe,"A",{href:!0});var rIt=s(cZ);xBr=r(rIt,"TFFlaubertForQuestionAnsweringSimple"),rIt.forEach(t),$Br=r(sGe," (FlauBERT model)"),sGe.forEach(t),kBr=i(ge),C5=n(ge,"LI",{});var lGe=s(C5);s3e=n(lGe,"STRONG",{});var tIt=s(s3e);SBr=r(tIt,"funnel"),tIt.forEach(t),RBr=r(lGe," \u2014 "),fZ=n(lGe,"A",{href:!0});var aIt=s(fZ);PBr=r(aIt,"TFFunnelForQuestionAnswering"),aIt.forEach(t),BBr=r(lGe," (Funnel Transformer model)"),lGe.forEach(t),NBr=i(ge),w5=n(ge,"LI",{});var iGe=s(w5);l3e=n(iGe,"STRONG",{});var nIt=s(l3e);IBr=r(nIt,"gptj"),nIt.forEach(t),qBr=r(iGe," \u2014 "),mZ=n(iGe,"A",{href:!0});var sIt=s(mZ);jBr=r(sIt,"TFGPTJForQuestionAnswering"),sIt.forEach(t),DBr=r(iGe," (GPT-J model)"),iGe.forEach(t),GBr=i(ge),A5=n(ge,"LI",{});var dGe=s(A5);i3e=n(dGe,"STRONG",{});var lIt=s(i3e);OBr=r(lIt,"longformer"),lIt.forEach(t),VBr=r(dGe," \u2014 "),gZ=n(dGe,"A",{href:!0});var iIt=s(gZ);XBr=r(iIt,"TFLongformerForQuestionAnswering"),iIt.forEach(t),zBr=r(dGe," (Longformer model)"),dGe.forEach(t),QBr=i(ge),L5=n(ge,"LI",{});var cGe=s(L5);d3e=n(cGe,"STRONG",{});var dIt=s(d3e);WBr=r(dIt,"mobilebert"),dIt.forEach(t),HBr=r(cGe," \u2014 "),hZ=n(cGe,"A",{href:!0});var cIt=s(hZ);UBr=r(cIt,"TFMobileBertForQuestionAnswering"),cIt.forEach(t),JBr=r(cGe," (MobileBERT model)"),cGe.forEach(t),YBr=i(ge),y5=n(ge,"LI",{});var fGe=s(y5);c3e=n(fGe,"STRONG",{});var fIt=s(c3e);KBr=r(fIt,"mpnet"),fIt.forEach(t),ZBr=r(fGe," \u2014 "),pZ=n(fGe,"A",{href:!0});var mIt=s(pZ);eNr=r(mIt,"TFMPNetForQuestionAnswering"),mIt.forEach(t),oNr=r(fGe," (MPNet model)"),fGe.forEach(t),rNr=i(ge),x5=n(ge,"LI",{});var mGe=s(x5);f3e=n(mGe,"STRONG",{});var gIt=s(f3e);tNr=r(gIt,"rembert"),gIt.forEach(t),aNr=r(mGe," \u2014 "),_Z=n(mGe,"A",{href:!0});var hIt=s(_Z);nNr=r(hIt,"TFRemBertForQuestionAnswering"),hIt.forEach(t),sNr=r(mGe," (RemBERT model)"),mGe.forEach(t),lNr=i(ge),$5=n(ge,"LI",{});var gGe=s($5);m3e=n(gGe,"STRONG",{});var pIt=s(m3e);iNr=r(pIt,"roberta"),pIt.forEach(t),dNr=r(gGe," \u2014 "),uZ=n(gGe,"A",{href:!0});var _It=s(uZ);cNr=r(_It,"TFRobertaForQuestionAnswering"),_It.forEach(t),fNr=r(gGe," (RoBERTa model)"),gGe.forEach(t),mNr=i(ge),k5=n(ge,"LI",{});var hGe=s(k5);g3e=n(hGe,"STRONG",{});var uIt=s(g3e);gNr=r(uIt,"roformer"),uIt.forEach(t),hNr=r(hGe," \u2014 "),bZ=n(hGe,"A",{href:!0});var bIt=s(bZ);pNr=r(bIt,"TFRoFormerForQuestionAnswering"),bIt.forEach(t),_Nr=r(hGe," (RoFormer model)"),hGe.forEach(t),uNr=i(ge),S5=n(ge,"LI",{});var pGe=s(S5);h3e=n(pGe,"STRONG",{});var vIt=s(h3e);bNr=r(vIt,"xlm"),vIt.forEach(t),vNr=r(pGe," \u2014 "),vZ=n(pGe,"A",{href:!0});var FIt=s(vZ);FNr=r(FIt,"TFXLMForQuestionAnsweringSimple"),FIt.forEach(t),TNr=r(pGe," (XLM model)"),pGe.forEach(t),MNr=i(ge),R5=n(ge,"LI",{});var _Ge=s(R5);p3e=n(_Ge,"STRONG",{});var TIt=s(p3e);ENr=r(TIt,"xlm-roberta"),TIt.forEach(t),CNr=r(_Ge," \u2014 "),FZ=n(_Ge,"A",{href:!0});var MIt=s(FZ);wNr=r(MIt,"TFXLMRobertaForQuestionAnswering"),MIt.forEach(t),ANr=r(_Ge," (XLM-RoBERTa model)"),_Ge.forEach(t),LNr=i(ge),P5=n(ge,"LI",{});var uGe=s(P5);_3e=n(uGe,"STRONG",{});var EIt=s(_3e);yNr=r(EIt,"xlnet"),EIt.forEach(t),xNr=r(uGe," \u2014 "),TZ=n(uGe,"A",{href:!0});var CIt=s(TZ);$Nr=r(CIt,"TFXLNetForQuestionAnsweringSimple"),CIt.forEach(t),kNr=r(uGe," (XLNet model)"),uGe.forEach(t),ge.forEach(t),SNr=i(Jl),T(B5.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),ZXe=i(f),Dc=n(f,"H2",{class:!0});var iWe=s(Dc);N5=n(iWe,"A",{id:!0,class:!0,href:!0});var wIt=s(N5);u3e=n(wIt,"SPAN",{});var AIt=s(u3e);T(Xx.$$.fragment,AIt),AIt.forEach(t),wIt.forEach(t),RNr=i(iWe),b3e=n(iWe,"SPAN",{});var LIt=s(b3e);PNr=r(LIt,"TFAutoModelForVision2Seq"),LIt.forEach(t),iWe.forEach(t),eze=i(f),gr=n(f,"DIV",{class:!0});var Yl=s(gr);T(zx.$$.fragment,Yl),BNr=i(Yl),Gc=n(Yl,"P",{});var Pte=s(Gc);NNr=r(Pte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),MZ=n(Pte,"A",{href:!0});var yIt=s(MZ);INr=r(yIt,"from_pretrained()"),yIt.forEach(t),qNr=r(Pte," class method or the "),EZ=n(Pte,"A",{href:!0});var xIt=s(EZ);jNr=r(xIt,"from_config()"),xIt.forEach(t),DNr=r(Pte,` class
method.`),Pte.forEach(t),GNr=i(Yl),Qx=n(Yl,"P",{});var dWe=s(Qx);ONr=r(dWe,"This class cannot be instantiated directly using "),v3e=n(dWe,"CODE",{});var $It=s(v3e);VNr=r($It,"__init__()"),$It.forEach(t),XNr=r(dWe," (throws an error)."),dWe.forEach(t),zNr=i(Yl),Vt=n(Yl,"DIV",{class:!0});var vL=s(Vt);T(Wx.$$.fragment,vL),QNr=i(vL),F3e=n(vL,"P",{});var kIt=s(F3e);WNr=r(kIt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),kIt.forEach(t),HNr=i(vL),Oc=n(vL,"P",{});var Bte=s(Oc);UNr=r(Bte,`Note:
Loading a model from its configuration file does `),T3e=n(Bte,"STRONG",{});var SIt=s(T3e);JNr=r(SIt,"not"),SIt.forEach(t),YNr=r(Bte,` load the model weights. It only affects the
model\u2019s configuration. Use `),CZ=n(Bte,"A",{href:!0});var RIt=s(CZ);KNr=r(RIt,"from_pretrained()"),RIt.forEach(t),ZNr=r(Bte," to load the model weights."),Bte.forEach(t),eIr=i(vL),T(I5.$$.fragment,vL),vL.forEach(t),oIr=i(Yl),Gr=n(Yl,"DIV",{class:!0});var Kl=s(Gr);T(Hx.$$.fragment,Kl),rIr=i(Kl),M3e=n(Kl,"P",{});var PIt=s(M3e);tIr=r(PIt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),PIt.forEach(t),aIr=i(Kl),vn=n(Kl,"P",{});var FL=s(vn);nIr=r(FL,"The model class to instantiate is selected based on the "),E3e=n(FL,"CODE",{});var BIt=s(E3e);sIr=r(BIt,"model_type"),BIt.forEach(t),lIr=r(FL,` property of the config object (either
passed as an argument or loaded from `),C3e=n(FL,"CODE",{});var NIt=s(C3e);iIr=r(NIt,"pretrained_model_name_or_path"),NIt.forEach(t),dIr=r(FL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w3e=n(FL,"CODE",{});var IIt=s(w3e);cIr=r(IIt,"pretrained_model_name_or_path"),IIt.forEach(t),fIr=r(FL,":"),FL.forEach(t),mIr=i(Kl),A3e=n(Kl,"UL",{});var qIt=s(A3e);q5=n(qIt,"LI",{});var bGe=s(q5);L3e=n(bGe,"STRONG",{});var jIt=s(L3e);gIr=r(jIt,"vision-encoder-decoder"),jIt.forEach(t),hIr=r(bGe," \u2014 "),wZ=n(bGe,"A",{href:!0});var DIt=s(wZ);pIr=r(DIt,"TFVisionEncoderDecoderModel"),DIt.forEach(t),_Ir=r(bGe," (Vision Encoder decoder model)"),bGe.forEach(t),qIt.forEach(t),uIr=i(Kl),T(j5.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),oze=i(f),Vc=n(f,"H2",{class:!0});var cWe=s(Vc);D5=n(cWe,"A",{id:!0,class:!0,href:!0});var GIt=s(D5);y3e=n(GIt,"SPAN",{});var OIt=s(y3e);T(Ux.$$.fragment,OIt),OIt.forEach(t),GIt.forEach(t),bIr=i(cWe),x3e=n(cWe,"SPAN",{});var VIt=s(x3e);vIr=r(VIt,"TFAutoModelForSpeechSeq2Seq"),VIt.forEach(t),cWe.forEach(t),rze=i(f),hr=n(f,"DIV",{class:!0});var Zl=s(hr);T(Jx.$$.fragment,Zl),FIr=i(Zl),Xc=n(Zl,"P",{});var Nte=s(Xc);TIr=r(Nte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),AZ=n(Nte,"A",{href:!0});var XIt=s(AZ);MIr=r(XIt,"from_pretrained()"),XIt.forEach(t),EIr=r(Nte," class method or the "),LZ=n(Nte,"A",{href:!0});var zIt=s(LZ);CIr=r(zIt,"from_config()"),zIt.forEach(t),wIr=r(Nte,` class
method.`),Nte.forEach(t),AIr=i(Zl),Yx=n(Zl,"P",{});var fWe=s(Yx);LIr=r(fWe,"This class cannot be instantiated directly using "),$3e=n(fWe,"CODE",{});var QIt=s($3e);yIr=r(QIt,"__init__()"),QIt.forEach(t),xIr=r(fWe," (throws an error)."),fWe.forEach(t),$Ir=i(Zl),Xt=n(Zl,"DIV",{class:!0});var TL=s(Xt);T(Kx.$$.fragment,TL),kIr=i(TL),k3e=n(TL,"P",{});var WIt=s(k3e);SIr=r(WIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),WIt.forEach(t),RIr=i(TL),zc=n(TL,"P",{});var Ite=s(zc);PIr=r(Ite,`Note:
Loading a model from its configuration file does `),S3e=n(Ite,"STRONG",{});var HIt=s(S3e);BIr=r(HIt,"not"),HIt.forEach(t),NIr=r(Ite,` load the model weights. It only affects the
model\u2019s configuration. Use `),yZ=n(Ite,"A",{href:!0});var UIt=s(yZ);IIr=r(UIt,"from_pretrained()"),UIt.forEach(t),qIr=r(Ite," to load the model weights."),Ite.forEach(t),jIr=i(TL),T(G5.$$.fragment,TL),TL.forEach(t),DIr=i(Zl),Or=n(Zl,"DIV",{class:!0});var ei=s(Or);T(Zx.$$.fragment,ei),GIr=i(ei),R3e=n(ei,"P",{});var JIt=s(R3e);OIr=r(JIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),JIt.forEach(t),VIr=i(ei),Fn=n(ei,"P",{});var ML=s(Fn);XIr=r(ML,"The model class to instantiate is selected based on the "),P3e=n(ML,"CODE",{});var YIt=s(P3e);zIr=r(YIt,"model_type"),YIt.forEach(t),QIr=r(ML,` property of the config object (either
passed as an argument or loaded from `),B3e=n(ML,"CODE",{});var KIt=s(B3e);WIr=r(KIt,"pretrained_model_name_or_path"),KIt.forEach(t),HIr=r(ML,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N3e=n(ML,"CODE",{});var ZIt=s(N3e);UIr=r(ZIt,"pretrained_model_name_or_path"),ZIt.forEach(t),JIr=r(ML,":"),ML.forEach(t),YIr=i(ei),I3e=n(ei,"UL",{});var eqt=s(I3e);O5=n(eqt,"LI",{});var vGe=s(O5);q3e=n(vGe,"STRONG",{});var oqt=s(q3e);KIr=r(oqt,"speech_to_text"),oqt.forEach(t),ZIr=r(vGe," \u2014 "),xZ=n(vGe,"A",{href:!0});var rqt=s(xZ);eqr=r(rqt,"TFSpeech2TextForConditionalGeneration"),rqt.forEach(t),oqr=r(vGe," (Speech2Text model)"),vGe.forEach(t),eqt.forEach(t),rqr=i(ei),T(V5.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),tze=i(f),Qc=n(f,"H2",{class:!0});var mWe=s(Qc);X5=n(mWe,"A",{id:!0,class:!0,href:!0});var tqt=s(X5);j3e=n(tqt,"SPAN",{});var aqt=s(j3e);T(e$.$$.fragment,aqt),aqt.forEach(t),tqt.forEach(t),tqr=i(mWe),D3e=n(mWe,"SPAN",{});var nqt=s(D3e);aqr=r(nqt,"FlaxAutoModel"),nqt.forEach(t),mWe.forEach(t),aze=i(f),pr=n(f,"DIV",{class:!0});var oi=s(pr);T(o$.$$.fragment,oi),nqr=i(oi),Wc=n(oi,"P",{});var qte=s(Wc);sqr=r(qte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),$Z=n(qte,"A",{href:!0});var sqt=s($Z);lqr=r(sqt,"from_pretrained()"),sqt.forEach(t),iqr=r(qte," class method or the "),kZ=n(qte,"A",{href:!0});var lqt=s(kZ);dqr=r(lqt,"from_config()"),lqt.forEach(t),cqr=r(qte,` class
method.`),qte.forEach(t),fqr=i(oi),r$=n(oi,"P",{});var gWe=s(r$);mqr=r(gWe,"This class cannot be instantiated directly using "),G3e=n(gWe,"CODE",{});var iqt=s(G3e);gqr=r(iqt,"__init__()"),iqt.forEach(t),hqr=r(gWe," (throws an error)."),gWe.forEach(t),pqr=i(oi),zt=n(oi,"DIV",{class:!0});var EL=s(zt);T(t$.$$.fragment,EL),_qr=i(EL),O3e=n(EL,"P",{});var dqt=s(O3e);uqr=r(dqt,"Instantiates one of the base model classes of the library from a configuration."),dqt.forEach(t),bqr=i(EL),Hc=n(EL,"P",{});var jte=s(Hc);vqr=r(jte,`Note:
Loading a model from its configuration file does `),V3e=n(jte,"STRONG",{});var cqt=s(V3e);Fqr=r(cqt,"not"),cqt.forEach(t),Tqr=r(jte,` load the model weights. It only affects the
model\u2019s configuration. Use `),SZ=n(jte,"A",{href:!0});var fqt=s(SZ);Mqr=r(fqt,"from_pretrained()"),fqt.forEach(t),Eqr=r(jte," to load the model weights."),jte.forEach(t),Cqr=i(EL),T(z5.$$.fragment,EL),EL.forEach(t),wqr=i(oi),Vr=n(oi,"DIV",{class:!0});var ri=s(Vr);T(a$.$$.fragment,ri),Aqr=i(ri),X3e=n(ri,"P",{});var mqt=s(X3e);Lqr=r(mqt,"Instantiate one of the base model classes of the library from a pretrained model."),mqt.forEach(t),yqr=i(ri),Tn=n(ri,"P",{});var CL=s(Tn);xqr=r(CL,"The model class to instantiate is selected based on the "),z3e=n(CL,"CODE",{});var gqt=s(z3e);$qr=r(gqt,"model_type"),gqt.forEach(t),kqr=r(CL,` property of the config object (either
passed as an argument or loaded from `),Q3e=n(CL,"CODE",{});var hqt=s(Q3e);Sqr=r(hqt,"pretrained_model_name_or_path"),hqt.forEach(t),Rqr=r(CL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W3e=n(CL,"CODE",{});var pqt=s(W3e);Pqr=r(pqt,"pretrained_model_name_or_path"),pqt.forEach(t),Bqr=r(CL,":"),CL.forEach(t),Nqr=i(ri),oe=n(ri,"UL",{});var ae=s(oe);Q5=n(ae,"LI",{});var FGe=s(Q5);H3e=n(FGe,"STRONG",{});var _qt=s(H3e);Iqr=r(_qt,"albert"),_qt.forEach(t),qqr=r(FGe," \u2014 "),RZ=n(FGe,"A",{href:!0});var uqt=s(RZ);jqr=r(uqt,"FlaxAlbertModel"),uqt.forEach(t),Dqr=r(FGe," (ALBERT model)"),FGe.forEach(t),Gqr=i(ae),W5=n(ae,"LI",{});var TGe=s(W5);U3e=n(TGe,"STRONG",{});var bqt=s(U3e);Oqr=r(bqt,"bart"),bqt.forEach(t),Vqr=r(TGe," \u2014 "),PZ=n(TGe,"A",{href:!0});var vqt=s(PZ);Xqr=r(vqt,"FlaxBartModel"),vqt.forEach(t),zqr=r(TGe," (BART model)"),TGe.forEach(t),Qqr=i(ae),H5=n(ae,"LI",{});var MGe=s(H5);J3e=n(MGe,"STRONG",{});var Fqt=s(J3e);Wqr=r(Fqt,"beit"),Fqt.forEach(t),Hqr=r(MGe," \u2014 "),BZ=n(MGe,"A",{href:!0});var Tqt=s(BZ);Uqr=r(Tqt,"FlaxBeitModel"),Tqt.forEach(t),Jqr=r(MGe," (BEiT model)"),MGe.forEach(t),Yqr=i(ae),U5=n(ae,"LI",{});var EGe=s(U5);Y3e=n(EGe,"STRONG",{});var Mqt=s(Y3e);Kqr=r(Mqt,"bert"),Mqt.forEach(t),Zqr=r(EGe," \u2014 "),NZ=n(EGe,"A",{href:!0});var Eqt=s(NZ);ejr=r(Eqt,"FlaxBertModel"),Eqt.forEach(t),ojr=r(EGe," (BERT model)"),EGe.forEach(t),rjr=i(ae),J5=n(ae,"LI",{});var CGe=s(J5);K3e=n(CGe,"STRONG",{});var Cqt=s(K3e);tjr=r(Cqt,"big_bird"),Cqt.forEach(t),ajr=r(CGe," \u2014 "),IZ=n(CGe,"A",{href:!0});var wqt=s(IZ);njr=r(wqt,"FlaxBigBirdModel"),wqt.forEach(t),sjr=r(CGe," (BigBird model)"),CGe.forEach(t),ljr=i(ae),Y5=n(ae,"LI",{});var wGe=s(Y5);Z3e=n(wGe,"STRONG",{});var Aqt=s(Z3e);ijr=r(Aqt,"blenderbot"),Aqt.forEach(t),djr=r(wGe," \u2014 "),qZ=n(wGe,"A",{href:!0});var Lqt=s(qZ);cjr=r(Lqt,"FlaxBlenderbotModel"),Lqt.forEach(t),fjr=r(wGe," (Blenderbot model)"),wGe.forEach(t),mjr=i(ae),K5=n(ae,"LI",{});var AGe=s(K5);e5e=n(AGe,"STRONG",{});var yqt=s(e5e);gjr=r(yqt,"blenderbot-small"),yqt.forEach(t),hjr=r(AGe," \u2014 "),jZ=n(AGe,"A",{href:!0});var xqt=s(jZ);pjr=r(xqt,"FlaxBlenderbotSmallModel"),xqt.forEach(t),_jr=r(AGe," (BlenderbotSmall model)"),AGe.forEach(t),ujr=i(ae),Z5=n(ae,"LI",{});var LGe=s(Z5);o5e=n(LGe,"STRONG",{});var $qt=s(o5e);bjr=r($qt,"clip"),$qt.forEach(t),vjr=r(LGe," \u2014 "),DZ=n(LGe,"A",{href:!0});var kqt=s(DZ);Fjr=r(kqt,"FlaxCLIPModel"),kqt.forEach(t),Tjr=r(LGe," (CLIP model)"),LGe.forEach(t),Mjr=i(ae),e0=n(ae,"LI",{});var yGe=s(e0);r5e=n(yGe,"STRONG",{});var Sqt=s(r5e);Ejr=r(Sqt,"distilbert"),Sqt.forEach(t),Cjr=r(yGe," \u2014 "),GZ=n(yGe,"A",{href:!0});var Rqt=s(GZ);wjr=r(Rqt,"FlaxDistilBertModel"),Rqt.forEach(t),Ajr=r(yGe," (DistilBERT model)"),yGe.forEach(t),Ljr=i(ae),o0=n(ae,"LI",{});var xGe=s(o0);t5e=n(xGe,"STRONG",{});var Pqt=s(t5e);yjr=r(Pqt,"electra"),Pqt.forEach(t),xjr=r(xGe," \u2014 "),OZ=n(xGe,"A",{href:!0});var Bqt=s(OZ);$jr=r(Bqt,"FlaxElectraModel"),Bqt.forEach(t),kjr=r(xGe," (ELECTRA model)"),xGe.forEach(t),Sjr=i(ae),r0=n(ae,"LI",{});var $Ge=s(r0);a5e=n($Ge,"STRONG",{});var Nqt=s(a5e);Rjr=r(Nqt,"gpt2"),Nqt.forEach(t),Pjr=r($Ge," \u2014 "),VZ=n($Ge,"A",{href:!0});var Iqt=s(VZ);Bjr=r(Iqt,"FlaxGPT2Model"),Iqt.forEach(t),Njr=r($Ge," (OpenAI GPT-2 model)"),$Ge.forEach(t),Ijr=i(ae),t0=n(ae,"LI",{});var kGe=s(t0);n5e=n(kGe,"STRONG",{});var qqt=s(n5e);qjr=r(qqt,"gpt_neo"),qqt.forEach(t),jjr=r(kGe," \u2014 "),XZ=n(kGe,"A",{href:!0});var jqt=s(XZ);Djr=r(jqt,"FlaxGPTNeoModel"),jqt.forEach(t),Gjr=r(kGe," (GPT Neo model)"),kGe.forEach(t),Ojr=i(ae),a0=n(ae,"LI",{});var SGe=s(a0);s5e=n(SGe,"STRONG",{});var Dqt=s(s5e);Vjr=r(Dqt,"gptj"),Dqt.forEach(t),Xjr=r(SGe," \u2014 "),zZ=n(SGe,"A",{href:!0});var Gqt=s(zZ);zjr=r(Gqt,"FlaxGPTJModel"),Gqt.forEach(t),Qjr=r(SGe," (GPT-J model)"),SGe.forEach(t),Wjr=i(ae),n0=n(ae,"LI",{});var RGe=s(n0);l5e=n(RGe,"STRONG",{});var Oqt=s(l5e);Hjr=r(Oqt,"longt5"),Oqt.forEach(t),Ujr=r(RGe," \u2014 "),QZ=n(RGe,"A",{href:!0});var Vqt=s(QZ);Jjr=r(Vqt,"FlaxLongT5Model"),Vqt.forEach(t),Yjr=r(RGe," (LongT5 model)"),RGe.forEach(t),Kjr=i(ae),s0=n(ae,"LI",{});var PGe=s(s0);i5e=n(PGe,"STRONG",{});var Xqt=s(i5e);Zjr=r(Xqt,"marian"),Xqt.forEach(t),eDr=r(PGe," \u2014 "),WZ=n(PGe,"A",{href:!0});var zqt=s(WZ);oDr=r(zqt,"FlaxMarianModel"),zqt.forEach(t),rDr=r(PGe," (Marian model)"),PGe.forEach(t),tDr=i(ae),l0=n(ae,"LI",{});var BGe=s(l0);d5e=n(BGe,"STRONG",{});var Qqt=s(d5e);aDr=r(Qqt,"mbart"),Qqt.forEach(t),nDr=r(BGe," \u2014 "),HZ=n(BGe,"A",{href:!0});var Wqt=s(HZ);sDr=r(Wqt,"FlaxMBartModel"),Wqt.forEach(t),lDr=r(BGe," (mBART model)"),BGe.forEach(t),iDr=i(ae),i0=n(ae,"LI",{});var NGe=s(i0);c5e=n(NGe,"STRONG",{});var Hqt=s(c5e);dDr=r(Hqt,"mt5"),Hqt.forEach(t),cDr=r(NGe," \u2014 "),UZ=n(NGe,"A",{href:!0});var Uqt=s(UZ);fDr=r(Uqt,"FlaxMT5Model"),Uqt.forEach(t),mDr=r(NGe," (MT5 model)"),NGe.forEach(t),gDr=i(ae),d0=n(ae,"LI",{});var IGe=s(d0);f5e=n(IGe,"STRONG",{});var Jqt=s(f5e);hDr=r(Jqt,"opt"),Jqt.forEach(t),pDr=r(IGe," \u2014 "),JZ=n(IGe,"A",{href:!0});var Yqt=s(JZ);_Dr=r(Yqt,"FlaxOPTModel"),Yqt.forEach(t),uDr=r(IGe," (OPT model)"),IGe.forEach(t),bDr=i(ae),c0=n(ae,"LI",{});var qGe=s(c0);m5e=n(qGe,"STRONG",{});var Kqt=s(m5e);vDr=r(Kqt,"pegasus"),Kqt.forEach(t),FDr=r(qGe," \u2014 "),YZ=n(qGe,"A",{href:!0});var Zqt=s(YZ);TDr=r(Zqt,"FlaxPegasusModel"),Zqt.forEach(t),MDr=r(qGe," (Pegasus model)"),qGe.forEach(t),EDr=i(ae),f0=n(ae,"LI",{});var jGe=s(f0);g5e=n(jGe,"STRONG",{});var ejt=s(g5e);CDr=r(ejt,"roberta"),ejt.forEach(t),wDr=r(jGe," \u2014 "),KZ=n(jGe,"A",{href:!0});var ojt=s(KZ);ADr=r(ojt,"FlaxRobertaModel"),ojt.forEach(t),LDr=r(jGe," (RoBERTa model)"),jGe.forEach(t),yDr=i(ae),m0=n(ae,"LI",{});var DGe=s(m0);h5e=n(DGe,"STRONG",{});var rjt=s(h5e);xDr=r(rjt,"roformer"),rjt.forEach(t),$Dr=r(DGe," \u2014 "),ZZ=n(DGe,"A",{href:!0});var tjt=s(ZZ);kDr=r(tjt,"FlaxRoFormerModel"),tjt.forEach(t),SDr=r(DGe," (RoFormer model)"),DGe.forEach(t),RDr=i(ae),g0=n(ae,"LI",{});var GGe=s(g0);p5e=n(GGe,"STRONG",{});var ajt=s(p5e);PDr=r(ajt,"t5"),ajt.forEach(t),BDr=r(GGe," \u2014 "),eee=n(GGe,"A",{href:!0});var njt=s(eee);NDr=r(njt,"FlaxT5Model"),njt.forEach(t),IDr=r(GGe," (T5 model)"),GGe.forEach(t),qDr=i(ae),h0=n(ae,"LI",{});var OGe=s(h0);_5e=n(OGe,"STRONG",{});var sjt=s(_5e);jDr=r(sjt,"vision-text-dual-encoder"),sjt.forEach(t),DDr=r(OGe," \u2014 "),oee=n(OGe,"A",{href:!0});var ljt=s(oee);GDr=r(ljt,"FlaxVisionTextDualEncoderModel"),ljt.forEach(t),ODr=r(OGe," (VisionTextDualEncoder model)"),OGe.forEach(t),VDr=i(ae),p0=n(ae,"LI",{});var VGe=s(p0);u5e=n(VGe,"STRONG",{});var ijt=s(u5e);XDr=r(ijt,"vit"),ijt.forEach(t),zDr=r(VGe," \u2014 "),ree=n(VGe,"A",{href:!0});var djt=s(ree);QDr=r(djt,"FlaxViTModel"),djt.forEach(t),WDr=r(VGe," (ViT model)"),VGe.forEach(t),HDr=i(ae),_0=n(ae,"LI",{});var XGe=s(_0);b5e=n(XGe,"STRONG",{});var cjt=s(b5e);UDr=r(cjt,"wav2vec2"),cjt.forEach(t),JDr=r(XGe," \u2014 "),tee=n(XGe,"A",{href:!0});var fjt=s(tee);YDr=r(fjt,"FlaxWav2Vec2Model"),fjt.forEach(t),KDr=r(XGe," (Wav2Vec2 model)"),XGe.forEach(t),ZDr=i(ae),u0=n(ae,"LI",{});var zGe=s(u0);v5e=n(zGe,"STRONG",{});var mjt=s(v5e);eGr=r(mjt,"xglm"),mjt.forEach(t),oGr=r(zGe," \u2014 "),aee=n(zGe,"A",{href:!0});var gjt=s(aee);rGr=r(gjt,"FlaxXGLMModel"),gjt.forEach(t),tGr=r(zGe," (XGLM model)"),zGe.forEach(t),aGr=i(ae),b0=n(ae,"LI",{});var QGe=s(b0);F5e=n(QGe,"STRONG",{});var hjt=s(F5e);nGr=r(hjt,"xlm-roberta"),hjt.forEach(t),sGr=r(QGe," \u2014 "),nee=n(QGe,"A",{href:!0});var pjt=s(nee);lGr=r(pjt,"FlaxXLMRobertaModel"),pjt.forEach(t),iGr=r(QGe," (XLM-RoBERTa model)"),QGe.forEach(t),ae.forEach(t),dGr=i(ri),T(v0.$$.fragment,ri),ri.forEach(t),oi.forEach(t),nze=i(f),Uc=n(f,"H2",{class:!0});var hWe=s(Uc);F0=n(hWe,"A",{id:!0,class:!0,href:!0});var _jt=s(F0);T5e=n(_jt,"SPAN",{});var ujt=s(T5e);T(n$.$$.fragment,ujt),ujt.forEach(t),_jt.forEach(t),cGr=i(hWe),M5e=n(hWe,"SPAN",{});var bjt=s(M5e);fGr=r(bjt,"FlaxAutoModelForCausalLM"),bjt.forEach(t),hWe.forEach(t),sze=i(f),_r=n(f,"DIV",{class:!0});var ti=s(_r);T(s$.$$.fragment,ti),mGr=i(ti),Jc=n(ti,"P",{});var Dte=s(Jc);gGr=r(Dte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),see=n(Dte,"A",{href:!0});var vjt=s(see);hGr=r(vjt,"from_pretrained()"),vjt.forEach(t),pGr=r(Dte," class method or the "),lee=n(Dte,"A",{href:!0});var Fjt=s(lee);_Gr=r(Fjt,"from_config()"),Fjt.forEach(t),uGr=r(Dte,` class
method.`),Dte.forEach(t),bGr=i(ti),l$=n(ti,"P",{});var pWe=s(l$);vGr=r(pWe,"This class cannot be instantiated directly using "),E5e=n(pWe,"CODE",{});var Tjt=s(E5e);FGr=r(Tjt,"__init__()"),Tjt.forEach(t),TGr=r(pWe," (throws an error)."),pWe.forEach(t),MGr=i(ti),Qt=n(ti,"DIV",{class:!0});var wL=s(Qt);T(i$.$$.fragment,wL),EGr=i(wL),C5e=n(wL,"P",{});var Mjt=s(C5e);CGr=r(Mjt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Mjt.forEach(t),wGr=i(wL),Yc=n(wL,"P",{});var Gte=s(Yc);AGr=r(Gte,`Note:
Loading a model from its configuration file does `),w5e=n(Gte,"STRONG",{});var Ejt=s(w5e);LGr=r(Ejt,"not"),Ejt.forEach(t),yGr=r(Gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),iee=n(Gte,"A",{href:!0});var Cjt=s(iee);xGr=r(Cjt,"from_pretrained()"),Cjt.forEach(t),$Gr=r(Gte," to load the model weights."),Gte.forEach(t),kGr=i(wL),T(T0.$$.fragment,wL),wL.forEach(t),SGr=i(ti),Xr=n(ti,"DIV",{class:!0});var ai=s(Xr);T(d$.$$.fragment,ai),RGr=i(ai),A5e=n(ai,"P",{});var wjt=s(A5e);PGr=r(wjt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),wjt.forEach(t),BGr=i(ai),Mn=n(ai,"P",{});var AL=s(Mn);NGr=r(AL,"The model class to instantiate is selected based on the "),L5e=n(AL,"CODE",{});var Ajt=s(L5e);IGr=r(Ajt,"model_type"),Ajt.forEach(t),qGr=r(AL,` property of the config object (either
passed as an argument or loaded from `),y5e=n(AL,"CODE",{});var Ljt=s(y5e);jGr=r(Ljt,"pretrained_model_name_or_path"),Ljt.forEach(t),DGr=r(AL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x5e=n(AL,"CODE",{});var yjt=s(x5e);GGr=r(yjt,"pretrained_model_name_or_path"),yjt.forEach(t),OGr=r(AL,":"),AL.forEach(t),VGr=i(ai),xe=n(ai,"UL",{});var Ie=s(xe);M0=n(Ie,"LI",{});var WGe=s(M0);$5e=n(WGe,"STRONG",{});var xjt=s($5e);XGr=r(xjt,"bart"),xjt.forEach(t),zGr=r(WGe," \u2014 "),dee=n(WGe,"A",{href:!0});var $jt=s(dee);QGr=r($jt,"FlaxBartForCausalLM"),$jt.forEach(t),WGr=r(WGe," (BART model)"),WGe.forEach(t),HGr=i(Ie),E0=n(Ie,"LI",{});var HGe=s(E0);k5e=n(HGe,"STRONG",{});var kjt=s(k5e);UGr=r(kjt,"bert"),kjt.forEach(t),JGr=r(HGe," \u2014 "),cee=n(HGe,"A",{href:!0});var Sjt=s(cee);YGr=r(Sjt,"FlaxBertForCausalLM"),Sjt.forEach(t),KGr=r(HGe," (BERT model)"),HGe.forEach(t),ZGr=i(Ie),C0=n(Ie,"LI",{});var UGe=s(C0);S5e=n(UGe,"STRONG",{});var Rjt=s(S5e);eOr=r(Rjt,"big_bird"),Rjt.forEach(t),oOr=r(UGe," \u2014 "),fee=n(UGe,"A",{href:!0});var Pjt=s(fee);rOr=r(Pjt,"FlaxBigBirdForCausalLM"),Pjt.forEach(t),tOr=r(UGe," (BigBird model)"),UGe.forEach(t),aOr=i(Ie),w0=n(Ie,"LI",{});var JGe=s(w0);R5e=n(JGe,"STRONG",{});var Bjt=s(R5e);nOr=r(Bjt,"electra"),Bjt.forEach(t),sOr=r(JGe," \u2014 "),mee=n(JGe,"A",{href:!0});var Njt=s(mee);lOr=r(Njt,"FlaxElectraForCausalLM"),Njt.forEach(t),iOr=r(JGe," (ELECTRA model)"),JGe.forEach(t),dOr=i(Ie),A0=n(Ie,"LI",{});var YGe=s(A0);P5e=n(YGe,"STRONG",{});var Ijt=s(P5e);cOr=r(Ijt,"gpt2"),Ijt.forEach(t),fOr=r(YGe," \u2014 "),gee=n(YGe,"A",{href:!0});var qjt=s(gee);mOr=r(qjt,"FlaxGPT2LMHeadModel"),qjt.forEach(t),gOr=r(YGe," (OpenAI GPT-2 model)"),YGe.forEach(t),hOr=i(Ie),L0=n(Ie,"LI",{});var KGe=s(L0);B5e=n(KGe,"STRONG",{});var jjt=s(B5e);pOr=r(jjt,"gpt_neo"),jjt.forEach(t),_Or=r(KGe," \u2014 "),hee=n(KGe,"A",{href:!0});var Djt=s(hee);uOr=r(Djt,"FlaxGPTNeoForCausalLM"),Djt.forEach(t),bOr=r(KGe," (GPT Neo model)"),KGe.forEach(t),vOr=i(Ie),y0=n(Ie,"LI",{});var ZGe=s(y0);N5e=n(ZGe,"STRONG",{});var Gjt=s(N5e);FOr=r(Gjt,"gptj"),Gjt.forEach(t),TOr=r(ZGe," \u2014 "),pee=n(ZGe,"A",{href:!0});var Ojt=s(pee);MOr=r(Ojt,"FlaxGPTJForCausalLM"),Ojt.forEach(t),EOr=r(ZGe," (GPT-J model)"),ZGe.forEach(t),COr=i(Ie),x0=n(Ie,"LI",{});var eOe=s(x0);I5e=n(eOe,"STRONG",{});var Vjt=s(I5e);wOr=r(Vjt,"opt"),Vjt.forEach(t),AOr=r(eOe," \u2014 "),_ee=n(eOe,"A",{href:!0});var Xjt=s(_ee);LOr=r(Xjt,"FlaxOPTForCausalLM"),Xjt.forEach(t),yOr=r(eOe," (OPT model)"),eOe.forEach(t),xOr=i(Ie),$0=n(Ie,"LI",{});var oOe=s($0);q5e=n(oOe,"STRONG",{});var zjt=s(q5e);$Or=r(zjt,"roberta"),zjt.forEach(t),kOr=r(oOe," \u2014 "),uee=n(oOe,"A",{href:!0});var Qjt=s(uee);SOr=r(Qjt,"FlaxRobertaForCausalLM"),Qjt.forEach(t),ROr=r(oOe," (RoBERTa model)"),oOe.forEach(t),POr=i(Ie),k0=n(Ie,"LI",{});var rOe=s(k0);j5e=n(rOe,"STRONG",{});var Wjt=s(j5e);BOr=r(Wjt,"xglm"),Wjt.forEach(t),NOr=r(rOe," \u2014 "),bee=n(rOe,"A",{href:!0});var Hjt=s(bee);IOr=r(Hjt,"FlaxXGLMForCausalLM"),Hjt.forEach(t),qOr=r(rOe," (XGLM model)"),rOe.forEach(t),Ie.forEach(t),jOr=i(ai),T(S0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),lze=i(f),Kc=n(f,"H2",{class:!0});var _We=s(Kc);R0=n(_We,"A",{id:!0,class:!0,href:!0});var Ujt=s(R0);D5e=n(Ujt,"SPAN",{});var Jjt=s(D5e);T(c$.$$.fragment,Jjt),Jjt.forEach(t),Ujt.forEach(t),DOr=i(_We),G5e=n(_We,"SPAN",{});var Yjt=s(G5e);GOr=r(Yjt,"FlaxAutoModelForPreTraining"),Yjt.forEach(t),_We.forEach(t),ize=i(f),ur=n(f,"DIV",{class:!0});var ni=s(ur);T(f$.$$.fragment,ni),OOr=i(ni),Zc=n(ni,"P",{});var Ote=s(Zc);VOr=r(Ote,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),vee=n(Ote,"A",{href:!0});var Kjt=s(vee);XOr=r(Kjt,"from_pretrained()"),Kjt.forEach(t),zOr=r(Ote," class method or the "),Fee=n(Ote,"A",{href:!0});var Zjt=s(Fee);QOr=r(Zjt,"from_config()"),Zjt.forEach(t),WOr=r(Ote,` class
method.`),Ote.forEach(t),HOr=i(ni),m$=n(ni,"P",{});var uWe=s(m$);UOr=r(uWe,"This class cannot be instantiated directly using "),O5e=n(uWe,"CODE",{});var eDt=s(O5e);JOr=r(eDt,"__init__()"),eDt.forEach(t),YOr=r(uWe," (throws an error)."),uWe.forEach(t),KOr=i(ni),Wt=n(ni,"DIV",{class:!0});var LL=s(Wt);T(g$.$$.fragment,LL),ZOr=i(LL),V5e=n(LL,"P",{});var oDt=s(V5e);eVr=r(oDt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),oDt.forEach(t),oVr=i(LL),ef=n(LL,"P",{});var Vte=s(ef);rVr=r(Vte,`Note:
Loading a model from its configuration file does `),X5e=n(Vte,"STRONG",{});var rDt=s(X5e);tVr=r(rDt,"not"),rDt.forEach(t),aVr=r(Vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tee=n(Vte,"A",{href:!0});var tDt=s(Tee);nVr=r(tDt,"from_pretrained()"),tDt.forEach(t),sVr=r(Vte," to load the model weights."),Vte.forEach(t),lVr=i(LL),T(P0.$$.fragment,LL),LL.forEach(t),iVr=i(ni),zr=n(ni,"DIV",{class:!0});var si=s(zr);T(h$.$$.fragment,si),dVr=i(si),z5e=n(si,"P",{});var aDt=s(z5e);cVr=r(aDt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),aDt.forEach(t),fVr=i(si),En=n(si,"P",{});var yL=s(En);mVr=r(yL,"The model class to instantiate is selected based on the "),Q5e=n(yL,"CODE",{});var nDt=s(Q5e);gVr=r(nDt,"model_type"),nDt.forEach(t),hVr=r(yL,` property of the config object (either
passed as an argument or loaded from `),W5e=n(yL,"CODE",{});var sDt=s(W5e);pVr=r(sDt,"pretrained_model_name_or_path"),sDt.forEach(t),_Vr=r(yL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H5e=n(yL,"CODE",{});var lDt=s(H5e);uVr=r(lDt,"pretrained_model_name_or_path"),lDt.forEach(t),bVr=r(yL,":"),yL.forEach(t),vVr=i(si),Ee=n(si,"UL",{});var we=s(Ee);B0=n(we,"LI",{});var tOe=s(B0);U5e=n(tOe,"STRONG",{});var iDt=s(U5e);FVr=r(iDt,"albert"),iDt.forEach(t),TVr=r(tOe," \u2014 "),Mee=n(tOe,"A",{href:!0});var dDt=s(Mee);MVr=r(dDt,"FlaxAlbertForPreTraining"),dDt.forEach(t),EVr=r(tOe," (ALBERT model)"),tOe.forEach(t),CVr=i(we),N0=n(we,"LI",{});var aOe=s(N0);J5e=n(aOe,"STRONG",{});var cDt=s(J5e);wVr=r(cDt,"bart"),cDt.forEach(t),AVr=r(aOe," \u2014 "),Eee=n(aOe,"A",{href:!0});var fDt=s(Eee);LVr=r(fDt,"FlaxBartForConditionalGeneration"),fDt.forEach(t),yVr=r(aOe," (BART model)"),aOe.forEach(t),xVr=i(we),I0=n(we,"LI",{});var nOe=s(I0);Y5e=n(nOe,"STRONG",{});var mDt=s(Y5e);$Vr=r(mDt,"bert"),mDt.forEach(t),kVr=r(nOe," \u2014 "),Cee=n(nOe,"A",{href:!0});var gDt=s(Cee);SVr=r(gDt,"FlaxBertForPreTraining"),gDt.forEach(t),RVr=r(nOe," (BERT model)"),nOe.forEach(t),PVr=i(we),q0=n(we,"LI",{});var sOe=s(q0);K5e=n(sOe,"STRONG",{});var hDt=s(K5e);BVr=r(hDt,"big_bird"),hDt.forEach(t),NVr=r(sOe," \u2014 "),wee=n(sOe,"A",{href:!0});var pDt=s(wee);IVr=r(pDt,"FlaxBigBirdForPreTraining"),pDt.forEach(t),qVr=r(sOe," (BigBird model)"),sOe.forEach(t),jVr=i(we),j0=n(we,"LI",{});var lOe=s(j0);Z5e=n(lOe,"STRONG",{});var _Dt=s(Z5e);DVr=r(_Dt,"electra"),_Dt.forEach(t),GVr=r(lOe," \u2014 "),Aee=n(lOe,"A",{href:!0});var uDt=s(Aee);OVr=r(uDt,"FlaxElectraForPreTraining"),uDt.forEach(t),VVr=r(lOe," (ELECTRA model)"),lOe.forEach(t),XVr=i(we),D0=n(we,"LI",{});var iOe=s(D0);e0e=n(iOe,"STRONG",{});var bDt=s(e0e);zVr=r(bDt,"longt5"),bDt.forEach(t),QVr=r(iOe," \u2014 "),Lee=n(iOe,"A",{href:!0});var vDt=s(Lee);WVr=r(vDt,"FlaxLongT5ForConditionalGeneration"),vDt.forEach(t),HVr=r(iOe," (LongT5 model)"),iOe.forEach(t),UVr=i(we),G0=n(we,"LI",{});var dOe=s(G0);o0e=n(dOe,"STRONG",{});var FDt=s(o0e);JVr=r(FDt,"mbart"),FDt.forEach(t),YVr=r(dOe," \u2014 "),yee=n(dOe,"A",{href:!0});var TDt=s(yee);KVr=r(TDt,"FlaxMBartForConditionalGeneration"),TDt.forEach(t),ZVr=r(dOe," (mBART model)"),dOe.forEach(t),eXr=i(we),O0=n(we,"LI",{});var cOe=s(O0);r0e=n(cOe,"STRONG",{});var MDt=s(r0e);oXr=r(MDt,"mt5"),MDt.forEach(t),rXr=r(cOe," \u2014 "),xee=n(cOe,"A",{href:!0});var EDt=s(xee);tXr=r(EDt,"FlaxMT5ForConditionalGeneration"),EDt.forEach(t),aXr=r(cOe," (MT5 model)"),cOe.forEach(t),nXr=i(we),V0=n(we,"LI",{});var fOe=s(V0);t0e=n(fOe,"STRONG",{});var CDt=s(t0e);sXr=r(CDt,"roberta"),CDt.forEach(t),lXr=r(fOe," \u2014 "),$ee=n(fOe,"A",{href:!0});var wDt=s($ee);iXr=r(wDt,"FlaxRobertaForMaskedLM"),wDt.forEach(t),dXr=r(fOe," (RoBERTa model)"),fOe.forEach(t),cXr=i(we),X0=n(we,"LI",{});var mOe=s(X0);a0e=n(mOe,"STRONG",{});var ADt=s(a0e);fXr=r(ADt,"roformer"),ADt.forEach(t),mXr=r(mOe," \u2014 "),kee=n(mOe,"A",{href:!0});var LDt=s(kee);gXr=r(LDt,"FlaxRoFormerForMaskedLM"),LDt.forEach(t),hXr=r(mOe," (RoFormer model)"),mOe.forEach(t),pXr=i(we),z0=n(we,"LI",{});var gOe=s(z0);n0e=n(gOe,"STRONG",{});var yDt=s(n0e);_Xr=r(yDt,"t5"),yDt.forEach(t),uXr=r(gOe," \u2014 "),See=n(gOe,"A",{href:!0});var xDt=s(See);bXr=r(xDt,"FlaxT5ForConditionalGeneration"),xDt.forEach(t),vXr=r(gOe," (T5 model)"),gOe.forEach(t),FXr=i(we),Q0=n(we,"LI",{});var hOe=s(Q0);s0e=n(hOe,"STRONG",{});var $Dt=s(s0e);TXr=r($Dt,"wav2vec2"),$Dt.forEach(t),MXr=r(hOe," \u2014 "),Ree=n(hOe,"A",{href:!0});var kDt=s(Ree);EXr=r(kDt,"FlaxWav2Vec2ForPreTraining"),kDt.forEach(t),CXr=r(hOe," (Wav2Vec2 model)"),hOe.forEach(t),wXr=i(we),W0=n(we,"LI",{});var pOe=s(W0);l0e=n(pOe,"STRONG",{});var SDt=s(l0e);AXr=r(SDt,"xlm-roberta"),SDt.forEach(t),LXr=r(pOe," \u2014 "),Pee=n(pOe,"A",{href:!0});var RDt=s(Pee);yXr=r(RDt,"FlaxXLMRobertaForMaskedLM"),RDt.forEach(t),xXr=r(pOe," (XLM-RoBERTa model)"),pOe.forEach(t),we.forEach(t),$Xr=i(si),T(H0.$$.fragment,si),si.forEach(t),ni.forEach(t),dze=i(f),of=n(f,"H2",{class:!0});var bWe=s(of);U0=n(bWe,"A",{id:!0,class:!0,href:!0});var PDt=s(U0);i0e=n(PDt,"SPAN",{});var BDt=s(i0e);T(p$.$$.fragment,BDt),BDt.forEach(t),PDt.forEach(t),kXr=i(bWe),d0e=n(bWe,"SPAN",{});var NDt=s(d0e);SXr=r(NDt,"FlaxAutoModelForMaskedLM"),NDt.forEach(t),bWe.forEach(t),cze=i(f),br=n(f,"DIV",{class:!0});var li=s(br);T(_$.$$.fragment,li),RXr=i(li),rf=n(li,"P",{});var Xte=s(rf);PXr=r(Xte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Bee=n(Xte,"A",{href:!0});var IDt=s(Bee);BXr=r(IDt,"from_pretrained()"),IDt.forEach(t),NXr=r(Xte," class method or the "),Nee=n(Xte,"A",{href:!0});var qDt=s(Nee);IXr=r(qDt,"from_config()"),qDt.forEach(t),qXr=r(Xte,` class
method.`),Xte.forEach(t),jXr=i(li),u$=n(li,"P",{});var vWe=s(u$);DXr=r(vWe,"This class cannot be instantiated directly using "),c0e=n(vWe,"CODE",{});var jDt=s(c0e);GXr=r(jDt,"__init__()"),jDt.forEach(t),OXr=r(vWe," (throws an error)."),vWe.forEach(t),VXr=i(li),Ht=n(li,"DIV",{class:!0});var xL=s(Ht);T(b$.$$.fragment,xL),XXr=i(xL),f0e=n(xL,"P",{});var DDt=s(f0e);zXr=r(DDt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),DDt.forEach(t),QXr=i(xL),tf=n(xL,"P",{});var zte=s(tf);WXr=r(zte,`Note:
Loading a model from its configuration file does `),m0e=n(zte,"STRONG",{});var GDt=s(m0e);HXr=r(GDt,"not"),GDt.forEach(t),UXr=r(zte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Iee=n(zte,"A",{href:!0});var ODt=s(Iee);JXr=r(ODt,"from_pretrained()"),ODt.forEach(t),YXr=r(zte," to load the model weights."),zte.forEach(t),KXr=i(xL),T(J0.$$.fragment,xL),xL.forEach(t),ZXr=i(li),Qr=n(li,"DIV",{class:!0});var ii=s(Qr);T(v$.$$.fragment,ii),ezr=i(ii),g0e=n(ii,"P",{});var VDt=s(g0e);ozr=r(VDt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),VDt.forEach(t),rzr=i(ii),Cn=n(ii,"P",{});var $L=s(Cn);tzr=r($L,"The model class to instantiate is selected based on the "),h0e=n($L,"CODE",{});var XDt=s(h0e);azr=r(XDt,"model_type"),XDt.forEach(t),nzr=r($L,` property of the config object (either
passed as an argument or loaded from `),p0e=n($L,"CODE",{});var zDt=s(p0e);szr=r(zDt,"pretrained_model_name_or_path"),zDt.forEach(t),lzr=r($L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_0e=n($L,"CODE",{});var QDt=s(_0e);izr=r(QDt,"pretrained_model_name_or_path"),QDt.forEach(t),dzr=r($L,":"),$L.forEach(t),czr=i(ii),$e=n(ii,"UL",{});var qe=s($e);Y0=n(qe,"LI",{});var _Oe=s(Y0);u0e=n(_Oe,"STRONG",{});var WDt=s(u0e);fzr=r(WDt,"albert"),WDt.forEach(t),mzr=r(_Oe," \u2014 "),qee=n(_Oe,"A",{href:!0});var HDt=s(qee);gzr=r(HDt,"FlaxAlbertForMaskedLM"),HDt.forEach(t),hzr=r(_Oe," (ALBERT model)"),_Oe.forEach(t),pzr=i(qe),K0=n(qe,"LI",{});var uOe=s(K0);b0e=n(uOe,"STRONG",{});var UDt=s(b0e);_zr=r(UDt,"bart"),UDt.forEach(t),uzr=r(uOe," \u2014 "),jee=n(uOe,"A",{href:!0});var JDt=s(jee);bzr=r(JDt,"FlaxBartForConditionalGeneration"),JDt.forEach(t),vzr=r(uOe," (BART model)"),uOe.forEach(t),Fzr=i(qe),Z0=n(qe,"LI",{});var bOe=s(Z0);v0e=n(bOe,"STRONG",{});var YDt=s(v0e);Tzr=r(YDt,"bert"),YDt.forEach(t),Mzr=r(bOe," \u2014 "),Dee=n(bOe,"A",{href:!0});var KDt=s(Dee);Ezr=r(KDt,"FlaxBertForMaskedLM"),KDt.forEach(t),Czr=r(bOe," (BERT model)"),bOe.forEach(t),wzr=i(qe),ew=n(qe,"LI",{});var vOe=s(ew);F0e=n(vOe,"STRONG",{});var ZDt=s(F0e);Azr=r(ZDt,"big_bird"),ZDt.forEach(t),Lzr=r(vOe," \u2014 "),Gee=n(vOe,"A",{href:!0});var eGt=s(Gee);yzr=r(eGt,"FlaxBigBirdForMaskedLM"),eGt.forEach(t),xzr=r(vOe," (BigBird model)"),vOe.forEach(t),$zr=i(qe),ow=n(qe,"LI",{});var FOe=s(ow);T0e=n(FOe,"STRONG",{});var oGt=s(T0e);kzr=r(oGt,"distilbert"),oGt.forEach(t),Szr=r(FOe," \u2014 "),Oee=n(FOe,"A",{href:!0});var rGt=s(Oee);Rzr=r(rGt,"FlaxDistilBertForMaskedLM"),rGt.forEach(t),Pzr=r(FOe," (DistilBERT model)"),FOe.forEach(t),Bzr=i(qe),rw=n(qe,"LI",{});var TOe=s(rw);M0e=n(TOe,"STRONG",{});var tGt=s(M0e);Nzr=r(tGt,"electra"),tGt.forEach(t),Izr=r(TOe," \u2014 "),Vee=n(TOe,"A",{href:!0});var aGt=s(Vee);qzr=r(aGt,"FlaxElectraForMaskedLM"),aGt.forEach(t),jzr=r(TOe," (ELECTRA model)"),TOe.forEach(t),Dzr=i(qe),tw=n(qe,"LI",{});var MOe=s(tw);E0e=n(MOe,"STRONG",{});var nGt=s(E0e);Gzr=r(nGt,"mbart"),nGt.forEach(t),Ozr=r(MOe," \u2014 "),Xee=n(MOe,"A",{href:!0});var sGt=s(Xee);Vzr=r(sGt,"FlaxMBartForConditionalGeneration"),sGt.forEach(t),Xzr=r(MOe," (mBART model)"),MOe.forEach(t),zzr=i(qe),aw=n(qe,"LI",{});var EOe=s(aw);C0e=n(EOe,"STRONG",{});var lGt=s(C0e);Qzr=r(lGt,"roberta"),lGt.forEach(t),Wzr=r(EOe," \u2014 "),zee=n(EOe,"A",{href:!0});var iGt=s(zee);Hzr=r(iGt,"FlaxRobertaForMaskedLM"),iGt.forEach(t),Uzr=r(EOe," (RoBERTa model)"),EOe.forEach(t),Jzr=i(qe),nw=n(qe,"LI",{});var COe=s(nw);w0e=n(COe,"STRONG",{});var dGt=s(w0e);Yzr=r(dGt,"roformer"),dGt.forEach(t),Kzr=r(COe," \u2014 "),Qee=n(COe,"A",{href:!0});var cGt=s(Qee);Zzr=r(cGt,"FlaxRoFormerForMaskedLM"),cGt.forEach(t),eQr=r(COe," (RoFormer model)"),COe.forEach(t),oQr=i(qe),sw=n(qe,"LI",{});var wOe=s(sw);A0e=n(wOe,"STRONG",{});var fGt=s(A0e);rQr=r(fGt,"xlm-roberta"),fGt.forEach(t),tQr=r(wOe," \u2014 "),Wee=n(wOe,"A",{href:!0});var mGt=s(Wee);aQr=r(mGt,"FlaxXLMRobertaForMaskedLM"),mGt.forEach(t),nQr=r(wOe," (XLM-RoBERTa model)"),wOe.forEach(t),qe.forEach(t),sQr=i(ii),T(lw.$$.fragment,ii),ii.forEach(t),li.forEach(t),fze=i(f),af=n(f,"H2",{class:!0});var FWe=s(af);iw=n(FWe,"A",{id:!0,class:!0,href:!0});var gGt=s(iw);L0e=n(gGt,"SPAN",{});var hGt=s(L0e);T(F$.$$.fragment,hGt),hGt.forEach(t),gGt.forEach(t),lQr=i(FWe),y0e=n(FWe,"SPAN",{});var pGt=s(y0e);iQr=r(pGt,"FlaxAutoModelForSeq2SeqLM"),pGt.forEach(t),FWe.forEach(t),mze=i(f),vr=n(f,"DIV",{class:!0});var di=s(vr);T(T$.$$.fragment,di),dQr=i(di),nf=n(di,"P",{});var Qte=s(nf);cQr=r(Qte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Hee=n(Qte,"A",{href:!0});var _Gt=s(Hee);fQr=r(_Gt,"from_pretrained()"),_Gt.forEach(t),mQr=r(Qte," class method or the "),Uee=n(Qte,"A",{href:!0});var uGt=s(Uee);gQr=r(uGt,"from_config()"),uGt.forEach(t),hQr=r(Qte,` class
method.`),Qte.forEach(t),pQr=i(di),M$=n(di,"P",{});var TWe=s(M$);_Qr=r(TWe,"This class cannot be instantiated directly using "),x0e=n(TWe,"CODE",{});var bGt=s(x0e);uQr=r(bGt,"__init__()"),bGt.forEach(t),bQr=r(TWe," (throws an error)."),TWe.forEach(t),vQr=i(di),Ut=n(di,"DIV",{class:!0});var kL=s(Ut);T(E$.$$.fragment,kL),FQr=i(kL),$0e=n(kL,"P",{});var vGt=s($0e);TQr=r(vGt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vGt.forEach(t),MQr=i(kL),sf=n(kL,"P",{});var Wte=s(sf);EQr=r(Wte,`Note:
Loading a model from its configuration file does `),k0e=n(Wte,"STRONG",{});var FGt=s(k0e);CQr=r(FGt,"not"),FGt.forEach(t),wQr=r(Wte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(Wte,"A",{href:!0});var TGt=s(Jee);AQr=r(TGt,"from_pretrained()"),TGt.forEach(t),LQr=r(Wte," to load the model weights."),Wte.forEach(t),yQr=i(kL),T(dw.$$.fragment,kL),kL.forEach(t),xQr=i(di),Wr=n(di,"DIV",{class:!0});var ci=s(Wr);T(C$.$$.fragment,ci),$Qr=i(ci),S0e=n(ci,"P",{});var MGt=s(S0e);kQr=r(MGt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),MGt.forEach(t),SQr=i(ci),wn=n(ci,"P",{});var SL=s(wn);RQr=r(SL,"The model class to instantiate is selected based on the "),R0e=n(SL,"CODE",{});var EGt=s(R0e);PQr=r(EGt,"model_type"),EGt.forEach(t),BQr=r(SL,` property of the config object (either
passed as an argument or loaded from `),P0e=n(SL,"CODE",{});var CGt=s(P0e);NQr=r(CGt,"pretrained_model_name_or_path"),CGt.forEach(t),IQr=r(SL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B0e=n(SL,"CODE",{});var wGt=s(B0e);qQr=r(wGt,"pretrained_model_name_or_path"),wGt.forEach(t),jQr=r(SL,":"),SL.forEach(t),DQr=i(ci),ke=n(ci,"UL",{});var je=s(ke);cw=n(je,"LI",{});var AOe=s(cw);N0e=n(AOe,"STRONG",{});var AGt=s(N0e);GQr=r(AGt,"bart"),AGt.forEach(t),OQr=r(AOe," \u2014 "),Yee=n(AOe,"A",{href:!0});var LGt=s(Yee);VQr=r(LGt,"FlaxBartForConditionalGeneration"),LGt.forEach(t),XQr=r(AOe," (BART model)"),AOe.forEach(t),zQr=i(je),fw=n(je,"LI",{});var LOe=s(fw);I0e=n(LOe,"STRONG",{});var yGt=s(I0e);QQr=r(yGt,"blenderbot"),yGt.forEach(t),WQr=r(LOe," \u2014 "),Kee=n(LOe,"A",{href:!0});var xGt=s(Kee);HQr=r(xGt,"FlaxBlenderbotForConditionalGeneration"),xGt.forEach(t),UQr=r(LOe," (Blenderbot model)"),LOe.forEach(t),JQr=i(je),mw=n(je,"LI",{});var yOe=s(mw);q0e=n(yOe,"STRONG",{});var $Gt=s(q0e);YQr=r($Gt,"blenderbot-small"),$Gt.forEach(t),KQr=r(yOe," \u2014 "),Zee=n(yOe,"A",{href:!0});var kGt=s(Zee);ZQr=r(kGt,"FlaxBlenderbotSmallForConditionalGeneration"),kGt.forEach(t),eWr=r(yOe," (BlenderbotSmall model)"),yOe.forEach(t),oWr=i(je),gw=n(je,"LI",{});var xOe=s(gw);j0e=n(xOe,"STRONG",{});var SGt=s(j0e);rWr=r(SGt,"encoder-decoder"),SGt.forEach(t),tWr=r(xOe," \u2014 "),eoe=n(xOe,"A",{href:!0});var RGt=s(eoe);aWr=r(RGt,"FlaxEncoderDecoderModel"),RGt.forEach(t),nWr=r(xOe," (Encoder decoder model)"),xOe.forEach(t),sWr=i(je),hw=n(je,"LI",{});var $Oe=s(hw);D0e=n($Oe,"STRONG",{});var PGt=s(D0e);lWr=r(PGt,"longt5"),PGt.forEach(t),iWr=r($Oe," \u2014 "),ooe=n($Oe,"A",{href:!0});var BGt=s(ooe);dWr=r(BGt,"FlaxLongT5ForConditionalGeneration"),BGt.forEach(t),cWr=r($Oe," (LongT5 model)"),$Oe.forEach(t),fWr=i(je),pw=n(je,"LI",{});var kOe=s(pw);G0e=n(kOe,"STRONG",{});var NGt=s(G0e);mWr=r(NGt,"marian"),NGt.forEach(t),gWr=r(kOe," \u2014 "),roe=n(kOe,"A",{href:!0});var IGt=s(roe);hWr=r(IGt,"FlaxMarianMTModel"),IGt.forEach(t),pWr=r(kOe," (Marian model)"),kOe.forEach(t),_Wr=i(je),_w=n(je,"LI",{});var SOe=s(_w);O0e=n(SOe,"STRONG",{});var qGt=s(O0e);uWr=r(qGt,"mbart"),qGt.forEach(t),bWr=r(SOe," \u2014 "),toe=n(SOe,"A",{href:!0});var jGt=s(toe);vWr=r(jGt,"FlaxMBartForConditionalGeneration"),jGt.forEach(t),FWr=r(SOe," (mBART model)"),SOe.forEach(t),TWr=i(je),uw=n(je,"LI",{});var ROe=s(uw);V0e=n(ROe,"STRONG",{});var DGt=s(V0e);MWr=r(DGt,"mt5"),DGt.forEach(t),EWr=r(ROe," \u2014 "),aoe=n(ROe,"A",{href:!0});var GGt=s(aoe);CWr=r(GGt,"FlaxMT5ForConditionalGeneration"),GGt.forEach(t),wWr=r(ROe," (MT5 model)"),ROe.forEach(t),AWr=i(je),bw=n(je,"LI",{});var POe=s(bw);X0e=n(POe,"STRONG",{});var OGt=s(X0e);LWr=r(OGt,"pegasus"),OGt.forEach(t),yWr=r(POe," \u2014 "),noe=n(POe,"A",{href:!0});var VGt=s(noe);xWr=r(VGt,"FlaxPegasusForConditionalGeneration"),VGt.forEach(t),$Wr=r(POe," (Pegasus model)"),POe.forEach(t),kWr=i(je),vw=n(je,"LI",{});var BOe=s(vw);z0e=n(BOe,"STRONG",{});var XGt=s(z0e);SWr=r(XGt,"t5"),XGt.forEach(t),RWr=r(BOe," \u2014 "),soe=n(BOe,"A",{href:!0});var zGt=s(soe);PWr=r(zGt,"FlaxT5ForConditionalGeneration"),zGt.forEach(t),BWr=r(BOe," (T5 model)"),BOe.forEach(t),je.forEach(t),NWr=i(ci),T(Fw.$$.fragment,ci),ci.forEach(t),di.forEach(t),gze=i(f),lf=n(f,"H2",{class:!0});var MWe=s(lf);Tw=n(MWe,"A",{id:!0,class:!0,href:!0});var QGt=s(Tw);Q0e=n(QGt,"SPAN",{});var WGt=s(Q0e);T(w$.$$.fragment,WGt),WGt.forEach(t),QGt.forEach(t),IWr=i(MWe),W0e=n(MWe,"SPAN",{});var HGt=s(W0e);qWr=r(HGt,"FlaxAutoModelForSequenceClassification"),HGt.forEach(t),MWe.forEach(t),hze=i(f),Fr=n(f,"DIV",{class:!0});var fi=s(Fr);T(A$.$$.fragment,fi),jWr=i(fi),df=n(fi,"P",{});var Hte=s(df);DWr=r(Hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),loe=n(Hte,"A",{href:!0});var UGt=s(loe);GWr=r(UGt,"from_pretrained()"),UGt.forEach(t),OWr=r(Hte," class method or the "),ioe=n(Hte,"A",{href:!0});var JGt=s(ioe);VWr=r(JGt,"from_config()"),JGt.forEach(t),XWr=r(Hte,` class
method.`),Hte.forEach(t),zWr=i(fi),L$=n(fi,"P",{});var EWe=s(L$);QWr=r(EWe,"This class cannot be instantiated directly using "),H0e=n(EWe,"CODE",{});var YGt=s(H0e);WWr=r(YGt,"__init__()"),YGt.forEach(t),HWr=r(EWe," (throws an error)."),EWe.forEach(t),UWr=i(fi),Jt=n(fi,"DIV",{class:!0});var RL=s(Jt);T(y$.$$.fragment,RL),JWr=i(RL),U0e=n(RL,"P",{});var KGt=s(U0e);YWr=r(KGt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),KGt.forEach(t),KWr=i(RL),cf=n(RL,"P",{});var Ute=s(cf);ZWr=r(Ute,`Note:
Loading a model from its configuration file does `),J0e=n(Ute,"STRONG",{});var ZGt=s(J0e);eHr=r(ZGt,"not"),ZGt.forEach(t),oHr=r(Ute,` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=n(Ute,"A",{href:!0});var eOt=s(doe);rHr=r(eOt,"from_pretrained()"),eOt.forEach(t),tHr=r(Ute," to load the model weights."),Ute.forEach(t),aHr=i(RL),T(Mw.$$.fragment,RL),RL.forEach(t),nHr=i(fi),Hr=n(fi,"DIV",{class:!0});var mi=s(Hr);T(x$.$$.fragment,mi),sHr=i(mi),Y0e=n(mi,"P",{});var oOt=s(Y0e);lHr=r(oOt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oOt.forEach(t),iHr=i(mi),An=n(mi,"P",{});var PL=s(An);dHr=r(PL,"The model class to instantiate is selected based on the "),K0e=n(PL,"CODE",{});var rOt=s(K0e);cHr=r(rOt,"model_type"),rOt.forEach(t),fHr=r(PL,` property of the config object (either
passed as an argument or loaded from `),Z0e=n(PL,"CODE",{});var tOt=s(Z0e);mHr=r(tOt,"pretrained_model_name_or_path"),tOt.forEach(t),gHr=r(PL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=n(PL,"CODE",{});var aOt=s(ewe);hHr=r(aOt,"pretrained_model_name_or_path"),aOt.forEach(t),pHr=r(PL,":"),PL.forEach(t),_Hr=i(mi),Se=n(mi,"UL",{});var De=s(Se);Ew=n(De,"LI",{});var NOe=s(Ew);owe=n(NOe,"STRONG",{});var nOt=s(owe);uHr=r(nOt,"albert"),nOt.forEach(t),bHr=r(NOe," \u2014 "),coe=n(NOe,"A",{href:!0});var sOt=s(coe);vHr=r(sOt,"FlaxAlbertForSequenceClassification"),sOt.forEach(t),FHr=r(NOe," (ALBERT model)"),NOe.forEach(t),THr=i(De),Cw=n(De,"LI",{});var IOe=s(Cw);rwe=n(IOe,"STRONG",{});var lOt=s(rwe);MHr=r(lOt,"bart"),lOt.forEach(t),EHr=r(IOe," \u2014 "),foe=n(IOe,"A",{href:!0});var iOt=s(foe);CHr=r(iOt,"FlaxBartForSequenceClassification"),iOt.forEach(t),wHr=r(IOe," (BART model)"),IOe.forEach(t),AHr=i(De),ww=n(De,"LI",{});var qOe=s(ww);twe=n(qOe,"STRONG",{});var dOt=s(twe);LHr=r(dOt,"bert"),dOt.forEach(t),yHr=r(qOe," \u2014 "),moe=n(qOe,"A",{href:!0});var cOt=s(moe);xHr=r(cOt,"FlaxBertForSequenceClassification"),cOt.forEach(t),$Hr=r(qOe," (BERT model)"),qOe.forEach(t),kHr=i(De),Aw=n(De,"LI",{});var jOe=s(Aw);awe=n(jOe,"STRONG",{});var fOt=s(awe);SHr=r(fOt,"big_bird"),fOt.forEach(t),RHr=r(jOe," \u2014 "),goe=n(jOe,"A",{href:!0});var mOt=s(goe);PHr=r(mOt,"FlaxBigBirdForSequenceClassification"),mOt.forEach(t),BHr=r(jOe," (BigBird model)"),jOe.forEach(t),NHr=i(De),Lw=n(De,"LI",{});var DOe=s(Lw);nwe=n(DOe,"STRONG",{});var gOt=s(nwe);IHr=r(gOt,"distilbert"),gOt.forEach(t),qHr=r(DOe," \u2014 "),hoe=n(DOe,"A",{href:!0});var hOt=s(hoe);jHr=r(hOt,"FlaxDistilBertForSequenceClassification"),hOt.forEach(t),DHr=r(DOe," (DistilBERT model)"),DOe.forEach(t),GHr=i(De),yw=n(De,"LI",{});var GOe=s(yw);swe=n(GOe,"STRONG",{});var pOt=s(swe);OHr=r(pOt,"electra"),pOt.forEach(t),VHr=r(GOe," \u2014 "),poe=n(GOe,"A",{href:!0});var _Ot=s(poe);XHr=r(_Ot,"FlaxElectraForSequenceClassification"),_Ot.forEach(t),zHr=r(GOe," (ELECTRA model)"),GOe.forEach(t),QHr=i(De),xw=n(De,"LI",{});var OOe=s(xw);lwe=n(OOe,"STRONG",{});var uOt=s(lwe);WHr=r(uOt,"mbart"),uOt.forEach(t),HHr=r(OOe," \u2014 "),_oe=n(OOe,"A",{href:!0});var bOt=s(_oe);UHr=r(bOt,"FlaxMBartForSequenceClassification"),bOt.forEach(t),JHr=r(OOe," (mBART model)"),OOe.forEach(t),YHr=i(De),$w=n(De,"LI",{});var VOe=s($w);iwe=n(VOe,"STRONG",{});var vOt=s(iwe);KHr=r(vOt,"roberta"),vOt.forEach(t),ZHr=r(VOe," \u2014 "),uoe=n(VOe,"A",{href:!0});var FOt=s(uoe);eUr=r(FOt,"FlaxRobertaForSequenceClassification"),FOt.forEach(t),oUr=r(VOe," (RoBERTa model)"),VOe.forEach(t),rUr=i(De),kw=n(De,"LI",{});var XOe=s(kw);dwe=n(XOe,"STRONG",{});var TOt=s(dwe);tUr=r(TOt,"roformer"),TOt.forEach(t),aUr=r(XOe," \u2014 "),boe=n(XOe,"A",{href:!0});var MOt=s(boe);nUr=r(MOt,"FlaxRoFormerForSequenceClassification"),MOt.forEach(t),sUr=r(XOe," (RoFormer model)"),XOe.forEach(t),lUr=i(De),Sw=n(De,"LI",{});var zOe=s(Sw);cwe=n(zOe,"STRONG",{});var EOt=s(cwe);iUr=r(EOt,"xlm-roberta"),EOt.forEach(t),dUr=r(zOe," \u2014 "),voe=n(zOe,"A",{href:!0});var COt=s(voe);cUr=r(COt,"FlaxXLMRobertaForSequenceClassification"),COt.forEach(t),fUr=r(zOe," (XLM-RoBERTa model)"),zOe.forEach(t),De.forEach(t),mUr=i(mi),T(Rw.$$.fragment,mi),mi.forEach(t),fi.forEach(t),pze=i(f),ff=n(f,"H2",{class:!0});var CWe=s(ff);Pw=n(CWe,"A",{id:!0,class:!0,href:!0});var wOt=s(Pw);fwe=n(wOt,"SPAN",{});var AOt=s(fwe);T($$.$$.fragment,AOt),AOt.forEach(t),wOt.forEach(t),gUr=i(CWe),mwe=n(CWe,"SPAN",{});var LOt=s(mwe);hUr=r(LOt,"FlaxAutoModelForQuestionAnswering"),LOt.forEach(t),CWe.forEach(t),_ze=i(f),Tr=n(f,"DIV",{class:!0});var gi=s(Tr);T(k$.$$.fragment,gi),pUr=i(gi),mf=n(gi,"P",{});var Jte=s(mf);_Ur=r(Jte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Foe=n(Jte,"A",{href:!0});var yOt=s(Foe);uUr=r(yOt,"from_pretrained()"),yOt.forEach(t),bUr=r(Jte," class method or the "),Toe=n(Jte,"A",{href:!0});var xOt=s(Toe);vUr=r(xOt,"from_config()"),xOt.forEach(t),FUr=r(Jte,` class
method.`),Jte.forEach(t),TUr=i(gi),S$=n(gi,"P",{});var wWe=s(S$);MUr=r(wWe,"This class cannot be instantiated directly using "),gwe=n(wWe,"CODE",{});var $Ot=s(gwe);EUr=r($Ot,"__init__()"),$Ot.forEach(t),CUr=r(wWe," (throws an error)."),wWe.forEach(t),wUr=i(gi),Yt=n(gi,"DIV",{class:!0});var BL=s(Yt);T(R$.$$.fragment,BL),AUr=i(BL),hwe=n(BL,"P",{});var kOt=s(hwe);LUr=r(kOt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),kOt.forEach(t),yUr=i(BL),gf=n(BL,"P",{});var Yte=s(gf);xUr=r(Yte,`Note:
Loading a model from its configuration file does `),pwe=n(Yte,"STRONG",{});var SOt=s(pwe);$Ur=r(SOt,"not"),SOt.forEach(t),kUr=r(Yte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Moe=n(Yte,"A",{href:!0});var ROt=s(Moe);SUr=r(ROt,"from_pretrained()"),ROt.forEach(t),RUr=r(Yte," to load the model weights."),Yte.forEach(t),PUr=i(BL),T(Bw.$$.fragment,BL),BL.forEach(t),BUr=i(gi),Ur=n(gi,"DIV",{class:!0});var hi=s(Ur);T(P$.$$.fragment,hi),NUr=i(hi),_we=n(hi,"P",{});var POt=s(_we);IUr=r(POt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),POt.forEach(t),qUr=i(hi),Ln=n(hi,"P",{});var NL=s(Ln);jUr=r(NL,"The model class to instantiate is selected based on the "),uwe=n(NL,"CODE",{});var BOt=s(uwe);DUr=r(BOt,"model_type"),BOt.forEach(t),GUr=r(NL,` property of the config object (either
passed as an argument or loaded from `),bwe=n(NL,"CODE",{});var NOt=s(bwe);OUr=r(NOt,"pretrained_model_name_or_path"),NOt.forEach(t),VUr=r(NL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vwe=n(NL,"CODE",{});var IOt=s(vwe);XUr=r(IOt,"pretrained_model_name_or_path"),IOt.forEach(t),zUr=r(NL,":"),NL.forEach(t),QUr=i(hi),Re=n(hi,"UL",{});var Ge=s(Re);Nw=n(Ge,"LI",{});var QOe=s(Nw);Fwe=n(QOe,"STRONG",{});var qOt=s(Fwe);WUr=r(qOt,"albert"),qOt.forEach(t),HUr=r(QOe," \u2014 "),Eoe=n(QOe,"A",{href:!0});var jOt=s(Eoe);UUr=r(jOt,"FlaxAlbertForQuestionAnswering"),jOt.forEach(t),JUr=r(QOe," (ALBERT model)"),QOe.forEach(t),YUr=i(Ge),Iw=n(Ge,"LI",{});var WOe=s(Iw);Twe=n(WOe,"STRONG",{});var DOt=s(Twe);KUr=r(DOt,"bart"),DOt.forEach(t),ZUr=r(WOe," \u2014 "),Coe=n(WOe,"A",{href:!0});var GOt=s(Coe);eJr=r(GOt,"FlaxBartForQuestionAnswering"),GOt.forEach(t),oJr=r(WOe," (BART model)"),WOe.forEach(t),rJr=i(Ge),qw=n(Ge,"LI",{});var HOe=s(qw);Mwe=n(HOe,"STRONG",{});var OOt=s(Mwe);tJr=r(OOt,"bert"),OOt.forEach(t),aJr=r(HOe," \u2014 "),woe=n(HOe,"A",{href:!0});var VOt=s(woe);nJr=r(VOt,"FlaxBertForQuestionAnswering"),VOt.forEach(t),sJr=r(HOe," (BERT model)"),HOe.forEach(t),lJr=i(Ge),jw=n(Ge,"LI",{});var UOe=s(jw);Ewe=n(UOe,"STRONG",{});var XOt=s(Ewe);iJr=r(XOt,"big_bird"),XOt.forEach(t),dJr=r(UOe," \u2014 "),Aoe=n(UOe,"A",{href:!0});var zOt=s(Aoe);cJr=r(zOt,"FlaxBigBirdForQuestionAnswering"),zOt.forEach(t),fJr=r(UOe," (BigBird model)"),UOe.forEach(t),mJr=i(Ge),Dw=n(Ge,"LI",{});var JOe=s(Dw);Cwe=n(JOe,"STRONG",{});var QOt=s(Cwe);gJr=r(QOt,"distilbert"),QOt.forEach(t),hJr=r(JOe," \u2014 "),Loe=n(JOe,"A",{href:!0});var WOt=s(Loe);pJr=r(WOt,"FlaxDistilBertForQuestionAnswering"),WOt.forEach(t),_Jr=r(JOe," (DistilBERT model)"),JOe.forEach(t),uJr=i(Ge),Gw=n(Ge,"LI",{});var YOe=s(Gw);wwe=n(YOe,"STRONG",{});var HOt=s(wwe);bJr=r(HOt,"electra"),HOt.forEach(t),vJr=r(YOe," \u2014 "),yoe=n(YOe,"A",{href:!0});var UOt=s(yoe);FJr=r(UOt,"FlaxElectraForQuestionAnswering"),UOt.forEach(t),TJr=r(YOe," (ELECTRA model)"),YOe.forEach(t),MJr=i(Ge),Ow=n(Ge,"LI",{});var KOe=s(Ow);Awe=n(KOe,"STRONG",{});var JOt=s(Awe);EJr=r(JOt,"mbart"),JOt.forEach(t),CJr=r(KOe," \u2014 "),xoe=n(KOe,"A",{href:!0});var YOt=s(xoe);wJr=r(YOt,"FlaxMBartForQuestionAnswering"),YOt.forEach(t),AJr=r(KOe," (mBART model)"),KOe.forEach(t),LJr=i(Ge),Vw=n(Ge,"LI",{});var ZOe=s(Vw);Lwe=n(ZOe,"STRONG",{});var KOt=s(Lwe);yJr=r(KOt,"roberta"),KOt.forEach(t),xJr=r(ZOe," \u2014 "),$oe=n(ZOe,"A",{href:!0});var ZOt=s($oe);$Jr=r(ZOt,"FlaxRobertaForQuestionAnswering"),ZOt.forEach(t),kJr=r(ZOe," (RoBERTa model)"),ZOe.forEach(t),SJr=i(Ge),Xw=n(Ge,"LI",{});var eVe=s(Xw);ywe=n(eVe,"STRONG",{});var eVt=s(ywe);RJr=r(eVt,"roformer"),eVt.forEach(t),PJr=r(eVe," \u2014 "),koe=n(eVe,"A",{href:!0});var oVt=s(koe);BJr=r(oVt,"FlaxRoFormerForQuestionAnswering"),oVt.forEach(t),NJr=r(eVe," (RoFormer model)"),eVe.forEach(t),IJr=i(Ge),zw=n(Ge,"LI",{});var oVe=s(zw);xwe=n(oVe,"STRONG",{});var rVt=s(xwe);qJr=r(rVt,"xlm-roberta"),rVt.forEach(t),jJr=r(oVe," \u2014 "),Soe=n(oVe,"A",{href:!0});var tVt=s(Soe);DJr=r(tVt,"FlaxXLMRobertaForQuestionAnswering"),tVt.forEach(t),GJr=r(oVe," (XLM-RoBERTa model)"),oVe.forEach(t),Ge.forEach(t),OJr=i(hi),T(Qw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),uze=i(f),hf=n(f,"H2",{class:!0});var AWe=s(hf);Ww=n(AWe,"A",{id:!0,class:!0,href:!0});var aVt=s(Ww);$we=n(aVt,"SPAN",{});var nVt=s($we);T(B$.$$.fragment,nVt),nVt.forEach(t),aVt.forEach(t),VJr=i(AWe),kwe=n(AWe,"SPAN",{});var sVt=s(kwe);XJr=r(sVt,"FlaxAutoModelForTokenClassification"),sVt.forEach(t),AWe.forEach(t),bze=i(f),Mr=n(f,"DIV",{class:!0});var pi=s(Mr);T(N$.$$.fragment,pi),zJr=i(pi),pf=n(pi,"P",{});var Kte=s(pf);QJr=r(Kte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Roe=n(Kte,"A",{href:!0});var lVt=s(Roe);WJr=r(lVt,"from_pretrained()"),lVt.forEach(t),HJr=r(Kte," class method or the "),Poe=n(Kte,"A",{href:!0});var iVt=s(Poe);UJr=r(iVt,"from_config()"),iVt.forEach(t),JJr=r(Kte,` class
method.`),Kte.forEach(t),YJr=i(pi),I$=n(pi,"P",{});var LWe=s(I$);KJr=r(LWe,"This class cannot be instantiated directly using "),Swe=n(LWe,"CODE",{});var dVt=s(Swe);ZJr=r(dVt,"__init__()"),dVt.forEach(t),eYr=r(LWe," (throws an error)."),LWe.forEach(t),oYr=i(pi),Kt=n(pi,"DIV",{class:!0});var IL=s(Kt);T(q$.$$.fragment,IL),rYr=i(IL),Rwe=n(IL,"P",{});var cVt=s(Rwe);tYr=r(cVt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),cVt.forEach(t),aYr=i(IL),_f=n(IL,"P",{});var Zte=s(_f);nYr=r(Zte,`Note:
Loading a model from its configuration file does `),Pwe=n(Zte,"STRONG",{});var fVt=s(Pwe);sYr=r(fVt,"not"),fVt.forEach(t),lYr=r(Zte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Boe=n(Zte,"A",{href:!0});var mVt=s(Boe);iYr=r(mVt,"from_pretrained()"),mVt.forEach(t),dYr=r(Zte," to load the model weights."),Zte.forEach(t),cYr=i(IL),T(Hw.$$.fragment,IL),IL.forEach(t),fYr=i(pi),Jr=n(pi,"DIV",{class:!0});var _i=s(Jr);T(j$.$$.fragment,_i),mYr=i(_i),Bwe=n(_i,"P",{});var gVt=s(Bwe);gYr=r(gVt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),gVt.forEach(t),hYr=i(_i),yn=n(_i,"P",{});var qL=s(yn);pYr=r(qL,"The model class to instantiate is selected based on the "),Nwe=n(qL,"CODE",{});var hVt=s(Nwe);_Yr=r(hVt,"model_type"),hVt.forEach(t),uYr=r(qL,` property of the config object (either
passed as an argument or loaded from `),Iwe=n(qL,"CODE",{});var pVt=s(Iwe);bYr=r(pVt,"pretrained_model_name_or_path"),pVt.forEach(t),vYr=r(qL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qwe=n(qL,"CODE",{});var _Vt=s(qwe);FYr=r(_Vt,"pretrained_model_name_or_path"),_Vt.forEach(t),TYr=r(qL,":"),qL.forEach(t),MYr=i(_i),Ve=n(_i,"UL",{});var To=s(Ve);Uw=n(To,"LI",{});var rVe=s(Uw);jwe=n(rVe,"STRONG",{});var uVt=s(jwe);EYr=r(uVt,"albert"),uVt.forEach(t),CYr=r(rVe," \u2014 "),Noe=n(rVe,"A",{href:!0});var bVt=s(Noe);wYr=r(bVt,"FlaxAlbertForTokenClassification"),bVt.forEach(t),AYr=r(rVe," (ALBERT model)"),rVe.forEach(t),LYr=i(To),Jw=n(To,"LI",{});var tVe=s(Jw);Dwe=n(tVe,"STRONG",{});var vVt=s(Dwe);yYr=r(vVt,"bert"),vVt.forEach(t),xYr=r(tVe," \u2014 "),Ioe=n(tVe,"A",{href:!0});var FVt=s(Ioe);$Yr=r(FVt,"FlaxBertForTokenClassification"),FVt.forEach(t),kYr=r(tVe," (BERT model)"),tVe.forEach(t),SYr=i(To),Yw=n(To,"LI",{});var aVe=s(Yw);Gwe=n(aVe,"STRONG",{});var TVt=s(Gwe);RYr=r(TVt,"big_bird"),TVt.forEach(t),PYr=r(aVe," \u2014 "),qoe=n(aVe,"A",{href:!0});var MVt=s(qoe);BYr=r(MVt,"FlaxBigBirdForTokenClassification"),MVt.forEach(t),NYr=r(aVe," (BigBird model)"),aVe.forEach(t),IYr=i(To),Kw=n(To,"LI",{});var nVe=s(Kw);Owe=n(nVe,"STRONG",{});var EVt=s(Owe);qYr=r(EVt,"distilbert"),EVt.forEach(t),jYr=r(nVe," \u2014 "),joe=n(nVe,"A",{href:!0});var CVt=s(joe);DYr=r(CVt,"FlaxDistilBertForTokenClassification"),CVt.forEach(t),GYr=r(nVe," (DistilBERT model)"),nVe.forEach(t),OYr=i(To),Zw=n(To,"LI",{});var sVe=s(Zw);Vwe=n(sVe,"STRONG",{});var wVt=s(Vwe);VYr=r(wVt,"electra"),wVt.forEach(t),XYr=r(sVe," \u2014 "),Doe=n(sVe,"A",{href:!0});var AVt=s(Doe);zYr=r(AVt,"FlaxElectraForTokenClassification"),AVt.forEach(t),QYr=r(sVe," (ELECTRA model)"),sVe.forEach(t),WYr=i(To),eA=n(To,"LI",{});var lVe=s(eA);Xwe=n(lVe,"STRONG",{});var LVt=s(Xwe);HYr=r(LVt,"roberta"),LVt.forEach(t),UYr=r(lVe," \u2014 "),Goe=n(lVe,"A",{href:!0});var yVt=s(Goe);JYr=r(yVt,"FlaxRobertaForTokenClassification"),yVt.forEach(t),YYr=r(lVe," (RoBERTa model)"),lVe.forEach(t),KYr=i(To),oA=n(To,"LI",{});var iVe=s(oA);zwe=n(iVe,"STRONG",{});var xVt=s(zwe);ZYr=r(xVt,"roformer"),xVt.forEach(t),eKr=r(iVe," \u2014 "),Ooe=n(iVe,"A",{href:!0});var $Vt=s(Ooe);oKr=r($Vt,"FlaxRoFormerForTokenClassification"),$Vt.forEach(t),rKr=r(iVe," (RoFormer model)"),iVe.forEach(t),tKr=i(To),rA=n(To,"LI",{});var dVe=s(rA);Qwe=n(dVe,"STRONG",{});var kVt=s(Qwe);aKr=r(kVt,"xlm-roberta"),kVt.forEach(t),nKr=r(dVe," \u2014 "),Voe=n(dVe,"A",{href:!0});var SVt=s(Voe);sKr=r(SVt,"FlaxXLMRobertaForTokenClassification"),SVt.forEach(t),lKr=r(dVe," (XLM-RoBERTa model)"),dVe.forEach(t),To.forEach(t),iKr=i(_i),T(tA.$$.fragment,_i),_i.forEach(t),pi.forEach(t),vze=i(f),uf=n(f,"H2",{class:!0});var yWe=s(uf);aA=n(yWe,"A",{id:!0,class:!0,href:!0});var RVt=s(aA);Wwe=n(RVt,"SPAN",{});var PVt=s(Wwe);T(D$.$$.fragment,PVt),PVt.forEach(t),RVt.forEach(t),dKr=i(yWe),Hwe=n(yWe,"SPAN",{});var BVt=s(Hwe);cKr=r(BVt,"FlaxAutoModelForMultipleChoice"),BVt.forEach(t),yWe.forEach(t),Fze=i(f),Er=n(f,"DIV",{class:!0});var ui=s(Er);T(G$.$$.fragment,ui),fKr=i(ui),bf=n(ui,"P",{});var eae=s(bf);mKr=r(eae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Xoe=n(eae,"A",{href:!0});var NVt=s(Xoe);gKr=r(NVt,"from_pretrained()"),NVt.forEach(t),hKr=r(eae," class method or the "),zoe=n(eae,"A",{href:!0});var IVt=s(zoe);pKr=r(IVt,"from_config()"),IVt.forEach(t),_Kr=r(eae,` class
method.`),eae.forEach(t),uKr=i(ui),O$=n(ui,"P",{});var xWe=s(O$);bKr=r(xWe,"This class cannot be instantiated directly using "),Uwe=n(xWe,"CODE",{});var qVt=s(Uwe);vKr=r(qVt,"__init__()"),qVt.forEach(t),FKr=r(xWe," (throws an error)."),xWe.forEach(t),TKr=i(ui),Zt=n(ui,"DIV",{class:!0});var jL=s(Zt);T(V$.$$.fragment,jL),MKr=i(jL),Jwe=n(jL,"P",{});var jVt=s(Jwe);EKr=r(jVt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),jVt.forEach(t),CKr=i(jL),vf=n(jL,"P",{});var oae=s(vf);wKr=r(oae,`Note:
Loading a model from its configuration file does `),Ywe=n(oae,"STRONG",{});var DVt=s(Ywe);AKr=r(DVt,"not"),DVt.forEach(t),LKr=r(oae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qoe=n(oae,"A",{href:!0});var GVt=s(Qoe);yKr=r(GVt,"from_pretrained()"),GVt.forEach(t),xKr=r(oae," to load the model weights."),oae.forEach(t),$Kr=i(jL),T(nA.$$.fragment,jL),jL.forEach(t),kKr=i(ui),Yr=n(ui,"DIV",{class:!0});var bi=s(Yr);T(X$.$$.fragment,bi),SKr=i(bi),Kwe=n(bi,"P",{});var OVt=s(Kwe);RKr=r(OVt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),OVt.forEach(t),PKr=i(bi),xn=n(bi,"P",{});var DL=s(xn);BKr=r(DL,"The model class to instantiate is selected based on the "),Zwe=n(DL,"CODE",{});var VVt=s(Zwe);NKr=r(VVt,"model_type"),VVt.forEach(t),IKr=r(DL,` property of the config object (either
passed as an argument or loaded from `),eAe=n(DL,"CODE",{});var XVt=s(eAe);qKr=r(XVt,"pretrained_model_name_or_path"),XVt.forEach(t),jKr=r(DL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oAe=n(DL,"CODE",{});var zVt=s(oAe);DKr=r(zVt,"pretrained_model_name_or_path"),zVt.forEach(t),GKr=r(DL,":"),DL.forEach(t),OKr=i(bi),Xe=n(bi,"UL",{});var Mo=s(Xe);sA=n(Mo,"LI",{});var cVe=s(sA);rAe=n(cVe,"STRONG",{});var QVt=s(rAe);VKr=r(QVt,"albert"),QVt.forEach(t),XKr=r(cVe," \u2014 "),Woe=n(cVe,"A",{href:!0});var WVt=s(Woe);zKr=r(WVt,"FlaxAlbertForMultipleChoice"),WVt.forEach(t),QKr=r(cVe," (ALBERT model)"),cVe.forEach(t),WKr=i(Mo),lA=n(Mo,"LI",{});var fVe=s(lA);tAe=n(fVe,"STRONG",{});var HVt=s(tAe);HKr=r(HVt,"bert"),HVt.forEach(t),UKr=r(fVe," \u2014 "),Hoe=n(fVe,"A",{href:!0});var UVt=s(Hoe);JKr=r(UVt,"FlaxBertForMultipleChoice"),UVt.forEach(t),YKr=r(fVe," (BERT model)"),fVe.forEach(t),KKr=i(Mo),iA=n(Mo,"LI",{});var mVe=s(iA);aAe=n(mVe,"STRONG",{});var JVt=s(aAe);ZKr=r(JVt,"big_bird"),JVt.forEach(t),eZr=r(mVe," \u2014 "),Uoe=n(mVe,"A",{href:!0});var YVt=s(Uoe);oZr=r(YVt,"FlaxBigBirdForMultipleChoice"),YVt.forEach(t),rZr=r(mVe," (BigBird model)"),mVe.forEach(t),tZr=i(Mo),dA=n(Mo,"LI",{});var gVe=s(dA);nAe=n(gVe,"STRONG",{});var KVt=s(nAe);aZr=r(KVt,"distilbert"),KVt.forEach(t),nZr=r(gVe," \u2014 "),Joe=n(gVe,"A",{href:!0});var ZVt=s(Joe);sZr=r(ZVt,"FlaxDistilBertForMultipleChoice"),ZVt.forEach(t),lZr=r(gVe," (DistilBERT model)"),gVe.forEach(t),iZr=i(Mo),cA=n(Mo,"LI",{});var hVe=s(cA);sAe=n(hVe,"STRONG",{});var eXt=s(sAe);dZr=r(eXt,"electra"),eXt.forEach(t),cZr=r(hVe," \u2014 "),Yoe=n(hVe,"A",{href:!0});var oXt=s(Yoe);fZr=r(oXt,"FlaxElectraForMultipleChoice"),oXt.forEach(t),mZr=r(hVe," (ELECTRA model)"),hVe.forEach(t),gZr=i(Mo),fA=n(Mo,"LI",{});var pVe=s(fA);lAe=n(pVe,"STRONG",{});var rXt=s(lAe);hZr=r(rXt,"roberta"),rXt.forEach(t),pZr=r(pVe," \u2014 "),Koe=n(pVe,"A",{href:!0});var tXt=s(Koe);_Zr=r(tXt,"FlaxRobertaForMultipleChoice"),tXt.forEach(t),uZr=r(pVe," (RoBERTa model)"),pVe.forEach(t),bZr=i(Mo),mA=n(Mo,"LI",{});var _Ve=s(mA);iAe=n(_Ve,"STRONG",{});var aXt=s(iAe);vZr=r(aXt,"roformer"),aXt.forEach(t),FZr=r(_Ve," \u2014 "),Zoe=n(_Ve,"A",{href:!0});var nXt=s(Zoe);TZr=r(nXt,"FlaxRoFormerForMultipleChoice"),nXt.forEach(t),MZr=r(_Ve," (RoFormer model)"),_Ve.forEach(t),EZr=i(Mo),gA=n(Mo,"LI",{});var uVe=s(gA);dAe=n(uVe,"STRONG",{});var sXt=s(dAe);CZr=r(sXt,"xlm-roberta"),sXt.forEach(t),wZr=r(uVe," \u2014 "),ere=n(uVe,"A",{href:!0});var lXt=s(ere);AZr=r(lXt,"FlaxXLMRobertaForMultipleChoice"),lXt.forEach(t),LZr=r(uVe," (XLM-RoBERTa model)"),uVe.forEach(t),Mo.forEach(t),yZr=i(bi),T(hA.$$.fragment,bi),bi.forEach(t),ui.forEach(t),Tze=i(f),Ff=n(f,"H2",{class:!0});var $We=s(Ff);pA=n($We,"A",{id:!0,class:!0,href:!0});var iXt=s(pA);cAe=n(iXt,"SPAN",{});var dXt=s(cAe);T(z$.$$.fragment,dXt),dXt.forEach(t),iXt.forEach(t),xZr=i($We),fAe=n($We,"SPAN",{});var cXt=s(fAe);$Zr=r(cXt,"FlaxAutoModelForNextSentencePrediction"),cXt.forEach(t),$We.forEach(t),Mze=i(f),Cr=n(f,"DIV",{class:!0});var vi=s(Cr);T(Q$.$$.fragment,vi),kZr=i(vi),Tf=n(vi,"P",{});var rae=s(Tf);SZr=r(rae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ore=n(rae,"A",{href:!0});var fXt=s(ore);RZr=r(fXt,"from_pretrained()"),fXt.forEach(t),PZr=r(rae," class method or the "),rre=n(rae,"A",{href:!0});var mXt=s(rre);BZr=r(mXt,"from_config()"),mXt.forEach(t),NZr=r(rae,` class
method.`),rae.forEach(t),IZr=i(vi),W$=n(vi,"P",{});var kWe=s(W$);qZr=r(kWe,"This class cannot be instantiated directly using "),mAe=n(kWe,"CODE",{});var gXt=s(mAe);jZr=r(gXt,"__init__()"),gXt.forEach(t),DZr=r(kWe," (throws an error)."),kWe.forEach(t),GZr=i(vi),ea=n(vi,"DIV",{class:!0});var GL=s(ea);T(H$.$$.fragment,GL),OZr=i(GL),gAe=n(GL,"P",{});var hXt=s(gAe);VZr=r(hXt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),hXt.forEach(t),XZr=i(GL),Mf=n(GL,"P",{});var tae=s(Mf);zZr=r(tae,`Note:
Loading a model from its configuration file does `),hAe=n(tae,"STRONG",{});var pXt=s(hAe);QZr=r(pXt,"not"),pXt.forEach(t),WZr=r(tae,` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=n(tae,"A",{href:!0});var _Xt=s(tre);HZr=r(_Xt,"from_pretrained()"),_Xt.forEach(t),UZr=r(tae," to load the model weights."),tae.forEach(t),JZr=i(GL),T(_A.$$.fragment,GL),GL.forEach(t),YZr=i(vi),Kr=n(vi,"DIV",{class:!0});var Fi=s(Kr);T(U$.$$.fragment,Fi),KZr=i(Fi),pAe=n(Fi,"P",{});var uXt=s(pAe);ZZr=r(uXt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),uXt.forEach(t),eet=i(Fi),$n=n(Fi,"P",{});var OL=s($n);oet=r(OL,"The model class to instantiate is selected based on the "),_Ae=n(OL,"CODE",{});var bXt=s(_Ae);ret=r(bXt,"model_type"),bXt.forEach(t),tet=r(OL,` property of the config object (either
passed as an argument or loaded from `),uAe=n(OL,"CODE",{});var vXt=s(uAe);aet=r(vXt,"pretrained_model_name_or_path"),vXt.forEach(t),net=r(OL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bAe=n(OL,"CODE",{});var FXt=s(bAe);set=r(FXt,"pretrained_model_name_or_path"),FXt.forEach(t),iet=r(OL,":"),OL.forEach(t),det=i(Fi),vAe=n(Fi,"UL",{});var TXt=s(vAe);uA=n(TXt,"LI",{});var bVe=s(uA);FAe=n(bVe,"STRONG",{});var MXt=s(FAe);cet=r(MXt,"bert"),MXt.forEach(t),fet=r(bVe," \u2014 "),are=n(bVe,"A",{href:!0});var EXt=s(are);met=r(EXt,"FlaxBertForNextSentencePrediction"),EXt.forEach(t),get=r(bVe," (BERT model)"),bVe.forEach(t),TXt.forEach(t),het=i(Fi),T(bA.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),Eze=i(f),Ef=n(f,"H2",{class:!0});var SWe=s(Ef);vA=n(SWe,"A",{id:!0,class:!0,href:!0});var CXt=s(vA);TAe=n(CXt,"SPAN",{});var wXt=s(TAe);T(J$.$$.fragment,wXt),wXt.forEach(t),CXt.forEach(t),pet=i(SWe),MAe=n(SWe,"SPAN",{});var AXt=s(MAe);_et=r(AXt,"FlaxAutoModelForImageClassification"),AXt.forEach(t),SWe.forEach(t),Cze=i(f),wr=n(f,"DIV",{class:!0});var Ti=s(wr);T(Y$.$$.fragment,Ti),uet=i(Ti),Cf=n(Ti,"P",{});var aae=s(Cf);bet=r(aae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),nre=n(aae,"A",{href:!0});var LXt=s(nre);vet=r(LXt,"from_pretrained()"),LXt.forEach(t),Fet=r(aae," class method or the "),sre=n(aae,"A",{href:!0});var yXt=s(sre);Tet=r(yXt,"from_config()"),yXt.forEach(t),Met=r(aae,` class
method.`),aae.forEach(t),Eet=i(Ti),K$=n(Ti,"P",{});var RWe=s(K$);Cet=r(RWe,"This class cannot be instantiated directly using "),EAe=n(RWe,"CODE",{});var xXt=s(EAe);wet=r(xXt,"__init__()"),xXt.forEach(t),Aet=r(RWe," (throws an error)."),RWe.forEach(t),Let=i(Ti),oa=n(Ti,"DIV",{class:!0});var VL=s(oa);T(Z$.$$.fragment,VL),yet=i(VL),CAe=n(VL,"P",{});var $Xt=s(CAe);xet=r($Xt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$Xt.forEach(t),$et=i(VL),wf=n(VL,"P",{});var nae=s(wf);ket=r(nae,`Note:
Loading a model from its configuration file does `),wAe=n(nae,"STRONG",{});var kXt=s(wAe);Set=r(kXt,"not"),kXt.forEach(t),Ret=r(nae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=n(nae,"A",{href:!0});var SXt=s(lre);Pet=r(SXt,"from_pretrained()"),SXt.forEach(t),Bet=r(nae," to load the model weights."),nae.forEach(t),Net=i(VL),T(FA.$$.fragment,VL),VL.forEach(t),Iet=i(Ti),Zr=n(Ti,"DIV",{class:!0});var Mi=s(Zr);T(ek.$$.fragment,Mi),qet=i(Mi),AAe=n(Mi,"P",{});var RXt=s(AAe);jet=r(RXt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),RXt.forEach(t),Det=i(Mi),kn=n(Mi,"P",{});var XL=s(kn);Get=r(XL,"The model class to instantiate is selected based on the "),LAe=n(XL,"CODE",{});var PXt=s(LAe);Oet=r(PXt,"model_type"),PXt.forEach(t),Vet=r(XL,` property of the config object (either
passed as an argument or loaded from `),yAe=n(XL,"CODE",{});var BXt=s(yAe);Xet=r(BXt,"pretrained_model_name_or_path"),BXt.forEach(t),zet=r(XL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xAe=n(XL,"CODE",{});var NXt=s(xAe);Qet=r(NXt,"pretrained_model_name_or_path"),NXt.forEach(t),Wet=r(XL,":"),XL.forEach(t),Het=i(Mi),ok=n(Mi,"UL",{});var PWe=s(ok);TA=n(PWe,"LI",{});var vVe=s(TA);$Ae=n(vVe,"STRONG",{});var IXt=s($Ae);Uet=r(IXt,"beit"),IXt.forEach(t),Jet=r(vVe," \u2014 "),ire=n(vVe,"A",{href:!0});var qXt=s(ire);Yet=r(qXt,"FlaxBeitForImageClassification"),qXt.forEach(t),Ket=r(vVe," (BEiT model)"),vVe.forEach(t),Zet=i(PWe),MA=n(PWe,"LI",{});var FVe=s(MA);kAe=n(FVe,"STRONG",{});var jXt=s(kAe);eot=r(jXt,"vit"),jXt.forEach(t),oot=r(FVe," \u2014 "),dre=n(FVe,"A",{href:!0});var DXt=s(dre);rot=r(DXt,"FlaxViTForImageClassification"),DXt.forEach(t),tot=r(FVe," (ViT model)"),FVe.forEach(t),PWe.forEach(t),aot=i(Mi),T(EA.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),wze=i(f),Af=n(f,"H2",{class:!0});var BWe=s(Af);CA=n(BWe,"A",{id:!0,class:!0,href:!0});var GXt=s(CA);SAe=n(GXt,"SPAN",{});var OXt=s(SAe);T(rk.$$.fragment,OXt),OXt.forEach(t),GXt.forEach(t),not=i(BWe),RAe=n(BWe,"SPAN",{});var VXt=s(RAe);sot=r(VXt,"FlaxAutoModelForVision2Seq"),VXt.forEach(t),BWe.forEach(t),Aze=i(f),Ar=n(f,"DIV",{class:!0});var Ei=s(Ar);T(tk.$$.fragment,Ei),lot=i(Ei),Lf=n(Ei,"P",{});var sae=s(Lf);iot=r(sae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cre=n(sae,"A",{href:!0});var XXt=s(cre);dot=r(XXt,"from_pretrained()"),XXt.forEach(t),cot=r(sae," class method or the "),fre=n(sae,"A",{href:!0});var zXt=s(fre);fot=r(zXt,"from_config()"),zXt.forEach(t),mot=r(sae,` class
method.`),sae.forEach(t),got=i(Ei),ak=n(Ei,"P",{});var NWe=s(ak);hot=r(NWe,"This class cannot be instantiated directly using "),PAe=n(NWe,"CODE",{});var QXt=s(PAe);pot=r(QXt,"__init__()"),QXt.forEach(t),_ot=r(NWe," (throws an error)."),NWe.forEach(t),uot=i(Ei),ra=n(Ei,"DIV",{class:!0});var zL=s(ra);T(nk.$$.fragment,zL),bot=i(zL),BAe=n(zL,"P",{});var WXt=s(BAe);vot=r(WXt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WXt.forEach(t),Fot=i(zL),yf=n(zL,"P",{});var lae=s(yf);Tot=r(lae,`Note:
Loading a model from its configuration file does `),NAe=n(lae,"STRONG",{});var HXt=s(NAe);Mot=r(HXt,"not"),HXt.forEach(t),Eot=r(lae,` load the model weights. It only affects the
model\u2019s configuration. Use `),mre=n(lae,"A",{href:!0});var UXt=s(mre);Cot=r(UXt,"from_pretrained()"),UXt.forEach(t),wot=r(lae," to load the model weights."),lae.forEach(t),Aot=i(zL),T(wA.$$.fragment,zL),zL.forEach(t),Lot=i(Ei),et=n(Ei,"DIV",{class:!0});var Ci=s(et);T(sk.$$.fragment,Ci),yot=i(Ci),IAe=n(Ci,"P",{});var JXt=s(IAe);xot=r(JXt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),JXt.forEach(t),$ot=i(Ci),Sn=n(Ci,"P",{});var QL=s(Sn);kot=r(QL,"The model class to instantiate is selected based on the "),qAe=n(QL,"CODE",{});var YXt=s(qAe);Sot=r(YXt,"model_type"),YXt.forEach(t),Rot=r(QL,` property of the config object (either
passed as an argument or loaded from `),jAe=n(QL,"CODE",{});var KXt=s(jAe);Pot=r(KXt,"pretrained_model_name_or_path"),KXt.forEach(t),Bot=r(QL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DAe=n(QL,"CODE",{});var ZXt=s(DAe);Not=r(ZXt,"pretrained_model_name_or_path"),ZXt.forEach(t),Iot=r(QL,":"),QL.forEach(t),qot=i(Ci),GAe=n(Ci,"UL",{});var ezt=s(GAe);AA=n(ezt,"LI",{});var TVe=s(AA);OAe=n(TVe,"STRONG",{});var ozt=s(OAe);jot=r(ozt,"vision-encoder-decoder"),ozt.forEach(t),Dot=r(TVe," \u2014 "),gre=n(TVe,"A",{href:!0});var rzt=s(gre);Got=r(rzt,"FlaxVisionEncoderDecoderModel"),rzt.forEach(t),Oot=r(TVe," (Vision Encoder decoder model)"),TVe.forEach(t),ezt.forEach(t),Vot=i(Ci),T(LA.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(iWt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Pn,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoConfig"),c(Nn,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoTokenizer"),c(ki,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertModel"),c(Nf,"id","extending-the-auto-classes"),c(Nf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nf,"href","#extending-the-auto-classes"),c(Si,"class","relative group"),c(qf,"id","transformers.AutoConfig"),c(qf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qf,"href","#transformers.AutoConfig"),c(Ri,"class","relative group"),c(RS,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(PS,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertConfig"),c(BS,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartConfig"),c(NS,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitConfig"),c(IS,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertConfig"),c(qS,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(jS,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdConfig"),c(DS,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(GS,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(OS,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(VS,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomConfig"),c(XS,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertConfig"),c(zS,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineConfig"),c(QS,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPConfig"),c(WS,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenConfig"),c(HS,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertConfig"),c(US,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextConfig"),c(JS,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLConfig"),c(YS,"href","/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtConfig"),c(KS,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(ZS,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(eR,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(oR,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaConfig"),c(rR,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(tR,"href","/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(aR,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTConfig"),c(nR,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrConfig"),c(sR,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertConfig"),c(lR,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRConfig"),c(iR,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTConfig"),c(dR,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraConfig"),c(cR,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(fR,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertConfig"),c(mR,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaConfig"),c(gR,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetConfig"),c(hR,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTConfig"),c(pR,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelConfig"),c(_R,"href","/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNConfig"),c(uR,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Config"),c(bR,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(vR,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(FR,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJConfig"),c(TR,"href","/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTConfig"),c(MR,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertConfig"),c(ER,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertConfig"),c(CR,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(wR,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(AR,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(LR,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(yR,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDConfig"),c(xR,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitConfig"),c($R,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerConfig"),c(kR,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Config"),c(SR,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeConfig"),c(RR,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertConfig"),c(PR,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Config"),c(BR,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianConfig"),c(NR,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(IR,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartConfig"),c(qR,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTConfig"),c(jR,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(DR,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(GR,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetConfig"),c(OR,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Config"),c(VR,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpConfig"),c(XR,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaConfig"),c(zR,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(QR,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(WR,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTConfig"),c(HR,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusConfig"),c(UR,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverConfig"),c(JR,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartConfig"),c(YR,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(KR,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(ZR,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(eP,"href","/docs/transformers/pr_17427/en/model_doc/rag#transformers.RagConfig"),c(oP,"href","/docs/transformers/pr_17427/en/model_doc/realm#transformers.RealmConfig"),c(rP,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerConfig"),c(tP,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetConfig"),c(aP,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertConfig"),c(nP,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetConfig"),c(sP,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertConfig"),c(lP,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaConfig"),c(iP,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerConfig"),c(dP,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerConfig"),c(cP,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWConfig"),c(fP,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDConfig"),c(mP,"href","/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(gP,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(hP,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(pP,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterConfig"),c(_P,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(uP,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinConfig"),c(bP,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Config"),c(vP,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasConfig"),c(FP,"href","/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(TP,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(MP,"href","/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRConfig"),c(EP,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(CP,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(wP,"href","/docs/transformers/pr_17427/en/model_doc/van#transformers.VanConfig"),c(AP,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltConfig"),c(LP,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(yP,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(xP,"href","/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertConfig"),c($P,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTConfig"),c(kP,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(SP,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(RP,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(PP,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMConfig"),c(BP,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMConfig"),c(NP,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMConfig"),c(IP,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(qP,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(jP,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(DP,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetConfig"),c(GP,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosConfig"),c(OP,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoConfig"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ug,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jg,"id","transformers.AutoTokenizer"),c(Jg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jg,"href","#transformers.AutoTokenizer"),c(Bi,"class","relative group"),c(VP,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(XP,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizer"),c(zP,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(QP,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartTokenizer"),c(WP,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartTokenizerFast"),c(HP,"href","/docs/transformers/pr_17427/en/model_doc/barthez#transformers.BarthezTokenizer"),c(UP,"href","/docs/transformers/pr_17427/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(JP,"href","/docs/transformers/pr_17427/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(YP,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(KP,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(ZP,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(eB,"href","/docs/transformers/pr_17427/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(oB,"href","/docs/transformers/pr_17427/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(rB,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(tB,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(aB,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(nB,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(sB,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(lB,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(iB,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(dB,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(cB,"href","/docs/transformers/pr_17427/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(fB,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertTokenizer"),c(mB,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(gB,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineTokenizer"),c(hB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizer"),c(pB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(_B,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(uB,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(bB,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(vB,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17427/en/model_doc/cpm#transformers.CpmTokenizer"),c(TB,"href","/docs/transformers/pr_17427/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(MB,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(EB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(CB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(wB,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaTokenizer"),c(AB,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(LB,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(yB,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(xB,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c($B,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(kB,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(SB,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(RB,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraTokenizer"),c(PB,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(BB,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(NB,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetTokenizer"),c(IB,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(qB,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(jB,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelTokenizer"),c(DB,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(GB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(OB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(VB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(XB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(zB,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(QB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(WB,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(HB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizer"),c(UB,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(JB,"href","/docs/transformers/pr_17427/en/model_doc/herbert#transformers.HerbertTokenizer"),c(YB,"href","/docs/transformers/pr_17427/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(KB,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(ZB,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(eN,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(oN,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(rN,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(tN,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(aN,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(nN,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(sN,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(lN,"href","/docs/transformers/pr_17427/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(iN,"href","/docs/transformers/pr_17427/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(dN,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDTokenizer"),c(cN,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDTokenizerFast"),c(fN,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerTokenizer"),c(mN,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(gN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Tokenizer"),c(hN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5TokenizerFast"),c(pN,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeTokenizer"),c(_N,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(uN,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(bN,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(vN,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianTokenizer"),c(FN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartTokenizer"),c(TN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(MN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(EN,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(CN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(wN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(AN,"href","/docs/transformers/pr_17427/en/model_doc/mluke#transformers.MLukeTokenizer"),c(LN,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(yN,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(xN,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetTokenizer"),c($N,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(kN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Tokenizer"),c(SN,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5TokenizerFast"),c(RN,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpTokenizer"),c(PN,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(BN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(NN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(IN,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizer"),c(qN,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(jN,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(DN,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(GN,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ON,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(VN,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(XN,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(zN,"href","/docs/transformers/pr_17427/en/model_doc/phobert#transformers.PhobertTokenizer"),c(QN,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartTokenizer"),c(WN,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(HN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(UN,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(JN,"href","/docs/transformers/pr_17427/en/model_doc/rag#transformers.RagTokenizer"),c(YN,"href","/docs/transformers/pr_17427/en/model_doc/realm#transformers.RealmTokenizer"),c(KN,"href","/docs/transformers/pr_17427/en/model_doc/realm#transformers.RealmTokenizerFast"),c(ZN,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerTokenizer"),c(eI,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(oI,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertTokenizer"),c(rI,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(tI,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(aI,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(nI,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(sI,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(lI,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(iI,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(dI,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(cI,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(fI,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterTokenizer"),c(mI,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(gI,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(hI,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(pI,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Tokenizer"),c(_I,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5TokenizerFast"),c(uI,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasTokenizer"),c(bI,"href","/docs/transformers/pr_17427/en/model_doc/tapex#transformers.TapexTokenizer"),c(vI,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(FI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(TI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(MI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizer"),c(EI,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertTokenizerFast"),c(CI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(wI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(AI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(LI,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMTokenizer"),c(yI,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(xI,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMTokenizer"),c($I,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(kI,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(SI,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(RI,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizer"),c(PI,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(BI,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(NI,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(II,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizer"),c(qI,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sh,"id","transformers.AutoFeatureExtractor"),c(Sh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sh,"href","#transformers.AutoFeatureExtractor"),c(Ni,"class","relative group"),c(jI,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(DI,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(GI,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(OI,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(VI,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(XI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(zI,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(QI,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(WI,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(HI,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(UI,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(JI,"href","/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(YI,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(KI,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(ZI,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(eq,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(oq,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(rq,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(tq,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(aq,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(nq,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(sq,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(lq,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(iq,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dq,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(cq,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(fq,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(mq,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(gq,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(hq,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(pq,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(_q,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(uq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bq,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pp,"id","transformers.AutoProcessor"),c(pp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pp,"href","#transformers.AutoProcessor"),c(Ii,"class","relative group"),c(vq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(Fq,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPProcessor"),c(Tq,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPProcessor"),c(Mq,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(Eq,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(Cq,"href","/docs/transformers/pr_17427/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(wq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Aq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Lq,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(yq,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(xq,"href","/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRProcessor"),c($q,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(kq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Sq,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltProcessor"),c(Rq,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Pq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Bq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Nq,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Np,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ip,"id","transformers.AutoModel"),c(Ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ip,"href","#transformers.AutoModel"),c(ji,"class","relative group"),c(Iq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jq,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dq,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertModel"),c(Gq,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartModel"),c(Oq,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitModel"),c(Vq,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertModel"),c(Xq,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(zq,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdModel"),c(Qq,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(Wq,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(Hq,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(Uq,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomModel"),c(Jq,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertModel"),c(Yq,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineModel"),c(Kq,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.CLIPModel"),c(Zq,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenModel"),c(ej,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertModel"),c(oj,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextModel"),c(rj,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLModel"),c(tj,"href","/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtModel"),c(aj,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(nj,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(sj,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(lj,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaModel"),c(ij,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(dj,"href","/docs/transformers/pr_17427/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(cj,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTModel"),c(fj,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrModel"),c(mj,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertModel"),c(gj,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(hj,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTModel"),c(pj,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraModel"),c(_j,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertModel"),c(uj,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaModel"),c(bj,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetModel"),c(vj,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTModel"),c(Fj,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelModel"),c(Tj,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelBaseModel"),c(Mj,"href","/docs/transformers/pr_17427/en/model_doc/glpn#transformers.GLPNModel"),c(Ej,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2Model"),c(Cj,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(wj,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Aj,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJModel"),c(Lj,"href","/docs/transformers/pr_17427/en/model_doc/groupvit#transformers.GroupViTModel"),c(yj,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertModel"),c(xj,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertModel"),c($j,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(kj,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Sj,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Rj,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Pj,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDModel"),c(Bj,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitModel"),c(Nj,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerModel"),c(Ij,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5Model"),c(qj,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeModel"),c(jj,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertModel"),c(Dj,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100Model"),c(Gj,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianModel"),c(Oj,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Vj,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartModel"),c(Xj,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTModel"),c(zj,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Qj,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertModel"),c(Wj,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetModel"),c(Hj,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5Model"),c(Uj,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpModel"),c(Jj,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaModel"),c(Yj,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerModel"),c(Kj,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(Zj,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTModel"),c(eD,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusModel"),c(oD,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverModel"),c(rD,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartModel"),c(tD,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerModel"),c(aD,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(nD,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertModel"),c(sD,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModel"),c(lD,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetModel"),c(iD,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertModel"),c(dD,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetModel"),c(cD,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel"),c(fD,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaModel"),c(mD,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerModel"),c(gD,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerModel"),c(hD,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWModel"),c(pD,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDModel"),c(_D,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(uD,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterModel"),c(bD,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(vD,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinModel"),c(FD,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5Model"),c(TD,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasModel"),c(MD,"href","/docs/transformers/pr_17427/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(ED,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(CD,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechModel"),c(wD,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(AD,"href","/docs/transformers/pr_17427/en/model_doc/van#transformers.VanModel"),c(LD,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltModel"),c(yD,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(xD,"href","/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertModel"),c($D,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTModel"),c(kD,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(SD,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(RD,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(PD,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMModel"),c(BD,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMModel"),c(ND,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMModel"),c(ID,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(qD,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(jD,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(DD,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetModel"),c(GD,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosModel"),c(OD,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ou,"id","transformers.AutoModelForPreTraining"),c(Ou,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ou,"href","#transformers.AutoModelForPreTraining"),c(Oi,"class","relative group"),c(VD,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XD,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zD,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QD,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForPreTraining"),c(WD,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(HD,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForPreTraining"),c(UD,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(JD,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM"),c(YD,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(KD,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(ZD,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(eG,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(oG,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(rG,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(tG,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForPreTraining"),c(aG,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(nG,"href","/docs/transformers/pr_17427/en/model_doc/flava#transformers.FlavaForPreTraining"),c(sG,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForPreTraining"),c(lG,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(iG,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(dG,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(cG,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(fG,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(mG,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(gG,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(hG,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(pG,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(_G,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(uG,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(bG,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(vG,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FG,"href","/docs/transformers/pr_17427/en/model_doc/retribert#transformers.RetriBertModel"),c(TG,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(MG,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(EG,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(CG,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(wG,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(AG,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(LG,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(yG,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(xG,"href","/docs/transformers/pr_17427/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c($G,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(kG,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(SG,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(RG,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PG,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(BG,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(NG,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I2,"id","transformers.AutoModelForCausalLM"),c(I2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I2,"href","#transformers.AutoModelForCausalLM"),c(zi,"class","relative group"),c(IG,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qG,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jG,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DG,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForCausalLM"),c(GG,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertLMHeadModel"),c(OG,"href","/docs/transformers/pr_17427/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(VG,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(XG,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(zG,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(QG,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(WG,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForCausalLM"),c(HG,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(UG,"href","/docs/transformers/pr_17427/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(JG,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(YG,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(KG,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForCausalLM"),c(ZG,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(eO,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(oO,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(rO,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(tO,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianForCausalLM"),c(aO,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForCausalLM"),c(nO,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(sO,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForCausalLM"),c(lO,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(iO,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.OPTForCausalLM"),c(dO,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(cO,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(fO,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(mO,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(gO,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(hO,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(pO,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(_O,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(uO,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(bO,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(vO,"href","/docs/transformers/pr_17427/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(FO,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(TO,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(MO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(EO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(CO,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(wO,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L1,"id","transformers.AutoModelForMaskedLM"),c(L1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L1,"href","#transformers.AutoModelForMaskedLM"),c(Hi,"class","relative group"),c(AO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yO,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xO,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMaskedLM"),c($O,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(kO,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMaskedLM"),c(SO,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(RO,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(PO,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(BO,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(NO,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(IO,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(qO,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(jO,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(DO,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(GO,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(OO,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(VO,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(XO,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(zO,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(QO,"href","/docs/transformers/pr_17427/en/model_doc/luke#transformers.LukeForMaskedLM"),c(WO,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(HO,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(UO,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(JO,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(YO,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(KO,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(ZO,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(eV,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(oV,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(rV,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(tV,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(aV,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(nV,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(sV,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(lV,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(iV,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(dV,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(cV,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(fV,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p7,"id","transformers.AutoModelForSeq2SeqLM"),c(p7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p7,"href","#transformers.AutoModelForSeq2SeqLM"),c(Yi,"class","relative group"),c(mV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pV,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(_V,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(uV,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(bV,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(vV,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(FV,"href","/docs/transformers/pr_17427/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(TV,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(MV,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(EV,"href","/docs/transformers/pr_17427/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(CV,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.MarianMTModel"),c(wV,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(AV,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(LV,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(yV,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(xV,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c($V,"href","/docs/transformers/pr_17427/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(kV,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(SV,"href","/docs/transformers/pr_17427/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I7,"id","transformers.AutoModelForSequenceClassification"),c(I7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I7,"href","#transformers.AutoModelForSequenceClassification"),c(ed,"class","relative group"),c(RV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BV,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NV,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(GV,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(OV,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(VV,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(XV,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(zV,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(QV,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(WV,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(HV,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(UV,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(JV,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(YV,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(KV,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(ZV,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(eX,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(oX,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(rX,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(tX,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(aX,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(nX,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(sX,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(lX,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForSequenceClassification"),c(iX,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(dX,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(cX,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(fX,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(mX,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(gX,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(hX,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(pX,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(_X,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(uX,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(bX,"href","/docs/transformers/pr_17427/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(vX,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(FX,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(TX,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(MX,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(EX,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(CX,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(wX,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(AX,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(LX,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(yX,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(xX,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c($X,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(kX,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I4,"id","transformers.AutoModelForMultipleChoice"),c(I4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I4,"href","#transformers.AutoModelForMultipleChoice"),c(td,"class","relative group"),c(SX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PX,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BX,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(NX,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForMultipleChoice"),c(IX,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(qX,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(jX,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(DX,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(GX,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(OX,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(VX,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(XX,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(zX,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(QX,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(WX,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(HX,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(UX,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(JX,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(YX,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(KX,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(ZX,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(ez,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(oz,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(rz,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(tz,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(az,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(nz,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(sz,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(lz,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(iz,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(dz,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(cz,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ub,"id","transformers.AutoModelForNextSentencePrediction"),c(ub,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ub,"href","#transformers.AutoModelForNextSentencePrediction"),c(sd,"class","relative group"),c(fz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hz,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(pz,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(_z,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(uz,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(bz,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(vz,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lb,"id","transformers.AutoModelForTokenClassification"),c(Lb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lb,"href","#transformers.AutoModelForTokenClassification"),c(dd,"class","relative group"),c(Fz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mz,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ez,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(Cz,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForTokenClassification"),c(wz,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(Az,"href","/docs/transformers/pr_17427/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(Lz,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(yz,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForTokenClassification"),c(xz,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c($z,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(kz,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(Sz,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(Rz,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(Pz,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(Bz,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(Nz,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(Iz,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(qz,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(jz,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(Dz,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(Gz,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(Oz,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(Vz,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(Xz,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(zz,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(Qz,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(Wz,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(Hz,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(Uz,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(Jz,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(Yz,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(Kz,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(Zz,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(eQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(oQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(rQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(tQ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(aQ,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gv,"id","transformers.AutoModelForQuestionAnswering"),c(gv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gv,"href","#transformers.AutoModelForQuestionAnswering"),c(md,"class","relative group"),c(nQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iQ,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(dQ,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(cQ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(fQ,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(mQ,"href","/docs/transformers/pr_17427/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(gQ,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(hQ,"href","/docs/transformers/pr_17427/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(pQ,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(_Q,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(uQ,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(bQ,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(vQ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(FQ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(TQ,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(MQ,"href","/docs/transformers/pr_17427/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(EQ,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(CQ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(wQ,"href","/docs/transformers/pr_17427/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(AQ,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(LQ,"href","/docs/transformers/pr_17427/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(yQ,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(xQ,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c($Q,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(kQ,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(SQ,"href","/docs/transformers/pr_17427/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(RQ,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(PQ,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(BQ,"href","/docs/transformers/pr_17427/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(NQ,"href","/docs/transformers/pr_17427/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(IQ,"href","/docs/transformers/pr_17427/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(qQ,"href","/docs/transformers/pr_17427/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(jQ,"href","/docs/transformers/pr_17427/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(DQ,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(GQ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(OQ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(VQ,"href","/docs/transformers/pr_17427/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(XQ,"href","/docs/transformers/pr_17427/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(zQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(QQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(WQ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(HQ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(UQ,"href","/docs/transformers/pr_17427/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nF,"id","transformers.AutoModelForTableQuestionAnswering"),c(nF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(pd,"class","relative group"),c(JQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KQ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZQ,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cF,"id","transformers.AutoModelForImageClassification"),c(cF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cF,"href","#transformers.AutoModelForImageClassification"),c(bd,"class","relative group"),c(eW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tW,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForImageClassification"),c(aW,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(nW,"href","/docs/transformers/pr_17427/en/model_doc/cvt#transformers.CvtForImageClassification"),c(sW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(lW,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassification"),c(iW,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(dW,"href","/docs/transformers/pr_17427/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(cW,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassification"),c(fW,"href","/docs/transformers/pr_17427/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(mW,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(gW,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(hW,"href","/docs/transformers/pr_17427/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(pW,"href","/docs/transformers/pr_17427/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(_W,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(uW,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(bW,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(vW,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForImageClassification"),c(FW,"href","/docs/transformers/pr_17427/en/model_doc/van#transformers.VanForImageClassification"),c(TW,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AF,"id","transformers.AutoModelForVision2Seq"),c(AF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AF,"href","#transformers.AutoModelForVision2Seq"),c(Td,"class","relative group"),c(MW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kF,"id","transformers.AutoModelForVisualQuestionAnswering"),c(kF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kF,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Cd,"class","relative group"),c(AW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xW,"href","/docs/transformers/pr_17427/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NF,"id","transformers.AutoModelForAudioClassification"),c(NF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(NF,"href","#transformers.AutoModelForAudioClassification"),c(Ld,"class","relative group"),c($W,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(PW,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(BW,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(NW,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(IW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(qW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(jW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(DW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(GW,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UF,"id","transformers.AutoModelForAudioFrameClassification"),c(UF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UF,"href","#transformers.AutoModelForAudioFrameClassification"),c($d,"class","relative group"),c(OW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(QW,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(WW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(HW,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(UW,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aT,"id","transformers.AutoModelForCTC"),c(aT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aT,"href","#transformers.AutoModelForCTC"),c(Rd,"class","relative group"),c(JW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KW,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZW,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(eH,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.HubertForCTC"),c(oH,"href","/docs/transformers/pr_17427/en/model_doc/mctct#transformers.MCTCTForCTC"),c(rH,"href","/docs/transformers/pr_17427/en/model_doc/sew#transformers.SEWForCTC"),c(tH,"href","/docs/transformers/pr_17427/en/model_doc/sew-d#transformers.SEWDForCTC"),c(aH,"href","/docs/transformers/pr_17427/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(nH,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(sH,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(lH,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(iH,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bT,"id","transformers.AutoModelForSpeechSeq2Seq"),c(bT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bT,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Nd,"class","relative group"),c(dH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mH,"href","/docs/transformers/pr_17427/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(gH,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CT,"id","transformers.AutoModelForAudioXVector"),c(CT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CT,"href","#transformers.AutoModelForAudioXVector"),c(jd,"class","relative group"),c(hH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_H,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uH,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(bH,"href","/docs/transformers/pr_17427/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(vH,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(FH,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(TH,"href","/docs/transformers/pr_17427/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RT,"id","transformers.AutoModelForMaskedImageModeling"),c(RT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RT,"href","#transformers.AutoModelForMaskedImageModeling"),c(Od,"class","relative group"),c(MH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wH,"href","/docs/transformers/pr_17427/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(AH,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(LH,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.AutoModelForObjectDetection"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.AutoModelForObjectDetection"),c(Qd,"class","relative group"),c(yH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($H,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kH,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForObjectDetection"),c(SH,"href","/docs/transformers/pr_17427/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QT,"id","transformers.AutoModelForImageSegmentation"),c(QT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QT,"href","#transformers.AutoModelForImageSegmentation"),c(Ud,"class","relative group"),c(RH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NH,"href","/docs/transformers/pr_17427/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YT,"id","transformers.AutoModelForSemanticSegmentation"),c(YT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YT,"href","#transformers.AutoModelForSemanticSegmentation"),c(Kd,"class","relative group"),c(IH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DH,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(GH,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(OH,"href","/docs/transformers/pr_17427/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(VH,"href","/docs/transformers/pr_17427/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nM,"id","transformers.AutoModelForInstanceSegmentation"),c(nM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nM,"href","#transformers.AutoModelForInstanceSegmentation"),c(oc,"class","relative group"),c(XH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WH,"href","/docs/transformers/pr_17427/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cM,"id","transformers.TFAutoModel"),c(cM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cM,"href","#transformers.TFAutoModel"),c(ac,"class","relative group"),c(HH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JH,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YH,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertModel"),c(KH,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartModel"),c(ZH,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertModel"),c(eU,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(oU,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(rU,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertModel"),c(tU,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.TFCLIPModel"),c(aU,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertModel"),c(nU,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextModel"),c(sU,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLModel"),c(lU,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(iU,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaModel"),c(dU,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(cU,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(fU,"href","/docs/transformers/pr_17427/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(mU,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraModel"),c(gU,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(hU,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelModel"),c(pU,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(_U,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2Model"),c(uU,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJModel"),c(bU,"href","/docs/transformers/pr_17427/en/model_doc/hubert#transformers.TFHubertModel"),c(vU,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(FU,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDModel"),c(TU,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerModel"),c(MU,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertModel"),c(EU,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianModel"),c(CU,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartModel"),c(wU,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(AU,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetModel"),c(LU,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5Model"),c(yU,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(xU,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTModel"),c($U,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusModel"),c(kU,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetModel"),c(SU,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertModel"),c(RU,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetModel"),c(PU,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaModel"),c(BU,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerModel"),c(NU,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(IU,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinModel"),c(qU,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5Model"),c(jU,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasModel"),c(DU,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(GU,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTModel"),c(OU,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(VU,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(XU,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMModel"),c(zU,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(QU,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lE,"id","transformers.TFAutoModelForPreTraining"),c(lE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lE,"href","#transformers.TFAutoModelForPreTraining"),c(lc,"class","relative group"),c(WU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UU,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JU,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(YU,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(KU,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForPreTraining"),c(ZU,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(oJ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(tJ,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(aJ,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(nJ,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(sJ,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(lJ,"href","/docs/transformers/pr_17427/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(iJ,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(dJ,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(cJ,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(fJ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(mJ,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(gJ,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(hJ,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(pJ,"href","/docs/transformers/pr_17427/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(_J,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(uJ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(bJ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RE,"id","transformers.TFAutoModelForCausalLM"),c(RE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RE,"href","#transformers.TFAutoModelForCausalLM"),c(cc,"class","relative group"),c(vJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MJ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(EJ,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(CJ,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(wJ,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(AJ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(LJ,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(yJ,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(xJ,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c($J,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(kJ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(SJ,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(RJ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(PJ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UE,"id","transformers.TFAutoModelForImageClassification"),c(UE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UE,"href","#transformers.TFAutoModelForImageClassification"),c(gc,"class","relative group"),c(BJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qJ,"href","/docs/transformers/pr_17427/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(jJ,"href","/docs/transformers/pr_17427/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(DJ,"href","/docs/transformers/pr_17427/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(GJ,"href","/docs/transformers/pr_17427/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(OJ,"href","/docs/transformers/pr_17427/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(VJ,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aC,"id","transformers.TFAutoModelForMaskedLM"),c(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aC,"href","#transformers.TFAutoModelForMaskedLM"),c(_c,"class","relative group"),c(XJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WJ,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(HJ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(UJ,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(JJ,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(YJ,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(KJ,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(ZJ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(eY,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(oY,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(rY,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(tY,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(aY,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(nY,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(sY,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(lY,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(iY,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(dY,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(cY,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(fY,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(mY,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LC,"id","transformers.TFAutoModelForSeq2SeqLM"),c(LC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LC,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(vc,"class","relative group"),c(gY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_Y,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(uY,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(bY,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(vY,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(FY,"href","/docs/transformers/pr_17427/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(TY,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.TFMarianMTModel"),c(MY,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(EY,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(CY,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(wY,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.TFAutoModelForSequenceClassification"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.TFAutoModelForSequenceClassification"),c(Mc,"class","relative group"),c(AY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yY,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xY,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c($Y,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(kY,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(SY,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(RY,"href","/docs/transformers/pr_17427/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(PY,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(BY,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(NY,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(IY,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(qY,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(jY,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(DY,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(GY,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(OY,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(VY,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(XY,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(zY,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(QY,"href","/docs/transformers/pr_17427/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(WY,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(HY,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(UY,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(JY,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(YY,"href","/docs/transformers/pr_17427/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(KY,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(ZY,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(eK,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p3,"id","transformers.TFAutoModelForMultipleChoice"),c(p3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p3,"href","#transformers.TFAutoModelForMultipleChoice"),c(wc,"class","relative group"),c(oK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aK,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(nK,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(sK,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(lK,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(iK,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(dK,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(cK,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(fK,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(mK,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(gK,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(hK,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(pK,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(_K,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(uK,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(bK,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(vK,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(FK,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B3,"id","transformers.TFAutoModelForNextSentencePrediction"),c(B3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B3,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(yc,"class","relative group"),c(TK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CK,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(wK,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D3,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(D3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D3,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(kc,"class","relative group"),c(AK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17427/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X3,"id","transformers.TFAutoModelForTokenClassification"),c(X3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X3,"href","#transformers.TFAutoModelForTokenClassification"),c(Pc,"class","relative group"),c($K,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(PK,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(BK,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(NK,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(IK,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(qK,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(jK,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(DK,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(GK,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(OK,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(VK,"href","/docs/transformers/pr_17427/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(XK,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(zK,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(QK,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(WK,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(HK,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(UK,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(JK,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(YK,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(KK,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g5,"id","transformers.TFAutoModelForQuestionAnswering"),c(g5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g5,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Ic,"class","relative group"),c(ZK,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rZ,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(tZ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(aZ,"href","/docs/transformers/pr_17427/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(nZ,"href","/docs/transformers/pr_17427/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(sZ,"href","/docs/transformers/pr_17427/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(lZ,"href","/docs/transformers/pr_17427/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(iZ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(dZ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(cZ,"href","/docs/transformers/pr_17427/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(fZ,"href","/docs/transformers/pr_17427/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(mZ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(gZ,"href","/docs/transformers/pr_17427/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(hZ,"href","/docs/transformers/pr_17427/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(pZ,"href","/docs/transformers/pr_17427/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(_Z,"href","/docs/transformers/pr_17427/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(uZ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(bZ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(vZ,"href","/docs/transformers/pr_17427/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(FZ,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(TZ,"href","/docs/transformers/pr_17427/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N5,"id","transformers.TFAutoModelForVision2Seq"),c(N5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N5,"href","#transformers.TFAutoModelForVision2Seq"),c(Dc,"class","relative group"),c(MZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wZ,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(D5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Vc,"class","relative group"),c(AZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xZ,"href","/docs/transformers/pr_17427/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X5,"id","transformers.FlaxAutoModel"),c(X5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X5,"href","#transformers.FlaxAutoModel"),c(Qc,"class","relative group"),c($Z,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SZ,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RZ,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertModel"),c(PZ,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartModel"),c(BZ,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitModel"),c(NZ,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertModel"),c(IZ,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(qZ,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(jZ,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(DZ,"href","/docs/transformers/pr_17427/en/model_doc/clip#transformers.FlaxCLIPModel"),c(GZ,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(OZ,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraModel"),c(VZ,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(XZ,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(zZ,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(QZ,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(WZ,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianModel"),c(HZ,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartModel"),c(UZ,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5Model"),c(JZ,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTModel"),c(YZ,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(KZ,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(ZZ,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(eee,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5Model"),c(oee,"href","/docs/transformers/pr_17427/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(ree,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTModel"),c(tee,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(aee,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(nee,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F0,"id","transformers.FlaxAutoModelForCausalLM"),c(F0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F0,"href","#transformers.FlaxAutoModelForCausalLM"),c(Uc,"class","relative group"),c(see,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(cee,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(fee,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(mee,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(gee,"href","/docs/transformers/pr_17427/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(hee,"href","/docs/transformers/pr_17427/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(pee,"href","/docs/transformers/pr_17427/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(_ee,"href","/docs/transformers/pr_17427/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(uee,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(bee,"href","/docs/transformers/pr_17427/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R0,"id","transformers.FlaxAutoModelForPreTraining"),c(R0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R0,"href","#transformers.FlaxAutoModelForPreTraining"),c(Kc,"class","relative group"),c(vee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mee,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(Eee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Cee,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(wee,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(Aee,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(Lee,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(yee,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(xee,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c($ee,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(kee,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(See,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Ree,"href","/docs/transformers/pr_17427/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Pee,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U0,"id","transformers.FlaxAutoModelForMaskedLM"),c(U0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(of,"class","relative group"),c(Bee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Iee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qee,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(jee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Dee,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Gee,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Oee,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Vee,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Xee,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(zee,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Qee,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Wee,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iw,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iw,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(af,"class","relative group"),c(Hee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jee,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yee,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Kee,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Zee,"href","/docs/transformers/pr_17427/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(eoe,"href","/docs/transformers/pr_17427/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(ooe,"href","/docs/transformers/pr_17427/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(roe,"href","/docs/transformers/pr_17427/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(toe,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(aoe,"href","/docs/transformers/pr_17427/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(noe,"href","/docs/transformers/pr_17427/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(soe,"href","/docs/transformers/pr_17427/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tw,"id","transformers.FlaxAutoModelForSequenceClassification"),c(Tw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Tw,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(lf,"class","relative group"),c(loe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ioe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(doe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(coe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(foe,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(moe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(goe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(hoe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(poe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(_oe,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(uoe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(boe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(voe,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pw,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(Pw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pw,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(ff,"class","relative group"),c(Foe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Toe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Moe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eoe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(Coe,"href","/docs/transformers/pr_17427/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(woe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Aoe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Loe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(yoe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(xoe,"href","/docs/transformers/pr_17427/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c($oe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(koe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Soe,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ww,"id","transformers.FlaxAutoModelForTokenClassification"),c(Ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ww,"href","#transformers.FlaxAutoModelForTokenClassification"),c(hf,"class","relative group"),c(Roe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Poe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Boe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Noe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Ioe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(qoe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(joe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Doe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Goe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Ooe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Voe,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aA,"id","transformers.FlaxAutoModelForMultipleChoice"),c(aA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aA,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(uf,"class","relative group"),c(Xoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qoe,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Woe,"href","/docs/transformers/pr_17427/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Hoe,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Uoe,"href","/docs/transformers/pr_17427/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Joe,"href","/docs/transformers/pr_17427/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Yoe,"href","/docs/transformers/pr_17427/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Koe,"href","/docs/transformers/pr_17427/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Zoe,"href","/docs/transformers/pr_17427/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(ere,"href","/docs/transformers/pr_17427/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pA,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(pA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pA,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Ff,"class","relative group"),c(ore,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(are,"href","/docs/transformers/pr_17427/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vA,"id","transformers.FlaxAutoModelForImageClassification"),c(vA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vA,"href","#transformers.FlaxAutoModelForImageClassification"),c(Ef,"class","relative group"),c(nre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ire,"href","/docs/transformers/pr_17427/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(dre,"href","/docs/transformers/pr_17427/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CA,"id","transformers.FlaxAutoModelForVision2Seq"),c(CA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CA,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Af,"class","relative group"),c(cre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mre,"href","/docs/transformers/pr_17427/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gre,"href","/docs/transformers/pr_17427/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,wi),b(f,Sf,u),b(f,nt,u),e(nt,Ai),e(nt,Li),e(Li,WL),e(nt,Rf),b(f,Oe,u),b(f,Qe,u),e(Qe,yi),e(Qe,Pn),e(Pn,HL),e(Qe,Bn),e(Qe,Nn),e(Nn,UL),e(Qe,xi),e(Qe,In),e(In,JL),e(Qe,$i),b(f,Pf,u),M(ka,f,u),b(f,We,u),b(f,Ae,u),e(Ae,LS),e(Ae,ki),e(ki,yS),e(Ae,xS),b(f,Co,u),b(f,Sa,u),e(Sa,$S),e(Sa,Bf),e(Bf,kS),e(Sa,IWe),b(f,MVe,u),b(f,Si,u),e(Si,Nf),e(Nf,iae),M(YL,iae,null),e(Si,qWe),e(Si,dae),e(dae,jWe),b(f,EVe,u),b(f,qn,u),e(qn,DWe),e(qn,cae),e(cae,GWe),e(qn,OWe),e(qn,fae),e(fae,VWe),e(qn,XWe),b(f,CVe,u),M(KL,f,u),b(f,wVe,u),b(f,SS,u),e(SS,zWe),b(f,AVe,u),M(If,f,u),b(f,LVe,u),b(f,Ri,u),e(Ri,qf),e(qf,mae),M(ZL,mae,null),e(Ri,QWe),e(Ri,gae),e(gae,WWe),b(f,yVe,u),b(f,wo,u),M(ey,wo,null),e(wo,HWe),e(wo,oy),e(oy,UWe),e(oy,RS),e(RS,JWe),e(oy,YWe),e(wo,KWe),e(wo,ry),e(ry,ZWe),e(ry,hae),e(hae,eHe),e(ry,oHe),e(wo,rHe),e(wo,Lr),M(ty,Lr,null),e(Lr,tHe),e(Lr,pae),e(pae,aHe),e(Lr,nHe),e(Lr,Pi),e(Pi,sHe),e(Pi,_ae),e(_ae,lHe),e(Pi,iHe),e(Pi,uae),e(uae,dHe),e(Pi,cHe),e(Lr,fHe),e(Lr,A),e(A,jf),e(jf,bae),e(bae,mHe),e(jf,gHe),e(jf,PS),e(PS,hHe),e(jf,pHe),e(A,_He),e(A,Df),e(Df,vae),e(vae,uHe),e(Df,bHe),e(Df,BS),e(BS,vHe),e(Df,FHe),e(A,THe),e(A,Gf),e(Gf,Fae),e(Fae,MHe),e(Gf,EHe),e(Gf,NS),e(NS,CHe),e(Gf,wHe),e(A,AHe),e(A,Of),e(Of,Tae),e(Tae,LHe),e(Of,yHe),e(Of,IS),e(IS,xHe),e(Of,$He),e(A,kHe),e(A,Vf),e(Vf,Mae),e(Mae,SHe),e(Vf,RHe),e(Vf,qS),e(qS,PHe),e(Vf,BHe),e(A,NHe),e(A,Xf),e(Xf,Eae),e(Eae,IHe),e(Xf,qHe),e(Xf,jS),e(jS,jHe),e(Xf,DHe),e(A,GHe),e(A,zf),e(zf,Cae),e(Cae,OHe),e(zf,VHe),e(zf,DS),e(DS,XHe),e(zf,zHe),e(A,QHe),e(A,Qf),e(Qf,wae),e(wae,WHe),e(Qf,HHe),e(Qf,GS),e(GS,UHe),e(Qf,JHe),e(A,YHe),e(A,Wf),e(Wf,Aae),e(Aae,KHe),e(Wf,ZHe),e(Wf,OS),e(OS,eUe),e(Wf,oUe),e(A,rUe),e(A,Hf),e(Hf,Lae),e(Lae,tUe),e(Hf,aUe),e(Hf,VS),e(VS,nUe),e(Hf,sUe),e(A,lUe),e(A,Uf),e(Uf,yae),e(yae,iUe),e(Uf,dUe),e(Uf,XS),e(XS,cUe),e(Uf,fUe),e(A,mUe),e(A,Jf),e(Jf,xae),e(xae,gUe),e(Jf,hUe),e(Jf,zS),e(zS,pUe),e(Jf,_Ue),e(A,uUe),e(A,Yf),e(Yf,$ae),e($ae,bUe),e(Yf,vUe),e(Yf,QS),e(QS,FUe),e(Yf,TUe),e(A,MUe),e(A,Kf),e(Kf,kae),e(kae,EUe),e(Kf,CUe),e(Kf,WS),e(WS,wUe),e(Kf,AUe),e(A,LUe),e(A,Zf),e(Zf,Sae),e(Sae,yUe),e(Zf,xUe),e(Zf,HS),e(HS,$Ue),e(Zf,kUe),e(A,SUe),e(A,em),e(em,Rae),e(Rae,RUe),e(em,PUe),e(em,US),e(US,BUe),e(em,NUe),e(A,IUe),e(A,om),e(om,Pae),e(Pae,qUe),e(om,jUe),e(om,JS),e(JS,DUe),e(om,GUe),e(A,OUe),e(A,rm),e(rm,Bae),e(Bae,VUe),e(rm,XUe),e(rm,YS),e(YS,zUe),e(rm,QUe),e(A,WUe),e(A,tm),e(tm,Nae),e(Nae,HUe),e(tm,UUe),e(tm,KS),e(KS,JUe),e(tm,YUe),e(A,KUe),e(A,am),e(am,Iae),e(Iae,ZUe),e(am,eJe),e(am,ZS),e(ZS,oJe),e(am,rJe),e(A,tJe),e(A,nm),e(nm,qae),e(qae,aJe),e(nm,nJe),e(nm,eR),e(eR,sJe),e(nm,lJe),e(A,iJe),e(A,sm),e(sm,jae),e(jae,dJe),e(sm,cJe),e(sm,oR),e(oR,fJe),e(sm,mJe),e(A,gJe),e(A,lm),e(lm,Dae),e(Dae,hJe),e(lm,pJe),e(lm,rR),e(rR,_Je),e(lm,uJe),e(A,bJe),e(A,im),e(im,Gae),e(Gae,vJe),e(im,FJe),e(im,tR),e(tR,TJe),e(im,MJe),e(A,EJe),e(A,dm),e(dm,Oae),e(Oae,CJe),e(dm,wJe),e(dm,aR),e(aR,AJe),e(dm,LJe),e(A,yJe),e(A,cm),e(cm,Vae),e(Vae,xJe),e(cm,$Je),e(cm,nR),e(nR,kJe),e(cm,SJe),e(A,RJe),e(A,fm),e(fm,Xae),e(Xae,PJe),e(fm,BJe),e(fm,sR),e(sR,NJe),e(fm,IJe),e(A,qJe),e(A,mm),e(mm,zae),e(zae,jJe),e(mm,DJe),e(mm,lR),e(lR,GJe),e(mm,OJe),e(A,VJe),e(A,gm),e(gm,Qae),e(Qae,XJe),e(gm,zJe),e(gm,iR),e(iR,QJe),e(gm,WJe),e(A,HJe),e(A,hm),e(hm,Wae),e(Wae,UJe),e(hm,JJe),e(hm,dR),e(dR,YJe),e(hm,KJe),e(A,ZJe),e(A,pm),e(pm,Hae),e(Hae,eYe),e(pm,oYe),e(pm,cR),e(cR,rYe),e(pm,tYe),e(A,aYe),e(A,_m),e(_m,Uae),e(Uae,nYe),e(_m,sYe),e(_m,fR),e(fR,lYe),e(_m,iYe),e(A,dYe),e(A,um),e(um,Jae),e(Jae,cYe),e(um,fYe),e(um,mR),e(mR,mYe),e(um,gYe),e(A,hYe),e(A,bm),e(bm,Yae),e(Yae,pYe),e(bm,_Ye),e(bm,gR),e(gR,uYe),e(bm,bYe),e(A,vYe),e(A,vm),e(vm,Kae),e(Kae,FYe),e(vm,TYe),e(vm,hR),e(hR,MYe),e(vm,EYe),e(A,CYe),e(A,Fm),e(Fm,Zae),e(Zae,wYe),e(Fm,AYe),e(Fm,pR),e(pR,LYe),e(Fm,yYe),e(A,xYe),e(A,Tm),e(Tm,ene),e(ene,$Ye),e(Tm,kYe),e(Tm,_R),e(_R,SYe),e(Tm,RYe),e(A,PYe),e(A,Mm),e(Mm,one),e(one,BYe),e(Mm,NYe),e(Mm,uR),e(uR,IYe),e(Mm,qYe),e(A,jYe),e(A,Em),e(Em,rne),e(rne,DYe),e(Em,GYe),e(Em,bR),e(bR,OYe),e(Em,VYe),e(A,XYe),e(A,Cm),e(Cm,tne),e(tne,zYe),e(Cm,QYe),e(Cm,vR),e(vR,WYe),e(Cm,HYe),e(A,UYe),e(A,wm),e(wm,ane),e(ane,JYe),e(wm,YYe),e(wm,FR),e(FR,KYe),e(wm,ZYe),e(A,eKe),e(A,Am),e(Am,nne),e(nne,oKe),e(Am,rKe),e(Am,TR),e(TR,tKe),e(Am,aKe),e(A,nKe),e(A,Lm),e(Lm,sne),e(sne,sKe),e(Lm,lKe),e(Lm,MR),e(MR,iKe),e(Lm,dKe),e(A,cKe),e(A,ym),e(ym,lne),e(lne,fKe),e(ym,mKe),e(ym,ER),e(ER,gKe),e(ym,hKe),e(A,pKe),e(A,xm),e(xm,ine),e(ine,_Ke),e(xm,uKe),e(xm,CR),e(CR,bKe),e(xm,vKe),e(A,FKe),e(A,$m),e($m,dne),e(dne,TKe),e($m,MKe),e($m,wR),e(wR,EKe),e($m,CKe),e(A,wKe),e(A,km),e(km,cne),e(cne,AKe),e(km,LKe),e(km,AR),e(AR,yKe),e(km,xKe),e(A,$Ke),e(A,Sm),e(Sm,fne),e(fne,kKe),e(Sm,SKe),e(Sm,LR),e(LR,RKe),e(Sm,PKe),e(A,BKe),e(A,Rm),e(Rm,mne),e(mne,NKe),e(Rm,IKe),e(Rm,yR),e(yR,qKe),e(Rm,jKe),e(A,DKe),e(A,Pm),e(Pm,gne),e(gne,GKe),e(Pm,OKe),e(Pm,xR),e(xR,VKe),e(Pm,XKe),e(A,zKe),e(A,Bm),e(Bm,hne),e(hne,QKe),e(Bm,WKe),e(Bm,$R),e($R,HKe),e(Bm,UKe),e(A,JKe),e(A,Nm),e(Nm,pne),e(pne,YKe),e(Nm,KKe),e(Nm,kR),e(kR,ZKe),e(Nm,eZe),e(A,oZe),e(A,Im),e(Im,_ne),e(_ne,rZe),e(Im,tZe),e(Im,SR),e(SR,aZe),e(Im,nZe),e(A,sZe),e(A,qm),e(qm,une),e(une,lZe),e(qm,iZe),e(qm,RR),e(RR,dZe),e(qm,cZe),e(A,fZe),e(A,jm),e(jm,bne),e(bne,mZe),e(jm,gZe),e(jm,PR),e(PR,hZe),e(jm,pZe),e(A,_Ze),e(A,Dm),e(Dm,vne),e(vne,uZe),e(Dm,bZe),e(Dm,BR),e(BR,vZe),e(Dm,FZe),e(A,TZe),e(A,Gm),e(Gm,Fne),e(Fne,MZe),e(Gm,EZe),e(Gm,NR),e(NR,CZe),e(Gm,wZe),e(A,AZe),e(A,Om),e(Om,Tne),e(Tne,LZe),e(Om,yZe),e(Om,IR),e(IR,xZe),e(Om,$Ze),e(A,kZe),e(A,Vm),e(Vm,Mne),e(Mne,SZe),e(Vm,RZe),e(Vm,qR),e(qR,PZe),e(Vm,BZe),e(A,NZe),e(A,Xm),e(Xm,Ene),e(Ene,IZe),e(Xm,qZe),e(Xm,jR),e(jR,jZe),e(Xm,DZe),e(A,GZe),e(A,zm),e(zm,Cne),e(Cne,OZe),e(zm,VZe),e(zm,DR),e(DR,XZe),e(zm,zZe),e(A,QZe),e(A,Qm),e(Qm,wne),e(wne,WZe),e(Qm,HZe),e(Qm,GR),e(GR,UZe),e(Qm,JZe),e(A,YZe),e(A,Wm),e(Wm,Ane),e(Ane,KZe),e(Wm,ZZe),e(Wm,OR),e(OR,eeo),e(Wm,oeo),e(A,reo),e(A,Hm),e(Hm,Lne),e(Lne,teo),e(Hm,aeo),e(Hm,VR),e(VR,neo),e(Hm,seo),e(A,leo),e(A,Um),e(Um,yne),e(yne,ieo),e(Um,deo),e(Um,XR),e(XR,ceo),e(Um,feo),e(A,meo),e(A,Jm),e(Jm,xne),e(xne,geo),e(Jm,heo),e(Jm,zR),e(zR,peo),e(Jm,_eo),e(A,ueo),e(A,Ym),e(Ym,$ne),e($ne,beo),e(Ym,veo),e(Ym,QR),e(QR,Feo),e(Ym,Teo),e(A,Meo),e(A,Km),e(Km,kne),e(kne,Eeo),e(Km,Ceo),e(Km,WR),e(WR,weo),e(Km,Aeo),e(A,Leo),e(A,Zm),e(Zm,Sne),e(Sne,yeo),e(Zm,xeo),e(Zm,HR),e(HR,$eo),e(Zm,keo),e(A,Seo),e(A,eg),e(eg,Rne),e(Rne,Reo),e(eg,Peo),e(eg,UR),e(UR,Beo),e(eg,Neo),e(A,Ieo),e(A,og),e(og,Pne),e(Pne,qeo),e(og,jeo),e(og,JR),e(JR,Deo),e(og,Geo),e(A,Oeo),e(A,rg),e(rg,Bne),e(Bne,Veo),e(rg,Xeo),e(rg,YR),e(YR,zeo),e(rg,Qeo),e(A,Weo),e(A,tg),e(tg,Nne),e(Nne,Heo),e(tg,Ueo),e(tg,KR),e(KR,Jeo),e(tg,Yeo),e(A,Keo),e(A,ag),e(ag,Ine),e(Ine,Zeo),e(ag,eoo),e(ag,ZR),e(ZR,ooo),e(ag,roo),e(A,too),e(A,ng),e(ng,qne),e(qne,aoo),e(ng,noo),e(ng,eP),e(eP,soo),e(ng,loo),e(A,ioo),e(A,sg),e(sg,jne),e(jne,doo),e(sg,coo),e(sg,oP),e(oP,foo),e(sg,moo),e(A,goo),e(A,lg),e(lg,Dne),e(Dne,hoo),e(lg,poo),e(lg,rP),e(rP,_oo),e(lg,uoo),e(A,boo),e(A,ig),e(ig,Gne),e(Gne,voo),e(ig,Foo),e(ig,tP),e(tP,Too),e(ig,Moo),e(A,Eoo),e(A,dg),e(dg,One),e(One,Coo),e(dg,woo),e(dg,aP),e(aP,Aoo),e(dg,Loo),e(A,yoo),e(A,cg),e(cg,Vne),e(Vne,xoo),e(cg,$oo),e(cg,nP),e(nP,koo),e(cg,Soo),e(A,Roo),e(A,fg),e(fg,Xne),e(Xne,Poo),e(fg,Boo),e(fg,sP),e(sP,Noo),e(fg,Ioo),e(A,qoo),e(A,mg),e(mg,zne),e(zne,joo),e(mg,Doo),e(mg,lP),e(lP,Goo),e(mg,Ooo),e(A,Voo),e(A,gg),e(gg,Qne),e(Qne,Xoo),e(gg,zoo),e(gg,iP),e(iP,Qoo),e(gg,Woo),e(A,Hoo),e(A,hg),e(hg,Wne),e(Wne,Uoo),e(hg,Joo),e(hg,dP),e(dP,Yoo),e(hg,Koo),e(A,Zoo),e(A,pg),e(pg,Hne),e(Hne,ero),e(pg,oro),e(pg,cP),e(cP,rro),e(pg,tro),e(A,aro),e(A,_g),e(_g,Une),e(Une,nro),e(_g,sro),e(_g,fP),e(fP,lro),e(_g,iro),e(A,dro),e(A,ug),e(ug,Jne),e(Jne,cro),e(ug,fro),e(ug,mP),e(mP,mro),e(ug,gro),e(A,hro),e(A,bg),e(bg,Yne),e(Yne,pro),e(bg,_ro),e(bg,gP),e(gP,uro),e(bg,bro),e(A,vro),e(A,vg),e(vg,Kne),e(Kne,Fro),e(vg,Tro),e(vg,hP),e(hP,Mro),e(vg,Ero),e(A,Cro),e(A,Fg),e(Fg,Zne),e(Zne,wro),e(Fg,Aro),e(Fg,pP),e(pP,Lro),e(Fg,yro),e(A,xro),e(A,Tg),e(Tg,ese),e(ese,$ro),e(Tg,kro),e(Tg,_P),e(_P,Sro),e(Tg,Rro),e(A,Pro),e(A,Mg),e(Mg,ose),e(ose,Bro),e(Mg,Nro),e(Mg,uP),e(uP,Iro),e(Mg,qro),e(A,jro),e(A,Eg),e(Eg,rse),e(rse,Dro),e(Eg,Gro),e(Eg,bP),e(bP,Oro),e(Eg,Vro),e(A,Xro),e(A,Cg),e(Cg,tse),e(tse,zro),e(Cg,Qro),e(Cg,vP),e(vP,Wro),e(Cg,Hro),e(A,Uro),e(A,wg),e(wg,ase),e(ase,Jro),e(wg,Yro),e(wg,FP),e(FP,Kro),e(wg,Zro),e(A,eto),e(A,Ag),e(Ag,nse),e(nse,oto),e(Ag,rto),e(Ag,TP),e(TP,tto),e(Ag,ato),e(A,nto),e(A,Lg),e(Lg,sse),e(sse,sto),e(Lg,lto),e(Lg,MP),e(MP,ito),e(Lg,dto),e(A,cto),e(A,yg),e(yg,lse),e(lse,fto),e(yg,mto),e(yg,EP),e(EP,gto),e(yg,hto),e(A,pto),e(A,xg),e(xg,ise),e(ise,_to),e(xg,uto),e(xg,CP),e(CP,bto),e(xg,vto),e(A,Fto),e(A,$g),e($g,dse),e(dse,Tto),e($g,Mto),e($g,wP),e(wP,Eto),e($g,Cto),e(A,wto),e(A,kg),e(kg,cse),e(cse,Ato),e(kg,Lto),e(kg,AP),e(AP,yto),e(kg,xto),e(A,$to),e(A,Sg),e(Sg,fse),e(fse,kto),e(Sg,Sto),e(Sg,LP),e(LP,Rto),e(Sg,Pto),e(A,Bto),e(A,Rg),e(Rg,mse),e(mse,Nto),e(Rg,Ito),e(Rg,yP),e(yP,qto),e(Rg,jto),e(A,Dto),e(A,Pg),e(Pg,gse),e(gse,Gto),e(Pg,Oto),e(Pg,xP),e(xP,Vto),e(Pg,Xto),e(A,zto),e(A,Bg),e(Bg,hse),e(hse,Qto),e(Bg,Wto),e(Bg,$P),e($P,Hto),e(Bg,Uto),e(A,Jto),e(A,Ng),e(Ng,pse),e(pse,Yto),e(Ng,Kto),e(Ng,kP),e(kP,Zto),e(Ng,eao),e(A,oao),e(A,Ig),e(Ig,_se),e(_se,rao),e(Ig,tao),e(Ig,SP),e(SP,aao),e(Ig,nao),e(A,sao),e(A,qg),e(qg,use),e(use,lao),e(qg,iao),e(qg,RP),e(RP,dao),e(qg,cao),e(A,fao),e(A,jg),e(jg,bse),e(bse,mao),e(jg,gao),e(jg,PP),e(PP,hao),e(jg,pao),e(A,_ao),e(A,Dg),e(Dg,vse),e(vse,uao),e(Dg,bao),e(Dg,BP),e(BP,vao),e(Dg,Fao),e(A,Tao),e(A,Gg),e(Gg,Fse),e(Fse,Mao),e(Gg,Eao),e(Gg,NP),e(NP,Cao),e(Gg,wao),e(A,Aao),e(A,Og),e(Og,Tse),e(Tse,Lao),e(Og,yao),e(Og,IP),e(IP,xao),e(Og,$ao),e(A,kao),e(A,Vg),e(Vg,Mse),e(Mse,Sao),e(Vg,Rao),e(Vg,qP),e(qP,Pao),e(Vg,Bao),e(A,Nao),e(A,Xg),e(Xg,Ese),e(Ese,Iao),e(Xg,qao),e(Xg,jP),e(jP,jao),e(Xg,Dao),e(A,Gao),e(A,zg),e(zg,Cse),e(Cse,Oao),e(zg,Vao),e(zg,DP),e(DP,Xao),e(zg,zao),e(A,Qao),e(A,Qg),e(Qg,wse),e(wse,Wao),e(Qg,Hao),e(Qg,GP),e(GP,Uao),e(Qg,Jao),e(A,Yao),e(A,Wg),e(Wg,Ase),e(Ase,Kao),e(Wg,Zao),e(Wg,OP),e(OP,eno),e(Wg,ono),e(Lr,rno),M(Hg,Lr,null),e(wo,tno),e(wo,Ug),M(ay,Ug,null),e(Ug,ano),e(Ug,Lse),e(Lse,nno),b(f,xVe,u),b(f,Bi,u),e(Bi,Jg),e(Jg,yse),M(ny,yse,null),e(Bi,sno),e(Bi,xse),e(xse,lno),b(f,$Ve,u),b(f,Ao,u),M(sy,Ao,null),e(Ao,ino),e(Ao,ly),e(ly,dno),e(ly,VP),e(VP,cno),e(ly,fno),e(Ao,mno),e(Ao,iy),e(iy,gno),e(iy,$se),e($se,hno),e(iy,pno),e(Ao,_no),e(Ao,yr),M(dy,yr,null),e(yr,uno),e(yr,kse),e(kse,bno),e(yr,vno),e(yr,Ra),e(Ra,Fno),e(Ra,Sse),e(Sse,Tno),e(Ra,Mno),e(Ra,Rse),e(Rse,Eno),e(Ra,Cno),e(Ra,Pse),e(Pse,wno),e(Ra,Ano),e(yr,Lno),e(yr,k),e(k,jn),e(jn,Bse),e(Bse,yno),e(jn,xno),e(jn,XP),e(XP,$no),e(jn,kno),e(jn,zP),e(zP,Sno),e(jn,Rno),e(k,Pno),e(k,Dn),e(Dn,Nse),e(Nse,Bno),e(Dn,Nno),e(Dn,QP),e(QP,Ino),e(Dn,qno),e(Dn,WP),e(WP,jno),e(Dn,Dno),e(k,Gno),e(k,Gn),e(Gn,Ise),e(Ise,Ono),e(Gn,Vno),e(Gn,HP),e(HP,Xno),e(Gn,zno),e(Gn,UP),e(UP,Qno),e(Gn,Wno),e(k,Hno),e(k,Yg),e(Yg,qse),e(qse,Uno),e(Yg,Jno),e(Yg,JP),e(JP,Yno),e(Yg,Kno),e(k,Zno),e(k,On),e(On,jse),e(jse,eso),e(On,oso),e(On,YP),e(YP,rso),e(On,tso),e(On,KP),e(KP,aso),e(On,nso),e(k,sso),e(k,Kg),e(Kg,Dse),e(Dse,lso),e(Kg,iso),e(Kg,ZP),e(ZP,dso),e(Kg,cso),e(k,fso),e(k,Zg),e(Zg,Gse),e(Gse,mso),e(Zg,gso),e(Zg,eB),e(eB,hso),e(Zg,pso),e(k,_so),e(k,eh),e(eh,Ose),e(Ose,uso),e(eh,bso),e(eh,oB),e(oB,vso),e(eh,Fso),e(k,Tso),e(k,Vn),e(Vn,Vse),e(Vse,Mso),e(Vn,Eso),e(Vn,rB),e(rB,Cso),e(Vn,wso),e(Vn,tB),e(tB,Aso),e(Vn,Lso),e(k,yso),e(k,Xn),e(Xn,Xse),e(Xse,xso),e(Xn,$so),e(Xn,aB),e(aB,kso),e(Xn,Sso),e(Xn,nB),e(nB,Rso),e(Xn,Pso),e(k,Bso),e(k,zn),e(zn,zse),e(zse,Nso),e(zn,Iso),e(zn,sB),e(sB,qso),e(zn,jso),e(zn,lB),e(lB,Dso),e(zn,Gso),e(k,Oso),e(k,oh),e(oh,Qse),e(Qse,Vso),e(oh,Xso),e(oh,iB),e(iB,zso),e(oh,Qso),e(k,Wso),e(k,rh),e(rh,Wse),e(Wse,Hso),e(rh,Uso),e(rh,dB),e(dB,Jso),e(rh,Yso),e(k,Kso),e(k,th),e(th,Hse),e(Hse,Zso),e(th,elo),e(th,cB),e(cB,olo),e(th,rlo),e(k,tlo),e(k,Qn),e(Qn,Use),e(Use,alo),e(Qn,nlo),e(Qn,fB),e(fB,slo),e(Qn,llo),e(Qn,mB),e(mB,ilo),e(Qn,dlo),e(k,clo),e(k,ah),e(ah,Jse),e(Jse,flo),e(ah,mlo),e(ah,gB),e(gB,glo),e(ah,hlo),e(k,plo),e(k,Wn),e(Wn,Yse),e(Yse,_lo),e(Wn,ulo),e(Wn,hB),e(hB,blo),e(Wn,vlo),e(Wn,pB),e(pB,Flo),e(Wn,Tlo),e(k,Mlo),e(k,Hn),e(Hn,Kse),e(Kse,Elo),e(Hn,Clo),e(Hn,_B),e(_B,wlo),e(Hn,Alo),e(Hn,uB),e(uB,Llo),e(Hn,ylo),e(k,xlo),e(k,Un),e(Un,Zse),e(Zse,$lo),e(Un,klo),e(Un,bB),e(bB,Slo),e(Un,Rlo),e(Un,vB),e(vB,Plo),e(Un,Blo),e(k,Nlo),e(k,Jn),e(Jn,ele),e(ele,Ilo),e(Jn,qlo),e(Jn,FB),e(FB,jlo),e(Jn,Dlo),e(Jn,TB),e(TB,Glo),e(Jn,Olo),e(k,Vlo),e(k,nh),e(nh,ole),e(ole,Xlo),e(nh,zlo),e(nh,MB),e(MB,Qlo),e(nh,Wlo),e(k,Hlo),e(k,Yn),e(Yn,rle),e(rle,Ulo),e(Yn,Jlo),e(Yn,EB),e(EB,Ylo),e(Yn,Klo),e(Yn,CB),e(CB,Zlo),e(Yn,eio),e(k,oio),e(k,Kn),e(Kn,tle),e(tle,rio),e(Kn,tio),e(Kn,wB),e(wB,aio),e(Kn,nio),e(Kn,AB),e(AB,sio),e(Kn,lio),e(k,iio),e(k,Zn),e(Zn,ale),e(ale,dio),e(Zn,cio),e(Zn,LB),e(LB,fio),e(Zn,mio),e(Zn,yB),e(yB,gio),e(Zn,hio),e(k,pio),e(k,es),e(es,nle),e(nle,_io),e(es,uio),e(es,xB),e(xB,bio),e(es,vio),e(es,$B),e($B,Fio),e(es,Tio),e(k,Mio),e(k,os),e(os,sle),e(sle,Eio),e(os,Cio),e(os,kB),e(kB,wio),e(os,Aio),e(os,SB),e(SB,Lio),e(os,yio),e(k,xio),e(k,rs),e(rs,lle),e(lle,$io),e(rs,kio),e(rs,RB),e(RB,Sio),e(rs,Rio),e(rs,PB),e(PB,Pio),e(rs,Bio),e(k,Nio),e(k,sh),e(sh,ile),e(ile,Iio),e(sh,qio),e(sh,BB),e(BB,jio),e(sh,Dio),e(k,Gio),e(k,ts),e(ts,dle),e(dle,Oio),e(ts,Vio),e(ts,NB),e(NB,Xio),e(ts,zio),e(ts,IB),e(IB,Qio),e(ts,Wio),e(k,Hio),e(k,lh),e(lh,cle),e(cle,Uio),e(lh,Jio),e(lh,qB),e(qB,Yio),e(lh,Kio),e(k,Zio),e(k,as),e(as,fle),e(fle,edo),e(as,odo),e(as,jB),e(jB,rdo),e(as,tdo),e(as,DB),e(DB,ado),e(as,ndo),e(k,sdo),e(k,ns),e(ns,mle),e(mle,ldo),e(ns,ido),e(ns,GB),e(GB,ddo),e(ns,cdo),e(ns,OB),e(OB,fdo),e(ns,mdo),e(k,gdo),e(k,ss),e(ss,gle),e(gle,hdo),e(ss,pdo),e(ss,VB),e(VB,_do),e(ss,udo),e(ss,XB),e(XB,bdo),e(ss,vdo),e(k,Fdo),e(k,ih),e(ih,hle),e(hle,Tdo),e(ih,Mdo),e(ih,zB),e(zB,Edo),e(ih,Cdo),e(k,wdo),e(k,ls),e(ls,ple),e(ple,Ado),e(ls,Ldo),e(ls,QB),e(QB,ydo),e(ls,xdo),e(ls,WB),e(WB,$do),e(ls,kdo),e(k,Sdo),e(k,is),e(is,_le),e(_le,Rdo),e(is,Pdo),e(is,HB),e(HB,Bdo),e(is,Ndo),e(is,UB),e(UB,Ido),e(is,qdo),e(k,jdo),e(k,ds),e(ds,ule),e(ule,Ddo),e(ds,Gdo),e(ds,JB),e(JB,Odo),e(ds,Vdo),e(ds,YB),e(YB,Xdo),e(ds,zdo),e(k,Qdo),e(k,dh),e(dh,ble),e(ble,Wdo),e(dh,Hdo),e(dh,KB),e(KB,Udo),e(dh,Jdo),e(k,Ydo),e(k,cs),e(cs,vle),e(vle,Kdo),e(cs,Zdo),e(cs,ZB),e(ZB,eco),e(cs,oco),e(cs,eN),e(eN,rco),e(cs,tco),e(k,aco),e(k,fs),e(fs,Fle),e(Fle,nco),e(fs,sco),e(fs,oN),e(oN,lco),e(fs,ico),e(fs,rN),e(rN,dco),e(fs,cco),e(k,fco),e(k,ms),e(ms,Tle),e(Tle,mco),e(ms,gco),e(ms,tN),e(tN,hco),e(ms,pco),e(ms,aN),e(aN,_co),e(ms,uco),e(k,bco),e(k,gs),e(gs,Mle),e(Mle,vco),e(gs,Fco),e(gs,nN),e(nN,Tco),e(gs,Mco),e(gs,sN),e(sN,Eco),e(gs,Cco),e(k,wco),e(k,hs),e(hs,Ele),e(Ele,Aco),e(hs,Lco),e(hs,lN),e(lN,yco),e(hs,xco),e(hs,iN),e(iN,$co),e(hs,kco),e(k,Sco),e(k,ps),e(ps,Cle),e(Cle,Rco),e(ps,Pco),e(ps,dN),e(dN,Bco),e(ps,Nco),e(ps,cN),e(cN,Ico),e(ps,qco),e(k,jco),e(k,_s),e(_s,wle),e(wle,Dco),e(_s,Gco),e(_s,fN),e(fN,Oco),e(_s,Vco),e(_s,mN),e(mN,Xco),e(_s,zco),e(k,Qco),e(k,us),e(us,Ale),e(Ale,Wco),e(us,Hco),e(us,gN),e(gN,Uco),e(us,Jco),e(us,hN),e(hN,Yco),e(us,Kco),e(k,Zco),e(k,ch),e(ch,Lle),e(Lle,efo),e(ch,ofo),e(ch,pN),e(pN,rfo),e(ch,tfo),e(k,afo),e(k,bs),e(bs,yle),e(yle,nfo),e(bs,sfo),e(bs,_N),e(_N,lfo),e(bs,ifo),e(bs,uN),e(uN,dfo),e(bs,cfo),e(k,ffo),e(k,fh),e(fh,xle),e(xle,mfo),e(fh,gfo),e(fh,bN),e(bN,hfo),e(fh,pfo),e(k,_fo),e(k,mh),e(mh,$le),e($le,ufo),e(mh,bfo),e(mh,vN),e(vN,vfo),e(mh,Ffo),e(k,Tfo),e(k,vs),e(vs,kle),e(kle,Mfo),e(vs,Efo),e(vs,FN),e(FN,Cfo),e(vs,wfo),e(vs,TN),e(TN,Afo),e(vs,Lfo),e(k,yfo),e(k,Fs),e(Fs,Sle),e(Sle,xfo),e(Fs,$fo),e(Fs,MN),e(MN,kfo),e(Fs,Sfo),e(Fs,EN),e(EN,Rfo),e(Fs,Pfo),e(k,Bfo),e(k,Ts),e(Ts,Rle),e(Rle,Nfo),e(Ts,Ifo),e(Ts,CN),e(CN,qfo),e(Ts,jfo),e(Ts,wN),e(wN,Dfo),e(Ts,Gfo),e(k,Ofo),e(k,gh),e(gh,Ple),e(Ple,Vfo),e(gh,Xfo),e(gh,AN),e(AN,zfo),e(gh,Qfo),e(k,Wfo),e(k,Ms),e(Ms,Ble),e(Ble,Hfo),e(Ms,Ufo),e(Ms,LN),e(LN,Jfo),e(Ms,Yfo),e(Ms,yN),e(yN,Kfo),e(Ms,Zfo),e(k,emo),e(k,Es),e(Es,Nle),e(Nle,omo),e(Es,rmo),e(Es,xN),e(xN,tmo),e(Es,amo),e(Es,$N),e($N,nmo),e(Es,smo),e(k,lmo),e(k,Cs),e(Cs,Ile),e(Ile,imo),e(Cs,dmo),e(Cs,kN),e(kN,cmo),e(Cs,fmo),e(Cs,SN),e(SN,mmo),e(Cs,gmo),e(k,hmo),e(k,ws),e(ws,qle),e(qle,pmo),e(ws,_mo),e(ws,RN),e(RN,umo),e(ws,bmo),e(ws,PN),e(PN,vmo),e(ws,Fmo),e(k,Tmo),e(k,As),e(As,jle),e(jle,Mmo),e(As,Emo),e(As,BN),e(BN,Cmo),e(As,wmo),e(As,NN),e(NN,Amo),e(As,Lmo),e(k,ymo),e(k,Ls),e(Ls,Dle),e(Dle,xmo),e(Ls,$mo),e(Ls,IN),e(IN,kmo),e(Ls,Smo),e(Ls,qN),e(qN,Rmo),e(Ls,Pmo),e(k,Bmo),e(k,ys),e(ys,Gle),e(Gle,Nmo),e(ys,Imo),e(ys,jN),e(jN,qmo),e(ys,jmo),e(ys,DN),e(DN,Dmo),e(ys,Gmo),e(k,Omo),e(k,hh),e(hh,Ole),e(Ole,Vmo),e(hh,Xmo),e(hh,GN),e(GN,zmo),e(hh,Qmo),e(k,Wmo),e(k,xs),e(xs,Vle),e(Vle,Hmo),e(xs,Umo),e(xs,ON),e(ON,Jmo),e(xs,Ymo),e(xs,VN),e(VN,Kmo),e(xs,Zmo),e(k,ego),e(k,ph),e(ph,Xle),e(Xle,ogo),e(ph,rgo),e(ph,XN),e(XN,tgo),e(ph,ago),e(k,ngo),e(k,_h),e(_h,zle),e(zle,sgo),e(_h,lgo),e(_h,zN),e(zN,igo),e(_h,dgo),e(k,cgo),e(k,uh),e(uh,Qle),e(Qle,fgo),e(uh,mgo),e(uh,QN),e(QN,ggo),e(uh,hgo),e(k,pgo),e(k,bh),e(bh,Wle),e(Wle,_go),e(bh,ugo),e(bh,WN),e(WN,bgo),e(bh,vgo),e(k,Fgo),e(k,$s),e($s,Hle),e(Hle,Tgo),e($s,Mgo),e($s,HN),e(HN,Ego),e($s,Cgo),e($s,UN),e(UN,wgo),e($s,Ago),e(k,Lgo),e(k,vh),e(vh,Ule),e(Ule,ygo),e(vh,xgo),e(vh,JN),e(JN,$go),e(vh,kgo),e(k,Sgo),e(k,ks),e(ks,Jle),e(Jle,Rgo),e(ks,Pgo),e(ks,YN),e(YN,Bgo),e(ks,Ngo),e(ks,KN),e(KN,Igo),e(ks,qgo),e(k,jgo),e(k,Ss),e(Ss,Yle),e(Yle,Dgo),e(Ss,Ggo),e(Ss,ZN),e(ZN,Ogo),e(Ss,Vgo),e(Ss,eI),e(eI,Xgo),e(Ss,zgo),e(k,Qgo),e(k,Rs),e(Rs,Kle),e(Kle,Wgo),e(Rs,Hgo),e(Rs,oI),e(oI,Ugo),e(Rs,Jgo),e(Rs,rI),e(rI,Ygo),e(Rs,Kgo),e(k,Zgo),e(k,Ps),e(Ps,Zle),e(Zle,eho),e(Ps,oho),e(Ps,tI),e(tI,rho),e(Ps,tho),e(Ps,aI),e(aI,aho),e(Ps,nho),e(k,sho),e(k,Bs),e(Bs,eie),e(eie,lho),e(Bs,iho),e(Bs,nI),e(nI,dho),e(Bs,cho),e(Bs,sI),e(sI,fho),e(Bs,mho),e(k,gho),e(k,Ns),e(Ns,oie),e(oie,hho),e(Ns,pho),e(Ns,lI),e(lI,_ho),e(Ns,uho),e(Ns,iI),e(iI,bho),e(Ns,vho),e(k,Fho),e(k,Fh),e(Fh,rie),e(rie,Tho),e(Fh,Mho),e(Fh,dI),e(dI,Eho),e(Fh,Cho),e(k,who),e(k,Th),e(Th,tie),e(tie,Aho),e(Th,Lho),e(Th,cI),e(cI,yho),e(Th,xho),e(k,$ho),e(k,Is),e(Is,aie),e(aie,kho),e(Is,Sho),e(Is,fI),e(fI,Rho),e(Is,Pho),e(Is,mI),e(mI,Bho),e(Is,Nho),e(k,Iho),e(k,qs),e(qs,nie),e(nie,qho),e(qs,jho),e(qs,gI),e(gI,Dho),e(qs,Gho),e(qs,hI),e(hI,Oho),e(qs,Vho),e(k,Xho),e(k,js),e(js,sie),e(sie,zho),e(js,Qho),e(js,pI),e(pI,Who),e(js,Hho),e(js,_I),e(_I,Uho),e(js,Jho),e(k,Yho),e(k,Mh),e(Mh,lie),e(lie,Kho),e(Mh,Zho),e(Mh,uI),e(uI,epo),e(Mh,opo),e(k,rpo),e(k,Eh),e(Eh,iie),e(iie,tpo),e(Eh,apo),e(Eh,bI),e(bI,npo),e(Eh,spo),e(k,lpo),e(k,Ch),e(Ch,die),e(die,ipo),e(Ch,dpo),e(Ch,vI),e(vI,cpo),e(Ch,fpo),e(k,mpo),e(k,Ds),e(Ds,cie),e(cie,gpo),e(Ds,hpo),e(Ds,FI),e(FI,ppo),e(Ds,_po),e(Ds,TI),e(TI,upo),e(Ds,bpo),e(k,vpo),e(k,Gs),e(Gs,fie),e(fie,Fpo),e(Gs,Tpo),e(Gs,MI),e(MI,Mpo),e(Gs,Epo),e(Gs,EI),e(EI,Cpo),e(Gs,wpo),e(k,Apo),e(k,wh),e(wh,mie),e(mie,Lpo),e(wh,ypo),e(wh,CI),e(CI,xpo),e(wh,$po),e(k,kpo),e(k,Ah),e(Ah,gie),e(gie,Spo),e(Ah,Rpo),e(Ah,wI),e(wI,Ppo),e(Ah,Bpo),e(k,Npo),e(k,Lh),e(Lh,hie),e(hie,Ipo),e(Lh,qpo),e(Lh,AI),e(AI,jpo),e(Lh,Dpo),e(k,Gpo),e(k,Os),e(Os,pie),e(pie,Opo),e(Os,Vpo),e(Os,LI),e(LI,Xpo),e(Os,zpo),e(Os,yI),e(yI,Qpo),e(Os,Wpo),e(k,Hpo),e(k,yh),e(yh,_ie),e(_ie,Upo),e(yh,Jpo),e(yh,xI),e(xI,Ypo),e(yh,Kpo),e(k,Zpo),e(k,xh),e(xh,uie),e(uie,e_o),e(xh,o_o),e(xh,$I),e($I,r_o),e(xh,t_o),e(k,a_o),e(k,Vs),e(Vs,bie),e(bie,n_o),e(Vs,s_o),e(Vs,kI),e(kI,l_o),e(Vs,i_o),e(Vs,SI),e(SI,d_o),e(Vs,c_o),e(k,f_o),e(k,Xs),e(Xs,vie),e(vie,m_o),e(Xs,g_o),e(Xs,RI),e(RI,h_o),e(Xs,p_o),e(Xs,PI),e(PI,__o),e(Xs,u_o),e(k,b_o),e(k,zs),e(zs,Fie),e(Fie,v_o),e(zs,F_o),e(zs,BI),e(BI,T_o),e(zs,M_o),e(zs,NI),e(NI,E_o),e(zs,C_o),e(k,w_o),e(k,Qs),e(Qs,Tie),e(Tie,A_o),e(Qs,L_o),e(Qs,II),e(II,y_o),e(Qs,x_o),e(Qs,qI),e(qI,$_o),e(Qs,k_o),e(yr,S_o),M($h,yr,null),e(Ao,R_o),e(Ao,kh),M(cy,kh,null),e(kh,P_o),e(kh,Mie),e(Mie,B_o),b(f,kVe,u),b(f,Ni,u),e(Ni,Sh),e(Sh,Eie),M(fy,Eie,null),e(Ni,N_o),e(Ni,Cie),e(Cie,I_o),b(f,SVe,u),b(f,Lo,u),M(my,Lo,null),e(Lo,q_o),e(Lo,gy),e(gy,j_o),e(gy,jI),e(jI,D_o),e(gy,G_o),e(Lo,O_o),e(Lo,hy),e(hy,V_o),e(hy,wie),e(wie,X_o),e(hy,z_o),e(Lo,Q_o),e(Lo,He),M(py,He,null),e(He,W_o),e(He,Aie),e(Aie,H_o),e(He,U_o),e(He,Pa),e(Pa,J_o),e(Pa,Lie),e(Lie,Y_o),e(Pa,K_o),e(Pa,yie),e(yie,Z_o),e(Pa,euo),e(Pa,xie),e(xie,ouo),e(Pa,ruo),e(He,tuo),e(He,Y),e(Y,Rh),e(Rh,$ie),e($ie,auo),e(Rh,nuo),e(Rh,DI),e(DI,suo),e(Rh,luo),e(Y,iuo),e(Y,Ph),e(Ph,kie),e(kie,duo),e(Ph,cuo),e(Ph,GI),e(GI,fuo),e(Ph,muo),e(Y,guo),e(Y,Bh),e(Bh,Sie),e(Sie,huo),e(Bh,puo),e(Bh,OI),e(OI,_uo),e(Bh,uuo),e(Y,buo),e(Y,Nh),e(Nh,Rie),e(Rie,vuo),e(Nh,Fuo),e(Nh,VI),e(VI,Tuo),e(Nh,Muo),e(Y,Euo),e(Y,Ih),e(Ih,Pie),e(Pie,Cuo),e(Ih,wuo),e(Ih,XI),e(XI,Auo),e(Ih,Luo),e(Y,yuo),e(Y,qh),e(qh,Bie),e(Bie,xuo),e(qh,$uo),e(qh,zI),e(zI,kuo),e(qh,Suo),e(Y,Ruo),e(Y,jh),e(jh,Nie),e(Nie,Puo),e(jh,Buo),e(jh,QI),e(QI,Nuo),e(jh,Iuo),e(Y,quo),e(Y,Dh),e(Dh,Iie),e(Iie,juo),e(Dh,Duo),e(Dh,WI),e(WI,Guo),e(Dh,Ouo),e(Y,Vuo),e(Y,Gh),e(Gh,qie),e(qie,Xuo),e(Gh,zuo),e(Gh,HI),e(HI,Quo),e(Gh,Wuo),e(Y,Huo),e(Y,Oh),e(Oh,jie),e(jie,Uuo),e(Oh,Juo),e(Oh,UI),e(UI,Yuo),e(Oh,Kuo),e(Y,Zuo),e(Y,Vh),e(Vh,Die),e(Die,e2o),e(Vh,o2o),e(Vh,JI),e(JI,r2o),e(Vh,t2o),e(Y,a2o),e(Y,Xh),e(Xh,Gie),e(Gie,n2o),e(Xh,s2o),e(Xh,YI),e(YI,l2o),e(Xh,i2o),e(Y,d2o),e(Y,zh),e(zh,Oie),e(Oie,c2o),e(zh,f2o),e(zh,KI),e(KI,m2o),e(zh,g2o),e(Y,h2o),e(Y,Qh),e(Qh,Vie),e(Vie,p2o),e(Qh,_2o),e(Qh,ZI),e(ZI,u2o),e(Qh,b2o),e(Y,v2o),e(Y,Wh),e(Wh,Xie),e(Xie,F2o),e(Wh,T2o),e(Wh,eq),e(eq,M2o),e(Wh,E2o),e(Y,C2o),e(Y,Hh),e(Hh,zie),e(zie,w2o),e(Hh,A2o),e(Hh,oq),e(oq,L2o),e(Hh,y2o),e(Y,x2o),e(Y,Uh),e(Uh,Qie),e(Qie,$2o),e(Uh,k2o),e(Uh,rq),e(rq,S2o),e(Uh,R2o),e(Y,P2o),e(Y,Jh),e(Jh,Wie),e(Wie,B2o),e(Jh,N2o),e(Jh,tq),e(tq,I2o),e(Jh,q2o),e(Y,j2o),e(Y,Yh),e(Yh,Hie),e(Hie,D2o),e(Yh,G2o),e(Yh,aq),e(aq,O2o),e(Yh,V2o),e(Y,X2o),e(Y,Kh),e(Kh,Uie),e(Uie,z2o),e(Kh,Q2o),e(Kh,nq),e(nq,W2o),e(Kh,H2o),e(Y,U2o),e(Y,Zh),e(Zh,Jie),e(Jie,J2o),e(Zh,Y2o),e(Zh,sq),e(sq,K2o),e(Zh,Z2o),e(Y,e1o),e(Y,ep),e(ep,Yie),e(Yie,o1o),e(ep,r1o),e(ep,lq),e(lq,t1o),e(ep,a1o),e(Y,n1o),e(Y,op),e(op,Kie),e(Kie,s1o),e(op,l1o),e(op,iq),e(iq,i1o),e(op,d1o),e(Y,c1o),e(Y,rp),e(rp,Zie),e(Zie,f1o),e(rp,m1o),e(rp,dq),e(dq,g1o),e(rp,h1o),e(Y,p1o),e(Y,tp),e(tp,ede),e(ede,_1o),e(tp,u1o),e(tp,cq),e(cq,b1o),e(tp,v1o),e(Y,F1o),e(Y,ap),e(ap,ode),e(ode,T1o),e(ap,M1o),e(ap,fq),e(fq,E1o),e(ap,C1o),e(Y,w1o),e(Y,np),e(np,rde),e(rde,A1o),e(np,L1o),e(np,mq),e(mq,y1o),e(np,x1o),e(Y,$1o),e(Y,sp),e(sp,tde),e(tde,k1o),e(sp,S1o),e(sp,gq),e(gq,R1o),e(sp,P1o),e(Y,B1o),e(Y,lp),e(lp,ade),e(ade,N1o),e(lp,I1o),e(lp,hq),e(hq,q1o),e(lp,j1o),e(Y,D1o),e(Y,ip),e(ip,nde),e(nde,G1o),e(ip,O1o),e(ip,pq),e(pq,V1o),e(ip,X1o),e(Y,z1o),e(Y,dp),e(dp,sde),e(sde,Q1o),e(dp,W1o),e(dp,_q),e(_q,H1o),e(dp,U1o),e(Y,J1o),e(Y,cp),e(cp,lde),e(lde,Y1o),e(cp,K1o),e(cp,uq),e(uq,Z1o),e(cp,e7o),e(Y,o7o),e(Y,fp),e(fp,ide),e(ide,r7o),e(fp,t7o),e(fp,bq),e(bq,a7o),e(fp,n7o),e(He,s7o),M(mp,He,null),e(He,l7o),M(gp,He,null),e(Lo,i7o),e(Lo,hp),M(_y,hp,null),e(hp,d7o),e(hp,dde),e(dde,c7o),b(f,RVe,u),b(f,Ii,u),e(Ii,pp),e(pp,cde),M(uy,cde,null),e(Ii,f7o),e(Ii,fde),e(fde,m7o),b(f,PVe,u),b(f,yo,u),M(by,yo,null),e(yo,g7o),e(yo,vy),e(vy,h7o),e(vy,vq),e(vq,p7o),e(vy,_7o),e(yo,u7o),e(yo,Fy),e(Fy,b7o),e(Fy,mde),e(mde,v7o),e(Fy,F7o),e(yo,T7o),e(yo,Ue),M(Ty,Ue,null),e(Ue,M7o),e(Ue,gde),e(gde,E7o),e(Ue,C7o),e(Ue,qi),e(qi,w7o),e(qi,hde),e(hde,A7o),e(qi,L7o),e(qi,pde),e(pde,y7o),e(qi,x7o),e(Ue,$7o),e(Ue,he),e(he,_p),e(_p,_de),e(_de,k7o),e(_p,S7o),e(_p,Fq),e(Fq,R7o),e(_p,P7o),e(he,B7o),e(he,up),e(up,ude),e(ude,N7o),e(up,I7o),e(up,bde),e(bde,q7o),e(up,j7o),e(he,D7o),e(he,bp),e(bp,vde),e(vde,G7o),e(bp,O7o),e(bp,Tq),e(Tq,V7o),e(bp,X7o),e(he,z7o),e(he,vp),e(vp,Fde),e(Fde,Q7o),e(vp,W7o),e(vp,Mq),e(Mq,H7o),e(vp,U7o),e(he,J7o),e(he,Fp),e(Fp,Tde),e(Tde,Y7o),e(Fp,K7o),e(Fp,Eq),e(Eq,Z7o),e(Fp,e4o),e(he,o4o),e(he,Tp),e(Tp,Mde),e(Mde,r4o),e(Tp,t4o),e(Tp,Cq),e(Cq,a4o),e(Tp,n4o),e(he,s4o),e(he,Mp),e(Mp,Ede),e(Ede,l4o),e(Mp,i4o),e(Mp,wq),e(wq,d4o),e(Mp,c4o),e(he,f4o),e(he,Ep),e(Ep,Cde),e(Cde,m4o),e(Ep,g4o),e(Ep,Aq),e(Aq,h4o),e(Ep,p4o),e(he,_4o),e(he,Cp),e(Cp,wde),e(wde,u4o),e(Cp,b4o),e(Cp,Lq),e(Lq,v4o),e(Cp,F4o),e(he,T4o),e(he,wp),e(wp,Ade),e(Ade,M4o),e(wp,E4o),e(wp,yq),e(yq,C4o),e(wp,w4o),e(he,A4o),e(he,Ap),e(Ap,Lde),e(Lde,L4o),e(Ap,y4o),e(Ap,xq),e(xq,x4o),e(Ap,$4o),e(he,k4o),e(he,Lp),e(Lp,yde),e(yde,S4o),e(Lp,R4o),e(Lp,$q),e($q,P4o),e(Lp,B4o),e(he,N4o),e(he,yp),e(yp,xde),e(xde,I4o),e(yp,q4o),e(yp,kq),e(kq,j4o),e(yp,D4o),e(he,G4o),e(he,xp),e(xp,$de),e($de,O4o),e(xp,V4o),e(xp,Sq),e(Sq,X4o),e(xp,z4o),e(he,Q4o),e(he,$p),e($p,kde),e(kde,W4o),e($p,H4o),e($p,Rq),e(Rq,U4o),e($p,J4o),e(he,Y4o),e(he,kp),e(kp,Sde),e(Sde,K4o),e(kp,Z4o),e(kp,Pq),e(Pq,ebo),e(kp,obo),e(he,rbo),e(he,Sp),e(Sp,Rde),e(Rde,tbo),e(Sp,abo),e(Sp,Bq),e(Bq,nbo),e(Sp,sbo),e(he,lbo),e(he,Rp),e(Rp,Pde),e(Pde,ibo),e(Rp,dbo),e(Rp,Nq),e(Nq,cbo),e(Rp,fbo),e(Ue,mbo),M(Pp,Ue,null),e(Ue,gbo),M(Bp,Ue,null),e(yo,hbo),e(yo,Np),M(My,Np,null),e(Np,pbo),e(Np,Bde),e(Bde,_bo),b(f,BVe,u),b(f,ji,u),e(ji,Ip),e(Ip,Nde),M(Ey,Nde,null),e(ji,ubo),e(ji,Ide),e(Ide,bbo),b(f,NVe,u),b(f,xo,u),M(Cy,xo,null),e(xo,vbo),e(xo,Di),e(Di,Fbo),e(Di,Iq),e(Iq,Tbo),e(Di,Mbo),e(Di,qq),e(qq,Ebo),e(Di,Cbo),e(xo,wbo),e(xo,wy),e(wy,Abo),e(wy,qde),e(qde,Lbo),e(wy,ybo),e(xo,xbo),e(xo,st),M(Ay,st,null),e(st,$bo),e(st,jde),e(jde,kbo),e(st,Sbo),e(st,Gi),e(Gi,Rbo),e(Gi,Dde),e(Dde,Pbo),e(Gi,Bbo),e(Gi,jq),e(jq,Nbo),e(Gi,Ibo),e(st,qbo),M(qp,st,null),e(xo,jbo),e(xo,Je),M(Ly,Je,null),e(Je,Dbo),e(Je,Gde),e(Gde,Gbo),e(Je,Obo),e(Je,Ba),e(Ba,Vbo),e(Ba,Ode),e(Ode,Xbo),e(Ba,zbo),e(Ba,Vde),e(Vde,Qbo),e(Ba,Wbo),e(Ba,Xde),e(Xde,Hbo),e(Ba,Ubo),e(Je,Jbo),e(Je,y),e(y,jp),e(jp,zde),e(zde,Ybo),e(jp,Kbo),e(jp,Dq),e(Dq,Zbo),e(jp,evo),e(y,ovo),e(y,Dp),e(Dp,Qde),e(Qde,rvo),e(Dp,tvo),e(Dp,Gq),e(Gq,avo),e(Dp,nvo),e(y,svo),e(y,Gp),e(Gp,Wde),e(Wde,lvo),e(Gp,ivo),e(Gp,Oq),e(Oq,dvo),e(Gp,cvo),e(y,fvo),e(y,Op),e(Op,Hde),e(Hde,mvo),e(Op,gvo),e(Op,Vq),e(Vq,hvo),e(Op,pvo),e(y,_vo),e(y,Vp),e(Vp,Ude),e(Ude,uvo),e(Vp,bvo),e(Vp,Xq),e(Xq,vvo),e(Vp,Fvo),e(y,Tvo),e(y,Xp),e(Xp,Jde),e(Jde,Mvo),e(Xp,Evo),e(Xp,zq),e(zq,Cvo),e(Xp,wvo),e(y,Avo),e(y,zp),e(zp,Yde),e(Yde,Lvo),e(zp,yvo),e(zp,Qq),e(Qq,xvo),e(zp,$vo),e(y,kvo),e(y,Qp),e(Qp,Kde),e(Kde,Svo),e(Qp,Rvo),e(Qp,Wq),e(Wq,Pvo),e(Qp,Bvo),e(y,Nvo),e(y,Wp),e(Wp,Zde),e(Zde,Ivo),e(Wp,qvo),e(Wp,Hq),e(Hq,jvo),e(Wp,Dvo),e(y,Gvo),e(y,Hp),e(Hp,ece),e(ece,Ovo),e(Hp,Vvo),e(Hp,Uq),e(Uq,Xvo),e(Hp,zvo),e(y,Qvo),e(y,Up),e(Up,oce),e(oce,Wvo),e(Up,Hvo),e(Up,Jq),e(Jq,Uvo),e(Up,Jvo),e(y,Yvo),e(y,Jp),e(Jp,rce),e(rce,Kvo),e(Jp,Zvo),e(Jp,Yq),e(Yq,eFo),e(Jp,oFo),e(y,rFo),e(y,Yp),e(Yp,tce),e(tce,tFo),e(Yp,aFo),e(Yp,Kq),e(Kq,nFo),e(Yp,sFo),e(y,lFo),e(y,Kp),e(Kp,ace),e(ace,iFo),e(Kp,dFo),e(Kp,Zq),e(Zq,cFo),e(Kp,fFo),e(y,mFo),e(y,Zp),e(Zp,nce),e(nce,gFo),e(Zp,hFo),e(Zp,ej),e(ej,pFo),e(Zp,_Fo),e(y,uFo),e(y,e_),e(e_,sce),e(sce,bFo),e(e_,vFo),e(e_,oj),e(oj,FFo),e(e_,TFo),e(y,MFo),e(y,o_),e(o_,lce),e(lce,EFo),e(o_,CFo),e(o_,rj),e(rj,wFo),e(o_,AFo),e(y,LFo),e(y,r_),e(r_,ice),e(ice,yFo),e(r_,xFo),e(r_,tj),e(tj,$Fo),e(r_,kFo),e(y,SFo),e(y,t_),e(t_,dce),e(dce,RFo),e(t_,PFo),e(t_,aj),e(aj,BFo),e(t_,NFo),e(y,IFo),e(y,a_),e(a_,cce),e(cce,qFo),e(a_,jFo),e(a_,nj),e(nj,DFo),e(a_,GFo),e(y,OFo),e(y,n_),e(n_,fce),e(fce,VFo),e(n_,XFo),e(n_,sj),e(sj,zFo),e(n_,QFo),e(y,WFo),e(y,s_),e(s_,mce),e(mce,HFo),e(s_,UFo),e(s_,lj),e(lj,JFo),e(s_,YFo),e(y,KFo),e(y,l_),e(l_,gce),e(gce,ZFo),e(l_,eTo),e(l_,ij),e(ij,oTo),e(l_,rTo),e(y,tTo),e(y,i_),e(i_,hce),e(hce,aTo),e(i_,nTo),e(i_,dj),e(dj,sTo),e(i_,lTo),e(y,iTo),e(y,d_),e(d_,pce),e(pce,dTo),e(d_,cTo),e(d_,cj),e(cj,fTo),e(d_,mTo),e(y,gTo),e(y,c_),e(c_,_ce),e(_ce,hTo),e(c_,pTo),e(c_,fj),e(fj,_To),e(c_,uTo),e(y,bTo),e(y,f_),e(f_,uce),e(uce,vTo),e(f_,FTo),e(f_,mj),e(mj,TTo),e(f_,MTo),e(y,ETo),e(y,m_),e(m_,bce),e(bce,CTo),e(m_,wTo),e(m_,gj),e(gj,ATo),e(m_,LTo),e(y,yTo),e(y,g_),e(g_,vce),e(vce,xTo),e(g_,$To),e(g_,hj),e(hj,kTo),e(g_,STo),e(y,RTo),e(y,h_),e(h_,Fce),e(Fce,PTo),e(h_,BTo),e(h_,pj),e(pj,NTo),e(h_,ITo),e(y,qTo),e(y,p_),e(p_,Tce),e(Tce,jTo),e(p_,DTo),e(p_,_j),e(_j,GTo),e(p_,OTo),e(y,VTo),e(y,__),e(__,Mce),e(Mce,XTo),e(__,zTo),e(__,uj),e(uj,QTo),e(__,WTo),e(y,HTo),e(y,u_),e(u_,Ece),e(Ece,UTo),e(u_,JTo),e(u_,bj),e(bj,YTo),e(u_,KTo),e(y,ZTo),e(y,b_),e(b_,Cce),e(Cce,eMo),e(b_,oMo),e(b_,vj),e(vj,rMo),e(b_,tMo),e(y,aMo),e(y,Ws),e(Ws,wce),e(wce,nMo),e(Ws,sMo),e(Ws,Fj),e(Fj,lMo),e(Ws,iMo),e(Ws,Tj),e(Tj,dMo),e(Ws,cMo),e(y,fMo),e(y,v_),e(v_,Ace),e(Ace,mMo),e(v_,gMo),e(v_,Mj),e(Mj,hMo),e(v_,pMo),e(y,_Mo),e(y,F_),e(F_,Lce),e(Lce,uMo),e(F_,bMo),e(F_,Ej),e(Ej,vMo),e(F_,FMo),e(y,TMo),e(y,T_),e(T_,yce),e(yce,MMo),e(T_,EMo),e(T_,Cj),e(Cj,CMo),e(T_,wMo),e(y,AMo),e(y,M_),e(M_,xce),e(xce,LMo),e(M_,yMo),e(M_,wj),e(wj,xMo),e(M_,$Mo),e(y,kMo),e(y,E_),e(E_,$ce),e($ce,SMo),e(E_,RMo),e(E_,Aj),e(Aj,PMo),e(E_,BMo),e(y,NMo),e(y,C_),e(C_,kce),e(kce,IMo),e(C_,qMo),e(C_,Lj),e(Lj,jMo),e(C_,DMo),e(y,GMo),e(y,w_),e(w_,Sce),e(Sce,OMo),e(w_,VMo),e(w_,yj),e(yj,XMo),e(w_,zMo),e(y,QMo),e(y,A_),e(A_,Rce),e(Rce,WMo),e(A_,HMo),e(A_,xj),e(xj,UMo),e(A_,JMo),e(y,YMo),e(y,L_),e(L_,Pce),e(Pce,KMo),e(L_,ZMo),e(L_,$j),e($j,eEo),e(L_,oEo),e(y,rEo),e(y,y_),e(y_,Bce),e(Bce,tEo),e(y_,aEo),e(y_,kj),e(kj,nEo),e(y_,sEo),e(y,lEo),e(y,x_),e(x_,Nce),e(Nce,iEo),e(x_,dEo),e(x_,Sj),e(Sj,cEo),e(x_,fEo),e(y,mEo),e(y,$_),e($_,Ice),e(Ice,gEo),e($_,hEo),e($_,Rj),e(Rj,pEo),e($_,_Eo),e(y,uEo),e(y,k_),e(k_,qce),e(qce,bEo),e(k_,vEo),e(k_,Pj),e(Pj,FEo),e(k_,TEo),e(y,MEo),e(y,S_),e(S_,jce),e(jce,EEo),e(S_,CEo),e(S_,Bj),e(Bj,wEo),e(S_,AEo),e(y,LEo),e(y,R_),e(R_,Dce),e(Dce,yEo),e(R_,xEo),e(R_,Nj),e(Nj,$Eo),e(R_,kEo),e(y,SEo),e(y,P_),e(P_,Gce),e(Gce,REo),e(P_,PEo),e(P_,Ij),e(Ij,BEo),e(P_,NEo),e(y,IEo),e(y,B_),e(B_,Oce),e(Oce,qEo),e(B_,jEo),e(B_,qj),e(qj,DEo),e(B_,GEo),e(y,OEo),e(y,N_),e(N_,Vce),e(Vce,VEo),e(N_,XEo),e(N_,jj),e(jj,zEo),e(N_,QEo),e(y,WEo),e(y,I_),e(I_,Xce),e(Xce,HEo),e(I_,UEo),e(I_,Dj),e(Dj,JEo),e(I_,YEo),e(y,KEo),e(y,q_),e(q_,zce),e(zce,ZEo),e(q_,eCo),e(q_,Gj),e(Gj,oCo),e(q_,rCo),e(y,tCo),e(y,j_),e(j_,Qce),e(Qce,aCo),e(j_,nCo),e(j_,Oj),e(Oj,sCo),e(j_,lCo),e(y,iCo),e(y,D_),e(D_,Wce),e(Wce,dCo),e(D_,cCo),e(D_,Vj),e(Vj,fCo),e(D_,mCo),e(y,gCo),e(y,G_),e(G_,Hce),e(Hce,hCo),e(G_,pCo),e(G_,Xj),e(Xj,_Co),e(G_,uCo),e(y,bCo),e(y,O_),e(O_,Uce),e(Uce,vCo),e(O_,FCo),e(O_,zj),e(zj,TCo),e(O_,MCo),e(y,ECo),e(y,V_),e(V_,Jce),e(Jce,CCo),e(V_,wCo),e(V_,Qj),e(Qj,ACo),e(V_,LCo),e(y,yCo),e(y,X_),e(X_,Yce),e(Yce,xCo),e(X_,$Co),e(X_,Wj),e(Wj,kCo),e(X_,SCo),e(y,RCo),e(y,z_),e(z_,Kce),e(Kce,PCo),e(z_,BCo),e(z_,Hj),e(Hj,NCo),e(z_,ICo),e(y,qCo),e(y,Q_),e(Q_,Zce),e(Zce,jCo),e(Q_,DCo),e(Q_,Uj),e(Uj,GCo),e(Q_,OCo),e(y,VCo),e(y,W_),e(W_,efe),e(efe,XCo),e(W_,zCo),e(W_,Jj),e(Jj,QCo),e(W_,WCo),e(y,HCo),e(y,H_),e(H_,ofe),e(ofe,UCo),e(H_,JCo),e(H_,Yj),e(Yj,YCo),e(H_,KCo),e(y,ZCo),e(y,U_),e(U_,rfe),e(rfe,e3o),e(U_,o3o),e(U_,Kj),e(Kj,r3o),e(U_,t3o),e(y,a3o),e(y,J_),e(J_,tfe),e(tfe,n3o),e(J_,s3o),e(J_,Zj),e(Zj,l3o),e(J_,i3o),e(y,d3o),e(y,Y_),e(Y_,afe),e(afe,c3o),e(Y_,f3o),e(Y_,eD),e(eD,m3o),e(Y_,g3o),e(y,h3o),e(y,K_),e(K_,nfe),e(nfe,p3o),e(K_,_3o),e(K_,oD),e(oD,u3o),e(K_,b3o),e(y,v3o),e(y,Z_),e(Z_,sfe),e(sfe,F3o),e(Z_,T3o),e(Z_,rD),e(rD,M3o),e(Z_,E3o),e(y,C3o),e(y,eu),e(eu,lfe),e(lfe,w3o),e(eu,A3o),e(eu,tD),e(tD,L3o),e(eu,y3o),e(y,x3o),e(y,ou),e(ou,ife),e(ife,$3o),e(ou,k3o),e(ou,aD),e(aD,S3o),e(ou,R3o),e(y,P3o),e(y,ru),e(ru,dfe),e(dfe,B3o),e(ru,N3o),e(ru,nD),e(nD,I3o),e(ru,q3o),e(y,j3o),e(y,tu),e(tu,cfe),e(cfe,D3o),e(tu,G3o),e(tu,sD),e(sD,O3o),e(tu,V3o),e(y,X3o),e(y,au),e(au,ffe),e(ffe,z3o),e(au,Q3o),e(au,lD),e(lD,W3o),e(au,H3o),e(y,U3o),e(y,nu),e(nu,mfe),e(mfe,J3o),e(nu,Y3o),e(nu,iD),e(iD,K3o),e(nu,Z3o),e(y,e5o),e(y,su),e(su,gfe),e(gfe,o5o),e(su,r5o),e(su,dD),e(dD,t5o),e(su,a5o),e(y,n5o),e(y,lu),e(lu,hfe),e(hfe,s5o),e(lu,l5o),e(lu,cD),e(cD,i5o),e(lu,d5o),e(y,c5o),e(y,iu),e(iu,pfe),e(pfe,f5o),e(iu,m5o),e(iu,fD),e(fD,g5o),e(iu,h5o),e(y,p5o),e(y,du),e(du,_fe),e(_fe,_5o),e(du,u5o),e(du,mD),e(mD,b5o),e(du,v5o),e(y,F5o),e(y,cu),e(cu,ufe),e(ufe,T5o),e(cu,M5o),e(cu,gD),e(gD,E5o),e(cu,C5o),e(y,w5o),e(y,fu),e(fu,bfe),e(bfe,A5o),e(fu,L5o),e(fu,hD),e(hD,y5o),e(fu,x5o),e(y,$5o),e(y,mu),e(mu,vfe),e(vfe,k5o),e(mu,S5o),e(mu,pD),e(pD,R5o),e(mu,P5o),e(y,B5o),e(y,gu),e(gu,Ffe),e(Ffe,N5o),e(gu,I5o),e(gu,_D),e(_D,q5o),e(gu,j5o),e(y,D5o),e(y,hu),e(hu,Tfe),e(Tfe,G5o),e(hu,O5o),e(hu,uD),e(uD,V5o),e(hu,X5o),e(y,z5o),e(y,pu),e(pu,Mfe),e(Mfe,Q5o),e(pu,W5o),e(pu,bD),e(bD,H5o),e(pu,U5o),e(y,J5o),e(y,_u),e(_u,Efe),e(Efe,Y5o),e(_u,K5o),e(_u,vD),e(vD,Z5o),e(_u,e0o),e(y,o0o),e(y,uu),e(uu,Cfe),e(Cfe,r0o),e(uu,t0o),e(uu,FD),e(FD,a0o),e(uu,n0o),e(y,s0o),e(y,bu),e(bu,wfe),e(wfe,l0o),e(bu,i0o),e(bu,TD),e(TD,d0o),e(bu,c0o),e(y,f0o),e(y,vu),e(vu,Afe),e(Afe,m0o),e(vu,g0o),e(vu,MD),e(MD,h0o),e(vu,p0o),e(y,_0o),e(y,Fu),e(Fu,Lfe),e(Lfe,u0o),e(Fu,b0o),e(Fu,ED),e(ED,v0o),e(Fu,F0o),e(y,T0o),e(y,Tu),e(Tu,yfe),e(yfe,M0o),e(Tu,E0o),e(Tu,CD),e(CD,C0o),e(Tu,w0o),e(y,A0o),e(y,Mu),e(Mu,xfe),e(xfe,L0o),e(Mu,y0o),e(Mu,wD),e(wD,x0o),e(Mu,$0o),e(y,k0o),e(y,Eu),e(Eu,$fe),e($fe,S0o),e(Eu,R0o),e(Eu,AD),e(AD,P0o),e(Eu,B0o),e(y,N0o),e(y,Cu),e(Cu,kfe),e(kfe,I0o),e(Cu,q0o),e(Cu,LD),e(LD,j0o),e(Cu,D0o),e(y,G0o),e(y,wu),e(wu,Sfe),e(Sfe,O0o),e(wu,V0o),e(wu,yD),e(yD,X0o),e(wu,z0o),e(y,Q0o),e(y,Au),e(Au,Rfe),e(Rfe,W0o),e(Au,H0o),e(Au,xD),e(xD,U0o),e(Au,J0o),e(y,Y0o),e(y,Lu),e(Lu,Pfe),e(Pfe,K0o),e(Lu,Z0o),e(Lu,$D),e($D,ewo),e(Lu,owo),e(y,rwo),e(y,yu),e(yu,Bfe),e(Bfe,two),e(yu,awo),e(yu,kD),e(kD,nwo),e(yu,swo),e(y,lwo),e(y,xu),e(xu,Nfe),e(Nfe,iwo),e(xu,dwo),e(xu,SD),e(SD,cwo),e(xu,fwo),e(y,mwo),e(y,$u),e($u,Ife),e(Ife,gwo),e($u,hwo),e($u,RD),e(RD,pwo),e($u,_wo),e(y,uwo),e(y,ku),e(ku,qfe),e(qfe,bwo),e(ku,vwo),e(ku,PD),e(PD,Fwo),e(ku,Two),e(y,Mwo),e(y,Su),e(Su,jfe),e(jfe,Ewo),e(Su,Cwo),e(Su,BD),e(BD,wwo),e(Su,Awo),e(y,Lwo),e(y,Ru),e(Ru,Dfe),e(Dfe,ywo),e(Ru,xwo),e(Ru,ND),e(ND,$wo),e(Ru,kwo),e(y,Swo),e(y,Pu),e(Pu,Gfe),e(Gfe,Rwo),e(Pu,Pwo),e(Pu,ID),e(ID,Bwo),e(Pu,Nwo),e(y,Iwo),e(y,Bu),e(Bu,Ofe),e(Ofe,qwo),e(Bu,jwo),e(Bu,qD),e(qD,Dwo),e(Bu,Gwo),e(y,Owo),e(y,Nu),e(Nu,Vfe),e(Vfe,Vwo),e(Nu,Xwo),e(Nu,jD),e(jD,zwo),e(Nu,Qwo),e(y,Wwo),e(y,Iu),e(Iu,Xfe),e(Xfe,Hwo),e(Iu,Uwo),e(Iu,DD),e(DD,Jwo),e(Iu,Ywo),e(y,Kwo),e(y,qu),e(qu,zfe),e(zfe,Zwo),e(qu,eAo),e(qu,GD),e(GD,oAo),e(qu,rAo),e(y,tAo),e(y,ju),e(ju,Qfe),e(Qfe,aAo),e(ju,nAo),e(ju,OD),e(OD,sAo),e(ju,lAo),e(Je,iAo),e(Je,Du),e(Du,dAo),e(Du,Wfe),e(Wfe,cAo),e(Du,fAo),e(Du,Hfe),e(Hfe,mAo),e(Je,gAo),M(Gu,Je,null),b(f,IVe,u),b(f,Oi,u),e(Oi,Ou),e(Ou,Ufe),M(yy,Ufe,null),e(Oi,hAo),e(Oi,Jfe),e(Jfe,pAo),b(f,qVe,u),b(f,$o,u),M(xy,$o,null),e($o,_Ao),e($o,Vi),e(Vi,uAo),e(Vi,VD),e(VD,bAo),e(Vi,vAo),e(Vi,XD),e(XD,FAo),e(Vi,TAo),e($o,MAo),e($o,$y),e($y,EAo),e($y,Yfe),e(Yfe,CAo),e($y,wAo),e($o,AAo),e($o,lt),M(ky,lt,null),e(lt,LAo),e(lt,Kfe),e(Kfe,yAo),e(lt,xAo),e(lt,Xi),e(Xi,$Ao),e(Xi,Zfe),e(Zfe,kAo),e(Xi,SAo),e(Xi,zD),e(zD,RAo),e(Xi,PAo),e(lt,BAo),M(Vu,lt,null),e($o,NAo),e($o,Ye),M(Sy,Ye,null),e(Ye,IAo),e(Ye,eme),e(eme,qAo),e(Ye,jAo),e(Ye,Na),e(Na,DAo),e(Na,ome),e(ome,GAo),e(Na,OAo),e(Na,rme),e(rme,VAo),e(Na,XAo),e(Na,tme),e(tme,zAo),e(Na,QAo),e(Ye,WAo),e(Ye,G),e(G,Xu),e(Xu,ame),e(ame,HAo),e(Xu,UAo),e(Xu,QD),e(QD,JAo),e(Xu,YAo),e(G,KAo),e(G,zu),e(zu,nme),e(nme,ZAo),e(zu,e6o),e(zu,WD),e(WD,o6o),e(zu,r6o),e(G,t6o),e(G,Qu),e(Qu,sme),e(sme,a6o),e(Qu,n6o),e(Qu,HD),e(HD,s6o),e(Qu,l6o),e(G,i6o),e(G,Wu),e(Wu,lme),e(lme,d6o),e(Wu,c6o),e(Wu,UD),e(UD,f6o),e(Wu,m6o),e(G,g6o),e(G,Hu),e(Hu,ime),e(ime,h6o),e(Hu,p6o),e(Hu,JD),e(JD,_6o),e(Hu,u6o),e(G,b6o),e(G,Uu),e(Uu,dme),e(dme,v6o),e(Uu,F6o),e(Uu,YD),e(YD,T6o),e(Uu,M6o),e(G,E6o),e(G,Ju),e(Ju,cme),e(cme,C6o),e(Ju,w6o),e(Ju,KD),e(KD,A6o),e(Ju,L6o),e(G,y6o),e(G,Yu),e(Yu,fme),e(fme,x6o),e(Yu,$6o),e(Yu,ZD),e(ZD,k6o),e(Yu,S6o),e(G,R6o),e(G,Ku),e(Ku,mme),e(mme,P6o),e(Ku,B6o),e(Ku,eG),e(eG,N6o),e(Ku,I6o),e(G,q6o),e(G,Zu),e(Zu,gme),e(gme,j6o),e(Zu,D6o),e(Zu,oG),e(oG,G6o),e(Zu,O6o),e(G,V6o),e(G,e2),e(e2,hme),e(hme,X6o),e(e2,z6o),e(e2,rG),e(rG,Q6o),e(e2,W6o),e(G,H6o),e(G,o2),e(o2,pme),e(pme,U6o),e(o2,J6o),e(o2,tG),e(tG,Y6o),e(o2,K6o),e(G,Z6o),e(G,r2),e(r2,_me),e(_me,eLo),e(r2,oLo),e(r2,aG),e(aG,rLo),e(r2,tLo),e(G,aLo),e(G,t2),e(t2,ume),e(ume,nLo),e(t2,sLo),e(t2,nG),e(nG,lLo),e(t2,iLo),e(G,dLo),e(G,a2),e(a2,bme),e(bme,cLo),e(a2,fLo),e(a2,sG),e(sG,mLo),e(a2,gLo),e(G,hLo),e(G,n2),e(n2,vme),e(vme,pLo),e(n2,_Lo),e(n2,lG),e(lG,uLo),e(n2,bLo),e(G,vLo),e(G,s2),e(s2,Fme),e(Fme,FLo),e(s2,TLo),e(s2,iG),e(iG,MLo),e(s2,ELo),e(G,CLo),e(G,l2),e(l2,Tme),e(Tme,wLo),e(l2,ALo),e(l2,dG),e(dG,LLo),e(l2,yLo),e(G,xLo),e(G,i2),e(i2,Mme),e(Mme,$Lo),e(i2,kLo),e(i2,cG),e(cG,SLo),e(i2,RLo),e(G,PLo),e(G,d2),e(d2,Eme),e(Eme,BLo),e(d2,NLo),e(d2,fG),e(fG,ILo),e(d2,qLo),e(G,jLo),e(G,c2),e(c2,Cme),e(Cme,DLo),e(c2,GLo),e(c2,mG),e(mG,OLo),e(c2,VLo),e(G,XLo),e(G,f2),e(f2,wme),e(wme,zLo),e(f2,QLo),e(f2,gG),e(gG,WLo),e(f2,HLo),e(G,ULo),e(G,m2),e(m2,Ame),e(Ame,JLo),e(m2,YLo),e(m2,hG),e(hG,KLo),e(m2,ZLo),e(G,eyo),e(G,g2),e(g2,Lme),e(Lme,oyo),e(g2,ryo),e(g2,pG),e(pG,tyo),e(g2,ayo),e(G,nyo),e(G,h2),e(h2,yme),e(yme,syo),e(h2,lyo),e(h2,_G),e(_G,iyo),e(h2,dyo),e(G,cyo),e(G,p2),e(p2,xme),e(xme,fyo),e(p2,myo),e(p2,uG),e(uG,gyo),e(p2,hyo),e(G,pyo),e(G,_2),e(_2,$me),e($me,_yo),e(_2,uyo),e(_2,bG),e(bG,byo),e(_2,vyo),e(G,Fyo),e(G,u2),e(u2,kme),e(kme,Tyo),e(u2,Myo),e(u2,vG),e(vG,Eyo),e(u2,Cyo),e(G,wyo),e(G,b2),e(b2,Sme),e(Sme,Ayo),e(b2,Lyo),e(b2,FG),e(FG,yyo),e(b2,xyo),e(G,$yo),e(G,v2),e(v2,Rme),e(Rme,kyo),e(v2,Syo),e(v2,TG),e(TG,Ryo),e(v2,Pyo),e(G,Byo),e(G,F2),e(F2,Pme),e(Pme,Nyo),e(F2,Iyo),e(F2,MG),e(MG,qyo),e(F2,jyo),e(G,Dyo),e(G,T2),e(T2,Bme),e(Bme,Gyo),e(T2,Oyo),e(T2,EG),e(EG,Vyo),e(T2,Xyo),e(G,zyo),e(G,M2),e(M2,Nme),e(Nme,Qyo),e(M2,Wyo),e(M2,CG),e(CG,Hyo),e(M2,Uyo),e(G,Jyo),e(G,E2),e(E2,Ime),e(Ime,Yyo),e(E2,Kyo),e(E2,wG),e(wG,Zyo),e(E2,e8o),e(G,o8o),e(G,C2),e(C2,qme),e(qme,r8o),e(C2,t8o),e(C2,AG),e(AG,a8o),e(C2,n8o),e(G,s8o),e(G,w2),e(w2,jme),e(jme,l8o),e(w2,i8o),e(w2,LG),e(LG,d8o),e(w2,c8o),e(G,f8o),e(G,A2),e(A2,Dme),e(Dme,m8o),e(A2,g8o),e(A2,yG),e(yG,h8o),e(A2,p8o),e(G,_8o),e(G,L2),e(L2,Gme),e(Gme,u8o),e(L2,b8o),e(L2,xG),e(xG,v8o),e(L2,F8o),e(G,T8o),e(G,y2),e(y2,Ome),e(Ome,M8o),e(y2,E8o),e(y2,$G),e($G,C8o),e(y2,w8o),e(G,A8o),e(G,x2),e(x2,Vme),e(Vme,L8o),e(x2,y8o),e(x2,kG),e(kG,x8o),e(x2,$8o),e(G,k8o),e(G,$2),e($2,Xme),e(Xme,S8o),e($2,R8o),e($2,SG),e(SG,P8o),e($2,B8o),e(G,N8o),e(G,k2),e(k2,zme),e(zme,I8o),e(k2,q8o),e(k2,RG),e(RG,j8o),e(k2,D8o),e(G,G8o),e(G,S2),e(S2,Qme),e(Qme,O8o),e(S2,V8o),e(S2,PG),e(PG,X8o),e(S2,z8o),e(G,Q8o),e(G,R2),e(R2,Wme),e(Wme,W8o),e(R2,H8o),e(R2,BG),e(BG,U8o),e(R2,J8o),e(G,Y8o),e(G,P2),e(P2,Hme),e(Hme,K8o),e(P2,Z8o),e(P2,NG),e(NG,e9o),e(P2,o9o),e(Ye,r9o),e(Ye,B2),e(B2,t9o),e(B2,Ume),e(Ume,a9o),e(B2,n9o),e(B2,Jme),e(Jme,s9o),e(Ye,l9o),M(N2,Ye,null),b(f,jVe,u),b(f,zi,u),e(zi,I2),e(I2,Yme),M(Ry,Yme,null),e(zi,i9o),e(zi,Kme),e(Kme,d9o),b(f,DVe,u),b(f,ko,u),M(Py,ko,null),e(ko,c9o),e(ko,Qi),e(Qi,f9o),e(Qi,IG),e(IG,m9o),e(Qi,g9o),e(Qi,qG),e(qG,h9o),e(Qi,p9o),e(ko,_9o),e(ko,By),e(By,u9o),e(By,Zme),e(Zme,b9o),e(By,v9o),e(ko,F9o),e(ko,it),M(Ny,it,null),e(it,T9o),e(it,ege),e(ege,M9o),e(it,E9o),e(it,Wi),e(Wi,C9o),e(Wi,oge),e(oge,w9o),e(Wi,A9o),e(Wi,jG),e(jG,L9o),e(Wi,y9o),e(it,x9o),M(q2,it,null),e(ko,$9o),e(ko,Ke),M(Iy,Ke,null),e(Ke,k9o),e(Ke,rge),e(rge,S9o),e(Ke,R9o),e(Ke,Ia),e(Ia,P9o),e(Ia,tge),e(tge,B9o),e(Ia,N9o),e(Ia,age),e(age,I9o),e(Ia,q9o),e(Ia,nge),e(nge,j9o),e(Ia,D9o),e(Ke,G9o),e(Ke,z),e(z,j2),e(j2,sge),e(sge,O9o),e(j2,V9o),e(j2,DG),e(DG,X9o),e(j2,z9o),e(z,Q9o),e(z,D2),e(D2,lge),e(lge,W9o),e(D2,H9o),e(D2,GG),e(GG,U9o),e(D2,J9o),e(z,Y9o),e(z,G2),e(G2,ige),e(ige,K9o),e(G2,Z9o),e(G2,OG),e(OG,exo),e(G2,oxo),e(z,rxo),e(z,O2),e(O2,dge),e(dge,txo),e(O2,axo),e(O2,VG),e(VG,nxo),e(O2,sxo),e(z,lxo),e(z,V2),e(V2,cge),e(cge,ixo),e(V2,dxo),e(V2,XG),e(XG,cxo),e(V2,fxo),e(z,mxo),e(z,X2),e(X2,fge),e(fge,gxo),e(X2,hxo),e(X2,zG),e(zG,pxo),e(X2,_xo),e(z,uxo),e(z,z2),e(z2,mge),e(mge,bxo),e(z2,vxo),e(z2,QG),e(QG,Fxo),e(z2,Txo),e(z,Mxo),e(z,Q2),e(Q2,gge),e(gge,Exo),e(Q2,Cxo),e(Q2,WG),e(WG,wxo),e(Q2,Axo),e(z,Lxo),e(z,W2),e(W2,hge),e(hge,yxo),e(W2,xxo),e(W2,HG),e(HG,$xo),e(W2,kxo),e(z,Sxo),e(z,H2),e(H2,pge),e(pge,Rxo),e(H2,Pxo),e(H2,UG),e(UG,Bxo),e(H2,Nxo),e(z,Ixo),e(z,U2),e(U2,_ge),e(_ge,qxo),e(U2,jxo),e(U2,JG),e(JG,Dxo),e(U2,Gxo),e(z,Oxo),e(z,J2),e(J2,uge),e(uge,Vxo),e(J2,Xxo),e(J2,YG),e(YG,zxo),e(J2,Qxo),e(z,Wxo),e(z,Y2),e(Y2,bge),e(bge,Hxo),e(Y2,Uxo),e(Y2,KG),e(KG,Jxo),e(Y2,Yxo),e(z,Kxo),e(z,K2),e(K2,vge),e(vge,Zxo),e(K2,e$o),e(K2,ZG),e(ZG,o$o),e(K2,r$o),e(z,t$o),e(z,Z2),e(Z2,Fge),e(Fge,a$o),e(Z2,n$o),e(Z2,eO),e(eO,s$o),e(Z2,l$o),e(z,i$o),e(z,e1),e(e1,Tge),e(Tge,d$o),e(e1,c$o),e(e1,oO),e(oO,f$o),e(e1,m$o),e(z,g$o),e(z,o1),e(o1,Mge),e(Mge,h$o),e(o1,p$o),e(o1,rO),e(rO,_$o),e(o1,u$o),e(z,b$o),e(z,r1),e(r1,Ege),e(Ege,v$o),e(r1,F$o),e(r1,tO),e(tO,T$o),e(r1,M$o),e(z,E$o),e(z,t1),e(t1,Cge),e(Cge,C$o),e(t1,w$o),e(t1,aO),e(aO,A$o),e(t1,L$o),e(z,y$o),e(z,a1),e(a1,wge),e(wge,x$o),e(a1,$$o),e(a1,nO),e(nO,k$o),e(a1,S$o),e(z,R$o),e(z,n1),e(n1,Age),e(Age,P$o),e(n1,B$o),e(n1,sO),e(sO,N$o),e(n1,I$o),e(z,q$o),e(z,s1),e(s1,Lge),e(Lge,j$o),e(s1,D$o),e(s1,lO),e(lO,G$o),e(s1,O$o),e(z,V$o),e(z,l1),e(l1,yge),e(yge,X$o),e(l1,z$o),e(l1,iO),e(iO,Q$o),e(l1,W$o),e(z,H$o),e(z,i1),e(i1,xge),e(xge,U$o),e(i1,J$o),e(i1,dO),e(dO,Y$o),e(i1,K$o),e(z,Z$o),e(z,d1),e(d1,$ge),e($ge,eko),e(d1,oko),e(d1,cO),e(cO,rko),e(d1,tko),e(z,ako),e(z,c1),e(c1,kge),e(kge,nko),e(c1,sko),e(c1,fO),e(fO,lko),e(c1,iko),e(z,dko),e(z,f1),e(f1,Sge),e(Sge,cko),e(f1,fko),e(f1,mO),e(mO,mko),e(f1,gko),e(z,hko),e(z,m1),e(m1,Rge),e(Rge,pko),e(m1,_ko),e(m1,gO),e(gO,uko),e(m1,bko),e(z,vko),e(z,g1),e(g1,Pge),e(Pge,Fko),e(g1,Tko),e(g1,hO),e(hO,Mko),e(g1,Eko),e(z,Cko),e(z,h1),e(h1,Bge),e(Bge,wko),e(h1,Ako),e(h1,pO),e(pO,Lko),e(h1,yko),e(z,xko),e(z,p1),e(p1,Nge),e(Nge,$ko),e(p1,kko),e(p1,_O),e(_O,Sko),e(p1,Rko),e(z,Pko),e(z,_1),e(_1,Ige),e(Ige,Bko),e(_1,Nko),e(_1,uO),e(uO,Iko),e(_1,qko),e(z,jko),e(z,u1),e(u1,qge),e(qge,Dko),e(u1,Gko),e(u1,bO),e(bO,Oko),e(u1,Vko),e(z,Xko),e(z,b1),e(b1,jge),e(jge,zko),e(b1,Qko),e(b1,vO),e(vO,Wko),e(b1,Hko),e(z,Uko),e(z,v1),e(v1,Dge),e(Dge,Jko),e(v1,Yko),e(v1,FO),e(FO,Kko),e(v1,Zko),e(z,eSo),e(z,F1),e(F1,Gge),e(Gge,oSo),e(F1,rSo),e(F1,TO),e(TO,tSo),e(F1,aSo),e(z,nSo),e(z,T1),e(T1,Oge),e(Oge,sSo),e(T1,lSo),e(T1,MO),e(MO,iSo),e(T1,dSo),e(z,cSo),e(z,M1),e(M1,Vge),e(Vge,fSo),e(M1,mSo),e(M1,EO),e(EO,gSo),e(M1,hSo),e(z,pSo),e(z,E1),e(E1,Xge),e(Xge,_So),e(E1,uSo),e(E1,CO),e(CO,bSo),e(E1,vSo),e(z,FSo),e(z,C1),e(C1,zge),e(zge,TSo),e(C1,MSo),e(C1,wO),e(wO,ESo),e(C1,CSo),e(Ke,wSo),e(Ke,w1),e(w1,ASo),e(w1,Qge),e(Qge,LSo),e(w1,ySo),e(w1,Wge),e(Wge,xSo),e(Ke,$So),M(A1,Ke,null),b(f,GVe,u),b(f,Hi,u),e(Hi,L1),e(L1,Hge),M(qy,Hge,null),e(Hi,kSo),e(Hi,Uge),e(Uge,SSo),b(f,OVe,u),b(f,So,u),M(jy,So,null),e(So,RSo),e(So,Ui),e(Ui,PSo),e(Ui,AO),e(AO,BSo),e(Ui,NSo),e(Ui,LO),e(LO,ISo),e(Ui,qSo),e(So,jSo),e(So,Dy),e(Dy,DSo),e(Dy,Jge),e(Jge,GSo),e(Dy,OSo),e(So,VSo),e(So,dt),M(Gy,dt,null),e(dt,XSo),e(dt,Yge),e(Yge,zSo),e(dt,QSo),e(dt,Ji),e(Ji,WSo),e(Ji,Kge),e(Kge,HSo),e(Ji,USo),e(Ji,yO),e(yO,JSo),e(Ji,YSo),e(dt,KSo),M(y1,dt,null),e(So,ZSo),e(So,Ze),M(Oy,Ze,null),e(Ze,eRo),e(Ze,Zge),e(Zge,oRo),e(Ze,rRo),e(Ze,qa),e(qa,tRo),e(qa,ehe),e(ehe,aRo),e(qa,nRo),e(qa,ohe),e(ohe,sRo),e(qa,lRo),e(qa,rhe),e(rhe,iRo),e(qa,dRo),e(Ze,cRo),e(Ze,W),e(W,x1),e(x1,the),e(the,fRo),e(x1,mRo),e(x1,xO),e(xO,gRo),e(x1,hRo),e(W,pRo),e(W,$1),e($1,ahe),e(ahe,_Ro),e($1,uRo),e($1,$O),e($O,bRo),e($1,vRo),e(W,FRo),e(W,k1),e(k1,nhe),e(nhe,TRo),e(k1,MRo),e(k1,kO),e(kO,ERo),e(k1,CRo),e(W,wRo),e(W,S1),e(S1,she),e(she,ARo),e(S1,LRo),e(S1,SO),e(SO,yRo),e(S1,xRo),e(W,$Ro),e(W,R1),e(R1,lhe),e(lhe,kRo),e(R1,SRo),e(R1,RO),e(RO,RRo),e(R1,PRo),e(W,BRo),e(W,P1),e(P1,ihe),e(ihe,NRo),e(P1,IRo),e(P1,PO),e(PO,qRo),e(P1,jRo),e(W,DRo),e(W,B1),e(B1,dhe),e(dhe,GRo),e(B1,ORo),e(B1,BO),e(BO,VRo),e(B1,XRo),e(W,zRo),e(W,N1),e(N1,che),e(che,QRo),e(N1,WRo),e(N1,NO),e(NO,HRo),e(N1,URo),e(W,JRo),e(W,I1),e(I1,fhe),e(fhe,YRo),e(I1,KRo),e(I1,IO),e(IO,ZRo),e(I1,ePo),e(W,oPo),e(W,q1),e(q1,mhe),e(mhe,rPo),e(q1,tPo),e(q1,qO),e(qO,aPo),e(q1,nPo),e(W,sPo),e(W,j1),e(j1,ghe),e(ghe,lPo),e(j1,iPo),e(j1,jO),e(jO,dPo),e(j1,cPo),e(W,fPo),e(W,D1),e(D1,hhe),e(hhe,mPo),e(D1,gPo),e(D1,DO),e(DO,hPo),e(D1,pPo),e(W,_Po),e(W,G1),e(G1,phe),e(phe,uPo),e(G1,bPo),e(G1,GO),e(GO,vPo),e(G1,FPo),e(W,TPo),e(W,O1),e(O1,_he),e(_he,MPo),e(O1,EPo),e(O1,OO),e(OO,CPo),e(O1,wPo),e(W,APo),e(W,V1),e(V1,uhe),e(uhe,LPo),e(V1,yPo),e(V1,VO),e(VO,xPo),e(V1,$Po),e(W,kPo),e(W,X1),e(X1,bhe),e(bhe,SPo),e(X1,RPo),e(X1,XO),e(XO,PPo),e(X1,BPo),e(W,NPo),e(W,z1),e(z1,vhe),e(vhe,IPo),e(z1,qPo),e(z1,zO),e(zO,jPo),e(z1,DPo),e(W,GPo),e(W,Q1),e(Q1,Fhe),e(Fhe,OPo),e(Q1,VPo),e(Q1,QO),e(QO,XPo),e(Q1,zPo),e(W,QPo),e(W,W1),e(W1,The),e(The,WPo),e(W1,HPo),e(W1,WO),e(WO,UPo),e(W1,JPo),e(W,YPo),e(W,H1),e(H1,Mhe),e(Mhe,KPo),e(H1,ZPo),e(H1,HO),e(HO,eBo),e(H1,oBo),e(W,rBo),e(W,U1),e(U1,Ehe),e(Ehe,tBo),e(U1,aBo),e(U1,UO),e(UO,nBo),e(U1,sBo),e(W,lBo),e(W,J1),e(J1,Che),e(Che,iBo),e(J1,dBo),e(J1,JO),e(JO,cBo),e(J1,fBo),e(W,mBo),e(W,Y1),e(Y1,whe),e(whe,gBo),e(Y1,hBo),e(Y1,YO),e(YO,pBo),e(Y1,_Bo),e(W,uBo),e(W,K1),e(K1,Ahe),e(Ahe,bBo),e(K1,vBo),e(K1,KO),e(KO,FBo),e(K1,TBo),e(W,MBo),e(W,Z1),e(Z1,Lhe),e(Lhe,EBo),e(Z1,CBo),e(Z1,ZO),e(ZO,wBo),e(Z1,ABo),e(W,LBo),e(W,e7),e(e7,yhe),e(yhe,yBo),e(e7,xBo),e(e7,eV),e(eV,$Bo),e(e7,kBo),e(W,SBo),e(W,o7),e(o7,xhe),e(xhe,RBo),e(o7,PBo),e(o7,oV),e(oV,BBo),e(o7,NBo),e(W,IBo),e(W,r7),e(r7,$he),e($he,qBo),e(r7,jBo),e(r7,rV),e(rV,DBo),e(r7,GBo),e(W,OBo),e(W,t7),e(t7,khe),e(khe,VBo),e(t7,XBo),e(t7,tV),e(tV,zBo),e(t7,QBo),e(W,WBo),e(W,a7),e(a7,She),e(She,HBo),e(a7,UBo),e(a7,aV),e(aV,JBo),e(a7,YBo),e(W,KBo),e(W,n7),e(n7,Rhe),e(Rhe,ZBo),e(n7,eNo),e(n7,nV),e(nV,oNo),e(n7,rNo),e(W,tNo),e(W,s7),e(s7,Phe),e(Phe,aNo),e(s7,nNo),e(s7,sV),e(sV,sNo),e(s7,lNo),e(W,iNo),e(W,l7),e(l7,Bhe),e(Bhe,dNo),e(l7,cNo),e(l7,lV),e(lV,fNo),e(l7,mNo),e(W,gNo),e(W,i7),e(i7,Nhe),e(Nhe,hNo),e(i7,pNo),e(i7,Ihe),e(Ihe,_No),e(i7,uNo),e(W,bNo),e(W,d7),e(d7,qhe),e(qhe,vNo),e(d7,FNo),e(d7,iV),e(iV,TNo),e(d7,MNo),e(W,ENo),e(W,c7),e(c7,jhe),e(jhe,CNo),e(c7,wNo),e(c7,dV),e(dV,ANo),e(c7,LNo),e(W,yNo),e(W,f7),e(f7,Dhe),e(Dhe,xNo),e(f7,$No),e(f7,cV),e(cV,kNo),e(f7,SNo),e(W,RNo),e(W,m7),e(m7,Ghe),e(Ghe,PNo),e(m7,BNo),e(m7,fV),e(fV,NNo),e(m7,INo),e(Ze,qNo),e(Ze,g7),e(g7,jNo),e(g7,Ohe),e(Ohe,DNo),e(g7,GNo),e(g7,Vhe),e(Vhe,ONo),e(Ze,VNo),M(h7,Ze,null),b(f,VVe,u),b(f,Yi,u),e(Yi,p7),e(p7,Xhe),M(Vy,Xhe,null),e(Yi,XNo),e(Yi,zhe),e(zhe,zNo),b(f,XVe,u),b(f,Ro,u),M(Xy,Ro,null),e(Ro,QNo),e(Ro,Ki),e(Ki,WNo),e(Ki,mV),e(mV,HNo),e(Ki,UNo),e(Ki,gV),e(gV,JNo),e(Ki,YNo),e(Ro,KNo),e(Ro,zy),e(zy,ZNo),e(zy,Qhe),e(Qhe,eIo),e(zy,oIo),e(Ro,rIo),e(Ro,ct),M(Qy,ct,null),e(ct,tIo),e(ct,Whe),e(Whe,aIo),e(ct,nIo),e(ct,Zi),e(Zi,sIo),e(Zi,Hhe),e(Hhe,lIo),e(Zi,iIo),e(Zi,hV),e(hV,dIo),e(Zi,cIo),e(ct,fIo),M(_7,ct,null),e(Ro,mIo),e(Ro,eo),M(Wy,eo,null),e(eo,gIo),e(eo,Uhe),e(Uhe,hIo),e(eo,pIo),e(eo,ja),e(ja,_Io),e(ja,Jhe),e(Jhe,uIo),e(ja,bIo),e(ja,Yhe),e(Yhe,vIo),e(ja,FIo),e(ja,Khe),e(Khe,TIo),e(ja,MIo),e(eo,EIo),e(eo,pe),e(pe,u7),e(u7,Zhe),e(Zhe,CIo),e(u7,wIo),e(u7,pV),e(pV,AIo),e(u7,LIo),e(pe,yIo),e(pe,b7),e(b7,epe),e(epe,xIo),e(b7,$Io),e(b7,_V),e(_V,kIo),e(b7,SIo),e(pe,RIo),e(pe,v7),e(v7,ope),e(ope,PIo),e(v7,BIo),e(v7,uV),e(uV,NIo),e(v7,IIo),e(pe,qIo),e(pe,F7),e(F7,rpe),e(rpe,jIo),e(F7,DIo),e(F7,bV),e(bV,GIo),e(F7,OIo),e(pe,VIo),e(pe,T7),e(T7,tpe),e(tpe,XIo),e(T7,zIo),e(T7,vV),e(vV,QIo),e(T7,WIo),e(pe,HIo),e(pe,M7),e(M7,ape),e(ape,UIo),e(M7,JIo),e(M7,FV),e(FV,YIo),e(M7,KIo),e(pe,ZIo),e(pe,E7),e(E7,npe),e(npe,eqo),e(E7,oqo),e(E7,TV),e(TV,rqo),e(E7,tqo),e(pe,aqo),e(pe,C7),e(C7,spe),e(spe,nqo),e(C7,sqo),e(C7,MV),e(MV,lqo),e(C7,iqo),e(pe,dqo),e(pe,w7),e(w7,lpe),e(lpe,cqo),e(w7,fqo),e(w7,EV),e(EV,mqo),e(w7,gqo),e(pe,hqo),e(pe,A7),e(A7,ipe),e(ipe,pqo),e(A7,_qo),e(A7,CV),e(CV,uqo),e(A7,bqo),e(pe,vqo),e(pe,L7),e(L7,dpe),e(dpe,Fqo),e(L7,Tqo),e(L7,wV),e(wV,Mqo),e(L7,Eqo),e(pe,Cqo),e(pe,y7),e(y7,cpe),e(cpe,wqo),e(y7,Aqo),e(y7,AV),e(AV,Lqo),e(y7,yqo),e(pe,xqo),e(pe,x7),e(x7,fpe),e(fpe,$qo),e(x7,kqo),e(x7,LV),e(LV,Sqo),e(x7,Rqo),e(pe,Pqo),e(pe,$7),e($7,mpe),e(mpe,Bqo),e($7,Nqo),e($7,yV),e(yV,Iqo),e($7,qqo),e(pe,jqo),e(pe,k7),e(k7,gpe),e(gpe,Dqo),e(k7,Gqo),e(k7,xV),e(xV,Oqo),e(k7,Vqo),e(pe,Xqo),e(pe,S7),e(S7,hpe),e(hpe,zqo),e(S7,Qqo),e(S7,$V),e($V,Wqo),e(S7,Hqo),e(pe,Uqo),e(pe,R7),e(R7,ppe),e(ppe,Jqo),e(R7,Yqo),e(R7,kV),e(kV,Kqo),e(R7,Zqo),e(pe,ejo),e(pe,P7),e(P7,_pe),e(_pe,ojo),e(P7,rjo),e(P7,SV),e(SV,tjo),e(P7,ajo),e(eo,njo),e(eo,B7),e(B7,sjo),e(B7,upe),e(upe,ljo),e(B7,ijo),e(B7,bpe),e(bpe,djo),e(eo,cjo),M(N7,eo,null),b(f,zVe,u),b(f,ed,u),e(ed,I7),e(I7,vpe),M(Hy,vpe,null),e(ed,fjo),e(ed,Fpe),e(Fpe,mjo),b(f,QVe,u),b(f,Po,u),M(Uy,Po,null),e(Po,gjo),e(Po,od),e(od,hjo),e(od,RV),e(RV,pjo),e(od,_jo),e(od,PV),e(PV,ujo),e(od,bjo),e(Po,vjo),e(Po,Jy),e(Jy,Fjo),e(Jy,Tpe),e(Tpe,Tjo),e(Jy,Mjo),e(Po,Ejo),e(Po,ft),M(Yy,ft,null),e(ft,Cjo),e(ft,Mpe),e(Mpe,wjo),e(ft,Ajo),e(ft,rd),e(rd,Ljo),e(rd,Epe),e(Epe,yjo),e(rd,xjo),e(rd,BV),e(BV,$jo),e(rd,kjo),e(ft,Sjo),M(q7,ft,null),e(Po,Rjo),e(Po,oo),M(Ky,oo,null),e(oo,Pjo),e(oo,Cpe),e(Cpe,Bjo),e(oo,Njo),e(oo,Da),e(Da,Ijo),e(Da,wpe),e(wpe,qjo),e(Da,jjo),e(Da,Ape),e(Ape,Djo),e(Da,Gjo),e(Da,Lpe),e(Lpe,Ojo),e(Da,Vjo),e(oo,Xjo),e(oo,I),e(I,j7),e(j7,ype),e(ype,zjo),e(j7,Qjo),e(j7,NV),e(NV,Wjo),e(j7,Hjo),e(I,Ujo),e(I,D7),e(D7,xpe),e(xpe,Jjo),e(D7,Yjo),e(D7,IV),e(IV,Kjo),e(D7,Zjo),e(I,eDo),e(I,G7),e(G7,$pe),e($pe,oDo),e(G7,rDo),e(G7,qV),e(qV,tDo),e(G7,aDo),e(I,nDo),e(I,O7),e(O7,kpe),e(kpe,sDo),e(O7,lDo),e(O7,jV),e(jV,iDo),e(O7,dDo),e(I,cDo),e(I,V7),e(V7,Spe),e(Spe,fDo),e(V7,mDo),e(V7,DV),e(DV,gDo),e(V7,hDo),e(I,pDo),e(I,X7),e(X7,Rpe),e(Rpe,_Do),e(X7,uDo),e(X7,GV),e(GV,bDo),e(X7,vDo),e(I,FDo),e(I,z7),e(z7,Ppe),e(Ppe,TDo),e(z7,MDo),e(z7,OV),e(OV,EDo),e(z7,CDo),e(I,wDo),e(I,Q7),e(Q7,Bpe),e(Bpe,ADo),e(Q7,LDo),e(Q7,VV),e(VV,yDo),e(Q7,xDo),e(I,$Do),e(I,W7),e(W7,Npe),e(Npe,kDo),e(W7,SDo),e(W7,XV),e(XV,RDo),e(W7,PDo),e(I,BDo),e(I,H7),e(H7,Ipe),e(Ipe,NDo),e(H7,IDo),e(H7,zV),e(zV,qDo),e(H7,jDo),e(I,DDo),e(I,U7),e(U7,qpe),e(qpe,GDo),e(U7,ODo),e(U7,QV),e(QV,VDo),e(U7,XDo),e(I,zDo),e(I,J7),e(J7,jpe),e(jpe,QDo),e(J7,WDo),e(J7,WV),e(WV,HDo),e(J7,UDo),e(I,JDo),e(I,Y7),e(Y7,Dpe),e(Dpe,YDo),e(Y7,KDo),e(Y7,HV),e(HV,ZDo),e(Y7,eGo),e(I,oGo),e(I,K7),e(K7,Gpe),e(Gpe,rGo),e(K7,tGo),e(K7,UV),e(UV,aGo),e(K7,nGo),e(I,sGo),e(I,Z7),e(Z7,Ope),e(Ope,lGo),e(Z7,iGo),e(Z7,JV),e(JV,dGo),e(Z7,cGo),e(I,fGo),e(I,e4),e(e4,Vpe),e(Vpe,mGo),e(e4,gGo),e(e4,YV),e(YV,hGo),e(e4,pGo),e(I,_Go),e(I,o4),e(o4,Xpe),e(Xpe,uGo),e(o4,bGo),e(o4,KV),e(KV,vGo),e(o4,FGo),e(I,TGo),e(I,r4),e(r4,zpe),e(zpe,MGo),e(r4,EGo),e(r4,ZV),e(ZV,CGo),e(r4,wGo),e(I,AGo),e(I,t4),e(t4,Qpe),e(Qpe,LGo),e(t4,yGo),e(t4,eX),e(eX,xGo),e(t4,$Go),e(I,kGo),e(I,a4),e(a4,Wpe),e(Wpe,SGo),e(a4,RGo),e(a4,oX),e(oX,PGo),e(a4,BGo),e(I,NGo),e(I,n4),e(n4,Hpe),e(Hpe,IGo),e(n4,qGo),e(n4,rX),e(rX,jGo),e(n4,DGo),e(I,GGo),e(I,s4),e(s4,Upe),e(Upe,OGo),e(s4,VGo),e(s4,tX),e(tX,XGo),e(s4,zGo),e(I,QGo),e(I,l4),e(l4,Jpe),e(Jpe,WGo),e(l4,HGo),e(l4,aX),e(aX,UGo),e(l4,JGo),e(I,YGo),e(I,i4),e(i4,Ype),e(Ype,KGo),e(i4,ZGo),e(i4,nX),e(nX,eOo),e(i4,oOo),e(I,rOo),e(I,d4),e(d4,Kpe),e(Kpe,tOo),e(d4,aOo),e(d4,sX),e(sX,nOo),e(d4,sOo),e(I,lOo),e(I,c4),e(c4,Zpe),e(Zpe,iOo),e(c4,dOo),e(c4,lX),e(lX,cOo),e(c4,fOo),e(I,mOo),e(I,f4),e(f4,e_e),e(e_e,gOo),e(f4,hOo),e(f4,iX),e(iX,pOo),e(f4,_Oo),e(I,uOo),e(I,m4),e(m4,o_e),e(o_e,bOo),e(m4,vOo),e(m4,dX),e(dX,FOo),e(m4,TOo),e(I,MOo),e(I,g4),e(g4,r_e),e(r_e,EOo),e(g4,COo),e(g4,cX),e(cX,wOo),e(g4,AOo),e(I,LOo),e(I,h4),e(h4,t_e),e(t_e,yOo),e(h4,xOo),e(h4,fX),e(fX,$Oo),e(h4,kOo),e(I,SOo),e(I,p4),e(p4,a_e),e(a_e,ROo),e(p4,POo),e(p4,mX),e(mX,BOo),e(p4,NOo),e(I,IOo),e(I,_4),e(_4,n_e),e(n_e,qOo),e(_4,jOo),e(_4,gX),e(gX,DOo),e(_4,GOo),e(I,OOo),e(I,u4),e(u4,s_e),e(s_e,VOo),e(u4,XOo),e(u4,hX),e(hX,zOo),e(u4,QOo),e(I,WOo),e(I,b4),e(b4,l_e),e(l_e,HOo),e(b4,UOo),e(b4,pX),e(pX,JOo),e(b4,YOo),e(I,KOo),e(I,v4),e(v4,i_e),e(i_e,ZOo),e(v4,eVo),e(v4,_X),e(_X,oVo),e(v4,rVo),e(I,tVo),e(I,F4),e(F4,d_e),e(d_e,aVo),e(F4,nVo),e(F4,uX),e(uX,sVo),e(F4,lVo),e(I,iVo),e(I,T4),e(T4,c_e),e(c_e,dVo),e(T4,cVo),e(T4,bX),e(bX,fVo),e(T4,mVo),e(I,gVo),e(I,M4),e(M4,f_e),e(f_e,hVo),e(M4,pVo),e(M4,vX),e(vX,_Vo),e(M4,uVo),e(I,bVo),e(I,E4),e(E4,m_e),e(m_e,vVo),e(E4,FVo),e(E4,FX),e(FX,TVo),e(E4,MVo),e(I,EVo),e(I,C4),e(C4,g_e),e(g_e,CVo),e(C4,wVo),e(C4,TX),e(TX,AVo),e(C4,LVo),e(I,yVo),e(I,w4),e(w4,h_e),e(h_e,xVo),e(w4,$Vo),e(w4,MX),e(MX,kVo),e(w4,SVo),e(I,RVo),e(I,A4),e(A4,p_e),e(p_e,PVo),e(A4,BVo),e(A4,EX),e(EX,NVo),e(A4,IVo),e(I,qVo),e(I,L4),e(L4,__e),e(__e,jVo),e(L4,DVo),e(L4,CX),e(CX,GVo),e(L4,OVo),e(I,VVo),e(I,y4),e(y4,u_e),e(u_e,XVo),e(y4,zVo),e(y4,wX),e(wX,QVo),e(y4,WVo),e(I,HVo),e(I,x4),e(x4,b_e),e(b_e,UVo),e(x4,JVo),e(x4,AX),e(AX,YVo),e(x4,KVo),e(I,ZVo),e(I,$4),e($4,v_e),e(v_e,eXo),e($4,oXo),e($4,LX),e(LX,rXo),e($4,tXo),e(I,aXo),e(I,k4),e(k4,F_e),e(F_e,nXo),e(k4,sXo),e(k4,yX),e(yX,lXo),e(k4,iXo),e(I,dXo),e(I,S4),e(S4,T_e),e(T_e,cXo),e(S4,fXo),e(S4,xX),e(xX,mXo),e(S4,gXo),e(I,hXo),e(I,R4),e(R4,M_e),e(M_e,pXo),e(R4,_Xo),e(R4,$X),e($X,uXo),e(R4,bXo),e(I,vXo),e(I,P4),e(P4,E_e),e(E_e,FXo),e(P4,TXo),e(P4,kX),e(kX,MXo),e(P4,EXo),e(oo,CXo),e(oo,B4),e(B4,wXo),e(B4,C_e),e(C_e,AXo),e(B4,LXo),e(B4,w_e),e(w_e,yXo),e(oo,xXo),M(N4,oo,null),b(f,WVe,u),b(f,td,u),e(td,I4),e(I4,A_e),M(Zy,A_e,null),e(td,$Xo),e(td,L_e),e(L_e,kXo),b(f,HVe,u),b(f,Bo,u),M(e8,Bo,null),e(Bo,SXo),e(Bo,ad),e(ad,RXo),e(ad,SX),e(SX,PXo),e(ad,BXo),e(ad,RX),e(RX,NXo),e(ad,IXo),e(Bo,qXo),e(Bo,o8),e(o8,jXo),e(o8,y_e),e(y_e,DXo),e(o8,GXo),e(Bo,OXo),e(Bo,mt),M(r8,mt,null),e(mt,VXo),e(mt,x_e),e(x_e,XXo),e(mt,zXo),e(mt,nd),e(nd,QXo),e(nd,$_e),e($_e,WXo),e(nd,HXo),e(nd,PX),e(PX,UXo),e(nd,JXo),e(mt,YXo),M(q4,mt,null),e(Bo,KXo),e(Bo,ro),M(t8,ro,null),e(ro,ZXo),e(ro,k_e),e(k_e,ezo),e(ro,ozo),e(ro,Ga),e(Ga,rzo),e(Ga,S_e),e(S_e,tzo),e(Ga,azo),e(Ga,R_e),e(R_e,nzo),e(Ga,szo),e(Ga,P_e),e(P_e,lzo),e(Ga,izo),e(ro,dzo),e(ro,Z),e(Z,j4),e(j4,B_e),e(B_e,czo),e(j4,fzo),e(j4,BX),e(BX,mzo),e(j4,gzo),e(Z,hzo),e(Z,D4),e(D4,N_e),e(N_e,pzo),e(D4,_zo),e(D4,NX),e(NX,uzo),e(D4,bzo),e(Z,vzo),e(Z,G4),e(G4,I_e),e(I_e,Fzo),e(G4,Tzo),e(G4,IX),e(IX,Mzo),e(G4,Ezo),e(Z,Czo),e(Z,O4),e(O4,q_e),e(q_e,wzo),e(O4,Azo),e(O4,qX),e(qX,Lzo),e(O4,yzo),e(Z,xzo),e(Z,V4),e(V4,j_e),e(j_e,$zo),e(V4,kzo),e(V4,jX),e(jX,Szo),e(V4,Rzo),e(Z,Pzo),e(Z,X4),e(X4,D_e),e(D_e,Bzo),e(X4,Nzo),e(X4,DX),e(DX,Izo),e(X4,qzo),e(Z,jzo),e(Z,z4),e(z4,G_e),e(G_e,Dzo),e(z4,Gzo),e(z4,GX),e(GX,Ozo),e(z4,Vzo),e(Z,Xzo),e(Z,Q4),e(Q4,O_e),e(O_e,zzo),e(Q4,Qzo),e(Q4,OX),e(OX,Wzo),e(Q4,Hzo),e(Z,Uzo),e(Z,W4),e(W4,V_e),e(V_e,Jzo),e(W4,Yzo),e(W4,VX),e(VX,Kzo),e(W4,Zzo),e(Z,eQo),e(Z,H4),e(H4,X_e),e(X_e,oQo),e(H4,rQo),e(H4,XX),e(XX,tQo),e(H4,aQo),e(Z,nQo),e(Z,U4),e(U4,z_e),e(z_e,sQo),e(U4,lQo),e(U4,zX),e(zX,iQo),e(U4,dQo),e(Z,cQo),e(Z,J4),e(J4,Q_e),e(Q_e,fQo),e(J4,mQo),e(J4,QX),e(QX,gQo),e(J4,hQo),e(Z,pQo),e(Z,Y4),e(Y4,W_e),e(W_e,_Qo),e(Y4,uQo),e(Y4,WX),e(WX,bQo),e(Y4,vQo),e(Z,FQo),e(Z,K4),e(K4,H_e),e(H_e,TQo),e(K4,MQo),e(K4,HX),e(HX,EQo),e(K4,CQo),e(Z,wQo),e(Z,Z4),e(Z4,U_e),e(U_e,AQo),e(Z4,LQo),e(Z4,UX),e(UX,yQo),e(Z4,xQo),e(Z,$Qo),e(Z,eb),e(eb,J_e),e(J_e,kQo),e(eb,SQo),e(eb,JX),e(JX,RQo),e(eb,PQo),e(Z,BQo),e(Z,ob),e(ob,Y_e),e(Y_e,NQo),e(ob,IQo),e(ob,YX),e(YX,qQo),e(ob,jQo),e(Z,DQo),e(Z,rb),e(rb,K_e),e(K_e,GQo),e(rb,OQo),e(rb,KX),e(KX,VQo),e(rb,XQo),e(Z,zQo),e(Z,tb),e(tb,Z_e),e(Z_e,QQo),e(tb,WQo),e(tb,ZX),e(ZX,HQo),e(tb,UQo),e(Z,JQo),e(Z,ab),e(ab,eue),e(eue,YQo),e(ab,KQo),e(ab,ez),e(ez,ZQo),e(ab,eWo),e(Z,oWo),e(Z,nb),e(nb,oue),e(oue,rWo),e(nb,tWo),e(nb,oz),e(oz,aWo),e(nb,nWo),e(Z,sWo),e(Z,sb),e(sb,rue),e(rue,lWo),e(sb,iWo),e(sb,rz),e(rz,dWo),e(sb,cWo),e(Z,fWo),e(Z,lb),e(lb,tue),e(tue,mWo),e(lb,gWo),e(lb,tz),e(tz,hWo),e(lb,pWo),e(Z,_Wo),e(Z,ib),e(ib,aue),e(aue,uWo),e(ib,bWo),e(ib,az),e(az,vWo),e(ib,FWo),e(Z,TWo),e(Z,db),e(db,nue),e(nue,MWo),e(db,EWo),e(db,nz),e(nz,CWo),e(db,wWo),e(Z,AWo),e(Z,cb),e(cb,sue),e(sue,LWo),e(cb,yWo),e(cb,sz),e(sz,xWo),e(cb,$Wo),e(Z,kWo),e(Z,fb),e(fb,lue),e(lue,SWo),e(fb,RWo),e(fb,lz),e(lz,PWo),e(fb,BWo),e(Z,NWo),e(Z,mb),e(mb,iue),e(iue,IWo),e(mb,qWo),e(mb,iz),e(iz,jWo),e(mb,DWo),e(Z,GWo),e(Z,gb),e(gb,due),e(due,OWo),e(gb,VWo),e(gb,dz),e(dz,XWo),e(gb,zWo),e(Z,QWo),e(Z,hb),e(hb,cue),e(cue,WWo),e(hb,HWo),e(hb,cz),e(cz,UWo),e(hb,JWo),e(ro,YWo),e(ro,pb),e(pb,KWo),e(pb,fue),e(fue,ZWo),e(pb,eHo),e(pb,mue),e(mue,oHo),e(ro,rHo),M(_b,ro,null),b(f,UVe,u),b(f,sd,u),e(sd,ub),e(ub,gue),M(a8,gue,null),e(sd,tHo),e(sd,hue),e(hue,aHo),b(f,JVe,u),b(f,No,u),M(n8,No,null),e(No,nHo),e(No,ld),e(ld,sHo),e(ld,fz),e(fz,lHo),e(ld,iHo),e(ld,mz),e(mz,dHo),e(ld,cHo),e(No,fHo),e(No,s8),e(s8,mHo),e(s8,pue),e(pue,gHo),e(s8,hHo),e(No,pHo),e(No,gt),M(l8,gt,null),e(gt,_Ho),e(gt,_ue),e(_ue,uHo),e(gt,bHo),e(gt,id),e(id,vHo),e(id,uue),e(uue,FHo),e(id,THo),e(id,gz),e(gz,MHo),e(id,EHo),e(gt,CHo),M(bb,gt,null),e(No,wHo),e(No,to),M(i8,to,null),e(to,AHo),e(to,bue),e(bue,LHo),e(to,yHo),e(to,Oa),e(Oa,xHo),e(Oa,vue),e(vue,$Ho),e(Oa,kHo),e(Oa,Fue),e(Fue,SHo),e(Oa,RHo),e(Oa,Tue),e(Tue,PHo),e(Oa,BHo),e(to,NHo),e(to,Io),e(Io,vb),e(vb,Mue),e(Mue,IHo),e(vb,qHo),e(vb,hz),e(hz,jHo),e(vb,DHo),e(Io,GHo),e(Io,Fb),e(Fb,Eue),e(Eue,OHo),e(Fb,VHo),e(Fb,pz),e(pz,XHo),e(Fb,zHo),e(Io,QHo),e(Io,Tb),e(Tb,Cue),e(Cue,WHo),e(Tb,HHo),e(Tb,_z),e(_z,UHo),e(Tb,JHo),e(Io,YHo),e(Io,Mb),e(Mb,wue),e(wue,KHo),e(Mb,ZHo),e(Mb,uz),e(uz,eUo),e(Mb,oUo),e(Io,rUo),e(Io,Eb),e(Eb,Aue),e(Aue,tUo),e(Eb,aUo),e(Eb,bz),e(bz,nUo),e(Eb,sUo),e(Io,lUo),e(Io,Cb),e(Cb,Lue),e(Lue,iUo),e(Cb,dUo),e(Cb,vz),e(vz,cUo),e(Cb,fUo),e(to,mUo),e(to,wb),e(wb,gUo),e(wb,yue),e(yue,hUo),e(wb,pUo),e(wb,xue),e(xue,_Uo),e(to,uUo),M(Ab,to,null),b(f,YVe,u),b(f,dd,u),e(dd,Lb),e(Lb,$ue),M(d8,$ue,null),e(dd,bUo),e(dd,kue),e(kue,vUo),b(f,KVe,u),b(f,qo,u),M(c8,qo,null),e(qo,FUo),e(qo,cd),e(cd,TUo),e(cd,Fz),e(Fz,MUo),e(cd,EUo),e(cd,Tz),e(Tz,CUo),e(cd,wUo),e(qo,AUo),e(qo,f8),e(f8,LUo),e(f8,Sue),e(Sue,yUo),e(f8,xUo),e(qo,$Uo),e(qo,ht),M(m8,ht,null),e(ht,kUo),e(ht,Rue),e(Rue,SUo),e(ht,RUo),e(ht,fd),e(fd,PUo),e(fd,Pue),e(Pue,BUo),e(fd,NUo),e(fd,Mz),e(Mz,IUo),e(fd,qUo),e(ht,jUo),M(yb,ht,null),e(qo,DUo),e(qo,ao),M(g8,ao,null),e(ao,GUo),e(ao,Bue),e(Bue,OUo),e(ao,VUo),e(ao,Va),e(Va,XUo),e(Va,Nue),e(Nue,zUo),e(Va,QUo),e(Va,Iue),e(Iue,WUo),e(Va,HUo),e(Va,que),e(que,UUo),e(Va,JUo),e(ao,YUo),e(ao,U),e(U,xb),e(xb,jue),e(jue,KUo),e(xb,ZUo),e(xb,Ez),e(Ez,eJo),e(xb,oJo),e(U,rJo),e(U,$b),e($b,Due),e(Due,tJo),e($b,aJo),e($b,Cz),e(Cz,nJo),e($b,sJo),e(U,lJo),e(U,kb),e(kb,Gue),e(Gue,iJo),e(kb,dJo),e(kb,wz),e(wz,cJo),e(kb,fJo),e(U,mJo),e(U,Sb),e(Sb,Oue),e(Oue,gJo),e(Sb,hJo),e(Sb,Az),e(Az,pJo),e(Sb,_Jo),e(U,uJo),e(U,Rb),e(Rb,Vue),e(Vue,bJo),e(Rb,vJo),e(Rb,Lz),e(Lz,FJo),e(Rb,TJo),e(U,MJo),e(U,Pb),e(Pb,Xue),e(Xue,EJo),e(Pb,CJo),e(Pb,yz),e(yz,wJo),e(Pb,AJo),e(U,LJo),e(U,Bb),e(Bb,zue),e(zue,yJo),e(Bb,xJo),e(Bb,xz),e(xz,$Jo),e(Bb,kJo),e(U,SJo),e(U,Nb),e(Nb,Que),e(Que,RJo),e(Nb,PJo),e(Nb,$z),e($z,BJo),e(Nb,NJo),e(U,IJo),e(U,Ib),e(Ib,Wue),e(Wue,qJo),e(Ib,jJo),e(Ib,kz),e(kz,DJo),e(Ib,GJo),e(U,OJo),e(U,qb),e(qb,Hue),e(Hue,VJo),e(qb,XJo),e(qb,Sz),e(Sz,zJo),e(qb,QJo),e(U,WJo),e(U,jb),e(jb,Uue),e(Uue,HJo),e(jb,UJo),e(jb,Rz),e(Rz,JJo),e(jb,YJo),e(U,KJo),e(U,Db),e(Db,Jue),e(Jue,ZJo),e(Db,eYo),e(Db,Pz),e(Pz,oYo),e(Db,rYo),e(U,tYo),e(U,Gb),e(Gb,Yue),e(Yue,aYo),e(Gb,nYo),e(Gb,Bz),e(Bz,sYo),e(Gb,lYo),e(U,iYo),e(U,Ob),e(Ob,Kue),e(Kue,dYo),e(Ob,cYo),e(Ob,Nz),e(Nz,fYo),e(Ob,mYo),e(U,gYo),e(U,Vb),e(Vb,Zue),e(Zue,hYo),e(Vb,pYo),e(Vb,Iz),e(Iz,_Yo),e(Vb,uYo),e(U,bYo),e(U,Xb),e(Xb,e2e),e(e2e,vYo),e(Xb,FYo),e(Xb,qz),e(qz,TYo),e(Xb,MYo),e(U,EYo),e(U,zb),e(zb,o2e),e(o2e,CYo),e(zb,wYo),e(zb,jz),e(jz,AYo),e(zb,LYo),e(U,yYo),e(U,Qb),e(Qb,r2e),e(r2e,xYo),e(Qb,$Yo),e(Qb,Dz),e(Dz,kYo),e(Qb,SYo),e(U,RYo),e(U,Wb),e(Wb,t2e),e(t2e,PYo),e(Wb,BYo),e(Wb,Gz),e(Gz,NYo),e(Wb,IYo),e(U,qYo),e(U,Hb),e(Hb,a2e),e(a2e,jYo),e(Hb,DYo),e(Hb,Oz),e(Oz,GYo),e(Hb,OYo),e(U,VYo),e(U,Ub),e(Ub,n2e),e(n2e,XYo),e(Ub,zYo),e(Ub,Vz),e(Vz,QYo),e(Ub,WYo),e(U,HYo),e(U,Jb),e(Jb,s2e),e(s2e,UYo),e(Jb,JYo),e(Jb,Xz),e(Xz,YYo),e(Jb,KYo),e(U,ZYo),e(U,Yb),e(Yb,l2e),e(l2e,eKo),e(Yb,oKo),e(Yb,zz),e(zz,rKo),e(Yb,tKo),e(U,aKo),e(U,Kb),e(Kb,i2e),e(i2e,nKo),e(Kb,sKo),e(Kb,Qz),e(Qz,lKo),e(Kb,iKo),e(U,dKo),e(U,Zb),e(Zb,d2e),e(d2e,cKo),e(Zb,fKo),e(Zb,Wz),e(Wz,mKo),e(Zb,gKo),e(U,hKo),e(U,ev),e(ev,c2e),e(c2e,pKo),e(ev,_Ko),e(ev,Hz),e(Hz,uKo),e(ev,bKo),e(U,vKo),e(U,ov),e(ov,f2e),e(f2e,FKo),e(ov,TKo),e(ov,Uz),e(Uz,MKo),e(ov,EKo),e(U,CKo),e(U,rv),e(rv,m2e),e(m2e,wKo),e(rv,AKo),e(rv,Jz),e(Jz,LKo),e(rv,yKo),e(U,xKo),e(U,tv),e(tv,g2e),e(g2e,$Ko),e(tv,kKo),e(tv,Yz),e(Yz,SKo),e(tv,RKo),e(U,PKo),e(U,av),e(av,h2e),e(h2e,BKo),e(av,NKo),e(av,Kz),e(Kz,IKo),e(av,qKo),e(U,jKo),e(U,nv),e(nv,p2e),e(p2e,DKo),e(nv,GKo),e(nv,Zz),e(Zz,OKo),e(nv,VKo),e(U,XKo),e(U,sv),e(sv,_2e),e(_2e,zKo),e(sv,QKo),e(sv,eQ),e(eQ,WKo),e(sv,HKo),e(U,UKo),e(U,lv),e(lv,u2e),e(u2e,JKo),e(lv,YKo),e(lv,oQ),e(oQ,KKo),e(lv,ZKo),e(U,eZo),e(U,iv),e(iv,b2e),e(b2e,oZo),e(iv,rZo),e(iv,rQ),e(rQ,tZo),e(iv,aZo),e(U,nZo),e(U,dv),e(dv,v2e),e(v2e,sZo),e(dv,lZo),e(dv,tQ),e(tQ,iZo),e(dv,dZo),e(U,cZo),e(U,cv),e(cv,F2e),e(F2e,fZo),e(cv,mZo),e(cv,aQ),e(aQ,gZo),e(cv,hZo),e(ao,pZo),e(ao,fv),e(fv,_Zo),e(fv,T2e),e(T2e,uZo),e(fv,bZo),e(fv,M2e),e(M2e,vZo),e(ao,FZo),M(mv,ao,null),b(f,ZVe,u),b(f,md,u),e(md,gv),e(gv,E2e),M(h8,E2e,null),e(md,TZo),e(md,C2e),e(C2e,MZo),b(f,eXe,u),b(f,jo,u),M(p8,jo,null),e(jo,EZo),e(jo,gd),e(gd,CZo),e(gd,nQ),e(nQ,wZo),e(gd,AZo),e(gd,sQ),e(sQ,LZo),e(gd,yZo),e(jo,xZo),e(jo,_8),e(_8,$Zo),e(_8,w2e),e(w2e,kZo),e(_8,SZo),e(jo,RZo),e(jo,pt),M(u8,pt,null),e(pt,PZo),e(pt,A2e),e(A2e,BZo),e(pt,NZo),e(pt,hd),e(hd,IZo),e(hd,L2e),e(L2e,qZo),e(hd,jZo),e(hd,lQ),e(lQ,DZo),e(hd,GZo),e(pt,OZo),M(hv,pt,null),e(jo,VZo),e(jo,no),M(b8,no,null),e(no,XZo),e(no,y2e),e(y2e,zZo),e(no,QZo),e(no,Xa),e(Xa,WZo),e(Xa,x2e),e(x2e,HZo),e(Xa,UZo),e(Xa,$2e),e($2e,JZo),e(Xa,YZo),e(Xa,k2e),e(k2e,KZo),e(Xa,ZZo),e(no,eer),e(no,V),e(V,pv),e(pv,S2e),e(S2e,oer),e(pv,rer),e(pv,iQ),e(iQ,ter),e(pv,aer),e(V,ner),e(V,_v),e(_v,R2e),e(R2e,ser),e(_v,ler),e(_v,dQ),e(dQ,ier),e(_v,der),e(V,cer),e(V,uv),e(uv,P2e),e(P2e,fer),e(uv,mer),e(uv,cQ),e(cQ,ger),e(uv,her),e(V,per),e(V,bv),e(bv,B2e),e(B2e,_er),e(bv,uer),e(bv,fQ),e(fQ,ber),e(bv,ver),e(V,Fer),e(V,vv),e(vv,N2e),e(N2e,Ter),e(vv,Mer),e(vv,mQ),e(mQ,Eer),e(vv,Cer),e(V,wer),e(V,Fv),e(Fv,I2e),e(I2e,Aer),e(Fv,Ler),e(Fv,gQ),e(gQ,yer),e(Fv,xer),e(V,$er),e(V,Tv),e(Tv,q2e),e(q2e,ker),e(Tv,Ser),e(Tv,hQ),e(hQ,Rer),e(Tv,Per),e(V,Ber),e(V,Mv),e(Mv,j2e),e(j2e,Ner),e(Mv,Ier),e(Mv,pQ),e(pQ,qer),e(Mv,jer),e(V,Der),e(V,Ev),e(Ev,D2e),e(D2e,Ger),e(Ev,Oer),e(Ev,_Q),e(_Q,Ver),e(Ev,Xer),e(V,zer),e(V,Cv),e(Cv,G2e),e(G2e,Qer),e(Cv,Wer),e(Cv,uQ),e(uQ,Her),e(Cv,Uer),e(V,Jer),e(V,wv),e(wv,O2e),e(O2e,Yer),e(wv,Ker),e(wv,bQ),e(bQ,Zer),e(wv,eor),e(V,oor),e(V,Av),e(Av,V2e),e(V2e,ror),e(Av,tor),e(Av,vQ),e(vQ,aor),e(Av,nor),e(V,sor),e(V,Lv),e(Lv,X2e),e(X2e,lor),e(Lv,ior),e(Lv,FQ),e(FQ,dor),e(Lv,cor),e(V,mor),e(V,yv),e(yv,z2e),e(z2e,gor),e(yv,hor),e(yv,TQ),e(TQ,por),e(yv,_or),e(V,uor),e(V,xv),e(xv,Q2e),e(Q2e,bor),e(xv,vor),e(xv,MQ),e(MQ,For),e(xv,Tor),e(V,Mor),e(V,$v),e($v,W2e),e(W2e,Eor),e($v,Cor),e($v,EQ),e(EQ,wor),e($v,Aor),e(V,Lor),e(V,kv),e(kv,H2e),e(H2e,yor),e(kv,xor),e(kv,CQ),e(CQ,$or),e(kv,kor),e(V,Sor),e(V,Sv),e(Sv,U2e),e(U2e,Ror),e(Sv,Por),e(Sv,wQ),e(wQ,Bor),e(Sv,Nor),e(V,Ior),e(V,Rv),e(Rv,J2e),e(J2e,qor),e(Rv,jor),e(Rv,AQ),e(AQ,Dor),e(Rv,Gor),e(V,Oor),e(V,Pv),e(Pv,Y2e),e(Y2e,Vor),e(Pv,Xor),e(Pv,LQ),e(LQ,zor),e(Pv,Qor),e(V,Wor),e(V,Bv),e(Bv,K2e),e(K2e,Hor),e(Bv,Uor),e(Bv,yQ),e(yQ,Jor),e(Bv,Yor),e(V,Kor),e(V,Nv),e(Nv,Z2e),e(Z2e,Zor),e(Nv,err),e(Nv,xQ),e(xQ,orr),e(Nv,rrr),e(V,trr),e(V,Iv),e(Iv,e1e),e(e1e,arr),e(Iv,nrr),e(Iv,$Q),e($Q,srr),e(Iv,lrr),e(V,irr),e(V,qv),e(qv,o1e),e(o1e,drr),e(qv,crr),e(qv,kQ),e(kQ,frr),e(qv,mrr),e(V,grr),e(V,jv),e(jv,r1e),e(r1e,hrr),e(jv,prr),e(jv,SQ),e(SQ,_rr),e(jv,urr),e(V,brr),e(V,Dv),e(Dv,t1e),e(t1e,vrr),e(Dv,Frr),e(Dv,RQ),e(RQ,Trr),e(Dv,Mrr),e(V,Err),e(V,Gv),e(Gv,a1e),e(a1e,Crr),e(Gv,wrr),e(Gv,PQ),e(PQ,Arr),e(Gv,Lrr),e(V,yrr),e(V,Ov),e(Ov,n1e),e(n1e,xrr),e(Ov,$rr),e(Ov,BQ),e(BQ,krr),e(Ov,Srr),e(V,Rrr),e(V,Vv),e(Vv,s1e),e(s1e,Prr),e(Vv,Brr),e(Vv,NQ),e(NQ,Nrr),e(Vv,Irr),e(V,qrr),e(V,Xv),e(Xv,l1e),e(l1e,jrr),e(Xv,Drr),e(Xv,IQ),e(IQ,Grr),e(Xv,Orr),e(V,Vrr),e(V,zv),e(zv,i1e),e(i1e,Xrr),e(zv,zrr),e(zv,qQ),e(qQ,Qrr),e(zv,Wrr),e(V,Hrr),e(V,Qv),e(Qv,d1e),e(d1e,Urr),e(Qv,Jrr),e(Qv,jQ),e(jQ,Yrr),e(Qv,Krr),e(V,Zrr),e(V,Wv),e(Wv,c1e),e(c1e,etr),e(Wv,otr),e(Wv,DQ),e(DQ,rtr),e(Wv,ttr),e(V,atr),e(V,Hv),e(Hv,f1e),e(f1e,ntr),e(Hv,str),e(Hv,GQ),e(GQ,ltr),e(Hv,itr),e(V,dtr),e(V,Uv),e(Uv,m1e),e(m1e,ctr),e(Uv,ftr),e(Uv,OQ),e(OQ,mtr),e(Uv,gtr),e(V,htr),e(V,Jv),e(Jv,g1e),e(g1e,ptr),e(Jv,_tr),e(Jv,VQ),e(VQ,utr),e(Jv,btr),e(V,vtr),e(V,Yv),e(Yv,h1e),e(h1e,Ftr),e(Yv,Ttr),e(Yv,XQ),e(XQ,Mtr),e(Yv,Etr),e(V,Ctr),e(V,Kv),e(Kv,p1e),e(p1e,wtr),e(Kv,Atr),e(Kv,zQ),e(zQ,Ltr),e(Kv,ytr),e(V,xtr),e(V,Zv),e(Zv,_1e),e(_1e,$tr),e(Zv,ktr),e(Zv,QQ),e(QQ,Str),e(Zv,Rtr),e(V,Ptr),e(V,eF),e(eF,u1e),e(u1e,Btr),e(eF,Ntr),e(eF,WQ),e(WQ,Itr),e(eF,qtr),e(V,jtr),e(V,oF),e(oF,b1e),e(b1e,Dtr),e(oF,Gtr),e(oF,HQ),e(HQ,Otr),e(oF,Vtr),e(V,Xtr),e(V,rF),e(rF,v1e),e(v1e,ztr),e(rF,Qtr),e(rF,UQ),e(UQ,Wtr),e(rF,Htr),e(no,Utr),e(no,tF),e(tF,Jtr),e(tF,F1e),e(F1e,Ytr),e(tF,Ktr),e(tF,T1e),e(T1e,Ztr),e(no,ear),M(aF,no,null),b(f,oXe,u),b(f,pd,u),e(pd,nF),e(nF,M1e),M(v8,M1e,null),e(pd,oar),e(pd,E1e),e(E1e,rar),b(f,rXe,u),b(f,Do,u),M(F8,Do,null),e(Do,tar),e(Do,_d),e(_d,aar),e(_d,JQ),e(JQ,nar),e(_d,sar),e(_d,YQ),e(YQ,lar),e(_d,iar),e(Do,dar),e(Do,T8),e(T8,car),e(T8,C1e),e(C1e,far),e(T8,mar),e(Do,gar),e(Do,_t),M(M8,_t,null),e(_t,har),e(_t,w1e),e(w1e,par),e(_t,_ar),e(_t,ud),e(ud,uar),e(ud,A1e),e(A1e,bar),e(ud,Far),e(ud,KQ),e(KQ,Tar),e(ud,Mar),e(_t,Ear),M(sF,_t,null),e(Do,Car),e(Do,so),M(E8,so,null),e(so,war),e(so,L1e),e(L1e,Aar),e(so,Lar),e(so,za),e(za,yar),e(za,y1e),e(y1e,xar),e(za,$ar),e(za,x1e),e(x1e,kar),e(za,Sar),e(za,$1e),e($1e,Rar),e(za,Par),e(so,Bar),e(so,k1e),e(k1e,lF),e(lF,S1e),e(S1e,Nar),e(lF,Iar),e(lF,ZQ),e(ZQ,qar),e(lF,jar),e(so,Dar),e(so,iF),e(iF,Gar),e(iF,R1e),e(R1e,Oar),e(iF,Var),e(iF,P1e),e(P1e,Xar),e(so,zar),M(dF,so,null),b(f,tXe,u),b(f,bd,u),e(bd,cF),e(cF,B1e),M(C8,B1e,null),e(bd,Qar),e(bd,N1e),e(N1e,War),b(f,aXe,u),b(f,Go,u),M(w8,Go,null),e(Go,Har),e(Go,vd),e(vd,Uar),e(vd,eW),e(eW,Jar),e(vd,Yar),e(vd,oW),e(oW,Kar),e(vd,Zar),e(Go,enr),e(Go,A8),e(A8,onr),e(A8,I1e),e(I1e,rnr),e(A8,tnr),e(Go,anr),e(Go,ut),M(L8,ut,null),e(ut,nnr),e(ut,q1e),e(q1e,snr),e(ut,lnr),e(ut,Fd),e(Fd,inr),e(Fd,j1e),e(j1e,dnr),e(Fd,cnr),e(Fd,rW),e(rW,fnr),e(Fd,mnr),e(ut,gnr),M(fF,ut,null),e(Go,hnr),e(Go,lo),M(y8,lo,null),e(lo,pnr),e(lo,D1e),e(D1e,_nr),e(lo,unr),e(lo,Qa),e(Qa,bnr),e(Qa,G1e),e(G1e,vnr),e(Qa,Fnr),e(Qa,O1e),e(O1e,Tnr),e(Qa,Mnr),e(Qa,V1e),e(V1e,Enr),e(Qa,Cnr),e(lo,wnr),e(lo,Fe),e(Fe,mF),e(mF,X1e),e(X1e,Anr),e(mF,Lnr),e(mF,tW),e(tW,ynr),e(mF,xnr),e(Fe,$nr),e(Fe,gF),e(gF,z1e),e(z1e,knr),e(gF,Snr),e(gF,aW),e(aW,Rnr),e(gF,Pnr),e(Fe,Bnr),e(Fe,hF),e(hF,Q1e),e(Q1e,Nnr),e(hF,Inr),e(hF,nW),e(nW,qnr),e(hF,jnr),e(Fe,Dnr),e(Fe,pF),e(pF,W1e),e(W1e,Gnr),e(pF,Onr),e(pF,sW),e(sW,Vnr),e(pF,Xnr),e(Fe,znr),e(Fe,Hs),e(Hs,H1e),e(H1e,Qnr),e(Hs,Wnr),e(Hs,lW),e(lW,Hnr),e(Hs,Unr),e(Hs,iW),e(iW,Jnr),e(Hs,Ynr),e(Fe,Knr),e(Fe,_F),e(_F,U1e),e(U1e,Znr),e(_F,esr),e(_F,dW),e(dW,osr),e(_F,rsr),e(Fe,tsr),e(Fe,Us),e(Us,J1e),e(J1e,asr),e(Us,nsr),e(Us,cW),e(cW,ssr),e(Us,lsr),e(Us,fW),e(fW,isr),e(Us,dsr),e(Fe,csr),e(Fe,bt),e(bt,Y1e),e(Y1e,fsr),e(bt,msr),e(bt,mW),e(mW,gsr),e(bt,hsr),e(bt,gW),e(gW,psr),e(bt,_sr),e(bt,hW),e(hW,usr),e(bt,bsr),e(Fe,vsr),e(Fe,uF),e(uF,K1e),e(K1e,Fsr),e(uF,Tsr),e(uF,pW),e(pW,Msr),e(uF,Esr),e(Fe,Csr),e(Fe,bF),e(bF,Z1e),e(Z1e,wsr),e(bF,Asr),e(bF,_W),e(_W,Lsr),e(bF,ysr),e(Fe,xsr),e(Fe,vF),e(vF,e7e),e(e7e,$sr),e(vF,ksr),e(vF,uW),e(uW,Ssr),e(vF,Rsr),e(Fe,Psr),e(Fe,FF),e(FF,o7e),e(o7e,Bsr),e(FF,Nsr),e(FF,bW),e(bW,Isr),e(FF,qsr),e(Fe,jsr),e(Fe,TF),e(TF,r7e),e(r7e,Dsr),e(TF,Gsr),e(TF,vW),e(vW,Osr),e(TF,Vsr),e(Fe,Xsr),e(Fe,MF),e(MF,t7e),e(t7e,zsr),e(MF,Qsr),e(MF,FW),e(FW,Wsr),e(MF,Hsr),e(Fe,Usr),e(Fe,EF),e(EF,a7e),e(a7e,Jsr),e(EF,Ysr),e(EF,TW),e(TW,Ksr),e(EF,Zsr),e(lo,elr),e(lo,CF),e(CF,olr),e(CF,n7e),e(n7e,rlr),e(CF,tlr),e(CF,s7e),e(s7e,alr),e(lo,nlr),M(wF,lo,null),b(f,nXe,u),b(f,Td,u),e(Td,AF),e(AF,l7e),M(x8,l7e,null),e(Td,slr),e(Td,i7e),e(i7e,llr),b(f,sXe,u),b(f,Oo,u),M($8,Oo,null),e(Oo,ilr),e(Oo,Md),e(Md,dlr),e(Md,MW),e(MW,clr),e(Md,flr),e(Md,EW),e(EW,mlr),e(Md,glr),e(Oo,hlr),e(Oo,k8),e(k8,plr),e(k8,d7e),e(d7e,_lr),e(k8,ulr),e(Oo,blr),e(Oo,vt),M(S8,vt,null),e(vt,vlr),e(vt,c7e),e(c7e,Flr),e(vt,Tlr),e(vt,Ed),e(Ed,Mlr),e(Ed,f7e),e(f7e,Elr),e(Ed,Clr),e(Ed,CW),e(CW,wlr),e(Ed,Alr),e(vt,Llr),M(LF,vt,null),e(Oo,ylr),e(Oo,io),M(R8,io,null),e(io,xlr),e(io,m7e),e(m7e,$lr),e(io,klr),e(io,Wa),e(Wa,Slr),e(Wa,g7e),e(g7e,Rlr),e(Wa,Plr),e(Wa,h7e),e(h7e,Blr),e(Wa,Nlr),e(Wa,p7e),e(p7e,Ilr),e(Wa,qlr),e(io,jlr),e(io,_7e),e(_7e,yF),e(yF,u7e),e(u7e,Dlr),e(yF,Glr),e(yF,wW),e(wW,Olr),e(yF,Vlr),e(io,Xlr),e(io,xF),e(xF,zlr),e(xF,b7e),e(b7e,Qlr),e(xF,Wlr),e(xF,v7e),e(v7e,Hlr),e(io,Ulr),M($F,io,null),b(f,lXe,u),b(f,Cd,u),e(Cd,kF),e(kF,F7e),M(P8,F7e,null),e(Cd,Jlr),e(Cd,T7e),e(T7e,Ylr),b(f,iXe,u),b(f,Vo,u),M(B8,Vo,null),e(Vo,Klr),e(Vo,wd),e(wd,Zlr),e(wd,AW),e(AW,eir),e(wd,oir),e(wd,LW),e(LW,rir),e(wd,tir),e(Vo,air),e(Vo,N8),e(N8,nir),e(N8,M7e),e(M7e,sir),e(N8,lir),e(Vo,iir),e(Vo,Ft),M(I8,Ft,null),e(Ft,dir),e(Ft,E7e),e(E7e,cir),e(Ft,fir),e(Ft,Ad),e(Ad,mir),e(Ad,C7e),e(C7e,gir),e(Ad,hir),e(Ad,yW),e(yW,pir),e(Ad,_ir),e(Ft,uir),M(SF,Ft,null),e(Vo,bir),e(Vo,co),M(q8,co,null),e(co,vir),e(co,w7e),e(w7e,Fir),e(co,Tir),e(co,Ha),e(Ha,Mir),e(Ha,A7e),e(A7e,Eir),e(Ha,Cir),e(Ha,L7e),e(L7e,wir),e(Ha,Air),e(Ha,y7e),e(y7e,Lir),e(Ha,yir),e(co,xir),e(co,x7e),e(x7e,RF),e(RF,$7e),e($7e,$ir),e(RF,kir),e(RF,xW),e(xW,Sir),e(RF,Rir),e(co,Pir),e(co,PF),e(PF,Bir),e(PF,k7e),e(k7e,Nir),e(PF,Iir),e(PF,S7e),e(S7e,qir),e(co,jir),M(BF,co,null),b(f,dXe,u),b(f,Ld,u),e(Ld,NF),e(NF,R7e),M(j8,R7e,null),e(Ld,Dir),e(Ld,P7e),e(P7e,Gir),b(f,cXe,u),b(f,Xo,u),M(D8,Xo,null),e(Xo,Oir),e(Xo,yd),e(yd,Vir),e(yd,$W),e($W,Xir),e(yd,zir),e(yd,kW),e(kW,Qir),e(yd,Wir),e(Xo,Hir),e(Xo,G8),e(G8,Uir),e(G8,B7e),e(B7e,Jir),e(G8,Yir),e(Xo,Kir),e(Xo,Tt),M(O8,Tt,null),e(Tt,Zir),e(Tt,N7e),e(N7e,edr),e(Tt,odr),e(Tt,xd),e(xd,rdr),e(xd,I7e),e(I7e,tdr),e(xd,adr),e(xd,SW),e(SW,ndr),e(xd,sdr),e(Tt,ldr),M(IF,Tt,null),e(Xo,idr),e(Xo,fo),M(V8,fo,null),e(fo,ddr),e(fo,q7e),e(q7e,cdr),e(fo,fdr),e(fo,Ua),e(Ua,mdr),e(Ua,j7e),e(j7e,gdr),e(Ua,hdr),e(Ua,D7e),e(D7e,pdr),e(Ua,_dr),e(Ua,G7e),e(G7e,udr),e(Ua,bdr),e(fo,vdr),e(fo,Pe),e(Pe,qF),e(qF,O7e),e(O7e,Fdr),e(qF,Tdr),e(qF,RW),e(RW,Mdr),e(qF,Edr),e(Pe,Cdr),e(Pe,jF),e(jF,V7e),e(V7e,wdr),e(jF,Adr),e(jF,PW),e(PW,Ldr),e(jF,ydr),e(Pe,xdr),e(Pe,DF),e(DF,X7e),e(X7e,$dr),e(DF,kdr),e(DF,BW),e(BW,Sdr),e(DF,Rdr),e(Pe,Pdr),e(Pe,GF),e(GF,z7e),e(z7e,Bdr),e(GF,Ndr),e(GF,NW),e(NW,Idr),e(GF,qdr),e(Pe,jdr),e(Pe,OF),e(OF,Q7e),e(Q7e,Ddr),e(OF,Gdr),e(OF,IW),e(IW,Odr),e(OF,Vdr),e(Pe,Xdr),e(Pe,VF),e(VF,W7e),e(W7e,zdr),e(VF,Qdr),e(VF,qW),e(qW,Wdr),e(VF,Hdr),e(Pe,Udr),e(Pe,XF),e(XF,H7e),e(H7e,Jdr),e(XF,Ydr),e(XF,jW),e(jW,Kdr),e(XF,Zdr),e(Pe,ecr),e(Pe,zF),e(zF,U7e),e(U7e,ocr),e(zF,rcr),e(zF,DW),e(DW,tcr),e(zF,acr),e(Pe,ncr),e(Pe,QF),e(QF,J7e),e(J7e,scr),e(QF,lcr),e(QF,GW),e(GW,icr),e(QF,dcr),e(fo,ccr),e(fo,WF),e(WF,fcr),e(WF,Y7e),e(Y7e,mcr),e(WF,gcr),e(WF,K7e),e(K7e,hcr),e(fo,pcr),M(HF,fo,null),b(f,fXe,u),b(f,$d,u),e($d,UF),e(UF,Z7e),M(X8,Z7e,null),e($d,_cr),e($d,e4e),e(e4e,ucr),b(f,mXe,u),b(f,zo,u),M(z8,zo,null),e(zo,bcr),e(zo,kd),e(kd,vcr),e(kd,OW),e(OW,Fcr),e(kd,Tcr),e(kd,VW),e(VW,Mcr),e(kd,Ecr),e(zo,Ccr),e(zo,Q8),e(Q8,wcr),e(Q8,o4e),e(o4e,Acr),e(Q8,Lcr),e(zo,ycr),e(zo,Mt),M(W8,Mt,null),e(Mt,xcr),e(Mt,r4e),e(r4e,$cr),e(Mt,kcr),e(Mt,Sd),e(Sd,Scr),e(Sd,t4e),e(t4e,Rcr),e(Sd,Pcr),e(Sd,XW),e(XW,Bcr),e(Sd,Ncr),e(Mt,Icr),M(JF,Mt,null),e(zo,qcr),e(zo,mo),M(H8,mo,null),e(mo,jcr),e(mo,a4e),e(a4e,Dcr),e(mo,Gcr),e(mo,Ja),e(Ja,Ocr),e(Ja,n4e),e(n4e,Vcr),e(Ja,Xcr),e(Ja,s4e),e(s4e,zcr),e(Ja,Qcr),e(Ja,l4e),e(l4e,Wcr),e(Ja,Hcr),e(mo,Ucr),e(mo,ot),e(ot,YF),e(YF,i4e),e(i4e,Jcr),e(YF,Ycr),e(YF,zW),e(zW,Kcr),e(YF,Zcr),e(ot,efr),e(ot,KF),e(KF,d4e),e(d4e,ofr),e(KF,rfr),e(KF,QW),e(QW,tfr),e(KF,afr),e(ot,nfr),e(ot,ZF),e(ZF,c4e),e(c4e,sfr),e(ZF,lfr),e(ZF,WW),e(WW,ifr),e(ZF,dfr),e(ot,cfr),e(ot,eT),e(eT,f4e),e(f4e,ffr),e(eT,mfr),e(eT,HW),e(HW,gfr),e(eT,hfr),e(ot,pfr),e(ot,oT),e(oT,m4e),e(m4e,_fr),e(oT,ufr),e(oT,UW),e(UW,bfr),e(oT,vfr),e(mo,Ffr),e(mo,rT),e(rT,Tfr),e(rT,g4e),e(g4e,Mfr),e(rT,Efr),e(rT,h4e),e(h4e,Cfr),e(mo,wfr),M(tT,mo,null),b(f,gXe,u),b(f,Rd,u),e(Rd,aT),e(aT,p4e),M(U8,p4e,null),e(Rd,Afr),e(Rd,_4e),e(_4e,Lfr),b(f,hXe,u),b(f,Qo,u),M(J8,Qo,null),e(Qo,yfr),e(Qo,Pd),e(Pd,xfr),e(Pd,JW),e(JW,$fr),e(Pd,kfr),e(Pd,YW),e(YW,Sfr),e(Pd,Rfr),e(Qo,Pfr),e(Qo,Y8),e(Y8,Bfr),e(Y8,u4e),e(u4e,Nfr),e(Y8,Ifr),e(Qo,qfr),e(Qo,Et),M(K8,Et,null),e(Et,jfr),e(Et,b4e),e(b4e,Dfr),e(Et,Gfr),e(Et,Bd),e(Bd,Ofr),e(Bd,v4e),e(v4e,Vfr),e(Bd,Xfr),e(Bd,KW),e(KW,zfr),e(Bd,Qfr),e(Et,Wfr),M(nT,Et,null),e(Qo,Hfr),e(Qo,go),M(Z8,go,null),e(go,Ufr),e(go,F4e),e(F4e,Jfr),e(go,Yfr),e(go,Ya),e(Ya,Kfr),e(Ya,T4e),e(T4e,Zfr),e(Ya,emr),e(Ya,M4e),e(M4e,omr),e(Ya,rmr),e(Ya,E4e),e(E4e,tmr),e(Ya,amr),e(go,nmr),e(go,Le),e(Le,sT),e(sT,C4e),e(C4e,smr),e(sT,lmr),e(sT,ZW),e(ZW,imr),e(sT,dmr),e(Le,cmr),e(Le,lT),e(lT,w4e),e(w4e,fmr),e(lT,mmr),e(lT,eH),e(eH,gmr),e(lT,hmr),e(Le,pmr),e(Le,iT),e(iT,A4e),e(A4e,_mr),e(iT,umr),e(iT,oH),e(oH,bmr),e(iT,vmr),e(Le,Fmr),e(Le,dT),e(dT,L4e),e(L4e,Tmr),e(dT,Mmr),e(dT,rH),e(rH,Emr),e(dT,Cmr),e(Le,wmr),e(Le,cT),e(cT,y4e),e(y4e,Amr),e(cT,Lmr),e(cT,tH),e(tH,ymr),e(cT,xmr),e(Le,$mr),e(Le,fT),e(fT,x4e),e(x4e,kmr),e(fT,Smr),e(fT,aH),e(aH,Rmr),e(fT,Pmr),e(Le,Bmr),e(Le,mT),e(mT,$4e),e($4e,Nmr),e(mT,Imr),e(mT,nH),e(nH,qmr),e(mT,jmr),e(Le,Dmr),e(Le,gT),e(gT,k4e),e(k4e,Gmr),e(gT,Omr),e(gT,sH),e(sH,Vmr),e(gT,Xmr),e(Le,zmr),e(Le,hT),e(hT,S4e),e(S4e,Qmr),e(hT,Wmr),e(hT,lH),e(lH,Hmr),e(hT,Umr),e(Le,Jmr),e(Le,pT),e(pT,R4e),e(R4e,Ymr),e(pT,Kmr),e(pT,iH),e(iH,Zmr),e(pT,egr),e(go,ogr),e(go,_T),e(_T,rgr),e(_T,P4e),e(P4e,tgr),e(_T,agr),e(_T,B4e),e(B4e,ngr),e(go,sgr),M(uT,go,null),b(f,pXe,u),b(f,Nd,u),e(Nd,bT),e(bT,N4e),M(e9,N4e,null),e(Nd,lgr),e(Nd,I4e),e(I4e,igr),b(f,_Xe,u),b(f,Wo,u),M(o9,Wo,null),e(Wo,dgr),e(Wo,Id),e(Id,cgr),e(Id,dH),e(dH,fgr),e(Id,mgr),e(Id,cH),e(cH,ggr),e(Id,hgr),e(Wo,pgr),e(Wo,r9),e(r9,_gr),e(r9,q4e),e(q4e,ugr),e(r9,bgr),e(Wo,vgr),e(Wo,Ct),M(t9,Ct,null),e(Ct,Fgr),e(Ct,j4e),e(j4e,Tgr),e(Ct,Mgr),e(Ct,qd),e(qd,Egr),e(qd,D4e),e(D4e,Cgr),e(qd,wgr),e(qd,fH),e(fH,Agr),e(qd,Lgr),e(Ct,ygr),M(vT,Ct,null),e(Wo,xgr),e(Wo,ho),M(a9,ho,null),e(ho,$gr),e(ho,G4e),e(G4e,kgr),e(ho,Sgr),e(ho,Ka),e(Ka,Rgr),e(Ka,O4e),e(O4e,Pgr),e(Ka,Bgr),e(Ka,V4e),e(V4e,Ngr),e(Ka,Igr),e(Ka,X4e),e(X4e,qgr),e(Ka,jgr),e(ho,Dgr),e(ho,n9),e(n9,FT),e(FT,z4e),e(z4e,Ggr),e(FT,Ogr),e(FT,mH),e(mH,Vgr),e(FT,Xgr),e(n9,zgr),e(n9,TT),e(TT,Q4e),e(Q4e,Qgr),e(TT,Wgr),e(TT,gH),e(gH,Hgr),e(TT,Ugr),e(ho,Jgr),e(ho,MT),e(MT,Ygr),e(MT,W4e),e(W4e,Kgr),e(MT,Zgr),e(MT,H4e),e(H4e,ehr),e(ho,ohr),M(ET,ho,null),b(f,uXe,u),b(f,jd,u),e(jd,CT),e(CT,U4e),M(s9,U4e,null),e(jd,rhr),e(jd,J4e),e(J4e,thr),b(f,bXe,u),b(f,Ho,u),M(l9,Ho,null),e(Ho,ahr),e(Ho,Dd),e(Dd,nhr),e(Dd,hH),e(hH,shr),e(Dd,lhr),e(Dd,pH),e(pH,ihr),e(Dd,dhr),e(Ho,chr),e(Ho,i9),e(i9,fhr),e(i9,Y4e),e(Y4e,mhr),e(i9,ghr),e(Ho,hhr),e(Ho,wt),M(d9,wt,null),e(wt,phr),e(wt,K4e),e(K4e,_hr),e(wt,uhr),e(wt,Gd),e(Gd,bhr),e(Gd,Z4e),e(Z4e,vhr),e(Gd,Fhr),e(Gd,_H),e(_H,Thr),e(Gd,Mhr),e(wt,Ehr),M(wT,wt,null),e(Ho,Chr),e(Ho,po),M(c9,po,null),e(po,whr),e(po,ebe),e(ebe,Ahr),e(po,Lhr),e(po,Za),e(Za,yhr),e(Za,obe),e(obe,xhr),e(Za,$hr),e(Za,rbe),e(rbe,khr),e(Za,Shr),e(Za,tbe),e(tbe,Rhr),e(Za,Phr),e(po,Bhr),e(po,rt),e(rt,AT),e(AT,abe),e(abe,Nhr),e(AT,Ihr),e(AT,uH),e(uH,qhr),e(AT,jhr),e(rt,Dhr),e(rt,LT),e(LT,nbe),e(nbe,Ghr),e(LT,Ohr),e(LT,bH),e(bH,Vhr),e(LT,Xhr),e(rt,zhr),e(rt,yT),e(yT,sbe),e(sbe,Qhr),e(yT,Whr),e(yT,vH),e(vH,Hhr),e(yT,Uhr),e(rt,Jhr),e(rt,xT),e(xT,lbe),e(lbe,Yhr),e(xT,Khr),e(xT,FH),e(FH,Zhr),e(xT,epr),e(rt,opr),e(rt,$T),e($T,ibe),e(ibe,rpr),e($T,tpr),e($T,TH),e(TH,apr),e($T,npr),e(po,spr),e(po,kT),e(kT,lpr),e(kT,dbe),e(dbe,ipr),e(kT,dpr),e(kT,cbe),e(cbe,cpr),e(po,fpr),M(ST,po,null),b(f,vXe,u),b(f,Od,u),e(Od,RT),e(RT,fbe),M(f9,fbe,null),e(Od,mpr),e(Od,mbe),e(mbe,gpr),b(f,FXe,u),b(f,Uo,u),M(m9,Uo,null),e(Uo,hpr),e(Uo,Vd),e(Vd,ppr),e(Vd,MH),e(MH,_pr),e(Vd,upr),e(Vd,EH),e(EH,bpr),e(Vd,vpr),e(Uo,Fpr),e(Uo,g9),e(g9,Tpr),e(g9,gbe),e(gbe,Mpr),e(g9,Epr),e(Uo,Cpr),e(Uo,At),M(h9,At,null),e(At,wpr),e(At,hbe),e(hbe,Apr),e(At,Lpr),e(At,Xd),e(Xd,ypr),e(Xd,pbe),e(pbe,xpr),e(Xd,$pr),e(Xd,CH),e(CH,kpr),e(Xd,Spr),e(At,Rpr),M(PT,At,null),e(Uo,Ppr),e(Uo,_o),M(p9,_o,null),e(_o,Bpr),e(_o,_be),e(_be,Npr),e(_o,Ipr),e(_o,en),e(en,qpr),e(en,ube),e(ube,jpr),e(en,Dpr),e(en,bbe),e(bbe,Gpr),e(en,Opr),e(en,vbe),e(vbe,Vpr),e(en,Xpr),e(_o,zpr),e(_o,zd),e(zd,BT),e(BT,Fbe),e(Fbe,Qpr),e(BT,Wpr),e(BT,wH),e(wH,Hpr),e(BT,Upr),e(zd,Jpr),e(zd,NT),e(NT,Tbe),e(Tbe,Ypr),e(NT,Kpr),e(NT,AH),e(AH,Zpr),e(NT,e_r),e(zd,o_r),e(zd,IT),e(IT,Mbe),e(Mbe,r_r),e(IT,t_r),e(IT,LH),e(LH,a_r),e(IT,n_r),e(_o,s_r),e(_o,qT),e(qT,l_r),e(qT,Ebe),e(Ebe,i_r),e(qT,d_r),e(qT,Cbe),e(Cbe,c_r),e(_o,f_r),M(jT,_o,null),b(f,TXe,u),b(f,Qd,u),e(Qd,DT),e(DT,wbe),M(_9,wbe,null),e(Qd,m_r),e(Qd,Abe),e(Abe,g_r),b(f,MXe,u),b(f,Jo,u),M(u9,Jo,null),e(Jo,h_r),e(Jo,Wd),e(Wd,p_r),e(Wd,yH),e(yH,__r),e(Wd,u_r),e(Wd,xH),e(xH,b_r),e(Wd,v_r),e(Jo,F_r),e(Jo,b9),e(b9,T_r),e(b9,Lbe),e(Lbe,M_r),e(b9,E_r),e(Jo,C_r),e(Jo,Lt),M(v9,Lt,null),e(Lt,w_r),e(Lt,ybe),e(ybe,A_r),e(Lt,L_r),e(Lt,Hd),e(Hd,y_r),e(Hd,xbe),e(xbe,x_r),e(Hd,$_r),e(Hd,$H),e($H,k_r),e(Hd,S_r),e(Lt,R_r),M(GT,Lt,null),e(Jo,P_r),e(Jo,uo),M(F9,uo,null),e(uo,B_r),e(uo,$be),e($be,N_r),e(uo,I_r),e(uo,on),e(on,q_r),e(on,kbe),e(kbe,j_r),e(on,D_r),e(on,Sbe),e(Sbe,G_r),e(on,O_r),e(on,Rbe),e(Rbe,V_r),e(on,X_r),e(uo,z_r),e(uo,T9),e(T9,OT),e(OT,Pbe),e(Pbe,Q_r),e(OT,W_r),e(OT,kH),e(kH,H_r),e(OT,U_r),e(T9,J_r),e(T9,VT),e(VT,Bbe),e(Bbe,Y_r),e(VT,K_r),e(VT,SH),e(SH,Z_r),e(VT,eur),e(uo,our),e(uo,XT),e(XT,rur),e(XT,Nbe),e(Nbe,tur),e(XT,aur),e(XT,Ibe),e(Ibe,nur),e(uo,sur),M(zT,uo,null),b(f,EXe,u),b(f,Ud,u),e(Ud,QT),e(QT,qbe),M(M9,qbe,null),e(Ud,lur),e(Ud,jbe),e(jbe,iur),b(f,CXe,u),b(f,Yo,u),M(E9,Yo,null),e(Yo,dur),e(Yo,Jd),e(Jd,cur),e(Jd,RH),e(RH,fur),e(Jd,mur),e(Jd,PH),e(PH,gur),e(Jd,hur),e(Yo,pur),e(Yo,C9),e(C9,_ur),e(C9,Dbe),e(Dbe,uur),e(C9,bur),e(Yo,vur),e(Yo,yt),M(w9,yt,null),e(yt,Fur),e(yt,Gbe),e(Gbe,Tur),e(yt,Mur),e(yt,Yd),e(Yd,Eur),e(Yd,Obe),e(Obe,Cur),e(Yd,wur),e(Yd,BH),e(BH,Aur),e(Yd,Lur),e(yt,yur),M(WT,yt,null),e(Yo,xur),e(Yo,bo),M(A9,bo,null),e(bo,$ur),e(bo,Vbe),e(Vbe,kur),e(bo,Sur),e(bo,rn),e(rn,Rur),e(rn,Xbe),e(Xbe,Pur),e(rn,Bur),e(rn,zbe),e(zbe,Nur),e(rn,Iur),e(rn,Qbe),e(Qbe,qur),e(rn,jur),e(bo,Dur),e(bo,Wbe),e(Wbe,HT),e(HT,Hbe),e(Hbe,Gur),e(HT,Our),e(HT,NH),e(NH,Vur),e(HT,Xur),e(bo,zur),e(bo,UT),e(UT,Qur),e(UT,Ube),e(Ube,Wur),e(UT,Hur),e(UT,Jbe),e(Jbe,Uur),e(bo,Jur),M(JT,bo,null),b(f,wXe,u),b(f,Kd,u),e(Kd,YT),e(YT,Ybe),M(L9,Ybe,null),e(Kd,Yur),e(Kd,Kbe),e(Kbe,Kur),b(f,AXe,u),b(f,Ko,u),M(y9,Ko,null),e(Ko,Zur),e(Ko,Zd),e(Zd,e2r),e(Zd,IH),e(IH,o2r),e(Zd,r2r),e(Zd,qH),e(qH,t2r),e(Zd,a2r),e(Ko,n2r),e(Ko,x9),e(x9,s2r),e(x9,Zbe),e(Zbe,l2r),e(x9,i2r),e(Ko,d2r),e(Ko,xt),M($9,xt,null),e(xt,c2r),e(xt,eve),e(eve,f2r),e(xt,m2r),e(xt,ec),e(ec,g2r),e(ec,ove),e(ove,h2r),e(ec,p2r),e(ec,jH),e(jH,_2r),e(ec,u2r),e(xt,b2r),M(KT,xt,null),e(Ko,v2r),e(Ko,vo),M(k9,vo,null),e(vo,F2r),e(vo,rve),e(rve,T2r),e(vo,M2r),e(vo,tn),e(tn,E2r),e(tn,tve),e(tve,C2r),e(tn,w2r),e(tn,ave),e(ave,A2r),e(tn,L2r),e(tn,nve),e(nve,y2r),e(tn,x2r),e(vo,$2r),e(vo,an),e(an,ZT),e(ZT,sve),e(sve,k2r),e(ZT,S2r),e(ZT,DH),e(DH,R2r),e(ZT,P2r),e(an,B2r),e(an,eM),e(eM,lve),e(lve,N2r),e(eM,I2r),e(eM,GH),e(GH,q2r),e(eM,j2r),e(an,D2r),e(an,oM),e(oM,ive),e(ive,G2r),e(oM,O2r),e(oM,OH),e(OH,V2r),e(oM,X2r),e(an,z2r),e(an,rM),e(rM,dve),e(dve,Q2r),e(rM,W2r),e(rM,VH),e(VH,H2r),e(rM,U2r),e(vo,J2r),e(vo,tM),e(tM,Y2r),e(tM,cve),e(cve,K2r),e(tM,Z2r),e(tM,fve),e(fve,e1r),e(vo,o1r),M(aM,vo,null),b(f,LXe,u),b(f,oc,u),e(oc,nM),e(nM,mve),M(S9,mve,null),e(oc,r1r),e(oc,gve),e(gve,t1r),b(f,yXe,u),b(f,Zo,u),M(R9,Zo,null),e(Zo,a1r),e(Zo,rc),e(rc,n1r),e(rc,XH),e(XH,s1r),e(rc,l1r),e(rc,zH),e(zH,i1r),e(rc,d1r),e(Zo,c1r),e(Zo,P9),e(P9,f1r),e(P9,hve),e(hve,m1r),e(P9,g1r),e(Zo,h1r),e(Zo,$t),M(B9,$t,null),e($t,p1r),e($t,pve),e(pve,_1r),e($t,u1r),e($t,tc),e(tc,b1r),e(tc,_ve),e(_ve,v1r),e(tc,F1r),e(tc,QH),e(QH,T1r),e(tc,M1r),e($t,E1r),M(sM,$t,null),e(Zo,C1r),e(Zo,Fo),M(N9,Fo,null),e(Fo,w1r),e(Fo,uve),e(uve,A1r),e(Fo,L1r),e(Fo,nn),e(nn,y1r),e(nn,bve),e(bve,x1r),e(nn,$1r),e(nn,vve),e(vve,k1r),e(nn,S1r),e(nn,Fve),e(Fve,R1r),e(nn,P1r),e(Fo,B1r),e(Fo,Tve),e(Tve,lM),e(lM,Mve),e(Mve,N1r),e(lM,I1r),e(lM,WH),e(WH,q1r),e(lM,j1r),e(Fo,D1r),e(Fo,iM),e(iM,G1r),e(iM,Eve),e(Eve,O1r),e(iM,V1r),e(iM,Cve),e(Cve,X1r),e(Fo,z1r),M(dM,Fo,null),b(f,xXe,u),b(f,ac,u),e(ac,cM),e(cM,wve),M(I9,wve,null),e(ac,Q1r),e(ac,Ave),e(Ave,W1r),b(f,$Xe,u),b(f,er,u),M(q9,er,null),e(er,H1r),e(er,nc),e(nc,U1r),e(nc,HH),e(HH,J1r),e(nc,Y1r),e(nc,UH),e(UH,K1r),e(nc,Z1r),e(er,e7r),e(er,j9),e(j9,o7r),e(j9,Lve),e(Lve,r7r),e(j9,t7r),e(er,a7r),e(er,kt),M(D9,kt,null),e(kt,n7r),e(kt,yve),e(yve,s7r),e(kt,l7r),e(kt,sc),e(sc,i7r),e(sc,xve),e(xve,d7r),e(sc,c7r),e(sc,JH),e(JH,f7r),e(sc,m7r),e(kt,g7r),M(fM,kt,null),e(er,h7r),e(er,xr),M(G9,xr,null),e(xr,p7r),e(xr,$ve),e($ve,_7r),e(xr,u7r),e(xr,sn),e(sn,b7r),e(sn,kve),e(kve,v7r),e(sn,F7r),e(sn,Sve),e(Sve,T7r),e(sn,M7r),e(sn,Rve),e(Rve,E7r),e(sn,C7r),e(xr,w7r),e(xr,q),e(q,mM),e(mM,Pve),e(Pve,A7r),e(mM,L7r),e(mM,YH),e(YH,y7r),e(mM,x7r),e(q,$7r),e(q,gM),e(gM,Bve),e(Bve,k7r),e(gM,S7r),e(gM,KH),e(KH,R7r),e(gM,P7r),e(q,B7r),e(q,hM),e(hM,Nve),e(Nve,N7r),e(hM,I7r),e(hM,ZH),e(ZH,q7r),e(hM,j7r),e(q,D7r),e(q,pM),e(pM,Ive),e(Ive,G7r),e(pM,O7r),e(pM,eU),e(eU,V7r),e(pM,X7r),e(q,z7r),e(q,_M),e(_M,qve),e(qve,Q7r),e(_M,W7r),e(_M,oU),e(oU,H7r),e(_M,U7r),e(q,J7r),e(q,uM),e(uM,jve),e(jve,Y7r),e(uM,K7r),e(uM,rU),e(rU,Z7r),e(uM,e4r),e(q,o4r),e(q,bM),e(bM,Dve),e(Dve,r4r),e(bM,t4r),e(bM,tU),e(tU,a4r),e(bM,n4r),e(q,s4r),e(q,vM),e(vM,Gve),e(Gve,l4r),e(vM,i4r),e(vM,aU),e(aU,d4r),e(vM,c4r),e(q,f4r),e(q,FM),e(FM,Ove),e(Ove,m4r),e(FM,g4r),e(FM,nU),e(nU,h4r),e(FM,p4r),e(q,_4r),e(q,TM),e(TM,Vve),e(Vve,u4r),e(TM,b4r),e(TM,sU),e(sU,v4r),e(TM,F4r),e(q,T4r),e(q,MM),e(MM,Xve),e(Xve,M4r),e(MM,E4r),e(MM,lU),e(lU,C4r),e(MM,w4r),e(q,A4r),e(q,EM),e(EM,zve),e(zve,L4r),e(EM,y4r),e(EM,iU),e(iU,x4r),e(EM,$4r),e(q,k4r),e(q,CM),e(CM,Qve),e(Qve,S4r),e(CM,R4r),e(CM,dU),e(dU,P4r),e(CM,B4r),e(q,N4r),e(q,wM),e(wM,Wve),e(Wve,I4r),e(wM,q4r),e(wM,cU),e(cU,j4r),e(wM,D4r),e(q,G4r),e(q,AM),e(AM,Hve),e(Hve,O4r),e(AM,V4r),e(AM,fU),e(fU,X4r),e(AM,z4r),e(q,Q4r),e(q,LM),e(LM,Uve),e(Uve,W4r),e(LM,H4r),e(LM,mU),e(mU,U4r),e(LM,J4r),e(q,Y4r),e(q,yM),e(yM,Jve),e(Jve,K4r),e(yM,Z4r),e(yM,gU),e(gU,ebr),e(yM,obr),e(q,rbr),e(q,Js),e(Js,Yve),e(Yve,tbr),e(Js,abr),e(Js,hU),e(hU,nbr),e(Js,sbr),e(Js,pU),e(pU,lbr),e(Js,ibr),e(q,dbr),e(q,xM),e(xM,Kve),e(Kve,cbr),e(xM,fbr),e(xM,_U),e(_U,mbr),e(xM,gbr),e(q,hbr),e(q,$M),e($M,Zve),e(Zve,pbr),e($M,_br),e($M,uU),e(uU,ubr),e($M,bbr),e(q,vbr),e(q,kM),e(kM,eFe),e(eFe,Fbr),e(kM,Tbr),e(kM,bU),e(bU,Mbr),e(kM,Ebr),e(q,Cbr),e(q,SM),e(SM,oFe),e(oFe,wbr),e(SM,Abr),e(SM,vU),e(vU,Lbr),e(SM,ybr),e(q,xbr),e(q,RM),e(RM,rFe),e(rFe,$br),e(RM,kbr),e(RM,FU),e(FU,Sbr),e(RM,Rbr),e(q,Pbr),e(q,PM),e(PM,tFe),e(tFe,Bbr),e(PM,Nbr),e(PM,TU),e(TU,Ibr),e(PM,qbr),e(q,jbr),e(q,BM),e(BM,aFe),e(aFe,Dbr),e(BM,Gbr),e(BM,MU),e(MU,Obr),e(BM,Vbr),e(q,Xbr),e(q,NM),e(NM,nFe),e(nFe,zbr),e(NM,Qbr),e(NM,EU),e(EU,Wbr),e(NM,Hbr),e(q,Ubr),e(q,IM),e(IM,sFe),e(sFe,Jbr),e(IM,Ybr),e(IM,CU),e(CU,Kbr),e(IM,Zbr),e(q,evr),e(q,qM),e(qM,lFe),e(lFe,ovr),e(qM,rvr),e(qM,wU),e(wU,tvr),e(qM,avr),e(q,nvr),e(q,jM),e(jM,iFe),e(iFe,svr),e(jM,lvr),e(jM,AU),e(AU,ivr),e(jM,dvr),e(q,cvr),e(q,DM),e(DM,dFe),e(dFe,fvr),e(DM,mvr),e(DM,LU),e(LU,gvr),e(DM,hvr),e(q,pvr),e(q,GM),e(GM,cFe),e(cFe,_vr),e(GM,uvr),e(GM,yU),e(yU,bvr),e(GM,vvr),e(q,Fvr),e(q,OM),e(OM,fFe),e(fFe,Tvr),e(OM,Mvr),e(OM,xU),e(xU,Evr),e(OM,Cvr),e(q,wvr),e(q,VM),e(VM,mFe),e(mFe,Avr),e(VM,Lvr),e(VM,$U),e($U,yvr),e(VM,xvr),e(q,$vr),e(q,XM),e(XM,gFe),e(gFe,kvr),e(XM,Svr),e(XM,kU),e(kU,Rvr),e(XM,Pvr),e(q,Bvr),e(q,zM),e(zM,hFe),e(hFe,Nvr),e(zM,Ivr),e(zM,SU),e(SU,qvr),e(zM,jvr),e(q,Dvr),e(q,QM),e(QM,pFe),e(pFe,Gvr),e(QM,Ovr),e(QM,RU),e(RU,Vvr),e(QM,Xvr),e(q,zvr),e(q,WM),e(WM,_Fe),e(_Fe,Qvr),e(WM,Wvr),e(WM,PU),e(PU,Hvr),e(WM,Uvr),e(q,Jvr),e(q,HM),e(HM,uFe),e(uFe,Yvr),e(HM,Kvr),e(HM,BU),e(BU,Zvr),e(HM,eFr),e(q,oFr),e(q,UM),e(UM,bFe),e(bFe,rFr),e(UM,tFr),e(UM,NU),e(NU,aFr),e(UM,nFr),e(q,sFr),e(q,JM),e(JM,vFe),e(vFe,lFr),e(JM,iFr),e(JM,IU),e(IU,dFr),e(JM,cFr),e(q,fFr),e(q,YM),e(YM,FFe),e(FFe,mFr),e(YM,gFr),e(YM,qU),e(qU,hFr),e(YM,pFr),e(q,_Fr),e(q,KM),e(KM,TFe),e(TFe,uFr),e(KM,bFr),e(KM,jU),e(jU,vFr),e(KM,FFr),e(q,TFr),e(q,ZM),e(ZM,MFe),e(MFe,MFr),e(ZM,EFr),e(ZM,DU),e(DU,CFr),e(ZM,wFr),e(q,AFr),e(q,eE),e(eE,EFe),e(EFe,LFr),e(eE,yFr),e(eE,GU),e(GU,xFr),e(eE,$Fr),e(q,kFr),e(q,oE),e(oE,CFe),e(CFe,SFr),e(oE,RFr),e(oE,OU),e(OU,PFr),e(oE,BFr),e(q,NFr),e(q,rE),e(rE,wFe),e(wFe,IFr),e(rE,qFr),e(rE,VU),e(VU,jFr),e(rE,DFr),e(q,GFr),e(q,tE),e(tE,AFe),e(AFe,OFr),e(tE,VFr),e(tE,XU),e(XU,XFr),e(tE,zFr),e(q,QFr),e(q,aE),e(aE,LFe),e(LFe,WFr),e(aE,HFr),e(aE,zU),e(zU,UFr),e(aE,JFr),e(q,YFr),e(q,nE),e(nE,yFe),e(yFe,KFr),e(nE,ZFr),e(nE,QU),e(QU,eTr),e(nE,oTr),e(xr,rTr),M(sE,xr,null),b(f,kXe,u),b(f,lc,u),e(lc,lE),e(lE,xFe),M(O9,xFe,null),e(lc,tTr),e(lc,$Fe),e($Fe,aTr),b(f,SXe,u),b(f,or,u),M(V9,or,null),e(or,nTr),e(or,ic),e(ic,sTr),e(ic,WU),e(WU,lTr),e(ic,iTr),e(ic,HU),e(HU,dTr),e(ic,cTr),e(or,fTr),e(or,X9),e(X9,mTr),e(X9,kFe),e(kFe,gTr),e(X9,hTr),e(or,pTr),e(or,St),M(z9,St,null),e(St,_Tr),e(St,SFe),e(SFe,uTr),e(St,bTr),e(St,dc),e(dc,vTr),e(dc,RFe),e(RFe,FTr),e(dc,TTr),e(dc,UU),e(UU,MTr),e(dc,ETr),e(St,CTr),M(iE,St,null),e(or,wTr),e(or,$r),M(Q9,$r,null),e($r,ATr),e($r,PFe),e(PFe,LTr),e($r,yTr),e($r,ln),e(ln,xTr),e(ln,BFe),e(BFe,$Tr),e(ln,kTr),e(ln,NFe),e(NFe,STr),e(ln,RTr),e(ln,IFe),e(IFe,PTr),e(ln,BTr),e($r,NTr),e($r,se),e(se,dE),e(dE,qFe),e(qFe,ITr),e(dE,qTr),e(dE,JU),e(JU,jTr),e(dE,DTr),e(se,GTr),e(se,cE),e(cE,jFe),e(jFe,OTr),e(cE,VTr),e(cE,YU),e(YU,XTr),e(cE,zTr),e(se,QTr),e(se,fE),e(fE,DFe),e(DFe,WTr),e(fE,HTr),e(fE,KU),e(KU,UTr),e(fE,JTr),e(se,YTr),e(se,mE),e(mE,GFe),e(GFe,KTr),e(mE,ZTr),e(mE,ZU),e(ZU,eMr),e(mE,oMr),e(se,rMr),e(se,gE),e(gE,OFe),e(OFe,tMr),e(gE,aMr),e(gE,eJ),e(eJ,nMr),e(gE,sMr),e(se,lMr),e(se,hE),e(hE,VFe),e(VFe,iMr),e(hE,dMr),e(hE,oJ),e(oJ,cMr),e(hE,fMr),e(se,mMr),e(se,pE),e(pE,XFe),e(XFe,gMr),e(pE,hMr),e(pE,rJ),e(rJ,pMr),e(pE,_Mr),e(se,uMr),e(se,_E),e(_E,zFe),e(zFe,bMr),e(_E,vMr),e(_E,tJ),e(tJ,FMr),e(_E,TMr),e(se,MMr),e(se,uE),e(uE,QFe),e(QFe,EMr),e(uE,CMr),e(uE,aJ),e(aJ,wMr),e(uE,AMr),e(se,LMr),e(se,bE),e(bE,WFe),e(WFe,yMr),e(bE,xMr),e(bE,nJ),e(nJ,$Mr),e(bE,kMr),e(se,SMr),e(se,vE),e(vE,HFe),e(HFe,RMr),e(vE,PMr),e(vE,sJ),e(sJ,BMr),e(vE,NMr),e(se,IMr),e(se,FE),e(FE,UFe),e(UFe,qMr),e(FE,jMr),e(FE,lJ),e(lJ,DMr),e(FE,GMr),e(se,OMr),e(se,TE),e(TE,JFe),e(JFe,VMr),e(TE,XMr),e(TE,iJ),e(iJ,zMr),e(TE,QMr),e(se,WMr),e(se,ME),e(ME,YFe),e(YFe,HMr),e(ME,UMr),e(ME,dJ),e(dJ,JMr),e(ME,YMr),e(se,KMr),e(se,EE),e(EE,KFe),e(KFe,ZMr),e(EE,eEr),e(EE,cJ),e(cJ,oEr),e(EE,rEr),e(se,tEr),e(se,CE),e(CE,ZFe),e(ZFe,aEr),e(CE,nEr),e(CE,fJ),e(fJ,sEr),e(CE,lEr),e(se,iEr),e(se,wE),e(wE,eTe),e(eTe,dEr),e(wE,cEr),e(wE,mJ),e(mJ,fEr),e(wE,mEr),e(se,gEr),e(se,AE),e(AE,oTe),e(oTe,hEr),e(AE,pEr),e(AE,gJ),e(gJ,_Er),e(AE,uEr),e(se,bEr),e(se,LE),e(LE,rTe),e(rTe,vEr),e(LE,FEr),e(LE,hJ),e(hJ,TEr),e(LE,MEr),e(se,EEr),e(se,yE),e(yE,tTe),e(tTe,CEr),e(yE,wEr),e(yE,pJ),e(pJ,AEr),e(yE,LEr),e(se,yEr),e(se,xE),e(xE,aTe),e(aTe,xEr),e(xE,$Er),e(xE,_J),e(_J,kEr),e(xE,SEr),e(se,REr),e(se,$E),e($E,nTe),e(nTe,PEr),e($E,BEr),e($E,uJ),e(uJ,NEr),e($E,IEr),e(se,qEr),e(se,kE),e(kE,sTe),e(sTe,jEr),e(kE,DEr),e(kE,bJ),e(bJ,GEr),e(kE,OEr),e($r,VEr),M(SE,$r,null),b(f,RXe,u),b(f,cc,u),e(cc,RE),e(RE,lTe),M(W9,lTe,null),e(cc,XEr),e(cc,iTe),e(iTe,zEr),b(f,PXe,u),b(f,rr,u),M(H9,rr,null),e(rr,QEr),e(rr,fc),e(fc,WEr),e(fc,vJ),e(vJ,HEr),e(fc,UEr),e(fc,FJ),e(FJ,JEr),e(fc,YEr),e(rr,KEr),e(rr,U9),e(U9,ZEr),e(U9,dTe),e(dTe,eCr),e(U9,oCr),e(rr,rCr),e(rr,Rt),M(J9,Rt,null),e(Rt,tCr),e(Rt,cTe),e(cTe,aCr),e(Rt,nCr),e(Rt,mc),e(mc,sCr),e(mc,fTe),e(fTe,lCr),e(mc,iCr),e(mc,TJ),e(TJ,dCr),e(mc,cCr),e(Rt,fCr),M(PE,Rt,null),e(rr,mCr),e(rr,kr),M(Y9,kr,null),e(kr,gCr),e(kr,mTe),e(mTe,hCr),e(kr,pCr),e(kr,dn),e(dn,_Cr),e(dn,gTe),e(gTe,uCr),e(dn,bCr),e(dn,hTe),e(hTe,vCr),e(dn,FCr),e(dn,pTe),e(pTe,TCr),e(dn,MCr),e(kr,ECr),e(kr,Me),e(Me,BE),e(BE,_Te),e(_Te,CCr),e(BE,wCr),e(BE,MJ),e(MJ,ACr),e(BE,LCr),e(Me,yCr),e(Me,NE),e(NE,uTe),e(uTe,xCr),e(NE,$Cr),e(NE,EJ),e(EJ,kCr),e(NE,SCr),e(Me,RCr),e(Me,IE),e(IE,bTe),e(bTe,PCr),e(IE,BCr),e(IE,CJ),e(CJ,NCr),e(IE,ICr),e(Me,qCr),e(Me,qE),e(qE,vTe),e(vTe,jCr),e(qE,DCr),e(qE,wJ),e(wJ,GCr),e(qE,OCr),e(Me,VCr),e(Me,jE),e(jE,FTe),e(FTe,XCr),e(jE,zCr),e(jE,AJ),e(AJ,QCr),e(jE,WCr),e(Me,HCr),e(Me,DE),e(DE,TTe),e(TTe,UCr),e(DE,JCr),e(DE,LJ),e(LJ,YCr),e(DE,KCr),e(Me,ZCr),e(Me,GE),e(GE,MTe),e(MTe,e3r),e(GE,o3r),e(GE,yJ),e(yJ,r3r),e(GE,t3r),e(Me,a3r),e(Me,OE),e(OE,ETe),e(ETe,n3r),e(OE,s3r),e(OE,xJ),e(xJ,l3r),e(OE,i3r),e(Me,d3r),e(Me,VE),e(VE,CTe),e(CTe,c3r),e(VE,f3r),e(VE,$J),e($J,m3r),e(VE,g3r),e(Me,h3r),e(Me,XE),e(XE,wTe),e(wTe,p3r),e(XE,_3r),e(XE,kJ),e(kJ,u3r),e(XE,b3r),e(Me,v3r),e(Me,zE),e(zE,ATe),e(ATe,F3r),e(zE,T3r),e(zE,SJ),e(SJ,M3r),e(zE,E3r),e(Me,C3r),e(Me,QE),e(QE,LTe),e(LTe,w3r),e(QE,A3r),e(QE,RJ),e(RJ,L3r),e(QE,y3r),e(Me,x3r),e(Me,WE),e(WE,yTe),e(yTe,$3r),e(WE,k3r),e(WE,PJ),e(PJ,S3r),e(WE,R3r),e(kr,P3r),M(HE,kr,null),b(f,BXe,u),b(f,gc,u),e(gc,UE),e(UE,xTe),M(K9,xTe,null),e(gc,B3r),e(gc,$Te),e($Te,N3r),b(f,NXe,u),b(f,tr,u),M(Z9,tr,null),e(tr,I3r),e(tr,hc),e(hc,q3r),e(hc,BJ),e(BJ,j3r),e(hc,D3r),e(hc,NJ),e(NJ,G3r),e(hc,O3r),e(tr,V3r),e(tr,ex),e(ex,X3r),e(ex,kTe),e(kTe,z3r),e(ex,Q3r),e(tr,W3r),e(tr,Pt),M(ox,Pt,null),e(Pt,H3r),e(Pt,STe),e(STe,U3r),e(Pt,J3r),e(Pt,pc),e(pc,Y3r),e(pc,RTe),e(RTe,K3r),e(pc,Z3r),e(pc,IJ),e(IJ,e5r),e(pc,o5r),e(Pt,r5r),M(JE,Pt,null),e(tr,t5r),e(tr,Sr),M(rx,Sr,null),e(Sr,a5r),e(Sr,PTe),e(PTe,n5r),e(Sr,s5r),e(Sr,cn),e(cn,l5r),e(cn,BTe),e(BTe,i5r),e(cn,d5r),e(cn,NTe),e(NTe,c5r),e(cn,f5r),e(cn,ITe),e(ITe,m5r),e(cn,g5r),e(Sr,h5r),e(Sr,ar),e(ar,YE),e(YE,qTe),e(qTe,p5r),e(YE,_5r),e(YE,qJ),e(qJ,u5r),e(YE,b5r),e(ar,v5r),e(ar,KE),e(KE,jTe),e(jTe,F5r),e(KE,T5r),e(KE,jJ),e(jJ,M5r),e(KE,E5r),e(ar,C5r),e(ar,ZE),e(ZE,DTe),e(DTe,w5r),e(ZE,A5r),e(ZE,DJ),e(DJ,L5r),e(ZE,y5r),e(ar,x5r),e(ar,eC),e(eC,GTe),e(GTe,$5r),e(eC,k5r),e(eC,GJ),e(GJ,S5r),e(eC,R5r),e(ar,P5r),e(ar,oC),e(oC,OTe),e(OTe,B5r),e(oC,N5r),e(oC,OJ),e(OJ,I5r),e(oC,q5r),e(ar,j5r),e(ar,rC),e(rC,VTe),e(VTe,D5r),e(rC,G5r),e(rC,VJ),e(VJ,O5r),e(rC,V5r),e(Sr,X5r),M(tC,Sr,null),b(f,IXe,u),b(f,_c,u),e(_c,aC),e(aC,XTe),M(tx,XTe,null),e(_c,z5r),e(_c,zTe),e(zTe,Q5r),b(f,qXe,u),b(f,nr,u),M(ax,nr,null),e(nr,W5r),e(nr,uc),e(uc,H5r),e(uc,XJ),e(XJ,U5r),e(uc,J5r),e(uc,zJ),e(zJ,Y5r),e(uc,K5r),e(nr,Z5r),e(nr,nx),e(nx,e0r),e(nx,QTe),e(QTe,o0r),e(nx,r0r),e(nr,t0r),e(nr,Bt),M(sx,Bt,null),e(Bt,a0r),e(Bt,WTe),e(WTe,n0r),e(Bt,s0r),e(Bt,bc),e(bc,l0r),e(bc,HTe),e(HTe,i0r),e(bc,d0r),e(bc,QJ),e(QJ,c0r),e(bc,f0r),e(Bt,m0r),M(nC,Bt,null),e(nr,g0r),e(nr,Rr),M(lx,Rr,null),e(Rr,h0r),e(Rr,UTe),e(UTe,p0r),e(Rr,_0r),e(Rr,fn),e(fn,u0r),e(fn,JTe),e(JTe,b0r),e(fn,v0r),e(fn,YTe),e(YTe,F0r),e(fn,T0r),e(fn,KTe),e(KTe,M0r),e(fn,E0r),e(Rr,C0r),e(Rr,ie),e(ie,sC),e(sC,ZTe),e(ZTe,w0r),e(sC,A0r),e(sC,WJ),e(WJ,L0r),e(sC,y0r),e(ie,x0r),e(ie,lC),e(lC,eMe),e(eMe,$0r),e(lC,k0r),e(lC,HJ),e(HJ,S0r),e(lC,R0r),e(ie,P0r),e(ie,iC),e(iC,oMe),e(oMe,B0r),e(iC,N0r),e(iC,UJ),e(UJ,I0r),e(iC,q0r),e(ie,j0r),e(ie,dC),e(dC,rMe),e(rMe,D0r),e(dC,G0r),e(dC,JJ),e(JJ,O0r),e(dC,V0r),e(ie,X0r),e(ie,cC),e(cC,tMe),e(tMe,z0r),e(cC,Q0r),e(cC,YJ),e(YJ,W0r),e(cC,H0r),e(ie,U0r),e(ie,fC),e(fC,aMe),e(aMe,J0r),e(fC,Y0r),e(fC,KJ),e(KJ,K0r),e(fC,Z0r),e(ie,ewr),e(ie,mC),e(mC,nMe),e(nMe,owr),e(mC,rwr),e(mC,ZJ),e(ZJ,twr),e(mC,awr),e(ie,nwr),e(ie,gC),e(gC,sMe),e(sMe,swr),e(gC,lwr),e(gC,eY),e(eY,iwr),e(gC,dwr),e(ie,cwr),e(ie,hC),e(hC,lMe),e(lMe,fwr),e(hC,mwr),e(hC,oY),e(oY,gwr),e(hC,hwr),e(ie,pwr),e(ie,pC),e(pC,iMe),e(iMe,_wr),e(pC,uwr),e(pC,rY),e(rY,bwr),e(pC,vwr),e(ie,Fwr),e(ie,_C),e(_C,dMe),e(dMe,Twr),e(_C,Mwr),e(_C,tY),e(tY,Ewr),e(_C,Cwr),e(ie,wwr),e(ie,uC),e(uC,cMe),e(cMe,Awr),e(uC,Lwr),e(uC,aY),e(aY,ywr),e(uC,xwr),e(ie,$wr),e(ie,bC),e(bC,fMe),e(fMe,kwr),e(bC,Swr),e(bC,nY),e(nY,Rwr),e(bC,Pwr),e(ie,Bwr),e(ie,vC),e(vC,mMe),e(mMe,Nwr),e(vC,Iwr),e(vC,sY),e(sY,qwr),e(vC,jwr),e(ie,Dwr),e(ie,FC),e(FC,gMe),e(gMe,Gwr),e(FC,Owr),e(FC,lY),e(lY,Vwr),e(FC,Xwr),e(ie,zwr),e(ie,TC),e(TC,hMe),e(hMe,Qwr),e(TC,Wwr),e(TC,iY),e(iY,Hwr),e(TC,Uwr),e(ie,Jwr),e(ie,MC),e(MC,pMe),e(pMe,Ywr),e(MC,Kwr),e(MC,dY),e(dY,Zwr),e(MC,eAr),e(ie,oAr),e(ie,EC),e(EC,_Me),e(_Me,rAr),e(EC,tAr),e(EC,cY),e(cY,aAr),e(EC,nAr),e(ie,sAr),e(ie,CC),e(CC,uMe),e(uMe,lAr),e(CC,iAr),e(CC,fY),e(fY,dAr),e(CC,cAr),e(ie,fAr),e(ie,wC),e(wC,bMe),e(bMe,mAr),e(wC,gAr),e(wC,mY),e(mY,hAr),e(wC,pAr),e(Rr,_Ar),M(AC,Rr,null),b(f,jXe,u),b(f,vc,u),e(vc,LC),e(LC,vMe),M(ix,vMe,null),e(vc,uAr),e(vc,FMe),e(FMe,bAr),b(f,DXe,u),b(f,sr,u),M(dx,sr,null),e(sr,vAr),e(sr,Fc),e(Fc,FAr),e(Fc,gY),e(gY,TAr),e(Fc,MAr),e(Fc,hY),e(hY,EAr),e(Fc,CAr),e(sr,wAr),e(sr,cx),e(cx,AAr),e(cx,TMe),e(TMe,LAr),e(cx,yAr),e(sr,xAr),e(sr,Nt),M(fx,Nt,null),e(Nt,$Ar),e(Nt,MMe),e(MMe,kAr),e(Nt,SAr),e(Nt,Tc),e(Tc,RAr),e(Tc,EMe),e(EMe,PAr),e(Tc,BAr),e(Tc,pY),e(pY,NAr),e(Tc,IAr),e(Nt,qAr),M(yC,Nt,null),e(sr,jAr),e(sr,Pr),M(mx,Pr,null),e(Pr,DAr),e(Pr,CMe),e(CMe,GAr),e(Pr,OAr),e(Pr,mn),e(mn,VAr),e(mn,wMe),e(wMe,XAr),e(mn,zAr),e(mn,AMe),e(AMe,QAr),e(mn,WAr),e(mn,LMe),e(LMe,HAr),e(mn,UAr),e(Pr,JAr),e(Pr,ye),e(ye,xC),e(xC,yMe),e(yMe,YAr),e(xC,KAr),e(xC,_Y),e(_Y,ZAr),e(xC,e6r),e(ye,o6r),e(ye,$C),e($C,xMe),e(xMe,r6r),e($C,t6r),e($C,uY),e(uY,a6r),e($C,n6r),e(ye,s6r),e(ye,kC),e(kC,$Me),e($Me,l6r),e(kC,i6r),e(kC,bY),e(bY,d6r),e(kC,c6r),e(ye,f6r),e(ye,SC),e(SC,kMe),e(kMe,m6r),e(SC,g6r),e(SC,vY),e(vY,h6r),e(SC,p6r),e(ye,_6r),e(ye,RC),e(RC,SMe),e(SMe,u6r),e(RC,b6r),e(RC,FY),e(FY,v6r),e(RC,F6r),e(ye,T6r),e(ye,PC),e(PC,RMe),e(RMe,M6r),e(PC,E6r),e(PC,TY),e(TY,C6r),e(PC,w6r),e(ye,A6r),e(ye,BC),e(BC,PMe),e(PMe,L6r),e(BC,y6r),e(BC,MY),e(MY,x6r),e(BC,$6r),e(ye,k6r),e(ye,NC),e(NC,BMe),e(BMe,S6r),e(NC,R6r),e(NC,EY),e(EY,P6r),e(NC,B6r),e(ye,N6r),e(ye,IC),e(IC,NMe),e(NMe,I6r),e(IC,q6r),e(IC,CY),e(CY,j6r),e(IC,D6r),e(ye,G6r),e(ye,qC),e(qC,IMe),e(IMe,O6r),e(qC,V6r),e(qC,wY),e(wY,X6r),e(qC,z6r),e(Pr,Q6r),M(jC,Pr,null),b(f,GXe,u),b(f,Mc,u),e(Mc,DC),e(DC,qMe),M(gx,qMe,null),e(Mc,W6r),e(Mc,jMe),e(jMe,H6r),b(f,OXe,u),b(f,lr,u),M(hx,lr,null),e(lr,U6r),e(lr,Ec),e(Ec,J6r),e(Ec,AY),e(AY,Y6r),e(Ec,K6r),e(Ec,LY),e(LY,Z6r),e(Ec,eLr),e(lr,oLr),e(lr,px),e(px,rLr),e(px,DMe),e(DMe,tLr),e(px,aLr),e(lr,nLr),e(lr,It),M(_x,It,null),e(It,sLr),e(It,GMe),e(GMe,lLr),e(It,iLr),e(It,Cc),e(Cc,dLr),e(Cc,OMe),e(OMe,cLr),e(Cc,fLr),e(Cc,yY),e(yY,mLr),e(Cc,gLr),e(It,hLr),M(GC,It,null),e(lr,pLr),e(lr,Br),M(ux,Br,null),e(Br,_Lr),e(Br,VMe),e(VMe,uLr),e(Br,bLr),e(Br,gn),e(gn,vLr),e(gn,XMe),e(XMe,FLr),e(gn,TLr),e(gn,zMe),e(zMe,MLr),e(gn,ELr),e(gn,QMe),e(QMe,CLr),e(gn,wLr),e(Br,ALr),e(Br,te),e(te,OC),e(OC,WMe),e(WMe,LLr),e(OC,yLr),e(OC,xY),e(xY,xLr),e(OC,$Lr),e(te,kLr),e(te,VC),e(VC,HMe),e(HMe,SLr),e(VC,RLr),e(VC,$Y),e($Y,PLr),e(VC,BLr),e(te,NLr),e(te,XC),e(XC,UMe),e(UMe,ILr),e(XC,qLr),e(XC,kY),e(kY,jLr),e(XC,DLr),e(te,GLr),e(te,zC),e(zC,JMe),e(JMe,OLr),e(zC,VLr),e(zC,SY),e(SY,XLr),e(zC,zLr),e(te,QLr),e(te,QC),e(QC,YMe),e(YMe,WLr),e(QC,HLr),e(QC,RY),e(RY,ULr),e(QC,JLr),e(te,YLr),e(te,WC),e(WC,KMe),e(KMe,KLr),e(WC,ZLr),e(WC,PY),e(PY,eyr),e(WC,oyr),e(te,ryr),e(te,HC),e(HC,ZMe),e(ZMe,tyr),e(HC,ayr),e(HC,BY),e(BY,nyr),e(HC,syr),e(te,lyr),e(te,UC),e(UC,eEe),e(eEe,iyr),e(UC,dyr),e(UC,NY),e(NY,cyr),e(UC,fyr),e(te,myr),e(te,JC),e(JC,oEe),e(oEe,gyr),e(JC,hyr),e(JC,IY),e(IY,pyr),e(JC,_yr),e(te,uyr),e(te,YC),e(YC,rEe),e(rEe,byr),e(YC,vyr),e(YC,qY),e(qY,Fyr),e(YC,Tyr),e(te,Myr),e(te,KC),e(KC,tEe),e(tEe,Eyr),e(KC,Cyr),e(KC,jY),e(jY,wyr),e(KC,Ayr),e(te,Lyr),e(te,ZC),e(ZC,aEe),e(aEe,yyr),e(ZC,xyr),e(ZC,DY),e(DY,$yr),e(ZC,kyr),e(te,Syr),e(te,e3),e(e3,nEe),e(nEe,Ryr),e(e3,Pyr),e(e3,GY),e(GY,Byr),e(e3,Nyr),e(te,Iyr),e(te,o3),e(o3,sEe),e(sEe,qyr),e(o3,jyr),e(o3,OY),e(OY,Dyr),e(o3,Gyr),e(te,Oyr),e(te,r3),e(r3,lEe),e(lEe,Vyr),e(r3,Xyr),e(r3,VY),e(VY,zyr),e(r3,Qyr),e(te,Wyr),e(te,t3),e(t3,iEe),e(iEe,Hyr),e(t3,Uyr),e(t3,XY),e(XY,Jyr),e(t3,Yyr),e(te,Kyr),e(te,a3),e(a3,dEe),e(dEe,Zyr),e(a3,e8r),e(a3,zY),e(zY,o8r),e(a3,r8r),e(te,t8r),e(te,n3),e(n3,cEe),e(cEe,a8r),e(n3,n8r),e(n3,QY),e(QY,s8r),e(n3,l8r),e(te,i8r),e(te,s3),e(s3,fEe),e(fEe,d8r),e(s3,c8r),e(s3,WY),e(WY,f8r),e(s3,m8r),e(te,g8r),e(te,l3),e(l3,mEe),e(mEe,h8r),e(l3,p8r),e(l3,HY),e(HY,_8r),e(l3,u8r),e(te,b8r),e(te,i3),e(i3,gEe),e(gEe,v8r),e(i3,F8r),e(i3,UY),e(UY,T8r),e(i3,M8r),e(te,E8r),e(te,d3),e(d3,hEe),e(hEe,C8r),e(d3,w8r),e(d3,JY),e(JY,A8r),e(d3,L8r),e(te,y8r),e(te,c3),e(c3,pEe),e(pEe,x8r),e(c3,$8r),e(c3,YY),e(YY,k8r),e(c3,S8r),e(te,R8r),e(te,f3),e(f3,_Ee),e(_Ee,P8r),e(f3,B8r),e(f3,KY),e(KY,N8r),e(f3,I8r),e(te,q8r),e(te,m3),e(m3,uEe),e(uEe,j8r),e(m3,D8r),e(m3,ZY),e(ZY,G8r),e(m3,O8r),e(te,V8r),e(te,g3),e(g3,bEe),e(bEe,X8r),e(g3,z8r),e(g3,eK),e(eK,Q8r),e(g3,W8r),e(Br,H8r),M(h3,Br,null),b(f,VXe,u),b(f,wc,u),e(wc,p3),e(p3,vEe),M(bx,vEe,null),e(wc,U8r),e(wc,FEe),e(FEe,J8r),b(f,XXe,u),b(f,ir,u),M(vx,ir,null),e(ir,Y8r),e(ir,Ac),e(Ac,K8r),e(Ac,oK),e(oK,Z8r),e(Ac,e9r),e(Ac,rK),e(rK,o9r),e(Ac,r9r),e(ir,t9r),e(ir,Fx),e(Fx,a9r),e(Fx,TEe),e(TEe,n9r),e(Fx,s9r),e(ir,l9r),e(ir,qt),M(Tx,qt,null),e(qt,i9r),e(qt,MEe),e(MEe,d9r),e(qt,c9r),e(qt,Lc),e(Lc,f9r),e(Lc,EEe),e(EEe,m9r),e(Lc,g9r),e(Lc,tK),e(tK,h9r),e(Lc,p9r),e(qt,_9r),M(_3,qt,null),e(ir,u9r),e(ir,Nr),M(Mx,Nr,null),e(Nr,b9r),e(Nr,CEe),e(CEe,v9r),e(Nr,F9r),e(Nr,hn),e(hn,T9r),e(hn,wEe),e(wEe,M9r),e(hn,E9r),e(hn,AEe),e(AEe,C9r),e(hn,w9r),e(hn,LEe),e(LEe,A9r),e(hn,L9r),e(Nr,y9r),e(Nr,_e),e(_e,u3),e(u3,yEe),e(yEe,x9r),e(u3,$9r),e(u3,aK),e(aK,k9r),e(u3,S9r),e(_e,R9r),e(_e,b3),e(b3,xEe),e(xEe,P9r),e(b3,B9r),e(b3,nK),e(nK,N9r),e(b3,I9r),e(_e,q9r),e(_e,v3),e(v3,$Ee),e($Ee,j9r),e(v3,D9r),e(v3,sK),e(sK,G9r),e(v3,O9r),e(_e,V9r),e(_e,F3),e(F3,kEe),e(kEe,X9r),e(F3,z9r),e(F3,lK),e(lK,Q9r),e(F3,W9r),e(_e,H9r),e(_e,T3),e(T3,SEe),e(SEe,U9r),e(T3,J9r),e(T3,iK),e(iK,Y9r),e(T3,K9r),e(_e,Z9r),e(_e,M3),e(M3,REe),e(REe,exr),e(M3,oxr),e(M3,dK),e(dK,rxr),e(M3,txr),e(_e,axr),e(_e,E3),e(E3,PEe),e(PEe,nxr),e(E3,sxr),e(E3,cK),e(cK,lxr),e(E3,ixr),e(_e,dxr),e(_e,C3),e(C3,BEe),e(BEe,cxr),e(C3,fxr),e(C3,fK),e(fK,mxr),e(C3,gxr),e(_e,hxr),e(_e,w3),e(w3,NEe),e(NEe,pxr),e(w3,_xr),e(w3,mK),e(mK,uxr),e(w3,bxr),e(_e,vxr),e(_e,A3),e(A3,IEe),e(IEe,Fxr),e(A3,Txr),e(A3,gK),e(gK,Mxr),e(A3,Exr),e(_e,Cxr),e(_e,L3),e(L3,qEe),e(qEe,wxr),e(L3,Axr),e(L3,hK),e(hK,Lxr),e(L3,yxr),e(_e,xxr),e(_e,y3),e(y3,jEe),e(jEe,$xr),e(y3,kxr),e(y3,pK),e(pK,Sxr),e(y3,Rxr),e(_e,Pxr),e(_e,x3),e(x3,DEe),e(DEe,Bxr),e(x3,Nxr),e(x3,_K),e(_K,Ixr),e(x3,qxr),e(_e,jxr),e(_e,$3),e($3,GEe),e(GEe,Dxr),e($3,Gxr),e($3,uK),e(uK,Oxr),e($3,Vxr),e(_e,Xxr),e(_e,k3),e(k3,OEe),e(OEe,zxr),e(k3,Qxr),e(k3,bK),e(bK,Wxr),e(k3,Hxr),e(_e,Uxr),e(_e,S3),e(S3,VEe),e(VEe,Jxr),e(S3,Yxr),e(S3,vK),e(vK,Kxr),e(S3,Zxr),e(_e,e$r),e(_e,R3),e(R3,XEe),e(XEe,o$r),e(R3,r$r),e(R3,FK),e(FK,t$r),e(R3,a$r),e(Nr,n$r),M(P3,Nr,null),b(f,zXe,u),b(f,yc,u),e(yc,B3),e(B3,zEe),M(Ex,zEe,null),e(yc,s$r),e(yc,QEe),e(QEe,l$r),b(f,QXe,u),b(f,dr,u),M(Cx,dr,null),e(dr,i$r),e(dr,xc),e(xc,d$r),e(xc,TK),e(TK,c$r),e(xc,f$r),e(xc,MK),e(MK,m$r),e(xc,g$r),e(dr,h$r),e(dr,wx),e(wx,p$r),e(wx,WEe),e(WEe,_$r),e(wx,u$r),e(dr,b$r),e(dr,jt),M(Ax,jt,null),e(jt,v$r),e(jt,HEe),e(HEe,F$r),e(jt,T$r),e(jt,$c),e($c,M$r),e($c,UEe),e(UEe,E$r),e($c,C$r),e($c,EK),e(EK,w$r),e($c,A$r),e(jt,L$r),M(N3,jt,null),e(dr,y$r),e(dr,Ir),M(Lx,Ir,null),e(Ir,x$r),e(Ir,JEe),e(JEe,$$r),e(Ir,k$r),e(Ir,pn),e(pn,S$r),e(pn,YEe),e(YEe,R$r),e(pn,P$r),e(pn,KEe),e(KEe,B$r),e(pn,N$r),e(pn,ZEe),e(ZEe,I$r),e(pn,q$r),e(Ir,j$r),e(Ir,yx),e(yx,I3),e(I3,eCe),e(eCe,D$r),e(I3,G$r),e(I3,CK),e(CK,O$r),e(I3,V$r),e(yx,X$r),e(yx,q3),e(q3,oCe),e(oCe,z$r),e(q3,Q$r),e(q3,wK),e(wK,W$r),e(q3,H$r),e(Ir,U$r),M(j3,Ir,null),b(f,WXe,u),b(f,kc,u),e(kc,D3),e(D3,rCe),M(xx,rCe,null),e(kc,J$r),e(kc,tCe),e(tCe,Y$r),b(f,HXe,u),b(f,cr,u),M($x,cr,null),e(cr,K$r),e(cr,Sc),e(Sc,Z$r),e(Sc,AK),e(AK,ekr),e(Sc,okr),e(Sc,LK),e(LK,rkr),e(Sc,tkr),e(cr,akr),e(cr,kx),e(kx,nkr),e(kx,aCe),e(aCe,skr),e(kx,lkr),e(cr,ikr),e(cr,Dt),M(Sx,Dt,null),e(Dt,dkr),e(Dt,nCe),e(nCe,ckr),e(Dt,fkr),e(Dt,Rc),e(Rc,mkr),e(Rc,sCe),e(sCe,gkr),e(Rc,hkr),e(Rc,yK),e(yK,pkr),e(Rc,_kr),e(Dt,ukr),M(G3,Dt,null),e(cr,bkr),e(cr,qr),M(Rx,qr,null),e(qr,vkr),e(qr,lCe),e(lCe,Fkr),e(qr,Tkr),e(qr,_n),e(_n,Mkr),e(_n,iCe),e(iCe,Ekr),e(_n,Ckr),e(_n,dCe),e(dCe,wkr),e(_n,Akr),e(_n,cCe),e(cCe,Lkr),e(_n,ykr),e(qr,xkr),e(qr,fCe),e(fCe,O3),e(O3,mCe),e(mCe,$kr),e(O3,kkr),e(O3,xK),e(xK,Skr),e(O3,Rkr),e(qr,Pkr),M(V3,qr,null),b(f,UXe,u),b(f,Pc,u),e(Pc,X3),e(X3,gCe),M(Px,gCe,null),e(Pc,Bkr),e(Pc,hCe),e(hCe,Nkr),b(f,JXe,u),b(f,fr,u),M(Bx,fr,null),e(fr,Ikr),e(fr,Bc),e(Bc,qkr),e(Bc,$K),e($K,jkr),e(Bc,Dkr),e(Bc,kK),e(kK,Gkr),e(Bc,Okr),e(fr,Vkr),e(fr,Nx),e(Nx,Xkr),e(Nx,pCe),e(pCe,zkr),e(Nx,Qkr),e(fr,Wkr),e(fr,Gt),M(Ix,Gt,null),e(Gt,Hkr),e(Gt,_Ce),e(_Ce,Ukr),e(Gt,Jkr),e(Gt,Nc),e(Nc,Ykr),e(Nc,uCe),e(uCe,Kkr),e(Nc,Zkr),e(Nc,SK),e(SK,eSr),e(Nc,oSr),e(Gt,rSr),M(z3,Gt,null),e(fr,tSr),e(fr,jr),M(qx,jr,null),e(jr,aSr),e(jr,bCe),e(bCe,nSr),e(jr,sSr),e(jr,un),e(un,lSr),e(un,vCe),e(vCe,iSr),e(un,dSr),e(un,FCe),e(FCe,cSr),e(un,fSr),e(un,TCe),e(TCe,mSr),e(un,gSr),e(jr,hSr),e(jr,de),e(de,Q3),e(Q3,MCe),e(MCe,pSr),e(Q3,_Sr),e(Q3,RK),e(RK,uSr),e(Q3,bSr),e(de,vSr),e(de,W3),e(W3,ECe),e(ECe,FSr),e(W3,TSr),e(W3,PK),e(PK,MSr),e(W3,ESr),e(de,CSr),e(de,H3),e(H3,CCe),e(CCe,wSr),e(H3,ASr),e(H3,BK),e(BK,LSr),e(H3,ySr),e(de,xSr),e(de,U3),e(U3,wCe),e(wCe,$Sr),e(U3,kSr),e(U3,NK),e(NK,SSr),e(U3,RSr),e(de,PSr),e(de,J3),e(J3,ACe),e(ACe,BSr),e(J3,NSr),e(J3,IK),e(IK,ISr),e(J3,qSr),e(de,jSr),e(de,Y3),e(Y3,LCe),e(LCe,DSr),e(Y3,GSr),e(Y3,qK),e(qK,OSr),e(Y3,VSr),e(de,XSr),e(de,K3),e(K3,yCe),e(yCe,zSr),e(K3,QSr),e(K3,jK),e(jK,WSr),e(K3,HSr),e(de,USr),e(de,Z3),e(Z3,xCe),e(xCe,JSr),e(Z3,YSr),e(Z3,DK),e(DK,KSr),e(Z3,ZSr),e(de,eRr),e(de,e5),e(e5,$Ce),e($Ce,oRr),e(e5,rRr),e(e5,GK),e(GK,tRr),e(e5,aRr),e(de,nRr),e(de,o5),e(o5,kCe),e(kCe,sRr),e(o5,lRr),e(o5,OK),e(OK,iRr),e(o5,dRr),e(de,cRr),e(de,r5),e(r5,SCe),e(SCe,fRr),e(r5,mRr),e(r5,VK),e(VK,gRr),e(r5,hRr),e(de,pRr),e(de,t5),e(t5,RCe),e(RCe,_Rr),e(t5,uRr),e(t5,XK),e(XK,bRr),e(t5,vRr),e(de,FRr),e(de,a5),e(a5,PCe),e(PCe,TRr),e(a5,MRr),e(a5,zK),e(zK,ERr),e(a5,CRr),e(de,wRr),e(de,n5),e(n5,BCe),e(BCe,ARr),e(n5,LRr),e(n5,QK),e(QK,yRr),e(n5,xRr),e(de,$Rr),e(de,s5),e(s5,NCe),e(NCe,kRr),e(s5,SRr),e(s5,WK),e(WK,RRr),e(s5,PRr),e(de,BRr),e(de,l5),e(l5,ICe),e(ICe,NRr),e(l5,IRr),e(l5,HK),e(HK,qRr),e(l5,jRr),e(de,DRr),e(de,i5),e(i5,qCe),e(qCe,GRr),e(i5,ORr),e(i5,UK),e(UK,VRr),e(i5,XRr),e(de,zRr),e(de,d5),e(d5,jCe),e(jCe,QRr),e(d5,WRr),e(d5,JK),e(JK,HRr),e(d5,URr),e(de,JRr),e(de,c5),e(c5,DCe),e(DCe,YRr),e(c5,KRr),e(c5,YK),e(YK,ZRr),e(c5,ePr),e(de,oPr),e(de,f5),e(f5,GCe),e(GCe,rPr),e(f5,tPr),e(f5,KK),e(KK,aPr),e(f5,nPr),e(jr,sPr),M(m5,jr,null),b(f,YXe,u),b(f,Ic,u),e(Ic,g5),e(g5,OCe),M(jx,OCe,null),e(Ic,lPr),e(Ic,VCe),e(VCe,iPr),b(f,KXe,u),b(f,mr,u),M(Dx,mr,null),e(mr,dPr),e(mr,qc),e(qc,cPr),e(qc,ZK),e(ZK,fPr),e(qc,mPr),e(qc,eZ),e(eZ,gPr),e(qc,hPr),e(mr,pPr),e(mr,Gx),e(Gx,_Pr),e(Gx,XCe),e(XCe,uPr),e(Gx,bPr),e(mr,vPr),e(mr,Ot),M(Ox,Ot,null),e(Ot,FPr),e(Ot,zCe),e(zCe,TPr),e(Ot,MPr),e(Ot,jc),e(jc,EPr),e(jc,QCe),e(QCe,CPr),e(jc,wPr),e(jc,oZ),e(oZ,APr),e(jc,LPr),e(Ot,yPr),M(h5,Ot,null),e(mr,xPr),e(mr,Dr),M(Vx,Dr,null),e(Dr,$Pr),e(Dr,WCe),e(WCe,kPr),e(Dr,SPr),e(Dr,bn),e(bn,RPr),e(bn,HCe),e(HCe,PPr),e(bn,BPr),e(bn,UCe),e(UCe,NPr),e(bn,IPr),e(bn,JCe),e(JCe,qPr),e(bn,jPr),e(Dr,DPr),e(Dr,ce),e(ce,p5),e(p5,YCe),e(YCe,GPr),e(p5,OPr),e(p5,rZ),e(rZ,VPr),e(p5,XPr),e(ce,zPr),e(ce,_5),e(_5,KCe),e(KCe,QPr),e(_5,WPr),e(_5,tZ),e(tZ,HPr),e(_5,UPr),e(ce,JPr),e(ce,u5),e(u5,ZCe),e(ZCe,YPr),e(u5,KPr),e(u5,aZ),e(aZ,ZPr),e(u5,eBr),e(ce,oBr),e(ce,b5),e(b5,e3e),e(e3e,rBr),e(b5,tBr),e(b5,nZ),e(nZ,aBr),e(b5,nBr),e(ce,sBr),e(ce,v5),e(v5,o3e),e(o3e,lBr),e(v5,iBr),e(v5,sZ),e(sZ,dBr),e(v5,cBr),e(ce,fBr),e(ce,F5),e(F5,r3e),e(r3e,mBr),e(F5,gBr),e(F5,lZ),e(lZ,hBr),e(F5,pBr),e(ce,_Br),e(ce,T5),e(T5,t3e),e(t3e,uBr),e(T5,bBr),e(T5,iZ),e(iZ,vBr),e(T5,FBr),e(ce,TBr),e(ce,M5),e(M5,a3e),e(a3e,MBr),e(M5,EBr),e(M5,dZ),e(dZ,CBr),e(M5,wBr),e(ce,ABr),e(ce,E5),e(E5,n3e),e(n3e,LBr),e(E5,yBr),e(E5,cZ),e(cZ,xBr),e(E5,$Br),e(ce,kBr),e(ce,C5),e(C5,s3e),e(s3e,SBr),e(C5,RBr),e(C5,fZ),e(fZ,PBr),e(C5,BBr),e(ce,NBr),e(ce,w5),e(w5,l3e),e(l3e,IBr),e(w5,qBr),e(w5,mZ),e(mZ,jBr),e(w5,DBr),e(ce,GBr),e(ce,A5),e(A5,i3e),e(i3e,OBr),e(A5,VBr),e(A5,gZ),e(gZ,XBr),e(A5,zBr),e(ce,QBr),e(ce,L5),e(L5,d3e),e(d3e,WBr),e(L5,HBr),e(L5,hZ),e(hZ,UBr),e(L5,JBr),e(ce,YBr),e(ce,y5),e(y5,c3e),e(c3e,KBr),e(y5,ZBr),e(y5,pZ),e(pZ,eNr),e(y5,oNr),e(ce,rNr),e(ce,x5),e(x5,f3e),e(f3e,tNr),e(x5,aNr),e(x5,_Z),e(_Z,nNr),e(x5,sNr),e(ce,lNr),e(ce,$5),e($5,m3e),e(m3e,iNr),e($5,dNr),e($5,uZ),e(uZ,cNr),e($5,fNr),e(ce,mNr),e(ce,k5),e(k5,g3e),e(g3e,gNr),e(k5,hNr),e(k5,bZ),e(bZ,pNr),e(k5,_Nr),e(ce,uNr),e(ce,S5),e(S5,h3e),e(h3e,bNr),e(S5,vNr),e(S5,vZ),e(vZ,FNr),e(S5,TNr),e(ce,MNr),e(ce,R5),e(R5,p3e),e(p3e,ENr),e(R5,CNr),e(R5,FZ),e(FZ,wNr),e(R5,ANr),e(ce,LNr),e(ce,P5),e(P5,_3e),e(_3e,yNr),e(P5,xNr),e(P5,TZ),e(TZ,$Nr),e(P5,kNr),e(Dr,SNr),M(B5,Dr,null),b(f,ZXe,u),b(f,Dc,u),e(Dc,N5),e(N5,u3e),M(Xx,u3e,null),e(Dc,RNr),e(Dc,b3e),e(b3e,PNr),b(f,eze,u),b(f,gr,u),M(zx,gr,null),e(gr,BNr),e(gr,Gc),e(Gc,NNr),e(Gc,MZ),e(MZ,INr),e(Gc,qNr),e(Gc,EZ),e(EZ,jNr),e(Gc,DNr),e(gr,GNr),e(gr,Qx),e(Qx,ONr),e(Qx,v3e),e(v3e,VNr),e(Qx,XNr),e(gr,zNr),e(gr,Vt),M(Wx,Vt,null),e(Vt,QNr),e(Vt,F3e),e(F3e,WNr),e(Vt,HNr),e(Vt,Oc),e(Oc,UNr),e(Oc,T3e),e(T3e,JNr),e(Oc,YNr),e(Oc,CZ),e(CZ,KNr),e(Oc,ZNr),e(Vt,eIr),M(I5,Vt,null),e(gr,oIr),e(gr,Gr),M(Hx,Gr,null),e(Gr,rIr),e(Gr,M3e),e(M3e,tIr),e(Gr,aIr),e(Gr,vn),e(vn,nIr),e(vn,E3e),e(E3e,sIr),e(vn,lIr),e(vn,C3e),e(C3e,iIr),e(vn,dIr),e(vn,w3e),e(w3e,cIr),e(vn,fIr),e(Gr,mIr),e(Gr,A3e),e(A3e,q5),e(q5,L3e),e(L3e,gIr),e(q5,hIr),e(q5,wZ),e(wZ,pIr),e(q5,_Ir),e(Gr,uIr),M(j5,Gr,null),b(f,oze,u),b(f,Vc,u),e(Vc,D5),e(D5,y3e),M(Ux,y3e,null),e(Vc,bIr),e(Vc,x3e),e(x3e,vIr),b(f,rze,u),b(f,hr,u),M(Jx,hr,null),e(hr,FIr),e(hr,Xc),e(Xc,TIr),e(Xc,AZ),e(AZ,MIr),e(Xc,EIr),e(Xc,LZ),e(LZ,CIr),e(Xc,wIr),e(hr,AIr),e(hr,Yx),e(Yx,LIr),e(Yx,$3e),e($3e,yIr),e(Yx,xIr),e(hr,$Ir),e(hr,Xt),M(Kx,Xt,null),e(Xt,kIr),e(Xt,k3e),e(k3e,SIr),e(Xt,RIr),e(Xt,zc),e(zc,PIr),e(zc,S3e),e(S3e,BIr),e(zc,NIr),e(zc,yZ),e(yZ,IIr),e(zc,qIr),e(Xt,jIr),M(G5,Xt,null),e(hr,DIr),e(hr,Or),M(Zx,Or,null),e(Or,GIr),e(Or,R3e),e(R3e,OIr),e(Or,VIr),e(Or,Fn),e(Fn,XIr),e(Fn,P3e),e(P3e,zIr),e(Fn,QIr),e(Fn,B3e),e(B3e,WIr),e(Fn,HIr),e(Fn,N3e),e(N3e,UIr),e(Fn,JIr),e(Or,YIr),e(Or,I3e),e(I3e,O5),e(O5,q3e),e(q3e,KIr),e(O5,ZIr),e(O5,xZ),e(xZ,eqr),e(O5,oqr),e(Or,rqr),M(V5,Or,null),b(f,tze,u),b(f,Qc,u),e(Qc,X5),e(X5,j3e),M(e$,j3e,null),e(Qc,tqr),e(Qc,D3e),e(D3e,aqr),b(f,aze,u),b(f,pr,u),M(o$,pr,null),e(pr,nqr),e(pr,Wc),e(Wc,sqr),e(Wc,$Z),e($Z,lqr),e(Wc,iqr),e(Wc,kZ),e(kZ,dqr),e(Wc,cqr),e(pr,fqr),e(pr,r$),e(r$,mqr),e(r$,G3e),e(G3e,gqr),e(r$,hqr),e(pr,pqr),e(pr,zt),M(t$,zt,null),e(zt,_qr),e(zt,O3e),e(O3e,uqr),e(zt,bqr),e(zt,Hc),e(Hc,vqr),e(Hc,V3e),e(V3e,Fqr),e(Hc,Tqr),e(Hc,SZ),e(SZ,Mqr),e(Hc,Eqr),e(zt,Cqr),M(z5,zt,null),e(pr,wqr),e(pr,Vr),M(a$,Vr,null),e(Vr,Aqr),e(Vr,X3e),e(X3e,Lqr),e(Vr,yqr),e(Vr,Tn),e(Tn,xqr),e(Tn,z3e),e(z3e,$qr),e(Tn,kqr),e(Tn,Q3e),e(Q3e,Sqr),e(Tn,Rqr),e(Tn,W3e),e(W3e,Pqr),e(Tn,Bqr),e(Vr,Nqr),e(Vr,oe),e(oe,Q5),e(Q5,H3e),e(H3e,Iqr),e(Q5,qqr),e(Q5,RZ),e(RZ,jqr),e(Q5,Dqr),e(oe,Gqr),e(oe,W5),e(W5,U3e),e(U3e,Oqr),e(W5,Vqr),e(W5,PZ),e(PZ,Xqr),e(W5,zqr),e(oe,Qqr),e(oe,H5),e(H5,J3e),e(J3e,Wqr),e(H5,Hqr),e(H5,BZ),e(BZ,Uqr),e(H5,Jqr),e(oe,Yqr),e(oe,U5),e(U5,Y3e),e(Y3e,Kqr),e(U5,Zqr),e(U5,NZ),e(NZ,ejr),e(U5,ojr),e(oe,rjr),e(oe,J5),e(J5,K3e),e(K3e,tjr),e(J5,ajr),e(J5,IZ),e(IZ,njr),e(J5,sjr),e(oe,ljr),e(oe,Y5),e(Y5,Z3e),e(Z3e,ijr),e(Y5,djr),e(Y5,qZ),e(qZ,cjr),e(Y5,fjr),e(oe,mjr),e(oe,K5),e(K5,e5e),e(e5e,gjr),e(K5,hjr),e(K5,jZ),e(jZ,pjr),e(K5,_jr),e(oe,ujr),e(oe,Z5),e(Z5,o5e),e(o5e,bjr),e(Z5,vjr),e(Z5,DZ),e(DZ,Fjr),e(Z5,Tjr),e(oe,Mjr),e(oe,e0),e(e0,r5e),e(r5e,Ejr),e(e0,Cjr),e(e0,GZ),e(GZ,wjr),e(e0,Ajr),e(oe,Ljr),e(oe,o0),e(o0,t5e),e(t5e,yjr),e(o0,xjr),e(o0,OZ),e(OZ,$jr),e(o0,kjr),e(oe,Sjr),e(oe,r0),e(r0,a5e),e(a5e,Rjr),e(r0,Pjr),e(r0,VZ),e(VZ,Bjr),e(r0,Njr),e(oe,Ijr),e(oe,t0),e(t0,n5e),e(n5e,qjr),e(t0,jjr),e(t0,XZ),e(XZ,Djr),e(t0,Gjr),e(oe,Ojr),e(oe,a0),e(a0,s5e),e(s5e,Vjr),e(a0,Xjr),e(a0,zZ),e(zZ,zjr),e(a0,Qjr),e(oe,Wjr),e(oe,n0),e(n0,l5e),e(l5e,Hjr),e(n0,Ujr),e(n0,QZ),e(QZ,Jjr),e(n0,Yjr),e(oe,Kjr),e(oe,s0),e(s0,i5e),e(i5e,Zjr),e(s0,eDr),e(s0,WZ),e(WZ,oDr),e(s0,rDr),e(oe,tDr),e(oe,l0),e(l0,d5e),e(d5e,aDr),e(l0,nDr),e(l0,HZ),e(HZ,sDr),e(l0,lDr),e(oe,iDr),e(oe,i0),e(i0,c5e),e(c5e,dDr),e(i0,cDr),e(i0,UZ),e(UZ,fDr),e(i0,mDr),e(oe,gDr),e(oe,d0),e(d0,f5e),e(f5e,hDr),e(d0,pDr),e(d0,JZ),e(JZ,_Dr),e(d0,uDr),e(oe,bDr),e(oe,c0),e(c0,m5e),e(m5e,vDr),e(c0,FDr),e(c0,YZ),e(YZ,TDr),e(c0,MDr),e(oe,EDr),e(oe,f0),e(f0,g5e),e(g5e,CDr),e(f0,wDr),e(f0,KZ),e(KZ,ADr),e(f0,LDr),e(oe,yDr),e(oe,m0),e(m0,h5e),e(h5e,xDr),e(m0,$Dr),e(m0,ZZ),e(ZZ,kDr),e(m0,SDr),e(oe,RDr),e(oe,g0),e(g0,p5e),e(p5e,PDr),e(g0,BDr),e(g0,eee),e(eee,NDr),e(g0,IDr),e(oe,qDr),e(oe,h0),e(h0,_5e),e(_5e,jDr),e(h0,DDr),e(h0,oee),e(oee,GDr),e(h0,ODr),e(oe,VDr),e(oe,p0),e(p0,u5e),e(u5e,XDr),e(p0,zDr),e(p0,ree),e(ree,QDr),e(p0,WDr),e(oe,HDr),e(oe,_0),e(_0,b5e),e(b5e,UDr),e(_0,JDr),e(_0,tee),e(tee,YDr),e(_0,KDr),e(oe,ZDr),e(oe,u0),e(u0,v5e),e(v5e,eGr),e(u0,oGr),e(u0,aee),e(aee,rGr),e(u0,tGr),e(oe,aGr),e(oe,b0),e(b0,F5e),e(F5e,nGr),e(b0,sGr),e(b0,nee),e(nee,lGr),e(b0,iGr),e(Vr,dGr),M(v0,Vr,null),b(f,nze,u),b(f,Uc,u),e(Uc,F0),e(F0,T5e),M(n$,T5e,null),e(Uc,cGr),e(Uc,M5e),e(M5e,fGr),b(f,sze,u),b(f,_r,u),M(s$,_r,null),e(_r,mGr),e(_r,Jc),e(Jc,gGr),e(Jc,see),e(see,hGr),e(Jc,pGr),e(Jc,lee),e(lee,_Gr),e(Jc,uGr),e(_r,bGr),e(_r,l$),e(l$,vGr),e(l$,E5e),e(E5e,FGr),e(l$,TGr),e(_r,MGr),e(_r,Qt),M(i$,Qt,null),e(Qt,EGr),e(Qt,C5e),e(C5e,CGr),e(Qt,wGr),e(Qt,Yc),e(Yc,AGr),e(Yc,w5e),e(w5e,LGr),e(Yc,yGr),e(Yc,iee),e(iee,xGr),e(Yc,$Gr),e(Qt,kGr),M(T0,Qt,null),e(_r,SGr),e(_r,Xr),M(d$,Xr,null),e(Xr,RGr),e(Xr,A5e),e(A5e,PGr),e(Xr,BGr),e(Xr,Mn),e(Mn,NGr),e(Mn,L5e),e(L5e,IGr),e(Mn,qGr),e(Mn,y5e),e(y5e,jGr),e(Mn,DGr),e(Mn,x5e),e(x5e,GGr),e(Mn,OGr),e(Xr,VGr),e(Xr,xe),e(xe,M0),e(M0,$5e),e($5e,XGr),e(M0,zGr),e(M0,dee),e(dee,QGr),e(M0,WGr),e(xe,HGr),e(xe,E0),e(E0,k5e),e(k5e,UGr),e(E0,JGr),e(E0,cee),e(cee,YGr),e(E0,KGr),e(xe,ZGr),e(xe,C0),e(C0,S5e),e(S5e,eOr),e(C0,oOr),e(C0,fee),e(fee,rOr),e(C0,tOr),e(xe,aOr),e(xe,w0),e(w0,R5e),e(R5e,nOr),e(w0,sOr),e(w0,mee),e(mee,lOr),e(w0,iOr),e(xe,dOr),e(xe,A0),e(A0,P5e),e(P5e,cOr),e(A0,fOr),e(A0,gee),e(gee,mOr),e(A0,gOr),e(xe,hOr),e(xe,L0),e(L0,B5e),e(B5e,pOr),e(L0,_Or),e(L0,hee),e(hee,uOr),e(L0,bOr),e(xe,vOr),e(xe,y0),e(y0,N5e),e(N5e,FOr),e(y0,TOr),e(y0,pee),e(pee,MOr),e(y0,EOr),e(xe,COr),e(xe,x0),e(x0,I5e),e(I5e,wOr),e(x0,AOr),e(x0,_ee),e(_ee,LOr),e(x0,yOr),e(xe,xOr),e(xe,$0),e($0,q5e),e(q5e,$Or),e($0,kOr),e($0,uee),e(uee,SOr),e($0,ROr),e(xe,POr),e(xe,k0),e(k0,j5e),e(j5e,BOr),e(k0,NOr),e(k0,bee),e(bee,IOr),e(k0,qOr),e(Xr,jOr),M(S0,Xr,null),b(f,lze,u),b(f,Kc,u),e(Kc,R0),e(R0,D5e),M(c$,D5e,null),e(Kc,DOr),e(Kc,G5e),e(G5e,GOr),b(f,ize,u),b(f,ur,u),M(f$,ur,null),e(ur,OOr),e(ur,Zc),e(Zc,VOr),e(Zc,vee),e(vee,XOr),e(Zc,zOr),e(Zc,Fee),e(Fee,QOr),e(Zc,WOr),e(ur,HOr),e(ur,m$),e(m$,UOr),e(m$,O5e),e(O5e,JOr),e(m$,YOr),e(ur,KOr),e(ur,Wt),M(g$,Wt,null),e(Wt,ZOr),e(Wt,V5e),e(V5e,eVr),e(Wt,oVr),e(Wt,ef),e(ef,rVr),e(ef,X5e),e(X5e,tVr),e(ef,aVr),e(ef,Tee),e(Tee,nVr),e(ef,sVr),e(Wt,lVr),M(P0,Wt,null),e(ur,iVr),e(ur,zr),M(h$,zr,null),e(zr,dVr),e(zr,z5e),e(z5e,cVr),e(zr,fVr),e(zr,En),e(En,mVr),e(En,Q5e),e(Q5e,gVr),e(En,hVr),e(En,W5e),e(W5e,pVr),e(En,_Vr),e(En,H5e),e(H5e,uVr),e(En,bVr),e(zr,vVr),e(zr,Ee),e(Ee,B0),e(B0,U5e),e(U5e,FVr),e(B0,TVr),e(B0,Mee),e(Mee,MVr),e(B0,EVr),e(Ee,CVr),e(Ee,N0),e(N0,J5e),e(J5e,wVr),e(N0,AVr),e(N0,Eee),e(Eee,LVr),e(N0,yVr),e(Ee,xVr),e(Ee,I0),e(I0,Y5e),e(Y5e,$Vr),e(I0,kVr),e(I0,Cee),e(Cee,SVr),e(I0,RVr),e(Ee,PVr),e(Ee,q0),e(q0,K5e),e(K5e,BVr),e(q0,NVr),e(q0,wee),e(wee,IVr),e(q0,qVr),e(Ee,jVr),e(Ee,j0),e(j0,Z5e),e(Z5e,DVr),e(j0,GVr),e(j0,Aee),e(Aee,OVr),e(j0,VVr),e(Ee,XVr),e(Ee,D0),e(D0,e0e),e(e0e,zVr),e(D0,QVr),e(D0,Lee),e(Lee,WVr),e(D0,HVr),e(Ee,UVr),e(Ee,G0),e(G0,o0e),e(o0e,JVr),e(G0,YVr),e(G0,yee),e(yee,KVr),e(G0,ZVr),e(Ee,eXr),e(Ee,O0),e(O0,r0e),e(r0e,oXr),e(O0,rXr),e(O0,xee),e(xee,tXr),e(O0,aXr),e(Ee,nXr),e(Ee,V0),e(V0,t0e),e(t0e,sXr),e(V0,lXr),e(V0,$ee),e($ee,iXr),e(V0,dXr),e(Ee,cXr),e(Ee,X0),e(X0,a0e),e(a0e,fXr),e(X0,mXr),e(X0,kee),e(kee,gXr),e(X0,hXr),e(Ee,pXr),e(Ee,z0),e(z0,n0e),e(n0e,_Xr),e(z0,uXr),e(z0,See),e(See,bXr),e(z0,vXr),e(Ee,FXr),e(Ee,Q0),e(Q0,s0e),e(s0e,TXr),e(Q0,MXr),e(Q0,Ree),e(Ree,EXr),e(Q0,CXr),e(Ee,wXr),e(Ee,W0),e(W0,l0e),e(l0e,AXr),e(W0,LXr),e(W0,Pee),e(Pee,yXr),e(W0,xXr),e(zr,$Xr),M(H0,zr,null),b(f,dze,u),b(f,of,u),e(of,U0),e(U0,i0e),M(p$,i0e,null),e(of,kXr),e(of,d0e),e(d0e,SXr),b(f,cze,u),b(f,br,u),M(_$,br,null),e(br,RXr),e(br,rf),e(rf,PXr),e(rf,Bee),e(Bee,BXr),e(rf,NXr),e(rf,Nee),e(Nee,IXr),e(rf,qXr),e(br,jXr),e(br,u$),e(u$,DXr),e(u$,c0e),e(c0e,GXr),e(u$,OXr),e(br,VXr),e(br,Ht),M(b$,Ht,null),e(Ht,XXr),e(Ht,f0e),e(f0e,zXr),e(Ht,QXr),e(Ht,tf),e(tf,WXr),e(tf,m0e),e(m0e,HXr),e(tf,UXr),e(tf,Iee),e(Iee,JXr),e(tf,YXr),e(Ht,KXr),M(J0,Ht,null),e(br,ZXr),e(br,Qr),M(v$,Qr,null),e(Qr,ezr),e(Qr,g0e),e(g0e,ozr),e(Qr,rzr),e(Qr,Cn),e(Cn,tzr),e(Cn,h0e),e(h0e,azr),e(Cn,nzr),e(Cn,p0e),e(p0e,szr),e(Cn,lzr),e(Cn,_0e),e(_0e,izr),e(Cn,dzr),e(Qr,czr),e(Qr,$e),e($e,Y0),e(Y0,u0e),e(u0e,fzr),e(Y0,mzr),e(Y0,qee),e(qee,gzr),e(Y0,hzr),e($e,pzr),e($e,K0),e(K0,b0e),e(b0e,_zr),e(K0,uzr),e(K0,jee),e(jee,bzr),e(K0,vzr),e($e,Fzr),e($e,Z0),e(Z0,v0e),e(v0e,Tzr),e(Z0,Mzr),e(Z0,Dee),e(Dee,Ezr),e(Z0,Czr),e($e,wzr),e($e,ew),e(ew,F0e),e(F0e,Azr),e(ew,Lzr),e(ew,Gee),e(Gee,yzr),e(ew,xzr),e($e,$zr),e($e,ow),e(ow,T0e),e(T0e,kzr),e(ow,Szr),e(ow,Oee),e(Oee,Rzr),e(ow,Pzr),e($e,Bzr),e($e,rw),e(rw,M0e),e(M0e,Nzr),e(rw,Izr),e(rw,Vee),e(Vee,qzr),e(rw,jzr),e($e,Dzr),e($e,tw),e(tw,E0e),e(E0e,Gzr),e(tw,Ozr),e(tw,Xee),e(Xee,Vzr),e(tw,Xzr),e($e,zzr),e($e,aw),e(aw,C0e),e(C0e,Qzr),e(aw,Wzr),e(aw,zee),e(zee,Hzr),e(aw,Uzr),e($e,Jzr),e($e,nw),e(nw,w0e),e(w0e,Yzr),e(nw,Kzr),e(nw,Qee),e(Qee,Zzr),e(nw,eQr),e($e,oQr),e($e,sw),e(sw,A0e),e(A0e,rQr),e(sw,tQr),e(sw,Wee),e(Wee,aQr),e(sw,nQr),e(Qr,sQr),M(lw,Qr,null),b(f,fze,u),b(f,af,u),e(af,iw),e(iw,L0e),M(F$,L0e,null),e(af,lQr),e(af,y0e),e(y0e,iQr),b(f,mze,u),b(f,vr,u),M(T$,vr,null),e(vr,dQr),e(vr,nf),e(nf,cQr),e(nf,Hee),e(Hee,fQr),e(nf,mQr),e(nf,Uee),e(Uee,gQr),e(nf,hQr),e(vr,pQr),e(vr,M$),e(M$,_Qr),e(M$,x0e),e(x0e,uQr),e(M$,bQr),e(vr,vQr),e(vr,Ut),M(E$,Ut,null),e(Ut,FQr),e(Ut,$0e),e($0e,TQr),e(Ut,MQr),e(Ut,sf),e(sf,EQr),e(sf,k0e),e(k0e,CQr),e(sf,wQr),e(sf,Jee),e(Jee,AQr),e(sf,LQr),e(Ut,yQr),M(dw,Ut,null),e(vr,xQr),e(vr,Wr),M(C$,Wr,null),e(Wr,$Qr),e(Wr,S0e),e(S0e,kQr),e(Wr,SQr),e(Wr,wn),e(wn,RQr),e(wn,R0e),e(R0e,PQr),e(wn,BQr),e(wn,P0e),e(P0e,NQr),e(wn,IQr),e(wn,B0e),e(B0e,qQr),e(wn,jQr),e(Wr,DQr),e(Wr,ke),e(ke,cw),e(cw,N0e),e(N0e,GQr),e(cw,OQr),e(cw,Yee),e(Yee,VQr),e(cw,XQr),e(ke,zQr),e(ke,fw),e(fw,I0e),e(I0e,QQr),e(fw,WQr),e(fw,Kee),e(Kee,HQr),e(fw,UQr),e(ke,JQr),e(ke,mw),e(mw,q0e),e(q0e,YQr),e(mw,KQr),e(mw,Zee),e(Zee,ZQr),e(mw,eWr),e(ke,oWr),e(ke,gw),e(gw,j0e),e(j0e,rWr),e(gw,tWr),e(gw,eoe),e(eoe,aWr),e(gw,nWr),e(ke,sWr),e(ke,hw),e(hw,D0e),e(D0e,lWr),e(hw,iWr),e(hw,ooe),e(ooe,dWr),e(hw,cWr),e(ke,fWr),e(ke,pw),e(pw,G0e),e(G0e,mWr),e(pw,gWr),e(pw,roe),e(roe,hWr),e(pw,pWr),e(ke,_Wr),e(ke,_w),e(_w,O0e),e(O0e,uWr),e(_w,bWr),e(_w,toe),e(toe,vWr),e(_w,FWr),e(ke,TWr),e(ke,uw),e(uw,V0e),e(V0e,MWr),e(uw,EWr),e(uw,aoe),e(aoe,CWr),e(uw,wWr),e(ke,AWr),e(ke,bw),e(bw,X0e),e(X0e,LWr),e(bw,yWr),e(bw,noe),e(noe,xWr),e(bw,$Wr),e(ke,kWr),e(ke,vw),e(vw,z0e),e(z0e,SWr),e(vw,RWr),e(vw,soe),e(soe,PWr),e(vw,BWr),e(Wr,NWr),M(Fw,Wr,null),b(f,gze,u),b(f,lf,u),e(lf,Tw),e(Tw,Q0e),M(w$,Q0e,null),e(lf,IWr),e(lf,W0e),e(W0e,qWr),b(f,hze,u),b(f,Fr,u),M(A$,Fr,null),e(Fr,jWr),e(Fr,df),e(df,DWr),e(df,loe),e(loe,GWr),e(df,OWr),e(df,ioe),e(ioe,VWr),e(df,XWr),e(Fr,zWr),e(Fr,L$),e(L$,QWr),e(L$,H0e),e(H0e,WWr),e(L$,HWr),e(Fr,UWr),e(Fr,Jt),M(y$,Jt,null),e(Jt,JWr),e(Jt,U0e),e(U0e,YWr),e(Jt,KWr),e(Jt,cf),e(cf,ZWr),e(cf,J0e),e(J0e,eHr),e(cf,oHr),e(cf,doe),e(doe,rHr),e(cf,tHr),e(Jt,aHr),M(Mw,Jt,null),e(Fr,nHr),e(Fr,Hr),M(x$,Hr,null),e(Hr,sHr),e(Hr,Y0e),e(Y0e,lHr),e(Hr,iHr),e(Hr,An),e(An,dHr),e(An,K0e),e(K0e,cHr),e(An,fHr),e(An,Z0e),e(Z0e,mHr),e(An,gHr),e(An,ewe),e(ewe,hHr),e(An,pHr),e(Hr,_Hr),e(Hr,Se),e(Se,Ew),e(Ew,owe),e(owe,uHr),e(Ew,bHr),e(Ew,coe),e(coe,vHr),e(Ew,FHr),e(Se,THr),e(Se,Cw),e(Cw,rwe),e(rwe,MHr),e(Cw,EHr),e(Cw,foe),e(foe,CHr),e(Cw,wHr),e(Se,AHr),e(Se,ww),e(ww,twe),e(twe,LHr),e(ww,yHr),e(ww,moe),e(moe,xHr),e(ww,$Hr),e(Se,kHr),e(Se,Aw),e(Aw,awe),e(awe,SHr),e(Aw,RHr),e(Aw,goe),e(goe,PHr),e(Aw,BHr),e(Se,NHr),e(Se,Lw),e(Lw,nwe),e(nwe,IHr),e(Lw,qHr),e(Lw,hoe),e(hoe,jHr),e(Lw,DHr),e(Se,GHr),e(Se,yw),e(yw,swe),e(swe,OHr),e(yw,VHr),e(yw,poe),e(poe,XHr),e(yw,zHr),e(Se,QHr),e(Se,xw),e(xw,lwe),e(lwe,WHr),e(xw,HHr),e(xw,_oe),e(_oe,UHr),e(xw,JHr),e(Se,YHr),e(Se,$w),e($w,iwe),e(iwe,KHr),e($w,ZHr),e($w,uoe),e(uoe,eUr),e($w,oUr),e(Se,rUr),e(Se,kw),e(kw,dwe),e(dwe,tUr),e(kw,aUr),e(kw,boe),e(boe,nUr),e(kw,sUr),e(Se,lUr),e(Se,Sw),e(Sw,cwe),e(cwe,iUr),e(Sw,dUr),e(Sw,voe),e(voe,cUr),e(Sw,fUr),e(Hr,mUr),M(Rw,Hr,null),b(f,pze,u),b(f,ff,u),e(ff,Pw),e(Pw,fwe),M($$,fwe,null),e(ff,gUr),e(ff,mwe),e(mwe,hUr),b(f,_ze,u),b(f,Tr,u),M(k$,Tr,null),e(Tr,pUr),e(Tr,mf),e(mf,_Ur),e(mf,Foe),e(Foe,uUr),e(mf,bUr),e(mf,Toe),e(Toe,vUr),e(mf,FUr),e(Tr,TUr),e(Tr,S$),e(S$,MUr),e(S$,gwe),e(gwe,EUr),e(S$,CUr),e(Tr,wUr),e(Tr,Yt),M(R$,Yt,null),e(Yt,AUr),e(Yt,hwe),e(hwe,LUr),e(Yt,yUr),e(Yt,gf),e(gf,xUr),e(gf,pwe),e(pwe,$Ur),e(gf,kUr),e(gf,Moe),e(Moe,SUr),e(gf,RUr),e(Yt,PUr),M(Bw,Yt,null),e(Tr,BUr),e(Tr,Ur),M(P$,Ur,null),e(Ur,NUr),e(Ur,_we),e(_we,IUr),e(Ur,qUr),e(Ur,Ln),e(Ln,jUr),e(Ln,uwe),e(uwe,DUr),e(Ln,GUr),e(Ln,bwe),e(bwe,OUr),e(Ln,VUr),e(Ln,vwe),e(vwe,XUr),e(Ln,zUr),e(Ur,QUr),e(Ur,Re),e(Re,Nw),e(Nw,Fwe),e(Fwe,WUr),e(Nw,HUr),e(Nw,Eoe),e(Eoe,UUr),e(Nw,JUr),e(Re,YUr),e(Re,Iw),e(Iw,Twe),e(Twe,KUr),e(Iw,ZUr),e(Iw,Coe),e(Coe,eJr),e(Iw,oJr),e(Re,rJr),e(Re,qw),e(qw,Mwe),e(Mwe,tJr),e(qw,aJr),e(qw,woe),e(woe,nJr),e(qw,sJr),e(Re,lJr),e(Re,jw),e(jw,Ewe),e(Ewe,iJr),e(jw,dJr),e(jw,Aoe),e(Aoe,cJr),e(jw,fJr),e(Re,mJr),e(Re,Dw),e(Dw,Cwe),e(Cwe,gJr),e(Dw,hJr),e(Dw,Loe),e(Loe,pJr),e(Dw,_Jr),e(Re,uJr),e(Re,Gw),e(Gw,wwe),e(wwe,bJr),e(Gw,vJr),e(Gw,yoe),e(yoe,FJr),e(Gw,TJr),e(Re,MJr),e(Re,Ow),e(Ow,Awe),e(Awe,EJr),e(Ow,CJr),e(Ow,xoe),e(xoe,wJr),e(Ow,AJr),e(Re,LJr),e(Re,Vw),e(Vw,Lwe),e(Lwe,yJr),e(Vw,xJr),e(Vw,$oe),e($oe,$Jr),e(Vw,kJr),e(Re,SJr),e(Re,Xw),e(Xw,ywe),e(ywe,RJr),e(Xw,PJr),e(Xw,koe),e(koe,BJr),e(Xw,NJr),e(Re,IJr),e(Re,zw),e(zw,xwe),e(xwe,qJr),e(zw,jJr),e(zw,Soe),e(Soe,DJr),e(zw,GJr),e(Ur,OJr),M(Qw,Ur,null),b(f,uze,u),b(f,hf,u),e(hf,Ww),e(Ww,$we),M(B$,$we,null),e(hf,VJr),e(hf,kwe),e(kwe,XJr),b(f,bze,u),b(f,Mr,u),M(N$,Mr,null),e(Mr,zJr),e(Mr,pf),e(pf,QJr),e(pf,Roe),e(Roe,WJr),e(pf,HJr),e(pf,Poe),e(Poe,UJr),e(pf,JJr),e(Mr,YJr),e(Mr,I$),e(I$,KJr),e(I$,Swe),e(Swe,ZJr),e(I$,eYr),e(Mr,oYr),e(Mr,Kt),M(q$,Kt,null),e(Kt,rYr),e(Kt,Rwe),e(Rwe,tYr),e(Kt,aYr),e(Kt,_f),e(_f,nYr),e(_f,Pwe),e(Pwe,sYr),e(_f,lYr),e(_f,Boe),e(Boe,iYr),e(_f,dYr),e(Kt,cYr),M(Hw,Kt,null),e(Mr,fYr),e(Mr,Jr),M(j$,Jr,null),e(Jr,mYr),e(Jr,Bwe),e(Bwe,gYr),e(Jr,hYr),e(Jr,yn),e(yn,pYr),e(yn,Nwe),e(Nwe,_Yr),e(yn,uYr),e(yn,Iwe),e(Iwe,bYr),e(yn,vYr),e(yn,qwe),e(qwe,FYr),e(yn,TYr),e(Jr,MYr),e(Jr,Ve),e(Ve,Uw),e(Uw,jwe),e(jwe,EYr),e(Uw,CYr),e(Uw,Noe),e(Noe,wYr),e(Uw,AYr),e(Ve,LYr),e(Ve,Jw),e(Jw,Dwe),e(Dwe,yYr),e(Jw,xYr),e(Jw,Ioe),e(Ioe,$Yr),e(Jw,kYr),e(Ve,SYr),e(Ve,Yw),e(Yw,Gwe),e(Gwe,RYr),e(Yw,PYr),e(Yw,qoe),e(qoe,BYr),e(Yw,NYr),e(Ve,IYr),e(Ve,Kw),e(Kw,Owe),e(Owe,qYr),e(Kw,jYr),e(Kw,joe),e(joe,DYr),e(Kw,GYr),e(Ve,OYr),e(Ve,Zw),e(Zw,Vwe),e(Vwe,VYr),e(Zw,XYr),e(Zw,Doe),e(Doe,zYr),e(Zw,QYr),e(Ve,WYr),e(Ve,eA),e(eA,Xwe),e(Xwe,HYr),e(eA,UYr),e(eA,Goe),e(Goe,JYr),e(eA,YYr),e(Ve,KYr),e(Ve,oA),e(oA,zwe),e(zwe,ZYr),e(oA,eKr),e(oA,Ooe),e(Ooe,oKr),e(oA,rKr),e(Ve,tKr),e(Ve,rA),e(rA,Qwe),e(Qwe,aKr),e(rA,nKr),e(rA,Voe),e(Voe,sKr),e(rA,lKr),e(Jr,iKr),M(tA,Jr,null),b(f,vze,u),b(f,uf,u),e(uf,aA),e(aA,Wwe),M(D$,Wwe,null),e(uf,dKr),e(uf,Hwe),e(Hwe,cKr),b(f,Fze,u),b(f,Er,u),M(G$,Er,null),e(Er,fKr),e(Er,bf),e(bf,mKr),e(bf,Xoe),e(Xoe,gKr),e(bf,hKr),e(bf,zoe),e(zoe,pKr),e(bf,_Kr),e(Er,uKr),e(Er,O$),e(O$,bKr),e(O$,Uwe),e(Uwe,vKr),e(O$,FKr),e(Er,TKr),e(Er,Zt),M(V$,Zt,null),e(Zt,MKr),e(Zt,Jwe),e(Jwe,EKr),e(Zt,CKr),e(Zt,vf),e(vf,wKr),e(vf,Ywe),e(Ywe,AKr),e(vf,LKr),e(vf,Qoe),e(Qoe,yKr),e(vf,xKr),e(Zt,$Kr),M(nA,Zt,null),e(Er,kKr),e(Er,Yr),M(X$,Yr,null),e(Yr,SKr),e(Yr,Kwe),e(Kwe,RKr),e(Yr,PKr),e(Yr,xn),e(xn,BKr),e(xn,Zwe),e(Zwe,NKr),e(xn,IKr),e(xn,eAe),e(eAe,qKr),e(xn,jKr),e(xn,oAe),e(oAe,DKr),e(xn,GKr),e(Yr,OKr),e(Yr,Xe),e(Xe,sA),e(sA,rAe),e(rAe,VKr),e(sA,XKr),e(sA,Woe),e(Woe,zKr),e(sA,QKr),e(Xe,WKr),e(Xe,lA),e(lA,tAe),e(tAe,HKr),e(lA,UKr),e(lA,Hoe),e(Hoe,JKr),e(lA,YKr),e(Xe,KKr),e(Xe,iA),e(iA,aAe),e(aAe,ZKr),e(iA,eZr),e(iA,Uoe),e(Uoe,oZr),e(iA,rZr),e(Xe,tZr),e(Xe,dA),e(dA,nAe),e(nAe,aZr),e(dA,nZr),e(dA,Joe),e(Joe,sZr),e(dA,lZr),e(Xe,iZr),e(Xe,cA),e(cA,sAe),e(sAe,dZr),e(cA,cZr),e(cA,Yoe),e(Yoe,fZr),e(cA,mZr),e(Xe,gZr),e(Xe,fA),e(fA,lAe),e(lAe,hZr),e(fA,pZr),e(fA,Koe),e(Koe,_Zr),e(fA,uZr),e(Xe,bZr),e(Xe,mA),e(mA,iAe),e(iAe,vZr),e(mA,FZr),e(mA,Zoe),e(Zoe,TZr),e(mA,MZr),e(Xe,EZr),e(Xe,gA),e(gA,dAe),e(dAe,CZr),e(gA,wZr),e(gA,ere),e(ere,AZr),e(gA,LZr),e(Yr,yZr),M(hA,Yr,null),b(f,Tze,u),b(f,Ff,u),e(Ff,pA),e(pA,cAe),M(z$,cAe,null),e(Ff,xZr),e(Ff,fAe),e(fAe,$Zr),b(f,Mze,u),b(f,Cr,u),M(Q$,Cr,null),e(Cr,kZr),e(Cr,Tf),e(Tf,SZr),e(Tf,ore),e(ore,RZr),e(Tf,PZr),e(Tf,rre),e(rre,BZr),e(Tf,NZr),e(Cr,IZr),e(Cr,W$),e(W$,qZr),e(W$,mAe),e(mAe,jZr),e(W$,DZr),e(Cr,GZr),e(Cr,ea),M(H$,ea,null),e(ea,OZr),e(ea,gAe),e(gAe,VZr),e(ea,XZr),e(ea,Mf),e(Mf,zZr),e(Mf,hAe),e(hAe,QZr),e(Mf,WZr),e(Mf,tre),e(tre,HZr),e(Mf,UZr),e(ea,JZr),M(_A,ea,null),e(Cr,YZr),e(Cr,Kr),M(U$,Kr,null),e(Kr,KZr),e(Kr,pAe),e(pAe,ZZr),e(Kr,eet),e(Kr,$n),e($n,oet),e($n,_Ae),e(_Ae,ret),e($n,tet),e($n,uAe),e(uAe,aet),e($n,net),e($n,bAe),e(bAe,set),e($n,iet),e(Kr,det),e(Kr,vAe),e(vAe,uA),e(uA,FAe),e(FAe,cet),e(uA,fet),e(uA,are),e(are,met),e(uA,get),e(Kr,het),M(bA,Kr,null),b(f,Eze,u),b(f,Ef,u),e(Ef,vA),e(vA,TAe),M(J$,TAe,null),e(Ef,pet),e(Ef,MAe),e(MAe,_et),b(f,Cze,u),b(f,wr,u),M(Y$,wr,null),e(wr,uet),e(wr,Cf),e(Cf,bet),e(Cf,nre),e(nre,vet),e(Cf,Fet),e(Cf,sre),e(sre,Tet),e(Cf,Met),e(wr,Eet),e(wr,K$),e(K$,Cet),e(K$,EAe),e(EAe,wet),e(K$,Aet),e(wr,Let),e(wr,oa),M(Z$,oa,null),e(oa,yet),e(oa,CAe),e(CAe,xet),e(oa,$et),e(oa,wf),e(wf,ket),e(wf,wAe),e(wAe,Set),e(wf,Ret),e(wf,lre),e(lre,Pet),e(wf,Bet),e(oa,Net),M(FA,oa,null),e(wr,Iet),e(wr,Zr),M(ek,Zr,null),e(Zr,qet),e(Zr,AAe),e(AAe,jet),e(Zr,Det),e(Zr,kn),e(kn,Get),e(kn,LAe),e(LAe,Oet),e(kn,Vet),e(kn,yAe),e(yAe,Xet),e(kn,zet),e(kn,xAe),e(xAe,Qet),e(kn,Wet),e(Zr,Het),e(Zr,ok),e(ok,TA),e(TA,$Ae),e($Ae,Uet),e(TA,Jet),e(TA,ire),e(ire,Yet),e(TA,Ket),e(ok,Zet),e(ok,MA),e(MA,kAe),e(kAe,eot),e(MA,oot),e(MA,dre),e(dre,rot),e(MA,tot),e(Zr,aot),M(EA,Zr,null),b(f,wze,u),b(f,Af,u),e(Af,CA),e(CA,SAe),M(rk,SAe,null),e(Af,not),e(Af,RAe),e(RAe,sot),b(f,Aze,u),b(f,Ar,u),M(tk,Ar,null),e(Ar,lot),e(Ar,Lf),e(Lf,iot),e(Lf,cre),e(cre,dot),e(Lf,cot),e(Lf,fre),e(fre,fot),e(Lf,mot),e(Ar,got),e(Ar,ak),e(ak,hot),e(ak,PAe),e(PAe,pot),e(ak,_ot),e(Ar,uot),e(Ar,ra),M(nk,ra,null),e(ra,bot),e(ra,BAe),e(BAe,vot),e(ra,Fot),e(ra,yf),e(yf,Tot),e(yf,NAe),e(NAe,Mot),e(yf,Eot),e(yf,mre),e(mre,Cot),e(yf,wot),e(ra,Aot),M(wA,ra,null),e(Ar,Lot),e(Ar,et),M(sk,et,null),e(et,yot),e(et,IAe),e(IAe,xot),e(et,$ot),e(et,Sn),e(Sn,kot),e(Sn,qAe),e(qAe,Sot),e(Sn,Rot),e(Sn,jAe),e(jAe,Pot),e(Sn,Bot),e(Sn,DAe),e(DAe,Not),e(Sn,Iot),e(et,qot),e(et,GAe),e(GAe,AA),e(AA,OAe),e(OAe,jot),e(AA,Dot),e(AA,gre),e(gre,Got),e(AA,Oot),e(et,Vot),M(LA,et,null),Lze=!0},p(f,[u]){const lk={};u&2&&(lk.$$scope={dirty:u,ctx:f}),If.$set(lk);const VAe={};u&2&&(VAe.$$scope={dirty:u,ctx:f}),Hg.$set(VAe);const XAe={};u&2&&(XAe.$$scope={dirty:u,ctx:f}),$h.$set(XAe);const zAe={};u&2&&(zAe.$$scope={dirty:u,ctx:f}),mp.$set(zAe);const ik={};u&2&&(ik.$$scope={dirty:u,ctx:f}),gp.$set(ik);const QAe={};u&2&&(QAe.$$scope={dirty:u,ctx:f}),Pp.$set(QAe);const Rn={};u&2&&(Rn.$$scope={dirty:u,ctx:f}),Bp.$set(Rn);const WAe={};u&2&&(WAe.$$scope={dirty:u,ctx:f}),qp.$set(WAe);const HAe={};u&2&&(HAe.$$scope={dirty:u,ctx:f}),Gu.$set(HAe);const UAe={};u&2&&(UAe.$$scope={dirty:u,ctx:f}),Vu.$set(UAe);const dk={};u&2&&(dk.$$scope={dirty:u,ctx:f}),N2.$set(dk);const JAe={};u&2&&(JAe.$$scope={dirty:u,ctx:f}),q2.$set(JAe);const ck={};u&2&&(ck.$$scope={dirty:u,ctx:f}),A1.$set(ck);const YAe={};u&2&&(YAe.$$scope={dirty:u,ctx:f}),y1.$set(YAe);const fk={};u&2&&(fk.$$scope={dirty:u,ctx:f}),h7.$set(fk);const KAe={};u&2&&(KAe.$$scope={dirty:u,ctx:f}),_7.$set(KAe);const ZAe={};u&2&&(ZAe.$$scope={dirty:u,ctx:f}),N7.$set(ZAe);const e6e={};u&2&&(e6e.$$scope={dirty:u,ctx:f}),q7.$set(e6e);const xf={};u&2&&(xf.$$scope={dirty:u,ctx:f}),N4.$set(xf);const o6e={};u&2&&(o6e.$$scope={dirty:u,ctx:f}),q4.$set(o6e);const r6e={};u&2&&(r6e.$$scope={dirty:u,ctx:f}),_b.$set(r6e);const t6e={};u&2&&(t6e.$$scope={dirty:u,ctx:f}),bb.$set(t6e);const mk={};u&2&&(mk.$$scope={dirty:u,ctx:f}),Ab.$set(mk);const a6e={};u&2&&(a6e.$$scope={dirty:u,ctx:f}),yb.$set(a6e);const n6e={};u&2&&(n6e.$$scope={dirty:u,ctx:f}),mv.$set(n6e);const s6e={};u&2&&(s6e.$$scope={dirty:u,ctx:f}),hv.$set(s6e);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),aF.$set(tt);const gk={};u&2&&(gk.$$scope={dirty:u,ctx:f}),sF.$set(gk);const l6e={};u&2&&(l6e.$$scope={dirty:u,ctx:f}),dF.$set(l6e);const hk={};u&2&&(hk.$$scope={dirty:u,ctx:f}),fF.$set(hk);const i6e={};u&2&&(i6e.$$scope={dirty:u,ctx:f}),wF.$set(i6e);const at={};u&2&&(at.$$scope={dirty:u,ctx:f}),LF.$set(at);const d6e={};u&2&&(d6e.$$scope={dirty:u,ctx:f}),$F.$set(d6e);const $f={};u&2&&($f.$$scope={dirty:u,ctx:f}),SF.$set($f);const c6e={};u&2&&(c6e.$$scope={dirty:u,ctx:f}),BF.$set(c6e);const f6e={};u&2&&(f6e.$$scope={dirty:u,ctx:f}),IF.$set(f6e);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),HF.$set(L);const yA={};u&2&&(yA.$$scope={dirty:u,ctx:f}),JF.$set(yA);const m6e={};u&2&&(m6e.$$scope={dirty:u,ctx:f}),tT.$set(m6e);const g6e={};u&2&&(g6e.$$scope={dirty:u,ctx:f}),nT.$set(g6e);const xA={};u&2&&(xA.$$scope={dirty:u,ctx:f}),uT.$set(xA);const h6e={};u&2&&(h6e.$$scope={dirty:u,ctx:f}),vT.$set(h6e);const p6e={};u&2&&(p6e.$$scope={dirty:u,ctx:f}),ET.$set(p6e);const $A={};u&2&&($A.$$scope={dirty:u,ctx:f}),wT.$set($A);const _6e={};u&2&&(_6e.$$scope={dirty:u,ctx:f}),ST.$set(_6e);const u6e={};u&2&&(u6e.$$scope={dirty:u,ctx:f}),PT.$set(u6e);const kA={};u&2&&(kA.$$scope={dirty:u,ctx:f}),jT.$set(kA);const b6e={};u&2&&(b6e.$$scope={dirty:u,ctx:f}),GT.$set(b6e);const v6e={};u&2&&(v6e.$$scope={dirty:u,ctx:f}),zT.$set(v6e);const SA={};u&2&&(SA.$$scope={dirty:u,ctx:f}),WT.$set(SA);const F6e={};u&2&&(F6e.$$scope={dirty:u,ctx:f}),JT.$set(F6e);const T6e={};u&2&&(T6e.$$scope={dirty:u,ctx:f}),KT.$set(T6e);const RA={};u&2&&(RA.$$scope={dirty:u,ctx:f}),aM.$set(RA);const M6e={};u&2&&(M6e.$$scope={dirty:u,ctx:f}),sM.$set(M6e);const E6e={};u&2&&(E6e.$$scope={dirty:u,ctx:f}),dM.$set(E6e);const PA={};u&2&&(PA.$$scope={dirty:u,ctx:f}),fM.$set(PA);const C6e={};u&2&&(C6e.$$scope={dirty:u,ctx:f}),sE.$set(C6e);const w6e={};u&2&&(w6e.$$scope={dirty:u,ctx:f}),iE.$set(w6e);const BA={};u&2&&(BA.$$scope={dirty:u,ctx:f}),SE.$set(BA);const A6e={};u&2&&(A6e.$$scope={dirty:u,ctx:f}),PE.$set(A6e);const L6e={};u&2&&(L6e.$$scope={dirty:u,ctx:f}),HE.$set(L6e);const NA={};u&2&&(NA.$$scope={dirty:u,ctx:f}),JE.$set(NA);const y6e={};u&2&&(y6e.$$scope={dirty:u,ctx:f}),tC.$set(y6e);const x6e={};u&2&&(x6e.$$scope={dirty:u,ctx:f}),nC.$set(x6e);const IA={};u&2&&(IA.$$scope={dirty:u,ctx:f}),AC.$set(IA);const $6e={};u&2&&($6e.$$scope={dirty:u,ctx:f}),yC.$set($6e);const k6e={};u&2&&(k6e.$$scope={dirty:u,ctx:f}),jC.$set(k6e);const qA={};u&2&&(qA.$$scope={dirty:u,ctx:f}),GC.$set(qA);const S6e={};u&2&&(S6e.$$scope={dirty:u,ctx:f}),h3.$set(S6e);const R6e={};u&2&&(R6e.$$scope={dirty:u,ctx:f}),_3.$set(R6e);const jA={};u&2&&(jA.$$scope={dirty:u,ctx:f}),P3.$set(jA);const P6e={};u&2&&(P6e.$$scope={dirty:u,ctx:f}),N3.$set(P6e);const B6e={};u&2&&(B6e.$$scope={dirty:u,ctx:f}),j3.$set(B6e);const DA={};u&2&&(DA.$$scope={dirty:u,ctx:f}),G3.$set(DA);const N6e={};u&2&&(N6e.$$scope={dirty:u,ctx:f}),V3.$set(N6e);const I6e={};u&2&&(I6e.$$scope={dirty:u,ctx:f}),z3.$set(I6e);const GA={};u&2&&(GA.$$scope={dirty:u,ctx:f}),m5.$set(GA);const q6e={};u&2&&(q6e.$$scope={dirty:u,ctx:f}),h5.$set(q6e);const j6e={};u&2&&(j6e.$$scope={dirty:u,ctx:f}),B5.$set(j6e);const OA={};u&2&&(OA.$$scope={dirty:u,ctx:f}),I5.$set(OA);const D6e={};u&2&&(D6e.$$scope={dirty:u,ctx:f}),j5.$set(D6e);const G6e={};u&2&&(G6e.$$scope={dirty:u,ctx:f}),G5.$set(G6e);const VA={};u&2&&(VA.$$scope={dirty:u,ctx:f}),V5.$set(VA);const O6e={};u&2&&(O6e.$$scope={dirty:u,ctx:f}),z5.$set(O6e);const V6e={};u&2&&(V6e.$$scope={dirty:u,ctx:f}),v0.$set(V6e);const XA={};u&2&&(XA.$$scope={dirty:u,ctx:f}),T0.$set(XA);const X6e={};u&2&&(X6e.$$scope={dirty:u,ctx:f}),S0.$set(X6e);const z6e={};u&2&&(z6e.$$scope={dirty:u,ctx:f}),P0.$set(z6e);const zA={};u&2&&(zA.$$scope={dirty:u,ctx:f}),H0.$set(zA);const Q6e={};u&2&&(Q6e.$$scope={dirty:u,ctx:f}),J0.$set(Q6e);const W6e={};u&2&&(W6e.$$scope={dirty:u,ctx:f}),lw.$set(W6e);const QA={};u&2&&(QA.$$scope={dirty:u,ctx:f}),dw.$set(QA);const H6e={};u&2&&(H6e.$$scope={dirty:u,ctx:f}),Fw.$set(H6e);const U6e={};u&2&&(U6e.$$scope={dirty:u,ctx:f}),Mw.$set(U6e);const WA={};u&2&&(WA.$$scope={dirty:u,ctx:f}),Rw.$set(WA);const J6e={};u&2&&(J6e.$$scope={dirty:u,ctx:f}),Bw.$set(J6e);const Y6e={};u&2&&(Y6e.$$scope={dirty:u,ctx:f}),Qw.$set(Y6e);const HA={};u&2&&(HA.$$scope={dirty:u,ctx:f}),Hw.$set(HA);const K6e={};u&2&&(K6e.$$scope={dirty:u,ctx:f}),tA.$set(K6e);const Z6e={};u&2&&(Z6e.$$scope={dirty:u,ctx:f}),nA.$set(Z6e);const UA={};u&2&&(UA.$$scope={dirty:u,ctx:f}),hA.$set(UA);const eLe={};u&2&&(eLe.$$scope={dirty:u,ctx:f}),_A.$set(eLe);const oLe={};u&2&&(oLe.$$scope={dirty:u,ctx:f}),bA.$set(oLe);const JA={};u&2&&(JA.$$scope={dirty:u,ctx:f}),FA.$set(JA);const rLe={};u&2&&(rLe.$$scope={dirty:u,ctx:f}),EA.$set(rLe);const tLe={};u&2&&(tLe.$$scope={dirty:u,ctx:f}),wA.$set(tLe);const YA={};u&2&&(YA.$$scope={dirty:u,ctx:f}),LA.$set(YA)},i(f){Lze||(E(d.$$.fragment,f),E(ka.$$.fragment,f),E(YL.$$.fragment,f),E(KL.$$.fragment,f),E(If.$$.fragment,f),E(ZL.$$.fragment,f),E(ey.$$.fragment,f),E(ty.$$.fragment,f),E(Hg.$$.fragment,f),E(ay.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(dy.$$.fragment,f),E($h.$$.fragment,f),E(cy.$$.fragment,f),E(fy.$$.fragment,f),E(my.$$.fragment,f),E(py.$$.fragment,f),E(mp.$$.fragment,f),E(gp.$$.fragment,f),E(_y.$$.fragment,f),E(uy.$$.fragment,f),E(by.$$.fragment,f),E(Ty.$$.fragment,f),E(Pp.$$.fragment,f),E(Bp.$$.fragment,f),E(My.$$.fragment,f),E(Ey.$$.fragment,f),E(Cy.$$.fragment,f),E(Ay.$$.fragment,f),E(qp.$$.fragment,f),E(Ly.$$.fragment,f),E(Gu.$$.fragment,f),E(yy.$$.fragment,f),E(xy.$$.fragment,f),E(ky.$$.fragment,f),E(Vu.$$.fragment,f),E(Sy.$$.fragment,f),E(N2.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Ny.$$.fragment,f),E(q2.$$.fragment,f),E(Iy.$$.fragment,f),E(A1.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(y1.$$.fragment,f),E(Oy.$$.fragment,f),E(h7.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Qy.$$.fragment,f),E(_7.$$.fragment,f),E(Wy.$$.fragment,f),E(N7.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(q7.$$.fragment,f),E(Ky.$$.fragment,f),E(N4.$$.fragment,f),E(Zy.$$.fragment,f),E(e8.$$.fragment,f),E(r8.$$.fragment,f),E(q4.$$.fragment,f),E(t8.$$.fragment,f),E(_b.$$.fragment,f),E(a8.$$.fragment,f),E(n8.$$.fragment,f),E(l8.$$.fragment,f),E(bb.$$.fragment,f),E(i8.$$.fragment,f),E(Ab.$$.fragment,f),E(d8.$$.fragment,f),E(c8.$$.fragment,f),E(m8.$$.fragment,f),E(yb.$$.fragment,f),E(g8.$$.fragment,f),E(mv.$$.fragment,f),E(h8.$$.fragment,f),E(p8.$$.fragment,f),E(u8.$$.fragment,f),E(hv.$$.fragment,f),E(b8.$$.fragment,f),E(aF.$$.fragment,f),E(v8.$$.fragment,f),E(F8.$$.fragment,f),E(M8.$$.fragment,f),E(sF.$$.fragment,f),E(E8.$$.fragment,f),E(dF.$$.fragment,f),E(C8.$$.fragment,f),E(w8.$$.fragment,f),E(L8.$$.fragment,f),E(fF.$$.fragment,f),E(y8.$$.fragment,f),E(wF.$$.fragment,f),E(x8.$$.fragment,f),E($8.$$.fragment,f),E(S8.$$.fragment,f),E(LF.$$.fragment,f),E(R8.$$.fragment,f),E($F.$$.fragment,f),E(P8.$$.fragment,f),E(B8.$$.fragment,f),E(I8.$$.fragment,f),E(SF.$$.fragment,f),E(q8.$$.fragment,f),E(BF.$$.fragment,f),E(j8.$$.fragment,f),E(D8.$$.fragment,f),E(O8.$$.fragment,f),E(IF.$$.fragment,f),E(V8.$$.fragment,f),E(HF.$$.fragment,f),E(X8.$$.fragment,f),E(z8.$$.fragment,f),E(W8.$$.fragment,f),E(JF.$$.fragment,f),E(H8.$$.fragment,f),E(tT.$$.fragment,f),E(U8.$$.fragment,f),E(J8.$$.fragment,f),E(K8.$$.fragment,f),E(nT.$$.fragment,f),E(Z8.$$.fragment,f),E(uT.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(vT.$$.fragment,f),E(a9.$$.fragment,f),E(ET.$$.fragment,f),E(s9.$$.fragment,f),E(l9.$$.fragment,f),E(d9.$$.fragment,f),E(wT.$$.fragment,f),E(c9.$$.fragment,f),E(ST.$$.fragment,f),E(f9.$$.fragment,f),E(m9.$$.fragment,f),E(h9.$$.fragment,f),E(PT.$$.fragment,f),E(p9.$$.fragment,f),E(jT.$$.fragment,f),E(_9.$$.fragment,f),E(u9.$$.fragment,f),E(v9.$$.fragment,f),E(GT.$$.fragment,f),E(F9.$$.fragment,f),E(zT.$$.fragment,f),E(M9.$$.fragment,f),E(E9.$$.fragment,f),E(w9.$$.fragment,f),E(WT.$$.fragment,f),E(A9.$$.fragment,f),E(JT.$$.fragment,f),E(L9.$$.fragment,f),E(y9.$$.fragment,f),E($9.$$.fragment,f),E(KT.$$.fragment,f),E(k9.$$.fragment,f),E(aM.$$.fragment,f),E(S9.$$.fragment,f),E(R9.$$.fragment,f),E(B9.$$.fragment,f),E(sM.$$.fragment,f),E(N9.$$.fragment,f),E(dM.$$.fragment,f),E(I9.$$.fragment,f),E(q9.$$.fragment,f),E(D9.$$.fragment,f),E(fM.$$.fragment,f),E(G9.$$.fragment,f),E(sE.$$.fragment,f),E(O9.$$.fragment,f),E(V9.$$.fragment,f),E(z9.$$.fragment,f),E(iE.$$.fragment,f),E(Q9.$$.fragment,f),E(SE.$$.fragment,f),E(W9.$$.fragment,f),E(H9.$$.fragment,f),E(J9.$$.fragment,f),E(PE.$$.fragment,f),E(Y9.$$.fragment,f),E(HE.$$.fragment,f),E(K9.$$.fragment,f),E(Z9.$$.fragment,f),E(ox.$$.fragment,f),E(JE.$$.fragment,f),E(rx.$$.fragment,f),E(tC.$$.fragment,f),E(tx.$$.fragment,f),E(ax.$$.fragment,f),E(sx.$$.fragment,f),E(nC.$$.fragment,f),E(lx.$$.fragment,f),E(AC.$$.fragment,f),E(ix.$$.fragment,f),E(dx.$$.fragment,f),E(fx.$$.fragment,f),E(yC.$$.fragment,f),E(mx.$$.fragment,f),E(jC.$$.fragment,f),E(gx.$$.fragment,f),E(hx.$$.fragment,f),E(_x.$$.fragment,f),E(GC.$$.fragment,f),E(ux.$$.fragment,f),E(h3.$$.fragment,f),E(bx.$$.fragment,f),E(vx.$$.fragment,f),E(Tx.$$.fragment,f),E(_3.$$.fragment,f),E(Mx.$$.fragment,f),E(P3.$$.fragment,f),E(Ex.$$.fragment,f),E(Cx.$$.fragment,f),E(Ax.$$.fragment,f),E(N3.$$.fragment,f),E(Lx.$$.fragment,f),E(j3.$$.fragment,f),E(xx.$$.fragment,f),E($x.$$.fragment,f),E(Sx.$$.fragment,f),E(G3.$$.fragment,f),E(Rx.$$.fragment,f),E(V3.$$.fragment,f),E(Px.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(z3.$$.fragment,f),E(qx.$$.fragment,f),E(m5.$$.fragment,f),E(jx.$$.fragment,f),E(Dx.$$.fragment,f),E(Ox.$$.fragment,f),E(h5.$$.fragment,f),E(Vx.$$.fragment,f),E(B5.$$.fragment,f),E(Xx.$$.fragment,f),E(zx.$$.fragment,f),E(Wx.$$.fragment,f),E(I5.$$.fragment,f),E(Hx.$$.fragment,f),E(j5.$$.fragment,f),E(Ux.$$.fragment,f),E(Jx.$$.fragment,f),E(Kx.$$.fragment,f),E(G5.$$.fragment,f),E(Zx.$$.fragment,f),E(V5.$$.fragment,f),E(e$.$$.fragment,f),E(o$.$$.fragment,f),E(t$.$$.fragment,f),E(z5.$$.fragment,f),E(a$.$$.fragment,f),E(v0.$$.fragment,f),E(n$.$$.fragment,f),E(s$.$$.fragment,f),E(i$.$$.fragment,f),E(T0.$$.fragment,f),E(d$.$$.fragment,f),E(S0.$$.fragment,f),E(c$.$$.fragment,f),E(f$.$$.fragment,f),E(g$.$$.fragment,f),E(P0.$$.fragment,f),E(h$.$$.fragment,f),E(H0.$$.fragment,f),E(p$.$$.fragment,f),E(_$.$$.fragment,f),E(b$.$$.fragment,f),E(J0.$$.fragment,f),E(v$.$$.fragment,f),E(lw.$$.fragment,f),E(F$.$$.fragment,f),E(T$.$$.fragment,f),E(E$.$$.fragment,f),E(dw.$$.fragment,f),E(C$.$$.fragment,f),E(Fw.$$.fragment,f),E(w$.$$.fragment,f),E(A$.$$.fragment,f),E(y$.$$.fragment,f),E(Mw.$$.fragment,f),E(x$.$$.fragment,f),E(Rw.$$.fragment,f),E($$.$$.fragment,f),E(k$.$$.fragment,f),E(R$.$$.fragment,f),E(Bw.$$.fragment,f),E(P$.$$.fragment,f),E(Qw.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(q$.$$.fragment,f),E(Hw.$$.fragment,f),E(j$.$$.fragment,f),E(tA.$$.fragment,f),E(D$.$$.fragment,f),E(G$.$$.fragment,f),E(V$.$$.fragment,f),E(nA.$$.fragment,f),E(X$.$$.fragment,f),E(hA.$$.fragment,f),E(z$.$$.fragment,f),E(Q$.$$.fragment,f),E(H$.$$.fragment,f),E(_A.$$.fragment,f),E(U$.$$.fragment,f),E(bA.$$.fragment,f),E(J$.$$.fragment,f),E(Y$.$$.fragment,f),E(Z$.$$.fragment,f),E(FA.$$.fragment,f),E(ek.$$.fragment,f),E(EA.$$.fragment,f),E(rk.$$.fragment,f),E(tk.$$.fragment,f),E(nk.$$.fragment,f),E(wA.$$.fragment,f),E(sk.$$.fragment,f),E(LA.$$.fragment,f),Lze=!0)},o(f){C(d.$$.fragment,f),C(ka.$$.fragment,f),C(YL.$$.fragment,f),C(KL.$$.fragment,f),C(If.$$.fragment,f),C(ZL.$$.fragment,f),C(ey.$$.fragment,f),C(ty.$$.fragment,f),C(Hg.$$.fragment,f),C(ay.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(dy.$$.fragment,f),C($h.$$.fragment,f),C(cy.$$.fragment,f),C(fy.$$.fragment,f),C(my.$$.fragment,f),C(py.$$.fragment,f),C(mp.$$.fragment,f),C(gp.$$.fragment,f),C(_y.$$.fragment,f),C(uy.$$.fragment,f),C(by.$$.fragment,f),C(Ty.$$.fragment,f),C(Pp.$$.fragment,f),C(Bp.$$.fragment,f),C(My.$$.fragment,f),C(Ey.$$.fragment,f),C(Cy.$$.fragment,f),C(Ay.$$.fragment,f),C(qp.$$.fragment,f),C(Ly.$$.fragment,f),C(Gu.$$.fragment,f),C(yy.$$.fragment,f),C(xy.$$.fragment,f),C(ky.$$.fragment,f),C(Vu.$$.fragment,f),C(Sy.$$.fragment,f),C(N2.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Ny.$$.fragment,f),C(q2.$$.fragment,f),C(Iy.$$.fragment,f),C(A1.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(y1.$$.fragment,f),C(Oy.$$.fragment,f),C(h7.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Qy.$$.fragment,f),C(_7.$$.fragment,f),C(Wy.$$.fragment,f),C(N7.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(q7.$$.fragment,f),C(Ky.$$.fragment,f),C(N4.$$.fragment,f),C(Zy.$$.fragment,f),C(e8.$$.fragment,f),C(r8.$$.fragment,f),C(q4.$$.fragment,f),C(t8.$$.fragment,f),C(_b.$$.fragment,f),C(a8.$$.fragment,f),C(n8.$$.fragment,f),C(l8.$$.fragment,f),C(bb.$$.fragment,f),C(i8.$$.fragment,f),C(Ab.$$.fragment,f),C(d8.$$.fragment,f),C(c8.$$.fragment,f),C(m8.$$.fragment,f),C(yb.$$.fragment,f),C(g8.$$.fragment,f),C(mv.$$.fragment,f),C(h8.$$.fragment,f),C(p8.$$.fragment,f),C(u8.$$.fragment,f),C(hv.$$.fragment,f),C(b8.$$.fragment,f),C(aF.$$.fragment,f),C(v8.$$.fragment,f),C(F8.$$.fragment,f),C(M8.$$.fragment,f),C(sF.$$.fragment,f),C(E8.$$.fragment,f),C(dF.$$.fragment,f),C(C8.$$.fragment,f),C(w8.$$.fragment,f),C(L8.$$.fragment,f),C(fF.$$.fragment,f),C(y8.$$.fragment,f),C(wF.$$.fragment,f),C(x8.$$.fragment,f),C($8.$$.fragment,f),C(S8.$$.fragment,f),C(LF.$$.fragment,f),C(R8.$$.fragment,f),C($F.$$.fragment,f),C(P8.$$.fragment,f),C(B8.$$.fragment,f),C(I8.$$.fragment,f),C(SF.$$.fragment,f),C(q8.$$.fragment,f),C(BF.$$.fragment,f),C(j8.$$.fragment,f),C(D8.$$.fragment,f),C(O8.$$.fragment,f),C(IF.$$.fragment,f),C(V8.$$.fragment,f),C(HF.$$.fragment,f),C(X8.$$.fragment,f),C(z8.$$.fragment,f),C(W8.$$.fragment,f),C(JF.$$.fragment,f),C(H8.$$.fragment,f),C(tT.$$.fragment,f),C(U8.$$.fragment,f),C(J8.$$.fragment,f),C(K8.$$.fragment,f),C(nT.$$.fragment,f),C(Z8.$$.fragment,f),C(uT.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(vT.$$.fragment,f),C(a9.$$.fragment,f),C(ET.$$.fragment,f),C(s9.$$.fragment,f),C(l9.$$.fragment,f),C(d9.$$.fragment,f),C(wT.$$.fragment,f),C(c9.$$.fragment,f),C(ST.$$.fragment,f),C(f9.$$.fragment,f),C(m9.$$.fragment,f),C(h9.$$.fragment,f),C(PT.$$.fragment,f),C(p9.$$.fragment,f),C(jT.$$.fragment,f),C(_9.$$.fragment,f),C(u9.$$.fragment,f),C(v9.$$.fragment,f),C(GT.$$.fragment,f),C(F9.$$.fragment,f),C(zT.$$.fragment,f),C(M9.$$.fragment,f),C(E9.$$.fragment,f),C(w9.$$.fragment,f),C(WT.$$.fragment,f),C(A9.$$.fragment,f),C(JT.$$.fragment,f),C(L9.$$.fragment,f),C(y9.$$.fragment,f),C($9.$$.fragment,f),C(KT.$$.fragment,f),C(k9.$$.fragment,f),C(aM.$$.fragment,f),C(S9.$$.fragment,f),C(R9.$$.fragment,f),C(B9.$$.fragment,f),C(sM.$$.fragment,f),C(N9.$$.fragment,f),C(dM.$$.fragment,f),C(I9.$$.fragment,f),C(q9.$$.fragment,f),C(D9.$$.fragment,f),C(fM.$$.fragment,f),C(G9.$$.fragment,f),C(sE.$$.fragment,f),C(O9.$$.fragment,f),C(V9.$$.fragment,f),C(z9.$$.fragment,f),C(iE.$$.fragment,f),C(Q9.$$.fragment,f),C(SE.$$.fragment,f),C(W9.$$.fragment,f),C(H9.$$.fragment,f),C(J9.$$.fragment,f),C(PE.$$.fragment,f),C(Y9.$$.fragment,f),C(HE.$$.fragment,f),C(K9.$$.fragment,f),C(Z9.$$.fragment,f),C(ox.$$.fragment,f),C(JE.$$.fragment,f),C(rx.$$.fragment,f),C(tC.$$.fragment,f),C(tx.$$.fragment,f),C(ax.$$.fragment,f),C(sx.$$.fragment,f),C(nC.$$.fragment,f),C(lx.$$.fragment,f),C(AC.$$.fragment,f),C(ix.$$.fragment,f),C(dx.$$.fragment,f),C(fx.$$.fragment,f),C(yC.$$.fragment,f),C(mx.$$.fragment,f),C(jC.$$.fragment,f),C(gx.$$.fragment,f),C(hx.$$.fragment,f),C(_x.$$.fragment,f),C(GC.$$.fragment,f),C(ux.$$.fragment,f),C(h3.$$.fragment,f),C(bx.$$.fragment,f),C(vx.$$.fragment,f),C(Tx.$$.fragment,f),C(_3.$$.fragment,f),C(Mx.$$.fragment,f),C(P3.$$.fragment,f),C(Ex.$$.fragment,f),C(Cx.$$.fragment,f),C(Ax.$$.fragment,f),C(N3.$$.fragment,f),C(Lx.$$.fragment,f),C(j3.$$.fragment,f),C(xx.$$.fragment,f),C($x.$$.fragment,f),C(Sx.$$.fragment,f),C(G3.$$.fragment,f),C(Rx.$$.fragment,f),C(V3.$$.fragment,f),C(Px.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(z3.$$.fragment,f),C(qx.$$.fragment,f),C(m5.$$.fragment,f),C(jx.$$.fragment,f),C(Dx.$$.fragment,f),C(Ox.$$.fragment,f),C(h5.$$.fragment,f),C(Vx.$$.fragment,f),C(B5.$$.fragment,f),C(Xx.$$.fragment,f),C(zx.$$.fragment,f),C(Wx.$$.fragment,f),C(I5.$$.fragment,f),C(Hx.$$.fragment,f),C(j5.$$.fragment,f),C(Ux.$$.fragment,f),C(Jx.$$.fragment,f),C(Kx.$$.fragment,f),C(G5.$$.fragment,f),C(Zx.$$.fragment,f),C(V5.$$.fragment,f),C(e$.$$.fragment,f),C(o$.$$.fragment,f),C(t$.$$.fragment,f),C(z5.$$.fragment,f),C(a$.$$.fragment,f),C(v0.$$.fragment,f),C(n$.$$.fragment,f),C(s$.$$.fragment,f),C(i$.$$.fragment,f),C(T0.$$.fragment,f),C(d$.$$.fragment,f),C(S0.$$.fragment,f),C(c$.$$.fragment,f),C(f$.$$.fragment,f),C(g$.$$.fragment,f),C(P0.$$.fragment,f),C(h$.$$.fragment,f),C(H0.$$.fragment,f),C(p$.$$.fragment,f),C(_$.$$.fragment,f),C(b$.$$.fragment,f),C(J0.$$.fragment,f),C(v$.$$.fragment,f),C(lw.$$.fragment,f),C(F$.$$.fragment,f),C(T$.$$.fragment,f),C(E$.$$.fragment,f),C(dw.$$.fragment,f),C(C$.$$.fragment,f),C(Fw.$$.fragment,f),C(w$.$$.fragment,f),C(A$.$$.fragment,f),C(y$.$$.fragment,f),C(Mw.$$.fragment,f),C(x$.$$.fragment,f),C(Rw.$$.fragment,f),C($$.$$.fragment,f),C(k$.$$.fragment,f),C(R$.$$.fragment,f),C(Bw.$$.fragment,f),C(P$.$$.fragment,f),C(Qw.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(q$.$$.fragment,f),C(Hw.$$.fragment,f),C(j$.$$.fragment,f),C(tA.$$.fragment,f),C(D$.$$.fragment,f),C(G$.$$.fragment,f),C(V$.$$.fragment,f),C(nA.$$.fragment,f),C(X$.$$.fragment,f),C(hA.$$.fragment,f),C(z$.$$.fragment,f),C(Q$.$$.fragment,f),C(H$.$$.fragment,f),C(_A.$$.fragment,f),C(U$.$$.fragment,f),C(bA.$$.fragment,f),C(J$.$$.fragment,f),C(Y$.$$.fragment,f),C(Z$.$$.fragment,f),C(FA.$$.fragment,f),C(ek.$$.fragment,f),C(EA.$$.fragment,f),C(rk.$$.fragment,f),C(tk.$$.fragment,f),C(nk.$$.fragment,f),C(wA.$$.fragment,f),C(sk.$$.fragment,f),C(LA.$$.fragment,f),Lze=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(Sf),f&&t(nt),f&&t(Oe),f&&t(Qe),f&&t(Pf),w(ka,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t(Sa),f&&t(MVe),f&&t(Si),w(YL),f&&t(EVe),f&&t(qn),f&&t(CVe),w(KL,f),f&&t(wVe),f&&t(SS),f&&t(AVe),w(If,f),f&&t(LVe),f&&t(Ri),w(ZL),f&&t(yVe),f&&t(wo),w(ey),w(ty),w(Hg),w(ay),f&&t(xVe),f&&t(Bi),w(ny),f&&t($Ve),f&&t(Ao),w(sy),w(dy),w($h),w(cy),f&&t(kVe),f&&t(Ni),w(fy),f&&t(SVe),f&&t(Lo),w(my),w(py),w(mp),w(gp),w(_y),f&&t(RVe),f&&t(Ii),w(uy),f&&t(PVe),f&&t(yo),w(by),w(Ty),w(Pp),w(Bp),w(My),f&&t(BVe),f&&t(ji),w(Ey),f&&t(NVe),f&&t(xo),w(Cy),w(Ay),w(qp),w(Ly),w(Gu),f&&t(IVe),f&&t(Oi),w(yy),f&&t(qVe),f&&t($o),w(xy),w(ky),w(Vu),w(Sy),w(N2),f&&t(jVe),f&&t(zi),w(Ry),f&&t(DVe),f&&t(ko),w(Py),w(Ny),w(q2),w(Iy),w(A1),f&&t(GVe),f&&t(Hi),w(qy),f&&t(OVe),f&&t(So),w(jy),w(Gy),w(y1),w(Oy),w(h7),f&&t(VVe),f&&t(Yi),w(Vy),f&&t(XVe),f&&t(Ro),w(Xy),w(Qy),w(_7),w(Wy),w(N7),f&&t(zVe),f&&t(ed),w(Hy),f&&t(QVe),f&&t(Po),w(Uy),w(Yy),w(q7),w(Ky),w(N4),f&&t(WVe),f&&t(td),w(Zy),f&&t(HVe),f&&t(Bo),w(e8),w(r8),w(q4),w(t8),w(_b),f&&t(UVe),f&&t(sd),w(a8),f&&t(JVe),f&&t(No),w(n8),w(l8),w(bb),w(i8),w(Ab),f&&t(YVe),f&&t(dd),w(d8),f&&t(KVe),f&&t(qo),w(c8),w(m8),w(yb),w(g8),w(mv),f&&t(ZVe),f&&t(md),w(h8),f&&t(eXe),f&&t(jo),w(p8),w(u8),w(hv),w(b8),w(aF),f&&t(oXe),f&&t(pd),w(v8),f&&t(rXe),f&&t(Do),w(F8),w(M8),w(sF),w(E8),w(dF),f&&t(tXe),f&&t(bd),w(C8),f&&t(aXe),f&&t(Go),w(w8),w(L8),w(fF),w(y8),w(wF),f&&t(nXe),f&&t(Td),w(x8),f&&t(sXe),f&&t(Oo),w($8),w(S8),w(LF),w(R8),w($F),f&&t(lXe),f&&t(Cd),w(P8),f&&t(iXe),f&&t(Vo),w(B8),w(I8),w(SF),w(q8),w(BF),f&&t(dXe),f&&t(Ld),w(j8),f&&t(cXe),f&&t(Xo),w(D8),w(O8),w(IF),w(V8),w(HF),f&&t(fXe),f&&t($d),w(X8),f&&t(mXe),f&&t(zo),w(z8),w(W8),w(JF),w(H8),w(tT),f&&t(gXe),f&&t(Rd),w(U8),f&&t(hXe),f&&t(Qo),w(J8),w(K8),w(nT),w(Z8),w(uT),f&&t(pXe),f&&t(Nd),w(e9),f&&t(_Xe),f&&t(Wo),w(o9),w(t9),w(vT),w(a9),w(ET),f&&t(uXe),f&&t(jd),w(s9),f&&t(bXe),f&&t(Ho),w(l9),w(d9),w(wT),w(c9),w(ST),f&&t(vXe),f&&t(Od),w(f9),f&&t(FXe),f&&t(Uo),w(m9),w(h9),w(PT),w(p9),w(jT),f&&t(TXe),f&&t(Qd),w(_9),f&&t(MXe),f&&t(Jo),w(u9),w(v9),w(GT),w(F9),w(zT),f&&t(EXe),f&&t(Ud),w(M9),f&&t(CXe),f&&t(Yo),w(E9),w(w9),w(WT),w(A9),w(JT),f&&t(wXe),f&&t(Kd),w(L9),f&&t(AXe),f&&t(Ko),w(y9),w($9),w(KT),w(k9),w(aM),f&&t(LXe),f&&t(oc),w(S9),f&&t(yXe),f&&t(Zo),w(R9),w(B9),w(sM),w(N9),w(dM),f&&t(xXe),f&&t(ac),w(I9),f&&t($Xe),f&&t(er),w(q9),w(D9),w(fM),w(G9),w(sE),f&&t(kXe),f&&t(lc),w(O9),f&&t(SXe),f&&t(or),w(V9),w(z9),w(iE),w(Q9),w(SE),f&&t(RXe),f&&t(cc),w(W9),f&&t(PXe),f&&t(rr),w(H9),w(J9),w(PE),w(Y9),w(HE),f&&t(BXe),f&&t(gc),w(K9),f&&t(NXe),f&&t(tr),w(Z9),w(ox),w(JE),w(rx),w(tC),f&&t(IXe),f&&t(_c),w(tx),f&&t(qXe),f&&t(nr),w(ax),w(sx),w(nC),w(lx),w(AC),f&&t(jXe),f&&t(vc),w(ix),f&&t(DXe),f&&t(sr),w(dx),w(fx),w(yC),w(mx),w(jC),f&&t(GXe),f&&t(Mc),w(gx),f&&t(OXe),f&&t(lr),w(hx),w(_x),w(GC),w(ux),w(h3),f&&t(VXe),f&&t(wc),w(bx),f&&t(XXe),f&&t(ir),w(vx),w(Tx),w(_3),w(Mx),w(P3),f&&t(zXe),f&&t(yc),w(Ex),f&&t(QXe),f&&t(dr),w(Cx),w(Ax),w(N3),w(Lx),w(j3),f&&t(WXe),f&&t(kc),w(xx),f&&t(HXe),f&&t(cr),w($x),w(Sx),w(G3),w(Rx),w(V3),f&&t(UXe),f&&t(Pc),w(Px),f&&t(JXe),f&&t(fr),w(Bx),w(Ix),w(z3),w(qx),w(m5),f&&t(YXe),f&&t(Ic),w(jx),f&&t(KXe),f&&t(mr),w(Dx),w(Ox),w(h5),w(Vx),w(B5),f&&t(ZXe),f&&t(Dc),w(Xx),f&&t(eze),f&&t(gr),w(zx),w(Wx),w(I5),w(Hx),w(j5),f&&t(oze),f&&t(Vc),w(Ux),f&&t(rze),f&&t(hr),w(Jx),w(Kx),w(G5),w(Zx),w(V5),f&&t(tze),f&&t(Qc),w(e$),f&&t(aze),f&&t(pr),w(o$),w(t$),w(z5),w(a$),w(v0),f&&t(nze),f&&t(Uc),w(n$),f&&t(sze),f&&t(_r),w(s$),w(i$),w(T0),w(d$),w(S0),f&&t(lze),f&&t(Kc),w(c$),f&&t(ize),f&&t(ur),w(f$),w(g$),w(P0),w(h$),w(H0),f&&t(dze),f&&t(of),w(p$),f&&t(cze),f&&t(br),w(_$),w(b$),w(J0),w(v$),w(lw),f&&t(fze),f&&t(af),w(F$),f&&t(mze),f&&t(vr),w(T$),w(E$),w(dw),w(C$),w(Fw),f&&t(gze),f&&t(lf),w(w$),f&&t(hze),f&&t(Fr),w(A$),w(y$),w(Mw),w(x$),w(Rw),f&&t(pze),f&&t(ff),w($$),f&&t(_ze),f&&t(Tr),w(k$),w(R$),w(Bw),w(P$),w(Qw),f&&t(uze),f&&t(hf),w(B$),f&&t(bze),f&&t(Mr),w(N$),w(q$),w(Hw),w(j$),w(tA),f&&t(vze),f&&t(uf),w(D$),f&&t(Fze),f&&t(Er),w(G$),w(V$),w(nA),w(X$),w(hA),f&&t(Tze),f&&t(Ff),w(z$),f&&t(Mze),f&&t(Cr),w(Q$),w(H$),w(_A),w(U$),w(bA),f&&t(Eze),f&&t(Ef),w(J$),f&&t(Cze),f&&t(wr),w(Y$),w(Z$),w(FA),w(ek),w(EA),f&&t(wze),f&&t(Af),w(rk),f&&t(Aze),f&&t(Ar),w(tk),w(nk),w(wA),w(sk),w(LA)}}}const iWt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function dWt($){return lzt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _Wt extends tzt{constructor(g){super();azt(this,g,dWt,lWt,nzt,{})}}export{_Wt as default,iWt as metadata};
