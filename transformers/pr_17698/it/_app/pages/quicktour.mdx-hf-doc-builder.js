import{S as ea,i as ta,s as aa,e as p,c as m,a as d,d as n,b,N as ya,g as h,L as Y,F as gt,G as o,Q as cs,Y as rc,H as $t,I as vt,J as bt,q as j,o as A,v as ur,X as cr,O as Qu,P as Hu,f as dc,w as S,x as N,y as M,B as D,k as z,m as E,n as Pe,p as Se,Z as uc,l as Me,t as c,h as f,j as cc,W as _c,K as fc,M as hc}from"../chunks/vendor-hf-doc-builder.js";import{T as Ta}from"../chunks/Tip-hf-doc-builder.js";import{I as ht}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as H}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as qa,M as $e}from"../chunks/Markdown-hf-doc-builder.js";function gc(r){let e,s;return{c(){e=p("iframe"),this.h()},l(t){e=m(t,"IFRAME",{class:!0,src:!0,title:!0,frameborder:!0,allow:!0}),d(e).forEach(n),this.h()},h(){b(e,"class","w-full xl:w-4/6 h-80"),ya(e.src,s="https://www.youtube-nocookie.com/embed/"+r[0])||b(e,"src",s),b(e,"title","YouTube video player"),b(e,"frameborder","0"),b(e,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),e.allowFullscreen=!0},m(t,l){h(t,e,l)},p(t,[l]){l&1&&!ya(e.src,s="https://www.youtube-nocookie.com/embed/"+t[0])&&b(e,"src",s)},i:Y,o:Y,d(t){t&&n(e)}}}function $c(r,e,s){let{id:t}=e;return r.$$set=l=>{"id"in l&&s(0,t=l.id)},[t]}class Ju extends ea{constructor(e){super();ta(this,e,$c,gc,aa,{id:0})}}function vc(r){let e,s,t,l,i,u;const g=r[7].default,_=gt(g,r,r[6],null);return{c(){e=p("div"),s=p("ul"),_&&_.c(),this.h()},l(v){e=m(v,"DIV",{class:!0});var q=d(e);s=m(q,"UL",{class:!0});var I=d(s);_&&_.l(I),I.forEach(n),q.forEach(n),this.h()},h(){b(s,"class","min-w-full w-auto"),b(e,"class",t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(r[2]==="right"?"right-0":"left-0")+" "+r[0])},m(v,q){h(v,e,q),o(e,s),_&&_.m(s,null),r[8](e),l=!0,i||(u=cs(e,"click",function(){rc(r[1])&&r[1].apply(this,arguments)}),i=!0)},p(v,[q]){r=v,_&&_.p&&(!l||q&64)&&$t(_,g,r,r[6],l?bt(g,r[6],q,null):vt(r[6]),null),(!l||q&5&&t!==(t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(r[2]==="right"?"right-0":"left-0")+" "+r[0]))&&b(e,"class",t)},i(v){l||(j(_,v),l=!0)},o(v){A(_,v),l=!1},d(v){v&&n(e),_&&_.d(v),r[8](null),i=!1,u()}}}function bc(r,e,s){let{$$slots:t={},$$scope:l}=e,{classNames:i=""}=e,{dropdownElement:u=void 0}=e,{forceAlignement:g=void 0}=e,{onClose:_}=e,v=g!=null?g:"left",q;ur(()=>{var y,P;if(document.addEventListener("click",I),!g){const w=document.documentElement.clientWidth,C=(q==null?void 0:q.getBoundingClientRect())||{},k=(y=C.left)!=null?y:0,T=(P=C.width)!=null?P:0;s(2,v=k+T>w?"right":"left")}return()=>{document.removeEventListener("click",I)}});function I(y){const P=y.target;P!==u&&!(u==null?void 0:u.contains(P))&&_()}function F(y){cr[y?"unshift":"push"](()=>{q=y,s(3,q)})}return r.$$set=y=>{"classNames"in y&&s(0,i=y.classNames),"dropdownElement"in y&&s(4,u=y.dropdownElement),"forceAlignement"in y&&s(5,g=y.forceAlignement),"onClose"in y&&s(1,_=y.onClose),"$$scope"in y&&s(6,l=y.$$scope)},[i,_,v,q,u,g,l,t,F]}class kc extends ea{constructor(e){super();ta(this,e,bc,vc,aa,{classNames:0,dropdownElement:4,forceAlignement:5,onClose:1})}}function wc(r){let e,s;return{c(){e=Qu("svg"),s=Qu("path"),this.h()},l(t){e=Hu(t,"svg",{class:!0,xmlns:!0,"xmlns:xlink":!0,"aria-hidden":!0,focusable:!0,role:!0,width:!0,height:!0,preserveAspectRatio:!0,viewBox:!0,style:!0});var l=d(e);s=Hu(l,"path",{d:!0,fill:!0}),d(s).forEach(n),l.forEach(n),this.h()},h(){b(s,"d","M7 10l5 5l5-5z"),b(s,"fill","currentColor"),b(e,"class",r[0]),b(e,"xmlns","http://www.w3.org/2000/svg"),b(e,"xmlns:xlink","http://www.w3.org/1999/xlink"),b(e,"aria-hidden","true"),b(e,"focusable","false"),b(e,"role","img"),b(e,"width","1em"),b(e,"height","1em"),b(e,"preserveAspectRatio","xMidYMid meet"),b(e,"viewBox","0 0 24 24"),dc(e,"transform","rotate(360deg)")},m(t,l){h(t,e,l),o(e,s)},p(t,[l]){l&1&&b(e,"class",t[0])},i:Y,o:Y,d(t){t&&n(e)}}}function zc(r,e,s){let{classNames:t=""}=e;return r.$$set=l=>{"classNames"in l&&s(0,t=l.classNames)},[t]}class Ec extends ea{constructor(e){super();ta(this,e,zc,wc,aa,{classNames:0})}}const jc=r=>({}),Vu=r=>({}),Ac=r=>({}),Wu=r=>({});function Cc(r){let e,s,t,l,i,u=r[2]&&Yu(r),g=r[10]&&Ku();return{c(){u&&u.c(),e=z(),s=c(r[4]),t=z(),g&&g.c(),l=Me()},l(_){u&&u.l(_),e=E(_),s=f(_,r[4]),t=E(_),g&&g.l(_),l=Me()},m(_,v){u&&u.m(_,v),h(_,e,v),h(_,s,v),h(_,t,v),g&&g.m(_,v),h(_,l,v),i=!0},p(_,v){_[2]?u?(u.p(_,v),v&4&&j(u,1)):(u=Yu(_),u.c(),j(u,1),u.m(e.parentNode,e)):u&&(Pe(),A(u,1,1,()=>{u=null}),Se()),(!i||v&16)&&cc(s,_[4]),_[10]?g?v&1024&&j(g,1):(g=Ku(),g.c(),j(g,1),g.m(l.parentNode,l)):g&&(Pe(),A(g,1,1,()=>{g=null}),Se())},i(_){i||(j(u),j(g),i=!0)},o(_){A(u),A(g),i=!1},d(_){u&&u.d(_),_&&n(e),_&&n(s),_&&n(t),g&&g.d(_),_&&n(l)}}}function qc(r){let e;const s=r[14].button,t=gt(s,r,r[18],Wu);return{c(){t&&t.c()},l(l){t&&t.l(l)},m(l,i){t&&t.m(l,i),e=!0},p(l,i){t&&t.p&&(!e||i&262144)&&$t(t,s,l,l[18],e?bt(s,l[18],i,Ac):vt(l[18]),Wu)},i(l){e||(j(t,l),e=!0)},o(l){A(t,l),e=!1},d(l){t&&t.d(l)}}}function Yu(r){let e,s,t;var l=r[2];function i(u){return{props:{classNames:"mr-1.5 "+u[3]}}}return l&&(e=new l(i(r))),{c(){e&&S(e.$$.fragment),s=Me()},l(u){e&&N(e.$$.fragment,u),s=Me()},m(u,g){e&&M(e,u,g),h(u,s,g),t=!0},p(u,g){const _={};if(g&8&&(_.classNames="mr-1.5 "+u[3]),l!==(l=u[2])){if(e){Pe();const v=e;A(v.$$.fragment,1,0,()=>{D(v,1)}),Se()}l?(e=new l(i(u)),S(e.$$.fragment),j(e.$$.fragment,1),M(e,s.parentNode,s)):e=null}else l&&e.$set(_)},i(u){t||(e&&j(e.$$.fragment,u),t=!0)},o(u){e&&A(e.$$.fragment,u),t=!1},d(u){u&&n(s),e&&D(e,u)}}}function Ku(r){let e,s;return e=new Ec({props:{classNames:"-mr-1 text-gray-500"}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Zu(r){let e,s;return e=new kc({props:{classNames:r[6]+" "+(r[9]?"v2-dropdown-menu hidden":""),dropdownElement:r[11],forceAlignement:r[5],onClose:r[16],$$slots:{default:[Tc]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&576&&(i.classNames=t[6]+" "+(t[9]?"v2-dropdown-menu hidden":"")),l&2048&&(i.dropdownElement=t[11]),l&32&&(i.forceAlignement=t[5]),l&4096&&(i.onClose=t[16]),l&262144&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Tc(r){let e;const s=r[14].menu,t=gt(s,r,r[18],Vu);return{c(){t&&t.c()},l(l){t&&t.l(l)},m(l,i){t&&t.m(l,i),e=!0},p(l,i){t&&t.p&&(!e||i&262144)&&$t(t,s,l,l[18],e?bt(s,l[18],i,jc):vt(l[18]),Vu)},i(l){e||(j(t,l),e=!0)},o(l){A(t,l),e=!1},d(l){t&&t.d(l)}}}function yc(r){let e,s,t,l,i,u,g,_,v,q,I;const F=[qc,Cc],y=[];function P(C,k){return C[13].button?0:1}t=P(r),l=y[t]=F[t](r);let w=(r[12]||r[9])&&Zu(r);return{c(){e=p("div"),s=p("button"),l.c(),u=z(),w&&w.c(),this.h()},l(C){e=m(C,"DIV",{class:!0,"selected-value":!0});var k=d(e);s=m(k,"BUTTON",{class:!0,type:!0});var T=d(s);l.l(T),T.forEach(n),u=E(k),w&&w.l(k),k.forEach(n),this.h()},h(){b(s,"class",i=""+r[1]+" "+(r[7]?"":"cursor-pointer w-full btn text-sm")+" "+(r[9]?"v2-dropdown-button":"")),b(s,"type","button"),b(e,"class",g="relative "+r[0]+" "+(r[9]?"v2-dropdown":"")),b(e,"selected-value",_=r[8]||void 0)},m(C,k){h(C,e,k),o(e,s),y[t].m(s,null),o(e,u),w&&w.m(e,null),r[17](e),v=!0,q||(I=cs(s,"click",r[15]),q=!0)},p(C,[k]){let T=t;t=P(C),t===T?y[t].p(C,k):(Pe(),A(y[T],1,1,()=>{y[T]=null}),Se(),l=y[t],l?l.p(C,k):(l=y[t]=F[t](C),l.c()),j(l,1),l.m(s,null)),(!v||k&642&&i!==(i=""+C[1]+" "+(C[7]?"":"cursor-pointer w-full btn text-sm")+" "+(C[9]?"v2-dropdown-button":"")))&&b(s,"class",i),C[12]||C[9]?w?(w.p(C,k),k&4608&&j(w,1)):(w=Zu(C),w.c(),j(w,1),w.m(e,null)):w&&(Pe(),A(w,1,1,()=>{w=null}),Se()),(!v||k&513&&g!==(g="relative "+C[0]+" "+(C[9]?"v2-dropdown":"")))&&b(e,"class",g),(!v||k&256&&_!==(_=C[8]||void 0))&&b(e,"selected-value",_)},i(C){v||(j(l),j(w),v=!0)},o(C){A(l),A(w),v=!1},d(C){C&&n(e),y[t].d(),w&&w.d(),r[17](null),q=!1,I()}}}function Pc(r,e,s){let{$$slots:t={},$$scope:l}=e;const i=uc(t);let{classNames:u=""}=e,{btnClassNames:g=""}=e,{btnIcon:_=void 0}=e,{btnIconClassNames:v=""}=e,{btnLabel:q=""}=e,{forceMenuAlignement:I=void 0}=e,{menuClassNames:F=""}=e,{noBtnClass:y=void 0}=e,{selectedValue:P=void 0}=e,{useDeprecatedJS:w=!0}=e,{withBtnCaret:C=!1}=e,k,T=!1;const R=()=>s(12,T=!T),G=()=>s(12,T=!1);function V(U){cr[U?"unshift":"push"](()=>{k=U,s(11,k)})}return r.$$set=U=>{"classNames"in U&&s(0,u=U.classNames),"btnClassNames"in U&&s(1,g=U.btnClassNames),"btnIcon"in U&&s(2,_=U.btnIcon),"btnIconClassNames"in U&&s(3,v=U.btnIconClassNames),"btnLabel"in U&&s(4,q=U.btnLabel),"forceMenuAlignement"in U&&s(5,I=U.forceMenuAlignement),"menuClassNames"in U&&s(6,F=U.menuClassNames),"noBtnClass"in U&&s(7,y=U.noBtnClass),"selectedValue"in U&&s(8,P=U.selectedValue),"useDeprecatedJS"in U&&s(9,w=U.useDeprecatedJS),"withBtnCaret"in U&&s(10,C=U.withBtnCaret),"$$scope"in U&&s(18,l=U.$$scope)},[u,g,_,v,q,I,F,y,P,w,C,k,T,i,t,R,G,V,l]}class pc extends ea{constructor(e){super();ta(this,e,Pc,yc,aa,{classNames:0,btnClassNames:1,btnIcon:2,btnIconClassNames:3,btnLabel:4,forceMenuAlignement:5,menuClassNames:6,noBtnClass:7,selectedValue:8,useDeprecatedJS:9,withBtnCaret:10})}}function Sc(r){let e,s,t,l=r[5]&&Xu(r);return{c(){l&&l.c(),e=z(),s=c(r[7])},l(i){l&&l.l(i),e=E(i),s=f(i,r[7])},m(i,u){l&&l.m(i,u),h(i,e,u),h(i,s,u),t=!0},p(i,u){i[5]?l?(l.p(i,u),u&32&&j(l,1)):(l=Xu(i),l.c(),j(l,1),l.m(e.parentNode,e)):l&&(Pe(),A(l,1,1,()=>{l=null}),Se()),(!t||u&128)&&cc(s,i[7])},i(i){t||(j(l),t=!0)},o(i){A(l),t=!1},d(i){l&&l.d(i),i&&n(e),i&&n(s)}}}function Mc(r){let e;const s=r[15].default,t=gt(s,r,r[14],null);return{c(){t&&t.c()},l(l){t&&t.l(l)},m(l,i){t&&t.m(l,i),e=!0},p(l,i){t&&t.p&&(!e||i&16384)&&$t(t,s,l,l[14],e?bt(s,l[14],i,null):vt(l[14]),null)},i(l){e||(j(t,l),e=!0)},o(l){A(t,l),e=!1},d(l){t&&t.d(l)}}}function Xu(r){let e,s,t;var l=r[5];function i(u){return{props:{classNames:"mr-1.5 "+u[6]}}}return l&&(e=new l(i(r))),{c(){e&&S(e.$$.fragment),s=Me()},l(u){e&&N(e.$$.fragment,u),s=Me()},m(u,g){e&&M(e,u,g),h(u,s,g),t=!0},p(u,g){const _={};if(g&64&&(_.classNames="mr-1.5 "+u[6]),l!==(l=u[5])){if(e){Pe();const v=e;A(v.$$.fragment,1,0,()=>{D(v,1)}),Se()}l?(e=new l(i(u)),S(e.$$.fragment),j(e.$$.fragment,1),M(e,s.parentNode,s)):e=null}else l&&e.$set(_)},i(u){t||(e&&j(e.$$.fragment,u),t=!0)},o(u){e&&A(e.$$.fragment,u),t=!1},d(u){u&&n(s),e&&D(e,u)}}}function Dc(r){let e,s,t,l,i,u,g,_,v,q;const I=[Mc,Sc],F=[];function y(P,w){return P[13].default?0:1}return t=y(r),l=F[t]=I[t](r),{c(){e=p("li"),s=p("a"),l.c(),this.h()},l(P){e=m(P,"LI",{});var w=d(e);s=m(w,"A",{class:!0,"data-label":!0,"data-url":!0,"data-value":!0,href:!0,rel:!0,target:!0});var C=d(s);l.l(C),C.forEach(n),w.forEach(n),this.h()},h(){b(s,"class",i="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+r[0]+" "+(r[9]?"hover:underline":"")+" "+(r[12]?"v2-dropdown-entry":"")),b(s,"data-label",r[1]),b(s,"data-url",r[2]),b(s,"data-value",r[3]),b(s,"href",r[4]),b(s,"rel",u=r[8]?"nofollow":void 0),b(s,"target",g=r[11]?"_blank":void 0)},m(P,w){h(P,e,w),o(e,s),F[t].m(s,null),_=!0,v||(q=cs(s,"click",function(){rc(r[10])&&r[10].apply(this,arguments)}),v=!0)},p(P,[w]){r=P;let C=t;t=y(r),t===C?F[t].p(r,w):(Pe(),A(F[C],1,1,()=>{F[C]=null}),Se(),l=F[t],l?l.p(r,w):(l=F[t]=I[t](r),l.c()),j(l,1),l.m(s,null)),(!_||w&4609&&i!==(i="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+r[0]+" "+(r[9]?"hover:underline":"")+" "+(r[12]?"v2-dropdown-entry":"")))&&b(s,"class",i),(!_||w&2)&&b(s,"data-label",r[1]),(!_||w&4)&&b(s,"data-url",r[2]),(!_||w&8)&&b(s,"data-value",r[3]),(!_||w&16)&&b(s,"href",r[4]),(!_||w&256&&u!==(u=r[8]?"nofollow":void 0))&&b(s,"rel",u),(!_||w&2048&&g!==(g=r[11]?"_blank":void 0))&&b(s,"target",g)},i(P){_||(j(l),_=!0)},o(P){A(l),_=!1},d(P){P&&n(e),F[t].d(),v=!1,q()}}}function Nc(r,e,s){let{$$slots:t={},$$scope:l}=e;const i=uc(t);let{classNames:u=""}=e,{dataLabel:g=void 0}=e,{dataUrl:_=void 0}=e,{dataValue:v=void 0}=e,{href:q=void 0}=e,{icon:I=void 0}=e,{iconClassNames:F=""}=e,{label:y=""}=e,{noFollow:P=!1}=e,{underline:w=!1}=e,{onClick:C=()=>{}}=e,{targetBlank:k=!1}=e,{useDeprecatedJS:T=!0}=e;return r.$$set=R=>{"classNames"in R&&s(0,u=R.classNames),"dataLabel"in R&&s(1,g=R.dataLabel),"dataUrl"in R&&s(2,_=R.dataUrl),"dataValue"in R&&s(3,v=R.dataValue),"href"in R&&s(4,q=R.href),"icon"in R&&s(5,I=R.icon),"iconClassNames"in R&&s(6,F=R.iconClassNames),"label"in R&&s(7,y=R.label),"noFollow"in R&&s(8,P=R.noFollow),"underline"in R&&s(9,w=R.underline),"onClick"in R&&s(10,C=R.onClick),"targetBlank"in R&&s(11,k=R.targetBlank),"useDeprecatedJS"in R&&s(12,T=R.useDeprecatedJS),"$$scope"in R&&s(14,l=R.$$scope)},[u,g,_,v,q,I,F,y,P,w,C,k,T,i,l,t]}class mc extends ea{constructor(e){super();ta(this,e,Nc,Dc,aa,{classNames:0,dataLabel:1,dataUrl:2,dataValue:3,href:4,icon:5,iconClassNames:6,label:7,noFollow:8,underline:9,onClick:10,targetBlank:11,useDeprecatedJS:12})}}const{window:Fc}=_c,Ic=r=>({}),xu=r=>({slot:"button"});function ec(r,e,s){const t=r.slice();return t[11]=e[s].label,t[12]=e[s].value,t}const Oc=r=>({}),tc=r=>({slot:"menu"}),Lc=r=>({}),ac=r=>({slot:"button"});function lc(r,e,s){const t=r.slice();return t[11]=e[s].label,t[12]=e[s].value,t}const Rc=r=>({}),oc=r=>({slot:"menu"});function Uc(r){let e,s;return e=new pc({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[Jc],button:[Qc]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&1024&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Bc(r){let e,s,t;return{c(){e=p("a"),s=p("img"),this.h()},l(l){e=m(l,"A",{href:!0,target:!0});var i=d(e);s=m(i,"IMG",{alt:!0,class:!0,src:!0}),i.forEach(n),this.h()},h(){b(s,"alt","Open In Colab"),b(s,"class","!m-0"),ya(s.src,t="https://colab.research.google.com/assets/colab-badge.svg")||b(s,"src",t),b(e,"href",r[2][0].value),b(e,"target","_blank")},m(l,i){h(l,e,i),o(e,s)},p:Y,i:Y,o:Y,d(l){l&&n(e)}}}function Gc(r){let e,s;return{c(){e=p("img"),this.h()},l(t){e=m(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){b(e,"alt","Open In Colab"),b(e,"class","!m-0"),ya(e.src,s="https://colab.research.google.com/assets/colab-badge.svg")||b(e,"src",s)},m(t,l){h(t,e,l)},d(t){t&&n(e)}}}function Qc(r){let e;const s=r[6].default,t=gt(s,r,r[10],ac),l=t||Gc();return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,u){l&&l.m(i,u),e=!0},p(i,u){t&&t.p&&(!e||u&1024)&&$t(t,s,i,i[10],e?bt(s,i[10],u,Lc):vt(i[10]),ac)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function sc(r){let e,s;function t(){return r[7](r[12])}return e=new mc({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:r[11],onClick:t,useDeprecatedJS:!1}}),{c(){S(e.$$.fragment)},l(l){N(e.$$.fragment,l)},m(l,i){M(e,l,i),s=!0},p(l,i){r=l},i(l){s||(j(e.$$.fragment,l),s=!0)},o(l){A(e.$$.fragment,l),s=!1},d(l){D(e,l)}}}function Hc(r){let e,s,t=r[2],l=[];for(let u=0;u<t.length;u+=1)l[u]=sc(lc(r,t,u));const i=u=>A(l[u],1,1,()=>{l[u]=null});return{c(){for(let u=0;u<l.length;u+=1)l[u].c();e=Me()},l(u){for(let g=0;g<l.length;g+=1)l[g].l(u);e=Me()},m(u,g){for(let _=0;_<l.length;_+=1)l[_].m(u,g);h(u,e,g),s=!0},p(u,g){if(g&4){t=u[2];let _;for(_=0;_<t.length;_+=1){const v=lc(u,t,_);l[_]?(l[_].p(v,g),j(l[_],1)):(l[_]=sc(v),l[_].c(),j(l[_],1),l[_].m(e.parentNode,e))}for(Pe(),_=t.length;_<l.length;_+=1)i(_);Se()}},i(u){if(!s){for(let g=0;g<t.length;g+=1)j(l[g]);s=!0}},o(u){l=l.filter(Boolean);for(let g=0;g<l.length;g+=1)A(l[g]);s=!1},d(u){fc(l,u),u&&n(e)}}}function Jc(r){let e;const s=r[6].default,t=gt(s,r,r[10],oc),l=t||Hc(r);return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,u){l&&l.m(i,u),e=!0},p(i,u){t&&t.p&&(!e||u&1024)&&$t(t,s,i,i[10],e?bt(s,i[10],u,Rc):vt(i[10]),oc)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function Vc(r){let e,s;return e=new pc({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[Xc],button:[Kc]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&1024&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Wc(r){let e,s,t;return{c(){e=p("a"),s=p("img"),this.h()},l(l){e=m(l,"A",{href:!0,target:!0});var i=d(e);s=m(i,"IMG",{alt:!0,class:!0,src:!0}),i.forEach(n),this.h()},h(){b(s,"alt","Open In Studio Lab"),b(s,"class","!m-0"),ya(s.src,t="https://studiolab.sagemaker.aws/studiolab.svg")||b(s,"src",t),b(e,"href",r[3][0].value),b(e,"target","_blank")},m(l,i){h(l,e,i),o(e,s)},p:Y,i:Y,o:Y,d(l){l&&n(e)}}}function Yc(r){let e,s;return{c(){e=p("img"),this.h()},l(t){e=m(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){b(e,"alt","Open In Studio Lab"),b(e,"class","!m-0"),ya(e.src,s="https://studiolab.sagemaker.aws/studiolab.svg")||b(e,"src",s)},m(t,l){h(t,e,l)},d(t){t&&n(e)}}}function Kc(r){let e;const s=r[6].default,t=gt(s,r,r[10],xu),l=t||Yc();return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,u){l&&l.m(i,u),e=!0},p(i,u){t&&t.p&&(!e||u&1024)&&$t(t,s,i,i[10],e?bt(s,i[10],u,Ic):vt(i[10]),xu)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function nc(r){let e,s;function t(){return r[8](r[12])}return e=new mc({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:r[11],onClick:t,useDeprecatedJS:!1}}),{c(){S(e.$$.fragment)},l(l){N(e.$$.fragment,l)},m(l,i){M(e,l,i),s=!0},p(l,i){r=l},i(l){s||(j(e.$$.fragment,l),s=!0)},o(l){A(e.$$.fragment,l),s=!1},d(l){D(e,l)}}}function Zc(r){let e,s,t=r[3],l=[];for(let u=0;u<t.length;u+=1)l[u]=nc(ec(r,t,u));const i=u=>A(l[u],1,1,()=>{l[u]=null});return{c(){for(let u=0;u<l.length;u+=1)l[u].c();e=Me()},l(u){for(let g=0;g<l.length;g+=1)l[g].l(u);e=Me()},m(u,g){for(let _=0;_<l.length;_+=1)l[_].m(u,g);h(u,e,g),s=!0},p(u,g){if(g&8){t=u[3];let _;for(_=0;_<t.length;_+=1){const v=ec(u,t,_);l[_]?(l[_].p(v,g),j(l[_],1)):(l[_]=nc(v),l[_].c(),j(l[_],1),l[_].m(e.parentNode,e))}for(Pe(),_=t.length;_<l.length;_+=1)i(_);Se()}},i(u){if(!s){for(let g=0;g<t.length;g+=1)j(l[g]);s=!0}},o(u){l=l.filter(Boolean);for(let g=0;g<l.length;g+=1)A(l[g]);s=!1},d(u){fc(l,u),u&&n(e)}}}function Xc(r){let e;const s=r[6].default,t=gt(s,r,r[10],tc),l=t||Zc(r);return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,u){l&&l.m(i,u),e=!0},p(i,u){t&&t.p&&(!e||u&1024)&&$t(t,s,i,i[10],e?bt(s,i[10],u,Oc):vt(i[10]),tc)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function xc(r){let e,s,t,l,i,u,g,_,v,q;const I=[Bc,Uc],F=[];function y(k,T){return k[2].length===1?0:1}s=y(r),t=F[s]=I[s](r);const P=[Wc,Vc],w=[];function C(k,T){return k[3].length===1?0:1}return i=C(r),u=w[i]=P[i](r),{c(){e=p("div"),t.c(),l=z(),u.c(),this.h()},l(k){e=m(k,"DIV",{class:!0});var T=d(e);t.l(T),l=E(T),u.l(T),T.forEach(n),this.h()},h(){b(e,"class",g="flex space-x-1 "+r[0])},m(k,T){h(k,e,T),F[s].m(e,null),o(e,l),w[i].m(e,null),r[9](e),_=!0,v||(q=cs(Fc,"resize",r[4]),v=!0)},p(k,[T]){t.p(k,T),u.p(k,T),(!_||T&1&&g!==(g="flex space-x-1 "+k[0]))&&b(e,"class",g)},i(k){_||(j(t),j(u),_=!0)},o(k){A(t),A(u),_=!1},d(k){k&&n(e),F[s].d(),w[i].d(),r[9](null),v=!1,q()}}}function ic(r){window.open(r)}function ef(r,e,s){let{$$slots:t={},$$scope:l}=e,{options:i=[]}=e,{classNames:u=""}=e,g;const _=i.filter(P=>P.value.includes("colab.research.google.com")),v=i.filter(P=>P.value.includes("studiolab.sagemaker.aws"));function q(){const P=document.querySelector(".prose-doc h1"),w=document.querySelector(".prose-doc h1 > span");if(P&&w){const{width:C}=P.getBoundingClientRect(),{width:k}=w.getBoundingClientRect();let T=0;for(let G=0;G<g.children.length;G++)T+=g.children.item(G).clientWidth;const R=20;C-k<T+R?g.classList.remove("absolute"):g.classList.add("absolute")}}ur(()=>{q()});const I=P=>ic(P),F=P=>ic(P);function y(P){cr[P?"unshift":"push"](()=>{g=P,s(1,g)})}return r.$$set=P=>{"options"in P&&s(5,i=P.options),"classNames"in P&&s(0,u=P.classNames),"$$scope"in P&&s(10,l=P.$$scope)},[u,g,_,v,q,i,t,I,F,y,l]}class tf extends ea{constructor(e){super();ta(this,e,ef,xc,aa,{options:5,classNames:0})}}function af(r){let e,s;return{c(){e=p("p"),s=c(`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non \xE8 presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`)},l(t){e=m(t,"P",{});var l=d(e);s=f(l,`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non \xE8 presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`),l.forEach(n)},m(t,l){h(t,e,l),o(e,s)},d(t){t&&n(e)}}}function lf(r){let e,s,t,l,i,u,g,_;return{c(){e=p("p"),s=c("Per maggiori dettagli legati alla "),t=p("code"),l=c("pipeline()"),i=c(" e ai compiti ad essa associati, fai riferimento alla documentazione "),u=p("a"),g=c("qui"),_=c("."),this.h()},l(v){e=m(v,"P",{});var q=d(e);s=f(q,"Per maggiori dettagli legati alla "),t=m(q,"CODE",{});var I=d(t);l=f(I,"pipeline()"),I.forEach(n),i=f(q," e ai compiti ad essa associati, fai riferimento alla documentazione "),u=m(q,"A",{href:!0});var F=d(u);g=f(F,"qui"),F.forEach(n),_=f(q,"."),q.forEach(n),this.h()},h(){b(u,"href","./main_classes/pipelines")},m(v,q){h(v,e,q),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_)},d(v){v&&n(e)}}}function of(r){let e,s;return e=new H({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p:Y,i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function sf(r){let e,s;return e=new $e({props:{$$slots:{default:[of]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function nf(r){let e,s;return e=new H({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p:Y,i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function rf(r){let e,s;return e=new $e({props:{$$slots:{default:[nf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function uf(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P;return y=new H({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=p("p"),s=c("Usa "),t=p("code"),l=c("AutoModelForSequenceClassification"),i=c(" e "),u=p("code"),g=c("AutoTokenizer"),_=c(" per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=p("code"),q=c("AutoClass"),I=c(" in seguito):"),F=z(),S(y.$$.fragment)},l(w){e=m(w,"P",{});var C=d(e);s=f(C,"Usa "),t=m(C,"CODE",{});var k=d(t);l=f(k,"AutoModelForSequenceClassification"),k.forEach(n),i=f(C," e "),u=m(C,"CODE",{});var T=d(u);g=f(T,"AutoTokenizer"),T.forEach(n),_=f(C," per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=m(C,"CODE",{});var R=d(v);q=f(R,"AutoClass"),R.forEach(n),I=f(C," in seguito):"),C.forEach(n),F=E(w),N(y.$$.fragment,w)},m(w,C){h(w,e,C),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_),o(e,v),o(v,q),o(e,I),h(w,F,C),M(y,w,C),P=!0},p:Y,i(w){P||(j(y.$$.fragment,w),P=!0)},o(w){A(y.$$.fragment,w),P=!1},d(w){w&&n(e),w&&n(F),D(y,w)}}}function cf(r){let e,s;return e=new $e({props:{$$slots:{default:[uf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function ff(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P;return y=new H({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=p("p"),s=c("Usa "),t=p("code"),l=c("TFAutoModelForSequenceClassification"),i=c(" e "),u=p("code"),g=c("AutoTokenizer"),_=c(" per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=p("code"),q=c("TFAutoClass"),I=c(" in seguito):"),F=z(),S(y.$$.fragment)},l(w){e=m(w,"P",{});var C=d(e);s=f(C,"Usa "),t=m(C,"CODE",{});var k=d(t);l=f(k,"TFAutoModelForSequenceClassification"),k.forEach(n),i=f(C," e "),u=m(C,"CODE",{});var T=d(u);g=f(T,"AutoTokenizer"),T.forEach(n),_=f(C," per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=m(C,"CODE",{});var R=d(v);q=f(R,"TFAutoClass"),R.forEach(n),I=f(C," in seguito):"),C.forEach(n),F=E(w),N(y.$$.fragment,w)},m(w,C){h(w,e,C),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_),o(e,v),o(v,q),o(e,I),h(w,F,C),M(y,w,C),P=!0},p:Y,i(w){P||(j(y.$$.fragment,w),P=!0)},o(w){A(y.$$.fragment,w),P=!1},d(w){w&&n(e),w&&n(F),D(y,w)}}}function pf(r){let e,s;return e=new $e({props:{$$slots:{default:[ff]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function mf(r){let e,s;return e=new H({props:{code:`pt_batch = tokenizer(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p:Y,i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function df(r){let e,s;return e=new $e({props:{$$slots:{default:[mf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function _f(r){let e,s;return e=new H({props:{code:`tf_batch = tokenizer(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p:Y,i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function hf(r){let e,s;return e=new $e({props:{$$slots:{default:[_f]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function gf(r){let e,s,t,l,i,u,g,_;return{c(){e=p("p"),s=c("Guarda il "),t=p("a"),l=c("task summary"),i=c(" per sapere quale classe di "),u=p("code"),g=c("AutoModel"),_=c(" utilizzare per quale compito."),this.h()},l(v){e=m(v,"P",{});var q=d(e);s=f(q,"Guarda il "),t=m(q,"A",{href:!0});var I=d(t);l=f(I,"task summary"),I.forEach(n),i=f(q," per sapere quale classe di "),u=m(q,"CODE",{});var F=d(u);g=f(F,"AutoModel"),F.forEach(n),_=f(q," utilizzare per quale compito."),q.forEach(n),this.h()},h(){b(t,"href","./task_summary")},m(v,q){h(v,e,q),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_)},d(v){v&&n(e)}}}function $f(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P,w,C,k,T,R,G,V,U,ae,K,J,te,Z,X,de,se,he,ne,le,ie,ge,L,B,re;return C=new H({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),T=new Ta({props:{$$slots:{default:[gf]},$$scope:{ctx:r}}}),te=new H({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),B=new H({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0041</span>, <span class="hljs-number">0.0037</span>, <span class="hljs-number">0.0203</span>, <span class="hljs-number">0.2005</span>, <span class="hljs-number">0.7713</span>],
        [<span class="hljs-number">0.3766</span>, <span class="hljs-number">0.3292</span>, <span class="hljs-number">0.1832</span>, <span class="hljs-number">0.0558</span>, <span class="hljs-number">0.0552</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){e=p("p"),s=c("\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=p("code"),l=c("AutoModel"),i=c(" come caricheresti un "),u=p("code"),g=c("AutoTokenizer"),_=c(". L\u2019unica differenza \xE8 selezionare l\u2019"),v=p("code"),q=c("AutoModel"),I=c(" corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=p("code"),y=c("AutoModelForSequenceClassification"),P=c(":"),w=z(),S(C.$$.fragment),k=z(),S(T.$$.fragment),R=z(),G=p("p"),V=c("Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo "),U=p("code"),ae=c("**"),K=c(":"),J=z(),S(te.$$.fragment),Z=z(),X=p("p"),de=c("Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),se=p("code"),he=c("logits"),ne=c(". Applica la funzione softmax a "),le=p("code"),ie=c("logits"),ge=c(" per ottenere le probabilit\xE0:"),L=z(),S(B.$$.fragment)},l(O){e=m(O,"P",{});var Q=d(e);s=f(Q,"\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=m(Q,"CODE",{});var ce=d(t);l=f(ce,"AutoModel"),ce.forEach(n),i=f(Q," come caricheresti un "),u=m(Q,"CODE",{});var De=d(u);g=f(De,"AutoTokenizer"),De.forEach(n),_=f(Q,". L\u2019unica differenza \xE8 selezionare l\u2019"),v=m(Q,"CODE",{});var _e=d(v);q=f(_e,"AutoModel"),_e.forEach(n),I=f(Q," corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=m(Q,"CODE",{});var ve=d(F);y=f(ve,"AutoModelForSequenceClassification"),ve.forEach(n),P=f(Q,":"),Q.forEach(n),w=E(O),N(C.$$.fragment,O),k=E(O),N(T.$$.fragment,O),R=E(O),G=m(O,"P",{});var ue=d(G);V=f(ue,"Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo "),U=m(ue,"CODE",{});var Be=d(U);ae=f(Be,"**"),Be.forEach(n),K=f(ue,":"),ue.forEach(n),J=E(O),N(te.$$.fragment,O),Z=E(O),X=m(O,"P",{});var be=d(X);de=f(be,"Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),se=m(be,"CODE",{});var la=d(se);he=f(la,"logits"),la.forEach(n),ne=f(be,". Applica la funzione softmax a "),le=m(be,"CODE",{});var kt=d(le);ie=f(kt,"logits"),kt.forEach(n),ge=f(be," per ottenere le probabilit\xE0:"),be.forEach(n),L=E(O),N(B.$$.fragment,O)},m(O,Q){h(O,e,Q),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_),o(e,v),o(v,q),o(e,I),o(e,F),o(F,y),o(e,P),h(O,w,Q),M(C,O,Q),h(O,k,Q),M(T,O,Q),h(O,R,Q),h(O,G,Q),o(G,V),o(G,U),o(U,ae),o(G,K),h(O,J,Q),M(te,O,Q),h(O,Z,Q),h(O,X,Q),o(X,de),o(X,se),o(se,he),o(X,ne),o(X,le),o(le,ie),o(X,ge),h(O,L,Q),M(B,O,Q),re=!0},p(O,Q){const ce={};Q&2&&(ce.$$scope={dirty:Q,ctx:O}),T.$set(ce)},i(O){re||(j(C.$$.fragment,O),j(T.$$.fragment,O),j(te.$$.fragment,O),j(B.$$.fragment,O),re=!0)},o(O){A(C.$$.fragment,O),A(T.$$.fragment,O),A(te.$$.fragment,O),A(B.$$.fragment,O),re=!1},d(O){O&&n(e),O&&n(w),D(C,O),O&&n(k),D(T,O),O&&n(R),O&&n(G),O&&n(J),D(te,O),O&&n(Z),O&&n(X),O&&n(L),D(B,O)}}}function vf(r){let e,s;return e=new $e({props:{$$slots:{default:[$f]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function bf(r){let e,s,t,l,i,u,g,_;return{c(){e=p("p"),s=c("Guarda il "),t=p("a"),l=c("task summary"),i=c(" per sapere quale classe di "),u=p("code"),g=c("AutoModel"),_=c(" utilizzare per quale compito."),this.h()},l(v){e=m(v,"P",{});var q=d(e);s=f(q,"Guarda il "),t=m(q,"A",{href:!0});var I=d(t);l=f(I,"task summary"),I.forEach(n),i=f(q," per sapere quale classe di "),u=m(q,"CODE",{});var F=d(u);g=f(F,"AutoModel"),F.forEach(n),_=f(q," utilizzare per quale compito."),q.forEach(n),this.h()},h(){b(t,"href","./task_summary")},m(v,q){h(v,e,q),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_)},d(v){v&&n(e)}}}function kf(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P,w,C,k,T,R,G,V,U,ae,K,J,te,Z,X,de,se,he,ne,le,ie,ge;return C=new H({props:{code:`from transformers import TFAutoModelForSequenceClassification

nome_del_modello = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`}}),T=new Ta({props:{$$slots:{default:[bf]},$$scope:{ctx:r}}}),ae=new H({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),ie=new H({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){e=p("p"),s=c("\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=p("code"),l=c("TFAutoModel"),i=c(" come caricheresti un "),u=p("code"),g=c("AutoTokenizer"),_=c(". L\u2019unica differenza \xE8 selezionare il "),v=p("code"),q=c("TFAutoModel"),I=c(" corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=p("code"),y=c("TFAutoModelForSequenceClassification"),P=c(":"),w=z(),S(C.$$.fragment),k=z(),S(T.$$.fragment),R=z(),G=p("p"),V=c("Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:"),U=z(),S(ae.$$.fragment),K=z(),J=p("p"),te=c("Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),Z=p("code"),X=c("logits"),de=c(". Applica la funzione softmax a "),se=p("code"),he=c("logits"),ne=c(" per ottenere le probabilit\xE0:"),le=z(),S(ie.$$.fragment)},l(L){e=m(L,"P",{});var B=d(e);s=f(B,"\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=m(B,"CODE",{});var re=d(t);l=f(re,"TFAutoModel"),re.forEach(n),i=f(B," come caricheresti un "),u=m(B,"CODE",{});var O=d(u);g=f(O,"AutoTokenizer"),O.forEach(n),_=f(B,". L\u2019unica differenza \xE8 selezionare il "),v=m(B,"CODE",{});var Q=d(v);q=f(Q,"TFAutoModel"),Q.forEach(n),I=f(B," corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=m(B,"CODE",{});var ce=d(F);y=f(ce,"TFAutoModelForSequenceClassification"),ce.forEach(n),P=f(B,":"),B.forEach(n),w=E(L),N(C.$$.fragment,L),k=E(L),N(T.$$.fragment,L),R=E(L),G=m(L,"P",{});var De=d(G);V=f(De,"Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:"),De.forEach(n),U=E(L),N(ae.$$.fragment,L),K=E(L),J=m(L,"P",{});var _e=d(J);te=f(_e,"Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),Z=m(_e,"CODE",{});var ve=d(Z);X=f(ve,"logits"),ve.forEach(n),de=f(_e,". Applica la funzione softmax a "),se=m(_e,"CODE",{});var ue=d(se);he=f(ue,"logits"),ue.forEach(n),ne=f(_e," per ottenere le probabilit\xE0:"),_e.forEach(n),le=E(L),N(ie.$$.fragment,L)},m(L,B){h(L,e,B),o(e,s),o(e,t),o(t,l),o(e,i),o(e,u),o(u,g),o(e,_),o(e,v),o(v,q),o(e,I),o(e,F),o(F,y),o(e,P),h(L,w,B),M(C,L,B),h(L,k,B),M(T,L,B),h(L,R,B),h(L,G,B),o(G,V),h(L,U,B),M(ae,L,B),h(L,K,B),h(L,J,B),o(J,te),o(J,Z),o(Z,X),o(J,de),o(J,se),o(se,he),o(J,ne),h(L,le,B),M(ie,L,B),ge=!0},p(L,B){const re={};B&2&&(re.$$scope={dirty:B,ctx:L}),T.$set(re)},i(L){ge||(j(C.$$.fragment,L),j(T.$$.fragment,L),j(ae.$$.fragment,L),j(ie.$$.fragment,L),ge=!0)},o(L){A(C.$$.fragment,L),A(T.$$.fragment,L),A(ae.$$.fragment,L),A(ie.$$.fragment,L),ge=!1},d(L){L&&n(e),L&&n(w),D(C,L),L&&n(k),D(T,L),L&&n(R),L&&n(G),L&&n(U),D(ae,L),L&&n(K),L&&n(J),L&&n(le),D(ie,L)}}}function wf(r){let e,s;return e=new $e({props:{$$slots:{default:[kf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function zf(r){let e,s,t,l,i;return{c(){e=p("p"),s=c("Tutti i modelli di \u{1F917} Transformers (PyTorch e TensorFlow) restituiscono i tensori "),t=p("em"),l=c("prima"),i=c(` della funzione finale
di attivazione (come la softmax) perch\xE9 la funzione di attivazione finale viene spesso unita a quella di perdita.`)},l(u){e=m(u,"P",{});var g=d(e);s=f(g,"Tutti i modelli di \u{1F917} Transformers (PyTorch e TensorFlow) restituiscono i tensori "),t=m(g,"EM",{});var _=d(t);l=f(_,"prima"),_.forEach(n),i=f(g,` della funzione finale
di attivazione (come la softmax) perch\xE9 la funzione di attivazione finale viene spesso unita a quella di perdita.`),g.forEach(n)},m(u,g){h(u,e,g),o(e,s),o(e,t),o(t,l),o(e,i)},d(u){u&&n(e)}}}function Ef(r){let e,s,t,l,i;return{c(){e=p("p"),s=c(`Gli output del modello di \u{1F917} Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all\u2019interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono `),t=p("code"),l=c("None"),i=c(" vengono ignorati.")},l(u){e=m(u,"P",{});var g=d(e);s=f(g,`Gli output del modello di \u{1F917} Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all\u2019interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono `),t=m(g,"CODE",{});var _=d(t);l=f(_,"None"),_.forEach(n),i=f(g," vengono ignorati."),g.forEach(n)},m(u,g){h(u,e,g),o(e,s),o(e,t),o(t,l),o(e,i)},d(u){u&&n(e)}}}function jf(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P,w,C;return g=new H({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),w=new H({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){e=p("p"),s=c("Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=p("code"),l=c("PreTrainedModel.save_pretrained()"),i=c(":"),u=z(),S(g.$$.fragment),_=z(),v=p("p"),q=c("Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=p("code"),F=c("PreTrainedModel.from_pretrained()"),y=c(":"),P=z(),S(w.$$.fragment)},l(k){e=m(k,"P",{});var T=d(e);s=f(T,"Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=m(T,"CODE",{});var R=d(t);l=f(R,"PreTrainedModel.save_pretrained()"),R.forEach(n),i=f(T,":"),T.forEach(n),u=E(k),N(g.$$.fragment,k),_=E(k),v=m(k,"P",{});var G=d(v);q=f(G,"Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=m(G,"CODE",{});var V=d(I);F=f(V,"PreTrainedModel.from_pretrained()"),V.forEach(n),y=f(G,":"),G.forEach(n),P=E(k),N(w.$$.fragment,k)},m(k,T){h(k,e,T),o(e,s),o(e,t),o(t,l),o(e,i),h(k,u,T),M(g,k,T),h(k,_,T),h(k,v,T),o(v,q),o(v,I),o(I,F),o(v,y),h(k,P,T),M(w,k,T),C=!0},p:Y,i(k){C||(j(g.$$.fragment,k),j(w.$$.fragment,k),C=!0)},o(k){A(g.$$.fragment,k),A(w.$$.fragment,k),C=!1},d(k){k&&n(e),k&&n(u),D(g,k),k&&n(_),k&&n(v),k&&n(P),D(w,k)}}}function Af(r){let e,s;return e=new $e({props:{$$slots:{default:[jf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Cf(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P,w,C;return g=new H({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),w=new H({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){e=p("p"),s=c("Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=p("code"),l=c("TFPreTrainedModel.save_pretrained()"),i=c(":"),u=z(),S(g.$$.fragment),_=z(),v=p("p"),q=c("Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=p("code"),F=c("TFPreTrainedModel.from_pretrained()"),y=c(":"),P=z(),S(w.$$.fragment)},l(k){e=m(k,"P",{});var T=d(e);s=f(T,"Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=m(T,"CODE",{});var R=d(t);l=f(R,"TFPreTrainedModel.save_pretrained()"),R.forEach(n),i=f(T,":"),T.forEach(n),u=E(k),N(g.$$.fragment,k),_=E(k),v=m(k,"P",{});var G=d(v);q=f(G,"Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=m(G,"CODE",{});var V=d(I);F=f(V,"TFPreTrainedModel.from_pretrained()"),V.forEach(n),y=f(G,":"),G.forEach(n),P=E(k),N(w.$$.fragment,k)},m(k,T){h(k,e,T),o(e,s),o(e,t),o(t,l),o(e,i),h(k,u,T),M(g,k,T),h(k,_,T),h(k,v,T),o(v,q),o(v,I),o(I,F),o(v,y),h(k,P,T),M(w,k,T),C=!0},p:Y,i(k){C||(j(g.$$.fragment,k),j(w.$$.fragment,k),C=!0)},o(k){A(g.$$.fragment,k),A(w.$$.fragment,k),C=!1},d(k){k&&n(e),k&&n(u),D(g,k),k&&n(_),k&&n(v),k&&n(P),D(w,k)}}}function qf(r){let e,s;return e=new $e({props:{$$slots:{default:[Cf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Tf(r){let e,s;return e=new H({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p:Y,i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function yf(r){let e,s;return e=new $e({props:{$$slots:{default:[Tf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Pf(r){let e,s;return e=new H({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p:Y,i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Sf(r){let e,s;return e=new $e({props:{$$slots:{default:[Pf]},$$scope:{ctx:r}}}),{c(){S(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),s=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){s||(j(e.$$.fragment,t),s=!0)},o(t){A(e.$$.fragment,t),s=!1},d(t){D(e,t)}}}function Mf(r){let e,s,t,l,i,u,g,_,v,q,I,F,y,P,w,C,k,T,R,G,V,U,ae,K,J,te,Z,X,de,se,he,ne,le,ie,ge,L,B,re,O,Q,ce,De,_e,ve,ue,Be,be,la,kt,W,Pa,fs,ps,Sa,ms,ds,Ma,_s,hs,Da,gs,$s,Na,vs,bs,Fa,ks,ws,Ia,zs,Es,Oa,js,Ll,wt,La,As,Cs,Rl,ke,Ra,qs,Ts,Ua,ys,Ps,Ba,Ss,Ul,zt,Ga,Ms,Ds,Bl,Ge,Qa,Ns,Fs,Ha,Is,Gl,Qe,Ql,Ne,He,Ja,Et,Os,Va,Ls,Hl,Je,Rs,Wa,Us,Bs,Jl,oa,Gs,Vl,Ve,Wl,We,Qs,Ya,Hs,Js,Yl,jt,Kl,we,Vs,At,Ws,Ys,Ka,Ks,Zs,Zl,Ct,Xl,Ye,Xs,Za,xs,en,xl,qt,eo,ze,tn,Xa,an,ln,Tt,on,sn,to,yt,ao,Ke,nn,xa,rn,un,lo,Pt,oo,Ee,cn,St,fn,pn,Mt,mn,dn,so,Dt,no,Ze,_n,el,hn,gn,io,Nt,ro,sa,$n,uo,Ft,co,Xe,vn,na,bn,kn,fo,Fe,xe,tl,It,wn,al,zn,po,fe,En,ll,jn,An,Ot,Cn,qn,ol,Tn,yn,Lt,Pn,Sn,mo,Rt,_o,et,ho,je,Mn,sl,Dn,Nn,nl,Fn,In,go,Ut,$o,Ae,On,ia,Ln,Rn,ra,Un,Bn,vo,Ie,tt,il,Bt,Gn,rl,Qn,bo,Gt,ko,x,Hn,ul,Jn,Vn,cl,Wn,Yn,fl,Kn,Zn,ua,Xn,xn,pl,ei,ti,ml,ai,li,wo,Ce,oi,dl,si,ni,_l,ii,ri,zo,Oe,at,hl,Qt,ui,gl,ci,Eo,qe,fi,$l,pi,mi,ca,di,_i,jo,lt,hi,vl,gi,$i,Ao,Ht,Co,ot,vi,bl,bi,ki,qo,fa,wi,To,Jt,yo,pa,zi,Po,st,ma,da,Ei,ji,Ai,_a,ha,Ci,qi,So,nt,Ti,kl,yi,Pi,Mo,it,Do,rt,Si,ga,Mi,Di,No,Le,ut,wl,Vt,Ni,zl,Fi,Fo,ct,Io,ft,Oo,ee,Ii,Wt,El,Oi,Li,Yt,jl,Ri,Ui,Al,Bi,Gi,Cl,Qi,Hi,Kt,Ji,Vi,$a,Wi,Yi,Lo,pt,Ro,Re,mt,ql,Zt,Ki,Tl,Zi,Uo,dt,Bo,Te,Xi,yl,xi,er,Pl,tr,ar,Go,_t,Qo;return u=new ht({}),I=new tf({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"}]}}),U=new Ta({props:{$$slots:{default:[af]},$$scope:{ctx:r}}}),Z=new ht({}),B=new Ju({props:{id:"tiZFewofSLM"}}),Qe=new Ta({props:{$$slots:{default:[lf]},$$scope:{ctx:r}}}),Et=new ht({}),Ve=new qa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[rf],pytorch:[sf]},$$scope:{ctx:r}}}),jt=new H({props:{code:`from transformers import pipeline

classificatore = pipeline("sentiment-analysis", model="MilaNLProc/feel-it-italian-sentiment")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=<span class="hljs-string">&quot;MilaNLProc/feel-it-italian-sentiment&quot;</span>)`}}),Ct=new H({props:{code:'classificatore("Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;positive&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9997</span>}]`}}),qt=new H({props:{code:`risultati = classificatore(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."]
)
for risultato in risultati:
    print(f"etichetta: {risultato['label']}, con punteggio: {round(risultato['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultati = classificatore(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>]
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> risultato <span class="hljs-keyword">in</span> risultati:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;etichetta: <span class="hljs-subst">{risultato[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, con punteggio: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(risultato[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
etichetta: positive, con punteggio: <span class="hljs-number">0.9998</span>
etichetta: negative, con punteggio: <span class="hljs-number">0.9998</span>`}}),yt=new H({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),Pt=new H({props:{code:`import torch
from transformers import pipeline

riconoscitore_vocale = pipeline(
    "automatic-speech-recognition", model="radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>riconoscitore_vocale = pipeline(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram&quot;</span>
<span class="hljs-meta">... </span>)`}}),Dt=new H({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="it-IT", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;it-IT&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Nt=new H({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))'}}),Ft=new H({props:{code:`risultato = riconoscitore_vocale(dataset[:4]["audio"])
print([d["text"] for d in risultato])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultato = riconoscitore_vocale(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> risultato])
[<span class="hljs-string">&#x27;dovrei caricare dei soldi sul mio conto corrente&#x27;</span>, <span class="hljs-string">&#x27;buongiorno e senza vorrei depositare denaro sul mio conto corrente come devo fare per cortesia&#x27;</span>, <span class="hljs-string">&#x27;s\xEC salve vorrei depositare del denaro sul mio conto&#x27;</span>, <span class="hljs-string">&#x27;e buon pomeriggio vorrei depositare dei soldi sul mio conto bancario volleo sapere come posso fare se e posso farlo online ed un altro conto o andandoo tramite bancomut&#x27;</span>]`}}),It=new ht({}),Rt=new H({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),et=new qa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pf],pytorch:[cf]},$$scope:{ctx:r}}}),Ut=new H({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Bt=new ht({}),Gt=new Ju({props:{id:"AhChOFRegn4"}}),Qt=new ht({}),Ht=new H({props:{code:`from transformers import AutoTokenizer

nome_del_modello = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`}}),Jt=new H({props:{code:`encoding = tokenizer("Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">56821</span>, <span class="hljs-number">10132</span>, <span class="hljs-number">14407</span>, <span class="hljs-number">13019</span>, <span class="hljs-number">13007</span>, <span class="hljs-number">10120</span>, <span class="hljs-number">47201</span>, <span class="hljs-number">10330</span>, <span class="hljs-number">10106</span>, <span class="hljs-number">91686</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),it=new qa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[hf],pytorch:[df]},$$scope:{ctx:r}}}),Vt=new ht({}),ct=new qa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[wf],pytorch:[vf]},$$scope:{ctx:r}}}),ft=new Ta({props:{$$slots:{default:[zf]},$$scope:{ctx:r}}}),pt=new Ta({props:{$$slots:{default:[Ef]},$$scope:{ctx:r}}}),Zt=new ht({}),dt=new qa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[qf],pytorch:[Af]},$$scope:{ctx:r}}}),_t=new qa({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Sf],pytorch:[yf]},$$scope:{ctx:r}}}),{c(){e=p("meta"),s=z(),t=p("h1"),l=p("a"),i=p("span"),S(u.$$.fragment),g=z(),_=p("span"),v=c("Quick tour"),q=z(),S(I.$$.fragment),F=z(),y=p("p"),P=c("Entra in azione con \u{1F917} Transformers! Inizia utilizzando "),w=p("code"),C=c("pipeline()"),k=c(" per un\u2019inferenza veloce, carica un modello pre-allenato e un tokenizer con una "),T=p("a"),R=c("AutoClass"),G=c(" per risolvere i tuoi compiti legati a testo, immagini o audio."),V=z(),S(U.$$.fragment),ae=z(),K=p("h2"),J=p("a"),te=p("span"),S(Z.$$.fragment),X=z(),de=p("span"),se=c("Pipeline"),he=z(),ne=p("p"),le=p("code"),ie=c("pipeline()"),ge=c(" \xE8 il modo pi\xF9 semplice per utilizzare un modello pre-allenato per un dato compito."),L=z(),S(B.$$.fragment),re=z(),O=p("p"),Q=c("La "),ce=p("code"),De=c("pipeline()"),_e=c(" supporta molti compiti comuni:"),ve=z(),ue=p("p"),Be=p("strong"),be=c("Testo"),la=c(":"),kt=z(),W=p("ul"),Pa=p("li"),fs=c("Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarit\xE0 di un testo dato."),ps=z(),Sa=p("li"),ms=c("Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input."),ds=z(),Ma=p("li"),_s=c("Riconoscimento di Entit\xE0 (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l\u2019entit\xE0 che questa rappresenta (persona, data, luogo, ecc.)."),hs=z(),Da=p("li"),gs=c("Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda."),$s=z(),Na=p("li"),vs=c("Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate."),bs=z(),Fa=p("li"),ks=c("Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento."),ws=z(),Ia=p("li"),zs=c("Traduzione (Translation, in inglese): traduce un testo in un\u2019altra lingua."),Es=z(),Oa=p("li"),js=c("Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo."),Ll=z(),wt=p("p"),La=p("strong"),As=c("Immagini"),Cs=c(":"),Rl=z(),ke=p("ul"),Ra=p("li"),qs=c("Classificazione di Immagini (Image Classification, in inglese): classifica un\u2019immagine."),Ts=z(),Ua=p("li"),ys=c("Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un\u2019immagine."),Ps=z(),Ba=p("li"),Ss=c("Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all\u2019interno di un\u2019immagine."),Ul=z(),zt=p("p"),Ga=p("strong"),Ms=c("Audio"),Ds=c(":"),Bl=z(),Ge=p("ul"),Qa=p("li"),Ns=c("Classificazione di Audio (Audio Classification, in inglese): assegna un\u2019etichetta ad un segmento di audio dato."),Fs=z(),Ha=p("li"),Is=c("Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo."),Gl=z(),S(Qe.$$.fragment),Ql=z(),Ne=p("h3"),He=p("a"),Ja=p("span"),S(Et.$$.fragment),Os=z(),Va=p("span"),Ls=c("Utilizzo della Pipeline"),Hl=z(),Je=p("p"),Rs=c("Nel seguente esempio, utilizzerai la "),Wa=p("code"),Us=c("pipeline()"),Bs=c(" per l\u2019analisi del sentimento."),Jl=z(),oa=p("p"),Gs=c("Installa le seguenti dipendenze se non lo hai gi\xE0 fatto:"),Vl=z(),S(Ve.$$.fragment),Wl=z(),We=p("p"),Qs=c("Importa "),Ya=p("code"),Hs=c("pipeline()"),Js=c(" e specifica il compito che vuoi completare:"),Yl=z(),S(jt.$$.fragment),Kl=z(),we=p("p"),Vs=c("La pipeline scarica e salva il "),At=p("a"),Ws=c("modello pre-allenato"),Ys=c(" e il tokenizer per l\u2019analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il "),Ka=p("code"),Ks=c("classifier"),Zs=c(" sul tuo testo obiettivo:"),Zl=z(),S(Ct.$$.fragment),Xl=z(),Ye=p("p"),Xs=c("Per pi\xF9 di una frase, passa una lista di frasi alla "),Za=p("code"),xs=c("pipeline()"),en=c(" la quale restituir\xE0 una lista di dizionari:"),xl=z(),S(qt.$$.fragment),eo=z(),ze=p("p"),tn=c("La "),Xa=p("code"),an=c("pipeline()"),ln=c(" pu\xF2 anche iterare su un dataset intero. Inizia installando la libreria "),Tt=p("a"),on=c("\u{1F917} Datasets"),sn=c(":"),to=z(),S(yt.$$.fragment),ao=z(),Ke=p("p"),nn=c("Crea una "),xa=p("code"),rn=c("pipeline()"),un=c(" con il compito che vuoi risolvere e con il modello che vuoi utilizzare."),lo=z(),S(Pt.$$.fragment),oo=z(),Ee=p("p"),cn=c("Poi, carica un dataset (vedi \u{1F917} Datasets "),St=p("a"),fn=c("Quick Start"),pn=c(" per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset "),Mt=p("a"),mn=c("MInDS-14"),dn=c(":"),so=z(),S(Dt.$$.fragment),no=z(),Ze=p("p"),_n=c("Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui \xE8 stato addestrato "),el=p("code"),hn=c("radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"),gn=c("."),io=z(),S(Nt.$$.fragment),ro=z(),sa=p("p"),$n=c(`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna \u201Caudio\u201D.
Estraiamo i vettori delle forme d\u2019onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`),uo=z(),S(Ft.$$.fragment),co=z(),Xe=p("p"),vn=c("Per un dataset pi\xF9 grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la "),na=p("a"),bn=c("documentazione della pipeline"),kn=c(" per maggiori informazioni."),fo=z(),Fe=p("h3"),xe=p("a"),tl=p("span"),S(It.$$.fragment),wn=z(),al=p("span"),zn=c("Utilizzare un altro modello e tokenizer nella pipeline"),po=z(),fe=p("p"),En=c("La "),ll=p("code"),jn=c("pipeline()"),An=c(" pu\xF2 ospitare qualsiasi modello del "),Ot=p("a"),Cn=c("Model Hub"),qn=c(", rendendo semplice l\u2019adattamento della "),ol=p("code"),Tn=c("pipeline()"),yn=c(" per altri casi d\u2019uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua "),Lt=p("a"),Pn=c("BERT model"),Sn=c(" fine-tuned per l\u2019analisi del sentimento. Ottimo, utilizziamo questo modello!"),mo=z(),S(Rt.$$.fragment),_o=z(),S(et.$$.fragment),ho=z(),je=p("p"),Mn=c("Poi puoi specificare il modello e il tokenizer nella "),sl=p("code"),Dn=c("pipeline()"),Nn=c(", e applicare il "),nl=p("code"),Fn=c("classifier"),In=c(" sul tuo testo obiettivo:"),go=z(),S(Ut.$$.fragment),$o=z(),Ae=p("p"),On=c("Se non riesci a trovare un modello per il tuo caso d\u2019uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un\u2019occhiata al nostro tutorial "),ia=p("a"),Ln=c("fine-tuning tutorial"),Rn=c(" per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial "),ra=p("a"),Un=c("qui"),Bn=c(") con la comunit\xE0 sul Model Hub per democratizzare l\u2019NLP! \u{1F917}"),vo=z(),Ie=p("h2"),tt=p("a"),il=p("span"),S(Bt.$$.fragment),Gn=z(),rl=p("span"),Qn=c("AutoClass"),bo=z(),S(Gt.$$.fragment),ko=z(),x=p("p"),Hn=c("Al suo interno, le classi "),ul=p("code"),Jn=c("AutoModelForSequenceClassification"),Vn=c(" e "),cl=p("code"),Wn=c("AutoTokenizer"),Yn=c(" lavorano assieme per dare potere alla "),fl=p("code"),Kn=c("pipeline()"),Zn=c(". Una "),ua=p("a"),Xn=c("AutoClass"),xn=c(" \xE8 una scorciatoia che automaticamente recupera l\u2019architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la "),pl=p("code"),ei=c("AutoClass"),ti=c(" appropriata per il tuo compito e il suo tokenizer associato con "),ml=p("code"),ai=c("AutoTokenizer"),li=c("."),wo=z(),Ce=p("p"),oi=c("Ritorniamo al nostro esempio e vediamo come puoi utilizzare la "),dl=p("code"),si=c("AutoClass"),ni=c(" per replicare i risultati della "),_l=p("code"),ii=c("pipeline()"),ri=c("."),zo=z(),Oe=p("h3"),at=p("a"),hl=p("span"),S(Qt.$$.fragment),ui=z(),gl=p("span"),ci=c("AutoTokenizer"),Eo=z(),qe=p("p"),fi=c("Un tokenizer \xE8 responsabile dell\u2019elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer divider\xE0 il testo in parole chiamate "),$l=p("em"),pi=c("token"),mi=c(". Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di pi\xF9 sulla tokenizzazione "),ca=p("a"),di=c("qui"),_i=c("). La cosa pi\xF9 importante da ricordare comunque \xE8 che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello \xE8 stato pre-allenato."),jo=z(),lt=p("p"),hi=c("Carica un tokenizer con "),vl=p("code"),gi=c("AutoTokenizer"),$i=c(":"),Ao=z(),S(Ht.$$.fragment),Co=z(),ot=p("p"),vi=c("Dopodich\xE9, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo \xE8 conosciuto come il "),bl=p("em"),bi=c("vocabolario"),ki=c(" del modello."),qo=z(),fa=p("p"),wi=c("Passa il tuo testo al tokenizer:"),To=z(),S(Jt.$$.fragment),yo=z(),pa=p("p"),zi=c("Il tokenizer restituir\xE0 un dizionario contenente:"),Po=z(),st=p("ul"),ma=p("li"),da=p("a"),Ei=c("input_ids"),ji=c(": rappresentazioni numeriche dei tuoi token."),Ai=z(),_a=p("li"),ha=p("a"),Ci=c("attention_mask"),qi=c(": indica quali token devono essere presi in considerazione."),So=z(),nt=p("p"),Ti=c("Come con la "),kl=p("code"),yi=c("pipeline()"),Pi=c(", il tokenizer accetter\xE0 una lista di input. In pi\xF9, il tokenizer pu\xF2 anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:"),Mo=z(),S(it.$$.fragment),Do=z(),rt=p("p"),Si=c("Leggi il tutorial sul "),ga=p("a"),Mi=c("preproccesing"),Di=c(" per maggiori dettagli sulla tokenizzazione."),No=z(),Le=p("h3"),ut=p("a"),wl=p("span"),S(Vt.$$.fragment),Ni=z(),zl=p("span"),Fi=c("AutoModel"),Fo=z(),S(ct.$$.fragment),Io=z(),S(ft.$$.fragment),Oo=z(),ee=p("p"),Ii=c("I modelli sono "),Wt=p("a"),El=p("code"),Oi=c("torch.nn.Module"),Li=c(" o "),Yt=p("a"),jl=p("code"),Ri=c("tf.keras.Model"),Ui=c(" standard cos\xEC puoi utilizzarli all\u2019interno del tuo training loop usuale. Tuttavia, per rendere le cose pi\xF9 semplici, \u{1F917} Transformers fornisce una classe "),Al=p("code"),Bi=c("Trainer"),Gi=c(" per PyTorch che aggiunge delle funzionalit\xE0 per l\u2019allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo "),Cl=p("code"),Qi=c("fit"),Hi=c(" di "),Kt=p("a"),Ji=c("Keras"),Vi=c(". Fai riferimento al "),$a=p("a"),Wi=c("tutorial per il training"),Yi=c(" per maggiori dettagli."),Lo=z(),S(pt.$$.fragment),Ro=z(),Re=p("h3"),mt=p("a"),ql=p("span"),S(Zt.$$.fragment),Ki=z(),Tl=p("span"),Zi=c("Salva un modello"),Uo=z(),S(dt.$$.fragment),Bo=z(),Te=p("p"),Xi=c("Una caratteristica particolarmente interessante di \u{1F917} Transformers \xE8 la sua abilit\xE0 di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri "),yl=p("code"),xi=c("from_pt"),er=c(" o "),Pl=p("code"),tr=c("from_tf"),ar=c(" possono convertire un modello da un framework all\u2019altro:"),Go=z(),S(_t.$$.fragment),this.h()},l(a){const $=hc('[data-svelte="svelte-1phssyn"]',document.head);e=m($,"META",{name:!0,content:!0}),$.forEach(n),s=E(a),t=m(a,"H1",{class:!0});var Xt=d(t);l=m(Xt,"A",{id:!0,class:!0,href:!0});var Sl=d(l);i=m(Sl,"SPAN",{});var Ml=d(i);N(u.$$.fragment,Ml),Ml.forEach(n),Sl.forEach(n),g=E(Xt),_=m(Xt,"SPAN",{});var Dl=d(_);v=f(Dl,"Quick tour"),Dl.forEach(n),Xt.forEach(n),q=E(a),N(I.$$.fragment,a),F=E(a),y=m(a,"P",{});var Ue=d(y);P=f(Ue,"Entra in azione con \u{1F917} Transformers! Inizia utilizzando "),w=m(Ue,"CODE",{});var Nl=d(w);C=f(Nl,"pipeline()"),Nl.forEach(n),k=f(Ue," per un\u2019inferenza veloce, carica un modello pre-allenato e un tokenizer con una "),T=m(Ue,"A",{href:!0});var Fl=d(T);R=f(Fl,"AutoClass"),Fl.forEach(n),G=f(Ue," per risolvere i tuoi compiti legati a testo, immagini o audio."),Ue.forEach(n),V=E(a),N(U.$$.fragment,a),ae=E(a),K=m(a,"H2",{class:!0});var xt=d(K);J=m(xt,"A",{id:!0,class:!0,href:!0});var Il=d(J);te=m(Il,"SPAN",{});var Ol=d(te);N(Z.$$.fragment,Ol),Ol.forEach(n),Il.forEach(n),X=E(xt),de=m(xt,"SPAN",{});var fr=d(de);se=f(fr,"Pipeline"),fr.forEach(n),xt.forEach(n),he=E(a),ne=m(a,"P",{});var lr=d(ne);le=m(lr,"CODE",{});var pr=d(le);ie=f(pr,"pipeline()"),pr.forEach(n),ge=f(lr," \xE8 il modo pi\xF9 semplice per utilizzare un modello pre-allenato per un dato compito."),lr.forEach(n),L=E(a),N(B.$$.fragment,a),re=E(a),O=m(a,"P",{});var Ho=d(O);Q=f(Ho,"La "),ce=m(Ho,"CODE",{});var mr=d(ce);De=f(mr,"pipeline()"),mr.forEach(n),_e=f(Ho," supporta molti compiti comuni:"),Ho.forEach(n),ve=E(a),ue=m(a,"P",{});var or=d(ue);Be=m(or,"STRONG",{});var dr=d(Be);be=f(dr,"Testo"),dr.forEach(n),la=f(or,":"),or.forEach(n),kt=E(a),W=m(a,"UL",{});var oe=d(W);Pa=m(oe,"LI",{});var _r=d(Pa);fs=f(_r,"Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarit\xE0 di un testo dato."),_r.forEach(n),ps=E(oe),Sa=m(oe,"LI",{});var hr=d(Sa);ms=f(hr,"Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input."),hr.forEach(n),ds=E(oe),Ma=m(oe,"LI",{});var gr=d(Ma);_s=f(gr,"Riconoscimento di Entit\xE0 (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l\u2019entit\xE0 che questa rappresenta (persona, data, luogo, ecc.)."),gr.forEach(n),hs=E(oe),Da=m(oe,"LI",{});var $r=d(Da);gs=f($r,"Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda."),$r.forEach(n),$s=E(oe),Na=m(oe,"LI",{});var vr=d(Na);vs=f(vr,"Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate."),vr.forEach(n),bs=E(oe),Fa=m(oe,"LI",{});var br=d(Fa);ks=f(br,"Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento."),br.forEach(n),ws=E(oe),Ia=m(oe,"LI",{});var kr=d(Ia);zs=f(kr,"Traduzione (Translation, in inglese): traduce un testo in un\u2019altra lingua."),kr.forEach(n),Es=E(oe),Oa=m(oe,"LI",{});var wr=d(Oa);js=f(wr,"Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo."),wr.forEach(n),oe.forEach(n),Ll=E(a),wt=m(a,"P",{});var sr=d(wt);La=m(sr,"STRONG",{});var zr=d(La);As=f(zr,"Immagini"),zr.forEach(n),Cs=f(sr,":"),sr.forEach(n),Rl=E(a),ke=m(a,"UL",{});var va=d(ke);Ra=m(va,"LI",{});var Er=d(Ra);qs=f(Er,"Classificazione di Immagini (Image Classification, in inglese): classifica un\u2019immagine."),Er.forEach(n),Ts=E(va),Ua=m(va,"LI",{});var jr=d(Ua);ys=f(jr,"Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un\u2019immagine."),jr.forEach(n),Ps=E(va),Ba=m(va,"LI",{});var Ar=d(Ba);Ss=f(Ar,"Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all\u2019interno di un\u2019immagine."),Ar.forEach(n),va.forEach(n),Ul=E(a),zt=m(a,"P",{});var nr=d(zt);Ga=m(nr,"STRONG",{});var Cr=d(Ga);Ms=f(Cr,"Audio"),Cr.forEach(n),Ds=f(nr,":"),nr.forEach(n),Bl=E(a),Ge=m(a,"UL",{});var Jo=d(Ge);Qa=m(Jo,"LI",{});var qr=d(Qa);Ns=f(qr,"Classificazione di Audio (Audio Classification, in inglese): assegna un\u2019etichetta ad un segmento di audio dato."),qr.forEach(n),Fs=E(Jo),Ha=m(Jo,"LI",{});var Tr=d(Ha);Is=f(Tr,"Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo."),Tr.forEach(n),Jo.forEach(n),Gl=E(a),N(Qe.$$.fragment,a),Ql=E(a),Ne=m(a,"H3",{class:!0});var Vo=d(Ne);He=m(Vo,"A",{id:!0,class:!0,href:!0});var yr=d(He);Ja=m(yr,"SPAN",{});var Pr=d(Ja);N(Et.$$.fragment,Pr),Pr.forEach(n),yr.forEach(n),Os=E(Vo),Va=m(Vo,"SPAN",{});var Sr=d(Va);Ls=f(Sr,"Utilizzo della Pipeline"),Sr.forEach(n),Vo.forEach(n),Hl=E(a),Je=m(a,"P",{});var Wo=d(Je);Rs=f(Wo,"Nel seguente esempio, utilizzerai la "),Wa=m(Wo,"CODE",{});var Mr=d(Wa);Us=f(Mr,"pipeline()"),Mr.forEach(n),Bs=f(Wo," per l\u2019analisi del sentimento."),Wo.forEach(n),Jl=E(a),oa=m(a,"P",{});var Dr=d(oa);Gs=f(Dr,"Installa le seguenti dipendenze se non lo hai gi\xE0 fatto:"),Dr.forEach(n),Vl=E(a),N(Ve.$$.fragment,a),Wl=E(a),We=m(a,"P",{});var Yo=d(We);Qs=f(Yo,"Importa "),Ya=m(Yo,"CODE",{});var Nr=d(Ya);Hs=f(Nr,"pipeline()"),Nr.forEach(n),Js=f(Yo," e specifica il compito che vuoi completare:"),Yo.forEach(n),Yl=E(a),N(jt.$$.fragment,a),Kl=E(a),we=m(a,"P",{});var ba=d(we);Vs=f(ba,"La pipeline scarica e salva il "),At=m(ba,"A",{href:!0,rel:!0});var Fr=d(At);Ws=f(Fr,"modello pre-allenato"),Fr.forEach(n),Ys=f(ba," e il tokenizer per l\u2019analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il "),Ka=m(ba,"CODE",{});var Ir=d(Ka);Ks=f(Ir,"classifier"),Ir.forEach(n),Zs=f(ba," sul tuo testo obiettivo:"),ba.forEach(n),Zl=E(a),N(Ct.$$.fragment,a),Xl=E(a),Ye=m(a,"P",{});var Ko=d(Ye);Xs=f(Ko,"Per pi\xF9 di una frase, passa una lista di frasi alla "),Za=m(Ko,"CODE",{});var Or=d(Za);xs=f(Or,"pipeline()"),Or.forEach(n),en=f(Ko," la quale restituir\xE0 una lista di dizionari:"),Ko.forEach(n),xl=E(a),N(qt.$$.fragment,a),eo=E(a),ze=m(a,"P",{});var ka=d(ze);tn=f(ka,"La "),Xa=m(ka,"CODE",{});var Lr=d(Xa);an=f(Lr,"pipeline()"),Lr.forEach(n),ln=f(ka," pu\xF2 anche iterare su un dataset intero. Inizia installando la libreria "),Tt=m(ka,"A",{href:!0,rel:!0});var Rr=d(Tt);on=f(Rr,"\u{1F917} Datasets"),Rr.forEach(n),sn=f(ka,":"),ka.forEach(n),to=E(a),N(yt.$$.fragment,a),ao=E(a),Ke=m(a,"P",{});var Zo=d(Ke);nn=f(Zo,"Crea una "),xa=m(Zo,"CODE",{});var Ur=d(xa);rn=f(Ur,"pipeline()"),Ur.forEach(n),un=f(Zo," con il compito che vuoi risolvere e con il modello che vuoi utilizzare."),Zo.forEach(n),lo=E(a),N(Pt.$$.fragment,a),oo=E(a),Ee=m(a,"P",{});var wa=d(Ee);cn=f(wa,"Poi, carica un dataset (vedi \u{1F917} Datasets "),St=m(wa,"A",{href:!0,rel:!0});var Br=d(St);fn=f(Br,"Quick Start"),Br.forEach(n),pn=f(wa," per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset "),Mt=m(wa,"A",{href:!0,rel:!0});var Gr=d(Mt);mn=f(Gr,"MInDS-14"),Gr.forEach(n),dn=f(wa,":"),wa.forEach(n),so=E(a),N(Dt.$$.fragment,a),no=E(a),Ze=m(a,"P",{});var Xo=d(Ze);_n=f(Xo,"Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui \xE8 stato addestrato "),el=m(Xo,"CODE",{});var Qr=d(el);hn=f(Qr,"radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"),Qr.forEach(n),gn=f(Xo,"."),Xo.forEach(n),io=E(a),N(Nt.$$.fragment,a),ro=E(a),sa=m(a,"P",{});var Hr=d(sa);$n=f(Hr,`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna \u201Caudio\u201D.
Estraiamo i vettori delle forme d\u2019onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`),Hr.forEach(n),uo=E(a),N(Ft.$$.fragment,a),co=E(a),Xe=m(a,"P",{});var xo=d(Xe);vn=f(xo,"Per un dataset pi\xF9 grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la "),na=m(xo,"A",{href:!0});var Jr=d(na);bn=f(Jr,"documentazione della pipeline"),Jr.forEach(n),kn=f(xo," per maggiori informazioni."),xo.forEach(n),fo=E(a),Fe=m(a,"H3",{class:!0});var es=d(Fe);xe=m(es,"A",{id:!0,class:!0,href:!0});var Vr=d(xe);tl=m(Vr,"SPAN",{});var Wr=d(tl);N(It.$$.fragment,Wr),Wr.forEach(n),Vr.forEach(n),wn=E(es),al=m(es,"SPAN",{});var Yr=d(al);zn=f(Yr,"Utilizzare un altro modello e tokenizer nella pipeline"),Yr.forEach(n),es.forEach(n),po=E(a),fe=m(a,"P",{});var ye=d(fe);En=f(ye,"La "),ll=m(ye,"CODE",{});var Kr=d(ll);jn=f(Kr,"pipeline()"),Kr.forEach(n),An=f(ye," pu\xF2 ospitare qualsiasi modello del "),Ot=m(ye,"A",{href:!0,rel:!0});var Zr=d(Ot);Cn=f(Zr,"Model Hub"),Zr.forEach(n),qn=f(ye,", rendendo semplice l\u2019adattamento della "),ol=m(ye,"CODE",{});var Xr=d(ol);Tn=f(Xr,"pipeline()"),Xr.forEach(n),yn=f(ye," per altri casi d\u2019uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua "),Lt=m(ye,"A",{href:!0,rel:!0});var xr=d(Lt);Pn=f(xr,"BERT model"),xr.forEach(n),Sn=f(ye," fine-tuned per l\u2019analisi del sentimento. Ottimo, utilizziamo questo modello!"),ye.forEach(n),mo=E(a),N(Rt.$$.fragment,a),_o=E(a),N(et.$$.fragment,a),ho=E(a),je=m(a,"P",{});var za=d(je);Mn=f(za,"Poi puoi specificare il modello e il tokenizer nella "),sl=m(za,"CODE",{});var eu=d(sl);Dn=f(eu,"pipeline()"),eu.forEach(n),Nn=f(za,", e applicare il "),nl=m(za,"CODE",{});var tu=d(nl);Fn=f(tu,"classifier"),tu.forEach(n),In=f(za," sul tuo testo obiettivo:"),za.forEach(n),go=E(a),N(Ut.$$.fragment,a),$o=E(a),Ae=m(a,"P",{});var Ea=d(Ae);On=f(Ea,"Se non riesci a trovare un modello per il tuo caso d\u2019uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un\u2019occhiata al nostro tutorial "),ia=m(Ea,"A",{href:!0});var au=d(ia);Ln=f(au,"fine-tuning tutorial"),au.forEach(n),Rn=f(Ea," per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial "),ra=m(Ea,"A",{href:!0});var lu=d(ra);Un=f(lu,"qui"),lu.forEach(n),Bn=f(Ea,") con la comunit\xE0 sul Model Hub per democratizzare l\u2019NLP! \u{1F917}"),Ea.forEach(n),vo=E(a),Ie=m(a,"H2",{class:!0});var ts=d(Ie);tt=m(ts,"A",{id:!0,class:!0,href:!0});var ou=d(tt);il=m(ou,"SPAN",{});var su=d(il);N(Bt.$$.fragment,su),su.forEach(n),ou.forEach(n),Gn=E(ts),rl=m(ts,"SPAN",{});var nu=d(rl);Qn=f(nu,"AutoClass"),nu.forEach(n),ts.forEach(n),bo=E(a),N(Gt.$$.fragment,a),ko=E(a),x=m(a,"P",{});var pe=d(x);Hn=f(pe,"Al suo interno, le classi "),ul=m(pe,"CODE",{});var iu=d(ul);Jn=f(iu,"AutoModelForSequenceClassification"),iu.forEach(n),Vn=f(pe," e "),cl=m(pe,"CODE",{});var ru=d(cl);Wn=f(ru,"AutoTokenizer"),ru.forEach(n),Yn=f(pe," lavorano assieme per dare potere alla "),fl=m(pe,"CODE",{});var uu=d(fl);Kn=f(uu,"pipeline()"),uu.forEach(n),Zn=f(pe,". Una "),ua=m(pe,"A",{href:!0});var cu=d(ua);Xn=f(cu,"AutoClass"),cu.forEach(n),xn=f(pe," \xE8 una scorciatoia che automaticamente recupera l\u2019architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la "),pl=m(pe,"CODE",{});var fu=d(pl);ei=f(fu,"AutoClass"),fu.forEach(n),ti=f(pe," appropriata per il tuo compito e il suo tokenizer associato con "),ml=m(pe,"CODE",{});var pu=d(ml);ai=f(pu,"AutoTokenizer"),pu.forEach(n),li=f(pe,"."),pe.forEach(n),wo=E(a),Ce=m(a,"P",{});var ja=d(Ce);oi=f(ja,"Ritorniamo al nostro esempio e vediamo come puoi utilizzare la "),dl=m(ja,"CODE",{});var mu=d(dl);si=f(mu,"AutoClass"),mu.forEach(n),ni=f(ja," per replicare i risultati della "),_l=m(ja,"CODE",{});var du=d(_l);ii=f(du,"pipeline()"),du.forEach(n),ri=f(ja,"."),ja.forEach(n),zo=E(a),Oe=m(a,"H3",{class:!0});var as=d(Oe);at=m(as,"A",{id:!0,class:!0,href:!0});var _u=d(at);hl=m(_u,"SPAN",{});var hu=d(hl);N(Qt.$$.fragment,hu),hu.forEach(n),_u.forEach(n),ui=E(as),gl=m(as,"SPAN",{});var gu=d(gl);ci=f(gu,"AutoTokenizer"),gu.forEach(n),as.forEach(n),Eo=E(a),qe=m(a,"P",{});var Aa=d(qe);fi=f(Aa,"Un tokenizer \xE8 responsabile dell\u2019elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer divider\xE0 il testo in parole chiamate "),$l=m(Aa,"EM",{});var $u=d($l);pi=f($u,"token"),$u.forEach(n),mi=f(Aa,". Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di pi\xF9 sulla tokenizzazione "),ca=m(Aa,"A",{href:!0});var vu=d(ca);di=f(vu,"qui"),vu.forEach(n),_i=f(Aa,"). La cosa pi\xF9 importante da ricordare comunque \xE8 che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello \xE8 stato pre-allenato."),Aa.forEach(n),jo=E(a),lt=m(a,"P",{});var ls=d(lt);hi=f(ls,"Carica un tokenizer con "),vl=m(ls,"CODE",{});var bu=d(vl);gi=f(bu,"AutoTokenizer"),bu.forEach(n),$i=f(ls,":"),ls.forEach(n),Ao=E(a),N(Ht.$$.fragment,a),Co=E(a),ot=m(a,"P",{});var os=d(ot);vi=f(os,"Dopodich\xE9, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo \xE8 conosciuto come il "),bl=m(os,"EM",{});var ku=d(bl);bi=f(ku,"vocabolario"),ku.forEach(n),ki=f(os," del modello."),os.forEach(n),qo=E(a),fa=m(a,"P",{});var wu=d(fa);wi=f(wu,"Passa il tuo testo al tokenizer:"),wu.forEach(n),To=E(a),N(Jt.$$.fragment,a),yo=E(a),pa=m(a,"P",{});var zu=d(pa);zi=f(zu,"Il tokenizer restituir\xE0 un dizionario contenente:"),zu.forEach(n),Po=E(a),st=m(a,"UL",{});var ss=d(st);ma=m(ss,"LI",{});var ir=d(ma);da=m(ir,"A",{href:!0});var Eu=d(da);Ei=f(Eu,"input_ids"),Eu.forEach(n),ji=f(ir,": rappresentazioni numeriche dei tuoi token."),ir.forEach(n),Ai=E(ss),_a=m(ss,"LI",{});var rr=d(_a);ha=m(rr,"A",{href:!0});var ju=d(ha);Ci=f(ju,"attention_mask"),ju.forEach(n),qi=f(rr,": indica quali token devono essere presi in considerazione."),rr.forEach(n),ss.forEach(n),So=E(a),nt=m(a,"P",{});var ns=d(nt);Ti=f(ns,"Come con la "),kl=m(ns,"CODE",{});var Au=d(kl);yi=f(Au,"pipeline()"),Au.forEach(n),Pi=f(ns,", il tokenizer accetter\xE0 una lista di input. In pi\xF9, il tokenizer pu\xF2 anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:"),ns.forEach(n),Mo=E(a),N(it.$$.fragment,a),Do=E(a),rt=m(a,"P",{});var is=d(rt);Si=f(is,"Leggi il tutorial sul "),ga=m(is,"A",{href:!0});var Cu=d(ga);Mi=f(Cu,"preproccesing"),Cu.forEach(n),Di=f(is," per maggiori dettagli sulla tokenizzazione."),is.forEach(n),No=E(a),Le=m(a,"H3",{class:!0});var rs=d(Le);ut=m(rs,"A",{id:!0,class:!0,href:!0});var qu=d(ut);wl=m(qu,"SPAN",{});var Tu=d(wl);N(Vt.$$.fragment,Tu),Tu.forEach(n),qu.forEach(n),Ni=E(rs),zl=m(rs,"SPAN",{});var yu=d(zl);Fi=f(yu,"AutoModel"),yu.forEach(n),rs.forEach(n),Fo=E(a),N(ct.$$.fragment,a),Io=E(a),N(ft.$$.fragment,a),Oo=E(a),ee=m(a,"P",{});var me=d(ee);Ii=f(me,"I modelli sono "),Wt=m(me,"A",{href:!0,rel:!0});var Pu=d(Wt);El=m(Pu,"CODE",{});var Su=d(El);Oi=f(Su,"torch.nn.Module"),Su.forEach(n),Pu.forEach(n),Li=f(me," o "),Yt=m(me,"A",{href:!0,rel:!0});var Mu=d(Yt);jl=m(Mu,"CODE",{});var Du=d(jl);Ri=f(Du,"tf.keras.Model"),Du.forEach(n),Mu.forEach(n),Ui=f(me," standard cos\xEC puoi utilizzarli all\u2019interno del tuo training loop usuale. Tuttavia, per rendere le cose pi\xF9 semplici, \u{1F917} Transformers fornisce una classe "),Al=m(me,"CODE",{});var Nu=d(Al);Bi=f(Nu,"Trainer"),Nu.forEach(n),Gi=f(me," per PyTorch che aggiunge delle funzionalit\xE0 per l\u2019allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo "),Cl=m(me,"CODE",{});var Fu=d(Cl);Qi=f(Fu,"fit"),Fu.forEach(n),Hi=f(me," di "),Kt=m(me,"A",{href:!0,rel:!0});var Iu=d(Kt);Ji=f(Iu,"Keras"),Iu.forEach(n),Vi=f(me,". Fai riferimento al "),$a=m(me,"A",{href:!0});var Ou=d($a);Wi=f(Ou,"tutorial per il training"),Ou.forEach(n),Yi=f(me," per maggiori dettagli."),me.forEach(n),Lo=E(a),N(pt.$$.fragment,a),Ro=E(a),Re=m(a,"H3",{class:!0});var us=d(Re);mt=m(us,"A",{id:!0,class:!0,href:!0});var Lu=d(mt);ql=m(Lu,"SPAN",{});var Ru=d(ql);N(Zt.$$.fragment,Ru),Ru.forEach(n),Lu.forEach(n),Ki=E(us),Tl=m(us,"SPAN",{});var Uu=d(Tl);Zi=f(Uu,"Salva un modello"),Uu.forEach(n),us.forEach(n),Uo=E(a),N(dt.$$.fragment,a),Bo=E(a),Te=m(a,"P",{});var Ca=d(Te);Xi=f(Ca,"Una caratteristica particolarmente interessante di \u{1F917} Transformers \xE8 la sua abilit\xE0 di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri "),yl=m(Ca,"CODE",{});var Bu=d(yl);xi=f(Bu,"from_pt"),Bu.forEach(n),er=f(Ca," o "),Pl=m(Ca,"CODE",{});var Gu=d(Pl);tr=f(Gu,"from_tf"),Gu.forEach(n),ar=f(Ca," possono convertire un modello da un framework all\u2019altro:"),Ca.forEach(n),Go=E(a),N(_t.$$.fragment,a),this.h()},h(){b(e,"name","hf:doc:metadata"),b(e,"content",JSON.stringify(Df)),b(l,"id","quick-tour"),b(l,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(l,"href","#quick-tour"),b(t,"class","relative group"),b(T,"href","./model_doc/auto"),b(J,"id","pipeline"),b(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(J,"href","#pipeline"),b(K,"class","relative group"),b(He,"id","utilizzo-della-pipeline"),b(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(He,"href","#utilizzo-della-pipeline"),b(Ne,"class","relative group"),b(At,"href","https://huggingface.co/MilaNLProc/feel-it-italian-sentiment"),b(At,"rel","nofollow"),b(Tt,"href","https://huggingface.co/docs/datasets/"),b(Tt,"rel","nofollow"),b(St,"href","https://huggingface.co/docs/datasets/quickstart.html"),b(St,"rel","nofollow"),b(Mt,"href","https://huggingface.co/datasets/PolyAI/minds14"),b(Mt,"rel","nofollow"),b(na,"href","./main_classes/pipelines"),b(xe,"id","utilizzare-un-altro-modello-e-tokenizer-nella-pipeline"),b(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(xe,"href","#utilizzare-un-altro-modello-e-tokenizer-nella-pipeline"),b(Fe,"class","relative group"),b(Ot,"href","https://huggingface.co/models"),b(Ot,"rel","nofollow"),b(Lt,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),b(Lt,"rel","nofollow"),b(ia,"href","./training"),b(ra,"href","./model_sharing"),b(tt,"id","autoclass"),b(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(tt,"href","#autoclass"),b(Ie,"class","relative group"),b(ua,"href","./model_doc/auto"),b(at,"id","autotokenizer"),b(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(at,"href","#autotokenizer"),b(Oe,"class","relative group"),b(ca,"href","./tokenizer_summary"),b(da,"href","./glossary#input-ids"),b(ha,"href",".glossary#attention-mask"),b(ga,"href","./preprocessing"),b(ut,"id","automodel"),b(ut,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ut,"href","#automodel"),b(Le,"class","relative group"),b(Wt,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),b(Wt,"rel","nofollow"),b(Yt,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),b(Yt,"rel","nofollow"),b(Kt,"href","https://keras.io/"),b(Kt,"rel","nofollow"),b($a,"href","./training"),b(mt,"id","salva-un-modello"),b(mt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(mt,"href","#salva-un-modello"),b(Re,"class","relative group")},m(a,$){o(document.head,e),h(a,s,$),h(a,t,$),o(t,l),o(l,i),M(u,i,null),o(t,g),o(t,_),o(_,v),h(a,q,$),M(I,a,$),h(a,F,$),h(a,y,$),o(y,P),o(y,w),o(w,C),o(y,k),o(y,T),o(T,R),o(y,G),h(a,V,$),M(U,a,$),h(a,ae,$),h(a,K,$),o(K,J),o(J,te),M(Z,te,null),o(K,X),o(K,de),o(de,se),h(a,he,$),h(a,ne,$),o(ne,le),o(le,ie),o(ne,ge),h(a,L,$),M(B,a,$),h(a,re,$),h(a,O,$),o(O,Q),o(O,ce),o(ce,De),o(O,_e),h(a,ve,$),h(a,ue,$),o(ue,Be),o(Be,be),o(ue,la),h(a,kt,$),h(a,W,$),o(W,Pa),o(Pa,fs),o(W,ps),o(W,Sa),o(Sa,ms),o(W,ds),o(W,Ma),o(Ma,_s),o(W,hs),o(W,Da),o(Da,gs),o(W,$s),o(W,Na),o(Na,vs),o(W,bs),o(W,Fa),o(Fa,ks),o(W,ws),o(W,Ia),o(Ia,zs),o(W,Es),o(W,Oa),o(Oa,js),h(a,Ll,$),h(a,wt,$),o(wt,La),o(La,As),o(wt,Cs),h(a,Rl,$),h(a,ke,$),o(ke,Ra),o(Ra,qs),o(ke,Ts),o(ke,Ua),o(Ua,ys),o(ke,Ps),o(ke,Ba),o(Ba,Ss),h(a,Ul,$),h(a,zt,$),o(zt,Ga),o(Ga,Ms),o(zt,Ds),h(a,Bl,$),h(a,Ge,$),o(Ge,Qa),o(Qa,Ns),o(Ge,Fs),o(Ge,Ha),o(Ha,Is),h(a,Gl,$),M(Qe,a,$),h(a,Ql,$),h(a,Ne,$),o(Ne,He),o(He,Ja),M(Et,Ja,null),o(Ne,Os),o(Ne,Va),o(Va,Ls),h(a,Hl,$),h(a,Je,$),o(Je,Rs),o(Je,Wa),o(Wa,Us),o(Je,Bs),h(a,Jl,$),h(a,oa,$),o(oa,Gs),h(a,Vl,$),M(Ve,a,$),h(a,Wl,$),h(a,We,$),o(We,Qs),o(We,Ya),o(Ya,Hs),o(We,Js),h(a,Yl,$),M(jt,a,$),h(a,Kl,$),h(a,we,$),o(we,Vs),o(we,At),o(At,Ws),o(we,Ys),o(we,Ka),o(Ka,Ks),o(we,Zs),h(a,Zl,$),M(Ct,a,$),h(a,Xl,$),h(a,Ye,$),o(Ye,Xs),o(Ye,Za),o(Za,xs),o(Ye,en),h(a,xl,$),M(qt,a,$),h(a,eo,$),h(a,ze,$),o(ze,tn),o(ze,Xa),o(Xa,an),o(ze,ln),o(ze,Tt),o(Tt,on),o(ze,sn),h(a,to,$),M(yt,a,$),h(a,ao,$),h(a,Ke,$),o(Ke,nn),o(Ke,xa),o(xa,rn),o(Ke,un),h(a,lo,$),M(Pt,a,$),h(a,oo,$),h(a,Ee,$),o(Ee,cn),o(Ee,St),o(St,fn),o(Ee,pn),o(Ee,Mt),o(Mt,mn),o(Ee,dn),h(a,so,$),M(Dt,a,$),h(a,no,$),h(a,Ze,$),o(Ze,_n),o(Ze,el),o(el,hn),o(Ze,gn),h(a,io,$),M(Nt,a,$),h(a,ro,$),h(a,sa,$),o(sa,$n),h(a,uo,$),M(Ft,a,$),h(a,co,$),h(a,Xe,$),o(Xe,vn),o(Xe,na),o(na,bn),o(Xe,kn),h(a,fo,$),h(a,Fe,$),o(Fe,xe),o(xe,tl),M(It,tl,null),o(Fe,wn),o(Fe,al),o(al,zn),h(a,po,$),h(a,fe,$),o(fe,En),o(fe,ll),o(ll,jn),o(fe,An),o(fe,Ot),o(Ot,Cn),o(fe,qn),o(fe,ol),o(ol,Tn),o(fe,yn),o(fe,Lt),o(Lt,Pn),o(fe,Sn),h(a,mo,$),M(Rt,a,$),h(a,_o,$),M(et,a,$),h(a,ho,$),h(a,je,$),o(je,Mn),o(je,sl),o(sl,Dn),o(je,Nn),o(je,nl),o(nl,Fn),o(je,In),h(a,go,$),M(Ut,a,$),h(a,$o,$),h(a,Ae,$),o(Ae,On),o(Ae,ia),o(ia,Ln),o(Ae,Rn),o(Ae,ra),o(ra,Un),o(Ae,Bn),h(a,vo,$),h(a,Ie,$),o(Ie,tt),o(tt,il),M(Bt,il,null),o(Ie,Gn),o(Ie,rl),o(rl,Qn),h(a,bo,$),M(Gt,a,$),h(a,ko,$),h(a,x,$),o(x,Hn),o(x,ul),o(ul,Jn),o(x,Vn),o(x,cl),o(cl,Wn),o(x,Yn),o(x,fl),o(fl,Kn),o(x,Zn),o(x,ua),o(ua,Xn),o(x,xn),o(x,pl),o(pl,ei),o(x,ti),o(x,ml),o(ml,ai),o(x,li),h(a,wo,$),h(a,Ce,$),o(Ce,oi),o(Ce,dl),o(dl,si),o(Ce,ni),o(Ce,_l),o(_l,ii),o(Ce,ri),h(a,zo,$),h(a,Oe,$),o(Oe,at),o(at,hl),M(Qt,hl,null),o(Oe,ui),o(Oe,gl),o(gl,ci),h(a,Eo,$),h(a,qe,$),o(qe,fi),o(qe,$l),o($l,pi),o(qe,mi),o(qe,ca),o(ca,di),o(qe,_i),h(a,jo,$),h(a,lt,$),o(lt,hi),o(lt,vl),o(vl,gi),o(lt,$i),h(a,Ao,$),M(Ht,a,$),h(a,Co,$),h(a,ot,$),o(ot,vi),o(ot,bl),o(bl,bi),o(ot,ki),h(a,qo,$),h(a,fa,$),o(fa,wi),h(a,To,$),M(Jt,a,$),h(a,yo,$),h(a,pa,$),o(pa,zi),h(a,Po,$),h(a,st,$),o(st,ma),o(ma,da),o(da,Ei),o(ma,ji),o(st,Ai),o(st,_a),o(_a,ha),o(ha,Ci),o(_a,qi),h(a,So,$),h(a,nt,$),o(nt,Ti),o(nt,kl),o(kl,yi),o(nt,Pi),h(a,Mo,$),M(it,a,$),h(a,Do,$),h(a,rt,$),o(rt,Si),o(rt,ga),o(ga,Mi),o(rt,Di),h(a,No,$),h(a,Le,$),o(Le,ut),o(ut,wl),M(Vt,wl,null),o(Le,Ni),o(Le,zl),o(zl,Fi),h(a,Fo,$),M(ct,a,$),h(a,Io,$),M(ft,a,$),h(a,Oo,$),h(a,ee,$),o(ee,Ii),o(ee,Wt),o(Wt,El),o(El,Oi),o(ee,Li),o(ee,Yt),o(Yt,jl),o(jl,Ri),o(ee,Ui),o(ee,Al),o(Al,Bi),o(ee,Gi),o(ee,Cl),o(Cl,Qi),o(ee,Hi),o(ee,Kt),o(Kt,Ji),o(ee,Vi),o(ee,$a),o($a,Wi),o(ee,Yi),h(a,Lo,$),M(pt,a,$),h(a,Ro,$),h(a,Re,$),o(Re,mt),o(mt,ql),M(Zt,ql,null),o(Re,Ki),o(Re,Tl),o(Tl,Zi),h(a,Uo,$),M(dt,a,$),h(a,Bo,$),h(a,Te,$),o(Te,Xi),o(Te,yl),o(yl,xi),o(Te,er),o(Te,Pl),o(Pl,tr),o(Te,ar),h(a,Go,$),M(_t,a,$),Qo=!0},p(a,[$]){const Xt={};$&2&&(Xt.$$scope={dirty:$,ctx:a}),U.$set(Xt);const Sl={};$&2&&(Sl.$$scope={dirty:$,ctx:a}),Qe.$set(Sl);const Ml={};$&2&&(Ml.$$scope={dirty:$,ctx:a}),Ve.$set(Ml);const Dl={};$&2&&(Dl.$$scope={dirty:$,ctx:a}),et.$set(Dl);const Ue={};$&2&&(Ue.$$scope={dirty:$,ctx:a}),it.$set(Ue);const Nl={};$&2&&(Nl.$$scope={dirty:$,ctx:a}),ct.$set(Nl);const Fl={};$&2&&(Fl.$$scope={dirty:$,ctx:a}),ft.$set(Fl);const xt={};$&2&&(xt.$$scope={dirty:$,ctx:a}),pt.$set(xt);const Il={};$&2&&(Il.$$scope={dirty:$,ctx:a}),dt.$set(Il);const Ol={};$&2&&(Ol.$$scope={dirty:$,ctx:a}),_t.$set(Ol)},i(a){Qo||(j(u.$$.fragment,a),j(I.$$.fragment,a),j(U.$$.fragment,a),j(Z.$$.fragment,a),j(B.$$.fragment,a),j(Qe.$$.fragment,a),j(Et.$$.fragment,a),j(Ve.$$.fragment,a),j(jt.$$.fragment,a),j(Ct.$$.fragment,a),j(qt.$$.fragment,a),j(yt.$$.fragment,a),j(Pt.$$.fragment,a),j(Dt.$$.fragment,a),j(Nt.$$.fragment,a),j(Ft.$$.fragment,a),j(It.$$.fragment,a),j(Rt.$$.fragment,a),j(et.$$.fragment,a),j(Ut.$$.fragment,a),j(Bt.$$.fragment,a),j(Gt.$$.fragment,a),j(Qt.$$.fragment,a),j(Ht.$$.fragment,a),j(Jt.$$.fragment,a),j(it.$$.fragment,a),j(Vt.$$.fragment,a),j(ct.$$.fragment,a),j(ft.$$.fragment,a),j(pt.$$.fragment,a),j(Zt.$$.fragment,a),j(dt.$$.fragment,a),j(_t.$$.fragment,a),Qo=!0)},o(a){A(u.$$.fragment,a),A(I.$$.fragment,a),A(U.$$.fragment,a),A(Z.$$.fragment,a),A(B.$$.fragment,a),A(Qe.$$.fragment,a),A(Et.$$.fragment,a),A(Ve.$$.fragment,a),A(jt.$$.fragment,a),A(Ct.$$.fragment,a),A(qt.$$.fragment,a),A(yt.$$.fragment,a),A(Pt.$$.fragment,a),A(Dt.$$.fragment,a),A(Nt.$$.fragment,a),A(Ft.$$.fragment,a),A(It.$$.fragment,a),A(Rt.$$.fragment,a),A(et.$$.fragment,a),A(Ut.$$.fragment,a),A(Bt.$$.fragment,a),A(Gt.$$.fragment,a),A(Qt.$$.fragment,a),A(Ht.$$.fragment,a),A(Jt.$$.fragment,a),A(it.$$.fragment,a),A(Vt.$$.fragment,a),A(ct.$$.fragment,a),A(ft.$$.fragment,a),A(pt.$$.fragment,a),A(Zt.$$.fragment,a),A(dt.$$.fragment,a),A(_t.$$.fragment,a),Qo=!1},d(a){n(e),a&&n(s),a&&n(t),D(u),a&&n(q),D(I,a),a&&n(F),a&&n(y),a&&n(V),D(U,a),a&&n(ae),a&&n(K),D(Z),a&&n(he),a&&n(ne),a&&n(L),D(B,a),a&&n(re),a&&n(O),a&&n(ve),a&&n(ue),a&&n(kt),a&&n(W),a&&n(Ll),a&&n(wt),a&&n(Rl),a&&n(ke),a&&n(Ul),a&&n(zt),a&&n(Bl),a&&n(Ge),a&&n(Gl),D(Qe,a),a&&n(Ql),a&&n(Ne),D(Et),a&&n(Hl),a&&n(Je),a&&n(Jl),a&&n(oa),a&&n(Vl),D(Ve,a),a&&n(Wl),a&&n(We),a&&n(Yl),D(jt,a),a&&n(Kl),a&&n(we),a&&n(Zl),D(Ct,a),a&&n(Xl),a&&n(Ye),a&&n(xl),D(qt,a),a&&n(eo),a&&n(ze),a&&n(to),D(yt,a),a&&n(ao),a&&n(Ke),a&&n(lo),D(Pt,a),a&&n(oo),a&&n(Ee),a&&n(so),D(Dt,a),a&&n(no),a&&n(Ze),a&&n(io),D(Nt,a),a&&n(ro),a&&n(sa),a&&n(uo),D(Ft,a),a&&n(co),a&&n(Xe),a&&n(fo),a&&n(Fe),D(It),a&&n(po),a&&n(fe),a&&n(mo),D(Rt,a),a&&n(_o),D(et,a),a&&n(ho),a&&n(je),a&&n(go),D(Ut,a),a&&n($o),a&&n(Ae),a&&n(vo),a&&n(Ie),D(Bt),a&&n(bo),D(Gt,a),a&&n(ko),a&&n(x),a&&n(wo),a&&n(Ce),a&&n(zo),a&&n(Oe),D(Qt),a&&n(Eo),a&&n(qe),a&&n(jo),a&&n(lt),a&&n(Ao),D(Ht,a),a&&n(Co),a&&n(ot),a&&n(qo),a&&n(fa),a&&n(To),D(Jt,a),a&&n(yo),a&&n(pa),a&&n(Po),a&&n(st),a&&n(So),a&&n(nt),a&&n(Mo),D(it,a),a&&n(Do),a&&n(rt),a&&n(No),a&&n(Le),D(Vt),a&&n(Fo),D(ct,a),a&&n(Io),D(ft,a),a&&n(Oo),a&&n(ee),a&&n(Lo),D(pt,a),a&&n(Ro),a&&n(Re),D(Zt),a&&n(Uo),D(dt,a),a&&n(Bo),a&&n(Te),a&&n(Go),D(_t,a)}}}const Df={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"utilizzo-della-pipeline",title:"Utilizzo della Pipeline"},{local:"utilizzare-un-altro-modello-e-tokenizer-nella-pipeline",title:"Utilizzare un altro modello e tokenizer nella pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"salva-un-modello",title:"Salva un modello"}],title:"AutoClass"}],title:"Quick tour"};function Nf(r){return ur(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Uf extends ea{constructor(e){super();ta(this,e,Nf,Mf,aa,{})}}export{Uf as default,Df as metadata};
