import{S as It,i as Wt,s as Jt,e as o,k as d,w as m,t as c,M as Rt,c as n,d as a,m as u,a as s,x as f,h as p,b as i,G as t,g as l,y as h,L as Kt,q as v,o as _,B as $,v as Qt}from"../chunks/vendor-hf-doc-builder.js";import{I as le}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as B}from"../chunks/CodeBlock-hf-doc-builder.js";function Vt(st){let w,Ue,E,C,he,G,ba,ve,ga,De,q,wa,M,Ea,ka,Le,k,S,_e,F,ya,$e,Aa,Oe,ie,Pa,Te,I,Be,b,ja,W,be,za,Ca,ge,qa,Sa,Ge,J,Me,y,N,we,R,Na,Ee,xa,Fe,x,Ha,K,ke,Ua,Da,Ie,Q,We,A,H,ye,V,La,Ae,Oa,Je,g,Ta,Pe,Ba,Ga,X,je,Ma,Fa,Re,Y,Ke,ce,Ia,Qe,Z,Ve,P,U,ze,ee,Wa,Ce,Ja,Xe,pe,Ra,Ye,j,D,qe,ae,Ka,Se,Qa,Ze,de,Va,ea,te,aa,ue,Xa,ta,re,ra,z,L,Ne,oe,Ya,xe,Za,oa,O,et,He,at,tt,na,ne,sa,T,rt,se,ot,nt,la;return G=new le({}),F=new le({}),I=new B({props:{code:"pip install accelerate",highlighted:"pip install accelerate"}}),J=new B({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

<span class="hljs-meta">&gt;&gt;&gt; </span>accelerator = Accelerator()`}}),R=new le({}),Q=new B({props:{code:`train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
    train_dataloader, eval_dataloader, model, optimizer
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
<span class="hljs-meta">... </span>    train_dataloader, eval_dataloader, model, optimizer
<span class="hljs-meta">... </span>)`}}),V=new le({}),Y=new B({props:{code:`for epoch in range(num_epochs):
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        accelerator.backward(loss)

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),Z=new B({props:{code:`






`,highlighted:`<span class="hljs-addition">+ from accelerate import Accelerator</span>
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

<span class="hljs-addition">+ accelerator = Accelerator()</span>

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

<span class="hljs-deletion">- device = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)</span>
<span class="hljs-deletion">- model.to(device)</span>

<span class="hljs-addition">+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(</span>
<span class="hljs-addition">+     train_dataloader, eval_dataloader, model, optimizer</span>
<span class="hljs-addition">+ )</span>

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      &quot;linear&quot;,
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
<span class="hljs-deletion">-         batch = {k: v.to(device) for k, v in batch.items()}</span>
          outputs = model(**batch)
          loss = outputs.loss
<span class="hljs-deletion">-         loss.backward()</span>
<span class="hljs-addition">+         accelerator.backward(loss)</span>

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)`}}),ee=new le({}),ae=new le({}),te=new B({props:{code:"accelerate config",highlighted:"accelerate config"}}),re=new B({props:{code:"accelerate launch train.py",highlighted:"accelerate launch train.py"}}),oe=new le({}),ne=new B({props:{code:`from accelerate import notebook_launcher

notebook_launcher(training_function)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> notebook_launcher

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_launcher(training_function)`}}),{c(){w=o("meta"),Ue=d(),E=o("h1"),C=o("a"),he=o("span"),m(G.$$.fragment),ba=d(),ve=o("span"),ga=c("Entrenamiento distribuido con \u{1F917} Accelerate"),De=d(),q=o("p"),wa=c("El paralelismo ha emergido como una estrategia para entrenar modelos grandes en hardware limitado e incrementar la velocidad de entrenamiento en varios \xF3rdenes de magnitud. En Hugging Face creamos la biblioteca "),M=o("a"),Ea=c("\u{1F917} Accelerate"),ka=c(" para ayudar a los usuarios a entrenar modelos \u{1F917} Transformers en cualquier tipo de configuraci\xF3n distribuida, ya sea en una m\xE1quina con m\xFAltiples GPUs o en m\xFAltiples GPUs distribuidas entre muchas m\xE1quinas. En este tutorial aprender\xE1s c\xF3mo personalizar tu bucle de entrenamiento de PyTorch nativo para poder entrenar en entornos distribuidos."),Le=d(),k=o("h2"),S=o("a"),_e=o("span"),m(F.$$.fragment),ya=d(),$e=o("span"),Aa=c("Configuraci\xF3n"),Oe=d(),ie=o("p"),Pa=c("Empecemos por instalar \u{1F917} Accelerate:"),Te=d(),m(I.$$.fragment),Be=d(),b=o("p"),ja=c("Luego, importamos y creamos un objeto "),W=o("a"),be=o("code"),za=c("Accelerator"),Ca=c(". "),ge=o("code"),qa=c("Accelerator"),Sa=c(" detectar\xE1 autom\xE1ticamente el tipo de configuraci\xF3n distribuida que tengas disponible e inicializar\xE1 todos los componentes necesarios para el entrenamiento. No necesitas especificar el dispositivo en donde se debe colocar tu modelo."),Ge=d(),m(J.$$.fragment),Me=d(),y=o("h2"),N=o("a"),we=o("span"),m(R.$$.fragment),Na=d(),Ee=o("span"),xa=c("Prep\xE1rate para acelerar"),Fe=d(),x=o("p"),Ha=c("Pasa todos los objetos relevantes para el entrenamiento al m\xE9todo "),K=o("a"),ke=o("code"),Ua=c("prepare"),Da=c(". Esto incluye los DataLoaders de entrenamiento y evaluaci\xF3n, un modelo y un optimizador:"),Ie=d(),m(Q.$$.fragment),We=d(),A=o("h2"),H=o("a"),ye=o("span"),m(V.$$.fragment),La=d(),Ae=o("span"),Oa=c("Backward"),Je=d(),g=o("p"),Ta=c("Por \xFAltimo, reemplaza el t\xEDpico "),Pe=o("code"),Ba=c("loss.backward()"),Ga=c(" en tu bucle de entrenamiento con el m\xE9todo "),X=o("a"),je=o("code"),Ma=c("backward"),Fa=c(" de \u{1F917} Accelerate:"),Re=d(),m(Y.$$.fragment),Ke=d(),ce=o("p"),Ia=c("Como se puede ver en el siguiente c\xF3digo, \xA1solo necesitas adicionar cuatro l\xEDneas de c\xF3digo a tu bucle de entrenamiento para habilitar el entrenamiento distribuido!"),Qe=d(),m(Z.$$.fragment),Ve=d(),P=o("h2"),U=o("a"),ze=o("span"),m(ee.$$.fragment),Wa=d(),Ce=o("span"),Ja=c("Entrenamiento"),Xe=d(),pe=o("p"),Ra=c("Una vez que hayas a\xF1adido las l\xEDneas de c\xF3digo relevantes, inicia el entrenamiento desde un script o notebook como Colaboratory."),Ye=d(),j=o("h3"),D=o("a"),qe=o("span"),m(ae.$$.fragment),Ka=d(),Se=o("span"),Qa=c("Entrenar con un script"),Ze=d(),de=o("p"),Va=c("Si est\xE1s corriendo tu entrenamiento desde un script ejecuta el siguiente comando para crear y guardar un archivo de configuraci\xF3n:"),ea=d(),m(te.$$.fragment),aa=d(),ue=o("p"),Xa=c("Comienza el entrenamiento con:"),ta=d(),m(re.$$.fragment),ra=d(),z=o("h3"),L=o("a"),Ne=o("span"),m(oe.$$.fragment),Ya=d(),xe=o("span"),Za=c("Entrenar con un notebook"),oa=d(),O=o("p"),et=c("\u{1F917} Accelerate puede correr en un notebook si, por ejemplo, est\xE1s planeando utilizar las TPUs de Colaboratory. Encierra el c\xF3digo responsable del entrenamiento en una funci\xF3n y p\xE1salo a "),He=o("code"),at=c("notebook_launcher"),tt=c(":"),na=d(),m(ne.$$.fragment),sa=d(),T=o("p"),rt=c("Para obtener m\xE1s informaci\xF3n sobre \u{1F917} Accelerate y sus numerosas funciones, consulta la "),se=o("a"),ot=c("documentaci\xF3n"),nt=c("."),this.h()},l(e){const r=Rt('[data-svelte="svelte-1phssyn"]',document.head);w=n(r,"META",{name:!0,content:!0}),r.forEach(a),Ue=u(e),E=n(e,"H1",{class:!0});var ia=s(E);C=n(ia,"A",{id:!0,class:!0,href:!0});var lt=s(C);he=n(lt,"SPAN",{});var it=s(he);f(G.$$.fragment,it),it.forEach(a),lt.forEach(a),ba=u(ia),ve=n(ia,"SPAN",{});var ct=s(ve);ga=p(ct,"Entrenamiento distribuido con \u{1F917} Accelerate"),ct.forEach(a),ia.forEach(a),De=u(e),q=n(e,"P",{});var ca=s(q);wa=p(ca,"El paralelismo ha emergido como una estrategia para entrenar modelos grandes en hardware limitado e incrementar la velocidad de entrenamiento en varios \xF3rdenes de magnitud. En Hugging Face creamos la biblioteca "),M=n(ca,"A",{href:!0,rel:!0});var pt=s(M);Ea=p(pt,"\u{1F917} Accelerate"),pt.forEach(a),ka=p(ca," para ayudar a los usuarios a entrenar modelos \u{1F917} Transformers en cualquier tipo de configuraci\xF3n distribuida, ya sea en una m\xE1quina con m\xFAltiples GPUs o en m\xFAltiples GPUs distribuidas entre muchas m\xE1quinas. En este tutorial aprender\xE1s c\xF3mo personalizar tu bucle de entrenamiento de PyTorch nativo para poder entrenar en entornos distribuidos."),ca.forEach(a),Le=u(e),k=n(e,"H2",{class:!0});var pa=s(k);S=n(pa,"A",{id:!0,class:!0,href:!0});var dt=s(S);_e=n(dt,"SPAN",{});var ut=s(_e);f(F.$$.fragment,ut),ut.forEach(a),dt.forEach(a),ya=u(pa),$e=n(pa,"SPAN",{});var mt=s($e);Aa=p(mt,"Configuraci\xF3n"),mt.forEach(a),pa.forEach(a),Oe=u(e),ie=n(e,"P",{});var ft=s(ie);Pa=p(ft,"Empecemos por instalar \u{1F917} Accelerate:"),ft.forEach(a),Te=u(e),f(I.$$.fragment,e),Be=u(e),b=n(e,"P",{});var me=s(b);ja=p(me,"Luego, importamos y creamos un objeto "),W=n(me,"A",{href:!0,rel:!0});var ht=s(W);be=n(ht,"CODE",{});var vt=s(be);za=p(vt,"Accelerator"),vt.forEach(a),ht.forEach(a),Ca=p(me,". "),ge=n(me,"CODE",{});var _t=s(ge);qa=p(_t,"Accelerator"),_t.forEach(a),Sa=p(me," detectar\xE1 autom\xE1ticamente el tipo de configuraci\xF3n distribuida que tengas disponible e inicializar\xE1 todos los componentes necesarios para el entrenamiento. No necesitas especificar el dispositivo en donde se debe colocar tu modelo."),me.forEach(a),Ge=u(e),f(J.$$.fragment,e),Me=u(e),y=n(e,"H2",{class:!0});var da=s(y);N=n(da,"A",{id:!0,class:!0,href:!0});var $t=s(N);we=n($t,"SPAN",{});var bt=s(we);f(R.$$.fragment,bt),bt.forEach(a),$t.forEach(a),Na=u(da),Ee=n(da,"SPAN",{});var gt=s(Ee);xa=p(gt,"Prep\xE1rate para acelerar"),gt.forEach(a),da.forEach(a),Fe=u(e),x=n(e,"P",{});var ua=s(x);Ha=p(ua,"Pasa todos los objetos relevantes para el entrenamiento al m\xE9todo "),K=n(ua,"A",{href:!0,rel:!0});var wt=s(K);ke=n(wt,"CODE",{});var Et=s(ke);Ua=p(Et,"prepare"),Et.forEach(a),wt.forEach(a),Da=p(ua,". Esto incluye los DataLoaders de entrenamiento y evaluaci\xF3n, un modelo y un optimizador:"),ua.forEach(a),Ie=u(e),f(Q.$$.fragment,e),We=u(e),A=n(e,"H2",{class:!0});var ma=s(A);H=n(ma,"A",{id:!0,class:!0,href:!0});var kt=s(H);ye=n(kt,"SPAN",{});var yt=s(ye);f(V.$$.fragment,yt),yt.forEach(a),kt.forEach(a),La=u(ma),Ae=n(ma,"SPAN",{});var At=s(Ae);Oa=p(At,"Backward"),At.forEach(a),ma.forEach(a),Je=u(e),g=n(e,"P",{});var fe=s(g);Ta=p(fe,"Por \xFAltimo, reemplaza el t\xEDpico "),Pe=n(fe,"CODE",{});var Pt=s(Pe);Ba=p(Pt,"loss.backward()"),Pt.forEach(a),Ga=p(fe," en tu bucle de entrenamiento con el m\xE9todo "),X=n(fe,"A",{href:!0,rel:!0});var jt=s(X);je=n(jt,"CODE",{});var zt=s(je);Ma=p(zt,"backward"),zt.forEach(a),jt.forEach(a),Fa=p(fe," de \u{1F917} Accelerate:"),fe.forEach(a),Re=u(e),f(Y.$$.fragment,e),Ke=u(e),ce=n(e,"P",{});var Ct=s(ce);Ia=p(Ct,"Como se puede ver en el siguiente c\xF3digo, \xA1solo necesitas adicionar cuatro l\xEDneas de c\xF3digo a tu bucle de entrenamiento para habilitar el entrenamiento distribuido!"),Ct.forEach(a),Qe=u(e),f(Z.$$.fragment,e),Ve=u(e),P=n(e,"H2",{class:!0});var fa=s(P);U=n(fa,"A",{id:!0,class:!0,href:!0});var qt=s(U);ze=n(qt,"SPAN",{});var St=s(ze);f(ee.$$.fragment,St),St.forEach(a),qt.forEach(a),Wa=u(fa),Ce=n(fa,"SPAN",{});var Nt=s(Ce);Ja=p(Nt,"Entrenamiento"),Nt.forEach(a),fa.forEach(a),Xe=u(e),pe=n(e,"P",{});var xt=s(pe);Ra=p(xt,"Una vez que hayas a\xF1adido las l\xEDneas de c\xF3digo relevantes, inicia el entrenamiento desde un script o notebook como Colaboratory."),xt.forEach(a),Ye=u(e),j=n(e,"H3",{class:!0});var ha=s(j);D=n(ha,"A",{id:!0,class:!0,href:!0});var Ht=s(D);qe=n(Ht,"SPAN",{});var Ut=s(qe);f(ae.$$.fragment,Ut),Ut.forEach(a),Ht.forEach(a),Ka=u(ha),Se=n(ha,"SPAN",{});var Dt=s(Se);Qa=p(Dt,"Entrenar con un script"),Dt.forEach(a),ha.forEach(a),Ze=u(e),de=n(e,"P",{});var Lt=s(de);Va=p(Lt,"Si est\xE1s corriendo tu entrenamiento desde un script ejecuta el siguiente comando para crear y guardar un archivo de configuraci\xF3n:"),Lt.forEach(a),ea=u(e),f(te.$$.fragment,e),aa=u(e),ue=n(e,"P",{});var Ot=s(ue);Xa=p(Ot,"Comienza el entrenamiento con:"),Ot.forEach(a),ta=u(e),f(re.$$.fragment,e),ra=u(e),z=n(e,"H3",{class:!0});var va=s(z);L=n(va,"A",{id:!0,class:!0,href:!0});var Tt=s(L);Ne=n(Tt,"SPAN",{});var Bt=s(Ne);f(oe.$$.fragment,Bt),Bt.forEach(a),Tt.forEach(a),Ya=u(va),xe=n(va,"SPAN",{});var Gt=s(xe);Za=p(Gt,"Entrenar con un notebook"),Gt.forEach(a),va.forEach(a),oa=u(e),O=n(e,"P",{});var _a=s(O);et=p(_a,"\u{1F917} Accelerate puede correr en un notebook si, por ejemplo, est\xE1s planeando utilizar las TPUs de Colaboratory. Encierra el c\xF3digo responsable del entrenamiento en una funci\xF3n y p\xE1salo a "),He=n(_a,"CODE",{});var Mt=s(He);at=p(Mt,"notebook_launcher"),Mt.forEach(a),tt=p(_a,":"),_a.forEach(a),na=u(e),f(ne.$$.fragment,e),sa=u(e),T=n(e,"P",{});var $a=s(T);rt=p($a,"Para obtener m\xE1s informaci\xF3n sobre \u{1F917} Accelerate y sus numerosas funciones, consulta la "),se=n($a,"A",{href:!0,rel:!0});var Ft=s(se);ot=p(Ft,"documentaci\xF3n"),Ft.forEach(a),nt=p($a,"."),$a.forEach(a),this.h()},h(){i(w,"name","hf:doc:metadata"),i(w,"content",JSON.stringify(Xt)),i(C,"id","entrenamiento-distribuido-con-accelerate"),i(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(C,"href","#entrenamiento-distribuido-con-accelerate"),i(E,"class","relative group"),i(M,"href","https://huggingface.co/docs/accelerate/index.html"),i(M,"rel","nofollow"),i(S,"id","configuracin"),i(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(S,"href","#configuracin"),i(k,"class","relative group"),i(W,"href","https://huggingface.co/docs/accelerate/accelerator.html#accelerate.Accelerator"),i(W,"rel","nofollow"),i(N,"id","preprate-para-acelerar"),i(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(N,"href","#preprate-para-acelerar"),i(y,"class","relative group"),i(K,"href","https://huggingface.co/docs/accelerate/accelerator.html#accelerate.Accelerator.prepare"),i(K,"rel","nofollow"),i(H,"id","backward"),i(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(H,"href","#backward"),i(A,"class","relative group"),i(X,"href","https://huggingface.co/docs/accelerate/accelerator.html#accelerate.Accelerator.backward"),i(X,"rel","nofollow"),i(U,"id","entrenamiento"),i(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(U,"href","#entrenamiento"),i(P,"class","relative group"),i(D,"id","entrenar-con-un-script"),i(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(D,"href","#entrenar-con-un-script"),i(j,"class","relative group"),i(L,"id","entrenar-con-un-notebook"),i(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(L,"href","#entrenar-con-un-notebook"),i(z,"class","relative group"),i(se,"href","https://huggingface.co/docs/accelerate/index.html"),i(se,"rel","nofollow")},m(e,r){t(document.head,w),l(e,Ue,r),l(e,E,r),t(E,C),t(C,he),h(G,he,null),t(E,ba),t(E,ve),t(ve,ga),l(e,De,r),l(e,q,r),t(q,wa),t(q,M),t(M,Ea),t(q,ka),l(e,Le,r),l(e,k,r),t(k,S),t(S,_e),h(F,_e,null),t(k,ya),t(k,$e),t($e,Aa),l(e,Oe,r),l(e,ie,r),t(ie,Pa),l(e,Te,r),h(I,e,r),l(e,Be,r),l(e,b,r),t(b,ja),t(b,W),t(W,be),t(be,za),t(b,Ca),t(b,ge),t(ge,qa),t(b,Sa),l(e,Ge,r),h(J,e,r),l(e,Me,r),l(e,y,r),t(y,N),t(N,we),h(R,we,null),t(y,Na),t(y,Ee),t(Ee,xa),l(e,Fe,r),l(e,x,r),t(x,Ha),t(x,K),t(K,ke),t(ke,Ua),t(x,Da),l(e,Ie,r),h(Q,e,r),l(e,We,r),l(e,A,r),t(A,H),t(H,ye),h(V,ye,null),t(A,La),t(A,Ae),t(Ae,Oa),l(e,Je,r),l(e,g,r),t(g,Ta),t(g,Pe),t(Pe,Ba),t(g,Ga),t(g,X),t(X,je),t(je,Ma),t(g,Fa),l(e,Re,r),h(Y,e,r),l(e,Ke,r),l(e,ce,r),t(ce,Ia),l(e,Qe,r),h(Z,e,r),l(e,Ve,r),l(e,P,r),t(P,U),t(U,ze),h(ee,ze,null),t(P,Wa),t(P,Ce),t(Ce,Ja),l(e,Xe,r),l(e,pe,r),t(pe,Ra),l(e,Ye,r),l(e,j,r),t(j,D),t(D,qe),h(ae,qe,null),t(j,Ka),t(j,Se),t(Se,Qa),l(e,Ze,r),l(e,de,r),t(de,Va),l(e,ea,r),h(te,e,r),l(e,aa,r),l(e,ue,r),t(ue,Xa),l(e,ta,r),h(re,e,r),l(e,ra,r),l(e,z,r),t(z,L),t(L,Ne),h(oe,Ne,null),t(z,Ya),t(z,xe),t(xe,Za),l(e,oa,r),l(e,O,r),t(O,et),t(O,He),t(He,at),t(O,tt),l(e,na,r),h(ne,e,r),l(e,sa,r),l(e,T,r),t(T,rt),t(T,se),t(se,ot),t(T,nt),la=!0},p:Kt,i(e){la||(v(G.$$.fragment,e),v(F.$$.fragment,e),v(I.$$.fragment,e),v(J.$$.fragment,e),v(R.$$.fragment,e),v(Q.$$.fragment,e),v(V.$$.fragment,e),v(Y.$$.fragment,e),v(Z.$$.fragment,e),v(ee.$$.fragment,e),v(ae.$$.fragment,e),v(te.$$.fragment,e),v(re.$$.fragment,e),v(oe.$$.fragment,e),v(ne.$$.fragment,e),la=!0)},o(e){_(G.$$.fragment,e),_(F.$$.fragment,e),_(I.$$.fragment,e),_(J.$$.fragment,e),_(R.$$.fragment,e),_(Q.$$.fragment,e),_(V.$$.fragment,e),_(Y.$$.fragment,e),_(Z.$$.fragment,e),_(ee.$$.fragment,e),_(ae.$$.fragment,e),_(te.$$.fragment,e),_(re.$$.fragment,e),_(oe.$$.fragment,e),_(ne.$$.fragment,e),la=!1},d(e){a(w),e&&a(Ue),e&&a(E),$(G),e&&a(De),e&&a(q),e&&a(Le),e&&a(k),$(F),e&&a(Oe),e&&a(ie),e&&a(Te),$(I,e),e&&a(Be),e&&a(b),e&&a(Ge),$(J,e),e&&a(Me),e&&a(y),$(R),e&&a(Fe),e&&a(x),e&&a(Ie),$(Q,e),e&&a(We),e&&a(A),$(V),e&&a(Je),e&&a(g),e&&a(Re),$(Y,e),e&&a(Ke),e&&a(ce),e&&a(Qe),$(Z,e),e&&a(Ve),e&&a(P),$(ee),e&&a(Xe),e&&a(pe),e&&a(Ye),e&&a(j),$(ae),e&&a(Ze),e&&a(de),e&&a(ea),$(te,e),e&&a(aa),e&&a(ue),e&&a(ta),$(re,e),e&&a(ra),e&&a(z),$(oe),e&&a(oa),e&&a(O),e&&a(na),$(ne,e),e&&a(sa),e&&a(T)}}}const Xt={local:"entrenamiento-distribuido-con-accelerate",sections:[{local:"configuracin",title:"Configuraci\xF3n"},{local:"preprate-para-acelerar",title:"Prep\xE1rate para acelerar"},{local:"backward",title:"Backward"},{local:"entrenamiento",sections:[{local:"entrenar-con-un-script",title:"Entrenar con un script"},{local:"entrenar-con-un-notebook",title:"Entrenar con un notebook"}],title:"Entrenamiento"}],title:"Entrenamiento distribuido con \u{1F917} Accelerate"};function Yt(st){return Qt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tr extends It{constructor(w){super();Wt(this,w,Yt,Vt,Jt,{})}}export{tr as default,Xt as metadata};
