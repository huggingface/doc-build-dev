import{S as kLt,i as SLt,s as RLt,e as a,k as l,w as F,t as o,M as PLt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,F as e,g as b,y as M,q as E,o as C,B as w,v as BLt,L as I}from"../../chunks/vendor-6b77c823.js";import{T as IDr}from"../../chunks/Tip-39098574.js";import{D as R}from"../../chunks/Docstring-1088f2fb.js";import{C as P}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as re}from"../../chunks/IconCopyLink-7a11ce68.js";import{E as B}from"../../chunks/ExampleCodeBlock-5212b321.js";function ILt(L){let g,v,p,m,u,d,h,Mo,ci,hf,rt,fi,mi,s6,pf,De,We,gi,yn,l6,Ln,xn,i6,hi,$n,d6,pi,uf,Ca;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),ci=a("code"),hf=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),fi=a("code"),mi=o('"new-model"'),s6=o(")."),pf=l(),De=a("p"),We=o("Likewise, if your "),gi=a("code"),yn=o("NewModel"),l6=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),i6=o(`, make sure its
`),hi=a("code"),$n=o("config_class"),d6=o(` attribute is set to the same class you use when registering the model (here
`),pi=a("code"),uf=o("NewModelConfig"),Ca=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var y$=s(p);m=r(y$,"NewModelConfig"),y$.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var ui=s(d);h=r(ui,"PretrainedConfig"),ui.forEach(t),Mo=r(Ae,`, make sure its
`),ci=n(Ae,"CODE",{});var L$=s(ci);hf=r(L$,"model_type"),L$.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),fi=n(Ae,"CODE",{});var x$=s(fi);mi=r(x$,'"new-model"'),x$.forEach(t),s6=r(Ae,")."),Ae.forEach(t),pf=i(Qe),De=n(Qe,"P",{});var Eo=s(De);We=r(Eo,"Likewise, if your "),gi=n(Eo,"CODE",{});var wa=s(gi);yn=r(wa,"NewModel"),wa.forEach(t),l6=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var $$=s(Ln);xn=r($$,"PreTrainedModel"),$$.forEach(t),i6=r(Eo,`, make sure its
`),hi=n(Eo,"CODE",{});var _f=s(hi);$n=r(_f,"config_class"),_f.forEach(t),d6=r(Eo,` attribute is set to the same class you use when registering the model (here
`),pi=n(Eo,"CODE",{});var k$=s(pi);uf=r(k$,"NewModelConfig"),k$.forEach(t),Ca=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Mo),e(g,ci),e(ci,hf),e(g,rt),e(g,fi),e(fi,mi),e(g,s6),b(Qe,pf,Ae),b(Qe,De,Ae),e(De,We),e(De,gi),e(gi,yn),e(De,l6),e(De,Ln),e(Ln,xn),e(De,i6),e(De,hi),e(hi,$n),e(De,d6),e(De,pi),e(pi,uf),e(De,Ca)},d(Qe){Qe&&t(g),Qe&&t(pf),Qe&&t(De)}}}function qLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jLt(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function DLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GLt(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function OLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ULt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZLt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function e8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function o8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function r8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function t8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function a8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function n8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function s8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function l8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function i8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function d8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function c8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function f8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function m8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function g8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function h8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function p8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function u8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function b8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function v8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function F8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function T8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function M8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function E8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function C8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function w8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function A8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function y8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function L8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function x8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function k8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function S8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function R8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function P8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function B8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function I8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function q8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function N8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function j8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function D8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function G8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function O8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function V8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function X8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function z8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function W8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Q8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function H8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function U8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function J8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Y8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function K8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Z8t(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ext(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function txt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function axt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ixt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _xt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Txt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ext(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Axt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $xt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sxt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rxt(L){let g,v,p,m,u,d,h,Mo,ci,hf,rt,fi,mi,s6,pf,De,We,gi,yn,l6,Ln,xn,i6,hi,$n,d6,pi,uf,Ca,Qe,Ae,y$,ui,L$,x$,Eo,wa,$$,_f,k$,HDe,qIe,_i,bf,Cee,c6,UDe,wee,JDe,NIe,kn,YDe,Aee,KDe,ZDe,yee,eGe,oGe,jIe,f6,DIe,S$,rGe,GIe,vf,OIe,bi,Ff,Lee,m6,tGe,xee,aGe,VIe,Co,g6,nGe,h6,sGe,R$,lGe,iGe,dGe,p6,cGe,$ee,fGe,mGe,gGe,Er,u6,hGe,kee,pGe,uGe,vi,_Ge,See,bGe,vGe,Ree,FGe,TGe,MGe,A,Tf,Pee,EGe,CGe,P$,wGe,AGe,yGe,Mf,Bee,LGe,xGe,B$,$Ge,kGe,SGe,Ef,Iee,RGe,PGe,I$,BGe,IGe,qGe,Cf,qee,NGe,jGe,q$,DGe,GGe,OGe,wf,Nee,VGe,XGe,N$,zGe,WGe,QGe,Af,jee,HGe,UGe,j$,JGe,YGe,KGe,yf,Dee,ZGe,eOe,D$,oOe,rOe,tOe,Lf,Gee,aOe,nOe,G$,sOe,lOe,iOe,xf,Oee,dOe,cOe,O$,fOe,mOe,gOe,$f,Vee,hOe,pOe,V$,uOe,_Oe,bOe,kf,Xee,vOe,FOe,X$,TOe,MOe,EOe,Sf,zee,COe,wOe,z$,AOe,yOe,LOe,Rf,Wee,xOe,$Oe,W$,kOe,SOe,ROe,Pf,Qee,POe,BOe,Q$,IOe,qOe,NOe,Bf,Hee,jOe,DOe,H$,GOe,OOe,VOe,If,Uee,XOe,zOe,U$,WOe,QOe,HOe,qf,Jee,UOe,JOe,J$,YOe,KOe,ZOe,Nf,Yee,eVe,oVe,Y$,rVe,tVe,aVe,jf,Kee,nVe,sVe,K$,lVe,iVe,dVe,Df,Zee,cVe,fVe,Z$,mVe,gVe,hVe,Gf,eoe,pVe,uVe,ek,_Ve,bVe,vVe,Of,ooe,FVe,TVe,ok,MVe,EVe,CVe,Vf,roe,wVe,AVe,rk,yVe,LVe,xVe,Xf,toe,$Ve,kVe,tk,SVe,RVe,PVe,zf,aoe,BVe,IVe,ak,qVe,NVe,jVe,Wf,noe,DVe,GVe,nk,OVe,VVe,XVe,Qf,soe,zVe,WVe,sk,QVe,HVe,UVe,Hf,loe,JVe,YVe,lk,KVe,ZVe,eXe,Uf,ioe,oXe,rXe,ik,tXe,aXe,nXe,Jf,doe,sXe,lXe,dk,iXe,dXe,cXe,Yf,coe,fXe,mXe,ck,gXe,hXe,pXe,Kf,foe,uXe,_Xe,fk,bXe,vXe,FXe,Zf,moe,TXe,MXe,mk,EXe,CXe,wXe,em,goe,AXe,yXe,gk,LXe,xXe,$Xe,om,hoe,kXe,SXe,hk,RXe,PXe,BXe,rm,poe,IXe,qXe,pk,NXe,jXe,DXe,tm,uoe,GXe,OXe,uk,VXe,XXe,zXe,am,_oe,WXe,QXe,_k,HXe,UXe,JXe,nm,boe,YXe,KXe,bk,ZXe,eze,oze,sm,voe,rze,tze,vk,aze,nze,sze,lm,Foe,lze,ize,Fk,dze,cze,fze,im,Toe,mze,gze,Tk,hze,pze,uze,dm,Moe,_ze,bze,Mk,vze,Fze,Tze,cm,Eoe,Mze,Eze,Ek,Cze,wze,Aze,fm,Coe,yze,Lze,Ck,xze,$ze,kze,mm,woe,Sze,Rze,wk,Pze,Bze,Ize,gm,Aoe,qze,Nze,Ak,jze,Dze,Gze,hm,yoe,Oze,Vze,yk,Xze,zze,Wze,pm,Loe,Qze,Hze,Lk,Uze,Jze,Yze,um,xoe,Kze,Zze,xk,eWe,oWe,rWe,_m,$oe,tWe,aWe,$k,nWe,sWe,lWe,bm,koe,iWe,dWe,kk,cWe,fWe,mWe,vm,Soe,gWe,hWe,Sk,pWe,uWe,_We,Fm,Roe,bWe,vWe,Rk,FWe,TWe,MWe,Tm,Poe,EWe,CWe,Pk,wWe,AWe,yWe,Mm,Boe,LWe,xWe,Bk,$We,kWe,SWe,Em,Ioe,RWe,PWe,Ik,BWe,IWe,qWe,Cm,qoe,NWe,jWe,qk,DWe,GWe,OWe,wm,Noe,VWe,XWe,Nk,zWe,WWe,QWe,Am,joe,HWe,UWe,jk,JWe,YWe,KWe,ym,Doe,ZWe,eQe,Dk,oQe,rQe,tQe,Lm,Goe,aQe,nQe,Gk,sQe,lQe,iQe,xm,Ooe,dQe,cQe,Ok,fQe,mQe,gQe,$m,Voe,hQe,pQe,Vk,uQe,_Qe,bQe,km,Xoe,vQe,FQe,Xk,TQe,MQe,EQe,Sm,zoe,CQe,wQe,zk,AQe,yQe,LQe,Rm,Woe,xQe,$Qe,Wk,kQe,SQe,RQe,Pm,Qoe,PQe,BQe,Qk,IQe,qQe,NQe,Bm,Hoe,jQe,DQe,Hk,GQe,OQe,VQe,Im,Uoe,XQe,zQe,Uk,WQe,QQe,HQe,qm,Joe,UQe,JQe,Jk,YQe,KQe,ZQe,Nm,Yoe,eHe,oHe,Yk,rHe,tHe,aHe,jm,Koe,nHe,sHe,Kk,lHe,iHe,dHe,Dm,Zoe,cHe,fHe,Zk,mHe,gHe,hHe,Gm,ere,pHe,uHe,eS,_He,bHe,vHe,Om,ore,FHe,THe,oS,MHe,EHe,CHe,Vm,rre,wHe,AHe,rS,yHe,LHe,xHe,Xm,tre,$He,kHe,tS,SHe,RHe,PHe,zm,are,BHe,IHe,aS,qHe,NHe,jHe,Wm,nre,DHe,GHe,nS,OHe,VHe,XHe,Qm,sre,zHe,WHe,sS,QHe,HHe,UHe,Hm,lre,JHe,YHe,lS,KHe,ZHe,eUe,Um,ire,oUe,rUe,iS,tUe,aUe,nUe,Jm,dre,sUe,lUe,dS,iUe,dUe,cUe,Ym,cre,fUe,mUe,cS,gUe,hUe,pUe,Km,fre,uUe,_Ue,fS,bUe,vUe,FUe,Zm,mre,TUe,MUe,mS,EUe,CUe,wUe,eg,gre,AUe,yUe,gS,LUe,xUe,$Ue,og,hre,kUe,SUe,hS,RUe,PUe,BUe,rg,pre,IUe,qUe,pS,NUe,jUe,DUe,tg,ure,GUe,OUe,uS,VUe,XUe,zUe,ag,_re,WUe,QUe,_S,HUe,UUe,JUe,ng,bre,YUe,KUe,bS,ZUe,eJe,oJe,sg,vre,rJe,tJe,vS,aJe,nJe,sJe,lg,Fre,lJe,iJe,FS,dJe,cJe,fJe,ig,Tre,mJe,gJe,TS,hJe,pJe,uJe,dg,Mre,_Je,bJe,MS,vJe,FJe,TJe,cg,Ere,MJe,EJe,ES,CJe,wJe,AJe,fg,Cre,yJe,LJe,CS,xJe,$Je,kJe,mg,wre,SJe,RJe,wS,PJe,BJe,IJe,gg,Are,qJe,NJe,AS,jJe,DJe,GJe,hg,yre,OJe,VJe,yS,XJe,zJe,WJe,pg,Lre,QJe,HJe,LS,UJe,JJe,YJe,ug,xre,KJe,ZJe,xS,eYe,oYe,rYe,_g,$re,tYe,aYe,$S,nYe,sYe,lYe,bg,iYe,vg,_6,dYe,kre,cYe,XIe,Fi,Fg,Sre,b6,fYe,Rre,mYe,zIe,wo,v6,gYe,F6,hYe,kS,pYe,uYe,_Ye,T6,bYe,Pre,vYe,FYe,TYe,Cr,M6,MYe,Bre,EYe,CYe,Aa,wYe,Ire,AYe,yYe,qre,LYe,xYe,Nre,$Ye,kYe,SYe,k,Sn,jre,RYe,PYe,SS,BYe,IYe,RS,qYe,NYe,jYe,Rn,Dre,DYe,GYe,PS,OYe,VYe,BS,XYe,zYe,WYe,Pn,Gre,QYe,HYe,IS,UYe,JYe,qS,YYe,KYe,ZYe,Tg,Ore,eKe,oKe,NS,rKe,tKe,aKe,Bn,Vre,nKe,sKe,jS,lKe,iKe,DS,dKe,cKe,fKe,Mg,Xre,mKe,gKe,GS,hKe,pKe,uKe,Eg,zre,_Ke,bKe,OS,vKe,FKe,TKe,Cg,Wre,MKe,EKe,VS,CKe,wKe,AKe,In,Qre,yKe,LKe,XS,xKe,$Ke,zS,kKe,SKe,RKe,qn,Hre,PKe,BKe,WS,IKe,qKe,QS,NKe,jKe,DKe,Nn,Ure,GKe,OKe,HS,VKe,XKe,US,zKe,WKe,QKe,wg,Jre,HKe,UKe,JS,JKe,YKe,KKe,Ag,Yre,ZKe,eZe,YS,oZe,rZe,tZe,jn,Kre,aZe,nZe,KS,sZe,lZe,ZS,iZe,dZe,cZe,yg,Zre,fZe,mZe,eR,gZe,hZe,pZe,Dn,ete,uZe,_Ze,oR,bZe,vZe,rR,FZe,TZe,MZe,Gn,ote,EZe,CZe,tR,wZe,AZe,aR,yZe,LZe,xZe,On,rte,$Ze,kZe,nR,SZe,RZe,sR,PZe,BZe,IZe,Lg,tte,qZe,NZe,lR,jZe,DZe,GZe,Vn,ate,OZe,VZe,iR,XZe,zZe,dR,WZe,QZe,HZe,Xn,nte,UZe,JZe,cR,YZe,KZe,fR,ZZe,eeo,oeo,zn,ste,reo,teo,mR,aeo,neo,gR,seo,leo,ieo,Wn,lte,deo,ceo,hR,feo,meo,pR,geo,heo,peo,Qn,ite,ueo,_eo,uR,beo,veo,_R,Feo,Teo,Meo,Hn,dte,Eeo,Ceo,bR,weo,Aeo,vR,yeo,Leo,xeo,xg,cte,$eo,keo,FR,Seo,Reo,Peo,Un,fte,Beo,Ieo,TR,qeo,Neo,MR,jeo,Deo,Geo,$g,mte,Oeo,Veo,ER,Xeo,zeo,Weo,Jn,gte,Qeo,Heo,CR,Ueo,Jeo,wR,Yeo,Keo,Zeo,Yn,hte,eoo,ooo,AR,roo,too,yR,aoo,noo,soo,Kn,pte,loo,ioo,LR,doo,coo,xR,foo,moo,goo,Zn,ute,hoo,poo,$R,uoo,_oo,kR,boo,voo,Foo,es,_te,Too,Moo,SR,Eoo,Coo,RR,woo,Aoo,yoo,kg,bte,Loo,xoo,PR,$oo,koo,Soo,os,vte,Roo,Poo,BR,Boo,Ioo,IR,qoo,Noo,joo,rs,Fte,Doo,Goo,qR,Ooo,Voo,NR,Xoo,zoo,Woo,ts,Tte,Qoo,Hoo,jR,Uoo,Joo,DR,Yoo,Koo,Zoo,as,Mte,ero,oro,GR,rro,tro,OR,aro,nro,sro,ns,Ete,lro,iro,VR,dro,cro,XR,fro,mro,gro,ss,Cte,hro,pro,zR,uro,_ro,WR,bro,vro,Fro,Sg,wte,Tro,Mro,QR,Ero,Cro,wro,ls,Ate,Aro,yro,HR,Lro,xro,UR,$ro,kro,Sro,Rg,yte,Rro,Pro,JR,Bro,Iro,qro,Pg,Lte,Nro,jro,YR,Dro,Gro,Oro,is,xte,Vro,Xro,KR,zro,Wro,ZR,Qro,Hro,Uro,ds,$te,Jro,Yro,eP,Kro,Zro,oP,eto,oto,rto,cs,kte,tto,ato,rP,nto,sto,tP,lto,ito,dto,Bg,Ste,cto,fto,aP,mto,gto,hto,fs,Rte,pto,uto,nP,_to,bto,sP,vto,Fto,Tto,ms,Pte,Mto,Eto,lP,Cto,wto,iP,Ato,yto,Lto,gs,Bte,xto,$to,dP,kto,Sto,cP,Rto,Pto,Bto,hs,Ite,Ito,qto,fP,Nto,jto,mP,Dto,Gto,Oto,ps,qte,Vto,Xto,gP,zto,Wto,hP,Qto,Hto,Uto,Ig,Nte,Jto,Yto,pP,Kto,Zto,eao,us,jte,oao,rao,uP,tao,aao,_P,nao,sao,lao,qg,Dte,iao,dao,bP,cao,fao,mao,Ng,Gte,gao,hao,vP,pao,uao,_ao,jg,Ote,bao,vao,FP,Fao,Tao,Mao,Dg,Vte,Eao,Cao,TP,wao,Aao,yao,_s,Xte,Lao,xao,MP,$ao,kao,EP,Sao,Rao,Pao,Gg,zte,Bao,Iao,CP,qao,Nao,jao,bs,Wte,Dao,Gao,wP,Oao,Vao,AP,Xao,zao,Wao,vs,Qte,Qao,Hao,yP,Uao,Jao,LP,Yao,Kao,Zao,Fs,Hte,eno,ono,xP,rno,tno,$P,ano,nno,sno,Ts,Ute,lno,ino,kP,dno,cno,SP,fno,mno,gno,Ms,Jte,hno,pno,RP,uno,_no,PP,bno,vno,Fno,Es,Yte,Tno,Mno,BP,Eno,Cno,IP,wno,Ano,yno,Og,Kte,Lno,xno,qP,$no,kno,Sno,Vg,Zte,Rno,Pno,NP,Bno,Ino,qno,Cs,eae,Nno,jno,jP,Dno,Gno,DP,Ono,Vno,Xno,ws,oae,zno,Wno,GP,Qno,Hno,OP,Uno,Jno,Yno,As,rae,Kno,Zno,VP,eso,oso,XP,rso,tso,aso,Xg,tae,nso,sso,zP,lso,iso,dso,zg,aae,cso,fso,WP,mso,gso,hso,Wg,nae,pso,uso,QP,_so,bso,vso,ys,sae,Fso,Tso,HP,Mso,Eso,UP,Cso,wso,Aso,Qg,lae,yso,Lso,JP,xso,$so,kso,Hg,iae,Sso,Rso,YP,Pso,Bso,Iso,Ug,dae,qso,Nso,KP,jso,Dso,Gso,Ls,cae,Oso,Vso,ZP,Xso,zso,eB,Wso,Qso,Hso,Jg,fae,Uso,Jso,oB,Yso,Kso,Zso,Yg,mae,elo,olo,rB,rlo,tlo,alo,xs,gae,nlo,slo,tB,llo,ilo,aB,dlo,clo,flo,$s,hae,mlo,glo,nB,hlo,plo,sB,ulo,_lo,blo,ks,pae,vlo,Flo,lB,Tlo,Mlo,iB,Elo,Clo,wlo,Ss,uae,Alo,ylo,dB,Llo,xlo,cB,$lo,klo,Slo,Kg,Rlo,Zg,E6,Plo,_ae,Blo,WIe,Ti,eh,bae,C6,Ilo,vae,qlo,QIe,Ao,w6,Nlo,A6,jlo,fB,Dlo,Glo,Olo,y6,Vlo,Fae,Xlo,zlo,Wlo,He,L6,Qlo,Tae,Hlo,Ulo,ya,Jlo,Mae,Ylo,Klo,Eae,Zlo,eio,Cae,oio,rio,tio,Z,oh,wae,aio,nio,mB,sio,lio,iio,rh,Aae,dio,cio,gB,fio,mio,gio,th,yae,hio,pio,hB,uio,_io,bio,ah,Lae,vio,Fio,pB,Tio,Mio,Eio,nh,xae,Cio,wio,uB,Aio,yio,Lio,sh,$ae,xio,$io,_B,kio,Sio,Rio,lh,kae,Pio,Bio,bB,Iio,qio,Nio,ih,Sae,jio,Dio,vB,Gio,Oio,Vio,dh,Rae,Xio,zio,FB,Wio,Qio,Hio,ch,Pae,Uio,Jio,TB,Yio,Kio,Zio,fh,Bae,edo,odo,MB,rdo,tdo,ado,mh,Iae,ndo,sdo,EB,ldo,ido,ddo,gh,qae,cdo,fdo,CB,mdo,gdo,hdo,hh,Nae,pdo,udo,wB,_do,bdo,vdo,ph,jae,Fdo,Tdo,AB,Mdo,Edo,Cdo,uh,Dae,wdo,Ado,yB,ydo,Ldo,xdo,_h,Gae,$do,kdo,LB,Sdo,Rdo,Pdo,bh,Oae,Bdo,Ido,xB,qdo,Ndo,jdo,vh,Vae,Ddo,Gdo,$B,Odo,Vdo,Xdo,Fh,Xae,zdo,Wdo,kB,Qdo,Hdo,Udo,Th,zae,Jdo,Ydo,SB,Kdo,Zdo,eco,Mh,Wae,oco,rco,RB,tco,aco,nco,Eh,Qae,sco,lco,PB,ico,dco,cco,Ch,Hae,fco,mco,BB,gco,hco,pco,wh,Uae,uco,_co,IB,bco,vco,Fco,Ah,Jae,Tco,Mco,qB,Eco,Cco,wco,yh,Aco,Lh,yco,xh,x6,Lco,Yae,xco,HIe,Mi,$h,Kae,$6,$co,Zae,kco,UIe,yo,k6,Sco,S6,Rco,NB,Pco,Bco,Ico,R6,qco,ene,Nco,jco,Dco,Ue,P6,Gco,one,Oco,Vco,Ei,Xco,rne,zco,Wco,tne,Qco,Hco,Uco,pe,kh,ane,Jco,Yco,jB,Kco,Zco,efo,Sh,nne,ofo,rfo,sne,tfo,afo,nfo,Rh,lne,sfo,lfo,DB,ifo,dfo,cfo,Ph,ine,ffo,mfo,GB,gfo,hfo,pfo,Bh,dne,ufo,_fo,OB,bfo,vfo,Ffo,Ih,cne,Tfo,Mfo,VB,Efo,Cfo,wfo,qh,fne,Afo,yfo,XB,Lfo,xfo,$fo,Nh,mne,kfo,Sfo,zB,Rfo,Pfo,Bfo,jh,gne,Ifo,qfo,WB,Nfo,jfo,Dfo,Dh,hne,Gfo,Ofo,QB,Vfo,Xfo,zfo,Gh,pne,Wfo,Qfo,HB,Hfo,Ufo,Jfo,Oh,une,Yfo,Kfo,UB,Zfo,emo,omo,Vh,_ne,rmo,tmo,JB,amo,nmo,smo,Xh,bne,lmo,imo,YB,dmo,cmo,fmo,zh,vne,mmo,gmo,KB,hmo,pmo,umo,Wh,Fne,_mo,bmo,ZB,vmo,Fmo,Tmo,Qh,Mmo,Hh,Emo,Uh,B6,Cmo,Tne,wmo,JIe,Ci,Jh,Mne,I6,Amo,Ene,ymo,YIe,Lo,q6,Lmo,wi,xmo,eI,$mo,kmo,oI,Smo,Rmo,Pmo,N6,Bmo,Cne,Imo,qmo,Nmo,tt,j6,jmo,wne,Dmo,Gmo,Ai,Omo,Ane,Vmo,Xmo,rI,zmo,Wmo,Qmo,Yh,Hmo,Je,D6,Umo,yne,Jmo,Ymo,La,Kmo,Lne,Zmo,ego,xne,ogo,rgo,$ne,tgo,ago,ngo,x,Kh,kne,sgo,lgo,tI,igo,dgo,cgo,Zh,Sne,fgo,mgo,aI,ggo,hgo,pgo,ep,Rne,ugo,_go,nI,bgo,vgo,Fgo,op,Pne,Tgo,Mgo,sI,Ego,Cgo,wgo,rp,Bne,Ago,ygo,lI,Lgo,xgo,$go,tp,Ine,kgo,Sgo,iI,Rgo,Pgo,Bgo,ap,qne,Igo,qgo,dI,Ngo,jgo,Dgo,np,Nne,Ggo,Ogo,cI,Vgo,Xgo,zgo,sp,jne,Wgo,Qgo,fI,Hgo,Ugo,Jgo,lp,Dne,Ygo,Kgo,mI,Zgo,eho,oho,ip,Gne,rho,tho,gI,aho,nho,sho,dp,One,lho,iho,hI,dho,cho,fho,cp,Vne,mho,gho,pI,hho,pho,uho,fp,Xne,_ho,bho,uI,vho,Fho,Tho,mp,zne,Mho,Eho,_I,Cho,who,Aho,gp,Wne,yho,Lho,bI,xho,$ho,kho,hp,Qne,Sho,Rho,vI,Pho,Bho,Iho,pp,Hne,qho,Nho,FI,jho,Dho,Gho,up,Une,Oho,Vho,TI,Xho,zho,Who,_p,Jne,Qho,Hho,MI,Uho,Jho,Yho,bp,Yne,Kho,Zho,EI,epo,opo,rpo,vp,Kne,tpo,apo,CI,npo,spo,lpo,Fp,Zne,ipo,dpo,wI,cpo,fpo,mpo,Tp,ese,gpo,hpo,AI,ppo,upo,_po,Mp,ose,bpo,vpo,yI,Fpo,Tpo,Mpo,Ep,rse,Epo,Cpo,LI,wpo,Apo,ypo,Cp,tse,Lpo,xpo,xI,$po,kpo,Spo,wp,ase,Rpo,Ppo,$I,Bpo,Ipo,qpo,Ap,nse,Npo,jpo,kI,Dpo,Gpo,Opo,yp,sse,Vpo,Xpo,SI,zpo,Wpo,Qpo,Lp,lse,Hpo,Upo,RI,Jpo,Ypo,Kpo,Rs,ise,Zpo,euo,PI,ouo,ruo,BI,tuo,auo,nuo,xp,dse,suo,luo,II,iuo,duo,cuo,$p,cse,fuo,muo,qI,guo,huo,puo,kp,fse,uuo,_uo,NI,buo,vuo,Fuo,Sp,mse,Tuo,Muo,jI,Euo,Cuo,wuo,Rp,gse,Auo,yuo,DI,Luo,xuo,$uo,Pp,hse,kuo,Suo,GI,Ruo,Puo,Buo,Bp,pse,Iuo,quo,OI,Nuo,juo,Duo,Ip,use,Guo,Ouo,VI,Vuo,Xuo,zuo,qp,_se,Wuo,Quo,XI,Huo,Uuo,Juo,Np,bse,Yuo,Kuo,zI,Zuo,e_o,o_o,jp,vse,r_o,t_o,WI,a_o,n_o,s_o,Dp,Fse,l_o,i_o,QI,d_o,c_o,f_o,Gp,Tse,m_o,g_o,HI,h_o,p_o,u_o,Op,Mse,__o,b_o,UI,v_o,F_o,T_o,Vp,Ese,M_o,E_o,JI,C_o,w_o,A_o,Xp,Cse,y_o,L_o,YI,x_o,$_o,k_o,zp,wse,S_o,R_o,KI,P_o,B_o,I_o,Wp,Ase,q_o,N_o,ZI,j_o,D_o,G_o,Qp,yse,O_o,V_o,eq,X_o,z_o,W_o,Hp,Lse,Q_o,H_o,oq,U_o,J_o,Y_o,Up,xse,K_o,Z_o,rq,e2o,o2o,r2o,Jp,$se,t2o,a2o,tq,n2o,s2o,l2o,Yp,kse,i2o,d2o,aq,c2o,f2o,m2o,Kp,Sse,g2o,h2o,nq,p2o,u2o,_2o,Zp,Rse,b2o,v2o,sq,F2o,T2o,M2o,eu,Pse,E2o,C2o,lq,w2o,A2o,y2o,ou,Bse,L2o,x2o,iq,$2o,k2o,S2o,ru,Ise,R2o,P2o,dq,B2o,I2o,q2o,tu,qse,N2o,j2o,cq,D2o,G2o,O2o,au,Nse,V2o,X2o,fq,z2o,W2o,Q2o,nu,jse,H2o,U2o,mq,J2o,Y2o,K2o,su,Dse,Z2o,e1o,gq,o1o,r1o,t1o,lu,Gse,a1o,n1o,hq,s1o,l1o,i1o,iu,Ose,d1o,c1o,pq,f1o,m1o,g1o,du,Vse,h1o,p1o,uq,u1o,_1o,b1o,cu,Xse,v1o,F1o,_q,T1o,M1o,E1o,fu,zse,C1o,w1o,bq,A1o,y1o,L1o,mu,Wse,x1o,$1o,vq,k1o,S1o,R1o,gu,Qse,P1o,B1o,Fq,I1o,q1o,N1o,hu,Hse,j1o,D1o,Tq,G1o,O1o,V1o,pu,Use,X1o,z1o,Mq,W1o,Q1o,H1o,uu,Jse,U1o,J1o,Eq,Y1o,K1o,Z1o,_u,Yse,e7o,o7o,Cq,r7o,t7o,a7o,bu,Kse,n7o,s7o,wq,l7o,i7o,d7o,vu,Zse,c7o,f7o,Aq,m7o,g7o,h7o,Fu,ele,p7o,u7o,yq,_7o,b7o,v7o,Tu,ole,F7o,T7o,Lq,M7o,E7o,C7o,Mu,rle,w7o,A7o,xq,y7o,L7o,x7o,Eu,tle,$7o,k7o,$q,S7o,R7o,P7o,Cu,ale,B7o,I7o,kq,q7o,N7o,j7o,wu,nle,D7o,G7o,Sq,O7o,V7o,X7o,Au,sle,z7o,W7o,Rq,Q7o,H7o,U7o,yu,lle,J7o,Y7o,Pq,K7o,Z7o,ebo,Lu,ile,obo,rbo,Bq,tbo,abo,nbo,xu,dle,sbo,lbo,Iq,ibo,dbo,cbo,$u,cle,fbo,mbo,qq,gbo,hbo,pbo,ku,fle,ubo,_bo,Nq,bbo,vbo,Fbo,Su,mle,Tbo,Mbo,jq,Ebo,Cbo,wbo,Ru,gle,Abo,ybo,Dq,Lbo,xbo,$bo,Pu,hle,kbo,Sbo,Gq,Rbo,Pbo,Bbo,Bu,ple,Ibo,qbo,Oq,Nbo,jbo,Dbo,Iu,ule,Gbo,Obo,Vq,Vbo,Xbo,zbo,qu,_le,Wbo,Qbo,Xq,Hbo,Ubo,Jbo,Nu,ble,Ybo,Kbo,zq,Zbo,evo,ovo,ju,vle,rvo,tvo,Wq,avo,nvo,svo,Du,Fle,lvo,ivo,Qq,dvo,cvo,fvo,Gu,mvo,Tle,gvo,hvo,Mle,pvo,uvo,Ou,KIe,yi,Vu,Ele,G6,_vo,Cle,bvo,ZIe,xo,O6,vvo,Li,Fvo,Hq,Tvo,Mvo,Uq,Evo,Cvo,wvo,V6,Avo,wle,yvo,Lvo,xvo,at,X6,$vo,Ale,kvo,Svo,xi,Rvo,yle,Pvo,Bvo,Jq,Ivo,qvo,Nvo,Xu,jvo,Ye,z6,Dvo,Lle,Gvo,Ovo,xa,Vvo,xle,Xvo,zvo,$le,Wvo,Qvo,kle,Hvo,Uvo,Jvo,G,zu,Sle,Yvo,Kvo,Yq,Zvo,eFo,oFo,Wu,Rle,rFo,tFo,Kq,aFo,nFo,sFo,Qu,Ple,lFo,iFo,Zq,dFo,cFo,fFo,Hu,Ble,mFo,gFo,eN,hFo,pFo,uFo,Uu,Ile,_Fo,bFo,oN,vFo,FFo,TFo,Ju,qle,MFo,EFo,rN,CFo,wFo,AFo,Yu,Nle,yFo,LFo,tN,xFo,$Fo,kFo,Ku,jle,SFo,RFo,aN,PFo,BFo,IFo,Zu,Dle,qFo,NFo,nN,jFo,DFo,GFo,e_,Gle,OFo,VFo,sN,XFo,zFo,WFo,o_,Ole,QFo,HFo,lN,UFo,JFo,YFo,r_,Vle,KFo,ZFo,iN,eTo,oTo,rTo,t_,Xle,tTo,aTo,dN,nTo,sTo,lTo,a_,zle,iTo,dTo,cN,cTo,fTo,mTo,n_,Wle,gTo,hTo,fN,pTo,uTo,_To,s_,Qle,bTo,vTo,mN,FTo,TTo,MTo,l_,Hle,ETo,CTo,gN,wTo,ATo,yTo,i_,Ule,LTo,xTo,hN,$To,kTo,STo,d_,Jle,RTo,PTo,pN,BTo,ITo,qTo,c_,Yle,NTo,jTo,uN,DTo,GTo,OTo,f_,Kle,VTo,XTo,_N,zTo,WTo,QTo,m_,Zle,HTo,UTo,bN,JTo,YTo,KTo,g_,eie,ZTo,eMo,vN,oMo,rMo,tMo,h_,oie,aMo,nMo,FN,sMo,lMo,iMo,p_,rie,dMo,cMo,TN,fMo,mMo,gMo,u_,tie,hMo,pMo,MN,uMo,_Mo,bMo,__,aie,vMo,FMo,EN,TMo,MMo,EMo,b_,nie,CMo,wMo,CN,AMo,yMo,LMo,v_,sie,xMo,$Mo,wN,kMo,SMo,RMo,F_,lie,PMo,BMo,AN,IMo,qMo,NMo,T_,iie,jMo,DMo,yN,GMo,OMo,VMo,M_,die,XMo,zMo,LN,WMo,QMo,HMo,E_,cie,UMo,JMo,xN,YMo,KMo,ZMo,C_,fie,e4o,o4o,$N,r4o,t4o,a4o,w_,mie,n4o,s4o,kN,l4o,i4o,d4o,A_,gie,c4o,f4o,SN,m4o,g4o,h4o,y_,hie,p4o,u4o,RN,_4o,b4o,v4o,L_,pie,F4o,T4o,PN,M4o,E4o,C4o,x_,uie,w4o,A4o,BN,y4o,L4o,x4o,$_,_ie,$4o,k4o,IN,S4o,R4o,P4o,k_,bie,B4o,I4o,qN,q4o,N4o,j4o,S_,D4o,vie,G4o,O4o,Fie,V4o,X4o,R_,eqe,$i,P_,Tie,W6,z4o,Mie,W4o,oqe,$o,Q6,Q4o,ki,H4o,NN,U4o,J4o,jN,Y4o,K4o,Z4o,H6,eEo,Eie,oEo,rEo,tEo,nt,U6,aEo,Cie,nEo,sEo,Si,lEo,wie,iEo,dEo,DN,cEo,fEo,mEo,B_,gEo,Ke,J6,hEo,Aie,pEo,uEo,$a,_Eo,yie,bEo,vEo,Lie,FEo,TEo,xie,MEo,EEo,CEo,z,I_,$ie,wEo,AEo,GN,yEo,LEo,xEo,q_,kie,$Eo,kEo,ON,SEo,REo,PEo,N_,Sie,BEo,IEo,VN,qEo,NEo,jEo,j_,Rie,DEo,GEo,XN,OEo,VEo,XEo,D_,Pie,zEo,WEo,zN,QEo,HEo,UEo,G_,Bie,JEo,YEo,WN,KEo,ZEo,eCo,O_,Iie,oCo,rCo,QN,tCo,aCo,nCo,V_,qie,sCo,lCo,HN,iCo,dCo,cCo,X_,Nie,fCo,mCo,UN,gCo,hCo,pCo,z_,jie,uCo,_Co,JN,bCo,vCo,FCo,W_,Die,TCo,MCo,YN,ECo,CCo,wCo,Q_,Gie,ACo,yCo,KN,LCo,xCo,$Co,H_,Oie,kCo,SCo,ZN,RCo,PCo,BCo,U_,Vie,ICo,qCo,ej,NCo,jCo,DCo,J_,Xie,GCo,OCo,oj,VCo,XCo,zCo,Y_,zie,WCo,QCo,rj,HCo,UCo,JCo,K_,Wie,YCo,KCo,tj,ZCo,e5o,o5o,Z_,Qie,r5o,t5o,aj,a5o,n5o,s5o,e2,Hie,l5o,i5o,nj,d5o,c5o,f5o,o2,Uie,m5o,g5o,sj,h5o,p5o,u5o,r2,Jie,_5o,b5o,lj,v5o,F5o,T5o,t2,Yie,M5o,E5o,ij,C5o,w5o,A5o,a2,Kie,y5o,L5o,dj,x5o,$5o,k5o,n2,Zie,S5o,R5o,cj,P5o,B5o,I5o,s2,ede,q5o,N5o,fj,j5o,D5o,G5o,l2,ode,O5o,V5o,mj,X5o,z5o,W5o,i2,rde,Q5o,H5o,gj,U5o,J5o,Y5o,d2,tde,K5o,Z5o,hj,e3o,o3o,r3o,c2,ade,t3o,a3o,pj,n3o,s3o,l3o,f2,nde,i3o,d3o,uj,c3o,f3o,m3o,m2,sde,g3o,h3o,_j,p3o,u3o,_3o,g2,lde,b3o,v3o,bj,F3o,T3o,M3o,h2,ide,E3o,C3o,vj,w3o,A3o,y3o,p2,dde,L3o,x3o,Fj,$3o,k3o,S3o,u2,cde,R3o,P3o,Tj,B3o,I3o,q3o,_2,fde,N3o,j3o,Mj,D3o,G3o,O3o,b2,V3o,mde,X3o,z3o,gde,W3o,Q3o,v2,rqe,Ri,F2,hde,Y6,H3o,pde,U3o,tqe,ko,K6,J3o,Pi,Y3o,Ej,K3o,Z3o,Cj,ewo,owo,rwo,Z6,two,ude,awo,nwo,swo,st,ey,lwo,_de,iwo,dwo,Bi,cwo,bde,fwo,mwo,wj,gwo,hwo,pwo,T2,uwo,Ze,oy,_wo,vde,bwo,vwo,ka,Fwo,Fde,Two,Mwo,Tde,Ewo,Cwo,Mde,wwo,Awo,ywo,W,M2,Ede,Lwo,xwo,Aj,$wo,kwo,Swo,E2,Cde,Rwo,Pwo,yj,Bwo,Iwo,qwo,C2,wde,Nwo,jwo,Lj,Dwo,Gwo,Owo,w2,Ade,Vwo,Xwo,xj,zwo,Wwo,Qwo,A2,yde,Hwo,Uwo,$j,Jwo,Ywo,Kwo,y2,Lde,Zwo,eAo,kj,oAo,rAo,tAo,L2,xde,aAo,nAo,Sj,sAo,lAo,iAo,x2,$de,dAo,cAo,Rj,fAo,mAo,gAo,$2,kde,hAo,pAo,Pj,uAo,_Ao,bAo,k2,Sde,vAo,FAo,Bj,TAo,MAo,EAo,S2,Rde,CAo,wAo,Ij,AAo,yAo,LAo,R2,Pde,xAo,$Ao,qj,kAo,SAo,RAo,P2,Bde,PAo,BAo,Nj,IAo,qAo,NAo,B2,Ide,jAo,DAo,jj,GAo,OAo,VAo,I2,qde,XAo,zAo,Dj,WAo,QAo,HAo,q2,Nde,UAo,JAo,Gj,YAo,KAo,ZAo,N2,jde,e0o,o0o,Oj,r0o,t0o,a0o,j2,Dde,n0o,s0o,Vj,l0o,i0o,d0o,D2,Gde,c0o,f0o,Xj,m0o,g0o,h0o,G2,Ode,p0o,u0o,zj,_0o,b0o,v0o,O2,Vde,F0o,T0o,Wj,M0o,E0o,C0o,V2,Xde,w0o,A0o,Qj,y0o,L0o,x0o,X2,zde,$0o,k0o,Hj,S0o,R0o,P0o,z2,Wde,B0o,I0o,Uj,q0o,N0o,j0o,W2,Qde,D0o,G0o,Jj,O0o,V0o,X0o,Q2,Hde,z0o,W0o,Yj,Q0o,H0o,U0o,H2,Ude,J0o,Y0o,Kj,K0o,Z0o,e6o,U2,Jde,o6o,r6o,Zj,t6o,a6o,n6o,J2,Yde,s6o,l6o,eD,i6o,d6o,c6o,Y2,Kde,f6o,m6o,oD,g6o,h6o,p6o,K2,Zde,u6o,_6o,ece,b6o,v6o,F6o,Z2,oce,T6o,M6o,rD,E6o,C6o,w6o,e1,rce,A6o,y6o,tD,L6o,x6o,$6o,o1,tce,k6o,S6o,aD,R6o,P6o,B6o,r1,ace,I6o,q6o,nD,N6o,j6o,D6o,t1,G6o,nce,O6o,V6o,sce,X6o,z6o,a1,aqe,Ii,n1,lce,ry,W6o,ice,Q6o,nqe,So,ty,H6o,qi,U6o,sD,J6o,Y6o,lD,K6o,Z6o,eyo,ay,oyo,dce,ryo,tyo,ayo,lt,ny,nyo,cce,syo,lyo,Ni,iyo,fce,dyo,cyo,iD,fyo,myo,gyo,s1,hyo,eo,sy,pyo,mce,uyo,_yo,Sa,byo,gce,vyo,Fyo,hce,Tyo,Myo,pce,Eyo,Cyo,wyo,ue,l1,uce,Ayo,yyo,dD,Lyo,xyo,$yo,i1,_ce,kyo,Syo,cD,Ryo,Pyo,Byo,d1,bce,Iyo,qyo,fD,Nyo,jyo,Dyo,c1,vce,Gyo,Oyo,mD,Vyo,Xyo,zyo,f1,Fce,Wyo,Qyo,gD,Hyo,Uyo,Jyo,m1,Tce,Yyo,Kyo,hD,Zyo,eLo,oLo,g1,Mce,rLo,tLo,pD,aLo,nLo,sLo,h1,Ece,lLo,iLo,uD,dLo,cLo,fLo,p1,Cce,mLo,gLo,_D,hLo,pLo,uLo,u1,wce,_Lo,bLo,bD,vLo,FLo,TLo,_1,Ace,MLo,ELo,vD,CLo,wLo,ALo,b1,yce,yLo,LLo,FD,xLo,$Lo,kLo,v1,Lce,SLo,RLo,TD,PLo,BLo,ILo,F1,xce,qLo,NLo,MD,jLo,DLo,GLo,T1,$ce,OLo,VLo,ED,XLo,zLo,WLo,M1,kce,QLo,HLo,CD,ULo,JLo,YLo,E1,KLo,Sce,ZLo,e8o,Rce,o8o,r8o,C1,sqe,ji,w1,Pce,ly,t8o,Bce,a8o,lqe,Ro,iy,n8o,Di,s8o,wD,l8o,i8o,AD,d8o,c8o,f8o,dy,m8o,Ice,g8o,h8o,p8o,it,cy,u8o,qce,_8o,b8o,Gi,v8o,Nce,F8o,T8o,yD,M8o,E8o,C8o,A1,w8o,oo,fy,A8o,jce,y8o,L8o,Ra,x8o,Dce,$8o,k8o,Gce,S8o,R8o,Oce,P8o,B8o,I8o,N,y1,Vce,q8o,N8o,LD,j8o,D8o,G8o,L1,Xce,O8o,V8o,xD,X8o,z8o,W8o,x1,zce,Q8o,H8o,$D,U8o,J8o,Y8o,$1,Wce,K8o,Z8o,kD,exo,oxo,rxo,k1,Qce,txo,axo,SD,nxo,sxo,lxo,S1,Hce,ixo,dxo,RD,cxo,fxo,mxo,R1,Uce,gxo,hxo,PD,pxo,uxo,_xo,P1,Jce,bxo,vxo,BD,Fxo,Txo,Mxo,B1,Yce,Exo,Cxo,ID,wxo,Axo,yxo,I1,Kce,Lxo,xxo,qD,$xo,kxo,Sxo,q1,Zce,Rxo,Pxo,ND,Bxo,Ixo,qxo,N1,efe,Nxo,jxo,jD,Dxo,Gxo,Oxo,j1,ofe,Vxo,Xxo,DD,zxo,Wxo,Qxo,D1,rfe,Hxo,Uxo,GD,Jxo,Yxo,Kxo,G1,tfe,Zxo,e9o,OD,o9o,r9o,t9o,O1,afe,a9o,n9o,VD,s9o,l9o,i9o,V1,nfe,d9o,c9o,XD,f9o,m9o,g9o,X1,sfe,h9o,p9o,zD,u9o,_9o,b9o,z1,lfe,v9o,F9o,WD,T9o,M9o,E9o,W1,ife,C9o,w9o,QD,A9o,y9o,L9o,Q1,dfe,x9o,$9o,HD,k9o,S9o,R9o,H1,cfe,P9o,B9o,UD,I9o,q9o,N9o,U1,ffe,j9o,D9o,JD,G9o,O9o,V9o,J1,mfe,X9o,z9o,YD,W9o,Q9o,H9o,Y1,gfe,U9o,J9o,KD,Y9o,K9o,Z9o,K1,hfe,e$o,o$o,ZD,r$o,t$o,a$o,Z1,pfe,n$o,s$o,eG,l$o,i$o,d$o,e7,ufe,c$o,f$o,oG,m$o,g$o,h$o,o7,_fe,p$o,u$o,rG,_$o,b$o,v$o,r7,bfe,F$o,T$o,tG,M$o,E$o,C$o,t7,vfe,w$o,A$o,aG,y$o,L$o,x$o,a7,Ffe,$$o,k$o,nG,S$o,R$o,P$o,n7,Tfe,B$o,I$o,sG,q$o,N$o,j$o,s7,Mfe,D$o,G$o,lG,O$o,V$o,X$o,l7,Efe,z$o,W$o,iG,Q$o,H$o,U$o,i7,Cfe,J$o,Y$o,dG,K$o,Z$o,eko,d7,wfe,oko,rko,cG,tko,ako,nko,c7,Afe,sko,lko,fG,iko,dko,cko,f7,yfe,fko,mko,mG,gko,hko,pko,m7,Lfe,uko,_ko,gG,bko,vko,Fko,g7,xfe,Tko,Mko,hG,Eko,Cko,wko,h7,$fe,Ako,yko,pG,Lko,xko,$ko,p7,kfe,kko,Sko,uG,Rko,Pko,Bko,u7,Sfe,Iko,qko,_G,Nko,jko,Dko,_7,Rfe,Gko,Oko,bG,Vko,Xko,zko,b7,Pfe,Wko,Qko,vG,Hko,Uko,Jko,v7,Yko,Bfe,Kko,Zko,Ife,eSo,oSo,F7,iqe,Oi,T7,qfe,my,rSo,Nfe,tSo,dqe,Po,gy,aSo,Vi,nSo,FG,sSo,lSo,TG,iSo,dSo,cSo,hy,fSo,jfe,mSo,gSo,hSo,dt,py,pSo,Dfe,uSo,_So,Xi,bSo,Gfe,vSo,FSo,MG,TSo,MSo,ESo,M7,CSo,ro,uy,wSo,Ofe,ASo,ySo,Pa,LSo,Vfe,xSo,$So,Xfe,kSo,SSo,zfe,RSo,PSo,BSo,Y,E7,Wfe,ISo,qSo,EG,NSo,jSo,DSo,C7,Qfe,GSo,OSo,CG,VSo,XSo,zSo,w7,Hfe,WSo,QSo,wG,HSo,USo,JSo,A7,Ufe,YSo,KSo,AG,ZSo,eRo,oRo,y7,Jfe,rRo,tRo,yG,aRo,nRo,sRo,L7,Yfe,lRo,iRo,LG,dRo,cRo,fRo,x7,Kfe,mRo,gRo,xG,hRo,pRo,uRo,$7,Zfe,_Ro,bRo,$G,vRo,FRo,TRo,k7,eme,MRo,ERo,kG,CRo,wRo,ARo,S7,ome,yRo,LRo,SG,xRo,$Ro,kRo,R7,rme,SRo,RRo,RG,PRo,BRo,IRo,P7,tme,qRo,NRo,PG,jRo,DRo,GRo,B7,ame,ORo,VRo,BG,XRo,zRo,WRo,I7,nme,QRo,HRo,IG,URo,JRo,YRo,q7,sme,KRo,ZRo,qG,ePo,oPo,rPo,N7,lme,tPo,aPo,NG,nPo,sPo,lPo,j7,ime,iPo,dPo,jG,cPo,fPo,mPo,D7,dme,gPo,hPo,DG,pPo,uPo,_Po,G7,cme,bPo,vPo,GG,FPo,TPo,MPo,O7,fme,EPo,CPo,OG,wPo,APo,yPo,V7,mme,LPo,xPo,VG,$Po,kPo,SPo,X7,gme,RPo,PPo,XG,BPo,IPo,qPo,z7,hme,NPo,jPo,zG,DPo,GPo,OPo,W7,pme,VPo,XPo,WG,zPo,WPo,QPo,Q7,ume,HPo,UPo,QG,JPo,YPo,KPo,H7,_me,ZPo,eBo,HG,oBo,rBo,tBo,U7,bme,aBo,nBo,UG,sBo,lBo,iBo,J7,vme,dBo,cBo,JG,fBo,mBo,gBo,Y7,Fme,hBo,pBo,YG,uBo,_Bo,bBo,K7,vBo,Tme,FBo,TBo,Mme,MBo,EBo,Z7,cqe,zi,eb,Eme,_y,CBo,Cme,wBo,fqe,Bo,by,ABo,Wi,yBo,KG,LBo,xBo,ZG,$Bo,kBo,SBo,vy,RBo,wme,PBo,BBo,IBo,ct,Fy,qBo,Ame,NBo,jBo,Qi,DBo,yme,GBo,OBo,eO,VBo,XBo,zBo,ob,WBo,to,Ty,QBo,Lme,HBo,UBo,Ba,JBo,xme,YBo,KBo,$me,ZBo,eIo,kme,oIo,rIo,tIo,Yr,rb,Sme,aIo,nIo,oO,sIo,lIo,iIo,tb,Rme,dIo,cIo,rO,fIo,mIo,gIo,ab,Pme,hIo,pIo,tO,uIo,_Io,bIo,nb,Bme,vIo,FIo,aO,TIo,MIo,EIo,sb,Ime,CIo,wIo,nO,AIo,yIo,LIo,lb,xIo,qme,$Io,kIo,Nme,SIo,RIo,ib,mqe,Hi,db,jme,My,PIo,Dme,BIo,gqe,Io,Ey,IIo,Ui,qIo,sO,NIo,jIo,lO,DIo,GIo,OIo,Cy,VIo,Gme,XIo,zIo,WIo,ft,wy,QIo,Ome,HIo,UIo,Ji,JIo,Vme,YIo,KIo,iO,ZIo,eqo,oqo,cb,rqo,ao,Ay,tqo,Xme,aqo,nqo,Ia,sqo,zme,lqo,iqo,Wme,dqo,cqo,Qme,fqo,mqo,gqo,U,fb,Hme,hqo,pqo,dO,uqo,_qo,bqo,mb,Ume,vqo,Fqo,cO,Tqo,Mqo,Eqo,gb,Jme,Cqo,wqo,fO,Aqo,yqo,Lqo,hb,Yme,xqo,$qo,mO,kqo,Sqo,Rqo,pb,Kme,Pqo,Bqo,gO,Iqo,qqo,Nqo,ub,Zme,jqo,Dqo,hO,Gqo,Oqo,Vqo,_b,ege,Xqo,zqo,pO,Wqo,Qqo,Hqo,bb,oge,Uqo,Jqo,uO,Yqo,Kqo,Zqo,vb,rge,eNo,oNo,_O,rNo,tNo,aNo,Fb,tge,nNo,sNo,bO,lNo,iNo,dNo,Tb,age,cNo,fNo,vO,mNo,gNo,hNo,Mb,nge,pNo,uNo,FO,_No,bNo,vNo,Eb,sge,FNo,TNo,TO,MNo,ENo,CNo,Cb,lge,wNo,ANo,MO,yNo,LNo,xNo,wb,ige,$No,kNo,EO,SNo,RNo,PNo,Ab,dge,BNo,INo,CO,qNo,NNo,jNo,yb,cge,DNo,GNo,wO,ONo,VNo,XNo,Lb,fge,zNo,WNo,AO,QNo,HNo,UNo,xb,mge,JNo,YNo,yO,KNo,ZNo,ejo,$b,gge,ojo,rjo,LO,tjo,ajo,njo,kb,hge,sjo,ljo,xO,ijo,djo,cjo,Sb,pge,fjo,mjo,$O,gjo,hjo,pjo,Rb,uge,ujo,_jo,kO,bjo,vjo,Fjo,Pb,_ge,Tjo,Mjo,SO,Ejo,Cjo,wjo,Bb,bge,Ajo,yjo,RO,Ljo,xjo,$jo,Ib,vge,kjo,Sjo,PO,Rjo,Pjo,Bjo,qb,Fge,Ijo,qjo,BO,Njo,jjo,Djo,Nb,Tge,Gjo,Ojo,IO,Vjo,Xjo,zjo,jb,Mge,Wjo,Qjo,qO,Hjo,Ujo,Jjo,Db,Ege,Yjo,Kjo,NO,Zjo,eDo,oDo,Gb,Cge,rDo,tDo,jO,aDo,nDo,sDo,Ob,wge,lDo,iDo,DO,dDo,cDo,fDo,Vb,Age,mDo,gDo,GO,hDo,pDo,uDo,Xb,_Do,yge,bDo,vDo,Lge,FDo,TDo,zb,hqe,Yi,Wb,xge,yy,MDo,$ge,EDo,pqe,qo,Ly,CDo,Ki,wDo,OO,ADo,yDo,VO,LDo,xDo,$Do,xy,kDo,kge,SDo,RDo,PDo,mt,$y,BDo,Sge,IDo,qDo,Zi,NDo,Rge,jDo,DDo,XO,GDo,ODo,VDo,Qb,XDo,no,ky,zDo,Pge,WDo,QDo,qa,HDo,Bge,UDo,JDo,Ige,YDo,KDo,qge,ZDo,eGo,oGo,V,Hb,Nge,rGo,tGo,zO,aGo,nGo,sGo,Ub,jge,lGo,iGo,WO,dGo,cGo,fGo,Jb,Dge,mGo,gGo,QO,hGo,pGo,uGo,Yb,Gge,_Go,bGo,HO,vGo,FGo,TGo,Kb,Oge,MGo,EGo,UO,CGo,wGo,AGo,Zb,Vge,yGo,LGo,JO,xGo,$Go,kGo,ev,Xge,SGo,RGo,YO,PGo,BGo,IGo,ov,zge,qGo,NGo,KO,jGo,DGo,GGo,rv,Wge,OGo,VGo,ZO,XGo,zGo,WGo,tv,Qge,QGo,HGo,eV,UGo,JGo,YGo,av,Hge,KGo,ZGo,oV,eOo,oOo,rOo,nv,Uge,tOo,aOo,rV,nOo,sOo,lOo,sv,Jge,iOo,dOo,tV,cOo,fOo,mOo,lv,Yge,gOo,hOo,aV,pOo,uOo,_Oo,iv,Kge,bOo,vOo,nV,FOo,TOo,MOo,dv,Zge,EOo,COo,sV,wOo,AOo,yOo,cv,ehe,LOo,xOo,lV,$Oo,kOo,SOo,fv,ohe,ROo,POo,iV,BOo,IOo,qOo,mv,rhe,NOo,jOo,dV,DOo,GOo,OOo,gv,the,VOo,XOo,cV,zOo,WOo,QOo,hv,ahe,HOo,UOo,fV,JOo,YOo,KOo,pv,nhe,ZOo,eVo,mV,oVo,rVo,tVo,uv,she,aVo,nVo,gV,sVo,lVo,iVo,_v,lhe,dVo,cVo,hV,fVo,mVo,gVo,bv,ihe,hVo,pVo,pV,uVo,_Vo,bVo,vv,dhe,vVo,FVo,uV,TVo,MVo,EVo,Fv,che,CVo,wVo,_V,AVo,yVo,LVo,Tv,fhe,xVo,$Vo,bV,kVo,SVo,RVo,Mv,mhe,PVo,BVo,vV,IVo,qVo,NVo,Ev,ghe,jVo,DVo,FV,GVo,OVo,VVo,Cv,hhe,XVo,zVo,TV,WVo,QVo,HVo,wv,phe,UVo,JVo,MV,YVo,KVo,ZVo,Av,uhe,eXo,oXo,EV,rXo,tXo,aXo,yv,_he,nXo,sXo,CV,lXo,iXo,dXo,Lv,bhe,cXo,fXo,wV,mXo,gXo,hXo,xv,vhe,pXo,uXo,AV,_Xo,bXo,vXo,$v,Fhe,FXo,TXo,yV,MXo,EXo,CXo,kv,The,wXo,AXo,LV,yXo,LXo,xXo,Sv,Mhe,$Xo,kXo,xV,SXo,RXo,PXo,Rv,BXo,Ehe,IXo,qXo,Che,NXo,jXo,Pv,uqe,ed,Bv,whe,Sy,DXo,Ahe,GXo,_qe,No,Ry,OXo,od,VXo,$V,XXo,zXo,kV,WXo,QXo,HXo,Py,UXo,yhe,JXo,YXo,KXo,gt,By,ZXo,Lhe,ezo,ozo,rd,rzo,xhe,tzo,azo,SV,nzo,szo,lzo,Iv,izo,so,Iy,dzo,$he,czo,fzo,Na,mzo,khe,gzo,hzo,She,pzo,uzo,Rhe,_zo,bzo,vzo,Phe,qv,Bhe,Fzo,Tzo,RV,Mzo,Ezo,Czo,Nv,wzo,Ihe,Azo,yzo,qhe,Lzo,xzo,jv,bqe,td,Dv,Nhe,qy,$zo,jhe,kzo,vqe,jo,Ny,Szo,ad,Rzo,PV,Pzo,Bzo,BV,Izo,qzo,Nzo,jy,jzo,Dhe,Dzo,Gzo,Ozo,ht,Dy,Vzo,Ghe,Xzo,zzo,nd,Wzo,Ohe,Qzo,Hzo,IV,Uzo,Jzo,Yzo,Gv,Kzo,lo,Gy,Zzo,Vhe,eWo,oWo,ja,rWo,Xhe,tWo,aWo,zhe,nWo,sWo,Whe,lWo,iWo,dWo,Fe,Ov,Qhe,cWo,fWo,qV,mWo,gWo,hWo,Vv,Hhe,pWo,uWo,NV,_Wo,bWo,vWo,Xv,Uhe,FWo,TWo,jV,MWo,EWo,CWo,Ps,Jhe,wWo,AWo,DV,yWo,LWo,GV,xWo,$Wo,kWo,zv,Yhe,SWo,RWo,OV,PWo,BWo,IWo,pt,Khe,qWo,NWo,VV,jWo,DWo,XV,GWo,OWo,zV,VWo,XWo,zWo,Wv,Zhe,WWo,QWo,WV,HWo,UWo,JWo,Qv,epe,YWo,KWo,QV,ZWo,eQo,oQo,Hv,ope,rQo,tQo,HV,aQo,nQo,sQo,Uv,rpe,lQo,iQo,UV,dQo,cQo,fQo,Jv,tpe,mQo,gQo,JV,hQo,pQo,uQo,Yv,ape,_Qo,bQo,YV,vQo,FQo,TQo,Kv,npe,MQo,EQo,KV,CQo,wQo,AQo,Zv,yQo,spe,LQo,xQo,lpe,$Qo,kQo,eF,Fqe,sd,oF,ipe,Oy,SQo,dpe,RQo,Tqe,Do,Vy,PQo,ld,BQo,ZV,IQo,qQo,eX,NQo,jQo,DQo,Xy,GQo,cpe,OQo,VQo,XQo,ut,zy,zQo,fpe,WQo,QQo,id,HQo,mpe,UQo,JQo,oX,YQo,KQo,ZQo,rF,eHo,io,Wy,oHo,gpe,rHo,tHo,Da,aHo,hpe,nHo,sHo,ppe,lHo,iHo,upe,dHo,cHo,fHo,_pe,tF,bpe,mHo,gHo,rX,hHo,pHo,uHo,aF,_Ho,vpe,bHo,vHo,Fpe,FHo,THo,nF,Mqe,dd,sF,Tpe,Qy,MHo,Mpe,EHo,Eqe,Go,Hy,CHo,cd,wHo,tX,AHo,yHo,aX,LHo,xHo,$Ho,Uy,kHo,Epe,SHo,RHo,PHo,_t,Jy,BHo,Cpe,IHo,qHo,fd,NHo,wpe,jHo,DHo,nX,GHo,OHo,VHo,lF,XHo,co,Yy,zHo,Ape,WHo,QHo,Ga,HHo,ype,UHo,JHo,Lpe,YHo,KHo,xpe,ZHo,eUo,oUo,Se,iF,$pe,rUo,tUo,sX,aUo,nUo,sUo,dF,kpe,lUo,iUo,lX,dUo,cUo,fUo,cF,Spe,mUo,gUo,iX,hUo,pUo,uUo,fF,Rpe,_Uo,bUo,dX,vUo,FUo,TUo,mF,Ppe,MUo,EUo,cX,CUo,wUo,AUo,gF,Bpe,yUo,LUo,fX,xUo,$Uo,kUo,hF,Ipe,SUo,RUo,mX,PUo,BUo,IUo,pF,qpe,qUo,NUo,gX,jUo,DUo,GUo,uF,Npe,OUo,VUo,hX,XUo,zUo,WUo,_F,QUo,jpe,HUo,UUo,Dpe,JUo,YUo,bF,Cqe,md,vF,Gpe,Ky,KUo,Ope,ZUo,wqe,Oo,Zy,eJo,gd,oJo,pX,rJo,tJo,uX,aJo,nJo,sJo,eL,lJo,Vpe,iJo,dJo,cJo,bt,oL,fJo,Xpe,mJo,gJo,hd,hJo,zpe,pJo,uJo,_X,_Jo,bJo,vJo,FF,FJo,fo,rL,TJo,Wpe,MJo,EJo,Oa,CJo,Qpe,wJo,AJo,Hpe,yJo,LJo,Upe,xJo,$Jo,kJo,Kr,TF,Jpe,SJo,RJo,bX,PJo,BJo,IJo,MF,Ype,qJo,NJo,vX,jJo,DJo,GJo,EF,Kpe,OJo,VJo,FX,XJo,zJo,WJo,CF,Zpe,QJo,HJo,TX,UJo,JJo,YJo,wF,eue,KJo,ZJo,MX,eYo,oYo,rYo,AF,tYo,oue,aYo,nYo,rue,sYo,lYo,yF,Aqe,pd,LF,tue,tL,iYo,aue,dYo,yqe,Vo,aL,cYo,ud,fYo,EX,mYo,gYo,CX,hYo,pYo,uYo,nL,_Yo,nue,bYo,vYo,FYo,vt,sL,TYo,sue,MYo,EYo,_d,CYo,lue,wYo,AYo,wX,yYo,LYo,xYo,xF,$Yo,mo,lL,kYo,iue,SYo,RYo,Va,PYo,due,BYo,IYo,cue,qYo,NYo,fue,jYo,DYo,GYo,Re,$F,mue,OYo,VYo,AX,XYo,zYo,WYo,kF,gue,QYo,HYo,yX,UYo,JYo,YYo,SF,hue,KYo,ZYo,LX,eKo,oKo,rKo,RF,pue,tKo,aKo,xX,nKo,sKo,lKo,PF,uue,iKo,dKo,$X,cKo,fKo,mKo,BF,_ue,gKo,hKo,kX,pKo,uKo,_Ko,IF,bue,bKo,vKo,SX,FKo,TKo,MKo,qF,vue,EKo,CKo,RX,wKo,AKo,yKo,NF,Fue,LKo,xKo,PX,$Ko,kKo,SKo,jF,RKo,Tue,PKo,BKo,Mue,IKo,qKo,DF,Lqe,bd,GF,Eue,iL,NKo,Cue,jKo,xqe,Xo,dL,DKo,vd,GKo,BX,OKo,VKo,IX,XKo,zKo,WKo,cL,QKo,wue,HKo,UKo,JKo,Ft,fL,YKo,Aue,KKo,ZKo,Fd,eZo,yue,oZo,rZo,qX,tZo,aZo,nZo,OF,sZo,go,mL,lZo,Lue,iZo,dZo,Xa,cZo,xue,fZo,mZo,$ue,gZo,hZo,kue,pZo,uZo,_Zo,gL,VF,Sue,bZo,vZo,NX,FZo,TZo,MZo,XF,Rue,EZo,CZo,jX,wZo,AZo,yZo,zF,LZo,Pue,xZo,$Zo,Bue,kZo,SZo,WF,$qe,Td,QF,Iue,hL,RZo,que,PZo,kqe,zo,pL,BZo,Md,IZo,DX,qZo,NZo,GX,jZo,DZo,GZo,uL,OZo,Nue,VZo,XZo,zZo,Tt,_L,WZo,jue,QZo,HZo,Ed,UZo,Due,JZo,YZo,OX,KZo,ZZo,eer,HF,oer,ho,bL,rer,Gue,ter,aer,za,ner,Oue,ser,ler,Vue,ier,der,Xue,cer,fer,mer,Zr,UF,zue,ger,her,VX,per,uer,_er,JF,Wue,ber,ver,XX,Fer,Ter,Mer,YF,Que,Eer,Cer,zX,wer,Aer,yer,KF,Hue,Ler,xer,WX,$er,ker,Ser,ZF,Uue,Rer,Per,QX,Ber,Ier,qer,eT,Ner,Jue,jer,Der,Yue,Ger,Oer,oT,Sqe,Cd,rT,Kue,vL,Ver,Zue,Xer,Rqe,Wo,FL,zer,wd,Wer,HX,Qer,Her,UX,Uer,Jer,Yer,TL,Ker,e_e,Zer,eor,oor,Mt,ML,ror,o_e,tor,aor,Ad,nor,r_e,sor,lor,JX,ior,dor,cor,tT,mor,po,EL,gor,t_e,hor,por,Wa,uor,a_e,_or,bor,n_e,vor,For,s_e,Tor,Mor,Eor,yd,aT,l_e,Cor,wor,YX,Aor,yor,Lor,nT,i_e,xor,$or,KX,kor,Sor,Ror,sT,d_e,Por,Bor,ZX,Ior,qor,Nor,lT,jor,c_e,Dor,Gor,f_e,Oor,Vor,iT,Pqe,Ld,dT,m_e,CL,Xor,g_e,zor,Bqe,Qo,wL,Wor,xd,Qor,ez,Hor,Uor,oz,Jor,Yor,Kor,AL,Zor,h_e,err,orr,rrr,Et,yL,trr,p_e,arr,nrr,$d,srr,u_e,lrr,irr,rz,drr,crr,frr,cT,mrr,uo,LL,grr,__e,hrr,prr,Qa,urr,b_e,_rr,brr,v_e,vrr,Frr,F_e,Trr,Mrr,Err,xL,fT,T_e,Crr,wrr,tz,Arr,yrr,Lrr,mT,M_e,xrr,$rr,az,krr,Srr,Rrr,gT,Prr,E_e,Brr,Irr,C_e,qrr,Nrr,hT,Iqe,kd,pT,w_e,$L,jrr,A_e,Drr,qqe,Ho,kL,Grr,Sd,Orr,nz,Vrr,Xrr,sz,zrr,Wrr,Qrr,SL,Hrr,y_e,Urr,Jrr,Yrr,Ct,RL,Krr,L_e,Zrr,etr,Rd,otr,x_e,rtr,ttr,lz,atr,ntr,str,uT,ltr,_o,PL,itr,$_e,dtr,ctr,Ha,ftr,k_e,mtr,gtr,S_e,htr,ptr,R_e,utr,_tr,btr,P_e,_T,B_e,vtr,Ftr,iz,Ttr,Mtr,Etr,bT,Ctr,I_e,wtr,Atr,q_e,ytr,Ltr,vT,Nqe,Pd,FT,N_e,BL,xtr,j_e,$tr,jqe,Uo,IL,ktr,Bd,Str,dz,Rtr,Ptr,cz,Btr,Itr,qtr,qL,Ntr,D_e,jtr,Dtr,Gtr,wt,NL,Otr,G_e,Vtr,Xtr,Id,ztr,O_e,Wtr,Qtr,fz,Htr,Utr,Jtr,TT,Ytr,bo,jL,Ktr,V_e,Ztr,ear,Ua,oar,X_e,rar,tar,z_e,aar,nar,W_e,sar,lar,iar,Ja,MT,Q_e,dar,car,mz,far,mar,gar,ET,H_e,har,par,gz,uar,_ar,bar,CT,U_e,Far,Tar,hz,Mar,Ear,Car,wT,J_e,war,Aar,pz,yar,Lar,xar,AT,$ar,Y_e,kar,Sar,K_e,Rar,Par,yT,Dqe,qd,LT,Z_e,DL,Bar,e2e,Iar,Gqe,Jo,GL,qar,Nd,Nar,uz,jar,Dar,_z,Gar,Oar,Var,OL,Xar,o2e,zar,War,Qar,At,VL,Har,r2e,Uar,Jar,jd,Yar,t2e,Kar,Zar,bz,enr,onr,rnr,xT,tnr,vo,XL,anr,a2e,nnr,snr,Ya,lnr,n2e,inr,dnr,s2e,cnr,fnr,l2e,mnr,gnr,hnr,i2e,$T,d2e,pnr,unr,vz,_nr,bnr,vnr,kT,Fnr,c2e,Tnr,Mnr,f2e,Enr,Cnr,ST,Oqe,Dd,RT,m2e,zL,wnr,g2e,Anr,Vqe,Yo,WL,ynr,Gd,Lnr,Fz,xnr,$nr,Tz,knr,Snr,Rnr,QL,Pnr,h2e,Bnr,Inr,qnr,yt,HL,Nnr,p2e,jnr,Dnr,Od,Gnr,u2e,Onr,Vnr,Mz,Xnr,znr,Wnr,PT,Qnr,wr,UL,Hnr,_2e,Unr,Jnr,Ka,Ynr,b2e,Knr,Znr,v2e,esr,osr,F2e,rsr,tsr,asr,q,BT,T2e,nsr,ssr,Ez,lsr,isr,dsr,IT,M2e,csr,fsr,Cz,msr,gsr,hsr,qT,E2e,psr,usr,wz,_sr,bsr,vsr,NT,C2e,Fsr,Tsr,Az,Msr,Esr,Csr,jT,w2e,wsr,Asr,yz,ysr,Lsr,xsr,DT,A2e,$sr,ksr,Lz,Ssr,Rsr,Psr,GT,y2e,Bsr,Isr,xz,qsr,Nsr,jsr,OT,L2e,Dsr,Gsr,$z,Osr,Vsr,Xsr,VT,x2e,zsr,Wsr,kz,Qsr,Hsr,Usr,XT,$2e,Jsr,Ysr,Sz,Ksr,Zsr,elr,zT,k2e,olr,rlr,Rz,tlr,alr,nlr,WT,S2e,slr,llr,Pz,ilr,dlr,clr,QT,R2e,flr,mlr,Bz,glr,hlr,plr,HT,P2e,ulr,_lr,Iz,blr,vlr,Flr,UT,B2e,Tlr,Mlr,qz,Elr,Clr,wlr,JT,I2e,Alr,ylr,Nz,Llr,xlr,$lr,YT,q2e,klr,Slr,jz,Rlr,Plr,Blr,Bs,N2e,Ilr,qlr,Dz,Nlr,jlr,Gz,Dlr,Glr,Olr,KT,j2e,Vlr,Xlr,Oz,zlr,Wlr,Qlr,ZT,D2e,Hlr,Ulr,Vz,Jlr,Ylr,Klr,eM,G2e,Zlr,eir,Xz,oir,rir,tir,oM,O2e,air,nir,zz,sir,lir,iir,rM,V2e,dir,cir,Wz,fir,mir,gir,tM,X2e,hir,pir,Qz,uir,_ir,bir,aM,z2e,vir,Fir,Hz,Tir,Mir,Eir,nM,W2e,Cir,wir,Uz,Air,yir,Lir,sM,Q2e,xir,$ir,Jz,kir,Sir,Rir,lM,H2e,Pir,Bir,Yz,Iir,qir,Nir,iM,U2e,jir,Dir,Kz,Gir,Oir,Vir,dM,J2e,Xir,zir,Zz,Wir,Qir,Hir,cM,Y2e,Uir,Jir,eW,Yir,Kir,Zir,fM,K2e,edr,odr,oW,rdr,tdr,adr,mM,Z2e,ndr,sdr,rW,ldr,idr,ddr,gM,e1e,cdr,fdr,tW,mdr,gdr,hdr,hM,o1e,pdr,udr,aW,_dr,bdr,vdr,pM,r1e,Fdr,Tdr,nW,Mdr,Edr,Cdr,uM,t1e,wdr,Adr,sW,ydr,Ldr,xdr,_M,a1e,$dr,kdr,lW,Sdr,Rdr,Pdr,bM,n1e,Bdr,Idr,iW,qdr,Ndr,jdr,vM,s1e,Ddr,Gdr,dW,Odr,Vdr,Xdr,FM,l1e,zdr,Wdr,cW,Qdr,Hdr,Udr,TM,i1e,Jdr,Ydr,fW,Kdr,Zdr,ecr,MM,d1e,ocr,rcr,mW,tcr,acr,ncr,EM,c1e,scr,lcr,gW,icr,dcr,ccr,CM,f1e,fcr,mcr,hW,gcr,hcr,pcr,wM,m1e,ucr,_cr,pW,bcr,vcr,Fcr,AM,g1e,Tcr,Mcr,uW,Ecr,Ccr,wcr,yM,Xqe,Vd,LM,h1e,JL,Acr,p1e,ycr,zqe,Ko,YL,Lcr,Xd,xcr,_W,$cr,kcr,bW,Scr,Rcr,Pcr,KL,Bcr,u1e,Icr,qcr,Ncr,Lt,ZL,jcr,_1e,Dcr,Gcr,zd,Ocr,b1e,Vcr,Xcr,vW,zcr,Wcr,Qcr,xM,Hcr,Ar,e8,Ucr,v1e,Jcr,Ycr,Za,Kcr,F1e,Zcr,efr,T1e,ofr,rfr,M1e,tfr,afr,nfr,se,$M,E1e,sfr,lfr,FW,ifr,dfr,cfr,kM,C1e,ffr,mfr,TW,gfr,hfr,pfr,SM,w1e,ufr,_fr,MW,bfr,vfr,Ffr,RM,A1e,Tfr,Mfr,EW,Efr,Cfr,wfr,PM,y1e,Afr,yfr,CW,Lfr,xfr,$fr,BM,L1e,kfr,Sfr,wW,Rfr,Pfr,Bfr,IM,x1e,Ifr,qfr,AW,Nfr,jfr,Dfr,qM,$1e,Gfr,Ofr,yW,Vfr,Xfr,zfr,NM,k1e,Wfr,Qfr,LW,Hfr,Ufr,Jfr,jM,S1e,Yfr,Kfr,xW,Zfr,emr,omr,DM,R1e,rmr,tmr,$W,amr,nmr,smr,GM,P1e,lmr,imr,kW,dmr,cmr,fmr,OM,B1e,mmr,gmr,SW,hmr,pmr,umr,VM,I1e,_mr,bmr,RW,vmr,Fmr,Tmr,XM,q1e,Mmr,Emr,PW,Cmr,wmr,Amr,zM,N1e,ymr,Lmr,BW,xmr,$mr,kmr,WM,j1e,Smr,Rmr,IW,Pmr,Bmr,Imr,QM,D1e,qmr,Nmr,qW,jmr,Dmr,Gmr,HM,G1e,Omr,Vmr,NW,Xmr,zmr,Wmr,UM,O1e,Qmr,Hmr,jW,Umr,Jmr,Ymr,JM,V1e,Kmr,Zmr,DW,egr,ogr,rgr,YM,X1e,tgr,agr,GW,ngr,sgr,lgr,KM,z1e,igr,dgr,OW,cgr,fgr,mgr,ZM,Wqe,Wd,e4,W1e,o8,ggr,Q1e,hgr,Qqe,Zo,r8,pgr,Qd,ugr,VW,_gr,bgr,XW,vgr,Fgr,Tgr,t8,Mgr,H1e,Egr,Cgr,wgr,xt,a8,Agr,U1e,ygr,Lgr,Hd,xgr,J1e,$gr,kgr,zW,Sgr,Rgr,Pgr,o4,Bgr,yr,n8,Igr,Y1e,qgr,Ngr,en,jgr,K1e,Dgr,Ggr,Z1e,Ogr,Vgr,e7e,Xgr,zgr,Wgr,Te,r4,o7e,Qgr,Hgr,WW,Ugr,Jgr,Ygr,t4,r7e,Kgr,Zgr,QW,ehr,ohr,rhr,a4,t7e,thr,ahr,HW,nhr,shr,lhr,n4,a7e,ihr,dhr,UW,chr,fhr,mhr,s4,n7e,ghr,hhr,JW,phr,uhr,_hr,l4,s7e,bhr,vhr,YW,Fhr,Thr,Mhr,i4,l7e,Ehr,Chr,KW,whr,Ahr,yhr,d4,i7e,Lhr,xhr,ZW,$hr,khr,Shr,c4,d7e,Rhr,Phr,eQ,Bhr,Ihr,qhr,f4,c7e,Nhr,jhr,oQ,Dhr,Ghr,Ohr,m4,f7e,Vhr,Xhr,rQ,zhr,Whr,Qhr,g4,m7e,Hhr,Uhr,tQ,Jhr,Yhr,Khr,h4,Hqe,Ud,p4,g7e,s8,Zhr,h7e,epr,Uqe,er,l8,opr,Jd,rpr,aQ,tpr,apr,nQ,npr,spr,lpr,i8,ipr,p7e,dpr,cpr,fpr,$t,d8,mpr,u7e,gpr,hpr,Yd,ppr,_7e,upr,_pr,sQ,bpr,vpr,Fpr,u4,Tpr,Lr,c8,Mpr,b7e,Epr,Cpr,on,wpr,v7e,Apr,ypr,F7e,Lpr,xpr,T7e,$pr,kpr,Spr,rn,_4,M7e,Rpr,Ppr,lQ,Bpr,Ipr,qpr,b4,E7e,Npr,jpr,iQ,Dpr,Gpr,Opr,v4,C7e,Vpr,Xpr,dQ,zpr,Wpr,Qpr,F4,w7e,Hpr,Upr,cQ,Jpr,Ypr,Kpr,T4,Jqe,Kd,M4,A7e,f8,Zpr,y7e,eur,Yqe,or,m8,our,Zd,rur,fQ,tur,aur,mQ,nur,sur,lur,g8,iur,L7e,dur,cur,fur,kt,h8,mur,x7e,gur,hur,ec,pur,$7e,uur,_ur,gQ,bur,vur,Fur,E4,Tur,xr,p8,Mur,k7e,Eur,Cur,tn,wur,S7e,Aur,yur,R7e,Lur,xur,P7e,$ur,kur,Sur,ie,C4,B7e,Rur,Pur,hQ,Bur,Iur,qur,w4,I7e,Nur,jur,pQ,Dur,Gur,Our,A4,q7e,Vur,Xur,uQ,zur,Wur,Qur,y4,N7e,Hur,Uur,_Q,Jur,Yur,Kur,L4,j7e,Zur,e_r,bQ,o_r,r_r,t_r,x4,D7e,a_r,n_r,vQ,s_r,l_r,i_r,$4,G7e,d_r,c_r,FQ,f_r,m_r,g_r,k4,O7e,h_r,p_r,TQ,u_r,__r,b_r,S4,V7e,v_r,F_r,MQ,T_r,M_r,E_r,R4,X7e,C_r,w_r,EQ,A_r,y_r,L_r,P4,z7e,x_r,$_r,CQ,k_r,S_r,R_r,B4,W7e,P_r,B_r,wQ,I_r,q_r,N_r,I4,Q7e,j_r,D_r,AQ,G_r,O_r,V_r,q4,H7e,X_r,z_r,yQ,W_r,Q_r,H_r,N4,U7e,U_r,J_r,LQ,Y_r,K_r,Z_r,j4,J7e,e2r,o2r,xQ,r2r,t2r,a2r,D4,Y7e,n2r,s2r,$Q,l2r,i2r,d2r,G4,K7e,c2r,f2r,kQ,m2r,g2r,h2r,O4,Z7e,p2r,u2r,SQ,_2r,b2r,v2r,V4,ebe,F2r,T2r,RQ,M2r,E2r,C2r,X4,Kqe,oc,z4,obe,u8,w2r,rbe,A2r,Zqe,rr,_8,y2r,rc,L2r,PQ,x2r,$2r,BQ,k2r,S2r,R2r,b8,P2r,tbe,B2r,I2r,q2r,St,v8,N2r,abe,j2r,D2r,tc,G2r,nbe,O2r,V2r,IQ,X2r,z2r,W2r,W4,Q2r,$r,F8,H2r,sbe,U2r,J2r,an,Y2r,lbe,K2r,Z2r,ibe,e1r,o1r,dbe,r1r,t1r,a1r,ye,Q4,cbe,n1r,s1r,qQ,l1r,i1r,d1r,H4,fbe,c1r,f1r,NQ,m1r,g1r,h1r,U4,mbe,p1r,u1r,jQ,_1r,b1r,v1r,J4,gbe,F1r,T1r,DQ,M1r,E1r,C1r,Y4,hbe,w1r,A1r,GQ,y1r,L1r,x1r,K4,pbe,$1r,k1r,OQ,S1r,R1r,P1r,Z4,ube,B1r,I1r,VQ,q1r,N1r,j1r,eE,_be,D1r,G1r,XQ,O1r,V1r,X1r,oE,bbe,z1r,W1r,zQ,Q1r,H1r,U1r,rE,vbe,J1r,Y1r,WQ,K1r,Z1r,e7r,tE,eNe,ac,aE,Fbe,T8,o7r,Tbe,r7r,oNe,tr,M8,t7r,nc,a7r,QQ,n7r,s7r,HQ,l7r,i7r,d7r,E8,c7r,Mbe,f7r,m7r,g7r,Rt,C8,h7r,Ebe,p7r,u7r,sc,_7r,Cbe,b7r,v7r,UQ,F7r,T7r,M7r,nE,E7r,kr,w8,C7r,wbe,w7r,A7r,nn,y7r,Abe,L7r,x7r,ybe,$7r,k7r,Lbe,S7r,R7r,P7r,ee,sE,xbe,B7r,I7r,JQ,q7r,N7r,j7r,lE,$be,D7r,G7r,YQ,O7r,V7r,X7r,iE,kbe,z7r,W7r,KQ,Q7r,H7r,U7r,dE,Sbe,J7r,Y7r,ZQ,K7r,Z7r,ebr,cE,Rbe,obr,rbr,eH,tbr,abr,nbr,fE,Pbe,sbr,lbr,oH,ibr,dbr,cbr,mE,Bbe,fbr,mbr,rH,gbr,hbr,pbr,gE,Ibe,ubr,_br,tH,bbr,vbr,Fbr,hE,qbe,Tbr,Mbr,aH,Ebr,Cbr,wbr,pE,Nbe,Abr,ybr,nH,Lbr,xbr,$br,uE,jbe,kbr,Sbr,sH,Rbr,Pbr,Bbr,_E,Dbe,Ibr,qbr,lH,Nbr,jbr,Dbr,bE,Gbe,Gbr,Obr,iH,Vbr,Xbr,zbr,vE,Obe,Wbr,Qbr,dH,Hbr,Ubr,Jbr,FE,Vbe,Ybr,Kbr,cH,Zbr,evr,ovr,TE,Xbe,rvr,tvr,fH,avr,nvr,svr,ME,zbe,lvr,ivr,mH,dvr,cvr,fvr,EE,Wbe,mvr,gvr,gH,hvr,pvr,uvr,CE,Qbe,_vr,bvr,hH,vvr,Fvr,Tvr,wE,Hbe,Mvr,Evr,pH,Cvr,wvr,Avr,AE,Ube,yvr,Lvr,uH,xvr,$vr,kvr,yE,Jbe,Svr,Rvr,_H,Pvr,Bvr,Ivr,LE,Ybe,qvr,Nvr,bH,jvr,Dvr,Gvr,xE,Kbe,Ovr,Vvr,vH,Xvr,zvr,Wvr,$E,Zbe,Qvr,Hvr,FH,Uvr,Jvr,Yvr,kE,eve,Kvr,Zvr,TH,eFr,oFr,rFr,SE,rNe,lc,RE,ove,A8,tFr,rve,aFr,tNe,ar,y8,nFr,ic,sFr,MH,lFr,iFr,EH,dFr,cFr,fFr,L8,mFr,tve,gFr,hFr,pFr,Pt,x8,uFr,ave,_Fr,bFr,dc,vFr,nve,FFr,TFr,CH,MFr,EFr,CFr,PE,wFr,Sr,$8,AFr,sve,yFr,LFr,sn,xFr,lve,$Fr,kFr,ive,SFr,RFr,dve,PFr,BFr,IFr,he,BE,cve,qFr,NFr,wH,jFr,DFr,GFr,IE,fve,OFr,VFr,AH,XFr,zFr,WFr,qE,mve,QFr,HFr,yH,UFr,JFr,YFr,NE,gve,KFr,ZFr,LH,eTr,oTr,rTr,jE,hve,tTr,aTr,xH,nTr,sTr,lTr,DE,pve,iTr,dTr,$H,cTr,fTr,mTr,GE,uve,gTr,hTr,kH,pTr,uTr,_Tr,OE,_ve,bTr,vTr,SH,FTr,TTr,MTr,VE,bve,ETr,CTr,RH,wTr,ATr,yTr,XE,vve,LTr,xTr,PH,$Tr,kTr,STr,zE,Fve,RTr,PTr,BH,BTr,ITr,qTr,WE,Tve,NTr,jTr,IH,DTr,GTr,OTr,QE,Mve,VTr,XTr,qH,zTr,WTr,QTr,HE,Eve,HTr,UTr,NH,JTr,YTr,KTr,UE,Cve,ZTr,eMr,jH,oMr,rMr,tMr,JE,wve,aMr,nMr,DH,sMr,lMr,iMr,YE,Ave,dMr,cMr,GH,fMr,mMr,gMr,KE,aNe,cc,ZE,yve,k8,hMr,Lve,pMr,nNe,nr,S8,uMr,fc,_Mr,OH,bMr,vMr,VH,FMr,TMr,MMr,R8,EMr,xve,CMr,wMr,AMr,Bt,P8,yMr,$ve,LMr,xMr,mc,$Mr,kve,kMr,SMr,XH,RMr,PMr,BMr,eC,IMr,Rr,B8,qMr,Sve,NMr,jMr,ln,DMr,Rve,GMr,OMr,Pve,VMr,XMr,Bve,zMr,WMr,QMr,I8,oC,Ive,HMr,UMr,zH,JMr,YMr,KMr,rC,qve,ZMr,e4r,WH,o4r,r4r,t4r,tC,sNe,gc,aC,Nve,q8,a4r,jve,n4r,lNe,sr,N8,s4r,hc,l4r,QH,i4r,d4r,HH,c4r,f4r,m4r,j8,g4r,Dve,h4r,p4r,u4r,It,D8,_4r,Gve,b4r,v4r,pc,F4r,Ove,T4r,M4r,UH,E4r,C4r,w4r,nC,A4r,Pr,G8,y4r,Vve,L4r,x4r,dn,$4r,Xve,k4r,S4r,zve,R4r,P4r,Wve,B4r,I4r,q4r,Qve,sC,Hve,N4r,j4r,JH,D4r,G4r,O4r,lC,iNe,uc,iC,Uve,O8,V4r,Jve,X4r,dNe,lr,V8,z4r,_c,W4r,YH,Q4r,H4r,KH,U4r,J4r,Y4r,X8,K4r,Yve,Z4r,eEr,oEr,qt,z8,rEr,Kve,tEr,aEr,bc,nEr,Zve,sEr,lEr,ZH,iEr,dEr,cEr,dC,fEr,Br,W8,mEr,eFe,gEr,hEr,cn,pEr,oFe,uEr,_Er,rFe,bEr,vEr,tFe,FEr,TEr,MEr,de,cC,aFe,EEr,CEr,eU,wEr,AEr,yEr,fC,nFe,LEr,xEr,oU,$Er,kEr,SEr,mC,sFe,REr,PEr,rU,BEr,IEr,qEr,gC,lFe,NEr,jEr,tU,DEr,GEr,OEr,hC,iFe,VEr,XEr,aU,zEr,WEr,QEr,pC,dFe,HEr,UEr,nU,JEr,YEr,KEr,uC,cFe,ZEr,eCr,sU,oCr,rCr,tCr,_C,fFe,aCr,nCr,lU,sCr,lCr,iCr,bC,mFe,dCr,cCr,iU,fCr,mCr,gCr,vC,gFe,hCr,pCr,dU,uCr,_Cr,bCr,FC,hFe,vCr,FCr,cU,TCr,MCr,ECr,TC,pFe,CCr,wCr,fU,ACr,yCr,LCr,MC,uFe,xCr,$Cr,mU,kCr,SCr,RCr,EC,_Fe,PCr,BCr,gU,ICr,qCr,NCr,CC,bFe,jCr,DCr,hU,GCr,OCr,VCr,wC,vFe,XCr,zCr,pU,WCr,QCr,HCr,AC,FFe,UCr,JCr,uU,YCr,KCr,ZCr,yC,TFe,e5r,o5r,_U,r5r,t5r,a5r,LC,MFe,n5r,s5r,bU,l5r,i5r,d5r,xC,EFe,c5r,f5r,vU,m5r,g5r,h5r,$C,cNe,vc,kC,CFe,Q8,p5r,wFe,u5r,fNe,ir,H8,_5r,Fc,b5r,FU,v5r,F5r,TU,T5r,M5r,E5r,U8,C5r,AFe,w5r,A5r,y5r,Nt,J8,L5r,yFe,x5r,$5r,Tc,k5r,LFe,S5r,R5r,MU,P5r,B5r,I5r,SC,q5r,Ir,Y8,N5r,xFe,j5r,D5r,fn,G5r,$Fe,O5r,V5r,kFe,X5r,z5r,SFe,W5r,Q5r,H5r,ce,RC,RFe,U5r,J5r,EU,Y5r,K5r,Z5r,PC,PFe,e3r,o3r,CU,r3r,t3r,a3r,BC,BFe,n3r,s3r,wU,l3r,i3r,d3r,IC,IFe,c3r,f3r,AU,m3r,g3r,h3r,qC,qFe,p3r,u3r,yU,_3r,b3r,v3r,NC,NFe,F3r,T3r,LU,M3r,E3r,C3r,jC,jFe,w3r,A3r,xU,y3r,L3r,x3r,DC,DFe,$3r,k3r,$U,S3r,R3r,P3r,GC,GFe,B3r,I3r,kU,q3r,N3r,j3r,OC,OFe,D3r,G3r,SU,O3r,V3r,X3r,VC,VFe,z3r,W3r,RU,Q3r,H3r,U3r,XC,XFe,J3r,Y3r,PU,K3r,Z3r,ewr,zC,zFe,owr,rwr,BU,twr,awr,nwr,WC,WFe,swr,lwr,IU,iwr,dwr,cwr,QC,QFe,fwr,mwr,qU,gwr,hwr,pwr,HC,HFe,uwr,_wr,NU,bwr,vwr,Fwr,UC,UFe,Twr,Mwr,jU,Ewr,Cwr,wwr,JC,JFe,Awr,ywr,DU,Lwr,xwr,$wr,YC,YFe,kwr,Swr,GU,Rwr,Pwr,Bwr,KC,KFe,Iwr,qwr,OU,Nwr,jwr,Dwr,ZC,mNe,Mc,e5,ZFe,K8,Gwr,eTe,Owr,gNe,dr,Z8,Vwr,Ec,Xwr,VU,zwr,Wwr,XU,Qwr,Hwr,Uwr,ex,Jwr,oTe,Ywr,Kwr,Zwr,jt,ox,eAr,rTe,oAr,rAr,Cc,tAr,tTe,aAr,nAr,zU,sAr,lAr,iAr,o5,dAr,qr,rx,cAr,aTe,fAr,mAr,mn,gAr,nTe,hAr,pAr,sTe,uAr,_Ar,lTe,bAr,vAr,FAr,iTe,r5,dTe,TAr,MAr,WU,EAr,CAr,wAr,t5,hNe,wc,a5,cTe,tx,AAr,fTe,yAr,pNe,cr,ax,LAr,Ac,xAr,QU,$Ar,kAr,HU,SAr,RAr,PAr,nx,BAr,mTe,IAr,qAr,NAr,Dt,sx,jAr,gTe,DAr,GAr,yc,OAr,hTe,VAr,XAr,UU,zAr,WAr,QAr,n5,HAr,Nr,lx,UAr,pTe,JAr,YAr,gn,KAr,uTe,ZAr,e0r,_Te,o0r,r0r,bTe,t0r,a0r,n0r,vTe,s5,FTe,s0r,l0r,JU,i0r,d0r,c0r,l5,uNe,Lc,i5,TTe,ix,f0r,MTe,m0r,_Ne,fr,dx,g0r,xc,h0r,YU,p0r,u0r,KU,_0r,b0r,v0r,cx,F0r,ETe,T0r,M0r,E0r,Gt,fx,C0r,CTe,w0r,A0r,$c,y0r,wTe,L0r,x0r,ZU,$0r,k0r,S0r,d5,R0r,jr,mx,P0r,ATe,B0r,I0r,hn,q0r,yTe,N0r,j0r,LTe,D0r,G0r,xTe,O0r,V0r,X0r,oe,c5,$Te,z0r,W0r,eJ,Q0r,H0r,U0r,f5,kTe,J0r,Y0r,oJ,K0r,Z0r,e6r,m5,STe,o6r,r6r,rJ,t6r,a6r,n6r,g5,RTe,s6r,l6r,tJ,i6r,d6r,c6r,h5,PTe,f6r,m6r,aJ,g6r,h6r,p6r,p5,BTe,u6r,_6r,nJ,b6r,v6r,F6r,u5,ITe,T6r,M6r,sJ,E6r,C6r,w6r,_5,qTe,A6r,y6r,lJ,L6r,x6r,$6r,b5,NTe,k6r,S6r,iJ,R6r,P6r,B6r,v5,jTe,I6r,q6r,dJ,N6r,j6r,D6r,F5,DTe,G6r,O6r,cJ,V6r,X6r,z6r,T5,GTe,W6r,Q6r,fJ,H6r,U6r,J6r,M5,OTe,Y6r,K6r,mJ,Z6r,eyr,oyr,E5,VTe,ryr,tyr,gJ,ayr,nyr,syr,C5,XTe,lyr,iyr,hJ,dyr,cyr,fyr,w5,zTe,myr,gyr,pJ,hyr,pyr,uyr,A5,WTe,_yr,byr,uJ,vyr,Fyr,Tyr,y5,QTe,Myr,Eyr,_J,Cyr,wyr,Ayr,L5,HTe,yyr,Lyr,bJ,xyr,$yr,kyr,x5,UTe,Syr,Ryr,vJ,Pyr,Byr,Iyr,$5,JTe,qyr,Nyr,FJ,jyr,Dyr,Gyr,k5,YTe,Oyr,Vyr,TJ,Xyr,zyr,Wyr,S5,KTe,Qyr,Hyr,MJ,Uyr,Jyr,Yyr,R5,ZTe,Kyr,Zyr,EJ,eLr,oLr,rLr,P5,eMe,tLr,aLr,CJ,nLr,sLr,lLr,B5,oMe,iLr,dLr,wJ,cLr,fLr,mLr,I5,bNe,kc,q5,rMe,gx,gLr,tMe,hLr,vNe,mr,hx,pLr,Sc,uLr,AJ,_Lr,bLr,yJ,vLr,FLr,TLr,px,MLr,aMe,ELr,CLr,wLr,Ot,ux,ALr,nMe,yLr,LLr,Rc,xLr,sMe,$Lr,kLr,LJ,SLr,RLr,PLr,N5,BLr,Dr,_x,ILr,lMe,qLr,NLr,pn,jLr,iMe,DLr,GLr,dMe,OLr,VLr,cMe,XLr,zLr,WLr,Le,j5,fMe,QLr,HLr,xJ,ULr,JLr,YLr,D5,mMe,KLr,ZLr,$J,e8r,o8r,r8r,G5,gMe,t8r,a8r,kJ,n8r,s8r,l8r,O5,hMe,i8r,d8r,SJ,c8r,f8r,m8r,V5,pMe,g8r,h8r,RJ,p8r,u8r,_8r,X5,uMe,b8r,v8r,PJ,F8r,T8r,M8r,z5,_Me,E8r,C8r,BJ,w8r,A8r,y8r,W5,bMe,L8r,x8r,IJ,$8r,k8r,S8r,Q5,vMe,R8r,P8r,qJ,B8r,I8r,q8r,H5,FMe,N8r,j8r,NJ,D8r,G8r,O8r,U5,FNe,Pc,J5,TMe,bx,V8r,MMe,X8r,TNe,gr,vx,z8r,Bc,W8r,jJ,Q8r,H8r,DJ,U8r,J8r,Y8r,Fx,K8r,EMe,Z8r,exr,oxr,Vt,Tx,rxr,CMe,txr,axr,Ic,nxr,wMe,sxr,lxr,GJ,ixr,dxr,cxr,Y5,fxr,Gr,Mx,mxr,AMe,gxr,hxr,un,pxr,yMe,uxr,_xr,LMe,bxr,vxr,xMe,Fxr,Txr,Mxr,Me,K5,$Me,Exr,Cxr,OJ,wxr,Axr,yxr,Z5,kMe,Lxr,xxr,VJ,$xr,kxr,Sxr,e3,SMe,Rxr,Pxr,XJ,Bxr,Ixr,qxr,o3,RMe,Nxr,jxr,zJ,Dxr,Gxr,Oxr,r3,PMe,Vxr,Xxr,WJ,zxr,Wxr,Qxr,t3,BMe,Hxr,Uxr,QJ,Jxr,Yxr,Kxr,a3,IMe,Zxr,e9r,HJ,o9r,r9r,t9r,n3,qMe,a9r,n9r,UJ,s9r,l9r,i9r,s3,NMe,d9r,c9r,JJ,f9r,m9r,g9r,l3,jMe,h9r,p9r,YJ,u9r,_9r,b9r,i3,DMe,v9r,F9r,KJ,T9r,M9r,E9r,d3,GMe,C9r,w9r,ZJ,A9r,y9r,L9r,c3,MNe,qc,f3,OMe,Ex,x9r,VMe,$9r,ENe,hr,Cx,k9r,Nc,S9r,eY,R9r,P9r,oY,B9r,I9r,q9r,wx,N9r,XMe,j9r,D9r,G9r,Xt,Ax,O9r,zMe,V9r,X9r,jc,z9r,WMe,W9r,Q9r,rY,H9r,U9r,J9r,m3,Y9r,Or,yx,K9r,QMe,Z9r,e$r,_n,o$r,HMe,r$r,t$r,UMe,a$r,n$r,JMe,s$r,l$r,i$r,xe,g3,YMe,d$r,c$r,tY,f$r,m$r,g$r,h3,KMe,h$r,p$r,aY,u$r,_$r,b$r,p3,ZMe,v$r,F$r,nY,T$r,M$r,E$r,u3,e4e,C$r,w$r,sY,A$r,y$r,L$r,_3,o4e,x$r,$$r,lY,k$r,S$r,R$r,b3,r4e,P$r,B$r,iY,I$r,q$r,N$r,v3,t4e,j$r,D$r,dY,G$r,O$r,V$r,F3,a4e,X$r,z$r,cY,W$r,Q$r,H$r,T3,n4e,U$r,J$r,fY,Y$r,K$r,Z$r,M3,s4e,ekr,okr,mY,rkr,tkr,akr,E3,CNe,Dc,C3,l4e,Lx,nkr,i4e,skr,wNe,pr,xx,lkr,Gc,ikr,gY,dkr,ckr,hY,fkr,mkr,gkr,$x,hkr,d4e,pkr,ukr,_kr,zt,kx,bkr,c4e,vkr,Fkr,Oc,Tkr,f4e,Mkr,Ekr,pY,Ckr,wkr,Akr,w3,ykr,Vr,Sx,Lkr,m4e,xkr,$kr,bn,kkr,g4e,Skr,Rkr,h4e,Pkr,Bkr,p4e,Ikr,qkr,Nkr,Pe,A3,u4e,jkr,Dkr,uY,Gkr,Okr,Vkr,y3,_4e,Xkr,zkr,_Y,Wkr,Qkr,Hkr,L3,b4e,Ukr,Jkr,bY,Ykr,Kkr,Zkr,x3,v4e,eSr,oSr,vY,rSr,tSr,aSr,$3,F4e,nSr,sSr,FY,lSr,iSr,dSr,k3,T4e,cSr,fSr,TY,mSr,gSr,hSr,S3,M4e,pSr,uSr,MY,_Sr,bSr,vSr,R3,E4e,FSr,TSr,EY,MSr,ESr,CSr,P3,C4e,wSr,ASr,CY,ySr,LSr,xSr,B3,ANe,Vc,I3,w4e,Rx,$Sr,A4e,kSr,yNe,ur,Px,SSr,Xc,RSr,wY,PSr,BSr,AY,ISr,qSr,NSr,Bx,jSr,y4e,DSr,GSr,OSr,Wt,Ix,VSr,L4e,XSr,zSr,zc,WSr,x4e,QSr,HSr,yY,USr,JSr,YSr,q3,KSr,Xr,qx,ZSr,$4e,eRr,oRr,vn,rRr,k4e,tRr,aRr,S4e,nRr,sRr,R4e,lRr,iRr,dRr,$e,N3,P4e,cRr,fRr,LY,mRr,gRr,hRr,j3,B4e,pRr,uRr,xY,_Rr,bRr,vRr,D3,I4e,FRr,TRr,$Y,MRr,ERr,CRr,G3,q4e,wRr,ARr,kY,yRr,LRr,xRr,O3,N4e,$Rr,kRr,SY,SRr,RRr,PRr,V3,j4e,BRr,IRr,RY,qRr,NRr,jRr,X3,D4e,DRr,GRr,PY,ORr,VRr,XRr,z3,G4e,zRr,WRr,BY,QRr,HRr,URr,W3,O4e,JRr,YRr,IY,KRr,ZRr,ePr,Q3,V4e,oPr,rPr,qY,tPr,aPr,nPr,H3,LNe,Wc,U3,X4e,Nx,sPr,z4e,lPr,xNe,_r,jx,iPr,Qc,dPr,NY,cPr,fPr,jY,mPr,gPr,hPr,Dx,pPr,W4e,uPr,_Pr,bPr,Qt,Gx,vPr,Q4e,FPr,TPr,Hc,MPr,H4e,EPr,CPr,DY,wPr,APr,yPr,J3,LPr,zr,Ox,xPr,U4e,$Pr,kPr,Fn,SPr,J4e,RPr,PPr,Y4e,BPr,IPr,K4e,qPr,NPr,jPr,ke,Y3,Z4e,DPr,GPr,GY,OPr,VPr,XPr,K3,eEe,zPr,WPr,OY,QPr,HPr,UPr,Z3,oEe,JPr,YPr,VY,KPr,ZPr,eBr,ew,rEe,oBr,rBr,XY,tBr,aBr,nBr,ow,tEe,sBr,lBr,zY,iBr,dBr,cBr,rw,aEe,fBr,mBr,WY,gBr,hBr,pBr,tw,nEe,uBr,_Br,QY,bBr,vBr,FBr,aw,sEe,TBr,MBr,HY,EBr,CBr,wBr,nw,lEe,ABr,yBr,UY,LBr,xBr,$Br,sw,iEe,kBr,SBr,JY,RBr,PBr,BBr,lw,$Ne,Uc,iw,dEe,Vx,IBr,cEe,qBr,kNe,br,Xx,NBr,Jc,jBr,YY,DBr,GBr,KY,OBr,VBr,XBr,zx,zBr,fEe,WBr,QBr,HBr,Ht,Wx,UBr,mEe,JBr,YBr,Yc,KBr,gEe,ZBr,eIr,ZY,oIr,rIr,tIr,dw,aIr,Wr,Qx,nIr,hEe,sIr,lIr,Tn,iIr,pEe,dIr,cIr,uEe,fIr,mIr,_Ee,gIr,hIr,pIr,Ge,cw,bEe,uIr,_Ir,eK,bIr,vIr,FIr,fw,vEe,TIr,MIr,oK,EIr,CIr,wIr,mw,FEe,AIr,yIr,rK,LIr,xIr,$Ir,gw,TEe,kIr,SIr,tK,RIr,PIr,BIr,hw,MEe,IIr,qIr,aK,NIr,jIr,DIr,pw,EEe,GIr,OIr,nK,VIr,XIr,zIr,uw,CEe,WIr,QIr,sK,HIr,UIr,JIr,_w,wEe,YIr,KIr,lK,ZIr,eqr,oqr,bw,SNe,Kc,vw,AEe,Hx,rqr,yEe,tqr,RNe,vr,Ux,aqr,Zc,nqr,iK,sqr,lqr,dK,iqr,dqr,cqr,Jx,fqr,LEe,mqr,gqr,hqr,Ut,Yx,pqr,xEe,uqr,_qr,ef,bqr,$Ee,vqr,Fqr,cK,Tqr,Mqr,Eqr,Fw,Cqr,Qr,Kx,wqr,kEe,Aqr,yqr,Mn,Lqr,SEe,xqr,$qr,REe,kqr,Sqr,PEe,Rqr,Pqr,Bqr,Oe,Tw,BEe,Iqr,qqr,fK,Nqr,jqr,Dqr,Mw,IEe,Gqr,Oqr,mK,Vqr,Xqr,zqr,Ew,qEe,Wqr,Qqr,gK,Hqr,Uqr,Jqr,Cw,NEe,Yqr,Kqr,hK,Zqr,eNr,oNr,ww,jEe,rNr,tNr,pK,aNr,nNr,sNr,Aw,DEe,lNr,iNr,uK,dNr,cNr,fNr,yw,GEe,mNr,gNr,_K,hNr,pNr,uNr,Lw,OEe,_Nr,bNr,bK,vNr,FNr,TNr,xw,PNe,of,$w,VEe,Zx,MNr,XEe,ENr,BNe,Fr,e9,CNr,rf,wNr,vK,ANr,yNr,FK,LNr,xNr,$Nr,o9,kNr,zEe,SNr,RNr,PNr,Jt,r9,BNr,WEe,INr,qNr,tf,NNr,QEe,jNr,DNr,TK,GNr,ONr,VNr,kw,XNr,Hr,t9,zNr,HEe,WNr,QNr,En,HNr,UEe,UNr,JNr,JEe,YNr,KNr,YEe,ZNr,ejr,ojr,KEe,Sw,ZEe,rjr,tjr,MK,ajr,njr,sjr,Rw,INe,af,Pw,eCe,a9,ljr,oCe,ijr,qNe,Tr,n9,djr,nf,cjr,EK,fjr,mjr,CK,gjr,hjr,pjr,s9,ujr,rCe,_jr,bjr,vjr,Yt,l9,Fjr,tCe,Tjr,Mjr,sf,Ejr,aCe,Cjr,wjr,wK,Ajr,yjr,Ljr,Bw,xjr,Ur,i9,$jr,nCe,kjr,Sjr,Cn,Rjr,sCe,Pjr,Bjr,lCe,Ijr,qjr,iCe,Njr,jjr,Djr,d9,Iw,dCe,Gjr,Ojr,AK,Vjr,Xjr,zjr,qw,cCe,Wjr,Qjr,yK,Hjr,Ujr,Jjr,Nw,NNe,lf,jw,fCe,c9,Yjr,mCe,Kjr,jNe,Mr,f9,Zjr,df,eDr,LK,oDr,rDr,xK,tDr,aDr,nDr,m9,sDr,gCe,lDr,iDr,dDr,Kt,g9,cDr,hCe,fDr,mDr,cf,gDr,pCe,hDr,pDr,$K,uDr,_Dr,bDr,Dw,vDr,Jr,h9,FDr,uCe,TDr,MDr,wn,EDr,_Ce,CDr,wDr,bCe,ADr,yDr,vCe,LDr,xDr,$Dr,FCe,Gw,TCe,kDr,SDr,kK,RDr,PDr,BDr,Ow,DNe;return d=new re({}),Ca=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),c6=new re({}),f6=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),vf=new IDr({props:{warning:!0,$$slots:{default:[ILt]},$$scope:{ctx:L}}}),m6=new re({}),g6=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/configuration_auto.py#L573"}}),u6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/configuration_auto.py#L596"}}),bg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[qLt]},$$scope:{ctx:L}}}),_6=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/configuration_auto.py#L719"}}),b6=new re({}),v6=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/tokenization_auto.py#L388"}}),M6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17227/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/tokenization_auto.py#L402"}}),Kg=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[NLt]},$$scope:{ctx:L}}}),E6=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/tokenization_auto.py#L598"}}),C6=new re({}),w6=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/feature_extraction_auto.py#L187"}}),L6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17227/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/feature_extraction_auto.py#L201"}}),yh=new IDr({props:{$$slots:{default:[jLt]},$$scope:{ctx:L}}}),Lh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[DLt]},$$scope:{ctx:L}}}),x6=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/feature_extraction_auto.py#L328"}}),$6=new re({}),k6=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/processing_auto.py#L87"}}),P6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/processing_auto.py#L101"}}),Qh=new IDr({props:{$$slots:{default:[GLt]},$$scope:{ctx:L}}}),Hh=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[OLt]},$$scope:{ctx:L}}}),B6=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/processing_auto.py#L254"}}),I6=new re({}),q6=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L725"}}),j6=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Yh=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[VLt]},$$scope:{ctx:L}}}),D6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Ou=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[XLt]},$$scope:{ctx:L}}}),G6=new re({}),O6=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L732"}}),X6=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Xu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[zLt]},$$scope:{ctx:L}}}),z6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),R_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[WLt]},$$scope:{ctx:L}}}),W6=new re({}),Q6=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L747"}}),U6=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),B_=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[QLt]},$$scope:{ctx:L}}}),J6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),v2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[HLt]},$$scope:{ctx:L}}}),Y6=new re({}),K6=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L754"}}),ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),T2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[ULt]},$$scope:{ctx:L}}}),oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),a1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[JLt]},$$scope:{ctx:L}}}),ry=new re({}),ty=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L761"}}),ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),s1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[YLt]},$$scope:{ctx:L}}}),sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),C1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[KLt]},$$scope:{ctx:L}}}),ly=new re({}),iy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L770"}}),cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),A1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[ZLt]},$$scope:{ctx:L}}}),fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),F7=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[e8t]},$$scope:{ctx:L}}}),my=new re({}),gy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L804"}}),py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),M7=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[o8t]},$$scope:{ctx:L}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Z7=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[r8t]},$$scope:{ctx:L}}}),_y=new re({}),by=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L811"}}),Fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),ob=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[t8t]},$$scope:{ctx:L}}}),Ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),ib=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[a8t]},$$scope:{ctx:L}}}),My=new re({}),Ey=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L797"}}),wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),cb=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[n8t]},$$scope:{ctx:L}}}),Ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),zb=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[s8t]},$$scope:{ctx:L}}}),yy=new re({}),Ly=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L779"}}),$y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Qb=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[l8t]},$$scope:{ctx:L}}}),ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Pv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[i8t]},$$scope:{ctx:L}}}),Sy=new re({}),Ry=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L786"}}),By=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Iv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[d8t]},$$scope:{ctx:L}}}),Iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),jv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[c8t]},$$scope:{ctx:L}}}),qy=new re({}),Ny=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L820"}}),Dy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Gv=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[f8t]},$$scope:{ctx:L}}}),Gy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),eF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[m8t]},$$scope:{ctx:L}}}),Oy=new re({}),Vy=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L859"}}),zy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),rF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[g8t]},$$scope:{ctx:L}}}),Wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),nF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[h8t]},$$scope:{ctx:L}}}),Qy=new re({}),Hy=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L866"}}),Jy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),lF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[p8t]},$$scope:{ctx:L}}}),Yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),bF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[u8t]},$$scope:{ctx:L}}}),Ky=new re({}),Zy=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L889"}}),oL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),FF=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[_8t]},$$scope:{ctx:L}}}),rL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),yF=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[b8t]},$$scope:{ctx:L}}}),tL=new re({}),aL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L873"}}),sL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),xF=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[v8t]},$$scope:{ctx:L}}}),lL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),DF=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[F8t]},$$scope:{ctx:L}}}),iL=new re({}),dL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L880"}}),fL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),OF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[T8t]},$$scope:{ctx:L}}}),mL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),WF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[M8t]},$$scope:{ctx:L}}}),hL=new re({}),pL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L898"}}),_L=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),HF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[E8t]},$$scope:{ctx:L}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),oT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[C8t]},$$scope:{ctx:L}}}),vL=new re({}),FL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L905"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),tT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[w8t]},$$scope:{ctx:L}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),iT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[A8t]},$$scope:{ctx:L}}}),CL=new re({}),wL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L852"}}),yL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),cT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[y8t]},$$scope:{ctx:L}}}),LL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),hT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[L8t]},$$scope:{ctx:L}}}),$L=new re({}),kL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L827"}}),RL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),uT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[x8t]},$$scope:{ctx:L}}}),PL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),vT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[$8t]},$$scope:{ctx:L}}}),BL=new re({}),IL=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L834"}}),NL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),TT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[k8t]},$$scope:{ctx:L}}}),jL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),yT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[S8t]},$$scope:{ctx:L}}}),DL=new re({}),GL=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L843"}}),VL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),xT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[R8t]},$$scope:{ctx:L}}}),XL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),ST=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[P8t]},$$scope:{ctx:L}}}),zL=new re({}),WL=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L395"}}),HL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),PT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[B8t]},$$scope:{ctx:L}}}),UL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),yM=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[I8t]},$$scope:{ctx:L}}}),JL=new re({}),YL=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L402"}}),ZL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),xM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[q8t]},$$scope:{ctx:L}}}),e8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[N8t]},$$scope:{ctx:L}}}),o8=new re({}),r8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L417"}}),a8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),o4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[j8t]},$$scope:{ctx:L}}}),n8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),h4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[D8t]},$$scope:{ctx:L}}}),s8=new re({}),l8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),d8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),u4=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[G8t]},$$scope:{ctx:L}}}),c8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),T4=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[O8t]},$$scope:{ctx:L}}}),f8=new re({}),m8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L449"}}),h8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),E4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[V8t]},$$scope:{ctx:L}}}),p8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),X4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[X8t]},$$scope:{ctx:L}}}),u8=new re({}),_8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),v8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),W4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[z8t]},$$scope:{ctx:L}}}),F8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[W8t]},$$scope:{ctx:L}}}),T8=new re({}),M8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L465"}}),C8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Q8t]},$$scope:{ctx:L}}}),w8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),SE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[H8t]},$$scope:{ctx:L}}}),A8=new re({}),y8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),x8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),PE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[U8t]},$$scope:{ctx:L}}}),$8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),KE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[J8t]},$$scope:{ctx:L}}}),k8=new re({}),S8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L508"}}),P8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),eC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Y8t]},$$scope:{ctx:L}}}),B8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[K8t]},$$scope:{ctx:L}}}),q8=new re({}),N8=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),D8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Z8t]},$$scope:{ctx:L}}}),G8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),lC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[ext]},$$scope:{ctx:L}}}),O8=new re({}),V8=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L492"}}),z8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),dC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[oxt]},$$scope:{ctx:L}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[rxt]},$$scope:{ctx:L}}}),Q8=new re({}),H8=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L474"}}),J8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[txt]},$$scope:{ctx:L}}}),Y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),ZC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[axt]},$$scope:{ctx:L}}}),K8=new re({}),Z8=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L442"}}),ox=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),o5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[nxt]},$$scope:{ctx:L}}}),rx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),t5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[sxt]},$$scope:{ctx:L}}}),tx=new re({}),ax=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L517"}}),sx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),n5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[lxt]},$$scope:{ctx:L}}}),lx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),l5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[ixt]},$$scope:{ctx:L}}}),ix=new re({}),dx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L243"}}),fx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),d5=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[dxt]},$$scope:{ctx:L}}}),mx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),I5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[cxt]},$$scope:{ctx:L}}}),gx=new re({}),hx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L257"}}),ux=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),N5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[fxt]},$$scope:{ctx:L}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),U5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[mxt]},$$scope:{ctx:L}}}),bx=new re({}),vx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L250"}}),Tx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Y5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[gxt]},$$scope:{ctx:L}}}),Mx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),c3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[hxt]},$$scope:{ctx:L}}}),Ex=new re({}),Cx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),Ax=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[pxt]},$$scope:{ctx:L}}}),yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),E3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[uxt]},$$scope:{ctx:L}}}),Lx=new re({}),xx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L271"}}),kx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),w3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[_xt]},$$scope:{ctx:L}}}),Sx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),B3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[bxt]},$$scope:{ctx:L}}}),Rx=new re({}),Px=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L280"}}),Ix=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[vxt]},$$scope:{ctx:L}}}),qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Fxt]},$$scope:{ctx:L}}}),Nx=new re({}),jx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L289"}}),Gx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),J3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Txt]},$$scope:{ctx:L}}}),Ox=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),lw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Mxt]},$$scope:{ctx:L}}}),Vx=new re({}),Xx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L296"}}),Wx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),dw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Ext]},$$scope:{ctx:L}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),bw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Cxt]},$$scope:{ctx:L}}}),Hx=new re({}),Ux=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L305"}}),Yx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Fw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[wxt]},$$scope:{ctx:L}}}),Kx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),xw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Axt]},$$scope:{ctx:L}}}),Zx=new re({}),e9=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L312"}}),r9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),kw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[yxt]},$$scope:{ctx:L}}}),t9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Rw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Lxt]},$$scope:{ctx:L}}}),a9=new re({}),n9=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L321"}}),l9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Bw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[xxt]},$$scope:{ctx:L}}}),i9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Nw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[$xt]},$$scope:{ctx:L}}}),c9=new re({}),f9=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L330"}}),g9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Dw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[kxt]},$$scope:{ctx:L}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Ow=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Sxt]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),ci=o("Auto Classes"),hf=l(),rt=a("p"),fi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),mi=a("code"),s6=o("from_pretrained()"),pf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),De=l(),We=a("p"),gi=o("Instantiating one of "),yn=a("a"),l6=o("AutoConfig"),Ln=o(", "),xn=a("a"),i6=o("AutoModel"),hi=o(`, and
`),$n=a("a"),d6=o("AutoTokenizer"),pi=o(" will directly create a class of the relevant architecture. For instance"),uf=l(),F(Ca.$$.fragment),Qe=l(),Ae=a("p"),y$=o("will create a model that is an instance of "),ui=a("a"),L$=o("BertModel"),x$=o("."),Eo=l(),wa=a("p"),$$=o("There is one class of "),_f=a("code"),k$=o("AutoModel"),HDe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),qIe=l(),_i=a("h2"),bf=a("a"),Cee=a("span"),F(c6.$$.fragment),UDe=l(),wee=a("span"),JDe=o("Extending the Auto Classes"),NIe=l(),kn=a("p"),YDe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Aee=a("code"),KDe=o("NewModel"),ZDe=o(", make sure you have a "),yee=a("code"),eGe=o("NewModelConfig"),oGe=o(` then you can add those to the auto
classes like this:`),jIe=l(),F(f6.$$.fragment),DIe=l(),S$=a("p"),rGe=o("You will then be able to use the auto classes like you would usually do!"),GIe=l(),F(vf.$$.fragment),OIe=l(),bi=a("h2"),Ff=a("a"),Lee=a("span"),F(m6.$$.fragment),tGe=l(),xee=a("span"),aGe=o("AutoConfig"),VIe=l(),Co=a("div"),F(g6.$$.fragment),nGe=l(),h6=a("p"),sGe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),R$=a("a"),lGe=o("from_pretrained()"),iGe=o(" class method."),dGe=l(),p6=a("p"),cGe=o("This class cannot be instantiated directly using "),$ee=a("code"),fGe=o("__init__()"),mGe=o(" (throws an error)."),gGe=l(),Er=a("div"),F(u6.$$.fragment),hGe=l(),kee=a("p"),pGe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),uGe=l(),vi=a("p"),_Ge=o("The configuration class to instantiate is selected based on the "),See=a("code"),bGe=o("model_type"),vGe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Ree=a("code"),FGe=o("pretrained_model_name_or_path"),TGe=o(":"),MGe=l(),A=a("ul"),Tf=a("li"),Pee=a("strong"),EGe=o("albert"),CGe=o(" \u2014 "),P$=a("a"),wGe=o("AlbertConfig"),AGe=o(" (ALBERT model)"),yGe=l(),Mf=a("li"),Bee=a("strong"),LGe=o("bart"),xGe=o(" \u2014 "),B$=a("a"),$Ge=o("BartConfig"),kGe=o(" (BART model)"),SGe=l(),Ef=a("li"),Iee=a("strong"),RGe=o("beit"),PGe=o(" \u2014 "),I$=a("a"),BGe=o("BeitConfig"),IGe=o(" (BEiT model)"),qGe=l(),Cf=a("li"),qee=a("strong"),NGe=o("bert"),jGe=o(" \u2014 "),q$=a("a"),DGe=o("BertConfig"),GGe=o(" (BERT model)"),OGe=l(),wf=a("li"),Nee=a("strong"),VGe=o("bert-generation"),XGe=o(" \u2014 "),N$=a("a"),zGe=o("BertGenerationConfig"),WGe=o(" (Bert Generation model)"),QGe=l(),Af=a("li"),jee=a("strong"),HGe=o("big_bird"),UGe=o(" \u2014 "),j$=a("a"),JGe=o("BigBirdConfig"),YGe=o(" (BigBird model)"),KGe=l(),yf=a("li"),Dee=a("strong"),ZGe=o("bigbird_pegasus"),eOe=o(" \u2014 "),D$=a("a"),oOe=o("BigBirdPegasusConfig"),rOe=o(" (BigBirdPegasus model)"),tOe=l(),Lf=a("li"),Gee=a("strong"),aOe=o("blenderbot"),nOe=o(" \u2014 "),G$=a("a"),sOe=o("BlenderbotConfig"),lOe=o(" (Blenderbot model)"),iOe=l(),xf=a("li"),Oee=a("strong"),dOe=o("blenderbot-small"),cOe=o(" \u2014 "),O$=a("a"),fOe=o("BlenderbotSmallConfig"),mOe=o(" (BlenderbotSmall model)"),gOe=l(),$f=a("li"),Vee=a("strong"),hOe=o("camembert"),pOe=o(" \u2014 "),V$=a("a"),uOe=o("CamembertConfig"),_Oe=o(" (CamemBERT model)"),bOe=l(),kf=a("li"),Xee=a("strong"),vOe=o("canine"),FOe=o(" \u2014 "),X$=a("a"),TOe=o("CanineConfig"),MOe=o(" (Canine model)"),EOe=l(),Sf=a("li"),zee=a("strong"),COe=o("clip"),wOe=o(" \u2014 "),z$=a("a"),AOe=o("CLIPConfig"),yOe=o(" (CLIP model)"),LOe=l(),Rf=a("li"),Wee=a("strong"),xOe=o("convbert"),$Oe=o(" \u2014 "),W$=a("a"),kOe=o("ConvBertConfig"),SOe=o(" (ConvBERT model)"),ROe=l(),Pf=a("li"),Qee=a("strong"),POe=o("convnext"),BOe=o(" \u2014 "),Q$=a("a"),IOe=o("ConvNextConfig"),qOe=o(" (ConvNext model)"),NOe=l(),Bf=a("li"),Hee=a("strong"),jOe=o("ctrl"),DOe=o(" \u2014 "),H$=a("a"),GOe=o("CTRLConfig"),OOe=o(" (CTRL model)"),VOe=l(),If=a("li"),Uee=a("strong"),XOe=o("data2vec-audio"),zOe=o(" \u2014 "),U$=a("a"),WOe=o("Data2VecAudioConfig"),QOe=o(" (Data2VecAudio model)"),HOe=l(),qf=a("li"),Jee=a("strong"),UOe=o("data2vec-text"),JOe=o(" \u2014 "),J$=a("a"),YOe=o("Data2VecTextConfig"),KOe=o(" (Data2VecText model)"),ZOe=l(),Nf=a("li"),Yee=a("strong"),eVe=o("data2vec-vision"),oVe=o(" \u2014 "),Y$=a("a"),rVe=o("Data2VecVisionConfig"),tVe=o(" (Data2VecVision model)"),aVe=l(),jf=a("li"),Kee=a("strong"),nVe=o("deberta"),sVe=o(" \u2014 "),K$=a("a"),lVe=o("DebertaConfig"),iVe=o(" (DeBERTa model)"),dVe=l(),Df=a("li"),Zee=a("strong"),cVe=o("deberta-v2"),fVe=o(" \u2014 "),Z$=a("a"),mVe=o("DebertaV2Config"),gVe=o(" (DeBERTa-v2 model)"),hVe=l(),Gf=a("li"),eoe=a("strong"),pVe=o("decision_transformer"),uVe=o(" \u2014 "),ek=a("a"),_Ve=o("DecisionTransformerConfig"),bVe=o(" (Decision Transformer model)"),vVe=l(),Of=a("li"),ooe=a("strong"),FVe=o("deit"),TVe=o(" \u2014 "),ok=a("a"),MVe=o("DeiTConfig"),EVe=o(" (DeiT model)"),CVe=l(),Vf=a("li"),roe=a("strong"),wVe=o("detr"),AVe=o(" \u2014 "),rk=a("a"),yVe=o("DetrConfig"),LVe=o(" (DETR model)"),xVe=l(),Xf=a("li"),toe=a("strong"),$Ve=o("distilbert"),kVe=o(" \u2014 "),tk=a("a"),SVe=o("DistilBertConfig"),RVe=o(" (DistilBERT model)"),PVe=l(),zf=a("li"),aoe=a("strong"),BVe=o("dpr"),IVe=o(" \u2014 "),ak=a("a"),qVe=o("DPRConfig"),NVe=o(" (DPR model)"),jVe=l(),Wf=a("li"),noe=a("strong"),DVe=o("dpt"),GVe=o(" \u2014 "),nk=a("a"),OVe=o("DPTConfig"),VVe=o(" (DPT model)"),XVe=l(),Qf=a("li"),soe=a("strong"),zVe=o("electra"),WVe=o(" \u2014 "),sk=a("a"),QVe=o("ElectraConfig"),HVe=o(" (ELECTRA model)"),UVe=l(),Hf=a("li"),loe=a("strong"),JVe=o("encoder-decoder"),YVe=o(" \u2014 "),lk=a("a"),KVe=o("EncoderDecoderConfig"),ZVe=o(" (Encoder decoder model)"),eXe=l(),Uf=a("li"),ioe=a("strong"),oXe=o("flaubert"),rXe=o(" \u2014 "),ik=a("a"),tXe=o("FlaubertConfig"),aXe=o(" (FlauBERT model)"),nXe=l(),Jf=a("li"),doe=a("strong"),sXe=o("flava"),lXe=o(" \u2014 "),dk=a("a"),iXe=o("FlavaConfig"),dXe=o(" (Flava model)"),cXe=l(),Yf=a("li"),coe=a("strong"),fXe=o("fnet"),mXe=o(" \u2014 "),ck=a("a"),gXe=o("FNetConfig"),hXe=o(" (FNet model)"),pXe=l(),Kf=a("li"),foe=a("strong"),uXe=o("fsmt"),_Xe=o(" \u2014 "),fk=a("a"),bXe=o("FSMTConfig"),vXe=o(" (FairSeq Machine-Translation model)"),FXe=l(),Zf=a("li"),moe=a("strong"),TXe=o("funnel"),MXe=o(" \u2014 "),mk=a("a"),EXe=o("FunnelConfig"),CXe=o(" (Funnel Transformer model)"),wXe=l(),em=a("li"),goe=a("strong"),AXe=o("glpn"),yXe=o(" \u2014 "),gk=a("a"),LXe=o("GLPNConfig"),xXe=o(" (GLPN model)"),$Xe=l(),om=a("li"),hoe=a("strong"),kXe=o("gpt2"),SXe=o(" \u2014 "),hk=a("a"),RXe=o("GPT2Config"),PXe=o(" (OpenAI GPT-2 model)"),BXe=l(),rm=a("li"),poe=a("strong"),IXe=o("gpt_neo"),qXe=o(" \u2014 "),pk=a("a"),NXe=o("GPTNeoConfig"),jXe=o(" (GPT Neo model)"),DXe=l(),tm=a("li"),uoe=a("strong"),GXe=o("gptj"),OXe=o(" \u2014 "),uk=a("a"),VXe=o("GPTJConfig"),XXe=o(" (GPT-J model)"),zXe=l(),am=a("li"),_oe=a("strong"),WXe=o("hubert"),QXe=o(" \u2014 "),_k=a("a"),HXe=o("HubertConfig"),UXe=o(" (Hubert model)"),JXe=l(),nm=a("li"),boe=a("strong"),YXe=o("ibert"),KXe=o(" \u2014 "),bk=a("a"),ZXe=o("IBertConfig"),eze=o(" (I-BERT model)"),oze=l(),sm=a("li"),voe=a("strong"),rze=o("imagegpt"),tze=o(" \u2014 "),vk=a("a"),aze=o("ImageGPTConfig"),nze=o(" (ImageGPT model)"),sze=l(),lm=a("li"),Foe=a("strong"),lze=o("layoutlm"),ize=o(" \u2014 "),Fk=a("a"),dze=o("LayoutLMConfig"),cze=o(" (LayoutLM model)"),fze=l(),im=a("li"),Toe=a("strong"),mze=o("layoutlmv2"),gze=o(" \u2014 "),Tk=a("a"),hze=o("LayoutLMv2Config"),pze=o(" (LayoutLMv2 model)"),uze=l(),dm=a("li"),Moe=a("strong"),_ze=o("led"),bze=o(" \u2014 "),Mk=a("a"),vze=o("LEDConfig"),Fze=o(" (LED model)"),Tze=l(),cm=a("li"),Eoe=a("strong"),Mze=o("longformer"),Eze=o(" \u2014 "),Ek=a("a"),Cze=o("LongformerConfig"),wze=o(" (Longformer model)"),Aze=l(),fm=a("li"),Coe=a("strong"),yze=o("luke"),Lze=o(" \u2014 "),Ck=a("a"),xze=o("LukeConfig"),$ze=o(" (LUKE model)"),kze=l(),mm=a("li"),woe=a("strong"),Sze=o("lxmert"),Rze=o(" \u2014 "),wk=a("a"),Pze=o("LxmertConfig"),Bze=o(" (LXMERT model)"),Ize=l(),gm=a("li"),Aoe=a("strong"),qze=o("m2m_100"),Nze=o(" \u2014 "),Ak=a("a"),jze=o("M2M100Config"),Dze=o(" (M2M100 model)"),Gze=l(),hm=a("li"),yoe=a("strong"),Oze=o("marian"),Vze=o(" \u2014 "),yk=a("a"),Xze=o("MarianConfig"),zze=o(" (Marian model)"),Wze=l(),pm=a("li"),Loe=a("strong"),Qze=o("maskformer"),Hze=o(" \u2014 "),Lk=a("a"),Uze=o("MaskFormerConfig"),Jze=o(" (MaskFormer model)"),Yze=l(),um=a("li"),xoe=a("strong"),Kze=o("mbart"),Zze=o(" \u2014 "),xk=a("a"),eWe=o("MBartConfig"),oWe=o(" (mBART model)"),rWe=l(),_m=a("li"),$oe=a("strong"),tWe=o("megatron-bert"),aWe=o(" \u2014 "),$k=a("a"),nWe=o("MegatronBertConfig"),sWe=o(" (MegatronBert model)"),lWe=l(),bm=a("li"),koe=a("strong"),iWe=o("mobilebert"),dWe=o(" \u2014 "),kk=a("a"),cWe=o("MobileBertConfig"),fWe=o(" (MobileBERT model)"),mWe=l(),vm=a("li"),Soe=a("strong"),gWe=o("mpnet"),hWe=o(" \u2014 "),Sk=a("a"),pWe=o("MPNetConfig"),uWe=o(" (MPNet model)"),_We=l(),Fm=a("li"),Roe=a("strong"),bWe=o("mt5"),vWe=o(" \u2014 "),Rk=a("a"),FWe=o("MT5Config"),TWe=o(" (mT5 model)"),MWe=l(),Tm=a("li"),Poe=a("strong"),EWe=o("nystromformer"),CWe=o(" \u2014 "),Pk=a("a"),wWe=o("NystromformerConfig"),AWe=o(" (Nystromformer model)"),yWe=l(),Mm=a("li"),Boe=a("strong"),LWe=o("openai-gpt"),xWe=o(" \u2014 "),Bk=a("a"),$We=o("OpenAIGPTConfig"),kWe=o(" (OpenAI GPT model)"),SWe=l(),Em=a("li"),Ioe=a("strong"),RWe=o("opt"),PWe=o(" \u2014 "),Ik=a("a"),BWe=o("OPTConfig"),IWe=o(" (OPT model)"),qWe=l(),Cm=a("li"),qoe=a("strong"),NWe=o("pegasus"),jWe=o(" \u2014 "),qk=a("a"),DWe=o("PegasusConfig"),GWe=o(" (Pegasus model)"),OWe=l(),wm=a("li"),Noe=a("strong"),VWe=o("perceiver"),XWe=o(" \u2014 "),Nk=a("a"),zWe=o("PerceiverConfig"),WWe=o(" (Perceiver model)"),QWe=l(),Am=a("li"),joe=a("strong"),HWe=o("plbart"),UWe=o(" \u2014 "),jk=a("a"),JWe=o("PLBartConfig"),YWe=o(" (PLBart model)"),KWe=l(),ym=a("li"),Doe=a("strong"),ZWe=o("poolformer"),eQe=o(" \u2014 "),Dk=a("a"),oQe=o("PoolFormerConfig"),rQe=o(" (PoolFormer model)"),tQe=l(),Lm=a("li"),Goe=a("strong"),aQe=o("prophetnet"),nQe=o(" \u2014 "),Gk=a("a"),sQe=o("ProphetNetConfig"),lQe=o(" (ProphetNet model)"),iQe=l(),xm=a("li"),Ooe=a("strong"),dQe=o("qdqbert"),cQe=o(" \u2014 "),Ok=a("a"),fQe=o("QDQBertConfig"),mQe=o(" (QDQBert model)"),gQe=l(),$m=a("li"),Voe=a("strong"),hQe=o("rag"),pQe=o(" \u2014 "),Vk=a("a"),uQe=o("RagConfig"),_Qe=o(" (RAG model)"),bQe=l(),km=a("li"),Xoe=a("strong"),vQe=o("realm"),FQe=o(" \u2014 "),Xk=a("a"),TQe=o("RealmConfig"),MQe=o(" (Realm model)"),EQe=l(),Sm=a("li"),zoe=a("strong"),CQe=o("reformer"),wQe=o(" \u2014 "),zk=a("a"),AQe=o("ReformerConfig"),yQe=o(" (Reformer model)"),LQe=l(),Rm=a("li"),Woe=a("strong"),xQe=o("regnet"),$Qe=o(" \u2014 "),Wk=a("a"),kQe=o("RegNetConfig"),SQe=o(" (RegNet model)"),RQe=l(),Pm=a("li"),Qoe=a("strong"),PQe=o("rembert"),BQe=o(" \u2014 "),Qk=a("a"),IQe=o("RemBertConfig"),qQe=o(" (RemBERT model)"),NQe=l(),Bm=a("li"),Hoe=a("strong"),jQe=o("resnet"),DQe=o(" \u2014 "),Hk=a("a"),GQe=o("ResNetConfig"),OQe=o(" (ResNet model)"),VQe=l(),Im=a("li"),Uoe=a("strong"),XQe=o("retribert"),zQe=o(" \u2014 "),Uk=a("a"),WQe=o("RetriBertConfig"),QQe=o(" (RetriBERT model)"),HQe=l(),qm=a("li"),Joe=a("strong"),UQe=o("roberta"),JQe=o(" \u2014 "),Jk=a("a"),YQe=o("RobertaConfig"),KQe=o(" (RoBERTa model)"),ZQe=l(),Nm=a("li"),Yoe=a("strong"),eHe=o("roformer"),oHe=o(" \u2014 "),Yk=a("a"),rHe=o("RoFormerConfig"),tHe=o(" (RoFormer model)"),aHe=l(),jm=a("li"),Koe=a("strong"),nHe=o("segformer"),sHe=o(" \u2014 "),Kk=a("a"),lHe=o("SegformerConfig"),iHe=o(" (SegFormer model)"),dHe=l(),Dm=a("li"),Zoe=a("strong"),cHe=o("sew"),fHe=o(" \u2014 "),Zk=a("a"),mHe=o("SEWConfig"),gHe=o(" (SEW model)"),hHe=l(),Gm=a("li"),ere=a("strong"),pHe=o("sew-d"),uHe=o(" \u2014 "),eS=a("a"),_He=o("SEWDConfig"),bHe=o(" (SEW-D model)"),vHe=l(),Om=a("li"),ore=a("strong"),FHe=o("speech-encoder-decoder"),THe=o(" \u2014 "),oS=a("a"),MHe=o("SpeechEncoderDecoderConfig"),EHe=o(" (Speech Encoder decoder model)"),CHe=l(),Vm=a("li"),rre=a("strong"),wHe=o("speech_to_text"),AHe=o(" \u2014 "),rS=a("a"),yHe=o("Speech2TextConfig"),LHe=o(" (Speech2Text model)"),xHe=l(),Xm=a("li"),tre=a("strong"),$He=o("speech_to_text_2"),kHe=o(" \u2014 "),tS=a("a"),SHe=o("Speech2Text2Config"),RHe=o(" (Speech2Text2 model)"),PHe=l(),zm=a("li"),are=a("strong"),BHe=o("splinter"),IHe=o(" \u2014 "),aS=a("a"),qHe=o("SplinterConfig"),NHe=o(" (Splinter model)"),jHe=l(),Wm=a("li"),nre=a("strong"),DHe=o("squeezebert"),GHe=o(" \u2014 "),nS=a("a"),OHe=o("SqueezeBertConfig"),VHe=o(" (SqueezeBERT model)"),XHe=l(),Qm=a("li"),sre=a("strong"),zHe=o("swin"),WHe=o(" \u2014 "),sS=a("a"),QHe=o("SwinConfig"),HHe=o(" (Swin model)"),UHe=l(),Hm=a("li"),lre=a("strong"),JHe=o("t5"),YHe=o(" \u2014 "),lS=a("a"),KHe=o("T5Config"),ZHe=o(" (T5 model)"),eUe=l(),Um=a("li"),ire=a("strong"),oUe=o("tapas"),rUe=o(" \u2014 "),iS=a("a"),tUe=o("TapasConfig"),aUe=o(" (TAPAS model)"),nUe=l(),Jm=a("li"),dre=a("strong"),sUe=o("transfo-xl"),lUe=o(" \u2014 "),dS=a("a"),iUe=o("TransfoXLConfig"),dUe=o(" (Transformer-XL model)"),cUe=l(),Ym=a("li"),cre=a("strong"),fUe=o("trocr"),mUe=o(" \u2014 "),cS=a("a"),gUe=o("TrOCRConfig"),hUe=o(" (TrOCR model)"),pUe=l(),Km=a("li"),fre=a("strong"),uUe=o("unispeech"),_Ue=o(" \u2014 "),fS=a("a"),bUe=o("UniSpeechConfig"),vUe=o(" (UniSpeech model)"),FUe=l(),Zm=a("li"),mre=a("strong"),TUe=o("unispeech-sat"),MUe=o(" \u2014 "),mS=a("a"),EUe=o("UniSpeechSatConfig"),CUe=o(" (UniSpeechSat model)"),wUe=l(),eg=a("li"),gre=a("strong"),AUe=o("van"),yUe=o(" \u2014 "),gS=a("a"),LUe=o("VanConfig"),xUe=o(" (VAN model)"),$Ue=l(),og=a("li"),hre=a("strong"),kUe=o("vilt"),SUe=o(" \u2014 "),hS=a("a"),RUe=o("ViltConfig"),PUe=o(" (ViLT model)"),BUe=l(),rg=a("li"),pre=a("strong"),IUe=o("vision-encoder-decoder"),qUe=o(" \u2014 "),pS=a("a"),NUe=o("VisionEncoderDecoderConfig"),jUe=o(" (Vision Encoder decoder model)"),DUe=l(),tg=a("li"),ure=a("strong"),GUe=o("vision-text-dual-encoder"),OUe=o(" \u2014 "),uS=a("a"),VUe=o("VisionTextDualEncoderConfig"),XUe=o(" (VisionTextDualEncoder model)"),zUe=l(),ag=a("li"),_re=a("strong"),WUe=o("visual_bert"),QUe=o(" \u2014 "),_S=a("a"),HUe=o("VisualBertConfig"),UUe=o(" (VisualBert model)"),JUe=l(),ng=a("li"),bre=a("strong"),YUe=o("vit"),KUe=o(" \u2014 "),bS=a("a"),ZUe=o("ViTConfig"),eJe=o(" (ViT model)"),oJe=l(),sg=a("li"),vre=a("strong"),rJe=o("vit_mae"),tJe=o(" \u2014 "),vS=a("a"),aJe=o("ViTMAEConfig"),nJe=o(" (ViTMAE model)"),sJe=l(),lg=a("li"),Fre=a("strong"),lJe=o("wav2vec2"),iJe=o(" \u2014 "),FS=a("a"),dJe=o("Wav2Vec2Config"),cJe=o(" (Wav2Vec2 model)"),fJe=l(),ig=a("li"),Tre=a("strong"),mJe=o("wav2vec2-conformer"),gJe=o(" \u2014 "),TS=a("a"),hJe=o("Wav2Vec2ConformerConfig"),pJe=o(" (Wav2Vec2-Conformer model)"),uJe=l(),dg=a("li"),Mre=a("strong"),_Je=o("wavlm"),bJe=o(" \u2014 "),MS=a("a"),vJe=o("WavLMConfig"),FJe=o(" (WavLM model)"),TJe=l(),cg=a("li"),Ere=a("strong"),MJe=o("xglm"),EJe=o(" \u2014 "),ES=a("a"),CJe=o("XGLMConfig"),wJe=o(" (XGLM model)"),AJe=l(),fg=a("li"),Cre=a("strong"),yJe=o("xlm"),LJe=o(" \u2014 "),CS=a("a"),xJe=o("XLMConfig"),$Je=o(" (XLM model)"),kJe=l(),mg=a("li"),wre=a("strong"),SJe=o("xlm-prophetnet"),RJe=o(" \u2014 "),wS=a("a"),PJe=o("XLMProphetNetConfig"),BJe=o(" (XLMProphetNet model)"),IJe=l(),gg=a("li"),Are=a("strong"),qJe=o("xlm-roberta"),NJe=o(" \u2014 "),AS=a("a"),jJe=o("XLMRobertaConfig"),DJe=o(" (XLM-RoBERTa model)"),GJe=l(),hg=a("li"),yre=a("strong"),OJe=o("xlm-roberta-xl"),VJe=o(" \u2014 "),yS=a("a"),XJe=o("XLMRobertaXLConfig"),zJe=o(" (XLM-RoBERTa-XL model)"),WJe=l(),pg=a("li"),Lre=a("strong"),QJe=o("xlnet"),HJe=o(" \u2014 "),LS=a("a"),UJe=o("XLNetConfig"),JJe=o(" (XLNet model)"),YJe=l(),ug=a("li"),xre=a("strong"),KJe=o("yolos"),ZJe=o(" \u2014 "),xS=a("a"),eYe=o("YolosConfig"),oYe=o(" (YOLOS model)"),rYe=l(),_g=a("li"),$re=a("strong"),tYe=o("yoso"),aYe=o(" \u2014 "),$S=a("a"),nYe=o("YosoConfig"),sYe=o(" (YOSO model)"),lYe=l(),F(bg.$$.fragment),iYe=l(),vg=a("div"),F(_6.$$.fragment),dYe=l(),kre=a("p"),cYe=o("Register a new configuration for this class."),XIe=l(),Fi=a("h2"),Fg=a("a"),Sre=a("span"),F(b6.$$.fragment),fYe=l(),Rre=a("span"),mYe=o("AutoTokenizer"),zIe=l(),wo=a("div"),F(v6.$$.fragment),gYe=l(),F6=a("p"),hYe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),kS=a("a"),pYe=o("AutoTokenizer.from_pretrained()"),uYe=o(" class method."),_Ye=l(),T6=a("p"),bYe=o("This class cannot be instantiated directly using "),Pre=a("code"),vYe=o("__init__()"),FYe=o(" (throws an error)."),TYe=l(),Cr=a("div"),F(M6.$$.fragment),MYe=l(),Bre=a("p"),EYe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),CYe=l(),Aa=a("p"),wYe=o("The tokenizer class to instantiate is selected based on the "),Ire=a("code"),AYe=o("model_type"),yYe=o(` property of the config object (either
passed as an argument or loaded from `),qre=a("code"),LYe=o("pretrained_model_name_or_path"),xYe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nre=a("code"),$Ye=o("pretrained_model_name_or_path"),kYe=o(":"),SYe=l(),k=a("ul"),Sn=a("li"),jre=a("strong"),RYe=o("albert"),PYe=o(" \u2014 "),SS=a("a"),BYe=o("AlbertTokenizer"),IYe=o(" or "),RS=a("a"),qYe=o("AlbertTokenizerFast"),NYe=o(" (ALBERT model)"),jYe=l(),Rn=a("li"),Dre=a("strong"),DYe=o("bart"),GYe=o(" \u2014 "),PS=a("a"),OYe=o("BartTokenizer"),VYe=o(" or "),BS=a("a"),XYe=o("BartTokenizerFast"),zYe=o(" (BART model)"),WYe=l(),Pn=a("li"),Gre=a("strong"),QYe=o("barthez"),HYe=o(" \u2014 "),IS=a("a"),UYe=o("BarthezTokenizer"),JYe=o(" or "),qS=a("a"),YYe=o("BarthezTokenizerFast"),KYe=o(" (BARThez model)"),ZYe=l(),Tg=a("li"),Ore=a("strong"),eKe=o("bartpho"),oKe=o(" \u2014 "),NS=a("a"),rKe=o("BartphoTokenizer"),tKe=o(" (BARTpho model)"),aKe=l(),Bn=a("li"),Vre=a("strong"),nKe=o("bert"),sKe=o(" \u2014 "),jS=a("a"),lKe=o("BertTokenizer"),iKe=o(" or "),DS=a("a"),dKe=o("BertTokenizerFast"),cKe=o(" (BERT model)"),fKe=l(),Mg=a("li"),Xre=a("strong"),mKe=o("bert-generation"),gKe=o(" \u2014 "),GS=a("a"),hKe=o("BertGenerationTokenizer"),pKe=o(" (Bert Generation model)"),uKe=l(),Eg=a("li"),zre=a("strong"),_Ke=o("bert-japanese"),bKe=o(" \u2014 "),OS=a("a"),vKe=o("BertJapaneseTokenizer"),FKe=o(" (BertJapanese model)"),TKe=l(),Cg=a("li"),Wre=a("strong"),MKe=o("bertweet"),EKe=o(" \u2014 "),VS=a("a"),CKe=o("BertweetTokenizer"),wKe=o(" (Bertweet model)"),AKe=l(),In=a("li"),Qre=a("strong"),yKe=o("big_bird"),LKe=o(" \u2014 "),XS=a("a"),xKe=o("BigBirdTokenizer"),$Ke=o(" or "),zS=a("a"),kKe=o("BigBirdTokenizerFast"),SKe=o(" (BigBird model)"),RKe=l(),qn=a("li"),Hre=a("strong"),PKe=o("bigbird_pegasus"),BKe=o(" \u2014 "),WS=a("a"),IKe=o("PegasusTokenizer"),qKe=o(" or "),QS=a("a"),NKe=o("PegasusTokenizerFast"),jKe=o(" (BigBirdPegasus model)"),DKe=l(),Nn=a("li"),Ure=a("strong"),GKe=o("blenderbot"),OKe=o(" \u2014 "),HS=a("a"),VKe=o("BlenderbotTokenizer"),XKe=o(" or "),US=a("a"),zKe=o("BlenderbotTokenizerFast"),WKe=o(" (Blenderbot model)"),QKe=l(),wg=a("li"),Jre=a("strong"),HKe=o("blenderbot-small"),UKe=o(" \u2014 "),JS=a("a"),JKe=o("BlenderbotSmallTokenizer"),YKe=o(" (BlenderbotSmall model)"),KKe=l(),Ag=a("li"),Yre=a("strong"),ZKe=o("byt5"),eZe=o(" \u2014 "),YS=a("a"),oZe=o("ByT5Tokenizer"),rZe=o(" (ByT5 model)"),tZe=l(),jn=a("li"),Kre=a("strong"),aZe=o("camembert"),nZe=o(" \u2014 "),KS=a("a"),sZe=o("CamembertTokenizer"),lZe=o(" or "),ZS=a("a"),iZe=o("CamembertTokenizerFast"),dZe=o(" (CamemBERT model)"),cZe=l(),yg=a("li"),Zre=a("strong"),fZe=o("canine"),mZe=o(" \u2014 "),eR=a("a"),gZe=o("CanineTokenizer"),hZe=o(" (Canine model)"),pZe=l(),Dn=a("li"),ete=a("strong"),uZe=o("clip"),_Ze=o(" \u2014 "),oR=a("a"),bZe=o("CLIPTokenizer"),vZe=o(" or "),rR=a("a"),FZe=o("CLIPTokenizerFast"),TZe=o(" (CLIP model)"),MZe=l(),Gn=a("li"),ote=a("strong"),EZe=o("convbert"),CZe=o(" \u2014 "),tR=a("a"),wZe=o("ConvBertTokenizer"),AZe=o(" or "),aR=a("a"),yZe=o("ConvBertTokenizerFast"),LZe=o(" (ConvBERT model)"),xZe=l(),On=a("li"),rte=a("strong"),$Ze=o("cpm"),kZe=o(" \u2014 "),nR=a("a"),SZe=o("CpmTokenizer"),RZe=o(" or "),sR=a("a"),PZe=o("CpmTokenizerFast"),BZe=o(" (CPM model)"),IZe=l(),Lg=a("li"),tte=a("strong"),qZe=o("ctrl"),NZe=o(" \u2014 "),lR=a("a"),jZe=o("CTRLTokenizer"),DZe=o(" (CTRL model)"),GZe=l(),Vn=a("li"),ate=a("strong"),OZe=o("data2vec-text"),VZe=o(" \u2014 "),iR=a("a"),XZe=o("RobertaTokenizer"),zZe=o(" or "),dR=a("a"),WZe=o("RobertaTokenizerFast"),QZe=o(" (Data2VecText model)"),HZe=l(),Xn=a("li"),nte=a("strong"),UZe=o("deberta"),JZe=o(" \u2014 "),cR=a("a"),YZe=o("DebertaTokenizer"),KZe=o(" or "),fR=a("a"),ZZe=o("DebertaTokenizerFast"),eeo=o(" (DeBERTa model)"),oeo=l(),zn=a("li"),ste=a("strong"),reo=o("deberta-v2"),teo=o(" \u2014 "),mR=a("a"),aeo=o("DebertaV2Tokenizer"),neo=o(" or "),gR=a("a"),seo=o("DebertaV2TokenizerFast"),leo=o(" (DeBERTa-v2 model)"),ieo=l(),Wn=a("li"),lte=a("strong"),deo=o("distilbert"),ceo=o(" \u2014 "),hR=a("a"),feo=o("DistilBertTokenizer"),meo=o(" or "),pR=a("a"),geo=o("DistilBertTokenizerFast"),heo=o(" (DistilBERT model)"),peo=l(),Qn=a("li"),ite=a("strong"),ueo=o("dpr"),_eo=o(" \u2014 "),uR=a("a"),beo=o("DPRQuestionEncoderTokenizer"),veo=o(" or "),_R=a("a"),Feo=o("DPRQuestionEncoderTokenizerFast"),Teo=o(" (DPR model)"),Meo=l(),Hn=a("li"),dte=a("strong"),Eeo=o("electra"),Ceo=o(" \u2014 "),bR=a("a"),weo=o("ElectraTokenizer"),Aeo=o(" or "),vR=a("a"),yeo=o("ElectraTokenizerFast"),Leo=o(" (ELECTRA model)"),xeo=l(),xg=a("li"),cte=a("strong"),$eo=o("flaubert"),keo=o(" \u2014 "),FR=a("a"),Seo=o("FlaubertTokenizer"),Reo=o(" (FlauBERT model)"),Peo=l(),Un=a("li"),fte=a("strong"),Beo=o("fnet"),Ieo=o(" \u2014 "),TR=a("a"),qeo=o("FNetTokenizer"),Neo=o(" or "),MR=a("a"),jeo=o("FNetTokenizerFast"),Deo=o(" (FNet model)"),Geo=l(),$g=a("li"),mte=a("strong"),Oeo=o("fsmt"),Veo=o(" \u2014 "),ER=a("a"),Xeo=o("FSMTTokenizer"),zeo=o(" (FairSeq Machine-Translation model)"),Weo=l(),Jn=a("li"),gte=a("strong"),Qeo=o("funnel"),Heo=o(" \u2014 "),CR=a("a"),Ueo=o("FunnelTokenizer"),Jeo=o(" or "),wR=a("a"),Yeo=o("FunnelTokenizerFast"),Keo=o(" (Funnel Transformer model)"),Zeo=l(),Yn=a("li"),hte=a("strong"),eoo=o("gpt2"),ooo=o(" \u2014 "),AR=a("a"),roo=o("GPT2Tokenizer"),too=o(" or "),yR=a("a"),aoo=o("GPT2TokenizerFast"),noo=o(" (OpenAI GPT-2 model)"),soo=l(),Kn=a("li"),pte=a("strong"),loo=o("gpt_neo"),ioo=o(" \u2014 "),LR=a("a"),doo=o("GPT2Tokenizer"),coo=o(" or "),xR=a("a"),foo=o("GPT2TokenizerFast"),moo=o(" (GPT Neo model)"),goo=l(),Zn=a("li"),ute=a("strong"),hoo=o("gptj"),poo=o(" \u2014 "),$R=a("a"),uoo=o("GPT2Tokenizer"),_oo=o(" or "),kR=a("a"),boo=o("GPT2TokenizerFast"),voo=o(" (GPT-J model)"),Foo=l(),es=a("li"),_te=a("strong"),Too=o("herbert"),Moo=o(" \u2014 "),SR=a("a"),Eoo=o("HerbertTokenizer"),Coo=o(" or "),RR=a("a"),woo=o("HerbertTokenizerFast"),Aoo=o(" (HerBERT model)"),yoo=l(),kg=a("li"),bte=a("strong"),Loo=o("hubert"),xoo=o(" \u2014 "),PR=a("a"),$oo=o("Wav2Vec2CTCTokenizer"),koo=o(" (Hubert model)"),Soo=l(),os=a("li"),vte=a("strong"),Roo=o("ibert"),Poo=o(" \u2014 "),BR=a("a"),Boo=o("RobertaTokenizer"),Ioo=o(" or "),IR=a("a"),qoo=o("RobertaTokenizerFast"),Noo=o(" (I-BERT model)"),joo=l(),rs=a("li"),Fte=a("strong"),Doo=o("layoutlm"),Goo=o(" \u2014 "),qR=a("a"),Ooo=o("LayoutLMTokenizer"),Voo=o(" or "),NR=a("a"),Xoo=o("LayoutLMTokenizerFast"),zoo=o(" (LayoutLM model)"),Woo=l(),ts=a("li"),Tte=a("strong"),Qoo=o("layoutlmv2"),Hoo=o(" \u2014 "),jR=a("a"),Uoo=o("LayoutLMv2Tokenizer"),Joo=o(" or "),DR=a("a"),Yoo=o("LayoutLMv2TokenizerFast"),Koo=o(" (LayoutLMv2 model)"),Zoo=l(),as=a("li"),Mte=a("strong"),ero=o("layoutxlm"),oro=o(" \u2014 "),GR=a("a"),rro=o("LayoutXLMTokenizer"),tro=o(" or "),OR=a("a"),aro=o("LayoutXLMTokenizerFast"),nro=o(" (LayoutXLM model)"),sro=l(),ns=a("li"),Ete=a("strong"),lro=o("led"),iro=o(" \u2014 "),VR=a("a"),dro=o("LEDTokenizer"),cro=o(" or "),XR=a("a"),fro=o("LEDTokenizerFast"),mro=o(" (LED model)"),gro=l(),ss=a("li"),Cte=a("strong"),hro=o("longformer"),pro=o(" \u2014 "),zR=a("a"),uro=o("LongformerTokenizer"),_ro=o(" or "),WR=a("a"),bro=o("LongformerTokenizerFast"),vro=o(" (Longformer model)"),Fro=l(),Sg=a("li"),wte=a("strong"),Tro=o("luke"),Mro=o(" \u2014 "),QR=a("a"),Ero=o("LukeTokenizer"),Cro=o(" (LUKE model)"),wro=l(),ls=a("li"),Ate=a("strong"),Aro=o("lxmert"),yro=o(" \u2014 "),HR=a("a"),Lro=o("LxmertTokenizer"),xro=o(" or "),UR=a("a"),$ro=o("LxmertTokenizerFast"),kro=o(" (LXMERT model)"),Sro=l(),Rg=a("li"),yte=a("strong"),Rro=o("m2m_100"),Pro=o(" \u2014 "),JR=a("a"),Bro=o("M2M100Tokenizer"),Iro=o(" (M2M100 model)"),qro=l(),Pg=a("li"),Lte=a("strong"),Nro=o("marian"),jro=o(" \u2014 "),YR=a("a"),Dro=o("MarianTokenizer"),Gro=o(" (Marian model)"),Oro=l(),is=a("li"),xte=a("strong"),Vro=o("mbart"),Xro=o(" \u2014 "),KR=a("a"),zro=o("MBartTokenizer"),Wro=o(" or "),ZR=a("a"),Qro=o("MBartTokenizerFast"),Hro=o(" (mBART model)"),Uro=l(),ds=a("li"),$te=a("strong"),Jro=o("mbart50"),Yro=o(" \u2014 "),eP=a("a"),Kro=o("MBart50Tokenizer"),Zro=o(" or "),oP=a("a"),eto=o("MBart50TokenizerFast"),oto=o(" (mBART-50 model)"),rto=l(),cs=a("li"),kte=a("strong"),tto=o("megatron-bert"),ato=o(" \u2014 "),rP=a("a"),nto=o("BertTokenizer"),sto=o(" or "),tP=a("a"),lto=o("BertTokenizerFast"),ito=o(" (MegatronBert model)"),dto=l(),Bg=a("li"),Ste=a("strong"),cto=o("mluke"),fto=o(" \u2014 "),aP=a("a"),mto=o("MLukeTokenizer"),gto=o(" (mLUKE model)"),hto=l(),fs=a("li"),Rte=a("strong"),pto=o("mobilebert"),uto=o(" \u2014 "),nP=a("a"),_to=o("MobileBertTokenizer"),bto=o(" or "),sP=a("a"),vto=o("MobileBertTokenizerFast"),Fto=o(" (MobileBERT model)"),Tto=l(),ms=a("li"),Pte=a("strong"),Mto=o("mpnet"),Eto=o(" \u2014 "),lP=a("a"),Cto=o("MPNetTokenizer"),wto=o(" or "),iP=a("a"),Ato=o("MPNetTokenizerFast"),yto=o(" (MPNet model)"),Lto=l(),gs=a("li"),Bte=a("strong"),xto=o("mt5"),$to=o(" \u2014 "),dP=a("a"),kto=o("MT5Tokenizer"),Sto=o(" or "),cP=a("a"),Rto=o("MT5TokenizerFast"),Pto=o(" (mT5 model)"),Bto=l(),hs=a("li"),Ite=a("strong"),Ito=o("nystromformer"),qto=o(" \u2014 "),fP=a("a"),Nto=o("AlbertTokenizer"),jto=o(" or "),mP=a("a"),Dto=o("AlbertTokenizerFast"),Gto=o(" (Nystromformer model)"),Oto=l(),ps=a("li"),qte=a("strong"),Vto=o("openai-gpt"),Xto=o(" \u2014 "),gP=a("a"),zto=o("OpenAIGPTTokenizer"),Wto=o(" or "),hP=a("a"),Qto=o("OpenAIGPTTokenizerFast"),Hto=o(" (OpenAI GPT model)"),Uto=l(),Ig=a("li"),Nte=a("strong"),Jto=o("opt"),Yto=o(" \u2014 "),pP=a("a"),Kto=o("GPT2Tokenizer"),Zto=o(" (OPT model)"),eao=l(),us=a("li"),jte=a("strong"),oao=o("pegasus"),rao=o(" \u2014 "),uP=a("a"),tao=o("PegasusTokenizer"),aao=o(" or "),_P=a("a"),nao=o("PegasusTokenizerFast"),sao=o(" (Pegasus model)"),lao=l(),qg=a("li"),Dte=a("strong"),iao=o("perceiver"),dao=o(" \u2014 "),bP=a("a"),cao=o("PerceiverTokenizer"),fao=o(" (Perceiver model)"),mao=l(),Ng=a("li"),Gte=a("strong"),gao=o("phobert"),hao=o(" \u2014 "),vP=a("a"),pao=o("PhobertTokenizer"),uao=o(" (PhoBERT model)"),_ao=l(),jg=a("li"),Ote=a("strong"),bao=o("plbart"),vao=o(" \u2014 "),FP=a("a"),Fao=o("PLBartTokenizer"),Tao=o(" (PLBart model)"),Mao=l(),Dg=a("li"),Vte=a("strong"),Eao=o("prophetnet"),Cao=o(" \u2014 "),TP=a("a"),wao=o("ProphetNetTokenizer"),Aao=o(" (ProphetNet model)"),yao=l(),_s=a("li"),Xte=a("strong"),Lao=o("qdqbert"),xao=o(" \u2014 "),MP=a("a"),$ao=o("BertTokenizer"),kao=o(" or "),EP=a("a"),Sao=o("BertTokenizerFast"),Rao=o(" (QDQBert model)"),Pao=l(),Gg=a("li"),zte=a("strong"),Bao=o("rag"),Iao=o(" \u2014 "),CP=a("a"),qao=o("RagTokenizer"),Nao=o(" (RAG model)"),jao=l(),bs=a("li"),Wte=a("strong"),Dao=o("realm"),Gao=o(" \u2014 "),wP=a("a"),Oao=o("RealmTokenizer"),Vao=o(" or "),AP=a("a"),Xao=o("RealmTokenizerFast"),zao=o(" (Realm model)"),Wao=l(),vs=a("li"),Qte=a("strong"),Qao=o("reformer"),Hao=o(" \u2014 "),yP=a("a"),Uao=o("ReformerTokenizer"),Jao=o(" or "),LP=a("a"),Yao=o("ReformerTokenizerFast"),Kao=o(" (Reformer model)"),Zao=l(),Fs=a("li"),Hte=a("strong"),eno=o("rembert"),ono=o(" \u2014 "),xP=a("a"),rno=o("RemBertTokenizer"),tno=o(" or "),$P=a("a"),ano=o("RemBertTokenizerFast"),nno=o(" (RemBERT model)"),sno=l(),Ts=a("li"),Ute=a("strong"),lno=o("retribert"),ino=o(" \u2014 "),kP=a("a"),dno=o("RetriBertTokenizer"),cno=o(" or "),SP=a("a"),fno=o("RetriBertTokenizerFast"),mno=o(" (RetriBERT model)"),gno=l(),Ms=a("li"),Jte=a("strong"),hno=o("roberta"),pno=o(" \u2014 "),RP=a("a"),uno=o("RobertaTokenizer"),_no=o(" or "),PP=a("a"),bno=o("RobertaTokenizerFast"),vno=o(" (RoBERTa model)"),Fno=l(),Es=a("li"),Yte=a("strong"),Tno=o("roformer"),Mno=o(" \u2014 "),BP=a("a"),Eno=o("RoFormerTokenizer"),Cno=o(" or "),IP=a("a"),wno=o("RoFormerTokenizerFast"),Ano=o(" (RoFormer model)"),yno=l(),Og=a("li"),Kte=a("strong"),Lno=o("speech_to_text"),xno=o(" \u2014 "),qP=a("a"),$no=o("Speech2TextTokenizer"),kno=o(" (Speech2Text model)"),Sno=l(),Vg=a("li"),Zte=a("strong"),Rno=o("speech_to_text_2"),Pno=o(" \u2014 "),NP=a("a"),Bno=o("Speech2Text2Tokenizer"),Ino=o(" (Speech2Text2 model)"),qno=l(),Cs=a("li"),eae=a("strong"),Nno=o("splinter"),jno=o(" \u2014 "),jP=a("a"),Dno=o("SplinterTokenizer"),Gno=o(" or "),DP=a("a"),Ono=o("SplinterTokenizerFast"),Vno=o(" (Splinter model)"),Xno=l(),ws=a("li"),oae=a("strong"),zno=o("squeezebert"),Wno=o(" \u2014 "),GP=a("a"),Qno=o("SqueezeBertTokenizer"),Hno=o(" or "),OP=a("a"),Uno=o("SqueezeBertTokenizerFast"),Jno=o(" (SqueezeBERT model)"),Yno=l(),As=a("li"),rae=a("strong"),Kno=o("t5"),Zno=o(" \u2014 "),VP=a("a"),eso=o("T5Tokenizer"),oso=o(" or "),XP=a("a"),rso=o("T5TokenizerFast"),tso=o(" (T5 model)"),aso=l(),Xg=a("li"),tae=a("strong"),nso=o("tapas"),sso=o(" \u2014 "),zP=a("a"),lso=o("TapasTokenizer"),iso=o(" (TAPAS model)"),dso=l(),zg=a("li"),aae=a("strong"),cso=o("tapex"),fso=o(" \u2014 "),WP=a("a"),mso=o("TapexTokenizer"),gso=o(" (TAPEX model)"),hso=l(),Wg=a("li"),nae=a("strong"),pso=o("transfo-xl"),uso=o(" \u2014 "),QP=a("a"),_so=o("TransfoXLTokenizer"),bso=o(" (Transformer-XL model)"),vso=l(),ys=a("li"),sae=a("strong"),Fso=o("visual_bert"),Tso=o(" \u2014 "),HP=a("a"),Mso=o("BertTokenizer"),Eso=o(" or "),UP=a("a"),Cso=o("BertTokenizerFast"),wso=o(" (VisualBert model)"),Aso=l(),Qg=a("li"),lae=a("strong"),yso=o("wav2vec2"),Lso=o(" \u2014 "),JP=a("a"),xso=o("Wav2Vec2CTCTokenizer"),$so=o(" (Wav2Vec2 model)"),kso=l(),Hg=a("li"),iae=a("strong"),Sso=o("wav2vec2-conformer"),Rso=o(" \u2014 "),YP=a("a"),Pso=o("Wav2Vec2CTCTokenizer"),Bso=o(" (Wav2Vec2-Conformer model)"),Iso=l(),Ug=a("li"),dae=a("strong"),qso=o("wav2vec2_phoneme"),Nso=o(" \u2014 "),KP=a("a"),jso=o("Wav2Vec2PhonemeCTCTokenizer"),Dso=o(" (Wav2Vec2Phoneme model)"),Gso=l(),Ls=a("li"),cae=a("strong"),Oso=o("xglm"),Vso=o(" \u2014 "),ZP=a("a"),Xso=o("XGLMTokenizer"),zso=o(" or "),eB=a("a"),Wso=o("XGLMTokenizerFast"),Qso=o(" (XGLM model)"),Hso=l(),Jg=a("li"),fae=a("strong"),Uso=o("xlm"),Jso=o(" \u2014 "),oB=a("a"),Yso=o("XLMTokenizer"),Kso=o(" (XLM model)"),Zso=l(),Yg=a("li"),mae=a("strong"),elo=o("xlm-prophetnet"),olo=o(" \u2014 "),rB=a("a"),rlo=o("XLMProphetNetTokenizer"),tlo=o(" (XLMProphetNet model)"),alo=l(),xs=a("li"),gae=a("strong"),nlo=o("xlm-roberta"),slo=o(" \u2014 "),tB=a("a"),llo=o("XLMRobertaTokenizer"),ilo=o(" or "),aB=a("a"),dlo=o("XLMRobertaTokenizerFast"),clo=o(" (XLM-RoBERTa model)"),flo=l(),$s=a("li"),hae=a("strong"),mlo=o("xlm-roberta-xl"),glo=o(" \u2014 "),nB=a("a"),hlo=o("RobertaTokenizer"),plo=o(" or "),sB=a("a"),ulo=o("RobertaTokenizerFast"),_lo=o(" (XLM-RoBERTa-XL model)"),blo=l(),ks=a("li"),pae=a("strong"),vlo=o("xlnet"),Flo=o(" \u2014 "),lB=a("a"),Tlo=o("XLNetTokenizer"),Mlo=o(" or "),iB=a("a"),Elo=o("XLNetTokenizerFast"),Clo=o(" (XLNet model)"),wlo=l(),Ss=a("li"),uae=a("strong"),Alo=o("yoso"),ylo=o(" \u2014 "),dB=a("a"),Llo=o("AlbertTokenizer"),xlo=o(" or "),cB=a("a"),$lo=o("AlbertTokenizerFast"),klo=o(" (YOSO model)"),Slo=l(),F(Kg.$$.fragment),Rlo=l(),Zg=a("div"),F(E6.$$.fragment),Plo=l(),_ae=a("p"),Blo=o("Register a new tokenizer in this mapping."),WIe=l(),Ti=a("h2"),eh=a("a"),bae=a("span"),F(C6.$$.fragment),Ilo=l(),vae=a("span"),qlo=o("AutoFeatureExtractor"),QIe=l(),Ao=a("div"),F(w6.$$.fragment),Nlo=l(),A6=a("p"),jlo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),fB=a("a"),Dlo=o("AutoFeatureExtractor.from_pretrained()"),Glo=o(" class method."),Olo=l(),y6=a("p"),Vlo=o("This class cannot be instantiated directly using "),Fae=a("code"),Xlo=o("__init__()"),zlo=o(" (throws an error)."),Wlo=l(),He=a("div"),F(L6.$$.fragment),Qlo=l(),Tae=a("p"),Hlo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Ulo=l(),ya=a("p"),Jlo=o("The feature extractor class to instantiate is selected based on the "),Mae=a("code"),Ylo=o("model_type"),Klo=o(` property of the config object
(either passed as an argument or loaded from `),Eae=a("code"),Zlo=o("pretrained_model_name_or_path"),eio=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Cae=a("code"),oio=o("pretrained_model_name_or_path"),rio=o(":"),tio=l(),Z=a("ul"),oh=a("li"),wae=a("strong"),aio=o("beit"),nio=o(" \u2014 "),mB=a("a"),sio=o("BeitFeatureExtractor"),lio=o(" (BEiT model)"),iio=l(),rh=a("li"),Aae=a("strong"),dio=o("clip"),cio=o(" \u2014 "),gB=a("a"),fio=o("CLIPFeatureExtractor"),mio=o(" (CLIP model)"),gio=l(),th=a("li"),yae=a("strong"),hio=o("convnext"),pio=o(" \u2014 "),hB=a("a"),uio=o("ConvNextFeatureExtractor"),_io=o(" (ConvNext model)"),bio=l(),ah=a("li"),Lae=a("strong"),vio=o("data2vec-audio"),Fio=o(" \u2014 "),pB=a("a"),Tio=o("Wav2Vec2FeatureExtractor"),Mio=o(" (Data2VecAudio model)"),Eio=l(),nh=a("li"),xae=a("strong"),Cio=o("data2vec-vision"),wio=o(" \u2014 "),uB=a("a"),Aio=o("BeitFeatureExtractor"),yio=o(" (Data2VecVision model)"),Lio=l(),sh=a("li"),$ae=a("strong"),xio=o("deit"),$io=o(" \u2014 "),_B=a("a"),kio=o("DeiTFeatureExtractor"),Sio=o(" (DeiT model)"),Rio=l(),lh=a("li"),kae=a("strong"),Pio=o("detr"),Bio=o(" \u2014 "),bB=a("a"),Iio=o("DetrFeatureExtractor"),qio=o(" (DETR model)"),Nio=l(),ih=a("li"),Sae=a("strong"),jio=o("dpt"),Dio=o(" \u2014 "),vB=a("a"),Gio=o("DPTFeatureExtractor"),Oio=o(" (DPT model)"),Vio=l(),dh=a("li"),Rae=a("strong"),Xio=o("flava"),zio=o(" \u2014 "),FB=a("a"),Wio=o("FlavaFeatureExtractor"),Qio=o(" (Flava model)"),Hio=l(),ch=a("li"),Pae=a("strong"),Uio=o("glpn"),Jio=o(" \u2014 "),TB=a("a"),Yio=o("GLPNFeatureExtractor"),Kio=o(" (GLPN model)"),Zio=l(),fh=a("li"),Bae=a("strong"),edo=o("hubert"),odo=o(" \u2014 "),MB=a("a"),rdo=o("Wav2Vec2FeatureExtractor"),tdo=o(" (Hubert model)"),ado=l(),mh=a("li"),Iae=a("strong"),ndo=o("layoutlmv2"),sdo=o(" \u2014 "),EB=a("a"),ldo=o("LayoutLMv2FeatureExtractor"),ido=o(" (LayoutLMv2 model)"),ddo=l(),gh=a("li"),qae=a("strong"),cdo=o("maskformer"),fdo=o(" \u2014 "),CB=a("a"),mdo=o("MaskFormerFeatureExtractor"),gdo=o(" (MaskFormer model)"),hdo=l(),hh=a("li"),Nae=a("strong"),pdo=o("perceiver"),udo=o(" \u2014 "),wB=a("a"),_do=o("PerceiverFeatureExtractor"),bdo=o(" (Perceiver model)"),vdo=l(),ph=a("li"),jae=a("strong"),Fdo=o("poolformer"),Tdo=o(" \u2014 "),AB=a("a"),Mdo=o("PoolFormerFeatureExtractor"),Edo=o(" (PoolFormer model)"),Cdo=l(),uh=a("li"),Dae=a("strong"),wdo=o("regnet"),Ado=o(" \u2014 "),yB=a("a"),ydo=o("ConvNextFeatureExtractor"),Ldo=o(" (RegNet model)"),xdo=l(),_h=a("li"),Gae=a("strong"),$do=o("resnet"),kdo=o(" \u2014 "),LB=a("a"),Sdo=o("ConvNextFeatureExtractor"),Rdo=o(" (ResNet model)"),Pdo=l(),bh=a("li"),Oae=a("strong"),Bdo=o("segformer"),Ido=o(" \u2014 "),xB=a("a"),qdo=o("SegformerFeatureExtractor"),Ndo=o(" (SegFormer model)"),jdo=l(),vh=a("li"),Vae=a("strong"),Ddo=o("speech_to_text"),Gdo=o(" \u2014 "),$B=a("a"),Odo=o("Speech2TextFeatureExtractor"),Vdo=o(" (Speech2Text model)"),Xdo=l(),Fh=a("li"),Xae=a("strong"),zdo=o("swin"),Wdo=o(" \u2014 "),kB=a("a"),Qdo=o("ViTFeatureExtractor"),Hdo=o(" (Swin model)"),Udo=l(),Th=a("li"),zae=a("strong"),Jdo=o("van"),Ydo=o(" \u2014 "),SB=a("a"),Kdo=o("ConvNextFeatureExtractor"),Zdo=o(" (VAN model)"),eco=l(),Mh=a("li"),Wae=a("strong"),oco=o("vit"),rco=o(" \u2014 "),RB=a("a"),tco=o("ViTFeatureExtractor"),aco=o(" (ViT model)"),nco=l(),Eh=a("li"),Qae=a("strong"),sco=o("vit_mae"),lco=o(" \u2014 "),PB=a("a"),ico=o("ViTFeatureExtractor"),dco=o(" (ViTMAE model)"),cco=l(),Ch=a("li"),Hae=a("strong"),fco=o("wav2vec2"),mco=o(" \u2014 "),BB=a("a"),gco=o("Wav2Vec2FeatureExtractor"),hco=o(" (Wav2Vec2 model)"),pco=l(),wh=a("li"),Uae=a("strong"),uco=o("wav2vec2-conformer"),_co=o(" \u2014 "),IB=a("a"),bco=o("Wav2Vec2FeatureExtractor"),vco=o(" (Wav2Vec2-Conformer model)"),Fco=l(),Ah=a("li"),Jae=a("strong"),Tco=o("yolos"),Mco=o(" \u2014 "),qB=a("a"),Eco=o("YolosFeatureExtractor"),Cco=o(" (YOLOS model)"),wco=l(),F(yh.$$.fragment),Aco=l(),F(Lh.$$.fragment),yco=l(),xh=a("div"),F(x6.$$.fragment),Lco=l(),Yae=a("p"),xco=o("Register a new feature extractor for this class."),HIe=l(),Mi=a("h2"),$h=a("a"),Kae=a("span"),F($6.$$.fragment),$co=l(),Zae=a("span"),kco=o("AutoProcessor"),UIe=l(),yo=a("div"),F(k6.$$.fragment),Sco=l(),S6=a("p"),Rco=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),NB=a("a"),Pco=o("AutoProcessor.from_pretrained()"),Bco=o(" class method."),Ico=l(),R6=a("p"),qco=o("This class cannot be instantiated directly using "),ene=a("code"),Nco=o("__init__()"),jco=o(" (throws an error)."),Dco=l(),Ue=a("div"),F(P6.$$.fragment),Gco=l(),one=a("p"),Oco=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Vco=l(),Ei=a("p"),Xco=o("The processor class to instantiate is selected based on the "),rne=a("code"),zco=o("model_type"),Wco=o(` property of the config object (either
passed as an argument or loaded from `),tne=a("code"),Qco=o("pretrained_model_name_or_path"),Hco=o(" if possible):"),Uco=l(),pe=a("ul"),kh=a("li"),ane=a("strong"),Jco=o("clip"),Yco=o(" \u2014 "),jB=a("a"),Kco=o("CLIPProcessor"),Zco=o(" (CLIP model)"),efo=l(),Sh=a("li"),nne=a("strong"),ofo=o("flava"),rfo=o(" \u2014 "),sne=a("code"),tfo=o("FLAVAProcessor"),afo=o(" (Flava model)"),nfo=l(),Rh=a("li"),lne=a("strong"),sfo=o("layoutlmv2"),lfo=o(" \u2014 "),DB=a("a"),ifo=o("LayoutLMv2Processor"),dfo=o(" (LayoutLMv2 model)"),cfo=l(),Ph=a("li"),ine=a("strong"),ffo=o("layoutxlm"),mfo=o(" \u2014 "),GB=a("a"),gfo=o("LayoutXLMProcessor"),hfo=o(" (LayoutXLM model)"),pfo=l(),Bh=a("li"),dne=a("strong"),ufo=o("sew"),_fo=o(" \u2014 "),OB=a("a"),bfo=o("Wav2Vec2Processor"),vfo=o(" (SEW model)"),Ffo=l(),Ih=a("li"),cne=a("strong"),Tfo=o("sew-d"),Mfo=o(" \u2014 "),VB=a("a"),Efo=o("Wav2Vec2Processor"),Cfo=o(" (SEW-D model)"),wfo=l(),qh=a("li"),fne=a("strong"),Afo=o("speech_to_text"),yfo=o(" \u2014 "),XB=a("a"),Lfo=o("Speech2TextProcessor"),xfo=o(" (Speech2Text model)"),$fo=l(),Nh=a("li"),mne=a("strong"),kfo=o("speech_to_text_2"),Sfo=o(" \u2014 "),zB=a("a"),Rfo=o("Speech2Text2Processor"),Pfo=o(" (Speech2Text2 model)"),Bfo=l(),jh=a("li"),gne=a("strong"),Ifo=o("trocr"),qfo=o(" \u2014 "),WB=a("a"),Nfo=o("TrOCRProcessor"),jfo=o(" (TrOCR model)"),Dfo=l(),Dh=a("li"),hne=a("strong"),Gfo=o("unispeech"),Ofo=o(" \u2014 "),QB=a("a"),Vfo=o("Wav2Vec2Processor"),Xfo=o(" (UniSpeech model)"),zfo=l(),Gh=a("li"),pne=a("strong"),Wfo=o("unispeech-sat"),Qfo=o(" \u2014 "),HB=a("a"),Hfo=o("Wav2Vec2Processor"),Ufo=o(" (UniSpeechSat model)"),Jfo=l(),Oh=a("li"),une=a("strong"),Yfo=o("vilt"),Kfo=o(" \u2014 "),UB=a("a"),Zfo=o("ViltProcessor"),emo=o(" (ViLT model)"),omo=l(),Vh=a("li"),_ne=a("strong"),rmo=o("vision-text-dual-encoder"),tmo=o(" \u2014 "),JB=a("a"),amo=o("VisionTextDualEncoderProcessor"),nmo=o(" (VisionTextDualEncoder model)"),smo=l(),Xh=a("li"),bne=a("strong"),lmo=o("wav2vec2"),imo=o(" \u2014 "),YB=a("a"),dmo=o("Wav2Vec2Processor"),cmo=o(" (Wav2Vec2 model)"),fmo=l(),zh=a("li"),vne=a("strong"),mmo=o("wav2vec2-conformer"),gmo=o(" \u2014 "),KB=a("a"),hmo=o("Wav2Vec2Processor"),pmo=o(" (Wav2Vec2-Conformer model)"),umo=l(),Wh=a("li"),Fne=a("strong"),_mo=o("wavlm"),bmo=o(" \u2014 "),ZB=a("a"),vmo=o("Wav2Vec2Processor"),Fmo=o(" (WavLM model)"),Tmo=l(),F(Qh.$$.fragment),Mmo=l(),F(Hh.$$.fragment),Emo=l(),Uh=a("div"),F(B6.$$.fragment),Cmo=l(),Tne=a("p"),wmo=o("Register a new processor for this class."),JIe=l(),Ci=a("h2"),Jh=a("a"),Mne=a("span"),F(I6.$$.fragment),Amo=l(),Ene=a("span"),ymo=o("AutoModel"),YIe=l(),Lo=a("div"),F(q6.$$.fragment),Lmo=l(),wi=a("p"),xmo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),eI=a("a"),$mo=o("from_pretrained()"),kmo=o(" class method or the "),oI=a("a"),Smo=o("from_config()"),Rmo=o(` class
method.`),Pmo=l(),N6=a("p"),Bmo=o("This class cannot be instantiated directly using "),Cne=a("code"),Imo=o("__init__()"),qmo=o(" (throws an error)."),Nmo=l(),tt=a("div"),F(j6.$$.fragment),jmo=l(),wne=a("p"),Dmo=o("Instantiates one of the base model classes of the library from a configuration."),Gmo=l(),Ai=a("p"),Omo=o(`Note:
Loading a model from its configuration file does `),Ane=a("strong"),Vmo=o("not"),Xmo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rI=a("a"),zmo=o("from_pretrained()"),Wmo=o(" to load the model weights."),Qmo=l(),F(Yh.$$.fragment),Hmo=l(),Je=a("div"),F(D6.$$.fragment),Umo=l(),yne=a("p"),Jmo=o("Instantiate one of the base model classes of the library from a pretrained model."),Ymo=l(),La=a("p"),Kmo=o("The model class to instantiate is selected based on the "),Lne=a("code"),Zmo=o("model_type"),ego=o(` property of the config object (either
passed as an argument or loaded from `),xne=a("code"),ogo=o("pretrained_model_name_or_path"),rgo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ne=a("code"),tgo=o("pretrained_model_name_or_path"),ago=o(":"),ngo=l(),x=a("ul"),Kh=a("li"),kne=a("strong"),sgo=o("albert"),lgo=o(" \u2014 "),tI=a("a"),igo=o("AlbertModel"),dgo=o(" (ALBERT model)"),cgo=l(),Zh=a("li"),Sne=a("strong"),fgo=o("bart"),mgo=o(" \u2014 "),aI=a("a"),ggo=o("BartModel"),hgo=o(" (BART model)"),pgo=l(),ep=a("li"),Rne=a("strong"),ugo=o("beit"),_go=o(" \u2014 "),nI=a("a"),bgo=o("BeitModel"),vgo=o(" (BEiT model)"),Fgo=l(),op=a("li"),Pne=a("strong"),Tgo=o("bert"),Mgo=o(" \u2014 "),sI=a("a"),Ego=o("BertModel"),Cgo=o(" (BERT model)"),wgo=l(),rp=a("li"),Bne=a("strong"),Ago=o("bert-generation"),ygo=o(" \u2014 "),lI=a("a"),Lgo=o("BertGenerationEncoder"),xgo=o(" (Bert Generation model)"),$go=l(),tp=a("li"),Ine=a("strong"),kgo=o("big_bird"),Sgo=o(" \u2014 "),iI=a("a"),Rgo=o("BigBirdModel"),Pgo=o(" (BigBird model)"),Bgo=l(),ap=a("li"),qne=a("strong"),Igo=o("bigbird_pegasus"),qgo=o(" \u2014 "),dI=a("a"),Ngo=o("BigBirdPegasusModel"),jgo=o(" (BigBirdPegasus model)"),Dgo=l(),np=a("li"),Nne=a("strong"),Ggo=o("blenderbot"),Ogo=o(" \u2014 "),cI=a("a"),Vgo=o("BlenderbotModel"),Xgo=o(" (Blenderbot model)"),zgo=l(),sp=a("li"),jne=a("strong"),Wgo=o("blenderbot-small"),Qgo=o(" \u2014 "),fI=a("a"),Hgo=o("BlenderbotSmallModel"),Ugo=o(" (BlenderbotSmall model)"),Jgo=l(),lp=a("li"),Dne=a("strong"),Ygo=o("camembert"),Kgo=o(" \u2014 "),mI=a("a"),Zgo=o("CamembertModel"),eho=o(" (CamemBERT model)"),oho=l(),ip=a("li"),Gne=a("strong"),rho=o("canine"),tho=o(" \u2014 "),gI=a("a"),aho=o("CanineModel"),nho=o(" (Canine model)"),sho=l(),dp=a("li"),One=a("strong"),lho=o("clip"),iho=o(" \u2014 "),hI=a("a"),dho=o("CLIPModel"),cho=o(" (CLIP model)"),fho=l(),cp=a("li"),Vne=a("strong"),mho=o("convbert"),gho=o(" \u2014 "),pI=a("a"),hho=o("ConvBertModel"),pho=o(" (ConvBERT model)"),uho=l(),fp=a("li"),Xne=a("strong"),_ho=o("convnext"),bho=o(" \u2014 "),uI=a("a"),vho=o("ConvNextModel"),Fho=o(" (ConvNext model)"),Tho=l(),mp=a("li"),zne=a("strong"),Mho=o("ctrl"),Eho=o(" \u2014 "),_I=a("a"),Cho=o("CTRLModel"),who=o(" (CTRL model)"),Aho=l(),gp=a("li"),Wne=a("strong"),yho=o("data2vec-audio"),Lho=o(" \u2014 "),bI=a("a"),xho=o("Data2VecAudioModel"),$ho=o(" (Data2VecAudio model)"),kho=l(),hp=a("li"),Qne=a("strong"),Sho=o("data2vec-text"),Rho=o(" \u2014 "),vI=a("a"),Pho=o("Data2VecTextModel"),Bho=o(" (Data2VecText model)"),Iho=l(),pp=a("li"),Hne=a("strong"),qho=o("data2vec-vision"),Nho=o(" \u2014 "),FI=a("a"),jho=o("Data2VecVisionModel"),Dho=o(" (Data2VecVision model)"),Gho=l(),up=a("li"),Une=a("strong"),Oho=o("deberta"),Vho=o(" \u2014 "),TI=a("a"),Xho=o("DebertaModel"),zho=o(" (DeBERTa model)"),Who=l(),_p=a("li"),Jne=a("strong"),Qho=o("deberta-v2"),Hho=o(" \u2014 "),MI=a("a"),Uho=o("DebertaV2Model"),Jho=o(" (DeBERTa-v2 model)"),Yho=l(),bp=a("li"),Yne=a("strong"),Kho=o("decision_transformer"),Zho=o(" \u2014 "),EI=a("a"),epo=o("DecisionTransformerModel"),opo=o(" (Decision Transformer model)"),rpo=l(),vp=a("li"),Kne=a("strong"),tpo=o("deit"),apo=o(" \u2014 "),CI=a("a"),npo=o("DeiTModel"),spo=o(" (DeiT model)"),lpo=l(),Fp=a("li"),Zne=a("strong"),ipo=o("detr"),dpo=o(" \u2014 "),wI=a("a"),cpo=o("DetrModel"),fpo=o(" (DETR model)"),mpo=l(),Tp=a("li"),ese=a("strong"),gpo=o("distilbert"),hpo=o(" \u2014 "),AI=a("a"),ppo=o("DistilBertModel"),upo=o(" (DistilBERT model)"),_po=l(),Mp=a("li"),ose=a("strong"),bpo=o("dpr"),vpo=o(" \u2014 "),yI=a("a"),Fpo=o("DPRQuestionEncoder"),Tpo=o(" (DPR model)"),Mpo=l(),Ep=a("li"),rse=a("strong"),Epo=o("dpt"),Cpo=o(" \u2014 "),LI=a("a"),wpo=o("DPTModel"),Apo=o(" (DPT model)"),ypo=l(),Cp=a("li"),tse=a("strong"),Lpo=o("electra"),xpo=o(" \u2014 "),xI=a("a"),$po=o("ElectraModel"),kpo=o(" (ELECTRA model)"),Spo=l(),wp=a("li"),ase=a("strong"),Rpo=o("flaubert"),Ppo=o(" \u2014 "),$I=a("a"),Bpo=o("FlaubertModel"),Ipo=o(" (FlauBERT model)"),qpo=l(),Ap=a("li"),nse=a("strong"),Npo=o("flava"),jpo=o(" \u2014 "),kI=a("a"),Dpo=o("FlavaModel"),Gpo=o(" (Flava model)"),Opo=l(),yp=a("li"),sse=a("strong"),Vpo=o("fnet"),Xpo=o(" \u2014 "),SI=a("a"),zpo=o("FNetModel"),Wpo=o(" (FNet model)"),Qpo=l(),Lp=a("li"),lse=a("strong"),Hpo=o("fsmt"),Upo=o(" \u2014 "),RI=a("a"),Jpo=o("FSMTModel"),Ypo=o(" (FairSeq Machine-Translation model)"),Kpo=l(),Rs=a("li"),ise=a("strong"),Zpo=o("funnel"),euo=o(" \u2014 "),PI=a("a"),ouo=o("FunnelModel"),ruo=o(" or "),BI=a("a"),tuo=o("FunnelBaseModel"),auo=o(" (Funnel Transformer model)"),nuo=l(),xp=a("li"),dse=a("strong"),suo=o("glpn"),luo=o(" \u2014 "),II=a("a"),iuo=o("GLPNModel"),duo=o(" (GLPN model)"),cuo=l(),$p=a("li"),cse=a("strong"),fuo=o("gpt2"),muo=o(" \u2014 "),qI=a("a"),guo=o("GPT2Model"),huo=o(" (OpenAI GPT-2 model)"),puo=l(),kp=a("li"),fse=a("strong"),uuo=o("gpt_neo"),_uo=o(" \u2014 "),NI=a("a"),buo=o("GPTNeoModel"),vuo=o(" (GPT Neo model)"),Fuo=l(),Sp=a("li"),mse=a("strong"),Tuo=o("gptj"),Muo=o(" \u2014 "),jI=a("a"),Euo=o("GPTJModel"),Cuo=o(" (GPT-J model)"),wuo=l(),Rp=a("li"),gse=a("strong"),Auo=o("hubert"),yuo=o(" \u2014 "),DI=a("a"),Luo=o("HubertModel"),xuo=o(" (Hubert model)"),$uo=l(),Pp=a("li"),hse=a("strong"),kuo=o("ibert"),Suo=o(" \u2014 "),GI=a("a"),Ruo=o("IBertModel"),Puo=o(" (I-BERT model)"),Buo=l(),Bp=a("li"),pse=a("strong"),Iuo=o("imagegpt"),quo=o(" \u2014 "),OI=a("a"),Nuo=o("ImageGPTModel"),juo=o(" (ImageGPT model)"),Duo=l(),Ip=a("li"),use=a("strong"),Guo=o("layoutlm"),Ouo=o(" \u2014 "),VI=a("a"),Vuo=o("LayoutLMModel"),Xuo=o(" (LayoutLM model)"),zuo=l(),qp=a("li"),_se=a("strong"),Wuo=o("layoutlmv2"),Quo=o(" \u2014 "),XI=a("a"),Huo=o("LayoutLMv2Model"),Uuo=o(" (LayoutLMv2 model)"),Juo=l(),Np=a("li"),bse=a("strong"),Yuo=o("led"),Kuo=o(" \u2014 "),zI=a("a"),Zuo=o("LEDModel"),e_o=o(" (LED model)"),o_o=l(),jp=a("li"),vse=a("strong"),r_o=o("longformer"),t_o=o(" \u2014 "),WI=a("a"),a_o=o("LongformerModel"),n_o=o(" (Longformer model)"),s_o=l(),Dp=a("li"),Fse=a("strong"),l_o=o("luke"),i_o=o(" \u2014 "),QI=a("a"),d_o=o("LukeModel"),c_o=o(" (LUKE model)"),f_o=l(),Gp=a("li"),Tse=a("strong"),m_o=o("lxmert"),g_o=o(" \u2014 "),HI=a("a"),h_o=o("LxmertModel"),p_o=o(" (LXMERT model)"),u_o=l(),Op=a("li"),Mse=a("strong"),__o=o("m2m_100"),b_o=o(" \u2014 "),UI=a("a"),v_o=o("M2M100Model"),F_o=o(" (M2M100 model)"),T_o=l(),Vp=a("li"),Ese=a("strong"),M_o=o("marian"),E_o=o(" \u2014 "),JI=a("a"),C_o=o("MarianModel"),w_o=o(" (Marian model)"),A_o=l(),Xp=a("li"),Cse=a("strong"),y_o=o("maskformer"),L_o=o(" \u2014 "),YI=a("a"),x_o=o("MaskFormerModel"),$_o=o(" (MaskFormer model)"),k_o=l(),zp=a("li"),wse=a("strong"),S_o=o("mbart"),R_o=o(" \u2014 "),KI=a("a"),P_o=o("MBartModel"),B_o=o(" (mBART model)"),I_o=l(),Wp=a("li"),Ase=a("strong"),q_o=o("megatron-bert"),N_o=o(" \u2014 "),ZI=a("a"),j_o=o("MegatronBertModel"),D_o=o(" (MegatronBert model)"),G_o=l(),Qp=a("li"),yse=a("strong"),O_o=o("mobilebert"),V_o=o(" \u2014 "),eq=a("a"),X_o=o("MobileBertModel"),z_o=o(" (MobileBERT model)"),W_o=l(),Hp=a("li"),Lse=a("strong"),Q_o=o("mpnet"),H_o=o(" \u2014 "),oq=a("a"),U_o=o("MPNetModel"),J_o=o(" (MPNet model)"),Y_o=l(),Up=a("li"),xse=a("strong"),K_o=o("mt5"),Z_o=o(" \u2014 "),rq=a("a"),e2o=o("MT5Model"),o2o=o(" (mT5 model)"),r2o=l(),Jp=a("li"),$se=a("strong"),t2o=o("nystromformer"),a2o=o(" \u2014 "),tq=a("a"),n2o=o("NystromformerModel"),s2o=o(" (Nystromformer model)"),l2o=l(),Yp=a("li"),kse=a("strong"),i2o=o("openai-gpt"),d2o=o(" \u2014 "),aq=a("a"),c2o=o("OpenAIGPTModel"),f2o=o(" (OpenAI GPT model)"),m2o=l(),Kp=a("li"),Sse=a("strong"),g2o=o("opt"),h2o=o(" \u2014 "),nq=a("a"),p2o=o("OPTModel"),u2o=o(" (OPT model)"),_2o=l(),Zp=a("li"),Rse=a("strong"),b2o=o("pegasus"),v2o=o(" \u2014 "),sq=a("a"),F2o=o("PegasusModel"),T2o=o(" (Pegasus model)"),M2o=l(),eu=a("li"),Pse=a("strong"),E2o=o("perceiver"),C2o=o(" \u2014 "),lq=a("a"),w2o=o("PerceiverModel"),A2o=o(" (Perceiver model)"),y2o=l(),ou=a("li"),Bse=a("strong"),L2o=o("plbart"),x2o=o(" \u2014 "),iq=a("a"),$2o=o("PLBartModel"),k2o=o(" (PLBart model)"),S2o=l(),ru=a("li"),Ise=a("strong"),R2o=o("poolformer"),P2o=o(" \u2014 "),dq=a("a"),B2o=o("PoolFormerModel"),I2o=o(" (PoolFormer model)"),q2o=l(),tu=a("li"),qse=a("strong"),N2o=o("prophetnet"),j2o=o(" \u2014 "),cq=a("a"),D2o=o("ProphetNetModel"),G2o=o(" (ProphetNet model)"),O2o=l(),au=a("li"),Nse=a("strong"),V2o=o("qdqbert"),X2o=o(" \u2014 "),fq=a("a"),z2o=o("QDQBertModel"),W2o=o(" (QDQBert model)"),Q2o=l(),nu=a("li"),jse=a("strong"),H2o=o("reformer"),U2o=o(" \u2014 "),mq=a("a"),J2o=o("ReformerModel"),Y2o=o(" (Reformer model)"),K2o=l(),su=a("li"),Dse=a("strong"),Z2o=o("regnet"),e1o=o(" \u2014 "),gq=a("a"),o1o=o("RegNetModel"),r1o=o(" (RegNet model)"),t1o=l(),lu=a("li"),Gse=a("strong"),a1o=o("rembert"),n1o=o(" \u2014 "),hq=a("a"),s1o=o("RemBertModel"),l1o=o(" (RemBERT model)"),i1o=l(),iu=a("li"),Ose=a("strong"),d1o=o("resnet"),c1o=o(" \u2014 "),pq=a("a"),f1o=o("ResNetModel"),m1o=o(" (ResNet model)"),g1o=l(),du=a("li"),Vse=a("strong"),h1o=o("retribert"),p1o=o(" \u2014 "),uq=a("a"),u1o=o("RetriBertModel"),_1o=o(" (RetriBERT model)"),b1o=l(),cu=a("li"),Xse=a("strong"),v1o=o("roberta"),F1o=o(" \u2014 "),_q=a("a"),T1o=o("RobertaModel"),M1o=o(" (RoBERTa model)"),E1o=l(),fu=a("li"),zse=a("strong"),C1o=o("roformer"),w1o=o(" \u2014 "),bq=a("a"),A1o=o("RoFormerModel"),y1o=o(" (RoFormer model)"),L1o=l(),mu=a("li"),Wse=a("strong"),x1o=o("segformer"),$1o=o(" \u2014 "),vq=a("a"),k1o=o("SegformerModel"),S1o=o(" (SegFormer model)"),R1o=l(),gu=a("li"),Qse=a("strong"),P1o=o("sew"),B1o=o(" \u2014 "),Fq=a("a"),I1o=o("SEWModel"),q1o=o(" (SEW model)"),N1o=l(),hu=a("li"),Hse=a("strong"),j1o=o("sew-d"),D1o=o(" \u2014 "),Tq=a("a"),G1o=o("SEWDModel"),O1o=o(" (SEW-D model)"),V1o=l(),pu=a("li"),Use=a("strong"),X1o=o("speech_to_text"),z1o=o(" \u2014 "),Mq=a("a"),W1o=o("Speech2TextModel"),Q1o=o(" (Speech2Text model)"),H1o=l(),uu=a("li"),Jse=a("strong"),U1o=o("splinter"),J1o=o(" \u2014 "),Eq=a("a"),Y1o=o("SplinterModel"),K1o=o(" (Splinter model)"),Z1o=l(),_u=a("li"),Yse=a("strong"),e7o=o("squeezebert"),o7o=o(" \u2014 "),Cq=a("a"),r7o=o("SqueezeBertModel"),t7o=o(" (SqueezeBERT model)"),a7o=l(),bu=a("li"),Kse=a("strong"),n7o=o("swin"),s7o=o(" \u2014 "),wq=a("a"),l7o=o("SwinModel"),i7o=o(" (Swin model)"),d7o=l(),vu=a("li"),Zse=a("strong"),c7o=o("t5"),f7o=o(" \u2014 "),Aq=a("a"),m7o=o("T5Model"),g7o=o(" (T5 model)"),h7o=l(),Fu=a("li"),ele=a("strong"),p7o=o("tapas"),u7o=o(" \u2014 "),yq=a("a"),_7o=o("TapasModel"),b7o=o(" (TAPAS model)"),v7o=l(),Tu=a("li"),ole=a("strong"),F7o=o("transfo-xl"),T7o=o(" \u2014 "),Lq=a("a"),M7o=o("TransfoXLModel"),E7o=o(" (Transformer-XL model)"),C7o=l(),Mu=a("li"),rle=a("strong"),w7o=o("unispeech"),A7o=o(" \u2014 "),xq=a("a"),y7o=o("UniSpeechModel"),L7o=o(" (UniSpeech model)"),x7o=l(),Eu=a("li"),tle=a("strong"),$7o=o("unispeech-sat"),k7o=o(" \u2014 "),$q=a("a"),S7o=o("UniSpeechSatModel"),R7o=o(" (UniSpeechSat model)"),P7o=l(),Cu=a("li"),ale=a("strong"),B7o=o("van"),I7o=o(" \u2014 "),kq=a("a"),q7o=o("VanModel"),N7o=o(" (VAN model)"),j7o=l(),wu=a("li"),nle=a("strong"),D7o=o("vilt"),G7o=o(" \u2014 "),Sq=a("a"),O7o=o("ViltModel"),V7o=o(" (ViLT model)"),X7o=l(),Au=a("li"),sle=a("strong"),z7o=o("vision-text-dual-encoder"),W7o=o(" \u2014 "),Rq=a("a"),Q7o=o("VisionTextDualEncoderModel"),H7o=o(" (VisionTextDualEncoder model)"),U7o=l(),yu=a("li"),lle=a("strong"),J7o=o("visual_bert"),Y7o=o(" \u2014 "),Pq=a("a"),K7o=o("VisualBertModel"),Z7o=o(" (VisualBert model)"),ebo=l(),Lu=a("li"),ile=a("strong"),obo=o("vit"),rbo=o(" \u2014 "),Bq=a("a"),tbo=o("ViTModel"),abo=o(" (ViT model)"),nbo=l(),xu=a("li"),dle=a("strong"),sbo=o("vit_mae"),lbo=o(" \u2014 "),Iq=a("a"),ibo=o("ViTMAEModel"),dbo=o(" (ViTMAE model)"),cbo=l(),$u=a("li"),cle=a("strong"),fbo=o("wav2vec2"),mbo=o(" \u2014 "),qq=a("a"),gbo=o("Wav2Vec2Model"),hbo=o(" (Wav2Vec2 model)"),pbo=l(),ku=a("li"),fle=a("strong"),ubo=o("wav2vec2-conformer"),_bo=o(" \u2014 "),Nq=a("a"),bbo=o("Wav2Vec2ConformerModel"),vbo=o(" (Wav2Vec2-Conformer model)"),Fbo=l(),Su=a("li"),mle=a("strong"),Tbo=o("wavlm"),Mbo=o(" \u2014 "),jq=a("a"),Ebo=o("WavLMModel"),Cbo=o(" (WavLM model)"),wbo=l(),Ru=a("li"),gle=a("strong"),Abo=o("xglm"),ybo=o(" \u2014 "),Dq=a("a"),Lbo=o("XGLMModel"),xbo=o(" (XGLM model)"),$bo=l(),Pu=a("li"),hle=a("strong"),kbo=o("xlm"),Sbo=o(" \u2014 "),Gq=a("a"),Rbo=o("XLMModel"),Pbo=o(" (XLM model)"),Bbo=l(),Bu=a("li"),ple=a("strong"),Ibo=o("xlm-prophetnet"),qbo=o(" \u2014 "),Oq=a("a"),Nbo=o("XLMProphetNetModel"),jbo=o(" (XLMProphetNet model)"),Dbo=l(),Iu=a("li"),ule=a("strong"),Gbo=o("xlm-roberta"),Obo=o(" \u2014 "),Vq=a("a"),Vbo=o("XLMRobertaModel"),Xbo=o(" (XLM-RoBERTa model)"),zbo=l(),qu=a("li"),_le=a("strong"),Wbo=o("xlm-roberta-xl"),Qbo=o(" \u2014 "),Xq=a("a"),Hbo=o("XLMRobertaXLModel"),Ubo=o(" (XLM-RoBERTa-XL model)"),Jbo=l(),Nu=a("li"),ble=a("strong"),Ybo=o("xlnet"),Kbo=o(" \u2014 "),zq=a("a"),Zbo=o("XLNetModel"),evo=o(" (XLNet model)"),ovo=l(),ju=a("li"),vle=a("strong"),rvo=o("yolos"),tvo=o(" \u2014 "),Wq=a("a"),avo=o("YolosModel"),nvo=o(" (YOLOS model)"),svo=l(),Du=a("li"),Fle=a("strong"),lvo=o("yoso"),ivo=o(" \u2014 "),Qq=a("a"),dvo=o("YosoModel"),cvo=o(" (YOSO model)"),fvo=l(),Gu=a("p"),mvo=o("The model is set in evaluation mode by default using "),Tle=a("code"),gvo=o("model.eval()"),hvo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mle=a("code"),pvo=o("model.train()"),uvo=l(),F(Ou.$$.fragment),KIe=l(),yi=a("h2"),Vu=a("a"),Ele=a("span"),F(G6.$$.fragment),_vo=l(),Cle=a("span"),bvo=o("AutoModelForPreTraining"),ZIe=l(),xo=a("div"),F(O6.$$.fragment),vvo=l(),Li=a("p"),Fvo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Hq=a("a"),Tvo=o("from_pretrained()"),Mvo=o(" class method or the "),Uq=a("a"),Evo=o("from_config()"),Cvo=o(` class
method.`),wvo=l(),V6=a("p"),Avo=o("This class cannot be instantiated directly using "),wle=a("code"),yvo=o("__init__()"),Lvo=o(" (throws an error)."),xvo=l(),at=a("div"),F(X6.$$.fragment),$vo=l(),Ale=a("p"),kvo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Svo=l(),xi=a("p"),Rvo=o(`Note:
Loading a model from its configuration file does `),yle=a("strong"),Pvo=o("not"),Bvo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jq=a("a"),Ivo=o("from_pretrained()"),qvo=o(" to load the model weights."),Nvo=l(),F(Xu.$$.fragment),jvo=l(),Ye=a("div"),F(z6.$$.fragment),Dvo=l(),Lle=a("p"),Gvo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Ovo=l(),xa=a("p"),Vvo=o("The model class to instantiate is selected based on the "),xle=a("code"),Xvo=o("model_type"),zvo=o(` property of the config object (either
passed as an argument or loaded from `),$le=a("code"),Wvo=o("pretrained_model_name_or_path"),Qvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kle=a("code"),Hvo=o("pretrained_model_name_or_path"),Uvo=o(":"),Jvo=l(),G=a("ul"),zu=a("li"),Sle=a("strong"),Yvo=o("albert"),Kvo=o(" \u2014 "),Yq=a("a"),Zvo=o("AlbertForPreTraining"),eFo=o(" (ALBERT model)"),oFo=l(),Wu=a("li"),Rle=a("strong"),rFo=o("bart"),tFo=o(" \u2014 "),Kq=a("a"),aFo=o("BartForConditionalGeneration"),nFo=o(" (BART model)"),sFo=l(),Qu=a("li"),Ple=a("strong"),lFo=o("bert"),iFo=o(" \u2014 "),Zq=a("a"),dFo=o("BertForPreTraining"),cFo=o(" (BERT model)"),fFo=l(),Hu=a("li"),Ble=a("strong"),mFo=o("big_bird"),gFo=o(" \u2014 "),eN=a("a"),hFo=o("BigBirdForPreTraining"),pFo=o(" (BigBird model)"),uFo=l(),Uu=a("li"),Ile=a("strong"),_Fo=o("camembert"),bFo=o(" \u2014 "),oN=a("a"),vFo=o("CamembertForMaskedLM"),FFo=o(" (CamemBERT model)"),TFo=l(),Ju=a("li"),qle=a("strong"),MFo=o("ctrl"),EFo=o(" \u2014 "),rN=a("a"),CFo=o("CTRLLMHeadModel"),wFo=o(" (CTRL model)"),AFo=l(),Yu=a("li"),Nle=a("strong"),yFo=o("data2vec-text"),LFo=o(" \u2014 "),tN=a("a"),xFo=o("Data2VecTextForMaskedLM"),$Fo=o(" (Data2VecText model)"),kFo=l(),Ku=a("li"),jle=a("strong"),SFo=o("deberta"),RFo=o(" \u2014 "),aN=a("a"),PFo=o("DebertaForMaskedLM"),BFo=o(" (DeBERTa model)"),IFo=l(),Zu=a("li"),Dle=a("strong"),qFo=o("deberta-v2"),NFo=o(" \u2014 "),nN=a("a"),jFo=o("DebertaV2ForMaskedLM"),DFo=o(" (DeBERTa-v2 model)"),GFo=l(),e_=a("li"),Gle=a("strong"),OFo=o("distilbert"),VFo=o(" \u2014 "),sN=a("a"),XFo=o("DistilBertForMaskedLM"),zFo=o(" (DistilBERT model)"),WFo=l(),o_=a("li"),Ole=a("strong"),QFo=o("electra"),HFo=o(" \u2014 "),lN=a("a"),UFo=o("ElectraForPreTraining"),JFo=o(" (ELECTRA model)"),YFo=l(),r_=a("li"),Vle=a("strong"),KFo=o("flaubert"),ZFo=o(" \u2014 "),iN=a("a"),eTo=o("FlaubertWithLMHeadModel"),oTo=o(" (FlauBERT model)"),rTo=l(),t_=a("li"),Xle=a("strong"),tTo=o("flava"),aTo=o(" \u2014 "),dN=a("a"),nTo=o("FlavaForPreTraining"),sTo=o(" (Flava model)"),lTo=l(),a_=a("li"),zle=a("strong"),iTo=o("fnet"),dTo=o(" \u2014 "),cN=a("a"),cTo=o("FNetForPreTraining"),fTo=o(" (FNet model)"),mTo=l(),n_=a("li"),Wle=a("strong"),gTo=o("fsmt"),hTo=o(" \u2014 "),fN=a("a"),pTo=o("FSMTForConditionalGeneration"),uTo=o(" (FairSeq Machine-Translation model)"),_To=l(),s_=a("li"),Qle=a("strong"),bTo=o("funnel"),vTo=o(" \u2014 "),mN=a("a"),FTo=o("FunnelForPreTraining"),TTo=o(" (Funnel Transformer model)"),MTo=l(),l_=a("li"),Hle=a("strong"),ETo=o("gpt2"),CTo=o(" \u2014 "),gN=a("a"),wTo=o("GPT2LMHeadModel"),ATo=o(" (OpenAI GPT-2 model)"),yTo=l(),i_=a("li"),Ule=a("strong"),LTo=o("ibert"),xTo=o(" \u2014 "),hN=a("a"),$To=o("IBertForMaskedLM"),kTo=o(" (I-BERT model)"),STo=l(),d_=a("li"),Jle=a("strong"),RTo=o("layoutlm"),PTo=o(" \u2014 "),pN=a("a"),BTo=o("LayoutLMForMaskedLM"),ITo=o(" (LayoutLM model)"),qTo=l(),c_=a("li"),Yle=a("strong"),NTo=o("longformer"),jTo=o(" \u2014 "),uN=a("a"),DTo=o("LongformerForMaskedLM"),GTo=o(" (Longformer model)"),OTo=l(),f_=a("li"),Kle=a("strong"),VTo=o("lxmert"),XTo=o(" \u2014 "),_N=a("a"),zTo=o("LxmertForPreTraining"),WTo=o(" (LXMERT model)"),QTo=l(),m_=a("li"),Zle=a("strong"),HTo=o("megatron-bert"),UTo=o(" \u2014 "),bN=a("a"),JTo=o("MegatronBertForPreTraining"),YTo=o(" (MegatronBert model)"),KTo=l(),g_=a("li"),eie=a("strong"),ZTo=o("mobilebert"),eMo=o(" \u2014 "),vN=a("a"),oMo=o("MobileBertForPreTraining"),rMo=o(" (MobileBERT model)"),tMo=l(),h_=a("li"),oie=a("strong"),aMo=o("mpnet"),nMo=o(" \u2014 "),FN=a("a"),sMo=o("MPNetForMaskedLM"),lMo=o(" (MPNet model)"),iMo=l(),p_=a("li"),rie=a("strong"),dMo=o("openai-gpt"),cMo=o(" \u2014 "),TN=a("a"),fMo=o("OpenAIGPTLMHeadModel"),mMo=o(" (OpenAI GPT model)"),gMo=l(),u_=a("li"),tie=a("strong"),hMo=o("retribert"),pMo=o(" \u2014 "),MN=a("a"),uMo=o("RetriBertModel"),_Mo=o(" (RetriBERT model)"),bMo=l(),__=a("li"),aie=a("strong"),vMo=o("roberta"),FMo=o(" \u2014 "),EN=a("a"),TMo=o("RobertaForMaskedLM"),MMo=o(" (RoBERTa model)"),EMo=l(),b_=a("li"),nie=a("strong"),CMo=o("squeezebert"),wMo=o(" \u2014 "),CN=a("a"),AMo=o("SqueezeBertForMaskedLM"),yMo=o(" (SqueezeBERT model)"),LMo=l(),v_=a("li"),sie=a("strong"),xMo=o("t5"),$Mo=o(" \u2014 "),wN=a("a"),kMo=o("T5ForConditionalGeneration"),SMo=o(" (T5 model)"),RMo=l(),F_=a("li"),lie=a("strong"),PMo=o("tapas"),BMo=o(" \u2014 "),AN=a("a"),IMo=o("TapasForMaskedLM"),qMo=o(" (TAPAS model)"),NMo=l(),T_=a("li"),iie=a("strong"),jMo=o("transfo-xl"),DMo=o(" \u2014 "),yN=a("a"),GMo=o("TransfoXLLMHeadModel"),OMo=o(" (Transformer-XL model)"),VMo=l(),M_=a("li"),die=a("strong"),XMo=o("unispeech"),zMo=o(" \u2014 "),LN=a("a"),WMo=o("UniSpeechForPreTraining"),QMo=o(" (UniSpeech model)"),HMo=l(),E_=a("li"),cie=a("strong"),UMo=o("unispeech-sat"),JMo=o(" \u2014 "),xN=a("a"),YMo=o("UniSpeechSatForPreTraining"),KMo=o(" (UniSpeechSat model)"),ZMo=l(),C_=a("li"),fie=a("strong"),e4o=o("visual_bert"),o4o=o(" \u2014 "),$N=a("a"),r4o=o("VisualBertForPreTraining"),t4o=o(" (VisualBert model)"),a4o=l(),w_=a("li"),mie=a("strong"),n4o=o("vit_mae"),s4o=o(" \u2014 "),kN=a("a"),l4o=o("ViTMAEForPreTraining"),i4o=o(" (ViTMAE model)"),d4o=l(),A_=a("li"),gie=a("strong"),c4o=o("wav2vec2"),f4o=o(" \u2014 "),SN=a("a"),m4o=o("Wav2Vec2ForPreTraining"),g4o=o(" (Wav2Vec2 model)"),h4o=l(),y_=a("li"),hie=a("strong"),p4o=o("wav2vec2-conformer"),u4o=o(" \u2014 "),RN=a("a"),_4o=o("Wav2Vec2ConformerForPreTraining"),b4o=o(" (Wav2Vec2-Conformer model)"),v4o=l(),L_=a("li"),pie=a("strong"),F4o=o("xlm"),T4o=o(" \u2014 "),PN=a("a"),M4o=o("XLMWithLMHeadModel"),E4o=o(" (XLM model)"),C4o=l(),x_=a("li"),uie=a("strong"),w4o=o("xlm-roberta"),A4o=o(" \u2014 "),BN=a("a"),y4o=o("XLMRobertaForMaskedLM"),L4o=o(" (XLM-RoBERTa model)"),x4o=l(),$_=a("li"),_ie=a("strong"),$4o=o("xlm-roberta-xl"),k4o=o(" \u2014 "),IN=a("a"),S4o=o("XLMRobertaXLForMaskedLM"),R4o=o(" (XLM-RoBERTa-XL model)"),P4o=l(),k_=a("li"),bie=a("strong"),B4o=o("xlnet"),I4o=o(" \u2014 "),qN=a("a"),q4o=o("XLNetLMHeadModel"),N4o=o(" (XLNet model)"),j4o=l(),S_=a("p"),D4o=o("The model is set in evaluation mode by default using "),vie=a("code"),G4o=o("model.eval()"),O4o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fie=a("code"),V4o=o("model.train()"),X4o=l(),F(R_.$$.fragment),eqe=l(),$i=a("h2"),P_=a("a"),Tie=a("span"),F(W6.$$.fragment),z4o=l(),Mie=a("span"),W4o=o("AutoModelForCausalLM"),oqe=l(),$o=a("div"),F(Q6.$$.fragment),Q4o=l(),ki=a("p"),H4o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),NN=a("a"),U4o=o("from_pretrained()"),J4o=o(" class method or the "),jN=a("a"),Y4o=o("from_config()"),K4o=o(` class
method.`),Z4o=l(),H6=a("p"),eEo=o("This class cannot be instantiated directly using "),Eie=a("code"),oEo=o("__init__()"),rEo=o(" (throws an error)."),tEo=l(),nt=a("div"),F(U6.$$.fragment),aEo=l(),Cie=a("p"),nEo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),sEo=l(),Si=a("p"),lEo=o(`Note:
Loading a model from its configuration file does `),wie=a("strong"),iEo=o("not"),dEo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DN=a("a"),cEo=o("from_pretrained()"),fEo=o(" to load the model weights."),mEo=l(),F(B_.$$.fragment),gEo=l(),Ke=a("div"),F(J6.$$.fragment),hEo=l(),Aie=a("p"),pEo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uEo=l(),$a=a("p"),_Eo=o("The model class to instantiate is selected based on the "),yie=a("code"),bEo=o("model_type"),vEo=o(` property of the config object (either
passed as an argument or loaded from `),Lie=a("code"),FEo=o("pretrained_model_name_or_path"),TEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xie=a("code"),MEo=o("pretrained_model_name_or_path"),EEo=o(":"),CEo=l(),z=a("ul"),I_=a("li"),$ie=a("strong"),wEo=o("bart"),AEo=o(" \u2014 "),GN=a("a"),yEo=o("BartForCausalLM"),LEo=o(" (BART model)"),xEo=l(),q_=a("li"),kie=a("strong"),$Eo=o("bert"),kEo=o(" \u2014 "),ON=a("a"),SEo=o("BertLMHeadModel"),REo=o(" (BERT model)"),PEo=l(),N_=a("li"),Sie=a("strong"),BEo=o("bert-generation"),IEo=o(" \u2014 "),VN=a("a"),qEo=o("BertGenerationDecoder"),NEo=o(" (Bert Generation model)"),jEo=l(),j_=a("li"),Rie=a("strong"),DEo=o("big_bird"),GEo=o(" \u2014 "),XN=a("a"),OEo=o("BigBirdForCausalLM"),VEo=o(" (BigBird model)"),XEo=l(),D_=a("li"),Pie=a("strong"),zEo=o("bigbird_pegasus"),WEo=o(" \u2014 "),zN=a("a"),QEo=o("BigBirdPegasusForCausalLM"),HEo=o(" (BigBirdPegasus model)"),UEo=l(),G_=a("li"),Bie=a("strong"),JEo=o("blenderbot"),YEo=o(" \u2014 "),WN=a("a"),KEo=o("BlenderbotForCausalLM"),ZEo=o(" (Blenderbot model)"),eCo=l(),O_=a("li"),Iie=a("strong"),oCo=o("blenderbot-small"),rCo=o(" \u2014 "),QN=a("a"),tCo=o("BlenderbotSmallForCausalLM"),aCo=o(" (BlenderbotSmall model)"),nCo=l(),V_=a("li"),qie=a("strong"),sCo=o("camembert"),lCo=o(" \u2014 "),HN=a("a"),iCo=o("CamembertForCausalLM"),dCo=o(" (CamemBERT model)"),cCo=l(),X_=a("li"),Nie=a("strong"),fCo=o("ctrl"),mCo=o(" \u2014 "),UN=a("a"),gCo=o("CTRLLMHeadModel"),hCo=o(" (CTRL model)"),pCo=l(),z_=a("li"),jie=a("strong"),uCo=o("data2vec-text"),_Co=o(" \u2014 "),JN=a("a"),bCo=o("Data2VecTextForCausalLM"),vCo=o(" (Data2VecText model)"),FCo=l(),W_=a("li"),Die=a("strong"),TCo=o("electra"),MCo=o(" \u2014 "),YN=a("a"),ECo=o("ElectraForCausalLM"),CCo=o(" (ELECTRA model)"),wCo=l(),Q_=a("li"),Gie=a("strong"),ACo=o("gpt2"),yCo=o(" \u2014 "),KN=a("a"),LCo=o("GPT2LMHeadModel"),xCo=o(" (OpenAI GPT-2 model)"),$Co=l(),H_=a("li"),Oie=a("strong"),kCo=o("gpt_neo"),SCo=o(" \u2014 "),ZN=a("a"),RCo=o("GPTNeoForCausalLM"),PCo=o(" (GPT Neo model)"),BCo=l(),U_=a("li"),Vie=a("strong"),ICo=o("gptj"),qCo=o(" \u2014 "),ej=a("a"),NCo=o("GPTJForCausalLM"),jCo=o(" (GPT-J model)"),DCo=l(),J_=a("li"),Xie=a("strong"),GCo=o("marian"),OCo=o(" \u2014 "),oj=a("a"),VCo=o("MarianForCausalLM"),XCo=o(" (Marian model)"),zCo=l(),Y_=a("li"),zie=a("strong"),WCo=o("mbart"),QCo=o(" \u2014 "),rj=a("a"),HCo=o("MBartForCausalLM"),UCo=o(" (mBART model)"),JCo=l(),K_=a("li"),Wie=a("strong"),YCo=o("megatron-bert"),KCo=o(" \u2014 "),tj=a("a"),ZCo=o("MegatronBertForCausalLM"),e5o=o(" (MegatronBert model)"),o5o=l(),Z_=a("li"),Qie=a("strong"),r5o=o("openai-gpt"),t5o=o(" \u2014 "),aj=a("a"),a5o=o("OpenAIGPTLMHeadModel"),n5o=o(" (OpenAI GPT model)"),s5o=l(),e2=a("li"),Hie=a("strong"),l5o=o("opt"),i5o=o(" \u2014 "),nj=a("a"),d5o=o("OPTForCausalLM"),c5o=o(" (OPT model)"),f5o=l(),o2=a("li"),Uie=a("strong"),m5o=o("pegasus"),g5o=o(" \u2014 "),sj=a("a"),h5o=o("PegasusForCausalLM"),p5o=o(" (Pegasus model)"),u5o=l(),r2=a("li"),Jie=a("strong"),_5o=o("plbart"),b5o=o(" \u2014 "),lj=a("a"),v5o=o("PLBartForCausalLM"),F5o=o(" (PLBart model)"),T5o=l(),t2=a("li"),Yie=a("strong"),M5o=o("prophetnet"),E5o=o(" \u2014 "),ij=a("a"),C5o=o("ProphetNetForCausalLM"),w5o=o(" (ProphetNet model)"),A5o=l(),a2=a("li"),Kie=a("strong"),y5o=o("qdqbert"),L5o=o(" \u2014 "),dj=a("a"),x5o=o("QDQBertLMHeadModel"),$5o=o(" (QDQBert model)"),k5o=l(),n2=a("li"),Zie=a("strong"),S5o=o("reformer"),R5o=o(" \u2014 "),cj=a("a"),P5o=o("ReformerModelWithLMHead"),B5o=o(" (Reformer model)"),I5o=l(),s2=a("li"),ede=a("strong"),q5o=o("rembert"),N5o=o(" \u2014 "),fj=a("a"),j5o=o("RemBertForCausalLM"),D5o=o(" (RemBERT model)"),G5o=l(),l2=a("li"),ode=a("strong"),O5o=o("roberta"),V5o=o(" \u2014 "),mj=a("a"),X5o=o("RobertaForCausalLM"),z5o=o(" (RoBERTa model)"),W5o=l(),i2=a("li"),rde=a("strong"),Q5o=o("roformer"),H5o=o(" \u2014 "),gj=a("a"),U5o=o("RoFormerForCausalLM"),J5o=o(" (RoFormer model)"),Y5o=l(),d2=a("li"),tde=a("strong"),K5o=o("speech_to_text_2"),Z5o=o(" \u2014 "),hj=a("a"),e3o=o("Speech2Text2ForCausalLM"),o3o=o(" (Speech2Text2 model)"),r3o=l(),c2=a("li"),ade=a("strong"),t3o=o("transfo-xl"),a3o=o(" \u2014 "),pj=a("a"),n3o=o("TransfoXLLMHeadModel"),s3o=o(" (Transformer-XL model)"),l3o=l(),f2=a("li"),nde=a("strong"),i3o=o("trocr"),d3o=o(" \u2014 "),uj=a("a"),c3o=o("TrOCRForCausalLM"),f3o=o(" (TrOCR model)"),m3o=l(),m2=a("li"),sde=a("strong"),g3o=o("xglm"),h3o=o(" \u2014 "),_j=a("a"),p3o=o("XGLMForCausalLM"),u3o=o(" (XGLM model)"),_3o=l(),g2=a("li"),lde=a("strong"),b3o=o("xlm"),v3o=o(" \u2014 "),bj=a("a"),F3o=o("XLMWithLMHeadModel"),T3o=o(" (XLM model)"),M3o=l(),h2=a("li"),ide=a("strong"),E3o=o("xlm-prophetnet"),C3o=o(" \u2014 "),vj=a("a"),w3o=o("XLMProphetNetForCausalLM"),A3o=o(" (XLMProphetNet model)"),y3o=l(),p2=a("li"),dde=a("strong"),L3o=o("xlm-roberta"),x3o=o(" \u2014 "),Fj=a("a"),$3o=o("XLMRobertaForCausalLM"),k3o=o(" (XLM-RoBERTa model)"),S3o=l(),u2=a("li"),cde=a("strong"),R3o=o("xlm-roberta-xl"),P3o=o(" \u2014 "),Tj=a("a"),B3o=o("XLMRobertaXLForCausalLM"),I3o=o(" (XLM-RoBERTa-XL model)"),q3o=l(),_2=a("li"),fde=a("strong"),N3o=o("xlnet"),j3o=o(" \u2014 "),Mj=a("a"),D3o=o("XLNetLMHeadModel"),G3o=o(" (XLNet model)"),O3o=l(),b2=a("p"),V3o=o("The model is set in evaluation mode by default using "),mde=a("code"),X3o=o("model.eval()"),z3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gde=a("code"),W3o=o("model.train()"),Q3o=l(),F(v2.$$.fragment),rqe=l(),Ri=a("h2"),F2=a("a"),hde=a("span"),F(Y6.$$.fragment),H3o=l(),pde=a("span"),U3o=o("AutoModelForMaskedLM"),tqe=l(),ko=a("div"),F(K6.$$.fragment),J3o=l(),Pi=a("p"),Y3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Ej=a("a"),K3o=o("from_pretrained()"),Z3o=o(" class method or the "),Cj=a("a"),ewo=o("from_config()"),owo=o(` class
method.`),rwo=l(),Z6=a("p"),two=o("This class cannot be instantiated directly using "),ude=a("code"),awo=o("__init__()"),nwo=o(" (throws an error)."),swo=l(),st=a("div"),F(ey.$$.fragment),lwo=l(),_de=a("p"),iwo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dwo=l(),Bi=a("p"),cwo=o(`Note:
Loading a model from its configuration file does `),bde=a("strong"),fwo=o("not"),mwo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wj=a("a"),gwo=o("from_pretrained()"),hwo=o(" to load the model weights."),pwo=l(),F(T2.$$.fragment),uwo=l(),Ze=a("div"),F(oy.$$.fragment),_wo=l(),vde=a("p"),bwo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),vwo=l(),ka=a("p"),Fwo=o("The model class to instantiate is selected based on the "),Fde=a("code"),Two=o("model_type"),Mwo=o(` property of the config object (either
passed as an argument or loaded from `),Tde=a("code"),Ewo=o("pretrained_model_name_or_path"),Cwo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mde=a("code"),wwo=o("pretrained_model_name_or_path"),Awo=o(":"),ywo=l(),W=a("ul"),M2=a("li"),Ede=a("strong"),Lwo=o("albert"),xwo=o(" \u2014 "),Aj=a("a"),$wo=o("AlbertForMaskedLM"),kwo=o(" (ALBERT model)"),Swo=l(),E2=a("li"),Cde=a("strong"),Rwo=o("bart"),Pwo=o(" \u2014 "),yj=a("a"),Bwo=o("BartForConditionalGeneration"),Iwo=o(" (BART model)"),qwo=l(),C2=a("li"),wde=a("strong"),Nwo=o("bert"),jwo=o(" \u2014 "),Lj=a("a"),Dwo=o("BertForMaskedLM"),Gwo=o(" (BERT model)"),Owo=l(),w2=a("li"),Ade=a("strong"),Vwo=o("big_bird"),Xwo=o(" \u2014 "),xj=a("a"),zwo=o("BigBirdForMaskedLM"),Wwo=o(" (BigBird model)"),Qwo=l(),A2=a("li"),yde=a("strong"),Hwo=o("camembert"),Uwo=o(" \u2014 "),$j=a("a"),Jwo=o("CamembertForMaskedLM"),Ywo=o(" (CamemBERT model)"),Kwo=l(),y2=a("li"),Lde=a("strong"),Zwo=o("convbert"),eAo=o(" \u2014 "),kj=a("a"),oAo=o("ConvBertForMaskedLM"),rAo=o(" (ConvBERT model)"),tAo=l(),L2=a("li"),xde=a("strong"),aAo=o("data2vec-text"),nAo=o(" \u2014 "),Sj=a("a"),sAo=o("Data2VecTextForMaskedLM"),lAo=o(" (Data2VecText model)"),iAo=l(),x2=a("li"),$de=a("strong"),dAo=o("deberta"),cAo=o(" \u2014 "),Rj=a("a"),fAo=o("DebertaForMaskedLM"),mAo=o(" (DeBERTa model)"),gAo=l(),$2=a("li"),kde=a("strong"),hAo=o("deberta-v2"),pAo=o(" \u2014 "),Pj=a("a"),uAo=o("DebertaV2ForMaskedLM"),_Ao=o(" (DeBERTa-v2 model)"),bAo=l(),k2=a("li"),Sde=a("strong"),vAo=o("distilbert"),FAo=o(" \u2014 "),Bj=a("a"),TAo=o("DistilBertForMaskedLM"),MAo=o(" (DistilBERT model)"),EAo=l(),S2=a("li"),Rde=a("strong"),CAo=o("electra"),wAo=o(" \u2014 "),Ij=a("a"),AAo=o("ElectraForMaskedLM"),yAo=o(" (ELECTRA model)"),LAo=l(),R2=a("li"),Pde=a("strong"),xAo=o("flaubert"),$Ao=o(" \u2014 "),qj=a("a"),kAo=o("FlaubertWithLMHeadModel"),SAo=o(" (FlauBERT model)"),RAo=l(),P2=a("li"),Bde=a("strong"),PAo=o("fnet"),BAo=o(" \u2014 "),Nj=a("a"),IAo=o("FNetForMaskedLM"),qAo=o(" (FNet model)"),NAo=l(),B2=a("li"),Ide=a("strong"),jAo=o("funnel"),DAo=o(" \u2014 "),jj=a("a"),GAo=o("FunnelForMaskedLM"),OAo=o(" (Funnel Transformer model)"),VAo=l(),I2=a("li"),qde=a("strong"),XAo=o("ibert"),zAo=o(" \u2014 "),Dj=a("a"),WAo=o("IBertForMaskedLM"),QAo=o(" (I-BERT model)"),HAo=l(),q2=a("li"),Nde=a("strong"),UAo=o("layoutlm"),JAo=o(" \u2014 "),Gj=a("a"),YAo=o("LayoutLMForMaskedLM"),KAo=o(" (LayoutLM model)"),ZAo=l(),N2=a("li"),jde=a("strong"),e0o=o("longformer"),o0o=o(" \u2014 "),Oj=a("a"),r0o=o("LongformerForMaskedLM"),t0o=o(" (Longformer model)"),a0o=l(),j2=a("li"),Dde=a("strong"),n0o=o("mbart"),s0o=o(" \u2014 "),Vj=a("a"),l0o=o("MBartForConditionalGeneration"),i0o=o(" (mBART model)"),d0o=l(),D2=a("li"),Gde=a("strong"),c0o=o("megatron-bert"),f0o=o(" \u2014 "),Xj=a("a"),m0o=o("MegatronBertForMaskedLM"),g0o=o(" (MegatronBert model)"),h0o=l(),G2=a("li"),Ode=a("strong"),p0o=o("mobilebert"),u0o=o(" \u2014 "),zj=a("a"),_0o=o("MobileBertForMaskedLM"),b0o=o(" (MobileBERT model)"),v0o=l(),O2=a("li"),Vde=a("strong"),F0o=o("mpnet"),T0o=o(" \u2014 "),Wj=a("a"),M0o=o("MPNetForMaskedLM"),E0o=o(" (MPNet model)"),C0o=l(),V2=a("li"),Xde=a("strong"),w0o=o("nystromformer"),A0o=o(" \u2014 "),Qj=a("a"),y0o=o("NystromformerForMaskedLM"),L0o=o(" (Nystromformer model)"),x0o=l(),X2=a("li"),zde=a("strong"),$0o=o("perceiver"),k0o=o(" \u2014 "),Hj=a("a"),S0o=o("PerceiverForMaskedLM"),R0o=o(" (Perceiver model)"),P0o=l(),z2=a("li"),Wde=a("strong"),B0o=o("qdqbert"),I0o=o(" \u2014 "),Uj=a("a"),q0o=o("QDQBertForMaskedLM"),N0o=o(" (QDQBert model)"),j0o=l(),W2=a("li"),Qde=a("strong"),D0o=o("reformer"),G0o=o(" \u2014 "),Jj=a("a"),O0o=o("ReformerForMaskedLM"),V0o=o(" (Reformer model)"),X0o=l(),Q2=a("li"),Hde=a("strong"),z0o=o("rembert"),W0o=o(" \u2014 "),Yj=a("a"),Q0o=o("RemBertForMaskedLM"),H0o=o(" (RemBERT model)"),U0o=l(),H2=a("li"),Ude=a("strong"),J0o=o("roberta"),Y0o=o(" \u2014 "),Kj=a("a"),K0o=o("RobertaForMaskedLM"),Z0o=o(" (RoBERTa model)"),e6o=l(),U2=a("li"),Jde=a("strong"),o6o=o("roformer"),r6o=o(" \u2014 "),Zj=a("a"),t6o=o("RoFormerForMaskedLM"),a6o=o(" (RoFormer model)"),n6o=l(),J2=a("li"),Yde=a("strong"),s6o=o("squeezebert"),l6o=o(" \u2014 "),eD=a("a"),i6o=o("SqueezeBertForMaskedLM"),d6o=o(" (SqueezeBERT model)"),c6o=l(),Y2=a("li"),Kde=a("strong"),f6o=o("tapas"),m6o=o(" \u2014 "),oD=a("a"),g6o=o("TapasForMaskedLM"),h6o=o(" (TAPAS model)"),p6o=l(),K2=a("li"),Zde=a("strong"),u6o=o("wav2vec2"),_6o=o(" \u2014 "),ece=a("code"),b6o=o("Wav2Vec2ForMaskedLM"),v6o=o(" (Wav2Vec2 model)"),F6o=l(),Z2=a("li"),oce=a("strong"),T6o=o("xlm"),M6o=o(" \u2014 "),rD=a("a"),E6o=o("XLMWithLMHeadModel"),C6o=o(" (XLM model)"),w6o=l(),e1=a("li"),rce=a("strong"),A6o=o("xlm-roberta"),y6o=o(" \u2014 "),tD=a("a"),L6o=o("XLMRobertaForMaskedLM"),x6o=o(" (XLM-RoBERTa model)"),$6o=l(),o1=a("li"),tce=a("strong"),k6o=o("xlm-roberta-xl"),S6o=o(" \u2014 "),aD=a("a"),R6o=o("XLMRobertaXLForMaskedLM"),P6o=o(" (XLM-RoBERTa-XL model)"),B6o=l(),r1=a("li"),ace=a("strong"),I6o=o("yoso"),q6o=o(" \u2014 "),nD=a("a"),N6o=o("YosoForMaskedLM"),j6o=o(" (YOSO model)"),D6o=l(),t1=a("p"),G6o=o("The model is set in evaluation mode by default using "),nce=a("code"),O6o=o("model.eval()"),V6o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sce=a("code"),X6o=o("model.train()"),z6o=l(),F(a1.$$.fragment),aqe=l(),Ii=a("h2"),n1=a("a"),lce=a("span"),F(ry.$$.fragment),W6o=l(),ice=a("span"),Q6o=o("AutoModelForSeq2SeqLM"),nqe=l(),So=a("div"),F(ty.$$.fragment),H6o=l(),qi=a("p"),U6o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),sD=a("a"),J6o=o("from_pretrained()"),Y6o=o(" class method or the "),lD=a("a"),K6o=o("from_config()"),Z6o=o(` class
method.`),eyo=l(),ay=a("p"),oyo=o("This class cannot be instantiated directly using "),dce=a("code"),ryo=o("__init__()"),tyo=o(" (throws an error)."),ayo=l(),lt=a("div"),F(ny.$$.fragment),nyo=l(),cce=a("p"),syo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lyo=l(),Ni=a("p"),iyo=o(`Note:
Loading a model from its configuration file does `),fce=a("strong"),dyo=o("not"),cyo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iD=a("a"),fyo=o("from_pretrained()"),myo=o(" to load the model weights."),gyo=l(),F(s1.$$.fragment),hyo=l(),eo=a("div"),F(sy.$$.fragment),pyo=l(),mce=a("p"),uyo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),_yo=l(),Sa=a("p"),byo=o("The model class to instantiate is selected based on the "),gce=a("code"),vyo=o("model_type"),Fyo=o(` property of the config object (either
passed as an argument or loaded from `),hce=a("code"),Tyo=o("pretrained_model_name_or_path"),Myo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pce=a("code"),Eyo=o("pretrained_model_name_or_path"),Cyo=o(":"),wyo=l(),ue=a("ul"),l1=a("li"),uce=a("strong"),Ayo=o("bart"),yyo=o(" \u2014 "),dD=a("a"),Lyo=o("BartForConditionalGeneration"),xyo=o(" (BART model)"),$yo=l(),i1=a("li"),_ce=a("strong"),kyo=o("bigbird_pegasus"),Syo=o(" \u2014 "),cD=a("a"),Ryo=o("BigBirdPegasusForConditionalGeneration"),Pyo=o(" (BigBirdPegasus model)"),Byo=l(),d1=a("li"),bce=a("strong"),Iyo=o("blenderbot"),qyo=o(" \u2014 "),fD=a("a"),Nyo=o("BlenderbotForConditionalGeneration"),jyo=o(" (Blenderbot model)"),Dyo=l(),c1=a("li"),vce=a("strong"),Gyo=o("blenderbot-small"),Oyo=o(" \u2014 "),mD=a("a"),Vyo=o("BlenderbotSmallForConditionalGeneration"),Xyo=o(" (BlenderbotSmall model)"),zyo=l(),f1=a("li"),Fce=a("strong"),Wyo=o("encoder-decoder"),Qyo=o(" \u2014 "),gD=a("a"),Hyo=o("EncoderDecoderModel"),Uyo=o(" (Encoder decoder model)"),Jyo=l(),m1=a("li"),Tce=a("strong"),Yyo=o("fsmt"),Kyo=o(" \u2014 "),hD=a("a"),Zyo=o("FSMTForConditionalGeneration"),eLo=o(" (FairSeq Machine-Translation model)"),oLo=l(),g1=a("li"),Mce=a("strong"),rLo=o("led"),tLo=o(" \u2014 "),pD=a("a"),aLo=o("LEDForConditionalGeneration"),nLo=o(" (LED model)"),sLo=l(),h1=a("li"),Ece=a("strong"),lLo=o("m2m_100"),iLo=o(" \u2014 "),uD=a("a"),dLo=o("M2M100ForConditionalGeneration"),cLo=o(" (M2M100 model)"),fLo=l(),p1=a("li"),Cce=a("strong"),mLo=o("marian"),gLo=o(" \u2014 "),_D=a("a"),hLo=o("MarianMTModel"),pLo=o(" (Marian model)"),uLo=l(),u1=a("li"),wce=a("strong"),_Lo=o("mbart"),bLo=o(" \u2014 "),bD=a("a"),vLo=o("MBartForConditionalGeneration"),FLo=o(" (mBART model)"),TLo=l(),_1=a("li"),Ace=a("strong"),MLo=o("mt5"),ELo=o(" \u2014 "),vD=a("a"),CLo=o("MT5ForConditionalGeneration"),wLo=o(" (mT5 model)"),ALo=l(),b1=a("li"),yce=a("strong"),yLo=o("pegasus"),LLo=o(" \u2014 "),FD=a("a"),xLo=o("PegasusForConditionalGeneration"),$Lo=o(" (Pegasus model)"),kLo=l(),v1=a("li"),Lce=a("strong"),SLo=o("plbart"),RLo=o(" \u2014 "),TD=a("a"),PLo=o("PLBartForConditionalGeneration"),BLo=o(" (PLBart model)"),ILo=l(),F1=a("li"),xce=a("strong"),qLo=o("prophetnet"),NLo=o(" \u2014 "),MD=a("a"),jLo=o("ProphetNetForConditionalGeneration"),DLo=o(" (ProphetNet model)"),GLo=l(),T1=a("li"),$ce=a("strong"),OLo=o("t5"),VLo=o(" \u2014 "),ED=a("a"),XLo=o("T5ForConditionalGeneration"),zLo=o(" (T5 model)"),WLo=l(),M1=a("li"),kce=a("strong"),QLo=o("xlm-prophetnet"),HLo=o(" \u2014 "),CD=a("a"),ULo=o("XLMProphetNetForConditionalGeneration"),JLo=o(" (XLMProphetNet model)"),YLo=l(),E1=a("p"),KLo=o("The model is set in evaluation mode by default using "),Sce=a("code"),ZLo=o("model.eval()"),e8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rce=a("code"),o8o=o("model.train()"),r8o=l(),F(C1.$$.fragment),sqe=l(),ji=a("h2"),w1=a("a"),Pce=a("span"),F(ly.$$.fragment),t8o=l(),Bce=a("span"),a8o=o("AutoModelForSequenceClassification"),lqe=l(),Ro=a("div"),F(iy.$$.fragment),n8o=l(),Di=a("p"),s8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wD=a("a"),l8o=o("from_pretrained()"),i8o=o(" class method or the "),AD=a("a"),d8o=o("from_config()"),c8o=o(` class
method.`),f8o=l(),dy=a("p"),m8o=o("This class cannot be instantiated directly using "),Ice=a("code"),g8o=o("__init__()"),h8o=o(" (throws an error)."),p8o=l(),it=a("div"),F(cy.$$.fragment),u8o=l(),qce=a("p"),_8o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),b8o=l(),Gi=a("p"),v8o=o(`Note:
Loading a model from its configuration file does `),Nce=a("strong"),F8o=o("not"),T8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yD=a("a"),M8o=o("from_pretrained()"),E8o=o(" to load the model weights."),C8o=l(),F(A1.$$.fragment),w8o=l(),oo=a("div"),F(fy.$$.fragment),A8o=l(),jce=a("p"),y8o=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),L8o=l(),Ra=a("p"),x8o=o("The model class to instantiate is selected based on the "),Dce=a("code"),$8o=o("model_type"),k8o=o(` property of the config object (either
passed as an argument or loaded from `),Gce=a("code"),S8o=o("pretrained_model_name_or_path"),R8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oce=a("code"),P8o=o("pretrained_model_name_or_path"),B8o=o(":"),I8o=l(),N=a("ul"),y1=a("li"),Vce=a("strong"),q8o=o("albert"),N8o=o(" \u2014 "),LD=a("a"),j8o=o("AlbertForSequenceClassification"),D8o=o(" (ALBERT model)"),G8o=l(),L1=a("li"),Xce=a("strong"),O8o=o("bart"),V8o=o(" \u2014 "),xD=a("a"),X8o=o("BartForSequenceClassification"),z8o=o(" (BART model)"),W8o=l(),x1=a("li"),zce=a("strong"),Q8o=o("bert"),H8o=o(" \u2014 "),$D=a("a"),U8o=o("BertForSequenceClassification"),J8o=o(" (BERT model)"),Y8o=l(),$1=a("li"),Wce=a("strong"),K8o=o("big_bird"),Z8o=o(" \u2014 "),kD=a("a"),exo=o("BigBirdForSequenceClassification"),oxo=o(" (BigBird model)"),rxo=l(),k1=a("li"),Qce=a("strong"),txo=o("bigbird_pegasus"),axo=o(" \u2014 "),SD=a("a"),nxo=o("BigBirdPegasusForSequenceClassification"),sxo=o(" (BigBirdPegasus model)"),lxo=l(),S1=a("li"),Hce=a("strong"),ixo=o("camembert"),dxo=o(" \u2014 "),RD=a("a"),cxo=o("CamembertForSequenceClassification"),fxo=o(" (CamemBERT model)"),mxo=l(),R1=a("li"),Uce=a("strong"),gxo=o("canine"),hxo=o(" \u2014 "),PD=a("a"),pxo=o("CanineForSequenceClassification"),uxo=o(" (Canine model)"),_xo=l(),P1=a("li"),Jce=a("strong"),bxo=o("convbert"),vxo=o(" \u2014 "),BD=a("a"),Fxo=o("ConvBertForSequenceClassification"),Txo=o(" (ConvBERT model)"),Mxo=l(),B1=a("li"),Yce=a("strong"),Exo=o("ctrl"),Cxo=o(" \u2014 "),ID=a("a"),wxo=o("CTRLForSequenceClassification"),Axo=o(" (CTRL model)"),yxo=l(),I1=a("li"),Kce=a("strong"),Lxo=o("data2vec-text"),xxo=o(" \u2014 "),qD=a("a"),$xo=o("Data2VecTextForSequenceClassification"),kxo=o(" (Data2VecText model)"),Sxo=l(),q1=a("li"),Zce=a("strong"),Rxo=o("deberta"),Pxo=o(" \u2014 "),ND=a("a"),Bxo=o("DebertaForSequenceClassification"),Ixo=o(" (DeBERTa model)"),qxo=l(),N1=a("li"),efe=a("strong"),Nxo=o("deberta-v2"),jxo=o(" \u2014 "),jD=a("a"),Dxo=o("DebertaV2ForSequenceClassification"),Gxo=o(" (DeBERTa-v2 model)"),Oxo=l(),j1=a("li"),ofe=a("strong"),Vxo=o("distilbert"),Xxo=o(" \u2014 "),DD=a("a"),zxo=o("DistilBertForSequenceClassification"),Wxo=o(" (DistilBERT model)"),Qxo=l(),D1=a("li"),rfe=a("strong"),Hxo=o("electra"),Uxo=o(" \u2014 "),GD=a("a"),Jxo=o("ElectraForSequenceClassification"),Yxo=o(" (ELECTRA model)"),Kxo=l(),G1=a("li"),tfe=a("strong"),Zxo=o("flaubert"),e9o=o(" \u2014 "),OD=a("a"),o9o=o("FlaubertForSequenceClassification"),r9o=o(" (FlauBERT model)"),t9o=l(),O1=a("li"),afe=a("strong"),a9o=o("fnet"),n9o=o(" \u2014 "),VD=a("a"),s9o=o("FNetForSequenceClassification"),l9o=o(" (FNet model)"),i9o=l(),V1=a("li"),nfe=a("strong"),d9o=o("funnel"),c9o=o(" \u2014 "),XD=a("a"),f9o=o("FunnelForSequenceClassification"),m9o=o(" (Funnel Transformer model)"),g9o=l(),X1=a("li"),sfe=a("strong"),h9o=o("gpt2"),p9o=o(" \u2014 "),zD=a("a"),u9o=o("GPT2ForSequenceClassification"),_9o=o(" (OpenAI GPT-2 model)"),b9o=l(),z1=a("li"),lfe=a("strong"),v9o=o("gpt_neo"),F9o=o(" \u2014 "),WD=a("a"),T9o=o("GPTNeoForSequenceClassification"),M9o=o(" (GPT Neo model)"),E9o=l(),W1=a("li"),ife=a("strong"),C9o=o("gptj"),w9o=o(" \u2014 "),QD=a("a"),A9o=o("GPTJForSequenceClassification"),y9o=o(" (GPT-J model)"),L9o=l(),Q1=a("li"),dfe=a("strong"),x9o=o("ibert"),$9o=o(" \u2014 "),HD=a("a"),k9o=o("IBertForSequenceClassification"),S9o=o(" (I-BERT model)"),R9o=l(),H1=a("li"),cfe=a("strong"),P9o=o("layoutlm"),B9o=o(" \u2014 "),UD=a("a"),I9o=o("LayoutLMForSequenceClassification"),q9o=o(" (LayoutLM model)"),N9o=l(),U1=a("li"),ffe=a("strong"),j9o=o("layoutlmv2"),D9o=o(" \u2014 "),JD=a("a"),G9o=o("LayoutLMv2ForSequenceClassification"),O9o=o(" (LayoutLMv2 model)"),V9o=l(),J1=a("li"),mfe=a("strong"),X9o=o("led"),z9o=o(" \u2014 "),YD=a("a"),W9o=o("LEDForSequenceClassification"),Q9o=o(" (LED model)"),H9o=l(),Y1=a("li"),gfe=a("strong"),U9o=o("longformer"),J9o=o(" \u2014 "),KD=a("a"),Y9o=o("LongformerForSequenceClassification"),K9o=o(" (Longformer model)"),Z9o=l(),K1=a("li"),hfe=a("strong"),e$o=o("mbart"),o$o=o(" \u2014 "),ZD=a("a"),r$o=o("MBartForSequenceClassification"),t$o=o(" (mBART model)"),a$o=l(),Z1=a("li"),pfe=a("strong"),n$o=o("megatron-bert"),s$o=o(" \u2014 "),eG=a("a"),l$o=o("MegatronBertForSequenceClassification"),i$o=o(" (MegatronBert model)"),d$o=l(),e7=a("li"),ufe=a("strong"),c$o=o("mobilebert"),f$o=o(" \u2014 "),oG=a("a"),m$o=o("MobileBertForSequenceClassification"),g$o=o(" (MobileBERT model)"),h$o=l(),o7=a("li"),_fe=a("strong"),p$o=o("mpnet"),u$o=o(" \u2014 "),rG=a("a"),_$o=o("MPNetForSequenceClassification"),b$o=o(" (MPNet model)"),v$o=l(),r7=a("li"),bfe=a("strong"),F$o=o("nystromformer"),T$o=o(" \u2014 "),tG=a("a"),M$o=o("NystromformerForSequenceClassification"),E$o=o(" (Nystromformer model)"),C$o=l(),t7=a("li"),vfe=a("strong"),w$o=o("openai-gpt"),A$o=o(" \u2014 "),aG=a("a"),y$o=o("OpenAIGPTForSequenceClassification"),L$o=o(" (OpenAI GPT model)"),x$o=l(),a7=a("li"),Ffe=a("strong"),$$o=o("perceiver"),k$o=o(" \u2014 "),nG=a("a"),S$o=o("PerceiverForSequenceClassification"),R$o=o(" (Perceiver model)"),P$o=l(),n7=a("li"),Tfe=a("strong"),B$o=o("plbart"),I$o=o(" \u2014 "),sG=a("a"),q$o=o("PLBartForSequenceClassification"),N$o=o(" (PLBart model)"),j$o=l(),s7=a("li"),Mfe=a("strong"),D$o=o("qdqbert"),G$o=o(" \u2014 "),lG=a("a"),O$o=o("QDQBertForSequenceClassification"),V$o=o(" (QDQBert model)"),X$o=l(),l7=a("li"),Efe=a("strong"),z$o=o("reformer"),W$o=o(" \u2014 "),iG=a("a"),Q$o=o("ReformerForSequenceClassification"),H$o=o(" (Reformer model)"),U$o=l(),i7=a("li"),Cfe=a("strong"),J$o=o("rembert"),Y$o=o(" \u2014 "),dG=a("a"),K$o=o("RemBertForSequenceClassification"),Z$o=o(" (RemBERT model)"),eko=l(),d7=a("li"),wfe=a("strong"),oko=o("roberta"),rko=o(" \u2014 "),cG=a("a"),tko=o("RobertaForSequenceClassification"),ako=o(" (RoBERTa model)"),nko=l(),c7=a("li"),Afe=a("strong"),sko=o("roformer"),lko=o(" \u2014 "),fG=a("a"),iko=o("RoFormerForSequenceClassification"),dko=o(" (RoFormer model)"),cko=l(),f7=a("li"),yfe=a("strong"),fko=o("squeezebert"),mko=o(" \u2014 "),mG=a("a"),gko=o("SqueezeBertForSequenceClassification"),hko=o(" (SqueezeBERT model)"),pko=l(),m7=a("li"),Lfe=a("strong"),uko=o("tapas"),_ko=o(" \u2014 "),gG=a("a"),bko=o("TapasForSequenceClassification"),vko=o(" (TAPAS model)"),Fko=l(),g7=a("li"),xfe=a("strong"),Tko=o("transfo-xl"),Mko=o(" \u2014 "),hG=a("a"),Eko=o("TransfoXLForSequenceClassification"),Cko=o(" (Transformer-XL model)"),wko=l(),h7=a("li"),$fe=a("strong"),Ako=o("xlm"),yko=o(" \u2014 "),pG=a("a"),Lko=o("XLMForSequenceClassification"),xko=o(" (XLM model)"),$ko=l(),p7=a("li"),kfe=a("strong"),kko=o("xlm-roberta"),Sko=o(" \u2014 "),uG=a("a"),Rko=o("XLMRobertaForSequenceClassification"),Pko=o(" (XLM-RoBERTa model)"),Bko=l(),u7=a("li"),Sfe=a("strong"),Iko=o("xlm-roberta-xl"),qko=o(" \u2014 "),_G=a("a"),Nko=o("XLMRobertaXLForSequenceClassification"),jko=o(" (XLM-RoBERTa-XL model)"),Dko=l(),_7=a("li"),Rfe=a("strong"),Gko=o("xlnet"),Oko=o(" \u2014 "),bG=a("a"),Vko=o("XLNetForSequenceClassification"),Xko=o(" (XLNet model)"),zko=l(),b7=a("li"),Pfe=a("strong"),Wko=o("yoso"),Qko=o(" \u2014 "),vG=a("a"),Hko=o("YosoForSequenceClassification"),Uko=o(" (YOSO model)"),Jko=l(),v7=a("p"),Yko=o("The model is set in evaluation mode by default using "),Bfe=a("code"),Kko=o("model.eval()"),Zko=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ife=a("code"),eSo=o("model.train()"),oSo=l(),F(F7.$$.fragment),iqe=l(),Oi=a("h2"),T7=a("a"),qfe=a("span"),F(my.$$.fragment),rSo=l(),Nfe=a("span"),tSo=o("AutoModelForMultipleChoice"),dqe=l(),Po=a("div"),F(gy.$$.fragment),aSo=l(),Vi=a("p"),nSo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FG=a("a"),sSo=o("from_pretrained()"),lSo=o(" class method or the "),TG=a("a"),iSo=o("from_config()"),dSo=o(` class
method.`),cSo=l(),hy=a("p"),fSo=o("This class cannot be instantiated directly using "),jfe=a("code"),mSo=o("__init__()"),gSo=o(" (throws an error)."),hSo=l(),dt=a("div"),F(py.$$.fragment),pSo=l(),Dfe=a("p"),uSo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),_So=l(),Xi=a("p"),bSo=o(`Note:
Loading a model from its configuration file does `),Gfe=a("strong"),vSo=o("not"),FSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MG=a("a"),TSo=o("from_pretrained()"),MSo=o(" to load the model weights."),ESo=l(),F(M7.$$.fragment),CSo=l(),ro=a("div"),F(uy.$$.fragment),wSo=l(),Ofe=a("p"),ASo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ySo=l(),Pa=a("p"),LSo=o("The model class to instantiate is selected based on the "),Vfe=a("code"),xSo=o("model_type"),$So=o(` property of the config object (either
passed as an argument or loaded from `),Xfe=a("code"),kSo=o("pretrained_model_name_or_path"),SSo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zfe=a("code"),RSo=o("pretrained_model_name_or_path"),PSo=o(":"),BSo=l(),Y=a("ul"),E7=a("li"),Wfe=a("strong"),ISo=o("albert"),qSo=o(" \u2014 "),EG=a("a"),NSo=o("AlbertForMultipleChoice"),jSo=o(" (ALBERT model)"),DSo=l(),C7=a("li"),Qfe=a("strong"),GSo=o("bert"),OSo=o(" \u2014 "),CG=a("a"),VSo=o("BertForMultipleChoice"),XSo=o(" (BERT model)"),zSo=l(),w7=a("li"),Hfe=a("strong"),WSo=o("big_bird"),QSo=o(" \u2014 "),wG=a("a"),HSo=o("BigBirdForMultipleChoice"),USo=o(" (BigBird model)"),JSo=l(),A7=a("li"),Ufe=a("strong"),YSo=o("camembert"),KSo=o(" \u2014 "),AG=a("a"),ZSo=o("CamembertForMultipleChoice"),eRo=o(" (CamemBERT model)"),oRo=l(),y7=a("li"),Jfe=a("strong"),rRo=o("canine"),tRo=o(" \u2014 "),yG=a("a"),aRo=o("CanineForMultipleChoice"),nRo=o(" (Canine model)"),sRo=l(),L7=a("li"),Yfe=a("strong"),lRo=o("convbert"),iRo=o(" \u2014 "),LG=a("a"),dRo=o("ConvBertForMultipleChoice"),cRo=o(" (ConvBERT model)"),fRo=l(),x7=a("li"),Kfe=a("strong"),mRo=o("data2vec-text"),gRo=o(" \u2014 "),xG=a("a"),hRo=o("Data2VecTextForMultipleChoice"),pRo=o(" (Data2VecText model)"),uRo=l(),$7=a("li"),Zfe=a("strong"),_Ro=o("deberta-v2"),bRo=o(" \u2014 "),$G=a("a"),vRo=o("DebertaV2ForMultipleChoice"),FRo=o(" (DeBERTa-v2 model)"),TRo=l(),k7=a("li"),eme=a("strong"),MRo=o("distilbert"),ERo=o(" \u2014 "),kG=a("a"),CRo=o("DistilBertForMultipleChoice"),wRo=o(" (DistilBERT model)"),ARo=l(),S7=a("li"),ome=a("strong"),yRo=o("electra"),LRo=o(" \u2014 "),SG=a("a"),xRo=o("ElectraForMultipleChoice"),$Ro=o(" (ELECTRA model)"),kRo=l(),R7=a("li"),rme=a("strong"),SRo=o("flaubert"),RRo=o(" \u2014 "),RG=a("a"),PRo=o("FlaubertForMultipleChoice"),BRo=o(" (FlauBERT model)"),IRo=l(),P7=a("li"),tme=a("strong"),qRo=o("fnet"),NRo=o(" \u2014 "),PG=a("a"),jRo=o("FNetForMultipleChoice"),DRo=o(" (FNet model)"),GRo=l(),B7=a("li"),ame=a("strong"),ORo=o("funnel"),VRo=o(" \u2014 "),BG=a("a"),XRo=o("FunnelForMultipleChoice"),zRo=o(" (Funnel Transformer model)"),WRo=l(),I7=a("li"),nme=a("strong"),QRo=o("ibert"),HRo=o(" \u2014 "),IG=a("a"),URo=o("IBertForMultipleChoice"),JRo=o(" (I-BERT model)"),YRo=l(),q7=a("li"),sme=a("strong"),KRo=o("longformer"),ZRo=o(" \u2014 "),qG=a("a"),ePo=o("LongformerForMultipleChoice"),oPo=o(" (Longformer model)"),rPo=l(),N7=a("li"),lme=a("strong"),tPo=o("megatron-bert"),aPo=o(" \u2014 "),NG=a("a"),nPo=o("MegatronBertForMultipleChoice"),sPo=o(" (MegatronBert model)"),lPo=l(),j7=a("li"),ime=a("strong"),iPo=o("mobilebert"),dPo=o(" \u2014 "),jG=a("a"),cPo=o("MobileBertForMultipleChoice"),fPo=o(" (MobileBERT model)"),mPo=l(),D7=a("li"),dme=a("strong"),gPo=o("mpnet"),hPo=o(" \u2014 "),DG=a("a"),pPo=o("MPNetForMultipleChoice"),uPo=o(" (MPNet model)"),_Po=l(),G7=a("li"),cme=a("strong"),bPo=o("nystromformer"),vPo=o(" \u2014 "),GG=a("a"),FPo=o("NystromformerForMultipleChoice"),TPo=o(" (Nystromformer model)"),MPo=l(),O7=a("li"),fme=a("strong"),EPo=o("qdqbert"),CPo=o(" \u2014 "),OG=a("a"),wPo=o("QDQBertForMultipleChoice"),APo=o(" (QDQBert model)"),yPo=l(),V7=a("li"),mme=a("strong"),LPo=o("rembert"),xPo=o(" \u2014 "),VG=a("a"),$Po=o("RemBertForMultipleChoice"),kPo=o(" (RemBERT model)"),SPo=l(),X7=a("li"),gme=a("strong"),RPo=o("roberta"),PPo=o(" \u2014 "),XG=a("a"),BPo=o("RobertaForMultipleChoice"),IPo=o(" (RoBERTa model)"),qPo=l(),z7=a("li"),hme=a("strong"),NPo=o("roformer"),jPo=o(" \u2014 "),zG=a("a"),DPo=o("RoFormerForMultipleChoice"),GPo=o(" (RoFormer model)"),OPo=l(),W7=a("li"),pme=a("strong"),VPo=o("squeezebert"),XPo=o(" \u2014 "),WG=a("a"),zPo=o("SqueezeBertForMultipleChoice"),WPo=o(" (SqueezeBERT model)"),QPo=l(),Q7=a("li"),ume=a("strong"),HPo=o("xlm"),UPo=o(" \u2014 "),QG=a("a"),JPo=o("XLMForMultipleChoice"),YPo=o(" (XLM model)"),KPo=l(),H7=a("li"),_me=a("strong"),ZPo=o("xlm-roberta"),eBo=o(" \u2014 "),HG=a("a"),oBo=o("XLMRobertaForMultipleChoice"),rBo=o(" (XLM-RoBERTa model)"),tBo=l(),U7=a("li"),bme=a("strong"),aBo=o("xlm-roberta-xl"),nBo=o(" \u2014 "),UG=a("a"),sBo=o("XLMRobertaXLForMultipleChoice"),lBo=o(" (XLM-RoBERTa-XL model)"),iBo=l(),J7=a("li"),vme=a("strong"),dBo=o("xlnet"),cBo=o(" \u2014 "),JG=a("a"),fBo=o("XLNetForMultipleChoice"),mBo=o(" (XLNet model)"),gBo=l(),Y7=a("li"),Fme=a("strong"),hBo=o("yoso"),pBo=o(" \u2014 "),YG=a("a"),uBo=o("YosoForMultipleChoice"),_Bo=o(" (YOSO model)"),bBo=l(),K7=a("p"),vBo=o("The model is set in evaluation mode by default using "),Tme=a("code"),FBo=o("model.eval()"),TBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mme=a("code"),MBo=o("model.train()"),EBo=l(),F(Z7.$$.fragment),cqe=l(),zi=a("h2"),eb=a("a"),Eme=a("span"),F(_y.$$.fragment),CBo=l(),Cme=a("span"),wBo=o("AutoModelForNextSentencePrediction"),fqe=l(),Bo=a("div"),F(by.$$.fragment),ABo=l(),Wi=a("p"),yBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),KG=a("a"),LBo=o("from_pretrained()"),xBo=o(" class method or the "),ZG=a("a"),$Bo=o("from_config()"),kBo=o(` class
method.`),SBo=l(),vy=a("p"),RBo=o("This class cannot be instantiated directly using "),wme=a("code"),PBo=o("__init__()"),BBo=o(" (throws an error)."),IBo=l(),ct=a("div"),F(Fy.$$.fragment),qBo=l(),Ame=a("p"),NBo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jBo=l(),Qi=a("p"),DBo=o(`Note:
Loading a model from its configuration file does `),yme=a("strong"),GBo=o("not"),OBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eO=a("a"),VBo=o("from_pretrained()"),XBo=o(" to load the model weights."),zBo=l(),F(ob.$$.fragment),WBo=l(),to=a("div"),F(Ty.$$.fragment),QBo=l(),Lme=a("p"),HBo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),UBo=l(),Ba=a("p"),JBo=o("The model class to instantiate is selected based on the "),xme=a("code"),YBo=o("model_type"),KBo=o(` property of the config object (either
passed as an argument or loaded from `),$me=a("code"),ZBo=o("pretrained_model_name_or_path"),eIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kme=a("code"),oIo=o("pretrained_model_name_or_path"),rIo=o(":"),tIo=l(),Yr=a("ul"),rb=a("li"),Sme=a("strong"),aIo=o("bert"),nIo=o(" \u2014 "),oO=a("a"),sIo=o("BertForNextSentencePrediction"),lIo=o(" (BERT model)"),iIo=l(),tb=a("li"),Rme=a("strong"),dIo=o("fnet"),cIo=o(" \u2014 "),rO=a("a"),fIo=o("FNetForNextSentencePrediction"),mIo=o(" (FNet model)"),gIo=l(),ab=a("li"),Pme=a("strong"),hIo=o("megatron-bert"),pIo=o(" \u2014 "),tO=a("a"),uIo=o("MegatronBertForNextSentencePrediction"),_Io=o(" (MegatronBert model)"),bIo=l(),nb=a("li"),Bme=a("strong"),vIo=o("mobilebert"),FIo=o(" \u2014 "),aO=a("a"),TIo=o("MobileBertForNextSentencePrediction"),MIo=o(" (MobileBERT model)"),EIo=l(),sb=a("li"),Ime=a("strong"),CIo=o("qdqbert"),wIo=o(" \u2014 "),nO=a("a"),AIo=o("QDQBertForNextSentencePrediction"),yIo=o(" (QDQBert model)"),LIo=l(),lb=a("p"),xIo=o("The model is set in evaluation mode by default using "),qme=a("code"),$Io=o("model.eval()"),kIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=a("code"),SIo=o("model.train()"),RIo=l(),F(ib.$$.fragment),mqe=l(),Hi=a("h2"),db=a("a"),jme=a("span"),F(My.$$.fragment),PIo=l(),Dme=a("span"),BIo=o("AutoModelForTokenClassification"),gqe=l(),Io=a("div"),F(Ey.$$.fragment),IIo=l(),Ui=a("p"),qIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),sO=a("a"),NIo=o("from_pretrained()"),jIo=o(" class method or the "),lO=a("a"),DIo=o("from_config()"),GIo=o(` class
method.`),OIo=l(),Cy=a("p"),VIo=o("This class cannot be instantiated directly using "),Gme=a("code"),XIo=o("__init__()"),zIo=o(" (throws an error)."),WIo=l(),ft=a("div"),F(wy.$$.fragment),QIo=l(),Ome=a("p"),HIo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),UIo=l(),Ji=a("p"),JIo=o(`Note:
Loading a model from its configuration file does `),Vme=a("strong"),YIo=o("not"),KIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=a("a"),ZIo=o("from_pretrained()"),eqo=o(" to load the model weights."),oqo=l(),F(cb.$$.fragment),rqo=l(),ao=a("div"),F(Ay.$$.fragment),tqo=l(),Xme=a("p"),aqo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),nqo=l(),Ia=a("p"),sqo=o("The model class to instantiate is selected based on the "),zme=a("code"),lqo=o("model_type"),iqo=o(` property of the config object (either
passed as an argument or loaded from `),Wme=a("code"),dqo=o("pretrained_model_name_or_path"),cqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=a("code"),fqo=o("pretrained_model_name_or_path"),mqo=o(":"),gqo=l(),U=a("ul"),fb=a("li"),Hme=a("strong"),hqo=o("albert"),pqo=o(" \u2014 "),dO=a("a"),uqo=o("AlbertForTokenClassification"),_qo=o(" (ALBERT model)"),bqo=l(),mb=a("li"),Ume=a("strong"),vqo=o("bert"),Fqo=o(" \u2014 "),cO=a("a"),Tqo=o("BertForTokenClassification"),Mqo=o(" (BERT model)"),Eqo=l(),gb=a("li"),Jme=a("strong"),Cqo=o("big_bird"),wqo=o(" \u2014 "),fO=a("a"),Aqo=o("BigBirdForTokenClassification"),yqo=o(" (BigBird model)"),Lqo=l(),hb=a("li"),Yme=a("strong"),xqo=o("camembert"),$qo=o(" \u2014 "),mO=a("a"),kqo=o("CamembertForTokenClassification"),Sqo=o(" (CamemBERT model)"),Rqo=l(),pb=a("li"),Kme=a("strong"),Pqo=o("canine"),Bqo=o(" \u2014 "),gO=a("a"),Iqo=o("CanineForTokenClassification"),qqo=o(" (Canine model)"),Nqo=l(),ub=a("li"),Zme=a("strong"),jqo=o("convbert"),Dqo=o(" \u2014 "),hO=a("a"),Gqo=o("ConvBertForTokenClassification"),Oqo=o(" (ConvBERT model)"),Vqo=l(),_b=a("li"),ege=a("strong"),Xqo=o("data2vec-text"),zqo=o(" \u2014 "),pO=a("a"),Wqo=o("Data2VecTextForTokenClassification"),Qqo=o(" (Data2VecText model)"),Hqo=l(),bb=a("li"),oge=a("strong"),Uqo=o("deberta"),Jqo=o(" \u2014 "),uO=a("a"),Yqo=o("DebertaForTokenClassification"),Kqo=o(" (DeBERTa model)"),Zqo=l(),vb=a("li"),rge=a("strong"),eNo=o("deberta-v2"),oNo=o(" \u2014 "),_O=a("a"),rNo=o("DebertaV2ForTokenClassification"),tNo=o(" (DeBERTa-v2 model)"),aNo=l(),Fb=a("li"),tge=a("strong"),nNo=o("distilbert"),sNo=o(" \u2014 "),bO=a("a"),lNo=o("DistilBertForTokenClassification"),iNo=o(" (DistilBERT model)"),dNo=l(),Tb=a("li"),age=a("strong"),cNo=o("electra"),fNo=o(" \u2014 "),vO=a("a"),mNo=o("ElectraForTokenClassification"),gNo=o(" (ELECTRA model)"),hNo=l(),Mb=a("li"),nge=a("strong"),pNo=o("flaubert"),uNo=o(" \u2014 "),FO=a("a"),_No=o("FlaubertForTokenClassification"),bNo=o(" (FlauBERT model)"),vNo=l(),Eb=a("li"),sge=a("strong"),FNo=o("fnet"),TNo=o(" \u2014 "),TO=a("a"),MNo=o("FNetForTokenClassification"),ENo=o(" (FNet model)"),CNo=l(),Cb=a("li"),lge=a("strong"),wNo=o("funnel"),ANo=o(" \u2014 "),MO=a("a"),yNo=o("FunnelForTokenClassification"),LNo=o(" (Funnel Transformer model)"),xNo=l(),wb=a("li"),ige=a("strong"),$No=o("gpt2"),kNo=o(" \u2014 "),EO=a("a"),SNo=o("GPT2ForTokenClassification"),RNo=o(" (OpenAI GPT-2 model)"),PNo=l(),Ab=a("li"),dge=a("strong"),BNo=o("ibert"),INo=o(" \u2014 "),CO=a("a"),qNo=o("IBertForTokenClassification"),NNo=o(" (I-BERT model)"),jNo=l(),yb=a("li"),cge=a("strong"),DNo=o("layoutlm"),GNo=o(" \u2014 "),wO=a("a"),ONo=o("LayoutLMForTokenClassification"),VNo=o(" (LayoutLM model)"),XNo=l(),Lb=a("li"),fge=a("strong"),zNo=o("layoutlmv2"),WNo=o(" \u2014 "),AO=a("a"),QNo=o("LayoutLMv2ForTokenClassification"),HNo=o(" (LayoutLMv2 model)"),UNo=l(),xb=a("li"),mge=a("strong"),JNo=o("longformer"),YNo=o(" \u2014 "),yO=a("a"),KNo=o("LongformerForTokenClassification"),ZNo=o(" (Longformer model)"),ejo=l(),$b=a("li"),gge=a("strong"),ojo=o("megatron-bert"),rjo=o(" \u2014 "),LO=a("a"),tjo=o("MegatronBertForTokenClassification"),ajo=o(" (MegatronBert model)"),njo=l(),kb=a("li"),hge=a("strong"),sjo=o("mobilebert"),ljo=o(" \u2014 "),xO=a("a"),ijo=o("MobileBertForTokenClassification"),djo=o(" (MobileBERT model)"),cjo=l(),Sb=a("li"),pge=a("strong"),fjo=o("mpnet"),mjo=o(" \u2014 "),$O=a("a"),gjo=o("MPNetForTokenClassification"),hjo=o(" (MPNet model)"),pjo=l(),Rb=a("li"),uge=a("strong"),ujo=o("nystromformer"),_jo=o(" \u2014 "),kO=a("a"),bjo=o("NystromformerForTokenClassification"),vjo=o(" (Nystromformer model)"),Fjo=l(),Pb=a("li"),_ge=a("strong"),Tjo=o("qdqbert"),Mjo=o(" \u2014 "),SO=a("a"),Ejo=o("QDQBertForTokenClassification"),Cjo=o(" (QDQBert model)"),wjo=l(),Bb=a("li"),bge=a("strong"),Ajo=o("rembert"),yjo=o(" \u2014 "),RO=a("a"),Ljo=o("RemBertForTokenClassification"),xjo=o(" (RemBERT model)"),$jo=l(),Ib=a("li"),vge=a("strong"),kjo=o("roberta"),Sjo=o(" \u2014 "),PO=a("a"),Rjo=o("RobertaForTokenClassification"),Pjo=o(" (RoBERTa model)"),Bjo=l(),qb=a("li"),Fge=a("strong"),Ijo=o("roformer"),qjo=o(" \u2014 "),BO=a("a"),Njo=o("RoFormerForTokenClassification"),jjo=o(" (RoFormer model)"),Djo=l(),Nb=a("li"),Tge=a("strong"),Gjo=o("squeezebert"),Ojo=o(" \u2014 "),IO=a("a"),Vjo=o("SqueezeBertForTokenClassification"),Xjo=o(" (SqueezeBERT model)"),zjo=l(),jb=a("li"),Mge=a("strong"),Wjo=o("xlm"),Qjo=o(" \u2014 "),qO=a("a"),Hjo=o("XLMForTokenClassification"),Ujo=o(" (XLM model)"),Jjo=l(),Db=a("li"),Ege=a("strong"),Yjo=o("xlm-roberta"),Kjo=o(" \u2014 "),NO=a("a"),Zjo=o("XLMRobertaForTokenClassification"),eDo=o(" (XLM-RoBERTa model)"),oDo=l(),Gb=a("li"),Cge=a("strong"),rDo=o("xlm-roberta-xl"),tDo=o(" \u2014 "),jO=a("a"),aDo=o("XLMRobertaXLForTokenClassification"),nDo=o(" (XLM-RoBERTa-XL model)"),sDo=l(),Ob=a("li"),wge=a("strong"),lDo=o("xlnet"),iDo=o(" \u2014 "),DO=a("a"),dDo=o("XLNetForTokenClassification"),cDo=o(" (XLNet model)"),fDo=l(),Vb=a("li"),Age=a("strong"),mDo=o("yoso"),gDo=o(" \u2014 "),GO=a("a"),hDo=o("YosoForTokenClassification"),pDo=o(" (YOSO model)"),uDo=l(),Xb=a("p"),_Do=o("The model is set in evaluation mode by default using "),yge=a("code"),bDo=o("model.eval()"),vDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lge=a("code"),FDo=o("model.train()"),TDo=l(),F(zb.$$.fragment),hqe=l(),Yi=a("h2"),Wb=a("a"),xge=a("span"),F(yy.$$.fragment),MDo=l(),$ge=a("span"),EDo=o("AutoModelForQuestionAnswering"),pqe=l(),qo=a("div"),F(Ly.$$.fragment),CDo=l(),Ki=a("p"),wDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),OO=a("a"),ADo=o("from_pretrained()"),yDo=o(" class method or the "),VO=a("a"),LDo=o("from_config()"),xDo=o(` class
method.`),$Do=l(),xy=a("p"),kDo=o("This class cannot be instantiated directly using "),kge=a("code"),SDo=o("__init__()"),RDo=o(" (throws an error)."),PDo=l(),mt=a("div"),F($y.$$.fragment),BDo=l(),Sge=a("p"),IDo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),qDo=l(),Zi=a("p"),NDo=o(`Note:
Loading a model from its configuration file does `),Rge=a("strong"),jDo=o("not"),DDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XO=a("a"),GDo=o("from_pretrained()"),ODo=o(" to load the model weights."),VDo=l(),F(Qb.$$.fragment),XDo=l(),no=a("div"),F(ky.$$.fragment),zDo=l(),Pge=a("p"),WDo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),QDo=l(),qa=a("p"),HDo=o("The model class to instantiate is selected based on the "),Bge=a("code"),UDo=o("model_type"),JDo=o(` property of the config object (either
passed as an argument or loaded from `),Ige=a("code"),YDo=o("pretrained_model_name_or_path"),KDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qge=a("code"),ZDo=o("pretrained_model_name_or_path"),eGo=o(":"),oGo=l(),V=a("ul"),Hb=a("li"),Nge=a("strong"),rGo=o("albert"),tGo=o(" \u2014 "),zO=a("a"),aGo=o("AlbertForQuestionAnswering"),nGo=o(" (ALBERT model)"),sGo=l(),Ub=a("li"),jge=a("strong"),lGo=o("bart"),iGo=o(" \u2014 "),WO=a("a"),dGo=o("BartForQuestionAnswering"),cGo=o(" (BART model)"),fGo=l(),Jb=a("li"),Dge=a("strong"),mGo=o("bert"),gGo=o(" \u2014 "),QO=a("a"),hGo=o("BertForQuestionAnswering"),pGo=o(" (BERT model)"),uGo=l(),Yb=a("li"),Gge=a("strong"),_Go=o("big_bird"),bGo=o(" \u2014 "),HO=a("a"),vGo=o("BigBirdForQuestionAnswering"),FGo=o(" (BigBird model)"),TGo=l(),Kb=a("li"),Oge=a("strong"),MGo=o("bigbird_pegasus"),EGo=o(" \u2014 "),UO=a("a"),CGo=o("BigBirdPegasusForQuestionAnswering"),wGo=o(" (BigBirdPegasus model)"),AGo=l(),Zb=a("li"),Vge=a("strong"),yGo=o("camembert"),LGo=o(" \u2014 "),JO=a("a"),xGo=o("CamembertForQuestionAnswering"),$Go=o(" (CamemBERT model)"),kGo=l(),ev=a("li"),Xge=a("strong"),SGo=o("canine"),RGo=o(" \u2014 "),YO=a("a"),PGo=o("CanineForQuestionAnswering"),BGo=o(" (Canine model)"),IGo=l(),ov=a("li"),zge=a("strong"),qGo=o("convbert"),NGo=o(" \u2014 "),KO=a("a"),jGo=o("ConvBertForQuestionAnswering"),DGo=o(" (ConvBERT model)"),GGo=l(),rv=a("li"),Wge=a("strong"),OGo=o("data2vec-text"),VGo=o(" \u2014 "),ZO=a("a"),XGo=o("Data2VecTextForQuestionAnswering"),zGo=o(" (Data2VecText model)"),WGo=l(),tv=a("li"),Qge=a("strong"),QGo=o("deberta"),HGo=o(" \u2014 "),eV=a("a"),UGo=o("DebertaForQuestionAnswering"),JGo=o(" (DeBERTa model)"),YGo=l(),av=a("li"),Hge=a("strong"),KGo=o("deberta-v2"),ZGo=o(" \u2014 "),oV=a("a"),eOo=o("DebertaV2ForQuestionAnswering"),oOo=o(" (DeBERTa-v2 model)"),rOo=l(),nv=a("li"),Uge=a("strong"),tOo=o("distilbert"),aOo=o(" \u2014 "),rV=a("a"),nOo=o("DistilBertForQuestionAnswering"),sOo=o(" (DistilBERT model)"),lOo=l(),sv=a("li"),Jge=a("strong"),iOo=o("electra"),dOo=o(" \u2014 "),tV=a("a"),cOo=o("ElectraForQuestionAnswering"),fOo=o(" (ELECTRA model)"),mOo=l(),lv=a("li"),Yge=a("strong"),gOo=o("flaubert"),hOo=o(" \u2014 "),aV=a("a"),pOo=o("FlaubertForQuestionAnsweringSimple"),uOo=o(" (FlauBERT model)"),_Oo=l(),iv=a("li"),Kge=a("strong"),bOo=o("fnet"),vOo=o(" \u2014 "),nV=a("a"),FOo=o("FNetForQuestionAnswering"),TOo=o(" (FNet model)"),MOo=l(),dv=a("li"),Zge=a("strong"),EOo=o("funnel"),COo=o(" \u2014 "),sV=a("a"),wOo=o("FunnelForQuestionAnswering"),AOo=o(" (Funnel Transformer model)"),yOo=l(),cv=a("li"),ehe=a("strong"),LOo=o("gptj"),xOo=o(" \u2014 "),lV=a("a"),$Oo=o("GPTJForQuestionAnswering"),kOo=o(" (GPT-J model)"),SOo=l(),fv=a("li"),ohe=a("strong"),ROo=o("ibert"),POo=o(" \u2014 "),iV=a("a"),BOo=o("IBertForQuestionAnswering"),IOo=o(" (I-BERT model)"),qOo=l(),mv=a("li"),rhe=a("strong"),NOo=o("layoutlmv2"),jOo=o(" \u2014 "),dV=a("a"),DOo=o("LayoutLMv2ForQuestionAnswering"),GOo=o(" (LayoutLMv2 model)"),OOo=l(),gv=a("li"),the=a("strong"),VOo=o("led"),XOo=o(" \u2014 "),cV=a("a"),zOo=o("LEDForQuestionAnswering"),WOo=o(" (LED model)"),QOo=l(),hv=a("li"),ahe=a("strong"),HOo=o("longformer"),UOo=o(" \u2014 "),fV=a("a"),JOo=o("LongformerForQuestionAnswering"),YOo=o(" (Longformer model)"),KOo=l(),pv=a("li"),nhe=a("strong"),ZOo=o("lxmert"),eVo=o(" \u2014 "),mV=a("a"),oVo=o("LxmertForQuestionAnswering"),rVo=o(" (LXMERT model)"),tVo=l(),uv=a("li"),she=a("strong"),aVo=o("mbart"),nVo=o(" \u2014 "),gV=a("a"),sVo=o("MBartForQuestionAnswering"),lVo=o(" (mBART model)"),iVo=l(),_v=a("li"),lhe=a("strong"),dVo=o("megatron-bert"),cVo=o(" \u2014 "),hV=a("a"),fVo=o("MegatronBertForQuestionAnswering"),mVo=o(" (MegatronBert model)"),gVo=l(),bv=a("li"),ihe=a("strong"),hVo=o("mobilebert"),pVo=o(" \u2014 "),pV=a("a"),uVo=o("MobileBertForQuestionAnswering"),_Vo=o(" (MobileBERT model)"),bVo=l(),vv=a("li"),dhe=a("strong"),vVo=o("mpnet"),FVo=o(" \u2014 "),uV=a("a"),TVo=o("MPNetForQuestionAnswering"),MVo=o(" (MPNet model)"),EVo=l(),Fv=a("li"),che=a("strong"),CVo=o("nystromformer"),wVo=o(" \u2014 "),_V=a("a"),AVo=o("NystromformerForQuestionAnswering"),yVo=o(" (Nystromformer model)"),LVo=l(),Tv=a("li"),fhe=a("strong"),xVo=o("qdqbert"),$Vo=o(" \u2014 "),bV=a("a"),kVo=o("QDQBertForQuestionAnswering"),SVo=o(" (QDQBert model)"),RVo=l(),Mv=a("li"),mhe=a("strong"),PVo=o("reformer"),BVo=o(" \u2014 "),vV=a("a"),IVo=o("ReformerForQuestionAnswering"),qVo=o(" (Reformer model)"),NVo=l(),Ev=a("li"),ghe=a("strong"),jVo=o("rembert"),DVo=o(" \u2014 "),FV=a("a"),GVo=o("RemBertForQuestionAnswering"),OVo=o(" (RemBERT model)"),VVo=l(),Cv=a("li"),hhe=a("strong"),XVo=o("roberta"),zVo=o(" \u2014 "),TV=a("a"),WVo=o("RobertaForQuestionAnswering"),QVo=o(" (RoBERTa model)"),HVo=l(),wv=a("li"),phe=a("strong"),UVo=o("roformer"),JVo=o(" \u2014 "),MV=a("a"),YVo=o("RoFormerForQuestionAnswering"),KVo=o(" (RoFormer model)"),ZVo=l(),Av=a("li"),uhe=a("strong"),eXo=o("splinter"),oXo=o(" \u2014 "),EV=a("a"),rXo=o("SplinterForQuestionAnswering"),tXo=o(" (Splinter model)"),aXo=l(),yv=a("li"),_he=a("strong"),nXo=o("squeezebert"),sXo=o(" \u2014 "),CV=a("a"),lXo=o("SqueezeBertForQuestionAnswering"),iXo=o(" (SqueezeBERT model)"),dXo=l(),Lv=a("li"),bhe=a("strong"),cXo=o("xlm"),fXo=o(" \u2014 "),wV=a("a"),mXo=o("XLMForQuestionAnsweringSimple"),gXo=o(" (XLM model)"),hXo=l(),xv=a("li"),vhe=a("strong"),pXo=o("xlm-roberta"),uXo=o(" \u2014 "),AV=a("a"),_Xo=o("XLMRobertaForQuestionAnswering"),bXo=o(" (XLM-RoBERTa model)"),vXo=l(),$v=a("li"),Fhe=a("strong"),FXo=o("xlm-roberta-xl"),TXo=o(" \u2014 "),yV=a("a"),MXo=o("XLMRobertaXLForQuestionAnswering"),EXo=o(" (XLM-RoBERTa-XL model)"),CXo=l(),kv=a("li"),The=a("strong"),wXo=o("xlnet"),AXo=o(" \u2014 "),LV=a("a"),yXo=o("XLNetForQuestionAnsweringSimple"),LXo=o(" (XLNet model)"),xXo=l(),Sv=a("li"),Mhe=a("strong"),$Xo=o("yoso"),kXo=o(" \u2014 "),xV=a("a"),SXo=o("YosoForQuestionAnswering"),RXo=o(" (YOSO model)"),PXo=l(),Rv=a("p"),BXo=o("The model is set in evaluation mode by default using "),Ehe=a("code"),IXo=o("model.eval()"),qXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Che=a("code"),NXo=o("model.train()"),jXo=l(),F(Pv.$$.fragment),uqe=l(),ed=a("h2"),Bv=a("a"),whe=a("span"),F(Sy.$$.fragment),DXo=l(),Ahe=a("span"),GXo=o("AutoModelForTableQuestionAnswering"),_qe=l(),No=a("div"),F(Ry.$$.fragment),OXo=l(),od=a("p"),VXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$V=a("a"),XXo=o("from_pretrained()"),zXo=o(" class method or the "),kV=a("a"),WXo=o("from_config()"),QXo=o(` class
method.`),HXo=l(),Py=a("p"),UXo=o("This class cannot be instantiated directly using "),yhe=a("code"),JXo=o("__init__()"),YXo=o(" (throws an error)."),KXo=l(),gt=a("div"),F(By.$$.fragment),ZXo=l(),Lhe=a("p"),ezo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ozo=l(),rd=a("p"),rzo=o(`Note:
Loading a model from its configuration file does `),xhe=a("strong"),tzo=o("not"),azo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SV=a("a"),nzo=o("from_pretrained()"),szo=o(" to load the model weights."),lzo=l(),F(Iv.$$.fragment),izo=l(),so=a("div"),F(Iy.$$.fragment),dzo=l(),$he=a("p"),czo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),fzo=l(),Na=a("p"),mzo=o("The model class to instantiate is selected based on the "),khe=a("code"),gzo=o("model_type"),hzo=o(` property of the config object (either
passed as an argument or loaded from `),She=a("code"),pzo=o("pretrained_model_name_or_path"),uzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rhe=a("code"),_zo=o("pretrained_model_name_or_path"),bzo=o(":"),vzo=l(),Phe=a("ul"),qv=a("li"),Bhe=a("strong"),Fzo=o("tapas"),Tzo=o(" \u2014 "),RV=a("a"),Mzo=o("TapasForQuestionAnswering"),Ezo=o(" (TAPAS model)"),Czo=l(),Nv=a("p"),wzo=o("The model is set in evaluation mode by default using "),Ihe=a("code"),Azo=o("model.eval()"),yzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qhe=a("code"),Lzo=o("model.train()"),xzo=l(),F(jv.$$.fragment),bqe=l(),td=a("h2"),Dv=a("a"),Nhe=a("span"),F(qy.$$.fragment),$zo=l(),jhe=a("span"),kzo=o("AutoModelForImageClassification"),vqe=l(),jo=a("div"),F(Ny.$$.fragment),Szo=l(),ad=a("p"),Rzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),PV=a("a"),Pzo=o("from_pretrained()"),Bzo=o(" class method or the "),BV=a("a"),Izo=o("from_config()"),qzo=o(` class
method.`),Nzo=l(),jy=a("p"),jzo=o("This class cannot be instantiated directly using "),Dhe=a("code"),Dzo=o("__init__()"),Gzo=o(" (throws an error)."),Ozo=l(),ht=a("div"),F(Dy.$$.fragment),Vzo=l(),Ghe=a("p"),Xzo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),zzo=l(),nd=a("p"),Wzo=o(`Note:
Loading a model from its configuration file does `),Ohe=a("strong"),Qzo=o("not"),Hzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IV=a("a"),Uzo=o("from_pretrained()"),Jzo=o(" to load the model weights."),Yzo=l(),F(Gv.$$.fragment),Kzo=l(),lo=a("div"),F(Gy.$$.fragment),Zzo=l(),Vhe=a("p"),eWo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),oWo=l(),ja=a("p"),rWo=o("The model class to instantiate is selected based on the "),Xhe=a("code"),tWo=o("model_type"),aWo=o(` property of the config object (either
passed as an argument or loaded from `),zhe=a("code"),nWo=o("pretrained_model_name_or_path"),sWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Whe=a("code"),lWo=o("pretrained_model_name_or_path"),iWo=o(":"),dWo=l(),Fe=a("ul"),Ov=a("li"),Qhe=a("strong"),cWo=o("beit"),fWo=o(" \u2014 "),qV=a("a"),mWo=o("BeitForImageClassification"),gWo=o(" (BEiT model)"),hWo=l(),Vv=a("li"),Hhe=a("strong"),pWo=o("convnext"),uWo=o(" \u2014 "),NV=a("a"),_Wo=o("ConvNextForImageClassification"),bWo=o(" (ConvNext model)"),vWo=l(),Xv=a("li"),Uhe=a("strong"),FWo=o("data2vec-vision"),TWo=o(" \u2014 "),jV=a("a"),MWo=o("Data2VecVisionForImageClassification"),EWo=o(" (Data2VecVision model)"),CWo=l(),Ps=a("li"),Jhe=a("strong"),wWo=o("deit"),AWo=o(" \u2014 "),DV=a("a"),yWo=o("DeiTForImageClassification"),LWo=o(" or "),GV=a("a"),xWo=o("DeiTForImageClassificationWithTeacher"),$Wo=o(" (DeiT model)"),kWo=l(),zv=a("li"),Yhe=a("strong"),SWo=o("imagegpt"),RWo=o(" \u2014 "),OV=a("a"),PWo=o("ImageGPTForImageClassification"),BWo=o(" (ImageGPT model)"),IWo=l(),pt=a("li"),Khe=a("strong"),qWo=o("perceiver"),NWo=o(" \u2014 "),VV=a("a"),jWo=o("PerceiverForImageClassificationLearned"),DWo=o(" or "),XV=a("a"),GWo=o("PerceiverForImageClassificationFourier"),OWo=o(" or "),zV=a("a"),VWo=o("PerceiverForImageClassificationConvProcessing"),XWo=o(" (Perceiver model)"),zWo=l(),Wv=a("li"),Zhe=a("strong"),WWo=o("poolformer"),QWo=o(" \u2014 "),WV=a("a"),HWo=o("PoolFormerForImageClassification"),UWo=o(" (PoolFormer model)"),JWo=l(),Qv=a("li"),epe=a("strong"),YWo=o("regnet"),KWo=o(" \u2014 "),QV=a("a"),ZWo=o("RegNetForImageClassification"),eQo=o(" (RegNet model)"),oQo=l(),Hv=a("li"),ope=a("strong"),rQo=o("resnet"),tQo=o(" \u2014 "),HV=a("a"),aQo=o("ResNetForImageClassification"),nQo=o(" (ResNet model)"),sQo=l(),Uv=a("li"),rpe=a("strong"),lQo=o("segformer"),iQo=o(" \u2014 "),UV=a("a"),dQo=o("SegformerForImageClassification"),cQo=o(" (SegFormer model)"),fQo=l(),Jv=a("li"),tpe=a("strong"),mQo=o("swin"),gQo=o(" \u2014 "),JV=a("a"),hQo=o("SwinForImageClassification"),pQo=o(" (Swin model)"),uQo=l(),Yv=a("li"),ape=a("strong"),_Qo=o("van"),bQo=o(" \u2014 "),YV=a("a"),vQo=o("VanForImageClassification"),FQo=o(" (VAN model)"),TQo=l(),Kv=a("li"),npe=a("strong"),MQo=o("vit"),EQo=o(" \u2014 "),KV=a("a"),CQo=o("ViTForImageClassification"),wQo=o(" (ViT model)"),AQo=l(),Zv=a("p"),yQo=o("The model is set in evaluation mode by default using "),spe=a("code"),LQo=o("model.eval()"),xQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lpe=a("code"),$Qo=o("model.train()"),kQo=l(),F(eF.$$.fragment),Fqe=l(),sd=a("h2"),oF=a("a"),ipe=a("span"),F(Oy.$$.fragment),SQo=l(),dpe=a("span"),RQo=o("AutoModelForVision2Seq"),Tqe=l(),Do=a("div"),F(Vy.$$.fragment),PQo=l(),ld=a("p"),BQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ZV=a("a"),IQo=o("from_pretrained()"),qQo=o(" class method or the "),eX=a("a"),NQo=o("from_config()"),jQo=o(` class
method.`),DQo=l(),Xy=a("p"),GQo=o("This class cannot be instantiated directly using "),cpe=a("code"),OQo=o("__init__()"),VQo=o(" (throws an error)."),XQo=l(),ut=a("div"),F(zy.$$.fragment),zQo=l(),fpe=a("p"),WQo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),QQo=l(),id=a("p"),HQo=o(`Note:
Loading a model from its configuration file does `),mpe=a("strong"),UQo=o("not"),JQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oX=a("a"),YQo=o("from_pretrained()"),KQo=o(" to load the model weights."),ZQo=l(),F(rF.$$.fragment),eHo=l(),io=a("div"),F(Wy.$$.fragment),oHo=l(),gpe=a("p"),rHo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),tHo=l(),Da=a("p"),aHo=o("The model class to instantiate is selected based on the "),hpe=a("code"),nHo=o("model_type"),sHo=o(` property of the config object (either
passed as an argument or loaded from `),ppe=a("code"),lHo=o("pretrained_model_name_or_path"),iHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),upe=a("code"),dHo=o("pretrained_model_name_or_path"),cHo=o(":"),fHo=l(),_pe=a("ul"),tF=a("li"),bpe=a("strong"),mHo=o("vision-encoder-decoder"),gHo=o(" \u2014 "),rX=a("a"),hHo=o("VisionEncoderDecoderModel"),pHo=o(" (Vision Encoder decoder model)"),uHo=l(),aF=a("p"),_Ho=o("The model is set in evaluation mode by default using "),vpe=a("code"),bHo=o("model.eval()"),vHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fpe=a("code"),FHo=o("model.train()"),THo=l(),F(nF.$$.fragment),Mqe=l(),dd=a("h2"),sF=a("a"),Tpe=a("span"),F(Qy.$$.fragment),MHo=l(),Mpe=a("span"),EHo=o("AutoModelForAudioClassification"),Eqe=l(),Go=a("div"),F(Hy.$$.fragment),CHo=l(),cd=a("p"),wHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),tX=a("a"),AHo=o("from_pretrained()"),yHo=o(" class method or the "),aX=a("a"),LHo=o("from_config()"),xHo=o(` class
method.`),$Ho=l(),Uy=a("p"),kHo=o("This class cannot be instantiated directly using "),Epe=a("code"),SHo=o("__init__()"),RHo=o(" (throws an error)."),PHo=l(),_t=a("div"),F(Jy.$$.fragment),BHo=l(),Cpe=a("p"),IHo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),qHo=l(),fd=a("p"),NHo=o(`Note:
Loading a model from its configuration file does `),wpe=a("strong"),jHo=o("not"),DHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nX=a("a"),GHo=o("from_pretrained()"),OHo=o(" to load the model weights."),VHo=l(),F(lF.$$.fragment),XHo=l(),co=a("div"),F(Yy.$$.fragment),zHo=l(),Ape=a("p"),WHo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),QHo=l(),Ga=a("p"),HHo=o("The model class to instantiate is selected based on the "),ype=a("code"),UHo=o("model_type"),JHo=o(` property of the config object (either
passed as an argument or loaded from `),Lpe=a("code"),YHo=o("pretrained_model_name_or_path"),KHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xpe=a("code"),ZHo=o("pretrained_model_name_or_path"),eUo=o(":"),oUo=l(),Se=a("ul"),iF=a("li"),$pe=a("strong"),rUo=o("data2vec-audio"),tUo=o(" \u2014 "),sX=a("a"),aUo=o("Data2VecAudioForSequenceClassification"),nUo=o(" (Data2VecAudio model)"),sUo=l(),dF=a("li"),kpe=a("strong"),lUo=o("hubert"),iUo=o(" \u2014 "),lX=a("a"),dUo=o("HubertForSequenceClassification"),cUo=o(" (Hubert model)"),fUo=l(),cF=a("li"),Spe=a("strong"),mUo=o("sew"),gUo=o(" \u2014 "),iX=a("a"),hUo=o("SEWForSequenceClassification"),pUo=o(" (SEW model)"),uUo=l(),fF=a("li"),Rpe=a("strong"),_Uo=o("sew-d"),bUo=o(" \u2014 "),dX=a("a"),vUo=o("SEWDForSequenceClassification"),FUo=o(" (SEW-D model)"),TUo=l(),mF=a("li"),Ppe=a("strong"),MUo=o("unispeech"),EUo=o(" \u2014 "),cX=a("a"),CUo=o("UniSpeechForSequenceClassification"),wUo=o(" (UniSpeech model)"),AUo=l(),gF=a("li"),Bpe=a("strong"),yUo=o("unispeech-sat"),LUo=o(" \u2014 "),fX=a("a"),xUo=o("UniSpeechSatForSequenceClassification"),$Uo=o(" (UniSpeechSat model)"),kUo=l(),hF=a("li"),Ipe=a("strong"),SUo=o("wav2vec2"),RUo=o(" \u2014 "),mX=a("a"),PUo=o("Wav2Vec2ForSequenceClassification"),BUo=o(" (Wav2Vec2 model)"),IUo=l(),pF=a("li"),qpe=a("strong"),qUo=o("wav2vec2-conformer"),NUo=o(" \u2014 "),gX=a("a"),jUo=o("Wav2Vec2ConformerForSequenceClassification"),DUo=o(" (Wav2Vec2-Conformer model)"),GUo=l(),uF=a("li"),Npe=a("strong"),OUo=o("wavlm"),VUo=o(" \u2014 "),hX=a("a"),XUo=o("WavLMForSequenceClassification"),zUo=o(" (WavLM model)"),WUo=l(),_F=a("p"),QUo=o("The model is set in evaluation mode by default using "),jpe=a("code"),HUo=o("model.eval()"),UUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dpe=a("code"),JUo=o("model.train()"),YUo=l(),F(bF.$$.fragment),Cqe=l(),md=a("h2"),vF=a("a"),Gpe=a("span"),F(Ky.$$.fragment),KUo=l(),Ope=a("span"),ZUo=o("AutoModelForAudioFrameClassification"),wqe=l(),Oo=a("div"),F(Zy.$$.fragment),eJo=l(),gd=a("p"),oJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),pX=a("a"),rJo=o("from_pretrained()"),tJo=o(" class method or the "),uX=a("a"),aJo=o("from_config()"),nJo=o(` class
method.`),sJo=l(),eL=a("p"),lJo=o("This class cannot be instantiated directly using "),Vpe=a("code"),iJo=o("__init__()"),dJo=o(" (throws an error)."),cJo=l(),bt=a("div"),F(oL.$$.fragment),fJo=l(),Xpe=a("p"),mJo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),gJo=l(),hd=a("p"),hJo=o(`Note:
Loading a model from its configuration file does `),zpe=a("strong"),pJo=o("not"),uJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_X=a("a"),_Jo=o("from_pretrained()"),bJo=o(" to load the model weights."),vJo=l(),F(FF.$$.fragment),FJo=l(),fo=a("div"),F(rL.$$.fragment),TJo=l(),Wpe=a("p"),MJo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),EJo=l(),Oa=a("p"),CJo=o("The model class to instantiate is selected based on the "),Qpe=a("code"),wJo=o("model_type"),AJo=o(` property of the config object (either
passed as an argument or loaded from `),Hpe=a("code"),yJo=o("pretrained_model_name_or_path"),LJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Upe=a("code"),xJo=o("pretrained_model_name_or_path"),$Jo=o(":"),kJo=l(),Kr=a("ul"),TF=a("li"),Jpe=a("strong"),SJo=o("data2vec-audio"),RJo=o(" \u2014 "),bX=a("a"),PJo=o("Data2VecAudioForAudioFrameClassification"),BJo=o(" (Data2VecAudio model)"),IJo=l(),MF=a("li"),Ype=a("strong"),qJo=o("unispeech-sat"),NJo=o(" \u2014 "),vX=a("a"),jJo=o("UniSpeechSatForAudioFrameClassification"),DJo=o(" (UniSpeechSat model)"),GJo=l(),EF=a("li"),Kpe=a("strong"),OJo=o("wav2vec2"),VJo=o(" \u2014 "),FX=a("a"),XJo=o("Wav2Vec2ForAudioFrameClassification"),zJo=o(" (Wav2Vec2 model)"),WJo=l(),CF=a("li"),Zpe=a("strong"),QJo=o("wav2vec2-conformer"),HJo=o(" \u2014 "),TX=a("a"),UJo=o("Wav2Vec2ConformerForAudioFrameClassification"),JJo=o(" (Wav2Vec2-Conformer model)"),YJo=l(),wF=a("li"),eue=a("strong"),KJo=o("wavlm"),ZJo=o(" \u2014 "),MX=a("a"),eYo=o("WavLMForAudioFrameClassification"),oYo=o(" (WavLM model)"),rYo=l(),AF=a("p"),tYo=o("The model is set in evaluation mode by default using "),oue=a("code"),aYo=o("model.eval()"),nYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rue=a("code"),sYo=o("model.train()"),lYo=l(),F(yF.$$.fragment),Aqe=l(),pd=a("h2"),LF=a("a"),tue=a("span"),F(tL.$$.fragment),iYo=l(),aue=a("span"),dYo=o("AutoModelForCTC"),yqe=l(),Vo=a("div"),F(aL.$$.fragment),cYo=l(),ud=a("p"),fYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),EX=a("a"),mYo=o("from_pretrained()"),gYo=o(" class method or the "),CX=a("a"),hYo=o("from_config()"),pYo=o(` class
method.`),uYo=l(),nL=a("p"),_Yo=o("This class cannot be instantiated directly using "),nue=a("code"),bYo=o("__init__()"),vYo=o(" (throws an error)."),FYo=l(),vt=a("div"),F(sL.$$.fragment),TYo=l(),sue=a("p"),MYo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),EYo=l(),_d=a("p"),CYo=o(`Note:
Loading a model from its configuration file does `),lue=a("strong"),wYo=o("not"),AYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wX=a("a"),yYo=o("from_pretrained()"),LYo=o(" to load the model weights."),xYo=l(),F(xF.$$.fragment),$Yo=l(),mo=a("div"),F(lL.$$.fragment),kYo=l(),iue=a("p"),SYo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),RYo=l(),Va=a("p"),PYo=o("The model class to instantiate is selected based on the "),due=a("code"),BYo=o("model_type"),IYo=o(` property of the config object (either
passed as an argument or loaded from `),cue=a("code"),qYo=o("pretrained_model_name_or_path"),NYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fue=a("code"),jYo=o("pretrained_model_name_or_path"),DYo=o(":"),GYo=l(),Re=a("ul"),$F=a("li"),mue=a("strong"),OYo=o("data2vec-audio"),VYo=o(" \u2014 "),AX=a("a"),XYo=o("Data2VecAudioForCTC"),zYo=o(" (Data2VecAudio model)"),WYo=l(),kF=a("li"),gue=a("strong"),QYo=o("hubert"),HYo=o(" \u2014 "),yX=a("a"),UYo=o("HubertForCTC"),JYo=o(" (Hubert model)"),YYo=l(),SF=a("li"),hue=a("strong"),KYo=o("sew"),ZYo=o(" \u2014 "),LX=a("a"),eKo=o("SEWForCTC"),oKo=o(" (SEW model)"),rKo=l(),RF=a("li"),pue=a("strong"),tKo=o("sew-d"),aKo=o(" \u2014 "),xX=a("a"),nKo=o("SEWDForCTC"),sKo=o(" (SEW-D model)"),lKo=l(),PF=a("li"),uue=a("strong"),iKo=o("unispeech"),dKo=o(" \u2014 "),$X=a("a"),cKo=o("UniSpeechForCTC"),fKo=o(" (UniSpeech model)"),mKo=l(),BF=a("li"),_ue=a("strong"),gKo=o("unispeech-sat"),hKo=o(" \u2014 "),kX=a("a"),pKo=o("UniSpeechSatForCTC"),uKo=o(" (UniSpeechSat model)"),_Ko=l(),IF=a("li"),bue=a("strong"),bKo=o("wav2vec2"),vKo=o(" \u2014 "),SX=a("a"),FKo=o("Wav2Vec2ForCTC"),TKo=o(" (Wav2Vec2 model)"),MKo=l(),qF=a("li"),vue=a("strong"),EKo=o("wav2vec2-conformer"),CKo=o(" \u2014 "),RX=a("a"),wKo=o("Wav2Vec2ConformerForCTC"),AKo=o(" (Wav2Vec2-Conformer model)"),yKo=l(),NF=a("li"),Fue=a("strong"),LKo=o("wavlm"),xKo=o(" \u2014 "),PX=a("a"),$Ko=o("WavLMForCTC"),kKo=o(" (WavLM model)"),SKo=l(),jF=a("p"),RKo=o("The model is set in evaluation mode by default using "),Tue=a("code"),PKo=o("model.eval()"),BKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mue=a("code"),IKo=o("model.train()"),qKo=l(),F(DF.$$.fragment),Lqe=l(),bd=a("h2"),GF=a("a"),Eue=a("span"),F(iL.$$.fragment),NKo=l(),Cue=a("span"),jKo=o("AutoModelForSpeechSeq2Seq"),xqe=l(),Xo=a("div"),F(dL.$$.fragment),DKo=l(),vd=a("p"),GKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),BX=a("a"),OKo=o("from_pretrained()"),VKo=o(" class method or the "),IX=a("a"),XKo=o("from_config()"),zKo=o(` class
method.`),WKo=l(),cL=a("p"),QKo=o("This class cannot be instantiated directly using "),wue=a("code"),HKo=o("__init__()"),UKo=o(" (throws an error)."),JKo=l(),Ft=a("div"),F(fL.$$.fragment),YKo=l(),Aue=a("p"),KKo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ZKo=l(),Fd=a("p"),eZo=o(`Note:
Loading a model from its configuration file does `),yue=a("strong"),oZo=o("not"),rZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qX=a("a"),tZo=o("from_pretrained()"),aZo=o(" to load the model weights."),nZo=l(),F(OF.$$.fragment),sZo=l(),go=a("div"),F(mL.$$.fragment),lZo=l(),Lue=a("p"),iZo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),dZo=l(),Xa=a("p"),cZo=o("The model class to instantiate is selected based on the "),xue=a("code"),fZo=o("model_type"),mZo=o(` property of the config object (either
passed as an argument or loaded from `),$ue=a("code"),gZo=o("pretrained_model_name_or_path"),hZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kue=a("code"),pZo=o("pretrained_model_name_or_path"),uZo=o(":"),_Zo=l(),gL=a("ul"),VF=a("li"),Sue=a("strong"),bZo=o("speech-encoder-decoder"),vZo=o(" \u2014 "),NX=a("a"),FZo=o("SpeechEncoderDecoderModel"),TZo=o(" (Speech Encoder decoder model)"),MZo=l(),XF=a("li"),Rue=a("strong"),EZo=o("speech_to_text"),CZo=o(" \u2014 "),jX=a("a"),wZo=o("Speech2TextForConditionalGeneration"),AZo=o(" (Speech2Text model)"),yZo=l(),zF=a("p"),LZo=o("The model is set in evaluation mode by default using "),Pue=a("code"),xZo=o("model.eval()"),$Zo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bue=a("code"),kZo=o("model.train()"),SZo=l(),F(WF.$$.fragment),$qe=l(),Td=a("h2"),QF=a("a"),Iue=a("span"),F(hL.$$.fragment),RZo=l(),que=a("span"),PZo=o("AutoModelForAudioXVector"),kqe=l(),zo=a("div"),F(pL.$$.fragment),BZo=l(),Md=a("p"),IZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),DX=a("a"),qZo=o("from_pretrained()"),NZo=o(" class method or the "),GX=a("a"),jZo=o("from_config()"),DZo=o(` class
method.`),GZo=l(),uL=a("p"),OZo=o("This class cannot be instantiated directly using "),Nue=a("code"),VZo=o("__init__()"),XZo=o(" (throws an error)."),zZo=l(),Tt=a("div"),F(_L.$$.fragment),WZo=l(),jue=a("p"),QZo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),HZo=l(),Ed=a("p"),UZo=o(`Note:
Loading a model from its configuration file does `),Due=a("strong"),JZo=o("not"),YZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OX=a("a"),KZo=o("from_pretrained()"),ZZo=o(" to load the model weights."),eer=l(),F(HF.$$.fragment),oer=l(),ho=a("div"),F(bL.$$.fragment),rer=l(),Gue=a("p"),ter=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),aer=l(),za=a("p"),ner=o("The model class to instantiate is selected based on the "),Oue=a("code"),ser=o("model_type"),ler=o(` property of the config object (either
passed as an argument or loaded from `),Vue=a("code"),ier=o("pretrained_model_name_or_path"),der=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xue=a("code"),cer=o("pretrained_model_name_or_path"),fer=o(":"),mer=l(),Zr=a("ul"),UF=a("li"),zue=a("strong"),ger=o("data2vec-audio"),her=o(" \u2014 "),VX=a("a"),per=o("Data2VecAudioForXVector"),uer=o(" (Data2VecAudio model)"),_er=l(),JF=a("li"),Wue=a("strong"),ber=o("unispeech-sat"),ver=o(" \u2014 "),XX=a("a"),Fer=o("UniSpeechSatForXVector"),Ter=o(" (UniSpeechSat model)"),Mer=l(),YF=a("li"),Que=a("strong"),Eer=o("wav2vec2"),Cer=o(" \u2014 "),zX=a("a"),wer=o("Wav2Vec2ForXVector"),Aer=o(" (Wav2Vec2 model)"),yer=l(),KF=a("li"),Hue=a("strong"),Ler=o("wav2vec2-conformer"),xer=o(" \u2014 "),WX=a("a"),$er=o("Wav2Vec2ConformerForXVector"),ker=o(" (Wav2Vec2-Conformer model)"),Ser=l(),ZF=a("li"),Uue=a("strong"),Rer=o("wavlm"),Per=o(" \u2014 "),QX=a("a"),Ber=o("WavLMForXVector"),Ier=o(" (WavLM model)"),qer=l(),eT=a("p"),Ner=o("The model is set in evaluation mode by default using "),Jue=a("code"),jer=o("model.eval()"),Der=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=a("code"),Ger=o("model.train()"),Oer=l(),F(oT.$$.fragment),Sqe=l(),Cd=a("h2"),rT=a("a"),Kue=a("span"),F(vL.$$.fragment),Ver=l(),Zue=a("span"),Xer=o("AutoModelForMaskedImageModeling"),Rqe=l(),Wo=a("div"),F(FL.$$.fragment),zer=l(),wd=a("p"),Wer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),HX=a("a"),Qer=o("from_pretrained()"),Her=o(" class method or the "),UX=a("a"),Uer=o("from_config()"),Jer=o(` class
method.`),Yer=l(),TL=a("p"),Ker=o("This class cannot be instantiated directly using "),e_e=a("code"),Zer=o("__init__()"),eor=o(" (throws an error)."),oor=l(),Mt=a("div"),F(ML.$$.fragment),ror=l(),o_e=a("p"),tor=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),aor=l(),Ad=a("p"),nor=o(`Note:
Loading a model from its configuration file does `),r_e=a("strong"),sor=o("not"),lor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=a("a"),ior=o("from_pretrained()"),dor=o(" to load the model weights."),cor=l(),F(tT.$$.fragment),mor=l(),po=a("div"),F(EL.$$.fragment),gor=l(),t_e=a("p"),hor=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),por=l(),Wa=a("p"),uor=o("The model class to instantiate is selected based on the "),a_e=a("code"),_or=o("model_type"),bor=o(` property of the config object (either
passed as an argument or loaded from `),n_e=a("code"),vor=o("pretrained_model_name_or_path"),For=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=a("code"),Tor=o("pretrained_model_name_or_path"),Mor=o(":"),Eor=l(),yd=a("ul"),aT=a("li"),l_e=a("strong"),Cor=o("deit"),wor=o(" \u2014 "),YX=a("a"),Aor=o("DeiTForMaskedImageModeling"),yor=o(" (DeiT model)"),Lor=l(),nT=a("li"),i_e=a("strong"),xor=o("swin"),$or=o(" \u2014 "),KX=a("a"),kor=o("SwinForMaskedImageModeling"),Sor=o(" (Swin model)"),Ror=l(),sT=a("li"),d_e=a("strong"),Por=o("vit"),Bor=o(" \u2014 "),ZX=a("a"),Ior=o("ViTForMaskedImageModeling"),qor=o(" (ViT model)"),Nor=l(),lT=a("p"),jor=o("The model is set in evaluation mode by default using "),c_e=a("code"),Dor=o("model.eval()"),Gor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f_e=a("code"),Oor=o("model.train()"),Vor=l(),F(iT.$$.fragment),Pqe=l(),Ld=a("h2"),dT=a("a"),m_e=a("span"),F(CL.$$.fragment),Xor=l(),g_e=a("span"),zor=o("AutoModelForObjectDetection"),Bqe=l(),Qo=a("div"),F(wL.$$.fragment),Wor=l(),xd=a("p"),Qor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),ez=a("a"),Hor=o("from_pretrained()"),Uor=o(" class method or the "),oz=a("a"),Jor=o("from_config()"),Yor=o(` class
method.`),Kor=l(),AL=a("p"),Zor=o("This class cannot be instantiated directly using "),h_e=a("code"),err=o("__init__()"),orr=o(" (throws an error)."),rrr=l(),Et=a("div"),F(yL.$$.fragment),trr=l(),p_e=a("p"),arr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),nrr=l(),$d=a("p"),srr=o(`Note:
Loading a model from its configuration file does `),u_e=a("strong"),lrr=o("not"),irr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rz=a("a"),drr=o("from_pretrained()"),crr=o(" to load the model weights."),frr=l(),F(cT.$$.fragment),mrr=l(),uo=a("div"),F(LL.$$.fragment),grr=l(),__e=a("p"),hrr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),prr=l(),Qa=a("p"),urr=o("The model class to instantiate is selected based on the "),b_e=a("code"),_rr=o("model_type"),brr=o(` property of the config object (either
passed as an argument or loaded from `),v_e=a("code"),vrr=o("pretrained_model_name_or_path"),Frr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F_e=a("code"),Trr=o("pretrained_model_name_or_path"),Mrr=o(":"),Err=l(),xL=a("ul"),fT=a("li"),T_e=a("strong"),Crr=o("detr"),wrr=o(" \u2014 "),tz=a("a"),Arr=o("DetrForObjectDetection"),yrr=o(" (DETR model)"),Lrr=l(),mT=a("li"),M_e=a("strong"),xrr=o("yolos"),$rr=o(" \u2014 "),az=a("a"),krr=o("YolosForObjectDetection"),Srr=o(" (YOLOS model)"),Rrr=l(),gT=a("p"),Prr=o("The model is set in evaluation mode by default using "),E_e=a("code"),Brr=o("model.eval()"),Irr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C_e=a("code"),qrr=o("model.train()"),Nrr=l(),F(hT.$$.fragment),Iqe=l(),kd=a("h2"),pT=a("a"),w_e=a("span"),F($L.$$.fragment),jrr=l(),A_e=a("span"),Drr=o("AutoModelForImageSegmentation"),qqe=l(),Ho=a("div"),F(kL.$$.fragment),Grr=l(),Sd=a("p"),Orr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),nz=a("a"),Vrr=o("from_pretrained()"),Xrr=o(" class method or the "),sz=a("a"),zrr=o("from_config()"),Wrr=o(` class
method.`),Qrr=l(),SL=a("p"),Hrr=o("This class cannot be instantiated directly using "),y_e=a("code"),Urr=o("__init__()"),Jrr=o(" (throws an error)."),Yrr=l(),Ct=a("div"),F(RL.$$.fragment),Krr=l(),L_e=a("p"),Zrr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),etr=l(),Rd=a("p"),otr=o(`Note:
Loading a model from its configuration file does `),x_e=a("strong"),rtr=o("not"),ttr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=a("a"),atr=o("from_pretrained()"),ntr=o(" to load the model weights."),str=l(),F(uT.$$.fragment),ltr=l(),_o=a("div"),F(PL.$$.fragment),itr=l(),$_e=a("p"),dtr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),ctr=l(),Ha=a("p"),ftr=o("The model class to instantiate is selected based on the "),k_e=a("code"),mtr=o("model_type"),gtr=o(` property of the config object (either
passed as an argument or loaded from `),S_e=a("code"),htr=o("pretrained_model_name_or_path"),ptr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R_e=a("code"),utr=o("pretrained_model_name_or_path"),_tr=o(":"),btr=l(),P_e=a("ul"),_T=a("li"),B_e=a("strong"),vtr=o("detr"),Ftr=o(" \u2014 "),iz=a("a"),Ttr=o("DetrForSegmentation"),Mtr=o(" (DETR model)"),Etr=l(),bT=a("p"),Ctr=o("The model is set in evaluation mode by default using "),I_e=a("code"),wtr=o("model.eval()"),Atr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q_e=a("code"),ytr=o("model.train()"),Ltr=l(),F(vT.$$.fragment),Nqe=l(),Pd=a("h2"),FT=a("a"),N_e=a("span"),F(BL.$$.fragment),xtr=l(),j_e=a("span"),$tr=o("AutoModelForSemanticSegmentation"),jqe=l(),Uo=a("div"),F(IL.$$.fragment),ktr=l(),Bd=a("p"),Str=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),dz=a("a"),Rtr=o("from_pretrained()"),Ptr=o(" class method or the "),cz=a("a"),Btr=o("from_config()"),Itr=o(` class
method.`),qtr=l(),qL=a("p"),Ntr=o("This class cannot be instantiated directly using "),D_e=a("code"),jtr=o("__init__()"),Dtr=o(" (throws an error)."),Gtr=l(),wt=a("div"),F(NL.$$.fragment),Otr=l(),G_e=a("p"),Vtr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Xtr=l(),Id=a("p"),ztr=o(`Note:
Loading a model from its configuration file does `),O_e=a("strong"),Wtr=o("not"),Qtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fz=a("a"),Htr=o("from_pretrained()"),Utr=o(" to load the model weights."),Jtr=l(),F(TT.$$.fragment),Ytr=l(),bo=a("div"),F(jL.$$.fragment),Ktr=l(),V_e=a("p"),Ztr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),ear=l(),Ua=a("p"),oar=o("The model class to instantiate is selected based on the "),X_e=a("code"),rar=o("model_type"),tar=o(` property of the config object (either
passed as an argument or loaded from `),z_e=a("code"),aar=o("pretrained_model_name_or_path"),nar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W_e=a("code"),sar=o("pretrained_model_name_or_path"),lar=o(":"),iar=l(),Ja=a("ul"),MT=a("li"),Q_e=a("strong"),dar=o("beit"),car=o(" \u2014 "),mz=a("a"),far=o("BeitForSemanticSegmentation"),mar=o(" (BEiT model)"),gar=l(),ET=a("li"),H_e=a("strong"),har=o("data2vec-vision"),par=o(" \u2014 "),gz=a("a"),uar=o("Data2VecVisionForSemanticSegmentation"),_ar=o(" (Data2VecVision model)"),bar=l(),CT=a("li"),U_e=a("strong"),Far=o("dpt"),Tar=o(" \u2014 "),hz=a("a"),Mar=o("DPTForSemanticSegmentation"),Ear=o(" (DPT model)"),Car=l(),wT=a("li"),J_e=a("strong"),war=o("segformer"),Aar=o(" \u2014 "),pz=a("a"),yar=o("SegformerForSemanticSegmentation"),Lar=o(" (SegFormer model)"),xar=l(),AT=a("p"),$ar=o("The model is set in evaluation mode by default using "),Y_e=a("code"),kar=o("model.eval()"),Sar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K_e=a("code"),Rar=o("model.train()"),Par=l(),F(yT.$$.fragment),Dqe=l(),qd=a("h2"),LT=a("a"),Z_e=a("span"),F(DL.$$.fragment),Bar=l(),e2e=a("span"),Iar=o("AutoModelForInstanceSegmentation"),Gqe=l(),Jo=a("div"),F(GL.$$.fragment),qar=l(),Nd=a("p"),Nar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),uz=a("a"),jar=o("from_pretrained()"),Dar=o(" class method or the "),_z=a("a"),Gar=o("from_config()"),Oar=o(` class
method.`),Var=l(),OL=a("p"),Xar=o("This class cannot be instantiated directly using "),o2e=a("code"),zar=o("__init__()"),War=o(" (throws an error)."),Qar=l(),At=a("div"),F(VL.$$.fragment),Har=l(),r2e=a("p"),Uar=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Jar=l(),jd=a("p"),Yar=o(`Note:
Loading a model from its configuration file does `),t2e=a("strong"),Kar=o("not"),Zar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bz=a("a"),enr=o("from_pretrained()"),onr=o(" to load the model weights."),rnr=l(),F(xT.$$.fragment),tnr=l(),vo=a("div"),F(XL.$$.fragment),anr=l(),a2e=a("p"),nnr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),snr=l(),Ya=a("p"),lnr=o("The model class to instantiate is selected based on the "),n2e=a("code"),inr=o("model_type"),dnr=o(` property of the config object (either
passed as an argument or loaded from `),s2e=a("code"),cnr=o("pretrained_model_name_or_path"),fnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l2e=a("code"),mnr=o("pretrained_model_name_or_path"),gnr=o(":"),hnr=l(),i2e=a("ul"),$T=a("li"),d2e=a("strong"),pnr=o("maskformer"),unr=o(" \u2014 "),vz=a("a"),_nr=o("MaskFormerForInstanceSegmentation"),bnr=o(" (MaskFormer model)"),vnr=l(),kT=a("p"),Fnr=o("The model is set in evaluation mode by default using "),c2e=a("code"),Tnr=o("model.eval()"),Mnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f2e=a("code"),Enr=o("model.train()"),Cnr=l(),F(ST.$$.fragment),Oqe=l(),Dd=a("h2"),RT=a("a"),m2e=a("span"),F(zL.$$.fragment),wnr=l(),g2e=a("span"),Anr=o("TFAutoModel"),Vqe=l(),Yo=a("div"),F(WL.$$.fragment),ynr=l(),Gd=a("p"),Lnr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Fz=a("a"),xnr=o("from_pretrained()"),$nr=o(" class method or the "),Tz=a("a"),knr=o("from_config()"),Snr=o(` class
method.`),Rnr=l(),QL=a("p"),Pnr=o("This class cannot be instantiated directly using "),h2e=a("code"),Bnr=o("__init__()"),Inr=o(" (throws an error)."),qnr=l(),yt=a("div"),F(HL.$$.fragment),Nnr=l(),p2e=a("p"),jnr=o("Instantiates one of the base model classes of the library from a configuration."),Dnr=l(),Od=a("p"),Gnr=o(`Note:
Loading a model from its configuration file does `),u2e=a("strong"),Onr=o("not"),Vnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mz=a("a"),Xnr=o("from_pretrained()"),znr=o(" to load the model weights."),Wnr=l(),F(PT.$$.fragment),Qnr=l(),wr=a("div"),F(UL.$$.fragment),Hnr=l(),_2e=a("p"),Unr=o("Instantiate one of the base model classes of the library from a pretrained model."),Jnr=l(),Ka=a("p"),Ynr=o("The model class to instantiate is selected based on the "),b2e=a("code"),Knr=o("model_type"),Znr=o(` property of the config object (either
passed as an argument or loaded from `),v2e=a("code"),esr=o("pretrained_model_name_or_path"),osr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F2e=a("code"),rsr=o("pretrained_model_name_or_path"),tsr=o(":"),asr=l(),q=a("ul"),BT=a("li"),T2e=a("strong"),nsr=o("albert"),ssr=o(" \u2014 "),Ez=a("a"),lsr=o("TFAlbertModel"),isr=o(" (ALBERT model)"),dsr=l(),IT=a("li"),M2e=a("strong"),csr=o("bart"),fsr=o(" \u2014 "),Cz=a("a"),msr=o("TFBartModel"),gsr=o(" (BART model)"),hsr=l(),qT=a("li"),E2e=a("strong"),psr=o("bert"),usr=o(" \u2014 "),wz=a("a"),_sr=o("TFBertModel"),bsr=o(" (BERT model)"),vsr=l(),NT=a("li"),C2e=a("strong"),Fsr=o("blenderbot"),Tsr=o(" \u2014 "),Az=a("a"),Msr=o("TFBlenderbotModel"),Esr=o(" (Blenderbot model)"),Csr=l(),jT=a("li"),w2e=a("strong"),wsr=o("blenderbot-small"),Asr=o(" \u2014 "),yz=a("a"),ysr=o("TFBlenderbotSmallModel"),Lsr=o(" (BlenderbotSmall model)"),xsr=l(),DT=a("li"),A2e=a("strong"),$sr=o("camembert"),ksr=o(" \u2014 "),Lz=a("a"),Ssr=o("TFCamembertModel"),Rsr=o(" (CamemBERT model)"),Psr=l(),GT=a("li"),y2e=a("strong"),Bsr=o("clip"),Isr=o(" \u2014 "),xz=a("a"),qsr=o("TFCLIPModel"),Nsr=o(" (CLIP model)"),jsr=l(),OT=a("li"),L2e=a("strong"),Dsr=o("convbert"),Gsr=o(" \u2014 "),$z=a("a"),Osr=o("TFConvBertModel"),Vsr=o(" (ConvBERT model)"),Xsr=l(),VT=a("li"),x2e=a("strong"),zsr=o("convnext"),Wsr=o(" \u2014 "),kz=a("a"),Qsr=o("TFConvNextModel"),Hsr=o(" (ConvNext model)"),Usr=l(),XT=a("li"),$2e=a("strong"),Jsr=o("ctrl"),Ysr=o(" \u2014 "),Sz=a("a"),Ksr=o("TFCTRLModel"),Zsr=o(" (CTRL model)"),elr=l(),zT=a("li"),k2e=a("strong"),olr=o("data2vec-vision"),rlr=o(" \u2014 "),Rz=a("a"),tlr=o("TFData2VecVisionModel"),alr=o(" (Data2VecVision model)"),nlr=l(),WT=a("li"),S2e=a("strong"),slr=o("deberta"),llr=o(" \u2014 "),Pz=a("a"),ilr=o("TFDebertaModel"),dlr=o(" (DeBERTa model)"),clr=l(),QT=a("li"),R2e=a("strong"),flr=o("deberta-v2"),mlr=o(" \u2014 "),Bz=a("a"),glr=o("TFDebertaV2Model"),hlr=o(" (DeBERTa-v2 model)"),plr=l(),HT=a("li"),P2e=a("strong"),ulr=o("distilbert"),_lr=o(" \u2014 "),Iz=a("a"),blr=o("TFDistilBertModel"),vlr=o(" (DistilBERT model)"),Flr=l(),UT=a("li"),B2e=a("strong"),Tlr=o("dpr"),Mlr=o(" \u2014 "),qz=a("a"),Elr=o("TFDPRQuestionEncoder"),Clr=o(" (DPR model)"),wlr=l(),JT=a("li"),I2e=a("strong"),Alr=o("electra"),ylr=o(" \u2014 "),Nz=a("a"),Llr=o("TFElectraModel"),xlr=o(" (ELECTRA model)"),$lr=l(),YT=a("li"),q2e=a("strong"),klr=o("flaubert"),Slr=o(" \u2014 "),jz=a("a"),Rlr=o("TFFlaubertModel"),Plr=o(" (FlauBERT model)"),Blr=l(),Bs=a("li"),N2e=a("strong"),Ilr=o("funnel"),qlr=o(" \u2014 "),Dz=a("a"),Nlr=o("TFFunnelModel"),jlr=o(" or "),Gz=a("a"),Dlr=o("TFFunnelBaseModel"),Glr=o(" (Funnel Transformer model)"),Olr=l(),KT=a("li"),j2e=a("strong"),Vlr=o("gpt2"),Xlr=o(" \u2014 "),Oz=a("a"),zlr=o("TFGPT2Model"),Wlr=o(" (OpenAI GPT-2 model)"),Qlr=l(),ZT=a("li"),D2e=a("strong"),Hlr=o("gptj"),Ulr=o(" \u2014 "),Vz=a("a"),Jlr=o("TFGPTJModel"),Ylr=o(" (GPT-J model)"),Klr=l(),eM=a("li"),G2e=a("strong"),Zlr=o("hubert"),eir=o(" \u2014 "),Xz=a("a"),oir=o("TFHubertModel"),rir=o(" (Hubert model)"),tir=l(),oM=a("li"),O2e=a("strong"),air=o("layoutlm"),nir=o(" \u2014 "),zz=a("a"),sir=o("TFLayoutLMModel"),lir=o(" (LayoutLM model)"),iir=l(),rM=a("li"),V2e=a("strong"),dir=o("led"),cir=o(" \u2014 "),Wz=a("a"),fir=o("TFLEDModel"),mir=o(" (LED model)"),gir=l(),tM=a("li"),X2e=a("strong"),hir=o("longformer"),pir=o(" \u2014 "),Qz=a("a"),uir=o("TFLongformerModel"),_ir=o(" (Longformer model)"),bir=l(),aM=a("li"),z2e=a("strong"),vir=o("lxmert"),Fir=o(" \u2014 "),Hz=a("a"),Tir=o("TFLxmertModel"),Mir=o(" (LXMERT model)"),Eir=l(),nM=a("li"),W2e=a("strong"),Cir=o("marian"),wir=o(" \u2014 "),Uz=a("a"),Air=o("TFMarianModel"),yir=o(" (Marian model)"),Lir=l(),sM=a("li"),Q2e=a("strong"),xir=o("mbart"),$ir=o(" \u2014 "),Jz=a("a"),kir=o("TFMBartModel"),Sir=o(" (mBART model)"),Rir=l(),lM=a("li"),H2e=a("strong"),Pir=o("mobilebert"),Bir=o(" \u2014 "),Yz=a("a"),Iir=o("TFMobileBertModel"),qir=o(" (MobileBERT model)"),Nir=l(),iM=a("li"),U2e=a("strong"),jir=o("mpnet"),Dir=o(" \u2014 "),Kz=a("a"),Gir=o("TFMPNetModel"),Oir=o(" (MPNet model)"),Vir=l(),dM=a("li"),J2e=a("strong"),Xir=o("mt5"),zir=o(" \u2014 "),Zz=a("a"),Wir=o("TFMT5Model"),Qir=o(" (mT5 model)"),Hir=l(),cM=a("li"),Y2e=a("strong"),Uir=o("openai-gpt"),Jir=o(" \u2014 "),eW=a("a"),Yir=o("TFOpenAIGPTModel"),Kir=o(" (OpenAI GPT model)"),Zir=l(),fM=a("li"),K2e=a("strong"),edr=o("opt"),odr=o(" \u2014 "),oW=a("a"),rdr=o("TFOPTModel"),tdr=o(" (OPT model)"),adr=l(),mM=a("li"),Z2e=a("strong"),ndr=o("pegasus"),sdr=o(" \u2014 "),rW=a("a"),ldr=o("TFPegasusModel"),idr=o(" (Pegasus model)"),ddr=l(),gM=a("li"),e1e=a("strong"),cdr=o("rembert"),fdr=o(" \u2014 "),tW=a("a"),mdr=o("TFRemBertModel"),gdr=o(" (RemBERT model)"),hdr=l(),hM=a("li"),o1e=a("strong"),pdr=o("roberta"),udr=o(" \u2014 "),aW=a("a"),_dr=o("TFRobertaModel"),bdr=o(" (RoBERTa model)"),vdr=l(),pM=a("li"),r1e=a("strong"),Fdr=o("roformer"),Tdr=o(" \u2014 "),nW=a("a"),Mdr=o("TFRoFormerModel"),Edr=o(" (RoFormer model)"),Cdr=l(),uM=a("li"),t1e=a("strong"),wdr=o("speech_to_text"),Adr=o(" \u2014 "),sW=a("a"),ydr=o("TFSpeech2TextModel"),Ldr=o(" (Speech2Text model)"),xdr=l(),_M=a("li"),a1e=a("strong"),$dr=o("swin"),kdr=o(" \u2014 "),lW=a("a"),Sdr=o("TFSwinModel"),Rdr=o(" (Swin model)"),Pdr=l(),bM=a("li"),n1e=a("strong"),Bdr=o("t5"),Idr=o(" \u2014 "),iW=a("a"),qdr=o("TFT5Model"),Ndr=o(" (T5 model)"),jdr=l(),vM=a("li"),s1e=a("strong"),Ddr=o("tapas"),Gdr=o(" \u2014 "),dW=a("a"),Odr=o("TFTapasModel"),Vdr=o(" (TAPAS model)"),Xdr=l(),FM=a("li"),l1e=a("strong"),zdr=o("transfo-xl"),Wdr=o(" \u2014 "),cW=a("a"),Qdr=o("TFTransfoXLModel"),Hdr=o(" (Transformer-XL model)"),Udr=l(),TM=a("li"),i1e=a("strong"),Jdr=o("vit"),Ydr=o(" \u2014 "),fW=a("a"),Kdr=o("TFViTModel"),Zdr=o(" (ViT model)"),ecr=l(),MM=a("li"),d1e=a("strong"),ocr=o("vit_mae"),rcr=o(" \u2014 "),mW=a("a"),tcr=o("TFViTMAEModel"),acr=o(" (ViTMAE model)"),ncr=l(),EM=a("li"),c1e=a("strong"),scr=o("wav2vec2"),lcr=o(" \u2014 "),gW=a("a"),icr=o("TFWav2Vec2Model"),dcr=o(" (Wav2Vec2 model)"),ccr=l(),CM=a("li"),f1e=a("strong"),fcr=o("xlm"),mcr=o(" \u2014 "),hW=a("a"),gcr=o("TFXLMModel"),hcr=o(" (XLM model)"),pcr=l(),wM=a("li"),m1e=a("strong"),ucr=o("xlm-roberta"),_cr=o(" \u2014 "),pW=a("a"),bcr=o("TFXLMRobertaModel"),vcr=o(" (XLM-RoBERTa model)"),Fcr=l(),AM=a("li"),g1e=a("strong"),Tcr=o("xlnet"),Mcr=o(" \u2014 "),uW=a("a"),Ecr=o("TFXLNetModel"),Ccr=o(" (XLNet model)"),wcr=l(),F(yM.$$.fragment),Xqe=l(),Vd=a("h2"),LM=a("a"),h1e=a("span"),F(JL.$$.fragment),Acr=l(),p1e=a("span"),ycr=o("TFAutoModelForPreTraining"),zqe=l(),Ko=a("div"),F(YL.$$.fragment),Lcr=l(),Xd=a("p"),xcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),_W=a("a"),$cr=o("from_pretrained()"),kcr=o(" class method or the "),bW=a("a"),Scr=o("from_config()"),Rcr=o(` class
method.`),Pcr=l(),KL=a("p"),Bcr=o("This class cannot be instantiated directly using "),u1e=a("code"),Icr=o("__init__()"),qcr=o(" (throws an error)."),Ncr=l(),Lt=a("div"),F(ZL.$$.fragment),jcr=l(),_1e=a("p"),Dcr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Gcr=l(),zd=a("p"),Ocr=o(`Note:
Loading a model from its configuration file does `),b1e=a("strong"),Vcr=o("not"),Xcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=a("a"),zcr=o("from_pretrained()"),Wcr=o(" to load the model weights."),Qcr=l(),F(xM.$$.fragment),Hcr=l(),Ar=a("div"),F(e8.$$.fragment),Ucr=l(),v1e=a("p"),Jcr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Ycr=l(),Za=a("p"),Kcr=o("The model class to instantiate is selected based on the "),F1e=a("code"),Zcr=o("model_type"),efr=o(` property of the config object (either
passed as an argument or loaded from `),T1e=a("code"),ofr=o("pretrained_model_name_or_path"),rfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M1e=a("code"),tfr=o("pretrained_model_name_or_path"),afr=o(":"),nfr=l(),se=a("ul"),$M=a("li"),E1e=a("strong"),sfr=o("albert"),lfr=o(" \u2014 "),FW=a("a"),ifr=o("TFAlbertForPreTraining"),dfr=o(" (ALBERT model)"),cfr=l(),kM=a("li"),C1e=a("strong"),ffr=o("bart"),mfr=o(" \u2014 "),TW=a("a"),gfr=o("TFBartForConditionalGeneration"),hfr=o(" (BART model)"),pfr=l(),SM=a("li"),w1e=a("strong"),ufr=o("bert"),_fr=o(" \u2014 "),MW=a("a"),bfr=o("TFBertForPreTraining"),vfr=o(" (BERT model)"),Ffr=l(),RM=a("li"),A1e=a("strong"),Tfr=o("camembert"),Mfr=o(" \u2014 "),EW=a("a"),Efr=o("TFCamembertForMaskedLM"),Cfr=o(" (CamemBERT model)"),wfr=l(),PM=a("li"),y1e=a("strong"),Afr=o("ctrl"),yfr=o(" \u2014 "),CW=a("a"),Lfr=o("TFCTRLLMHeadModel"),xfr=o(" (CTRL model)"),$fr=l(),BM=a("li"),L1e=a("strong"),kfr=o("distilbert"),Sfr=o(" \u2014 "),wW=a("a"),Rfr=o("TFDistilBertForMaskedLM"),Pfr=o(" (DistilBERT model)"),Bfr=l(),IM=a("li"),x1e=a("strong"),Ifr=o("electra"),qfr=o(" \u2014 "),AW=a("a"),Nfr=o("TFElectraForPreTraining"),jfr=o(" (ELECTRA model)"),Dfr=l(),qM=a("li"),$1e=a("strong"),Gfr=o("flaubert"),Ofr=o(" \u2014 "),yW=a("a"),Vfr=o("TFFlaubertWithLMHeadModel"),Xfr=o(" (FlauBERT model)"),zfr=l(),NM=a("li"),k1e=a("strong"),Wfr=o("funnel"),Qfr=o(" \u2014 "),LW=a("a"),Hfr=o("TFFunnelForPreTraining"),Ufr=o(" (Funnel Transformer model)"),Jfr=l(),jM=a("li"),S1e=a("strong"),Yfr=o("gpt2"),Kfr=o(" \u2014 "),xW=a("a"),Zfr=o("TFGPT2LMHeadModel"),emr=o(" (OpenAI GPT-2 model)"),omr=l(),DM=a("li"),R1e=a("strong"),rmr=o("layoutlm"),tmr=o(" \u2014 "),$W=a("a"),amr=o("TFLayoutLMForMaskedLM"),nmr=o(" (LayoutLM model)"),smr=l(),GM=a("li"),P1e=a("strong"),lmr=o("lxmert"),imr=o(" \u2014 "),kW=a("a"),dmr=o("TFLxmertForPreTraining"),cmr=o(" (LXMERT model)"),fmr=l(),OM=a("li"),B1e=a("strong"),mmr=o("mobilebert"),gmr=o(" \u2014 "),SW=a("a"),hmr=o("TFMobileBertForPreTraining"),pmr=o(" (MobileBERT model)"),umr=l(),VM=a("li"),I1e=a("strong"),_mr=o("mpnet"),bmr=o(" \u2014 "),RW=a("a"),vmr=o("TFMPNetForMaskedLM"),Fmr=o(" (MPNet model)"),Tmr=l(),XM=a("li"),q1e=a("strong"),Mmr=o("openai-gpt"),Emr=o(" \u2014 "),PW=a("a"),Cmr=o("TFOpenAIGPTLMHeadModel"),wmr=o(" (OpenAI GPT model)"),Amr=l(),zM=a("li"),N1e=a("strong"),ymr=o("roberta"),Lmr=o(" \u2014 "),BW=a("a"),xmr=o("TFRobertaForMaskedLM"),$mr=o(" (RoBERTa model)"),kmr=l(),WM=a("li"),j1e=a("strong"),Smr=o("t5"),Rmr=o(" \u2014 "),IW=a("a"),Pmr=o("TFT5ForConditionalGeneration"),Bmr=o(" (T5 model)"),Imr=l(),QM=a("li"),D1e=a("strong"),qmr=o("tapas"),Nmr=o(" \u2014 "),qW=a("a"),jmr=o("TFTapasForMaskedLM"),Dmr=o(" (TAPAS model)"),Gmr=l(),HM=a("li"),G1e=a("strong"),Omr=o("transfo-xl"),Vmr=o(" \u2014 "),NW=a("a"),Xmr=o("TFTransfoXLLMHeadModel"),zmr=o(" (Transformer-XL model)"),Wmr=l(),UM=a("li"),O1e=a("strong"),Qmr=o("vit_mae"),Hmr=o(" \u2014 "),jW=a("a"),Umr=o("TFViTMAEForPreTraining"),Jmr=o(" (ViTMAE model)"),Ymr=l(),JM=a("li"),V1e=a("strong"),Kmr=o("xlm"),Zmr=o(" \u2014 "),DW=a("a"),egr=o("TFXLMWithLMHeadModel"),ogr=o(" (XLM model)"),rgr=l(),YM=a("li"),X1e=a("strong"),tgr=o("xlm-roberta"),agr=o(" \u2014 "),GW=a("a"),ngr=o("TFXLMRobertaForMaskedLM"),sgr=o(" (XLM-RoBERTa model)"),lgr=l(),KM=a("li"),z1e=a("strong"),igr=o("xlnet"),dgr=o(" \u2014 "),OW=a("a"),cgr=o("TFXLNetLMHeadModel"),fgr=o(" (XLNet model)"),mgr=l(),F(ZM.$$.fragment),Wqe=l(),Wd=a("h2"),e4=a("a"),W1e=a("span"),F(o8.$$.fragment),ggr=l(),Q1e=a("span"),hgr=o("TFAutoModelForCausalLM"),Qqe=l(),Zo=a("div"),F(r8.$$.fragment),pgr=l(),Qd=a("p"),ugr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),VW=a("a"),_gr=o("from_pretrained()"),bgr=o(" class method or the "),XW=a("a"),vgr=o("from_config()"),Fgr=o(` class
method.`),Tgr=l(),t8=a("p"),Mgr=o("This class cannot be instantiated directly using "),H1e=a("code"),Egr=o("__init__()"),Cgr=o(" (throws an error)."),wgr=l(),xt=a("div"),F(a8.$$.fragment),Agr=l(),U1e=a("p"),ygr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Lgr=l(),Hd=a("p"),xgr=o(`Note:
Loading a model from its configuration file does `),J1e=a("strong"),$gr=o("not"),kgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zW=a("a"),Sgr=o("from_pretrained()"),Rgr=o(" to load the model weights."),Pgr=l(),F(o4.$$.fragment),Bgr=l(),yr=a("div"),F(n8.$$.fragment),Igr=l(),Y1e=a("p"),qgr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Ngr=l(),en=a("p"),jgr=o("The model class to instantiate is selected based on the "),K1e=a("code"),Dgr=o("model_type"),Ggr=o(` property of the config object (either
passed as an argument or loaded from `),Z1e=a("code"),Ogr=o("pretrained_model_name_or_path"),Vgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=a("code"),Xgr=o("pretrained_model_name_or_path"),zgr=o(":"),Wgr=l(),Te=a("ul"),r4=a("li"),o7e=a("strong"),Qgr=o("bert"),Hgr=o(" \u2014 "),WW=a("a"),Ugr=o("TFBertLMHeadModel"),Jgr=o(" (BERT model)"),Ygr=l(),t4=a("li"),r7e=a("strong"),Kgr=o("camembert"),Zgr=o(" \u2014 "),QW=a("a"),ehr=o("TFCamembertForCausalLM"),ohr=o(" (CamemBERT model)"),rhr=l(),a4=a("li"),t7e=a("strong"),thr=o("ctrl"),ahr=o(" \u2014 "),HW=a("a"),nhr=o("TFCTRLLMHeadModel"),shr=o(" (CTRL model)"),lhr=l(),n4=a("li"),a7e=a("strong"),ihr=o("gpt2"),dhr=o(" \u2014 "),UW=a("a"),chr=o("TFGPT2LMHeadModel"),fhr=o(" (OpenAI GPT-2 model)"),mhr=l(),s4=a("li"),n7e=a("strong"),ghr=o("gptj"),hhr=o(" \u2014 "),JW=a("a"),phr=o("TFGPTJForCausalLM"),uhr=o(" (GPT-J model)"),_hr=l(),l4=a("li"),s7e=a("strong"),bhr=o("openai-gpt"),vhr=o(" \u2014 "),YW=a("a"),Fhr=o("TFOpenAIGPTLMHeadModel"),Thr=o(" (OpenAI GPT model)"),Mhr=l(),i4=a("li"),l7e=a("strong"),Ehr=o("rembert"),Chr=o(" \u2014 "),KW=a("a"),whr=o("TFRemBertForCausalLM"),Ahr=o(" (RemBERT model)"),yhr=l(),d4=a("li"),i7e=a("strong"),Lhr=o("roberta"),xhr=o(" \u2014 "),ZW=a("a"),$hr=o("TFRobertaForCausalLM"),khr=o(" (RoBERTa model)"),Shr=l(),c4=a("li"),d7e=a("strong"),Rhr=o("roformer"),Phr=o(" \u2014 "),eQ=a("a"),Bhr=o("TFRoFormerForCausalLM"),Ihr=o(" (RoFormer model)"),qhr=l(),f4=a("li"),c7e=a("strong"),Nhr=o("transfo-xl"),jhr=o(" \u2014 "),oQ=a("a"),Dhr=o("TFTransfoXLLMHeadModel"),Ghr=o(" (Transformer-XL model)"),Ohr=l(),m4=a("li"),f7e=a("strong"),Vhr=o("xlm"),Xhr=o(" \u2014 "),rQ=a("a"),zhr=o("TFXLMWithLMHeadModel"),Whr=o(" (XLM model)"),Qhr=l(),g4=a("li"),m7e=a("strong"),Hhr=o("xlnet"),Uhr=o(" \u2014 "),tQ=a("a"),Jhr=o("TFXLNetLMHeadModel"),Yhr=o(" (XLNet model)"),Khr=l(),F(h4.$$.fragment),Hqe=l(),Ud=a("h2"),p4=a("a"),g7e=a("span"),F(s8.$$.fragment),Zhr=l(),h7e=a("span"),epr=o("TFAutoModelForImageClassification"),Uqe=l(),er=a("div"),F(l8.$$.fragment),opr=l(),Jd=a("p"),rpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aQ=a("a"),tpr=o("from_pretrained()"),apr=o(" class method or the "),nQ=a("a"),npr=o("from_config()"),spr=o(` class
method.`),lpr=l(),i8=a("p"),ipr=o("This class cannot be instantiated directly using "),p7e=a("code"),dpr=o("__init__()"),cpr=o(" (throws an error)."),fpr=l(),$t=a("div"),F(d8.$$.fragment),mpr=l(),u7e=a("p"),gpr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),hpr=l(),Yd=a("p"),ppr=o(`Note:
Loading a model from its configuration file does `),_7e=a("strong"),upr=o("not"),_pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=a("a"),bpr=o("from_pretrained()"),vpr=o(" to load the model weights."),Fpr=l(),F(u4.$$.fragment),Tpr=l(),Lr=a("div"),F(c8.$$.fragment),Mpr=l(),b7e=a("p"),Epr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Cpr=l(),on=a("p"),wpr=o("The model class to instantiate is selected based on the "),v7e=a("code"),Apr=o("model_type"),ypr=o(` property of the config object (either
passed as an argument or loaded from `),F7e=a("code"),Lpr=o("pretrained_model_name_or_path"),xpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T7e=a("code"),$pr=o("pretrained_model_name_or_path"),kpr=o(":"),Spr=l(),rn=a("ul"),_4=a("li"),M7e=a("strong"),Rpr=o("convnext"),Ppr=o(" \u2014 "),lQ=a("a"),Bpr=o("TFConvNextForImageClassification"),Ipr=o(" (ConvNext model)"),qpr=l(),b4=a("li"),E7e=a("strong"),Npr=o("data2vec-vision"),jpr=o(" \u2014 "),iQ=a("a"),Dpr=o("TFData2VecVisionForImageClassification"),Gpr=o(" (Data2VecVision model)"),Opr=l(),v4=a("li"),C7e=a("strong"),Vpr=o("swin"),Xpr=o(" \u2014 "),dQ=a("a"),zpr=o("TFSwinForImageClassification"),Wpr=o(" (Swin model)"),Qpr=l(),F4=a("li"),w7e=a("strong"),Hpr=o("vit"),Upr=o(" \u2014 "),cQ=a("a"),Jpr=o("TFViTForImageClassification"),Ypr=o(" (ViT model)"),Kpr=l(),F(T4.$$.fragment),Jqe=l(),Kd=a("h2"),M4=a("a"),A7e=a("span"),F(f8.$$.fragment),Zpr=l(),y7e=a("span"),eur=o("TFAutoModelForMaskedLM"),Yqe=l(),or=a("div"),F(m8.$$.fragment),our=l(),Zd=a("p"),rur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),fQ=a("a"),tur=o("from_pretrained()"),aur=o(" class method or the "),mQ=a("a"),nur=o("from_config()"),sur=o(` class
method.`),lur=l(),g8=a("p"),iur=o("This class cannot be instantiated directly using "),L7e=a("code"),dur=o("__init__()"),cur=o(" (throws an error)."),fur=l(),kt=a("div"),F(h8.$$.fragment),mur=l(),x7e=a("p"),gur=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),hur=l(),ec=a("p"),pur=o(`Note:
Loading a model from its configuration file does `),$7e=a("strong"),uur=o("not"),_ur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=a("a"),bur=o("from_pretrained()"),vur=o(" to load the model weights."),Fur=l(),F(E4.$$.fragment),Tur=l(),xr=a("div"),F(p8.$$.fragment),Mur=l(),k7e=a("p"),Eur=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Cur=l(),tn=a("p"),wur=o("The model class to instantiate is selected based on the "),S7e=a("code"),Aur=o("model_type"),yur=o(` property of the config object (either
passed as an argument or loaded from `),R7e=a("code"),Lur=o("pretrained_model_name_or_path"),xur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P7e=a("code"),$ur=o("pretrained_model_name_or_path"),kur=o(":"),Sur=l(),ie=a("ul"),C4=a("li"),B7e=a("strong"),Rur=o("albert"),Pur=o(" \u2014 "),hQ=a("a"),Bur=o("TFAlbertForMaskedLM"),Iur=o(" (ALBERT model)"),qur=l(),w4=a("li"),I7e=a("strong"),Nur=o("bert"),jur=o(" \u2014 "),pQ=a("a"),Dur=o("TFBertForMaskedLM"),Gur=o(" (BERT model)"),Our=l(),A4=a("li"),q7e=a("strong"),Vur=o("camembert"),Xur=o(" \u2014 "),uQ=a("a"),zur=o("TFCamembertForMaskedLM"),Wur=o(" (CamemBERT model)"),Qur=l(),y4=a("li"),N7e=a("strong"),Hur=o("convbert"),Uur=o(" \u2014 "),_Q=a("a"),Jur=o("TFConvBertForMaskedLM"),Yur=o(" (ConvBERT model)"),Kur=l(),L4=a("li"),j7e=a("strong"),Zur=o("deberta"),e_r=o(" \u2014 "),bQ=a("a"),o_r=o("TFDebertaForMaskedLM"),r_r=o(" (DeBERTa model)"),t_r=l(),x4=a("li"),D7e=a("strong"),a_r=o("deberta-v2"),n_r=o(" \u2014 "),vQ=a("a"),s_r=o("TFDebertaV2ForMaskedLM"),l_r=o(" (DeBERTa-v2 model)"),i_r=l(),$4=a("li"),G7e=a("strong"),d_r=o("distilbert"),c_r=o(" \u2014 "),FQ=a("a"),f_r=o("TFDistilBertForMaskedLM"),m_r=o(" (DistilBERT model)"),g_r=l(),k4=a("li"),O7e=a("strong"),h_r=o("electra"),p_r=o(" \u2014 "),TQ=a("a"),u_r=o("TFElectraForMaskedLM"),__r=o(" (ELECTRA model)"),b_r=l(),S4=a("li"),V7e=a("strong"),v_r=o("flaubert"),F_r=o(" \u2014 "),MQ=a("a"),T_r=o("TFFlaubertWithLMHeadModel"),M_r=o(" (FlauBERT model)"),E_r=l(),R4=a("li"),X7e=a("strong"),C_r=o("funnel"),w_r=o(" \u2014 "),EQ=a("a"),A_r=o("TFFunnelForMaskedLM"),y_r=o(" (Funnel Transformer model)"),L_r=l(),P4=a("li"),z7e=a("strong"),x_r=o("layoutlm"),$_r=o(" \u2014 "),CQ=a("a"),k_r=o("TFLayoutLMForMaskedLM"),S_r=o(" (LayoutLM model)"),R_r=l(),B4=a("li"),W7e=a("strong"),P_r=o("longformer"),B_r=o(" \u2014 "),wQ=a("a"),I_r=o("TFLongformerForMaskedLM"),q_r=o(" (Longformer model)"),N_r=l(),I4=a("li"),Q7e=a("strong"),j_r=o("mobilebert"),D_r=o(" \u2014 "),AQ=a("a"),G_r=o("TFMobileBertForMaskedLM"),O_r=o(" (MobileBERT model)"),V_r=l(),q4=a("li"),H7e=a("strong"),X_r=o("mpnet"),z_r=o(" \u2014 "),yQ=a("a"),W_r=o("TFMPNetForMaskedLM"),Q_r=o(" (MPNet model)"),H_r=l(),N4=a("li"),U7e=a("strong"),U_r=o("rembert"),J_r=o(" \u2014 "),LQ=a("a"),Y_r=o("TFRemBertForMaskedLM"),K_r=o(" (RemBERT model)"),Z_r=l(),j4=a("li"),J7e=a("strong"),e2r=o("roberta"),o2r=o(" \u2014 "),xQ=a("a"),r2r=o("TFRobertaForMaskedLM"),t2r=o(" (RoBERTa model)"),a2r=l(),D4=a("li"),Y7e=a("strong"),n2r=o("roformer"),s2r=o(" \u2014 "),$Q=a("a"),l2r=o("TFRoFormerForMaskedLM"),i2r=o(" (RoFormer model)"),d2r=l(),G4=a("li"),K7e=a("strong"),c2r=o("tapas"),f2r=o(" \u2014 "),kQ=a("a"),m2r=o("TFTapasForMaskedLM"),g2r=o(" (TAPAS model)"),h2r=l(),O4=a("li"),Z7e=a("strong"),p2r=o("xlm"),u2r=o(" \u2014 "),SQ=a("a"),_2r=o("TFXLMWithLMHeadModel"),b2r=o(" (XLM model)"),v2r=l(),V4=a("li"),ebe=a("strong"),F2r=o("xlm-roberta"),T2r=o(" \u2014 "),RQ=a("a"),M2r=o("TFXLMRobertaForMaskedLM"),E2r=o(" (XLM-RoBERTa model)"),C2r=l(),F(X4.$$.fragment),Kqe=l(),oc=a("h2"),z4=a("a"),obe=a("span"),F(u8.$$.fragment),w2r=l(),rbe=a("span"),A2r=o("TFAutoModelForSeq2SeqLM"),Zqe=l(),rr=a("div"),F(_8.$$.fragment),y2r=l(),rc=a("p"),L2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),PQ=a("a"),x2r=o("from_pretrained()"),$2r=o(" class method or the "),BQ=a("a"),k2r=o("from_config()"),S2r=o(` class
method.`),R2r=l(),b8=a("p"),P2r=o("This class cannot be instantiated directly using "),tbe=a("code"),B2r=o("__init__()"),I2r=o(" (throws an error)."),q2r=l(),St=a("div"),F(v8.$$.fragment),N2r=l(),abe=a("p"),j2r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),D2r=l(),tc=a("p"),G2r=o(`Note:
Loading a model from its configuration file does `),nbe=a("strong"),O2r=o("not"),V2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),X2r=o("from_pretrained()"),z2r=o(" to load the model weights."),W2r=l(),F(W4.$$.fragment),Q2r=l(),$r=a("div"),F(F8.$$.fragment),H2r=l(),sbe=a("p"),U2r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),J2r=l(),an=a("p"),Y2r=o("The model class to instantiate is selected based on the "),lbe=a("code"),K2r=o("model_type"),Z2r=o(` property of the config object (either
passed as an argument or loaded from `),ibe=a("code"),e1r=o("pretrained_model_name_or_path"),o1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dbe=a("code"),r1r=o("pretrained_model_name_or_path"),t1r=o(":"),a1r=l(),ye=a("ul"),Q4=a("li"),cbe=a("strong"),n1r=o("bart"),s1r=o(" \u2014 "),qQ=a("a"),l1r=o("TFBartForConditionalGeneration"),i1r=o(" (BART model)"),d1r=l(),H4=a("li"),fbe=a("strong"),c1r=o("blenderbot"),f1r=o(" \u2014 "),NQ=a("a"),m1r=o("TFBlenderbotForConditionalGeneration"),g1r=o(" (Blenderbot model)"),h1r=l(),U4=a("li"),mbe=a("strong"),p1r=o("blenderbot-small"),u1r=o(" \u2014 "),jQ=a("a"),_1r=o("TFBlenderbotSmallForConditionalGeneration"),b1r=o(" (BlenderbotSmall model)"),v1r=l(),J4=a("li"),gbe=a("strong"),F1r=o("encoder-decoder"),T1r=o(" \u2014 "),DQ=a("a"),M1r=o("TFEncoderDecoderModel"),E1r=o(" (Encoder decoder model)"),C1r=l(),Y4=a("li"),hbe=a("strong"),w1r=o("led"),A1r=o(" \u2014 "),GQ=a("a"),y1r=o("TFLEDForConditionalGeneration"),L1r=o(" (LED model)"),x1r=l(),K4=a("li"),pbe=a("strong"),$1r=o("marian"),k1r=o(" \u2014 "),OQ=a("a"),S1r=o("TFMarianMTModel"),R1r=o(" (Marian model)"),P1r=l(),Z4=a("li"),ube=a("strong"),B1r=o("mbart"),I1r=o(" \u2014 "),VQ=a("a"),q1r=o("TFMBartForConditionalGeneration"),N1r=o(" (mBART model)"),j1r=l(),eE=a("li"),_be=a("strong"),D1r=o("mt5"),G1r=o(" \u2014 "),XQ=a("a"),O1r=o("TFMT5ForConditionalGeneration"),V1r=o(" (mT5 model)"),X1r=l(),oE=a("li"),bbe=a("strong"),z1r=o("pegasus"),W1r=o(" \u2014 "),zQ=a("a"),Q1r=o("TFPegasusForConditionalGeneration"),H1r=o(" (Pegasus model)"),U1r=l(),rE=a("li"),vbe=a("strong"),J1r=o("t5"),Y1r=o(" \u2014 "),WQ=a("a"),K1r=o("TFT5ForConditionalGeneration"),Z1r=o(" (T5 model)"),e7r=l(),F(tE.$$.fragment),eNe=l(),ac=a("h2"),aE=a("a"),Fbe=a("span"),F(T8.$$.fragment),o7r=l(),Tbe=a("span"),r7r=o("TFAutoModelForSequenceClassification"),oNe=l(),tr=a("div"),F(M8.$$.fragment),t7r=l(),nc=a("p"),a7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),QQ=a("a"),n7r=o("from_pretrained()"),s7r=o(" class method or the "),HQ=a("a"),l7r=o("from_config()"),i7r=o(` class
method.`),d7r=l(),E8=a("p"),c7r=o("This class cannot be instantiated directly using "),Mbe=a("code"),f7r=o("__init__()"),m7r=o(" (throws an error)."),g7r=l(),Rt=a("div"),F(C8.$$.fragment),h7r=l(),Ebe=a("p"),p7r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),u7r=l(),sc=a("p"),_7r=o(`Note:
Loading a model from its configuration file does `),Cbe=a("strong"),b7r=o("not"),v7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UQ=a("a"),F7r=o("from_pretrained()"),T7r=o(" to load the model weights."),M7r=l(),F(nE.$$.fragment),E7r=l(),kr=a("div"),F(w8.$$.fragment),C7r=l(),wbe=a("p"),w7r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),A7r=l(),nn=a("p"),y7r=o("The model class to instantiate is selected based on the "),Abe=a("code"),L7r=o("model_type"),x7r=o(` property of the config object (either
passed as an argument or loaded from `),ybe=a("code"),$7r=o("pretrained_model_name_or_path"),k7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lbe=a("code"),S7r=o("pretrained_model_name_or_path"),R7r=o(":"),P7r=l(),ee=a("ul"),sE=a("li"),xbe=a("strong"),B7r=o("albert"),I7r=o(" \u2014 "),JQ=a("a"),q7r=o("TFAlbertForSequenceClassification"),N7r=o(" (ALBERT model)"),j7r=l(),lE=a("li"),$be=a("strong"),D7r=o("bert"),G7r=o(" \u2014 "),YQ=a("a"),O7r=o("TFBertForSequenceClassification"),V7r=o(" (BERT model)"),X7r=l(),iE=a("li"),kbe=a("strong"),z7r=o("camembert"),W7r=o(" \u2014 "),KQ=a("a"),Q7r=o("TFCamembertForSequenceClassification"),H7r=o(" (CamemBERT model)"),U7r=l(),dE=a("li"),Sbe=a("strong"),J7r=o("convbert"),Y7r=o(" \u2014 "),ZQ=a("a"),K7r=o("TFConvBertForSequenceClassification"),Z7r=o(" (ConvBERT model)"),ebr=l(),cE=a("li"),Rbe=a("strong"),obr=o("ctrl"),rbr=o(" \u2014 "),eH=a("a"),tbr=o("TFCTRLForSequenceClassification"),abr=o(" (CTRL model)"),nbr=l(),fE=a("li"),Pbe=a("strong"),sbr=o("deberta"),lbr=o(" \u2014 "),oH=a("a"),ibr=o("TFDebertaForSequenceClassification"),dbr=o(" (DeBERTa model)"),cbr=l(),mE=a("li"),Bbe=a("strong"),fbr=o("deberta-v2"),mbr=o(" \u2014 "),rH=a("a"),gbr=o("TFDebertaV2ForSequenceClassification"),hbr=o(" (DeBERTa-v2 model)"),pbr=l(),gE=a("li"),Ibe=a("strong"),ubr=o("distilbert"),_br=o(" \u2014 "),tH=a("a"),bbr=o("TFDistilBertForSequenceClassification"),vbr=o(" (DistilBERT model)"),Fbr=l(),hE=a("li"),qbe=a("strong"),Tbr=o("electra"),Mbr=o(" \u2014 "),aH=a("a"),Ebr=o("TFElectraForSequenceClassification"),Cbr=o(" (ELECTRA model)"),wbr=l(),pE=a("li"),Nbe=a("strong"),Abr=o("flaubert"),ybr=o(" \u2014 "),nH=a("a"),Lbr=o("TFFlaubertForSequenceClassification"),xbr=o(" (FlauBERT model)"),$br=l(),uE=a("li"),jbe=a("strong"),kbr=o("funnel"),Sbr=o(" \u2014 "),sH=a("a"),Rbr=o("TFFunnelForSequenceClassification"),Pbr=o(" (Funnel Transformer model)"),Bbr=l(),_E=a("li"),Dbe=a("strong"),Ibr=o("gpt2"),qbr=o(" \u2014 "),lH=a("a"),Nbr=o("TFGPT2ForSequenceClassification"),jbr=o(" (OpenAI GPT-2 model)"),Dbr=l(),bE=a("li"),Gbe=a("strong"),Gbr=o("gptj"),Obr=o(" \u2014 "),iH=a("a"),Vbr=o("TFGPTJForSequenceClassification"),Xbr=o(" (GPT-J model)"),zbr=l(),vE=a("li"),Obe=a("strong"),Wbr=o("layoutlm"),Qbr=o(" \u2014 "),dH=a("a"),Hbr=o("TFLayoutLMForSequenceClassification"),Ubr=o(" (LayoutLM model)"),Jbr=l(),FE=a("li"),Vbe=a("strong"),Ybr=o("longformer"),Kbr=o(" \u2014 "),cH=a("a"),Zbr=o("TFLongformerForSequenceClassification"),evr=o(" (Longformer model)"),ovr=l(),TE=a("li"),Xbe=a("strong"),rvr=o("mobilebert"),tvr=o(" \u2014 "),fH=a("a"),avr=o("TFMobileBertForSequenceClassification"),nvr=o(" (MobileBERT model)"),svr=l(),ME=a("li"),zbe=a("strong"),lvr=o("mpnet"),ivr=o(" \u2014 "),mH=a("a"),dvr=o("TFMPNetForSequenceClassification"),cvr=o(" (MPNet model)"),fvr=l(),EE=a("li"),Wbe=a("strong"),mvr=o("openai-gpt"),gvr=o(" \u2014 "),gH=a("a"),hvr=o("TFOpenAIGPTForSequenceClassification"),pvr=o(" (OpenAI GPT model)"),uvr=l(),CE=a("li"),Qbe=a("strong"),_vr=o("rembert"),bvr=o(" \u2014 "),hH=a("a"),vvr=o("TFRemBertForSequenceClassification"),Fvr=o(" (RemBERT model)"),Tvr=l(),wE=a("li"),Hbe=a("strong"),Mvr=o("roberta"),Evr=o(" \u2014 "),pH=a("a"),Cvr=o("TFRobertaForSequenceClassification"),wvr=o(" (RoBERTa model)"),Avr=l(),AE=a("li"),Ube=a("strong"),yvr=o("roformer"),Lvr=o(" \u2014 "),uH=a("a"),xvr=o("TFRoFormerForSequenceClassification"),$vr=o(" (RoFormer model)"),kvr=l(),yE=a("li"),Jbe=a("strong"),Svr=o("tapas"),Rvr=o(" \u2014 "),_H=a("a"),Pvr=o("TFTapasForSequenceClassification"),Bvr=o(" (TAPAS model)"),Ivr=l(),LE=a("li"),Ybe=a("strong"),qvr=o("transfo-xl"),Nvr=o(" \u2014 "),bH=a("a"),jvr=o("TFTransfoXLForSequenceClassification"),Dvr=o(" (Transformer-XL model)"),Gvr=l(),xE=a("li"),Kbe=a("strong"),Ovr=o("xlm"),Vvr=o(" \u2014 "),vH=a("a"),Xvr=o("TFXLMForSequenceClassification"),zvr=o(" (XLM model)"),Wvr=l(),$E=a("li"),Zbe=a("strong"),Qvr=o("xlm-roberta"),Hvr=o(" \u2014 "),FH=a("a"),Uvr=o("TFXLMRobertaForSequenceClassification"),Jvr=o(" (XLM-RoBERTa model)"),Yvr=l(),kE=a("li"),eve=a("strong"),Kvr=o("xlnet"),Zvr=o(" \u2014 "),TH=a("a"),eFr=o("TFXLNetForSequenceClassification"),oFr=o(" (XLNet model)"),rFr=l(),F(SE.$$.fragment),rNe=l(),lc=a("h2"),RE=a("a"),ove=a("span"),F(A8.$$.fragment),tFr=l(),rve=a("span"),aFr=o("TFAutoModelForMultipleChoice"),tNe=l(),ar=a("div"),F(y8.$$.fragment),nFr=l(),ic=a("p"),sFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),MH=a("a"),lFr=o("from_pretrained()"),iFr=o(" class method or the "),EH=a("a"),dFr=o("from_config()"),cFr=o(` class
method.`),fFr=l(),L8=a("p"),mFr=o("This class cannot be instantiated directly using "),tve=a("code"),gFr=o("__init__()"),hFr=o(" (throws an error)."),pFr=l(),Pt=a("div"),F(x8.$$.fragment),uFr=l(),ave=a("p"),_Fr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),bFr=l(),dc=a("p"),vFr=o(`Note:
Loading a model from its configuration file does `),nve=a("strong"),FFr=o("not"),TFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CH=a("a"),MFr=o("from_pretrained()"),EFr=o(" to load the model weights."),CFr=l(),F(PE.$$.fragment),wFr=l(),Sr=a("div"),F($8.$$.fragment),AFr=l(),sve=a("p"),yFr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),LFr=l(),sn=a("p"),xFr=o("The model class to instantiate is selected based on the "),lve=a("code"),$Fr=o("model_type"),kFr=o(` property of the config object (either
passed as an argument or loaded from `),ive=a("code"),SFr=o("pretrained_model_name_or_path"),RFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dve=a("code"),PFr=o("pretrained_model_name_or_path"),BFr=o(":"),IFr=l(),he=a("ul"),BE=a("li"),cve=a("strong"),qFr=o("albert"),NFr=o(" \u2014 "),wH=a("a"),jFr=o("TFAlbertForMultipleChoice"),DFr=o(" (ALBERT model)"),GFr=l(),IE=a("li"),fve=a("strong"),OFr=o("bert"),VFr=o(" \u2014 "),AH=a("a"),XFr=o("TFBertForMultipleChoice"),zFr=o(" (BERT model)"),WFr=l(),qE=a("li"),mve=a("strong"),QFr=o("camembert"),HFr=o(" \u2014 "),yH=a("a"),UFr=o("TFCamembertForMultipleChoice"),JFr=o(" (CamemBERT model)"),YFr=l(),NE=a("li"),gve=a("strong"),KFr=o("convbert"),ZFr=o(" \u2014 "),LH=a("a"),eTr=o("TFConvBertForMultipleChoice"),oTr=o(" (ConvBERT model)"),rTr=l(),jE=a("li"),hve=a("strong"),tTr=o("distilbert"),aTr=o(" \u2014 "),xH=a("a"),nTr=o("TFDistilBertForMultipleChoice"),sTr=o(" (DistilBERT model)"),lTr=l(),DE=a("li"),pve=a("strong"),iTr=o("electra"),dTr=o(" \u2014 "),$H=a("a"),cTr=o("TFElectraForMultipleChoice"),fTr=o(" (ELECTRA model)"),mTr=l(),GE=a("li"),uve=a("strong"),gTr=o("flaubert"),hTr=o(" \u2014 "),kH=a("a"),pTr=o("TFFlaubertForMultipleChoice"),uTr=o(" (FlauBERT model)"),_Tr=l(),OE=a("li"),_ve=a("strong"),bTr=o("funnel"),vTr=o(" \u2014 "),SH=a("a"),FTr=o("TFFunnelForMultipleChoice"),TTr=o(" (Funnel Transformer model)"),MTr=l(),VE=a("li"),bve=a("strong"),ETr=o("longformer"),CTr=o(" \u2014 "),RH=a("a"),wTr=o("TFLongformerForMultipleChoice"),ATr=o(" (Longformer model)"),yTr=l(),XE=a("li"),vve=a("strong"),LTr=o("mobilebert"),xTr=o(" \u2014 "),PH=a("a"),$Tr=o("TFMobileBertForMultipleChoice"),kTr=o(" (MobileBERT model)"),STr=l(),zE=a("li"),Fve=a("strong"),RTr=o("mpnet"),PTr=o(" \u2014 "),BH=a("a"),BTr=o("TFMPNetForMultipleChoice"),ITr=o(" (MPNet model)"),qTr=l(),WE=a("li"),Tve=a("strong"),NTr=o("rembert"),jTr=o(" \u2014 "),IH=a("a"),DTr=o("TFRemBertForMultipleChoice"),GTr=o(" (RemBERT model)"),OTr=l(),QE=a("li"),Mve=a("strong"),VTr=o("roberta"),XTr=o(" \u2014 "),qH=a("a"),zTr=o("TFRobertaForMultipleChoice"),WTr=o(" (RoBERTa model)"),QTr=l(),HE=a("li"),Eve=a("strong"),HTr=o("roformer"),UTr=o(" \u2014 "),NH=a("a"),JTr=o("TFRoFormerForMultipleChoice"),YTr=o(" (RoFormer model)"),KTr=l(),UE=a("li"),Cve=a("strong"),ZTr=o("xlm"),eMr=o(" \u2014 "),jH=a("a"),oMr=o("TFXLMForMultipleChoice"),rMr=o(" (XLM model)"),tMr=l(),JE=a("li"),wve=a("strong"),aMr=o("xlm-roberta"),nMr=o(" \u2014 "),DH=a("a"),sMr=o("TFXLMRobertaForMultipleChoice"),lMr=o(" (XLM-RoBERTa model)"),iMr=l(),YE=a("li"),Ave=a("strong"),dMr=o("xlnet"),cMr=o(" \u2014 "),GH=a("a"),fMr=o("TFXLNetForMultipleChoice"),mMr=o(" (XLNet model)"),gMr=l(),F(KE.$$.fragment),aNe=l(),cc=a("h2"),ZE=a("a"),yve=a("span"),F(k8.$$.fragment),hMr=l(),Lve=a("span"),pMr=o("TFAutoModelForNextSentencePrediction"),nNe=l(),nr=a("div"),F(S8.$$.fragment),uMr=l(),fc=a("p"),_Mr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OH=a("a"),bMr=o("from_pretrained()"),vMr=o(" class method or the "),VH=a("a"),FMr=o("from_config()"),TMr=o(` class
method.`),MMr=l(),R8=a("p"),EMr=o("This class cannot be instantiated directly using "),xve=a("code"),CMr=o("__init__()"),wMr=o(" (throws an error)."),AMr=l(),Bt=a("div"),F(P8.$$.fragment),yMr=l(),$ve=a("p"),LMr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),xMr=l(),mc=a("p"),$Mr=o(`Note:
Loading a model from its configuration file does `),kve=a("strong"),kMr=o("not"),SMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=a("a"),RMr=o("from_pretrained()"),PMr=o(" to load the model weights."),BMr=l(),F(eC.$$.fragment),IMr=l(),Rr=a("div"),F(B8.$$.fragment),qMr=l(),Sve=a("p"),NMr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),jMr=l(),ln=a("p"),DMr=o("The model class to instantiate is selected based on the "),Rve=a("code"),GMr=o("model_type"),OMr=o(` property of the config object (either
passed as an argument or loaded from `),Pve=a("code"),VMr=o("pretrained_model_name_or_path"),XMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bve=a("code"),zMr=o("pretrained_model_name_or_path"),WMr=o(":"),QMr=l(),I8=a("ul"),oC=a("li"),Ive=a("strong"),HMr=o("bert"),UMr=o(" \u2014 "),zH=a("a"),JMr=o("TFBertForNextSentencePrediction"),YMr=o(" (BERT model)"),KMr=l(),rC=a("li"),qve=a("strong"),ZMr=o("mobilebert"),e4r=o(" \u2014 "),WH=a("a"),o4r=o("TFMobileBertForNextSentencePrediction"),r4r=o(" (MobileBERT model)"),t4r=l(),F(tC.$$.fragment),sNe=l(),gc=a("h2"),aC=a("a"),Nve=a("span"),F(q8.$$.fragment),a4r=l(),jve=a("span"),n4r=o("TFAutoModelForTableQuestionAnswering"),lNe=l(),sr=a("div"),F(N8.$$.fragment),s4r=l(),hc=a("p"),l4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),QH=a("a"),i4r=o("from_pretrained()"),d4r=o(" class method or the "),HH=a("a"),c4r=o("from_config()"),f4r=o(` class
method.`),m4r=l(),j8=a("p"),g4r=o("This class cannot be instantiated directly using "),Dve=a("code"),h4r=o("__init__()"),p4r=o(" (throws an error)."),u4r=l(),It=a("div"),F(D8.$$.fragment),_4r=l(),Gve=a("p"),b4r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),v4r=l(),pc=a("p"),F4r=o(`Note:
Loading a model from its configuration file does `),Ove=a("strong"),T4r=o("not"),M4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UH=a("a"),E4r=o("from_pretrained()"),C4r=o(" to load the model weights."),w4r=l(),F(nC.$$.fragment),A4r=l(),Pr=a("div"),F(G8.$$.fragment),y4r=l(),Vve=a("p"),L4r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),x4r=l(),dn=a("p"),$4r=o("The model class to instantiate is selected based on the "),Xve=a("code"),k4r=o("model_type"),S4r=o(` property of the config object (either
passed as an argument or loaded from `),zve=a("code"),R4r=o("pretrained_model_name_or_path"),P4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=a("code"),B4r=o("pretrained_model_name_or_path"),I4r=o(":"),q4r=l(),Qve=a("ul"),sC=a("li"),Hve=a("strong"),N4r=o("tapas"),j4r=o(" \u2014 "),JH=a("a"),D4r=o("TFTapasForQuestionAnswering"),G4r=o(" (TAPAS model)"),O4r=l(),F(lC.$$.fragment),iNe=l(),uc=a("h2"),iC=a("a"),Uve=a("span"),F(O8.$$.fragment),V4r=l(),Jve=a("span"),X4r=o("TFAutoModelForTokenClassification"),dNe=l(),lr=a("div"),F(V8.$$.fragment),z4r=l(),_c=a("p"),W4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YH=a("a"),Q4r=o("from_pretrained()"),H4r=o(" class method or the "),KH=a("a"),U4r=o("from_config()"),J4r=o(` class
method.`),Y4r=l(),X8=a("p"),K4r=o("This class cannot be instantiated directly using "),Yve=a("code"),Z4r=o("__init__()"),eEr=o(" (throws an error)."),oEr=l(),qt=a("div"),F(z8.$$.fragment),rEr=l(),Kve=a("p"),tEr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),aEr=l(),bc=a("p"),nEr=o(`Note:
Loading a model from its configuration file does `),Zve=a("strong"),sEr=o("not"),lEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=a("a"),iEr=o("from_pretrained()"),dEr=o(" to load the model weights."),cEr=l(),F(dC.$$.fragment),fEr=l(),Br=a("div"),F(W8.$$.fragment),mEr=l(),eFe=a("p"),gEr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),hEr=l(),cn=a("p"),pEr=o("The model class to instantiate is selected based on the "),oFe=a("code"),uEr=o("model_type"),_Er=o(` property of the config object (either
passed as an argument or loaded from `),rFe=a("code"),bEr=o("pretrained_model_name_or_path"),vEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tFe=a("code"),FEr=o("pretrained_model_name_or_path"),TEr=o(":"),MEr=l(),de=a("ul"),cC=a("li"),aFe=a("strong"),EEr=o("albert"),CEr=o(" \u2014 "),eU=a("a"),wEr=o("TFAlbertForTokenClassification"),AEr=o(" (ALBERT model)"),yEr=l(),fC=a("li"),nFe=a("strong"),LEr=o("bert"),xEr=o(" \u2014 "),oU=a("a"),$Er=o("TFBertForTokenClassification"),kEr=o(" (BERT model)"),SEr=l(),mC=a("li"),sFe=a("strong"),REr=o("camembert"),PEr=o(" \u2014 "),rU=a("a"),BEr=o("TFCamembertForTokenClassification"),IEr=o(" (CamemBERT model)"),qEr=l(),gC=a("li"),lFe=a("strong"),NEr=o("convbert"),jEr=o(" \u2014 "),tU=a("a"),DEr=o("TFConvBertForTokenClassification"),GEr=o(" (ConvBERT model)"),OEr=l(),hC=a("li"),iFe=a("strong"),VEr=o("deberta"),XEr=o(" \u2014 "),aU=a("a"),zEr=o("TFDebertaForTokenClassification"),WEr=o(" (DeBERTa model)"),QEr=l(),pC=a("li"),dFe=a("strong"),HEr=o("deberta-v2"),UEr=o(" \u2014 "),nU=a("a"),JEr=o("TFDebertaV2ForTokenClassification"),YEr=o(" (DeBERTa-v2 model)"),KEr=l(),uC=a("li"),cFe=a("strong"),ZEr=o("distilbert"),eCr=o(" \u2014 "),sU=a("a"),oCr=o("TFDistilBertForTokenClassification"),rCr=o(" (DistilBERT model)"),tCr=l(),_C=a("li"),fFe=a("strong"),aCr=o("electra"),nCr=o(" \u2014 "),lU=a("a"),sCr=o("TFElectraForTokenClassification"),lCr=o(" (ELECTRA model)"),iCr=l(),bC=a("li"),mFe=a("strong"),dCr=o("flaubert"),cCr=o(" \u2014 "),iU=a("a"),fCr=o("TFFlaubertForTokenClassification"),mCr=o(" (FlauBERT model)"),gCr=l(),vC=a("li"),gFe=a("strong"),hCr=o("funnel"),pCr=o(" \u2014 "),dU=a("a"),uCr=o("TFFunnelForTokenClassification"),_Cr=o(" (Funnel Transformer model)"),bCr=l(),FC=a("li"),hFe=a("strong"),vCr=o("layoutlm"),FCr=o(" \u2014 "),cU=a("a"),TCr=o("TFLayoutLMForTokenClassification"),MCr=o(" (LayoutLM model)"),ECr=l(),TC=a("li"),pFe=a("strong"),CCr=o("longformer"),wCr=o(" \u2014 "),fU=a("a"),ACr=o("TFLongformerForTokenClassification"),yCr=o(" (Longformer model)"),LCr=l(),MC=a("li"),uFe=a("strong"),xCr=o("mobilebert"),$Cr=o(" \u2014 "),mU=a("a"),kCr=o("TFMobileBertForTokenClassification"),SCr=o(" (MobileBERT model)"),RCr=l(),EC=a("li"),_Fe=a("strong"),PCr=o("mpnet"),BCr=o(" \u2014 "),gU=a("a"),ICr=o("TFMPNetForTokenClassification"),qCr=o(" (MPNet model)"),NCr=l(),CC=a("li"),bFe=a("strong"),jCr=o("rembert"),DCr=o(" \u2014 "),hU=a("a"),GCr=o("TFRemBertForTokenClassification"),OCr=o(" (RemBERT model)"),VCr=l(),wC=a("li"),vFe=a("strong"),XCr=o("roberta"),zCr=o(" \u2014 "),pU=a("a"),WCr=o("TFRobertaForTokenClassification"),QCr=o(" (RoBERTa model)"),HCr=l(),AC=a("li"),FFe=a("strong"),UCr=o("roformer"),JCr=o(" \u2014 "),uU=a("a"),YCr=o("TFRoFormerForTokenClassification"),KCr=o(" (RoFormer model)"),ZCr=l(),yC=a("li"),TFe=a("strong"),e5r=o("xlm"),o5r=o(" \u2014 "),_U=a("a"),r5r=o("TFXLMForTokenClassification"),t5r=o(" (XLM model)"),a5r=l(),LC=a("li"),MFe=a("strong"),n5r=o("xlm-roberta"),s5r=o(" \u2014 "),bU=a("a"),l5r=o("TFXLMRobertaForTokenClassification"),i5r=o(" (XLM-RoBERTa model)"),d5r=l(),xC=a("li"),EFe=a("strong"),c5r=o("xlnet"),f5r=o(" \u2014 "),vU=a("a"),m5r=o("TFXLNetForTokenClassification"),g5r=o(" (XLNet model)"),h5r=l(),F($C.$$.fragment),cNe=l(),vc=a("h2"),kC=a("a"),CFe=a("span"),F(Q8.$$.fragment),p5r=l(),wFe=a("span"),u5r=o("TFAutoModelForQuestionAnswering"),fNe=l(),ir=a("div"),F(H8.$$.fragment),_5r=l(),Fc=a("p"),b5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),FU=a("a"),v5r=o("from_pretrained()"),F5r=o(" class method or the "),TU=a("a"),T5r=o("from_config()"),M5r=o(` class
method.`),E5r=l(),U8=a("p"),C5r=o("This class cannot be instantiated directly using "),AFe=a("code"),w5r=o("__init__()"),A5r=o(" (throws an error)."),y5r=l(),Nt=a("div"),F(J8.$$.fragment),L5r=l(),yFe=a("p"),x5r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),$5r=l(),Tc=a("p"),k5r=o(`Note:
Loading a model from its configuration file does `),LFe=a("strong"),S5r=o("not"),R5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=a("a"),P5r=o("from_pretrained()"),B5r=o(" to load the model weights."),I5r=l(),F(SC.$$.fragment),q5r=l(),Ir=a("div"),F(Y8.$$.fragment),N5r=l(),xFe=a("p"),j5r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),D5r=l(),fn=a("p"),G5r=o("The model class to instantiate is selected based on the "),$Fe=a("code"),O5r=o("model_type"),V5r=o(` property of the config object (either
passed as an argument or loaded from `),kFe=a("code"),X5r=o("pretrained_model_name_or_path"),z5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=a("code"),W5r=o("pretrained_model_name_or_path"),Q5r=o(":"),H5r=l(),ce=a("ul"),RC=a("li"),RFe=a("strong"),U5r=o("albert"),J5r=o(" \u2014 "),EU=a("a"),Y5r=o("TFAlbertForQuestionAnswering"),K5r=o(" (ALBERT model)"),Z5r=l(),PC=a("li"),PFe=a("strong"),e3r=o("bert"),o3r=o(" \u2014 "),CU=a("a"),r3r=o("TFBertForQuestionAnswering"),t3r=o(" (BERT model)"),a3r=l(),BC=a("li"),BFe=a("strong"),n3r=o("camembert"),s3r=o(" \u2014 "),wU=a("a"),l3r=o("TFCamembertForQuestionAnswering"),i3r=o(" (CamemBERT model)"),d3r=l(),IC=a("li"),IFe=a("strong"),c3r=o("convbert"),f3r=o(" \u2014 "),AU=a("a"),m3r=o("TFConvBertForQuestionAnswering"),g3r=o(" (ConvBERT model)"),h3r=l(),qC=a("li"),qFe=a("strong"),p3r=o("deberta"),u3r=o(" \u2014 "),yU=a("a"),_3r=o("TFDebertaForQuestionAnswering"),b3r=o(" (DeBERTa model)"),v3r=l(),NC=a("li"),NFe=a("strong"),F3r=o("deberta-v2"),T3r=o(" \u2014 "),LU=a("a"),M3r=o("TFDebertaV2ForQuestionAnswering"),E3r=o(" (DeBERTa-v2 model)"),C3r=l(),jC=a("li"),jFe=a("strong"),w3r=o("distilbert"),A3r=o(" \u2014 "),xU=a("a"),y3r=o("TFDistilBertForQuestionAnswering"),L3r=o(" (DistilBERT model)"),x3r=l(),DC=a("li"),DFe=a("strong"),$3r=o("electra"),k3r=o(" \u2014 "),$U=a("a"),S3r=o("TFElectraForQuestionAnswering"),R3r=o(" (ELECTRA model)"),P3r=l(),GC=a("li"),GFe=a("strong"),B3r=o("flaubert"),I3r=o(" \u2014 "),kU=a("a"),q3r=o("TFFlaubertForQuestionAnsweringSimple"),N3r=o(" (FlauBERT model)"),j3r=l(),OC=a("li"),OFe=a("strong"),D3r=o("funnel"),G3r=o(" \u2014 "),SU=a("a"),O3r=o("TFFunnelForQuestionAnswering"),V3r=o(" (Funnel Transformer model)"),X3r=l(),VC=a("li"),VFe=a("strong"),z3r=o("gptj"),W3r=o(" \u2014 "),RU=a("a"),Q3r=o("TFGPTJForQuestionAnswering"),H3r=o(" (GPT-J model)"),U3r=l(),XC=a("li"),XFe=a("strong"),J3r=o("longformer"),Y3r=o(" \u2014 "),PU=a("a"),K3r=o("TFLongformerForQuestionAnswering"),Z3r=o(" (Longformer model)"),ewr=l(),zC=a("li"),zFe=a("strong"),owr=o("mobilebert"),rwr=o(" \u2014 "),BU=a("a"),twr=o("TFMobileBertForQuestionAnswering"),awr=o(" (MobileBERT model)"),nwr=l(),WC=a("li"),WFe=a("strong"),swr=o("mpnet"),lwr=o(" \u2014 "),IU=a("a"),iwr=o("TFMPNetForQuestionAnswering"),dwr=o(" (MPNet model)"),cwr=l(),QC=a("li"),QFe=a("strong"),fwr=o("rembert"),mwr=o(" \u2014 "),qU=a("a"),gwr=o("TFRemBertForQuestionAnswering"),hwr=o(" (RemBERT model)"),pwr=l(),HC=a("li"),HFe=a("strong"),uwr=o("roberta"),_wr=o(" \u2014 "),NU=a("a"),bwr=o("TFRobertaForQuestionAnswering"),vwr=o(" (RoBERTa model)"),Fwr=l(),UC=a("li"),UFe=a("strong"),Twr=o("roformer"),Mwr=o(" \u2014 "),jU=a("a"),Ewr=o("TFRoFormerForQuestionAnswering"),Cwr=o(" (RoFormer model)"),wwr=l(),JC=a("li"),JFe=a("strong"),Awr=o("xlm"),ywr=o(" \u2014 "),DU=a("a"),Lwr=o("TFXLMForQuestionAnsweringSimple"),xwr=o(" (XLM model)"),$wr=l(),YC=a("li"),YFe=a("strong"),kwr=o("xlm-roberta"),Swr=o(" \u2014 "),GU=a("a"),Rwr=o("TFXLMRobertaForQuestionAnswering"),Pwr=o(" (XLM-RoBERTa model)"),Bwr=l(),KC=a("li"),KFe=a("strong"),Iwr=o("xlnet"),qwr=o(" \u2014 "),OU=a("a"),Nwr=o("TFXLNetForQuestionAnsweringSimple"),jwr=o(" (XLNet model)"),Dwr=l(),F(ZC.$$.fragment),mNe=l(),Mc=a("h2"),e5=a("a"),ZFe=a("span"),F(K8.$$.fragment),Gwr=l(),eTe=a("span"),Owr=o("TFAutoModelForVision2Seq"),gNe=l(),dr=a("div"),F(Z8.$$.fragment),Vwr=l(),Ec=a("p"),Xwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),VU=a("a"),zwr=o("from_pretrained()"),Wwr=o(" class method or the "),XU=a("a"),Qwr=o("from_config()"),Hwr=o(` class
method.`),Uwr=l(),ex=a("p"),Jwr=o("This class cannot be instantiated directly using "),oTe=a("code"),Ywr=o("__init__()"),Kwr=o(" (throws an error)."),Zwr=l(),jt=a("div"),F(ox.$$.fragment),eAr=l(),rTe=a("p"),oAr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),rAr=l(),Cc=a("p"),tAr=o(`Note:
Loading a model from its configuration file does `),tTe=a("strong"),aAr=o("not"),nAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zU=a("a"),sAr=o("from_pretrained()"),lAr=o(" to load the model weights."),iAr=l(),F(o5.$$.fragment),dAr=l(),qr=a("div"),F(rx.$$.fragment),cAr=l(),aTe=a("p"),fAr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mAr=l(),mn=a("p"),gAr=o("The model class to instantiate is selected based on the "),nTe=a("code"),hAr=o("model_type"),pAr=o(` property of the config object (either
passed as an argument or loaded from `),sTe=a("code"),uAr=o("pretrained_model_name_or_path"),_Ar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lTe=a("code"),bAr=o("pretrained_model_name_or_path"),vAr=o(":"),FAr=l(),iTe=a("ul"),r5=a("li"),dTe=a("strong"),TAr=o("vision-encoder-decoder"),MAr=o(" \u2014 "),WU=a("a"),EAr=o("TFVisionEncoderDecoderModel"),CAr=o(" (Vision Encoder decoder model)"),wAr=l(),F(t5.$$.fragment),hNe=l(),wc=a("h2"),a5=a("a"),cTe=a("span"),F(tx.$$.fragment),AAr=l(),fTe=a("span"),yAr=o("TFAutoModelForSpeechSeq2Seq"),pNe=l(),cr=a("div"),F(ax.$$.fragment),LAr=l(),Ac=a("p"),xAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),QU=a("a"),$Ar=o("from_pretrained()"),kAr=o(" class method or the "),HU=a("a"),SAr=o("from_config()"),RAr=o(` class
method.`),PAr=l(),nx=a("p"),BAr=o("This class cannot be instantiated directly using "),mTe=a("code"),IAr=o("__init__()"),qAr=o(" (throws an error)."),NAr=l(),Dt=a("div"),F(sx.$$.fragment),jAr=l(),gTe=a("p"),DAr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),GAr=l(),yc=a("p"),OAr=o(`Note:
Loading a model from its configuration file does `),hTe=a("strong"),VAr=o("not"),XAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UU=a("a"),zAr=o("from_pretrained()"),WAr=o(" to load the model weights."),QAr=l(),F(n5.$$.fragment),HAr=l(),Nr=a("div"),F(lx.$$.fragment),UAr=l(),pTe=a("p"),JAr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),YAr=l(),gn=a("p"),KAr=o("The model class to instantiate is selected based on the "),uTe=a("code"),ZAr=o("model_type"),e0r=o(` property of the config object (either
passed as an argument or loaded from `),_Te=a("code"),o0r=o("pretrained_model_name_or_path"),r0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bTe=a("code"),t0r=o("pretrained_model_name_or_path"),a0r=o(":"),n0r=l(),vTe=a("ul"),s5=a("li"),FTe=a("strong"),s0r=o("speech_to_text"),l0r=o(" \u2014 "),JU=a("a"),i0r=o("TFSpeech2TextForConditionalGeneration"),d0r=o(" (Speech2Text model)"),c0r=l(),F(l5.$$.fragment),uNe=l(),Lc=a("h2"),i5=a("a"),TTe=a("span"),F(ix.$$.fragment),f0r=l(),MTe=a("span"),m0r=o("FlaxAutoModel"),_Ne=l(),fr=a("div"),F(dx.$$.fragment),g0r=l(),xc=a("p"),h0r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),YU=a("a"),p0r=o("from_pretrained()"),u0r=o(" class method or the "),KU=a("a"),_0r=o("from_config()"),b0r=o(` class
method.`),v0r=l(),cx=a("p"),F0r=o("This class cannot be instantiated directly using "),ETe=a("code"),T0r=o("__init__()"),M0r=o(" (throws an error)."),E0r=l(),Gt=a("div"),F(fx.$$.fragment),C0r=l(),CTe=a("p"),w0r=o("Instantiates one of the base model classes of the library from a configuration."),A0r=l(),$c=a("p"),y0r=o(`Note:
Loading a model from its configuration file does `),wTe=a("strong"),L0r=o("not"),x0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZU=a("a"),$0r=o("from_pretrained()"),k0r=o(" to load the model weights."),S0r=l(),F(d5.$$.fragment),R0r=l(),jr=a("div"),F(mx.$$.fragment),P0r=l(),ATe=a("p"),B0r=o("Instantiate one of the base model classes of the library from a pretrained model."),I0r=l(),hn=a("p"),q0r=o("The model class to instantiate is selected based on the "),yTe=a("code"),N0r=o("model_type"),j0r=o(` property of the config object (either
passed as an argument or loaded from `),LTe=a("code"),D0r=o("pretrained_model_name_or_path"),G0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xTe=a("code"),O0r=o("pretrained_model_name_or_path"),V0r=o(":"),X0r=l(),oe=a("ul"),c5=a("li"),$Te=a("strong"),z0r=o("albert"),W0r=o(" \u2014 "),eJ=a("a"),Q0r=o("FlaxAlbertModel"),H0r=o(" (ALBERT model)"),U0r=l(),f5=a("li"),kTe=a("strong"),J0r=o("bart"),Y0r=o(" \u2014 "),oJ=a("a"),K0r=o("FlaxBartModel"),Z0r=o(" (BART model)"),e6r=l(),m5=a("li"),STe=a("strong"),o6r=o("beit"),r6r=o(" \u2014 "),rJ=a("a"),t6r=o("FlaxBeitModel"),a6r=o(" (BEiT model)"),n6r=l(),g5=a("li"),RTe=a("strong"),s6r=o("bert"),l6r=o(" \u2014 "),tJ=a("a"),i6r=o("FlaxBertModel"),d6r=o(" (BERT model)"),c6r=l(),h5=a("li"),PTe=a("strong"),f6r=o("big_bird"),m6r=o(" \u2014 "),aJ=a("a"),g6r=o("FlaxBigBirdModel"),h6r=o(" (BigBird model)"),p6r=l(),p5=a("li"),BTe=a("strong"),u6r=o("blenderbot"),_6r=o(" \u2014 "),nJ=a("a"),b6r=o("FlaxBlenderbotModel"),v6r=o(" (Blenderbot model)"),F6r=l(),u5=a("li"),ITe=a("strong"),T6r=o("blenderbot-small"),M6r=o(" \u2014 "),sJ=a("a"),E6r=o("FlaxBlenderbotSmallModel"),C6r=o(" (BlenderbotSmall model)"),w6r=l(),_5=a("li"),qTe=a("strong"),A6r=o("clip"),y6r=o(" \u2014 "),lJ=a("a"),L6r=o("FlaxCLIPModel"),x6r=o(" (CLIP model)"),$6r=l(),b5=a("li"),NTe=a("strong"),k6r=o("distilbert"),S6r=o(" \u2014 "),iJ=a("a"),R6r=o("FlaxDistilBertModel"),P6r=o(" (DistilBERT model)"),B6r=l(),v5=a("li"),jTe=a("strong"),I6r=o("electra"),q6r=o(" \u2014 "),dJ=a("a"),N6r=o("FlaxElectraModel"),j6r=o(" (ELECTRA model)"),D6r=l(),F5=a("li"),DTe=a("strong"),G6r=o("gpt2"),O6r=o(" \u2014 "),cJ=a("a"),V6r=o("FlaxGPT2Model"),X6r=o(" (OpenAI GPT-2 model)"),z6r=l(),T5=a("li"),GTe=a("strong"),W6r=o("gpt_neo"),Q6r=o(" \u2014 "),fJ=a("a"),H6r=o("FlaxGPTNeoModel"),U6r=o(" (GPT Neo model)"),J6r=l(),M5=a("li"),OTe=a("strong"),Y6r=o("gptj"),K6r=o(" \u2014 "),mJ=a("a"),Z6r=o("FlaxGPTJModel"),eyr=o(" (GPT-J model)"),oyr=l(),E5=a("li"),VTe=a("strong"),ryr=o("marian"),tyr=o(" \u2014 "),gJ=a("a"),ayr=o("FlaxMarianModel"),nyr=o(" (Marian model)"),syr=l(),C5=a("li"),XTe=a("strong"),lyr=o("mbart"),iyr=o(" \u2014 "),hJ=a("a"),dyr=o("FlaxMBartModel"),cyr=o(" (mBART model)"),fyr=l(),w5=a("li"),zTe=a("strong"),myr=o("mt5"),gyr=o(" \u2014 "),pJ=a("a"),hyr=o("FlaxMT5Model"),pyr=o(" (mT5 model)"),uyr=l(),A5=a("li"),WTe=a("strong"),_yr=o("opt"),byr=o(" \u2014 "),uJ=a("a"),vyr=o("FlaxOPTModel"),Fyr=o(" (OPT model)"),Tyr=l(),y5=a("li"),QTe=a("strong"),Myr=o("pegasus"),Eyr=o(" \u2014 "),_J=a("a"),Cyr=o("FlaxPegasusModel"),wyr=o(" (Pegasus model)"),Ayr=l(),L5=a("li"),HTe=a("strong"),yyr=o("roberta"),Lyr=o(" \u2014 "),bJ=a("a"),xyr=o("FlaxRobertaModel"),$yr=o(" (RoBERTa model)"),kyr=l(),x5=a("li"),UTe=a("strong"),Syr=o("roformer"),Ryr=o(" \u2014 "),vJ=a("a"),Pyr=o("FlaxRoFormerModel"),Byr=o(" (RoFormer model)"),Iyr=l(),$5=a("li"),JTe=a("strong"),qyr=o("t5"),Nyr=o(" \u2014 "),FJ=a("a"),jyr=o("FlaxT5Model"),Dyr=o(" (T5 model)"),Gyr=l(),k5=a("li"),YTe=a("strong"),Oyr=o("vision-text-dual-encoder"),Vyr=o(" \u2014 "),TJ=a("a"),Xyr=o("FlaxVisionTextDualEncoderModel"),zyr=o(" (VisionTextDualEncoder model)"),Wyr=l(),S5=a("li"),KTe=a("strong"),Qyr=o("vit"),Hyr=o(" \u2014 "),MJ=a("a"),Uyr=o("FlaxViTModel"),Jyr=o(" (ViT model)"),Yyr=l(),R5=a("li"),ZTe=a("strong"),Kyr=o("wav2vec2"),Zyr=o(" \u2014 "),EJ=a("a"),eLr=o("FlaxWav2Vec2Model"),oLr=o(" (Wav2Vec2 model)"),rLr=l(),P5=a("li"),eMe=a("strong"),tLr=o("xglm"),aLr=o(" \u2014 "),CJ=a("a"),nLr=o("FlaxXGLMModel"),sLr=o(" (XGLM model)"),lLr=l(),B5=a("li"),oMe=a("strong"),iLr=o("xlm-roberta"),dLr=o(" \u2014 "),wJ=a("a"),cLr=o("FlaxXLMRobertaModel"),fLr=o(" (XLM-RoBERTa model)"),mLr=l(),F(I5.$$.fragment),bNe=l(),kc=a("h2"),q5=a("a"),rMe=a("span"),F(gx.$$.fragment),gLr=l(),tMe=a("span"),hLr=o("FlaxAutoModelForCausalLM"),vNe=l(),mr=a("div"),F(hx.$$.fragment),pLr=l(),Sc=a("p"),uLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),AJ=a("a"),_Lr=o("from_pretrained()"),bLr=o(" class method or the "),yJ=a("a"),vLr=o("from_config()"),FLr=o(` class
method.`),TLr=l(),px=a("p"),MLr=o("This class cannot be instantiated directly using "),aMe=a("code"),ELr=o("__init__()"),CLr=o(" (throws an error)."),wLr=l(),Ot=a("div"),F(ux.$$.fragment),ALr=l(),nMe=a("p"),yLr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),LLr=l(),Rc=a("p"),xLr=o(`Note:
Loading a model from its configuration file does `),sMe=a("strong"),$Lr=o("not"),kLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LJ=a("a"),SLr=o("from_pretrained()"),RLr=o(" to load the model weights."),PLr=l(),F(N5.$$.fragment),BLr=l(),Dr=a("div"),F(_x.$$.fragment),ILr=l(),lMe=a("p"),qLr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),NLr=l(),pn=a("p"),jLr=o("The model class to instantiate is selected based on the "),iMe=a("code"),DLr=o("model_type"),GLr=o(` property of the config object (either
passed as an argument or loaded from `),dMe=a("code"),OLr=o("pretrained_model_name_or_path"),VLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cMe=a("code"),XLr=o("pretrained_model_name_or_path"),zLr=o(":"),WLr=l(),Le=a("ul"),j5=a("li"),fMe=a("strong"),QLr=o("bart"),HLr=o(" \u2014 "),xJ=a("a"),ULr=o("FlaxBartForCausalLM"),JLr=o(" (BART model)"),YLr=l(),D5=a("li"),mMe=a("strong"),KLr=o("bert"),ZLr=o(" \u2014 "),$J=a("a"),e8r=o("FlaxBertForCausalLM"),o8r=o(" (BERT model)"),r8r=l(),G5=a("li"),gMe=a("strong"),t8r=o("big_bird"),a8r=o(" \u2014 "),kJ=a("a"),n8r=o("FlaxBigBirdForCausalLM"),s8r=o(" (BigBird model)"),l8r=l(),O5=a("li"),hMe=a("strong"),i8r=o("electra"),d8r=o(" \u2014 "),SJ=a("a"),c8r=o("FlaxElectraForCausalLM"),f8r=o(" (ELECTRA model)"),m8r=l(),V5=a("li"),pMe=a("strong"),g8r=o("gpt2"),h8r=o(" \u2014 "),RJ=a("a"),p8r=o("FlaxGPT2LMHeadModel"),u8r=o(" (OpenAI GPT-2 model)"),_8r=l(),X5=a("li"),uMe=a("strong"),b8r=o("gpt_neo"),v8r=o(" \u2014 "),PJ=a("a"),F8r=o("FlaxGPTNeoForCausalLM"),T8r=o(" (GPT Neo model)"),M8r=l(),z5=a("li"),_Me=a("strong"),E8r=o("gptj"),C8r=o(" \u2014 "),BJ=a("a"),w8r=o("FlaxGPTJForCausalLM"),A8r=o(" (GPT-J model)"),y8r=l(),W5=a("li"),bMe=a("strong"),L8r=o("opt"),x8r=o(" \u2014 "),IJ=a("a"),$8r=o("FlaxOPTForCausalLM"),k8r=o(" (OPT model)"),S8r=l(),Q5=a("li"),vMe=a("strong"),R8r=o("roberta"),P8r=o(" \u2014 "),qJ=a("a"),B8r=o("FlaxRobertaForCausalLM"),I8r=o(" (RoBERTa model)"),q8r=l(),H5=a("li"),FMe=a("strong"),N8r=o("xglm"),j8r=o(" \u2014 "),NJ=a("a"),D8r=o("FlaxXGLMForCausalLM"),G8r=o(" (XGLM model)"),O8r=l(),F(U5.$$.fragment),FNe=l(),Pc=a("h2"),J5=a("a"),TMe=a("span"),F(bx.$$.fragment),V8r=l(),MMe=a("span"),X8r=o("FlaxAutoModelForPreTraining"),TNe=l(),gr=a("div"),F(vx.$$.fragment),z8r=l(),Bc=a("p"),W8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),jJ=a("a"),Q8r=o("from_pretrained()"),H8r=o(" class method or the "),DJ=a("a"),U8r=o("from_config()"),J8r=o(` class
method.`),Y8r=l(),Fx=a("p"),K8r=o("This class cannot be instantiated directly using "),EMe=a("code"),Z8r=o("__init__()"),exr=o(" (throws an error)."),oxr=l(),Vt=a("div"),F(Tx.$$.fragment),rxr=l(),CMe=a("p"),txr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),axr=l(),Ic=a("p"),nxr=o(`Note:
Loading a model from its configuration file does `),wMe=a("strong"),sxr=o("not"),lxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GJ=a("a"),ixr=o("from_pretrained()"),dxr=o(" to load the model weights."),cxr=l(),F(Y5.$$.fragment),fxr=l(),Gr=a("div"),F(Mx.$$.fragment),mxr=l(),AMe=a("p"),gxr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),hxr=l(),un=a("p"),pxr=o("The model class to instantiate is selected based on the "),yMe=a("code"),uxr=o("model_type"),_xr=o(` property of the config object (either
passed as an argument or loaded from `),LMe=a("code"),bxr=o("pretrained_model_name_or_path"),vxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=a("code"),Fxr=o("pretrained_model_name_or_path"),Txr=o(":"),Mxr=l(),Me=a("ul"),K5=a("li"),$Me=a("strong"),Exr=o("albert"),Cxr=o(" \u2014 "),OJ=a("a"),wxr=o("FlaxAlbertForPreTraining"),Axr=o(" (ALBERT model)"),yxr=l(),Z5=a("li"),kMe=a("strong"),Lxr=o("bart"),xxr=o(" \u2014 "),VJ=a("a"),$xr=o("FlaxBartForConditionalGeneration"),kxr=o(" (BART model)"),Sxr=l(),e3=a("li"),SMe=a("strong"),Rxr=o("bert"),Pxr=o(" \u2014 "),XJ=a("a"),Bxr=o("FlaxBertForPreTraining"),Ixr=o(" (BERT model)"),qxr=l(),o3=a("li"),RMe=a("strong"),Nxr=o("big_bird"),jxr=o(" \u2014 "),zJ=a("a"),Dxr=o("FlaxBigBirdForPreTraining"),Gxr=o(" (BigBird model)"),Oxr=l(),r3=a("li"),PMe=a("strong"),Vxr=o("electra"),Xxr=o(" \u2014 "),WJ=a("a"),zxr=o("FlaxElectraForPreTraining"),Wxr=o(" (ELECTRA model)"),Qxr=l(),t3=a("li"),BMe=a("strong"),Hxr=o("mbart"),Uxr=o(" \u2014 "),QJ=a("a"),Jxr=o("FlaxMBartForConditionalGeneration"),Yxr=o(" (mBART model)"),Kxr=l(),a3=a("li"),IMe=a("strong"),Zxr=o("mt5"),e9r=o(" \u2014 "),HJ=a("a"),o9r=o("FlaxMT5ForConditionalGeneration"),r9r=o(" (mT5 model)"),t9r=l(),n3=a("li"),qMe=a("strong"),a9r=o("roberta"),n9r=o(" \u2014 "),UJ=a("a"),s9r=o("FlaxRobertaForMaskedLM"),l9r=o(" (RoBERTa model)"),i9r=l(),s3=a("li"),NMe=a("strong"),d9r=o("roformer"),c9r=o(" \u2014 "),JJ=a("a"),f9r=o("FlaxRoFormerForMaskedLM"),m9r=o(" (RoFormer model)"),g9r=l(),l3=a("li"),jMe=a("strong"),h9r=o("t5"),p9r=o(" \u2014 "),YJ=a("a"),u9r=o("FlaxT5ForConditionalGeneration"),_9r=o(" (T5 model)"),b9r=l(),i3=a("li"),DMe=a("strong"),v9r=o("wav2vec2"),F9r=o(" \u2014 "),KJ=a("a"),T9r=o("FlaxWav2Vec2ForPreTraining"),M9r=o(" (Wav2Vec2 model)"),E9r=l(),d3=a("li"),GMe=a("strong"),C9r=o("xlm-roberta"),w9r=o(" \u2014 "),ZJ=a("a"),A9r=o("FlaxXLMRobertaForMaskedLM"),y9r=o(" (XLM-RoBERTa model)"),L9r=l(),F(c3.$$.fragment),MNe=l(),qc=a("h2"),f3=a("a"),OMe=a("span"),F(Ex.$$.fragment),x9r=l(),VMe=a("span"),$9r=o("FlaxAutoModelForMaskedLM"),ENe=l(),hr=a("div"),F(Cx.$$.fragment),k9r=l(),Nc=a("p"),S9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),eY=a("a"),R9r=o("from_pretrained()"),P9r=o(" class method or the "),oY=a("a"),B9r=o("from_config()"),I9r=o(` class
method.`),q9r=l(),wx=a("p"),N9r=o("This class cannot be instantiated directly using "),XMe=a("code"),j9r=o("__init__()"),D9r=o(" (throws an error)."),G9r=l(),Xt=a("div"),F(Ax.$$.fragment),O9r=l(),zMe=a("p"),V9r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),X9r=l(),jc=a("p"),z9r=o(`Note:
Loading a model from its configuration file does `),WMe=a("strong"),W9r=o("not"),Q9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rY=a("a"),H9r=o("from_pretrained()"),U9r=o(" to load the model weights."),J9r=l(),F(m3.$$.fragment),Y9r=l(),Or=a("div"),F(yx.$$.fragment),K9r=l(),QMe=a("p"),Z9r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),e$r=l(),_n=a("p"),o$r=o("The model class to instantiate is selected based on the "),HMe=a("code"),r$r=o("model_type"),t$r=o(` property of the config object (either
passed as an argument or loaded from `),UMe=a("code"),a$r=o("pretrained_model_name_or_path"),n$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JMe=a("code"),s$r=o("pretrained_model_name_or_path"),l$r=o(":"),i$r=l(),xe=a("ul"),g3=a("li"),YMe=a("strong"),d$r=o("albert"),c$r=o(" \u2014 "),tY=a("a"),f$r=o("FlaxAlbertForMaskedLM"),m$r=o(" (ALBERT model)"),g$r=l(),h3=a("li"),KMe=a("strong"),h$r=o("bart"),p$r=o(" \u2014 "),aY=a("a"),u$r=o("FlaxBartForConditionalGeneration"),_$r=o(" (BART model)"),b$r=l(),p3=a("li"),ZMe=a("strong"),v$r=o("bert"),F$r=o(" \u2014 "),nY=a("a"),T$r=o("FlaxBertForMaskedLM"),M$r=o(" (BERT model)"),E$r=l(),u3=a("li"),e4e=a("strong"),C$r=o("big_bird"),w$r=o(" \u2014 "),sY=a("a"),A$r=o("FlaxBigBirdForMaskedLM"),y$r=o(" (BigBird model)"),L$r=l(),_3=a("li"),o4e=a("strong"),x$r=o("distilbert"),$$r=o(" \u2014 "),lY=a("a"),k$r=o("FlaxDistilBertForMaskedLM"),S$r=o(" (DistilBERT model)"),R$r=l(),b3=a("li"),r4e=a("strong"),P$r=o("electra"),B$r=o(" \u2014 "),iY=a("a"),I$r=o("FlaxElectraForMaskedLM"),q$r=o(" (ELECTRA model)"),N$r=l(),v3=a("li"),t4e=a("strong"),j$r=o("mbart"),D$r=o(" \u2014 "),dY=a("a"),G$r=o("FlaxMBartForConditionalGeneration"),O$r=o(" (mBART model)"),V$r=l(),F3=a("li"),a4e=a("strong"),X$r=o("roberta"),z$r=o(" \u2014 "),cY=a("a"),W$r=o("FlaxRobertaForMaskedLM"),Q$r=o(" (RoBERTa model)"),H$r=l(),T3=a("li"),n4e=a("strong"),U$r=o("roformer"),J$r=o(" \u2014 "),fY=a("a"),Y$r=o("FlaxRoFormerForMaskedLM"),K$r=o(" (RoFormer model)"),Z$r=l(),M3=a("li"),s4e=a("strong"),ekr=o("xlm-roberta"),okr=o(" \u2014 "),mY=a("a"),rkr=o("FlaxXLMRobertaForMaskedLM"),tkr=o(" (XLM-RoBERTa model)"),akr=l(),F(E3.$$.fragment),CNe=l(),Dc=a("h2"),C3=a("a"),l4e=a("span"),F(Lx.$$.fragment),nkr=l(),i4e=a("span"),skr=o("FlaxAutoModelForSeq2SeqLM"),wNe=l(),pr=a("div"),F(xx.$$.fragment),lkr=l(),Gc=a("p"),ikr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gY=a("a"),dkr=o("from_pretrained()"),ckr=o(" class method or the "),hY=a("a"),fkr=o("from_config()"),mkr=o(` class
method.`),gkr=l(),$x=a("p"),hkr=o("This class cannot be instantiated directly using "),d4e=a("code"),pkr=o("__init__()"),ukr=o(" (throws an error)."),_kr=l(),zt=a("div"),F(kx.$$.fragment),bkr=l(),c4e=a("p"),vkr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Fkr=l(),Oc=a("p"),Tkr=o(`Note:
Loading a model from its configuration file does `),f4e=a("strong"),Mkr=o("not"),Ekr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pY=a("a"),Ckr=o("from_pretrained()"),wkr=o(" to load the model weights."),Akr=l(),F(w3.$$.fragment),ykr=l(),Vr=a("div"),F(Sx.$$.fragment),Lkr=l(),m4e=a("p"),xkr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$kr=l(),bn=a("p"),kkr=o("The model class to instantiate is selected based on the "),g4e=a("code"),Skr=o("model_type"),Rkr=o(` property of the config object (either
passed as an argument or loaded from `),h4e=a("code"),Pkr=o("pretrained_model_name_or_path"),Bkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p4e=a("code"),Ikr=o("pretrained_model_name_or_path"),qkr=o(":"),Nkr=l(),Pe=a("ul"),A3=a("li"),u4e=a("strong"),jkr=o("bart"),Dkr=o(" \u2014 "),uY=a("a"),Gkr=o("FlaxBartForConditionalGeneration"),Okr=o(" (BART model)"),Vkr=l(),y3=a("li"),_4e=a("strong"),Xkr=o("blenderbot"),zkr=o(" \u2014 "),_Y=a("a"),Wkr=o("FlaxBlenderbotForConditionalGeneration"),Qkr=o(" (Blenderbot model)"),Hkr=l(),L3=a("li"),b4e=a("strong"),Ukr=o("blenderbot-small"),Jkr=o(" \u2014 "),bY=a("a"),Ykr=o("FlaxBlenderbotSmallForConditionalGeneration"),Kkr=o(" (BlenderbotSmall model)"),Zkr=l(),x3=a("li"),v4e=a("strong"),eSr=o("encoder-decoder"),oSr=o(" \u2014 "),vY=a("a"),rSr=o("FlaxEncoderDecoderModel"),tSr=o(" (Encoder decoder model)"),aSr=l(),$3=a("li"),F4e=a("strong"),nSr=o("marian"),sSr=o(" \u2014 "),FY=a("a"),lSr=o("FlaxMarianMTModel"),iSr=o(" (Marian model)"),dSr=l(),k3=a("li"),T4e=a("strong"),cSr=o("mbart"),fSr=o(" \u2014 "),TY=a("a"),mSr=o("FlaxMBartForConditionalGeneration"),gSr=o(" (mBART model)"),hSr=l(),S3=a("li"),M4e=a("strong"),pSr=o("mt5"),uSr=o(" \u2014 "),MY=a("a"),_Sr=o("FlaxMT5ForConditionalGeneration"),bSr=o(" (mT5 model)"),vSr=l(),R3=a("li"),E4e=a("strong"),FSr=o("pegasus"),TSr=o(" \u2014 "),EY=a("a"),MSr=o("FlaxPegasusForConditionalGeneration"),ESr=o(" (Pegasus model)"),CSr=l(),P3=a("li"),C4e=a("strong"),wSr=o("t5"),ASr=o(" \u2014 "),CY=a("a"),ySr=o("FlaxT5ForConditionalGeneration"),LSr=o(" (T5 model)"),xSr=l(),F(B3.$$.fragment),ANe=l(),Vc=a("h2"),I3=a("a"),w4e=a("span"),F(Rx.$$.fragment),$Sr=l(),A4e=a("span"),kSr=o("FlaxAutoModelForSequenceClassification"),yNe=l(),ur=a("div"),F(Px.$$.fragment),SSr=l(),Xc=a("p"),RSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wY=a("a"),PSr=o("from_pretrained()"),BSr=o(" class method or the "),AY=a("a"),ISr=o("from_config()"),qSr=o(` class
method.`),NSr=l(),Bx=a("p"),jSr=o("This class cannot be instantiated directly using "),y4e=a("code"),DSr=o("__init__()"),GSr=o(" (throws an error)."),OSr=l(),Wt=a("div"),F(Ix.$$.fragment),VSr=l(),L4e=a("p"),XSr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zSr=l(),zc=a("p"),WSr=o(`Note:
Loading a model from its configuration file does `),x4e=a("strong"),QSr=o("not"),HSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=a("a"),USr=o("from_pretrained()"),JSr=o(" to load the model weights."),YSr=l(),F(q3.$$.fragment),KSr=l(),Xr=a("div"),F(qx.$$.fragment),ZSr=l(),$4e=a("p"),eRr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oRr=l(),vn=a("p"),rRr=o("The model class to instantiate is selected based on the "),k4e=a("code"),tRr=o("model_type"),aRr=o(` property of the config object (either
passed as an argument or loaded from `),S4e=a("code"),nRr=o("pretrained_model_name_or_path"),sRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=a("code"),lRr=o("pretrained_model_name_or_path"),iRr=o(":"),dRr=l(),$e=a("ul"),N3=a("li"),P4e=a("strong"),cRr=o("albert"),fRr=o(" \u2014 "),LY=a("a"),mRr=o("FlaxAlbertForSequenceClassification"),gRr=o(" (ALBERT model)"),hRr=l(),j3=a("li"),B4e=a("strong"),pRr=o("bart"),uRr=o(" \u2014 "),xY=a("a"),_Rr=o("FlaxBartForSequenceClassification"),bRr=o(" (BART model)"),vRr=l(),D3=a("li"),I4e=a("strong"),FRr=o("bert"),TRr=o(" \u2014 "),$Y=a("a"),MRr=o("FlaxBertForSequenceClassification"),ERr=o(" (BERT model)"),CRr=l(),G3=a("li"),q4e=a("strong"),wRr=o("big_bird"),ARr=o(" \u2014 "),kY=a("a"),yRr=o("FlaxBigBirdForSequenceClassification"),LRr=o(" (BigBird model)"),xRr=l(),O3=a("li"),N4e=a("strong"),$Rr=o("distilbert"),kRr=o(" \u2014 "),SY=a("a"),SRr=o("FlaxDistilBertForSequenceClassification"),RRr=o(" (DistilBERT model)"),PRr=l(),V3=a("li"),j4e=a("strong"),BRr=o("electra"),IRr=o(" \u2014 "),RY=a("a"),qRr=o("FlaxElectraForSequenceClassification"),NRr=o(" (ELECTRA model)"),jRr=l(),X3=a("li"),D4e=a("strong"),DRr=o("mbart"),GRr=o(" \u2014 "),PY=a("a"),ORr=o("FlaxMBartForSequenceClassification"),VRr=o(" (mBART model)"),XRr=l(),z3=a("li"),G4e=a("strong"),zRr=o("roberta"),WRr=o(" \u2014 "),BY=a("a"),QRr=o("FlaxRobertaForSequenceClassification"),HRr=o(" (RoBERTa model)"),URr=l(),W3=a("li"),O4e=a("strong"),JRr=o("roformer"),YRr=o(" \u2014 "),IY=a("a"),KRr=o("FlaxRoFormerForSequenceClassification"),ZRr=o(" (RoFormer model)"),ePr=l(),Q3=a("li"),V4e=a("strong"),oPr=o("xlm-roberta"),rPr=o(" \u2014 "),qY=a("a"),tPr=o("FlaxXLMRobertaForSequenceClassification"),aPr=o(" (XLM-RoBERTa model)"),nPr=l(),F(H3.$$.fragment),LNe=l(),Wc=a("h2"),U3=a("a"),X4e=a("span"),F(Nx.$$.fragment),sPr=l(),z4e=a("span"),lPr=o("FlaxAutoModelForQuestionAnswering"),xNe=l(),_r=a("div"),F(jx.$$.fragment),iPr=l(),Qc=a("p"),dPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),NY=a("a"),cPr=o("from_pretrained()"),fPr=o(" class method or the "),jY=a("a"),mPr=o("from_config()"),gPr=o(` class
method.`),hPr=l(),Dx=a("p"),pPr=o("This class cannot be instantiated directly using "),W4e=a("code"),uPr=o("__init__()"),_Pr=o(" (throws an error)."),bPr=l(),Qt=a("div"),F(Gx.$$.fragment),vPr=l(),Q4e=a("p"),FPr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),TPr=l(),Hc=a("p"),MPr=o(`Note:
Loading a model from its configuration file does `),H4e=a("strong"),EPr=o("not"),CPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=a("a"),wPr=o("from_pretrained()"),APr=o(" to load the model weights."),yPr=l(),F(J3.$$.fragment),LPr=l(),zr=a("div"),F(Ox.$$.fragment),xPr=l(),U4e=a("p"),$Pr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),kPr=l(),Fn=a("p"),SPr=o("The model class to instantiate is selected based on the "),J4e=a("code"),RPr=o("model_type"),PPr=o(` property of the config object (either
passed as an argument or loaded from `),Y4e=a("code"),BPr=o("pretrained_model_name_or_path"),IPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=a("code"),qPr=o("pretrained_model_name_or_path"),NPr=o(":"),jPr=l(),ke=a("ul"),Y3=a("li"),Z4e=a("strong"),DPr=o("albert"),GPr=o(" \u2014 "),GY=a("a"),OPr=o("FlaxAlbertForQuestionAnswering"),VPr=o(" (ALBERT model)"),XPr=l(),K3=a("li"),eEe=a("strong"),zPr=o("bart"),WPr=o(" \u2014 "),OY=a("a"),QPr=o("FlaxBartForQuestionAnswering"),HPr=o(" (BART model)"),UPr=l(),Z3=a("li"),oEe=a("strong"),JPr=o("bert"),YPr=o(" \u2014 "),VY=a("a"),KPr=o("FlaxBertForQuestionAnswering"),ZPr=o(" (BERT model)"),eBr=l(),ew=a("li"),rEe=a("strong"),oBr=o("big_bird"),rBr=o(" \u2014 "),XY=a("a"),tBr=o("FlaxBigBirdForQuestionAnswering"),aBr=o(" (BigBird model)"),nBr=l(),ow=a("li"),tEe=a("strong"),sBr=o("distilbert"),lBr=o(" \u2014 "),zY=a("a"),iBr=o("FlaxDistilBertForQuestionAnswering"),dBr=o(" (DistilBERT model)"),cBr=l(),rw=a("li"),aEe=a("strong"),fBr=o("electra"),mBr=o(" \u2014 "),WY=a("a"),gBr=o("FlaxElectraForQuestionAnswering"),hBr=o(" (ELECTRA model)"),pBr=l(),tw=a("li"),nEe=a("strong"),uBr=o("mbart"),_Br=o(" \u2014 "),QY=a("a"),bBr=o("FlaxMBartForQuestionAnswering"),vBr=o(" (mBART model)"),FBr=l(),aw=a("li"),sEe=a("strong"),TBr=o("roberta"),MBr=o(" \u2014 "),HY=a("a"),EBr=o("FlaxRobertaForQuestionAnswering"),CBr=o(" (RoBERTa model)"),wBr=l(),nw=a("li"),lEe=a("strong"),ABr=o("roformer"),yBr=o(" \u2014 "),UY=a("a"),LBr=o("FlaxRoFormerForQuestionAnswering"),xBr=o(" (RoFormer model)"),$Br=l(),sw=a("li"),iEe=a("strong"),kBr=o("xlm-roberta"),SBr=o(" \u2014 "),JY=a("a"),RBr=o("FlaxXLMRobertaForQuestionAnswering"),PBr=o(" (XLM-RoBERTa model)"),BBr=l(),F(lw.$$.fragment),$Ne=l(),Uc=a("h2"),iw=a("a"),dEe=a("span"),F(Vx.$$.fragment),IBr=l(),cEe=a("span"),qBr=o("FlaxAutoModelForTokenClassification"),kNe=l(),br=a("div"),F(Xx.$$.fragment),NBr=l(),Jc=a("p"),jBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YY=a("a"),DBr=o("from_pretrained()"),GBr=o(" class method or the "),KY=a("a"),OBr=o("from_config()"),VBr=o(` class
method.`),XBr=l(),zx=a("p"),zBr=o("This class cannot be instantiated directly using "),fEe=a("code"),WBr=o("__init__()"),QBr=o(" (throws an error)."),HBr=l(),Ht=a("div"),F(Wx.$$.fragment),UBr=l(),mEe=a("p"),JBr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),YBr=l(),Yc=a("p"),KBr=o(`Note:
Loading a model from its configuration file does `),gEe=a("strong"),ZBr=o("not"),eIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZY=a("a"),oIr=o("from_pretrained()"),rIr=o(" to load the model weights."),tIr=l(),F(dw.$$.fragment),aIr=l(),Wr=a("div"),F(Qx.$$.fragment),nIr=l(),hEe=a("p"),sIr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),lIr=l(),Tn=a("p"),iIr=o("The model class to instantiate is selected based on the "),pEe=a("code"),dIr=o("model_type"),cIr=o(` property of the config object (either
passed as an argument or loaded from `),uEe=a("code"),fIr=o("pretrained_model_name_or_path"),mIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ee=a("code"),gIr=o("pretrained_model_name_or_path"),hIr=o(":"),pIr=l(),Ge=a("ul"),cw=a("li"),bEe=a("strong"),uIr=o("albert"),_Ir=o(" \u2014 "),eK=a("a"),bIr=o("FlaxAlbertForTokenClassification"),vIr=o(" (ALBERT model)"),FIr=l(),fw=a("li"),vEe=a("strong"),TIr=o("bert"),MIr=o(" \u2014 "),oK=a("a"),EIr=o("FlaxBertForTokenClassification"),CIr=o(" (BERT model)"),wIr=l(),mw=a("li"),FEe=a("strong"),AIr=o("big_bird"),yIr=o(" \u2014 "),rK=a("a"),LIr=o("FlaxBigBirdForTokenClassification"),xIr=o(" (BigBird model)"),$Ir=l(),gw=a("li"),TEe=a("strong"),kIr=o("distilbert"),SIr=o(" \u2014 "),tK=a("a"),RIr=o("FlaxDistilBertForTokenClassification"),PIr=o(" (DistilBERT model)"),BIr=l(),hw=a("li"),MEe=a("strong"),IIr=o("electra"),qIr=o(" \u2014 "),aK=a("a"),NIr=o("FlaxElectraForTokenClassification"),jIr=o(" (ELECTRA model)"),DIr=l(),pw=a("li"),EEe=a("strong"),GIr=o("roberta"),OIr=o(" \u2014 "),nK=a("a"),VIr=o("FlaxRobertaForTokenClassification"),XIr=o(" (RoBERTa model)"),zIr=l(),uw=a("li"),CEe=a("strong"),WIr=o("roformer"),QIr=o(" \u2014 "),sK=a("a"),HIr=o("FlaxRoFormerForTokenClassification"),UIr=o(" (RoFormer model)"),JIr=l(),_w=a("li"),wEe=a("strong"),YIr=o("xlm-roberta"),KIr=o(" \u2014 "),lK=a("a"),ZIr=o("FlaxXLMRobertaForTokenClassification"),eqr=o(" (XLM-RoBERTa model)"),oqr=l(),F(bw.$$.fragment),SNe=l(),Kc=a("h2"),vw=a("a"),AEe=a("span"),F(Hx.$$.fragment),rqr=l(),yEe=a("span"),tqr=o("FlaxAutoModelForMultipleChoice"),RNe=l(),vr=a("div"),F(Ux.$$.fragment),aqr=l(),Zc=a("p"),nqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iK=a("a"),sqr=o("from_pretrained()"),lqr=o(" class method or the "),dK=a("a"),iqr=o("from_config()"),dqr=o(` class
method.`),cqr=l(),Jx=a("p"),fqr=o("This class cannot be instantiated directly using "),LEe=a("code"),mqr=o("__init__()"),gqr=o(" (throws an error)."),hqr=l(),Ut=a("div"),F(Yx.$$.fragment),pqr=l(),xEe=a("p"),uqr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),_qr=l(),ef=a("p"),bqr=o(`Note:
Loading a model from its configuration file does `),$Ee=a("strong"),vqr=o("not"),Fqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cK=a("a"),Tqr=o("from_pretrained()"),Mqr=o(" to load the model weights."),Eqr=l(),F(Fw.$$.fragment),Cqr=l(),Qr=a("div"),F(Kx.$$.fragment),wqr=l(),kEe=a("p"),Aqr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),yqr=l(),Mn=a("p"),Lqr=o("The model class to instantiate is selected based on the "),SEe=a("code"),xqr=o("model_type"),$qr=o(` property of the config object (either
passed as an argument or loaded from `),REe=a("code"),kqr=o("pretrained_model_name_or_path"),Sqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PEe=a("code"),Rqr=o("pretrained_model_name_or_path"),Pqr=o(":"),Bqr=l(),Oe=a("ul"),Tw=a("li"),BEe=a("strong"),Iqr=o("albert"),qqr=o(" \u2014 "),fK=a("a"),Nqr=o("FlaxAlbertForMultipleChoice"),jqr=o(" (ALBERT model)"),Dqr=l(),Mw=a("li"),IEe=a("strong"),Gqr=o("bert"),Oqr=o(" \u2014 "),mK=a("a"),Vqr=o("FlaxBertForMultipleChoice"),Xqr=o(" (BERT model)"),zqr=l(),Ew=a("li"),qEe=a("strong"),Wqr=o("big_bird"),Qqr=o(" \u2014 "),gK=a("a"),Hqr=o("FlaxBigBirdForMultipleChoice"),Uqr=o(" (BigBird model)"),Jqr=l(),Cw=a("li"),NEe=a("strong"),Yqr=o("distilbert"),Kqr=o(" \u2014 "),hK=a("a"),Zqr=o("FlaxDistilBertForMultipleChoice"),eNr=o(" (DistilBERT model)"),oNr=l(),ww=a("li"),jEe=a("strong"),rNr=o("electra"),tNr=o(" \u2014 "),pK=a("a"),aNr=o("FlaxElectraForMultipleChoice"),nNr=o(" (ELECTRA model)"),sNr=l(),Aw=a("li"),DEe=a("strong"),lNr=o("roberta"),iNr=o(" \u2014 "),uK=a("a"),dNr=o("FlaxRobertaForMultipleChoice"),cNr=o(" (RoBERTa model)"),fNr=l(),yw=a("li"),GEe=a("strong"),mNr=o("roformer"),gNr=o(" \u2014 "),_K=a("a"),hNr=o("FlaxRoFormerForMultipleChoice"),pNr=o(" (RoFormer model)"),uNr=l(),Lw=a("li"),OEe=a("strong"),_Nr=o("xlm-roberta"),bNr=o(" \u2014 "),bK=a("a"),vNr=o("FlaxXLMRobertaForMultipleChoice"),FNr=o(" (XLM-RoBERTa model)"),TNr=l(),F(xw.$$.fragment),PNe=l(),of=a("h2"),$w=a("a"),VEe=a("span"),F(Zx.$$.fragment),MNr=l(),XEe=a("span"),ENr=o("FlaxAutoModelForNextSentencePrediction"),BNe=l(),Fr=a("div"),F(e9.$$.fragment),CNr=l(),rf=a("p"),wNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),vK=a("a"),ANr=o("from_pretrained()"),yNr=o(" class method or the "),FK=a("a"),LNr=o("from_config()"),xNr=o(` class
method.`),$Nr=l(),o9=a("p"),kNr=o("This class cannot be instantiated directly using "),zEe=a("code"),SNr=o("__init__()"),RNr=o(" (throws an error)."),PNr=l(),Jt=a("div"),F(r9.$$.fragment),BNr=l(),WEe=a("p"),INr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),qNr=l(),tf=a("p"),NNr=o(`Note:
Loading a model from its configuration file does `),QEe=a("strong"),jNr=o("not"),DNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TK=a("a"),GNr=o("from_pretrained()"),ONr=o(" to load the model weights."),VNr=l(),F(kw.$$.fragment),XNr=l(),Hr=a("div"),F(t9.$$.fragment),zNr=l(),HEe=a("p"),WNr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),QNr=l(),En=a("p"),HNr=o("The model class to instantiate is selected based on the "),UEe=a("code"),UNr=o("model_type"),JNr=o(` property of the config object (either
passed as an argument or loaded from `),JEe=a("code"),YNr=o("pretrained_model_name_or_path"),KNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YEe=a("code"),ZNr=o("pretrained_model_name_or_path"),ejr=o(":"),ojr=l(),KEe=a("ul"),Sw=a("li"),ZEe=a("strong"),rjr=o("bert"),tjr=o(" \u2014 "),MK=a("a"),ajr=o("FlaxBertForNextSentencePrediction"),njr=o(" (BERT model)"),sjr=l(),F(Rw.$$.fragment),INe=l(),af=a("h2"),Pw=a("a"),eCe=a("span"),F(a9.$$.fragment),ljr=l(),oCe=a("span"),ijr=o("FlaxAutoModelForImageClassification"),qNe=l(),Tr=a("div"),F(n9.$$.fragment),djr=l(),nf=a("p"),cjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),EK=a("a"),fjr=o("from_pretrained()"),mjr=o(" class method or the "),CK=a("a"),gjr=o("from_config()"),hjr=o(` class
method.`),pjr=l(),s9=a("p"),ujr=o("This class cannot be instantiated directly using "),rCe=a("code"),_jr=o("__init__()"),bjr=o(" (throws an error)."),vjr=l(),Yt=a("div"),F(l9.$$.fragment),Fjr=l(),tCe=a("p"),Tjr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Mjr=l(),sf=a("p"),Ejr=o(`Note:
Loading a model from its configuration file does `),aCe=a("strong"),Cjr=o("not"),wjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=a("a"),Ajr=o("from_pretrained()"),yjr=o(" to load the model weights."),Ljr=l(),F(Bw.$$.fragment),xjr=l(),Ur=a("div"),F(i9.$$.fragment),$jr=l(),nCe=a("p"),kjr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Sjr=l(),Cn=a("p"),Rjr=o("The model class to instantiate is selected based on the "),sCe=a("code"),Pjr=o("model_type"),Bjr=o(` property of the config object (either
passed as an argument or loaded from `),lCe=a("code"),Ijr=o("pretrained_model_name_or_path"),qjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=a("code"),Njr=o("pretrained_model_name_or_path"),jjr=o(":"),Djr=l(),d9=a("ul"),Iw=a("li"),dCe=a("strong"),Gjr=o("beit"),Ojr=o(" \u2014 "),AK=a("a"),Vjr=o("FlaxBeitForImageClassification"),Xjr=o(" (BEiT model)"),zjr=l(),qw=a("li"),cCe=a("strong"),Wjr=o("vit"),Qjr=o(" \u2014 "),yK=a("a"),Hjr=o("FlaxViTForImageClassification"),Ujr=o(" (ViT model)"),Jjr=l(),F(Nw.$$.fragment),NNe=l(),lf=a("h2"),jw=a("a"),fCe=a("span"),F(c9.$$.fragment),Yjr=l(),mCe=a("span"),Kjr=o("FlaxAutoModelForVision2Seq"),jNe=l(),Mr=a("div"),F(f9.$$.fragment),Zjr=l(),df=a("p"),eDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),LK=a("a"),oDr=o("from_pretrained()"),rDr=o(" class method or the "),xK=a("a"),tDr=o("from_config()"),aDr=o(` class
method.`),nDr=l(),m9=a("p"),sDr=o("This class cannot be instantiated directly using "),gCe=a("code"),lDr=o("__init__()"),iDr=o(" (throws an error)."),dDr=l(),Kt=a("div"),F(g9.$$.fragment),cDr=l(),hCe=a("p"),fDr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),mDr=l(),cf=a("p"),gDr=o(`Note:
Loading a model from its configuration file does `),pCe=a("strong"),hDr=o("not"),pDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$K=a("a"),uDr=o("from_pretrained()"),_Dr=o(" to load the model weights."),bDr=l(),F(Dw.$$.fragment),vDr=l(),Jr=a("div"),F(h9.$$.fragment),FDr=l(),uCe=a("p"),TDr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),MDr=l(),wn=a("p"),EDr=o("The model class to instantiate is selected based on the "),_Ce=a("code"),CDr=o("model_type"),wDr=o(` property of the config object (either
passed as an argument or loaded from `),bCe=a("code"),ADr=o("pretrained_model_name_or_path"),yDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vCe=a("code"),LDr=o("pretrained_model_name_or_path"),xDr=o(":"),$Dr=l(),FCe=a("ul"),Gw=a("li"),TCe=a("strong"),kDr=o("vision-encoder-decoder"),SDr=o(" \u2014 "),kK=a("a"),RDr=o("FlaxVisionEncoderDecoderModel"),PDr=o(" (Vision Encoder decoder model)"),BDr=l(),F(Ow.$$.fragment),this.h()},l(f){const _=PLt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var p9=s(p);m=n(p9,"A",{id:!0,class:!0,href:!0});var MCe=s(m);u=n(MCe,"SPAN",{});var ECe=s(u);T(d.$$.fragment,ECe),ECe.forEach(t),MCe.forEach(t),h=i(p9),Mo=n(p9,"SPAN",{});var CCe=s(Mo);ci=r(CCe,"Auto Classes"),CCe.forEach(t),p9.forEach(t),hf=i(f),rt=n(f,"P",{});var u9=s(rt);fi=r(u9,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),mi=n(u9,"CODE",{});var wCe=s(mi);s6=r(wCe,"from_pretrained()"),wCe.forEach(t),pf=r(u9,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),u9.forEach(t),De=i(f),We=n(f,"P",{});var An=s(We);gi=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var ACe=s(yn);l6=r(ACe,"AutoConfig"),ACe.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var yCe=s(xn);i6=r(yCe,"AutoModel"),yCe.forEach(t),hi=r(An,`, and
`),$n=n(An,"A",{href:!0});var LCe=s($n);d6=r(LCe,"AutoTokenizer"),LCe.forEach(t),pi=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),uf=i(f),T(Ca.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var _9=s(Ae);y$=r(_9,"will create a model that is an instance of "),ui=n(_9,"A",{href:!0});var xCe=s(ui);L$=r(xCe,"BertModel"),xCe.forEach(t),x$=r(_9,"."),_9.forEach(t),Eo=i(f),wa=n(f,"P",{});var b9=s(wa);$$=r(b9,"There is one class of "),_f=n(b9,"CODE",{});var $Ce=s(_f);k$=r($Ce,"AutoModel"),$Ce.forEach(t),HDe=r(b9," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),b9.forEach(t),qIe=i(f),_i=n(f,"H2",{class:!0});var v9=s(_i);bf=n(v9,"A",{id:!0,class:!0,href:!0});var kCe=s(bf);Cee=n(kCe,"SPAN",{});var SCe=s(Cee);T(c6.$$.fragment,SCe),SCe.forEach(t),kCe.forEach(t),UDe=i(v9),wee=n(v9,"SPAN",{});var RCe=s(wee);JDe=r(RCe,"Extending the Auto Classes"),RCe.forEach(t),v9.forEach(t),NIe=i(f),kn=n(f,"P",{});var ff=s(kn);YDe=r(ff,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Aee=n(ff,"CODE",{});var PCe=s(Aee);KDe=r(PCe,"NewModel"),PCe.forEach(t),ZDe=r(ff,", make sure you have a "),yee=n(ff,"CODE",{});var BCe=s(yee);eGe=r(BCe,"NewModelConfig"),BCe.forEach(t),oGe=r(ff,` then you can add those to the auto
classes like this:`),ff.forEach(t),jIe=i(f),T(f6.$$.fragment,f),DIe=i(f),S$=n(f,"P",{});var ICe=s(S$);rGe=r(ICe,"You will then be able to use the auto classes like you would usually do!"),ICe.forEach(t),GIe=i(f),T(vf.$$.fragment,f),OIe=i(f),bi=n(f,"H2",{class:!0});var F9=s(bi);Ff=n(F9,"A",{id:!0,class:!0,href:!0});var qCe=s(Ff);Lee=n(qCe,"SPAN",{});var NCe=s(Lee);T(m6.$$.fragment,NCe),NCe.forEach(t),qCe.forEach(t),tGe=i(F9),xee=n(F9,"SPAN",{});var jCe=s(xee);aGe=r(jCe,"AutoConfig"),jCe.forEach(t),F9.forEach(t),VIe=i(f),Co=n(f,"DIV",{class:!0});var et=s(Co);T(g6.$$.fragment,et),nGe=i(et),h6=n(et,"P",{});var T9=s(h6);sGe=r(T9,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),R$=n(T9,"A",{href:!0});var DCe=s(R$);lGe=r(DCe,"from_pretrained()"),DCe.forEach(t),iGe=r(T9," class method."),T9.forEach(t),dGe=i(et),p6=n(et,"P",{});var M9=s(p6);cGe=r(M9,"This class cannot be instantiated directly using "),$ee=n(M9,"CODE",{});var GCe=s($ee);fGe=r(GCe,"__init__()"),GCe.forEach(t),mGe=r(M9," (throws an error)."),M9.forEach(t),gGe=i(et),Er=n(et,"DIV",{class:!0});var ot=s(Er);T(u6.$$.fragment,ot),hGe=i(ot),kee=n(ot,"P",{});var OCe=s(kee);pGe=r(OCe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),OCe.forEach(t),uGe=i(ot),vi=n(ot,"P",{});var mf=s(vi);_Ge=r(mf,"The configuration class to instantiate is selected based on the "),See=n(mf,"CODE",{});var VCe=s(See);bGe=r(VCe,"model_type"),VCe.forEach(t),vGe=r(mf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Ree=n(mf,"CODE",{});var XCe=s(Ree);FGe=r(XCe,"pretrained_model_name_or_path"),XCe.forEach(t),TGe=r(mf,":"),mf.forEach(t),MGe=i(ot),A=n(ot,"UL",{});var y=s(A);Tf=n(y,"LI",{});var Vw=s(Tf);Pee=n(Vw,"STRONG",{});var zCe=s(Pee);EGe=r(zCe,"albert"),zCe.forEach(t),CGe=r(Vw," \u2014 "),P$=n(Vw,"A",{href:!0});var WCe=s(P$);wGe=r(WCe,"AlbertConfig"),WCe.forEach(t),AGe=r(Vw," (ALBERT model)"),Vw.forEach(t),yGe=i(y),Mf=n(y,"LI",{});var Xw=s(Mf);Bee=n(Xw,"STRONG",{});var QCe=s(Bee);LGe=r(QCe,"bart"),QCe.forEach(t),xGe=r(Xw," \u2014 "),B$=n(Xw,"A",{href:!0});var HCe=s(B$);$Ge=r(HCe,"BartConfig"),HCe.forEach(t),kGe=r(Xw," (BART model)"),Xw.forEach(t),SGe=i(y),Ef=n(y,"LI",{});var zw=s(Ef);Iee=n(zw,"STRONG",{});var UCe=s(Iee);RGe=r(UCe,"beit"),UCe.forEach(t),PGe=r(zw," \u2014 "),I$=n(zw,"A",{href:!0});var JCe=s(I$);BGe=r(JCe,"BeitConfig"),JCe.forEach(t),IGe=r(zw," (BEiT model)"),zw.forEach(t),qGe=i(y),Cf=n(y,"LI",{});var Ww=s(Cf);qee=n(Ww,"STRONG",{});var YCe=s(qee);NGe=r(YCe,"bert"),YCe.forEach(t),jGe=r(Ww," \u2014 "),q$=n(Ww,"A",{href:!0});var KCe=s(q$);DGe=r(KCe,"BertConfig"),KCe.forEach(t),GGe=r(Ww," (BERT model)"),Ww.forEach(t),OGe=i(y),wf=n(y,"LI",{});var Qw=s(wf);Nee=n(Qw,"STRONG",{});var ZCe=s(Nee);VGe=r(ZCe,"bert-generation"),ZCe.forEach(t),XGe=r(Qw," \u2014 "),N$=n(Qw,"A",{href:!0});var e5e=s(N$);zGe=r(e5e,"BertGenerationConfig"),e5e.forEach(t),WGe=r(Qw," (Bert Generation model)"),Qw.forEach(t),QGe=i(y),Af=n(y,"LI",{});var Hw=s(Af);jee=n(Hw,"STRONG",{});var o5e=s(jee);HGe=r(o5e,"big_bird"),o5e.forEach(t),UGe=r(Hw," \u2014 "),j$=n(Hw,"A",{href:!0});var r5e=s(j$);JGe=r(r5e,"BigBirdConfig"),r5e.forEach(t),YGe=r(Hw," (BigBird model)"),Hw.forEach(t),KGe=i(y),yf=n(y,"LI",{});var Uw=s(yf);Dee=n(Uw,"STRONG",{});var t5e=s(Dee);ZGe=r(t5e,"bigbird_pegasus"),t5e.forEach(t),eOe=r(Uw," \u2014 "),D$=n(Uw,"A",{href:!0});var a5e=s(D$);oOe=r(a5e,"BigBirdPegasusConfig"),a5e.forEach(t),rOe=r(Uw," (BigBirdPegasus model)"),Uw.forEach(t),tOe=i(y),Lf=n(y,"LI",{});var Jw=s(Lf);Gee=n(Jw,"STRONG",{});var n5e=s(Gee);aOe=r(n5e,"blenderbot"),n5e.forEach(t),nOe=r(Jw," \u2014 "),G$=n(Jw,"A",{href:!0});var s5e=s(G$);sOe=r(s5e,"BlenderbotConfig"),s5e.forEach(t),lOe=r(Jw," (Blenderbot model)"),Jw.forEach(t),iOe=i(y),xf=n(y,"LI",{});var Yw=s(xf);Oee=n(Yw,"STRONG",{});var l5e=s(Oee);dOe=r(l5e,"blenderbot-small"),l5e.forEach(t),cOe=r(Yw," \u2014 "),O$=n(Yw,"A",{href:!0});var i5e=s(O$);fOe=r(i5e,"BlenderbotSmallConfig"),i5e.forEach(t),mOe=r(Yw," (BlenderbotSmall model)"),Yw.forEach(t),gOe=i(y),$f=n(y,"LI",{});var Kw=s($f);Vee=n(Kw,"STRONG",{});var d5e=s(Vee);hOe=r(d5e,"camembert"),d5e.forEach(t),pOe=r(Kw," \u2014 "),V$=n(Kw,"A",{href:!0});var c5e=s(V$);uOe=r(c5e,"CamembertConfig"),c5e.forEach(t),_Oe=r(Kw," (CamemBERT model)"),Kw.forEach(t),bOe=i(y),kf=n(y,"LI",{});var Zw=s(kf);Xee=n(Zw,"STRONG",{});var f5e=s(Xee);vOe=r(f5e,"canine"),f5e.forEach(t),FOe=r(Zw," \u2014 "),X$=n(Zw,"A",{href:!0});var m5e=s(X$);TOe=r(m5e,"CanineConfig"),m5e.forEach(t),MOe=r(Zw," (Canine model)"),Zw.forEach(t),EOe=i(y),Sf=n(y,"LI",{});var eA=s(Sf);zee=n(eA,"STRONG",{});var g5e=s(zee);COe=r(g5e,"clip"),g5e.forEach(t),wOe=r(eA," \u2014 "),z$=n(eA,"A",{href:!0});var h5e=s(z$);AOe=r(h5e,"CLIPConfig"),h5e.forEach(t),yOe=r(eA," (CLIP model)"),eA.forEach(t),LOe=i(y),Rf=n(y,"LI",{});var oA=s(Rf);Wee=n(oA,"STRONG",{});var p5e=s(Wee);xOe=r(p5e,"convbert"),p5e.forEach(t),$Oe=r(oA," \u2014 "),W$=n(oA,"A",{href:!0});var u5e=s(W$);kOe=r(u5e,"ConvBertConfig"),u5e.forEach(t),SOe=r(oA," (ConvBERT model)"),oA.forEach(t),ROe=i(y),Pf=n(y,"LI",{});var rA=s(Pf);Qee=n(rA,"STRONG",{});var _5e=s(Qee);POe=r(_5e,"convnext"),_5e.forEach(t),BOe=r(rA," \u2014 "),Q$=n(rA,"A",{href:!0});var b5e=s(Q$);IOe=r(b5e,"ConvNextConfig"),b5e.forEach(t),qOe=r(rA," (ConvNext model)"),rA.forEach(t),NOe=i(y),Bf=n(y,"LI",{});var tA=s(Bf);Hee=n(tA,"STRONG",{});var v5e=s(Hee);jOe=r(v5e,"ctrl"),v5e.forEach(t),DOe=r(tA," \u2014 "),H$=n(tA,"A",{href:!0});var F5e=s(H$);GOe=r(F5e,"CTRLConfig"),F5e.forEach(t),OOe=r(tA," (CTRL model)"),tA.forEach(t),VOe=i(y),If=n(y,"LI",{});var aA=s(If);Uee=n(aA,"STRONG",{});var T5e=s(Uee);XOe=r(T5e,"data2vec-audio"),T5e.forEach(t),zOe=r(aA," \u2014 "),U$=n(aA,"A",{href:!0});var M5e=s(U$);WOe=r(M5e,"Data2VecAudioConfig"),M5e.forEach(t),QOe=r(aA," (Data2VecAudio model)"),aA.forEach(t),HOe=i(y),qf=n(y,"LI",{});var nA=s(qf);Jee=n(nA,"STRONG",{});var E5e=s(Jee);UOe=r(E5e,"data2vec-text"),E5e.forEach(t),JOe=r(nA," \u2014 "),J$=n(nA,"A",{href:!0});var C5e=s(J$);YOe=r(C5e,"Data2VecTextConfig"),C5e.forEach(t),KOe=r(nA," (Data2VecText model)"),nA.forEach(t),ZOe=i(y),Nf=n(y,"LI",{});var sA=s(Nf);Yee=n(sA,"STRONG",{});var w5e=s(Yee);eVe=r(w5e,"data2vec-vision"),w5e.forEach(t),oVe=r(sA," \u2014 "),Y$=n(sA,"A",{href:!0});var A5e=s(Y$);rVe=r(A5e,"Data2VecVisionConfig"),A5e.forEach(t),tVe=r(sA," (Data2VecVision model)"),sA.forEach(t),aVe=i(y),jf=n(y,"LI",{});var lA=s(jf);Kee=n(lA,"STRONG",{});var y5e=s(Kee);nVe=r(y5e,"deberta"),y5e.forEach(t),sVe=r(lA," \u2014 "),K$=n(lA,"A",{href:!0});var L5e=s(K$);lVe=r(L5e,"DebertaConfig"),L5e.forEach(t),iVe=r(lA," (DeBERTa model)"),lA.forEach(t),dVe=i(y),Df=n(y,"LI",{});var iA=s(Df);Zee=n(iA,"STRONG",{});var x5e=s(Zee);cVe=r(x5e,"deberta-v2"),x5e.forEach(t),fVe=r(iA," \u2014 "),Z$=n(iA,"A",{href:!0});var $5e=s(Z$);mVe=r($5e,"DebertaV2Config"),$5e.forEach(t),gVe=r(iA," (DeBERTa-v2 model)"),iA.forEach(t),hVe=i(y),Gf=n(y,"LI",{});var dA=s(Gf);eoe=n(dA,"STRONG",{});var k5e=s(eoe);pVe=r(k5e,"decision_transformer"),k5e.forEach(t),uVe=r(dA," \u2014 "),ek=n(dA,"A",{href:!0});var S5e=s(ek);_Ve=r(S5e,"DecisionTransformerConfig"),S5e.forEach(t),bVe=r(dA," (Decision Transformer model)"),dA.forEach(t),vVe=i(y),Of=n(y,"LI",{});var cA=s(Of);ooe=n(cA,"STRONG",{});var R5e=s(ooe);FVe=r(R5e,"deit"),R5e.forEach(t),TVe=r(cA," \u2014 "),ok=n(cA,"A",{href:!0});var P5e=s(ok);MVe=r(P5e,"DeiTConfig"),P5e.forEach(t),EVe=r(cA," (DeiT model)"),cA.forEach(t),CVe=i(y),Vf=n(y,"LI",{});var fA=s(Vf);roe=n(fA,"STRONG",{});var B5e=s(roe);wVe=r(B5e,"detr"),B5e.forEach(t),AVe=r(fA," \u2014 "),rk=n(fA,"A",{href:!0});var qDr=s(rk);yVe=r(qDr,"DetrConfig"),qDr.forEach(t),LVe=r(fA," (DETR model)"),fA.forEach(t),xVe=i(y),Xf=n(y,"LI",{});var I5e=s(Xf);toe=n(I5e,"STRONG",{});var NDr=s(toe);$Ve=r(NDr,"distilbert"),NDr.forEach(t),kVe=r(I5e," \u2014 "),tk=n(I5e,"A",{href:!0});var jDr=s(tk);SVe=r(jDr,"DistilBertConfig"),jDr.forEach(t),RVe=r(I5e," (DistilBERT model)"),I5e.forEach(t),PVe=i(y),zf=n(y,"LI",{});var q5e=s(zf);aoe=n(q5e,"STRONG",{});var DDr=s(aoe);BVe=r(DDr,"dpr"),DDr.forEach(t),IVe=r(q5e," \u2014 "),ak=n(q5e,"A",{href:!0});var GDr=s(ak);qVe=r(GDr,"DPRConfig"),GDr.forEach(t),NVe=r(q5e," (DPR model)"),q5e.forEach(t),jVe=i(y),Wf=n(y,"LI",{});var N5e=s(Wf);noe=n(N5e,"STRONG",{});var ODr=s(noe);DVe=r(ODr,"dpt"),ODr.forEach(t),GVe=r(N5e," \u2014 "),nk=n(N5e,"A",{href:!0});var VDr=s(nk);OVe=r(VDr,"DPTConfig"),VDr.forEach(t),VVe=r(N5e," (DPT model)"),N5e.forEach(t),XVe=i(y),Qf=n(y,"LI",{});var j5e=s(Qf);soe=n(j5e,"STRONG",{});var XDr=s(soe);zVe=r(XDr,"electra"),XDr.forEach(t),WVe=r(j5e," \u2014 "),sk=n(j5e,"A",{href:!0});var zDr=s(sk);QVe=r(zDr,"ElectraConfig"),zDr.forEach(t),HVe=r(j5e," (ELECTRA model)"),j5e.forEach(t),UVe=i(y),Hf=n(y,"LI",{});var D5e=s(Hf);loe=n(D5e,"STRONG",{});var WDr=s(loe);JVe=r(WDr,"encoder-decoder"),WDr.forEach(t),YVe=r(D5e," \u2014 "),lk=n(D5e,"A",{href:!0});var QDr=s(lk);KVe=r(QDr,"EncoderDecoderConfig"),QDr.forEach(t),ZVe=r(D5e," (Encoder decoder model)"),D5e.forEach(t),eXe=i(y),Uf=n(y,"LI",{});var G5e=s(Uf);ioe=n(G5e,"STRONG",{});var HDr=s(ioe);oXe=r(HDr,"flaubert"),HDr.forEach(t),rXe=r(G5e," \u2014 "),ik=n(G5e,"A",{href:!0});var UDr=s(ik);tXe=r(UDr,"FlaubertConfig"),UDr.forEach(t),aXe=r(G5e," (FlauBERT model)"),G5e.forEach(t),nXe=i(y),Jf=n(y,"LI",{});var O5e=s(Jf);doe=n(O5e,"STRONG",{});var JDr=s(doe);sXe=r(JDr,"flava"),JDr.forEach(t),lXe=r(O5e," \u2014 "),dk=n(O5e,"A",{href:!0});var YDr=s(dk);iXe=r(YDr,"FlavaConfig"),YDr.forEach(t),dXe=r(O5e," (Flava model)"),O5e.forEach(t),cXe=i(y),Yf=n(y,"LI",{});var V5e=s(Yf);coe=n(V5e,"STRONG",{});var KDr=s(coe);fXe=r(KDr,"fnet"),KDr.forEach(t),mXe=r(V5e," \u2014 "),ck=n(V5e,"A",{href:!0});var ZDr=s(ck);gXe=r(ZDr,"FNetConfig"),ZDr.forEach(t),hXe=r(V5e," (FNet model)"),V5e.forEach(t),pXe=i(y),Kf=n(y,"LI",{});var X5e=s(Kf);foe=n(X5e,"STRONG",{});var eGr=s(foe);uXe=r(eGr,"fsmt"),eGr.forEach(t),_Xe=r(X5e," \u2014 "),fk=n(X5e,"A",{href:!0});var oGr=s(fk);bXe=r(oGr,"FSMTConfig"),oGr.forEach(t),vXe=r(X5e," (FairSeq Machine-Translation model)"),X5e.forEach(t),FXe=i(y),Zf=n(y,"LI",{});var z5e=s(Zf);moe=n(z5e,"STRONG",{});var rGr=s(moe);TXe=r(rGr,"funnel"),rGr.forEach(t),MXe=r(z5e," \u2014 "),mk=n(z5e,"A",{href:!0});var tGr=s(mk);EXe=r(tGr,"FunnelConfig"),tGr.forEach(t),CXe=r(z5e," (Funnel Transformer model)"),z5e.forEach(t),wXe=i(y),em=n(y,"LI",{});var W5e=s(em);goe=n(W5e,"STRONG",{});var aGr=s(goe);AXe=r(aGr,"glpn"),aGr.forEach(t),yXe=r(W5e," \u2014 "),gk=n(W5e,"A",{href:!0});var nGr=s(gk);LXe=r(nGr,"GLPNConfig"),nGr.forEach(t),xXe=r(W5e," (GLPN model)"),W5e.forEach(t),$Xe=i(y),om=n(y,"LI",{});var Q5e=s(om);hoe=n(Q5e,"STRONG",{});var sGr=s(hoe);kXe=r(sGr,"gpt2"),sGr.forEach(t),SXe=r(Q5e," \u2014 "),hk=n(Q5e,"A",{href:!0});var lGr=s(hk);RXe=r(lGr,"GPT2Config"),lGr.forEach(t),PXe=r(Q5e," (OpenAI GPT-2 model)"),Q5e.forEach(t),BXe=i(y),rm=n(y,"LI",{});var H5e=s(rm);poe=n(H5e,"STRONG",{});var iGr=s(poe);IXe=r(iGr,"gpt_neo"),iGr.forEach(t),qXe=r(H5e," \u2014 "),pk=n(H5e,"A",{href:!0});var dGr=s(pk);NXe=r(dGr,"GPTNeoConfig"),dGr.forEach(t),jXe=r(H5e," (GPT Neo model)"),H5e.forEach(t),DXe=i(y),tm=n(y,"LI",{});var U5e=s(tm);uoe=n(U5e,"STRONG",{});var cGr=s(uoe);GXe=r(cGr,"gptj"),cGr.forEach(t),OXe=r(U5e," \u2014 "),uk=n(U5e,"A",{href:!0});var fGr=s(uk);VXe=r(fGr,"GPTJConfig"),fGr.forEach(t),XXe=r(U5e," (GPT-J model)"),U5e.forEach(t),zXe=i(y),am=n(y,"LI",{});var J5e=s(am);_oe=n(J5e,"STRONG",{});var mGr=s(_oe);WXe=r(mGr,"hubert"),mGr.forEach(t),QXe=r(J5e," \u2014 "),_k=n(J5e,"A",{href:!0});var gGr=s(_k);HXe=r(gGr,"HubertConfig"),gGr.forEach(t),UXe=r(J5e," (Hubert model)"),J5e.forEach(t),JXe=i(y),nm=n(y,"LI",{});var Y5e=s(nm);boe=n(Y5e,"STRONG",{});var hGr=s(boe);YXe=r(hGr,"ibert"),hGr.forEach(t),KXe=r(Y5e," \u2014 "),bk=n(Y5e,"A",{href:!0});var pGr=s(bk);ZXe=r(pGr,"IBertConfig"),pGr.forEach(t),eze=r(Y5e," (I-BERT model)"),Y5e.forEach(t),oze=i(y),sm=n(y,"LI",{});var K5e=s(sm);voe=n(K5e,"STRONG",{});var uGr=s(voe);rze=r(uGr,"imagegpt"),uGr.forEach(t),tze=r(K5e," \u2014 "),vk=n(K5e,"A",{href:!0});var _Gr=s(vk);aze=r(_Gr,"ImageGPTConfig"),_Gr.forEach(t),nze=r(K5e," (ImageGPT model)"),K5e.forEach(t),sze=i(y),lm=n(y,"LI",{});var Z5e=s(lm);Foe=n(Z5e,"STRONG",{});var bGr=s(Foe);lze=r(bGr,"layoutlm"),bGr.forEach(t),ize=r(Z5e," \u2014 "),Fk=n(Z5e,"A",{href:!0});var vGr=s(Fk);dze=r(vGr,"LayoutLMConfig"),vGr.forEach(t),cze=r(Z5e," (LayoutLM model)"),Z5e.forEach(t),fze=i(y),im=n(y,"LI",{});var e3e=s(im);Toe=n(e3e,"STRONG",{});var FGr=s(Toe);mze=r(FGr,"layoutlmv2"),FGr.forEach(t),gze=r(e3e," \u2014 "),Tk=n(e3e,"A",{href:!0});var TGr=s(Tk);hze=r(TGr,"LayoutLMv2Config"),TGr.forEach(t),pze=r(e3e," (LayoutLMv2 model)"),e3e.forEach(t),uze=i(y),dm=n(y,"LI",{});var o3e=s(dm);Moe=n(o3e,"STRONG",{});var MGr=s(Moe);_ze=r(MGr,"led"),MGr.forEach(t),bze=r(o3e," \u2014 "),Mk=n(o3e,"A",{href:!0});var EGr=s(Mk);vze=r(EGr,"LEDConfig"),EGr.forEach(t),Fze=r(o3e," (LED model)"),o3e.forEach(t),Tze=i(y),cm=n(y,"LI",{});var r3e=s(cm);Eoe=n(r3e,"STRONG",{});var CGr=s(Eoe);Mze=r(CGr,"longformer"),CGr.forEach(t),Eze=r(r3e," \u2014 "),Ek=n(r3e,"A",{href:!0});var wGr=s(Ek);Cze=r(wGr,"LongformerConfig"),wGr.forEach(t),wze=r(r3e," (Longformer model)"),r3e.forEach(t),Aze=i(y),fm=n(y,"LI",{});var t3e=s(fm);Coe=n(t3e,"STRONG",{});var AGr=s(Coe);yze=r(AGr,"luke"),AGr.forEach(t),Lze=r(t3e," \u2014 "),Ck=n(t3e,"A",{href:!0});var yGr=s(Ck);xze=r(yGr,"LukeConfig"),yGr.forEach(t),$ze=r(t3e," (LUKE model)"),t3e.forEach(t),kze=i(y),mm=n(y,"LI",{});var a3e=s(mm);woe=n(a3e,"STRONG",{});var LGr=s(woe);Sze=r(LGr,"lxmert"),LGr.forEach(t),Rze=r(a3e," \u2014 "),wk=n(a3e,"A",{href:!0});var xGr=s(wk);Pze=r(xGr,"LxmertConfig"),xGr.forEach(t),Bze=r(a3e," (LXMERT model)"),a3e.forEach(t),Ize=i(y),gm=n(y,"LI",{});var n3e=s(gm);Aoe=n(n3e,"STRONG",{});var $Gr=s(Aoe);qze=r($Gr,"m2m_100"),$Gr.forEach(t),Nze=r(n3e," \u2014 "),Ak=n(n3e,"A",{href:!0});var kGr=s(Ak);jze=r(kGr,"M2M100Config"),kGr.forEach(t),Dze=r(n3e," (M2M100 model)"),n3e.forEach(t),Gze=i(y),hm=n(y,"LI",{});var s3e=s(hm);yoe=n(s3e,"STRONG",{});var SGr=s(yoe);Oze=r(SGr,"marian"),SGr.forEach(t),Vze=r(s3e," \u2014 "),yk=n(s3e,"A",{href:!0});var RGr=s(yk);Xze=r(RGr,"MarianConfig"),RGr.forEach(t),zze=r(s3e," (Marian model)"),s3e.forEach(t),Wze=i(y),pm=n(y,"LI",{});var l3e=s(pm);Loe=n(l3e,"STRONG",{});var PGr=s(Loe);Qze=r(PGr,"maskformer"),PGr.forEach(t),Hze=r(l3e," \u2014 "),Lk=n(l3e,"A",{href:!0});var BGr=s(Lk);Uze=r(BGr,"MaskFormerConfig"),BGr.forEach(t),Jze=r(l3e," (MaskFormer model)"),l3e.forEach(t),Yze=i(y),um=n(y,"LI",{});var i3e=s(um);xoe=n(i3e,"STRONG",{});var IGr=s(xoe);Kze=r(IGr,"mbart"),IGr.forEach(t),Zze=r(i3e," \u2014 "),xk=n(i3e,"A",{href:!0});var qGr=s(xk);eWe=r(qGr,"MBartConfig"),qGr.forEach(t),oWe=r(i3e," (mBART model)"),i3e.forEach(t),rWe=i(y),_m=n(y,"LI",{});var d3e=s(_m);$oe=n(d3e,"STRONG",{});var NGr=s($oe);tWe=r(NGr,"megatron-bert"),NGr.forEach(t),aWe=r(d3e," \u2014 "),$k=n(d3e,"A",{href:!0});var jGr=s($k);nWe=r(jGr,"MegatronBertConfig"),jGr.forEach(t),sWe=r(d3e," (MegatronBert model)"),d3e.forEach(t),lWe=i(y),bm=n(y,"LI",{});var c3e=s(bm);koe=n(c3e,"STRONG",{});var DGr=s(koe);iWe=r(DGr,"mobilebert"),DGr.forEach(t),dWe=r(c3e," \u2014 "),kk=n(c3e,"A",{href:!0});var GGr=s(kk);cWe=r(GGr,"MobileBertConfig"),GGr.forEach(t),fWe=r(c3e," (MobileBERT model)"),c3e.forEach(t),mWe=i(y),vm=n(y,"LI",{});var f3e=s(vm);Soe=n(f3e,"STRONG",{});var OGr=s(Soe);gWe=r(OGr,"mpnet"),OGr.forEach(t),hWe=r(f3e," \u2014 "),Sk=n(f3e,"A",{href:!0});var VGr=s(Sk);pWe=r(VGr,"MPNetConfig"),VGr.forEach(t),uWe=r(f3e," (MPNet model)"),f3e.forEach(t),_We=i(y),Fm=n(y,"LI",{});var m3e=s(Fm);Roe=n(m3e,"STRONG",{});var XGr=s(Roe);bWe=r(XGr,"mt5"),XGr.forEach(t),vWe=r(m3e," \u2014 "),Rk=n(m3e,"A",{href:!0});var zGr=s(Rk);FWe=r(zGr,"MT5Config"),zGr.forEach(t),TWe=r(m3e," (mT5 model)"),m3e.forEach(t),MWe=i(y),Tm=n(y,"LI",{});var g3e=s(Tm);Poe=n(g3e,"STRONG",{});var WGr=s(Poe);EWe=r(WGr,"nystromformer"),WGr.forEach(t),CWe=r(g3e," \u2014 "),Pk=n(g3e,"A",{href:!0});var QGr=s(Pk);wWe=r(QGr,"NystromformerConfig"),QGr.forEach(t),AWe=r(g3e," (Nystromformer model)"),g3e.forEach(t),yWe=i(y),Mm=n(y,"LI",{});var h3e=s(Mm);Boe=n(h3e,"STRONG",{});var HGr=s(Boe);LWe=r(HGr,"openai-gpt"),HGr.forEach(t),xWe=r(h3e," \u2014 "),Bk=n(h3e,"A",{href:!0});var UGr=s(Bk);$We=r(UGr,"OpenAIGPTConfig"),UGr.forEach(t),kWe=r(h3e," (OpenAI GPT model)"),h3e.forEach(t),SWe=i(y),Em=n(y,"LI",{});var p3e=s(Em);Ioe=n(p3e,"STRONG",{});var JGr=s(Ioe);RWe=r(JGr,"opt"),JGr.forEach(t),PWe=r(p3e," \u2014 "),Ik=n(p3e,"A",{href:!0});var YGr=s(Ik);BWe=r(YGr,"OPTConfig"),YGr.forEach(t),IWe=r(p3e," (OPT model)"),p3e.forEach(t),qWe=i(y),Cm=n(y,"LI",{});var u3e=s(Cm);qoe=n(u3e,"STRONG",{});var KGr=s(qoe);NWe=r(KGr,"pegasus"),KGr.forEach(t),jWe=r(u3e," \u2014 "),qk=n(u3e,"A",{href:!0});var ZGr=s(qk);DWe=r(ZGr,"PegasusConfig"),ZGr.forEach(t),GWe=r(u3e," (Pegasus model)"),u3e.forEach(t),OWe=i(y),wm=n(y,"LI",{});var _3e=s(wm);Noe=n(_3e,"STRONG",{});var eOr=s(Noe);VWe=r(eOr,"perceiver"),eOr.forEach(t),XWe=r(_3e," \u2014 "),Nk=n(_3e,"A",{href:!0});var oOr=s(Nk);zWe=r(oOr,"PerceiverConfig"),oOr.forEach(t),WWe=r(_3e," (Perceiver model)"),_3e.forEach(t),QWe=i(y),Am=n(y,"LI",{});var b3e=s(Am);joe=n(b3e,"STRONG",{});var rOr=s(joe);HWe=r(rOr,"plbart"),rOr.forEach(t),UWe=r(b3e," \u2014 "),jk=n(b3e,"A",{href:!0});var tOr=s(jk);JWe=r(tOr,"PLBartConfig"),tOr.forEach(t),YWe=r(b3e," (PLBart model)"),b3e.forEach(t),KWe=i(y),ym=n(y,"LI",{});var v3e=s(ym);Doe=n(v3e,"STRONG",{});var aOr=s(Doe);ZWe=r(aOr,"poolformer"),aOr.forEach(t),eQe=r(v3e," \u2014 "),Dk=n(v3e,"A",{href:!0});var nOr=s(Dk);oQe=r(nOr,"PoolFormerConfig"),nOr.forEach(t),rQe=r(v3e," (PoolFormer model)"),v3e.forEach(t),tQe=i(y),Lm=n(y,"LI",{});var F3e=s(Lm);Goe=n(F3e,"STRONG",{});var sOr=s(Goe);aQe=r(sOr,"prophetnet"),sOr.forEach(t),nQe=r(F3e," \u2014 "),Gk=n(F3e,"A",{href:!0});var lOr=s(Gk);sQe=r(lOr,"ProphetNetConfig"),lOr.forEach(t),lQe=r(F3e," (ProphetNet model)"),F3e.forEach(t),iQe=i(y),xm=n(y,"LI",{});var T3e=s(xm);Ooe=n(T3e,"STRONG",{});var iOr=s(Ooe);dQe=r(iOr,"qdqbert"),iOr.forEach(t),cQe=r(T3e," \u2014 "),Ok=n(T3e,"A",{href:!0});var dOr=s(Ok);fQe=r(dOr,"QDQBertConfig"),dOr.forEach(t),mQe=r(T3e," (QDQBert model)"),T3e.forEach(t),gQe=i(y),$m=n(y,"LI",{});var M3e=s($m);Voe=n(M3e,"STRONG",{});var cOr=s(Voe);hQe=r(cOr,"rag"),cOr.forEach(t),pQe=r(M3e," \u2014 "),Vk=n(M3e,"A",{href:!0});var fOr=s(Vk);uQe=r(fOr,"RagConfig"),fOr.forEach(t),_Qe=r(M3e," (RAG model)"),M3e.forEach(t),bQe=i(y),km=n(y,"LI",{});var E3e=s(km);Xoe=n(E3e,"STRONG",{});var mOr=s(Xoe);vQe=r(mOr,"realm"),mOr.forEach(t),FQe=r(E3e," \u2014 "),Xk=n(E3e,"A",{href:!0});var gOr=s(Xk);TQe=r(gOr,"RealmConfig"),gOr.forEach(t),MQe=r(E3e," (Realm model)"),E3e.forEach(t),EQe=i(y),Sm=n(y,"LI",{});var C3e=s(Sm);zoe=n(C3e,"STRONG",{});var hOr=s(zoe);CQe=r(hOr,"reformer"),hOr.forEach(t),wQe=r(C3e," \u2014 "),zk=n(C3e,"A",{href:!0});var pOr=s(zk);AQe=r(pOr,"ReformerConfig"),pOr.forEach(t),yQe=r(C3e," (Reformer model)"),C3e.forEach(t),LQe=i(y),Rm=n(y,"LI",{});var w3e=s(Rm);Woe=n(w3e,"STRONG",{});var uOr=s(Woe);xQe=r(uOr,"regnet"),uOr.forEach(t),$Qe=r(w3e," \u2014 "),Wk=n(w3e,"A",{href:!0});var _Or=s(Wk);kQe=r(_Or,"RegNetConfig"),_Or.forEach(t),SQe=r(w3e," (RegNet model)"),w3e.forEach(t),RQe=i(y),Pm=n(y,"LI",{});var A3e=s(Pm);Qoe=n(A3e,"STRONG",{});var bOr=s(Qoe);PQe=r(bOr,"rembert"),bOr.forEach(t),BQe=r(A3e," \u2014 "),Qk=n(A3e,"A",{href:!0});var vOr=s(Qk);IQe=r(vOr,"RemBertConfig"),vOr.forEach(t),qQe=r(A3e," (RemBERT model)"),A3e.forEach(t),NQe=i(y),Bm=n(y,"LI",{});var y3e=s(Bm);Hoe=n(y3e,"STRONG",{});var FOr=s(Hoe);jQe=r(FOr,"resnet"),FOr.forEach(t),DQe=r(y3e," \u2014 "),Hk=n(y3e,"A",{href:!0});var TOr=s(Hk);GQe=r(TOr,"ResNetConfig"),TOr.forEach(t),OQe=r(y3e," (ResNet model)"),y3e.forEach(t),VQe=i(y),Im=n(y,"LI",{});var L3e=s(Im);Uoe=n(L3e,"STRONG",{});var MOr=s(Uoe);XQe=r(MOr,"retribert"),MOr.forEach(t),zQe=r(L3e," \u2014 "),Uk=n(L3e,"A",{href:!0});var EOr=s(Uk);WQe=r(EOr,"RetriBertConfig"),EOr.forEach(t),QQe=r(L3e," (RetriBERT model)"),L3e.forEach(t),HQe=i(y),qm=n(y,"LI",{});var x3e=s(qm);Joe=n(x3e,"STRONG",{});var COr=s(Joe);UQe=r(COr,"roberta"),COr.forEach(t),JQe=r(x3e," \u2014 "),Jk=n(x3e,"A",{href:!0});var wOr=s(Jk);YQe=r(wOr,"RobertaConfig"),wOr.forEach(t),KQe=r(x3e," (RoBERTa model)"),x3e.forEach(t),ZQe=i(y),Nm=n(y,"LI",{});var $3e=s(Nm);Yoe=n($3e,"STRONG",{});var AOr=s(Yoe);eHe=r(AOr,"roformer"),AOr.forEach(t),oHe=r($3e," \u2014 "),Yk=n($3e,"A",{href:!0});var yOr=s(Yk);rHe=r(yOr,"RoFormerConfig"),yOr.forEach(t),tHe=r($3e," (RoFormer model)"),$3e.forEach(t),aHe=i(y),jm=n(y,"LI",{});var k3e=s(jm);Koe=n(k3e,"STRONG",{});var LOr=s(Koe);nHe=r(LOr,"segformer"),LOr.forEach(t),sHe=r(k3e," \u2014 "),Kk=n(k3e,"A",{href:!0});var xOr=s(Kk);lHe=r(xOr,"SegformerConfig"),xOr.forEach(t),iHe=r(k3e," (SegFormer model)"),k3e.forEach(t),dHe=i(y),Dm=n(y,"LI",{});var S3e=s(Dm);Zoe=n(S3e,"STRONG",{});var $Or=s(Zoe);cHe=r($Or,"sew"),$Or.forEach(t),fHe=r(S3e," \u2014 "),Zk=n(S3e,"A",{href:!0});var kOr=s(Zk);mHe=r(kOr,"SEWConfig"),kOr.forEach(t),gHe=r(S3e," (SEW model)"),S3e.forEach(t),hHe=i(y),Gm=n(y,"LI",{});var R3e=s(Gm);ere=n(R3e,"STRONG",{});var SOr=s(ere);pHe=r(SOr,"sew-d"),SOr.forEach(t),uHe=r(R3e," \u2014 "),eS=n(R3e,"A",{href:!0});var ROr=s(eS);_He=r(ROr,"SEWDConfig"),ROr.forEach(t),bHe=r(R3e," (SEW-D model)"),R3e.forEach(t),vHe=i(y),Om=n(y,"LI",{});var P3e=s(Om);ore=n(P3e,"STRONG",{});var POr=s(ore);FHe=r(POr,"speech-encoder-decoder"),POr.forEach(t),THe=r(P3e," \u2014 "),oS=n(P3e,"A",{href:!0});var BOr=s(oS);MHe=r(BOr,"SpeechEncoderDecoderConfig"),BOr.forEach(t),EHe=r(P3e," (Speech Encoder decoder model)"),P3e.forEach(t),CHe=i(y),Vm=n(y,"LI",{});var B3e=s(Vm);rre=n(B3e,"STRONG",{});var IOr=s(rre);wHe=r(IOr,"speech_to_text"),IOr.forEach(t),AHe=r(B3e," \u2014 "),rS=n(B3e,"A",{href:!0});var qOr=s(rS);yHe=r(qOr,"Speech2TextConfig"),qOr.forEach(t),LHe=r(B3e," (Speech2Text model)"),B3e.forEach(t),xHe=i(y),Xm=n(y,"LI",{});var I3e=s(Xm);tre=n(I3e,"STRONG",{});var NOr=s(tre);$He=r(NOr,"speech_to_text_2"),NOr.forEach(t),kHe=r(I3e," \u2014 "),tS=n(I3e,"A",{href:!0});var jOr=s(tS);SHe=r(jOr,"Speech2Text2Config"),jOr.forEach(t),RHe=r(I3e," (Speech2Text2 model)"),I3e.forEach(t),PHe=i(y),zm=n(y,"LI",{});var q3e=s(zm);are=n(q3e,"STRONG",{});var DOr=s(are);BHe=r(DOr,"splinter"),DOr.forEach(t),IHe=r(q3e," \u2014 "),aS=n(q3e,"A",{href:!0});var GOr=s(aS);qHe=r(GOr,"SplinterConfig"),GOr.forEach(t),NHe=r(q3e," (Splinter model)"),q3e.forEach(t),jHe=i(y),Wm=n(y,"LI",{});var N3e=s(Wm);nre=n(N3e,"STRONG",{});var OOr=s(nre);DHe=r(OOr,"squeezebert"),OOr.forEach(t),GHe=r(N3e," \u2014 "),nS=n(N3e,"A",{href:!0});var VOr=s(nS);OHe=r(VOr,"SqueezeBertConfig"),VOr.forEach(t),VHe=r(N3e," (SqueezeBERT model)"),N3e.forEach(t),XHe=i(y),Qm=n(y,"LI",{});var j3e=s(Qm);sre=n(j3e,"STRONG",{});var XOr=s(sre);zHe=r(XOr,"swin"),XOr.forEach(t),WHe=r(j3e," \u2014 "),sS=n(j3e,"A",{href:!0});var zOr=s(sS);QHe=r(zOr,"SwinConfig"),zOr.forEach(t),HHe=r(j3e," (Swin model)"),j3e.forEach(t),UHe=i(y),Hm=n(y,"LI",{});var D3e=s(Hm);lre=n(D3e,"STRONG",{});var WOr=s(lre);JHe=r(WOr,"t5"),WOr.forEach(t),YHe=r(D3e," \u2014 "),lS=n(D3e,"A",{href:!0});var QOr=s(lS);KHe=r(QOr,"T5Config"),QOr.forEach(t),ZHe=r(D3e," (T5 model)"),D3e.forEach(t),eUe=i(y),Um=n(y,"LI",{});var G3e=s(Um);ire=n(G3e,"STRONG",{});var HOr=s(ire);oUe=r(HOr,"tapas"),HOr.forEach(t),rUe=r(G3e," \u2014 "),iS=n(G3e,"A",{href:!0});var UOr=s(iS);tUe=r(UOr,"TapasConfig"),UOr.forEach(t),aUe=r(G3e," (TAPAS model)"),G3e.forEach(t),nUe=i(y),Jm=n(y,"LI",{});var O3e=s(Jm);dre=n(O3e,"STRONG",{});var JOr=s(dre);sUe=r(JOr,"transfo-xl"),JOr.forEach(t),lUe=r(O3e," \u2014 "),dS=n(O3e,"A",{href:!0});var YOr=s(dS);iUe=r(YOr,"TransfoXLConfig"),YOr.forEach(t),dUe=r(O3e," (Transformer-XL model)"),O3e.forEach(t),cUe=i(y),Ym=n(y,"LI",{});var V3e=s(Ym);cre=n(V3e,"STRONG",{});var KOr=s(cre);fUe=r(KOr,"trocr"),KOr.forEach(t),mUe=r(V3e," \u2014 "),cS=n(V3e,"A",{href:!0});var ZOr=s(cS);gUe=r(ZOr,"TrOCRConfig"),ZOr.forEach(t),hUe=r(V3e," (TrOCR model)"),V3e.forEach(t),pUe=i(y),Km=n(y,"LI",{});var X3e=s(Km);fre=n(X3e,"STRONG",{});var eVr=s(fre);uUe=r(eVr,"unispeech"),eVr.forEach(t),_Ue=r(X3e," \u2014 "),fS=n(X3e,"A",{href:!0});var oVr=s(fS);bUe=r(oVr,"UniSpeechConfig"),oVr.forEach(t),vUe=r(X3e," (UniSpeech model)"),X3e.forEach(t),FUe=i(y),Zm=n(y,"LI",{});var z3e=s(Zm);mre=n(z3e,"STRONG",{});var rVr=s(mre);TUe=r(rVr,"unispeech-sat"),rVr.forEach(t),MUe=r(z3e," \u2014 "),mS=n(z3e,"A",{href:!0});var tVr=s(mS);EUe=r(tVr,"UniSpeechSatConfig"),tVr.forEach(t),CUe=r(z3e," (UniSpeechSat model)"),z3e.forEach(t),wUe=i(y),eg=n(y,"LI",{});var W3e=s(eg);gre=n(W3e,"STRONG",{});var aVr=s(gre);AUe=r(aVr,"van"),aVr.forEach(t),yUe=r(W3e," \u2014 "),gS=n(W3e,"A",{href:!0});var nVr=s(gS);LUe=r(nVr,"VanConfig"),nVr.forEach(t),xUe=r(W3e," (VAN model)"),W3e.forEach(t),$Ue=i(y),og=n(y,"LI",{});var Q3e=s(og);hre=n(Q3e,"STRONG",{});var sVr=s(hre);kUe=r(sVr,"vilt"),sVr.forEach(t),SUe=r(Q3e," \u2014 "),hS=n(Q3e,"A",{href:!0});var lVr=s(hS);RUe=r(lVr,"ViltConfig"),lVr.forEach(t),PUe=r(Q3e," (ViLT model)"),Q3e.forEach(t),BUe=i(y),rg=n(y,"LI",{});var H3e=s(rg);pre=n(H3e,"STRONG",{});var iVr=s(pre);IUe=r(iVr,"vision-encoder-decoder"),iVr.forEach(t),qUe=r(H3e," \u2014 "),pS=n(H3e,"A",{href:!0});var dVr=s(pS);NUe=r(dVr,"VisionEncoderDecoderConfig"),dVr.forEach(t),jUe=r(H3e," (Vision Encoder decoder model)"),H3e.forEach(t),DUe=i(y),tg=n(y,"LI",{});var U3e=s(tg);ure=n(U3e,"STRONG",{});var cVr=s(ure);GUe=r(cVr,"vision-text-dual-encoder"),cVr.forEach(t),OUe=r(U3e," \u2014 "),uS=n(U3e,"A",{href:!0});var fVr=s(uS);VUe=r(fVr,"VisionTextDualEncoderConfig"),fVr.forEach(t),XUe=r(U3e," (VisionTextDualEncoder model)"),U3e.forEach(t),zUe=i(y),ag=n(y,"LI",{});var J3e=s(ag);_re=n(J3e,"STRONG",{});var mVr=s(_re);WUe=r(mVr,"visual_bert"),mVr.forEach(t),QUe=r(J3e," \u2014 "),_S=n(J3e,"A",{href:!0});var gVr=s(_S);HUe=r(gVr,"VisualBertConfig"),gVr.forEach(t),UUe=r(J3e," (VisualBert model)"),J3e.forEach(t),JUe=i(y),ng=n(y,"LI",{});var Y3e=s(ng);bre=n(Y3e,"STRONG",{});var hVr=s(bre);YUe=r(hVr,"vit"),hVr.forEach(t),KUe=r(Y3e," \u2014 "),bS=n(Y3e,"A",{href:!0});var pVr=s(bS);ZUe=r(pVr,"ViTConfig"),pVr.forEach(t),eJe=r(Y3e," (ViT model)"),Y3e.forEach(t),oJe=i(y),sg=n(y,"LI",{});var K3e=s(sg);vre=n(K3e,"STRONG",{});var uVr=s(vre);rJe=r(uVr,"vit_mae"),uVr.forEach(t),tJe=r(K3e," \u2014 "),vS=n(K3e,"A",{href:!0});var _Vr=s(vS);aJe=r(_Vr,"ViTMAEConfig"),_Vr.forEach(t),nJe=r(K3e," (ViTMAE model)"),K3e.forEach(t),sJe=i(y),lg=n(y,"LI",{});var Z3e=s(lg);Fre=n(Z3e,"STRONG",{});var bVr=s(Fre);lJe=r(bVr,"wav2vec2"),bVr.forEach(t),iJe=r(Z3e," \u2014 "),FS=n(Z3e,"A",{href:!0});var vVr=s(FS);dJe=r(vVr,"Wav2Vec2Config"),vVr.forEach(t),cJe=r(Z3e," (Wav2Vec2 model)"),Z3e.forEach(t),fJe=i(y),ig=n(y,"LI",{});var ewe=s(ig);Tre=n(ewe,"STRONG",{});var FVr=s(Tre);mJe=r(FVr,"wav2vec2-conformer"),FVr.forEach(t),gJe=r(ewe," \u2014 "),TS=n(ewe,"A",{href:!0});var TVr=s(TS);hJe=r(TVr,"Wav2Vec2ConformerConfig"),TVr.forEach(t),pJe=r(ewe," (Wav2Vec2-Conformer model)"),ewe.forEach(t),uJe=i(y),dg=n(y,"LI",{});var owe=s(dg);Mre=n(owe,"STRONG",{});var MVr=s(Mre);_Je=r(MVr,"wavlm"),MVr.forEach(t),bJe=r(owe," \u2014 "),MS=n(owe,"A",{href:!0});var EVr=s(MS);vJe=r(EVr,"WavLMConfig"),EVr.forEach(t),FJe=r(owe," (WavLM model)"),owe.forEach(t),TJe=i(y),cg=n(y,"LI",{});var rwe=s(cg);Ere=n(rwe,"STRONG",{});var CVr=s(Ere);MJe=r(CVr,"xglm"),CVr.forEach(t),EJe=r(rwe," \u2014 "),ES=n(rwe,"A",{href:!0});var wVr=s(ES);CJe=r(wVr,"XGLMConfig"),wVr.forEach(t),wJe=r(rwe," (XGLM model)"),rwe.forEach(t),AJe=i(y),fg=n(y,"LI",{});var twe=s(fg);Cre=n(twe,"STRONG",{});var AVr=s(Cre);yJe=r(AVr,"xlm"),AVr.forEach(t),LJe=r(twe," \u2014 "),CS=n(twe,"A",{href:!0});var yVr=s(CS);xJe=r(yVr,"XLMConfig"),yVr.forEach(t),$Je=r(twe," (XLM model)"),twe.forEach(t),kJe=i(y),mg=n(y,"LI",{});var awe=s(mg);wre=n(awe,"STRONG",{});var LVr=s(wre);SJe=r(LVr,"xlm-prophetnet"),LVr.forEach(t),RJe=r(awe," \u2014 "),wS=n(awe,"A",{href:!0});var xVr=s(wS);PJe=r(xVr,"XLMProphetNetConfig"),xVr.forEach(t),BJe=r(awe," (XLMProphetNet model)"),awe.forEach(t),IJe=i(y),gg=n(y,"LI",{});var nwe=s(gg);Are=n(nwe,"STRONG",{});var $Vr=s(Are);qJe=r($Vr,"xlm-roberta"),$Vr.forEach(t),NJe=r(nwe," \u2014 "),AS=n(nwe,"A",{href:!0});var kVr=s(AS);jJe=r(kVr,"XLMRobertaConfig"),kVr.forEach(t),DJe=r(nwe," (XLM-RoBERTa model)"),nwe.forEach(t),GJe=i(y),hg=n(y,"LI",{});var swe=s(hg);yre=n(swe,"STRONG",{});var SVr=s(yre);OJe=r(SVr,"xlm-roberta-xl"),SVr.forEach(t),VJe=r(swe," \u2014 "),yS=n(swe,"A",{href:!0});var RVr=s(yS);XJe=r(RVr,"XLMRobertaXLConfig"),RVr.forEach(t),zJe=r(swe," (XLM-RoBERTa-XL model)"),swe.forEach(t),WJe=i(y),pg=n(y,"LI",{});var lwe=s(pg);Lre=n(lwe,"STRONG",{});var PVr=s(Lre);QJe=r(PVr,"xlnet"),PVr.forEach(t),HJe=r(lwe," \u2014 "),LS=n(lwe,"A",{href:!0});var BVr=s(LS);UJe=r(BVr,"XLNetConfig"),BVr.forEach(t),JJe=r(lwe," (XLNet model)"),lwe.forEach(t),YJe=i(y),ug=n(y,"LI",{});var iwe=s(ug);xre=n(iwe,"STRONG",{});var IVr=s(xre);KJe=r(IVr,"yolos"),IVr.forEach(t),ZJe=r(iwe," \u2014 "),xS=n(iwe,"A",{href:!0});var qVr=s(xS);eYe=r(qVr,"YolosConfig"),qVr.forEach(t),oYe=r(iwe," (YOLOS model)"),iwe.forEach(t),rYe=i(y),_g=n(y,"LI",{});var dwe=s(_g);$re=n(dwe,"STRONG",{});var NVr=s($re);tYe=r(NVr,"yoso"),NVr.forEach(t),aYe=r(dwe," \u2014 "),$S=n(dwe,"A",{href:!0});var jVr=s($S);nYe=r(jVr,"YosoConfig"),jVr.forEach(t),sYe=r(dwe," (YOSO model)"),dwe.forEach(t),y.forEach(t),lYe=i(ot),T(bg.$$.fragment,ot),ot.forEach(t),iYe=i(et),vg=n(et,"DIV",{class:!0});var GNe=s(vg);T(_6.$$.fragment,GNe),dYe=i(GNe),kre=n(GNe,"P",{});var DVr=s(kre);cYe=r(DVr,"Register a new configuration for this class."),DVr.forEach(t),GNe.forEach(t),et.forEach(t),XIe=i(f),Fi=n(f,"H2",{class:!0});var ONe=s(Fi);Fg=n(ONe,"A",{id:!0,class:!0,href:!0});var GVr=s(Fg);Sre=n(GVr,"SPAN",{});var OVr=s(Sre);T(b6.$$.fragment,OVr),OVr.forEach(t),GVr.forEach(t),fYe=i(ONe),Rre=n(ONe,"SPAN",{});var VVr=s(Rre);mYe=r(VVr,"AutoTokenizer"),VVr.forEach(t),ONe.forEach(t),zIe=i(f),wo=n(f,"DIV",{class:!0});var Is=s(wo);T(v6.$$.fragment,Is),gYe=i(Is),F6=n(Is,"P",{});var VNe=s(F6);hYe=r(VNe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),kS=n(VNe,"A",{href:!0});var XVr=s(kS);pYe=r(XVr,"AutoTokenizer.from_pretrained()"),XVr.forEach(t),uYe=r(VNe," class method."),VNe.forEach(t),_Ye=i(Is),T6=n(Is,"P",{});var XNe=s(T6);bYe=r(XNe,"This class cannot be instantiated directly using "),Pre=n(XNe,"CODE",{});var zVr=s(Pre);vYe=r(zVr,"__init__()"),zVr.forEach(t),FYe=r(XNe," (throws an error)."),XNe.forEach(t),TYe=i(Is),Cr=n(Is,"DIV",{class:!0});var qs=s(Cr);T(M6.$$.fragment,qs),MYe=i(qs),Bre=n(qs,"P",{});var WVr=s(Bre);EYe=r(WVr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),WVr.forEach(t),CYe=i(qs),Aa=n(qs,"P",{});var mA=s(Aa);wYe=r(mA,"The tokenizer class to instantiate is selected based on the "),Ire=n(mA,"CODE",{});var QVr=s(Ire);AYe=r(QVr,"model_type"),QVr.forEach(t),yYe=r(mA,` property of the config object (either
passed as an argument or loaded from `),qre=n(mA,"CODE",{});var HVr=s(qre);LYe=r(HVr,"pretrained_model_name_or_path"),HVr.forEach(t),xYe=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nre=n(mA,"CODE",{});var UVr=s(Nre);$Ye=r(UVr,"pretrained_model_name_or_path"),UVr.forEach(t),kYe=r(mA,":"),mA.forEach(t),SYe=i(qs),k=n(qs,"UL",{});var S=s(k);Sn=n(S,"LI",{});var E9=s(Sn);jre=n(E9,"STRONG",{});var JVr=s(jre);RYe=r(JVr,"albert"),JVr.forEach(t),PYe=r(E9," \u2014 "),SS=n(E9,"A",{href:!0});var YVr=s(SS);BYe=r(YVr,"AlbertTokenizer"),YVr.forEach(t),IYe=r(E9," or "),RS=n(E9,"A",{href:!0});var KVr=s(RS);qYe=r(KVr,"AlbertTokenizerFast"),KVr.forEach(t),NYe=r(E9," (ALBERT model)"),E9.forEach(t),jYe=i(S),Rn=n(S,"LI",{});var C9=s(Rn);Dre=n(C9,"STRONG",{});var ZVr=s(Dre);DYe=r(ZVr,"bart"),ZVr.forEach(t),GYe=r(C9," \u2014 "),PS=n(C9,"A",{href:!0});var eXr=s(PS);OYe=r(eXr,"BartTokenizer"),eXr.forEach(t),VYe=r(C9," or "),BS=n(C9,"A",{href:!0});var oXr=s(BS);XYe=r(oXr,"BartTokenizerFast"),oXr.forEach(t),zYe=r(C9," (BART model)"),C9.forEach(t),WYe=i(S),Pn=n(S,"LI",{});var w9=s(Pn);Gre=n(w9,"STRONG",{});var rXr=s(Gre);QYe=r(rXr,"barthez"),rXr.forEach(t),HYe=r(w9," \u2014 "),IS=n(w9,"A",{href:!0});var tXr=s(IS);UYe=r(tXr,"BarthezTokenizer"),tXr.forEach(t),JYe=r(w9," or "),qS=n(w9,"A",{href:!0});var aXr=s(qS);YYe=r(aXr,"BarthezTokenizerFast"),aXr.forEach(t),KYe=r(w9," (BARThez model)"),w9.forEach(t),ZYe=i(S),Tg=n(S,"LI",{});var cwe=s(Tg);Ore=n(cwe,"STRONG",{});var nXr=s(Ore);eKe=r(nXr,"bartpho"),nXr.forEach(t),oKe=r(cwe," \u2014 "),NS=n(cwe,"A",{href:!0});var sXr=s(NS);rKe=r(sXr,"BartphoTokenizer"),sXr.forEach(t),tKe=r(cwe," (BARTpho model)"),cwe.forEach(t),aKe=i(S),Bn=n(S,"LI",{});var A9=s(Bn);Vre=n(A9,"STRONG",{});var lXr=s(Vre);nKe=r(lXr,"bert"),lXr.forEach(t),sKe=r(A9," \u2014 "),jS=n(A9,"A",{href:!0});var iXr=s(jS);lKe=r(iXr,"BertTokenizer"),iXr.forEach(t),iKe=r(A9," or "),DS=n(A9,"A",{href:!0});var dXr=s(DS);dKe=r(dXr,"BertTokenizerFast"),dXr.forEach(t),cKe=r(A9," (BERT model)"),A9.forEach(t),fKe=i(S),Mg=n(S,"LI",{});var fwe=s(Mg);Xre=n(fwe,"STRONG",{});var cXr=s(Xre);mKe=r(cXr,"bert-generation"),cXr.forEach(t),gKe=r(fwe," \u2014 "),GS=n(fwe,"A",{href:!0});var fXr=s(GS);hKe=r(fXr,"BertGenerationTokenizer"),fXr.forEach(t),pKe=r(fwe," (Bert Generation model)"),fwe.forEach(t),uKe=i(S),Eg=n(S,"LI",{});var mwe=s(Eg);zre=n(mwe,"STRONG",{});var mXr=s(zre);_Ke=r(mXr,"bert-japanese"),mXr.forEach(t),bKe=r(mwe," \u2014 "),OS=n(mwe,"A",{href:!0});var gXr=s(OS);vKe=r(gXr,"BertJapaneseTokenizer"),gXr.forEach(t),FKe=r(mwe," (BertJapanese model)"),mwe.forEach(t),TKe=i(S),Cg=n(S,"LI",{});var gwe=s(Cg);Wre=n(gwe,"STRONG",{});var hXr=s(Wre);MKe=r(hXr,"bertweet"),hXr.forEach(t),EKe=r(gwe," \u2014 "),VS=n(gwe,"A",{href:!0});var pXr=s(VS);CKe=r(pXr,"BertweetTokenizer"),pXr.forEach(t),wKe=r(gwe," (Bertweet model)"),gwe.forEach(t),AKe=i(S),In=n(S,"LI",{});var y9=s(In);Qre=n(y9,"STRONG",{});var uXr=s(Qre);yKe=r(uXr,"big_bird"),uXr.forEach(t),LKe=r(y9," \u2014 "),XS=n(y9,"A",{href:!0});var _Xr=s(XS);xKe=r(_Xr,"BigBirdTokenizer"),_Xr.forEach(t),$Ke=r(y9," or "),zS=n(y9,"A",{href:!0});var bXr=s(zS);kKe=r(bXr,"BigBirdTokenizerFast"),bXr.forEach(t),SKe=r(y9," (BigBird model)"),y9.forEach(t),RKe=i(S),qn=n(S,"LI",{});var L9=s(qn);Hre=n(L9,"STRONG",{});var vXr=s(Hre);PKe=r(vXr,"bigbird_pegasus"),vXr.forEach(t),BKe=r(L9," \u2014 "),WS=n(L9,"A",{href:!0});var FXr=s(WS);IKe=r(FXr,"PegasusTokenizer"),FXr.forEach(t),qKe=r(L9," or "),QS=n(L9,"A",{href:!0});var TXr=s(QS);NKe=r(TXr,"PegasusTokenizerFast"),TXr.forEach(t),jKe=r(L9," (BigBirdPegasus model)"),L9.forEach(t),DKe=i(S),Nn=n(S,"LI",{});var x9=s(Nn);Ure=n(x9,"STRONG",{});var MXr=s(Ure);GKe=r(MXr,"blenderbot"),MXr.forEach(t),OKe=r(x9," \u2014 "),HS=n(x9,"A",{href:!0});var EXr=s(HS);VKe=r(EXr,"BlenderbotTokenizer"),EXr.forEach(t),XKe=r(x9," or "),US=n(x9,"A",{href:!0});var CXr=s(US);zKe=r(CXr,"BlenderbotTokenizerFast"),CXr.forEach(t),WKe=r(x9," (Blenderbot model)"),x9.forEach(t),QKe=i(S),wg=n(S,"LI",{});var hwe=s(wg);Jre=n(hwe,"STRONG",{});var wXr=s(Jre);HKe=r(wXr,"blenderbot-small"),wXr.forEach(t),UKe=r(hwe," \u2014 "),JS=n(hwe,"A",{href:!0});var AXr=s(JS);JKe=r(AXr,"BlenderbotSmallTokenizer"),AXr.forEach(t),YKe=r(hwe," (BlenderbotSmall model)"),hwe.forEach(t),KKe=i(S),Ag=n(S,"LI",{});var pwe=s(Ag);Yre=n(pwe,"STRONG",{});var yXr=s(Yre);ZKe=r(yXr,"byt5"),yXr.forEach(t),eZe=r(pwe," \u2014 "),YS=n(pwe,"A",{href:!0});var LXr=s(YS);oZe=r(LXr,"ByT5Tokenizer"),LXr.forEach(t),rZe=r(pwe," (ByT5 model)"),pwe.forEach(t),tZe=i(S),jn=n(S,"LI",{});var $9=s(jn);Kre=n($9,"STRONG",{});var xXr=s(Kre);aZe=r(xXr,"camembert"),xXr.forEach(t),nZe=r($9," \u2014 "),KS=n($9,"A",{href:!0});var $Xr=s(KS);sZe=r($Xr,"CamembertTokenizer"),$Xr.forEach(t),lZe=r($9," or "),ZS=n($9,"A",{href:!0});var kXr=s(ZS);iZe=r(kXr,"CamembertTokenizerFast"),kXr.forEach(t),dZe=r($9," (CamemBERT model)"),$9.forEach(t),cZe=i(S),yg=n(S,"LI",{});var uwe=s(yg);Zre=n(uwe,"STRONG",{});var SXr=s(Zre);fZe=r(SXr,"canine"),SXr.forEach(t),mZe=r(uwe," \u2014 "),eR=n(uwe,"A",{href:!0});var RXr=s(eR);gZe=r(RXr,"CanineTokenizer"),RXr.forEach(t),hZe=r(uwe," (Canine model)"),uwe.forEach(t),pZe=i(S),Dn=n(S,"LI",{});var k9=s(Dn);ete=n(k9,"STRONG",{});var PXr=s(ete);uZe=r(PXr,"clip"),PXr.forEach(t),_Ze=r(k9," \u2014 "),oR=n(k9,"A",{href:!0});var BXr=s(oR);bZe=r(BXr,"CLIPTokenizer"),BXr.forEach(t),vZe=r(k9," or "),rR=n(k9,"A",{href:!0});var IXr=s(rR);FZe=r(IXr,"CLIPTokenizerFast"),IXr.forEach(t),TZe=r(k9," (CLIP model)"),k9.forEach(t),MZe=i(S),Gn=n(S,"LI",{});var S9=s(Gn);ote=n(S9,"STRONG",{});var qXr=s(ote);EZe=r(qXr,"convbert"),qXr.forEach(t),CZe=r(S9," \u2014 "),tR=n(S9,"A",{href:!0});var NXr=s(tR);wZe=r(NXr,"ConvBertTokenizer"),NXr.forEach(t),AZe=r(S9," or "),aR=n(S9,"A",{href:!0});var jXr=s(aR);yZe=r(jXr,"ConvBertTokenizerFast"),jXr.forEach(t),LZe=r(S9," (ConvBERT model)"),S9.forEach(t),xZe=i(S),On=n(S,"LI",{});var R9=s(On);rte=n(R9,"STRONG",{});var DXr=s(rte);$Ze=r(DXr,"cpm"),DXr.forEach(t),kZe=r(R9," \u2014 "),nR=n(R9,"A",{href:!0});var GXr=s(nR);SZe=r(GXr,"CpmTokenizer"),GXr.forEach(t),RZe=r(R9," or "),sR=n(R9,"A",{href:!0});var OXr=s(sR);PZe=r(OXr,"CpmTokenizerFast"),OXr.forEach(t),BZe=r(R9," (CPM model)"),R9.forEach(t),IZe=i(S),Lg=n(S,"LI",{});var _we=s(Lg);tte=n(_we,"STRONG",{});var VXr=s(tte);qZe=r(VXr,"ctrl"),VXr.forEach(t),NZe=r(_we," \u2014 "),lR=n(_we,"A",{href:!0});var XXr=s(lR);jZe=r(XXr,"CTRLTokenizer"),XXr.forEach(t),DZe=r(_we," (CTRL model)"),_we.forEach(t),GZe=i(S),Vn=n(S,"LI",{});var P9=s(Vn);ate=n(P9,"STRONG",{});var zXr=s(ate);OZe=r(zXr,"data2vec-text"),zXr.forEach(t),VZe=r(P9," \u2014 "),iR=n(P9,"A",{href:!0});var WXr=s(iR);XZe=r(WXr,"RobertaTokenizer"),WXr.forEach(t),zZe=r(P9," or "),dR=n(P9,"A",{href:!0});var QXr=s(dR);WZe=r(QXr,"RobertaTokenizerFast"),QXr.forEach(t),QZe=r(P9," (Data2VecText model)"),P9.forEach(t),HZe=i(S),Xn=n(S,"LI",{});var B9=s(Xn);nte=n(B9,"STRONG",{});var HXr=s(nte);UZe=r(HXr,"deberta"),HXr.forEach(t),JZe=r(B9," \u2014 "),cR=n(B9,"A",{href:!0});var UXr=s(cR);YZe=r(UXr,"DebertaTokenizer"),UXr.forEach(t),KZe=r(B9," or "),fR=n(B9,"A",{href:!0});var JXr=s(fR);ZZe=r(JXr,"DebertaTokenizerFast"),JXr.forEach(t),eeo=r(B9," (DeBERTa model)"),B9.forEach(t),oeo=i(S),zn=n(S,"LI",{});var I9=s(zn);ste=n(I9,"STRONG",{});var YXr=s(ste);reo=r(YXr,"deberta-v2"),YXr.forEach(t),teo=r(I9," \u2014 "),mR=n(I9,"A",{href:!0});var KXr=s(mR);aeo=r(KXr,"DebertaV2Tokenizer"),KXr.forEach(t),neo=r(I9," or "),gR=n(I9,"A",{href:!0});var ZXr=s(gR);seo=r(ZXr,"DebertaV2TokenizerFast"),ZXr.forEach(t),leo=r(I9," (DeBERTa-v2 model)"),I9.forEach(t),ieo=i(S),Wn=n(S,"LI",{});var q9=s(Wn);lte=n(q9,"STRONG",{});var ezr=s(lte);deo=r(ezr,"distilbert"),ezr.forEach(t),ceo=r(q9," \u2014 "),hR=n(q9,"A",{href:!0});var ozr=s(hR);feo=r(ozr,"DistilBertTokenizer"),ozr.forEach(t),meo=r(q9," or "),pR=n(q9,"A",{href:!0});var rzr=s(pR);geo=r(rzr,"DistilBertTokenizerFast"),rzr.forEach(t),heo=r(q9," (DistilBERT model)"),q9.forEach(t),peo=i(S),Qn=n(S,"LI",{});var N9=s(Qn);ite=n(N9,"STRONG",{});var tzr=s(ite);ueo=r(tzr,"dpr"),tzr.forEach(t),_eo=r(N9," \u2014 "),uR=n(N9,"A",{href:!0});var azr=s(uR);beo=r(azr,"DPRQuestionEncoderTokenizer"),azr.forEach(t),veo=r(N9," or "),_R=n(N9,"A",{href:!0});var nzr=s(_R);Feo=r(nzr,"DPRQuestionEncoderTokenizerFast"),nzr.forEach(t),Teo=r(N9," (DPR model)"),N9.forEach(t),Meo=i(S),Hn=n(S,"LI",{});var j9=s(Hn);dte=n(j9,"STRONG",{});var szr=s(dte);Eeo=r(szr,"electra"),szr.forEach(t),Ceo=r(j9," \u2014 "),bR=n(j9,"A",{href:!0});var lzr=s(bR);weo=r(lzr,"ElectraTokenizer"),lzr.forEach(t),Aeo=r(j9," or "),vR=n(j9,"A",{href:!0});var izr=s(vR);yeo=r(izr,"ElectraTokenizerFast"),izr.forEach(t),Leo=r(j9," (ELECTRA model)"),j9.forEach(t),xeo=i(S),xg=n(S,"LI",{});var bwe=s(xg);cte=n(bwe,"STRONG",{});var dzr=s(cte);$eo=r(dzr,"flaubert"),dzr.forEach(t),keo=r(bwe," \u2014 "),FR=n(bwe,"A",{href:!0});var czr=s(FR);Seo=r(czr,"FlaubertTokenizer"),czr.forEach(t),Reo=r(bwe," (FlauBERT model)"),bwe.forEach(t),Peo=i(S),Un=n(S,"LI",{});var D9=s(Un);fte=n(D9,"STRONG",{});var fzr=s(fte);Beo=r(fzr,"fnet"),fzr.forEach(t),Ieo=r(D9," \u2014 "),TR=n(D9,"A",{href:!0});var mzr=s(TR);qeo=r(mzr,"FNetTokenizer"),mzr.forEach(t),Neo=r(D9," or "),MR=n(D9,"A",{href:!0});var gzr=s(MR);jeo=r(gzr,"FNetTokenizerFast"),gzr.forEach(t),Deo=r(D9," (FNet model)"),D9.forEach(t),Geo=i(S),$g=n(S,"LI",{});var vwe=s($g);mte=n(vwe,"STRONG",{});var hzr=s(mte);Oeo=r(hzr,"fsmt"),hzr.forEach(t),Veo=r(vwe," \u2014 "),ER=n(vwe,"A",{href:!0});var pzr=s(ER);Xeo=r(pzr,"FSMTTokenizer"),pzr.forEach(t),zeo=r(vwe," (FairSeq Machine-Translation model)"),vwe.forEach(t),Weo=i(S),Jn=n(S,"LI",{});var G9=s(Jn);gte=n(G9,"STRONG",{});var uzr=s(gte);Qeo=r(uzr,"funnel"),uzr.forEach(t),Heo=r(G9," \u2014 "),CR=n(G9,"A",{href:!0});var _zr=s(CR);Ueo=r(_zr,"FunnelTokenizer"),_zr.forEach(t),Jeo=r(G9," or "),wR=n(G9,"A",{href:!0});var bzr=s(wR);Yeo=r(bzr,"FunnelTokenizerFast"),bzr.forEach(t),Keo=r(G9," (Funnel Transformer model)"),G9.forEach(t),Zeo=i(S),Yn=n(S,"LI",{});var O9=s(Yn);hte=n(O9,"STRONG",{});var vzr=s(hte);eoo=r(vzr,"gpt2"),vzr.forEach(t),ooo=r(O9," \u2014 "),AR=n(O9,"A",{href:!0});var Fzr=s(AR);roo=r(Fzr,"GPT2Tokenizer"),Fzr.forEach(t),too=r(O9," or "),yR=n(O9,"A",{href:!0});var Tzr=s(yR);aoo=r(Tzr,"GPT2TokenizerFast"),Tzr.forEach(t),noo=r(O9," (OpenAI GPT-2 model)"),O9.forEach(t),soo=i(S),Kn=n(S,"LI",{});var V9=s(Kn);pte=n(V9,"STRONG",{});var Mzr=s(pte);loo=r(Mzr,"gpt_neo"),Mzr.forEach(t),ioo=r(V9," \u2014 "),LR=n(V9,"A",{href:!0});var Ezr=s(LR);doo=r(Ezr,"GPT2Tokenizer"),Ezr.forEach(t),coo=r(V9," or "),xR=n(V9,"A",{href:!0});var Czr=s(xR);foo=r(Czr,"GPT2TokenizerFast"),Czr.forEach(t),moo=r(V9," (GPT Neo model)"),V9.forEach(t),goo=i(S),Zn=n(S,"LI",{});var X9=s(Zn);ute=n(X9,"STRONG",{});var wzr=s(ute);hoo=r(wzr,"gptj"),wzr.forEach(t),poo=r(X9," \u2014 "),$R=n(X9,"A",{href:!0});var Azr=s($R);uoo=r(Azr,"GPT2Tokenizer"),Azr.forEach(t),_oo=r(X9," or "),kR=n(X9,"A",{href:!0});var yzr=s(kR);boo=r(yzr,"GPT2TokenizerFast"),yzr.forEach(t),voo=r(X9," (GPT-J model)"),X9.forEach(t),Foo=i(S),es=n(S,"LI",{});var z9=s(es);_te=n(z9,"STRONG",{});var Lzr=s(_te);Too=r(Lzr,"herbert"),Lzr.forEach(t),Moo=r(z9," \u2014 "),SR=n(z9,"A",{href:!0});var xzr=s(SR);Eoo=r(xzr,"HerbertTokenizer"),xzr.forEach(t),Coo=r(z9," or "),RR=n(z9,"A",{href:!0});var $zr=s(RR);woo=r($zr,"HerbertTokenizerFast"),$zr.forEach(t),Aoo=r(z9," (HerBERT model)"),z9.forEach(t),yoo=i(S),kg=n(S,"LI",{});var Fwe=s(kg);bte=n(Fwe,"STRONG",{});var kzr=s(bte);Loo=r(kzr,"hubert"),kzr.forEach(t),xoo=r(Fwe," \u2014 "),PR=n(Fwe,"A",{href:!0});var Szr=s(PR);$oo=r(Szr,"Wav2Vec2CTCTokenizer"),Szr.forEach(t),koo=r(Fwe," (Hubert model)"),Fwe.forEach(t),Soo=i(S),os=n(S,"LI",{});var W9=s(os);vte=n(W9,"STRONG",{});var Rzr=s(vte);Roo=r(Rzr,"ibert"),Rzr.forEach(t),Poo=r(W9," \u2014 "),BR=n(W9,"A",{href:!0});var Pzr=s(BR);Boo=r(Pzr,"RobertaTokenizer"),Pzr.forEach(t),Ioo=r(W9," or "),IR=n(W9,"A",{href:!0});var Bzr=s(IR);qoo=r(Bzr,"RobertaTokenizerFast"),Bzr.forEach(t),Noo=r(W9," (I-BERT model)"),W9.forEach(t),joo=i(S),rs=n(S,"LI",{});var Q9=s(rs);Fte=n(Q9,"STRONG",{});var Izr=s(Fte);Doo=r(Izr,"layoutlm"),Izr.forEach(t),Goo=r(Q9," \u2014 "),qR=n(Q9,"A",{href:!0});var qzr=s(qR);Ooo=r(qzr,"LayoutLMTokenizer"),qzr.forEach(t),Voo=r(Q9," or "),NR=n(Q9,"A",{href:!0});var Nzr=s(NR);Xoo=r(Nzr,"LayoutLMTokenizerFast"),Nzr.forEach(t),zoo=r(Q9," (LayoutLM model)"),Q9.forEach(t),Woo=i(S),ts=n(S,"LI",{});var H9=s(ts);Tte=n(H9,"STRONG",{});var jzr=s(Tte);Qoo=r(jzr,"layoutlmv2"),jzr.forEach(t),Hoo=r(H9," \u2014 "),jR=n(H9,"A",{href:!0});var Dzr=s(jR);Uoo=r(Dzr,"LayoutLMv2Tokenizer"),Dzr.forEach(t),Joo=r(H9," or "),DR=n(H9,"A",{href:!0});var Gzr=s(DR);Yoo=r(Gzr,"LayoutLMv2TokenizerFast"),Gzr.forEach(t),Koo=r(H9," (LayoutLMv2 model)"),H9.forEach(t),Zoo=i(S),as=n(S,"LI",{});var U9=s(as);Mte=n(U9,"STRONG",{});var Ozr=s(Mte);ero=r(Ozr,"layoutxlm"),Ozr.forEach(t),oro=r(U9," \u2014 "),GR=n(U9,"A",{href:!0});var Vzr=s(GR);rro=r(Vzr,"LayoutXLMTokenizer"),Vzr.forEach(t),tro=r(U9," or "),OR=n(U9,"A",{href:!0});var Xzr=s(OR);aro=r(Xzr,"LayoutXLMTokenizerFast"),Xzr.forEach(t),nro=r(U9," (LayoutXLM model)"),U9.forEach(t),sro=i(S),ns=n(S,"LI",{});var J9=s(ns);Ete=n(J9,"STRONG",{});var zzr=s(Ete);lro=r(zzr,"led"),zzr.forEach(t),iro=r(J9," \u2014 "),VR=n(J9,"A",{href:!0});var Wzr=s(VR);dro=r(Wzr,"LEDTokenizer"),Wzr.forEach(t),cro=r(J9," or "),XR=n(J9,"A",{href:!0});var Qzr=s(XR);fro=r(Qzr,"LEDTokenizerFast"),Qzr.forEach(t),mro=r(J9," (LED model)"),J9.forEach(t),gro=i(S),ss=n(S,"LI",{});var Y9=s(ss);Cte=n(Y9,"STRONG",{});var Hzr=s(Cte);hro=r(Hzr,"longformer"),Hzr.forEach(t),pro=r(Y9," \u2014 "),zR=n(Y9,"A",{href:!0});var Uzr=s(zR);uro=r(Uzr,"LongformerTokenizer"),Uzr.forEach(t),_ro=r(Y9," or "),WR=n(Y9,"A",{href:!0});var Jzr=s(WR);bro=r(Jzr,"LongformerTokenizerFast"),Jzr.forEach(t),vro=r(Y9," (Longformer model)"),Y9.forEach(t),Fro=i(S),Sg=n(S,"LI",{});var Twe=s(Sg);wte=n(Twe,"STRONG",{});var Yzr=s(wte);Tro=r(Yzr,"luke"),Yzr.forEach(t),Mro=r(Twe," \u2014 "),QR=n(Twe,"A",{href:!0});var Kzr=s(QR);Ero=r(Kzr,"LukeTokenizer"),Kzr.forEach(t),Cro=r(Twe," (LUKE model)"),Twe.forEach(t),wro=i(S),ls=n(S,"LI",{});var K9=s(ls);Ate=n(K9,"STRONG",{});var Zzr=s(Ate);Aro=r(Zzr,"lxmert"),Zzr.forEach(t),yro=r(K9," \u2014 "),HR=n(K9,"A",{href:!0});var eWr=s(HR);Lro=r(eWr,"LxmertTokenizer"),eWr.forEach(t),xro=r(K9," or "),UR=n(K9,"A",{href:!0});var oWr=s(UR);$ro=r(oWr,"LxmertTokenizerFast"),oWr.forEach(t),kro=r(K9," (LXMERT model)"),K9.forEach(t),Sro=i(S),Rg=n(S,"LI",{});var Mwe=s(Rg);yte=n(Mwe,"STRONG",{});var rWr=s(yte);Rro=r(rWr,"m2m_100"),rWr.forEach(t),Pro=r(Mwe," \u2014 "),JR=n(Mwe,"A",{href:!0});var tWr=s(JR);Bro=r(tWr,"M2M100Tokenizer"),tWr.forEach(t),Iro=r(Mwe," (M2M100 model)"),Mwe.forEach(t),qro=i(S),Pg=n(S,"LI",{});var Ewe=s(Pg);Lte=n(Ewe,"STRONG",{});var aWr=s(Lte);Nro=r(aWr,"marian"),aWr.forEach(t),jro=r(Ewe," \u2014 "),YR=n(Ewe,"A",{href:!0});var nWr=s(YR);Dro=r(nWr,"MarianTokenizer"),nWr.forEach(t),Gro=r(Ewe," (Marian model)"),Ewe.forEach(t),Oro=i(S),is=n(S,"LI",{});var Z9=s(is);xte=n(Z9,"STRONG",{});var sWr=s(xte);Vro=r(sWr,"mbart"),sWr.forEach(t),Xro=r(Z9," \u2014 "),KR=n(Z9,"A",{href:!0});var lWr=s(KR);zro=r(lWr,"MBartTokenizer"),lWr.forEach(t),Wro=r(Z9," or "),ZR=n(Z9,"A",{href:!0});var iWr=s(ZR);Qro=r(iWr,"MBartTokenizerFast"),iWr.forEach(t),Hro=r(Z9," (mBART model)"),Z9.forEach(t),Uro=i(S),ds=n(S,"LI",{});var e$=s(ds);$te=n(e$,"STRONG",{});var dWr=s($te);Jro=r(dWr,"mbart50"),dWr.forEach(t),Yro=r(e$," \u2014 "),eP=n(e$,"A",{href:!0});var cWr=s(eP);Kro=r(cWr,"MBart50Tokenizer"),cWr.forEach(t),Zro=r(e$," or "),oP=n(e$,"A",{href:!0});var fWr=s(oP);eto=r(fWr,"MBart50TokenizerFast"),fWr.forEach(t),oto=r(e$," (mBART-50 model)"),e$.forEach(t),rto=i(S),cs=n(S,"LI",{});var o$=s(cs);kte=n(o$,"STRONG",{});var mWr=s(kte);tto=r(mWr,"megatron-bert"),mWr.forEach(t),ato=r(o$," \u2014 "),rP=n(o$,"A",{href:!0});var gWr=s(rP);nto=r(gWr,"BertTokenizer"),gWr.forEach(t),sto=r(o$," or "),tP=n(o$,"A",{href:!0});var hWr=s(tP);lto=r(hWr,"BertTokenizerFast"),hWr.forEach(t),ito=r(o$," (MegatronBert model)"),o$.forEach(t),dto=i(S),Bg=n(S,"LI",{});var Cwe=s(Bg);Ste=n(Cwe,"STRONG",{});var pWr=s(Ste);cto=r(pWr,"mluke"),pWr.forEach(t),fto=r(Cwe," \u2014 "),aP=n(Cwe,"A",{href:!0});var uWr=s(aP);mto=r(uWr,"MLukeTokenizer"),uWr.forEach(t),gto=r(Cwe," (mLUKE model)"),Cwe.forEach(t),hto=i(S),fs=n(S,"LI",{});var r$=s(fs);Rte=n(r$,"STRONG",{});var _Wr=s(Rte);pto=r(_Wr,"mobilebert"),_Wr.forEach(t),uto=r(r$," \u2014 "),nP=n(r$,"A",{href:!0});var bWr=s(nP);_to=r(bWr,"MobileBertTokenizer"),bWr.forEach(t),bto=r(r$," or "),sP=n(r$,"A",{href:!0});var vWr=s(sP);vto=r(vWr,"MobileBertTokenizerFast"),vWr.forEach(t),Fto=r(r$," (MobileBERT model)"),r$.forEach(t),Tto=i(S),ms=n(S,"LI",{});var t$=s(ms);Pte=n(t$,"STRONG",{});var FWr=s(Pte);Mto=r(FWr,"mpnet"),FWr.forEach(t),Eto=r(t$," \u2014 "),lP=n(t$,"A",{href:!0});var TWr=s(lP);Cto=r(TWr,"MPNetTokenizer"),TWr.forEach(t),wto=r(t$," or "),iP=n(t$,"A",{href:!0});var MWr=s(iP);Ato=r(MWr,"MPNetTokenizerFast"),MWr.forEach(t),yto=r(t$," (MPNet model)"),t$.forEach(t),Lto=i(S),gs=n(S,"LI",{});var a$=s(gs);Bte=n(a$,"STRONG",{});var EWr=s(Bte);xto=r(EWr,"mt5"),EWr.forEach(t),$to=r(a$," \u2014 "),dP=n(a$,"A",{href:!0});var CWr=s(dP);kto=r(CWr,"MT5Tokenizer"),CWr.forEach(t),Sto=r(a$," or "),cP=n(a$,"A",{href:!0});var wWr=s(cP);Rto=r(wWr,"MT5TokenizerFast"),wWr.forEach(t),Pto=r(a$," (mT5 model)"),a$.forEach(t),Bto=i(S),hs=n(S,"LI",{});var n$=s(hs);Ite=n(n$,"STRONG",{});var AWr=s(Ite);Ito=r(AWr,"nystromformer"),AWr.forEach(t),qto=r(n$," \u2014 "),fP=n(n$,"A",{href:!0});var yWr=s(fP);Nto=r(yWr,"AlbertTokenizer"),yWr.forEach(t),jto=r(n$," or "),mP=n(n$,"A",{href:!0});var LWr=s(mP);Dto=r(LWr,"AlbertTokenizerFast"),LWr.forEach(t),Gto=r(n$," (Nystromformer model)"),n$.forEach(t),Oto=i(S),ps=n(S,"LI",{});var s$=s(ps);qte=n(s$,"STRONG",{});var xWr=s(qte);Vto=r(xWr,"openai-gpt"),xWr.forEach(t),Xto=r(s$," \u2014 "),gP=n(s$,"A",{href:!0});var $Wr=s(gP);zto=r($Wr,"OpenAIGPTTokenizer"),$Wr.forEach(t),Wto=r(s$," or "),hP=n(s$,"A",{href:!0});var kWr=s(hP);Qto=r(kWr,"OpenAIGPTTokenizerFast"),kWr.forEach(t),Hto=r(s$," (OpenAI GPT model)"),s$.forEach(t),Uto=i(S),Ig=n(S,"LI",{});var wwe=s(Ig);Nte=n(wwe,"STRONG",{});var SWr=s(Nte);Jto=r(SWr,"opt"),SWr.forEach(t),Yto=r(wwe," \u2014 "),pP=n(wwe,"A",{href:!0});var RWr=s(pP);Kto=r(RWr,"GPT2Tokenizer"),RWr.forEach(t),Zto=r(wwe," (OPT model)"),wwe.forEach(t),eao=i(S),us=n(S,"LI",{});var l$=s(us);jte=n(l$,"STRONG",{});var PWr=s(jte);oao=r(PWr,"pegasus"),PWr.forEach(t),rao=r(l$," \u2014 "),uP=n(l$,"A",{href:!0});var BWr=s(uP);tao=r(BWr,"PegasusTokenizer"),BWr.forEach(t),aao=r(l$," or "),_P=n(l$,"A",{href:!0});var IWr=s(_P);nao=r(IWr,"PegasusTokenizerFast"),IWr.forEach(t),sao=r(l$," (Pegasus model)"),l$.forEach(t),lao=i(S),qg=n(S,"LI",{});var Awe=s(qg);Dte=n(Awe,"STRONG",{});var qWr=s(Dte);iao=r(qWr,"perceiver"),qWr.forEach(t),dao=r(Awe," \u2014 "),bP=n(Awe,"A",{href:!0});var NWr=s(bP);cao=r(NWr,"PerceiverTokenizer"),NWr.forEach(t),fao=r(Awe," (Perceiver model)"),Awe.forEach(t),mao=i(S),Ng=n(S,"LI",{});var ywe=s(Ng);Gte=n(ywe,"STRONG",{});var jWr=s(Gte);gao=r(jWr,"phobert"),jWr.forEach(t),hao=r(ywe," \u2014 "),vP=n(ywe,"A",{href:!0});var DWr=s(vP);pao=r(DWr,"PhobertTokenizer"),DWr.forEach(t),uao=r(ywe," (PhoBERT model)"),ywe.forEach(t),_ao=i(S),jg=n(S,"LI",{});var Lwe=s(jg);Ote=n(Lwe,"STRONG",{});var GWr=s(Ote);bao=r(GWr,"plbart"),GWr.forEach(t),vao=r(Lwe," \u2014 "),FP=n(Lwe,"A",{href:!0});var OWr=s(FP);Fao=r(OWr,"PLBartTokenizer"),OWr.forEach(t),Tao=r(Lwe," (PLBart model)"),Lwe.forEach(t),Mao=i(S),Dg=n(S,"LI",{});var xwe=s(Dg);Vte=n(xwe,"STRONG",{});var VWr=s(Vte);Eao=r(VWr,"prophetnet"),VWr.forEach(t),Cao=r(xwe," \u2014 "),TP=n(xwe,"A",{href:!0});var XWr=s(TP);wao=r(XWr,"ProphetNetTokenizer"),XWr.forEach(t),Aao=r(xwe," (ProphetNet model)"),xwe.forEach(t),yao=i(S),_s=n(S,"LI",{});var i$=s(_s);Xte=n(i$,"STRONG",{});var zWr=s(Xte);Lao=r(zWr,"qdqbert"),zWr.forEach(t),xao=r(i$," \u2014 "),MP=n(i$,"A",{href:!0});var WWr=s(MP);$ao=r(WWr,"BertTokenizer"),WWr.forEach(t),kao=r(i$," or "),EP=n(i$,"A",{href:!0});var QWr=s(EP);Sao=r(QWr,"BertTokenizerFast"),QWr.forEach(t),Rao=r(i$," (QDQBert model)"),i$.forEach(t),Pao=i(S),Gg=n(S,"LI",{});var $we=s(Gg);zte=n($we,"STRONG",{});var HWr=s(zte);Bao=r(HWr,"rag"),HWr.forEach(t),Iao=r($we," \u2014 "),CP=n($we,"A",{href:!0});var UWr=s(CP);qao=r(UWr,"RagTokenizer"),UWr.forEach(t),Nao=r($we," (RAG model)"),$we.forEach(t),jao=i(S),bs=n(S,"LI",{});var d$=s(bs);Wte=n(d$,"STRONG",{});var JWr=s(Wte);Dao=r(JWr,"realm"),JWr.forEach(t),Gao=r(d$," \u2014 "),wP=n(d$,"A",{href:!0});var YWr=s(wP);Oao=r(YWr,"RealmTokenizer"),YWr.forEach(t),Vao=r(d$," or "),AP=n(d$,"A",{href:!0});var KWr=s(AP);Xao=r(KWr,"RealmTokenizerFast"),KWr.forEach(t),zao=r(d$," (Realm model)"),d$.forEach(t),Wao=i(S),vs=n(S,"LI",{});var c$=s(vs);Qte=n(c$,"STRONG",{});var ZWr=s(Qte);Qao=r(ZWr,"reformer"),ZWr.forEach(t),Hao=r(c$," \u2014 "),yP=n(c$,"A",{href:!0});var eQr=s(yP);Uao=r(eQr,"ReformerTokenizer"),eQr.forEach(t),Jao=r(c$," or "),LP=n(c$,"A",{href:!0});var oQr=s(LP);Yao=r(oQr,"ReformerTokenizerFast"),oQr.forEach(t),Kao=r(c$," (Reformer model)"),c$.forEach(t),Zao=i(S),Fs=n(S,"LI",{});var f$=s(Fs);Hte=n(f$,"STRONG",{});var rQr=s(Hte);eno=r(rQr,"rembert"),rQr.forEach(t),ono=r(f$," \u2014 "),xP=n(f$,"A",{href:!0});var tQr=s(xP);rno=r(tQr,"RemBertTokenizer"),tQr.forEach(t),tno=r(f$," or "),$P=n(f$,"A",{href:!0});var aQr=s($P);ano=r(aQr,"RemBertTokenizerFast"),aQr.forEach(t),nno=r(f$," (RemBERT model)"),f$.forEach(t),sno=i(S),Ts=n(S,"LI",{});var m$=s(Ts);Ute=n(m$,"STRONG",{});var nQr=s(Ute);lno=r(nQr,"retribert"),nQr.forEach(t),ino=r(m$," \u2014 "),kP=n(m$,"A",{href:!0});var sQr=s(kP);dno=r(sQr,"RetriBertTokenizer"),sQr.forEach(t),cno=r(m$," or "),SP=n(m$,"A",{href:!0});var lQr=s(SP);fno=r(lQr,"RetriBertTokenizerFast"),lQr.forEach(t),mno=r(m$," (RetriBERT model)"),m$.forEach(t),gno=i(S),Ms=n(S,"LI",{});var g$=s(Ms);Jte=n(g$,"STRONG",{});var iQr=s(Jte);hno=r(iQr,"roberta"),iQr.forEach(t),pno=r(g$," \u2014 "),RP=n(g$,"A",{href:!0});var dQr=s(RP);uno=r(dQr,"RobertaTokenizer"),dQr.forEach(t),_no=r(g$," or "),PP=n(g$,"A",{href:!0});var cQr=s(PP);bno=r(cQr,"RobertaTokenizerFast"),cQr.forEach(t),vno=r(g$," (RoBERTa model)"),g$.forEach(t),Fno=i(S),Es=n(S,"LI",{});var h$=s(Es);Yte=n(h$,"STRONG",{});var fQr=s(Yte);Tno=r(fQr,"roformer"),fQr.forEach(t),Mno=r(h$," \u2014 "),BP=n(h$,"A",{href:!0});var mQr=s(BP);Eno=r(mQr,"RoFormerTokenizer"),mQr.forEach(t),Cno=r(h$," or "),IP=n(h$,"A",{href:!0});var gQr=s(IP);wno=r(gQr,"RoFormerTokenizerFast"),gQr.forEach(t),Ano=r(h$," (RoFormer model)"),h$.forEach(t),yno=i(S),Og=n(S,"LI",{});var kwe=s(Og);Kte=n(kwe,"STRONG",{});var hQr=s(Kte);Lno=r(hQr,"speech_to_text"),hQr.forEach(t),xno=r(kwe," \u2014 "),qP=n(kwe,"A",{href:!0});var pQr=s(qP);$no=r(pQr,"Speech2TextTokenizer"),pQr.forEach(t),kno=r(kwe," (Speech2Text model)"),kwe.forEach(t),Sno=i(S),Vg=n(S,"LI",{});var Swe=s(Vg);Zte=n(Swe,"STRONG",{});var uQr=s(Zte);Rno=r(uQr,"speech_to_text_2"),uQr.forEach(t),Pno=r(Swe," \u2014 "),NP=n(Swe,"A",{href:!0});var _Qr=s(NP);Bno=r(_Qr,"Speech2Text2Tokenizer"),_Qr.forEach(t),Ino=r(Swe," (Speech2Text2 model)"),Swe.forEach(t),qno=i(S),Cs=n(S,"LI",{});var p$=s(Cs);eae=n(p$,"STRONG",{});var bQr=s(eae);Nno=r(bQr,"splinter"),bQr.forEach(t),jno=r(p$," \u2014 "),jP=n(p$,"A",{href:!0});var vQr=s(jP);Dno=r(vQr,"SplinterTokenizer"),vQr.forEach(t),Gno=r(p$," or "),DP=n(p$,"A",{href:!0});var FQr=s(DP);Ono=r(FQr,"SplinterTokenizerFast"),FQr.forEach(t),Vno=r(p$," (Splinter model)"),p$.forEach(t),Xno=i(S),ws=n(S,"LI",{});var u$=s(ws);oae=n(u$,"STRONG",{});var TQr=s(oae);zno=r(TQr,"squeezebert"),TQr.forEach(t),Wno=r(u$," \u2014 "),GP=n(u$,"A",{href:!0});var MQr=s(GP);Qno=r(MQr,"SqueezeBertTokenizer"),MQr.forEach(t),Hno=r(u$," or "),OP=n(u$,"A",{href:!0});var EQr=s(OP);Uno=r(EQr,"SqueezeBertTokenizerFast"),EQr.forEach(t),Jno=r(u$," (SqueezeBERT model)"),u$.forEach(t),Yno=i(S),As=n(S,"LI",{});var _$=s(As);rae=n(_$,"STRONG",{});var CQr=s(rae);Kno=r(CQr,"t5"),CQr.forEach(t),Zno=r(_$," \u2014 "),VP=n(_$,"A",{href:!0});var wQr=s(VP);eso=r(wQr,"T5Tokenizer"),wQr.forEach(t),oso=r(_$," or "),XP=n(_$,"A",{href:!0});var AQr=s(XP);rso=r(AQr,"T5TokenizerFast"),AQr.forEach(t),tso=r(_$," (T5 model)"),_$.forEach(t),aso=i(S),Xg=n(S,"LI",{});var Rwe=s(Xg);tae=n(Rwe,"STRONG",{});var yQr=s(tae);nso=r(yQr,"tapas"),yQr.forEach(t),sso=r(Rwe," \u2014 "),zP=n(Rwe,"A",{href:!0});var LQr=s(zP);lso=r(LQr,"TapasTokenizer"),LQr.forEach(t),iso=r(Rwe," (TAPAS model)"),Rwe.forEach(t),dso=i(S),zg=n(S,"LI",{});var Pwe=s(zg);aae=n(Pwe,"STRONG",{});var xQr=s(aae);cso=r(xQr,"tapex"),xQr.forEach(t),fso=r(Pwe," \u2014 "),WP=n(Pwe,"A",{href:!0});var $Qr=s(WP);mso=r($Qr,"TapexTokenizer"),$Qr.forEach(t),gso=r(Pwe," (TAPEX model)"),Pwe.forEach(t),hso=i(S),Wg=n(S,"LI",{});var Bwe=s(Wg);nae=n(Bwe,"STRONG",{});var kQr=s(nae);pso=r(kQr,"transfo-xl"),kQr.forEach(t),uso=r(Bwe," \u2014 "),QP=n(Bwe,"A",{href:!0});var SQr=s(QP);_so=r(SQr,"TransfoXLTokenizer"),SQr.forEach(t),bso=r(Bwe," (Transformer-XL model)"),Bwe.forEach(t),vso=i(S),ys=n(S,"LI",{});var b$=s(ys);sae=n(b$,"STRONG",{});var RQr=s(sae);Fso=r(RQr,"visual_bert"),RQr.forEach(t),Tso=r(b$," \u2014 "),HP=n(b$,"A",{href:!0});var PQr=s(HP);Mso=r(PQr,"BertTokenizer"),PQr.forEach(t),Eso=r(b$," or "),UP=n(b$,"A",{href:!0});var BQr=s(UP);Cso=r(BQr,"BertTokenizerFast"),BQr.forEach(t),wso=r(b$," (VisualBert model)"),b$.forEach(t),Aso=i(S),Qg=n(S,"LI",{});var Iwe=s(Qg);lae=n(Iwe,"STRONG",{});var IQr=s(lae);yso=r(IQr,"wav2vec2"),IQr.forEach(t),Lso=r(Iwe," \u2014 "),JP=n(Iwe,"A",{href:!0});var qQr=s(JP);xso=r(qQr,"Wav2Vec2CTCTokenizer"),qQr.forEach(t),$so=r(Iwe," (Wav2Vec2 model)"),Iwe.forEach(t),kso=i(S),Hg=n(S,"LI",{});var qwe=s(Hg);iae=n(qwe,"STRONG",{});var NQr=s(iae);Sso=r(NQr,"wav2vec2-conformer"),NQr.forEach(t),Rso=r(qwe," \u2014 "),YP=n(qwe,"A",{href:!0});var jQr=s(YP);Pso=r(jQr,"Wav2Vec2CTCTokenizer"),jQr.forEach(t),Bso=r(qwe," (Wav2Vec2-Conformer model)"),qwe.forEach(t),Iso=i(S),Ug=n(S,"LI",{});var Nwe=s(Ug);dae=n(Nwe,"STRONG",{});var DQr=s(dae);qso=r(DQr,"wav2vec2_phoneme"),DQr.forEach(t),Nso=r(Nwe," \u2014 "),KP=n(Nwe,"A",{href:!0});var GQr=s(KP);jso=r(GQr,"Wav2Vec2PhonemeCTCTokenizer"),GQr.forEach(t),Dso=r(Nwe," (Wav2Vec2Phoneme model)"),Nwe.forEach(t),Gso=i(S),Ls=n(S,"LI",{});var v$=s(Ls);cae=n(v$,"STRONG",{});var OQr=s(cae);Oso=r(OQr,"xglm"),OQr.forEach(t),Vso=r(v$," \u2014 "),ZP=n(v$,"A",{href:!0});var VQr=s(ZP);Xso=r(VQr,"XGLMTokenizer"),VQr.forEach(t),zso=r(v$," or "),eB=n(v$,"A",{href:!0});var XQr=s(eB);Wso=r(XQr,"XGLMTokenizerFast"),XQr.forEach(t),Qso=r(v$," (XGLM model)"),v$.forEach(t),Hso=i(S),Jg=n(S,"LI",{});var jwe=s(Jg);fae=n(jwe,"STRONG",{});var zQr=s(fae);Uso=r(zQr,"xlm"),zQr.forEach(t),Jso=r(jwe," \u2014 "),oB=n(jwe,"A",{href:!0});var WQr=s(oB);Yso=r(WQr,"XLMTokenizer"),WQr.forEach(t),Kso=r(jwe," (XLM model)"),jwe.forEach(t),Zso=i(S),Yg=n(S,"LI",{});var Dwe=s(Yg);mae=n(Dwe,"STRONG",{});var QQr=s(mae);elo=r(QQr,"xlm-prophetnet"),QQr.forEach(t),olo=r(Dwe," \u2014 "),rB=n(Dwe,"A",{href:!0});var HQr=s(rB);rlo=r(HQr,"XLMProphetNetTokenizer"),HQr.forEach(t),tlo=r(Dwe," (XLMProphetNet model)"),Dwe.forEach(t),alo=i(S),xs=n(S,"LI",{});var F$=s(xs);gae=n(F$,"STRONG",{});var UQr=s(gae);nlo=r(UQr,"xlm-roberta"),UQr.forEach(t),slo=r(F$," \u2014 "),tB=n(F$,"A",{href:!0});var JQr=s(tB);llo=r(JQr,"XLMRobertaTokenizer"),JQr.forEach(t),ilo=r(F$," or "),aB=n(F$,"A",{href:!0});var YQr=s(aB);dlo=r(YQr,"XLMRobertaTokenizerFast"),YQr.forEach(t),clo=r(F$," (XLM-RoBERTa model)"),F$.forEach(t),flo=i(S),$s=n(S,"LI",{});var T$=s($s);hae=n(T$,"STRONG",{});var KQr=s(hae);mlo=r(KQr,"xlm-roberta-xl"),KQr.forEach(t),glo=r(T$," \u2014 "),nB=n(T$,"A",{href:!0});var ZQr=s(nB);hlo=r(ZQr,"RobertaTokenizer"),ZQr.forEach(t),plo=r(T$," or "),sB=n(T$,"A",{href:!0});var eHr=s(sB);ulo=r(eHr,"RobertaTokenizerFast"),eHr.forEach(t),_lo=r(T$," (XLM-RoBERTa-XL model)"),T$.forEach(t),blo=i(S),ks=n(S,"LI",{});var M$=s(ks);pae=n(M$,"STRONG",{});var oHr=s(pae);vlo=r(oHr,"xlnet"),oHr.forEach(t),Flo=r(M$," \u2014 "),lB=n(M$,"A",{href:!0});var rHr=s(lB);Tlo=r(rHr,"XLNetTokenizer"),rHr.forEach(t),Mlo=r(M$," or "),iB=n(M$,"A",{href:!0});var tHr=s(iB);Elo=r(tHr,"XLNetTokenizerFast"),tHr.forEach(t),Clo=r(M$," (XLNet model)"),M$.forEach(t),wlo=i(S),Ss=n(S,"LI",{});var E$=s(Ss);uae=n(E$,"STRONG",{});var aHr=s(uae);Alo=r(aHr,"yoso"),aHr.forEach(t),ylo=r(E$," \u2014 "),dB=n(E$,"A",{href:!0});var nHr=s(dB);Llo=r(nHr,"AlbertTokenizer"),nHr.forEach(t),xlo=r(E$," or "),cB=n(E$,"A",{href:!0});var sHr=s(cB);$lo=r(sHr,"AlbertTokenizerFast"),sHr.forEach(t),klo=r(E$," (YOSO model)"),E$.forEach(t),S.forEach(t),Slo=i(qs),T(Kg.$$.fragment,qs),qs.forEach(t),Rlo=i(Is),Zg=n(Is,"DIV",{class:!0});var zNe=s(Zg);T(E6.$$.fragment,zNe),Plo=i(zNe),_ae=n(zNe,"P",{});var lHr=s(_ae);Blo=r(lHr,"Register a new tokenizer in this mapping."),lHr.forEach(t),zNe.forEach(t),Is.forEach(t),WIe=i(f),Ti=n(f,"H2",{class:!0});var WNe=s(Ti);eh=n(WNe,"A",{id:!0,class:!0,href:!0});var iHr=s(eh);bae=n(iHr,"SPAN",{});var dHr=s(bae);T(C6.$$.fragment,dHr),dHr.forEach(t),iHr.forEach(t),Ilo=i(WNe),vae=n(WNe,"SPAN",{});var cHr=s(vae);qlo=r(cHr,"AutoFeatureExtractor"),cHr.forEach(t),WNe.forEach(t),QIe=i(f),Ao=n(f,"DIV",{class:!0});var Ns=s(Ao);T(w6.$$.fragment,Ns),Nlo=i(Ns),A6=n(Ns,"P",{});var QNe=s(A6);jlo=r(QNe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),fB=n(QNe,"A",{href:!0});var fHr=s(fB);Dlo=r(fHr,"AutoFeatureExtractor.from_pretrained()"),fHr.forEach(t),Glo=r(QNe," class method."),QNe.forEach(t),Olo=i(Ns),y6=n(Ns,"P",{});var HNe=s(y6);Vlo=r(HNe,"This class cannot be instantiated directly using "),Fae=n(HNe,"CODE",{});var mHr=s(Fae);Xlo=r(mHr,"__init__()"),mHr.forEach(t),zlo=r(HNe," (throws an error)."),HNe.forEach(t),Wlo=i(Ns),He=n(Ns,"DIV",{class:!0});var Zt=s(He);T(L6.$$.fragment,Zt),Qlo=i(Zt),Tae=n(Zt,"P",{});var gHr=s(Tae);Hlo=r(gHr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),gHr.forEach(t),Ulo=i(Zt),ya=n(Zt,"P",{});var gA=s(ya);Jlo=r(gA,"The feature extractor class to instantiate is selected based on the "),Mae=n(gA,"CODE",{});var hHr=s(Mae);Ylo=r(hHr,"model_type"),hHr.forEach(t),Klo=r(gA,` property of the config object
(either passed as an argument or loaded from `),Eae=n(gA,"CODE",{});var pHr=s(Eae);Zlo=r(pHr,"pretrained_model_name_or_path"),pHr.forEach(t),eio=r(gA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Cae=n(gA,"CODE",{});var uHr=s(Cae);oio=r(uHr,"pretrained_model_name_or_path"),uHr.forEach(t),rio=r(gA,":"),gA.forEach(t),tio=i(Zt),Z=n(Zt,"UL",{});var te=s(Z);oh=n(te,"LI",{});var Gwe=s(oh);wae=n(Gwe,"STRONG",{});var _Hr=s(wae);aio=r(_Hr,"beit"),_Hr.forEach(t),nio=r(Gwe," \u2014 "),mB=n(Gwe,"A",{href:!0});var bHr=s(mB);sio=r(bHr,"BeitFeatureExtractor"),bHr.forEach(t),lio=r(Gwe," (BEiT model)"),Gwe.forEach(t),iio=i(te),rh=n(te,"LI",{});var Owe=s(rh);Aae=n(Owe,"STRONG",{});var vHr=s(Aae);dio=r(vHr,"clip"),vHr.forEach(t),cio=r(Owe," \u2014 "),gB=n(Owe,"A",{href:!0});var FHr=s(gB);fio=r(FHr,"CLIPFeatureExtractor"),FHr.forEach(t),mio=r(Owe," (CLIP model)"),Owe.forEach(t),gio=i(te),th=n(te,"LI",{});var Vwe=s(th);yae=n(Vwe,"STRONG",{});var THr=s(yae);hio=r(THr,"convnext"),THr.forEach(t),pio=r(Vwe," \u2014 "),hB=n(Vwe,"A",{href:!0});var MHr=s(hB);uio=r(MHr,"ConvNextFeatureExtractor"),MHr.forEach(t),_io=r(Vwe," (ConvNext model)"),Vwe.forEach(t),bio=i(te),ah=n(te,"LI",{});var Xwe=s(ah);Lae=n(Xwe,"STRONG",{});var EHr=s(Lae);vio=r(EHr,"data2vec-audio"),EHr.forEach(t),Fio=r(Xwe," \u2014 "),pB=n(Xwe,"A",{href:!0});var CHr=s(pB);Tio=r(CHr,"Wav2Vec2FeatureExtractor"),CHr.forEach(t),Mio=r(Xwe," (Data2VecAudio model)"),Xwe.forEach(t),Eio=i(te),nh=n(te,"LI",{});var zwe=s(nh);xae=n(zwe,"STRONG",{});var wHr=s(xae);Cio=r(wHr,"data2vec-vision"),wHr.forEach(t),wio=r(zwe," \u2014 "),uB=n(zwe,"A",{href:!0});var AHr=s(uB);Aio=r(AHr,"BeitFeatureExtractor"),AHr.forEach(t),yio=r(zwe," (Data2VecVision model)"),zwe.forEach(t),Lio=i(te),sh=n(te,"LI",{});var Wwe=s(sh);$ae=n(Wwe,"STRONG",{});var yHr=s($ae);xio=r(yHr,"deit"),yHr.forEach(t),$io=r(Wwe," \u2014 "),_B=n(Wwe,"A",{href:!0});var LHr=s(_B);kio=r(LHr,"DeiTFeatureExtractor"),LHr.forEach(t),Sio=r(Wwe," (DeiT model)"),Wwe.forEach(t),Rio=i(te),lh=n(te,"LI",{});var Qwe=s(lh);kae=n(Qwe,"STRONG",{});var xHr=s(kae);Pio=r(xHr,"detr"),xHr.forEach(t),Bio=r(Qwe," \u2014 "),bB=n(Qwe,"A",{href:!0});var $Hr=s(bB);Iio=r($Hr,"DetrFeatureExtractor"),$Hr.forEach(t),qio=r(Qwe," (DETR model)"),Qwe.forEach(t),Nio=i(te),ih=n(te,"LI",{});var Hwe=s(ih);Sae=n(Hwe,"STRONG",{});var kHr=s(Sae);jio=r(kHr,"dpt"),kHr.forEach(t),Dio=r(Hwe," \u2014 "),vB=n(Hwe,"A",{href:!0});var SHr=s(vB);Gio=r(SHr,"DPTFeatureExtractor"),SHr.forEach(t),Oio=r(Hwe," (DPT model)"),Hwe.forEach(t),Vio=i(te),dh=n(te,"LI",{});var Uwe=s(dh);Rae=n(Uwe,"STRONG",{});var RHr=s(Rae);Xio=r(RHr,"flava"),RHr.forEach(t),zio=r(Uwe," \u2014 "),FB=n(Uwe,"A",{href:!0});var PHr=s(FB);Wio=r(PHr,"FlavaFeatureExtractor"),PHr.forEach(t),Qio=r(Uwe," (Flava model)"),Uwe.forEach(t),Hio=i(te),ch=n(te,"LI",{});var Jwe=s(ch);Pae=n(Jwe,"STRONG",{});var BHr=s(Pae);Uio=r(BHr,"glpn"),BHr.forEach(t),Jio=r(Jwe," \u2014 "),TB=n(Jwe,"A",{href:!0});var IHr=s(TB);Yio=r(IHr,"GLPNFeatureExtractor"),IHr.forEach(t),Kio=r(Jwe," (GLPN model)"),Jwe.forEach(t),Zio=i(te),fh=n(te,"LI",{});var Ywe=s(fh);Bae=n(Ywe,"STRONG",{});var qHr=s(Bae);edo=r(qHr,"hubert"),qHr.forEach(t),odo=r(Ywe," \u2014 "),MB=n(Ywe,"A",{href:!0});var NHr=s(MB);rdo=r(NHr,"Wav2Vec2FeatureExtractor"),NHr.forEach(t),tdo=r(Ywe," (Hubert model)"),Ywe.forEach(t),ado=i(te),mh=n(te,"LI",{});var Kwe=s(mh);Iae=n(Kwe,"STRONG",{});var jHr=s(Iae);ndo=r(jHr,"layoutlmv2"),jHr.forEach(t),sdo=r(Kwe," \u2014 "),EB=n(Kwe,"A",{href:!0});var DHr=s(EB);ldo=r(DHr,"LayoutLMv2FeatureExtractor"),DHr.forEach(t),ido=r(Kwe," (LayoutLMv2 model)"),Kwe.forEach(t),ddo=i(te),gh=n(te,"LI",{});var Zwe=s(gh);qae=n(Zwe,"STRONG",{});var GHr=s(qae);cdo=r(GHr,"maskformer"),GHr.forEach(t),fdo=r(Zwe," \u2014 "),CB=n(Zwe,"A",{href:!0});var OHr=s(CB);mdo=r(OHr,"MaskFormerFeatureExtractor"),OHr.forEach(t),gdo=r(Zwe," (MaskFormer model)"),Zwe.forEach(t),hdo=i(te),hh=n(te,"LI",{});var eAe=s(hh);Nae=n(eAe,"STRONG",{});var VHr=s(Nae);pdo=r(VHr,"perceiver"),VHr.forEach(t),udo=r(eAe," \u2014 "),wB=n(eAe,"A",{href:!0});var XHr=s(wB);_do=r(XHr,"PerceiverFeatureExtractor"),XHr.forEach(t),bdo=r(eAe," (Perceiver model)"),eAe.forEach(t),vdo=i(te),ph=n(te,"LI",{});var oAe=s(ph);jae=n(oAe,"STRONG",{});var zHr=s(jae);Fdo=r(zHr,"poolformer"),zHr.forEach(t),Tdo=r(oAe," \u2014 "),AB=n(oAe,"A",{href:!0});var WHr=s(AB);Mdo=r(WHr,"PoolFormerFeatureExtractor"),WHr.forEach(t),Edo=r(oAe," (PoolFormer model)"),oAe.forEach(t),Cdo=i(te),uh=n(te,"LI",{});var rAe=s(uh);Dae=n(rAe,"STRONG",{});var QHr=s(Dae);wdo=r(QHr,"regnet"),QHr.forEach(t),Ado=r(rAe," \u2014 "),yB=n(rAe,"A",{href:!0});var HHr=s(yB);ydo=r(HHr,"ConvNextFeatureExtractor"),HHr.forEach(t),Ldo=r(rAe," (RegNet model)"),rAe.forEach(t),xdo=i(te),_h=n(te,"LI",{});var tAe=s(_h);Gae=n(tAe,"STRONG",{});var UHr=s(Gae);$do=r(UHr,"resnet"),UHr.forEach(t),kdo=r(tAe," \u2014 "),LB=n(tAe,"A",{href:!0});var JHr=s(LB);Sdo=r(JHr,"ConvNextFeatureExtractor"),JHr.forEach(t),Rdo=r(tAe," (ResNet model)"),tAe.forEach(t),Pdo=i(te),bh=n(te,"LI",{});var aAe=s(bh);Oae=n(aAe,"STRONG",{});var YHr=s(Oae);Bdo=r(YHr,"segformer"),YHr.forEach(t),Ido=r(aAe," \u2014 "),xB=n(aAe,"A",{href:!0});var KHr=s(xB);qdo=r(KHr,"SegformerFeatureExtractor"),KHr.forEach(t),Ndo=r(aAe," (SegFormer model)"),aAe.forEach(t),jdo=i(te),vh=n(te,"LI",{});var nAe=s(vh);Vae=n(nAe,"STRONG",{});var ZHr=s(Vae);Ddo=r(ZHr,"speech_to_text"),ZHr.forEach(t),Gdo=r(nAe," \u2014 "),$B=n(nAe,"A",{href:!0});var eUr=s($B);Odo=r(eUr,"Speech2TextFeatureExtractor"),eUr.forEach(t),Vdo=r(nAe," (Speech2Text model)"),nAe.forEach(t),Xdo=i(te),Fh=n(te,"LI",{});var sAe=s(Fh);Xae=n(sAe,"STRONG",{});var oUr=s(Xae);zdo=r(oUr,"swin"),oUr.forEach(t),Wdo=r(sAe," \u2014 "),kB=n(sAe,"A",{href:!0});var rUr=s(kB);Qdo=r(rUr,"ViTFeatureExtractor"),rUr.forEach(t),Hdo=r(sAe," (Swin model)"),sAe.forEach(t),Udo=i(te),Th=n(te,"LI",{});var lAe=s(Th);zae=n(lAe,"STRONG",{});var tUr=s(zae);Jdo=r(tUr,"van"),tUr.forEach(t),Ydo=r(lAe," \u2014 "),SB=n(lAe,"A",{href:!0});var aUr=s(SB);Kdo=r(aUr,"ConvNextFeatureExtractor"),aUr.forEach(t),Zdo=r(lAe," (VAN model)"),lAe.forEach(t),eco=i(te),Mh=n(te,"LI",{});var iAe=s(Mh);Wae=n(iAe,"STRONG",{});var nUr=s(Wae);oco=r(nUr,"vit"),nUr.forEach(t),rco=r(iAe," \u2014 "),RB=n(iAe,"A",{href:!0});var sUr=s(RB);tco=r(sUr,"ViTFeatureExtractor"),sUr.forEach(t),aco=r(iAe," (ViT model)"),iAe.forEach(t),nco=i(te),Eh=n(te,"LI",{});var dAe=s(Eh);Qae=n(dAe,"STRONG",{});var lUr=s(Qae);sco=r(lUr,"vit_mae"),lUr.forEach(t),lco=r(dAe," \u2014 "),PB=n(dAe,"A",{href:!0});var iUr=s(PB);ico=r(iUr,"ViTFeatureExtractor"),iUr.forEach(t),dco=r(dAe," (ViTMAE model)"),dAe.forEach(t),cco=i(te),Ch=n(te,"LI",{});var cAe=s(Ch);Hae=n(cAe,"STRONG",{});var dUr=s(Hae);fco=r(dUr,"wav2vec2"),dUr.forEach(t),mco=r(cAe," \u2014 "),BB=n(cAe,"A",{href:!0});var cUr=s(BB);gco=r(cUr,"Wav2Vec2FeatureExtractor"),cUr.forEach(t),hco=r(cAe," (Wav2Vec2 model)"),cAe.forEach(t),pco=i(te),wh=n(te,"LI",{});var fAe=s(wh);Uae=n(fAe,"STRONG",{});var fUr=s(Uae);uco=r(fUr,"wav2vec2-conformer"),fUr.forEach(t),_co=r(fAe," \u2014 "),IB=n(fAe,"A",{href:!0});var mUr=s(IB);bco=r(mUr,"Wav2Vec2FeatureExtractor"),mUr.forEach(t),vco=r(fAe," (Wav2Vec2-Conformer model)"),fAe.forEach(t),Fco=i(te),Ah=n(te,"LI",{});var mAe=s(Ah);Jae=n(mAe,"STRONG",{});var gUr=s(Jae);Tco=r(gUr,"yolos"),gUr.forEach(t),Mco=r(mAe," \u2014 "),qB=n(mAe,"A",{href:!0});var hUr=s(qB);Eco=r(hUr,"YolosFeatureExtractor"),hUr.forEach(t),Cco=r(mAe," (YOLOS model)"),mAe.forEach(t),te.forEach(t),wco=i(Zt),T(yh.$$.fragment,Zt),Aco=i(Zt),T(Lh.$$.fragment,Zt),Zt.forEach(t),yco=i(Ns),xh=n(Ns,"DIV",{class:!0});var UNe=s(xh);T(x6.$$.fragment,UNe),Lco=i(UNe),Yae=n(UNe,"P",{});var pUr=s(Yae);xco=r(pUr,"Register a new feature extractor for this class."),pUr.forEach(t),UNe.forEach(t),Ns.forEach(t),HIe=i(f),Mi=n(f,"H2",{class:!0});var JNe=s(Mi);$h=n(JNe,"A",{id:!0,class:!0,href:!0});var uUr=s($h);Kae=n(uUr,"SPAN",{});var _Ur=s(Kae);T($6.$$.fragment,_Ur),_Ur.forEach(t),uUr.forEach(t),$co=i(JNe),Zae=n(JNe,"SPAN",{});var bUr=s(Zae);kco=r(bUr,"AutoProcessor"),bUr.forEach(t),JNe.forEach(t),UIe=i(f),yo=n(f,"DIV",{class:!0});var js=s(yo);T(k6.$$.fragment,js),Sco=i(js),S6=n(js,"P",{});var YNe=s(S6);Rco=r(YNe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),NB=n(YNe,"A",{href:!0});var vUr=s(NB);Pco=r(vUr,"AutoProcessor.from_pretrained()"),vUr.forEach(t),Bco=r(YNe," class method."),YNe.forEach(t),Ico=i(js),R6=n(js,"P",{});var KNe=s(R6);qco=r(KNe,"This class cannot be instantiated directly using "),ene=n(KNe,"CODE",{});var FUr=s(ene);Nco=r(FUr,"__init__()"),FUr.forEach(t),jco=r(KNe," (throws an error)."),KNe.forEach(t),Dco=i(js),Ue=n(js,"DIV",{class:!0});var ea=s(Ue);T(P6.$$.fragment,ea),Gco=i(ea),one=n(ea,"P",{});var TUr=s(one);Oco=r(TUr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),TUr.forEach(t),Vco=i(ea),Ei=n(ea,"P",{});var SK=s(Ei);Xco=r(SK,"The processor class to instantiate is selected based on the "),rne=n(SK,"CODE",{});var MUr=s(rne);zco=r(MUr,"model_type"),MUr.forEach(t),Wco=r(SK,` property of the config object (either
passed as an argument or loaded from `),tne=n(SK,"CODE",{});var EUr=s(tne);Qco=r(EUr,"pretrained_model_name_or_path"),EUr.forEach(t),Hco=r(SK," if possible):"),SK.forEach(t),Uco=i(ea),pe=n(ea,"UL",{});var be=s(pe);kh=n(be,"LI",{});var gAe=s(kh);ane=n(gAe,"STRONG",{});var CUr=s(ane);Jco=r(CUr,"clip"),CUr.forEach(t),Yco=r(gAe," \u2014 "),jB=n(gAe,"A",{href:!0});var wUr=s(jB);Kco=r(wUr,"CLIPProcessor"),wUr.forEach(t),Zco=r(gAe," (CLIP model)"),gAe.forEach(t),efo=i(be),Sh=n(be,"LI",{});var hAe=s(Sh);nne=n(hAe,"STRONG",{});var AUr=s(nne);ofo=r(AUr,"flava"),AUr.forEach(t),rfo=r(hAe," \u2014 "),sne=n(hAe,"CODE",{});var yUr=s(sne);tfo=r(yUr,"FLAVAProcessor"),yUr.forEach(t),afo=r(hAe," (Flava model)"),hAe.forEach(t),nfo=i(be),Rh=n(be,"LI",{});var pAe=s(Rh);lne=n(pAe,"STRONG",{});var LUr=s(lne);sfo=r(LUr,"layoutlmv2"),LUr.forEach(t),lfo=r(pAe," \u2014 "),DB=n(pAe,"A",{href:!0});var xUr=s(DB);ifo=r(xUr,"LayoutLMv2Processor"),xUr.forEach(t),dfo=r(pAe," (LayoutLMv2 model)"),pAe.forEach(t),cfo=i(be),Ph=n(be,"LI",{});var uAe=s(Ph);ine=n(uAe,"STRONG",{});var $Ur=s(ine);ffo=r($Ur,"layoutxlm"),$Ur.forEach(t),mfo=r(uAe," \u2014 "),GB=n(uAe,"A",{href:!0});var kUr=s(GB);gfo=r(kUr,"LayoutXLMProcessor"),kUr.forEach(t),hfo=r(uAe," (LayoutXLM model)"),uAe.forEach(t),pfo=i(be),Bh=n(be,"LI",{});var _Ae=s(Bh);dne=n(_Ae,"STRONG",{});var SUr=s(dne);ufo=r(SUr,"sew"),SUr.forEach(t),_fo=r(_Ae," \u2014 "),OB=n(_Ae,"A",{href:!0});var RUr=s(OB);bfo=r(RUr,"Wav2Vec2Processor"),RUr.forEach(t),vfo=r(_Ae," (SEW model)"),_Ae.forEach(t),Ffo=i(be),Ih=n(be,"LI",{});var bAe=s(Ih);cne=n(bAe,"STRONG",{});var PUr=s(cne);Tfo=r(PUr,"sew-d"),PUr.forEach(t),Mfo=r(bAe," \u2014 "),VB=n(bAe,"A",{href:!0});var BUr=s(VB);Efo=r(BUr,"Wav2Vec2Processor"),BUr.forEach(t),Cfo=r(bAe," (SEW-D model)"),bAe.forEach(t),wfo=i(be),qh=n(be,"LI",{});var vAe=s(qh);fne=n(vAe,"STRONG",{});var IUr=s(fne);Afo=r(IUr,"speech_to_text"),IUr.forEach(t),yfo=r(vAe," \u2014 "),XB=n(vAe,"A",{href:!0});var qUr=s(XB);Lfo=r(qUr,"Speech2TextProcessor"),qUr.forEach(t),xfo=r(vAe," (Speech2Text model)"),vAe.forEach(t),$fo=i(be),Nh=n(be,"LI",{});var FAe=s(Nh);mne=n(FAe,"STRONG",{});var NUr=s(mne);kfo=r(NUr,"speech_to_text_2"),NUr.forEach(t),Sfo=r(FAe," \u2014 "),zB=n(FAe,"A",{href:!0});var jUr=s(zB);Rfo=r(jUr,"Speech2Text2Processor"),jUr.forEach(t),Pfo=r(FAe," (Speech2Text2 model)"),FAe.forEach(t),Bfo=i(be),jh=n(be,"LI",{});var TAe=s(jh);gne=n(TAe,"STRONG",{});var DUr=s(gne);Ifo=r(DUr,"trocr"),DUr.forEach(t),qfo=r(TAe," \u2014 "),WB=n(TAe,"A",{href:!0});var GUr=s(WB);Nfo=r(GUr,"TrOCRProcessor"),GUr.forEach(t),jfo=r(TAe," (TrOCR model)"),TAe.forEach(t),Dfo=i(be),Dh=n(be,"LI",{});var MAe=s(Dh);hne=n(MAe,"STRONG",{});var OUr=s(hne);Gfo=r(OUr,"unispeech"),OUr.forEach(t),Ofo=r(MAe," \u2014 "),QB=n(MAe,"A",{href:!0});var VUr=s(QB);Vfo=r(VUr,"Wav2Vec2Processor"),VUr.forEach(t),Xfo=r(MAe," (UniSpeech model)"),MAe.forEach(t),zfo=i(be),Gh=n(be,"LI",{});var EAe=s(Gh);pne=n(EAe,"STRONG",{});var XUr=s(pne);Wfo=r(XUr,"unispeech-sat"),XUr.forEach(t),Qfo=r(EAe," \u2014 "),HB=n(EAe,"A",{href:!0});var zUr=s(HB);Hfo=r(zUr,"Wav2Vec2Processor"),zUr.forEach(t),Ufo=r(EAe," (UniSpeechSat model)"),EAe.forEach(t),Jfo=i(be),Oh=n(be,"LI",{});var CAe=s(Oh);une=n(CAe,"STRONG",{});var WUr=s(une);Yfo=r(WUr,"vilt"),WUr.forEach(t),Kfo=r(CAe," \u2014 "),UB=n(CAe,"A",{href:!0});var QUr=s(UB);Zfo=r(QUr,"ViltProcessor"),QUr.forEach(t),emo=r(CAe," (ViLT model)"),CAe.forEach(t),omo=i(be),Vh=n(be,"LI",{});var wAe=s(Vh);_ne=n(wAe,"STRONG",{});var HUr=s(_ne);rmo=r(HUr,"vision-text-dual-encoder"),HUr.forEach(t),tmo=r(wAe," \u2014 "),JB=n(wAe,"A",{href:!0});var UUr=s(JB);amo=r(UUr,"VisionTextDualEncoderProcessor"),UUr.forEach(t),nmo=r(wAe," (VisionTextDualEncoder model)"),wAe.forEach(t),smo=i(be),Xh=n(be,"LI",{});var AAe=s(Xh);bne=n(AAe,"STRONG",{});var JUr=s(bne);lmo=r(JUr,"wav2vec2"),JUr.forEach(t),imo=r(AAe," \u2014 "),YB=n(AAe,"A",{href:!0});var YUr=s(YB);dmo=r(YUr,"Wav2Vec2Processor"),YUr.forEach(t),cmo=r(AAe," (Wav2Vec2 model)"),AAe.forEach(t),fmo=i(be),zh=n(be,"LI",{});var yAe=s(zh);vne=n(yAe,"STRONG",{});var KUr=s(vne);mmo=r(KUr,"wav2vec2-conformer"),KUr.forEach(t),gmo=r(yAe," \u2014 "),KB=n(yAe,"A",{href:!0});var ZUr=s(KB);hmo=r(ZUr,"Wav2Vec2Processor"),ZUr.forEach(t),pmo=r(yAe," (Wav2Vec2-Conformer model)"),yAe.forEach(t),umo=i(be),Wh=n(be,"LI",{});var LAe=s(Wh);Fne=n(LAe,"STRONG",{});var eJr=s(Fne);_mo=r(eJr,"wavlm"),eJr.forEach(t),bmo=r(LAe," \u2014 "),ZB=n(LAe,"A",{href:!0});var oJr=s(ZB);vmo=r(oJr,"Wav2Vec2Processor"),oJr.forEach(t),Fmo=r(LAe," (WavLM model)"),LAe.forEach(t),be.forEach(t),Tmo=i(ea),T(Qh.$$.fragment,ea),Mmo=i(ea),T(Hh.$$.fragment,ea),ea.forEach(t),Emo=i(js),Uh=n(js,"DIV",{class:!0});var ZNe=s(Uh);T(B6.$$.fragment,ZNe),Cmo=i(ZNe),Tne=n(ZNe,"P",{});var rJr=s(Tne);wmo=r(rJr,"Register a new processor for this class."),rJr.forEach(t),ZNe.forEach(t),js.forEach(t),JIe=i(f),Ci=n(f,"H2",{class:!0});var eje=s(Ci);Jh=n(eje,"A",{id:!0,class:!0,href:!0});var tJr=s(Jh);Mne=n(tJr,"SPAN",{});var aJr=s(Mne);T(I6.$$.fragment,aJr),aJr.forEach(t),tJr.forEach(t),Amo=i(eje),Ene=n(eje,"SPAN",{});var nJr=s(Ene);ymo=r(nJr,"AutoModel"),nJr.forEach(t),eje.forEach(t),YIe=i(f),Lo=n(f,"DIV",{class:!0});var Ds=s(Lo);T(q6.$$.fragment,Ds),Lmo=i(Ds),wi=n(Ds,"P",{});var RK=s(wi);xmo=r(RK,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),eI=n(RK,"A",{href:!0});var sJr=s(eI);$mo=r(sJr,"from_pretrained()"),sJr.forEach(t),kmo=r(RK," class method or the "),oI=n(RK,"A",{href:!0});var lJr=s(oI);Smo=r(lJr,"from_config()"),lJr.forEach(t),Rmo=r(RK,` class
method.`),RK.forEach(t),Pmo=i(Ds),N6=n(Ds,"P",{});var oje=s(N6);Bmo=r(oje,"This class cannot be instantiated directly using "),Cne=n(oje,"CODE",{});var iJr=s(Cne);Imo=r(iJr,"__init__()"),iJr.forEach(t),qmo=r(oje," (throws an error)."),oje.forEach(t),Nmo=i(Ds),tt=n(Ds,"DIV",{class:!0});var hA=s(tt);T(j6.$$.fragment,hA),jmo=i(hA),wne=n(hA,"P",{});var dJr=s(wne);Dmo=r(dJr,"Instantiates one of the base model classes of the library from a configuration."),dJr.forEach(t),Gmo=i(hA),Ai=n(hA,"P",{});var PK=s(Ai);Omo=r(PK,`Note:
Loading a model from its configuration file does `),Ane=n(PK,"STRONG",{});var cJr=s(Ane);Vmo=r(cJr,"not"),cJr.forEach(t),Xmo=r(PK,` load the model weights. It only affects the
model\u2019s configuration. Use `),rI=n(PK,"A",{href:!0});var fJr=s(rI);zmo=r(fJr,"from_pretrained()"),fJr.forEach(t),Wmo=r(PK," to load the model weights."),PK.forEach(t),Qmo=i(hA),T(Yh.$$.fragment,hA),hA.forEach(t),Hmo=i(Ds),Je=n(Ds,"DIV",{class:!0});var oa=s(Je);T(D6.$$.fragment,oa),Umo=i(oa),yne=n(oa,"P",{});var mJr=s(yne);Jmo=r(mJr,"Instantiate one of the base model classes of the library from a pretrained model."),mJr.forEach(t),Ymo=i(oa),La=n(oa,"P",{});var pA=s(La);Kmo=r(pA,"The model class to instantiate is selected based on the "),Lne=n(pA,"CODE",{});var gJr=s(Lne);Zmo=r(gJr,"model_type"),gJr.forEach(t),ego=r(pA,` property of the config object (either
passed as an argument or loaded from `),xne=n(pA,"CODE",{});var hJr=s(xne);ogo=r(hJr,"pretrained_model_name_or_path"),hJr.forEach(t),rgo=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ne=n(pA,"CODE",{});var pJr=s($ne);tgo=r(pJr,"pretrained_model_name_or_path"),pJr.forEach(t),ago=r(pA,":"),pA.forEach(t),ngo=i(oa),x=n(oa,"UL",{});var $=s(x);Kh=n($,"LI",{});var xAe=s(Kh);kne=n(xAe,"STRONG",{});var uJr=s(kne);sgo=r(uJr,"albert"),uJr.forEach(t),lgo=r(xAe," \u2014 "),tI=n(xAe,"A",{href:!0});var _Jr=s(tI);igo=r(_Jr,"AlbertModel"),_Jr.forEach(t),dgo=r(xAe," (ALBERT model)"),xAe.forEach(t),cgo=i($),Zh=n($,"LI",{});var $Ae=s(Zh);Sne=n($Ae,"STRONG",{});var bJr=s(Sne);fgo=r(bJr,"bart"),bJr.forEach(t),mgo=r($Ae," \u2014 "),aI=n($Ae,"A",{href:!0});var vJr=s(aI);ggo=r(vJr,"BartModel"),vJr.forEach(t),hgo=r($Ae," (BART model)"),$Ae.forEach(t),pgo=i($),ep=n($,"LI",{});var kAe=s(ep);Rne=n(kAe,"STRONG",{});var FJr=s(Rne);ugo=r(FJr,"beit"),FJr.forEach(t),_go=r(kAe," \u2014 "),nI=n(kAe,"A",{href:!0});var TJr=s(nI);bgo=r(TJr,"BeitModel"),TJr.forEach(t),vgo=r(kAe," (BEiT model)"),kAe.forEach(t),Fgo=i($),op=n($,"LI",{});var SAe=s(op);Pne=n(SAe,"STRONG",{});var MJr=s(Pne);Tgo=r(MJr,"bert"),MJr.forEach(t),Mgo=r(SAe," \u2014 "),sI=n(SAe,"A",{href:!0});var EJr=s(sI);Ego=r(EJr,"BertModel"),EJr.forEach(t),Cgo=r(SAe," (BERT model)"),SAe.forEach(t),wgo=i($),rp=n($,"LI",{});var RAe=s(rp);Bne=n(RAe,"STRONG",{});var CJr=s(Bne);Ago=r(CJr,"bert-generation"),CJr.forEach(t),ygo=r(RAe," \u2014 "),lI=n(RAe,"A",{href:!0});var wJr=s(lI);Lgo=r(wJr,"BertGenerationEncoder"),wJr.forEach(t),xgo=r(RAe," (Bert Generation model)"),RAe.forEach(t),$go=i($),tp=n($,"LI",{});var PAe=s(tp);Ine=n(PAe,"STRONG",{});var AJr=s(Ine);kgo=r(AJr,"big_bird"),AJr.forEach(t),Sgo=r(PAe," \u2014 "),iI=n(PAe,"A",{href:!0});var yJr=s(iI);Rgo=r(yJr,"BigBirdModel"),yJr.forEach(t),Pgo=r(PAe," (BigBird model)"),PAe.forEach(t),Bgo=i($),ap=n($,"LI",{});var BAe=s(ap);qne=n(BAe,"STRONG",{});var LJr=s(qne);Igo=r(LJr,"bigbird_pegasus"),LJr.forEach(t),qgo=r(BAe," \u2014 "),dI=n(BAe,"A",{href:!0});var xJr=s(dI);Ngo=r(xJr,"BigBirdPegasusModel"),xJr.forEach(t),jgo=r(BAe," (BigBirdPegasus model)"),BAe.forEach(t),Dgo=i($),np=n($,"LI",{});var IAe=s(np);Nne=n(IAe,"STRONG",{});var $Jr=s(Nne);Ggo=r($Jr,"blenderbot"),$Jr.forEach(t),Ogo=r(IAe," \u2014 "),cI=n(IAe,"A",{href:!0});var kJr=s(cI);Vgo=r(kJr,"BlenderbotModel"),kJr.forEach(t),Xgo=r(IAe," (Blenderbot model)"),IAe.forEach(t),zgo=i($),sp=n($,"LI",{});var qAe=s(sp);jne=n(qAe,"STRONG",{});var SJr=s(jne);Wgo=r(SJr,"blenderbot-small"),SJr.forEach(t),Qgo=r(qAe," \u2014 "),fI=n(qAe,"A",{href:!0});var RJr=s(fI);Hgo=r(RJr,"BlenderbotSmallModel"),RJr.forEach(t),Ugo=r(qAe," (BlenderbotSmall model)"),qAe.forEach(t),Jgo=i($),lp=n($,"LI",{});var NAe=s(lp);Dne=n(NAe,"STRONG",{});var PJr=s(Dne);Ygo=r(PJr,"camembert"),PJr.forEach(t),Kgo=r(NAe," \u2014 "),mI=n(NAe,"A",{href:!0});var BJr=s(mI);Zgo=r(BJr,"CamembertModel"),BJr.forEach(t),eho=r(NAe," (CamemBERT model)"),NAe.forEach(t),oho=i($),ip=n($,"LI",{});var jAe=s(ip);Gne=n(jAe,"STRONG",{});var IJr=s(Gne);rho=r(IJr,"canine"),IJr.forEach(t),tho=r(jAe," \u2014 "),gI=n(jAe,"A",{href:!0});var qJr=s(gI);aho=r(qJr,"CanineModel"),qJr.forEach(t),nho=r(jAe," (Canine model)"),jAe.forEach(t),sho=i($),dp=n($,"LI",{});var DAe=s(dp);One=n(DAe,"STRONG",{});var NJr=s(One);lho=r(NJr,"clip"),NJr.forEach(t),iho=r(DAe," \u2014 "),hI=n(DAe,"A",{href:!0});var jJr=s(hI);dho=r(jJr,"CLIPModel"),jJr.forEach(t),cho=r(DAe," (CLIP model)"),DAe.forEach(t),fho=i($),cp=n($,"LI",{});var GAe=s(cp);Vne=n(GAe,"STRONG",{});var DJr=s(Vne);mho=r(DJr,"convbert"),DJr.forEach(t),gho=r(GAe," \u2014 "),pI=n(GAe,"A",{href:!0});var GJr=s(pI);hho=r(GJr,"ConvBertModel"),GJr.forEach(t),pho=r(GAe," (ConvBERT model)"),GAe.forEach(t),uho=i($),fp=n($,"LI",{});var OAe=s(fp);Xne=n(OAe,"STRONG",{});var OJr=s(Xne);_ho=r(OJr,"convnext"),OJr.forEach(t),bho=r(OAe," \u2014 "),uI=n(OAe,"A",{href:!0});var VJr=s(uI);vho=r(VJr,"ConvNextModel"),VJr.forEach(t),Fho=r(OAe," (ConvNext model)"),OAe.forEach(t),Tho=i($),mp=n($,"LI",{});var VAe=s(mp);zne=n(VAe,"STRONG",{});var XJr=s(zne);Mho=r(XJr,"ctrl"),XJr.forEach(t),Eho=r(VAe," \u2014 "),_I=n(VAe,"A",{href:!0});var zJr=s(_I);Cho=r(zJr,"CTRLModel"),zJr.forEach(t),who=r(VAe," (CTRL model)"),VAe.forEach(t),Aho=i($),gp=n($,"LI",{});var XAe=s(gp);Wne=n(XAe,"STRONG",{});var WJr=s(Wne);yho=r(WJr,"data2vec-audio"),WJr.forEach(t),Lho=r(XAe," \u2014 "),bI=n(XAe,"A",{href:!0});var QJr=s(bI);xho=r(QJr,"Data2VecAudioModel"),QJr.forEach(t),$ho=r(XAe," (Data2VecAudio model)"),XAe.forEach(t),kho=i($),hp=n($,"LI",{});var zAe=s(hp);Qne=n(zAe,"STRONG",{});var HJr=s(Qne);Sho=r(HJr,"data2vec-text"),HJr.forEach(t),Rho=r(zAe," \u2014 "),vI=n(zAe,"A",{href:!0});var UJr=s(vI);Pho=r(UJr,"Data2VecTextModel"),UJr.forEach(t),Bho=r(zAe," (Data2VecText model)"),zAe.forEach(t),Iho=i($),pp=n($,"LI",{});var WAe=s(pp);Hne=n(WAe,"STRONG",{});var JJr=s(Hne);qho=r(JJr,"data2vec-vision"),JJr.forEach(t),Nho=r(WAe," \u2014 "),FI=n(WAe,"A",{href:!0});var YJr=s(FI);jho=r(YJr,"Data2VecVisionModel"),YJr.forEach(t),Dho=r(WAe," (Data2VecVision model)"),WAe.forEach(t),Gho=i($),up=n($,"LI",{});var QAe=s(up);Une=n(QAe,"STRONG",{});var KJr=s(Une);Oho=r(KJr,"deberta"),KJr.forEach(t),Vho=r(QAe," \u2014 "),TI=n(QAe,"A",{href:!0});var ZJr=s(TI);Xho=r(ZJr,"DebertaModel"),ZJr.forEach(t),zho=r(QAe," (DeBERTa model)"),QAe.forEach(t),Who=i($),_p=n($,"LI",{});var HAe=s(_p);Jne=n(HAe,"STRONG",{});var eYr=s(Jne);Qho=r(eYr,"deberta-v2"),eYr.forEach(t),Hho=r(HAe," \u2014 "),MI=n(HAe,"A",{href:!0});var oYr=s(MI);Uho=r(oYr,"DebertaV2Model"),oYr.forEach(t),Jho=r(HAe," (DeBERTa-v2 model)"),HAe.forEach(t),Yho=i($),bp=n($,"LI",{});var UAe=s(bp);Yne=n(UAe,"STRONG",{});var rYr=s(Yne);Kho=r(rYr,"decision_transformer"),rYr.forEach(t),Zho=r(UAe," \u2014 "),EI=n(UAe,"A",{href:!0});var tYr=s(EI);epo=r(tYr,"DecisionTransformerModel"),tYr.forEach(t),opo=r(UAe," (Decision Transformer model)"),UAe.forEach(t),rpo=i($),vp=n($,"LI",{});var JAe=s(vp);Kne=n(JAe,"STRONG",{});var aYr=s(Kne);tpo=r(aYr,"deit"),aYr.forEach(t),apo=r(JAe," \u2014 "),CI=n(JAe,"A",{href:!0});var nYr=s(CI);npo=r(nYr,"DeiTModel"),nYr.forEach(t),spo=r(JAe," (DeiT model)"),JAe.forEach(t),lpo=i($),Fp=n($,"LI",{});var YAe=s(Fp);Zne=n(YAe,"STRONG",{});var sYr=s(Zne);ipo=r(sYr,"detr"),sYr.forEach(t),dpo=r(YAe," \u2014 "),wI=n(YAe,"A",{href:!0});var lYr=s(wI);cpo=r(lYr,"DetrModel"),lYr.forEach(t),fpo=r(YAe," (DETR model)"),YAe.forEach(t),mpo=i($),Tp=n($,"LI",{});var KAe=s(Tp);ese=n(KAe,"STRONG",{});var iYr=s(ese);gpo=r(iYr,"distilbert"),iYr.forEach(t),hpo=r(KAe," \u2014 "),AI=n(KAe,"A",{href:!0});var dYr=s(AI);ppo=r(dYr,"DistilBertModel"),dYr.forEach(t),upo=r(KAe," (DistilBERT model)"),KAe.forEach(t),_po=i($),Mp=n($,"LI",{});var ZAe=s(Mp);ose=n(ZAe,"STRONG",{});var cYr=s(ose);bpo=r(cYr,"dpr"),cYr.forEach(t),vpo=r(ZAe," \u2014 "),yI=n(ZAe,"A",{href:!0});var fYr=s(yI);Fpo=r(fYr,"DPRQuestionEncoder"),fYr.forEach(t),Tpo=r(ZAe," (DPR model)"),ZAe.forEach(t),Mpo=i($),Ep=n($,"LI",{});var e0e=s(Ep);rse=n(e0e,"STRONG",{});var mYr=s(rse);Epo=r(mYr,"dpt"),mYr.forEach(t),Cpo=r(e0e," \u2014 "),LI=n(e0e,"A",{href:!0});var gYr=s(LI);wpo=r(gYr,"DPTModel"),gYr.forEach(t),Apo=r(e0e," (DPT model)"),e0e.forEach(t),ypo=i($),Cp=n($,"LI",{});var o0e=s(Cp);tse=n(o0e,"STRONG",{});var hYr=s(tse);Lpo=r(hYr,"electra"),hYr.forEach(t),xpo=r(o0e," \u2014 "),xI=n(o0e,"A",{href:!0});var pYr=s(xI);$po=r(pYr,"ElectraModel"),pYr.forEach(t),kpo=r(o0e," (ELECTRA model)"),o0e.forEach(t),Spo=i($),wp=n($,"LI",{});var r0e=s(wp);ase=n(r0e,"STRONG",{});var uYr=s(ase);Rpo=r(uYr,"flaubert"),uYr.forEach(t),Ppo=r(r0e," \u2014 "),$I=n(r0e,"A",{href:!0});var _Yr=s($I);Bpo=r(_Yr,"FlaubertModel"),_Yr.forEach(t),Ipo=r(r0e," (FlauBERT model)"),r0e.forEach(t),qpo=i($),Ap=n($,"LI",{});var t0e=s(Ap);nse=n(t0e,"STRONG",{});var bYr=s(nse);Npo=r(bYr,"flava"),bYr.forEach(t),jpo=r(t0e," \u2014 "),kI=n(t0e,"A",{href:!0});var vYr=s(kI);Dpo=r(vYr,"FlavaModel"),vYr.forEach(t),Gpo=r(t0e," (Flava model)"),t0e.forEach(t),Opo=i($),yp=n($,"LI",{});var a0e=s(yp);sse=n(a0e,"STRONG",{});var FYr=s(sse);Vpo=r(FYr,"fnet"),FYr.forEach(t),Xpo=r(a0e," \u2014 "),SI=n(a0e,"A",{href:!0});var TYr=s(SI);zpo=r(TYr,"FNetModel"),TYr.forEach(t),Wpo=r(a0e," (FNet model)"),a0e.forEach(t),Qpo=i($),Lp=n($,"LI",{});var n0e=s(Lp);lse=n(n0e,"STRONG",{});var MYr=s(lse);Hpo=r(MYr,"fsmt"),MYr.forEach(t),Upo=r(n0e," \u2014 "),RI=n(n0e,"A",{href:!0});var EYr=s(RI);Jpo=r(EYr,"FSMTModel"),EYr.forEach(t),Ypo=r(n0e," (FairSeq Machine-Translation model)"),n0e.forEach(t),Kpo=i($),Rs=n($,"LI",{});var C$=s(Rs);ise=n(C$,"STRONG",{});var CYr=s(ise);Zpo=r(CYr,"funnel"),CYr.forEach(t),euo=r(C$," \u2014 "),PI=n(C$,"A",{href:!0});var wYr=s(PI);ouo=r(wYr,"FunnelModel"),wYr.forEach(t),ruo=r(C$," or "),BI=n(C$,"A",{href:!0});var AYr=s(BI);tuo=r(AYr,"FunnelBaseModel"),AYr.forEach(t),auo=r(C$," (Funnel Transformer model)"),C$.forEach(t),nuo=i($),xp=n($,"LI",{});var s0e=s(xp);dse=n(s0e,"STRONG",{});var yYr=s(dse);suo=r(yYr,"glpn"),yYr.forEach(t),luo=r(s0e," \u2014 "),II=n(s0e,"A",{href:!0});var LYr=s(II);iuo=r(LYr,"GLPNModel"),LYr.forEach(t),duo=r(s0e," (GLPN model)"),s0e.forEach(t),cuo=i($),$p=n($,"LI",{});var l0e=s($p);cse=n(l0e,"STRONG",{});var xYr=s(cse);fuo=r(xYr,"gpt2"),xYr.forEach(t),muo=r(l0e," \u2014 "),qI=n(l0e,"A",{href:!0});var $Yr=s(qI);guo=r($Yr,"GPT2Model"),$Yr.forEach(t),huo=r(l0e," (OpenAI GPT-2 model)"),l0e.forEach(t),puo=i($),kp=n($,"LI",{});var i0e=s(kp);fse=n(i0e,"STRONG",{});var kYr=s(fse);uuo=r(kYr,"gpt_neo"),kYr.forEach(t),_uo=r(i0e," \u2014 "),NI=n(i0e,"A",{href:!0});var SYr=s(NI);buo=r(SYr,"GPTNeoModel"),SYr.forEach(t),vuo=r(i0e," (GPT Neo model)"),i0e.forEach(t),Fuo=i($),Sp=n($,"LI",{});var d0e=s(Sp);mse=n(d0e,"STRONG",{});var RYr=s(mse);Tuo=r(RYr,"gptj"),RYr.forEach(t),Muo=r(d0e," \u2014 "),jI=n(d0e,"A",{href:!0});var PYr=s(jI);Euo=r(PYr,"GPTJModel"),PYr.forEach(t),Cuo=r(d0e," (GPT-J model)"),d0e.forEach(t),wuo=i($),Rp=n($,"LI",{});var c0e=s(Rp);gse=n(c0e,"STRONG",{});var BYr=s(gse);Auo=r(BYr,"hubert"),BYr.forEach(t),yuo=r(c0e," \u2014 "),DI=n(c0e,"A",{href:!0});var IYr=s(DI);Luo=r(IYr,"HubertModel"),IYr.forEach(t),xuo=r(c0e," (Hubert model)"),c0e.forEach(t),$uo=i($),Pp=n($,"LI",{});var f0e=s(Pp);hse=n(f0e,"STRONG",{});var qYr=s(hse);kuo=r(qYr,"ibert"),qYr.forEach(t),Suo=r(f0e," \u2014 "),GI=n(f0e,"A",{href:!0});var NYr=s(GI);Ruo=r(NYr,"IBertModel"),NYr.forEach(t),Puo=r(f0e," (I-BERT model)"),f0e.forEach(t),Buo=i($),Bp=n($,"LI",{});var m0e=s(Bp);pse=n(m0e,"STRONG",{});var jYr=s(pse);Iuo=r(jYr,"imagegpt"),jYr.forEach(t),quo=r(m0e," \u2014 "),OI=n(m0e,"A",{href:!0});var DYr=s(OI);Nuo=r(DYr,"ImageGPTModel"),DYr.forEach(t),juo=r(m0e," (ImageGPT model)"),m0e.forEach(t),Duo=i($),Ip=n($,"LI",{});var g0e=s(Ip);use=n(g0e,"STRONG",{});var GYr=s(use);Guo=r(GYr,"layoutlm"),GYr.forEach(t),Ouo=r(g0e," \u2014 "),VI=n(g0e,"A",{href:!0});var OYr=s(VI);Vuo=r(OYr,"LayoutLMModel"),OYr.forEach(t),Xuo=r(g0e," (LayoutLM model)"),g0e.forEach(t),zuo=i($),qp=n($,"LI",{});var h0e=s(qp);_se=n(h0e,"STRONG",{});var VYr=s(_se);Wuo=r(VYr,"layoutlmv2"),VYr.forEach(t),Quo=r(h0e," \u2014 "),XI=n(h0e,"A",{href:!0});var XYr=s(XI);Huo=r(XYr,"LayoutLMv2Model"),XYr.forEach(t),Uuo=r(h0e," (LayoutLMv2 model)"),h0e.forEach(t),Juo=i($),Np=n($,"LI",{});var p0e=s(Np);bse=n(p0e,"STRONG",{});var zYr=s(bse);Yuo=r(zYr,"led"),zYr.forEach(t),Kuo=r(p0e," \u2014 "),zI=n(p0e,"A",{href:!0});var WYr=s(zI);Zuo=r(WYr,"LEDModel"),WYr.forEach(t),e_o=r(p0e," (LED model)"),p0e.forEach(t),o_o=i($),jp=n($,"LI",{});var u0e=s(jp);vse=n(u0e,"STRONG",{});var QYr=s(vse);r_o=r(QYr,"longformer"),QYr.forEach(t),t_o=r(u0e," \u2014 "),WI=n(u0e,"A",{href:!0});var HYr=s(WI);a_o=r(HYr,"LongformerModel"),HYr.forEach(t),n_o=r(u0e," (Longformer model)"),u0e.forEach(t),s_o=i($),Dp=n($,"LI",{});var _0e=s(Dp);Fse=n(_0e,"STRONG",{});var UYr=s(Fse);l_o=r(UYr,"luke"),UYr.forEach(t),i_o=r(_0e," \u2014 "),QI=n(_0e,"A",{href:!0});var JYr=s(QI);d_o=r(JYr,"LukeModel"),JYr.forEach(t),c_o=r(_0e," (LUKE model)"),_0e.forEach(t),f_o=i($),Gp=n($,"LI",{});var b0e=s(Gp);Tse=n(b0e,"STRONG",{});var YYr=s(Tse);m_o=r(YYr,"lxmert"),YYr.forEach(t),g_o=r(b0e," \u2014 "),HI=n(b0e,"A",{href:!0});var KYr=s(HI);h_o=r(KYr,"LxmertModel"),KYr.forEach(t),p_o=r(b0e," (LXMERT model)"),b0e.forEach(t),u_o=i($),Op=n($,"LI",{});var v0e=s(Op);Mse=n(v0e,"STRONG",{});var ZYr=s(Mse);__o=r(ZYr,"m2m_100"),ZYr.forEach(t),b_o=r(v0e," \u2014 "),UI=n(v0e,"A",{href:!0});var eKr=s(UI);v_o=r(eKr,"M2M100Model"),eKr.forEach(t),F_o=r(v0e," (M2M100 model)"),v0e.forEach(t),T_o=i($),Vp=n($,"LI",{});var F0e=s(Vp);Ese=n(F0e,"STRONG",{});var oKr=s(Ese);M_o=r(oKr,"marian"),oKr.forEach(t),E_o=r(F0e," \u2014 "),JI=n(F0e,"A",{href:!0});var rKr=s(JI);C_o=r(rKr,"MarianModel"),rKr.forEach(t),w_o=r(F0e," (Marian model)"),F0e.forEach(t),A_o=i($),Xp=n($,"LI",{});var T0e=s(Xp);Cse=n(T0e,"STRONG",{});var tKr=s(Cse);y_o=r(tKr,"maskformer"),tKr.forEach(t),L_o=r(T0e," \u2014 "),YI=n(T0e,"A",{href:!0});var aKr=s(YI);x_o=r(aKr,"MaskFormerModel"),aKr.forEach(t),$_o=r(T0e," (MaskFormer model)"),T0e.forEach(t),k_o=i($),zp=n($,"LI",{});var M0e=s(zp);wse=n(M0e,"STRONG",{});var nKr=s(wse);S_o=r(nKr,"mbart"),nKr.forEach(t),R_o=r(M0e," \u2014 "),KI=n(M0e,"A",{href:!0});var sKr=s(KI);P_o=r(sKr,"MBartModel"),sKr.forEach(t),B_o=r(M0e," (mBART model)"),M0e.forEach(t),I_o=i($),Wp=n($,"LI",{});var E0e=s(Wp);Ase=n(E0e,"STRONG",{});var lKr=s(Ase);q_o=r(lKr,"megatron-bert"),lKr.forEach(t),N_o=r(E0e," \u2014 "),ZI=n(E0e,"A",{href:!0});var iKr=s(ZI);j_o=r(iKr,"MegatronBertModel"),iKr.forEach(t),D_o=r(E0e," (MegatronBert model)"),E0e.forEach(t),G_o=i($),Qp=n($,"LI",{});var C0e=s(Qp);yse=n(C0e,"STRONG",{});var dKr=s(yse);O_o=r(dKr,"mobilebert"),dKr.forEach(t),V_o=r(C0e," \u2014 "),eq=n(C0e,"A",{href:!0});var cKr=s(eq);X_o=r(cKr,"MobileBertModel"),cKr.forEach(t),z_o=r(C0e," (MobileBERT model)"),C0e.forEach(t),W_o=i($),Hp=n($,"LI",{});var w0e=s(Hp);Lse=n(w0e,"STRONG",{});var fKr=s(Lse);Q_o=r(fKr,"mpnet"),fKr.forEach(t),H_o=r(w0e," \u2014 "),oq=n(w0e,"A",{href:!0});var mKr=s(oq);U_o=r(mKr,"MPNetModel"),mKr.forEach(t),J_o=r(w0e," (MPNet model)"),w0e.forEach(t),Y_o=i($),Up=n($,"LI",{});var A0e=s(Up);xse=n(A0e,"STRONG",{});var gKr=s(xse);K_o=r(gKr,"mt5"),gKr.forEach(t),Z_o=r(A0e," \u2014 "),rq=n(A0e,"A",{href:!0});var hKr=s(rq);e2o=r(hKr,"MT5Model"),hKr.forEach(t),o2o=r(A0e," (mT5 model)"),A0e.forEach(t),r2o=i($),Jp=n($,"LI",{});var y0e=s(Jp);$se=n(y0e,"STRONG",{});var pKr=s($se);t2o=r(pKr,"nystromformer"),pKr.forEach(t),a2o=r(y0e," \u2014 "),tq=n(y0e,"A",{href:!0});var uKr=s(tq);n2o=r(uKr,"NystromformerModel"),uKr.forEach(t),s2o=r(y0e," (Nystromformer model)"),y0e.forEach(t),l2o=i($),Yp=n($,"LI",{});var L0e=s(Yp);kse=n(L0e,"STRONG",{});var _Kr=s(kse);i2o=r(_Kr,"openai-gpt"),_Kr.forEach(t),d2o=r(L0e," \u2014 "),aq=n(L0e,"A",{href:!0});var bKr=s(aq);c2o=r(bKr,"OpenAIGPTModel"),bKr.forEach(t),f2o=r(L0e," (OpenAI GPT model)"),L0e.forEach(t),m2o=i($),Kp=n($,"LI",{});var x0e=s(Kp);Sse=n(x0e,"STRONG",{});var vKr=s(Sse);g2o=r(vKr,"opt"),vKr.forEach(t),h2o=r(x0e," \u2014 "),nq=n(x0e,"A",{href:!0});var FKr=s(nq);p2o=r(FKr,"OPTModel"),FKr.forEach(t),u2o=r(x0e," (OPT model)"),x0e.forEach(t),_2o=i($),Zp=n($,"LI",{});var $0e=s(Zp);Rse=n($0e,"STRONG",{});var TKr=s(Rse);b2o=r(TKr,"pegasus"),TKr.forEach(t),v2o=r($0e," \u2014 "),sq=n($0e,"A",{href:!0});var MKr=s(sq);F2o=r(MKr,"PegasusModel"),MKr.forEach(t),T2o=r($0e," (Pegasus model)"),$0e.forEach(t),M2o=i($),eu=n($,"LI",{});var k0e=s(eu);Pse=n(k0e,"STRONG",{});var EKr=s(Pse);E2o=r(EKr,"perceiver"),EKr.forEach(t),C2o=r(k0e," \u2014 "),lq=n(k0e,"A",{href:!0});var CKr=s(lq);w2o=r(CKr,"PerceiverModel"),CKr.forEach(t),A2o=r(k0e," (Perceiver model)"),k0e.forEach(t),y2o=i($),ou=n($,"LI",{});var S0e=s(ou);Bse=n(S0e,"STRONG",{});var wKr=s(Bse);L2o=r(wKr,"plbart"),wKr.forEach(t),x2o=r(S0e," \u2014 "),iq=n(S0e,"A",{href:!0});var AKr=s(iq);$2o=r(AKr,"PLBartModel"),AKr.forEach(t),k2o=r(S0e," (PLBart model)"),S0e.forEach(t),S2o=i($),ru=n($,"LI",{});var R0e=s(ru);Ise=n(R0e,"STRONG",{});var yKr=s(Ise);R2o=r(yKr,"poolformer"),yKr.forEach(t),P2o=r(R0e," \u2014 "),dq=n(R0e,"A",{href:!0});var LKr=s(dq);B2o=r(LKr,"PoolFormerModel"),LKr.forEach(t),I2o=r(R0e," (PoolFormer model)"),R0e.forEach(t),q2o=i($),tu=n($,"LI",{});var P0e=s(tu);qse=n(P0e,"STRONG",{});var xKr=s(qse);N2o=r(xKr,"prophetnet"),xKr.forEach(t),j2o=r(P0e," \u2014 "),cq=n(P0e,"A",{href:!0});var $Kr=s(cq);D2o=r($Kr,"ProphetNetModel"),$Kr.forEach(t),G2o=r(P0e," (ProphetNet model)"),P0e.forEach(t),O2o=i($),au=n($,"LI",{});var B0e=s(au);Nse=n(B0e,"STRONG",{});var kKr=s(Nse);V2o=r(kKr,"qdqbert"),kKr.forEach(t),X2o=r(B0e," \u2014 "),fq=n(B0e,"A",{href:!0});var SKr=s(fq);z2o=r(SKr,"QDQBertModel"),SKr.forEach(t),W2o=r(B0e," (QDQBert model)"),B0e.forEach(t),Q2o=i($),nu=n($,"LI",{});var I0e=s(nu);jse=n(I0e,"STRONG",{});var RKr=s(jse);H2o=r(RKr,"reformer"),RKr.forEach(t),U2o=r(I0e," \u2014 "),mq=n(I0e,"A",{href:!0});var PKr=s(mq);J2o=r(PKr,"ReformerModel"),PKr.forEach(t),Y2o=r(I0e," (Reformer model)"),I0e.forEach(t),K2o=i($),su=n($,"LI",{});var q0e=s(su);Dse=n(q0e,"STRONG",{});var BKr=s(Dse);Z2o=r(BKr,"regnet"),BKr.forEach(t),e1o=r(q0e," \u2014 "),gq=n(q0e,"A",{href:!0});var IKr=s(gq);o1o=r(IKr,"RegNetModel"),IKr.forEach(t),r1o=r(q0e," (RegNet model)"),q0e.forEach(t),t1o=i($),lu=n($,"LI",{});var N0e=s(lu);Gse=n(N0e,"STRONG",{});var qKr=s(Gse);a1o=r(qKr,"rembert"),qKr.forEach(t),n1o=r(N0e," \u2014 "),hq=n(N0e,"A",{href:!0});var NKr=s(hq);s1o=r(NKr,"RemBertModel"),NKr.forEach(t),l1o=r(N0e," (RemBERT model)"),N0e.forEach(t),i1o=i($),iu=n($,"LI",{});var j0e=s(iu);Ose=n(j0e,"STRONG",{});var jKr=s(Ose);d1o=r(jKr,"resnet"),jKr.forEach(t),c1o=r(j0e," \u2014 "),pq=n(j0e,"A",{href:!0});var DKr=s(pq);f1o=r(DKr,"ResNetModel"),DKr.forEach(t),m1o=r(j0e," (ResNet model)"),j0e.forEach(t),g1o=i($),du=n($,"LI",{});var D0e=s(du);Vse=n(D0e,"STRONG",{});var GKr=s(Vse);h1o=r(GKr,"retribert"),GKr.forEach(t),p1o=r(D0e," \u2014 "),uq=n(D0e,"A",{href:!0});var OKr=s(uq);u1o=r(OKr,"RetriBertModel"),OKr.forEach(t),_1o=r(D0e," (RetriBERT model)"),D0e.forEach(t),b1o=i($),cu=n($,"LI",{});var G0e=s(cu);Xse=n(G0e,"STRONG",{});var VKr=s(Xse);v1o=r(VKr,"roberta"),VKr.forEach(t),F1o=r(G0e," \u2014 "),_q=n(G0e,"A",{href:!0});var XKr=s(_q);T1o=r(XKr,"RobertaModel"),XKr.forEach(t),M1o=r(G0e," (RoBERTa model)"),G0e.forEach(t),E1o=i($),fu=n($,"LI",{});var O0e=s(fu);zse=n(O0e,"STRONG",{});var zKr=s(zse);C1o=r(zKr,"roformer"),zKr.forEach(t),w1o=r(O0e," \u2014 "),bq=n(O0e,"A",{href:!0});var WKr=s(bq);A1o=r(WKr,"RoFormerModel"),WKr.forEach(t),y1o=r(O0e," (RoFormer model)"),O0e.forEach(t),L1o=i($),mu=n($,"LI",{});var V0e=s(mu);Wse=n(V0e,"STRONG",{});var QKr=s(Wse);x1o=r(QKr,"segformer"),QKr.forEach(t),$1o=r(V0e," \u2014 "),vq=n(V0e,"A",{href:!0});var HKr=s(vq);k1o=r(HKr,"SegformerModel"),HKr.forEach(t),S1o=r(V0e," (SegFormer model)"),V0e.forEach(t),R1o=i($),gu=n($,"LI",{});var X0e=s(gu);Qse=n(X0e,"STRONG",{});var UKr=s(Qse);P1o=r(UKr,"sew"),UKr.forEach(t),B1o=r(X0e," \u2014 "),Fq=n(X0e,"A",{href:!0});var JKr=s(Fq);I1o=r(JKr,"SEWModel"),JKr.forEach(t),q1o=r(X0e," (SEW model)"),X0e.forEach(t),N1o=i($),hu=n($,"LI",{});var z0e=s(hu);Hse=n(z0e,"STRONG",{});var YKr=s(Hse);j1o=r(YKr,"sew-d"),YKr.forEach(t),D1o=r(z0e," \u2014 "),Tq=n(z0e,"A",{href:!0});var KKr=s(Tq);G1o=r(KKr,"SEWDModel"),KKr.forEach(t),O1o=r(z0e," (SEW-D model)"),z0e.forEach(t),V1o=i($),pu=n($,"LI",{});var W0e=s(pu);Use=n(W0e,"STRONG",{});var ZKr=s(Use);X1o=r(ZKr,"speech_to_text"),ZKr.forEach(t),z1o=r(W0e," \u2014 "),Mq=n(W0e,"A",{href:!0});var eZr=s(Mq);W1o=r(eZr,"Speech2TextModel"),eZr.forEach(t),Q1o=r(W0e," (Speech2Text model)"),W0e.forEach(t),H1o=i($),uu=n($,"LI",{});var Q0e=s(uu);Jse=n(Q0e,"STRONG",{});var oZr=s(Jse);U1o=r(oZr,"splinter"),oZr.forEach(t),J1o=r(Q0e," \u2014 "),Eq=n(Q0e,"A",{href:!0});var rZr=s(Eq);Y1o=r(rZr,"SplinterModel"),rZr.forEach(t),K1o=r(Q0e," (Splinter model)"),Q0e.forEach(t),Z1o=i($),_u=n($,"LI",{});var H0e=s(_u);Yse=n(H0e,"STRONG",{});var tZr=s(Yse);e7o=r(tZr,"squeezebert"),tZr.forEach(t),o7o=r(H0e," \u2014 "),Cq=n(H0e,"A",{href:!0});var aZr=s(Cq);r7o=r(aZr,"SqueezeBertModel"),aZr.forEach(t),t7o=r(H0e," (SqueezeBERT model)"),H0e.forEach(t),a7o=i($),bu=n($,"LI",{});var U0e=s(bu);Kse=n(U0e,"STRONG",{});var nZr=s(Kse);n7o=r(nZr,"swin"),nZr.forEach(t),s7o=r(U0e," \u2014 "),wq=n(U0e,"A",{href:!0});var sZr=s(wq);l7o=r(sZr,"SwinModel"),sZr.forEach(t),i7o=r(U0e," (Swin model)"),U0e.forEach(t),d7o=i($),vu=n($,"LI",{});var J0e=s(vu);Zse=n(J0e,"STRONG",{});var lZr=s(Zse);c7o=r(lZr,"t5"),lZr.forEach(t),f7o=r(J0e," \u2014 "),Aq=n(J0e,"A",{href:!0});var iZr=s(Aq);m7o=r(iZr,"T5Model"),iZr.forEach(t),g7o=r(J0e," (T5 model)"),J0e.forEach(t),h7o=i($),Fu=n($,"LI",{});var Y0e=s(Fu);ele=n(Y0e,"STRONG",{});var dZr=s(ele);p7o=r(dZr,"tapas"),dZr.forEach(t),u7o=r(Y0e," \u2014 "),yq=n(Y0e,"A",{href:!0});var cZr=s(yq);_7o=r(cZr,"TapasModel"),cZr.forEach(t),b7o=r(Y0e," (TAPAS model)"),Y0e.forEach(t),v7o=i($),Tu=n($,"LI",{});var K0e=s(Tu);ole=n(K0e,"STRONG",{});var fZr=s(ole);F7o=r(fZr,"transfo-xl"),fZr.forEach(t),T7o=r(K0e," \u2014 "),Lq=n(K0e,"A",{href:!0});var mZr=s(Lq);M7o=r(mZr,"TransfoXLModel"),mZr.forEach(t),E7o=r(K0e," (Transformer-XL model)"),K0e.forEach(t),C7o=i($),Mu=n($,"LI",{});var Z0e=s(Mu);rle=n(Z0e,"STRONG",{});var gZr=s(rle);w7o=r(gZr,"unispeech"),gZr.forEach(t),A7o=r(Z0e," \u2014 "),xq=n(Z0e,"A",{href:!0});var hZr=s(xq);y7o=r(hZr,"UniSpeechModel"),hZr.forEach(t),L7o=r(Z0e," (UniSpeech model)"),Z0e.forEach(t),x7o=i($),Eu=n($,"LI",{});var e6e=s(Eu);tle=n(e6e,"STRONG",{});var pZr=s(tle);$7o=r(pZr,"unispeech-sat"),pZr.forEach(t),k7o=r(e6e," \u2014 "),$q=n(e6e,"A",{href:!0});var uZr=s($q);S7o=r(uZr,"UniSpeechSatModel"),uZr.forEach(t),R7o=r(e6e," (UniSpeechSat model)"),e6e.forEach(t),P7o=i($),Cu=n($,"LI",{});var o6e=s(Cu);ale=n(o6e,"STRONG",{});var _Zr=s(ale);B7o=r(_Zr,"van"),_Zr.forEach(t),I7o=r(o6e," \u2014 "),kq=n(o6e,"A",{href:!0});var bZr=s(kq);q7o=r(bZr,"VanModel"),bZr.forEach(t),N7o=r(o6e," (VAN model)"),o6e.forEach(t),j7o=i($),wu=n($,"LI",{});var r6e=s(wu);nle=n(r6e,"STRONG",{});var vZr=s(nle);D7o=r(vZr,"vilt"),vZr.forEach(t),G7o=r(r6e," \u2014 "),Sq=n(r6e,"A",{href:!0});var FZr=s(Sq);O7o=r(FZr,"ViltModel"),FZr.forEach(t),V7o=r(r6e," (ViLT model)"),r6e.forEach(t),X7o=i($),Au=n($,"LI",{});var t6e=s(Au);sle=n(t6e,"STRONG",{});var TZr=s(sle);z7o=r(TZr,"vision-text-dual-encoder"),TZr.forEach(t),W7o=r(t6e," \u2014 "),Rq=n(t6e,"A",{href:!0});var MZr=s(Rq);Q7o=r(MZr,"VisionTextDualEncoderModel"),MZr.forEach(t),H7o=r(t6e," (VisionTextDualEncoder model)"),t6e.forEach(t),U7o=i($),yu=n($,"LI",{});var a6e=s(yu);lle=n(a6e,"STRONG",{});var EZr=s(lle);J7o=r(EZr,"visual_bert"),EZr.forEach(t),Y7o=r(a6e," \u2014 "),Pq=n(a6e,"A",{href:!0});var CZr=s(Pq);K7o=r(CZr,"VisualBertModel"),CZr.forEach(t),Z7o=r(a6e," (VisualBert model)"),a6e.forEach(t),ebo=i($),Lu=n($,"LI",{});var n6e=s(Lu);ile=n(n6e,"STRONG",{});var wZr=s(ile);obo=r(wZr,"vit"),wZr.forEach(t),rbo=r(n6e," \u2014 "),Bq=n(n6e,"A",{href:!0});var AZr=s(Bq);tbo=r(AZr,"ViTModel"),AZr.forEach(t),abo=r(n6e," (ViT model)"),n6e.forEach(t),nbo=i($),xu=n($,"LI",{});var s6e=s(xu);dle=n(s6e,"STRONG",{});var yZr=s(dle);sbo=r(yZr,"vit_mae"),yZr.forEach(t),lbo=r(s6e," \u2014 "),Iq=n(s6e,"A",{href:!0});var LZr=s(Iq);ibo=r(LZr,"ViTMAEModel"),LZr.forEach(t),dbo=r(s6e," (ViTMAE model)"),s6e.forEach(t),cbo=i($),$u=n($,"LI",{});var l6e=s($u);cle=n(l6e,"STRONG",{});var xZr=s(cle);fbo=r(xZr,"wav2vec2"),xZr.forEach(t),mbo=r(l6e," \u2014 "),qq=n(l6e,"A",{href:!0});var $Zr=s(qq);gbo=r($Zr,"Wav2Vec2Model"),$Zr.forEach(t),hbo=r(l6e," (Wav2Vec2 model)"),l6e.forEach(t),pbo=i($),ku=n($,"LI",{});var i6e=s(ku);fle=n(i6e,"STRONG",{});var kZr=s(fle);ubo=r(kZr,"wav2vec2-conformer"),kZr.forEach(t),_bo=r(i6e," \u2014 "),Nq=n(i6e,"A",{href:!0});var SZr=s(Nq);bbo=r(SZr,"Wav2Vec2ConformerModel"),SZr.forEach(t),vbo=r(i6e," (Wav2Vec2-Conformer model)"),i6e.forEach(t),Fbo=i($),Su=n($,"LI",{});var d6e=s(Su);mle=n(d6e,"STRONG",{});var RZr=s(mle);Tbo=r(RZr,"wavlm"),RZr.forEach(t),Mbo=r(d6e," \u2014 "),jq=n(d6e,"A",{href:!0});var PZr=s(jq);Ebo=r(PZr,"WavLMModel"),PZr.forEach(t),Cbo=r(d6e," (WavLM model)"),d6e.forEach(t),wbo=i($),Ru=n($,"LI",{});var c6e=s(Ru);gle=n(c6e,"STRONG",{});var BZr=s(gle);Abo=r(BZr,"xglm"),BZr.forEach(t),ybo=r(c6e," \u2014 "),Dq=n(c6e,"A",{href:!0});var IZr=s(Dq);Lbo=r(IZr,"XGLMModel"),IZr.forEach(t),xbo=r(c6e," (XGLM model)"),c6e.forEach(t),$bo=i($),Pu=n($,"LI",{});var f6e=s(Pu);hle=n(f6e,"STRONG",{});var qZr=s(hle);kbo=r(qZr,"xlm"),qZr.forEach(t),Sbo=r(f6e," \u2014 "),Gq=n(f6e,"A",{href:!0});var NZr=s(Gq);Rbo=r(NZr,"XLMModel"),NZr.forEach(t),Pbo=r(f6e," (XLM model)"),f6e.forEach(t),Bbo=i($),Bu=n($,"LI",{});var m6e=s(Bu);ple=n(m6e,"STRONG",{});var jZr=s(ple);Ibo=r(jZr,"xlm-prophetnet"),jZr.forEach(t),qbo=r(m6e," \u2014 "),Oq=n(m6e,"A",{href:!0});var DZr=s(Oq);Nbo=r(DZr,"XLMProphetNetModel"),DZr.forEach(t),jbo=r(m6e," (XLMProphetNet model)"),m6e.forEach(t),Dbo=i($),Iu=n($,"LI",{});var g6e=s(Iu);ule=n(g6e,"STRONG",{});var GZr=s(ule);Gbo=r(GZr,"xlm-roberta"),GZr.forEach(t),Obo=r(g6e," \u2014 "),Vq=n(g6e,"A",{href:!0});var OZr=s(Vq);Vbo=r(OZr,"XLMRobertaModel"),OZr.forEach(t),Xbo=r(g6e," (XLM-RoBERTa model)"),g6e.forEach(t),zbo=i($),qu=n($,"LI",{});var h6e=s(qu);_le=n(h6e,"STRONG",{});var VZr=s(_le);Wbo=r(VZr,"xlm-roberta-xl"),VZr.forEach(t),Qbo=r(h6e," \u2014 "),Xq=n(h6e,"A",{href:!0});var XZr=s(Xq);Hbo=r(XZr,"XLMRobertaXLModel"),XZr.forEach(t),Ubo=r(h6e," (XLM-RoBERTa-XL model)"),h6e.forEach(t),Jbo=i($),Nu=n($,"LI",{});var p6e=s(Nu);ble=n(p6e,"STRONG",{});var zZr=s(ble);Ybo=r(zZr,"xlnet"),zZr.forEach(t),Kbo=r(p6e," \u2014 "),zq=n(p6e,"A",{href:!0});var WZr=s(zq);Zbo=r(WZr,"XLNetModel"),WZr.forEach(t),evo=r(p6e," (XLNet model)"),p6e.forEach(t),ovo=i($),ju=n($,"LI",{});var u6e=s(ju);vle=n(u6e,"STRONG",{});var QZr=s(vle);rvo=r(QZr,"yolos"),QZr.forEach(t),tvo=r(u6e," \u2014 "),Wq=n(u6e,"A",{href:!0});var HZr=s(Wq);avo=r(HZr,"YolosModel"),HZr.forEach(t),nvo=r(u6e," (YOLOS model)"),u6e.forEach(t),svo=i($),Du=n($,"LI",{});var _6e=s(Du);Fle=n(_6e,"STRONG",{});var UZr=s(Fle);lvo=r(UZr,"yoso"),UZr.forEach(t),ivo=r(_6e," \u2014 "),Qq=n(_6e,"A",{href:!0});var JZr=s(Qq);dvo=r(JZr,"YosoModel"),JZr.forEach(t),cvo=r(_6e," (YOSO model)"),_6e.forEach(t),$.forEach(t),fvo=i(oa),Gu=n(oa,"P",{});var b6e=s(Gu);mvo=r(b6e,"The model is set in evaluation mode by default using "),Tle=n(b6e,"CODE",{});var YZr=s(Tle);gvo=r(YZr,"model.eval()"),YZr.forEach(t),hvo=r(b6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mle=n(b6e,"CODE",{});var KZr=s(Mle);pvo=r(KZr,"model.train()"),KZr.forEach(t),b6e.forEach(t),uvo=i(oa),T(Ou.$$.fragment,oa),oa.forEach(t),Ds.forEach(t),KIe=i(f),yi=n(f,"H2",{class:!0});var rje=s(yi);Vu=n(rje,"A",{id:!0,class:!0,href:!0});var ZZr=s(Vu);Ele=n(ZZr,"SPAN",{});var eet=s(Ele);T(G6.$$.fragment,eet),eet.forEach(t),ZZr.forEach(t),_vo=i(rje),Cle=n(rje,"SPAN",{});var oet=s(Cle);bvo=r(oet,"AutoModelForPreTraining"),oet.forEach(t),rje.forEach(t),ZIe=i(f),xo=n(f,"DIV",{class:!0});var Gs=s(xo);T(O6.$$.fragment,Gs),vvo=i(Gs),Li=n(Gs,"P",{});var BK=s(Li);Fvo=r(BK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Hq=n(BK,"A",{href:!0});var ret=s(Hq);Tvo=r(ret,"from_pretrained()"),ret.forEach(t),Mvo=r(BK," class method or the "),Uq=n(BK,"A",{href:!0});var tet=s(Uq);Evo=r(tet,"from_config()"),tet.forEach(t),Cvo=r(BK,` class
method.`),BK.forEach(t),wvo=i(Gs),V6=n(Gs,"P",{});var tje=s(V6);Avo=r(tje,"This class cannot be instantiated directly using "),wle=n(tje,"CODE",{});var aet=s(wle);yvo=r(aet,"__init__()"),aet.forEach(t),Lvo=r(tje," (throws an error)."),tje.forEach(t),xvo=i(Gs),at=n(Gs,"DIV",{class:!0});var uA=s(at);T(X6.$$.fragment,uA),$vo=i(uA),Ale=n(uA,"P",{});var net=s(Ale);kvo=r(net,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),net.forEach(t),Svo=i(uA),xi=n(uA,"P",{});var IK=s(xi);Rvo=r(IK,`Note:
Loading a model from its configuration file does `),yle=n(IK,"STRONG",{});var set=s(yle);Pvo=r(set,"not"),set.forEach(t),Bvo=r(IK,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jq=n(IK,"A",{href:!0});var iet=s(Jq);Ivo=r(iet,"from_pretrained()"),iet.forEach(t),qvo=r(IK," to load the model weights."),IK.forEach(t),Nvo=i(uA),T(Xu.$$.fragment,uA),uA.forEach(t),jvo=i(Gs),Ye=n(Gs,"DIV",{class:!0});var ra=s(Ye);T(z6.$$.fragment,ra),Dvo=i(ra),Lle=n(ra,"P",{});var det=s(Lle);Gvo=r(det,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),det.forEach(t),Ovo=i(ra),xa=n(ra,"P",{});var _A=s(xa);Vvo=r(_A,"The model class to instantiate is selected based on the "),xle=n(_A,"CODE",{});var cet=s(xle);Xvo=r(cet,"model_type"),cet.forEach(t),zvo=r(_A,` property of the config object (either
passed as an argument or loaded from `),$le=n(_A,"CODE",{});var fet=s($le);Wvo=r(fet,"pretrained_model_name_or_path"),fet.forEach(t),Qvo=r(_A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kle=n(_A,"CODE",{});var met=s(kle);Hvo=r(met,"pretrained_model_name_or_path"),met.forEach(t),Uvo=r(_A,":"),_A.forEach(t),Jvo=i(ra),G=n(ra,"UL",{});var O=s(G);zu=n(O,"LI",{});var v6e=s(zu);Sle=n(v6e,"STRONG",{});var get=s(Sle);Yvo=r(get,"albert"),get.forEach(t),Kvo=r(v6e," \u2014 "),Yq=n(v6e,"A",{href:!0});var het=s(Yq);Zvo=r(het,"AlbertForPreTraining"),het.forEach(t),eFo=r(v6e," (ALBERT model)"),v6e.forEach(t),oFo=i(O),Wu=n(O,"LI",{});var F6e=s(Wu);Rle=n(F6e,"STRONG",{});var pet=s(Rle);rFo=r(pet,"bart"),pet.forEach(t),tFo=r(F6e," \u2014 "),Kq=n(F6e,"A",{href:!0});var uet=s(Kq);aFo=r(uet,"BartForConditionalGeneration"),uet.forEach(t),nFo=r(F6e," (BART model)"),F6e.forEach(t),sFo=i(O),Qu=n(O,"LI",{});var T6e=s(Qu);Ple=n(T6e,"STRONG",{});var _et=s(Ple);lFo=r(_et,"bert"),_et.forEach(t),iFo=r(T6e," \u2014 "),Zq=n(T6e,"A",{href:!0});var bet=s(Zq);dFo=r(bet,"BertForPreTraining"),bet.forEach(t),cFo=r(T6e," (BERT model)"),T6e.forEach(t),fFo=i(O),Hu=n(O,"LI",{});var M6e=s(Hu);Ble=n(M6e,"STRONG",{});var vet=s(Ble);mFo=r(vet,"big_bird"),vet.forEach(t),gFo=r(M6e," \u2014 "),eN=n(M6e,"A",{href:!0});var Fet=s(eN);hFo=r(Fet,"BigBirdForPreTraining"),Fet.forEach(t),pFo=r(M6e," (BigBird model)"),M6e.forEach(t),uFo=i(O),Uu=n(O,"LI",{});var E6e=s(Uu);Ile=n(E6e,"STRONG",{});var Tet=s(Ile);_Fo=r(Tet,"camembert"),Tet.forEach(t),bFo=r(E6e," \u2014 "),oN=n(E6e,"A",{href:!0});var Met=s(oN);vFo=r(Met,"CamembertForMaskedLM"),Met.forEach(t),FFo=r(E6e," (CamemBERT model)"),E6e.forEach(t),TFo=i(O),Ju=n(O,"LI",{});var C6e=s(Ju);qle=n(C6e,"STRONG",{});var Eet=s(qle);MFo=r(Eet,"ctrl"),Eet.forEach(t),EFo=r(C6e," \u2014 "),rN=n(C6e,"A",{href:!0});var Cet=s(rN);CFo=r(Cet,"CTRLLMHeadModel"),Cet.forEach(t),wFo=r(C6e," (CTRL model)"),C6e.forEach(t),AFo=i(O),Yu=n(O,"LI",{});var w6e=s(Yu);Nle=n(w6e,"STRONG",{});var wet=s(Nle);yFo=r(wet,"data2vec-text"),wet.forEach(t),LFo=r(w6e," \u2014 "),tN=n(w6e,"A",{href:!0});var Aet=s(tN);xFo=r(Aet,"Data2VecTextForMaskedLM"),Aet.forEach(t),$Fo=r(w6e," (Data2VecText model)"),w6e.forEach(t),kFo=i(O),Ku=n(O,"LI",{});var A6e=s(Ku);jle=n(A6e,"STRONG",{});var yet=s(jle);SFo=r(yet,"deberta"),yet.forEach(t),RFo=r(A6e," \u2014 "),aN=n(A6e,"A",{href:!0});var Let=s(aN);PFo=r(Let,"DebertaForMaskedLM"),Let.forEach(t),BFo=r(A6e," (DeBERTa model)"),A6e.forEach(t),IFo=i(O),Zu=n(O,"LI",{});var y6e=s(Zu);Dle=n(y6e,"STRONG",{});var xet=s(Dle);qFo=r(xet,"deberta-v2"),xet.forEach(t),NFo=r(y6e," \u2014 "),nN=n(y6e,"A",{href:!0});var $et=s(nN);jFo=r($et,"DebertaV2ForMaskedLM"),$et.forEach(t),DFo=r(y6e," (DeBERTa-v2 model)"),y6e.forEach(t),GFo=i(O),e_=n(O,"LI",{});var L6e=s(e_);Gle=n(L6e,"STRONG",{});var ket=s(Gle);OFo=r(ket,"distilbert"),ket.forEach(t),VFo=r(L6e," \u2014 "),sN=n(L6e,"A",{href:!0});var Set=s(sN);XFo=r(Set,"DistilBertForMaskedLM"),Set.forEach(t),zFo=r(L6e," (DistilBERT model)"),L6e.forEach(t),WFo=i(O),o_=n(O,"LI",{});var x6e=s(o_);Ole=n(x6e,"STRONG",{});var Ret=s(Ole);QFo=r(Ret,"electra"),Ret.forEach(t),HFo=r(x6e," \u2014 "),lN=n(x6e,"A",{href:!0});var Pet=s(lN);UFo=r(Pet,"ElectraForPreTraining"),Pet.forEach(t),JFo=r(x6e," (ELECTRA model)"),x6e.forEach(t),YFo=i(O),r_=n(O,"LI",{});var $6e=s(r_);Vle=n($6e,"STRONG",{});var Bet=s(Vle);KFo=r(Bet,"flaubert"),Bet.forEach(t),ZFo=r($6e," \u2014 "),iN=n($6e,"A",{href:!0});var Iet=s(iN);eTo=r(Iet,"FlaubertWithLMHeadModel"),Iet.forEach(t),oTo=r($6e," (FlauBERT model)"),$6e.forEach(t),rTo=i(O),t_=n(O,"LI",{});var k6e=s(t_);Xle=n(k6e,"STRONG",{});var qet=s(Xle);tTo=r(qet,"flava"),qet.forEach(t),aTo=r(k6e," \u2014 "),dN=n(k6e,"A",{href:!0});var Net=s(dN);nTo=r(Net,"FlavaForPreTraining"),Net.forEach(t),sTo=r(k6e," (Flava model)"),k6e.forEach(t),lTo=i(O),a_=n(O,"LI",{});var S6e=s(a_);zle=n(S6e,"STRONG",{});var jet=s(zle);iTo=r(jet,"fnet"),jet.forEach(t),dTo=r(S6e," \u2014 "),cN=n(S6e,"A",{href:!0});var Det=s(cN);cTo=r(Det,"FNetForPreTraining"),Det.forEach(t),fTo=r(S6e," (FNet model)"),S6e.forEach(t),mTo=i(O),n_=n(O,"LI",{});var R6e=s(n_);Wle=n(R6e,"STRONG",{});var Get=s(Wle);gTo=r(Get,"fsmt"),Get.forEach(t),hTo=r(R6e," \u2014 "),fN=n(R6e,"A",{href:!0});var Oet=s(fN);pTo=r(Oet,"FSMTForConditionalGeneration"),Oet.forEach(t),uTo=r(R6e," (FairSeq Machine-Translation model)"),R6e.forEach(t),_To=i(O),s_=n(O,"LI",{});var P6e=s(s_);Qle=n(P6e,"STRONG",{});var Vet=s(Qle);bTo=r(Vet,"funnel"),Vet.forEach(t),vTo=r(P6e," \u2014 "),mN=n(P6e,"A",{href:!0});var Xet=s(mN);FTo=r(Xet,"FunnelForPreTraining"),Xet.forEach(t),TTo=r(P6e," (Funnel Transformer model)"),P6e.forEach(t),MTo=i(O),l_=n(O,"LI",{});var B6e=s(l_);Hle=n(B6e,"STRONG",{});var zet=s(Hle);ETo=r(zet,"gpt2"),zet.forEach(t),CTo=r(B6e," \u2014 "),gN=n(B6e,"A",{href:!0});var Wet=s(gN);wTo=r(Wet,"GPT2LMHeadModel"),Wet.forEach(t),ATo=r(B6e," (OpenAI GPT-2 model)"),B6e.forEach(t),yTo=i(O),i_=n(O,"LI",{});var I6e=s(i_);Ule=n(I6e,"STRONG",{});var Qet=s(Ule);LTo=r(Qet,"ibert"),Qet.forEach(t),xTo=r(I6e," \u2014 "),hN=n(I6e,"A",{href:!0});var Het=s(hN);$To=r(Het,"IBertForMaskedLM"),Het.forEach(t),kTo=r(I6e," (I-BERT model)"),I6e.forEach(t),STo=i(O),d_=n(O,"LI",{});var q6e=s(d_);Jle=n(q6e,"STRONG",{});var Uet=s(Jle);RTo=r(Uet,"layoutlm"),Uet.forEach(t),PTo=r(q6e," \u2014 "),pN=n(q6e,"A",{href:!0});var Jet=s(pN);BTo=r(Jet,"LayoutLMForMaskedLM"),Jet.forEach(t),ITo=r(q6e," (LayoutLM model)"),q6e.forEach(t),qTo=i(O),c_=n(O,"LI",{});var N6e=s(c_);Yle=n(N6e,"STRONG",{});var Yet=s(Yle);NTo=r(Yet,"longformer"),Yet.forEach(t),jTo=r(N6e," \u2014 "),uN=n(N6e,"A",{href:!0});var Ket=s(uN);DTo=r(Ket,"LongformerForMaskedLM"),Ket.forEach(t),GTo=r(N6e," (Longformer model)"),N6e.forEach(t),OTo=i(O),f_=n(O,"LI",{});var j6e=s(f_);Kle=n(j6e,"STRONG",{});var Zet=s(Kle);VTo=r(Zet,"lxmert"),Zet.forEach(t),XTo=r(j6e," \u2014 "),_N=n(j6e,"A",{href:!0});var eot=s(_N);zTo=r(eot,"LxmertForPreTraining"),eot.forEach(t),WTo=r(j6e," (LXMERT model)"),j6e.forEach(t),QTo=i(O),m_=n(O,"LI",{});var D6e=s(m_);Zle=n(D6e,"STRONG",{});var oot=s(Zle);HTo=r(oot,"megatron-bert"),oot.forEach(t),UTo=r(D6e," \u2014 "),bN=n(D6e,"A",{href:!0});var rot=s(bN);JTo=r(rot,"MegatronBertForPreTraining"),rot.forEach(t),YTo=r(D6e," (MegatronBert model)"),D6e.forEach(t),KTo=i(O),g_=n(O,"LI",{});var G6e=s(g_);eie=n(G6e,"STRONG",{});var tot=s(eie);ZTo=r(tot,"mobilebert"),tot.forEach(t),eMo=r(G6e," \u2014 "),vN=n(G6e,"A",{href:!0});var aot=s(vN);oMo=r(aot,"MobileBertForPreTraining"),aot.forEach(t),rMo=r(G6e," (MobileBERT model)"),G6e.forEach(t),tMo=i(O),h_=n(O,"LI",{});var O6e=s(h_);oie=n(O6e,"STRONG",{});var not=s(oie);aMo=r(not,"mpnet"),not.forEach(t),nMo=r(O6e," \u2014 "),FN=n(O6e,"A",{href:!0});var sot=s(FN);sMo=r(sot,"MPNetForMaskedLM"),sot.forEach(t),lMo=r(O6e," (MPNet model)"),O6e.forEach(t),iMo=i(O),p_=n(O,"LI",{});var V6e=s(p_);rie=n(V6e,"STRONG",{});var lot=s(rie);dMo=r(lot,"openai-gpt"),lot.forEach(t),cMo=r(V6e," \u2014 "),TN=n(V6e,"A",{href:!0});var iot=s(TN);fMo=r(iot,"OpenAIGPTLMHeadModel"),iot.forEach(t),mMo=r(V6e," (OpenAI GPT model)"),V6e.forEach(t),gMo=i(O),u_=n(O,"LI",{});var X6e=s(u_);tie=n(X6e,"STRONG",{});var dot=s(tie);hMo=r(dot,"retribert"),dot.forEach(t),pMo=r(X6e," \u2014 "),MN=n(X6e,"A",{href:!0});var cot=s(MN);uMo=r(cot,"RetriBertModel"),cot.forEach(t),_Mo=r(X6e," (RetriBERT model)"),X6e.forEach(t),bMo=i(O),__=n(O,"LI",{});var z6e=s(__);aie=n(z6e,"STRONG",{});var fot=s(aie);vMo=r(fot,"roberta"),fot.forEach(t),FMo=r(z6e," \u2014 "),EN=n(z6e,"A",{href:!0});var mot=s(EN);TMo=r(mot,"RobertaForMaskedLM"),mot.forEach(t),MMo=r(z6e," (RoBERTa model)"),z6e.forEach(t),EMo=i(O),b_=n(O,"LI",{});var W6e=s(b_);nie=n(W6e,"STRONG",{});var got=s(nie);CMo=r(got,"squeezebert"),got.forEach(t),wMo=r(W6e," \u2014 "),CN=n(W6e,"A",{href:!0});var hot=s(CN);AMo=r(hot,"SqueezeBertForMaskedLM"),hot.forEach(t),yMo=r(W6e," (SqueezeBERT model)"),W6e.forEach(t),LMo=i(O),v_=n(O,"LI",{});var Q6e=s(v_);sie=n(Q6e,"STRONG",{});var pot=s(sie);xMo=r(pot,"t5"),pot.forEach(t),$Mo=r(Q6e," \u2014 "),wN=n(Q6e,"A",{href:!0});var uot=s(wN);kMo=r(uot,"T5ForConditionalGeneration"),uot.forEach(t),SMo=r(Q6e," (T5 model)"),Q6e.forEach(t),RMo=i(O),F_=n(O,"LI",{});var H6e=s(F_);lie=n(H6e,"STRONG",{});var _ot=s(lie);PMo=r(_ot,"tapas"),_ot.forEach(t),BMo=r(H6e," \u2014 "),AN=n(H6e,"A",{href:!0});var bot=s(AN);IMo=r(bot,"TapasForMaskedLM"),bot.forEach(t),qMo=r(H6e," (TAPAS model)"),H6e.forEach(t),NMo=i(O),T_=n(O,"LI",{});var U6e=s(T_);iie=n(U6e,"STRONG",{});var vot=s(iie);jMo=r(vot,"transfo-xl"),vot.forEach(t),DMo=r(U6e," \u2014 "),yN=n(U6e,"A",{href:!0});var Fot=s(yN);GMo=r(Fot,"TransfoXLLMHeadModel"),Fot.forEach(t),OMo=r(U6e," (Transformer-XL model)"),U6e.forEach(t),VMo=i(O),M_=n(O,"LI",{});var J6e=s(M_);die=n(J6e,"STRONG",{});var Tot=s(die);XMo=r(Tot,"unispeech"),Tot.forEach(t),zMo=r(J6e," \u2014 "),LN=n(J6e,"A",{href:!0});var Mot=s(LN);WMo=r(Mot,"UniSpeechForPreTraining"),Mot.forEach(t),QMo=r(J6e," (UniSpeech model)"),J6e.forEach(t),HMo=i(O),E_=n(O,"LI",{});var Y6e=s(E_);cie=n(Y6e,"STRONG",{});var Eot=s(cie);UMo=r(Eot,"unispeech-sat"),Eot.forEach(t),JMo=r(Y6e," \u2014 "),xN=n(Y6e,"A",{href:!0});var Cot=s(xN);YMo=r(Cot,"UniSpeechSatForPreTraining"),Cot.forEach(t),KMo=r(Y6e," (UniSpeechSat model)"),Y6e.forEach(t),ZMo=i(O),C_=n(O,"LI",{});var K6e=s(C_);fie=n(K6e,"STRONG",{});var wot=s(fie);e4o=r(wot,"visual_bert"),wot.forEach(t),o4o=r(K6e," \u2014 "),$N=n(K6e,"A",{href:!0});var Aot=s($N);r4o=r(Aot,"VisualBertForPreTraining"),Aot.forEach(t),t4o=r(K6e," (VisualBert model)"),K6e.forEach(t),a4o=i(O),w_=n(O,"LI",{});var Z6e=s(w_);mie=n(Z6e,"STRONG",{});var yot=s(mie);n4o=r(yot,"vit_mae"),yot.forEach(t),s4o=r(Z6e," \u2014 "),kN=n(Z6e,"A",{href:!0});var Lot=s(kN);l4o=r(Lot,"ViTMAEForPreTraining"),Lot.forEach(t),i4o=r(Z6e," (ViTMAE model)"),Z6e.forEach(t),d4o=i(O),A_=n(O,"LI",{});var eye=s(A_);gie=n(eye,"STRONG",{});var xot=s(gie);c4o=r(xot,"wav2vec2"),xot.forEach(t),f4o=r(eye," \u2014 "),SN=n(eye,"A",{href:!0});var $ot=s(SN);m4o=r($ot,"Wav2Vec2ForPreTraining"),$ot.forEach(t),g4o=r(eye," (Wav2Vec2 model)"),eye.forEach(t),h4o=i(O),y_=n(O,"LI",{});var oye=s(y_);hie=n(oye,"STRONG",{});var kot=s(hie);p4o=r(kot,"wav2vec2-conformer"),kot.forEach(t),u4o=r(oye," \u2014 "),RN=n(oye,"A",{href:!0});var Sot=s(RN);_4o=r(Sot,"Wav2Vec2ConformerForPreTraining"),Sot.forEach(t),b4o=r(oye," (Wav2Vec2-Conformer model)"),oye.forEach(t),v4o=i(O),L_=n(O,"LI",{});var rye=s(L_);pie=n(rye,"STRONG",{});var Rot=s(pie);F4o=r(Rot,"xlm"),Rot.forEach(t),T4o=r(rye," \u2014 "),PN=n(rye,"A",{href:!0});var Pot=s(PN);M4o=r(Pot,"XLMWithLMHeadModel"),Pot.forEach(t),E4o=r(rye," (XLM model)"),rye.forEach(t),C4o=i(O),x_=n(O,"LI",{});var tye=s(x_);uie=n(tye,"STRONG",{});var Bot=s(uie);w4o=r(Bot,"xlm-roberta"),Bot.forEach(t),A4o=r(tye," \u2014 "),BN=n(tye,"A",{href:!0});var Iot=s(BN);y4o=r(Iot,"XLMRobertaForMaskedLM"),Iot.forEach(t),L4o=r(tye," (XLM-RoBERTa model)"),tye.forEach(t),x4o=i(O),$_=n(O,"LI",{});var aye=s($_);_ie=n(aye,"STRONG",{});var qot=s(_ie);$4o=r(qot,"xlm-roberta-xl"),qot.forEach(t),k4o=r(aye," \u2014 "),IN=n(aye,"A",{href:!0});var Not=s(IN);S4o=r(Not,"XLMRobertaXLForMaskedLM"),Not.forEach(t),R4o=r(aye," (XLM-RoBERTa-XL model)"),aye.forEach(t),P4o=i(O),k_=n(O,"LI",{});var nye=s(k_);bie=n(nye,"STRONG",{});var jot=s(bie);B4o=r(jot,"xlnet"),jot.forEach(t),I4o=r(nye," \u2014 "),qN=n(nye,"A",{href:!0});var Dot=s(qN);q4o=r(Dot,"XLNetLMHeadModel"),Dot.forEach(t),N4o=r(nye," (XLNet model)"),nye.forEach(t),O.forEach(t),j4o=i(ra),S_=n(ra,"P",{});var sye=s(S_);D4o=r(sye,"The model is set in evaluation mode by default using "),vie=n(sye,"CODE",{});var Got=s(vie);G4o=r(Got,"model.eval()"),Got.forEach(t),O4o=r(sye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fie=n(sye,"CODE",{});var Oot=s(Fie);V4o=r(Oot,"model.train()"),Oot.forEach(t),sye.forEach(t),X4o=i(ra),T(R_.$$.fragment,ra),ra.forEach(t),Gs.forEach(t),eqe=i(f),$i=n(f,"H2",{class:!0});var aje=s($i);P_=n(aje,"A",{id:!0,class:!0,href:!0});var Vot=s(P_);Tie=n(Vot,"SPAN",{});var Xot=s(Tie);T(W6.$$.fragment,Xot),Xot.forEach(t),Vot.forEach(t),z4o=i(aje),Mie=n(aje,"SPAN",{});var zot=s(Mie);W4o=r(zot,"AutoModelForCausalLM"),zot.forEach(t),aje.forEach(t),oqe=i(f),$o=n(f,"DIV",{class:!0});var Os=s($o);T(Q6.$$.fragment,Os),Q4o=i(Os),ki=n(Os,"P",{});var qK=s(ki);H4o=r(qK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),NN=n(qK,"A",{href:!0});var Wot=s(NN);U4o=r(Wot,"from_pretrained()"),Wot.forEach(t),J4o=r(qK," class method or the "),jN=n(qK,"A",{href:!0});var Qot=s(jN);Y4o=r(Qot,"from_config()"),Qot.forEach(t),K4o=r(qK,` class
method.`),qK.forEach(t),Z4o=i(Os),H6=n(Os,"P",{});var nje=s(H6);eEo=r(nje,"This class cannot be instantiated directly using "),Eie=n(nje,"CODE",{});var Hot=s(Eie);oEo=r(Hot,"__init__()"),Hot.forEach(t),rEo=r(nje," (throws an error)."),nje.forEach(t),tEo=i(Os),nt=n(Os,"DIV",{class:!0});var bA=s(nt);T(U6.$$.fragment,bA),aEo=i(bA),Cie=n(bA,"P",{});var Uot=s(Cie);nEo=r(Uot,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Uot.forEach(t),sEo=i(bA),Si=n(bA,"P",{});var NK=s(Si);lEo=r(NK,`Note:
Loading a model from its configuration file does `),wie=n(NK,"STRONG",{});var Jot=s(wie);iEo=r(Jot,"not"),Jot.forEach(t),dEo=r(NK,` load the model weights. It only affects the
model\u2019s configuration. Use `),DN=n(NK,"A",{href:!0});var Yot=s(DN);cEo=r(Yot,"from_pretrained()"),Yot.forEach(t),fEo=r(NK," to load the model weights."),NK.forEach(t),mEo=i(bA),T(B_.$$.fragment,bA),bA.forEach(t),gEo=i(Os),Ke=n(Os,"DIV",{class:!0});var ta=s(Ke);T(J6.$$.fragment,ta),hEo=i(ta),Aie=n(ta,"P",{});var Kot=s(Aie);pEo=r(Kot,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Kot.forEach(t),uEo=i(ta),$a=n(ta,"P",{});var vA=s($a);_Eo=r(vA,"The model class to instantiate is selected based on the "),yie=n(vA,"CODE",{});var Zot=s(yie);bEo=r(Zot,"model_type"),Zot.forEach(t),vEo=r(vA,` property of the config object (either
passed as an argument or loaded from `),Lie=n(vA,"CODE",{});var ert=s(Lie);FEo=r(ert,"pretrained_model_name_or_path"),ert.forEach(t),TEo=r(vA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xie=n(vA,"CODE",{});var ort=s(xie);MEo=r(ort,"pretrained_model_name_or_path"),ort.forEach(t),EEo=r(vA,":"),vA.forEach(t),CEo=i(ta),z=n(ta,"UL",{});var Q=s(z);I_=n(Q,"LI",{});var lye=s(I_);$ie=n(lye,"STRONG",{});var rrt=s($ie);wEo=r(rrt,"bart"),rrt.forEach(t),AEo=r(lye," \u2014 "),GN=n(lye,"A",{href:!0});var trt=s(GN);yEo=r(trt,"BartForCausalLM"),trt.forEach(t),LEo=r(lye," (BART model)"),lye.forEach(t),xEo=i(Q),q_=n(Q,"LI",{});var iye=s(q_);kie=n(iye,"STRONG",{});var art=s(kie);$Eo=r(art,"bert"),art.forEach(t),kEo=r(iye," \u2014 "),ON=n(iye,"A",{href:!0});var nrt=s(ON);SEo=r(nrt,"BertLMHeadModel"),nrt.forEach(t),REo=r(iye," (BERT model)"),iye.forEach(t),PEo=i(Q),N_=n(Q,"LI",{});var dye=s(N_);Sie=n(dye,"STRONG",{});var srt=s(Sie);BEo=r(srt,"bert-generation"),srt.forEach(t),IEo=r(dye," \u2014 "),VN=n(dye,"A",{href:!0});var lrt=s(VN);qEo=r(lrt,"BertGenerationDecoder"),lrt.forEach(t),NEo=r(dye," (Bert Generation model)"),dye.forEach(t),jEo=i(Q),j_=n(Q,"LI",{});var cye=s(j_);Rie=n(cye,"STRONG",{});var irt=s(Rie);DEo=r(irt,"big_bird"),irt.forEach(t),GEo=r(cye," \u2014 "),XN=n(cye,"A",{href:!0});var drt=s(XN);OEo=r(drt,"BigBirdForCausalLM"),drt.forEach(t),VEo=r(cye," (BigBird model)"),cye.forEach(t),XEo=i(Q),D_=n(Q,"LI",{});var fye=s(D_);Pie=n(fye,"STRONG",{});var crt=s(Pie);zEo=r(crt,"bigbird_pegasus"),crt.forEach(t),WEo=r(fye," \u2014 "),zN=n(fye,"A",{href:!0});var frt=s(zN);QEo=r(frt,"BigBirdPegasusForCausalLM"),frt.forEach(t),HEo=r(fye," (BigBirdPegasus model)"),fye.forEach(t),UEo=i(Q),G_=n(Q,"LI",{});var mye=s(G_);Bie=n(mye,"STRONG",{});var mrt=s(Bie);JEo=r(mrt,"blenderbot"),mrt.forEach(t),YEo=r(mye," \u2014 "),WN=n(mye,"A",{href:!0});var grt=s(WN);KEo=r(grt,"BlenderbotForCausalLM"),grt.forEach(t),ZEo=r(mye," (Blenderbot model)"),mye.forEach(t),eCo=i(Q),O_=n(Q,"LI",{});var gye=s(O_);Iie=n(gye,"STRONG",{});var hrt=s(Iie);oCo=r(hrt,"blenderbot-small"),hrt.forEach(t),rCo=r(gye," \u2014 "),QN=n(gye,"A",{href:!0});var prt=s(QN);tCo=r(prt,"BlenderbotSmallForCausalLM"),prt.forEach(t),aCo=r(gye," (BlenderbotSmall model)"),gye.forEach(t),nCo=i(Q),V_=n(Q,"LI",{});var hye=s(V_);qie=n(hye,"STRONG",{});var urt=s(qie);sCo=r(urt,"camembert"),urt.forEach(t),lCo=r(hye," \u2014 "),HN=n(hye,"A",{href:!0});var _rt=s(HN);iCo=r(_rt,"CamembertForCausalLM"),_rt.forEach(t),dCo=r(hye," (CamemBERT model)"),hye.forEach(t),cCo=i(Q),X_=n(Q,"LI",{});var pye=s(X_);Nie=n(pye,"STRONG",{});var brt=s(Nie);fCo=r(brt,"ctrl"),brt.forEach(t),mCo=r(pye," \u2014 "),UN=n(pye,"A",{href:!0});var vrt=s(UN);gCo=r(vrt,"CTRLLMHeadModel"),vrt.forEach(t),hCo=r(pye," (CTRL model)"),pye.forEach(t),pCo=i(Q),z_=n(Q,"LI",{});var uye=s(z_);jie=n(uye,"STRONG",{});var Frt=s(jie);uCo=r(Frt,"data2vec-text"),Frt.forEach(t),_Co=r(uye," \u2014 "),JN=n(uye,"A",{href:!0});var Trt=s(JN);bCo=r(Trt,"Data2VecTextForCausalLM"),Trt.forEach(t),vCo=r(uye," (Data2VecText model)"),uye.forEach(t),FCo=i(Q),W_=n(Q,"LI",{});var _ye=s(W_);Die=n(_ye,"STRONG",{});var Mrt=s(Die);TCo=r(Mrt,"electra"),Mrt.forEach(t),MCo=r(_ye," \u2014 "),YN=n(_ye,"A",{href:!0});var Ert=s(YN);ECo=r(Ert,"ElectraForCausalLM"),Ert.forEach(t),CCo=r(_ye," (ELECTRA model)"),_ye.forEach(t),wCo=i(Q),Q_=n(Q,"LI",{});var bye=s(Q_);Gie=n(bye,"STRONG",{});var Crt=s(Gie);ACo=r(Crt,"gpt2"),Crt.forEach(t),yCo=r(bye," \u2014 "),KN=n(bye,"A",{href:!0});var wrt=s(KN);LCo=r(wrt,"GPT2LMHeadModel"),wrt.forEach(t),xCo=r(bye," (OpenAI GPT-2 model)"),bye.forEach(t),$Co=i(Q),H_=n(Q,"LI",{});var vye=s(H_);Oie=n(vye,"STRONG",{});var Art=s(Oie);kCo=r(Art,"gpt_neo"),Art.forEach(t),SCo=r(vye," \u2014 "),ZN=n(vye,"A",{href:!0});var yrt=s(ZN);RCo=r(yrt,"GPTNeoForCausalLM"),yrt.forEach(t),PCo=r(vye," (GPT Neo model)"),vye.forEach(t),BCo=i(Q),U_=n(Q,"LI",{});var Fye=s(U_);Vie=n(Fye,"STRONG",{});var Lrt=s(Vie);ICo=r(Lrt,"gptj"),Lrt.forEach(t),qCo=r(Fye," \u2014 "),ej=n(Fye,"A",{href:!0});var xrt=s(ej);NCo=r(xrt,"GPTJForCausalLM"),xrt.forEach(t),jCo=r(Fye," (GPT-J model)"),Fye.forEach(t),DCo=i(Q),J_=n(Q,"LI",{});var Tye=s(J_);Xie=n(Tye,"STRONG",{});var $rt=s(Xie);GCo=r($rt,"marian"),$rt.forEach(t),OCo=r(Tye," \u2014 "),oj=n(Tye,"A",{href:!0});var krt=s(oj);VCo=r(krt,"MarianForCausalLM"),krt.forEach(t),XCo=r(Tye," (Marian model)"),Tye.forEach(t),zCo=i(Q),Y_=n(Q,"LI",{});var Mye=s(Y_);zie=n(Mye,"STRONG",{});var Srt=s(zie);WCo=r(Srt,"mbart"),Srt.forEach(t),QCo=r(Mye," \u2014 "),rj=n(Mye,"A",{href:!0});var Rrt=s(rj);HCo=r(Rrt,"MBartForCausalLM"),Rrt.forEach(t),UCo=r(Mye," (mBART model)"),Mye.forEach(t),JCo=i(Q),K_=n(Q,"LI",{});var Eye=s(K_);Wie=n(Eye,"STRONG",{});var Prt=s(Wie);YCo=r(Prt,"megatron-bert"),Prt.forEach(t),KCo=r(Eye," \u2014 "),tj=n(Eye,"A",{href:!0});var Brt=s(tj);ZCo=r(Brt,"MegatronBertForCausalLM"),Brt.forEach(t),e5o=r(Eye," (MegatronBert model)"),Eye.forEach(t),o5o=i(Q),Z_=n(Q,"LI",{});var Cye=s(Z_);Qie=n(Cye,"STRONG",{});var Irt=s(Qie);r5o=r(Irt,"openai-gpt"),Irt.forEach(t),t5o=r(Cye," \u2014 "),aj=n(Cye,"A",{href:!0});var qrt=s(aj);a5o=r(qrt,"OpenAIGPTLMHeadModel"),qrt.forEach(t),n5o=r(Cye," (OpenAI GPT model)"),Cye.forEach(t),s5o=i(Q),e2=n(Q,"LI",{});var wye=s(e2);Hie=n(wye,"STRONG",{});var Nrt=s(Hie);l5o=r(Nrt,"opt"),Nrt.forEach(t),i5o=r(wye," \u2014 "),nj=n(wye,"A",{href:!0});var jrt=s(nj);d5o=r(jrt,"OPTForCausalLM"),jrt.forEach(t),c5o=r(wye," (OPT model)"),wye.forEach(t),f5o=i(Q),o2=n(Q,"LI",{});var Aye=s(o2);Uie=n(Aye,"STRONG",{});var Drt=s(Uie);m5o=r(Drt,"pegasus"),Drt.forEach(t),g5o=r(Aye," \u2014 "),sj=n(Aye,"A",{href:!0});var Grt=s(sj);h5o=r(Grt,"PegasusForCausalLM"),Grt.forEach(t),p5o=r(Aye," (Pegasus model)"),Aye.forEach(t),u5o=i(Q),r2=n(Q,"LI",{});var yye=s(r2);Jie=n(yye,"STRONG",{});var Ort=s(Jie);_5o=r(Ort,"plbart"),Ort.forEach(t),b5o=r(yye," \u2014 "),lj=n(yye,"A",{href:!0});var Vrt=s(lj);v5o=r(Vrt,"PLBartForCausalLM"),Vrt.forEach(t),F5o=r(yye," (PLBart model)"),yye.forEach(t),T5o=i(Q),t2=n(Q,"LI",{});var Lye=s(t2);Yie=n(Lye,"STRONG",{});var Xrt=s(Yie);M5o=r(Xrt,"prophetnet"),Xrt.forEach(t),E5o=r(Lye," \u2014 "),ij=n(Lye,"A",{href:!0});var zrt=s(ij);C5o=r(zrt,"ProphetNetForCausalLM"),zrt.forEach(t),w5o=r(Lye," (ProphetNet model)"),Lye.forEach(t),A5o=i(Q),a2=n(Q,"LI",{});var xye=s(a2);Kie=n(xye,"STRONG",{});var Wrt=s(Kie);y5o=r(Wrt,"qdqbert"),Wrt.forEach(t),L5o=r(xye," \u2014 "),dj=n(xye,"A",{href:!0});var Qrt=s(dj);x5o=r(Qrt,"QDQBertLMHeadModel"),Qrt.forEach(t),$5o=r(xye," (QDQBert model)"),xye.forEach(t),k5o=i(Q),n2=n(Q,"LI",{});var $ye=s(n2);Zie=n($ye,"STRONG",{});var Hrt=s(Zie);S5o=r(Hrt,"reformer"),Hrt.forEach(t),R5o=r($ye," \u2014 "),cj=n($ye,"A",{href:!0});var Urt=s(cj);P5o=r(Urt,"ReformerModelWithLMHead"),Urt.forEach(t),B5o=r($ye," (Reformer model)"),$ye.forEach(t),I5o=i(Q),s2=n(Q,"LI",{});var kye=s(s2);ede=n(kye,"STRONG",{});var Jrt=s(ede);q5o=r(Jrt,"rembert"),Jrt.forEach(t),N5o=r(kye," \u2014 "),fj=n(kye,"A",{href:!0});var Yrt=s(fj);j5o=r(Yrt,"RemBertForCausalLM"),Yrt.forEach(t),D5o=r(kye," (RemBERT model)"),kye.forEach(t),G5o=i(Q),l2=n(Q,"LI",{});var Sye=s(l2);ode=n(Sye,"STRONG",{});var Krt=s(ode);O5o=r(Krt,"roberta"),Krt.forEach(t),V5o=r(Sye," \u2014 "),mj=n(Sye,"A",{href:!0});var Zrt=s(mj);X5o=r(Zrt,"RobertaForCausalLM"),Zrt.forEach(t),z5o=r(Sye," (RoBERTa model)"),Sye.forEach(t),W5o=i(Q),i2=n(Q,"LI",{});var Rye=s(i2);rde=n(Rye,"STRONG",{});var ett=s(rde);Q5o=r(ett,"roformer"),ett.forEach(t),H5o=r(Rye," \u2014 "),gj=n(Rye,"A",{href:!0});var ott=s(gj);U5o=r(ott,"RoFormerForCausalLM"),ott.forEach(t),J5o=r(Rye," (RoFormer model)"),Rye.forEach(t),Y5o=i(Q),d2=n(Q,"LI",{});var Pye=s(d2);tde=n(Pye,"STRONG",{});var rtt=s(tde);K5o=r(rtt,"speech_to_text_2"),rtt.forEach(t),Z5o=r(Pye," \u2014 "),hj=n(Pye,"A",{href:!0});var ttt=s(hj);e3o=r(ttt,"Speech2Text2ForCausalLM"),ttt.forEach(t),o3o=r(Pye," (Speech2Text2 model)"),Pye.forEach(t),r3o=i(Q),c2=n(Q,"LI",{});var Bye=s(c2);ade=n(Bye,"STRONG",{});var att=s(ade);t3o=r(att,"transfo-xl"),att.forEach(t),a3o=r(Bye," \u2014 "),pj=n(Bye,"A",{href:!0});var ntt=s(pj);n3o=r(ntt,"TransfoXLLMHeadModel"),ntt.forEach(t),s3o=r(Bye," (Transformer-XL model)"),Bye.forEach(t),l3o=i(Q),f2=n(Q,"LI",{});var Iye=s(f2);nde=n(Iye,"STRONG",{});var stt=s(nde);i3o=r(stt,"trocr"),stt.forEach(t),d3o=r(Iye," \u2014 "),uj=n(Iye,"A",{href:!0});var ltt=s(uj);c3o=r(ltt,"TrOCRForCausalLM"),ltt.forEach(t),f3o=r(Iye," (TrOCR model)"),Iye.forEach(t),m3o=i(Q),m2=n(Q,"LI",{});var qye=s(m2);sde=n(qye,"STRONG",{});var itt=s(sde);g3o=r(itt,"xglm"),itt.forEach(t),h3o=r(qye," \u2014 "),_j=n(qye,"A",{href:!0});var dtt=s(_j);p3o=r(dtt,"XGLMForCausalLM"),dtt.forEach(t),u3o=r(qye," (XGLM model)"),qye.forEach(t),_3o=i(Q),g2=n(Q,"LI",{});var Nye=s(g2);lde=n(Nye,"STRONG",{});var ctt=s(lde);b3o=r(ctt,"xlm"),ctt.forEach(t),v3o=r(Nye," \u2014 "),bj=n(Nye,"A",{href:!0});var ftt=s(bj);F3o=r(ftt,"XLMWithLMHeadModel"),ftt.forEach(t),T3o=r(Nye," (XLM model)"),Nye.forEach(t),M3o=i(Q),h2=n(Q,"LI",{});var jye=s(h2);ide=n(jye,"STRONG",{});var mtt=s(ide);E3o=r(mtt,"xlm-prophetnet"),mtt.forEach(t),C3o=r(jye," \u2014 "),vj=n(jye,"A",{href:!0});var gtt=s(vj);w3o=r(gtt,"XLMProphetNetForCausalLM"),gtt.forEach(t),A3o=r(jye," (XLMProphetNet model)"),jye.forEach(t),y3o=i(Q),p2=n(Q,"LI",{});var Dye=s(p2);dde=n(Dye,"STRONG",{});var htt=s(dde);L3o=r(htt,"xlm-roberta"),htt.forEach(t),x3o=r(Dye," \u2014 "),Fj=n(Dye,"A",{href:!0});var ptt=s(Fj);$3o=r(ptt,"XLMRobertaForCausalLM"),ptt.forEach(t),k3o=r(Dye," (XLM-RoBERTa model)"),Dye.forEach(t),S3o=i(Q),u2=n(Q,"LI",{});var Gye=s(u2);cde=n(Gye,"STRONG",{});var utt=s(cde);R3o=r(utt,"xlm-roberta-xl"),utt.forEach(t),P3o=r(Gye," \u2014 "),Tj=n(Gye,"A",{href:!0});var _tt=s(Tj);B3o=r(_tt,"XLMRobertaXLForCausalLM"),_tt.forEach(t),I3o=r(Gye," (XLM-RoBERTa-XL model)"),Gye.forEach(t),q3o=i(Q),_2=n(Q,"LI",{});var Oye=s(_2);fde=n(Oye,"STRONG",{});var btt=s(fde);N3o=r(btt,"xlnet"),btt.forEach(t),j3o=r(Oye," \u2014 "),Mj=n(Oye,"A",{href:!0});var vtt=s(Mj);D3o=r(vtt,"XLNetLMHeadModel"),vtt.forEach(t),G3o=r(Oye," (XLNet model)"),Oye.forEach(t),Q.forEach(t),O3o=i(ta),b2=n(ta,"P",{});var Vye=s(b2);V3o=r(Vye,"The model is set in evaluation mode by default using "),mde=n(Vye,"CODE",{});var Ftt=s(mde);X3o=r(Ftt,"model.eval()"),Ftt.forEach(t),z3o=r(Vye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gde=n(Vye,"CODE",{});var Ttt=s(gde);W3o=r(Ttt,"model.train()"),Ttt.forEach(t),Vye.forEach(t),Q3o=i(ta),T(v2.$$.fragment,ta),ta.forEach(t),Os.forEach(t),rqe=i(f),Ri=n(f,"H2",{class:!0});var sje=s(Ri);F2=n(sje,"A",{id:!0,class:!0,href:!0});var Mtt=s(F2);hde=n(Mtt,"SPAN",{});var Ett=s(hde);T(Y6.$$.fragment,Ett),Ett.forEach(t),Mtt.forEach(t),H3o=i(sje),pde=n(sje,"SPAN",{});var Ctt=s(pde);U3o=r(Ctt,"AutoModelForMaskedLM"),Ctt.forEach(t),sje.forEach(t),tqe=i(f),ko=n(f,"DIV",{class:!0});var Vs=s(ko);T(K6.$$.fragment,Vs),J3o=i(Vs),Pi=n(Vs,"P",{});var jK=s(Pi);Y3o=r(jK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Ej=n(jK,"A",{href:!0});var wtt=s(Ej);K3o=r(wtt,"from_pretrained()"),wtt.forEach(t),Z3o=r(jK," class method or the "),Cj=n(jK,"A",{href:!0});var Att=s(Cj);ewo=r(Att,"from_config()"),Att.forEach(t),owo=r(jK,` class
method.`),jK.forEach(t),rwo=i(Vs),Z6=n(Vs,"P",{});var lje=s(Z6);two=r(lje,"This class cannot be instantiated directly using "),ude=n(lje,"CODE",{});var ytt=s(ude);awo=r(ytt,"__init__()"),ytt.forEach(t),nwo=r(lje," (throws an error)."),lje.forEach(t),swo=i(Vs),st=n(Vs,"DIV",{class:!0});var FA=s(st);T(ey.$$.fragment,FA),lwo=i(FA),_de=n(FA,"P",{});var Ltt=s(_de);iwo=r(Ltt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ltt.forEach(t),dwo=i(FA),Bi=n(FA,"P",{});var DK=s(Bi);cwo=r(DK,`Note:
Loading a model from its configuration file does `),bde=n(DK,"STRONG",{});var xtt=s(bde);fwo=r(xtt,"not"),xtt.forEach(t),mwo=r(DK,` load the model weights. It only affects the
model\u2019s configuration. Use `),wj=n(DK,"A",{href:!0});var $tt=s(wj);gwo=r($tt,"from_pretrained()"),$tt.forEach(t),hwo=r(DK," to load the model weights."),DK.forEach(t),pwo=i(FA),T(T2.$$.fragment,FA),FA.forEach(t),uwo=i(Vs),Ze=n(Vs,"DIV",{class:!0});var aa=s(Ze);T(oy.$$.fragment,aa),_wo=i(aa),vde=n(aa,"P",{});var ktt=s(vde);bwo=r(ktt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ktt.forEach(t),vwo=i(aa),ka=n(aa,"P",{});var TA=s(ka);Fwo=r(TA,"The model class to instantiate is selected based on the "),Fde=n(TA,"CODE",{});var Stt=s(Fde);Two=r(Stt,"model_type"),Stt.forEach(t),Mwo=r(TA,` property of the config object (either
passed as an argument or loaded from `),Tde=n(TA,"CODE",{});var Rtt=s(Tde);Ewo=r(Rtt,"pretrained_model_name_or_path"),Rtt.forEach(t),Cwo=r(TA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mde=n(TA,"CODE",{});var Ptt=s(Mde);wwo=r(Ptt,"pretrained_model_name_or_path"),Ptt.forEach(t),Awo=r(TA,":"),TA.forEach(t),ywo=i(aa),W=n(aa,"UL",{});var H=s(W);M2=n(H,"LI",{});var Xye=s(M2);Ede=n(Xye,"STRONG",{});var Btt=s(Ede);Lwo=r(Btt,"albert"),Btt.forEach(t),xwo=r(Xye," \u2014 "),Aj=n(Xye,"A",{href:!0});var Itt=s(Aj);$wo=r(Itt,"AlbertForMaskedLM"),Itt.forEach(t),kwo=r(Xye," (ALBERT model)"),Xye.forEach(t),Swo=i(H),E2=n(H,"LI",{});var zye=s(E2);Cde=n(zye,"STRONG",{});var qtt=s(Cde);Rwo=r(qtt,"bart"),qtt.forEach(t),Pwo=r(zye," \u2014 "),yj=n(zye,"A",{href:!0});var Ntt=s(yj);Bwo=r(Ntt,"BartForConditionalGeneration"),Ntt.forEach(t),Iwo=r(zye," (BART model)"),zye.forEach(t),qwo=i(H),C2=n(H,"LI",{});var Wye=s(C2);wde=n(Wye,"STRONG",{});var jtt=s(wde);Nwo=r(jtt,"bert"),jtt.forEach(t),jwo=r(Wye," \u2014 "),Lj=n(Wye,"A",{href:!0});var Dtt=s(Lj);Dwo=r(Dtt,"BertForMaskedLM"),Dtt.forEach(t),Gwo=r(Wye," (BERT model)"),Wye.forEach(t),Owo=i(H),w2=n(H,"LI",{});var Qye=s(w2);Ade=n(Qye,"STRONG",{});var Gtt=s(Ade);Vwo=r(Gtt,"big_bird"),Gtt.forEach(t),Xwo=r(Qye," \u2014 "),xj=n(Qye,"A",{href:!0});var Ott=s(xj);zwo=r(Ott,"BigBirdForMaskedLM"),Ott.forEach(t),Wwo=r(Qye," (BigBird model)"),Qye.forEach(t),Qwo=i(H),A2=n(H,"LI",{});var Hye=s(A2);yde=n(Hye,"STRONG",{});var Vtt=s(yde);Hwo=r(Vtt,"camembert"),Vtt.forEach(t),Uwo=r(Hye," \u2014 "),$j=n(Hye,"A",{href:!0});var Xtt=s($j);Jwo=r(Xtt,"CamembertForMaskedLM"),Xtt.forEach(t),Ywo=r(Hye," (CamemBERT model)"),Hye.forEach(t),Kwo=i(H),y2=n(H,"LI",{});var Uye=s(y2);Lde=n(Uye,"STRONG",{});var ztt=s(Lde);Zwo=r(ztt,"convbert"),ztt.forEach(t),eAo=r(Uye," \u2014 "),kj=n(Uye,"A",{href:!0});var Wtt=s(kj);oAo=r(Wtt,"ConvBertForMaskedLM"),Wtt.forEach(t),rAo=r(Uye," (ConvBERT model)"),Uye.forEach(t),tAo=i(H),L2=n(H,"LI",{});var Jye=s(L2);xde=n(Jye,"STRONG",{});var Qtt=s(xde);aAo=r(Qtt,"data2vec-text"),Qtt.forEach(t),nAo=r(Jye," \u2014 "),Sj=n(Jye,"A",{href:!0});var Htt=s(Sj);sAo=r(Htt,"Data2VecTextForMaskedLM"),Htt.forEach(t),lAo=r(Jye," (Data2VecText model)"),Jye.forEach(t),iAo=i(H),x2=n(H,"LI",{});var Yye=s(x2);$de=n(Yye,"STRONG",{});var Utt=s($de);dAo=r(Utt,"deberta"),Utt.forEach(t),cAo=r(Yye," \u2014 "),Rj=n(Yye,"A",{href:!0});var Jtt=s(Rj);fAo=r(Jtt,"DebertaForMaskedLM"),Jtt.forEach(t),mAo=r(Yye," (DeBERTa model)"),Yye.forEach(t),gAo=i(H),$2=n(H,"LI",{});var Kye=s($2);kde=n(Kye,"STRONG",{});var Ytt=s(kde);hAo=r(Ytt,"deberta-v2"),Ytt.forEach(t),pAo=r(Kye," \u2014 "),Pj=n(Kye,"A",{href:!0});var Ktt=s(Pj);uAo=r(Ktt,"DebertaV2ForMaskedLM"),Ktt.forEach(t),_Ao=r(Kye," (DeBERTa-v2 model)"),Kye.forEach(t),bAo=i(H),k2=n(H,"LI",{});var Zye=s(k2);Sde=n(Zye,"STRONG",{});var Ztt=s(Sde);vAo=r(Ztt,"distilbert"),Ztt.forEach(t),FAo=r(Zye," \u2014 "),Bj=n(Zye,"A",{href:!0});var eat=s(Bj);TAo=r(eat,"DistilBertForMaskedLM"),eat.forEach(t),MAo=r(Zye," (DistilBERT model)"),Zye.forEach(t),EAo=i(H),S2=n(H,"LI",{});var eLe=s(S2);Rde=n(eLe,"STRONG",{});var oat=s(Rde);CAo=r(oat,"electra"),oat.forEach(t),wAo=r(eLe," \u2014 "),Ij=n(eLe,"A",{href:!0});var rat=s(Ij);AAo=r(rat,"ElectraForMaskedLM"),rat.forEach(t),yAo=r(eLe," (ELECTRA model)"),eLe.forEach(t),LAo=i(H),R2=n(H,"LI",{});var oLe=s(R2);Pde=n(oLe,"STRONG",{});var tat=s(Pde);xAo=r(tat,"flaubert"),tat.forEach(t),$Ao=r(oLe," \u2014 "),qj=n(oLe,"A",{href:!0});var aat=s(qj);kAo=r(aat,"FlaubertWithLMHeadModel"),aat.forEach(t),SAo=r(oLe," (FlauBERT model)"),oLe.forEach(t),RAo=i(H),P2=n(H,"LI",{});var rLe=s(P2);Bde=n(rLe,"STRONG",{});var nat=s(Bde);PAo=r(nat,"fnet"),nat.forEach(t),BAo=r(rLe," \u2014 "),Nj=n(rLe,"A",{href:!0});var sat=s(Nj);IAo=r(sat,"FNetForMaskedLM"),sat.forEach(t),qAo=r(rLe," (FNet model)"),rLe.forEach(t),NAo=i(H),B2=n(H,"LI",{});var tLe=s(B2);Ide=n(tLe,"STRONG",{});var lat=s(Ide);jAo=r(lat,"funnel"),lat.forEach(t),DAo=r(tLe," \u2014 "),jj=n(tLe,"A",{href:!0});var iat=s(jj);GAo=r(iat,"FunnelForMaskedLM"),iat.forEach(t),OAo=r(tLe," (Funnel Transformer model)"),tLe.forEach(t),VAo=i(H),I2=n(H,"LI",{});var aLe=s(I2);qde=n(aLe,"STRONG",{});var dat=s(qde);XAo=r(dat,"ibert"),dat.forEach(t),zAo=r(aLe," \u2014 "),Dj=n(aLe,"A",{href:!0});var cat=s(Dj);WAo=r(cat,"IBertForMaskedLM"),cat.forEach(t),QAo=r(aLe," (I-BERT model)"),aLe.forEach(t),HAo=i(H),q2=n(H,"LI",{});var nLe=s(q2);Nde=n(nLe,"STRONG",{});var fat=s(Nde);UAo=r(fat,"layoutlm"),fat.forEach(t),JAo=r(nLe," \u2014 "),Gj=n(nLe,"A",{href:!0});var mat=s(Gj);YAo=r(mat,"LayoutLMForMaskedLM"),mat.forEach(t),KAo=r(nLe," (LayoutLM model)"),nLe.forEach(t),ZAo=i(H),N2=n(H,"LI",{});var sLe=s(N2);jde=n(sLe,"STRONG",{});var gat=s(jde);e0o=r(gat,"longformer"),gat.forEach(t),o0o=r(sLe," \u2014 "),Oj=n(sLe,"A",{href:!0});var hat=s(Oj);r0o=r(hat,"LongformerForMaskedLM"),hat.forEach(t),t0o=r(sLe," (Longformer model)"),sLe.forEach(t),a0o=i(H),j2=n(H,"LI",{});var lLe=s(j2);Dde=n(lLe,"STRONG",{});var pat=s(Dde);n0o=r(pat,"mbart"),pat.forEach(t),s0o=r(lLe," \u2014 "),Vj=n(lLe,"A",{href:!0});var uat=s(Vj);l0o=r(uat,"MBartForConditionalGeneration"),uat.forEach(t),i0o=r(lLe," (mBART model)"),lLe.forEach(t),d0o=i(H),D2=n(H,"LI",{});var iLe=s(D2);Gde=n(iLe,"STRONG",{});var _at=s(Gde);c0o=r(_at,"megatron-bert"),_at.forEach(t),f0o=r(iLe," \u2014 "),Xj=n(iLe,"A",{href:!0});var bat=s(Xj);m0o=r(bat,"MegatronBertForMaskedLM"),bat.forEach(t),g0o=r(iLe," (MegatronBert model)"),iLe.forEach(t),h0o=i(H),G2=n(H,"LI",{});var dLe=s(G2);Ode=n(dLe,"STRONG",{});var vat=s(Ode);p0o=r(vat,"mobilebert"),vat.forEach(t),u0o=r(dLe," \u2014 "),zj=n(dLe,"A",{href:!0});var Fat=s(zj);_0o=r(Fat,"MobileBertForMaskedLM"),Fat.forEach(t),b0o=r(dLe," (MobileBERT model)"),dLe.forEach(t),v0o=i(H),O2=n(H,"LI",{});var cLe=s(O2);Vde=n(cLe,"STRONG",{});var Tat=s(Vde);F0o=r(Tat,"mpnet"),Tat.forEach(t),T0o=r(cLe," \u2014 "),Wj=n(cLe,"A",{href:!0});var Mat=s(Wj);M0o=r(Mat,"MPNetForMaskedLM"),Mat.forEach(t),E0o=r(cLe," (MPNet model)"),cLe.forEach(t),C0o=i(H),V2=n(H,"LI",{});var fLe=s(V2);Xde=n(fLe,"STRONG",{});var Eat=s(Xde);w0o=r(Eat,"nystromformer"),Eat.forEach(t),A0o=r(fLe," \u2014 "),Qj=n(fLe,"A",{href:!0});var Cat=s(Qj);y0o=r(Cat,"NystromformerForMaskedLM"),Cat.forEach(t),L0o=r(fLe," (Nystromformer model)"),fLe.forEach(t),x0o=i(H),X2=n(H,"LI",{});var mLe=s(X2);zde=n(mLe,"STRONG",{});var wat=s(zde);$0o=r(wat,"perceiver"),wat.forEach(t),k0o=r(mLe," \u2014 "),Hj=n(mLe,"A",{href:!0});var Aat=s(Hj);S0o=r(Aat,"PerceiverForMaskedLM"),Aat.forEach(t),R0o=r(mLe," (Perceiver model)"),mLe.forEach(t),P0o=i(H),z2=n(H,"LI",{});var gLe=s(z2);Wde=n(gLe,"STRONG",{});var yat=s(Wde);B0o=r(yat,"qdqbert"),yat.forEach(t),I0o=r(gLe," \u2014 "),Uj=n(gLe,"A",{href:!0});var Lat=s(Uj);q0o=r(Lat,"QDQBertForMaskedLM"),Lat.forEach(t),N0o=r(gLe," (QDQBert model)"),gLe.forEach(t),j0o=i(H),W2=n(H,"LI",{});var hLe=s(W2);Qde=n(hLe,"STRONG",{});var xat=s(Qde);D0o=r(xat,"reformer"),xat.forEach(t),G0o=r(hLe," \u2014 "),Jj=n(hLe,"A",{href:!0});var $at=s(Jj);O0o=r($at,"ReformerForMaskedLM"),$at.forEach(t),V0o=r(hLe," (Reformer model)"),hLe.forEach(t),X0o=i(H),Q2=n(H,"LI",{});var pLe=s(Q2);Hde=n(pLe,"STRONG",{});var kat=s(Hde);z0o=r(kat,"rembert"),kat.forEach(t),W0o=r(pLe," \u2014 "),Yj=n(pLe,"A",{href:!0});var Sat=s(Yj);Q0o=r(Sat,"RemBertForMaskedLM"),Sat.forEach(t),H0o=r(pLe," (RemBERT model)"),pLe.forEach(t),U0o=i(H),H2=n(H,"LI",{});var uLe=s(H2);Ude=n(uLe,"STRONG",{});var Rat=s(Ude);J0o=r(Rat,"roberta"),Rat.forEach(t),Y0o=r(uLe," \u2014 "),Kj=n(uLe,"A",{href:!0});var Pat=s(Kj);K0o=r(Pat,"RobertaForMaskedLM"),Pat.forEach(t),Z0o=r(uLe," (RoBERTa model)"),uLe.forEach(t),e6o=i(H),U2=n(H,"LI",{});var _Le=s(U2);Jde=n(_Le,"STRONG",{});var Bat=s(Jde);o6o=r(Bat,"roformer"),Bat.forEach(t),r6o=r(_Le," \u2014 "),Zj=n(_Le,"A",{href:!0});var Iat=s(Zj);t6o=r(Iat,"RoFormerForMaskedLM"),Iat.forEach(t),a6o=r(_Le," (RoFormer model)"),_Le.forEach(t),n6o=i(H),J2=n(H,"LI",{});var bLe=s(J2);Yde=n(bLe,"STRONG",{});var qat=s(Yde);s6o=r(qat,"squeezebert"),qat.forEach(t),l6o=r(bLe," \u2014 "),eD=n(bLe,"A",{href:!0});var Nat=s(eD);i6o=r(Nat,"SqueezeBertForMaskedLM"),Nat.forEach(t),d6o=r(bLe," (SqueezeBERT model)"),bLe.forEach(t),c6o=i(H),Y2=n(H,"LI",{});var vLe=s(Y2);Kde=n(vLe,"STRONG",{});var jat=s(Kde);f6o=r(jat,"tapas"),jat.forEach(t),m6o=r(vLe," \u2014 "),oD=n(vLe,"A",{href:!0});var Dat=s(oD);g6o=r(Dat,"TapasForMaskedLM"),Dat.forEach(t),h6o=r(vLe," (TAPAS model)"),vLe.forEach(t),p6o=i(H),K2=n(H,"LI",{});var FLe=s(K2);Zde=n(FLe,"STRONG",{});var Gat=s(Zde);u6o=r(Gat,"wav2vec2"),Gat.forEach(t),_6o=r(FLe," \u2014 "),ece=n(FLe,"CODE",{});var Oat=s(ece);b6o=r(Oat,"Wav2Vec2ForMaskedLM"),Oat.forEach(t),v6o=r(FLe," (Wav2Vec2 model)"),FLe.forEach(t),F6o=i(H),Z2=n(H,"LI",{});var TLe=s(Z2);oce=n(TLe,"STRONG",{});var Vat=s(oce);T6o=r(Vat,"xlm"),Vat.forEach(t),M6o=r(TLe," \u2014 "),rD=n(TLe,"A",{href:!0});var Xat=s(rD);E6o=r(Xat,"XLMWithLMHeadModel"),Xat.forEach(t),C6o=r(TLe," (XLM model)"),TLe.forEach(t),w6o=i(H),e1=n(H,"LI",{});var MLe=s(e1);rce=n(MLe,"STRONG",{});var zat=s(rce);A6o=r(zat,"xlm-roberta"),zat.forEach(t),y6o=r(MLe," \u2014 "),tD=n(MLe,"A",{href:!0});var Wat=s(tD);L6o=r(Wat,"XLMRobertaForMaskedLM"),Wat.forEach(t),x6o=r(MLe," (XLM-RoBERTa model)"),MLe.forEach(t),$6o=i(H),o1=n(H,"LI",{});var ELe=s(o1);tce=n(ELe,"STRONG",{});var Qat=s(tce);k6o=r(Qat,"xlm-roberta-xl"),Qat.forEach(t),S6o=r(ELe," \u2014 "),aD=n(ELe,"A",{href:!0});var Hat=s(aD);R6o=r(Hat,"XLMRobertaXLForMaskedLM"),Hat.forEach(t),P6o=r(ELe," (XLM-RoBERTa-XL model)"),ELe.forEach(t),B6o=i(H),r1=n(H,"LI",{});var CLe=s(r1);ace=n(CLe,"STRONG",{});var Uat=s(ace);I6o=r(Uat,"yoso"),Uat.forEach(t),q6o=r(CLe," \u2014 "),nD=n(CLe,"A",{href:!0});var Jat=s(nD);N6o=r(Jat,"YosoForMaskedLM"),Jat.forEach(t),j6o=r(CLe," (YOSO model)"),CLe.forEach(t),H.forEach(t),D6o=i(aa),t1=n(aa,"P",{});var wLe=s(t1);G6o=r(wLe,"The model is set in evaluation mode by default using "),nce=n(wLe,"CODE",{});var Yat=s(nce);O6o=r(Yat,"model.eval()"),Yat.forEach(t),V6o=r(wLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sce=n(wLe,"CODE",{});var Kat=s(sce);X6o=r(Kat,"model.train()"),Kat.forEach(t),wLe.forEach(t),z6o=i(aa),T(a1.$$.fragment,aa),aa.forEach(t),Vs.forEach(t),aqe=i(f),Ii=n(f,"H2",{class:!0});var ije=s(Ii);n1=n(ije,"A",{id:!0,class:!0,href:!0});var Zat=s(n1);lce=n(Zat,"SPAN",{});var ent=s(lce);T(ry.$$.fragment,ent),ent.forEach(t),Zat.forEach(t),W6o=i(ije),ice=n(ije,"SPAN",{});var ont=s(ice);Q6o=r(ont,"AutoModelForSeq2SeqLM"),ont.forEach(t),ije.forEach(t),nqe=i(f),So=n(f,"DIV",{class:!0});var Xs=s(So);T(ty.$$.fragment,Xs),H6o=i(Xs),qi=n(Xs,"P",{});var GK=s(qi);U6o=r(GK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),sD=n(GK,"A",{href:!0});var rnt=s(sD);J6o=r(rnt,"from_pretrained()"),rnt.forEach(t),Y6o=r(GK," class method or the "),lD=n(GK,"A",{href:!0});var tnt=s(lD);K6o=r(tnt,"from_config()"),tnt.forEach(t),Z6o=r(GK,` class
method.`),GK.forEach(t),eyo=i(Xs),ay=n(Xs,"P",{});var dje=s(ay);oyo=r(dje,"This class cannot be instantiated directly using "),dce=n(dje,"CODE",{});var ant=s(dce);ryo=r(ant,"__init__()"),ant.forEach(t),tyo=r(dje," (throws an error)."),dje.forEach(t),ayo=i(Xs),lt=n(Xs,"DIV",{class:!0});var MA=s(lt);T(ny.$$.fragment,MA),nyo=i(MA),cce=n(MA,"P",{});var nnt=s(cce);syo=r(nnt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),nnt.forEach(t),lyo=i(MA),Ni=n(MA,"P",{});var OK=s(Ni);iyo=r(OK,`Note:
Loading a model from its configuration file does `),fce=n(OK,"STRONG",{});var snt=s(fce);dyo=r(snt,"not"),snt.forEach(t),cyo=r(OK,` load the model weights. It only affects the
model\u2019s configuration. Use `),iD=n(OK,"A",{href:!0});var lnt=s(iD);fyo=r(lnt,"from_pretrained()"),lnt.forEach(t),myo=r(OK," to load the model weights."),OK.forEach(t),gyo=i(MA),T(s1.$$.fragment,MA),MA.forEach(t),hyo=i(Xs),eo=n(Xs,"DIV",{class:!0});var na=s(eo);T(sy.$$.fragment,na),pyo=i(na),mce=n(na,"P",{});var int=s(mce);uyo=r(int,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),int.forEach(t),_yo=i(na),Sa=n(na,"P",{});var EA=s(Sa);byo=r(EA,"The model class to instantiate is selected based on the "),gce=n(EA,"CODE",{});var dnt=s(gce);vyo=r(dnt,"model_type"),dnt.forEach(t),Fyo=r(EA,` property of the config object (either
passed as an argument or loaded from `),hce=n(EA,"CODE",{});var cnt=s(hce);Tyo=r(cnt,"pretrained_model_name_or_path"),cnt.forEach(t),Myo=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pce=n(EA,"CODE",{});var fnt=s(pce);Eyo=r(fnt,"pretrained_model_name_or_path"),fnt.forEach(t),Cyo=r(EA,":"),EA.forEach(t),wyo=i(na),ue=n(na,"UL",{});var ve=s(ue);l1=n(ve,"LI",{});var ALe=s(l1);uce=n(ALe,"STRONG",{});var mnt=s(uce);Ayo=r(mnt,"bart"),mnt.forEach(t),yyo=r(ALe," \u2014 "),dD=n(ALe,"A",{href:!0});var gnt=s(dD);Lyo=r(gnt,"BartForConditionalGeneration"),gnt.forEach(t),xyo=r(ALe," (BART model)"),ALe.forEach(t),$yo=i(ve),i1=n(ve,"LI",{});var yLe=s(i1);_ce=n(yLe,"STRONG",{});var hnt=s(_ce);kyo=r(hnt,"bigbird_pegasus"),hnt.forEach(t),Syo=r(yLe," \u2014 "),cD=n(yLe,"A",{href:!0});var pnt=s(cD);Ryo=r(pnt,"BigBirdPegasusForConditionalGeneration"),pnt.forEach(t),Pyo=r(yLe," (BigBirdPegasus model)"),yLe.forEach(t),Byo=i(ve),d1=n(ve,"LI",{});var LLe=s(d1);bce=n(LLe,"STRONG",{});var unt=s(bce);Iyo=r(unt,"blenderbot"),unt.forEach(t),qyo=r(LLe," \u2014 "),fD=n(LLe,"A",{href:!0});var _nt=s(fD);Nyo=r(_nt,"BlenderbotForConditionalGeneration"),_nt.forEach(t),jyo=r(LLe," (Blenderbot model)"),LLe.forEach(t),Dyo=i(ve),c1=n(ve,"LI",{});var xLe=s(c1);vce=n(xLe,"STRONG",{});var bnt=s(vce);Gyo=r(bnt,"blenderbot-small"),bnt.forEach(t),Oyo=r(xLe," \u2014 "),mD=n(xLe,"A",{href:!0});var vnt=s(mD);Vyo=r(vnt,"BlenderbotSmallForConditionalGeneration"),vnt.forEach(t),Xyo=r(xLe," (BlenderbotSmall model)"),xLe.forEach(t),zyo=i(ve),f1=n(ve,"LI",{});var $Le=s(f1);Fce=n($Le,"STRONG",{});var Fnt=s(Fce);Wyo=r(Fnt,"encoder-decoder"),Fnt.forEach(t),Qyo=r($Le," \u2014 "),gD=n($Le,"A",{href:!0});var Tnt=s(gD);Hyo=r(Tnt,"EncoderDecoderModel"),Tnt.forEach(t),Uyo=r($Le," (Encoder decoder model)"),$Le.forEach(t),Jyo=i(ve),m1=n(ve,"LI",{});var kLe=s(m1);Tce=n(kLe,"STRONG",{});var Mnt=s(Tce);Yyo=r(Mnt,"fsmt"),Mnt.forEach(t),Kyo=r(kLe," \u2014 "),hD=n(kLe,"A",{href:!0});var Ent=s(hD);Zyo=r(Ent,"FSMTForConditionalGeneration"),Ent.forEach(t),eLo=r(kLe," (FairSeq Machine-Translation model)"),kLe.forEach(t),oLo=i(ve),g1=n(ve,"LI",{});var SLe=s(g1);Mce=n(SLe,"STRONG",{});var Cnt=s(Mce);rLo=r(Cnt,"led"),Cnt.forEach(t),tLo=r(SLe," \u2014 "),pD=n(SLe,"A",{href:!0});var wnt=s(pD);aLo=r(wnt,"LEDForConditionalGeneration"),wnt.forEach(t),nLo=r(SLe," (LED model)"),SLe.forEach(t),sLo=i(ve),h1=n(ve,"LI",{});var RLe=s(h1);Ece=n(RLe,"STRONG",{});var Ant=s(Ece);lLo=r(Ant,"m2m_100"),Ant.forEach(t),iLo=r(RLe," \u2014 "),uD=n(RLe,"A",{href:!0});var ynt=s(uD);dLo=r(ynt,"M2M100ForConditionalGeneration"),ynt.forEach(t),cLo=r(RLe," (M2M100 model)"),RLe.forEach(t),fLo=i(ve),p1=n(ve,"LI",{});var PLe=s(p1);Cce=n(PLe,"STRONG",{});var Lnt=s(Cce);mLo=r(Lnt,"marian"),Lnt.forEach(t),gLo=r(PLe," \u2014 "),_D=n(PLe,"A",{href:!0});var xnt=s(_D);hLo=r(xnt,"MarianMTModel"),xnt.forEach(t),pLo=r(PLe," (Marian model)"),PLe.forEach(t),uLo=i(ve),u1=n(ve,"LI",{});var BLe=s(u1);wce=n(BLe,"STRONG",{});var $nt=s(wce);_Lo=r($nt,"mbart"),$nt.forEach(t),bLo=r(BLe," \u2014 "),bD=n(BLe,"A",{href:!0});var knt=s(bD);vLo=r(knt,"MBartForConditionalGeneration"),knt.forEach(t),FLo=r(BLe," (mBART model)"),BLe.forEach(t),TLo=i(ve),_1=n(ve,"LI",{});var ILe=s(_1);Ace=n(ILe,"STRONG",{});var Snt=s(Ace);MLo=r(Snt,"mt5"),Snt.forEach(t),ELo=r(ILe," \u2014 "),vD=n(ILe,"A",{href:!0});var Rnt=s(vD);CLo=r(Rnt,"MT5ForConditionalGeneration"),Rnt.forEach(t),wLo=r(ILe," (mT5 model)"),ILe.forEach(t),ALo=i(ve),b1=n(ve,"LI",{});var qLe=s(b1);yce=n(qLe,"STRONG",{});var Pnt=s(yce);yLo=r(Pnt,"pegasus"),Pnt.forEach(t),LLo=r(qLe," \u2014 "),FD=n(qLe,"A",{href:!0});var Bnt=s(FD);xLo=r(Bnt,"PegasusForConditionalGeneration"),Bnt.forEach(t),$Lo=r(qLe," (Pegasus model)"),qLe.forEach(t),kLo=i(ve),v1=n(ve,"LI",{});var NLe=s(v1);Lce=n(NLe,"STRONG",{});var Int=s(Lce);SLo=r(Int,"plbart"),Int.forEach(t),RLo=r(NLe," \u2014 "),TD=n(NLe,"A",{href:!0});var qnt=s(TD);PLo=r(qnt,"PLBartForConditionalGeneration"),qnt.forEach(t),BLo=r(NLe," (PLBart model)"),NLe.forEach(t),ILo=i(ve),F1=n(ve,"LI",{});var jLe=s(F1);xce=n(jLe,"STRONG",{});var Nnt=s(xce);qLo=r(Nnt,"prophetnet"),Nnt.forEach(t),NLo=r(jLe," \u2014 "),MD=n(jLe,"A",{href:!0});var jnt=s(MD);jLo=r(jnt,"ProphetNetForConditionalGeneration"),jnt.forEach(t),DLo=r(jLe," (ProphetNet model)"),jLe.forEach(t),GLo=i(ve),T1=n(ve,"LI",{});var DLe=s(T1);$ce=n(DLe,"STRONG",{});var Dnt=s($ce);OLo=r(Dnt,"t5"),Dnt.forEach(t),VLo=r(DLe," \u2014 "),ED=n(DLe,"A",{href:!0});var Gnt=s(ED);XLo=r(Gnt,"T5ForConditionalGeneration"),Gnt.forEach(t),zLo=r(DLe," (T5 model)"),DLe.forEach(t),WLo=i(ve),M1=n(ve,"LI",{});var GLe=s(M1);kce=n(GLe,"STRONG",{});var Ont=s(kce);QLo=r(Ont,"xlm-prophetnet"),Ont.forEach(t),HLo=r(GLe," \u2014 "),CD=n(GLe,"A",{href:!0});var Vnt=s(CD);ULo=r(Vnt,"XLMProphetNetForConditionalGeneration"),Vnt.forEach(t),JLo=r(GLe," (XLMProphetNet model)"),GLe.forEach(t),ve.forEach(t),YLo=i(na),E1=n(na,"P",{});var OLe=s(E1);KLo=r(OLe,"The model is set in evaluation mode by default using "),Sce=n(OLe,"CODE",{});var Xnt=s(Sce);ZLo=r(Xnt,"model.eval()"),Xnt.forEach(t),e8o=r(OLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rce=n(OLe,"CODE",{});var znt=s(Rce);o8o=r(znt,"model.train()"),znt.forEach(t),OLe.forEach(t),r8o=i(na),T(C1.$$.fragment,na),na.forEach(t),Xs.forEach(t),sqe=i(f),ji=n(f,"H2",{class:!0});var cje=s(ji);w1=n(cje,"A",{id:!0,class:!0,href:!0});var Wnt=s(w1);Pce=n(Wnt,"SPAN",{});var Qnt=s(Pce);T(ly.$$.fragment,Qnt),Qnt.forEach(t),Wnt.forEach(t),t8o=i(cje),Bce=n(cje,"SPAN",{});var Hnt=s(Bce);a8o=r(Hnt,"AutoModelForSequenceClassification"),Hnt.forEach(t),cje.forEach(t),lqe=i(f),Ro=n(f,"DIV",{class:!0});var zs=s(Ro);T(iy.$$.fragment,zs),n8o=i(zs),Di=n(zs,"P",{});var VK=s(Di);s8o=r(VK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wD=n(VK,"A",{href:!0});var Unt=s(wD);l8o=r(Unt,"from_pretrained()"),Unt.forEach(t),i8o=r(VK," class method or the "),AD=n(VK,"A",{href:!0});var Jnt=s(AD);d8o=r(Jnt,"from_config()"),Jnt.forEach(t),c8o=r(VK,` class
method.`),VK.forEach(t),f8o=i(zs),dy=n(zs,"P",{});var fje=s(dy);m8o=r(fje,"This class cannot be instantiated directly using "),Ice=n(fje,"CODE",{});var Ynt=s(Ice);g8o=r(Ynt,"__init__()"),Ynt.forEach(t),h8o=r(fje," (throws an error)."),fje.forEach(t),p8o=i(zs),it=n(zs,"DIV",{class:!0});var CA=s(it);T(cy.$$.fragment,CA),u8o=i(CA),qce=n(CA,"P",{});var Knt=s(qce);_8o=r(Knt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Knt.forEach(t),b8o=i(CA),Gi=n(CA,"P",{});var XK=s(Gi);v8o=r(XK,`Note:
Loading a model from its configuration file does `),Nce=n(XK,"STRONG",{});var Znt=s(Nce);F8o=r(Znt,"not"),Znt.forEach(t),T8o=r(XK,` load the model weights. It only affects the
model\u2019s configuration. Use `),yD=n(XK,"A",{href:!0});var est=s(yD);M8o=r(est,"from_pretrained()"),est.forEach(t),E8o=r(XK," to load the model weights."),XK.forEach(t),C8o=i(CA),T(A1.$$.fragment,CA),CA.forEach(t),w8o=i(zs),oo=n(zs,"DIV",{class:!0});var sa=s(oo);T(fy.$$.fragment,sa),A8o=i(sa),jce=n(sa,"P",{});var ost=s(jce);y8o=r(ost,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ost.forEach(t),L8o=i(sa),Ra=n(sa,"P",{});var wA=s(Ra);x8o=r(wA,"The model class to instantiate is selected based on the "),Dce=n(wA,"CODE",{});var rst=s(Dce);$8o=r(rst,"model_type"),rst.forEach(t),k8o=r(wA,` property of the config object (either
passed as an argument or loaded from `),Gce=n(wA,"CODE",{});var tst=s(Gce);S8o=r(tst,"pretrained_model_name_or_path"),tst.forEach(t),R8o=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oce=n(wA,"CODE",{});var ast=s(Oce);P8o=r(ast,"pretrained_model_name_or_path"),ast.forEach(t),B8o=r(wA,":"),wA.forEach(t),I8o=i(sa),N=n(sa,"UL",{});var D=s(N);y1=n(D,"LI",{});var VLe=s(y1);Vce=n(VLe,"STRONG",{});var nst=s(Vce);q8o=r(nst,"albert"),nst.forEach(t),N8o=r(VLe," \u2014 "),LD=n(VLe,"A",{href:!0});var sst=s(LD);j8o=r(sst,"AlbertForSequenceClassification"),sst.forEach(t),D8o=r(VLe," (ALBERT model)"),VLe.forEach(t),G8o=i(D),L1=n(D,"LI",{});var XLe=s(L1);Xce=n(XLe,"STRONG",{});var lst=s(Xce);O8o=r(lst,"bart"),lst.forEach(t),V8o=r(XLe," \u2014 "),xD=n(XLe,"A",{href:!0});var ist=s(xD);X8o=r(ist,"BartForSequenceClassification"),ist.forEach(t),z8o=r(XLe," (BART model)"),XLe.forEach(t),W8o=i(D),x1=n(D,"LI",{});var zLe=s(x1);zce=n(zLe,"STRONG",{});var dst=s(zce);Q8o=r(dst,"bert"),dst.forEach(t),H8o=r(zLe," \u2014 "),$D=n(zLe,"A",{href:!0});var cst=s($D);U8o=r(cst,"BertForSequenceClassification"),cst.forEach(t),J8o=r(zLe," (BERT model)"),zLe.forEach(t),Y8o=i(D),$1=n(D,"LI",{});var WLe=s($1);Wce=n(WLe,"STRONG",{});var fst=s(Wce);K8o=r(fst,"big_bird"),fst.forEach(t),Z8o=r(WLe," \u2014 "),kD=n(WLe,"A",{href:!0});var mst=s(kD);exo=r(mst,"BigBirdForSequenceClassification"),mst.forEach(t),oxo=r(WLe," (BigBird model)"),WLe.forEach(t),rxo=i(D),k1=n(D,"LI",{});var QLe=s(k1);Qce=n(QLe,"STRONG",{});var gst=s(Qce);txo=r(gst,"bigbird_pegasus"),gst.forEach(t),axo=r(QLe," \u2014 "),SD=n(QLe,"A",{href:!0});var hst=s(SD);nxo=r(hst,"BigBirdPegasusForSequenceClassification"),hst.forEach(t),sxo=r(QLe," (BigBirdPegasus model)"),QLe.forEach(t),lxo=i(D),S1=n(D,"LI",{});var HLe=s(S1);Hce=n(HLe,"STRONG",{});var pst=s(Hce);ixo=r(pst,"camembert"),pst.forEach(t),dxo=r(HLe," \u2014 "),RD=n(HLe,"A",{href:!0});var ust=s(RD);cxo=r(ust,"CamembertForSequenceClassification"),ust.forEach(t),fxo=r(HLe," (CamemBERT model)"),HLe.forEach(t),mxo=i(D),R1=n(D,"LI",{});var ULe=s(R1);Uce=n(ULe,"STRONG",{});var _st=s(Uce);gxo=r(_st,"canine"),_st.forEach(t),hxo=r(ULe," \u2014 "),PD=n(ULe,"A",{href:!0});var bst=s(PD);pxo=r(bst,"CanineForSequenceClassification"),bst.forEach(t),uxo=r(ULe," (Canine model)"),ULe.forEach(t),_xo=i(D),P1=n(D,"LI",{});var JLe=s(P1);Jce=n(JLe,"STRONG",{});var vst=s(Jce);bxo=r(vst,"convbert"),vst.forEach(t),vxo=r(JLe," \u2014 "),BD=n(JLe,"A",{href:!0});var Fst=s(BD);Fxo=r(Fst,"ConvBertForSequenceClassification"),Fst.forEach(t),Txo=r(JLe," (ConvBERT model)"),JLe.forEach(t),Mxo=i(D),B1=n(D,"LI",{});var YLe=s(B1);Yce=n(YLe,"STRONG",{});var Tst=s(Yce);Exo=r(Tst,"ctrl"),Tst.forEach(t),Cxo=r(YLe," \u2014 "),ID=n(YLe,"A",{href:!0});var Mst=s(ID);wxo=r(Mst,"CTRLForSequenceClassification"),Mst.forEach(t),Axo=r(YLe," (CTRL model)"),YLe.forEach(t),yxo=i(D),I1=n(D,"LI",{});var KLe=s(I1);Kce=n(KLe,"STRONG",{});var Est=s(Kce);Lxo=r(Est,"data2vec-text"),Est.forEach(t),xxo=r(KLe," \u2014 "),qD=n(KLe,"A",{href:!0});var Cst=s(qD);$xo=r(Cst,"Data2VecTextForSequenceClassification"),Cst.forEach(t),kxo=r(KLe," (Data2VecText model)"),KLe.forEach(t),Sxo=i(D),q1=n(D,"LI",{});var ZLe=s(q1);Zce=n(ZLe,"STRONG",{});var wst=s(Zce);Rxo=r(wst,"deberta"),wst.forEach(t),Pxo=r(ZLe," \u2014 "),ND=n(ZLe,"A",{href:!0});var Ast=s(ND);Bxo=r(Ast,"DebertaForSequenceClassification"),Ast.forEach(t),Ixo=r(ZLe," (DeBERTa model)"),ZLe.forEach(t),qxo=i(D),N1=n(D,"LI",{});var e8e=s(N1);efe=n(e8e,"STRONG",{});var yst=s(efe);Nxo=r(yst,"deberta-v2"),yst.forEach(t),jxo=r(e8e," \u2014 "),jD=n(e8e,"A",{href:!0});var Lst=s(jD);Dxo=r(Lst,"DebertaV2ForSequenceClassification"),Lst.forEach(t),Gxo=r(e8e," (DeBERTa-v2 model)"),e8e.forEach(t),Oxo=i(D),j1=n(D,"LI",{});var o8e=s(j1);ofe=n(o8e,"STRONG",{});var xst=s(ofe);Vxo=r(xst,"distilbert"),xst.forEach(t),Xxo=r(o8e," \u2014 "),DD=n(o8e,"A",{href:!0});var $st=s(DD);zxo=r($st,"DistilBertForSequenceClassification"),$st.forEach(t),Wxo=r(o8e," (DistilBERT model)"),o8e.forEach(t),Qxo=i(D),D1=n(D,"LI",{});var r8e=s(D1);rfe=n(r8e,"STRONG",{});var kst=s(rfe);Hxo=r(kst,"electra"),kst.forEach(t),Uxo=r(r8e," \u2014 "),GD=n(r8e,"A",{href:!0});var Sst=s(GD);Jxo=r(Sst,"ElectraForSequenceClassification"),Sst.forEach(t),Yxo=r(r8e," (ELECTRA model)"),r8e.forEach(t),Kxo=i(D),G1=n(D,"LI",{});var t8e=s(G1);tfe=n(t8e,"STRONG",{});var Rst=s(tfe);Zxo=r(Rst,"flaubert"),Rst.forEach(t),e9o=r(t8e," \u2014 "),OD=n(t8e,"A",{href:!0});var Pst=s(OD);o9o=r(Pst,"FlaubertForSequenceClassification"),Pst.forEach(t),r9o=r(t8e," (FlauBERT model)"),t8e.forEach(t),t9o=i(D),O1=n(D,"LI",{});var a8e=s(O1);afe=n(a8e,"STRONG",{});var Bst=s(afe);a9o=r(Bst,"fnet"),Bst.forEach(t),n9o=r(a8e," \u2014 "),VD=n(a8e,"A",{href:!0});var Ist=s(VD);s9o=r(Ist,"FNetForSequenceClassification"),Ist.forEach(t),l9o=r(a8e," (FNet model)"),a8e.forEach(t),i9o=i(D),V1=n(D,"LI",{});var n8e=s(V1);nfe=n(n8e,"STRONG",{});var qst=s(nfe);d9o=r(qst,"funnel"),qst.forEach(t),c9o=r(n8e," \u2014 "),XD=n(n8e,"A",{href:!0});var Nst=s(XD);f9o=r(Nst,"FunnelForSequenceClassification"),Nst.forEach(t),m9o=r(n8e," (Funnel Transformer model)"),n8e.forEach(t),g9o=i(D),X1=n(D,"LI",{});var s8e=s(X1);sfe=n(s8e,"STRONG",{});var jst=s(sfe);h9o=r(jst,"gpt2"),jst.forEach(t),p9o=r(s8e," \u2014 "),zD=n(s8e,"A",{href:!0});var Dst=s(zD);u9o=r(Dst,"GPT2ForSequenceClassification"),Dst.forEach(t),_9o=r(s8e," (OpenAI GPT-2 model)"),s8e.forEach(t),b9o=i(D),z1=n(D,"LI",{});var l8e=s(z1);lfe=n(l8e,"STRONG",{});var Gst=s(lfe);v9o=r(Gst,"gpt_neo"),Gst.forEach(t),F9o=r(l8e," \u2014 "),WD=n(l8e,"A",{href:!0});var Ost=s(WD);T9o=r(Ost,"GPTNeoForSequenceClassification"),Ost.forEach(t),M9o=r(l8e," (GPT Neo model)"),l8e.forEach(t),E9o=i(D),W1=n(D,"LI",{});var i8e=s(W1);ife=n(i8e,"STRONG",{});var Vst=s(ife);C9o=r(Vst,"gptj"),Vst.forEach(t),w9o=r(i8e," \u2014 "),QD=n(i8e,"A",{href:!0});var Xst=s(QD);A9o=r(Xst,"GPTJForSequenceClassification"),Xst.forEach(t),y9o=r(i8e," (GPT-J model)"),i8e.forEach(t),L9o=i(D),Q1=n(D,"LI",{});var d8e=s(Q1);dfe=n(d8e,"STRONG",{});var zst=s(dfe);x9o=r(zst,"ibert"),zst.forEach(t),$9o=r(d8e," \u2014 "),HD=n(d8e,"A",{href:!0});var Wst=s(HD);k9o=r(Wst,"IBertForSequenceClassification"),Wst.forEach(t),S9o=r(d8e," (I-BERT model)"),d8e.forEach(t),R9o=i(D),H1=n(D,"LI",{});var c8e=s(H1);cfe=n(c8e,"STRONG",{});var Qst=s(cfe);P9o=r(Qst,"layoutlm"),Qst.forEach(t),B9o=r(c8e," \u2014 "),UD=n(c8e,"A",{href:!0});var Hst=s(UD);I9o=r(Hst,"LayoutLMForSequenceClassification"),Hst.forEach(t),q9o=r(c8e," (LayoutLM model)"),c8e.forEach(t),N9o=i(D),U1=n(D,"LI",{});var f8e=s(U1);ffe=n(f8e,"STRONG",{});var Ust=s(ffe);j9o=r(Ust,"layoutlmv2"),Ust.forEach(t),D9o=r(f8e," \u2014 "),JD=n(f8e,"A",{href:!0});var Jst=s(JD);G9o=r(Jst,"LayoutLMv2ForSequenceClassification"),Jst.forEach(t),O9o=r(f8e," (LayoutLMv2 model)"),f8e.forEach(t),V9o=i(D),J1=n(D,"LI",{});var m8e=s(J1);mfe=n(m8e,"STRONG",{});var Yst=s(mfe);X9o=r(Yst,"led"),Yst.forEach(t),z9o=r(m8e," \u2014 "),YD=n(m8e,"A",{href:!0});var Kst=s(YD);W9o=r(Kst,"LEDForSequenceClassification"),Kst.forEach(t),Q9o=r(m8e," (LED model)"),m8e.forEach(t),H9o=i(D),Y1=n(D,"LI",{});var g8e=s(Y1);gfe=n(g8e,"STRONG",{});var Zst=s(gfe);U9o=r(Zst,"longformer"),Zst.forEach(t),J9o=r(g8e," \u2014 "),KD=n(g8e,"A",{href:!0});var elt=s(KD);Y9o=r(elt,"LongformerForSequenceClassification"),elt.forEach(t),K9o=r(g8e," (Longformer model)"),g8e.forEach(t),Z9o=i(D),K1=n(D,"LI",{});var h8e=s(K1);hfe=n(h8e,"STRONG",{});var olt=s(hfe);e$o=r(olt,"mbart"),olt.forEach(t),o$o=r(h8e," \u2014 "),ZD=n(h8e,"A",{href:!0});var rlt=s(ZD);r$o=r(rlt,"MBartForSequenceClassification"),rlt.forEach(t),t$o=r(h8e," (mBART model)"),h8e.forEach(t),a$o=i(D),Z1=n(D,"LI",{});var p8e=s(Z1);pfe=n(p8e,"STRONG",{});var tlt=s(pfe);n$o=r(tlt,"megatron-bert"),tlt.forEach(t),s$o=r(p8e," \u2014 "),eG=n(p8e,"A",{href:!0});var alt=s(eG);l$o=r(alt,"MegatronBertForSequenceClassification"),alt.forEach(t),i$o=r(p8e," (MegatronBert model)"),p8e.forEach(t),d$o=i(D),e7=n(D,"LI",{});var u8e=s(e7);ufe=n(u8e,"STRONG",{});var nlt=s(ufe);c$o=r(nlt,"mobilebert"),nlt.forEach(t),f$o=r(u8e," \u2014 "),oG=n(u8e,"A",{href:!0});var slt=s(oG);m$o=r(slt,"MobileBertForSequenceClassification"),slt.forEach(t),g$o=r(u8e," (MobileBERT model)"),u8e.forEach(t),h$o=i(D),o7=n(D,"LI",{});var _8e=s(o7);_fe=n(_8e,"STRONG",{});var llt=s(_fe);p$o=r(llt,"mpnet"),llt.forEach(t),u$o=r(_8e," \u2014 "),rG=n(_8e,"A",{href:!0});var ilt=s(rG);_$o=r(ilt,"MPNetForSequenceClassification"),ilt.forEach(t),b$o=r(_8e," (MPNet model)"),_8e.forEach(t),v$o=i(D),r7=n(D,"LI",{});var b8e=s(r7);bfe=n(b8e,"STRONG",{});var dlt=s(bfe);F$o=r(dlt,"nystromformer"),dlt.forEach(t),T$o=r(b8e," \u2014 "),tG=n(b8e,"A",{href:!0});var clt=s(tG);M$o=r(clt,"NystromformerForSequenceClassification"),clt.forEach(t),E$o=r(b8e," (Nystromformer model)"),b8e.forEach(t),C$o=i(D),t7=n(D,"LI",{});var v8e=s(t7);vfe=n(v8e,"STRONG",{});var flt=s(vfe);w$o=r(flt,"openai-gpt"),flt.forEach(t),A$o=r(v8e," \u2014 "),aG=n(v8e,"A",{href:!0});var mlt=s(aG);y$o=r(mlt,"OpenAIGPTForSequenceClassification"),mlt.forEach(t),L$o=r(v8e," (OpenAI GPT model)"),v8e.forEach(t),x$o=i(D),a7=n(D,"LI",{});var F8e=s(a7);Ffe=n(F8e,"STRONG",{});var glt=s(Ffe);$$o=r(glt,"perceiver"),glt.forEach(t),k$o=r(F8e," \u2014 "),nG=n(F8e,"A",{href:!0});var hlt=s(nG);S$o=r(hlt,"PerceiverForSequenceClassification"),hlt.forEach(t),R$o=r(F8e," (Perceiver model)"),F8e.forEach(t),P$o=i(D),n7=n(D,"LI",{});var T8e=s(n7);Tfe=n(T8e,"STRONG",{});var plt=s(Tfe);B$o=r(plt,"plbart"),plt.forEach(t),I$o=r(T8e," \u2014 "),sG=n(T8e,"A",{href:!0});var ult=s(sG);q$o=r(ult,"PLBartForSequenceClassification"),ult.forEach(t),N$o=r(T8e," (PLBart model)"),T8e.forEach(t),j$o=i(D),s7=n(D,"LI",{});var M8e=s(s7);Mfe=n(M8e,"STRONG",{});var _lt=s(Mfe);D$o=r(_lt,"qdqbert"),_lt.forEach(t),G$o=r(M8e," \u2014 "),lG=n(M8e,"A",{href:!0});var blt=s(lG);O$o=r(blt,"QDQBertForSequenceClassification"),blt.forEach(t),V$o=r(M8e," (QDQBert model)"),M8e.forEach(t),X$o=i(D),l7=n(D,"LI",{});var E8e=s(l7);Efe=n(E8e,"STRONG",{});var vlt=s(Efe);z$o=r(vlt,"reformer"),vlt.forEach(t),W$o=r(E8e," \u2014 "),iG=n(E8e,"A",{href:!0});var Flt=s(iG);Q$o=r(Flt,"ReformerForSequenceClassification"),Flt.forEach(t),H$o=r(E8e," (Reformer model)"),E8e.forEach(t),U$o=i(D),i7=n(D,"LI",{});var C8e=s(i7);Cfe=n(C8e,"STRONG",{});var Tlt=s(Cfe);J$o=r(Tlt,"rembert"),Tlt.forEach(t),Y$o=r(C8e," \u2014 "),dG=n(C8e,"A",{href:!0});var Mlt=s(dG);K$o=r(Mlt,"RemBertForSequenceClassification"),Mlt.forEach(t),Z$o=r(C8e," (RemBERT model)"),C8e.forEach(t),eko=i(D),d7=n(D,"LI",{});var w8e=s(d7);wfe=n(w8e,"STRONG",{});var Elt=s(wfe);oko=r(Elt,"roberta"),Elt.forEach(t),rko=r(w8e," \u2014 "),cG=n(w8e,"A",{href:!0});var Clt=s(cG);tko=r(Clt,"RobertaForSequenceClassification"),Clt.forEach(t),ako=r(w8e," (RoBERTa model)"),w8e.forEach(t),nko=i(D),c7=n(D,"LI",{});var A8e=s(c7);Afe=n(A8e,"STRONG",{});var wlt=s(Afe);sko=r(wlt,"roformer"),wlt.forEach(t),lko=r(A8e," \u2014 "),fG=n(A8e,"A",{href:!0});var Alt=s(fG);iko=r(Alt,"RoFormerForSequenceClassification"),Alt.forEach(t),dko=r(A8e," (RoFormer model)"),A8e.forEach(t),cko=i(D),f7=n(D,"LI",{});var y8e=s(f7);yfe=n(y8e,"STRONG",{});var ylt=s(yfe);fko=r(ylt,"squeezebert"),ylt.forEach(t),mko=r(y8e," \u2014 "),mG=n(y8e,"A",{href:!0});var Llt=s(mG);gko=r(Llt,"SqueezeBertForSequenceClassification"),Llt.forEach(t),hko=r(y8e," (SqueezeBERT model)"),y8e.forEach(t),pko=i(D),m7=n(D,"LI",{});var L8e=s(m7);Lfe=n(L8e,"STRONG",{});var xlt=s(Lfe);uko=r(xlt,"tapas"),xlt.forEach(t),_ko=r(L8e," \u2014 "),gG=n(L8e,"A",{href:!0});var $lt=s(gG);bko=r($lt,"TapasForSequenceClassification"),$lt.forEach(t),vko=r(L8e," (TAPAS model)"),L8e.forEach(t),Fko=i(D),g7=n(D,"LI",{});var x8e=s(g7);xfe=n(x8e,"STRONG",{});var klt=s(xfe);Tko=r(klt,"transfo-xl"),klt.forEach(t),Mko=r(x8e," \u2014 "),hG=n(x8e,"A",{href:!0});var Slt=s(hG);Eko=r(Slt,"TransfoXLForSequenceClassification"),Slt.forEach(t),Cko=r(x8e," (Transformer-XL model)"),x8e.forEach(t),wko=i(D),h7=n(D,"LI",{});var $8e=s(h7);$fe=n($8e,"STRONG",{});var Rlt=s($fe);Ako=r(Rlt,"xlm"),Rlt.forEach(t),yko=r($8e," \u2014 "),pG=n($8e,"A",{href:!0});var Plt=s(pG);Lko=r(Plt,"XLMForSequenceClassification"),Plt.forEach(t),xko=r($8e," (XLM model)"),$8e.forEach(t),$ko=i(D),p7=n(D,"LI",{});var k8e=s(p7);kfe=n(k8e,"STRONG",{});var Blt=s(kfe);kko=r(Blt,"xlm-roberta"),Blt.forEach(t),Sko=r(k8e," \u2014 "),uG=n(k8e,"A",{href:!0});var Ilt=s(uG);Rko=r(Ilt,"XLMRobertaForSequenceClassification"),Ilt.forEach(t),Pko=r(k8e," (XLM-RoBERTa model)"),k8e.forEach(t),Bko=i(D),u7=n(D,"LI",{});var S8e=s(u7);Sfe=n(S8e,"STRONG",{});var qlt=s(Sfe);Iko=r(qlt,"xlm-roberta-xl"),qlt.forEach(t),qko=r(S8e," \u2014 "),_G=n(S8e,"A",{href:!0});var Nlt=s(_G);Nko=r(Nlt,"XLMRobertaXLForSequenceClassification"),Nlt.forEach(t),jko=r(S8e," (XLM-RoBERTa-XL model)"),S8e.forEach(t),Dko=i(D),_7=n(D,"LI",{});var R8e=s(_7);Rfe=n(R8e,"STRONG",{});var jlt=s(Rfe);Gko=r(jlt,"xlnet"),jlt.forEach(t),Oko=r(R8e," \u2014 "),bG=n(R8e,"A",{href:!0});var Dlt=s(bG);Vko=r(Dlt,"XLNetForSequenceClassification"),Dlt.forEach(t),Xko=r(R8e," (XLNet model)"),R8e.forEach(t),zko=i(D),b7=n(D,"LI",{});var P8e=s(b7);Pfe=n(P8e,"STRONG",{});var Glt=s(Pfe);Wko=r(Glt,"yoso"),Glt.forEach(t),Qko=r(P8e," \u2014 "),vG=n(P8e,"A",{href:!0});var Olt=s(vG);Hko=r(Olt,"YosoForSequenceClassification"),Olt.forEach(t),Uko=r(P8e," (YOSO model)"),P8e.forEach(t),D.forEach(t),Jko=i(sa),v7=n(sa,"P",{});var B8e=s(v7);Yko=r(B8e,"The model is set in evaluation mode by default using "),Bfe=n(B8e,"CODE",{});var Vlt=s(Bfe);Kko=r(Vlt,"model.eval()"),Vlt.forEach(t),Zko=r(B8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ife=n(B8e,"CODE",{});var Xlt=s(Ife);eSo=r(Xlt,"model.train()"),Xlt.forEach(t),B8e.forEach(t),oSo=i(sa),T(F7.$$.fragment,sa),sa.forEach(t),zs.forEach(t),iqe=i(f),Oi=n(f,"H2",{class:!0});var mje=s(Oi);T7=n(mje,"A",{id:!0,class:!0,href:!0});var zlt=s(T7);qfe=n(zlt,"SPAN",{});var Wlt=s(qfe);T(my.$$.fragment,Wlt),Wlt.forEach(t),zlt.forEach(t),rSo=i(mje),Nfe=n(mje,"SPAN",{});var Qlt=s(Nfe);tSo=r(Qlt,"AutoModelForMultipleChoice"),Qlt.forEach(t),mje.forEach(t),dqe=i(f),Po=n(f,"DIV",{class:!0});var Ws=s(Po);T(gy.$$.fragment,Ws),aSo=i(Ws),Vi=n(Ws,"P",{});var zK=s(Vi);nSo=r(zK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),FG=n(zK,"A",{href:!0});var Hlt=s(FG);sSo=r(Hlt,"from_pretrained()"),Hlt.forEach(t),lSo=r(zK," class method or the "),TG=n(zK,"A",{href:!0});var Ult=s(TG);iSo=r(Ult,"from_config()"),Ult.forEach(t),dSo=r(zK,` class
method.`),zK.forEach(t),cSo=i(Ws),hy=n(Ws,"P",{});var gje=s(hy);fSo=r(gje,"This class cannot be instantiated directly using "),jfe=n(gje,"CODE",{});var Jlt=s(jfe);mSo=r(Jlt,"__init__()"),Jlt.forEach(t),gSo=r(gje," (throws an error)."),gje.forEach(t),hSo=i(Ws),dt=n(Ws,"DIV",{class:!0});var AA=s(dt);T(py.$$.fragment,AA),pSo=i(AA),Dfe=n(AA,"P",{});var Ylt=s(Dfe);uSo=r(Ylt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ylt.forEach(t),_So=i(AA),Xi=n(AA,"P",{});var WK=s(Xi);bSo=r(WK,`Note:
Loading a model from its configuration file does `),Gfe=n(WK,"STRONG",{});var Klt=s(Gfe);vSo=r(Klt,"not"),Klt.forEach(t),FSo=r(WK,` load the model weights. It only affects the
model\u2019s configuration. Use `),MG=n(WK,"A",{href:!0});var Zlt=s(MG);TSo=r(Zlt,"from_pretrained()"),Zlt.forEach(t),MSo=r(WK," to load the model weights."),WK.forEach(t),ESo=i(AA),T(M7.$$.fragment,AA),AA.forEach(t),CSo=i(Ws),ro=n(Ws,"DIV",{class:!0});var la=s(ro);T(uy.$$.fragment,la),wSo=i(la),Ofe=n(la,"P",{});var eit=s(Ofe);ASo=r(eit,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),eit.forEach(t),ySo=i(la),Pa=n(la,"P",{});var yA=s(Pa);LSo=r(yA,"The model class to instantiate is selected based on the "),Vfe=n(yA,"CODE",{});var oit=s(Vfe);xSo=r(oit,"model_type"),oit.forEach(t),$So=r(yA,` property of the config object (either
passed as an argument or loaded from `),Xfe=n(yA,"CODE",{});var rit=s(Xfe);kSo=r(rit,"pretrained_model_name_or_path"),rit.forEach(t),SSo=r(yA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zfe=n(yA,"CODE",{});var tit=s(zfe);RSo=r(tit,"pretrained_model_name_or_path"),tit.forEach(t),PSo=r(yA,":"),yA.forEach(t),BSo=i(la),Y=n(la,"UL",{});var K=s(Y);E7=n(K,"LI",{});var I8e=s(E7);Wfe=n(I8e,"STRONG",{});var ait=s(Wfe);ISo=r(ait,"albert"),ait.forEach(t),qSo=r(I8e," \u2014 "),EG=n(I8e,"A",{href:!0});var nit=s(EG);NSo=r(nit,"AlbertForMultipleChoice"),nit.forEach(t),jSo=r(I8e," (ALBERT model)"),I8e.forEach(t),DSo=i(K),C7=n(K,"LI",{});var q8e=s(C7);Qfe=n(q8e,"STRONG",{});var sit=s(Qfe);GSo=r(sit,"bert"),sit.forEach(t),OSo=r(q8e," \u2014 "),CG=n(q8e,"A",{href:!0});var lit=s(CG);VSo=r(lit,"BertForMultipleChoice"),lit.forEach(t),XSo=r(q8e," (BERT model)"),q8e.forEach(t),zSo=i(K),w7=n(K,"LI",{});var N8e=s(w7);Hfe=n(N8e,"STRONG",{});var iit=s(Hfe);WSo=r(iit,"big_bird"),iit.forEach(t),QSo=r(N8e," \u2014 "),wG=n(N8e,"A",{href:!0});var dit=s(wG);HSo=r(dit,"BigBirdForMultipleChoice"),dit.forEach(t),USo=r(N8e," (BigBird model)"),N8e.forEach(t),JSo=i(K),A7=n(K,"LI",{});var j8e=s(A7);Ufe=n(j8e,"STRONG",{});var cit=s(Ufe);YSo=r(cit,"camembert"),cit.forEach(t),KSo=r(j8e," \u2014 "),AG=n(j8e,"A",{href:!0});var fit=s(AG);ZSo=r(fit,"CamembertForMultipleChoice"),fit.forEach(t),eRo=r(j8e," (CamemBERT model)"),j8e.forEach(t),oRo=i(K),y7=n(K,"LI",{});var D8e=s(y7);Jfe=n(D8e,"STRONG",{});var mit=s(Jfe);rRo=r(mit,"canine"),mit.forEach(t),tRo=r(D8e," \u2014 "),yG=n(D8e,"A",{href:!0});var git=s(yG);aRo=r(git,"CanineForMultipleChoice"),git.forEach(t),nRo=r(D8e," (Canine model)"),D8e.forEach(t),sRo=i(K),L7=n(K,"LI",{});var G8e=s(L7);Yfe=n(G8e,"STRONG",{});var hit=s(Yfe);lRo=r(hit,"convbert"),hit.forEach(t),iRo=r(G8e," \u2014 "),LG=n(G8e,"A",{href:!0});var pit=s(LG);dRo=r(pit,"ConvBertForMultipleChoice"),pit.forEach(t),cRo=r(G8e," (ConvBERT model)"),G8e.forEach(t),fRo=i(K),x7=n(K,"LI",{});var O8e=s(x7);Kfe=n(O8e,"STRONG",{});var uit=s(Kfe);mRo=r(uit,"data2vec-text"),uit.forEach(t),gRo=r(O8e," \u2014 "),xG=n(O8e,"A",{href:!0});var _it=s(xG);hRo=r(_it,"Data2VecTextForMultipleChoice"),_it.forEach(t),pRo=r(O8e," (Data2VecText model)"),O8e.forEach(t),uRo=i(K),$7=n(K,"LI",{});var V8e=s($7);Zfe=n(V8e,"STRONG",{});var bit=s(Zfe);_Ro=r(bit,"deberta-v2"),bit.forEach(t),bRo=r(V8e," \u2014 "),$G=n(V8e,"A",{href:!0});var vit=s($G);vRo=r(vit,"DebertaV2ForMultipleChoice"),vit.forEach(t),FRo=r(V8e," (DeBERTa-v2 model)"),V8e.forEach(t),TRo=i(K),k7=n(K,"LI",{});var X8e=s(k7);eme=n(X8e,"STRONG",{});var Fit=s(eme);MRo=r(Fit,"distilbert"),Fit.forEach(t),ERo=r(X8e," \u2014 "),kG=n(X8e,"A",{href:!0});var Tit=s(kG);CRo=r(Tit,"DistilBertForMultipleChoice"),Tit.forEach(t),wRo=r(X8e," (DistilBERT model)"),X8e.forEach(t),ARo=i(K),S7=n(K,"LI",{});var z8e=s(S7);ome=n(z8e,"STRONG",{});var Mit=s(ome);yRo=r(Mit,"electra"),Mit.forEach(t),LRo=r(z8e," \u2014 "),SG=n(z8e,"A",{href:!0});var Eit=s(SG);xRo=r(Eit,"ElectraForMultipleChoice"),Eit.forEach(t),$Ro=r(z8e," (ELECTRA model)"),z8e.forEach(t),kRo=i(K),R7=n(K,"LI",{});var W8e=s(R7);rme=n(W8e,"STRONG",{});var Cit=s(rme);SRo=r(Cit,"flaubert"),Cit.forEach(t),RRo=r(W8e," \u2014 "),RG=n(W8e,"A",{href:!0});var wit=s(RG);PRo=r(wit,"FlaubertForMultipleChoice"),wit.forEach(t),BRo=r(W8e," (FlauBERT model)"),W8e.forEach(t),IRo=i(K),P7=n(K,"LI",{});var Q8e=s(P7);tme=n(Q8e,"STRONG",{});var Ait=s(tme);qRo=r(Ait,"fnet"),Ait.forEach(t),NRo=r(Q8e," \u2014 "),PG=n(Q8e,"A",{href:!0});var yit=s(PG);jRo=r(yit,"FNetForMultipleChoice"),yit.forEach(t),DRo=r(Q8e," (FNet model)"),Q8e.forEach(t),GRo=i(K),B7=n(K,"LI",{});var H8e=s(B7);ame=n(H8e,"STRONG",{});var Lit=s(ame);ORo=r(Lit,"funnel"),Lit.forEach(t),VRo=r(H8e," \u2014 "),BG=n(H8e,"A",{href:!0});var xit=s(BG);XRo=r(xit,"FunnelForMultipleChoice"),xit.forEach(t),zRo=r(H8e," (Funnel Transformer model)"),H8e.forEach(t),WRo=i(K),I7=n(K,"LI",{});var U8e=s(I7);nme=n(U8e,"STRONG",{});var $it=s(nme);QRo=r($it,"ibert"),$it.forEach(t),HRo=r(U8e," \u2014 "),IG=n(U8e,"A",{href:!0});var kit=s(IG);URo=r(kit,"IBertForMultipleChoice"),kit.forEach(t),JRo=r(U8e," (I-BERT model)"),U8e.forEach(t),YRo=i(K),q7=n(K,"LI",{});var J8e=s(q7);sme=n(J8e,"STRONG",{});var Sit=s(sme);KRo=r(Sit,"longformer"),Sit.forEach(t),ZRo=r(J8e," \u2014 "),qG=n(J8e,"A",{href:!0});var Rit=s(qG);ePo=r(Rit,"LongformerForMultipleChoice"),Rit.forEach(t),oPo=r(J8e," (Longformer model)"),J8e.forEach(t),rPo=i(K),N7=n(K,"LI",{});var Y8e=s(N7);lme=n(Y8e,"STRONG",{});var Pit=s(lme);tPo=r(Pit,"megatron-bert"),Pit.forEach(t),aPo=r(Y8e," \u2014 "),NG=n(Y8e,"A",{href:!0});var Bit=s(NG);nPo=r(Bit,"MegatronBertForMultipleChoice"),Bit.forEach(t),sPo=r(Y8e," (MegatronBert model)"),Y8e.forEach(t),lPo=i(K),j7=n(K,"LI",{});var K8e=s(j7);ime=n(K8e,"STRONG",{});var Iit=s(ime);iPo=r(Iit,"mobilebert"),Iit.forEach(t),dPo=r(K8e," \u2014 "),jG=n(K8e,"A",{href:!0});var qit=s(jG);cPo=r(qit,"MobileBertForMultipleChoice"),qit.forEach(t),fPo=r(K8e," (MobileBERT model)"),K8e.forEach(t),mPo=i(K),D7=n(K,"LI",{});var Z8e=s(D7);dme=n(Z8e,"STRONG",{});var Nit=s(dme);gPo=r(Nit,"mpnet"),Nit.forEach(t),hPo=r(Z8e," \u2014 "),DG=n(Z8e,"A",{href:!0});var jit=s(DG);pPo=r(jit,"MPNetForMultipleChoice"),jit.forEach(t),uPo=r(Z8e," (MPNet model)"),Z8e.forEach(t),_Po=i(K),G7=n(K,"LI",{});var exe=s(G7);cme=n(exe,"STRONG",{});var Dit=s(cme);bPo=r(Dit,"nystromformer"),Dit.forEach(t),vPo=r(exe," \u2014 "),GG=n(exe,"A",{href:!0});var Git=s(GG);FPo=r(Git,"NystromformerForMultipleChoice"),Git.forEach(t),TPo=r(exe," (Nystromformer model)"),exe.forEach(t),MPo=i(K),O7=n(K,"LI",{});var oxe=s(O7);fme=n(oxe,"STRONG",{});var Oit=s(fme);EPo=r(Oit,"qdqbert"),Oit.forEach(t),CPo=r(oxe," \u2014 "),OG=n(oxe,"A",{href:!0});var Vit=s(OG);wPo=r(Vit,"QDQBertForMultipleChoice"),Vit.forEach(t),APo=r(oxe," (QDQBert model)"),oxe.forEach(t),yPo=i(K),V7=n(K,"LI",{});var rxe=s(V7);mme=n(rxe,"STRONG",{});var Xit=s(mme);LPo=r(Xit,"rembert"),Xit.forEach(t),xPo=r(rxe," \u2014 "),VG=n(rxe,"A",{href:!0});var zit=s(VG);$Po=r(zit,"RemBertForMultipleChoice"),zit.forEach(t),kPo=r(rxe," (RemBERT model)"),rxe.forEach(t),SPo=i(K),X7=n(K,"LI",{});var txe=s(X7);gme=n(txe,"STRONG",{});var Wit=s(gme);RPo=r(Wit,"roberta"),Wit.forEach(t),PPo=r(txe," \u2014 "),XG=n(txe,"A",{href:!0});var Qit=s(XG);BPo=r(Qit,"RobertaForMultipleChoice"),Qit.forEach(t),IPo=r(txe," (RoBERTa model)"),txe.forEach(t),qPo=i(K),z7=n(K,"LI",{});var axe=s(z7);hme=n(axe,"STRONG",{});var Hit=s(hme);NPo=r(Hit,"roformer"),Hit.forEach(t),jPo=r(axe," \u2014 "),zG=n(axe,"A",{href:!0});var Uit=s(zG);DPo=r(Uit,"RoFormerForMultipleChoice"),Uit.forEach(t),GPo=r(axe," (RoFormer model)"),axe.forEach(t),OPo=i(K),W7=n(K,"LI",{});var nxe=s(W7);pme=n(nxe,"STRONG",{});var Jit=s(pme);VPo=r(Jit,"squeezebert"),Jit.forEach(t),XPo=r(nxe," \u2014 "),WG=n(nxe,"A",{href:!0});var Yit=s(WG);zPo=r(Yit,"SqueezeBertForMultipleChoice"),Yit.forEach(t),WPo=r(nxe," (SqueezeBERT model)"),nxe.forEach(t),QPo=i(K),Q7=n(K,"LI",{});var sxe=s(Q7);ume=n(sxe,"STRONG",{});var Kit=s(ume);HPo=r(Kit,"xlm"),Kit.forEach(t),UPo=r(sxe," \u2014 "),QG=n(sxe,"A",{href:!0});var Zit=s(QG);JPo=r(Zit,"XLMForMultipleChoice"),Zit.forEach(t),YPo=r(sxe," (XLM model)"),sxe.forEach(t),KPo=i(K),H7=n(K,"LI",{});var lxe=s(H7);_me=n(lxe,"STRONG",{});var edt=s(_me);ZPo=r(edt,"xlm-roberta"),edt.forEach(t),eBo=r(lxe," \u2014 "),HG=n(lxe,"A",{href:!0});var odt=s(HG);oBo=r(odt,"XLMRobertaForMultipleChoice"),odt.forEach(t),rBo=r(lxe," (XLM-RoBERTa model)"),lxe.forEach(t),tBo=i(K),U7=n(K,"LI",{});var ixe=s(U7);bme=n(ixe,"STRONG",{});var rdt=s(bme);aBo=r(rdt,"xlm-roberta-xl"),rdt.forEach(t),nBo=r(ixe," \u2014 "),UG=n(ixe,"A",{href:!0});var tdt=s(UG);sBo=r(tdt,"XLMRobertaXLForMultipleChoice"),tdt.forEach(t),lBo=r(ixe," (XLM-RoBERTa-XL model)"),ixe.forEach(t),iBo=i(K),J7=n(K,"LI",{});var dxe=s(J7);vme=n(dxe,"STRONG",{});var adt=s(vme);dBo=r(adt,"xlnet"),adt.forEach(t),cBo=r(dxe," \u2014 "),JG=n(dxe,"A",{href:!0});var ndt=s(JG);fBo=r(ndt,"XLNetForMultipleChoice"),ndt.forEach(t),mBo=r(dxe," (XLNet model)"),dxe.forEach(t),gBo=i(K),Y7=n(K,"LI",{});var cxe=s(Y7);Fme=n(cxe,"STRONG",{});var sdt=s(Fme);hBo=r(sdt,"yoso"),sdt.forEach(t),pBo=r(cxe," \u2014 "),YG=n(cxe,"A",{href:!0});var ldt=s(YG);uBo=r(ldt,"YosoForMultipleChoice"),ldt.forEach(t),_Bo=r(cxe," (YOSO model)"),cxe.forEach(t),K.forEach(t),bBo=i(la),K7=n(la,"P",{});var fxe=s(K7);vBo=r(fxe,"The model is set in evaluation mode by default using "),Tme=n(fxe,"CODE",{});var idt=s(Tme);FBo=r(idt,"model.eval()"),idt.forEach(t),TBo=r(fxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mme=n(fxe,"CODE",{});var ddt=s(Mme);MBo=r(ddt,"model.train()"),ddt.forEach(t),fxe.forEach(t),EBo=i(la),T(Z7.$$.fragment,la),la.forEach(t),Ws.forEach(t),cqe=i(f),zi=n(f,"H2",{class:!0});var hje=s(zi);eb=n(hje,"A",{id:!0,class:!0,href:!0});var cdt=s(eb);Eme=n(cdt,"SPAN",{});var fdt=s(Eme);T(_y.$$.fragment,fdt),fdt.forEach(t),cdt.forEach(t),CBo=i(hje),Cme=n(hje,"SPAN",{});var mdt=s(Cme);wBo=r(mdt,"AutoModelForNextSentencePrediction"),mdt.forEach(t),hje.forEach(t),fqe=i(f),Bo=n(f,"DIV",{class:!0});var Qs=s(Bo);T(by.$$.fragment,Qs),ABo=i(Qs),Wi=n(Qs,"P",{});var QK=s(Wi);yBo=r(QK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),KG=n(QK,"A",{href:!0});var gdt=s(KG);LBo=r(gdt,"from_pretrained()"),gdt.forEach(t),xBo=r(QK," class method or the "),ZG=n(QK,"A",{href:!0});var hdt=s(ZG);$Bo=r(hdt,"from_config()"),hdt.forEach(t),kBo=r(QK,` class
method.`),QK.forEach(t),SBo=i(Qs),vy=n(Qs,"P",{});var pje=s(vy);RBo=r(pje,"This class cannot be instantiated directly using "),wme=n(pje,"CODE",{});var pdt=s(wme);PBo=r(pdt,"__init__()"),pdt.forEach(t),BBo=r(pje," (throws an error)."),pje.forEach(t),IBo=i(Qs),ct=n(Qs,"DIV",{class:!0});var LA=s(ct);T(Fy.$$.fragment,LA),qBo=i(LA),Ame=n(LA,"P",{});var udt=s(Ame);NBo=r(udt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),udt.forEach(t),jBo=i(LA),Qi=n(LA,"P",{});var HK=s(Qi);DBo=r(HK,`Note:
Loading a model from its configuration file does `),yme=n(HK,"STRONG",{});var _dt=s(yme);GBo=r(_dt,"not"),_dt.forEach(t),OBo=r(HK,` load the model weights. It only affects the
model\u2019s configuration. Use `),eO=n(HK,"A",{href:!0});var bdt=s(eO);VBo=r(bdt,"from_pretrained()"),bdt.forEach(t),XBo=r(HK," to load the model weights."),HK.forEach(t),zBo=i(LA),T(ob.$$.fragment,LA),LA.forEach(t),WBo=i(Qs),to=n(Qs,"DIV",{class:!0});var ia=s(to);T(Ty.$$.fragment,ia),QBo=i(ia),Lme=n(ia,"P",{});var vdt=s(Lme);HBo=r(vdt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),vdt.forEach(t),UBo=i(ia),Ba=n(ia,"P",{});var xA=s(Ba);JBo=r(xA,"The model class to instantiate is selected based on the "),xme=n(xA,"CODE",{});var Fdt=s(xme);YBo=r(Fdt,"model_type"),Fdt.forEach(t),KBo=r(xA,` property of the config object (either
passed as an argument or loaded from `),$me=n(xA,"CODE",{});var Tdt=s($me);ZBo=r(Tdt,"pretrained_model_name_or_path"),Tdt.forEach(t),eIo=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kme=n(xA,"CODE",{});var Mdt=s(kme);oIo=r(Mdt,"pretrained_model_name_or_path"),Mdt.forEach(t),rIo=r(xA,":"),xA.forEach(t),tIo=i(ia),Yr=n(ia,"UL",{});var Hs=s(Yr);rb=n(Hs,"LI",{});var mxe=s(rb);Sme=n(mxe,"STRONG",{});var Edt=s(Sme);aIo=r(Edt,"bert"),Edt.forEach(t),nIo=r(mxe," \u2014 "),oO=n(mxe,"A",{href:!0});var Cdt=s(oO);sIo=r(Cdt,"BertForNextSentencePrediction"),Cdt.forEach(t),lIo=r(mxe," (BERT model)"),mxe.forEach(t),iIo=i(Hs),tb=n(Hs,"LI",{});var gxe=s(tb);Rme=n(gxe,"STRONG",{});var wdt=s(Rme);dIo=r(wdt,"fnet"),wdt.forEach(t),cIo=r(gxe," \u2014 "),rO=n(gxe,"A",{href:!0});var Adt=s(rO);fIo=r(Adt,"FNetForNextSentencePrediction"),Adt.forEach(t),mIo=r(gxe," (FNet model)"),gxe.forEach(t),gIo=i(Hs),ab=n(Hs,"LI",{});var hxe=s(ab);Pme=n(hxe,"STRONG",{});var ydt=s(Pme);hIo=r(ydt,"megatron-bert"),ydt.forEach(t),pIo=r(hxe," \u2014 "),tO=n(hxe,"A",{href:!0});var Ldt=s(tO);uIo=r(Ldt,"MegatronBertForNextSentencePrediction"),Ldt.forEach(t),_Io=r(hxe," (MegatronBert model)"),hxe.forEach(t),bIo=i(Hs),nb=n(Hs,"LI",{});var pxe=s(nb);Bme=n(pxe,"STRONG",{});var xdt=s(Bme);vIo=r(xdt,"mobilebert"),xdt.forEach(t),FIo=r(pxe," \u2014 "),aO=n(pxe,"A",{href:!0});var $dt=s(aO);TIo=r($dt,"MobileBertForNextSentencePrediction"),$dt.forEach(t),MIo=r(pxe," (MobileBERT model)"),pxe.forEach(t),EIo=i(Hs),sb=n(Hs,"LI",{});var uxe=s(sb);Ime=n(uxe,"STRONG",{});var kdt=s(Ime);CIo=r(kdt,"qdqbert"),kdt.forEach(t),wIo=r(uxe," \u2014 "),nO=n(uxe,"A",{href:!0});var Sdt=s(nO);AIo=r(Sdt,"QDQBertForNextSentencePrediction"),Sdt.forEach(t),yIo=r(uxe," (QDQBert model)"),uxe.forEach(t),Hs.forEach(t),LIo=i(ia),lb=n(ia,"P",{});var _xe=s(lb);xIo=r(_xe,"The model is set in evaluation mode by default using "),qme=n(_xe,"CODE",{});var Rdt=s(qme);$Io=r(Rdt,"model.eval()"),Rdt.forEach(t),kIo=r(_xe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=n(_xe,"CODE",{});var Pdt=s(Nme);SIo=r(Pdt,"model.train()"),Pdt.forEach(t),_xe.forEach(t),RIo=i(ia),T(ib.$$.fragment,ia),ia.forEach(t),Qs.forEach(t),mqe=i(f),Hi=n(f,"H2",{class:!0});var uje=s(Hi);db=n(uje,"A",{id:!0,class:!0,href:!0});var Bdt=s(db);jme=n(Bdt,"SPAN",{});var Idt=s(jme);T(My.$$.fragment,Idt),Idt.forEach(t),Bdt.forEach(t),PIo=i(uje),Dme=n(uje,"SPAN",{});var qdt=s(Dme);BIo=r(qdt,"AutoModelForTokenClassification"),qdt.forEach(t),uje.forEach(t),gqe=i(f),Io=n(f,"DIV",{class:!0});var Us=s(Io);T(Ey.$$.fragment,Us),IIo=i(Us),Ui=n(Us,"P",{});var UK=s(Ui);qIo=r(UK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),sO=n(UK,"A",{href:!0});var Ndt=s(sO);NIo=r(Ndt,"from_pretrained()"),Ndt.forEach(t),jIo=r(UK," class method or the "),lO=n(UK,"A",{href:!0});var jdt=s(lO);DIo=r(jdt,"from_config()"),jdt.forEach(t),GIo=r(UK,` class
method.`),UK.forEach(t),OIo=i(Us),Cy=n(Us,"P",{});var _je=s(Cy);VIo=r(_je,"This class cannot be instantiated directly using "),Gme=n(_je,"CODE",{});var Ddt=s(Gme);XIo=r(Ddt,"__init__()"),Ddt.forEach(t),zIo=r(_je," (throws an error)."),_je.forEach(t),WIo=i(Us),ft=n(Us,"DIV",{class:!0});var $A=s(ft);T(wy.$$.fragment,$A),QIo=i($A),Ome=n($A,"P",{});var Gdt=s(Ome);HIo=r(Gdt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Gdt.forEach(t),UIo=i($A),Ji=n($A,"P",{});var JK=s(Ji);JIo=r(JK,`Note:
Loading a model from its configuration file does `),Vme=n(JK,"STRONG",{});var Odt=s(Vme);YIo=r(Odt,"not"),Odt.forEach(t),KIo=r(JK,` load the model weights. It only affects the
model\u2019s configuration. Use `),iO=n(JK,"A",{href:!0});var Vdt=s(iO);ZIo=r(Vdt,"from_pretrained()"),Vdt.forEach(t),eqo=r(JK," to load the model weights."),JK.forEach(t),oqo=i($A),T(cb.$$.fragment,$A),$A.forEach(t),rqo=i(Us),ao=n(Us,"DIV",{class:!0});var da=s(ao);T(Ay.$$.fragment,da),tqo=i(da),Xme=n(da,"P",{});var Xdt=s(Xme);aqo=r(Xdt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Xdt.forEach(t),nqo=i(da),Ia=n(da,"P",{});var kA=s(Ia);sqo=r(kA,"The model class to instantiate is selected based on the "),zme=n(kA,"CODE",{});var zdt=s(zme);lqo=r(zdt,"model_type"),zdt.forEach(t),iqo=r(kA,` property of the config object (either
passed as an argument or loaded from `),Wme=n(kA,"CODE",{});var Wdt=s(Wme);dqo=r(Wdt,"pretrained_model_name_or_path"),Wdt.forEach(t),cqo=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=n(kA,"CODE",{});var Qdt=s(Qme);fqo=r(Qdt,"pretrained_model_name_or_path"),Qdt.forEach(t),mqo=r(kA,":"),kA.forEach(t),gqo=i(da),U=n(da,"UL",{});var J=s(U);fb=n(J,"LI",{});var bxe=s(fb);Hme=n(bxe,"STRONG",{});var Hdt=s(Hme);hqo=r(Hdt,"albert"),Hdt.forEach(t),pqo=r(bxe," \u2014 "),dO=n(bxe,"A",{href:!0});var Udt=s(dO);uqo=r(Udt,"AlbertForTokenClassification"),Udt.forEach(t),_qo=r(bxe," (ALBERT model)"),bxe.forEach(t),bqo=i(J),mb=n(J,"LI",{});var vxe=s(mb);Ume=n(vxe,"STRONG",{});var Jdt=s(Ume);vqo=r(Jdt,"bert"),Jdt.forEach(t),Fqo=r(vxe," \u2014 "),cO=n(vxe,"A",{href:!0});var Ydt=s(cO);Tqo=r(Ydt,"BertForTokenClassification"),Ydt.forEach(t),Mqo=r(vxe," (BERT model)"),vxe.forEach(t),Eqo=i(J),gb=n(J,"LI",{});var Fxe=s(gb);Jme=n(Fxe,"STRONG",{});var Kdt=s(Jme);Cqo=r(Kdt,"big_bird"),Kdt.forEach(t),wqo=r(Fxe," \u2014 "),fO=n(Fxe,"A",{href:!0});var Zdt=s(fO);Aqo=r(Zdt,"BigBirdForTokenClassification"),Zdt.forEach(t),yqo=r(Fxe," (BigBird model)"),Fxe.forEach(t),Lqo=i(J),hb=n(J,"LI",{});var Txe=s(hb);Yme=n(Txe,"STRONG",{});var ect=s(Yme);xqo=r(ect,"camembert"),ect.forEach(t),$qo=r(Txe," \u2014 "),mO=n(Txe,"A",{href:!0});var oct=s(mO);kqo=r(oct,"CamembertForTokenClassification"),oct.forEach(t),Sqo=r(Txe," (CamemBERT model)"),Txe.forEach(t),Rqo=i(J),pb=n(J,"LI",{});var Mxe=s(pb);Kme=n(Mxe,"STRONG",{});var rct=s(Kme);Pqo=r(rct,"canine"),rct.forEach(t),Bqo=r(Mxe," \u2014 "),gO=n(Mxe,"A",{href:!0});var tct=s(gO);Iqo=r(tct,"CanineForTokenClassification"),tct.forEach(t),qqo=r(Mxe," (Canine model)"),Mxe.forEach(t),Nqo=i(J),ub=n(J,"LI",{});var Exe=s(ub);Zme=n(Exe,"STRONG",{});var act=s(Zme);jqo=r(act,"convbert"),act.forEach(t),Dqo=r(Exe," \u2014 "),hO=n(Exe,"A",{href:!0});var nct=s(hO);Gqo=r(nct,"ConvBertForTokenClassification"),nct.forEach(t),Oqo=r(Exe," (ConvBERT model)"),Exe.forEach(t),Vqo=i(J),_b=n(J,"LI",{});var Cxe=s(_b);ege=n(Cxe,"STRONG",{});var sct=s(ege);Xqo=r(sct,"data2vec-text"),sct.forEach(t),zqo=r(Cxe," \u2014 "),pO=n(Cxe,"A",{href:!0});var lct=s(pO);Wqo=r(lct,"Data2VecTextForTokenClassification"),lct.forEach(t),Qqo=r(Cxe," (Data2VecText model)"),Cxe.forEach(t),Hqo=i(J),bb=n(J,"LI",{});var wxe=s(bb);oge=n(wxe,"STRONG",{});var ict=s(oge);Uqo=r(ict,"deberta"),ict.forEach(t),Jqo=r(wxe," \u2014 "),uO=n(wxe,"A",{href:!0});var dct=s(uO);Yqo=r(dct,"DebertaForTokenClassification"),dct.forEach(t),Kqo=r(wxe," (DeBERTa model)"),wxe.forEach(t),Zqo=i(J),vb=n(J,"LI",{});var Axe=s(vb);rge=n(Axe,"STRONG",{});var cct=s(rge);eNo=r(cct,"deberta-v2"),cct.forEach(t),oNo=r(Axe," \u2014 "),_O=n(Axe,"A",{href:!0});var fct=s(_O);rNo=r(fct,"DebertaV2ForTokenClassification"),fct.forEach(t),tNo=r(Axe," (DeBERTa-v2 model)"),Axe.forEach(t),aNo=i(J),Fb=n(J,"LI",{});var yxe=s(Fb);tge=n(yxe,"STRONG",{});var mct=s(tge);nNo=r(mct,"distilbert"),mct.forEach(t),sNo=r(yxe," \u2014 "),bO=n(yxe,"A",{href:!0});var gct=s(bO);lNo=r(gct,"DistilBertForTokenClassification"),gct.forEach(t),iNo=r(yxe," (DistilBERT model)"),yxe.forEach(t),dNo=i(J),Tb=n(J,"LI",{});var Lxe=s(Tb);age=n(Lxe,"STRONG",{});var hct=s(age);cNo=r(hct,"electra"),hct.forEach(t),fNo=r(Lxe," \u2014 "),vO=n(Lxe,"A",{href:!0});var pct=s(vO);mNo=r(pct,"ElectraForTokenClassification"),pct.forEach(t),gNo=r(Lxe," (ELECTRA model)"),Lxe.forEach(t),hNo=i(J),Mb=n(J,"LI",{});var xxe=s(Mb);nge=n(xxe,"STRONG",{});var uct=s(nge);pNo=r(uct,"flaubert"),uct.forEach(t),uNo=r(xxe," \u2014 "),FO=n(xxe,"A",{href:!0});var _ct=s(FO);_No=r(_ct,"FlaubertForTokenClassification"),_ct.forEach(t),bNo=r(xxe," (FlauBERT model)"),xxe.forEach(t),vNo=i(J),Eb=n(J,"LI",{});var $xe=s(Eb);sge=n($xe,"STRONG",{});var bct=s(sge);FNo=r(bct,"fnet"),bct.forEach(t),TNo=r($xe," \u2014 "),TO=n($xe,"A",{href:!0});var vct=s(TO);MNo=r(vct,"FNetForTokenClassification"),vct.forEach(t),ENo=r($xe," (FNet model)"),$xe.forEach(t),CNo=i(J),Cb=n(J,"LI",{});var kxe=s(Cb);lge=n(kxe,"STRONG",{});var Fct=s(lge);wNo=r(Fct,"funnel"),Fct.forEach(t),ANo=r(kxe," \u2014 "),MO=n(kxe,"A",{href:!0});var Tct=s(MO);yNo=r(Tct,"FunnelForTokenClassification"),Tct.forEach(t),LNo=r(kxe," (Funnel Transformer model)"),kxe.forEach(t),xNo=i(J),wb=n(J,"LI",{});var Sxe=s(wb);ige=n(Sxe,"STRONG",{});var Mct=s(ige);$No=r(Mct,"gpt2"),Mct.forEach(t),kNo=r(Sxe," \u2014 "),EO=n(Sxe,"A",{href:!0});var Ect=s(EO);SNo=r(Ect,"GPT2ForTokenClassification"),Ect.forEach(t),RNo=r(Sxe," (OpenAI GPT-2 model)"),Sxe.forEach(t),PNo=i(J),Ab=n(J,"LI",{});var Rxe=s(Ab);dge=n(Rxe,"STRONG",{});var Cct=s(dge);BNo=r(Cct,"ibert"),Cct.forEach(t),INo=r(Rxe," \u2014 "),CO=n(Rxe,"A",{href:!0});var wct=s(CO);qNo=r(wct,"IBertForTokenClassification"),wct.forEach(t),NNo=r(Rxe," (I-BERT model)"),Rxe.forEach(t),jNo=i(J),yb=n(J,"LI",{});var Pxe=s(yb);cge=n(Pxe,"STRONG",{});var Act=s(cge);DNo=r(Act,"layoutlm"),Act.forEach(t),GNo=r(Pxe," \u2014 "),wO=n(Pxe,"A",{href:!0});var yct=s(wO);ONo=r(yct,"LayoutLMForTokenClassification"),yct.forEach(t),VNo=r(Pxe," (LayoutLM model)"),Pxe.forEach(t),XNo=i(J),Lb=n(J,"LI",{});var Bxe=s(Lb);fge=n(Bxe,"STRONG",{});var Lct=s(fge);zNo=r(Lct,"layoutlmv2"),Lct.forEach(t),WNo=r(Bxe," \u2014 "),AO=n(Bxe,"A",{href:!0});var xct=s(AO);QNo=r(xct,"LayoutLMv2ForTokenClassification"),xct.forEach(t),HNo=r(Bxe," (LayoutLMv2 model)"),Bxe.forEach(t),UNo=i(J),xb=n(J,"LI",{});var Ixe=s(xb);mge=n(Ixe,"STRONG",{});var $ct=s(mge);JNo=r($ct,"longformer"),$ct.forEach(t),YNo=r(Ixe," \u2014 "),yO=n(Ixe,"A",{href:!0});var kct=s(yO);KNo=r(kct,"LongformerForTokenClassification"),kct.forEach(t),ZNo=r(Ixe," (Longformer model)"),Ixe.forEach(t),ejo=i(J),$b=n(J,"LI",{});var qxe=s($b);gge=n(qxe,"STRONG",{});var Sct=s(gge);ojo=r(Sct,"megatron-bert"),Sct.forEach(t),rjo=r(qxe," \u2014 "),LO=n(qxe,"A",{href:!0});var Rct=s(LO);tjo=r(Rct,"MegatronBertForTokenClassification"),Rct.forEach(t),ajo=r(qxe," (MegatronBert model)"),qxe.forEach(t),njo=i(J),kb=n(J,"LI",{});var Nxe=s(kb);hge=n(Nxe,"STRONG",{});var Pct=s(hge);sjo=r(Pct,"mobilebert"),Pct.forEach(t),ljo=r(Nxe," \u2014 "),xO=n(Nxe,"A",{href:!0});var Bct=s(xO);ijo=r(Bct,"MobileBertForTokenClassification"),Bct.forEach(t),djo=r(Nxe," (MobileBERT model)"),Nxe.forEach(t),cjo=i(J),Sb=n(J,"LI",{});var jxe=s(Sb);pge=n(jxe,"STRONG",{});var Ict=s(pge);fjo=r(Ict,"mpnet"),Ict.forEach(t),mjo=r(jxe," \u2014 "),$O=n(jxe,"A",{href:!0});var qct=s($O);gjo=r(qct,"MPNetForTokenClassification"),qct.forEach(t),hjo=r(jxe," (MPNet model)"),jxe.forEach(t),pjo=i(J),Rb=n(J,"LI",{});var Dxe=s(Rb);uge=n(Dxe,"STRONG",{});var Nct=s(uge);ujo=r(Nct,"nystromformer"),Nct.forEach(t),_jo=r(Dxe," \u2014 "),kO=n(Dxe,"A",{href:!0});var jct=s(kO);bjo=r(jct,"NystromformerForTokenClassification"),jct.forEach(t),vjo=r(Dxe," (Nystromformer model)"),Dxe.forEach(t),Fjo=i(J),Pb=n(J,"LI",{});var Gxe=s(Pb);_ge=n(Gxe,"STRONG",{});var Dct=s(_ge);Tjo=r(Dct,"qdqbert"),Dct.forEach(t),Mjo=r(Gxe," \u2014 "),SO=n(Gxe,"A",{href:!0});var Gct=s(SO);Ejo=r(Gct,"QDQBertForTokenClassification"),Gct.forEach(t),Cjo=r(Gxe," (QDQBert model)"),Gxe.forEach(t),wjo=i(J),Bb=n(J,"LI",{});var Oxe=s(Bb);bge=n(Oxe,"STRONG",{});var Oct=s(bge);Ajo=r(Oct,"rembert"),Oct.forEach(t),yjo=r(Oxe," \u2014 "),RO=n(Oxe,"A",{href:!0});var Vct=s(RO);Ljo=r(Vct,"RemBertForTokenClassification"),Vct.forEach(t),xjo=r(Oxe," (RemBERT model)"),Oxe.forEach(t),$jo=i(J),Ib=n(J,"LI",{});var Vxe=s(Ib);vge=n(Vxe,"STRONG",{});var Xct=s(vge);kjo=r(Xct,"roberta"),Xct.forEach(t),Sjo=r(Vxe," \u2014 "),PO=n(Vxe,"A",{href:!0});var zct=s(PO);Rjo=r(zct,"RobertaForTokenClassification"),zct.forEach(t),Pjo=r(Vxe," (RoBERTa model)"),Vxe.forEach(t),Bjo=i(J),qb=n(J,"LI",{});var Xxe=s(qb);Fge=n(Xxe,"STRONG",{});var Wct=s(Fge);Ijo=r(Wct,"roformer"),Wct.forEach(t),qjo=r(Xxe," \u2014 "),BO=n(Xxe,"A",{href:!0});var Qct=s(BO);Njo=r(Qct,"RoFormerForTokenClassification"),Qct.forEach(t),jjo=r(Xxe," (RoFormer model)"),Xxe.forEach(t),Djo=i(J),Nb=n(J,"LI",{});var zxe=s(Nb);Tge=n(zxe,"STRONG",{});var Hct=s(Tge);Gjo=r(Hct,"squeezebert"),Hct.forEach(t),Ojo=r(zxe," \u2014 "),IO=n(zxe,"A",{href:!0});var Uct=s(IO);Vjo=r(Uct,"SqueezeBertForTokenClassification"),Uct.forEach(t),Xjo=r(zxe," (SqueezeBERT model)"),zxe.forEach(t),zjo=i(J),jb=n(J,"LI",{});var Wxe=s(jb);Mge=n(Wxe,"STRONG",{});var Jct=s(Mge);Wjo=r(Jct,"xlm"),Jct.forEach(t),Qjo=r(Wxe," \u2014 "),qO=n(Wxe,"A",{href:!0});var Yct=s(qO);Hjo=r(Yct,"XLMForTokenClassification"),Yct.forEach(t),Ujo=r(Wxe," (XLM model)"),Wxe.forEach(t),Jjo=i(J),Db=n(J,"LI",{});var Qxe=s(Db);Ege=n(Qxe,"STRONG",{});var Kct=s(Ege);Yjo=r(Kct,"xlm-roberta"),Kct.forEach(t),Kjo=r(Qxe," \u2014 "),NO=n(Qxe,"A",{href:!0});var Zct=s(NO);Zjo=r(Zct,"XLMRobertaForTokenClassification"),Zct.forEach(t),eDo=r(Qxe," (XLM-RoBERTa model)"),Qxe.forEach(t),oDo=i(J),Gb=n(J,"LI",{});var Hxe=s(Gb);Cge=n(Hxe,"STRONG",{});var eft=s(Cge);rDo=r(eft,"xlm-roberta-xl"),eft.forEach(t),tDo=r(Hxe," \u2014 "),jO=n(Hxe,"A",{href:!0});var oft=s(jO);aDo=r(oft,"XLMRobertaXLForTokenClassification"),oft.forEach(t),nDo=r(Hxe," (XLM-RoBERTa-XL model)"),Hxe.forEach(t),sDo=i(J),Ob=n(J,"LI",{});var Uxe=s(Ob);wge=n(Uxe,"STRONG",{});var rft=s(wge);lDo=r(rft,"xlnet"),rft.forEach(t),iDo=r(Uxe," \u2014 "),DO=n(Uxe,"A",{href:!0});var tft=s(DO);dDo=r(tft,"XLNetForTokenClassification"),tft.forEach(t),cDo=r(Uxe," (XLNet model)"),Uxe.forEach(t),fDo=i(J),Vb=n(J,"LI",{});var Jxe=s(Vb);Age=n(Jxe,"STRONG",{});var aft=s(Age);mDo=r(aft,"yoso"),aft.forEach(t),gDo=r(Jxe," \u2014 "),GO=n(Jxe,"A",{href:!0});var nft=s(GO);hDo=r(nft,"YosoForTokenClassification"),nft.forEach(t),pDo=r(Jxe," (YOSO model)"),Jxe.forEach(t),J.forEach(t),uDo=i(da),Xb=n(da,"P",{});var Yxe=s(Xb);_Do=r(Yxe,"The model is set in evaluation mode by default using "),yge=n(Yxe,"CODE",{});var sft=s(yge);bDo=r(sft,"model.eval()"),sft.forEach(t),vDo=r(Yxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lge=n(Yxe,"CODE",{});var lft=s(Lge);FDo=r(lft,"model.train()"),lft.forEach(t),Yxe.forEach(t),TDo=i(da),T(zb.$$.fragment,da),da.forEach(t),Us.forEach(t),hqe=i(f),Yi=n(f,"H2",{class:!0});var bje=s(Yi);Wb=n(bje,"A",{id:!0,class:!0,href:!0});var ift=s(Wb);xge=n(ift,"SPAN",{});var dft=s(xge);T(yy.$$.fragment,dft),dft.forEach(t),ift.forEach(t),MDo=i(bje),$ge=n(bje,"SPAN",{});var cft=s($ge);EDo=r(cft,"AutoModelForQuestionAnswering"),cft.forEach(t),bje.forEach(t),pqe=i(f),qo=n(f,"DIV",{class:!0});var Js=s(qo);T(Ly.$$.fragment,Js),CDo=i(Js),Ki=n(Js,"P",{});var YK=s(Ki);wDo=r(YK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),OO=n(YK,"A",{href:!0});var fft=s(OO);ADo=r(fft,"from_pretrained()"),fft.forEach(t),yDo=r(YK," class method or the "),VO=n(YK,"A",{href:!0});var mft=s(VO);LDo=r(mft,"from_config()"),mft.forEach(t),xDo=r(YK,` class
method.`),YK.forEach(t),$Do=i(Js),xy=n(Js,"P",{});var vje=s(xy);kDo=r(vje,"This class cannot be instantiated directly using "),kge=n(vje,"CODE",{});var gft=s(kge);SDo=r(gft,"__init__()"),gft.forEach(t),RDo=r(vje," (throws an error)."),vje.forEach(t),PDo=i(Js),mt=n(Js,"DIV",{class:!0});var SA=s(mt);T($y.$$.fragment,SA),BDo=i(SA),Sge=n(SA,"P",{});var hft=s(Sge);IDo=r(hft,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),hft.forEach(t),qDo=i(SA),Zi=n(SA,"P",{});var KK=s(Zi);NDo=r(KK,`Note:
Loading a model from its configuration file does `),Rge=n(KK,"STRONG",{});var pft=s(Rge);jDo=r(pft,"not"),pft.forEach(t),DDo=r(KK,` load the model weights. It only affects the
model\u2019s configuration. Use `),XO=n(KK,"A",{href:!0});var uft=s(XO);GDo=r(uft,"from_pretrained()"),uft.forEach(t),ODo=r(KK," to load the model weights."),KK.forEach(t),VDo=i(SA),T(Qb.$$.fragment,SA),SA.forEach(t),XDo=i(Js),no=n(Js,"DIV",{class:!0});var ca=s(no);T(ky.$$.fragment,ca),zDo=i(ca),Pge=n(ca,"P",{});var _ft=s(Pge);WDo=r(_ft,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),_ft.forEach(t),QDo=i(ca),qa=n(ca,"P",{});var RA=s(qa);HDo=r(RA,"The model class to instantiate is selected based on the "),Bge=n(RA,"CODE",{});var bft=s(Bge);UDo=r(bft,"model_type"),bft.forEach(t),JDo=r(RA,` property of the config object (either
passed as an argument or loaded from `),Ige=n(RA,"CODE",{});var vft=s(Ige);YDo=r(vft,"pretrained_model_name_or_path"),vft.forEach(t),KDo=r(RA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qge=n(RA,"CODE",{});var Fft=s(qge);ZDo=r(Fft,"pretrained_model_name_or_path"),Fft.forEach(t),eGo=r(RA,":"),RA.forEach(t),oGo=i(ca),V=n(ca,"UL",{});var X=s(V);Hb=n(X,"LI",{});var Kxe=s(Hb);Nge=n(Kxe,"STRONG",{});var Tft=s(Nge);rGo=r(Tft,"albert"),Tft.forEach(t),tGo=r(Kxe," \u2014 "),zO=n(Kxe,"A",{href:!0});var Mft=s(zO);aGo=r(Mft,"AlbertForQuestionAnswering"),Mft.forEach(t),nGo=r(Kxe," (ALBERT model)"),Kxe.forEach(t),sGo=i(X),Ub=n(X,"LI",{});var Zxe=s(Ub);jge=n(Zxe,"STRONG",{});var Eft=s(jge);lGo=r(Eft,"bart"),Eft.forEach(t),iGo=r(Zxe," \u2014 "),WO=n(Zxe,"A",{href:!0});var Cft=s(WO);dGo=r(Cft,"BartForQuestionAnswering"),Cft.forEach(t),cGo=r(Zxe," (BART model)"),Zxe.forEach(t),fGo=i(X),Jb=n(X,"LI",{});var e9e=s(Jb);Dge=n(e9e,"STRONG",{});var wft=s(Dge);mGo=r(wft,"bert"),wft.forEach(t),gGo=r(e9e," \u2014 "),QO=n(e9e,"A",{href:!0});var Aft=s(QO);hGo=r(Aft,"BertForQuestionAnswering"),Aft.forEach(t),pGo=r(e9e," (BERT model)"),e9e.forEach(t),uGo=i(X),Yb=n(X,"LI",{});var o9e=s(Yb);Gge=n(o9e,"STRONG",{});var yft=s(Gge);_Go=r(yft,"big_bird"),yft.forEach(t),bGo=r(o9e," \u2014 "),HO=n(o9e,"A",{href:!0});var Lft=s(HO);vGo=r(Lft,"BigBirdForQuestionAnswering"),Lft.forEach(t),FGo=r(o9e," (BigBird model)"),o9e.forEach(t),TGo=i(X),Kb=n(X,"LI",{});var r9e=s(Kb);Oge=n(r9e,"STRONG",{});var xft=s(Oge);MGo=r(xft,"bigbird_pegasus"),xft.forEach(t),EGo=r(r9e," \u2014 "),UO=n(r9e,"A",{href:!0});var $ft=s(UO);CGo=r($ft,"BigBirdPegasusForQuestionAnswering"),$ft.forEach(t),wGo=r(r9e," (BigBirdPegasus model)"),r9e.forEach(t),AGo=i(X),Zb=n(X,"LI",{});var t9e=s(Zb);Vge=n(t9e,"STRONG",{});var kft=s(Vge);yGo=r(kft,"camembert"),kft.forEach(t),LGo=r(t9e," \u2014 "),JO=n(t9e,"A",{href:!0});var Sft=s(JO);xGo=r(Sft,"CamembertForQuestionAnswering"),Sft.forEach(t),$Go=r(t9e," (CamemBERT model)"),t9e.forEach(t),kGo=i(X),ev=n(X,"LI",{});var a9e=s(ev);Xge=n(a9e,"STRONG",{});var Rft=s(Xge);SGo=r(Rft,"canine"),Rft.forEach(t),RGo=r(a9e," \u2014 "),YO=n(a9e,"A",{href:!0});var Pft=s(YO);PGo=r(Pft,"CanineForQuestionAnswering"),Pft.forEach(t),BGo=r(a9e," (Canine model)"),a9e.forEach(t),IGo=i(X),ov=n(X,"LI",{});var n9e=s(ov);zge=n(n9e,"STRONG",{});var Bft=s(zge);qGo=r(Bft,"convbert"),Bft.forEach(t),NGo=r(n9e," \u2014 "),KO=n(n9e,"A",{href:!0});var Ift=s(KO);jGo=r(Ift,"ConvBertForQuestionAnswering"),Ift.forEach(t),DGo=r(n9e," (ConvBERT model)"),n9e.forEach(t),GGo=i(X),rv=n(X,"LI",{});var s9e=s(rv);Wge=n(s9e,"STRONG",{});var qft=s(Wge);OGo=r(qft,"data2vec-text"),qft.forEach(t),VGo=r(s9e," \u2014 "),ZO=n(s9e,"A",{href:!0});var Nft=s(ZO);XGo=r(Nft,"Data2VecTextForQuestionAnswering"),Nft.forEach(t),zGo=r(s9e," (Data2VecText model)"),s9e.forEach(t),WGo=i(X),tv=n(X,"LI",{});var l9e=s(tv);Qge=n(l9e,"STRONG",{});var jft=s(Qge);QGo=r(jft,"deberta"),jft.forEach(t),HGo=r(l9e," \u2014 "),eV=n(l9e,"A",{href:!0});var Dft=s(eV);UGo=r(Dft,"DebertaForQuestionAnswering"),Dft.forEach(t),JGo=r(l9e," (DeBERTa model)"),l9e.forEach(t),YGo=i(X),av=n(X,"LI",{});var i9e=s(av);Hge=n(i9e,"STRONG",{});var Gft=s(Hge);KGo=r(Gft,"deberta-v2"),Gft.forEach(t),ZGo=r(i9e," \u2014 "),oV=n(i9e,"A",{href:!0});var Oft=s(oV);eOo=r(Oft,"DebertaV2ForQuestionAnswering"),Oft.forEach(t),oOo=r(i9e," (DeBERTa-v2 model)"),i9e.forEach(t),rOo=i(X),nv=n(X,"LI",{});var d9e=s(nv);Uge=n(d9e,"STRONG",{});var Vft=s(Uge);tOo=r(Vft,"distilbert"),Vft.forEach(t),aOo=r(d9e," \u2014 "),rV=n(d9e,"A",{href:!0});var Xft=s(rV);nOo=r(Xft,"DistilBertForQuestionAnswering"),Xft.forEach(t),sOo=r(d9e," (DistilBERT model)"),d9e.forEach(t),lOo=i(X),sv=n(X,"LI",{});var c9e=s(sv);Jge=n(c9e,"STRONG",{});var zft=s(Jge);iOo=r(zft,"electra"),zft.forEach(t),dOo=r(c9e," \u2014 "),tV=n(c9e,"A",{href:!0});var Wft=s(tV);cOo=r(Wft,"ElectraForQuestionAnswering"),Wft.forEach(t),fOo=r(c9e," (ELECTRA model)"),c9e.forEach(t),mOo=i(X),lv=n(X,"LI",{});var f9e=s(lv);Yge=n(f9e,"STRONG",{});var Qft=s(Yge);gOo=r(Qft,"flaubert"),Qft.forEach(t),hOo=r(f9e," \u2014 "),aV=n(f9e,"A",{href:!0});var Hft=s(aV);pOo=r(Hft,"FlaubertForQuestionAnsweringSimple"),Hft.forEach(t),uOo=r(f9e," (FlauBERT model)"),f9e.forEach(t),_Oo=i(X),iv=n(X,"LI",{});var m9e=s(iv);Kge=n(m9e,"STRONG",{});var Uft=s(Kge);bOo=r(Uft,"fnet"),Uft.forEach(t),vOo=r(m9e," \u2014 "),nV=n(m9e,"A",{href:!0});var Jft=s(nV);FOo=r(Jft,"FNetForQuestionAnswering"),Jft.forEach(t),TOo=r(m9e," (FNet model)"),m9e.forEach(t),MOo=i(X),dv=n(X,"LI",{});var g9e=s(dv);Zge=n(g9e,"STRONG",{});var Yft=s(Zge);EOo=r(Yft,"funnel"),Yft.forEach(t),COo=r(g9e," \u2014 "),sV=n(g9e,"A",{href:!0});var Kft=s(sV);wOo=r(Kft,"FunnelForQuestionAnswering"),Kft.forEach(t),AOo=r(g9e," (Funnel Transformer model)"),g9e.forEach(t),yOo=i(X),cv=n(X,"LI",{});var h9e=s(cv);ehe=n(h9e,"STRONG",{});var Zft=s(ehe);LOo=r(Zft,"gptj"),Zft.forEach(t),xOo=r(h9e," \u2014 "),lV=n(h9e,"A",{href:!0});var emt=s(lV);$Oo=r(emt,"GPTJForQuestionAnswering"),emt.forEach(t),kOo=r(h9e," (GPT-J model)"),h9e.forEach(t),SOo=i(X),fv=n(X,"LI",{});var p9e=s(fv);ohe=n(p9e,"STRONG",{});var omt=s(ohe);ROo=r(omt,"ibert"),omt.forEach(t),POo=r(p9e," \u2014 "),iV=n(p9e,"A",{href:!0});var rmt=s(iV);BOo=r(rmt,"IBertForQuestionAnswering"),rmt.forEach(t),IOo=r(p9e," (I-BERT model)"),p9e.forEach(t),qOo=i(X),mv=n(X,"LI",{});var u9e=s(mv);rhe=n(u9e,"STRONG",{});var tmt=s(rhe);NOo=r(tmt,"layoutlmv2"),tmt.forEach(t),jOo=r(u9e," \u2014 "),dV=n(u9e,"A",{href:!0});var amt=s(dV);DOo=r(amt,"LayoutLMv2ForQuestionAnswering"),amt.forEach(t),GOo=r(u9e," (LayoutLMv2 model)"),u9e.forEach(t),OOo=i(X),gv=n(X,"LI",{});var _9e=s(gv);the=n(_9e,"STRONG",{});var nmt=s(the);VOo=r(nmt,"led"),nmt.forEach(t),XOo=r(_9e," \u2014 "),cV=n(_9e,"A",{href:!0});var smt=s(cV);zOo=r(smt,"LEDForQuestionAnswering"),smt.forEach(t),WOo=r(_9e," (LED model)"),_9e.forEach(t),QOo=i(X),hv=n(X,"LI",{});var b9e=s(hv);ahe=n(b9e,"STRONG",{});var lmt=s(ahe);HOo=r(lmt,"longformer"),lmt.forEach(t),UOo=r(b9e," \u2014 "),fV=n(b9e,"A",{href:!0});var imt=s(fV);JOo=r(imt,"LongformerForQuestionAnswering"),imt.forEach(t),YOo=r(b9e," (Longformer model)"),b9e.forEach(t),KOo=i(X),pv=n(X,"LI",{});var v9e=s(pv);nhe=n(v9e,"STRONG",{});var dmt=s(nhe);ZOo=r(dmt,"lxmert"),dmt.forEach(t),eVo=r(v9e," \u2014 "),mV=n(v9e,"A",{href:!0});var cmt=s(mV);oVo=r(cmt,"LxmertForQuestionAnswering"),cmt.forEach(t),rVo=r(v9e," (LXMERT model)"),v9e.forEach(t),tVo=i(X),uv=n(X,"LI",{});var F9e=s(uv);she=n(F9e,"STRONG",{});var fmt=s(she);aVo=r(fmt,"mbart"),fmt.forEach(t),nVo=r(F9e," \u2014 "),gV=n(F9e,"A",{href:!0});var mmt=s(gV);sVo=r(mmt,"MBartForQuestionAnswering"),mmt.forEach(t),lVo=r(F9e," (mBART model)"),F9e.forEach(t),iVo=i(X),_v=n(X,"LI",{});var T9e=s(_v);lhe=n(T9e,"STRONG",{});var gmt=s(lhe);dVo=r(gmt,"megatron-bert"),gmt.forEach(t),cVo=r(T9e," \u2014 "),hV=n(T9e,"A",{href:!0});var hmt=s(hV);fVo=r(hmt,"MegatronBertForQuestionAnswering"),hmt.forEach(t),mVo=r(T9e," (MegatronBert model)"),T9e.forEach(t),gVo=i(X),bv=n(X,"LI",{});var M9e=s(bv);ihe=n(M9e,"STRONG",{});var pmt=s(ihe);hVo=r(pmt,"mobilebert"),pmt.forEach(t),pVo=r(M9e," \u2014 "),pV=n(M9e,"A",{href:!0});var umt=s(pV);uVo=r(umt,"MobileBertForQuestionAnswering"),umt.forEach(t),_Vo=r(M9e," (MobileBERT model)"),M9e.forEach(t),bVo=i(X),vv=n(X,"LI",{});var E9e=s(vv);dhe=n(E9e,"STRONG",{});var _mt=s(dhe);vVo=r(_mt,"mpnet"),_mt.forEach(t),FVo=r(E9e," \u2014 "),uV=n(E9e,"A",{href:!0});var bmt=s(uV);TVo=r(bmt,"MPNetForQuestionAnswering"),bmt.forEach(t),MVo=r(E9e," (MPNet model)"),E9e.forEach(t),EVo=i(X),Fv=n(X,"LI",{});var C9e=s(Fv);che=n(C9e,"STRONG",{});var vmt=s(che);CVo=r(vmt,"nystromformer"),vmt.forEach(t),wVo=r(C9e," \u2014 "),_V=n(C9e,"A",{href:!0});var Fmt=s(_V);AVo=r(Fmt,"NystromformerForQuestionAnswering"),Fmt.forEach(t),yVo=r(C9e," (Nystromformer model)"),C9e.forEach(t),LVo=i(X),Tv=n(X,"LI",{});var w9e=s(Tv);fhe=n(w9e,"STRONG",{});var Tmt=s(fhe);xVo=r(Tmt,"qdqbert"),Tmt.forEach(t),$Vo=r(w9e," \u2014 "),bV=n(w9e,"A",{href:!0});var Mmt=s(bV);kVo=r(Mmt,"QDQBertForQuestionAnswering"),Mmt.forEach(t),SVo=r(w9e," (QDQBert model)"),w9e.forEach(t),RVo=i(X),Mv=n(X,"LI",{});var A9e=s(Mv);mhe=n(A9e,"STRONG",{});var Emt=s(mhe);PVo=r(Emt,"reformer"),Emt.forEach(t),BVo=r(A9e," \u2014 "),vV=n(A9e,"A",{href:!0});var Cmt=s(vV);IVo=r(Cmt,"ReformerForQuestionAnswering"),Cmt.forEach(t),qVo=r(A9e," (Reformer model)"),A9e.forEach(t),NVo=i(X),Ev=n(X,"LI",{});var y9e=s(Ev);ghe=n(y9e,"STRONG",{});var wmt=s(ghe);jVo=r(wmt,"rembert"),wmt.forEach(t),DVo=r(y9e," \u2014 "),FV=n(y9e,"A",{href:!0});var Amt=s(FV);GVo=r(Amt,"RemBertForQuestionAnswering"),Amt.forEach(t),OVo=r(y9e," (RemBERT model)"),y9e.forEach(t),VVo=i(X),Cv=n(X,"LI",{});var L9e=s(Cv);hhe=n(L9e,"STRONG",{});var ymt=s(hhe);XVo=r(ymt,"roberta"),ymt.forEach(t),zVo=r(L9e," \u2014 "),TV=n(L9e,"A",{href:!0});var Lmt=s(TV);WVo=r(Lmt,"RobertaForQuestionAnswering"),Lmt.forEach(t),QVo=r(L9e," (RoBERTa model)"),L9e.forEach(t),HVo=i(X),wv=n(X,"LI",{});var x9e=s(wv);phe=n(x9e,"STRONG",{});var xmt=s(phe);UVo=r(xmt,"roformer"),xmt.forEach(t),JVo=r(x9e," \u2014 "),MV=n(x9e,"A",{href:!0});var $mt=s(MV);YVo=r($mt,"RoFormerForQuestionAnswering"),$mt.forEach(t),KVo=r(x9e," (RoFormer model)"),x9e.forEach(t),ZVo=i(X),Av=n(X,"LI",{});var $9e=s(Av);uhe=n($9e,"STRONG",{});var kmt=s(uhe);eXo=r(kmt,"splinter"),kmt.forEach(t),oXo=r($9e," \u2014 "),EV=n($9e,"A",{href:!0});var Smt=s(EV);rXo=r(Smt,"SplinterForQuestionAnswering"),Smt.forEach(t),tXo=r($9e," (Splinter model)"),$9e.forEach(t),aXo=i(X),yv=n(X,"LI",{});var k9e=s(yv);_he=n(k9e,"STRONG",{});var Rmt=s(_he);nXo=r(Rmt,"squeezebert"),Rmt.forEach(t),sXo=r(k9e," \u2014 "),CV=n(k9e,"A",{href:!0});var Pmt=s(CV);lXo=r(Pmt,"SqueezeBertForQuestionAnswering"),Pmt.forEach(t),iXo=r(k9e," (SqueezeBERT model)"),k9e.forEach(t),dXo=i(X),Lv=n(X,"LI",{});var S9e=s(Lv);bhe=n(S9e,"STRONG",{});var Bmt=s(bhe);cXo=r(Bmt,"xlm"),Bmt.forEach(t),fXo=r(S9e," \u2014 "),wV=n(S9e,"A",{href:!0});var Imt=s(wV);mXo=r(Imt,"XLMForQuestionAnsweringSimple"),Imt.forEach(t),gXo=r(S9e," (XLM model)"),S9e.forEach(t),hXo=i(X),xv=n(X,"LI",{});var R9e=s(xv);vhe=n(R9e,"STRONG",{});var qmt=s(vhe);pXo=r(qmt,"xlm-roberta"),qmt.forEach(t),uXo=r(R9e," \u2014 "),AV=n(R9e,"A",{href:!0});var Nmt=s(AV);_Xo=r(Nmt,"XLMRobertaForQuestionAnswering"),Nmt.forEach(t),bXo=r(R9e," (XLM-RoBERTa model)"),R9e.forEach(t),vXo=i(X),$v=n(X,"LI",{});var P9e=s($v);Fhe=n(P9e,"STRONG",{});var jmt=s(Fhe);FXo=r(jmt,"xlm-roberta-xl"),jmt.forEach(t),TXo=r(P9e," \u2014 "),yV=n(P9e,"A",{href:!0});var Dmt=s(yV);MXo=r(Dmt,"XLMRobertaXLForQuestionAnswering"),Dmt.forEach(t),EXo=r(P9e," (XLM-RoBERTa-XL model)"),P9e.forEach(t),CXo=i(X),kv=n(X,"LI",{});var B9e=s(kv);The=n(B9e,"STRONG",{});var Gmt=s(The);wXo=r(Gmt,"xlnet"),Gmt.forEach(t),AXo=r(B9e," \u2014 "),LV=n(B9e,"A",{href:!0});var Omt=s(LV);yXo=r(Omt,"XLNetForQuestionAnsweringSimple"),Omt.forEach(t),LXo=r(B9e," (XLNet model)"),B9e.forEach(t),xXo=i(X),Sv=n(X,"LI",{});var I9e=s(Sv);Mhe=n(I9e,"STRONG",{});var Vmt=s(Mhe);$Xo=r(Vmt,"yoso"),Vmt.forEach(t),kXo=r(I9e," \u2014 "),xV=n(I9e,"A",{href:!0});var Xmt=s(xV);SXo=r(Xmt,"YosoForQuestionAnswering"),Xmt.forEach(t),RXo=r(I9e," (YOSO model)"),I9e.forEach(t),X.forEach(t),PXo=i(ca),Rv=n(ca,"P",{});var q9e=s(Rv);BXo=r(q9e,"The model is set in evaluation mode by default using "),Ehe=n(q9e,"CODE",{});var zmt=s(Ehe);IXo=r(zmt,"model.eval()"),zmt.forEach(t),qXo=r(q9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Che=n(q9e,"CODE",{});var Wmt=s(Che);NXo=r(Wmt,"model.train()"),Wmt.forEach(t),q9e.forEach(t),jXo=i(ca),T(Pv.$$.fragment,ca),ca.forEach(t),Js.forEach(t),uqe=i(f),ed=n(f,"H2",{class:!0});var Fje=s(ed);Bv=n(Fje,"A",{id:!0,class:!0,href:!0});var Qmt=s(Bv);whe=n(Qmt,"SPAN",{});var Hmt=s(whe);T(Sy.$$.fragment,Hmt),Hmt.forEach(t),Qmt.forEach(t),DXo=i(Fje),Ahe=n(Fje,"SPAN",{});var Umt=s(Ahe);GXo=r(Umt,"AutoModelForTableQuestionAnswering"),Umt.forEach(t),Fje.forEach(t),_qe=i(f),No=n(f,"DIV",{class:!0});var Ys=s(No);T(Ry.$$.fragment,Ys),OXo=i(Ys),od=n(Ys,"P",{});var ZK=s(od);VXo=r(ZK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$V=n(ZK,"A",{href:!0});var Jmt=s($V);XXo=r(Jmt,"from_pretrained()"),Jmt.forEach(t),zXo=r(ZK," class method or the "),kV=n(ZK,"A",{href:!0});var Ymt=s(kV);WXo=r(Ymt,"from_config()"),Ymt.forEach(t),QXo=r(ZK,` class
method.`),ZK.forEach(t),HXo=i(Ys),Py=n(Ys,"P",{});var Tje=s(Py);UXo=r(Tje,"This class cannot be instantiated directly using "),yhe=n(Tje,"CODE",{});var Kmt=s(yhe);JXo=r(Kmt,"__init__()"),Kmt.forEach(t),YXo=r(Tje," (throws an error)."),Tje.forEach(t),KXo=i(Ys),gt=n(Ys,"DIV",{class:!0});var PA=s(gt);T(By.$$.fragment,PA),ZXo=i(PA),Lhe=n(PA,"P",{});var Zmt=s(Lhe);ezo=r(Zmt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Zmt.forEach(t),ozo=i(PA),rd=n(PA,"P",{});var eZ=s(rd);rzo=r(eZ,`Note:
Loading a model from its configuration file does `),xhe=n(eZ,"STRONG",{});var egt=s(xhe);tzo=r(egt,"not"),egt.forEach(t),azo=r(eZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),SV=n(eZ,"A",{href:!0});var ogt=s(SV);nzo=r(ogt,"from_pretrained()"),ogt.forEach(t),szo=r(eZ," to load the model weights."),eZ.forEach(t),lzo=i(PA),T(Iv.$$.fragment,PA),PA.forEach(t),izo=i(Ys),so=n(Ys,"DIV",{class:!0});var fa=s(so);T(Iy.$$.fragment,fa),dzo=i(fa),$he=n(fa,"P",{});var rgt=s($he);czo=r(rgt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),rgt.forEach(t),fzo=i(fa),Na=n(fa,"P",{});var BA=s(Na);mzo=r(BA,"The model class to instantiate is selected based on the "),khe=n(BA,"CODE",{});var tgt=s(khe);gzo=r(tgt,"model_type"),tgt.forEach(t),hzo=r(BA,` property of the config object (either
passed as an argument or loaded from `),She=n(BA,"CODE",{});var agt=s(She);pzo=r(agt,"pretrained_model_name_or_path"),agt.forEach(t),uzo=r(BA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rhe=n(BA,"CODE",{});var ngt=s(Rhe);_zo=r(ngt,"pretrained_model_name_or_path"),ngt.forEach(t),bzo=r(BA,":"),BA.forEach(t),vzo=i(fa),Phe=n(fa,"UL",{});var sgt=s(Phe);qv=n(sgt,"LI",{});var N9e=s(qv);Bhe=n(N9e,"STRONG",{});var lgt=s(Bhe);Fzo=r(lgt,"tapas"),lgt.forEach(t),Tzo=r(N9e," \u2014 "),RV=n(N9e,"A",{href:!0});var igt=s(RV);Mzo=r(igt,"TapasForQuestionAnswering"),igt.forEach(t),Ezo=r(N9e," (TAPAS model)"),N9e.forEach(t),sgt.forEach(t),Czo=i(fa),Nv=n(fa,"P",{});var j9e=s(Nv);wzo=r(j9e,"The model is set in evaluation mode by default using "),Ihe=n(j9e,"CODE",{});var dgt=s(Ihe);Azo=r(dgt,"model.eval()"),dgt.forEach(t),yzo=r(j9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qhe=n(j9e,"CODE",{});var cgt=s(qhe);Lzo=r(cgt,"model.train()"),cgt.forEach(t),j9e.forEach(t),xzo=i(fa),T(jv.$$.fragment,fa),fa.forEach(t),Ys.forEach(t),bqe=i(f),td=n(f,"H2",{class:!0});var Mje=s(td);Dv=n(Mje,"A",{id:!0,class:!0,href:!0});var fgt=s(Dv);Nhe=n(fgt,"SPAN",{});var mgt=s(Nhe);T(qy.$$.fragment,mgt),mgt.forEach(t),fgt.forEach(t),$zo=i(Mje),jhe=n(Mje,"SPAN",{});var ggt=s(jhe);kzo=r(ggt,"AutoModelForImageClassification"),ggt.forEach(t),Mje.forEach(t),vqe=i(f),jo=n(f,"DIV",{class:!0});var Ks=s(jo);T(Ny.$$.fragment,Ks),Szo=i(Ks),ad=n(Ks,"P",{});var oZ=s(ad);Rzo=r(oZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),PV=n(oZ,"A",{href:!0});var hgt=s(PV);Pzo=r(hgt,"from_pretrained()"),hgt.forEach(t),Bzo=r(oZ," class method or the "),BV=n(oZ,"A",{href:!0});var pgt=s(BV);Izo=r(pgt,"from_config()"),pgt.forEach(t),qzo=r(oZ,` class
method.`),oZ.forEach(t),Nzo=i(Ks),jy=n(Ks,"P",{});var Eje=s(jy);jzo=r(Eje,"This class cannot be instantiated directly using "),Dhe=n(Eje,"CODE",{});var ugt=s(Dhe);Dzo=r(ugt,"__init__()"),ugt.forEach(t),Gzo=r(Eje," (throws an error)."),Eje.forEach(t),Ozo=i(Ks),ht=n(Ks,"DIV",{class:!0});var IA=s(ht);T(Dy.$$.fragment,IA),Vzo=i(IA),Ghe=n(IA,"P",{});var _gt=s(Ghe);Xzo=r(_gt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_gt.forEach(t),zzo=i(IA),nd=n(IA,"P",{});var rZ=s(nd);Wzo=r(rZ,`Note:
Loading a model from its configuration file does `),Ohe=n(rZ,"STRONG",{});var bgt=s(Ohe);Qzo=r(bgt,"not"),bgt.forEach(t),Hzo=r(rZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),IV=n(rZ,"A",{href:!0});var vgt=s(IV);Uzo=r(vgt,"from_pretrained()"),vgt.forEach(t),Jzo=r(rZ," to load the model weights."),rZ.forEach(t),Yzo=i(IA),T(Gv.$$.fragment,IA),IA.forEach(t),Kzo=i(Ks),lo=n(Ks,"DIV",{class:!0});var ma=s(lo);T(Gy.$$.fragment,ma),Zzo=i(ma),Vhe=n(ma,"P",{});var Fgt=s(Vhe);eWo=r(Fgt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Fgt.forEach(t),oWo=i(ma),ja=n(ma,"P",{});var qA=s(ja);rWo=r(qA,"The model class to instantiate is selected based on the "),Xhe=n(qA,"CODE",{});var Tgt=s(Xhe);tWo=r(Tgt,"model_type"),Tgt.forEach(t),aWo=r(qA,` property of the config object (either
passed as an argument or loaded from `),zhe=n(qA,"CODE",{});var Mgt=s(zhe);nWo=r(Mgt,"pretrained_model_name_or_path"),Mgt.forEach(t),sWo=r(qA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Whe=n(qA,"CODE",{});var Egt=s(Whe);lWo=r(Egt,"pretrained_model_name_or_path"),Egt.forEach(t),iWo=r(qA,":"),qA.forEach(t),dWo=i(ma),Fe=n(ma,"UL",{});var Ee=s(Fe);Ov=n(Ee,"LI",{});var D9e=s(Ov);Qhe=n(D9e,"STRONG",{});var Cgt=s(Qhe);cWo=r(Cgt,"beit"),Cgt.forEach(t),fWo=r(D9e," \u2014 "),qV=n(D9e,"A",{href:!0});var wgt=s(qV);mWo=r(wgt,"BeitForImageClassification"),wgt.forEach(t),gWo=r(D9e," (BEiT model)"),D9e.forEach(t),hWo=i(Ee),Vv=n(Ee,"LI",{});var G9e=s(Vv);Hhe=n(G9e,"STRONG",{});var Agt=s(Hhe);pWo=r(Agt,"convnext"),Agt.forEach(t),uWo=r(G9e," \u2014 "),NV=n(G9e,"A",{href:!0});var ygt=s(NV);_Wo=r(ygt,"ConvNextForImageClassification"),ygt.forEach(t),bWo=r(G9e," (ConvNext model)"),G9e.forEach(t),vWo=i(Ee),Xv=n(Ee,"LI",{});var O9e=s(Xv);Uhe=n(O9e,"STRONG",{});var Lgt=s(Uhe);FWo=r(Lgt,"data2vec-vision"),Lgt.forEach(t),TWo=r(O9e," \u2014 "),jV=n(O9e,"A",{href:!0});var xgt=s(jV);MWo=r(xgt,"Data2VecVisionForImageClassification"),xgt.forEach(t),EWo=r(O9e," (Data2VecVision model)"),O9e.forEach(t),CWo=i(Ee),Ps=n(Ee,"LI",{});var w$=s(Ps);Jhe=n(w$,"STRONG",{});var $gt=s(Jhe);wWo=r($gt,"deit"),$gt.forEach(t),AWo=r(w$," \u2014 "),DV=n(w$,"A",{href:!0});var kgt=s(DV);yWo=r(kgt,"DeiTForImageClassification"),kgt.forEach(t),LWo=r(w$," or "),GV=n(w$,"A",{href:!0});var Sgt=s(GV);xWo=r(Sgt,"DeiTForImageClassificationWithTeacher"),Sgt.forEach(t),$Wo=r(w$," (DeiT model)"),w$.forEach(t),kWo=i(Ee),zv=n(Ee,"LI",{});var V9e=s(zv);Yhe=n(V9e,"STRONG",{});var Rgt=s(Yhe);SWo=r(Rgt,"imagegpt"),Rgt.forEach(t),RWo=r(V9e," \u2014 "),OV=n(V9e,"A",{href:!0});var Pgt=s(OV);PWo=r(Pgt,"ImageGPTForImageClassification"),Pgt.forEach(t),BWo=r(V9e," (ImageGPT model)"),V9e.forEach(t),IWo=i(Ee),pt=n(Ee,"LI",{});var gf=s(pt);Khe=n(gf,"STRONG",{});var Bgt=s(Khe);qWo=r(Bgt,"perceiver"),Bgt.forEach(t),NWo=r(gf," \u2014 "),VV=n(gf,"A",{href:!0});var Igt=s(VV);jWo=r(Igt,"PerceiverForImageClassificationLearned"),Igt.forEach(t),DWo=r(gf," or "),XV=n(gf,"A",{href:!0});var qgt=s(XV);GWo=r(qgt,"PerceiverForImageClassificationFourier"),qgt.forEach(t),OWo=r(gf," or "),zV=n(gf,"A",{href:!0});var Ngt=s(zV);VWo=r(Ngt,"PerceiverForImageClassificationConvProcessing"),Ngt.forEach(t),XWo=r(gf," (Perceiver model)"),gf.forEach(t),zWo=i(Ee),Wv=n(Ee,"LI",{});var X9e=s(Wv);Zhe=n(X9e,"STRONG",{});var jgt=s(Zhe);WWo=r(jgt,"poolformer"),jgt.forEach(t),QWo=r(X9e," \u2014 "),WV=n(X9e,"A",{href:!0});var Dgt=s(WV);HWo=r(Dgt,"PoolFormerForImageClassification"),Dgt.forEach(t),UWo=r(X9e," (PoolFormer model)"),X9e.forEach(t),JWo=i(Ee),Qv=n(Ee,"LI",{});var z9e=s(Qv);epe=n(z9e,"STRONG",{});var Ggt=s(epe);YWo=r(Ggt,"regnet"),Ggt.forEach(t),KWo=r(z9e," \u2014 "),QV=n(z9e,"A",{href:!0});var Ogt=s(QV);ZWo=r(Ogt,"RegNetForImageClassification"),Ogt.forEach(t),eQo=r(z9e," (RegNet model)"),z9e.forEach(t),oQo=i(Ee),Hv=n(Ee,"LI",{});var W9e=s(Hv);ope=n(W9e,"STRONG",{});var Vgt=s(ope);rQo=r(Vgt,"resnet"),Vgt.forEach(t),tQo=r(W9e," \u2014 "),HV=n(W9e,"A",{href:!0});var Xgt=s(HV);aQo=r(Xgt,"ResNetForImageClassification"),Xgt.forEach(t),nQo=r(W9e," (ResNet model)"),W9e.forEach(t),sQo=i(Ee),Uv=n(Ee,"LI",{});var Q9e=s(Uv);rpe=n(Q9e,"STRONG",{});var zgt=s(rpe);lQo=r(zgt,"segformer"),zgt.forEach(t),iQo=r(Q9e," \u2014 "),UV=n(Q9e,"A",{href:!0});var Wgt=s(UV);dQo=r(Wgt,"SegformerForImageClassification"),Wgt.forEach(t),cQo=r(Q9e," (SegFormer model)"),Q9e.forEach(t),fQo=i(Ee),Jv=n(Ee,"LI",{});var H9e=s(Jv);tpe=n(H9e,"STRONG",{});var Qgt=s(tpe);mQo=r(Qgt,"swin"),Qgt.forEach(t),gQo=r(H9e," \u2014 "),JV=n(H9e,"A",{href:!0});var Hgt=s(JV);hQo=r(Hgt,"SwinForImageClassification"),Hgt.forEach(t),pQo=r(H9e," (Swin model)"),H9e.forEach(t),uQo=i(Ee),Yv=n(Ee,"LI",{});var U9e=s(Yv);ape=n(U9e,"STRONG",{});var Ugt=s(ape);_Qo=r(Ugt,"van"),Ugt.forEach(t),bQo=r(U9e," \u2014 "),YV=n(U9e,"A",{href:!0});var Jgt=s(YV);vQo=r(Jgt,"VanForImageClassification"),Jgt.forEach(t),FQo=r(U9e," (VAN model)"),U9e.forEach(t),TQo=i(Ee),Kv=n(Ee,"LI",{});var J9e=s(Kv);npe=n(J9e,"STRONG",{});var Ygt=s(npe);MQo=r(Ygt,"vit"),Ygt.forEach(t),EQo=r(J9e," \u2014 "),KV=n(J9e,"A",{href:!0});var Kgt=s(KV);CQo=r(Kgt,"ViTForImageClassification"),Kgt.forEach(t),wQo=r(J9e," (ViT model)"),J9e.forEach(t),Ee.forEach(t),AQo=i(ma),Zv=n(ma,"P",{});var Y9e=s(Zv);yQo=r(Y9e,"The model is set in evaluation mode by default using "),spe=n(Y9e,"CODE",{});var Zgt=s(spe);LQo=r(Zgt,"model.eval()"),Zgt.forEach(t),xQo=r(Y9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lpe=n(Y9e,"CODE",{});var eht=s(lpe);$Qo=r(eht,"model.train()"),eht.forEach(t),Y9e.forEach(t),kQo=i(ma),T(eF.$$.fragment,ma),ma.forEach(t),Ks.forEach(t),Fqe=i(f),sd=n(f,"H2",{class:!0});var Cje=s(sd);oF=n(Cje,"A",{id:!0,class:!0,href:!0});var oht=s(oF);ipe=n(oht,"SPAN",{});var rht=s(ipe);T(Oy.$$.fragment,rht),rht.forEach(t),oht.forEach(t),SQo=i(Cje),dpe=n(Cje,"SPAN",{});var tht=s(dpe);RQo=r(tht,"AutoModelForVision2Seq"),tht.forEach(t),Cje.forEach(t),Tqe=i(f),Do=n(f,"DIV",{class:!0});var Zs=s(Do);T(Vy.$$.fragment,Zs),PQo=i(Zs),ld=n(Zs,"P",{});var tZ=s(ld);BQo=r(tZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ZV=n(tZ,"A",{href:!0});var aht=s(ZV);IQo=r(aht,"from_pretrained()"),aht.forEach(t),qQo=r(tZ," class method or the "),eX=n(tZ,"A",{href:!0});var nht=s(eX);NQo=r(nht,"from_config()"),nht.forEach(t),jQo=r(tZ,` class
method.`),tZ.forEach(t),DQo=i(Zs),Xy=n(Zs,"P",{});var wje=s(Xy);GQo=r(wje,"This class cannot be instantiated directly using "),cpe=n(wje,"CODE",{});var sht=s(cpe);OQo=r(sht,"__init__()"),sht.forEach(t),VQo=r(wje," (throws an error)."),wje.forEach(t),XQo=i(Zs),ut=n(Zs,"DIV",{class:!0});var NA=s(ut);T(zy.$$.fragment,NA),zQo=i(NA),fpe=n(NA,"P",{});var lht=s(fpe);WQo=r(lht,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),lht.forEach(t),QQo=i(NA),id=n(NA,"P",{});var aZ=s(id);HQo=r(aZ,`Note:
Loading a model from its configuration file does `),mpe=n(aZ,"STRONG",{});var iht=s(mpe);UQo=r(iht,"not"),iht.forEach(t),JQo=r(aZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),oX=n(aZ,"A",{href:!0});var dht=s(oX);YQo=r(dht,"from_pretrained()"),dht.forEach(t),KQo=r(aZ," to load the model weights."),aZ.forEach(t),ZQo=i(NA),T(rF.$$.fragment,NA),NA.forEach(t),eHo=i(Zs),io=n(Zs,"DIV",{class:!0});var ga=s(io);T(Wy.$$.fragment,ga),oHo=i(ga),gpe=n(ga,"P",{});var cht=s(gpe);rHo=r(cht,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),cht.forEach(t),tHo=i(ga),Da=n(ga,"P",{});var jA=s(Da);aHo=r(jA,"The model class to instantiate is selected based on the "),hpe=n(jA,"CODE",{});var fht=s(hpe);nHo=r(fht,"model_type"),fht.forEach(t),sHo=r(jA,` property of the config object (either
passed as an argument or loaded from `),ppe=n(jA,"CODE",{});var mht=s(ppe);lHo=r(mht,"pretrained_model_name_or_path"),mht.forEach(t),iHo=r(jA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),upe=n(jA,"CODE",{});var ght=s(upe);dHo=r(ght,"pretrained_model_name_or_path"),ght.forEach(t),cHo=r(jA,":"),jA.forEach(t),fHo=i(ga),_pe=n(ga,"UL",{});var hht=s(_pe);tF=n(hht,"LI",{});var K9e=s(tF);bpe=n(K9e,"STRONG",{});var pht=s(bpe);mHo=r(pht,"vision-encoder-decoder"),pht.forEach(t),gHo=r(K9e," \u2014 "),rX=n(K9e,"A",{href:!0});var uht=s(rX);hHo=r(uht,"VisionEncoderDecoderModel"),uht.forEach(t),pHo=r(K9e," (Vision Encoder decoder model)"),K9e.forEach(t),hht.forEach(t),uHo=i(ga),aF=n(ga,"P",{});var Z9e=s(aF);_Ho=r(Z9e,"The model is set in evaluation mode by default using "),vpe=n(Z9e,"CODE",{});var _ht=s(vpe);bHo=r(_ht,"model.eval()"),_ht.forEach(t),vHo=r(Z9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fpe=n(Z9e,"CODE",{});var bht=s(Fpe);FHo=r(bht,"model.train()"),bht.forEach(t),Z9e.forEach(t),THo=i(ga),T(nF.$$.fragment,ga),ga.forEach(t),Zs.forEach(t),Mqe=i(f),dd=n(f,"H2",{class:!0});var Aje=s(dd);sF=n(Aje,"A",{id:!0,class:!0,href:!0});var vht=s(sF);Tpe=n(vht,"SPAN",{});var Fht=s(Tpe);T(Qy.$$.fragment,Fht),Fht.forEach(t),vht.forEach(t),MHo=i(Aje),Mpe=n(Aje,"SPAN",{});var Tht=s(Mpe);EHo=r(Tht,"AutoModelForAudioClassification"),Tht.forEach(t),Aje.forEach(t),Eqe=i(f),Go=n(f,"DIV",{class:!0});var el=s(Go);T(Hy.$$.fragment,el),CHo=i(el),cd=n(el,"P",{});var nZ=s(cd);wHo=r(nZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),tX=n(nZ,"A",{href:!0});var Mht=s(tX);AHo=r(Mht,"from_pretrained()"),Mht.forEach(t),yHo=r(nZ," class method or the "),aX=n(nZ,"A",{href:!0});var Eht=s(aX);LHo=r(Eht,"from_config()"),Eht.forEach(t),xHo=r(nZ,` class
method.`),nZ.forEach(t),$Ho=i(el),Uy=n(el,"P",{});var yje=s(Uy);kHo=r(yje,"This class cannot be instantiated directly using "),Epe=n(yje,"CODE",{});var Cht=s(Epe);SHo=r(Cht,"__init__()"),Cht.forEach(t),RHo=r(yje," (throws an error)."),yje.forEach(t),PHo=i(el),_t=n(el,"DIV",{class:!0});var DA=s(_t);T(Jy.$$.fragment,DA),BHo=i(DA),Cpe=n(DA,"P",{});var wht=s(Cpe);IHo=r(wht,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),wht.forEach(t),qHo=i(DA),fd=n(DA,"P",{});var sZ=s(fd);NHo=r(sZ,`Note:
Loading a model from its configuration file does `),wpe=n(sZ,"STRONG",{});var Aht=s(wpe);jHo=r(Aht,"not"),Aht.forEach(t),DHo=r(sZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),nX=n(sZ,"A",{href:!0});var yht=s(nX);GHo=r(yht,"from_pretrained()"),yht.forEach(t),OHo=r(sZ," to load the model weights."),sZ.forEach(t),VHo=i(DA),T(lF.$$.fragment,DA),DA.forEach(t),XHo=i(el),co=n(el,"DIV",{class:!0});var ha=s(co);T(Yy.$$.fragment,ha),zHo=i(ha),Ape=n(ha,"P",{});var Lht=s(Ape);WHo=r(Lht,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Lht.forEach(t),QHo=i(ha),Ga=n(ha,"P",{});var GA=s(Ga);HHo=r(GA,"The model class to instantiate is selected based on the "),ype=n(GA,"CODE",{});var xht=s(ype);UHo=r(xht,"model_type"),xht.forEach(t),JHo=r(GA,` property of the config object (either
passed as an argument or loaded from `),Lpe=n(GA,"CODE",{});var $ht=s(Lpe);YHo=r($ht,"pretrained_model_name_or_path"),$ht.forEach(t),KHo=r(GA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xpe=n(GA,"CODE",{});var kht=s(xpe);ZHo=r(kht,"pretrained_model_name_or_path"),kht.forEach(t),eUo=r(GA,":"),GA.forEach(t),oUo=i(ha),Se=n(ha,"UL",{});var Ve=s(Se);iF=n(Ve,"LI",{});var e$e=s(iF);$pe=n(e$e,"STRONG",{});var Sht=s($pe);rUo=r(Sht,"data2vec-audio"),Sht.forEach(t),tUo=r(e$e," \u2014 "),sX=n(e$e,"A",{href:!0});var Rht=s(sX);aUo=r(Rht,"Data2VecAudioForSequenceClassification"),Rht.forEach(t),nUo=r(e$e," (Data2VecAudio model)"),e$e.forEach(t),sUo=i(Ve),dF=n(Ve,"LI",{});var o$e=s(dF);kpe=n(o$e,"STRONG",{});var Pht=s(kpe);lUo=r(Pht,"hubert"),Pht.forEach(t),iUo=r(o$e," \u2014 "),lX=n(o$e,"A",{href:!0});var Bht=s(lX);dUo=r(Bht,"HubertForSequenceClassification"),Bht.forEach(t),cUo=r(o$e," (Hubert model)"),o$e.forEach(t),fUo=i(Ve),cF=n(Ve,"LI",{});var r$e=s(cF);Spe=n(r$e,"STRONG",{});var Iht=s(Spe);mUo=r(Iht,"sew"),Iht.forEach(t),gUo=r(r$e," \u2014 "),iX=n(r$e,"A",{href:!0});var qht=s(iX);hUo=r(qht,"SEWForSequenceClassification"),qht.forEach(t),pUo=r(r$e," (SEW model)"),r$e.forEach(t),uUo=i(Ve),fF=n(Ve,"LI",{});var t$e=s(fF);Rpe=n(t$e,"STRONG",{});var Nht=s(Rpe);_Uo=r(Nht,"sew-d"),Nht.forEach(t),bUo=r(t$e," \u2014 "),dX=n(t$e,"A",{href:!0});var jht=s(dX);vUo=r(jht,"SEWDForSequenceClassification"),jht.forEach(t),FUo=r(t$e," (SEW-D model)"),t$e.forEach(t),TUo=i(Ve),mF=n(Ve,"LI",{});var a$e=s(mF);Ppe=n(a$e,"STRONG",{});var Dht=s(Ppe);MUo=r(Dht,"unispeech"),Dht.forEach(t),EUo=r(a$e," \u2014 "),cX=n(a$e,"A",{href:!0});var Ght=s(cX);CUo=r(Ght,"UniSpeechForSequenceClassification"),Ght.forEach(t),wUo=r(a$e," (UniSpeech model)"),a$e.forEach(t),AUo=i(Ve),gF=n(Ve,"LI",{});var n$e=s(gF);Bpe=n(n$e,"STRONG",{});var Oht=s(Bpe);yUo=r(Oht,"unispeech-sat"),Oht.forEach(t),LUo=r(n$e," \u2014 "),fX=n(n$e,"A",{href:!0});var Vht=s(fX);xUo=r(Vht,"UniSpeechSatForSequenceClassification"),Vht.forEach(t),$Uo=r(n$e," (UniSpeechSat model)"),n$e.forEach(t),kUo=i(Ve),hF=n(Ve,"LI",{});var s$e=s(hF);Ipe=n(s$e,"STRONG",{});var Xht=s(Ipe);SUo=r(Xht,"wav2vec2"),Xht.forEach(t),RUo=r(s$e," \u2014 "),mX=n(s$e,"A",{href:!0});var zht=s(mX);PUo=r(zht,"Wav2Vec2ForSequenceClassification"),zht.forEach(t),BUo=r(s$e," (Wav2Vec2 model)"),s$e.forEach(t),IUo=i(Ve),pF=n(Ve,"LI",{});var l$e=s(pF);qpe=n(l$e,"STRONG",{});var Wht=s(qpe);qUo=r(Wht,"wav2vec2-conformer"),Wht.forEach(t),NUo=r(l$e," \u2014 "),gX=n(l$e,"A",{href:!0});var Qht=s(gX);jUo=r(Qht,"Wav2Vec2ConformerForSequenceClassification"),Qht.forEach(t),DUo=r(l$e," (Wav2Vec2-Conformer model)"),l$e.forEach(t),GUo=i(Ve),uF=n(Ve,"LI",{});var i$e=s(uF);Npe=n(i$e,"STRONG",{});var Hht=s(Npe);OUo=r(Hht,"wavlm"),Hht.forEach(t),VUo=r(i$e," \u2014 "),hX=n(i$e,"A",{href:!0});var Uht=s(hX);XUo=r(Uht,"WavLMForSequenceClassification"),Uht.forEach(t),zUo=r(i$e," (WavLM model)"),i$e.forEach(t),Ve.forEach(t),WUo=i(ha),_F=n(ha,"P",{});var d$e=s(_F);QUo=r(d$e,"The model is set in evaluation mode by default using "),jpe=n(d$e,"CODE",{});var Jht=s(jpe);HUo=r(Jht,"model.eval()"),Jht.forEach(t),UUo=r(d$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dpe=n(d$e,"CODE",{});var Yht=s(Dpe);JUo=r(Yht,"model.train()"),Yht.forEach(t),d$e.forEach(t),YUo=i(ha),T(bF.$$.fragment,ha),ha.forEach(t),el.forEach(t),Cqe=i(f),md=n(f,"H2",{class:!0});var Lje=s(md);vF=n(Lje,"A",{id:!0,class:!0,href:!0});var Kht=s(vF);Gpe=n(Kht,"SPAN",{});var Zht=s(Gpe);T(Ky.$$.fragment,Zht),Zht.forEach(t),Kht.forEach(t),KUo=i(Lje),Ope=n(Lje,"SPAN",{});var ept=s(Ope);ZUo=r(ept,"AutoModelForAudioFrameClassification"),ept.forEach(t),Lje.forEach(t),wqe=i(f),Oo=n(f,"DIV",{class:!0});var ol=s(Oo);T(Zy.$$.fragment,ol),eJo=i(ol),gd=n(ol,"P",{});var lZ=s(gd);oJo=r(lZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),pX=n(lZ,"A",{href:!0});var opt=s(pX);rJo=r(opt,"from_pretrained()"),opt.forEach(t),tJo=r(lZ," class method or the "),uX=n(lZ,"A",{href:!0});var rpt=s(uX);aJo=r(rpt,"from_config()"),rpt.forEach(t),nJo=r(lZ,` class
method.`),lZ.forEach(t),sJo=i(ol),eL=n(ol,"P",{});var xje=s(eL);lJo=r(xje,"This class cannot be instantiated directly using "),Vpe=n(xje,"CODE",{});var tpt=s(Vpe);iJo=r(tpt,"__init__()"),tpt.forEach(t),dJo=r(xje," (throws an error)."),xje.forEach(t),cJo=i(ol),bt=n(ol,"DIV",{class:!0});var OA=s(bt);T(oL.$$.fragment,OA),fJo=i(OA),Xpe=n(OA,"P",{});var apt=s(Xpe);mJo=r(apt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),apt.forEach(t),gJo=i(OA),hd=n(OA,"P",{});var iZ=s(hd);hJo=r(iZ,`Note:
Loading a model from its configuration file does `),zpe=n(iZ,"STRONG",{});var npt=s(zpe);pJo=r(npt,"not"),npt.forEach(t),uJo=r(iZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_X=n(iZ,"A",{href:!0});var spt=s(_X);_Jo=r(spt,"from_pretrained()"),spt.forEach(t),bJo=r(iZ," to load the model weights."),iZ.forEach(t),vJo=i(OA),T(FF.$$.fragment,OA),OA.forEach(t),FJo=i(ol),fo=n(ol,"DIV",{class:!0});var pa=s(fo);T(rL.$$.fragment,pa),TJo=i(pa),Wpe=n(pa,"P",{});var lpt=s(Wpe);MJo=r(lpt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),lpt.forEach(t),EJo=i(pa),Oa=n(pa,"P",{});var VA=s(Oa);CJo=r(VA,"The model class to instantiate is selected based on the "),Qpe=n(VA,"CODE",{});var ipt=s(Qpe);wJo=r(ipt,"model_type"),ipt.forEach(t),AJo=r(VA,` property of the config object (either
passed as an argument or loaded from `),Hpe=n(VA,"CODE",{});var dpt=s(Hpe);yJo=r(dpt,"pretrained_model_name_or_path"),dpt.forEach(t),LJo=r(VA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Upe=n(VA,"CODE",{});var cpt=s(Upe);xJo=r(cpt,"pretrained_model_name_or_path"),cpt.forEach(t),$Jo=r(VA,":"),VA.forEach(t),kJo=i(pa),Kr=n(pa,"UL",{});var rl=s(Kr);TF=n(rl,"LI",{});var c$e=s(TF);Jpe=n(c$e,"STRONG",{});var fpt=s(Jpe);SJo=r(fpt,"data2vec-audio"),fpt.forEach(t),RJo=r(c$e," \u2014 "),bX=n(c$e,"A",{href:!0});var mpt=s(bX);PJo=r(mpt,"Data2VecAudioForAudioFrameClassification"),mpt.forEach(t),BJo=r(c$e," (Data2VecAudio model)"),c$e.forEach(t),IJo=i(rl),MF=n(rl,"LI",{});var f$e=s(MF);Ype=n(f$e,"STRONG",{});var gpt=s(Ype);qJo=r(gpt,"unispeech-sat"),gpt.forEach(t),NJo=r(f$e," \u2014 "),vX=n(f$e,"A",{href:!0});var hpt=s(vX);jJo=r(hpt,"UniSpeechSatForAudioFrameClassification"),hpt.forEach(t),DJo=r(f$e," (UniSpeechSat model)"),f$e.forEach(t),GJo=i(rl),EF=n(rl,"LI",{});var m$e=s(EF);Kpe=n(m$e,"STRONG",{});var ppt=s(Kpe);OJo=r(ppt,"wav2vec2"),ppt.forEach(t),VJo=r(m$e," \u2014 "),FX=n(m$e,"A",{href:!0});var upt=s(FX);XJo=r(upt,"Wav2Vec2ForAudioFrameClassification"),upt.forEach(t),zJo=r(m$e," (Wav2Vec2 model)"),m$e.forEach(t),WJo=i(rl),CF=n(rl,"LI",{});var g$e=s(CF);Zpe=n(g$e,"STRONG",{});var _pt=s(Zpe);QJo=r(_pt,"wav2vec2-conformer"),_pt.forEach(t),HJo=r(g$e," \u2014 "),TX=n(g$e,"A",{href:!0});var bpt=s(TX);UJo=r(bpt,"Wav2Vec2ConformerForAudioFrameClassification"),bpt.forEach(t),JJo=r(g$e," (Wav2Vec2-Conformer model)"),g$e.forEach(t),YJo=i(rl),wF=n(rl,"LI",{});var h$e=s(wF);eue=n(h$e,"STRONG",{});var vpt=s(eue);KJo=r(vpt,"wavlm"),vpt.forEach(t),ZJo=r(h$e," \u2014 "),MX=n(h$e,"A",{href:!0});var Fpt=s(MX);eYo=r(Fpt,"WavLMForAudioFrameClassification"),Fpt.forEach(t),oYo=r(h$e," (WavLM model)"),h$e.forEach(t),rl.forEach(t),rYo=i(pa),AF=n(pa,"P",{});var p$e=s(AF);tYo=r(p$e,"The model is set in evaluation mode by default using "),oue=n(p$e,"CODE",{});var Tpt=s(oue);aYo=r(Tpt,"model.eval()"),Tpt.forEach(t),nYo=r(p$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rue=n(p$e,"CODE",{});var Mpt=s(rue);sYo=r(Mpt,"model.train()"),Mpt.forEach(t),p$e.forEach(t),lYo=i(pa),T(yF.$$.fragment,pa),pa.forEach(t),ol.forEach(t),Aqe=i(f),pd=n(f,"H2",{class:!0});var $je=s(pd);LF=n($je,"A",{id:!0,class:!0,href:!0});var Ept=s(LF);tue=n(Ept,"SPAN",{});var Cpt=s(tue);T(tL.$$.fragment,Cpt),Cpt.forEach(t),Ept.forEach(t),iYo=i($je),aue=n($je,"SPAN",{});var wpt=s(aue);dYo=r(wpt,"AutoModelForCTC"),wpt.forEach(t),$je.forEach(t),yqe=i(f),Vo=n(f,"DIV",{class:!0});var tl=s(Vo);T(aL.$$.fragment,tl),cYo=i(tl),ud=n(tl,"P",{});var dZ=s(ud);fYo=r(dZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),EX=n(dZ,"A",{href:!0});var Apt=s(EX);mYo=r(Apt,"from_pretrained()"),Apt.forEach(t),gYo=r(dZ," class method or the "),CX=n(dZ,"A",{href:!0});var ypt=s(CX);hYo=r(ypt,"from_config()"),ypt.forEach(t),pYo=r(dZ,` class
method.`),dZ.forEach(t),uYo=i(tl),nL=n(tl,"P",{});var kje=s(nL);_Yo=r(kje,"This class cannot be instantiated directly using "),nue=n(kje,"CODE",{});var Lpt=s(nue);bYo=r(Lpt,"__init__()"),Lpt.forEach(t),vYo=r(kje," (throws an error)."),kje.forEach(t),FYo=i(tl),vt=n(tl,"DIV",{class:!0});var XA=s(vt);T(sL.$$.fragment,XA),TYo=i(XA),sue=n(XA,"P",{});var xpt=s(sue);MYo=r(xpt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),xpt.forEach(t),EYo=i(XA),_d=n(XA,"P",{});var cZ=s(_d);CYo=r(cZ,`Note:
Loading a model from its configuration file does `),lue=n(cZ,"STRONG",{});var $pt=s(lue);wYo=r($pt,"not"),$pt.forEach(t),AYo=r(cZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),wX=n(cZ,"A",{href:!0});var kpt=s(wX);yYo=r(kpt,"from_pretrained()"),kpt.forEach(t),LYo=r(cZ," to load the model weights."),cZ.forEach(t),xYo=i(XA),T(xF.$$.fragment,XA),XA.forEach(t),$Yo=i(tl),mo=n(tl,"DIV",{class:!0});var ua=s(mo);T(lL.$$.fragment,ua),kYo=i(ua),iue=n(ua,"P",{});var Spt=s(iue);SYo=r(Spt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Spt.forEach(t),RYo=i(ua),Va=n(ua,"P",{});var zA=s(Va);PYo=r(zA,"The model class to instantiate is selected based on the "),due=n(zA,"CODE",{});var Rpt=s(due);BYo=r(Rpt,"model_type"),Rpt.forEach(t),IYo=r(zA,` property of the config object (either
passed as an argument or loaded from `),cue=n(zA,"CODE",{});var Ppt=s(cue);qYo=r(Ppt,"pretrained_model_name_or_path"),Ppt.forEach(t),NYo=r(zA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fue=n(zA,"CODE",{});var Bpt=s(fue);jYo=r(Bpt,"pretrained_model_name_or_path"),Bpt.forEach(t),DYo=r(zA,":"),zA.forEach(t),GYo=i(ua),Re=n(ua,"UL",{});var Xe=s(Re);$F=n(Xe,"LI",{});var u$e=s($F);mue=n(u$e,"STRONG",{});var Ipt=s(mue);OYo=r(Ipt,"data2vec-audio"),Ipt.forEach(t),VYo=r(u$e," \u2014 "),AX=n(u$e,"A",{href:!0});var qpt=s(AX);XYo=r(qpt,"Data2VecAudioForCTC"),qpt.forEach(t),zYo=r(u$e," (Data2VecAudio model)"),u$e.forEach(t),WYo=i(Xe),kF=n(Xe,"LI",{});var _$e=s(kF);gue=n(_$e,"STRONG",{});var Npt=s(gue);QYo=r(Npt,"hubert"),Npt.forEach(t),HYo=r(_$e," \u2014 "),yX=n(_$e,"A",{href:!0});var jpt=s(yX);UYo=r(jpt,"HubertForCTC"),jpt.forEach(t),JYo=r(_$e," (Hubert model)"),_$e.forEach(t),YYo=i(Xe),SF=n(Xe,"LI",{});var b$e=s(SF);hue=n(b$e,"STRONG",{});var Dpt=s(hue);KYo=r(Dpt,"sew"),Dpt.forEach(t),ZYo=r(b$e," \u2014 "),LX=n(b$e,"A",{href:!0});var Gpt=s(LX);eKo=r(Gpt,"SEWForCTC"),Gpt.forEach(t),oKo=r(b$e," (SEW model)"),b$e.forEach(t),rKo=i(Xe),RF=n(Xe,"LI",{});var v$e=s(RF);pue=n(v$e,"STRONG",{});var Opt=s(pue);tKo=r(Opt,"sew-d"),Opt.forEach(t),aKo=r(v$e," \u2014 "),xX=n(v$e,"A",{href:!0});var Vpt=s(xX);nKo=r(Vpt,"SEWDForCTC"),Vpt.forEach(t),sKo=r(v$e," (SEW-D model)"),v$e.forEach(t),lKo=i(Xe),PF=n(Xe,"LI",{});var F$e=s(PF);uue=n(F$e,"STRONG",{});var Xpt=s(uue);iKo=r(Xpt,"unispeech"),Xpt.forEach(t),dKo=r(F$e," \u2014 "),$X=n(F$e,"A",{href:!0});var zpt=s($X);cKo=r(zpt,"UniSpeechForCTC"),zpt.forEach(t),fKo=r(F$e," (UniSpeech model)"),F$e.forEach(t),mKo=i(Xe),BF=n(Xe,"LI",{});var T$e=s(BF);_ue=n(T$e,"STRONG",{});var Wpt=s(_ue);gKo=r(Wpt,"unispeech-sat"),Wpt.forEach(t),hKo=r(T$e," \u2014 "),kX=n(T$e,"A",{href:!0});var Qpt=s(kX);pKo=r(Qpt,"UniSpeechSatForCTC"),Qpt.forEach(t),uKo=r(T$e," (UniSpeechSat model)"),T$e.forEach(t),_Ko=i(Xe),IF=n(Xe,"LI",{});var M$e=s(IF);bue=n(M$e,"STRONG",{});var Hpt=s(bue);bKo=r(Hpt,"wav2vec2"),Hpt.forEach(t),vKo=r(M$e," \u2014 "),SX=n(M$e,"A",{href:!0});var Upt=s(SX);FKo=r(Upt,"Wav2Vec2ForCTC"),Upt.forEach(t),TKo=r(M$e," (Wav2Vec2 model)"),M$e.forEach(t),MKo=i(Xe),qF=n(Xe,"LI",{});var E$e=s(qF);vue=n(E$e,"STRONG",{});var Jpt=s(vue);EKo=r(Jpt,"wav2vec2-conformer"),Jpt.forEach(t),CKo=r(E$e," \u2014 "),RX=n(E$e,"A",{href:!0});var Ypt=s(RX);wKo=r(Ypt,"Wav2Vec2ConformerForCTC"),Ypt.forEach(t),AKo=r(E$e," (Wav2Vec2-Conformer model)"),E$e.forEach(t),yKo=i(Xe),NF=n(Xe,"LI",{});var C$e=s(NF);Fue=n(C$e,"STRONG",{});var Kpt=s(Fue);LKo=r(Kpt,"wavlm"),Kpt.forEach(t),xKo=r(C$e," \u2014 "),PX=n(C$e,"A",{href:!0});var Zpt=s(PX);$Ko=r(Zpt,"WavLMForCTC"),Zpt.forEach(t),kKo=r(C$e," (WavLM model)"),C$e.forEach(t),Xe.forEach(t),SKo=i(ua),jF=n(ua,"P",{});var w$e=s(jF);RKo=r(w$e,"The model is set in evaluation mode by default using "),Tue=n(w$e,"CODE",{});var eut=s(Tue);PKo=r(eut,"model.eval()"),eut.forEach(t),BKo=r(w$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mue=n(w$e,"CODE",{});var out=s(Mue);IKo=r(out,"model.train()"),out.forEach(t),w$e.forEach(t),qKo=i(ua),T(DF.$$.fragment,ua),ua.forEach(t),tl.forEach(t),Lqe=i(f),bd=n(f,"H2",{class:!0});var Sje=s(bd);GF=n(Sje,"A",{id:!0,class:!0,href:!0});var rut=s(GF);Eue=n(rut,"SPAN",{});var tut=s(Eue);T(iL.$$.fragment,tut),tut.forEach(t),rut.forEach(t),NKo=i(Sje),Cue=n(Sje,"SPAN",{});var aut=s(Cue);jKo=r(aut,"AutoModelForSpeechSeq2Seq"),aut.forEach(t),Sje.forEach(t),xqe=i(f),Xo=n(f,"DIV",{class:!0});var al=s(Xo);T(dL.$$.fragment,al),DKo=i(al),vd=n(al,"P",{});var fZ=s(vd);GKo=r(fZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),BX=n(fZ,"A",{href:!0});var nut=s(BX);OKo=r(nut,"from_pretrained()"),nut.forEach(t),VKo=r(fZ," class method or the "),IX=n(fZ,"A",{href:!0});var sut=s(IX);XKo=r(sut,"from_config()"),sut.forEach(t),zKo=r(fZ,` class
method.`),fZ.forEach(t),WKo=i(al),cL=n(al,"P",{});var Rje=s(cL);QKo=r(Rje,"This class cannot be instantiated directly using "),wue=n(Rje,"CODE",{});var lut=s(wue);HKo=r(lut,"__init__()"),lut.forEach(t),UKo=r(Rje," (throws an error)."),Rje.forEach(t),JKo=i(al),Ft=n(al,"DIV",{class:!0});var WA=s(Ft);T(fL.$$.fragment,WA),YKo=i(WA),Aue=n(WA,"P",{});var iut=s(Aue);KKo=r(iut,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),iut.forEach(t),ZKo=i(WA),Fd=n(WA,"P",{});var mZ=s(Fd);eZo=r(mZ,`Note:
Loading a model from its configuration file does `),yue=n(mZ,"STRONG",{});var dut=s(yue);oZo=r(dut,"not"),dut.forEach(t),rZo=r(mZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),qX=n(mZ,"A",{href:!0});var cut=s(qX);tZo=r(cut,"from_pretrained()"),cut.forEach(t),aZo=r(mZ," to load the model weights."),mZ.forEach(t),nZo=i(WA),T(OF.$$.fragment,WA),WA.forEach(t),sZo=i(al),go=n(al,"DIV",{class:!0});var _a=s(go);T(mL.$$.fragment,_a),lZo=i(_a),Lue=n(_a,"P",{});var fut=s(Lue);iZo=r(fut,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fut.forEach(t),dZo=i(_a),Xa=n(_a,"P",{});var QA=s(Xa);cZo=r(QA,"The model class to instantiate is selected based on the "),xue=n(QA,"CODE",{});var mut=s(xue);fZo=r(mut,"model_type"),mut.forEach(t),mZo=r(QA,` property of the config object (either
passed as an argument or loaded from `),$ue=n(QA,"CODE",{});var gut=s($ue);gZo=r(gut,"pretrained_model_name_or_path"),gut.forEach(t),hZo=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kue=n(QA,"CODE",{});var hut=s(kue);pZo=r(hut,"pretrained_model_name_or_path"),hut.forEach(t),uZo=r(QA,":"),QA.forEach(t),_Zo=i(_a),gL=n(_a,"UL",{});var Pje=s(gL);VF=n(Pje,"LI",{});var A$e=s(VF);Sue=n(A$e,"STRONG",{});var put=s(Sue);bZo=r(put,"speech-encoder-decoder"),put.forEach(t),vZo=r(A$e," \u2014 "),NX=n(A$e,"A",{href:!0});var uut=s(NX);FZo=r(uut,"SpeechEncoderDecoderModel"),uut.forEach(t),TZo=r(A$e," (Speech Encoder decoder model)"),A$e.forEach(t),MZo=i(Pje),XF=n(Pje,"LI",{});var y$e=s(XF);Rue=n(y$e,"STRONG",{});var _ut=s(Rue);EZo=r(_ut,"speech_to_text"),_ut.forEach(t),CZo=r(y$e," \u2014 "),jX=n(y$e,"A",{href:!0});var but=s(jX);wZo=r(but,"Speech2TextForConditionalGeneration"),but.forEach(t),AZo=r(y$e," (Speech2Text model)"),y$e.forEach(t),Pje.forEach(t),yZo=i(_a),zF=n(_a,"P",{});var L$e=s(zF);LZo=r(L$e,"The model is set in evaluation mode by default using "),Pue=n(L$e,"CODE",{});var vut=s(Pue);xZo=r(vut,"model.eval()"),vut.forEach(t),$Zo=r(L$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bue=n(L$e,"CODE",{});var Fut=s(Bue);kZo=r(Fut,"model.train()"),Fut.forEach(t),L$e.forEach(t),SZo=i(_a),T(WF.$$.fragment,_a),_a.forEach(t),al.forEach(t),$qe=i(f),Td=n(f,"H2",{class:!0});var Bje=s(Td);QF=n(Bje,"A",{id:!0,class:!0,href:!0});var Tut=s(QF);Iue=n(Tut,"SPAN",{});var Mut=s(Iue);T(hL.$$.fragment,Mut),Mut.forEach(t),Tut.forEach(t),RZo=i(Bje),que=n(Bje,"SPAN",{});var Eut=s(que);PZo=r(Eut,"AutoModelForAudioXVector"),Eut.forEach(t),Bje.forEach(t),kqe=i(f),zo=n(f,"DIV",{class:!0});var nl=s(zo);T(pL.$$.fragment,nl),BZo=i(nl),Md=n(nl,"P",{});var gZ=s(Md);IZo=r(gZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),DX=n(gZ,"A",{href:!0});var Cut=s(DX);qZo=r(Cut,"from_pretrained()"),Cut.forEach(t),NZo=r(gZ," class method or the "),GX=n(gZ,"A",{href:!0});var wut=s(GX);jZo=r(wut,"from_config()"),wut.forEach(t),DZo=r(gZ,` class
method.`),gZ.forEach(t),GZo=i(nl),uL=n(nl,"P",{});var Ije=s(uL);OZo=r(Ije,"This class cannot be instantiated directly using "),Nue=n(Ije,"CODE",{});var Aut=s(Nue);VZo=r(Aut,"__init__()"),Aut.forEach(t),XZo=r(Ije," (throws an error)."),Ije.forEach(t),zZo=i(nl),Tt=n(nl,"DIV",{class:!0});var HA=s(Tt);T(_L.$$.fragment,HA),WZo=i(HA),jue=n(HA,"P",{});var yut=s(jue);QZo=r(yut,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),yut.forEach(t),HZo=i(HA),Ed=n(HA,"P",{});var hZ=s(Ed);UZo=r(hZ,`Note:
Loading a model from its configuration file does `),Due=n(hZ,"STRONG",{});var Lut=s(Due);JZo=r(Lut,"not"),Lut.forEach(t),YZo=r(hZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),OX=n(hZ,"A",{href:!0});var xut=s(OX);KZo=r(xut,"from_pretrained()"),xut.forEach(t),ZZo=r(hZ," to load the model weights."),hZ.forEach(t),eer=i(HA),T(HF.$$.fragment,HA),HA.forEach(t),oer=i(nl),ho=n(nl,"DIV",{class:!0});var ba=s(ho);T(bL.$$.fragment,ba),rer=i(ba),Gue=n(ba,"P",{});var $ut=s(Gue);ter=r($ut,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),$ut.forEach(t),aer=i(ba),za=n(ba,"P",{});var UA=s(za);ner=r(UA,"The model class to instantiate is selected based on the "),Oue=n(UA,"CODE",{});var kut=s(Oue);ser=r(kut,"model_type"),kut.forEach(t),ler=r(UA,` property of the config object (either
passed as an argument or loaded from `),Vue=n(UA,"CODE",{});var Sut=s(Vue);ier=r(Sut,"pretrained_model_name_or_path"),Sut.forEach(t),der=r(UA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xue=n(UA,"CODE",{});var Rut=s(Xue);cer=r(Rut,"pretrained_model_name_or_path"),Rut.forEach(t),fer=r(UA,":"),UA.forEach(t),mer=i(ba),Zr=n(ba,"UL",{});var sl=s(Zr);UF=n(sl,"LI",{});var x$e=s(UF);zue=n(x$e,"STRONG",{});var Put=s(zue);ger=r(Put,"data2vec-audio"),Put.forEach(t),her=r(x$e," \u2014 "),VX=n(x$e,"A",{href:!0});var But=s(VX);per=r(But,"Data2VecAudioForXVector"),But.forEach(t),uer=r(x$e," (Data2VecAudio model)"),x$e.forEach(t),_er=i(sl),JF=n(sl,"LI",{});var $$e=s(JF);Wue=n($$e,"STRONG",{});var Iut=s(Wue);ber=r(Iut,"unispeech-sat"),Iut.forEach(t),ver=r($$e," \u2014 "),XX=n($$e,"A",{href:!0});var qut=s(XX);Fer=r(qut,"UniSpeechSatForXVector"),qut.forEach(t),Ter=r($$e," (UniSpeechSat model)"),$$e.forEach(t),Mer=i(sl),YF=n(sl,"LI",{});var k$e=s(YF);Que=n(k$e,"STRONG",{});var Nut=s(Que);Eer=r(Nut,"wav2vec2"),Nut.forEach(t),Cer=r(k$e," \u2014 "),zX=n(k$e,"A",{href:!0});var jut=s(zX);wer=r(jut,"Wav2Vec2ForXVector"),jut.forEach(t),Aer=r(k$e," (Wav2Vec2 model)"),k$e.forEach(t),yer=i(sl),KF=n(sl,"LI",{});var S$e=s(KF);Hue=n(S$e,"STRONG",{});var Dut=s(Hue);Ler=r(Dut,"wav2vec2-conformer"),Dut.forEach(t),xer=r(S$e," \u2014 "),WX=n(S$e,"A",{href:!0});var Gut=s(WX);$er=r(Gut,"Wav2Vec2ConformerForXVector"),Gut.forEach(t),ker=r(S$e," (Wav2Vec2-Conformer model)"),S$e.forEach(t),Ser=i(sl),ZF=n(sl,"LI",{});var R$e=s(ZF);Uue=n(R$e,"STRONG",{});var Out=s(Uue);Rer=r(Out,"wavlm"),Out.forEach(t),Per=r(R$e," \u2014 "),QX=n(R$e,"A",{href:!0});var Vut=s(QX);Ber=r(Vut,"WavLMForXVector"),Vut.forEach(t),Ier=r(R$e," (WavLM model)"),R$e.forEach(t),sl.forEach(t),qer=i(ba),eT=n(ba,"P",{});var P$e=s(eT);Ner=r(P$e,"The model is set in evaluation mode by default using "),Jue=n(P$e,"CODE",{});var Xut=s(Jue);jer=r(Xut,"model.eval()"),Xut.forEach(t),Der=r(P$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=n(P$e,"CODE",{});var zut=s(Yue);Ger=r(zut,"model.train()"),zut.forEach(t),P$e.forEach(t),Oer=i(ba),T(oT.$$.fragment,ba),ba.forEach(t),nl.forEach(t),Sqe=i(f),Cd=n(f,"H2",{class:!0});var qje=s(Cd);rT=n(qje,"A",{id:!0,class:!0,href:!0});var Wut=s(rT);Kue=n(Wut,"SPAN",{});var Qut=s(Kue);T(vL.$$.fragment,Qut),Qut.forEach(t),Wut.forEach(t),Ver=i(qje),Zue=n(qje,"SPAN",{});var Hut=s(Zue);Xer=r(Hut,"AutoModelForMaskedImageModeling"),Hut.forEach(t),qje.forEach(t),Rqe=i(f),Wo=n(f,"DIV",{class:!0});var ll=s(Wo);T(FL.$$.fragment,ll),zer=i(ll),wd=n(ll,"P",{});var pZ=s(wd);Wer=r(pZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),HX=n(pZ,"A",{href:!0});var Uut=s(HX);Qer=r(Uut,"from_pretrained()"),Uut.forEach(t),Her=r(pZ," class method or the "),UX=n(pZ,"A",{href:!0});var Jut=s(UX);Uer=r(Jut,"from_config()"),Jut.forEach(t),Jer=r(pZ,` class
method.`),pZ.forEach(t),Yer=i(ll),TL=n(ll,"P",{});var Nje=s(TL);Ker=r(Nje,"This class cannot be instantiated directly using "),e_e=n(Nje,"CODE",{});var Yut=s(e_e);Zer=r(Yut,"__init__()"),Yut.forEach(t),eor=r(Nje," (throws an error)."),Nje.forEach(t),oor=i(ll),Mt=n(ll,"DIV",{class:!0});var JA=s(Mt);T(ML.$$.fragment,JA),ror=i(JA),o_e=n(JA,"P",{});var Kut=s(o_e);tor=r(Kut,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Kut.forEach(t),aor=i(JA),Ad=n(JA,"P",{});var uZ=s(Ad);nor=r(uZ,`Note:
Loading a model from its configuration file does `),r_e=n(uZ,"STRONG",{});var Zut=s(r_e);sor=r(Zut,"not"),Zut.forEach(t),lor=r(uZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=n(uZ,"A",{href:!0});var e_t=s(JX);ior=r(e_t,"from_pretrained()"),e_t.forEach(t),dor=r(uZ," to load the model weights."),uZ.forEach(t),cor=i(JA),T(tT.$$.fragment,JA),JA.forEach(t),mor=i(ll),po=n(ll,"DIV",{class:!0});var va=s(po);T(EL.$$.fragment,va),gor=i(va),t_e=n(va,"P",{});var o_t=s(t_e);hor=r(o_t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),o_t.forEach(t),por=i(va),Wa=n(va,"P",{});var YA=s(Wa);uor=r(YA,"The model class to instantiate is selected based on the "),a_e=n(YA,"CODE",{});var r_t=s(a_e);_or=r(r_t,"model_type"),r_t.forEach(t),bor=r(YA,` property of the config object (either
passed as an argument or loaded from `),n_e=n(YA,"CODE",{});var t_t=s(n_e);vor=r(t_t,"pretrained_model_name_or_path"),t_t.forEach(t),For=r(YA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=n(YA,"CODE",{});var a_t=s(s_e);Tor=r(a_t,"pretrained_model_name_or_path"),a_t.forEach(t),Mor=r(YA,":"),YA.forEach(t),Eor=i(va),yd=n(va,"UL",{});var _Z=s(yd);aT=n(_Z,"LI",{});var B$e=s(aT);l_e=n(B$e,"STRONG",{});var n_t=s(l_e);Cor=r(n_t,"deit"),n_t.forEach(t),wor=r(B$e," \u2014 "),YX=n(B$e,"A",{href:!0});var s_t=s(YX);Aor=r(s_t,"DeiTForMaskedImageModeling"),s_t.forEach(t),yor=r(B$e," (DeiT model)"),B$e.forEach(t),Lor=i(_Z),nT=n(_Z,"LI",{});var I$e=s(nT);i_e=n(I$e,"STRONG",{});var l_t=s(i_e);xor=r(l_t,"swin"),l_t.forEach(t),$or=r(I$e," \u2014 "),KX=n(I$e,"A",{href:!0});var i_t=s(KX);kor=r(i_t,"SwinForMaskedImageModeling"),i_t.forEach(t),Sor=r(I$e," (Swin model)"),I$e.forEach(t),Ror=i(_Z),sT=n(_Z,"LI",{});var q$e=s(sT);d_e=n(q$e,"STRONG",{});var d_t=s(d_e);Por=r(d_t,"vit"),d_t.forEach(t),Bor=r(q$e," \u2014 "),ZX=n(q$e,"A",{href:!0});var c_t=s(ZX);Ior=r(c_t,"ViTForMaskedImageModeling"),c_t.forEach(t),qor=r(q$e," (ViT model)"),q$e.forEach(t),_Z.forEach(t),Nor=i(va),lT=n(va,"P",{});var N$e=s(lT);jor=r(N$e,"The model is set in evaluation mode by default using "),c_e=n(N$e,"CODE",{});var f_t=s(c_e);Dor=r(f_t,"model.eval()"),f_t.forEach(t),Gor=r(N$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f_e=n(N$e,"CODE",{});var m_t=s(f_e);Oor=r(m_t,"model.train()"),m_t.forEach(t),N$e.forEach(t),Vor=i(va),T(iT.$$.fragment,va),va.forEach(t),ll.forEach(t),Pqe=i(f),Ld=n(f,"H2",{class:!0});var jje=s(Ld);dT=n(jje,"A",{id:!0,class:!0,href:!0});var g_t=s(dT);m_e=n(g_t,"SPAN",{});var h_t=s(m_e);T(CL.$$.fragment,h_t),h_t.forEach(t),g_t.forEach(t),Xor=i(jje),g_e=n(jje,"SPAN",{});var p_t=s(g_e);zor=r(p_t,"AutoModelForObjectDetection"),p_t.forEach(t),jje.forEach(t),Bqe=i(f),Qo=n(f,"DIV",{class:!0});var il=s(Qo);T(wL.$$.fragment,il),Wor=i(il),xd=n(il,"P",{});var bZ=s(xd);Qor=r(bZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),ez=n(bZ,"A",{href:!0});var u_t=s(ez);Hor=r(u_t,"from_pretrained()"),u_t.forEach(t),Uor=r(bZ," class method or the "),oz=n(bZ,"A",{href:!0});var __t=s(oz);Jor=r(__t,"from_config()"),__t.forEach(t),Yor=r(bZ,` class
method.`),bZ.forEach(t),Kor=i(il),AL=n(il,"P",{});var Dje=s(AL);Zor=r(Dje,"This class cannot be instantiated directly using "),h_e=n(Dje,"CODE",{});var b_t=s(h_e);err=r(b_t,"__init__()"),b_t.forEach(t),orr=r(Dje," (throws an error)."),Dje.forEach(t),rrr=i(il),Et=n(il,"DIV",{class:!0});var KA=s(Et);T(yL.$$.fragment,KA),trr=i(KA),p_e=n(KA,"P",{});var v_t=s(p_e);arr=r(v_t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),v_t.forEach(t),nrr=i(KA),$d=n(KA,"P",{});var vZ=s($d);srr=r(vZ,`Note:
Loading a model from its configuration file does `),u_e=n(vZ,"STRONG",{});var F_t=s(u_e);lrr=r(F_t,"not"),F_t.forEach(t),irr=r(vZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),rz=n(vZ,"A",{href:!0});var T_t=s(rz);drr=r(T_t,"from_pretrained()"),T_t.forEach(t),crr=r(vZ," to load the model weights."),vZ.forEach(t),frr=i(KA),T(cT.$$.fragment,KA),KA.forEach(t),mrr=i(il),uo=n(il,"DIV",{class:!0});var Fa=s(uo);T(LL.$$.fragment,Fa),grr=i(Fa),__e=n(Fa,"P",{});var M_t=s(__e);hrr=r(M_t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),M_t.forEach(t),prr=i(Fa),Qa=n(Fa,"P",{});var ZA=s(Qa);urr=r(ZA,"The model class to instantiate is selected based on the "),b_e=n(ZA,"CODE",{});var E_t=s(b_e);_rr=r(E_t,"model_type"),E_t.forEach(t),brr=r(ZA,` property of the config object (either
passed as an argument or loaded from `),v_e=n(ZA,"CODE",{});var C_t=s(v_e);vrr=r(C_t,"pretrained_model_name_or_path"),C_t.forEach(t),Frr=r(ZA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F_e=n(ZA,"CODE",{});var w_t=s(F_e);Trr=r(w_t,"pretrained_model_name_or_path"),w_t.forEach(t),Mrr=r(ZA,":"),ZA.forEach(t),Err=i(Fa),xL=n(Fa,"UL",{});var Gje=s(xL);fT=n(Gje,"LI",{});var j$e=s(fT);T_e=n(j$e,"STRONG",{});var A_t=s(T_e);Crr=r(A_t,"detr"),A_t.forEach(t),wrr=r(j$e," \u2014 "),tz=n(j$e,"A",{href:!0});var y_t=s(tz);Arr=r(y_t,"DetrForObjectDetection"),y_t.forEach(t),yrr=r(j$e," (DETR model)"),j$e.forEach(t),Lrr=i(Gje),mT=n(Gje,"LI",{});var D$e=s(mT);M_e=n(D$e,"STRONG",{});var L_t=s(M_e);xrr=r(L_t,"yolos"),L_t.forEach(t),$rr=r(D$e," \u2014 "),az=n(D$e,"A",{href:!0});var x_t=s(az);krr=r(x_t,"YolosForObjectDetection"),x_t.forEach(t),Srr=r(D$e," (YOLOS model)"),D$e.forEach(t),Gje.forEach(t),Rrr=i(Fa),gT=n(Fa,"P",{});var G$e=s(gT);Prr=r(G$e,"The model is set in evaluation mode by default using "),E_e=n(G$e,"CODE",{});var $_t=s(E_e);Brr=r($_t,"model.eval()"),$_t.forEach(t),Irr=r(G$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C_e=n(G$e,"CODE",{});var k_t=s(C_e);qrr=r(k_t,"model.train()"),k_t.forEach(t),G$e.forEach(t),Nrr=i(Fa),T(hT.$$.fragment,Fa),Fa.forEach(t),il.forEach(t),Iqe=i(f),kd=n(f,"H2",{class:!0});var Oje=s(kd);pT=n(Oje,"A",{id:!0,class:!0,href:!0});var S_t=s(pT);w_e=n(S_t,"SPAN",{});var R_t=s(w_e);T($L.$$.fragment,R_t),R_t.forEach(t),S_t.forEach(t),jrr=i(Oje),A_e=n(Oje,"SPAN",{});var P_t=s(A_e);Drr=r(P_t,"AutoModelForImageSegmentation"),P_t.forEach(t),Oje.forEach(t),qqe=i(f),Ho=n(f,"DIV",{class:!0});var dl=s(Ho);T(kL.$$.fragment,dl),Grr=i(dl),Sd=n(dl,"P",{});var FZ=s(Sd);Orr=r(FZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),nz=n(FZ,"A",{href:!0});var B_t=s(nz);Vrr=r(B_t,"from_pretrained()"),B_t.forEach(t),Xrr=r(FZ," class method or the "),sz=n(FZ,"A",{href:!0});var I_t=s(sz);zrr=r(I_t,"from_config()"),I_t.forEach(t),Wrr=r(FZ,` class
method.`),FZ.forEach(t),Qrr=i(dl),SL=n(dl,"P",{});var Vje=s(SL);Hrr=r(Vje,"This class cannot be instantiated directly using "),y_e=n(Vje,"CODE",{});var q_t=s(y_e);Urr=r(q_t,"__init__()"),q_t.forEach(t),Jrr=r(Vje," (throws an error)."),Vje.forEach(t),Yrr=i(dl),Ct=n(dl,"DIV",{class:!0});var e0=s(Ct);T(RL.$$.fragment,e0),Krr=i(e0),L_e=n(e0,"P",{});var N_t=s(L_e);Zrr=r(N_t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),N_t.forEach(t),etr=i(e0),Rd=n(e0,"P",{});var TZ=s(Rd);otr=r(TZ,`Note:
Loading a model from its configuration file does `),x_e=n(TZ,"STRONG",{});var j_t=s(x_e);rtr=r(j_t,"not"),j_t.forEach(t),ttr=r(TZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=n(TZ,"A",{href:!0});var D_t=s(lz);atr=r(D_t,"from_pretrained()"),D_t.forEach(t),ntr=r(TZ," to load the model weights."),TZ.forEach(t),str=i(e0),T(uT.$$.fragment,e0),e0.forEach(t),ltr=i(dl),_o=n(dl,"DIV",{class:!0});var Ta=s(_o);T(PL.$$.fragment,Ta),itr=i(Ta),$_e=n(Ta,"P",{});var G_t=s($_e);dtr=r(G_t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),G_t.forEach(t),ctr=i(Ta),Ha=n(Ta,"P",{});var o0=s(Ha);ftr=r(o0,"The model class to instantiate is selected based on the "),k_e=n(o0,"CODE",{});var O_t=s(k_e);mtr=r(O_t,"model_type"),O_t.forEach(t),gtr=r(o0,` property of the config object (either
passed as an argument or loaded from `),S_e=n(o0,"CODE",{});var V_t=s(S_e);htr=r(V_t,"pretrained_model_name_or_path"),V_t.forEach(t),ptr=r(o0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R_e=n(o0,"CODE",{});var X_t=s(R_e);utr=r(X_t,"pretrained_model_name_or_path"),X_t.forEach(t),_tr=r(o0,":"),o0.forEach(t),btr=i(Ta),P_e=n(Ta,"UL",{});var z_t=s(P_e);_T=n(z_t,"LI",{});var O$e=s(_T);B_e=n(O$e,"STRONG",{});var W_t=s(B_e);vtr=r(W_t,"detr"),W_t.forEach(t),Ftr=r(O$e," \u2014 "),iz=n(O$e,"A",{href:!0});var Q_t=s(iz);Ttr=r(Q_t,"DetrForSegmentation"),Q_t.forEach(t),Mtr=r(O$e," (DETR model)"),O$e.forEach(t),z_t.forEach(t),Etr=i(Ta),bT=n(Ta,"P",{});var V$e=s(bT);Ctr=r(V$e,"The model is set in evaluation mode by default using "),I_e=n(V$e,"CODE",{});var H_t=s(I_e);wtr=r(H_t,"model.eval()"),H_t.forEach(t),Atr=r(V$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q_e=n(V$e,"CODE",{});var U_t=s(q_e);ytr=r(U_t,"model.train()"),U_t.forEach(t),V$e.forEach(t),Ltr=i(Ta),T(vT.$$.fragment,Ta),Ta.forEach(t),dl.forEach(t),Nqe=i(f),Pd=n(f,"H2",{class:!0});var Xje=s(Pd);FT=n(Xje,"A",{id:!0,class:!0,href:!0});var J_t=s(FT);N_e=n(J_t,"SPAN",{});var Y_t=s(N_e);T(BL.$$.fragment,Y_t),Y_t.forEach(t),J_t.forEach(t),xtr=i(Xje),j_e=n(Xje,"SPAN",{});var K_t=s(j_e);$tr=r(K_t,"AutoModelForSemanticSegmentation"),K_t.forEach(t),Xje.forEach(t),jqe=i(f),Uo=n(f,"DIV",{class:!0});var cl=s(Uo);T(IL.$$.fragment,cl),ktr=i(cl),Bd=n(cl,"P",{});var MZ=s(Bd);Str=r(MZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),dz=n(MZ,"A",{href:!0});var Z_t=s(dz);Rtr=r(Z_t,"from_pretrained()"),Z_t.forEach(t),Ptr=r(MZ," class method or the "),cz=n(MZ,"A",{href:!0});var e2t=s(cz);Btr=r(e2t,"from_config()"),e2t.forEach(t),Itr=r(MZ,` class
method.`),MZ.forEach(t),qtr=i(cl),qL=n(cl,"P",{});var zje=s(qL);Ntr=r(zje,"This class cannot be instantiated directly using "),D_e=n(zje,"CODE",{});var o2t=s(D_e);jtr=r(o2t,"__init__()"),o2t.forEach(t),Dtr=r(zje," (throws an error)."),zje.forEach(t),Gtr=i(cl),wt=n(cl,"DIV",{class:!0});var r0=s(wt);T(NL.$$.fragment,r0),Otr=i(r0),G_e=n(r0,"P",{});var r2t=s(G_e);Vtr=r(r2t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),r2t.forEach(t),Xtr=i(r0),Id=n(r0,"P",{});var EZ=s(Id);ztr=r(EZ,`Note:
Loading a model from its configuration file does `),O_e=n(EZ,"STRONG",{});var t2t=s(O_e);Wtr=r(t2t,"not"),t2t.forEach(t),Qtr=r(EZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),fz=n(EZ,"A",{href:!0});var a2t=s(fz);Htr=r(a2t,"from_pretrained()"),a2t.forEach(t),Utr=r(EZ," to load the model weights."),EZ.forEach(t),Jtr=i(r0),T(TT.$$.fragment,r0),r0.forEach(t),Ytr=i(cl),bo=n(cl,"DIV",{class:!0});var Ma=s(bo);T(jL.$$.fragment,Ma),Ktr=i(Ma),V_e=n(Ma,"P",{});var n2t=s(V_e);Ztr=r(n2t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),n2t.forEach(t),ear=i(Ma),Ua=n(Ma,"P",{});var t0=s(Ua);oar=r(t0,"The model class to instantiate is selected based on the "),X_e=n(t0,"CODE",{});var s2t=s(X_e);rar=r(s2t,"model_type"),s2t.forEach(t),tar=r(t0,` property of the config object (either
passed as an argument or loaded from `),z_e=n(t0,"CODE",{});var l2t=s(z_e);aar=r(l2t,"pretrained_model_name_or_path"),l2t.forEach(t),nar=r(t0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W_e=n(t0,"CODE",{});var i2t=s(W_e);sar=r(i2t,"pretrained_model_name_or_path"),i2t.forEach(t),lar=r(t0,":"),t0.forEach(t),iar=i(Ma),Ja=n(Ma,"UL",{});var a0=s(Ja);MT=n(a0,"LI",{});var X$e=s(MT);Q_e=n(X$e,"STRONG",{});var d2t=s(Q_e);dar=r(d2t,"beit"),d2t.forEach(t),car=r(X$e," \u2014 "),mz=n(X$e,"A",{href:!0});var c2t=s(mz);far=r(c2t,"BeitForSemanticSegmentation"),c2t.forEach(t),mar=r(X$e," (BEiT model)"),X$e.forEach(t),gar=i(a0),ET=n(a0,"LI",{});var z$e=s(ET);H_e=n(z$e,"STRONG",{});var f2t=s(H_e);har=r(f2t,"data2vec-vision"),f2t.forEach(t),par=r(z$e," \u2014 "),gz=n(z$e,"A",{href:!0});var m2t=s(gz);uar=r(m2t,"Data2VecVisionForSemanticSegmentation"),m2t.forEach(t),_ar=r(z$e," (Data2VecVision model)"),z$e.forEach(t),bar=i(a0),CT=n(a0,"LI",{});var W$e=s(CT);U_e=n(W$e,"STRONG",{});var g2t=s(U_e);Far=r(g2t,"dpt"),g2t.forEach(t),Tar=r(W$e," \u2014 "),hz=n(W$e,"A",{href:!0});var h2t=s(hz);Mar=r(h2t,"DPTForSemanticSegmentation"),h2t.forEach(t),Ear=r(W$e," (DPT model)"),W$e.forEach(t),Car=i(a0),wT=n(a0,"LI",{});var Q$e=s(wT);J_e=n(Q$e,"STRONG",{});var p2t=s(J_e);war=r(p2t,"segformer"),p2t.forEach(t),Aar=r(Q$e," \u2014 "),pz=n(Q$e,"A",{href:!0});var u2t=s(pz);yar=r(u2t,"SegformerForSemanticSegmentation"),u2t.forEach(t),Lar=r(Q$e," (SegFormer model)"),Q$e.forEach(t),a0.forEach(t),xar=i(Ma),AT=n(Ma,"P",{});var H$e=s(AT);$ar=r(H$e,"The model is set in evaluation mode by default using "),Y_e=n(H$e,"CODE",{});var _2t=s(Y_e);kar=r(_2t,"model.eval()"),_2t.forEach(t),Sar=r(H$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K_e=n(H$e,"CODE",{});var b2t=s(K_e);Rar=r(b2t,"model.train()"),b2t.forEach(t),H$e.forEach(t),Par=i(Ma),T(yT.$$.fragment,Ma),Ma.forEach(t),cl.forEach(t),Dqe=i(f),qd=n(f,"H2",{class:!0});var Wje=s(qd);LT=n(Wje,"A",{id:!0,class:!0,href:!0});var v2t=s(LT);Z_e=n(v2t,"SPAN",{});var F2t=s(Z_e);T(DL.$$.fragment,F2t),F2t.forEach(t),v2t.forEach(t),Bar=i(Wje),e2e=n(Wje,"SPAN",{});var T2t=s(e2e);Iar=r(T2t,"AutoModelForInstanceSegmentation"),T2t.forEach(t),Wje.forEach(t),Gqe=i(f),Jo=n(f,"DIV",{class:!0});var fl=s(Jo);T(GL.$$.fragment,fl),qar=i(fl),Nd=n(fl,"P",{});var CZ=s(Nd);Nar=r(CZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),uz=n(CZ,"A",{href:!0});var M2t=s(uz);jar=r(M2t,"from_pretrained()"),M2t.forEach(t),Dar=r(CZ," class method or the "),_z=n(CZ,"A",{href:!0});var E2t=s(_z);Gar=r(E2t,"from_config()"),E2t.forEach(t),Oar=r(CZ,` class
method.`),CZ.forEach(t),Var=i(fl),OL=n(fl,"P",{});var Qje=s(OL);Xar=r(Qje,"This class cannot be instantiated directly using "),o2e=n(Qje,"CODE",{});var C2t=s(o2e);zar=r(C2t,"__init__()"),C2t.forEach(t),War=r(Qje," (throws an error)."),Qje.forEach(t),Qar=i(fl),At=n(fl,"DIV",{class:!0});var n0=s(At);T(VL.$$.fragment,n0),Har=i(n0),r2e=n(n0,"P",{});var w2t=s(r2e);Uar=r(w2t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),w2t.forEach(t),Jar=i(n0),jd=n(n0,"P",{});var wZ=s(jd);Yar=r(wZ,`Note:
Loading a model from its configuration file does `),t2e=n(wZ,"STRONG",{});var A2t=s(t2e);Kar=r(A2t,"not"),A2t.forEach(t),Zar=r(wZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),bz=n(wZ,"A",{href:!0});var y2t=s(bz);enr=r(y2t,"from_pretrained()"),y2t.forEach(t),onr=r(wZ," to load the model weights."),wZ.forEach(t),rnr=i(n0),T(xT.$$.fragment,n0),n0.forEach(t),tnr=i(fl),vo=n(fl,"DIV",{class:!0});var Ea=s(vo);T(XL.$$.fragment,Ea),anr=i(Ea),a2e=n(Ea,"P",{});var L2t=s(a2e);nnr=r(L2t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),L2t.forEach(t),snr=i(Ea),Ya=n(Ea,"P",{});var s0=s(Ya);lnr=r(s0,"The model class to instantiate is selected based on the "),n2e=n(s0,"CODE",{});var x2t=s(n2e);inr=r(x2t,"model_type"),x2t.forEach(t),dnr=r(s0,` property of the config object (either
passed as an argument or loaded from `),s2e=n(s0,"CODE",{});var $2t=s(s2e);cnr=r($2t,"pretrained_model_name_or_path"),$2t.forEach(t),fnr=r(s0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l2e=n(s0,"CODE",{});var k2t=s(l2e);mnr=r(k2t,"pretrained_model_name_or_path"),k2t.forEach(t),gnr=r(s0,":"),s0.forEach(t),hnr=i(Ea),i2e=n(Ea,"UL",{});var S2t=s(i2e);$T=n(S2t,"LI",{});var U$e=s($T);d2e=n(U$e,"STRONG",{});var R2t=s(d2e);pnr=r(R2t,"maskformer"),R2t.forEach(t),unr=r(U$e," \u2014 "),vz=n(U$e,"A",{href:!0});var P2t=s(vz);_nr=r(P2t,"MaskFormerForInstanceSegmentation"),P2t.forEach(t),bnr=r(U$e," (MaskFormer model)"),U$e.forEach(t),S2t.forEach(t),vnr=i(Ea),kT=n(Ea,"P",{});var J$e=s(kT);Fnr=r(J$e,"The model is set in evaluation mode by default using "),c2e=n(J$e,"CODE",{});var B2t=s(c2e);Tnr=r(B2t,"model.eval()"),B2t.forEach(t),Mnr=r(J$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f2e=n(J$e,"CODE",{});var I2t=s(f2e);Enr=r(I2t,"model.train()"),I2t.forEach(t),J$e.forEach(t),Cnr=i(Ea),T(ST.$$.fragment,Ea),Ea.forEach(t),fl.forEach(t),Oqe=i(f),Dd=n(f,"H2",{class:!0});var Hje=s(Dd);RT=n(Hje,"A",{id:!0,class:!0,href:!0});var q2t=s(RT);m2e=n(q2t,"SPAN",{});var N2t=s(m2e);T(zL.$$.fragment,N2t),N2t.forEach(t),q2t.forEach(t),wnr=i(Hje),g2e=n(Hje,"SPAN",{});var j2t=s(g2e);Anr=r(j2t,"TFAutoModel"),j2t.forEach(t),Hje.forEach(t),Vqe=i(f),Yo=n(f,"DIV",{class:!0});var ml=s(Yo);T(WL.$$.fragment,ml),ynr=i(ml),Gd=n(ml,"P",{});var AZ=s(Gd);Lnr=r(AZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Fz=n(AZ,"A",{href:!0});var D2t=s(Fz);xnr=r(D2t,"from_pretrained()"),D2t.forEach(t),$nr=r(AZ," class method or the "),Tz=n(AZ,"A",{href:!0});var G2t=s(Tz);knr=r(G2t,"from_config()"),G2t.forEach(t),Snr=r(AZ,` class
method.`),AZ.forEach(t),Rnr=i(ml),QL=n(ml,"P",{});var Uje=s(QL);Pnr=r(Uje,"This class cannot be instantiated directly using "),h2e=n(Uje,"CODE",{});var O2t=s(h2e);Bnr=r(O2t,"__init__()"),O2t.forEach(t),Inr=r(Uje," (throws an error)."),Uje.forEach(t),qnr=i(ml),yt=n(ml,"DIV",{class:!0});var l0=s(yt);T(HL.$$.fragment,l0),Nnr=i(l0),p2e=n(l0,"P",{});var V2t=s(p2e);jnr=r(V2t,"Instantiates one of the base model classes of the library from a configuration."),V2t.forEach(t),Dnr=i(l0),Od=n(l0,"P",{});var yZ=s(Od);Gnr=r(yZ,`Note:
Loading a model from its configuration file does `),u2e=n(yZ,"STRONG",{});var X2t=s(u2e);Onr=r(X2t,"not"),X2t.forEach(t),Vnr=r(yZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mz=n(yZ,"A",{href:!0});var z2t=s(Mz);Xnr=r(z2t,"from_pretrained()"),z2t.forEach(t),znr=r(yZ," to load the model weights."),yZ.forEach(t),Wnr=i(l0),T(PT.$$.fragment,l0),l0.forEach(t),Qnr=i(ml),wr=n(ml,"DIV",{class:!0});var gl=s(wr);T(UL.$$.fragment,gl),Hnr=i(gl),_2e=n(gl,"P",{});var W2t=s(_2e);Unr=r(W2t,"Instantiate one of the base model classes of the library from a pretrained model."),W2t.forEach(t),Jnr=i(gl),Ka=n(gl,"P",{});var i0=s(Ka);Ynr=r(i0,"The model class to instantiate is selected based on the "),b2e=n(i0,"CODE",{});var Q2t=s(b2e);Knr=r(Q2t,"model_type"),Q2t.forEach(t),Znr=r(i0,` property of the config object (either
passed as an argument or loaded from `),v2e=n(i0,"CODE",{});var H2t=s(v2e);esr=r(H2t,"pretrained_model_name_or_path"),H2t.forEach(t),osr=r(i0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F2e=n(i0,"CODE",{});var U2t=s(F2e);rsr=r(U2t,"pretrained_model_name_or_path"),U2t.forEach(t),tsr=r(i0,":"),i0.forEach(t),asr=i(gl),q=n(gl,"UL",{});var j=s(q);BT=n(j,"LI",{});var Y$e=s(BT);T2e=n(Y$e,"STRONG",{});var J2t=s(T2e);nsr=r(J2t,"albert"),J2t.forEach(t),ssr=r(Y$e," \u2014 "),Ez=n(Y$e,"A",{href:!0});var Y2t=s(Ez);lsr=r(Y2t,"TFAlbertModel"),Y2t.forEach(t),isr=r(Y$e," (ALBERT model)"),Y$e.forEach(t),dsr=i(j),IT=n(j,"LI",{});var K$e=s(IT);M2e=n(K$e,"STRONG",{});var K2t=s(M2e);csr=r(K2t,"bart"),K2t.forEach(t),fsr=r(K$e," \u2014 "),Cz=n(K$e,"A",{href:!0});var Z2t=s(Cz);msr=r(Z2t,"TFBartModel"),Z2t.forEach(t),gsr=r(K$e," (BART model)"),K$e.forEach(t),hsr=i(j),qT=n(j,"LI",{});var Z$e=s(qT);E2e=n(Z$e,"STRONG",{});var e1t=s(E2e);psr=r(e1t,"bert"),e1t.forEach(t),usr=r(Z$e," \u2014 "),wz=n(Z$e,"A",{href:!0});var o1t=s(wz);_sr=r(o1t,"TFBertModel"),o1t.forEach(t),bsr=r(Z$e," (BERT model)"),Z$e.forEach(t),vsr=i(j),NT=n(j,"LI",{});var eke=s(NT);C2e=n(eke,"STRONG",{});var r1t=s(C2e);Fsr=r(r1t,"blenderbot"),r1t.forEach(t),Tsr=r(eke," \u2014 "),Az=n(eke,"A",{href:!0});var t1t=s(Az);Msr=r(t1t,"TFBlenderbotModel"),t1t.forEach(t),Esr=r(eke," (Blenderbot model)"),eke.forEach(t),Csr=i(j),jT=n(j,"LI",{});var oke=s(jT);w2e=n(oke,"STRONG",{});var a1t=s(w2e);wsr=r(a1t,"blenderbot-small"),a1t.forEach(t),Asr=r(oke," \u2014 "),yz=n(oke,"A",{href:!0});var n1t=s(yz);ysr=r(n1t,"TFBlenderbotSmallModel"),n1t.forEach(t),Lsr=r(oke," (BlenderbotSmall model)"),oke.forEach(t),xsr=i(j),DT=n(j,"LI",{});var rke=s(DT);A2e=n(rke,"STRONG",{});var s1t=s(A2e);$sr=r(s1t,"camembert"),s1t.forEach(t),ksr=r(rke," \u2014 "),Lz=n(rke,"A",{href:!0});var l1t=s(Lz);Ssr=r(l1t,"TFCamembertModel"),l1t.forEach(t),Rsr=r(rke," (CamemBERT model)"),rke.forEach(t),Psr=i(j),GT=n(j,"LI",{});var tke=s(GT);y2e=n(tke,"STRONG",{});var i1t=s(y2e);Bsr=r(i1t,"clip"),i1t.forEach(t),Isr=r(tke," \u2014 "),xz=n(tke,"A",{href:!0});var d1t=s(xz);qsr=r(d1t,"TFCLIPModel"),d1t.forEach(t),Nsr=r(tke," (CLIP model)"),tke.forEach(t),jsr=i(j),OT=n(j,"LI",{});var ake=s(OT);L2e=n(ake,"STRONG",{});var c1t=s(L2e);Dsr=r(c1t,"convbert"),c1t.forEach(t),Gsr=r(ake," \u2014 "),$z=n(ake,"A",{href:!0});var f1t=s($z);Osr=r(f1t,"TFConvBertModel"),f1t.forEach(t),Vsr=r(ake," (ConvBERT model)"),ake.forEach(t),Xsr=i(j),VT=n(j,"LI",{});var nke=s(VT);x2e=n(nke,"STRONG",{});var m1t=s(x2e);zsr=r(m1t,"convnext"),m1t.forEach(t),Wsr=r(nke," \u2014 "),kz=n(nke,"A",{href:!0});var g1t=s(kz);Qsr=r(g1t,"TFConvNextModel"),g1t.forEach(t),Hsr=r(nke," (ConvNext model)"),nke.forEach(t),Usr=i(j),XT=n(j,"LI",{});var ske=s(XT);$2e=n(ske,"STRONG",{});var h1t=s($2e);Jsr=r(h1t,"ctrl"),h1t.forEach(t),Ysr=r(ske," \u2014 "),Sz=n(ske,"A",{href:!0});var p1t=s(Sz);Ksr=r(p1t,"TFCTRLModel"),p1t.forEach(t),Zsr=r(ske," (CTRL model)"),ske.forEach(t),elr=i(j),zT=n(j,"LI",{});var lke=s(zT);k2e=n(lke,"STRONG",{});var u1t=s(k2e);olr=r(u1t,"data2vec-vision"),u1t.forEach(t),rlr=r(lke," \u2014 "),Rz=n(lke,"A",{href:!0});var _1t=s(Rz);tlr=r(_1t,"TFData2VecVisionModel"),_1t.forEach(t),alr=r(lke," (Data2VecVision model)"),lke.forEach(t),nlr=i(j),WT=n(j,"LI",{});var ike=s(WT);S2e=n(ike,"STRONG",{});var b1t=s(S2e);slr=r(b1t,"deberta"),b1t.forEach(t),llr=r(ike," \u2014 "),Pz=n(ike,"A",{href:!0});var v1t=s(Pz);ilr=r(v1t,"TFDebertaModel"),v1t.forEach(t),dlr=r(ike," (DeBERTa model)"),ike.forEach(t),clr=i(j),QT=n(j,"LI",{});var dke=s(QT);R2e=n(dke,"STRONG",{});var F1t=s(R2e);flr=r(F1t,"deberta-v2"),F1t.forEach(t),mlr=r(dke," \u2014 "),Bz=n(dke,"A",{href:!0});var T1t=s(Bz);glr=r(T1t,"TFDebertaV2Model"),T1t.forEach(t),hlr=r(dke," (DeBERTa-v2 model)"),dke.forEach(t),plr=i(j),HT=n(j,"LI",{});var cke=s(HT);P2e=n(cke,"STRONG",{});var M1t=s(P2e);ulr=r(M1t,"distilbert"),M1t.forEach(t),_lr=r(cke," \u2014 "),Iz=n(cke,"A",{href:!0});var E1t=s(Iz);blr=r(E1t,"TFDistilBertModel"),E1t.forEach(t),vlr=r(cke," (DistilBERT model)"),cke.forEach(t),Flr=i(j),UT=n(j,"LI",{});var fke=s(UT);B2e=n(fke,"STRONG",{});var C1t=s(B2e);Tlr=r(C1t,"dpr"),C1t.forEach(t),Mlr=r(fke," \u2014 "),qz=n(fke,"A",{href:!0});var w1t=s(qz);Elr=r(w1t,"TFDPRQuestionEncoder"),w1t.forEach(t),Clr=r(fke," (DPR model)"),fke.forEach(t),wlr=i(j),JT=n(j,"LI",{});var mke=s(JT);I2e=n(mke,"STRONG",{});var A1t=s(I2e);Alr=r(A1t,"electra"),A1t.forEach(t),ylr=r(mke," \u2014 "),Nz=n(mke,"A",{href:!0});var y1t=s(Nz);Llr=r(y1t,"TFElectraModel"),y1t.forEach(t),xlr=r(mke," (ELECTRA model)"),mke.forEach(t),$lr=i(j),YT=n(j,"LI",{});var gke=s(YT);q2e=n(gke,"STRONG",{});var L1t=s(q2e);klr=r(L1t,"flaubert"),L1t.forEach(t),Slr=r(gke," \u2014 "),jz=n(gke,"A",{href:!0});var x1t=s(jz);Rlr=r(x1t,"TFFlaubertModel"),x1t.forEach(t),Plr=r(gke," (FlauBERT model)"),gke.forEach(t),Blr=i(j),Bs=n(j,"LI",{});var A$=s(Bs);N2e=n(A$,"STRONG",{});var $1t=s(N2e);Ilr=r($1t,"funnel"),$1t.forEach(t),qlr=r(A$," \u2014 "),Dz=n(A$,"A",{href:!0});var k1t=s(Dz);Nlr=r(k1t,"TFFunnelModel"),k1t.forEach(t),jlr=r(A$," or "),Gz=n(A$,"A",{href:!0});var S1t=s(Gz);Dlr=r(S1t,"TFFunnelBaseModel"),S1t.forEach(t),Glr=r(A$," (Funnel Transformer model)"),A$.forEach(t),Olr=i(j),KT=n(j,"LI",{});var hke=s(KT);j2e=n(hke,"STRONG",{});var R1t=s(j2e);Vlr=r(R1t,"gpt2"),R1t.forEach(t),Xlr=r(hke," \u2014 "),Oz=n(hke,"A",{href:!0});var P1t=s(Oz);zlr=r(P1t,"TFGPT2Model"),P1t.forEach(t),Wlr=r(hke," (OpenAI GPT-2 model)"),hke.forEach(t),Qlr=i(j),ZT=n(j,"LI",{});var pke=s(ZT);D2e=n(pke,"STRONG",{});var B1t=s(D2e);Hlr=r(B1t,"gptj"),B1t.forEach(t),Ulr=r(pke," \u2014 "),Vz=n(pke,"A",{href:!0});var I1t=s(Vz);Jlr=r(I1t,"TFGPTJModel"),I1t.forEach(t),Ylr=r(pke," (GPT-J model)"),pke.forEach(t),Klr=i(j),eM=n(j,"LI",{});var uke=s(eM);G2e=n(uke,"STRONG",{});var q1t=s(G2e);Zlr=r(q1t,"hubert"),q1t.forEach(t),eir=r(uke," \u2014 "),Xz=n(uke,"A",{href:!0});var N1t=s(Xz);oir=r(N1t,"TFHubertModel"),N1t.forEach(t),rir=r(uke," (Hubert model)"),uke.forEach(t),tir=i(j),oM=n(j,"LI",{});var _ke=s(oM);O2e=n(_ke,"STRONG",{});var j1t=s(O2e);air=r(j1t,"layoutlm"),j1t.forEach(t),nir=r(_ke," \u2014 "),zz=n(_ke,"A",{href:!0});var D1t=s(zz);sir=r(D1t,"TFLayoutLMModel"),D1t.forEach(t),lir=r(_ke," (LayoutLM model)"),_ke.forEach(t),iir=i(j),rM=n(j,"LI",{});var bke=s(rM);V2e=n(bke,"STRONG",{});var G1t=s(V2e);dir=r(G1t,"led"),G1t.forEach(t),cir=r(bke," \u2014 "),Wz=n(bke,"A",{href:!0});var O1t=s(Wz);fir=r(O1t,"TFLEDModel"),O1t.forEach(t),mir=r(bke," (LED model)"),bke.forEach(t),gir=i(j),tM=n(j,"LI",{});var vke=s(tM);X2e=n(vke,"STRONG",{});var V1t=s(X2e);hir=r(V1t,"longformer"),V1t.forEach(t),pir=r(vke," \u2014 "),Qz=n(vke,"A",{href:!0});var X1t=s(Qz);uir=r(X1t,"TFLongformerModel"),X1t.forEach(t),_ir=r(vke," (Longformer model)"),vke.forEach(t),bir=i(j),aM=n(j,"LI",{});var Fke=s(aM);z2e=n(Fke,"STRONG",{});var z1t=s(z2e);vir=r(z1t,"lxmert"),z1t.forEach(t),Fir=r(Fke," \u2014 "),Hz=n(Fke,"A",{href:!0});var W1t=s(Hz);Tir=r(W1t,"TFLxmertModel"),W1t.forEach(t),Mir=r(Fke," (LXMERT model)"),Fke.forEach(t),Eir=i(j),nM=n(j,"LI",{});var Tke=s(nM);W2e=n(Tke,"STRONG",{});var Q1t=s(W2e);Cir=r(Q1t,"marian"),Q1t.forEach(t),wir=r(Tke," \u2014 "),Uz=n(Tke,"A",{href:!0});var H1t=s(Uz);Air=r(H1t,"TFMarianModel"),H1t.forEach(t),yir=r(Tke," (Marian model)"),Tke.forEach(t),Lir=i(j),sM=n(j,"LI",{});var Mke=s(sM);Q2e=n(Mke,"STRONG",{});var U1t=s(Q2e);xir=r(U1t,"mbart"),U1t.forEach(t),$ir=r(Mke," \u2014 "),Jz=n(Mke,"A",{href:!0});var J1t=s(Jz);kir=r(J1t,"TFMBartModel"),J1t.forEach(t),Sir=r(Mke," (mBART model)"),Mke.forEach(t),Rir=i(j),lM=n(j,"LI",{});var Eke=s(lM);H2e=n(Eke,"STRONG",{});var Y1t=s(H2e);Pir=r(Y1t,"mobilebert"),Y1t.forEach(t),Bir=r(Eke," \u2014 "),Yz=n(Eke,"A",{href:!0});var K1t=s(Yz);Iir=r(K1t,"TFMobileBertModel"),K1t.forEach(t),qir=r(Eke," (MobileBERT model)"),Eke.forEach(t),Nir=i(j),iM=n(j,"LI",{});var Cke=s(iM);U2e=n(Cke,"STRONG",{});var Z1t=s(U2e);jir=r(Z1t,"mpnet"),Z1t.forEach(t),Dir=r(Cke," \u2014 "),Kz=n(Cke,"A",{href:!0});var e7t=s(Kz);Gir=r(e7t,"TFMPNetModel"),e7t.forEach(t),Oir=r(Cke," (MPNet model)"),Cke.forEach(t),Vir=i(j),dM=n(j,"LI",{});var wke=s(dM);J2e=n(wke,"STRONG",{});var o7t=s(J2e);Xir=r(o7t,"mt5"),o7t.forEach(t),zir=r(wke," \u2014 "),Zz=n(wke,"A",{href:!0});var r7t=s(Zz);Wir=r(r7t,"TFMT5Model"),r7t.forEach(t),Qir=r(wke," (mT5 model)"),wke.forEach(t),Hir=i(j),cM=n(j,"LI",{});var Ake=s(cM);Y2e=n(Ake,"STRONG",{});var t7t=s(Y2e);Uir=r(t7t,"openai-gpt"),t7t.forEach(t),Jir=r(Ake," \u2014 "),eW=n(Ake,"A",{href:!0});var a7t=s(eW);Yir=r(a7t,"TFOpenAIGPTModel"),a7t.forEach(t),Kir=r(Ake," (OpenAI GPT model)"),Ake.forEach(t),Zir=i(j),fM=n(j,"LI",{});var yke=s(fM);K2e=n(yke,"STRONG",{});var n7t=s(K2e);edr=r(n7t,"opt"),n7t.forEach(t),odr=r(yke," \u2014 "),oW=n(yke,"A",{href:!0});var s7t=s(oW);rdr=r(s7t,"TFOPTModel"),s7t.forEach(t),tdr=r(yke," (OPT model)"),yke.forEach(t),adr=i(j),mM=n(j,"LI",{});var Lke=s(mM);Z2e=n(Lke,"STRONG",{});var l7t=s(Z2e);ndr=r(l7t,"pegasus"),l7t.forEach(t),sdr=r(Lke," \u2014 "),rW=n(Lke,"A",{href:!0});var i7t=s(rW);ldr=r(i7t,"TFPegasusModel"),i7t.forEach(t),idr=r(Lke," (Pegasus model)"),Lke.forEach(t),ddr=i(j),gM=n(j,"LI",{});var xke=s(gM);e1e=n(xke,"STRONG",{});var d7t=s(e1e);cdr=r(d7t,"rembert"),d7t.forEach(t),fdr=r(xke," \u2014 "),tW=n(xke,"A",{href:!0});var c7t=s(tW);mdr=r(c7t,"TFRemBertModel"),c7t.forEach(t),gdr=r(xke," (RemBERT model)"),xke.forEach(t),hdr=i(j),hM=n(j,"LI",{});var $ke=s(hM);o1e=n($ke,"STRONG",{});var f7t=s(o1e);pdr=r(f7t,"roberta"),f7t.forEach(t),udr=r($ke," \u2014 "),aW=n($ke,"A",{href:!0});var m7t=s(aW);_dr=r(m7t,"TFRobertaModel"),m7t.forEach(t),bdr=r($ke," (RoBERTa model)"),$ke.forEach(t),vdr=i(j),pM=n(j,"LI",{});var kke=s(pM);r1e=n(kke,"STRONG",{});var g7t=s(r1e);Fdr=r(g7t,"roformer"),g7t.forEach(t),Tdr=r(kke," \u2014 "),nW=n(kke,"A",{href:!0});var h7t=s(nW);Mdr=r(h7t,"TFRoFormerModel"),h7t.forEach(t),Edr=r(kke," (RoFormer model)"),kke.forEach(t),Cdr=i(j),uM=n(j,"LI",{});var Ske=s(uM);t1e=n(Ske,"STRONG",{});var p7t=s(t1e);wdr=r(p7t,"speech_to_text"),p7t.forEach(t),Adr=r(Ske," \u2014 "),sW=n(Ske,"A",{href:!0});var u7t=s(sW);ydr=r(u7t,"TFSpeech2TextModel"),u7t.forEach(t),Ldr=r(Ske," (Speech2Text model)"),Ske.forEach(t),xdr=i(j),_M=n(j,"LI",{});var Rke=s(_M);a1e=n(Rke,"STRONG",{});var _7t=s(a1e);$dr=r(_7t,"swin"),_7t.forEach(t),kdr=r(Rke," \u2014 "),lW=n(Rke,"A",{href:!0});var b7t=s(lW);Sdr=r(b7t,"TFSwinModel"),b7t.forEach(t),Rdr=r(Rke," (Swin model)"),Rke.forEach(t),Pdr=i(j),bM=n(j,"LI",{});var Pke=s(bM);n1e=n(Pke,"STRONG",{});var v7t=s(n1e);Bdr=r(v7t,"t5"),v7t.forEach(t),Idr=r(Pke," \u2014 "),iW=n(Pke,"A",{href:!0});var F7t=s(iW);qdr=r(F7t,"TFT5Model"),F7t.forEach(t),Ndr=r(Pke," (T5 model)"),Pke.forEach(t),jdr=i(j),vM=n(j,"LI",{});var Bke=s(vM);s1e=n(Bke,"STRONG",{});var T7t=s(s1e);Ddr=r(T7t,"tapas"),T7t.forEach(t),Gdr=r(Bke," \u2014 "),dW=n(Bke,"A",{href:!0});var M7t=s(dW);Odr=r(M7t,"TFTapasModel"),M7t.forEach(t),Vdr=r(Bke," (TAPAS model)"),Bke.forEach(t),Xdr=i(j),FM=n(j,"LI",{});var Ike=s(FM);l1e=n(Ike,"STRONG",{});var E7t=s(l1e);zdr=r(E7t,"transfo-xl"),E7t.forEach(t),Wdr=r(Ike," \u2014 "),cW=n(Ike,"A",{href:!0});var C7t=s(cW);Qdr=r(C7t,"TFTransfoXLModel"),C7t.forEach(t),Hdr=r(Ike," (Transformer-XL model)"),Ike.forEach(t),Udr=i(j),TM=n(j,"LI",{});var qke=s(TM);i1e=n(qke,"STRONG",{});var w7t=s(i1e);Jdr=r(w7t,"vit"),w7t.forEach(t),Ydr=r(qke," \u2014 "),fW=n(qke,"A",{href:!0});var A7t=s(fW);Kdr=r(A7t,"TFViTModel"),A7t.forEach(t),Zdr=r(qke," (ViT model)"),qke.forEach(t),ecr=i(j),MM=n(j,"LI",{});var Nke=s(MM);d1e=n(Nke,"STRONG",{});var y7t=s(d1e);ocr=r(y7t,"vit_mae"),y7t.forEach(t),rcr=r(Nke," \u2014 "),mW=n(Nke,"A",{href:!0});var L7t=s(mW);tcr=r(L7t,"TFViTMAEModel"),L7t.forEach(t),acr=r(Nke," (ViTMAE model)"),Nke.forEach(t),ncr=i(j),EM=n(j,"LI",{});var jke=s(EM);c1e=n(jke,"STRONG",{});var x7t=s(c1e);scr=r(x7t,"wav2vec2"),x7t.forEach(t),lcr=r(jke," \u2014 "),gW=n(jke,"A",{href:!0});var $7t=s(gW);icr=r($7t,"TFWav2Vec2Model"),$7t.forEach(t),dcr=r(jke," (Wav2Vec2 model)"),jke.forEach(t),ccr=i(j),CM=n(j,"LI",{});var Dke=s(CM);f1e=n(Dke,"STRONG",{});var k7t=s(f1e);fcr=r(k7t,"xlm"),k7t.forEach(t),mcr=r(Dke," \u2014 "),hW=n(Dke,"A",{href:!0});var S7t=s(hW);gcr=r(S7t,"TFXLMModel"),S7t.forEach(t),hcr=r(Dke," (XLM model)"),Dke.forEach(t),pcr=i(j),wM=n(j,"LI",{});var Gke=s(wM);m1e=n(Gke,"STRONG",{});var R7t=s(m1e);ucr=r(R7t,"xlm-roberta"),R7t.forEach(t),_cr=r(Gke," \u2014 "),pW=n(Gke,"A",{href:!0});var P7t=s(pW);bcr=r(P7t,"TFXLMRobertaModel"),P7t.forEach(t),vcr=r(Gke," (XLM-RoBERTa model)"),Gke.forEach(t),Fcr=i(j),AM=n(j,"LI",{});var Oke=s(AM);g1e=n(Oke,"STRONG",{});var B7t=s(g1e);Tcr=r(B7t,"xlnet"),B7t.forEach(t),Mcr=r(Oke," \u2014 "),uW=n(Oke,"A",{href:!0});var I7t=s(uW);Ecr=r(I7t,"TFXLNetModel"),I7t.forEach(t),Ccr=r(Oke," (XLNet model)"),Oke.forEach(t),j.forEach(t),wcr=i(gl),T(yM.$$.fragment,gl),gl.forEach(t),ml.forEach(t),Xqe=i(f),Vd=n(f,"H2",{class:!0});var Jje=s(Vd);LM=n(Jje,"A",{id:!0,class:!0,href:!0});var q7t=s(LM);h1e=n(q7t,"SPAN",{});var N7t=s(h1e);T(JL.$$.fragment,N7t),N7t.forEach(t),q7t.forEach(t),Acr=i(Jje),p1e=n(Jje,"SPAN",{});var j7t=s(p1e);ycr=r(j7t,"TFAutoModelForPreTraining"),j7t.forEach(t),Jje.forEach(t),zqe=i(f),Ko=n(f,"DIV",{class:!0});var hl=s(Ko);T(YL.$$.fragment,hl),Lcr=i(hl),Xd=n(hl,"P",{});var LZ=s(Xd);xcr=r(LZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),_W=n(LZ,"A",{href:!0});var D7t=s(_W);$cr=r(D7t,"from_pretrained()"),D7t.forEach(t),kcr=r(LZ," class method or the "),bW=n(LZ,"A",{href:!0});var G7t=s(bW);Scr=r(G7t,"from_config()"),G7t.forEach(t),Rcr=r(LZ,` class
method.`),LZ.forEach(t),Pcr=i(hl),KL=n(hl,"P",{});var Yje=s(KL);Bcr=r(Yje,"This class cannot be instantiated directly using "),u1e=n(Yje,"CODE",{});var O7t=s(u1e);Icr=r(O7t,"__init__()"),O7t.forEach(t),qcr=r(Yje," (throws an error)."),Yje.forEach(t),Ncr=i(hl),Lt=n(hl,"DIV",{class:!0});var d0=s(Lt);T(ZL.$$.fragment,d0),jcr=i(d0),_1e=n(d0,"P",{});var V7t=s(_1e);Dcr=r(V7t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),V7t.forEach(t),Gcr=i(d0),zd=n(d0,"P",{});var xZ=s(zd);Ocr=r(xZ,`Note:
Loading a model from its configuration file does `),b1e=n(xZ,"STRONG",{});var X7t=s(b1e);Vcr=r(X7t,"not"),X7t.forEach(t),Xcr=r(xZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=n(xZ,"A",{href:!0});var z7t=s(vW);zcr=r(z7t,"from_pretrained()"),z7t.forEach(t),Wcr=r(xZ," to load the model weights."),xZ.forEach(t),Qcr=i(d0),T(xM.$$.fragment,d0),d0.forEach(t),Hcr=i(hl),Ar=n(hl,"DIV",{class:!0});var pl=s(Ar);T(e8.$$.fragment,pl),Ucr=i(pl),v1e=n(pl,"P",{});var W7t=s(v1e);Jcr=r(W7t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),W7t.forEach(t),Ycr=i(pl),Za=n(pl,"P",{});var c0=s(Za);Kcr=r(c0,"The model class to instantiate is selected based on the "),F1e=n(c0,"CODE",{});var Q7t=s(F1e);Zcr=r(Q7t,"model_type"),Q7t.forEach(t),efr=r(c0,` property of the config object (either
passed as an argument or loaded from `),T1e=n(c0,"CODE",{});var H7t=s(T1e);ofr=r(H7t,"pretrained_model_name_or_path"),H7t.forEach(t),rfr=r(c0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M1e=n(c0,"CODE",{});var U7t=s(M1e);tfr=r(U7t,"pretrained_model_name_or_path"),U7t.forEach(t),afr=r(c0,":"),c0.forEach(t),nfr=i(pl),se=n(pl,"UL",{});var le=s(se);$M=n(le,"LI",{});var Vke=s($M);E1e=n(Vke,"STRONG",{});var J7t=s(E1e);sfr=r(J7t,"albert"),J7t.forEach(t),lfr=r(Vke," \u2014 "),FW=n(Vke,"A",{href:!0});var Y7t=s(FW);ifr=r(Y7t,"TFAlbertForPreTraining"),Y7t.forEach(t),dfr=r(Vke," (ALBERT model)"),Vke.forEach(t),cfr=i(le),kM=n(le,"LI",{});var Xke=s(kM);C1e=n(Xke,"STRONG",{});var K7t=s(C1e);ffr=r(K7t,"bart"),K7t.forEach(t),mfr=r(Xke," \u2014 "),TW=n(Xke,"A",{href:!0});var Z7t=s(TW);gfr=r(Z7t,"TFBartForConditionalGeneration"),Z7t.forEach(t),hfr=r(Xke," (BART model)"),Xke.forEach(t),pfr=i(le),SM=n(le,"LI",{});var zke=s(SM);w1e=n(zke,"STRONG",{});var ebt=s(w1e);ufr=r(ebt,"bert"),ebt.forEach(t),_fr=r(zke," \u2014 "),MW=n(zke,"A",{href:!0});var obt=s(MW);bfr=r(obt,"TFBertForPreTraining"),obt.forEach(t),vfr=r(zke," (BERT model)"),zke.forEach(t),Ffr=i(le),RM=n(le,"LI",{});var Wke=s(RM);A1e=n(Wke,"STRONG",{});var rbt=s(A1e);Tfr=r(rbt,"camembert"),rbt.forEach(t),Mfr=r(Wke," \u2014 "),EW=n(Wke,"A",{href:!0});var tbt=s(EW);Efr=r(tbt,"TFCamembertForMaskedLM"),tbt.forEach(t),Cfr=r(Wke," (CamemBERT model)"),Wke.forEach(t),wfr=i(le),PM=n(le,"LI",{});var Qke=s(PM);y1e=n(Qke,"STRONG",{});var abt=s(y1e);Afr=r(abt,"ctrl"),abt.forEach(t),yfr=r(Qke," \u2014 "),CW=n(Qke,"A",{href:!0});var nbt=s(CW);Lfr=r(nbt,"TFCTRLLMHeadModel"),nbt.forEach(t),xfr=r(Qke," (CTRL model)"),Qke.forEach(t),$fr=i(le),BM=n(le,"LI",{});var Hke=s(BM);L1e=n(Hke,"STRONG",{});var sbt=s(L1e);kfr=r(sbt,"distilbert"),sbt.forEach(t),Sfr=r(Hke," \u2014 "),wW=n(Hke,"A",{href:!0});var lbt=s(wW);Rfr=r(lbt,"TFDistilBertForMaskedLM"),lbt.forEach(t),Pfr=r(Hke," (DistilBERT model)"),Hke.forEach(t),Bfr=i(le),IM=n(le,"LI",{});var Uke=s(IM);x1e=n(Uke,"STRONG",{});var ibt=s(x1e);Ifr=r(ibt,"electra"),ibt.forEach(t),qfr=r(Uke," \u2014 "),AW=n(Uke,"A",{href:!0});var dbt=s(AW);Nfr=r(dbt,"TFElectraForPreTraining"),dbt.forEach(t),jfr=r(Uke," (ELECTRA model)"),Uke.forEach(t),Dfr=i(le),qM=n(le,"LI",{});var Jke=s(qM);$1e=n(Jke,"STRONG",{});var cbt=s($1e);Gfr=r(cbt,"flaubert"),cbt.forEach(t),Ofr=r(Jke," \u2014 "),yW=n(Jke,"A",{href:!0});var fbt=s(yW);Vfr=r(fbt,"TFFlaubertWithLMHeadModel"),fbt.forEach(t),Xfr=r(Jke," (FlauBERT model)"),Jke.forEach(t),zfr=i(le),NM=n(le,"LI",{});var Yke=s(NM);k1e=n(Yke,"STRONG",{});var mbt=s(k1e);Wfr=r(mbt,"funnel"),mbt.forEach(t),Qfr=r(Yke," \u2014 "),LW=n(Yke,"A",{href:!0});var gbt=s(LW);Hfr=r(gbt,"TFFunnelForPreTraining"),gbt.forEach(t),Ufr=r(Yke," (Funnel Transformer model)"),Yke.forEach(t),Jfr=i(le),jM=n(le,"LI",{});var Kke=s(jM);S1e=n(Kke,"STRONG",{});var hbt=s(S1e);Yfr=r(hbt,"gpt2"),hbt.forEach(t),Kfr=r(Kke," \u2014 "),xW=n(Kke,"A",{href:!0});var pbt=s(xW);Zfr=r(pbt,"TFGPT2LMHeadModel"),pbt.forEach(t),emr=r(Kke," (OpenAI GPT-2 model)"),Kke.forEach(t),omr=i(le),DM=n(le,"LI",{});var Zke=s(DM);R1e=n(Zke,"STRONG",{});var ubt=s(R1e);rmr=r(ubt,"layoutlm"),ubt.forEach(t),tmr=r(Zke," \u2014 "),$W=n(Zke,"A",{href:!0});var _bt=s($W);amr=r(_bt,"TFLayoutLMForMaskedLM"),_bt.forEach(t),nmr=r(Zke," (LayoutLM model)"),Zke.forEach(t),smr=i(le),GM=n(le,"LI",{});var eSe=s(GM);P1e=n(eSe,"STRONG",{});var bbt=s(P1e);lmr=r(bbt,"lxmert"),bbt.forEach(t),imr=r(eSe," \u2014 "),kW=n(eSe,"A",{href:!0});var vbt=s(kW);dmr=r(vbt,"TFLxmertForPreTraining"),vbt.forEach(t),cmr=r(eSe," (LXMERT model)"),eSe.forEach(t),fmr=i(le),OM=n(le,"LI",{});var oSe=s(OM);B1e=n(oSe,"STRONG",{});var Fbt=s(B1e);mmr=r(Fbt,"mobilebert"),Fbt.forEach(t),gmr=r(oSe," \u2014 "),SW=n(oSe,"A",{href:!0});var Tbt=s(SW);hmr=r(Tbt,"TFMobileBertForPreTraining"),Tbt.forEach(t),pmr=r(oSe," (MobileBERT model)"),oSe.forEach(t),umr=i(le),VM=n(le,"LI",{});var rSe=s(VM);I1e=n(rSe,"STRONG",{});var Mbt=s(I1e);_mr=r(Mbt,"mpnet"),Mbt.forEach(t),bmr=r(rSe," \u2014 "),RW=n(rSe,"A",{href:!0});var Ebt=s(RW);vmr=r(Ebt,"TFMPNetForMaskedLM"),Ebt.forEach(t),Fmr=r(rSe," (MPNet model)"),rSe.forEach(t),Tmr=i(le),XM=n(le,"LI",{});var tSe=s(XM);q1e=n(tSe,"STRONG",{});var Cbt=s(q1e);Mmr=r(Cbt,"openai-gpt"),Cbt.forEach(t),Emr=r(tSe," \u2014 "),PW=n(tSe,"A",{href:!0});var wbt=s(PW);Cmr=r(wbt,"TFOpenAIGPTLMHeadModel"),wbt.forEach(t),wmr=r(tSe," (OpenAI GPT model)"),tSe.forEach(t),Amr=i(le),zM=n(le,"LI",{});var aSe=s(zM);N1e=n(aSe,"STRONG",{});var Abt=s(N1e);ymr=r(Abt,"roberta"),Abt.forEach(t),Lmr=r(aSe," \u2014 "),BW=n(aSe,"A",{href:!0});var ybt=s(BW);xmr=r(ybt,"TFRobertaForMaskedLM"),ybt.forEach(t),$mr=r(aSe," (RoBERTa model)"),aSe.forEach(t),kmr=i(le),WM=n(le,"LI",{});var nSe=s(WM);j1e=n(nSe,"STRONG",{});var Lbt=s(j1e);Smr=r(Lbt,"t5"),Lbt.forEach(t),Rmr=r(nSe," \u2014 "),IW=n(nSe,"A",{href:!0});var xbt=s(IW);Pmr=r(xbt,"TFT5ForConditionalGeneration"),xbt.forEach(t),Bmr=r(nSe," (T5 model)"),nSe.forEach(t),Imr=i(le),QM=n(le,"LI",{});var sSe=s(QM);D1e=n(sSe,"STRONG",{});var $bt=s(D1e);qmr=r($bt,"tapas"),$bt.forEach(t),Nmr=r(sSe," \u2014 "),qW=n(sSe,"A",{href:!0});var kbt=s(qW);jmr=r(kbt,"TFTapasForMaskedLM"),kbt.forEach(t),Dmr=r(sSe," (TAPAS model)"),sSe.forEach(t),Gmr=i(le),HM=n(le,"LI",{});var lSe=s(HM);G1e=n(lSe,"STRONG",{});var Sbt=s(G1e);Omr=r(Sbt,"transfo-xl"),Sbt.forEach(t),Vmr=r(lSe," \u2014 "),NW=n(lSe,"A",{href:!0});var Rbt=s(NW);Xmr=r(Rbt,"TFTransfoXLLMHeadModel"),Rbt.forEach(t),zmr=r(lSe," (Transformer-XL model)"),lSe.forEach(t),Wmr=i(le),UM=n(le,"LI",{});var iSe=s(UM);O1e=n(iSe,"STRONG",{});var Pbt=s(O1e);Qmr=r(Pbt,"vit_mae"),Pbt.forEach(t),Hmr=r(iSe," \u2014 "),jW=n(iSe,"A",{href:!0});var Bbt=s(jW);Umr=r(Bbt,"TFViTMAEForPreTraining"),Bbt.forEach(t),Jmr=r(iSe," (ViTMAE model)"),iSe.forEach(t),Ymr=i(le),JM=n(le,"LI",{});var dSe=s(JM);V1e=n(dSe,"STRONG",{});var Ibt=s(V1e);Kmr=r(Ibt,"xlm"),Ibt.forEach(t),Zmr=r(dSe," \u2014 "),DW=n(dSe,"A",{href:!0});var qbt=s(DW);egr=r(qbt,"TFXLMWithLMHeadModel"),qbt.forEach(t),ogr=r(dSe," (XLM model)"),dSe.forEach(t),rgr=i(le),YM=n(le,"LI",{});var cSe=s(YM);X1e=n(cSe,"STRONG",{});var Nbt=s(X1e);tgr=r(Nbt,"xlm-roberta"),Nbt.forEach(t),agr=r(cSe," \u2014 "),GW=n(cSe,"A",{href:!0});var jbt=s(GW);ngr=r(jbt,"TFXLMRobertaForMaskedLM"),jbt.forEach(t),sgr=r(cSe," (XLM-RoBERTa model)"),cSe.forEach(t),lgr=i(le),KM=n(le,"LI",{});var fSe=s(KM);z1e=n(fSe,"STRONG",{});var Dbt=s(z1e);igr=r(Dbt,"xlnet"),Dbt.forEach(t),dgr=r(fSe," \u2014 "),OW=n(fSe,"A",{href:!0});var Gbt=s(OW);cgr=r(Gbt,"TFXLNetLMHeadModel"),Gbt.forEach(t),fgr=r(fSe," (XLNet model)"),fSe.forEach(t),le.forEach(t),mgr=i(pl),T(ZM.$$.fragment,pl),pl.forEach(t),hl.forEach(t),Wqe=i(f),Wd=n(f,"H2",{class:!0});var Kje=s(Wd);e4=n(Kje,"A",{id:!0,class:!0,href:!0});var Obt=s(e4);W1e=n(Obt,"SPAN",{});var Vbt=s(W1e);T(o8.$$.fragment,Vbt),Vbt.forEach(t),Obt.forEach(t),ggr=i(Kje),Q1e=n(Kje,"SPAN",{});var Xbt=s(Q1e);hgr=r(Xbt,"TFAutoModelForCausalLM"),Xbt.forEach(t),Kje.forEach(t),Qqe=i(f),Zo=n(f,"DIV",{class:!0});var ul=s(Zo);T(r8.$$.fragment,ul),pgr=i(ul),Qd=n(ul,"P",{});var $Z=s(Qd);ugr=r($Z,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),VW=n($Z,"A",{href:!0});var zbt=s(VW);_gr=r(zbt,"from_pretrained()"),zbt.forEach(t),bgr=r($Z," class method or the "),XW=n($Z,"A",{href:!0});var Wbt=s(XW);vgr=r(Wbt,"from_config()"),Wbt.forEach(t),Fgr=r($Z,` class
method.`),$Z.forEach(t),Tgr=i(ul),t8=n(ul,"P",{});var Zje=s(t8);Mgr=r(Zje,"This class cannot be instantiated directly using "),H1e=n(Zje,"CODE",{});var Qbt=s(H1e);Egr=r(Qbt,"__init__()"),Qbt.forEach(t),Cgr=r(Zje," (throws an error)."),Zje.forEach(t),wgr=i(ul),xt=n(ul,"DIV",{class:!0});var f0=s(xt);T(a8.$$.fragment,f0),Agr=i(f0),U1e=n(f0,"P",{});var Hbt=s(U1e);ygr=r(Hbt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Hbt.forEach(t),Lgr=i(f0),Hd=n(f0,"P",{});var kZ=s(Hd);xgr=r(kZ,`Note:
Loading a model from its configuration file does `),J1e=n(kZ,"STRONG",{});var Ubt=s(J1e);$gr=r(Ubt,"not"),Ubt.forEach(t),kgr=r(kZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),zW=n(kZ,"A",{href:!0});var Jbt=s(zW);Sgr=r(Jbt,"from_pretrained()"),Jbt.forEach(t),Rgr=r(kZ," to load the model weights."),kZ.forEach(t),Pgr=i(f0),T(o4.$$.fragment,f0),f0.forEach(t),Bgr=i(ul),yr=n(ul,"DIV",{class:!0});var _l=s(yr);T(n8.$$.fragment,_l),Igr=i(_l),Y1e=n(_l,"P",{});var Ybt=s(Y1e);qgr=r(Ybt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Ybt.forEach(t),Ngr=i(_l),en=n(_l,"P",{});var m0=s(en);jgr=r(m0,"The model class to instantiate is selected based on the "),K1e=n(m0,"CODE",{});var Kbt=s(K1e);Dgr=r(Kbt,"model_type"),Kbt.forEach(t),Ggr=r(m0,` property of the config object (either
passed as an argument or loaded from `),Z1e=n(m0,"CODE",{});var Zbt=s(Z1e);Ogr=r(Zbt,"pretrained_model_name_or_path"),Zbt.forEach(t),Vgr=r(m0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=n(m0,"CODE",{});var evt=s(e7e);Xgr=r(evt,"pretrained_model_name_or_path"),evt.forEach(t),zgr=r(m0,":"),m0.forEach(t),Wgr=i(_l),Te=n(_l,"UL",{});var Ce=s(Te);r4=n(Ce,"LI",{});var mSe=s(r4);o7e=n(mSe,"STRONG",{});var ovt=s(o7e);Qgr=r(ovt,"bert"),ovt.forEach(t),Hgr=r(mSe," \u2014 "),WW=n(mSe,"A",{href:!0});var rvt=s(WW);Ugr=r(rvt,"TFBertLMHeadModel"),rvt.forEach(t),Jgr=r(mSe," (BERT model)"),mSe.forEach(t),Ygr=i(Ce),t4=n(Ce,"LI",{});var gSe=s(t4);r7e=n(gSe,"STRONG",{});var tvt=s(r7e);Kgr=r(tvt,"camembert"),tvt.forEach(t),Zgr=r(gSe," \u2014 "),QW=n(gSe,"A",{href:!0});var avt=s(QW);ehr=r(avt,"TFCamembertForCausalLM"),avt.forEach(t),ohr=r(gSe," (CamemBERT model)"),gSe.forEach(t),rhr=i(Ce),a4=n(Ce,"LI",{});var hSe=s(a4);t7e=n(hSe,"STRONG",{});var nvt=s(t7e);thr=r(nvt,"ctrl"),nvt.forEach(t),ahr=r(hSe," \u2014 "),HW=n(hSe,"A",{href:!0});var svt=s(HW);nhr=r(svt,"TFCTRLLMHeadModel"),svt.forEach(t),shr=r(hSe," (CTRL model)"),hSe.forEach(t),lhr=i(Ce),n4=n(Ce,"LI",{});var pSe=s(n4);a7e=n(pSe,"STRONG",{});var lvt=s(a7e);ihr=r(lvt,"gpt2"),lvt.forEach(t),dhr=r(pSe," \u2014 "),UW=n(pSe,"A",{href:!0});var ivt=s(UW);chr=r(ivt,"TFGPT2LMHeadModel"),ivt.forEach(t),fhr=r(pSe," (OpenAI GPT-2 model)"),pSe.forEach(t),mhr=i(Ce),s4=n(Ce,"LI",{});var uSe=s(s4);n7e=n(uSe,"STRONG",{});var dvt=s(n7e);ghr=r(dvt,"gptj"),dvt.forEach(t),hhr=r(uSe," \u2014 "),JW=n(uSe,"A",{href:!0});var cvt=s(JW);phr=r(cvt,"TFGPTJForCausalLM"),cvt.forEach(t),uhr=r(uSe," (GPT-J model)"),uSe.forEach(t),_hr=i(Ce),l4=n(Ce,"LI",{});var _Se=s(l4);s7e=n(_Se,"STRONG",{});var fvt=s(s7e);bhr=r(fvt,"openai-gpt"),fvt.forEach(t),vhr=r(_Se," \u2014 "),YW=n(_Se,"A",{href:!0});var mvt=s(YW);Fhr=r(mvt,"TFOpenAIGPTLMHeadModel"),mvt.forEach(t),Thr=r(_Se," (OpenAI GPT model)"),_Se.forEach(t),Mhr=i(Ce),i4=n(Ce,"LI",{});var bSe=s(i4);l7e=n(bSe,"STRONG",{});var gvt=s(l7e);Ehr=r(gvt,"rembert"),gvt.forEach(t),Chr=r(bSe," \u2014 "),KW=n(bSe,"A",{href:!0});var hvt=s(KW);whr=r(hvt,"TFRemBertForCausalLM"),hvt.forEach(t),Ahr=r(bSe," (RemBERT model)"),bSe.forEach(t),yhr=i(Ce),d4=n(Ce,"LI",{});var vSe=s(d4);i7e=n(vSe,"STRONG",{});var pvt=s(i7e);Lhr=r(pvt,"roberta"),pvt.forEach(t),xhr=r(vSe," \u2014 "),ZW=n(vSe,"A",{href:!0});var uvt=s(ZW);$hr=r(uvt,"TFRobertaForCausalLM"),uvt.forEach(t),khr=r(vSe," (RoBERTa model)"),vSe.forEach(t),Shr=i(Ce),c4=n(Ce,"LI",{});var FSe=s(c4);d7e=n(FSe,"STRONG",{});var _vt=s(d7e);Rhr=r(_vt,"roformer"),_vt.forEach(t),Phr=r(FSe," \u2014 "),eQ=n(FSe,"A",{href:!0});var bvt=s(eQ);Bhr=r(bvt,"TFRoFormerForCausalLM"),bvt.forEach(t),Ihr=r(FSe," (RoFormer model)"),FSe.forEach(t),qhr=i(Ce),f4=n(Ce,"LI",{});var TSe=s(f4);c7e=n(TSe,"STRONG",{});var vvt=s(c7e);Nhr=r(vvt,"transfo-xl"),vvt.forEach(t),jhr=r(TSe," \u2014 "),oQ=n(TSe,"A",{href:!0});var Fvt=s(oQ);Dhr=r(Fvt,"TFTransfoXLLMHeadModel"),Fvt.forEach(t),Ghr=r(TSe," (Transformer-XL model)"),TSe.forEach(t),Ohr=i(Ce),m4=n(Ce,"LI",{});var MSe=s(m4);f7e=n(MSe,"STRONG",{});var Tvt=s(f7e);Vhr=r(Tvt,"xlm"),Tvt.forEach(t),Xhr=r(MSe," \u2014 "),rQ=n(MSe,"A",{href:!0});var Mvt=s(rQ);zhr=r(Mvt,"TFXLMWithLMHeadModel"),Mvt.forEach(t),Whr=r(MSe," (XLM model)"),MSe.forEach(t),Qhr=i(Ce),g4=n(Ce,"LI",{});var ESe=s(g4);m7e=n(ESe,"STRONG",{});var Evt=s(m7e);Hhr=r(Evt,"xlnet"),Evt.forEach(t),Uhr=r(ESe," \u2014 "),tQ=n(ESe,"A",{href:!0});var Cvt=s(tQ);Jhr=r(Cvt,"TFXLNetLMHeadModel"),Cvt.forEach(t),Yhr=r(ESe," (XLNet model)"),ESe.forEach(t),Ce.forEach(t),Khr=i(_l),T(h4.$$.fragment,_l),_l.forEach(t),ul.forEach(t),Hqe=i(f),Ud=n(f,"H2",{class:!0});var eDe=s(Ud);p4=n(eDe,"A",{id:!0,class:!0,href:!0});var wvt=s(p4);g7e=n(wvt,"SPAN",{});var Avt=s(g7e);T(s8.$$.fragment,Avt),Avt.forEach(t),wvt.forEach(t),Zhr=i(eDe),h7e=n(eDe,"SPAN",{});var yvt=s(h7e);epr=r(yvt,"TFAutoModelForImageClassification"),yvt.forEach(t),eDe.forEach(t),Uqe=i(f),er=n(f,"DIV",{class:!0});var bl=s(er);T(l8.$$.fragment,bl),opr=i(bl),Jd=n(bl,"P",{});var SZ=s(Jd);rpr=r(SZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aQ=n(SZ,"A",{href:!0});var Lvt=s(aQ);tpr=r(Lvt,"from_pretrained()"),Lvt.forEach(t),apr=r(SZ," class method or the "),nQ=n(SZ,"A",{href:!0});var xvt=s(nQ);npr=r(xvt,"from_config()"),xvt.forEach(t),spr=r(SZ,` class
method.`),SZ.forEach(t),lpr=i(bl),i8=n(bl,"P",{});var oDe=s(i8);ipr=r(oDe,"This class cannot be instantiated directly using "),p7e=n(oDe,"CODE",{});var $vt=s(p7e);dpr=r($vt,"__init__()"),$vt.forEach(t),cpr=r(oDe," (throws an error)."),oDe.forEach(t),fpr=i(bl),$t=n(bl,"DIV",{class:!0});var g0=s($t);T(d8.$$.fragment,g0),mpr=i(g0),u7e=n(g0,"P",{});var kvt=s(u7e);gpr=r(kvt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),kvt.forEach(t),hpr=i(g0),Yd=n(g0,"P",{});var RZ=s(Yd);ppr=r(RZ,`Note:
Loading a model from its configuration file does `),_7e=n(RZ,"STRONG",{});var Svt=s(_7e);upr=r(Svt,"not"),Svt.forEach(t),_pr=r(RZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=n(RZ,"A",{href:!0});var Rvt=s(sQ);bpr=r(Rvt,"from_pretrained()"),Rvt.forEach(t),vpr=r(RZ," to load the model weights."),RZ.forEach(t),Fpr=i(g0),T(u4.$$.fragment,g0),g0.forEach(t),Tpr=i(bl),Lr=n(bl,"DIV",{class:!0});var vl=s(Lr);T(c8.$$.fragment,vl),Mpr=i(vl),b7e=n(vl,"P",{});var Pvt=s(b7e);Epr=r(Pvt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Pvt.forEach(t),Cpr=i(vl),on=n(vl,"P",{});var h0=s(on);wpr=r(h0,"The model class to instantiate is selected based on the "),v7e=n(h0,"CODE",{});var Bvt=s(v7e);Apr=r(Bvt,"model_type"),Bvt.forEach(t),ypr=r(h0,` property of the config object (either
passed as an argument or loaded from `),F7e=n(h0,"CODE",{});var Ivt=s(F7e);Lpr=r(Ivt,"pretrained_model_name_or_path"),Ivt.forEach(t),xpr=r(h0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T7e=n(h0,"CODE",{});var qvt=s(T7e);$pr=r(qvt,"pretrained_model_name_or_path"),qvt.forEach(t),kpr=r(h0,":"),h0.forEach(t),Spr=i(vl),rn=n(vl,"UL",{});var p0=s(rn);_4=n(p0,"LI",{});var CSe=s(_4);M7e=n(CSe,"STRONG",{});var Nvt=s(M7e);Rpr=r(Nvt,"convnext"),Nvt.forEach(t),Ppr=r(CSe," \u2014 "),lQ=n(CSe,"A",{href:!0});var jvt=s(lQ);Bpr=r(jvt,"TFConvNextForImageClassification"),jvt.forEach(t),Ipr=r(CSe," (ConvNext model)"),CSe.forEach(t),qpr=i(p0),b4=n(p0,"LI",{});var wSe=s(b4);E7e=n(wSe,"STRONG",{});var Dvt=s(E7e);Npr=r(Dvt,"data2vec-vision"),Dvt.forEach(t),jpr=r(wSe," \u2014 "),iQ=n(wSe,"A",{href:!0});var Gvt=s(iQ);Dpr=r(Gvt,"TFData2VecVisionForImageClassification"),Gvt.forEach(t),Gpr=r(wSe," (Data2VecVision model)"),wSe.forEach(t),Opr=i(p0),v4=n(p0,"LI",{});var ASe=s(v4);C7e=n(ASe,"STRONG",{});var Ovt=s(C7e);Vpr=r(Ovt,"swin"),Ovt.forEach(t),Xpr=r(ASe," \u2014 "),dQ=n(ASe,"A",{href:!0});var Vvt=s(dQ);zpr=r(Vvt,"TFSwinForImageClassification"),Vvt.forEach(t),Wpr=r(ASe," (Swin model)"),ASe.forEach(t),Qpr=i(p0),F4=n(p0,"LI",{});var ySe=s(F4);w7e=n(ySe,"STRONG",{});var Xvt=s(w7e);Hpr=r(Xvt,"vit"),Xvt.forEach(t),Upr=r(ySe," \u2014 "),cQ=n(ySe,"A",{href:!0});var zvt=s(cQ);Jpr=r(zvt,"TFViTForImageClassification"),zvt.forEach(t),Ypr=r(ySe," (ViT model)"),ySe.forEach(t),p0.forEach(t),Kpr=i(vl),T(T4.$$.fragment,vl),vl.forEach(t),bl.forEach(t),Jqe=i(f),Kd=n(f,"H2",{class:!0});var rDe=s(Kd);M4=n(rDe,"A",{id:!0,class:!0,href:!0});var Wvt=s(M4);A7e=n(Wvt,"SPAN",{});var Qvt=s(A7e);T(f8.$$.fragment,Qvt),Qvt.forEach(t),Wvt.forEach(t),Zpr=i(rDe),y7e=n(rDe,"SPAN",{});var Hvt=s(y7e);eur=r(Hvt,"TFAutoModelForMaskedLM"),Hvt.forEach(t),rDe.forEach(t),Yqe=i(f),or=n(f,"DIV",{class:!0});var Fl=s(or);T(m8.$$.fragment,Fl),our=i(Fl),Zd=n(Fl,"P",{});var PZ=s(Zd);rur=r(PZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),fQ=n(PZ,"A",{href:!0});var Uvt=s(fQ);tur=r(Uvt,"from_pretrained()"),Uvt.forEach(t),aur=r(PZ," class method or the "),mQ=n(PZ,"A",{href:!0});var Jvt=s(mQ);nur=r(Jvt,"from_config()"),Jvt.forEach(t),sur=r(PZ,` class
method.`),PZ.forEach(t),lur=i(Fl),g8=n(Fl,"P",{});var tDe=s(g8);iur=r(tDe,"This class cannot be instantiated directly using "),L7e=n(tDe,"CODE",{});var Yvt=s(L7e);dur=r(Yvt,"__init__()"),Yvt.forEach(t),cur=r(tDe," (throws an error)."),tDe.forEach(t),fur=i(Fl),kt=n(Fl,"DIV",{class:!0});var u0=s(kt);T(h8.$$.fragment,u0),mur=i(u0),x7e=n(u0,"P",{});var Kvt=s(x7e);gur=r(Kvt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Kvt.forEach(t),hur=i(u0),ec=n(u0,"P",{});var BZ=s(ec);pur=r(BZ,`Note:
Loading a model from its configuration file does `),$7e=n(BZ,"STRONG",{});var Zvt=s($7e);uur=r(Zvt,"not"),Zvt.forEach(t),_ur=r(BZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=n(BZ,"A",{href:!0});var eFt=s(gQ);bur=r(eFt,"from_pretrained()"),eFt.forEach(t),vur=r(BZ," to load the model weights."),BZ.forEach(t),Fur=i(u0),T(E4.$$.fragment,u0),u0.forEach(t),Tur=i(Fl),xr=n(Fl,"DIV",{class:!0});var Tl=s(xr);T(p8.$$.fragment,Tl),Mur=i(Tl),k7e=n(Tl,"P",{});var oFt=s(k7e);Eur=r(oFt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),oFt.forEach(t),Cur=i(Tl),tn=n(Tl,"P",{});var _0=s(tn);wur=r(_0,"The model class to instantiate is selected based on the "),S7e=n(_0,"CODE",{});var rFt=s(S7e);Aur=r(rFt,"model_type"),rFt.forEach(t),yur=r(_0,` property of the config object (either
passed as an argument or loaded from `),R7e=n(_0,"CODE",{});var tFt=s(R7e);Lur=r(tFt,"pretrained_model_name_or_path"),tFt.forEach(t),xur=r(_0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P7e=n(_0,"CODE",{});var aFt=s(P7e);$ur=r(aFt,"pretrained_model_name_or_path"),aFt.forEach(t),kur=r(_0,":"),_0.forEach(t),Sur=i(Tl),ie=n(Tl,"UL",{});var fe=s(ie);C4=n(fe,"LI",{});var LSe=s(C4);B7e=n(LSe,"STRONG",{});var nFt=s(B7e);Rur=r(nFt,"albert"),nFt.forEach(t),Pur=r(LSe," \u2014 "),hQ=n(LSe,"A",{href:!0});var sFt=s(hQ);Bur=r(sFt,"TFAlbertForMaskedLM"),sFt.forEach(t),Iur=r(LSe," (ALBERT model)"),LSe.forEach(t),qur=i(fe),w4=n(fe,"LI",{});var xSe=s(w4);I7e=n(xSe,"STRONG",{});var lFt=s(I7e);Nur=r(lFt,"bert"),lFt.forEach(t),jur=r(xSe," \u2014 "),pQ=n(xSe,"A",{href:!0});var iFt=s(pQ);Dur=r(iFt,"TFBertForMaskedLM"),iFt.forEach(t),Gur=r(xSe," (BERT model)"),xSe.forEach(t),Our=i(fe),A4=n(fe,"LI",{});var $Se=s(A4);q7e=n($Se,"STRONG",{});var dFt=s(q7e);Vur=r(dFt,"camembert"),dFt.forEach(t),Xur=r($Se," \u2014 "),uQ=n($Se,"A",{href:!0});var cFt=s(uQ);zur=r(cFt,"TFCamembertForMaskedLM"),cFt.forEach(t),Wur=r($Se," (CamemBERT model)"),$Se.forEach(t),Qur=i(fe),y4=n(fe,"LI",{});var kSe=s(y4);N7e=n(kSe,"STRONG",{});var fFt=s(N7e);Hur=r(fFt,"convbert"),fFt.forEach(t),Uur=r(kSe," \u2014 "),_Q=n(kSe,"A",{href:!0});var mFt=s(_Q);Jur=r(mFt,"TFConvBertForMaskedLM"),mFt.forEach(t),Yur=r(kSe," (ConvBERT model)"),kSe.forEach(t),Kur=i(fe),L4=n(fe,"LI",{});var SSe=s(L4);j7e=n(SSe,"STRONG",{});var gFt=s(j7e);Zur=r(gFt,"deberta"),gFt.forEach(t),e_r=r(SSe," \u2014 "),bQ=n(SSe,"A",{href:!0});var hFt=s(bQ);o_r=r(hFt,"TFDebertaForMaskedLM"),hFt.forEach(t),r_r=r(SSe," (DeBERTa model)"),SSe.forEach(t),t_r=i(fe),x4=n(fe,"LI",{});var RSe=s(x4);D7e=n(RSe,"STRONG",{});var pFt=s(D7e);a_r=r(pFt,"deberta-v2"),pFt.forEach(t),n_r=r(RSe," \u2014 "),vQ=n(RSe,"A",{href:!0});var uFt=s(vQ);s_r=r(uFt,"TFDebertaV2ForMaskedLM"),uFt.forEach(t),l_r=r(RSe," (DeBERTa-v2 model)"),RSe.forEach(t),i_r=i(fe),$4=n(fe,"LI",{});var PSe=s($4);G7e=n(PSe,"STRONG",{});var _Ft=s(G7e);d_r=r(_Ft,"distilbert"),_Ft.forEach(t),c_r=r(PSe," \u2014 "),FQ=n(PSe,"A",{href:!0});var bFt=s(FQ);f_r=r(bFt,"TFDistilBertForMaskedLM"),bFt.forEach(t),m_r=r(PSe," (DistilBERT model)"),PSe.forEach(t),g_r=i(fe),k4=n(fe,"LI",{});var BSe=s(k4);O7e=n(BSe,"STRONG",{});var vFt=s(O7e);h_r=r(vFt,"electra"),vFt.forEach(t),p_r=r(BSe," \u2014 "),TQ=n(BSe,"A",{href:!0});var FFt=s(TQ);u_r=r(FFt,"TFElectraForMaskedLM"),FFt.forEach(t),__r=r(BSe," (ELECTRA model)"),BSe.forEach(t),b_r=i(fe),S4=n(fe,"LI",{});var ISe=s(S4);V7e=n(ISe,"STRONG",{});var TFt=s(V7e);v_r=r(TFt,"flaubert"),TFt.forEach(t),F_r=r(ISe," \u2014 "),MQ=n(ISe,"A",{href:!0});var MFt=s(MQ);T_r=r(MFt,"TFFlaubertWithLMHeadModel"),MFt.forEach(t),M_r=r(ISe," (FlauBERT model)"),ISe.forEach(t),E_r=i(fe),R4=n(fe,"LI",{});var qSe=s(R4);X7e=n(qSe,"STRONG",{});var EFt=s(X7e);C_r=r(EFt,"funnel"),EFt.forEach(t),w_r=r(qSe," \u2014 "),EQ=n(qSe,"A",{href:!0});var CFt=s(EQ);A_r=r(CFt,"TFFunnelForMaskedLM"),CFt.forEach(t),y_r=r(qSe," (Funnel Transformer model)"),qSe.forEach(t),L_r=i(fe),P4=n(fe,"LI",{});var NSe=s(P4);z7e=n(NSe,"STRONG",{});var wFt=s(z7e);x_r=r(wFt,"layoutlm"),wFt.forEach(t),$_r=r(NSe," \u2014 "),CQ=n(NSe,"A",{href:!0});var AFt=s(CQ);k_r=r(AFt,"TFLayoutLMForMaskedLM"),AFt.forEach(t),S_r=r(NSe," (LayoutLM model)"),NSe.forEach(t),R_r=i(fe),B4=n(fe,"LI",{});var jSe=s(B4);W7e=n(jSe,"STRONG",{});var yFt=s(W7e);P_r=r(yFt,"longformer"),yFt.forEach(t),B_r=r(jSe," \u2014 "),wQ=n(jSe,"A",{href:!0});var LFt=s(wQ);I_r=r(LFt,"TFLongformerForMaskedLM"),LFt.forEach(t),q_r=r(jSe," (Longformer model)"),jSe.forEach(t),N_r=i(fe),I4=n(fe,"LI",{});var DSe=s(I4);Q7e=n(DSe,"STRONG",{});var xFt=s(Q7e);j_r=r(xFt,"mobilebert"),xFt.forEach(t),D_r=r(DSe," \u2014 "),AQ=n(DSe,"A",{href:!0});var $Ft=s(AQ);G_r=r($Ft,"TFMobileBertForMaskedLM"),$Ft.forEach(t),O_r=r(DSe," (MobileBERT model)"),DSe.forEach(t),V_r=i(fe),q4=n(fe,"LI",{});var GSe=s(q4);H7e=n(GSe,"STRONG",{});var kFt=s(H7e);X_r=r(kFt,"mpnet"),kFt.forEach(t),z_r=r(GSe," \u2014 "),yQ=n(GSe,"A",{href:!0});var SFt=s(yQ);W_r=r(SFt,"TFMPNetForMaskedLM"),SFt.forEach(t),Q_r=r(GSe," (MPNet model)"),GSe.forEach(t),H_r=i(fe),N4=n(fe,"LI",{});var OSe=s(N4);U7e=n(OSe,"STRONG",{});var RFt=s(U7e);U_r=r(RFt,"rembert"),RFt.forEach(t),J_r=r(OSe," \u2014 "),LQ=n(OSe,"A",{href:!0});var PFt=s(LQ);Y_r=r(PFt,"TFRemBertForMaskedLM"),PFt.forEach(t),K_r=r(OSe," (RemBERT model)"),OSe.forEach(t),Z_r=i(fe),j4=n(fe,"LI",{});var VSe=s(j4);J7e=n(VSe,"STRONG",{});var BFt=s(J7e);e2r=r(BFt,"roberta"),BFt.forEach(t),o2r=r(VSe," \u2014 "),xQ=n(VSe,"A",{href:!0});var IFt=s(xQ);r2r=r(IFt,"TFRobertaForMaskedLM"),IFt.forEach(t),t2r=r(VSe," (RoBERTa model)"),VSe.forEach(t),a2r=i(fe),D4=n(fe,"LI",{});var XSe=s(D4);Y7e=n(XSe,"STRONG",{});var qFt=s(Y7e);n2r=r(qFt,"roformer"),qFt.forEach(t),s2r=r(XSe," \u2014 "),$Q=n(XSe,"A",{href:!0});var NFt=s($Q);l2r=r(NFt,"TFRoFormerForMaskedLM"),NFt.forEach(t),i2r=r(XSe," (RoFormer model)"),XSe.forEach(t),d2r=i(fe),G4=n(fe,"LI",{});var zSe=s(G4);K7e=n(zSe,"STRONG",{});var jFt=s(K7e);c2r=r(jFt,"tapas"),jFt.forEach(t),f2r=r(zSe," \u2014 "),kQ=n(zSe,"A",{href:!0});var DFt=s(kQ);m2r=r(DFt,"TFTapasForMaskedLM"),DFt.forEach(t),g2r=r(zSe," (TAPAS model)"),zSe.forEach(t),h2r=i(fe),O4=n(fe,"LI",{});var WSe=s(O4);Z7e=n(WSe,"STRONG",{});var GFt=s(Z7e);p2r=r(GFt,"xlm"),GFt.forEach(t),u2r=r(WSe," \u2014 "),SQ=n(WSe,"A",{href:!0});var OFt=s(SQ);_2r=r(OFt,"TFXLMWithLMHeadModel"),OFt.forEach(t),b2r=r(WSe," (XLM model)"),WSe.forEach(t),v2r=i(fe),V4=n(fe,"LI",{});var QSe=s(V4);ebe=n(QSe,"STRONG",{});var VFt=s(ebe);F2r=r(VFt,"xlm-roberta"),VFt.forEach(t),T2r=r(QSe," \u2014 "),RQ=n(QSe,"A",{href:!0});var XFt=s(RQ);M2r=r(XFt,"TFXLMRobertaForMaskedLM"),XFt.forEach(t),E2r=r(QSe," (XLM-RoBERTa model)"),QSe.forEach(t),fe.forEach(t),C2r=i(Tl),T(X4.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),Kqe=i(f),oc=n(f,"H2",{class:!0});var aDe=s(oc);z4=n(aDe,"A",{id:!0,class:!0,href:!0});var zFt=s(z4);obe=n(zFt,"SPAN",{});var WFt=s(obe);T(u8.$$.fragment,WFt),WFt.forEach(t),zFt.forEach(t),w2r=i(aDe),rbe=n(aDe,"SPAN",{});var QFt=s(rbe);A2r=r(QFt,"TFAutoModelForSeq2SeqLM"),QFt.forEach(t),aDe.forEach(t),Zqe=i(f),rr=n(f,"DIV",{class:!0});var Ml=s(rr);T(_8.$$.fragment,Ml),y2r=i(Ml),rc=n(Ml,"P",{});var IZ=s(rc);L2r=r(IZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),PQ=n(IZ,"A",{href:!0});var HFt=s(PQ);x2r=r(HFt,"from_pretrained()"),HFt.forEach(t),$2r=r(IZ," class method or the "),BQ=n(IZ,"A",{href:!0});var UFt=s(BQ);k2r=r(UFt,"from_config()"),UFt.forEach(t),S2r=r(IZ,` class
method.`),IZ.forEach(t),R2r=i(Ml),b8=n(Ml,"P",{});var nDe=s(b8);P2r=r(nDe,"This class cannot be instantiated directly using "),tbe=n(nDe,"CODE",{});var JFt=s(tbe);B2r=r(JFt,"__init__()"),JFt.forEach(t),I2r=r(nDe," (throws an error)."),nDe.forEach(t),q2r=i(Ml),St=n(Ml,"DIV",{class:!0});var b0=s(St);T(v8.$$.fragment,b0),N2r=i(b0),abe=n(b0,"P",{});var YFt=s(abe);j2r=r(YFt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YFt.forEach(t),D2r=i(b0),tc=n(b0,"P",{});var qZ=s(tc);G2r=r(qZ,`Note:
Loading a model from its configuration file does `),nbe=n(qZ,"STRONG",{});var KFt=s(nbe);O2r=r(KFt,"not"),KFt.forEach(t),V2r=r(qZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(qZ,"A",{href:!0});var ZFt=s(IQ);X2r=r(ZFt,"from_pretrained()"),ZFt.forEach(t),z2r=r(qZ," to load the model weights."),qZ.forEach(t),W2r=i(b0),T(W4.$$.fragment,b0),b0.forEach(t),Q2r=i(Ml),$r=n(Ml,"DIV",{class:!0});var El=s($r);T(F8.$$.fragment,El),H2r=i(El),sbe=n(El,"P",{});var eTt=s(sbe);U2r=r(eTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),eTt.forEach(t),J2r=i(El),an=n(El,"P",{});var v0=s(an);Y2r=r(v0,"The model class to instantiate is selected based on the "),lbe=n(v0,"CODE",{});var oTt=s(lbe);K2r=r(oTt,"model_type"),oTt.forEach(t),Z2r=r(v0,` property of the config object (either
passed as an argument or loaded from `),ibe=n(v0,"CODE",{});var rTt=s(ibe);e1r=r(rTt,"pretrained_model_name_or_path"),rTt.forEach(t),o1r=r(v0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dbe=n(v0,"CODE",{});var tTt=s(dbe);r1r=r(tTt,"pretrained_model_name_or_path"),tTt.forEach(t),t1r=r(v0,":"),v0.forEach(t),a1r=i(El),ye=n(El,"UL",{});var Be=s(ye);Q4=n(Be,"LI",{});var HSe=s(Q4);cbe=n(HSe,"STRONG",{});var aTt=s(cbe);n1r=r(aTt,"bart"),aTt.forEach(t),s1r=r(HSe," \u2014 "),qQ=n(HSe,"A",{href:!0});var nTt=s(qQ);l1r=r(nTt,"TFBartForConditionalGeneration"),nTt.forEach(t),i1r=r(HSe," (BART model)"),HSe.forEach(t),d1r=i(Be),H4=n(Be,"LI",{});var USe=s(H4);fbe=n(USe,"STRONG",{});var sTt=s(fbe);c1r=r(sTt,"blenderbot"),sTt.forEach(t),f1r=r(USe," \u2014 "),NQ=n(USe,"A",{href:!0});var lTt=s(NQ);m1r=r(lTt,"TFBlenderbotForConditionalGeneration"),lTt.forEach(t),g1r=r(USe," (Blenderbot model)"),USe.forEach(t),h1r=i(Be),U4=n(Be,"LI",{});var JSe=s(U4);mbe=n(JSe,"STRONG",{});var iTt=s(mbe);p1r=r(iTt,"blenderbot-small"),iTt.forEach(t),u1r=r(JSe," \u2014 "),jQ=n(JSe,"A",{href:!0});var dTt=s(jQ);_1r=r(dTt,"TFBlenderbotSmallForConditionalGeneration"),dTt.forEach(t),b1r=r(JSe," (BlenderbotSmall model)"),JSe.forEach(t),v1r=i(Be),J4=n(Be,"LI",{});var YSe=s(J4);gbe=n(YSe,"STRONG",{});var cTt=s(gbe);F1r=r(cTt,"encoder-decoder"),cTt.forEach(t),T1r=r(YSe," \u2014 "),DQ=n(YSe,"A",{href:!0});var fTt=s(DQ);M1r=r(fTt,"TFEncoderDecoderModel"),fTt.forEach(t),E1r=r(YSe," (Encoder decoder model)"),YSe.forEach(t),C1r=i(Be),Y4=n(Be,"LI",{});var KSe=s(Y4);hbe=n(KSe,"STRONG",{});var mTt=s(hbe);w1r=r(mTt,"led"),mTt.forEach(t),A1r=r(KSe," \u2014 "),GQ=n(KSe,"A",{href:!0});var gTt=s(GQ);y1r=r(gTt,"TFLEDForConditionalGeneration"),gTt.forEach(t),L1r=r(KSe," (LED model)"),KSe.forEach(t),x1r=i(Be),K4=n(Be,"LI",{});var ZSe=s(K4);pbe=n(ZSe,"STRONG",{});var hTt=s(pbe);$1r=r(hTt,"marian"),hTt.forEach(t),k1r=r(ZSe," \u2014 "),OQ=n(ZSe,"A",{href:!0});var pTt=s(OQ);S1r=r(pTt,"TFMarianMTModel"),pTt.forEach(t),R1r=r(ZSe," (Marian model)"),ZSe.forEach(t),P1r=i(Be),Z4=n(Be,"LI",{});var eRe=s(Z4);ube=n(eRe,"STRONG",{});var uTt=s(ube);B1r=r(uTt,"mbart"),uTt.forEach(t),I1r=r(eRe," \u2014 "),VQ=n(eRe,"A",{href:!0});var _Tt=s(VQ);q1r=r(_Tt,"TFMBartForConditionalGeneration"),_Tt.forEach(t),N1r=r(eRe," (mBART model)"),eRe.forEach(t),j1r=i(Be),eE=n(Be,"LI",{});var oRe=s(eE);_be=n(oRe,"STRONG",{});var bTt=s(_be);D1r=r(bTt,"mt5"),bTt.forEach(t),G1r=r(oRe," \u2014 "),XQ=n(oRe,"A",{href:!0});var vTt=s(XQ);O1r=r(vTt,"TFMT5ForConditionalGeneration"),vTt.forEach(t),V1r=r(oRe," (mT5 model)"),oRe.forEach(t),X1r=i(Be),oE=n(Be,"LI",{});var rRe=s(oE);bbe=n(rRe,"STRONG",{});var FTt=s(bbe);z1r=r(FTt,"pegasus"),FTt.forEach(t),W1r=r(rRe," \u2014 "),zQ=n(rRe,"A",{href:!0});var TTt=s(zQ);Q1r=r(TTt,"TFPegasusForConditionalGeneration"),TTt.forEach(t),H1r=r(rRe," (Pegasus model)"),rRe.forEach(t),U1r=i(Be),rE=n(Be,"LI",{});var tRe=s(rE);vbe=n(tRe,"STRONG",{});var MTt=s(vbe);J1r=r(MTt,"t5"),MTt.forEach(t),Y1r=r(tRe," \u2014 "),WQ=n(tRe,"A",{href:!0});var ETt=s(WQ);K1r=r(ETt,"TFT5ForConditionalGeneration"),ETt.forEach(t),Z1r=r(tRe," (T5 model)"),tRe.forEach(t),Be.forEach(t),e7r=i(El),T(tE.$$.fragment,El),El.forEach(t),Ml.forEach(t),eNe=i(f),ac=n(f,"H2",{class:!0});var sDe=s(ac);aE=n(sDe,"A",{id:!0,class:!0,href:!0});var CTt=s(aE);Fbe=n(CTt,"SPAN",{});var wTt=s(Fbe);T(T8.$$.fragment,wTt),wTt.forEach(t),CTt.forEach(t),o7r=i(sDe),Tbe=n(sDe,"SPAN",{});var ATt=s(Tbe);r7r=r(ATt,"TFAutoModelForSequenceClassification"),ATt.forEach(t),sDe.forEach(t),oNe=i(f),tr=n(f,"DIV",{class:!0});var Cl=s(tr);T(M8.$$.fragment,Cl),t7r=i(Cl),nc=n(Cl,"P",{});var NZ=s(nc);a7r=r(NZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),QQ=n(NZ,"A",{href:!0});var yTt=s(QQ);n7r=r(yTt,"from_pretrained()"),yTt.forEach(t),s7r=r(NZ," class method or the "),HQ=n(NZ,"A",{href:!0});var LTt=s(HQ);l7r=r(LTt,"from_config()"),LTt.forEach(t),i7r=r(NZ,` class
method.`),NZ.forEach(t),d7r=i(Cl),E8=n(Cl,"P",{});var lDe=s(E8);c7r=r(lDe,"This class cannot be instantiated directly using "),Mbe=n(lDe,"CODE",{});var xTt=s(Mbe);f7r=r(xTt,"__init__()"),xTt.forEach(t),m7r=r(lDe," (throws an error)."),lDe.forEach(t),g7r=i(Cl),Rt=n(Cl,"DIV",{class:!0});var F0=s(Rt);T(C8.$$.fragment,F0),h7r=i(F0),Ebe=n(F0,"P",{});var $Tt=s(Ebe);p7r=r($Tt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),$Tt.forEach(t),u7r=i(F0),sc=n(F0,"P",{});var jZ=s(sc);_7r=r(jZ,`Note:
Loading a model from its configuration file does `),Cbe=n(jZ,"STRONG",{});var kTt=s(Cbe);b7r=r(kTt,"not"),kTt.forEach(t),v7r=r(jZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),UQ=n(jZ,"A",{href:!0});var STt=s(UQ);F7r=r(STt,"from_pretrained()"),STt.forEach(t),T7r=r(jZ," to load the model weights."),jZ.forEach(t),M7r=i(F0),T(nE.$$.fragment,F0),F0.forEach(t),E7r=i(Cl),kr=n(Cl,"DIV",{class:!0});var wl=s(kr);T(w8.$$.fragment,wl),C7r=i(wl),wbe=n(wl,"P",{});var RTt=s(wbe);w7r=r(RTt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),RTt.forEach(t),A7r=i(wl),nn=n(wl,"P",{});var T0=s(nn);y7r=r(T0,"The model class to instantiate is selected based on the "),Abe=n(T0,"CODE",{});var PTt=s(Abe);L7r=r(PTt,"model_type"),PTt.forEach(t),x7r=r(T0,` property of the config object (either
passed as an argument or loaded from `),ybe=n(T0,"CODE",{});var BTt=s(ybe);$7r=r(BTt,"pretrained_model_name_or_path"),BTt.forEach(t),k7r=r(T0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lbe=n(T0,"CODE",{});var ITt=s(Lbe);S7r=r(ITt,"pretrained_model_name_or_path"),ITt.forEach(t),R7r=r(T0,":"),T0.forEach(t),P7r=i(wl),ee=n(wl,"UL",{});var ae=s(ee);sE=n(ae,"LI",{});var aRe=s(sE);xbe=n(aRe,"STRONG",{});var qTt=s(xbe);B7r=r(qTt,"albert"),qTt.forEach(t),I7r=r(aRe," \u2014 "),JQ=n(aRe,"A",{href:!0});var NTt=s(JQ);q7r=r(NTt,"TFAlbertForSequenceClassification"),NTt.forEach(t),N7r=r(aRe," (ALBERT model)"),aRe.forEach(t),j7r=i(ae),lE=n(ae,"LI",{});var nRe=s(lE);$be=n(nRe,"STRONG",{});var jTt=s($be);D7r=r(jTt,"bert"),jTt.forEach(t),G7r=r(nRe," \u2014 "),YQ=n(nRe,"A",{href:!0});var DTt=s(YQ);O7r=r(DTt,"TFBertForSequenceClassification"),DTt.forEach(t),V7r=r(nRe," (BERT model)"),nRe.forEach(t),X7r=i(ae),iE=n(ae,"LI",{});var sRe=s(iE);kbe=n(sRe,"STRONG",{});var GTt=s(kbe);z7r=r(GTt,"camembert"),GTt.forEach(t),W7r=r(sRe," \u2014 "),KQ=n(sRe,"A",{href:!0});var OTt=s(KQ);Q7r=r(OTt,"TFCamembertForSequenceClassification"),OTt.forEach(t),H7r=r(sRe," (CamemBERT model)"),sRe.forEach(t),U7r=i(ae),dE=n(ae,"LI",{});var lRe=s(dE);Sbe=n(lRe,"STRONG",{});var VTt=s(Sbe);J7r=r(VTt,"convbert"),VTt.forEach(t),Y7r=r(lRe," \u2014 "),ZQ=n(lRe,"A",{href:!0});var XTt=s(ZQ);K7r=r(XTt,"TFConvBertForSequenceClassification"),XTt.forEach(t),Z7r=r(lRe," (ConvBERT model)"),lRe.forEach(t),ebr=i(ae),cE=n(ae,"LI",{});var iRe=s(cE);Rbe=n(iRe,"STRONG",{});var zTt=s(Rbe);obr=r(zTt,"ctrl"),zTt.forEach(t),rbr=r(iRe," \u2014 "),eH=n(iRe,"A",{href:!0});var WTt=s(eH);tbr=r(WTt,"TFCTRLForSequenceClassification"),WTt.forEach(t),abr=r(iRe," (CTRL model)"),iRe.forEach(t),nbr=i(ae),fE=n(ae,"LI",{});var dRe=s(fE);Pbe=n(dRe,"STRONG",{});var QTt=s(Pbe);sbr=r(QTt,"deberta"),QTt.forEach(t),lbr=r(dRe," \u2014 "),oH=n(dRe,"A",{href:!0});var HTt=s(oH);ibr=r(HTt,"TFDebertaForSequenceClassification"),HTt.forEach(t),dbr=r(dRe," (DeBERTa model)"),dRe.forEach(t),cbr=i(ae),mE=n(ae,"LI",{});var cRe=s(mE);Bbe=n(cRe,"STRONG",{});var UTt=s(Bbe);fbr=r(UTt,"deberta-v2"),UTt.forEach(t),mbr=r(cRe," \u2014 "),rH=n(cRe,"A",{href:!0});var JTt=s(rH);gbr=r(JTt,"TFDebertaV2ForSequenceClassification"),JTt.forEach(t),hbr=r(cRe," (DeBERTa-v2 model)"),cRe.forEach(t),pbr=i(ae),gE=n(ae,"LI",{});var fRe=s(gE);Ibe=n(fRe,"STRONG",{});var YTt=s(Ibe);ubr=r(YTt,"distilbert"),YTt.forEach(t),_br=r(fRe," \u2014 "),tH=n(fRe,"A",{href:!0});var KTt=s(tH);bbr=r(KTt,"TFDistilBertForSequenceClassification"),KTt.forEach(t),vbr=r(fRe," (DistilBERT model)"),fRe.forEach(t),Fbr=i(ae),hE=n(ae,"LI",{});var mRe=s(hE);qbe=n(mRe,"STRONG",{});var ZTt=s(qbe);Tbr=r(ZTt,"electra"),ZTt.forEach(t),Mbr=r(mRe," \u2014 "),aH=n(mRe,"A",{href:!0});var eMt=s(aH);Ebr=r(eMt,"TFElectraForSequenceClassification"),eMt.forEach(t),Cbr=r(mRe," (ELECTRA model)"),mRe.forEach(t),wbr=i(ae),pE=n(ae,"LI",{});var gRe=s(pE);Nbe=n(gRe,"STRONG",{});var oMt=s(Nbe);Abr=r(oMt,"flaubert"),oMt.forEach(t),ybr=r(gRe," \u2014 "),nH=n(gRe,"A",{href:!0});var rMt=s(nH);Lbr=r(rMt,"TFFlaubertForSequenceClassification"),rMt.forEach(t),xbr=r(gRe," (FlauBERT model)"),gRe.forEach(t),$br=i(ae),uE=n(ae,"LI",{});var hRe=s(uE);jbe=n(hRe,"STRONG",{});var tMt=s(jbe);kbr=r(tMt,"funnel"),tMt.forEach(t),Sbr=r(hRe," \u2014 "),sH=n(hRe,"A",{href:!0});var aMt=s(sH);Rbr=r(aMt,"TFFunnelForSequenceClassification"),aMt.forEach(t),Pbr=r(hRe," (Funnel Transformer model)"),hRe.forEach(t),Bbr=i(ae),_E=n(ae,"LI",{});var pRe=s(_E);Dbe=n(pRe,"STRONG",{});var nMt=s(Dbe);Ibr=r(nMt,"gpt2"),nMt.forEach(t),qbr=r(pRe," \u2014 "),lH=n(pRe,"A",{href:!0});var sMt=s(lH);Nbr=r(sMt,"TFGPT2ForSequenceClassification"),sMt.forEach(t),jbr=r(pRe," (OpenAI GPT-2 model)"),pRe.forEach(t),Dbr=i(ae),bE=n(ae,"LI",{});var uRe=s(bE);Gbe=n(uRe,"STRONG",{});var lMt=s(Gbe);Gbr=r(lMt,"gptj"),lMt.forEach(t),Obr=r(uRe," \u2014 "),iH=n(uRe,"A",{href:!0});var iMt=s(iH);Vbr=r(iMt,"TFGPTJForSequenceClassification"),iMt.forEach(t),Xbr=r(uRe," (GPT-J model)"),uRe.forEach(t),zbr=i(ae),vE=n(ae,"LI",{});var _Re=s(vE);Obe=n(_Re,"STRONG",{});var dMt=s(Obe);Wbr=r(dMt,"layoutlm"),dMt.forEach(t),Qbr=r(_Re," \u2014 "),dH=n(_Re,"A",{href:!0});var cMt=s(dH);Hbr=r(cMt,"TFLayoutLMForSequenceClassification"),cMt.forEach(t),Ubr=r(_Re," (LayoutLM model)"),_Re.forEach(t),Jbr=i(ae),FE=n(ae,"LI",{});var bRe=s(FE);Vbe=n(bRe,"STRONG",{});var fMt=s(Vbe);Ybr=r(fMt,"longformer"),fMt.forEach(t),Kbr=r(bRe," \u2014 "),cH=n(bRe,"A",{href:!0});var mMt=s(cH);Zbr=r(mMt,"TFLongformerForSequenceClassification"),mMt.forEach(t),evr=r(bRe," (Longformer model)"),bRe.forEach(t),ovr=i(ae),TE=n(ae,"LI",{});var vRe=s(TE);Xbe=n(vRe,"STRONG",{});var gMt=s(Xbe);rvr=r(gMt,"mobilebert"),gMt.forEach(t),tvr=r(vRe," \u2014 "),fH=n(vRe,"A",{href:!0});var hMt=s(fH);avr=r(hMt,"TFMobileBertForSequenceClassification"),hMt.forEach(t),nvr=r(vRe," (MobileBERT model)"),vRe.forEach(t),svr=i(ae),ME=n(ae,"LI",{});var FRe=s(ME);zbe=n(FRe,"STRONG",{});var pMt=s(zbe);lvr=r(pMt,"mpnet"),pMt.forEach(t),ivr=r(FRe," \u2014 "),mH=n(FRe,"A",{href:!0});var uMt=s(mH);dvr=r(uMt,"TFMPNetForSequenceClassification"),uMt.forEach(t),cvr=r(FRe," (MPNet model)"),FRe.forEach(t),fvr=i(ae),EE=n(ae,"LI",{});var TRe=s(EE);Wbe=n(TRe,"STRONG",{});var _Mt=s(Wbe);mvr=r(_Mt,"openai-gpt"),_Mt.forEach(t),gvr=r(TRe," \u2014 "),gH=n(TRe,"A",{href:!0});var bMt=s(gH);hvr=r(bMt,"TFOpenAIGPTForSequenceClassification"),bMt.forEach(t),pvr=r(TRe," (OpenAI GPT model)"),TRe.forEach(t),uvr=i(ae),CE=n(ae,"LI",{});var MRe=s(CE);Qbe=n(MRe,"STRONG",{});var vMt=s(Qbe);_vr=r(vMt,"rembert"),vMt.forEach(t),bvr=r(MRe," \u2014 "),hH=n(MRe,"A",{href:!0});var FMt=s(hH);vvr=r(FMt,"TFRemBertForSequenceClassification"),FMt.forEach(t),Fvr=r(MRe," (RemBERT model)"),MRe.forEach(t),Tvr=i(ae),wE=n(ae,"LI",{});var ERe=s(wE);Hbe=n(ERe,"STRONG",{});var TMt=s(Hbe);Mvr=r(TMt,"roberta"),TMt.forEach(t),Evr=r(ERe," \u2014 "),pH=n(ERe,"A",{href:!0});var MMt=s(pH);Cvr=r(MMt,"TFRobertaForSequenceClassification"),MMt.forEach(t),wvr=r(ERe," (RoBERTa model)"),ERe.forEach(t),Avr=i(ae),AE=n(ae,"LI",{});var CRe=s(AE);Ube=n(CRe,"STRONG",{});var EMt=s(Ube);yvr=r(EMt,"roformer"),EMt.forEach(t),Lvr=r(CRe," \u2014 "),uH=n(CRe,"A",{href:!0});var CMt=s(uH);xvr=r(CMt,"TFRoFormerForSequenceClassification"),CMt.forEach(t),$vr=r(CRe," (RoFormer model)"),CRe.forEach(t),kvr=i(ae),yE=n(ae,"LI",{});var wRe=s(yE);Jbe=n(wRe,"STRONG",{});var wMt=s(Jbe);Svr=r(wMt,"tapas"),wMt.forEach(t),Rvr=r(wRe," \u2014 "),_H=n(wRe,"A",{href:!0});var AMt=s(_H);Pvr=r(AMt,"TFTapasForSequenceClassification"),AMt.forEach(t),Bvr=r(wRe," (TAPAS model)"),wRe.forEach(t),Ivr=i(ae),LE=n(ae,"LI",{});var ARe=s(LE);Ybe=n(ARe,"STRONG",{});var yMt=s(Ybe);qvr=r(yMt,"transfo-xl"),yMt.forEach(t),Nvr=r(ARe," \u2014 "),bH=n(ARe,"A",{href:!0});var LMt=s(bH);jvr=r(LMt,"TFTransfoXLForSequenceClassification"),LMt.forEach(t),Dvr=r(ARe," (Transformer-XL model)"),ARe.forEach(t),Gvr=i(ae),xE=n(ae,"LI",{});var yRe=s(xE);Kbe=n(yRe,"STRONG",{});var xMt=s(Kbe);Ovr=r(xMt,"xlm"),xMt.forEach(t),Vvr=r(yRe," \u2014 "),vH=n(yRe,"A",{href:!0});var $Mt=s(vH);Xvr=r($Mt,"TFXLMForSequenceClassification"),$Mt.forEach(t),zvr=r(yRe," (XLM model)"),yRe.forEach(t),Wvr=i(ae),$E=n(ae,"LI",{});var LRe=s($E);Zbe=n(LRe,"STRONG",{});var kMt=s(Zbe);Qvr=r(kMt,"xlm-roberta"),kMt.forEach(t),Hvr=r(LRe," \u2014 "),FH=n(LRe,"A",{href:!0});var SMt=s(FH);Uvr=r(SMt,"TFXLMRobertaForSequenceClassification"),SMt.forEach(t),Jvr=r(LRe," (XLM-RoBERTa model)"),LRe.forEach(t),Yvr=i(ae),kE=n(ae,"LI",{});var xRe=s(kE);eve=n(xRe,"STRONG",{});var RMt=s(eve);Kvr=r(RMt,"xlnet"),RMt.forEach(t),Zvr=r(xRe," \u2014 "),TH=n(xRe,"A",{href:!0});var PMt=s(TH);eFr=r(PMt,"TFXLNetForSequenceClassification"),PMt.forEach(t),oFr=r(xRe," (XLNet model)"),xRe.forEach(t),ae.forEach(t),rFr=i(wl),T(SE.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),rNe=i(f),lc=n(f,"H2",{class:!0});var iDe=s(lc);RE=n(iDe,"A",{id:!0,class:!0,href:!0});var BMt=s(RE);ove=n(BMt,"SPAN",{});var IMt=s(ove);T(A8.$$.fragment,IMt),IMt.forEach(t),BMt.forEach(t),tFr=i(iDe),rve=n(iDe,"SPAN",{});var qMt=s(rve);aFr=r(qMt,"TFAutoModelForMultipleChoice"),qMt.forEach(t),iDe.forEach(t),tNe=i(f),ar=n(f,"DIV",{class:!0});var Al=s(ar);T(y8.$$.fragment,Al),nFr=i(Al),ic=n(Al,"P",{});var DZ=s(ic);sFr=r(DZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),MH=n(DZ,"A",{href:!0});var NMt=s(MH);lFr=r(NMt,"from_pretrained()"),NMt.forEach(t),iFr=r(DZ," class method or the "),EH=n(DZ,"A",{href:!0});var jMt=s(EH);dFr=r(jMt,"from_config()"),jMt.forEach(t),cFr=r(DZ,` class
method.`),DZ.forEach(t),fFr=i(Al),L8=n(Al,"P",{});var dDe=s(L8);mFr=r(dDe,"This class cannot be instantiated directly using "),tve=n(dDe,"CODE",{});var DMt=s(tve);gFr=r(DMt,"__init__()"),DMt.forEach(t),hFr=r(dDe," (throws an error)."),dDe.forEach(t),pFr=i(Al),Pt=n(Al,"DIV",{class:!0});var M0=s(Pt);T(x8.$$.fragment,M0),uFr=i(M0),ave=n(M0,"P",{});var GMt=s(ave);_Fr=r(GMt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),GMt.forEach(t),bFr=i(M0),dc=n(M0,"P",{});var GZ=s(dc);vFr=r(GZ,`Note:
Loading a model from its configuration file does `),nve=n(GZ,"STRONG",{});var OMt=s(nve);FFr=r(OMt,"not"),OMt.forEach(t),TFr=r(GZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),CH=n(GZ,"A",{href:!0});var VMt=s(CH);MFr=r(VMt,"from_pretrained()"),VMt.forEach(t),EFr=r(GZ," to load the model weights."),GZ.forEach(t),CFr=i(M0),T(PE.$$.fragment,M0),M0.forEach(t),wFr=i(Al),Sr=n(Al,"DIV",{class:!0});var yl=s(Sr);T($8.$$.fragment,yl),AFr=i(yl),sve=n(yl,"P",{});var XMt=s(sve);yFr=r(XMt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),XMt.forEach(t),LFr=i(yl),sn=n(yl,"P",{});var E0=s(sn);xFr=r(E0,"The model class to instantiate is selected based on the "),lve=n(E0,"CODE",{});var zMt=s(lve);$Fr=r(zMt,"model_type"),zMt.forEach(t),kFr=r(E0,` property of the config object (either
passed as an argument or loaded from `),ive=n(E0,"CODE",{});var WMt=s(ive);SFr=r(WMt,"pretrained_model_name_or_path"),WMt.forEach(t),RFr=r(E0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dve=n(E0,"CODE",{});var QMt=s(dve);PFr=r(QMt,"pretrained_model_name_or_path"),QMt.forEach(t),BFr=r(E0,":"),E0.forEach(t),IFr=i(yl),he=n(yl,"UL",{});var _e=s(he);BE=n(_e,"LI",{});var $Re=s(BE);cve=n($Re,"STRONG",{});var HMt=s(cve);qFr=r(HMt,"albert"),HMt.forEach(t),NFr=r($Re," \u2014 "),wH=n($Re,"A",{href:!0});var UMt=s(wH);jFr=r(UMt,"TFAlbertForMultipleChoice"),UMt.forEach(t),DFr=r($Re," (ALBERT model)"),$Re.forEach(t),GFr=i(_e),IE=n(_e,"LI",{});var kRe=s(IE);fve=n(kRe,"STRONG",{});var JMt=s(fve);OFr=r(JMt,"bert"),JMt.forEach(t),VFr=r(kRe," \u2014 "),AH=n(kRe,"A",{href:!0});var YMt=s(AH);XFr=r(YMt,"TFBertForMultipleChoice"),YMt.forEach(t),zFr=r(kRe," (BERT model)"),kRe.forEach(t),WFr=i(_e),qE=n(_e,"LI",{});var SRe=s(qE);mve=n(SRe,"STRONG",{});var KMt=s(mve);QFr=r(KMt,"camembert"),KMt.forEach(t),HFr=r(SRe," \u2014 "),yH=n(SRe,"A",{href:!0});var ZMt=s(yH);UFr=r(ZMt,"TFCamembertForMultipleChoice"),ZMt.forEach(t),JFr=r(SRe," (CamemBERT model)"),SRe.forEach(t),YFr=i(_e),NE=n(_e,"LI",{});var RRe=s(NE);gve=n(RRe,"STRONG",{});var e4t=s(gve);KFr=r(e4t,"convbert"),e4t.forEach(t),ZFr=r(RRe," \u2014 "),LH=n(RRe,"A",{href:!0});var o4t=s(LH);eTr=r(o4t,"TFConvBertForMultipleChoice"),o4t.forEach(t),oTr=r(RRe," (ConvBERT model)"),RRe.forEach(t),rTr=i(_e),jE=n(_e,"LI",{});var PRe=s(jE);hve=n(PRe,"STRONG",{});var r4t=s(hve);tTr=r(r4t,"distilbert"),r4t.forEach(t),aTr=r(PRe," \u2014 "),xH=n(PRe,"A",{href:!0});var t4t=s(xH);nTr=r(t4t,"TFDistilBertForMultipleChoice"),t4t.forEach(t),sTr=r(PRe," (DistilBERT model)"),PRe.forEach(t),lTr=i(_e),DE=n(_e,"LI",{});var BRe=s(DE);pve=n(BRe,"STRONG",{});var a4t=s(pve);iTr=r(a4t,"electra"),a4t.forEach(t),dTr=r(BRe," \u2014 "),$H=n(BRe,"A",{href:!0});var n4t=s($H);cTr=r(n4t,"TFElectraForMultipleChoice"),n4t.forEach(t),fTr=r(BRe," (ELECTRA model)"),BRe.forEach(t),mTr=i(_e),GE=n(_e,"LI",{});var IRe=s(GE);uve=n(IRe,"STRONG",{});var s4t=s(uve);gTr=r(s4t,"flaubert"),s4t.forEach(t),hTr=r(IRe," \u2014 "),kH=n(IRe,"A",{href:!0});var l4t=s(kH);pTr=r(l4t,"TFFlaubertForMultipleChoice"),l4t.forEach(t),uTr=r(IRe," (FlauBERT model)"),IRe.forEach(t),_Tr=i(_e),OE=n(_e,"LI",{});var qRe=s(OE);_ve=n(qRe,"STRONG",{});var i4t=s(_ve);bTr=r(i4t,"funnel"),i4t.forEach(t),vTr=r(qRe," \u2014 "),SH=n(qRe,"A",{href:!0});var d4t=s(SH);FTr=r(d4t,"TFFunnelForMultipleChoice"),d4t.forEach(t),TTr=r(qRe," (Funnel Transformer model)"),qRe.forEach(t),MTr=i(_e),VE=n(_e,"LI",{});var NRe=s(VE);bve=n(NRe,"STRONG",{});var c4t=s(bve);ETr=r(c4t,"longformer"),c4t.forEach(t),CTr=r(NRe," \u2014 "),RH=n(NRe,"A",{href:!0});var f4t=s(RH);wTr=r(f4t,"TFLongformerForMultipleChoice"),f4t.forEach(t),ATr=r(NRe," (Longformer model)"),NRe.forEach(t),yTr=i(_e),XE=n(_e,"LI",{});var jRe=s(XE);vve=n(jRe,"STRONG",{});var m4t=s(vve);LTr=r(m4t,"mobilebert"),m4t.forEach(t),xTr=r(jRe," \u2014 "),PH=n(jRe,"A",{href:!0});var g4t=s(PH);$Tr=r(g4t,"TFMobileBertForMultipleChoice"),g4t.forEach(t),kTr=r(jRe," (MobileBERT model)"),jRe.forEach(t),STr=i(_e),zE=n(_e,"LI",{});var DRe=s(zE);Fve=n(DRe,"STRONG",{});var h4t=s(Fve);RTr=r(h4t,"mpnet"),h4t.forEach(t),PTr=r(DRe," \u2014 "),BH=n(DRe,"A",{href:!0});var p4t=s(BH);BTr=r(p4t,"TFMPNetForMultipleChoice"),p4t.forEach(t),ITr=r(DRe," (MPNet model)"),DRe.forEach(t),qTr=i(_e),WE=n(_e,"LI",{});var GRe=s(WE);Tve=n(GRe,"STRONG",{});var u4t=s(Tve);NTr=r(u4t,"rembert"),u4t.forEach(t),jTr=r(GRe," \u2014 "),IH=n(GRe,"A",{href:!0});var _4t=s(IH);DTr=r(_4t,"TFRemBertForMultipleChoice"),_4t.forEach(t),GTr=r(GRe," (RemBERT model)"),GRe.forEach(t),OTr=i(_e),QE=n(_e,"LI",{});var ORe=s(QE);Mve=n(ORe,"STRONG",{});var b4t=s(Mve);VTr=r(b4t,"roberta"),b4t.forEach(t),XTr=r(ORe," \u2014 "),qH=n(ORe,"A",{href:!0});var v4t=s(qH);zTr=r(v4t,"TFRobertaForMultipleChoice"),v4t.forEach(t),WTr=r(ORe," (RoBERTa model)"),ORe.forEach(t),QTr=i(_e),HE=n(_e,"LI",{});var VRe=s(HE);Eve=n(VRe,"STRONG",{});var F4t=s(Eve);HTr=r(F4t,"roformer"),F4t.forEach(t),UTr=r(VRe," \u2014 "),NH=n(VRe,"A",{href:!0});var T4t=s(NH);JTr=r(T4t,"TFRoFormerForMultipleChoice"),T4t.forEach(t),YTr=r(VRe," (RoFormer model)"),VRe.forEach(t),KTr=i(_e),UE=n(_e,"LI",{});var XRe=s(UE);Cve=n(XRe,"STRONG",{});var M4t=s(Cve);ZTr=r(M4t,"xlm"),M4t.forEach(t),eMr=r(XRe," \u2014 "),jH=n(XRe,"A",{href:!0});var E4t=s(jH);oMr=r(E4t,"TFXLMForMultipleChoice"),E4t.forEach(t),rMr=r(XRe," (XLM model)"),XRe.forEach(t),tMr=i(_e),JE=n(_e,"LI",{});var zRe=s(JE);wve=n(zRe,"STRONG",{});var C4t=s(wve);aMr=r(C4t,"xlm-roberta"),C4t.forEach(t),nMr=r(zRe," \u2014 "),DH=n(zRe,"A",{href:!0});var w4t=s(DH);sMr=r(w4t,"TFXLMRobertaForMultipleChoice"),w4t.forEach(t),lMr=r(zRe," (XLM-RoBERTa model)"),zRe.forEach(t),iMr=i(_e),YE=n(_e,"LI",{});var WRe=s(YE);Ave=n(WRe,"STRONG",{});var A4t=s(Ave);dMr=r(A4t,"xlnet"),A4t.forEach(t),cMr=r(WRe," \u2014 "),GH=n(WRe,"A",{href:!0});var y4t=s(GH);fMr=r(y4t,"TFXLNetForMultipleChoice"),y4t.forEach(t),mMr=r(WRe," (XLNet model)"),WRe.forEach(t),_e.forEach(t),gMr=i(yl),T(KE.$$.fragment,yl),yl.forEach(t),Al.forEach(t),aNe=i(f),cc=n(f,"H2",{class:!0});var cDe=s(cc);ZE=n(cDe,"A",{id:!0,class:!0,href:!0});var L4t=s(ZE);yve=n(L4t,"SPAN",{});var x4t=s(yve);T(k8.$$.fragment,x4t),x4t.forEach(t),L4t.forEach(t),hMr=i(cDe),Lve=n(cDe,"SPAN",{});var $4t=s(Lve);pMr=r($4t,"TFAutoModelForNextSentencePrediction"),$4t.forEach(t),cDe.forEach(t),nNe=i(f),nr=n(f,"DIV",{class:!0});var Ll=s(nr);T(S8.$$.fragment,Ll),uMr=i(Ll),fc=n(Ll,"P",{});var OZ=s(fc);_Mr=r(OZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OH=n(OZ,"A",{href:!0});var k4t=s(OH);bMr=r(k4t,"from_pretrained()"),k4t.forEach(t),vMr=r(OZ," class method or the "),VH=n(OZ,"A",{href:!0});var S4t=s(VH);FMr=r(S4t,"from_config()"),S4t.forEach(t),TMr=r(OZ,` class
method.`),OZ.forEach(t),MMr=i(Ll),R8=n(Ll,"P",{});var fDe=s(R8);EMr=r(fDe,"This class cannot be instantiated directly using "),xve=n(fDe,"CODE",{});var R4t=s(xve);CMr=r(R4t,"__init__()"),R4t.forEach(t),wMr=r(fDe," (throws an error)."),fDe.forEach(t),AMr=i(Ll),Bt=n(Ll,"DIV",{class:!0});var C0=s(Bt);T(P8.$$.fragment,C0),yMr=i(C0),$ve=n(C0,"P",{});var P4t=s($ve);LMr=r(P4t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),P4t.forEach(t),xMr=i(C0),mc=n(C0,"P",{});var VZ=s(mc);$Mr=r(VZ,`Note:
Loading a model from its configuration file does `),kve=n(VZ,"STRONG",{});var B4t=s(kve);kMr=r(B4t,"not"),B4t.forEach(t),SMr=r(VZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=n(VZ,"A",{href:!0});var I4t=s(XH);RMr=r(I4t,"from_pretrained()"),I4t.forEach(t),PMr=r(VZ," to load the model weights."),VZ.forEach(t),BMr=i(C0),T(eC.$$.fragment,C0),C0.forEach(t),IMr=i(Ll),Rr=n(Ll,"DIV",{class:!0});var xl=s(Rr);T(B8.$$.fragment,xl),qMr=i(xl),Sve=n(xl,"P",{});var q4t=s(Sve);NMr=r(q4t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),q4t.forEach(t),jMr=i(xl),ln=n(xl,"P",{});var w0=s(ln);DMr=r(w0,"The model class to instantiate is selected based on the "),Rve=n(w0,"CODE",{});var N4t=s(Rve);GMr=r(N4t,"model_type"),N4t.forEach(t),OMr=r(w0,` property of the config object (either
passed as an argument or loaded from `),Pve=n(w0,"CODE",{});var j4t=s(Pve);VMr=r(j4t,"pretrained_model_name_or_path"),j4t.forEach(t),XMr=r(w0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bve=n(w0,"CODE",{});var D4t=s(Bve);zMr=r(D4t,"pretrained_model_name_or_path"),D4t.forEach(t),WMr=r(w0,":"),w0.forEach(t),QMr=i(xl),I8=n(xl,"UL",{});var mDe=s(I8);oC=n(mDe,"LI",{});var QRe=s(oC);Ive=n(QRe,"STRONG",{});var G4t=s(Ive);HMr=r(G4t,"bert"),G4t.forEach(t),UMr=r(QRe," \u2014 "),zH=n(QRe,"A",{href:!0});var O4t=s(zH);JMr=r(O4t,"TFBertForNextSentencePrediction"),O4t.forEach(t),YMr=r(QRe," (BERT model)"),QRe.forEach(t),KMr=i(mDe),rC=n(mDe,"LI",{});var HRe=s(rC);qve=n(HRe,"STRONG",{});var V4t=s(qve);ZMr=r(V4t,"mobilebert"),V4t.forEach(t),e4r=r(HRe," \u2014 "),WH=n(HRe,"A",{href:!0});var X4t=s(WH);o4r=r(X4t,"TFMobileBertForNextSentencePrediction"),X4t.forEach(t),r4r=r(HRe," (MobileBERT model)"),HRe.forEach(t),mDe.forEach(t),t4r=i(xl),T(tC.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),sNe=i(f),gc=n(f,"H2",{class:!0});var gDe=s(gc);aC=n(gDe,"A",{id:!0,class:!0,href:!0});var z4t=s(aC);Nve=n(z4t,"SPAN",{});var W4t=s(Nve);T(q8.$$.fragment,W4t),W4t.forEach(t),z4t.forEach(t),a4r=i(gDe),jve=n(gDe,"SPAN",{});var Q4t=s(jve);n4r=r(Q4t,"TFAutoModelForTableQuestionAnswering"),Q4t.forEach(t),gDe.forEach(t),lNe=i(f),sr=n(f,"DIV",{class:!0});var $l=s(sr);T(N8.$$.fragment,$l),s4r=i($l),hc=n($l,"P",{});var XZ=s(hc);l4r=r(XZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),QH=n(XZ,"A",{href:!0});var H4t=s(QH);i4r=r(H4t,"from_pretrained()"),H4t.forEach(t),d4r=r(XZ," class method or the "),HH=n(XZ,"A",{href:!0});var U4t=s(HH);c4r=r(U4t,"from_config()"),U4t.forEach(t),f4r=r(XZ,` class
method.`),XZ.forEach(t),m4r=i($l),j8=n($l,"P",{});var hDe=s(j8);g4r=r(hDe,"This class cannot be instantiated directly using "),Dve=n(hDe,"CODE",{});var J4t=s(Dve);h4r=r(J4t,"__init__()"),J4t.forEach(t),p4r=r(hDe," (throws an error)."),hDe.forEach(t),u4r=i($l),It=n($l,"DIV",{class:!0});var A0=s(It);T(D8.$$.fragment,A0),_4r=i(A0),Gve=n(A0,"P",{});var Y4t=s(Gve);b4r=r(Y4t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Y4t.forEach(t),v4r=i(A0),pc=n(A0,"P",{});var zZ=s(pc);F4r=r(zZ,`Note:
Loading a model from its configuration file does `),Ove=n(zZ,"STRONG",{});var K4t=s(Ove);T4r=r(K4t,"not"),K4t.forEach(t),M4r=r(zZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),UH=n(zZ,"A",{href:!0});var Z4t=s(UH);E4r=r(Z4t,"from_pretrained()"),Z4t.forEach(t),C4r=r(zZ," to load the model weights."),zZ.forEach(t),w4r=i(A0),T(nC.$$.fragment,A0),A0.forEach(t),A4r=i($l),Pr=n($l,"DIV",{class:!0});var kl=s(Pr);T(G8.$$.fragment,kl),y4r=i(kl),Vve=n(kl,"P",{});var eEt=s(Vve);L4r=r(eEt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eEt.forEach(t),x4r=i(kl),dn=n(kl,"P",{});var y0=s(dn);$4r=r(y0,"The model class to instantiate is selected based on the "),Xve=n(y0,"CODE",{});var oEt=s(Xve);k4r=r(oEt,"model_type"),oEt.forEach(t),S4r=r(y0,` property of the config object (either
passed as an argument or loaded from `),zve=n(y0,"CODE",{});var rEt=s(zve);R4r=r(rEt,"pretrained_model_name_or_path"),rEt.forEach(t),P4r=r(y0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=n(y0,"CODE",{});var tEt=s(Wve);B4r=r(tEt,"pretrained_model_name_or_path"),tEt.forEach(t),I4r=r(y0,":"),y0.forEach(t),q4r=i(kl),Qve=n(kl,"UL",{});var aEt=s(Qve);sC=n(aEt,"LI",{});var URe=s(sC);Hve=n(URe,"STRONG",{});var nEt=s(Hve);N4r=r(nEt,"tapas"),nEt.forEach(t),j4r=r(URe," \u2014 "),JH=n(URe,"A",{href:!0});var sEt=s(JH);D4r=r(sEt,"TFTapasForQuestionAnswering"),sEt.forEach(t),G4r=r(URe," (TAPAS model)"),URe.forEach(t),aEt.forEach(t),O4r=i(kl),T(lC.$$.fragment,kl),kl.forEach(t),$l.forEach(t),iNe=i(f),uc=n(f,"H2",{class:!0});var pDe=s(uc);iC=n(pDe,"A",{id:!0,class:!0,href:!0});var lEt=s(iC);Uve=n(lEt,"SPAN",{});var iEt=s(Uve);T(O8.$$.fragment,iEt),iEt.forEach(t),lEt.forEach(t),V4r=i(pDe),Jve=n(pDe,"SPAN",{});var dEt=s(Jve);X4r=r(dEt,"TFAutoModelForTokenClassification"),dEt.forEach(t),pDe.forEach(t),dNe=i(f),lr=n(f,"DIV",{class:!0});var Sl=s(lr);T(V8.$$.fragment,Sl),z4r=i(Sl),_c=n(Sl,"P",{});var WZ=s(_c);W4r=r(WZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YH=n(WZ,"A",{href:!0});var cEt=s(YH);Q4r=r(cEt,"from_pretrained()"),cEt.forEach(t),H4r=r(WZ," class method or the "),KH=n(WZ,"A",{href:!0});var fEt=s(KH);U4r=r(fEt,"from_config()"),fEt.forEach(t),J4r=r(WZ,` class
method.`),WZ.forEach(t),Y4r=i(Sl),X8=n(Sl,"P",{});var uDe=s(X8);K4r=r(uDe,"This class cannot be instantiated directly using "),Yve=n(uDe,"CODE",{});var mEt=s(Yve);Z4r=r(mEt,"__init__()"),mEt.forEach(t),eEr=r(uDe," (throws an error)."),uDe.forEach(t),oEr=i(Sl),qt=n(Sl,"DIV",{class:!0});var L0=s(qt);T(z8.$$.fragment,L0),rEr=i(L0),Kve=n(L0,"P",{});var gEt=s(Kve);tEr=r(gEt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gEt.forEach(t),aEr=i(L0),bc=n(L0,"P",{});var QZ=s(bc);nEr=r(QZ,`Note:
Loading a model from its configuration file does `),Zve=n(QZ,"STRONG",{});var hEt=s(Zve);sEr=r(hEt,"not"),hEt.forEach(t),lEr=r(QZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=n(QZ,"A",{href:!0});var pEt=s(ZH);iEr=r(pEt,"from_pretrained()"),pEt.forEach(t),dEr=r(QZ," to load the model weights."),QZ.forEach(t),cEr=i(L0),T(dC.$$.fragment,L0),L0.forEach(t),fEr=i(Sl),Br=n(Sl,"DIV",{class:!0});var Rl=s(Br);T(W8.$$.fragment,Rl),mEr=i(Rl),eFe=n(Rl,"P",{});var uEt=s(eFe);gEr=r(uEt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),uEt.forEach(t),hEr=i(Rl),cn=n(Rl,"P",{});var x0=s(cn);pEr=r(x0,"The model class to instantiate is selected based on the "),oFe=n(x0,"CODE",{});var _Et=s(oFe);uEr=r(_Et,"model_type"),_Et.forEach(t),_Er=r(x0,` property of the config object (either
passed as an argument or loaded from `),rFe=n(x0,"CODE",{});var bEt=s(rFe);bEr=r(bEt,"pretrained_model_name_or_path"),bEt.forEach(t),vEr=r(x0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tFe=n(x0,"CODE",{});var vEt=s(tFe);FEr=r(vEt,"pretrained_model_name_or_path"),vEt.forEach(t),TEr=r(x0,":"),x0.forEach(t),MEr=i(Rl),de=n(Rl,"UL",{});var me=s(de);cC=n(me,"LI",{});var JRe=s(cC);aFe=n(JRe,"STRONG",{});var FEt=s(aFe);EEr=r(FEt,"albert"),FEt.forEach(t),CEr=r(JRe," \u2014 "),eU=n(JRe,"A",{href:!0});var TEt=s(eU);wEr=r(TEt,"TFAlbertForTokenClassification"),TEt.forEach(t),AEr=r(JRe," (ALBERT model)"),JRe.forEach(t),yEr=i(me),fC=n(me,"LI",{});var YRe=s(fC);nFe=n(YRe,"STRONG",{});var MEt=s(nFe);LEr=r(MEt,"bert"),MEt.forEach(t),xEr=r(YRe," \u2014 "),oU=n(YRe,"A",{href:!0});var EEt=s(oU);$Er=r(EEt,"TFBertForTokenClassification"),EEt.forEach(t),kEr=r(YRe," (BERT model)"),YRe.forEach(t),SEr=i(me),mC=n(me,"LI",{});var KRe=s(mC);sFe=n(KRe,"STRONG",{});var CEt=s(sFe);REr=r(CEt,"camembert"),CEt.forEach(t),PEr=r(KRe," \u2014 "),rU=n(KRe,"A",{href:!0});var wEt=s(rU);BEr=r(wEt,"TFCamembertForTokenClassification"),wEt.forEach(t),IEr=r(KRe," (CamemBERT model)"),KRe.forEach(t),qEr=i(me),gC=n(me,"LI",{});var ZRe=s(gC);lFe=n(ZRe,"STRONG",{});var AEt=s(lFe);NEr=r(AEt,"convbert"),AEt.forEach(t),jEr=r(ZRe," \u2014 "),tU=n(ZRe,"A",{href:!0});var yEt=s(tU);DEr=r(yEt,"TFConvBertForTokenClassification"),yEt.forEach(t),GEr=r(ZRe," (ConvBERT model)"),ZRe.forEach(t),OEr=i(me),hC=n(me,"LI",{});var ePe=s(hC);iFe=n(ePe,"STRONG",{});var LEt=s(iFe);VEr=r(LEt,"deberta"),LEt.forEach(t),XEr=r(ePe," \u2014 "),aU=n(ePe,"A",{href:!0});var xEt=s(aU);zEr=r(xEt,"TFDebertaForTokenClassification"),xEt.forEach(t),WEr=r(ePe," (DeBERTa model)"),ePe.forEach(t),QEr=i(me),pC=n(me,"LI",{});var oPe=s(pC);dFe=n(oPe,"STRONG",{});var $Et=s(dFe);HEr=r($Et,"deberta-v2"),$Et.forEach(t),UEr=r(oPe," \u2014 "),nU=n(oPe,"A",{href:!0});var kEt=s(nU);JEr=r(kEt,"TFDebertaV2ForTokenClassification"),kEt.forEach(t),YEr=r(oPe," (DeBERTa-v2 model)"),oPe.forEach(t),KEr=i(me),uC=n(me,"LI",{});var rPe=s(uC);cFe=n(rPe,"STRONG",{});var SEt=s(cFe);ZEr=r(SEt,"distilbert"),SEt.forEach(t),eCr=r(rPe," \u2014 "),sU=n(rPe,"A",{href:!0});var REt=s(sU);oCr=r(REt,"TFDistilBertForTokenClassification"),REt.forEach(t),rCr=r(rPe," (DistilBERT model)"),rPe.forEach(t),tCr=i(me),_C=n(me,"LI",{});var tPe=s(_C);fFe=n(tPe,"STRONG",{});var PEt=s(fFe);aCr=r(PEt,"electra"),PEt.forEach(t),nCr=r(tPe," \u2014 "),lU=n(tPe,"A",{href:!0});var BEt=s(lU);sCr=r(BEt,"TFElectraForTokenClassification"),BEt.forEach(t),lCr=r(tPe," (ELECTRA model)"),tPe.forEach(t),iCr=i(me),bC=n(me,"LI",{});var aPe=s(bC);mFe=n(aPe,"STRONG",{});var IEt=s(mFe);dCr=r(IEt,"flaubert"),IEt.forEach(t),cCr=r(aPe," \u2014 "),iU=n(aPe,"A",{href:!0});var qEt=s(iU);fCr=r(qEt,"TFFlaubertForTokenClassification"),qEt.forEach(t),mCr=r(aPe," (FlauBERT model)"),aPe.forEach(t),gCr=i(me),vC=n(me,"LI",{});var nPe=s(vC);gFe=n(nPe,"STRONG",{});var NEt=s(gFe);hCr=r(NEt,"funnel"),NEt.forEach(t),pCr=r(nPe," \u2014 "),dU=n(nPe,"A",{href:!0});var jEt=s(dU);uCr=r(jEt,"TFFunnelForTokenClassification"),jEt.forEach(t),_Cr=r(nPe," (Funnel Transformer model)"),nPe.forEach(t),bCr=i(me),FC=n(me,"LI",{});var sPe=s(FC);hFe=n(sPe,"STRONG",{});var DEt=s(hFe);vCr=r(DEt,"layoutlm"),DEt.forEach(t),FCr=r(sPe," \u2014 "),cU=n(sPe,"A",{href:!0});var GEt=s(cU);TCr=r(GEt,"TFLayoutLMForTokenClassification"),GEt.forEach(t),MCr=r(sPe," (LayoutLM model)"),sPe.forEach(t),ECr=i(me),TC=n(me,"LI",{});var lPe=s(TC);pFe=n(lPe,"STRONG",{});var OEt=s(pFe);CCr=r(OEt,"longformer"),OEt.forEach(t),wCr=r(lPe," \u2014 "),fU=n(lPe,"A",{href:!0});var VEt=s(fU);ACr=r(VEt,"TFLongformerForTokenClassification"),VEt.forEach(t),yCr=r(lPe," (Longformer model)"),lPe.forEach(t),LCr=i(me),MC=n(me,"LI",{});var iPe=s(MC);uFe=n(iPe,"STRONG",{});var XEt=s(uFe);xCr=r(XEt,"mobilebert"),XEt.forEach(t),$Cr=r(iPe," \u2014 "),mU=n(iPe,"A",{href:!0});var zEt=s(mU);kCr=r(zEt,"TFMobileBertForTokenClassification"),zEt.forEach(t),SCr=r(iPe," (MobileBERT model)"),iPe.forEach(t),RCr=i(me),EC=n(me,"LI",{});var dPe=s(EC);_Fe=n(dPe,"STRONG",{});var WEt=s(_Fe);PCr=r(WEt,"mpnet"),WEt.forEach(t),BCr=r(dPe," \u2014 "),gU=n(dPe,"A",{href:!0});var QEt=s(gU);ICr=r(QEt,"TFMPNetForTokenClassification"),QEt.forEach(t),qCr=r(dPe," (MPNet model)"),dPe.forEach(t),NCr=i(me),CC=n(me,"LI",{});var cPe=s(CC);bFe=n(cPe,"STRONG",{});var HEt=s(bFe);jCr=r(HEt,"rembert"),HEt.forEach(t),DCr=r(cPe," \u2014 "),hU=n(cPe,"A",{href:!0});var UEt=s(hU);GCr=r(UEt,"TFRemBertForTokenClassification"),UEt.forEach(t),OCr=r(cPe," (RemBERT model)"),cPe.forEach(t),VCr=i(me),wC=n(me,"LI",{});var fPe=s(wC);vFe=n(fPe,"STRONG",{});var JEt=s(vFe);XCr=r(JEt,"roberta"),JEt.forEach(t),zCr=r(fPe," \u2014 "),pU=n(fPe,"A",{href:!0});var YEt=s(pU);WCr=r(YEt,"TFRobertaForTokenClassification"),YEt.forEach(t),QCr=r(fPe," (RoBERTa model)"),fPe.forEach(t),HCr=i(me),AC=n(me,"LI",{});var mPe=s(AC);FFe=n(mPe,"STRONG",{});var KEt=s(FFe);UCr=r(KEt,"roformer"),KEt.forEach(t),JCr=r(mPe," \u2014 "),uU=n(mPe,"A",{href:!0});var ZEt=s(uU);YCr=r(ZEt,"TFRoFormerForTokenClassification"),ZEt.forEach(t),KCr=r(mPe," (RoFormer model)"),mPe.forEach(t),ZCr=i(me),yC=n(me,"LI",{});var gPe=s(yC);TFe=n(gPe,"STRONG",{});var eCt=s(TFe);e5r=r(eCt,"xlm"),eCt.forEach(t),o5r=r(gPe," \u2014 "),_U=n(gPe,"A",{href:!0});var oCt=s(_U);r5r=r(oCt,"TFXLMForTokenClassification"),oCt.forEach(t),t5r=r(gPe," (XLM model)"),gPe.forEach(t),a5r=i(me),LC=n(me,"LI",{});var hPe=s(LC);MFe=n(hPe,"STRONG",{});var rCt=s(MFe);n5r=r(rCt,"xlm-roberta"),rCt.forEach(t),s5r=r(hPe," \u2014 "),bU=n(hPe,"A",{href:!0});var tCt=s(bU);l5r=r(tCt,"TFXLMRobertaForTokenClassification"),tCt.forEach(t),i5r=r(hPe," (XLM-RoBERTa model)"),hPe.forEach(t),d5r=i(me),xC=n(me,"LI",{});var pPe=s(xC);EFe=n(pPe,"STRONG",{});var aCt=s(EFe);c5r=r(aCt,"xlnet"),aCt.forEach(t),f5r=r(pPe," \u2014 "),vU=n(pPe,"A",{href:!0});var nCt=s(vU);m5r=r(nCt,"TFXLNetForTokenClassification"),nCt.forEach(t),g5r=r(pPe," (XLNet model)"),pPe.forEach(t),me.forEach(t),h5r=i(Rl),T($C.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),cNe=i(f),vc=n(f,"H2",{class:!0});var _De=s(vc);kC=n(_De,"A",{id:!0,class:!0,href:!0});var sCt=s(kC);CFe=n(sCt,"SPAN",{});var lCt=s(CFe);T(Q8.$$.fragment,lCt),lCt.forEach(t),sCt.forEach(t),p5r=i(_De),wFe=n(_De,"SPAN",{});var iCt=s(wFe);u5r=r(iCt,"TFAutoModelForQuestionAnswering"),iCt.forEach(t),_De.forEach(t),fNe=i(f),ir=n(f,"DIV",{class:!0});var Pl=s(ir);T(H8.$$.fragment,Pl),_5r=i(Pl),Fc=n(Pl,"P",{});var HZ=s(Fc);b5r=r(HZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),FU=n(HZ,"A",{href:!0});var dCt=s(FU);v5r=r(dCt,"from_pretrained()"),dCt.forEach(t),F5r=r(HZ," class method or the "),TU=n(HZ,"A",{href:!0});var cCt=s(TU);T5r=r(cCt,"from_config()"),cCt.forEach(t),M5r=r(HZ,` class
method.`),HZ.forEach(t),E5r=i(Pl),U8=n(Pl,"P",{});var bDe=s(U8);C5r=r(bDe,"This class cannot be instantiated directly using "),AFe=n(bDe,"CODE",{});var fCt=s(AFe);w5r=r(fCt,"__init__()"),fCt.forEach(t),A5r=r(bDe," (throws an error)."),bDe.forEach(t),y5r=i(Pl),Nt=n(Pl,"DIV",{class:!0});var $0=s(Nt);T(J8.$$.fragment,$0),L5r=i($0),yFe=n($0,"P",{});var mCt=s(yFe);x5r=r(mCt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),mCt.forEach(t),$5r=i($0),Tc=n($0,"P",{});var UZ=s(Tc);k5r=r(UZ,`Note:
Loading a model from its configuration file does `),LFe=n(UZ,"STRONG",{});var gCt=s(LFe);S5r=r(gCt,"not"),gCt.forEach(t),R5r=r(UZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),MU=n(UZ,"A",{href:!0});var hCt=s(MU);P5r=r(hCt,"from_pretrained()"),hCt.forEach(t),B5r=r(UZ," to load the model weights."),UZ.forEach(t),I5r=i($0),T(SC.$$.fragment,$0),$0.forEach(t),q5r=i(Pl),Ir=n(Pl,"DIV",{class:!0});var Bl=s(Ir);T(Y8.$$.fragment,Bl),N5r=i(Bl),xFe=n(Bl,"P",{});var pCt=s(xFe);j5r=r(pCt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),pCt.forEach(t),D5r=i(Bl),fn=n(Bl,"P",{});var k0=s(fn);G5r=r(k0,"The model class to instantiate is selected based on the "),$Fe=n(k0,"CODE",{});var uCt=s($Fe);O5r=r(uCt,"model_type"),uCt.forEach(t),V5r=r(k0,` property of the config object (either
passed as an argument or loaded from `),kFe=n(k0,"CODE",{});var _Ct=s(kFe);X5r=r(_Ct,"pretrained_model_name_or_path"),_Ct.forEach(t),z5r=r(k0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=n(k0,"CODE",{});var bCt=s(SFe);W5r=r(bCt,"pretrained_model_name_or_path"),bCt.forEach(t),Q5r=r(k0,":"),k0.forEach(t),H5r=i(Bl),ce=n(Bl,"UL",{});var ge=s(ce);RC=n(ge,"LI",{});var uPe=s(RC);RFe=n(uPe,"STRONG",{});var vCt=s(RFe);U5r=r(vCt,"albert"),vCt.forEach(t),J5r=r(uPe," \u2014 "),EU=n(uPe,"A",{href:!0});var FCt=s(EU);Y5r=r(FCt,"TFAlbertForQuestionAnswering"),FCt.forEach(t),K5r=r(uPe," (ALBERT model)"),uPe.forEach(t),Z5r=i(ge),PC=n(ge,"LI",{});var _Pe=s(PC);PFe=n(_Pe,"STRONG",{});var TCt=s(PFe);e3r=r(TCt,"bert"),TCt.forEach(t),o3r=r(_Pe," \u2014 "),CU=n(_Pe,"A",{href:!0});var MCt=s(CU);r3r=r(MCt,"TFBertForQuestionAnswering"),MCt.forEach(t),t3r=r(_Pe," (BERT model)"),_Pe.forEach(t),a3r=i(ge),BC=n(ge,"LI",{});var bPe=s(BC);BFe=n(bPe,"STRONG",{});var ECt=s(BFe);n3r=r(ECt,"camembert"),ECt.forEach(t),s3r=r(bPe," \u2014 "),wU=n(bPe,"A",{href:!0});var CCt=s(wU);l3r=r(CCt,"TFCamembertForQuestionAnswering"),CCt.forEach(t),i3r=r(bPe," (CamemBERT model)"),bPe.forEach(t),d3r=i(ge),IC=n(ge,"LI",{});var vPe=s(IC);IFe=n(vPe,"STRONG",{});var wCt=s(IFe);c3r=r(wCt,"convbert"),wCt.forEach(t),f3r=r(vPe," \u2014 "),AU=n(vPe,"A",{href:!0});var ACt=s(AU);m3r=r(ACt,"TFConvBertForQuestionAnswering"),ACt.forEach(t),g3r=r(vPe," (ConvBERT model)"),vPe.forEach(t),h3r=i(ge),qC=n(ge,"LI",{});var FPe=s(qC);qFe=n(FPe,"STRONG",{});var yCt=s(qFe);p3r=r(yCt,"deberta"),yCt.forEach(t),u3r=r(FPe," \u2014 "),yU=n(FPe,"A",{href:!0});var LCt=s(yU);_3r=r(LCt,"TFDebertaForQuestionAnswering"),LCt.forEach(t),b3r=r(FPe," (DeBERTa model)"),FPe.forEach(t),v3r=i(ge),NC=n(ge,"LI",{});var TPe=s(NC);NFe=n(TPe,"STRONG",{});var xCt=s(NFe);F3r=r(xCt,"deberta-v2"),xCt.forEach(t),T3r=r(TPe," \u2014 "),LU=n(TPe,"A",{href:!0});var $Ct=s(LU);M3r=r($Ct,"TFDebertaV2ForQuestionAnswering"),$Ct.forEach(t),E3r=r(TPe," (DeBERTa-v2 model)"),TPe.forEach(t),C3r=i(ge),jC=n(ge,"LI",{});var MPe=s(jC);jFe=n(MPe,"STRONG",{});var kCt=s(jFe);w3r=r(kCt,"distilbert"),kCt.forEach(t),A3r=r(MPe," \u2014 "),xU=n(MPe,"A",{href:!0});var SCt=s(xU);y3r=r(SCt,"TFDistilBertForQuestionAnswering"),SCt.forEach(t),L3r=r(MPe," (DistilBERT model)"),MPe.forEach(t),x3r=i(ge),DC=n(ge,"LI",{});var EPe=s(DC);DFe=n(EPe,"STRONG",{});var RCt=s(DFe);$3r=r(RCt,"electra"),RCt.forEach(t),k3r=r(EPe," \u2014 "),$U=n(EPe,"A",{href:!0});var PCt=s($U);S3r=r(PCt,"TFElectraForQuestionAnswering"),PCt.forEach(t),R3r=r(EPe," (ELECTRA model)"),EPe.forEach(t),P3r=i(ge),GC=n(ge,"LI",{});var CPe=s(GC);GFe=n(CPe,"STRONG",{});var BCt=s(GFe);B3r=r(BCt,"flaubert"),BCt.forEach(t),I3r=r(CPe," \u2014 "),kU=n(CPe,"A",{href:!0});var ICt=s(kU);q3r=r(ICt,"TFFlaubertForQuestionAnsweringSimple"),ICt.forEach(t),N3r=r(CPe," (FlauBERT model)"),CPe.forEach(t),j3r=i(ge),OC=n(ge,"LI",{});var wPe=s(OC);OFe=n(wPe,"STRONG",{});var qCt=s(OFe);D3r=r(qCt,"funnel"),qCt.forEach(t),G3r=r(wPe," \u2014 "),SU=n(wPe,"A",{href:!0});var NCt=s(SU);O3r=r(NCt,"TFFunnelForQuestionAnswering"),NCt.forEach(t),V3r=r(wPe," (Funnel Transformer model)"),wPe.forEach(t),X3r=i(ge),VC=n(ge,"LI",{});var APe=s(VC);VFe=n(APe,"STRONG",{});var jCt=s(VFe);z3r=r(jCt,"gptj"),jCt.forEach(t),W3r=r(APe," \u2014 "),RU=n(APe,"A",{href:!0});var DCt=s(RU);Q3r=r(DCt,"TFGPTJForQuestionAnswering"),DCt.forEach(t),H3r=r(APe," (GPT-J model)"),APe.forEach(t),U3r=i(ge),XC=n(ge,"LI",{});var yPe=s(XC);XFe=n(yPe,"STRONG",{});var GCt=s(XFe);J3r=r(GCt,"longformer"),GCt.forEach(t),Y3r=r(yPe," \u2014 "),PU=n(yPe,"A",{href:!0});var OCt=s(PU);K3r=r(OCt,"TFLongformerForQuestionAnswering"),OCt.forEach(t),Z3r=r(yPe," (Longformer model)"),yPe.forEach(t),ewr=i(ge),zC=n(ge,"LI",{});var LPe=s(zC);zFe=n(LPe,"STRONG",{});var VCt=s(zFe);owr=r(VCt,"mobilebert"),VCt.forEach(t),rwr=r(LPe," \u2014 "),BU=n(LPe,"A",{href:!0});var XCt=s(BU);twr=r(XCt,"TFMobileBertForQuestionAnswering"),XCt.forEach(t),awr=r(LPe," (MobileBERT model)"),LPe.forEach(t),nwr=i(ge),WC=n(ge,"LI",{});var xPe=s(WC);WFe=n(xPe,"STRONG",{});var zCt=s(WFe);swr=r(zCt,"mpnet"),zCt.forEach(t),lwr=r(xPe," \u2014 "),IU=n(xPe,"A",{href:!0});var WCt=s(IU);iwr=r(WCt,"TFMPNetForQuestionAnswering"),WCt.forEach(t),dwr=r(xPe," (MPNet model)"),xPe.forEach(t),cwr=i(ge),QC=n(ge,"LI",{});var $Pe=s(QC);QFe=n($Pe,"STRONG",{});var QCt=s(QFe);fwr=r(QCt,"rembert"),QCt.forEach(t),mwr=r($Pe," \u2014 "),qU=n($Pe,"A",{href:!0});var HCt=s(qU);gwr=r(HCt,"TFRemBertForQuestionAnswering"),HCt.forEach(t),hwr=r($Pe," (RemBERT model)"),$Pe.forEach(t),pwr=i(ge),HC=n(ge,"LI",{});var kPe=s(HC);HFe=n(kPe,"STRONG",{});var UCt=s(HFe);uwr=r(UCt,"roberta"),UCt.forEach(t),_wr=r(kPe," \u2014 "),NU=n(kPe,"A",{href:!0});var JCt=s(NU);bwr=r(JCt,"TFRobertaForQuestionAnswering"),JCt.forEach(t),vwr=r(kPe," (RoBERTa model)"),kPe.forEach(t),Fwr=i(ge),UC=n(ge,"LI",{});var SPe=s(UC);UFe=n(SPe,"STRONG",{});var YCt=s(UFe);Twr=r(YCt,"roformer"),YCt.forEach(t),Mwr=r(SPe," \u2014 "),jU=n(SPe,"A",{href:!0});var KCt=s(jU);Ewr=r(KCt,"TFRoFormerForQuestionAnswering"),KCt.forEach(t),Cwr=r(SPe," (RoFormer model)"),SPe.forEach(t),wwr=i(ge),JC=n(ge,"LI",{});var RPe=s(JC);JFe=n(RPe,"STRONG",{});var ZCt=s(JFe);Awr=r(ZCt,"xlm"),ZCt.forEach(t),ywr=r(RPe," \u2014 "),DU=n(RPe,"A",{href:!0});var e5t=s(DU);Lwr=r(e5t,"TFXLMForQuestionAnsweringSimple"),e5t.forEach(t),xwr=r(RPe," (XLM model)"),RPe.forEach(t),$wr=i(ge),YC=n(ge,"LI",{});var PPe=s(YC);YFe=n(PPe,"STRONG",{});var o5t=s(YFe);kwr=r(o5t,"xlm-roberta"),o5t.forEach(t),Swr=r(PPe," \u2014 "),GU=n(PPe,"A",{href:!0});var r5t=s(GU);Rwr=r(r5t,"TFXLMRobertaForQuestionAnswering"),r5t.forEach(t),Pwr=r(PPe," (XLM-RoBERTa model)"),PPe.forEach(t),Bwr=i(ge),KC=n(ge,"LI",{});var BPe=s(KC);KFe=n(BPe,"STRONG",{});var t5t=s(KFe);Iwr=r(t5t,"xlnet"),t5t.forEach(t),qwr=r(BPe," \u2014 "),OU=n(BPe,"A",{href:!0});var a5t=s(OU);Nwr=r(a5t,"TFXLNetForQuestionAnsweringSimple"),a5t.forEach(t),jwr=r(BPe," (XLNet model)"),BPe.forEach(t),ge.forEach(t),Dwr=i(Bl),T(ZC.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),mNe=i(f),Mc=n(f,"H2",{class:!0});var vDe=s(Mc);e5=n(vDe,"A",{id:!0,class:!0,href:!0});var n5t=s(e5);ZFe=n(n5t,"SPAN",{});var s5t=s(ZFe);T(K8.$$.fragment,s5t),s5t.forEach(t),n5t.forEach(t),Gwr=i(vDe),eTe=n(vDe,"SPAN",{});var l5t=s(eTe);Owr=r(l5t,"TFAutoModelForVision2Seq"),l5t.forEach(t),vDe.forEach(t),gNe=i(f),dr=n(f,"DIV",{class:!0});var Il=s(dr);T(Z8.$$.fragment,Il),Vwr=i(Il),Ec=n(Il,"P",{});var JZ=s(Ec);Xwr=r(JZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),VU=n(JZ,"A",{href:!0});var i5t=s(VU);zwr=r(i5t,"from_pretrained()"),i5t.forEach(t),Wwr=r(JZ," class method or the "),XU=n(JZ,"A",{href:!0});var d5t=s(XU);Qwr=r(d5t,"from_config()"),d5t.forEach(t),Hwr=r(JZ,` class
method.`),JZ.forEach(t),Uwr=i(Il),ex=n(Il,"P",{});var FDe=s(ex);Jwr=r(FDe,"This class cannot be instantiated directly using "),oTe=n(FDe,"CODE",{});var c5t=s(oTe);Ywr=r(c5t,"__init__()"),c5t.forEach(t),Kwr=r(FDe," (throws an error)."),FDe.forEach(t),Zwr=i(Il),jt=n(Il,"DIV",{class:!0});var S0=s(jt);T(ox.$$.fragment,S0),eAr=i(S0),rTe=n(S0,"P",{});var f5t=s(rTe);oAr=r(f5t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),f5t.forEach(t),rAr=i(S0),Cc=n(S0,"P",{});var YZ=s(Cc);tAr=r(YZ,`Note:
Loading a model from its configuration file does `),tTe=n(YZ,"STRONG",{});var m5t=s(tTe);aAr=r(m5t,"not"),m5t.forEach(t),nAr=r(YZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),zU=n(YZ,"A",{href:!0});var g5t=s(zU);sAr=r(g5t,"from_pretrained()"),g5t.forEach(t),lAr=r(YZ," to load the model weights."),YZ.forEach(t),iAr=i(S0),T(o5.$$.fragment,S0),S0.forEach(t),dAr=i(Il),qr=n(Il,"DIV",{class:!0});var ql=s(qr);T(rx.$$.fragment,ql),cAr=i(ql),aTe=n(ql,"P",{});var h5t=s(aTe);fAr=r(h5t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),h5t.forEach(t),mAr=i(ql),mn=n(ql,"P",{});var R0=s(mn);gAr=r(R0,"The model class to instantiate is selected based on the "),nTe=n(R0,"CODE",{});var p5t=s(nTe);hAr=r(p5t,"model_type"),p5t.forEach(t),pAr=r(R0,` property of the config object (either
passed as an argument or loaded from `),sTe=n(R0,"CODE",{});var u5t=s(sTe);uAr=r(u5t,"pretrained_model_name_or_path"),u5t.forEach(t),_Ar=r(R0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lTe=n(R0,"CODE",{});var _5t=s(lTe);bAr=r(_5t,"pretrained_model_name_or_path"),_5t.forEach(t),vAr=r(R0,":"),R0.forEach(t),FAr=i(ql),iTe=n(ql,"UL",{});var b5t=s(iTe);r5=n(b5t,"LI",{});var IPe=s(r5);dTe=n(IPe,"STRONG",{});var v5t=s(dTe);TAr=r(v5t,"vision-encoder-decoder"),v5t.forEach(t),MAr=r(IPe," \u2014 "),WU=n(IPe,"A",{href:!0});var F5t=s(WU);EAr=r(F5t,"TFVisionEncoderDecoderModel"),F5t.forEach(t),CAr=r(IPe," (Vision Encoder decoder model)"),IPe.forEach(t),b5t.forEach(t),wAr=i(ql),T(t5.$$.fragment,ql),ql.forEach(t),Il.forEach(t),hNe=i(f),wc=n(f,"H2",{class:!0});var TDe=s(wc);a5=n(TDe,"A",{id:!0,class:!0,href:!0});var T5t=s(a5);cTe=n(T5t,"SPAN",{});var M5t=s(cTe);T(tx.$$.fragment,M5t),M5t.forEach(t),T5t.forEach(t),AAr=i(TDe),fTe=n(TDe,"SPAN",{});var E5t=s(fTe);yAr=r(E5t,"TFAutoModelForSpeechSeq2Seq"),E5t.forEach(t),TDe.forEach(t),pNe=i(f),cr=n(f,"DIV",{class:!0});var Nl=s(cr);T(ax.$$.fragment,Nl),LAr=i(Nl),Ac=n(Nl,"P",{});var KZ=s(Ac);xAr=r(KZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),QU=n(KZ,"A",{href:!0});var C5t=s(QU);$Ar=r(C5t,"from_pretrained()"),C5t.forEach(t),kAr=r(KZ," class method or the "),HU=n(KZ,"A",{href:!0});var w5t=s(HU);SAr=r(w5t,"from_config()"),w5t.forEach(t),RAr=r(KZ,` class
method.`),KZ.forEach(t),PAr=i(Nl),nx=n(Nl,"P",{});var MDe=s(nx);BAr=r(MDe,"This class cannot be instantiated directly using "),mTe=n(MDe,"CODE",{});var A5t=s(mTe);IAr=r(A5t,"__init__()"),A5t.forEach(t),qAr=r(MDe," (throws an error)."),MDe.forEach(t),NAr=i(Nl),Dt=n(Nl,"DIV",{class:!0});var P0=s(Dt);T(sx.$$.fragment,P0),jAr=i(P0),gTe=n(P0,"P",{});var y5t=s(gTe);DAr=r(y5t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),y5t.forEach(t),GAr=i(P0),yc=n(P0,"P",{});var ZZ=s(yc);OAr=r(ZZ,`Note:
Loading a model from its configuration file does `),hTe=n(ZZ,"STRONG",{});var L5t=s(hTe);VAr=r(L5t,"not"),L5t.forEach(t),XAr=r(ZZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),UU=n(ZZ,"A",{href:!0});var x5t=s(UU);zAr=r(x5t,"from_pretrained()"),x5t.forEach(t),WAr=r(ZZ," to load the model weights."),ZZ.forEach(t),QAr=i(P0),T(n5.$$.fragment,P0),P0.forEach(t),HAr=i(Nl),Nr=n(Nl,"DIV",{class:!0});var jl=s(Nr);T(lx.$$.fragment,jl),UAr=i(jl),pTe=n(jl,"P",{});var $5t=s(pTe);JAr=r($5t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$5t.forEach(t),YAr=i(jl),gn=n(jl,"P",{});var B0=s(gn);KAr=r(B0,"The model class to instantiate is selected based on the "),uTe=n(B0,"CODE",{});var k5t=s(uTe);ZAr=r(k5t,"model_type"),k5t.forEach(t),e0r=r(B0,` property of the config object (either
passed as an argument or loaded from `),_Te=n(B0,"CODE",{});var S5t=s(_Te);o0r=r(S5t,"pretrained_model_name_or_path"),S5t.forEach(t),r0r=r(B0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bTe=n(B0,"CODE",{});var R5t=s(bTe);t0r=r(R5t,"pretrained_model_name_or_path"),R5t.forEach(t),a0r=r(B0,":"),B0.forEach(t),n0r=i(jl),vTe=n(jl,"UL",{});var P5t=s(vTe);s5=n(P5t,"LI",{});var qPe=s(s5);FTe=n(qPe,"STRONG",{});var B5t=s(FTe);s0r=r(B5t,"speech_to_text"),B5t.forEach(t),l0r=r(qPe," \u2014 "),JU=n(qPe,"A",{href:!0});var I5t=s(JU);i0r=r(I5t,"TFSpeech2TextForConditionalGeneration"),I5t.forEach(t),d0r=r(qPe," (Speech2Text model)"),qPe.forEach(t),P5t.forEach(t),c0r=i(jl),T(l5.$$.fragment,jl),jl.forEach(t),Nl.forEach(t),uNe=i(f),Lc=n(f,"H2",{class:!0});var EDe=s(Lc);i5=n(EDe,"A",{id:!0,class:!0,href:!0});var q5t=s(i5);TTe=n(q5t,"SPAN",{});var N5t=s(TTe);T(ix.$$.fragment,N5t),N5t.forEach(t),q5t.forEach(t),f0r=i(EDe),MTe=n(EDe,"SPAN",{});var j5t=s(MTe);m0r=r(j5t,"FlaxAutoModel"),j5t.forEach(t),EDe.forEach(t),_Ne=i(f),fr=n(f,"DIV",{class:!0});var Dl=s(fr);T(dx.$$.fragment,Dl),g0r=i(Dl),xc=n(Dl,"P",{});var eee=s(xc);h0r=r(eee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),YU=n(eee,"A",{href:!0});var D5t=s(YU);p0r=r(D5t,"from_pretrained()"),D5t.forEach(t),u0r=r(eee," class method or the "),KU=n(eee,"A",{href:!0});var G5t=s(KU);_0r=r(G5t,"from_config()"),G5t.forEach(t),b0r=r(eee,` class
method.`),eee.forEach(t),v0r=i(Dl),cx=n(Dl,"P",{});var CDe=s(cx);F0r=r(CDe,"This class cannot be instantiated directly using "),ETe=n(CDe,"CODE",{});var O5t=s(ETe);T0r=r(O5t,"__init__()"),O5t.forEach(t),M0r=r(CDe," (throws an error)."),CDe.forEach(t),E0r=i(Dl),Gt=n(Dl,"DIV",{class:!0});var I0=s(Gt);T(fx.$$.fragment,I0),C0r=i(I0),CTe=n(I0,"P",{});var V5t=s(CTe);w0r=r(V5t,"Instantiates one of the base model classes of the library from a configuration."),V5t.forEach(t),A0r=i(I0),$c=n(I0,"P",{});var oee=s($c);y0r=r(oee,`Note:
Loading a model from its configuration file does `),wTe=n(oee,"STRONG",{});var X5t=s(wTe);L0r=r(X5t,"not"),X5t.forEach(t),x0r=r(oee,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZU=n(oee,"A",{href:!0});var z5t=s(ZU);$0r=r(z5t,"from_pretrained()"),z5t.forEach(t),k0r=r(oee," to load the model weights."),oee.forEach(t),S0r=i(I0),T(d5.$$.fragment,I0),I0.forEach(t),R0r=i(Dl),jr=n(Dl,"DIV",{class:!0});var Gl=s(jr);T(mx.$$.fragment,Gl),P0r=i(Gl),ATe=n(Gl,"P",{});var W5t=s(ATe);B0r=r(W5t,"Instantiate one of the base model classes of the library from a pretrained model."),W5t.forEach(t),I0r=i(Gl),hn=n(Gl,"P",{});var q0=s(hn);q0r=r(q0,"The model class to instantiate is selected based on the "),yTe=n(q0,"CODE",{});var Q5t=s(yTe);N0r=r(Q5t,"model_type"),Q5t.forEach(t),j0r=r(q0,` property of the config object (either
passed as an argument or loaded from `),LTe=n(q0,"CODE",{});var H5t=s(LTe);D0r=r(H5t,"pretrained_model_name_or_path"),H5t.forEach(t),G0r=r(q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xTe=n(q0,"CODE",{});var U5t=s(xTe);O0r=r(U5t,"pretrained_model_name_or_path"),U5t.forEach(t),V0r=r(q0,":"),q0.forEach(t),X0r=i(Gl),oe=n(Gl,"UL",{});var ne=s(oe);c5=n(ne,"LI",{});var NPe=s(c5);$Te=n(NPe,"STRONG",{});var J5t=s($Te);z0r=r(J5t,"albert"),J5t.forEach(t),W0r=r(NPe," \u2014 "),eJ=n(NPe,"A",{href:!0});var Y5t=s(eJ);Q0r=r(Y5t,"FlaxAlbertModel"),Y5t.forEach(t),H0r=r(NPe," (ALBERT model)"),NPe.forEach(t),U0r=i(ne),f5=n(ne,"LI",{});var jPe=s(f5);kTe=n(jPe,"STRONG",{});var K5t=s(kTe);J0r=r(K5t,"bart"),K5t.forEach(t),Y0r=r(jPe," \u2014 "),oJ=n(jPe,"A",{href:!0});var Z5t=s(oJ);K0r=r(Z5t,"FlaxBartModel"),Z5t.forEach(t),Z0r=r(jPe," (BART model)"),jPe.forEach(t),e6r=i(ne),m5=n(ne,"LI",{});var DPe=s(m5);STe=n(DPe,"STRONG",{});var e3t=s(STe);o6r=r(e3t,"beit"),e3t.forEach(t),r6r=r(DPe," \u2014 "),rJ=n(DPe,"A",{href:!0});var o3t=s(rJ);t6r=r(o3t,"FlaxBeitModel"),o3t.forEach(t),a6r=r(DPe," (BEiT model)"),DPe.forEach(t),n6r=i(ne),g5=n(ne,"LI",{});var GPe=s(g5);RTe=n(GPe,"STRONG",{});var r3t=s(RTe);s6r=r(r3t,"bert"),r3t.forEach(t),l6r=r(GPe," \u2014 "),tJ=n(GPe,"A",{href:!0});var t3t=s(tJ);i6r=r(t3t,"FlaxBertModel"),t3t.forEach(t),d6r=r(GPe," (BERT model)"),GPe.forEach(t),c6r=i(ne),h5=n(ne,"LI",{});var OPe=s(h5);PTe=n(OPe,"STRONG",{});var a3t=s(PTe);f6r=r(a3t,"big_bird"),a3t.forEach(t),m6r=r(OPe," \u2014 "),aJ=n(OPe,"A",{href:!0});var n3t=s(aJ);g6r=r(n3t,"FlaxBigBirdModel"),n3t.forEach(t),h6r=r(OPe," (BigBird model)"),OPe.forEach(t),p6r=i(ne),p5=n(ne,"LI",{});var VPe=s(p5);BTe=n(VPe,"STRONG",{});var s3t=s(BTe);u6r=r(s3t,"blenderbot"),s3t.forEach(t),_6r=r(VPe," \u2014 "),nJ=n(VPe,"A",{href:!0});var l3t=s(nJ);b6r=r(l3t,"FlaxBlenderbotModel"),l3t.forEach(t),v6r=r(VPe," (Blenderbot model)"),VPe.forEach(t),F6r=i(ne),u5=n(ne,"LI",{});var XPe=s(u5);ITe=n(XPe,"STRONG",{});var i3t=s(ITe);T6r=r(i3t,"blenderbot-small"),i3t.forEach(t),M6r=r(XPe," \u2014 "),sJ=n(XPe,"A",{href:!0});var d3t=s(sJ);E6r=r(d3t,"FlaxBlenderbotSmallModel"),d3t.forEach(t),C6r=r(XPe," (BlenderbotSmall model)"),XPe.forEach(t),w6r=i(ne),_5=n(ne,"LI",{});var zPe=s(_5);qTe=n(zPe,"STRONG",{});var c3t=s(qTe);A6r=r(c3t,"clip"),c3t.forEach(t),y6r=r(zPe," \u2014 "),lJ=n(zPe,"A",{href:!0});var f3t=s(lJ);L6r=r(f3t,"FlaxCLIPModel"),f3t.forEach(t),x6r=r(zPe," (CLIP model)"),zPe.forEach(t),$6r=i(ne),b5=n(ne,"LI",{});var WPe=s(b5);NTe=n(WPe,"STRONG",{});var m3t=s(NTe);k6r=r(m3t,"distilbert"),m3t.forEach(t),S6r=r(WPe," \u2014 "),iJ=n(WPe,"A",{href:!0});var g3t=s(iJ);R6r=r(g3t,"FlaxDistilBertModel"),g3t.forEach(t),P6r=r(WPe," (DistilBERT model)"),WPe.forEach(t),B6r=i(ne),v5=n(ne,"LI",{});var QPe=s(v5);jTe=n(QPe,"STRONG",{});var h3t=s(jTe);I6r=r(h3t,"electra"),h3t.forEach(t),q6r=r(QPe," \u2014 "),dJ=n(QPe,"A",{href:!0});var p3t=s(dJ);N6r=r(p3t,"FlaxElectraModel"),p3t.forEach(t),j6r=r(QPe," (ELECTRA model)"),QPe.forEach(t),D6r=i(ne),F5=n(ne,"LI",{});var HPe=s(F5);DTe=n(HPe,"STRONG",{});var u3t=s(DTe);G6r=r(u3t,"gpt2"),u3t.forEach(t),O6r=r(HPe," \u2014 "),cJ=n(HPe,"A",{href:!0});var _3t=s(cJ);V6r=r(_3t,"FlaxGPT2Model"),_3t.forEach(t),X6r=r(HPe," (OpenAI GPT-2 model)"),HPe.forEach(t),z6r=i(ne),T5=n(ne,"LI",{});var UPe=s(T5);GTe=n(UPe,"STRONG",{});var b3t=s(GTe);W6r=r(b3t,"gpt_neo"),b3t.forEach(t),Q6r=r(UPe," \u2014 "),fJ=n(UPe,"A",{href:!0});var v3t=s(fJ);H6r=r(v3t,"FlaxGPTNeoModel"),v3t.forEach(t),U6r=r(UPe," (GPT Neo model)"),UPe.forEach(t),J6r=i(ne),M5=n(ne,"LI",{});var JPe=s(M5);OTe=n(JPe,"STRONG",{});var F3t=s(OTe);Y6r=r(F3t,"gptj"),F3t.forEach(t),K6r=r(JPe," \u2014 "),mJ=n(JPe,"A",{href:!0});var T3t=s(mJ);Z6r=r(T3t,"FlaxGPTJModel"),T3t.forEach(t),eyr=r(JPe," (GPT-J model)"),JPe.forEach(t),oyr=i(ne),E5=n(ne,"LI",{});var YPe=s(E5);VTe=n(YPe,"STRONG",{});var M3t=s(VTe);ryr=r(M3t,"marian"),M3t.forEach(t),tyr=r(YPe," \u2014 "),gJ=n(YPe,"A",{href:!0});var E3t=s(gJ);ayr=r(E3t,"FlaxMarianModel"),E3t.forEach(t),nyr=r(YPe," (Marian model)"),YPe.forEach(t),syr=i(ne),C5=n(ne,"LI",{});var KPe=s(C5);XTe=n(KPe,"STRONG",{});var C3t=s(XTe);lyr=r(C3t,"mbart"),C3t.forEach(t),iyr=r(KPe," \u2014 "),hJ=n(KPe,"A",{href:!0});var w3t=s(hJ);dyr=r(w3t,"FlaxMBartModel"),w3t.forEach(t),cyr=r(KPe," (mBART model)"),KPe.forEach(t),fyr=i(ne),w5=n(ne,"LI",{});var ZPe=s(w5);zTe=n(ZPe,"STRONG",{});var A3t=s(zTe);myr=r(A3t,"mt5"),A3t.forEach(t),gyr=r(ZPe," \u2014 "),pJ=n(ZPe,"A",{href:!0});var y3t=s(pJ);hyr=r(y3t,"FlaxMT5Model"),y3t.forEach(t),pyr=r(ZPe," (mT5 model)"),ZPe.forEach(t),uyr=i(ne),A5=n(ne,"LI",{});var eBe=s(A5);WTe=n(eBe,"STRONG",{});var L3t=s(WTe);_yr=r(L3t,"opt"),L3t.forEach(t),byr=r(eBe," \u2014 "),uJ=n(eBe,"A",{href:!0});var x3t=s(uJ);vyr=r(x3t,"FlaxOPTModel"),x3t.forEach(t),Fyr=r(eBe," (OPT model)"),eBe.forEach(t),Tyr=i(ne),y5=n(ne,"LI",{});var oBe=s(y5);QTe=n(oBe,"STRONG",{});var $3t=s(QTe);Myr=r($3t,"pegasus"),$3t.forEach(t),Eyr=r(oBe," \u2014 "),_J=n(oBe,"A",{href:!0});var k3t=s(_J);Cyr=r(k3t,"FlaxPegasusModel"),k3t.forEach(t),wyr=r(oBe," (Pegasus model)"),oBe.forEach(t),Ayr=i(ne),L5=n(ne,"LI",{});var rBe=s(L5);HTe=n(rBe,"STRONG",{});var S3t=s(HTe);yyr=r(S3t,"roberta"),S3t.forEach(t),Lyr=r(rBe," \u2014 "),bJ=n(rBe,"A",{href:!0});var R3t=s(bJ);xyr=r(R3t,"FlaxRobertaModel"),R3t.forEach(t),$yr=r(rBe," (RoBERTa model)"),rBe.forEach(t),kyr=i(ne),x5=n(ne,"LI",{});var tBe=s(x5);UTe=n(tBe,"STRONG",{});var P3t=s(UTe);Syr=r(P3t,"roformer"),P3t.forEach(t),Ryr=r(tBe," \u2014 "),vJ=n(tBe,"A",{href:!0});var B3t=s(vJ);Pyr=r(B3t,"FlaxRoFormerModel"),B3t.forEach(t),Byr=r(tBe," (RoFormer model)"),tBe.forEach(t),Iyr=i(ne),$5=n(ne,"LI",{});var aBe=s($5);JTe=n(aBe,"STRONG",{});var I3t=s(JTe);qyr=r(I3t,"t5"),I3t.forEach(t),Nyr=r(aBe," \u2014 "),FJ=n(aBe,"A",{href:!0});var q3t=s(FJ);jyr=r(q3t,"FlaxT5Model"),q3t.forEach(t),Dyr=r(aBe," (T5 model)"),aBe.forEach(t),Gyr=i(ne),k5=n(ne,"LI",{});var nBe=s(k5);YTe=n(nBe,"STRONG",{});var N3t=s(YTe);Oyr=r(N3t,"vision-text-dual-encoder"),N3t.forEach(t),Vyr=r(nBe," \u2014 "),TJ=n(nBe,"A",{href:!0});var j3t=s(TJ);Xyr=r(j3t,"FlaxVisionTextDualEncoderModel"),j3t.forEach(t),zyr=r(nBe," (VisionTextDualEncoder model)"),nBe.forEach(t),Wyr=i(ne),S5=n(ne,"LI",{});var sBe=s(S5);KTe=n(sBe,"STRONG",{});var D3t=s(KTe);Qyr=r(D3t,"vit"),D3t.forEach(t),Hyr=r(sBe," \u2014 "),MJ=n(sBe,"A",{href:!0});var G3t=s(MJ);Uyr=r(G3t,"FlaxViTModel"),G3t.forEach(t),Jyr=r(sBe," (ViT model)"),sBe.forEach(t),Yyr=i(ne),R5=n(ne,"LI",{});var lBe=s(R5);ZTe=n(lBe,"STRONG",{});var O3t=s(ZTe);Kyr=r(O3t,"wav2vec2"),O3t.forEach(t),Zyr=r(lBe," \u2014 "),EJ=n(lBe,"A",{href:!0});var V3t=s(EJ);eLr=r(V3t,"FlaxWav2Vec2Model"),V3t.forEach(t),oLr=r(lBe," (Wav2Vec2 model)"),lBe.forEach(t),rLr=i(ne),P5=n(ne,"LI",{});var iBe=s(P5);eMe=n(iBe,"STRONG",{});var X3t=s(eMe);tLr=r(X3t,"xglm"),X3t.forEach(t),aLr=r(iBe," \u2014 "),CJ=n(iBe,"A",{href:!0});var z3t=s(CJ);nLr=r(z3t,"FlaxXGLMModel"),z3t.forEach(t),sLr=r(iBe," (XGLM model)"),iBe.forEach(t),lLr=i(ne),B5=n(ne,"LI",{});var dBe=s(B5);oMe=n(dBe,"STRONG",{});var W3t=s(oMe);iLr=r(W3t,"xlm-roberta"),W3t.forEach(t),dLr=r(dBe," \u2014 "),wJ=n(dBe,"A",{href:!0});var Q3t=s(wJ);cLr=r(Q3t,"FlaxXLMRobertaModel"),Q3t.forEach(t),fLr=r(dBe," (XLM-RoBERTa model)"),dBe.forEach(t),ne.forEach(t),mLr=i(Gl),T(I5.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),bNe=i(f),kc=n(f,"H2",{class:!0});var wDe=s(kc);q5=n(wDe,"A",{id:!0,class:!0,href:!0});var H3t=s(q5);rMe=n(H3t,"SPAN",{});var U3t=s(rMe);T(gx.$$.fragment,U3t),U3t.forEach(t),H3t.forEach(t),gLr=i(wDe),tMe=n(wDe,"SPAN",{});var J3t=s(tMe);hLr=r(J3t,"FlaxAutoModelForCausalLM"),J3t.forEach(t),wDe.forEach(t),vNe=i(f),mr=n(f,"DIV",{class:!0});var Ol=s(mr);T(hx.$$.fragment,Ol),pLr=i(Ol),Sc=n(Ol,"P",{});var ree=s(Sc);uLr=r(ree,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),AJ=n(ree,"A",{href:!0});var Y3t=s(AJ);_Lr=r(Y3t,"from_pretrained()"),Y3t.forEach(t),bLr=r(ree," class method or the "),yJ=n(ree,"A",{href:!0});var K3t=s(yJ);vLr=r(K3t,"from_config()"),K3t.forEach(t),FLr=r(ree,` class
method.`),ree.forEach(t),TLr=i(Ol),px=n(Ol,"P",{});var ADe=s(px);MLr=r(ADe,"This class cannot be instantiated directly using "),aMe=n(ADe,"CODE",{});var Z3t=s(aMe);ELr=r(Z3t,"__init__()"),Z3t.forEach(t),CLr=r(ADe," (throws an error)."),ADe.forEach(t),wLr=i(Ol),Ot=n(Ol,"DIV",{class:!0});var N0=s(Ot);T(ux.$$.fragment,N0),ALr=i(N0),nMe=n(N0,"P",{});var ewt=s(nMe);yLr=r(ewt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ewt.forEach(t),LLr=i(N0),Rc=n(N0,"P",{});var tee=s(Rc);xLr=r(tee,`Note:
Loading a model from its configuration file does `),sMe=n(tee,"STRONG",{});var owt=s(sMe);$Lr=r(owt,"not"),owt.forEach(t),kLr=r(tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),LJ=n(tee,"A",{href:!0});var rwt=s(LJ);SLr=r(rwt,"from_pretrained()"),rwt.forEach(t),RLr=r(tee," to load the model weights."),tee.forEach(t),PLr=i(N0),T(N5.$$.fragment,N0),N0.forEach(t),BLr=i(Ol),Dr=n(Ol,"DIV",{class:!0});var Vl=s(Dr);T(_x.$$.fragment,Vl),ILr=i(Vl),lMe=n(Vl,"P",{});var twt=s(lMe);qLr=r(twt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),twt.forEach(t),NLr=i(Vl),pn=n(Vl,"P",{});var j0=s(pn);jLr=r(j0,"The model class to instantiate is selected based on the "),iMe=n(j0,"CODE",{});var awt=s(iMe);DLr=r(awt,"model_type"),awt.forEach(t),GLr=r(j0,` property of the config object (either
passed as an argument or loaded from `),dMe=n(j0,"CODE",{});var nwt=s(dMe);OLr=r(nwt,"pretrained_model_name_or_path"),nwt.forEach(t),VLr=r(j0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cMe=n(j0,"CODE",{});var swt=s(cMe);XLr=r(swt,"pretrained_model_name_or_path"),swt.forEach(t),zLr=r(j0,":"),j0.forEach(t),WLr=i(Vl),Le=n(Vl,"UL",{});var Ie=s(Le);j5=n(Ie,"LI",{});var cBe=s(j5);fMe=n(cBe,"STRONG",{});var lwt=s(fMe);QLr=r(lwt,"bart"),lwt.forEach(t),HLr=r(cBe," \u2014 "),xJ=n(cBe,"A",{href:!0});var iwt=s(xJ);ULr=r(iwt,"FlaxBartForCausalLM"),iwt.forEach(t),JLr=r(cBe," (BART model)"),cBe.forEach(t),YLr=i(Ie),D5=n(Ie,"LI",{});var fBe=s(D5);mMe=n(fBe,"STRONG",{});var dwt=s(mMe);KLr=r(dwt,"bert"),dwt.forEach(t),ZLr=r(fBe," \u2014 "),$J=n(fBe,"A",{href:!0});var cwt=s($J);e8r=r(cwt,"FlaxBertForCausalLM"),cwt.forEach(t),o8r=r(fBe," (BERT model)"),fBe.forEach(t),r8r=i(Ie),G5=n(Ie,"LI",{});var mBe=s(G5);gMe=n(mBe,"STRONG",{});var fwt=s(gMe);t8r=r(fwt,"big_bird"),fwt.forEach(t),a8r=r(mBe," \u2014 "),kJ=n(mBe,"A",{href:!0});var mwt=s(kJ);n8r=r(mwt,"FlaxBigBirdForCausalLM"),mwt.forEach(t),s8r=r(mBe," (BigBird model)"),mBe.forEach(t),l8r=i(Ie),O5=n(Ie,"LI",{});var gBe=s(O5);hMe=n(gBe,"STRONG",{});var gwt=s(hMe);i8r=r(gwt,"electra"),gwt.forEach(t),d8r=r(gBe," \u2014 "),SJ=n(gBe,"A",{href:!0});var hwt=s(SJ);c8r=r(hwt,"FlaxElectraForCausalLM"),hwt.forEach(t),f8r=r(gBe," (ELECTRA model)"),gBe.forEach(t),m8r=i(Ie),V5=n(Ie,"LI",{});var hBe=s(V5);pMe=n(hBe,"STRONG",{});var pwt=s(pMe);g8r=r(pwt,"gpt2"),pwt.forEach(t),h8r=r(hBe," \u2014 "),RJ=n(hBe,"A",{href:!0});var uwt=s(RJ);p8r=r(uwt,"FlaxGPT2LMHeadModel"),uwt.forEach(t),u8r=r(hBe," (OpenAI GPT-2 model)"),hBe.forEach(t),_8r=i(Ie),X5=n(Ie,"LI",{});var pBe=s(X5);uMe=n(pBe,"STRONG",{});var _wt=s(uMe);b8r=r(_wt,"gpt_neo"),_wt.forEach(t),v8r=r(pBe," \u2014 "),PJ=n(pBe,"A",{href:!0});var bwt=s(PJ);F8r=r(bwt,"FlaxGPTNeoForCausalLM"),bwt.forEach(t),T8r=r(pBe," (GPT Neo model)"),pBe.forEach(t),M8r=i(Ie),z5=n(Ie,"LI",{});var uBe=s(z5);_Me=n(uBe,"STRONG",{});var vwt=s(_Me);E8r=r(vwt,"gptj"),vwt.forEach(t),C8r=r(uBe," \u2014 "),BJ=n(uBe,"A",{href:!0});var Fwt=s(BJ);w8r=r(Fwt,"FlaxGPTJForCausalLM"),Fwt.forEach(t),A8r=r(uBe," (GPT-J model)"),uBe.forEach(t),y8r=i(Ie),W5=n(Ie,"LI",{});var _Be=s(W5);bMe=n(_Be,"STRONG",{});var Twt=s(bMe);L8r=r(Twt,"opt"),Twt.forEach(t),x8r=r(_Be," \u2014 "),IJ=n(_Be,"A",{href:!0});var Mwt=s(IJ);$8r=r(Mwt,"FlaxOPTForCausalLM"),Mwt.forEach(t),k8r=r(_Be," (OPT model)"),_Be.forEach(t),S8r=i(Ie),Q5=n(Ie,"LI",{});var bBe=s(Q5);vMe=n(bBe,"STRONG",{});var Ewt=s(vMe);R8r=r(Ewt,"roberta"),Ewt.forEach(t),P8r=r(bBe," \u2014 "),qJ=n(bBe,"A",{href:!0});var Cwt=s(qJ);B8r=r(Cwt,"FlaxRobertaForCausalLM"),Cwt.forEach(t),I8r=r(bBe," (RoBERTa model)"),bBe.forEach(t),q8r=i(Ie),H5=n(Ie,"LI",{});var vBe=s(H5);FMe=n(vBe,"STRONG",{});var wwt=s(FMe);N8r=r(wwt,"xglm"),wwt.forEach(t),j8r=r(vBe," \u2014 "),NJ=n(vBe,"A",{href:!0});var Awt=s(NJ);D8r=r(Awt,"FlaxXGLMForCausalLM"),Awt.forEach(t),G8r=r(vBe," (XGLM model)"),vBe.forEach(t),Ie.forEach(t),O8r=i(Vl),T(U5.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),FNe=i(f),Pc=n(f,"H2",{class:!0});var yDe=s(Pc);J5=n(yDe,"A",{id:!0,class:!0,href:!0});var ywt=s(J5);TMe=n(ywt,"SPAN",{});var Lwt=s(TMe);T(bx.$$.fragment,Lwt),Lwt.forEach(t),ywt.forEach(t),V8r=i(yDe),MMe=n(yDe,"SPAN",{});var xwt=s(MMe);X8r=r(xwt,"FlaxAutoModelForPreTraining"),xwt.forEach(t),yDe.forEach(t),TNe=i(f),gr=n(f,"DIV",{class:!0});var Xl=s(gr);T(vx.$$.fragment,Xl),z8r=i(Xl),Bc=n(Xl,"P",{});var aee=s(Bc);W8r=r(aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),jJ=n(aee,"A",{href:!0});var $wt=s(jJ);Q8r=r($wt,"from_pretrained()"),$wt.forEach(t),H8r=r(aee," class method or the "),DJ=n(aee,"A",{href:!0});var kwt=s(DJ);U8r=r(kwt,"from_config()"),kwt.forEach(t),J8r=r(aee,` class
method.`),aee.forEach(t),Y8r=i(Xl),Fx=n(Xl,"P",{});var LDe=s(Fx);K8r=r(LDe,"This class cannot be instantiated directly using "),EMe=n(LDe,"CODE",{});var Swt=s(EMe);Z8r=r(Swt,"__init__()"),Swt.forEach(t),exr=r(LDe," (throws an error)."),LDe.forEach(t),oxr=i(Xl),Vt=n(Xl,"DIV",{class:!0});var D0=s(Vt);T(Tx.$$.fragment,D0),rxr=i(D0),CMe=n(D0,"P",{});var Rwt=s(CMe);txr=r(Rwt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rwt.forEach(t),axr=i(D0),Ic=n(D0,"P",{});var nee=s(Ic);nxr=r(nee,`Note:
Loading a model from its configuration file does `),wMe=n(nee,"STRONG",{});var Pwt=s(wMe);sxr=r(Pwt,"not"),Pwt.forEach(t),lxr=r(nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),GJ=n(nee,"A",{href:!0});var Bwt=s(GJ);ixr=r(Bwt,"from_pretrained()"),Bwt.forEach(t),dxr=r(nee," to load the model weights."),nee.forEach(t),cxr=i(D0),T(Y5.$$.fragment,D0),D0.forEach(t),fxr=i(Xl),Gr=n(Xl,"DIV",{class:!0});var zl=s(Gr);T(Mx.$$.fragment,zl),mxr=i(zl),AMe=n(zl,"P",{});var Iwt=s(AMe);gxr=r(Iwt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Iwt.forEach(t),hxr=i(zl),un=n(zl,"P",{});var G0=s(un);pxr=r(G0,"The model class to instantiate is selected based on the "),yMe=n(G0,"CODE",{});var qwt=s(yMe);uxr=r(qwt,"model_type"),qwt.forEach(t),_xr=r(G0,` property of the config object (either
passed as an argument or loaded from `),LMe=n(G0,"CODE",{});var Nwt=s(LMe);bxr=r(Nwt,"pretrained_model_name_or_path"),Nwt.forEach(t),vxr=r(G0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=n(G0,"CODE",{});var jwt=s(xMe);Fxr=r(jwt,"pretrained_model_name_or_path"),jwt.forEach(t),Txr=r(G0,":"),G0.forEach(t),Mxr=i(zl),Me=n(zl,"UL",{});var we=s(Me);K5=n(we,"LI",{});var FBe=s(K5);$Me=n(FBe,"STRONG",{});var Dwt=s($Me);Exr=r(Dwt,"albert"),Dwt.forEach(t),Cxr=r(FBe," \u2014 "),OJ=n(FBe,"A",{href:!0});var Gwt=s(OJ);wxr=r(Gwt,"FlaxAlbertForPreTraining"),Gwt.forEach(t),Axr=r(FBe," (ALBERT model)"),FBe.forEach(t),yxr=i(we),Z5=n(we,"LI",{});var TBe=s(Z5);kMe=n(TBe,"STRONG",{});var Owt=s(kMe);Lxr=r(Owt,"bart"),Owt.forEach(t),xxr=r(TBe," \u2014 "),VJ=n(TBe,"A",{href:!0});var Vwt=s(VJ);$xr=r(Vwt,"FlaxBartForConditionalGeneration"),Vwt.forEach(t),kxr=r(TBe," (BART model)"),TBe.forEach(t),Sxr=i(we),e3=n(we,"LI",{});var MBe=s(e3);SMe=n(MBe,"STRONG",{});var Xwt=s(SMe);Rxr=r(Xwt,"bert"),Xwt.forEach(t),Pxr=r(MBe," \u2014 "),XJ=n(MBe,"A",{href:!0});var zwt=s(XJ);Bxr=r(zwt,"FlaxBertForPreTraining"),zwt.forEach(t),Ixr=r(MBe," (BERT model)"),MBe.forEach(t),qxr=i(we),o3=n(we,"LI",{});var EBe=s(o3);RMe=n(EBe,"STRONG",{});var Wwt=s(RMe);Nxr=r(Wwt,"big_bird"),Wwt.forEach(t),jxr=r(EBe," \u2014 "),zJ=n(EBe,"A",{href:!0});var Qwt=s(zJ);Dxr=r(Qwt,"FlaxBigBirdForPreTraining"),Qwt.forEach(t),Gxr=r(EBe," (BigBird model)"),EBe.forEach(t),Oxr=i(we),r3=n(we,"LI",{});var CBe=s(r3);PMe=n(CBe,"STRONG",{});var Hwt=s(PMe);Vxr=r(Hwt,"electra"),Hwt.forEach(t),Xxr=r(CBe," \u2014 "),WJ=n(CBe,"A",{href:!0});var Uwt=s(WJ);zxr=r(Uwt,"FlaxElectraForPreTraining"),Uwt.forEach(t),Wxr=r(CBe," (ELECTRA model)"),CBe.forEach(t),Qxr=i(we),t3=n(we,"LI",{});var wBe=s(t3);BMe=n(wBe,"STRONG",{});var Jwt=s(BMe);Hxr=r(Jwt,"mbart"),Jwt.forEach(t),Uxr=r(wBe," \u2014 "),QJ=n(wBe,"A",{href:!0});var Ywt=s(QJ);Jxr=r(Ywt,"FlaxMBartForConditionalGeneration"),Ywt.forEach(t),Yxr=r(wBe," (mBART model)"),wBe.forEach(t),Kxr=i(we),a3=n(we,"LI",{});var ABe=s(a3);IMe=n(ABe,"STRONG",{});var Kwt=s(IMe);Zxr=r(Kwt,"mt5"),Kwt.forEach(t),e9r=r(ABe," \u2014 "),HJ=n(ABe,"A",{href:!0});var Zwt=s(HJ);o9r=r(Zwt,"FlaxMT5ForConditionalGeneration"),Zwt.forEach(t),r9r=r(ABe," (mT5 model)"),ABe.forEach(t),t9r=i(we),n3=n(we,"LI",{});var yBe=s(n3);qMe=n(yBe,"STRONG",{});var eAt=s(qMe);a9r=r(eAt,"roberta"),eAt.forEach(t),n9r=r(yBe," \u2014 "),UJ=n(yBe,"A",{href:!0});var oAt=s(UJ);s9r=r(oAt,"FlaxRobertaForMaskedLM"),oAt.forEach(t),l9r=r(yBe," (RoBERTa model)"),yBe.forEach(t),i9r=i(we),s3=n(we,"LI",{});var LBe=s(s3);NMe=n(LBe,"STRONG",{});var rAt=s(NMe);d9r=r(rAt,"roformer"),rAt.forEach(t),c9r=r(LBe," \u2014 "),JJ=n(LBe,"A",{href:!0});var tAt=s(JJ);f9r=r(tAt,"FlaxRoFormerForMaskedLM"),tAt.forEach(t),m9r=r(LBe," (RoFormer model)"),LBe.forEach(t),g9r=i(we),l3=n(we,"LI",{});var xBe=s(l3);jMe=n(xBe,"STRONG",{});var aAt=s(jMe);h9r=r(aAt,"t5"),aAt.forEach(t),p9r=r(xBe," \u2014 "),YJ=n(xBe,"A",{href:!0});var nAt=s(YJ);u9r=r(nAt,"FlaxT5ForConditionalGeneration"),nAt.forEach(t),_9r=r(xBe," (T5 model)"),xBe.forEach(t),b9r=i(we),i3=n(we,"LI",{});var $Be=s(i3);DMe=n($Be,"STRONG",{});var sAt=s(DMe);v9r=r(sAt,"wav2vec2"),sAt.forEach(t),F9r=r($Be," \u2014 "),KJ=n($Be,"A",{href:!0});var lAt=s(KJ);T9r=r(lAt,"FlaxWav2Vec2ForPreTraining"),lAt.forEach(t),M9r=r($Be," (Wav2Vec2 model)"),$Be.forEach(t),E9r=i(we),d3=n(we,"LI",{});var kBe=s(d3);GMe=n(kBe,"STRONG",{});var iAt=s(GMe);C9r=r(iAt,"xlm-roberta"),iAt.forEach(t),w9r=r(kBe," \u2014 "),ZJ=n(kBe,"A",{href:!0});var dAt=s(ZJ);A9r=r(dAt,"FlaxXLMRobertaForMaskedLM"),dAt.forEach(t),y9r=r(kBe," (XLM-RoBERTa model)"),kBe.forEach(t),we.forEach(t),L9r=i(zl),T(c3.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),MNe=i(f),qc=n(f,"H2",{class:!0});var xDe=s(qc);f3=n(xDe,"A",{id:!0,class:!0,href:!0});var cAt=s(f3);OMe=n(cAt,"SPAN",{});var fAt=s(OMe);T(Ex.$$.fragment,fAt),fAt.forEach(t),cAt.forEach(t),x9r=i(xDe),VMe=n(xDe,"SPAN",{});var mAt=s(VMe);$9r=r(mAt,"FlaxAutoModelForMaskedLM"),mAt.forEach(t),xDe.forEach(t),ENe=i(f),hr=n(f,"DIV",{class:!0});var Wl=s(hr);T(Cx.$$.fragment,Wl),k9r=i(Wl),Nc=n(Wl,"P",{});var see=s(Nc);S9r=r(see,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),eY=n(see,"A",{href:!0});var gAt=s(eY);R9r=r(gAt,"from_pretrained()"),gAt.forEach(t),P9r=r(see," class method or the "),oY=n(see,"A",{href:!0});var hAt=s(oY);B9r=r(hAt,"from_config()"),hAt.forEach(t),I9r=r(see,` class
method.`),see.forEach(t),q9r=i(Wl),wx=n(Wl,"P",{});var $De=s(wx);N9r=r($De,"This class cannot be instantiated directly using "),XMe=n($De,"CODE",{});var pAt=s(XMe);j9r=r(pAt,"__init__()"),pAt.forEach(t),D9r=r($De," (throws an error)."),$De.forEach(t),G9r=i(Wl),Xt=n(Wl,"DIV",{class:!0});var O0=s(Xt);T(Ax.$$.fragment,O0),O9r=i(O0),zMe=n(O0,"P",{});var uAt=s(zMe);V9r=r(uAt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uAt.forEach(t),X9r=i(O0),jc=n(O0,"P",{});var lee=s(jc);z9r=r(lee,`Note:
Loading a model from its configuration file does `),WMe=n(lee,"STRONG",{});var _At=s(WMe);W9r=r(_At,"not"),_At.forEach(t),Q9r=r(lee,` load the model weights. It only affects the
model\u2019s configuration. Use `),rY=n(lee,"A",{href:!0});var bAt=s(rY);H9r=r(bAt,"from_pretrained()"),bAt.forEach(t),U9r=r(lee," to load the model weights."),lee.forEach(t),J9r=i(O0),T(m3.$$.fragment,O0),O0.forEach(t),Y9r=i(Wl),Or=n(Wl,"DIV",{class:!0});var Ql=s(Or);T(yx.$$.fragment,Ql),K9r=i(Ql),QMe=n(Ql,"P",{});var vAt=s(QMe);Z9r=r(vAt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),vAt.forEach(t),e$r=i(Ql),_n=n(Ql,"P",{});var V0=s(_n);o$r=r(V0,"The model class to instantiate is selected based on the "),HMe=n(V0,"CODE",{});var FAt=s(HMe);r$r=r(FAt,"model_type"),FAt.forEach(t),t$r=r(V0,` property of the config object (either
passed as an argument or loaded from `),UMe=n(V0,"CODE",{});var TAt=s(UMe);a$r=r(TAt,"pretrained_model_name_or_path"),TAt.forEach(t),n$r=r(V0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JMe=n(V0,"CODE",{});var MAt=s(JMe);s$r=r(MAt,"pretrained_model_name_or_path"),MAt.forEach(t),l$r=r(V0,":"),V0.forEach(t),i$r=i(Ql),xe=n(Ql,"UL",{});var qe=s(xe);g3=n(qe,"LI",{});var SBe=s(g3);YMe=n(SBe,"STRONG",{});var EAt=s(YMe);d$r=r(EAt,"albert"),EAt.forEach(t),c$r=r(SBe," \u2014 "),tY=n(SBe,"A",{href:!0});var CAt=s(tY);f$r=r(CAt,"FlaxAlbertForMaskedLM"),CAt.forEach(t),m$r=r(SBe," (ALBERT model)"),SBe.forEach(t),g$r=i(qe),h3=n(qe,"LI",{});var RBe=s(h3);KMe=n(RBe,"STRONG",{});var wAt=s(KMe);h$r=r(wAt,"bart"),wAt.forEach(t),p$r=r(RBe," \u2014 "),aY=n(RBe,"A",{href:!0});var AAt=s(aY);u$r=r(AAt,"FlaxBartForConditionalGeneration"),AAt.forEach(t),_$r=r(RBe," (BART model)"),RBe.forEach(t),b$r=i(qe),p3=n(qe,"LI",{});var PBe=s(p3);ZMe=n(PBe,"STRONG",{});var yAt=s(ZMe);v$r=r(yAt,"bert"),yAt.forEach(t),F$r=r(PBe," \u2014 "),nY=n(PBe,"A",{href:!0});var LAt=s(nY);T$r=r(LAt,"FlaxBertForMaskedLM"),LAt.forEach(t),M$r=r(PBe," (BERT model)"),PBe.forEach(t),E$r=i(qe),u3=n(qe,"LI",{});var BBe=s(u3);e4e=n(BBe,"STRONG",{});var xAt=s(e4e);C$r=r(xAt,"big_bird"),xAt.forEach(t),w$r=r(BBe," \u2014 "),sY=n(BBe,"A",{href:!0});var $At=s(sY);A$r=r($At,"FlaxBigBirdForMaskedLM"),$At.forEach(t),y$r=r(BBe," (BigBird model)"),BBe.forEach(t),L$r=i(qe),_3=n(qe,"LI",{});var IBe=s(_3);o4e=n(IBe,"STRONG",{});var kAt=s(o4e);x$r=r(kAt,"distilbert"),kAt.forEach(t),$$r=r(IBe," \u2014 "),lY=n(IBe,"A",{href:!0});var SAt=s(lY);k$r=r(SAt,"FlaxDistilBertForMaskedLM"),SAt.forEach(t),S$r=r(IBe," (DistilBERT model)"),IBe.forEach(t),R$r=i(qe),b3=n(qe,"LI",{});var qBe=s(b3);r4e=n(qBe,"STRONG",{});var RAt=s(r4e);P$r=r(RAt,"electra"),RAt.forEach(t),B$r=r(qBe," \u2014 "),iY=n(qBe,"A",{href:!0});var PAt=s(iY);I$r=r(PAt,"FlaxElectraForMaskedLM"),PAt.forEach(t),q$r=r(qBe," (ELECTRA model)"),qBe.forEach(t),N$r=i(qe),v3=n(qe,"LI",{});var NBe=s(v3);t4e=n(NBe,"STRONG",{});var BAt=s(t4e);j$r=r(BAt,"mbart"),BAt.forEach(t),D$r=r(NBe," \u2014 "),dY=n(NBe,"A",{href:!0});var IAt=s(dY);G$r=r(IAt,"FlaxMBartForConditionalGeneration"),IAt.forEach(t),O$r=r(NBe," (mBART model)"),NBe.forEach(t),V$r=i(qe),F3=n(qe,"LI",{});var jBe=s(F3);a4e=n(jBe,"STRONG",{});var qAt=s(a4e);X$r=r(qAt,"roberta"),qAt.forEach(t),z$r=r(jBe," \u2014 "),cY=n(jBe,"A",{href:!0});var NAt=s(cY);W$r=r(NAt,"FlaxRobertaForMaskedLM"),NAt.forEach(t),Q$r=r(jBe," (RoBERTa model)"),jBe.forEach(t),H$r=i(qe),T3=n(qe,"LI",{});var DBe=s(T3);n4e=n(DBe,"STRONG",{});var jAt=s(n4e);U$r=r(jAt,"roformer"),jAt.forEach(t),J$r=r(DBe," \u2014 "),fY=n(DBe,"A",{href:!0});var DAt=s(fY);Y$r=r(DAt,"FlaxRoFormerForMaskedLM"),DAt.forEach(t),K$r=r(DBe," (RoFormer model)"),DBe.forEach(t),Z$r=i(qe),M3=n(qe,"LI",{});var GBe=s(M3);s4e=n(GBe,"STRONG",{});var GAt=s(s4e);ekr=r(GAt,"xlm-roberta"),GAt.forEach(t),okr=r(GBe," \u2014 "),mY=n(GBe,"A",{href:!0});var OAt=s(mY);rkr=r(OAt,"FlaxXLMRobertaForMaskedLM"),OAt.forEach(t),tkr=r(GBe," (XLM-RoBERTa model)"),GBe.forEach(t),qe.forEach(t),akr=i(Ql),T(E3.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),CNe=i(f),Dc=n(f,"H2",{class:!0});var kDe=s(Dc);C3=n(kDe,"A",{id:!0,class:!0,href:!0});var VAt=s(C3);l4e=n(VAt,"SPAN",{});var XAt=s(l4e);T(Lx.$$.fragment,XAt),XAt.forEach(t),VAt.forEach(t),nkr=i(kDe),i4e=n(kDe,"SPAN",{});var zAt=s(i4e);skr=r(zAt,"FlaxAutoModelForSeq2SeqLM"),zAt.forEach(t),kDe.forEach(t),wNe=i(f),pr=n(f,"DIV",{class:!0});var Hl=s(pr);T(xx.$$.fragment,Hl),lkr=i(Hl),Gc=n(Hl,"P",{});var iee=s(Gc);ikr=r(iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gY=n(iee,"A",{href:!0});var WAt=s(gY);dkr=r(WAt,"from_pretrained()"),WAt.forEach(t),ckr=r(iee," class method or the "),hY=n(iee,"A",{href:!0});var QAt=s(hY);fkr=r(QAt,"from_config()"),QAt.forEach(t),mkr=r(iee,` class
method.`),iee.forEach(t),gkr=i(Hl),$x=n(Hl,"P",{});var SDe=s($x);hkr=r(SDe,"This class cannot be instantiated directly using "),d4e=n(SDe,"CODE",{});var HAt=s(d4e);pkr=r(HAt,"__init__()"),HAt.forEach(t),ukr=r(SDe," (throws an error)."),SDe.forEach(t),_kr=i(Hl),zt=n(Hl,"DIV",{class:!0});var X0=s(zt);T(kx.$$.fragment,X0),bkr=i(X0),c4e=n(X0,"P",{});var UAt=s(c4e);vkr=r(UAt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),UAt.forEach(t),Fkr=i(X0),Oc=n(X0,"P",{});var dee=s(Oc);Tkr=r(dee,`Note:
Loading a model from its configuration file does `),f4e=n(dee,"STRONG",{});var JAt=s(f4e);Mkr=r(JAt,"not"),JAt.forEach(t),Ekr=r(dee,` load the model weights. It only affects the
model\u2019s configuration. Use `),pY=n(dee,"A",{href:!0});var YAt=s(pY);Ckr=r(YAt,"from_pretrained()"),YAt.forEach(t),wkr=r(dee," to load the model weights."),dee.forEach(t),Akr=i(X0),T(w3.$$.fragment,X0),X0.forEach(t),ykr=i(Hl),Vr=n(Hl,"DIV",{class:!0});var Ul=s(Vr);T(Sx.$$.fragment,Ul),Lkr=i(Ul),m4e=n(Ul,"P",{});var KAt=s(m4e);xkr=r(KAt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),KAt.forEach(t),$kr=i(Ul),bn=n(Ul,"P",{});var z0=s(bn);kkr=r(z0,"The model class to instantiate is selected based on the "),g4e=n(z0,"CODE",{});var ZAt=s(g4e);Skr=r(ZAt,"model_type"),ZAt.forEach(t),Rkr=r(z0,` property of the config object (either
passed as an argument or loaded from `),h4e=n(z0,"CODE",{});var e0t=s(h4e);Pkr=r(e0t,"pretrained_model_name_or_path"),e0t.forEach(t),Bkr=r(z0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p4e=n(z0,"CODE",{});var o0t=s(p4e);Ikr=r(o0t,"pretrained_model_name_or_path"),o0t.forEach(t),qkr=r(z0,":"),z0.forEach(t),Nkr=i(Ul),Pe=n(Ul,"UL",{});var ze=s(Pe);A3=n(ze,"LI",{});var OBe=s(A3);u4e=n(OBe,"STRONG",{});var r0t=s(u4e);jkr=r(r0t,"bart"),r0t.forEach(t),Dkr=r(OBe," \u2014 "),uY=n(OBe,"A",{href:!0});var t0t=s(uY);Gkr=r(t0t,"FlaxBartForConditionalGeneration"),t0t.forEach(t),Okr=r(OBe," (BART model)"),OBe.forEach(t),Vkr=i(ze),y3=n(ze,"LI",{});var VBe=s(y3);_4e=n(VBe,"STRONG",{});var a0t=s(_4e);Xkr=r(a0t,"blenderbot"),a0t.forEach(t),zkr=r(VBe," \u2014 "),_Y=n(VBe,"A",{href:!0});var n0t=s(_Y);Wkr=r(n0t,"FlaxBlenderbotForConditionalGeneration"),n0t.forEach(t),Qkr=r(VBe," (Blenderbot model)"),VBe.forEach(t),Hkr=i(ze),L3=n(ze,"LI",{});var XBe=s(L3);b4e=n(XBe,"STRONG",{});var s0t=s(b4e);Ukr=r(s0t,"blenderbot-small"),s0t.forEach(t),Jkr=r(XBe," \u2014 "),bY=n(XBe,"A",{href:!0});var l0t=s(bY);Ykr=r(l0t,"FlaxBlenderbotSmallForConditionalGeneration"),l0t.forEach(t),Kkr=r(XBe," (BlenderbotSmall model)"),XBe.forEach(t),Zkr=i(ze),x3=n(ze,"LI",{});var zBe=s(x3);v4e=n(zBe,"STRONG",{});var i0t=s(v4e);eSr=r(i0t,"encoder-decoder"),i0t.forEach(t),oSr=r(zBe," \u2014 "),vY=n(zBe,"A",{href:!0});var d0t=s(vY);rSr=r(d0t,"FlaxEncoderDecoderModel"),d0t.forEach(t),tSr=r(zBe," (Encoder decoder model)"),zBe.forEach(t),aSr=i(ze),$3=n(ze,"LI",{});var WBe=s($3);F4e=n(WBe,"STRONG",{});var c0t=s(F4e);nSr=r(c0t,"marian"),c0t.forEach(t),sSr=r(WBe," \u2014 "),FY=n(WBe,"A",{href:!0});var f0t=s(FY);lSr=r(f0t,"FlaxMarianMTModel"),f0t.forEach(t),iSr=r(WBe," (Marian model)"),WBe.forEach(t),dSr=i(ze),k3=n(ze,"LI",{});var QBe=s(k3);T4e=n(QBe,"STRONG",{});var m0t=s(T4e);cSr=r(m0t,"mbart"),m0t.forEach(t),fSr=r(QBe," \u2014 "),TY=n(QBe,"A",{href:!0});var g0t=s(TY);mSr=r(g0t,"FlaxMBartForConditionalGeneration"),g0t.forEach(t),gSr=r(QBe," (mBART model)"),QBe.forEach(t),hSr=i(ze),S3=n(ze,"LI",{});var HBe=s(S3);M4e=n(HBe,"STRONG",{});var h0t=s(M4e);pSr=r(h0t,"mt5"),h0t.forEach(t),uSr=r(HBe," \u2014 "),MY=n(HBe,"A",{href:!0});var p0t=s(MY);_Sr=r(p0t,"FlaxMT5ForConditionalGeneration"),p0t.forEach(t),bSr=r(HBe," (mT5 model)"),HBe.forEach(t),vSr=i(ze),R3=n(ze,"LI",{});var UBe=s(R3);E4e=n(UBe,"STRONG",{});var u0t=s(E4e);FSr=r(u0t,"pegasus"),u0t.forEach(t),TSr=r(UBe," \u2014 "),EY=n(UBe,"A",{href:!0});var _0t=s(EY);MSr=r(_0t,"FlaxPegasusForConditionalGeneration"),_0t.forEach(t),ESr=r(UBe," (Pegasus model)"),UBe.forEach(t),CSr=i(ze),P3=n(ze,"LI",{});var JBe=s(P3);C4e=n(JBe,"STRONG",{});var b0t=s(C4e);wSr=r(b0t,"t5"),b0t.forEach(t),ASr=r(JBe," \u2014 "),CY=n(JBe,"A",{href:!0});var v0t=s(CY);ySr=r(v0t,"FlaxT5ForConditionalGeneration"),v0t.forEach(t),LSr=r(JBe," (T5 model)"),JBe.forEach(t),ze.forEach(t),xSr=i(Ul),T(B3.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),ANe=i(f),Vc=n(f,"H2",{class:!0});var RDe=s(Vc);I3=n(RDe,"A",{id:!0,class:!0,href:!0});var F0t=s(I3);w4e=n(F0t,"SPAN",{});var T0t=s(w4e);T(Rx.$$.fragment,T0t),T0t.forEach(t),F0t.forEach(t),$Sr=i(RDe),A4e=n(RDe,"SPAN",{});var M0t=s(A4e);kSr=r(M0t,"FlaxAutoModelForSequenceClassification"),M0t.forEach(t),RDe.forEach(t),yNe=i(f),ur=n(f,"DIV",{class:!0});var Jl=s(ur);T(Px.$$.fragment,Jl),SSr=i(Jl),Xc=n(Jl,"P",{});var cee=s(Xc);RSr=r(cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wY=n(cee,"A",{href:!0});var E0t=s(wY);PSr=r(E0t,"from_pretrained()"),E0t.forEach(t),BSr=r(cee," class method or the "),AY=n(cee,"A",{href:!0});var C0t=s(AY);ISr=r(C0t,"from_config()"),C0t.forEach(t),qSr=r(cee,` class
method.`),cee.forEach(t),NSr=i(Jl),Bx=n(Jl,"P",{});var PDe=s(Bx);jSr=r(PDe,"This class cannot be instantiated directly using "),y4e=n(PDe,"CODE",{});var w0t=s(y4e);DSr=r(w0t,"__init__()"),w0t.forEach(t),GSr=r(PDe," (throws an error)."),PDe.forEach(t),OSr=i(Jl),Wt=n(Jl,"DIV",{class:!0});var W0=s(Wt);T(Ix.$$.fragment,W0),VSr=i(W0),L4e=n(W0,"P",{});var A0t=s(L4e);XSr=r(A0t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),A0t.forEach(t),zSr=i(W0),zc=n(W0,"P",{});var fee=s(zc);WSr=r(fee,`Note:
Loading a model from its configuration file does `),x4e=n(fee,"STRONG",{});var y0t=s(x4e);QSr=r(y0t,"not"),y0t.forEach(t),HSr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),yY=n(fee,"A",{href:!0});var L0t=s(yY);USr=r(L0t,"from_pretrained()"),L0t.forEach(t),JSr=r(fee," to load the model weights."),fee.forEach(t),YSr=i(W0),T(q3.$$.fragment,W0),W0.forEach(t),KSr=i(Jl),Xr=n(Jl,"DIV",{class:!0});var Yl=s(Xr);T(qx.$$.fragment,Yl),ZSr=i(Yl),$4e=n(Yl,"P",{});var x0t=s($4e);eRr=r(x0t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),x0t.forEach(t),oRr=i(Yl),vn=n(Yl,"P",{});var Q0=s(vn);rRr=r(Q0,"The model class to instantiate is selected based on the "),k4e=n(Q0,"CODE",{});var $0t=s(k4e);tRr=r($0t,"model_type"),$0t.forEach(t),aRr=r(Q0,` property of the config object (either
passed as an argument or loaded from `),S4e=n(Q0,"CODE",{});var k0t=s(S4e);nRr=r(k0t,"pretrained_model_name_or_path"),k0t.forEach(t),sRr=r(Q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=n(Q0,"CODE",{});var S0t=s(R4e);lRr=r(S0t,"pretrained_model_name_or_path"),S0t.forEach(t),iRr=r(Q0,":"),Q0.forEach(t),dRr=i(Yl),$e=n(Yl,"UL",{});var Ne=s($e);N3=n(Ne,"LI",{});var YBe=s(N3);P4e=n(YBe,"STRONG",{});var R0t=s(P4e);cRr=r(R0t,"albert"),R0t.forEach(t),fRr=r(YBe," \u2014 "),LY=n(YBe,"A",{href:!0});var P0t=s(LY);mRr=r(P0t,"FlaxAlbertForSequenceClassification"),P0t.forEach(t),gRr=r(YBe," (ALBERT model)"),YBe.forEach(t),hRr=i(Ne),j3=n(Ne,"LI",{});var KBe=s(j3);B4e=n(KBe,"STRONG",{});var B0t=s(B4e);pRr=r(B0t,"bart"),B0t.forEach(t),uRr=r(KBe," \u2014 "),xY=n(KBe,"A",{href:!0});var I0t=s(xY);_Rr=r(I0t,"FlaxBartForSequenceClassification"),I0t.forEach(t),bRr=r(KBe," (BART model)"),KBe.forEach(t),vRr=i(Ne),D3=n(Ne,"LI",{});var ZBe=s(D3);I4e=n(ZBe,"STRONG",{});var q0t=s(I4e);FRr=r(q0t,"bert"),q0t.forEach(t),TRr=r(ZBe," \u2014 "),$Y=n(ZBe,"A",{href:!0});var N0t=s($Y);MRr=r(N0t,"FlaxBertForSequenceClassification"),N0t.forEach(t),ERr=r(ZBe," (BERT model)"),ZBe.forEach(t),CRr=i(Ne),G3=n(Ne,"LI",{});var eIe=s(G3);q4e=n(eIe,"STRONG",{});var j0t=s(q4e);wRr=r(j0t,"big_bird"),j0t.forEach(t),ARr=r(eIe," \u2014 "),kY=n(eIe,"A",{href:!0});var D0t=s(kY);yRr=r(D0t,"FlaxBigBirdForSequenceClassification"),D0t.forEach(t),LRr=r(eIe," (BigBird model)"),eIe.forEach(t),xRr=i(Ne),O3=n(Ne,"LI",{});var oIe=s(O3);N4e=n(oIe,"STRONG",{});var G0t=s(N4e);$Rr=r(G0t,"distilbert"),G0t.forEach(t),kRr=r(oIe," \u2014 "),SY=n(oIe,"A",{href:!0});var O0t=s(SY);SRr=r(O0t,"FlaxDistilBertForSequenceClassification"),O0t.forEach(t),RRr=r(oIe," (DistilBERT model)"),oIe.forEach(t),PRr=i(Ne),V3=n(Ne,"LI",{});var rIe=s(V3);j4e=n(rIe,"STRONG",{});var V0t=s(j4e);BRr=r(V0t,"electra"),V0t.forEach(t),IRr=r(rIe," \u2014 "),RY=n(rIe,"A",{href:!0});var X0t=s(RY);qRr=r(X0t,"FlaxElectraForSequenceClassification"),X0t.forEach(t),NRr=r(rIe," (ELECTRA model)"),rIe.forEach(t),jRr=i(Ne),X3=n(Ne,"LI",{});var tIe=s(X3);D4e=n(tIe,"STRONG",{});var z0t=s(D4e);DRr=r(z0t,"mbart"),z0t.forEach(t),GRr=r(tIe," \u2014 "),PY=n(tIe,"A",{href:!0});var W0t=s(PY);ORr=r(W0t,"FlaxMBartForSequenceClassification"),W0t.forEach(t),VRr=r(tIe," (mBART model)"),tIe.forEach(t),XRr=i(Ne),z3=n(Ne,"LI",{});var aIe=s(z3);G4e=n(aIe,"STRONG",{});var Q0t=s(G4e);zRr=r(Q0t,"roberta"),Q0t.forEach(t),WRr=r(aIe," \u2014 "),BY=n(aIe,"A",{href:!0});var H0t=s(BY);QRr=r(H0t,"FlaxRobertaForSequenceClassification"),H0t.forEach(t),HRr=r(aIe," (RoBERTa model)"),aIe.forEach(t),URr=i(Ne),W3=n(Ne,"LI",{});var nIe=s(W3);O4e=n(nIe,"STRONG",{});var U0t=s(O4e);JRr=r(U0t,"roformer"),U0t.forEach(t),YRr=r(nIe," \u2014 "),IY=n(nIe,"A",{href:!0});var J0t=s(IY);KRr=r(J0t,"FlaxRoFormerForSequenceClassification"),J0t.forEach(t),ZRr=r(nIe," (RoFormer model)"),nIe.forEach(t),ePr=i(Ne),Q3=n(Ne,"LI",{});var sIe=s(Q3);V4e=n(sIe,"STRONG",{});var Y0t=s(V4e);oPr=r(Y0t,"xlm-roberta"),Y0t.forEach(t),rPr=r(sIe," \u2014 "),qY=n(sIe,"A",{href:!0});var K0t=s(qY);tPr=r(K0t,"FlaxXLMRobertaForSequenceClassification"),K0t.forEach(t),aPr=r(sIe," (XLM-RoBERTa model)"),sIe.forEach(t),Ne.forEach(t),nPr=i(Yl),T(H3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),LNe=i(f),Wc=n(f,"H2",{class:!0});var BDe=s(Wc);U3=n(BDe,"A",{id:!0,class:!0,href:!0});var Z0t=s(U3);X4e=n(Z0t,"SPAN",{});var e6t=s(X4e);T(Nx.$$.fragment,e6t),e6t.forEach(t),Z0t.forEach(t),sPr=i(BDe),z4e=n(BDe,"SPAN",{});var o6t=s(z4e);lPr=r(o6t,"FlaxAutoModelForQuestionAnswering"),o6t.forEach(t),BDe.forEach(t),xNe=i(f),_r=n(f,"DIV",{class:!0});var Kl=s(_r);T(jx.$$.fragment,Kl),iPr=i(Kl),Qc=n(Kl,"P",{});var mee=s(Qc);dPr=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),NY=n(mee,"A",{href:!0});var r6t=s(NY);cPr=r(r6t,"from_pretrained()"),r6t.forEach(t),fPr=r(mee," class method or the "),jY=n(mee,"A",{href:!0});var t6t=s(jY);mPr=r(t6t,"from_config()"),t6t.forEach(t),gPr=r(mee,` class
method.`),mee.forEach(t),hPr=i(Kl),Dx=n(Kl,"P",{});var IDe=s(Dx);pPr=r(IDe,"This class cannot be instantiated directly using "),W4e=n(IDe,"CODE",{});var a6t=s(W4e);uPr=r(a6t,"__init__()"),a6t.forEach(t),_Pr=r(IDe," (throws an error)."),IDe.forEach(t),bPr=i(Kl),Qt=n(Kl,"DIV",{class:!0});var H0=s(Qt);T(Gx.$$.fragment,H0),vPr=i(H0),Q4e=n(H0,"P",{});var n6t=s(Q4e);FPr=r(n6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),n6t.forEach(t),TPr=i(H0),Hc=n(H0,"P",{});var gee=s(Hc);MPr=r(gee,`Note:
Loading a model from its configuration file does `),H4e=n(gee,"STRONG",{});var s6t=s(H4e);EPr=r(s6t,"not"),s6t.forEach(t),CPr=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),DY=n(gee,"A",{href:!0});var l6t=s(DY);wPr=r(l6t,"from_pretrained()"),l6t.forEach(t),APr=r(gee," to load the model weights."),gee.forEach(t),yPr=i(H0),T(J3.$$.fragment,H0),H0.forEach(t),LPr=i(Kl),zr=n(Kl,"DIV",{class:!0});var Zl=s(zr);T(Ox.$$.fragment,Zl),xPr=i(Zl),U4e=n(Zl,"P",{});var i6t=s(U4e);$Pr=r(i6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),i6t.forEach(t),kPr=i(Zl),Fn=n(Zl,"P",{});var U0=s(Fn);SPr=r(U0,"The model class to instantiate is selected based on the "),J4e=n(U0,"CODE",{});var d6t=s(J4e);RPr=r(d6t,"model_type"),d6t.forEach(t),PPr=r(U0,` property of the config object (either
passed as an argument or loaded from `),Y4e=n(U0,"CODE",{});var c6t=s(Y4e);BPr=r(c6t,"pretrained_model_name_or_path"),c6t.forEach(t),IPr=r(U0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=n(U0,"CODE",{});var f6t=s(K4e);qPr=r(f6t,"pretrained_model_name_or_path"),f6t.forEach(t),NPr=r(U0,":"),U0.forEach(t),jPr=i(Zl),ke=n(Zl,"UL",{});var je=s(ke);Y3=n(je,"LI",{});var lIe=s(Y3);Z4e=n(lIe,"STRONG",{});var m6t=s(Z4e);DPr=r(m6t,"albert"),m6t.forEach(t),GPr=r(lIe," \u2014 "),GY=n(lIe,"A",{href:!0});var g6t=s(GY);OPr=r(g6t,"FlaxAlbertForQuestionAnswering"),g6t.forEach(t),VPr=r(lIe," (ALBERT model)"),lIe.forEach(t),XPr=i(je),K3=n(je,"LI",{});var iIe=s(K3);eEe=n(iIe,"STRONG",{});var h6t=s(eEe);zPr=r(h6t,"bart"),h6t.forEach(t),WPr=r(iIe," \u2014 "),OY=n(iIe,"A",{href:!0});var p6t=s(OY);QPr=r(p6t,"FlaxBartForQuestionAnswering"),p6t.forEach(t),HPr=r(iIe," (BART model)"),iIe.forEach(t),UPr=i(je),Z3=n(je,"LI",{});var dIe=s(Z3);oEe=n(dIe,"STRONG",{});var u6t=s(oEe);JPr=r(u6t,"bert"),u6t.forEach(t),YPr=r(dIe," \u2014 "),VY=n(dIe,"A",{href:!0});var _6t=s(VY);KPr=r(_6t,"FlaxBertForQuestionAnswering"),_6t.forEach(t),ZPr=r(dIe," (BERT model)"),dIe.forEach(t),eBr=i(je),ew=n(je,"LI",{});var cIe=s(ew);rEe=n(cIe,"STRONG",{});var b6t=s(rEe);oBr=r(b6t,"big_bird"),b6t.forEach(t),rBr=r(cIe," \u2014 "),XY=n(cIe,"A",{href:!0});var v6t=s(XY);tBr=r(v6t,"FlaxBigBirdForQuestionAnswering"),v6t.forEach(t),aBr=r(cIe," (BigBird model)"),cIe.forEach(t),nBr=i(je),ow=n(je,"LI",{});var fIe=s(ow);tEe=n(fIe,"STRONG",{});var F6t=s(tEe);sBr=r(F6t,"distilbert"),F6t.forEach(t),lBr=r(fIe," \u2014 "),zY=n(fIe,"A",{href:!0});var T6t=s(zY);iBr=r(T6t,"FlaxDistilBertForQuestionAnswering"),T6t.forEach(t),dBr=r(fIe," (DistilBERT model)"),fIe.forEach(t),cBr=i(je),rw=n(je,"LI",{});var mIe=s(rw);aEe=n(mIe,"STRONG",{});var M6t=s(aEe);fBr=r(M6t,"electra"),M6t.forEach(t),mBr=r(mIe," \u2014 "),WY=n(mIe,"A",{href:!0});var E6t=s(WY);gBr=r(E6t,"FlaxElectraForQuestionAnswering"),E6t.forEach(t),hBr=r(mIe," (ELECTRA model)"),mIe.forEach(t),pBr=i(je),tw=n(je,"LI",{});var gIe=s(tw);nEe=n(gIe,"STRONG",{});var C6t=s(nEe);uBr=r(C6t,"mbart"),C6t.forEach(t),_Br=r(gIe," \u2014 "),QY=n(gIe,"A",{href:!0});var w6t=s(QY);bBr=r(w6t,"FlaxMBartForQuestionAnswering"),w6t.forEach(t),vBr=r(gIe," (mBART model)"),gIe.forEach(t),FBr=i(je),aw=n(je,"LI",{});var hIe=s(aw);sEe=n(hIe,"STRONG",{});var A6t=s(sEe);TBr=r(A6t,"roberta"),A6t.forEach(t),MBr=r(hIe," \u2014 "),HY=n(hIe,"A",{href:!0});var y6t=s(HY);EBr=r(y6t,"FlaxRobertaForQuestionAnswering"),y6t.forEach(t),CBr=r(hIe," (RoBERTa model)"),hIe.forEach(t),wBr=i(je),nw=n(je,"LI",{});var pIe=s(nw);lEe=n(pIe,"STRONG",{});var L6t=s(lEe);ABr=r(L6t,"roformer"),L6t.forEach(t),yBr=r(pIe," \u2014 "),UY=n(pIe,"A",{href:!0});var x6t=s(UY);LBr=r(x6t,"FlaxRoFormerForQuestionAnswering"),x6t.forEach(t),xBr=r(pIe," (RoFormer model)"),pIe.forEach(t),$Br=i(je),sw=n(je,"LI",{});var uIe=s(sw);iEe=n(uIe,"STRONG",{});var $6t=s(iEe);kBr=r($6t,"xlm-roberta"),$6t.forEach(t),SBr=r(uIe," \u2014 "),JY=n(uIe,"A",{href:!0});var k6t=s(JY);RBr=r(k6t,"FlaxXLMRobertaForQuestionAnswering"),k6t.forEach(t),PBr=r(uIe," (XLM-RoBERTa model)"),uIe.forEach(t),je.forEach(t),BBr=i(Zl),T(lw.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),$Ne=i(f),Uc=n(f,"H2",{class:!0});var qDe=s(Uc);iw=n(qDe,"A",{id:!0,class:!0,href:!0});var S6t=s(iw);dEe=n(S6t,"SPAN",{});var R6t=s(dEe);T(Vx.$$.fragment,R6t),R6t.forEach(t),S6t.forEach(t),IBr=i(qDe),cEe=n(qDe,"SPAN",{});var P6t=s(cEe);qBr=r(P6t,"FlaxAutoModelForTokenClassification"),P6t.forEach(t),qDe.forEach(t),kNe=i(f),br=n(f,"DIV",{class:!0});var ei=s(br);T(Xx.$$.fragment,ei),NBr=i(ei),Jc=n(ei,"P",{});var hee=s(Jc);jBr=r(hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YY=n(hee,"A",{href:!0});var B6t=s(YY);DBr=r(B6t,"from_pretrained()"),B6t.forEach(t),GBr=r(hee," class method or the "),KY=n(hee,"A",{href:!0});var I6t=s(KY);OBr=r(I6t,"from_config()"),I6t.forEach(t),VBr=r(hee,` class
method.`),hee.forEach(t),XBr=i(ei),zx=n(ei,"P",{});var NDe=s(zx);zBr=r(NDe,"This class cannot be instantiated directly using "),fEe=n(NDe,"CODE",{});var q6t=s(fEe);WBr=r(q6t,"__init__()"),q6t.forEach(t),QBr=r(NDe," (throws an error)."),NDe.forEach(t),HBr=i(ei),Ht=n(ei,"DIV",{class:!0});var J0=s(Ht);T(Wx.$$.fragment,J0),UBr=i(J0),mEe=n(J0,"P",{});var N6t=s(mEe);JBr=r(N6t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),N6t.forEach(t),YBr=i(J0),Yc=n(J0,"P",{});var pee=s(Yc);KBr=r(pee,`Note:
Loading a model from its configuration file does `),gEe=n(pee,"STRONG",{});var j6t=s(gEe);ZBr=r(j6t,"not"),j6t.forEach(t),eIr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZY=n(pee,"A",{href:!0});var D6t=s(ZY);oIr=r(D6t,"from_pretrained()"),D6t.forEach(t),rIr=r(pee," to load the model weights."),pee.forEach(t),tIr=i(J0),T(dw.$$.fragment,J0),J0.forEach(t),aIr=i(ei),Wr=n(ei,"DIV",{class:!0});var oi=s(Wr);T(Qx.$$.fragment,oi),nIr=i(oi),hEe=n(oi,"P",{});var G6t=s(hEe);sIr=r(G6t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),G6t.forEach(t),lIr=i(oi),Tn=n(oi,"P",{});var Y0=s(Tn);iIr=r(Y0,"The model class to instantiate is selected based on the "),pEe=n(Y0,"CODE",{});var O6t=s(pEe);dIr=r(O6t,"model_type"),O6t.forEach(t),cIr=r(Y0,` property of the config object (either
passed as an argument or loaded from `),uEe=n(Y0,"CODE",{});var V6t=s(uEe);fIr=r(V6t,"pretrained_model_name_or_path"),V6t.forEach(t),mIr=r(Y0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Ee=n(Y0,"CODE",{});var X6t=s(_Ee);gIr=r(X6t,"pretrained_model_name_or_path"),X6t.forEach(t),hIr=r(Y0,":"),Y0.forEach(t),pIr=i(oi),Ge=n(oi,"UL",{});var Fo=s(Ge);cw=n(Fo,"LI",{});var _Ie=s(cw);bEe=n(_Ie,"STRONG",{});var z6t=s(bEe);uIr=r(z6t,"albert"),z6t.forEach(t),_Ir=r(_Ie," \u2014 "),eK=n(_Ie,"A",{href:!0});var W6t=s(eK);bIr=r(W6t,"FlaxAlbertForTokenClassification"),W6t.forEach(t),vIr=r(_Ie," (ALBERT model)"),_Ie.forEach(t),FIr=i(Fo),fw=n(Fo,"LI",{});var bIe=s(fw);vEe=n(bIe,"STRONG",{});var Q6t=s(vEe);TIr=r(Q6t,"bert"),Q6t.forEach(t),MIr=r(bIe," \u2014 "),oK=n(bIe,"A",{href:!0});var H6t=s(oK);EIr=r(H6t,"FlaxBertForTokenClassification"),H6t.forEach(t),CIr=r(bIe," (BERT model)"),bIe.forEach(t),wIr=i(Fo),mw=n(Fo,"LI",{});var vIe=s(mw);FEe=n(vIe,"STRONG",{});var U6t=s(FEe);AIr=r(U6t,"big_bird"),U6t.forEach(t),yIr=r(vIe," \u2014 "),rK=n(vIe,"A",{href:!0});var J6t=s(rK);LIr=r(J6t,"FlaxBigBirdForTokenClassification"),J6t.forEach(t),xIr=r(vIe," (BigBird model)"),vIe.forEach(t),$Ir=i(Fo),gw=n(Fo,"LI",{});var FIe=s(gw);TEe=n(FIe,"STRONG",{});var Y6t=s(TEe);kIr=r(Y6t,"distilbert"),Y6t.forEach(t),SIr=r(FIe," \u2014 "),tK=n(FIe,"A",{href:!0});var K6t=s(tK);RIr=r(K6t,"FlaxDistilBertForTokenClassification"),K6t.forEach(t),PIr=r(FIe," (DistilBERT model)"),FIe.forEach(t),BIr=i(Fo),hw=n(Fo,"LI",{});var TIe=s(hw);MEe=n(TIe,"STRONG",{});var Z6t=s(MEe);IIr=r(Z6t,"electra"),Z6t.forEach(t),qIr=r(TIe," \u2014 "),aK=n(TIe,"A",{href:!0});var eyt=s(aK);NIr=r(eyt,"FlaxElectraForTokenClassification"),eyt.forEach(t),jIr=r(TIe," (ELECTRA model)"),TIe.forEach(t),DIr=i(Fo),pw=n(Fo,"LI",{});var MIe=s(pw);EEe=n(MIe,"STRONG",{});var oyt=s(EEe);GIr=r(oyt,"roberta"),oyt.forEach(t),OIr=r(MIe," \u2014 "),nK=n(MIe,"A",{href:!0});var ryt=s(nK);VIr=r(ryt,"FlaxRobertaForTokenClassification"),ryt.forEach(t),XIr=r(MIe," (RoBERTa model)"),MIe.forEach(t),zIr=i(Fo),uw=n(Fo,"LI",{});var EIe=s(uw);CEe=n(EIe,"STRONG",{});var tyt=s(CEe);WIr=r(tyt,"roformer"),tyt.forEach(t),QIr=r(EIe," \u2014 "),sK=n(EIe,"A",{href:!0});var ayt=s(sK);HIr=r(ayt,"FlaxRoFormerForTokenClassification"),ayt.forEach(t),UIr=r(EIe," (RoFormer model)"),EIe.forEach(t),JIr=i(Fo),_w=n(Fo,"LI",{});var CIe=s(_w);wEe=n(CIe,"STRONG",{});var nyt=s(wEe);YIr=r(nyt,"xlm-roberta"),nyt.forEach(t),KIr=r(CIe," \u2014 "),lK=n(CIe,"A",{href:!0});var syt=s(lK);ZIr=r(syt,"FlaxXLMRobertaForTokenClassification"),syt.forEach(t),eqr=r(CIe," (XLM-RoBERTa model)"),CIe.forEach(t),Fo.forEach(t),oqr=i(oi),T(bw.$$.fragment,oi),oi.forEach(t),ei.forEach(t),SNe=i(f),Kc=n(f,"H2",{class:!0});var jDe=s(Kc);vw=n(jDe,"A",{id:!0,class:!0,href:!0});var lyt=s(vw);AEe=n(lyt,"SPAN",{});var iyt=s(AEe);T(Hx.$$.fragment,iyt),iyt.forEach(t),lyt.forEach(t),rqr=i(jDe),yEe=n(jDe,"SPAN",{});var dyt=s(yEe);tqr=r(dyt,"FlaxAutoModelForMultipleChoice"),dyt.forEach(t),jDe.forEach(t),RNe=i(f),vr=n(f,"DIV",{class:!0});var ri=s(vr);T(Ux.$$.fragment,ri),aqr=i(ri),Zc=n(ri,"P",{});var uee=s(Zc);nqr=r(uee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),iK=n(uee,"A",{href:!0});var cyt=s(iK);sqr=r(cyt,"from_pretrained()"),cyt.forEach(t),lqr=r(uee," class method or the "),dK=n(uee,"A",{href:!0});var fyt=s(dK);iqr=r(fyt,"from_config()"),fyt.forEach(t),dqr=r(uee,` class
method.`),uee.forEach(t),cqr=i(ri),Jx=n(ri,"P",{});var DDe=s(Jx);fqr=r(DDe,"This class cannot be instantiated directly using "),LEe=n(DDe,"CODE",{});var myt=s(LEe);mqr=r(myt,"__init__()"),myt.forEach(t),gqr=r(DDe," (throws an error)."),DDe.forEach(t),hqr=i(ri),Ut=n(ri,"DIV",{class:!0});var K0=s(Ut);T(Yx.$$.fragment,K0),pqr=i(K0),xEe=n(K0,"P",{});var gyt=s(xEe);uqr=r(gyt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),gyt.forEach(t),_qr=i(K0),ef=n(K0,"P",{});var _ee=s(ef);bqr=r(_ee,`Note:
Loading a model from its configuration file does `),$Ee=n(_ee,"STRONG",{});var hyt=s($Ee);vqr=r(hyt,"not"),hyt.forEach(t),Fqr=r(_ee,` load the model weights. It only affects the
model\u2019s configuration. Use `),cK=n(_ee,"A",{href:!0});var pyt=s(cK);Tqr=r(pyt,"from_pretrained()"),pyt.forEach(t),Mqr=r(_ee," to load the model weights."),_ee.forEach(t),Eqr=i(K0),T(Fw.$$.fragment,K0),K0.forEach(t),Cqr=i(ri),Qr=n(ri,"DIV",{class:!0});var ti=s(Qr);T(Kx.$$.fragment,ti),wqr=i(ti),kEe=n(ti,"P",{});var uyt=s(kEe);Aqr=r(uyt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),uyt.forEach(t),yqr=i(ti),Mn=n(ti,"P",{});var Z0=s(Mn);Lqr=r(Z0,"The model class to instantiate is selected based on the "),SEe=n(Z0,"CODE",{});var _yt=s(SEe);xqr=r(_yt,"model_type"),_yt.forEach(t),$qr=r(Z0,` property of the config object (either
passed as an argument or loaded from `),REe=n(Z0,"CODE",{});var byt=s(REe);kqr=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),Sqr=r(Z0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PEe=n(Z0,"CODE",{});var vyt=s(PEe);Rqr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),Pqr=r(Z0,":"),Z0.forEach(t),Bqr=i(ti),Oe=n(ti,"UL",{});var To=s(Oe);Tw=n(To,"LI",{});var wIe=s(Tw);BEe=n(wIe,"STRONG",{});var Fyt=s(BEe);Iqr=r(Fyt,"albert"),Fyt.forEach(t),qqr=r(wIe," \u2014 "),fK=n(wIe,"A",{href:!0});var Tyt=s(fK);Nqr=r(Tyt,"FlaxAlbertForMultipleChoice"),Tyt.forEach(t),jqr=r(wIe," (ALBERT model)"),wIe.forEach(t),Dqr=i(To),Mw=n(To,"LI",{});var AIe=s(Mw);IEe=n(AIe,"STRONG",{});var Myt=s(IEe);Gqr=r(Myt,"bert"),Myt.forEach(t),Oqr=r(AIe," \u2014 "),mK=n(AIe,"A",{href:!0});var Eyt=s(mK);Vqr=r(Eyt,"FlaxBertForMultipleChoice"),Eyt.forEach(t),Xqr=r(AIe," (BERT model)"),AIe.forEach(t),zqr=i(To),Ew=n(To,"LI",{});var yIe=s(Ew);qEe=n(yIe,"STRONG",{});var Cyt=s(qEe);Wqr=r(Cyt,"big_bird"),Cyt.forEach(t),Qqr=r(yIe," \u2014 "),gK=n(yIe,"A",{href:!0});var wyt=s(gK);Hqr=r(wyt,"FlaxBigBirdForMultipleChoice"),wyt.forEach(t),Uqr=r(yIe," (BigBird model)"),yIe.forEach(t),Jqr=i(To),Cw=n(To,"LI",{});var LIe=s(Cw);NEe=n(LIe,"STRONG",{});var Ayt=s(NEe);Yqr=r(Ayt,"distilbert"),Ayt.forEach(t),Kqr=r(LIe," \u2014 "),hK=n(LIe,"A",{href:!0});var yyt=s(hK);Zqr=r(yyt,"FlaxDistilBertForMultipleChoice"),yyt.forEach(t),eNr=r(LIe," (DistilBERT model)"),LIe.forEach(t),oNr=i(To),ww=n(To,"LI",{});var xIe=s(ww);jEe=n(xIe,"STRONG",{});var Lyt=s(jEe);rNr=r(Lyt,"electra"),Lyt.forEach(t),tNr=r(xIe," \u2014 "),pK=n(xIe,"A",{href:!0});var xyt=s(pK);aNr=r(xyt,"FlaxElectraForMultipleChoice"),xyt.forEach(t),nNr=r(xIe," (ELECTRA model)"),xIe.forEach(t),sNr=i(To),Aw=n(To,"LI",{});var $Ie=s(Aw);DEe=n($Ie,"STRONG",{});var $yt=s(DEe);lNr=r($yt,"roberta"),$yt.forEach(t),iNr=r($Ie," \u2014 "),uK=n($Ie,"A",{href:!0});var kyt=s(uK);dNr=r(kyt,"FlaxRobertaForMultipleChoice"),kyt.forEach(t),cNr=r($Ie," (RoBERTa model)"),$Ie.forEach(t),fNr=i(To),yw=n(To,"LI",{});var kIe=s(yw);GEe=n(kIe,"STRONG",{});var Syt=s(GEe);mNr=r(Syt,"roformer"),Syt.forEach(t),gNr=r(kIe," \u2014 "),_K=n(kIe,"A",{href:!0});var Ryt=s(_K);hNr=r(Ryt,"FlaxRoFormerForMultipleChoice"),Ryt.forEach(t),pNr=r(kIe," (RoFormer model)"),kIe.forEach(t),uNr=i(To),Lw=n(To,"LI",{});var SIe=s(Lw);OEe=n(SIe,"STRONG",{});var Pyt=s(OEe);_Nr=r(Pyt,"xlm-roberta"),Pyt.forEach(t),bNr=r(SIe," \u2014 "),bK=n(SIe,"A",{href:!0});var Byt=s(bK);vNr=r(Byt,"FlaxXLMRobertaForMultipleChoice"),Byt.forEach(t),FNr=r(SIe," (XLM-RoBERTa model)"),SIe.forEach(t),To.forEach(t),TNr=i(ti),T(xw.$$.fragment,ti),ti.forEach(t),ri.forEach(t),PNe=i(f),of=n(f,"H2",{class:!0});var GDe=s(of);$w=n(GDe,"A",{id:!0,class:!0,href:!0});var Iyt=s($w);VEe=n(Iyt,"SPAN",{});var qyt=s(VEe);T(Zx.$$.fragment,qyt),qyt.forEach(t),Iyt.forEach(t),MNr=i(GDe),XEe=n(GDe,"SPAN",{});var Nyt=s(XEe);ENr=r(Nyt,"FlaxAutoModelForNextSentencePrediction"),Nyt.forEach(t),GDe.forEach(t),BNe=i(f),Fr=n(f,"DIV",{class:!0});var ai=s(Fr);T(e9.$$.fragment,ai),CNr=i(ai),rf=n(ai,"P",{});var bee=s(rf);wNr=r(bee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),vK=n(bee,"A",{href:!0});var jyt=s(vK);ANr=r(jyt,"from_pretrained()"),jyt.forEach(t),yNr=r(bee," class method or the "),FK=n(bee,"A",{href:!0});var Dyt=s(FK);LNr=r(Dyt,"from_config()"),Dyt.forEach(t),xNr=r(bee,` class
method.`),bee.forEach(t),$Nr=i(ai),o9=n(ai,"P",{});var ODe=s(o9);kNr=r(ODe,"This class cannot be instantiated directly using "),zEe=n(ODe,"CODE",{});var Gyt=s(zEe);SNr=r(Gyt,"__init__()"),Gyt.forEach(t),RNr=r(ODe," (throws an error)."),ODe.forEach(t),PNr=i(ai),Jt=n(ai,"DIV",{class:!0});var e6=s(Jt);T(r9.$$.fragment,e6),BNr=i(e6),WEe=n(e6,"P",{});var Oyt=s(WEe);INr=r(Oyt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Oyt.forEach(t),qNr=i(e6),tf=n(e6,"P",{});var vee=s(tf);NNr=r(vee,`Note:
Loading a model from its configuration file does `),QEe=n(vee,"STRONG",{});var Vyt=s(QEe);jNr=r(Vyt,"not"),Vyt.forEach(t),DNr=r(vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),TK=n(vee,"A",{href:!0});var Xyt=s(TK);GNr=r(Xyt,"from_pretrained()"),Xyt.forEach(t),ONr=r(vee," to load the model weights."),vee.forEach(t),VNr=i(e6),T(kw.$$.fragment,e6),e6.forEach(t),XNr=i(ai),Hr=n(ai,"DIV",{class:!0});var ni=s(Hr);T(t9.$$.fragment,ni),zNr=i(ni),HEe=n(ni,"P",{});var zyt=s(HEe);WNr=r(zyt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),zyt.forEach(t),QNr=i(ni),En=n(ni,"P",{});var o6=s(En);HNr=r(o6,"The model class to instantiate is selected based on the "),UEe=n(o6,"CODE",{});var Wyt=s(UEe);UNr=r(Wyt,"model_type"),Wyt.forEach(t),JNr=r(o6,` property of the config object (either
passed as an argument or loaded from `),JEe=n(o6,"CODE",{});var Qyt=s(JEe);YNr=r(Qyt,"pretrained_model_name_or_path"),Qyt.forEach(t),KNr=r(o6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YEe=n(o6,"CODE",{});var Hyt=s(YEe);ZNr=r(Hyt,"pretrained_model_name_or_path"),Hyt.forEach(t),ejr=r(o6,":"),o6.forEach(t),ojr=i(ni),KEe=n(ni,"UL",{});var Uyt=s(KEe);Sw=n(Uyt,"LI",{});var RIe=s(Sw);ZEe=n(RIe,"STRONG",{});var Jyt=s(ZEe);rjr=r(Jyt,"bert"),Jyt.forEach(t),tjr=r(RIe," \u2014 "),MK=n(RIe,"A",{href:!0});var Yyt=s(MK);ajr=r(Yyt,"FlaxBertForNextSentencePrediction"),Yyt.forEach(t),njr=r(RIe," (BERT model)"),RIe.forEach(t),Uyt.forEach(t),sjr=i(ni),T(Rw.$$.fragment,ni),ni.forEach(t),ai.forEach(t),INe=i(f),af=n(f,"H2",{class:!0});var VDe=s(af);Pw=n(VDe,"A",{id:!0,class:!0,href:!0});var Kyt=s(Pw);eCe=n(Kyt,"SPAN",{});var Zyt=s(eCe);T(a9.$$.fragment,Zyt),Zyt.forEach(t),Kyt.forEach(t),ljr=i(VDe),oCe=n(VDe,"SPAN",{});var eLt=s(oCe);ijr=r(eLt,"FlaxAutoModelForImageClassification"),eLt.forEach(t),VDe.forEach(t),qNe=i(f),Tr=n(f,"DIV",{class:!0});var si=s(Tr);T(n9.$$.fragment,si),djr=i(si),nf=n(si,"P",{});var Fee=s(nf);cjr=r(Fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),EK=n(Fee,"A",{href:!0});var oLt=s(EK);fjr=r(oLt,"from_pretrained()"),oLt.forEach(t),mjr=r(Fee," class method or the "),CK=n(Fee,"A",{href:!0});var rLt=s(CK);gjr=r(rLt,"from_config()"),rLt.forEach(t),hjr=r(Fee,` class
method.`),Fee.forEach(t),pjr=i(si),s9=n(si,"P",{});var XDe=s(s9);ujr=r(XDe,"This class cannot be instantiated directly using "),rCe=n(XDe,"CODE",{});var tLt=s(rCe);_jr=r(tLt,"__init__()"),tLt.forEach(t),bjr=r(XDe," (throws an error)."),XDe.forEach(t),vjr=i(si),Yt=n(si,"DIV",{class:!0});var r6=s(Yt);T(l9.$$.fragment,r6),Fjr=i(r6),tCe=n(r6,"P",{});var aLt=s(tCe);Tjr=r(aLt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aLt.forEach(t),Mjr=i(r6),sf=n(r6,"P",{});var Tee=s(sf);Ejr=r(Tee,`Note:
Loading a model from its configuration file does `),aCe=n(Tee,"STRONG",{});var nLt=s(aCe);Cjr=r(nLt,"not"),nLt.forEach(t),wjr=r(Tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=n(Tee,"A",{href:!0});var sLt=s(wK);Ajr=r(sLt,"from_pretrained()"),sLt.forEach(t),yjr=r(Tee," to load the model weights."),Tee.forEach(t),Ljr=i(r6),T(Bw.$$.fragment,r6),r6.forEach(t),xjr=i(si),Ur=n(si,"DIV",{class:!0});var li=s(Ur);T(i9.$$.fragment,li),$jr=i(li),nCe=n(li,"P",{});var lLt=s(nCe);kjr=r(lLt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lLt.forEach(t),Sjr=i(li),Cn=n(li,"P",{});var t6=s(Cn);Rjr=r(t6,"The model class to instantiate is selected based on the "),sCe=n(t6,"CODE",{});var iLt=s(sCe);Pjr=r(iLt,"model_type"),iLt.forEach(t),Bjr=r(t6,` property of the config object (either
passed as an argument or loaded from `),lCe=n(t6,"CODE",{});var dLt=s(lCe);Ijr=r(dLt,"pretrained_model_name_or_path"),dLt.forEach(t),qjr=r(t6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=n(t6,"CODE",{});var cLt=s(iCe);Njr=r(cLt,"pretrained_model_name_or_path"),cLt.forEach(t),jjr=r(t6,":"),t6.forEach(t),Djr=i(li),d9=n(li,"UL",{});var zDe=s(d9);Iw=n(zDe,"LI",{});var PIe=s(Iw);dCe=n(PIe,"STRONG",{});var fLt=s(dCe);Gjr=r(fLt,"beit"),fLt.forEach(t),Ojr=r(PIe," \u2014 "),AK=n(PIe,"A",{href:!0});var mLt=s(AK);Vjr=r(mLt,"FlaxBeitForImageClassification"),mLt.forEach(t),Xjr=r(PIe," (BEiT model)"),PIe.forEach(t),zjr=i(zDe),qw=n(zDe,"LI",{});var BIe=s(qw);cCe=n(BIe,"STRONG",{});var gLt=s(cCe);Wjr=r(gLt,"vit"),gLt.forEach(t),Qjr=r(BIe," \u2014 "),yK=n(BIe,"A",{href:!0});var hLt=s(yK);Hjr=r(hLt,"FlaxViTForImageClassification"),hLt.forEach(t),Ujr=r(BIe," (ViT model)"),BIe.forEach(t),zDe.forEach(t),Jjr=i(li),T(Nw.$$.fragment,li),li.forEach(t),si.forEach(t),NNe=i(f),lf=n(f,"H2",{class:!0});var WDe=s(lf);jw=n(WDe,"A",{id:!0,class:!0,href:!0});var pLt=s(jw);fCe=n(pLt,"SPAN",{});var uLt=s(fCe);T(c9.$$.fragment,uLt),uLt.forEach(t),pLt.forEach(t),Yjr=i(WDe),mCe=n(WDe,"SPAN",{});var _Lt=s(mCe);Kjr=r(_Lt,"FlaxAutoModelForVision2Seq"),_Lt.forEach(t),WDe.forEach(t),jNe=i(f),Mr=n(f,"DIV",{class:!0});var ii=s(Mr);T(f9.$$.fragment,ii),Zjr=i(ii),df=n(ii,"P",{});var Mee=s(df);eDr=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),LK=n(Mee,"A",{href:!0});var bLt=s(LK);oDr=r(bLt,"from_pretrained()"),bLt.forEach(t),rDr=r(Mee," class method or the "),xK=n(Mee,"A",{href:!0});var vLt=s(xK);tDr=r(vLt,"from_config()"),vLt.forEach(t),aDr=r(Mee,` class
method.`),Mee.forEach(t),nDr=i(ii),m9=n(ii,"P",{});var QDe=s(m9);sDr=r(QDe,"This class cannot be instantiated directly using "),gCe=n(QDe,"CODE",{});var FLt=s(gCe);lDr=r(FLt,"__init__()"),FLt.forEach(t),iDr=r(QDe," (throws an error)."),QDe.forEach(t),dDr=i(ii),Kt=n(ii,"DIV",{class:!0});var a6=s(Kt);T(g9.$$.fragment,a6),cDr=i(a6),hCe=n(a6,"P",{});var TLt=s(hCe);fDr=r(TLt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),TLt.forEach(t),mDr=i(a6),cf=n(a6,"P",{});var Eee=s(cf);gDr=r(Eee,`Note:
Loading a model from its configuration file does `),pCe=n(Eee,"STRONG",{});var MLt=s(pCe);hDr=r(MLt,"not"),MLt.forEach(t),pDr=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),$K=n(Eee,"A",{href:!0});var ELt=s($K);uDr=r(ELt,"from_pretrained()"),ELt.forEach(t),_Dr=r(Eee," to load the model weights."),Eee.forEach(t),bDr=i(a6),T(Dw.$$.fragment,a6),a6.forEach(t),vDr=i(ii),Jr=n(ii,"DIV",{class:!0});var di=s(Jr);T(h9.$$.fragment,di),FDr=i(di),uCe=n(di,"P",{});var CLt=s(uCe);TDr=r(CLt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CLt.forEach(t),MDr=i(di),wn=n(di,"P",{});var n6=s(wn);EDr=r(n6,"The model class to instantiate is selected based on the "),_Ce=n(n6,"CODE",{});var wLt=s(_Ce);CDr=r(wLt,"model_type"),wLt.forEach(t),wDr=r(n6,` property of the config object (either
passed as an argument or loaded from `),bCe=n(n6,"CODE",{});var ALt=s(bCe);ADr=r(ALt,"pretrained_model_name_or_path"),ALt.forEach(t),yDr=r(n6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vCe=n(n6,"CODE",{});var yLt=s(vCe);LDr=r(yLt,"pretrained_model_name_or_path"),yLt.forEach(t),xDr=r(n6,":"),n6.forEach(t),$Dr=i(di),FCe=n(di,"UL",{});var LLt=s(FCe);Gw=n(LLt,"LI",{});var IIe=s(Gw);TCe=n(IIe,"STRONG",{});var xLt=s(TCe);kDr=r(xLt,"vision-encoder-decoder"),xLt.forEach(t),SDr=r(IIe," \u2014 "),kK=n(IIe,"A",{href:!0});var $Lt=s(kK);RDr=r($Lt,"FlaxVisionEncoderDecoderModel"),$Lt.forEach(t),PDr=r(IIe," (Vision Encoder decoder model)"),IIe.forEach(t),LLt.forEach(t),BDr=i(di),T(Ow.$$.fragment,di),di.forEach(t),ii.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Pxt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoTokenizer"),c(ui,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertModel"),c(bf,"id","extending-the-auto-classes"),c(bf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bf,"href","#extending-the-auto-classes"),c(_i,"class","relative group"),c(Ff,"id","transformers.AutoConfig"),c(Ff,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ff,"href","#transformers.AutoConfig"),c(bi,"class","relative group"),c(R$,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(P$,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig"),c(B$,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig"),c(I$,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig"),c(q$,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig"),c(N$,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(j$,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig"),c(D$,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(G$,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(O$,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(V$,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig"),c(X$,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig"),c(z$,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig"),c(W$,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig"),c(Q$,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig"),c(H$,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig"),c(U$,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(J$,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(Y$,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(K$,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig"),c(Z$,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(ek,"href","/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(ok,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig"),c(rk,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig"),c(tk,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig"),c(ak,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRConfig"),c(nk,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTConfig"),c(sk,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig"),c(lk,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(ik,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig"),c(dk,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaConfig"),c(ck,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig"),c(fk,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig"),c(mk,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig"),c(gk,"href","/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNConfig"),c(hk,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config"),c(pk,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(uk,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig"),c(_k,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig"),c(bk,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig"),c(vk,"href","/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Fk,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Tk,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(Mk,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig"),c(Ek,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig"),c(Ck,"href","/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeConfig"),c(wk,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig"),c(Ak,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Config"),c(yk,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig"),c(Lk,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(xk,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig"),c($k,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(kk,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(Sk,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig"),c(Rk,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config"),c(Pk,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(Bk,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(Ik,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig"),c(qk,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig"),c(Nk,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig"),c(jk,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig"),c(Dk,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(Gk,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(Ok,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(Vk,"href","/docs/transformers/pr_17227/en/model_doc/rag#transformers.RagConfig"),c(Xk,"href","/docs/transformers/pr_17227/en/model_doc/realm#transformers.RealmConfig"),c(zk,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig"),c(Wk,"href","/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetConfig"),c(Qk,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig"),c(Hk,"href","/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetConfig"),c(Uk,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertConfig"),c(Jk,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig"),c(Yk,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig"),c(Kk,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig"),c(Zk,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig"),c(eS,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig"),c(oS,"href","/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(rS,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(tS,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(aS,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig"),c(nS,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(sS,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig"),c(lS,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config"),c(iS,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig"),c(dS,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(cS,"href","/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRConfig"),c(fS,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(mS,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(gS,"href","/docs/transformers/pr_17227/en/model_doc/van#transformers.VanConfig"),c(hS,"href","/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltConfig"),c(pS,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(uS,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(_S,"href","/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(bS,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig"),c(vS,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(FS,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(TS,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(MS,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig"),c(ES,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig"),c(CS,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig"),c(wS,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(AS,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(yS,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(LS,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig"),c(xS,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosConfig"),c($S,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fg,"id","transformers.AutoTokenizer"),c(Fg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fg,"href","#transformers.AutoTokenizer"),c(Fi,"class","relative group"),c(kS,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(SS,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizer"),c(RS,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(PS,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartTokenizer"),c(BS,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartTokenizerFast"),c(IS,"href","/docs/transformers/pr_17227/en/model_doc/barthez#transformers.BarthezTokenizer"),c(qS,"href","/docs/transformers/pr_17227/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(NS,"href","/docs/transformers/pr_17227/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(jS,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(DS,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(GS,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(OS,"href","/docs/transformers/pr_17227/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(VS,"href","/docs/transformers/pr_17227/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(XS,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(zS,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(WS,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(QS,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(HS,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(US,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(JS,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(YS,"href","/docs/transformers/pr_17227/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(KS,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertTokenizer"),c(ZS,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(eR,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineTokenizer"),c(oR,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPTokenizer"),c(rR,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(tR,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(aR,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(nR,"href","/docs/transformers/pr_17227/en/model_doc/cpm#transformers.CpmTokenizer"),c(sR,"href","/docs/transformers/pr_17227/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(lR,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(iR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(dR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(cR,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaTokenizer"),c(fR,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(mR,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(gR,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(hR,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(pR,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(uR,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(_R,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(bR,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraTokenizer"),c(vR,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(FR,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(TR,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetTokenizer"),c(MR,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(ER,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(CR,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelTokenizer"),c(wR,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(AR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(yR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(LR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(xR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c($R,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(kR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(SR,"href","/docs/transformers/pr_17227/en/model_doc/herbert#transformers.HerbertTokenizer"),c(RR,"href","/docs/transformers/pr_17227/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(PR,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(BR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(IR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(NR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(jR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(DR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(GR,"href","/docs/transformers/pr_17227/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(OR,"href","/docs/transformers/pr_17227/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(VR,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDTokenizer"),c(XR,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDTokenizerFast"),c(zR,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerTokenizer"),c(WR,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(QR,"href","/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeTokenizer"),c(HR,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(UR,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(JR,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(YR,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianTokenizer"),c(KR,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartTokenizer"),c(ZR,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(eP,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(oP,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(rP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(tP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(aP,"href","/docs/transformers/pr_17227/en/model_doc/mluke#transformers.MLukeTokenizer"),c(nP,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(sP,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(lP,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(iP,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(dP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5Tokenizer"),c(cP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5TokenizerFast"),c(fP,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizer"),c(mP,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(gP,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(hP,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(pP,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(uP,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(_P,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(bP,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(vP,"href","/docs/transformers/pr_17227/en/model_doc/phobert#transformers.PhobertTokenizer"),c(FP,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartTokenizer"),c(TP,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(MP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(EP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(CP,"href","/docs/transformers/pr_17227/en/model_doc/rag#transformers.RagTokenizer"),c(wP,"href","/docs/transformers/pr_17227/en/model_doc/realm#transformers.RealmTokenizer"),c(AP,"href","/docs/transformers/pr_17227/en/model_doc/realm#transformers.RealmTokenizerFast"),c(yP,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerTokenizer"),c(LP,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(xP,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertTokenizer"),c($P,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(kP,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(SP,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(RP,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(PP,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(BP,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(IP,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(qP,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(NP,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(jP,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterTokenizer"),c(DP,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(GP,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(OP,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(VP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5Tokenizer"),c(XP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5TokenizerFast"),c(zP,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasTokenizer"),c(WP,"href","/docs/transformers/pr_17227/en/model_doc/tapex#transformers.TapexTokenizer"),c(QP,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(HP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(UP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(JP,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(YP,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(KP,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(ZP,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMTokenizer"),c(eB,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(oB,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMTokenizer"),c(rB,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(tB,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(aB,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(nB,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(sB,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(lB,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(iB,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(dB,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizer"),c(cB,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eh,"id","transformers.AutoFeatureExtractor"),c(eh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eh,"href","#transformers.AutoFeatureExtractor"),c(Ti,"class","relative group"),c(fB,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(mB,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(gB,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(hB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(pB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(uB,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(_B,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(bB,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(vB,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(FB,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(TB,"href","/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(MB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(EB,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(CB,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(wB,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(AB,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(yB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(xB,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c($B,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(kB,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(SB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(RB,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PB,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(qB,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($h,"id","transformers.AutoProcessor"),c($h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($h,"href","#transformers.AutoProcessor"),c(Mi,"class","relative group"),c(NB,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jB,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPProcessor"),c(DB,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(GB,"href","/docs/transformers/pr_17227/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(OB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(VB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(XB,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(zB,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(WB,"href","/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRProcessor"),c(QB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UB,"href","/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltProcessor"),c(JB,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(YB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(KB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jh,"id","transformers.AutoModel"),c(Jh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jh,"href","#transformers.AutoModel"),c(Ci,"class","relative group"),c(eI,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oI,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rI,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tI,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertModel"),c(aI,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartModel"),c(nI,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitModel"),c(sI,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertModel"),c(lI,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(iI,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdModel"),c(dI,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(cI,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(fI,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(mI,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertModel"),c(gI,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineModel"),c(hI,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPModel"),c(pI,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertModel"),c(uI,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextModel"),c(_I,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLModel"),c(bI,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(vI,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(FI,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(TI,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaModel"),c(MI,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(EI,"href","/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(CI,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTModel"),c(wI,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrModel"),c(AI,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertModel"),c(yI,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(LI,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTModel"),c(xI,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraModel"),c($I,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertModel"),c(kI,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaModel"),c(SI,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetModel"),c(RI,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTModel"),c(PI,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelModel"),c(BI,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelBaseModel"),c(II,"href","/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNModel"),c(qI,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Model"),c(NI,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(jI,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJModel"),c(DI,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertModel"),c(GI,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertModel"),c(OI,"href","/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(VI,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(XI,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(zI,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDModel"),c(WI,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerModel"),c(QI,"href","/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeModel"),c(HI,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertModel"),c(UI,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Model"),c(JI,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianModel"),c(YI,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerModel"),c(KI,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartModel"),c(ZI,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(eq,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertModel"),c(oq,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetModel"),c(rq,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Model"),c(tq,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerModel"),c(aq,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(nq,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTModel"),c(sq,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusModel"),c(lq,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverModel"),c(iq,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartModel"),c(dq,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerModel"),c(cq,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(fq,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertModel"),c(mq,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModel"),c(gq,"href","/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetModel"),c(hq,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertModel"),c(pq,"href","/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetModel"),c(uq,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel"),c(_q,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaModel"),c(bq,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerModel"),c(vq,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerModel"),c(Fq,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWModel"),c(Tq,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDModel"),c(Mq,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Eq,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterModel"),c(Cq,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(wq,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinModel"),c(Aq,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Model"),c(yq,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasModel"),c(Lq,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(xq,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechModel"),c($q,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(kq,"href","/docs/transformers/pr_17227/en/model_doc/van#transformers.VanModel"),c(Sq,"href","/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltModel"),c(Rq,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Pq,"href","/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Bq,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTModel"),c(Iq,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(qq,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Nq,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(jq,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMModel"),c(Dq,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMModel"),c(Gq,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMModel"),c(Oq,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Vq,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Xq,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(zq,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetModel"),c(Wq,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosModel"),c(Qq,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vu,"id","transformers.AutoModelForPreTraining"),c(Vu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vu,"href","#transformers.AutoModelForPreTraining"),c(yi,"class","relative group"),c(Hq,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uq,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jq,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yq,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Kq,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Zq,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForPreTraining"),c(eN,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(oN,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(rN,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(tN,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(aN,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(nN,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(sN,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(lN,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForPreTraining"),c(iN,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(dN,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaForPreTraining"),c(cN,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForPreTraining"),c(fN,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(mN,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(gN,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(hN,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(pN,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(uN,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(_N,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(bN,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(vN,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(FN,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(TN,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(MN,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel"),c(EN,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(CN,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(wN,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(AN,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(yN,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(LN,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(xN,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c($N,"href","/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(kN,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(SN,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(RN,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(PN,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(BN,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(IN,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(qN,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P_,"id","transformers.AutoModelForCausalLM"),c(P_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P_,"href","#transformers.AutoModelForCausalLM"),c($i,"class","relative group"),c(NN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GN,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForCausalLM"),c(ON,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertLMHeadModel"),c(VN,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(XN,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(zN,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(WN,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(QN,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(HN,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(UN,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(JN,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(YN,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForCausalLM"),c(KN,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(ZN,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(ej,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(oj,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianForCausalLM"),c(rj,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForCausalLM"),c(tj,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(aj,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(nj,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTForCausalLM"),c(sj,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(lj,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(ij,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(dj,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(cj,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(fj,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(mj,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(gj,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(hj,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(pj,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(uj,"href","/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(_j,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(bj,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(vj,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(Fj,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(Tj,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(Mj,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F2,"id","transformers.AutoModelForMaskedLM"),c(F2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F2,"href","#transformers.AutoModelForMaskedLM"),c(Ri,"class","relative group"),c(Ej,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cj,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wj,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Aj,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(yj,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Lj,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMaskedLM"),c(xj,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c($j,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(kj,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(Sj,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(Rj,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Pj,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(Bj,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Ij,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(qj,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Nj,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(jj,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(Dj,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(Gj,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(Oj,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(Vj,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(Xj,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(zj,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(Wj,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(Qj,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(Hj,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(Uj,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(Jj,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(Yj,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(Kj,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(Zj,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(eD,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(oD,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(rD,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(tD,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(aD,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(nD,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n1,"id","transformers.AutoModelForSeq2SeqLM"),c(n1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Ii,"class","relative group"),c(sD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dD,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(cD,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(fD,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(mD,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(gD,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(hD,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(pD,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(uD,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(_D,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianMTModel"),c(bD,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(vD,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(FD,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(TD,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(MD,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(CD,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w1,"id","transformers.AutoModelForSequenceClassification"),c(w1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w1,"href","#transformers.AutoModelForSequenceClassification"),c(ji,"class","relative group"),c(wD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LD,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(xD,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForSequenceClassification"),c($D,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForSequenceClassification"),c(kD,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(SD,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(RD,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(PD,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(BD,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(ID,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(qD,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(ND,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(jD,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(DD,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(GD,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(OD,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(VD,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(XD,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(zD,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(WD,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(QD,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(HD,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(UD,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(JD,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(YD,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForSequenceClassification"),c(KD,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(ZD,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(eG,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(oG,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(rG,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(tG,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(aG,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(nG,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(sG,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(lG,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(iG,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(dG,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(cG,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(fG,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(mG,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(gG,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(hG,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(pG,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(uG,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(_G,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(bG,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(vG,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T7,"id","transformers.AutoModelForMultipleChoice"),c(T7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T7,"href","#transformers.AutoModelForMultipleChoice"),c(Oi,"class","relative group"),c(FG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EG,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(CG,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMultipleChoice"),c(wG,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(AG,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(yG,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(LG,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(xG,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c($G,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(kG,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(SG,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(RG,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(PG,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(BG,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(IG,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(qG,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(NG,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(jG,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(DG,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(GG,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(OG,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(VG,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(XG,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(zG,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(WG,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(QG,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(HG,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(UG,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(JG,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(YG,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eb,"id","transformers.AutoModelForNextSentencePrediction"),c(eb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eb,"href","#transformers.AutoModelForNextSentencePrediction"),c(zi,"class","relative group"),c(KG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oO,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(rO,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(tO,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(aO,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(nO,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(db,"id","transformers.AutoModelForTokenClassification"),c(db,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(db,"href","#transformers.AutoModelForTokenClassification"),c(Hi,"class","relative group"),c(sO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dO,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(cO,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForTokenClassification"),c(fO,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(mO,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(gO,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForTokenClassification"),c(hO,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(pO,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(uO,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(_O,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(bO,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(vO,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(FO,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(TO,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(MO,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(EO,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(CO,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(wO,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(AO,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(yO,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(LO,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(xO,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c($O,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(kO,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(SO,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(RO,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(PO,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(BO,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(IO,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(qO,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(NO,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(jO,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(DO,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(GO,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wb,"id","transformers.AutoModelForQuestionAnswering"),c(Wb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wb,"href","#transformers.AutoModelForQuestionAnswering"),c(Yi,"class","relative group"),c(OO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zO,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(WO,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(QO,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(HO,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(UO,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(JO,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(YO,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(KO,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(ZO,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(eV,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(oV,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(rV,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(tV,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(aV,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(nV,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(sV,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(lV,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(iV,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(dV,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(cV,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(fV,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(mV,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(gV,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(hV,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(pV,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(uV,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(_V,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(bV,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(vV,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(FV,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(TV,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(MV,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(EV,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(CV,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(wV,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(AV,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(yV,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(LV,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(xV,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bv,"id","transformers.AutoModelForTableQuestionAnswering"),c(Bv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bv,"href","#transformers.AutoModelForTableQuestionAnswering"),c(ed,"class","relative group"),c($V,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RV,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dv,"id","transformers.AutoModelForImageClassification"),c(Dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dv,"href","#transformers.AutoModelForImageClassification"),c(td,"class","relative group"),c(PV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qV,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForImageClassification"),c(NV,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(jV,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(DV,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassification"),c(GV,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(OV,"href","/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(VV,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(XV,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(zV,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(WV,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(QV,"href","/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(HV,"href","/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(UV,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(JV,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForImageClassification"),c(YV,"href","/docs/transformers/pr_17227/en/model_doc/van#transformers.VanForImageClassification"),c(KV,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oF,"id","transformers.AutoModelForVision2Seq"),c(oF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oF,"href","#transformers.AutoModelForVision2Seq"),c(sd,"class","relative group"),c(ZV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rX,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sF,"id","transformers.AutoModelForAudioClassification"),c(sF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sF,"href","#transformers.AutoModelForAudioClassification"),c(dd,"class","relative group"),c(tX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(lX,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(iX,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(dX,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(cX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(fX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(mX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(gX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(hX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vF,"id","transformers.AutoModelForAudioFrameClassification"),c(vF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vF,"href","#transformers.AutoModelForAudioFrameClassification"),c(md,"class","relative group"),c(pX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_X,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(vX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(FX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(TX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(MX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LF,"id","transformers.AutoModelForCTC"),c(LF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LF,"href","#transformers.AutoModelForCTC"),c(pd,"class","relative group"),c(EX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(yX,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForCTC"),c(LX,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForCTC"),c(xX,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForCTC"),c($X,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(kX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(SX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(RX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(PX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForCTC"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(GF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(bd,"class","relative group"),c(BX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NX,"href","/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(jX,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QF,"id","transformers.AutoModelForAudioXVector"),c(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QF,"href","#transformers.AutoModelForAudioXVector"),c(Td,"class","relative group"),c(DX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(XX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(zX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(WX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(QX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForXVector"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rT,"id","transformers.AutoModelForMaskedImageModeling"),c(rT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rT,"href","#transformers.AutoModelForMaskedImageModeling"),c(Cd,"class","relative group"),c(HX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YX,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(KX,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(ZX,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dT,"id","transformers.AutoModelForObjectDetection"),c(dT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dT,"href","#transformers.AutoModelForObjectDetection"),c(Ld,"class","relative group"),c(ez,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tz,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForObjectDetection"),c(az,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pT,"id","transformers.AutoModelForImageSegmentation"),c(pT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pT,"href","#transformers.AutoModelForImageSegmentation"),c(kd,"class","relative group"),c(nz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iz,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForSegmentation"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FT,"id","transformers.AutoModelForSemanticSegmentation"),c(FT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FT,"href","#transformers.AutoModelForSemanticSegmentation"),c(Pd,"class","relative group"),c(dz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mz,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(gz,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(hz,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(pz,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LT,"id","transformers.AutoModelForInstanceSegmentation"),c(LT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LT,"href","#transformers.AutoModelForInstanceSegmentation"),c(qd,"class","relative group"),c(uz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_z,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vz,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RT,"id","transformers.TFAutoModel"),c(RT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RT,"href","#transformers.TFAutoModel"),c(Dd,"class","relative group"),c(Fz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ez,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertModel"),c(Cz,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartModel"),c(wz,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertModel"),c(Az,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(yz,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(Lz,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertModel"),c(xz,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.TFCLIPModel"),c($z,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertModel"),c(kz,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextModel"),c(Sz,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLModel"),c(Rz,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(Pz,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaModel"),c(Bz,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(Iz,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(qz,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(Nz,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraModel"),c(jz,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(Dz,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelModel"),c(Gz,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(Oz,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2Model"),c(Vz,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJModel"),c(Xz,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.TFHubertModel"),c(zz,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(Wz,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDModel"),c(Qz,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerModel"),c(Hz,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Uz,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianModel"),c(Jz,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartModel"),c(Yz,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(Kz,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetModel"),c(Zz,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5Model"),c(eW,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(oW,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.TFOPTModel"),c(rW,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusModel"),c(tW,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertModel"),c(aW,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaModel"),c(nW,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerModel"),c(sW,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(lW,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinModel"),c(iW,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5Model"),c(dW,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasModel"),c(cW,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(fW,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTModel"),c(mW,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(gW,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(hW,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMModel"),c(pW,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(uW,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LM,"id","transformers.TFAutoModelForPreTraining"),c(LM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LM,"href","#transformers.TFAutoModelForPreTraining"),c(Vd,"class","relative group"),c(_W,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FW,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(TW,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(MW,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForPreTraining"),c(EW,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(CW,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(wW,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(AW,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(yW,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(LW,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(xW,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c($W,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(kW,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(SW,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(RW,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(PW,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(BW,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(IW,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(qW,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(NW,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(jW,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(DW,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(GW,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(OW,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e4,"id","transformers.TFAutoModelForCausalLM"),c(e4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e4,"href","#transformers.TFAutoModelForCausalLM"),c(Wd,"class","relative group"),c(VW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WW,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(QW,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(HW,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(UW,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(JW,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(YW,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(KW,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(ZW,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(eQ,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(oQ,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(rQ,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(tQ,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p4,"id","transformers.TFAutoModelForImageClassification"),c(p4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p4,"href","#transformers.TFAutoModelForImageClassification"),c(Ud,"class","relative group"),c(aQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lQ,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(iQ,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(dQ,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(cQ,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M4,"id","transformers.TFAutoModelForMaskedLM"),c(M4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M4,"href","#transformers.TFAutoModelForMaskedLM"),c(Kd,"class","relative group"),c(fQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hQ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(pQ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(uQ,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(_Q,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(bQ,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(vQ,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(FQ,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(TQ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(MQ,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(EQ,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(CQ,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(wQ,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(AQ,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(yQ,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(LQ,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(xQ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c($Q,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(kQ,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(SQ,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(RQ,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z4,"id","transformers.TFAutoModelForSeq2SeqLM"),c(z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z4,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(oc,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qQ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(NQ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(jQ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(DQ,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(GQ,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(OQ,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianMTModel"),c(VQ,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(XQ,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(zQ,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(WQ,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aE,"id","transformers.TFAutoModelForSequenceClassification"),c(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aE,"href","#transformers.TFAutoModelForSequenceClassification"),c(ac,"class","relative group"),c(QQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JQ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(YQ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(KQ,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(ZQ,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(eH,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(oH,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(rH,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(tH,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(aH,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(nH,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(sH,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(lH,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(iH,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(dH,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(cH,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(fH,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(mH,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(gH,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(hH,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(pH,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(uH,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(_H,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(bH,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(vH,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(FH,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(TH,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RE,"id","transformers.TFAutoModelForMultipleChoice"),c(RE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RE,"href","#transformers.TFAutoModelForMultipleChoice"),c(lc,"class","relative group"),c(MH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wH,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(AH,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(yH,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(LH,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(xH,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c($H,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(kH,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(SH,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(RH,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(PH,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(BH,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(IH,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(qH,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(NH,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(jH,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(DH,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(GH,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZE,"id","transformers.TFAutoModelForNextSentencePrediction"),c(ZE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZE,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(cc,"class","relative group"),c(OH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zH,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(WH,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aC,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(gc,"class","relative group"),c(QH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JH,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iC,"id","transformers.TFAutoModelForTokenClassification"),c(iC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iC,"href","#transformers.TFAutoModelForTokenClassification"),c(uc,"class","relative group"),c(YH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eU,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(oU,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(rU,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(tU,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(aU,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(nU,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(sU,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(lU,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(iU,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(dU,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(cU,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(fU,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(mU,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(gU,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(hU,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(pU,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(uU,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(_U,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(bU,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(vU,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kC,"id","transformers.TFAutoModelForQuestionAnswering"),c(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(vc,"class","relative group"),c(FU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EU,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(CU,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(wU,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(AU,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(yU,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(LU,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(xU,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c($U,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(kU,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(SU,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(RU,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(PU,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(BU,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(IU,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(qU,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(NU,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(jU,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(DU,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(GU,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(OU,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e5,"id","transformers.TFAutoModelForVision2Seq"),c(e5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e5,"href","#transformers.TFAutoModelForVision2Seq"),c(Mc,"class","relative group"),c(VU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WU,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(a5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(wc,"class","relative group"),c(QU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JU,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i5,"id","transformers.FlaxAutoModel"),c(i5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i5,"href","#transformers.FlaxAutoModel"),c(Lc,"class","relative group"),c(YU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eJ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertModel"),c(oJ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartModel"),c(rJ,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitModel"),c(tJ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertModel"),c(aJ,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(nJ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(sJ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(lJ,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.FlaxCLIPModel"),c(iJ,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(dJ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraModel"),c(cJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(fJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(mJ,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(gJ,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianModel"),c(hJ,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartModel"),c(pJ,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5Model"),c(uJ,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTModel"),c(_J,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(bJ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(vJ,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(FJ,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5Model"),c(TJ,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(MJ,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTModel"),c(EJ,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(CJ,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(wJ,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q5,"id","transformers.FlaxAutoModelForCausalLM"),c(q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q5,"href","#transformers.FlaxAutoModelForCausalLM"),c(kc,"class","relative group"),c(AJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xJ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c($J,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(kJ,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(SJ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(RJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(PJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(BJ,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(IJ,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(qJ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(NJ,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J5,"id","transformers.FlaxAutoModelForPreTraining"),c(J5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Pc,"class","relative group"),c(jJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OJ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(VJ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(XJ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(zJ,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(WJ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(QJ,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(HJ,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(UJ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(JJ,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(YJ,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(KJ,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(ZJ,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f3,"id","transformers.FlaxAutoModelForMaskedLM"),c(f3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f3,"href","#transformers.FlaxAutoModelForMaskedLM"),c(qc,"class","relative group"),c(eY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tY,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(aY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(nY,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(sY,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(lY,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(iY,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(dY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(cY,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(fY,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(mY,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C3,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(C3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C3,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Dc,"class","relative group"),c(gY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(_Y,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(bY,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(vY,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(FY,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(TY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(MY,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(EY,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(CY,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(I3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Vc,"class","relative group"),c(wY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LY,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(xY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c($Y,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(kY,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(SY,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(RY,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(PY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(BY,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(IY,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(qY,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U3,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(U3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Wc,"class","relative group"),c(NY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GY,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(OY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(VY,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(XY,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(zY,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(WY,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(QY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(HY,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(UY,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(JY,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iw,"id","transformers.FlaxAutoModelForTokenClassification"),c(iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Uc,"class","relative group"),c(YY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eK,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(oK,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(rK,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(tK,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(aK,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(nK,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(sK,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(lK,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(Kc,"class","relative group"),c(iK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fK,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(mK,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(gK,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(hK,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(pK,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(uK,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(_K,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(bK,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($w,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c($w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($w,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(of,"class","relative group"),c(vK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MK,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pw,"id","transformers.FlaxAutoModelForImageClassification"),c(Pw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pw,"href","#transformers.FlaxAutoModelForImageClassification"),c(af,"class","relative group"),c(EK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AK,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(yK,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jw,"id","transformers.FlaxAutoModelForVision2Seq"),c(jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jw,"href","#transformers.FlaxAutoModelForVision2Seq"),c(lf,"class","relative group"),c(LK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($K,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kK,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Mo),e(Mo,ci),b(f,hf,_),b(f,rt,_),e(rt,fi),e(rt,mi),e(mi,s6),e(rt,pf),b(f,De,_),b(f,We,_),e(We,gi),e(We,yn),e(yn,l6),e(We,Ln),e(We,xn),e(xn,i6),e(We,hi),e(We,$n),e($n,d6),e(We,pi),b(f,uf,_),M(Ca,f,_),b(f,Qe,_),b(f,Ae,_),e(Ae,y$),e(Ae,ui),e(ui,L$),e(Ae,x$),b(f,Eo,_),b(f,wa,_),e(wa,$$),e(wa,_f),e(_f,k$),e(wa,HDe),b(f,qIe,_),b(f,_i,_),e(_i,bf),e(bf,Cee),M(c6,Cee,null),e(_i,UDe),e(_i,wee),e(wee,JDe),b(f,NIe,_),b(f,kn,_),e(kn,YDe),e(kn,Aee),e(Aee,KDe),e(kn,ZDe),e(kn,yee),e(yee,eGe),e(kn,oGe),b(f,jIe,_),M(f6,f,_),b(f,DIe,_),b(f,S$,_),e(S$,rGe),b(f,GIe,_),M(vf,f,_),b(f,OIe,_),b(f,bi,_),e(bi,Ff),e(Ff,Lee),M(m6,Lee,null),e(bi,tGe),e(bi,xee),e(xee,aGe),b(f,VIe,_),b(f,Co,_),M(g6,Co,null),e(Co,nGe),e(Co,h6),e(h6,sGe),e(h6,R$),e(R$,lGe),e(h6,iGe),e(Co,dGe),e(Co,p6),e(p6,cGe),e(p6,$ee),e($ee,fGe),e(p6,mGe),e(Co,gGe),e(Co,Er),M(u6,Er,null),e(Er,hGe),e(Er,kee),e(kee,pGe),e(Er,uGe),e(Er,vi),e(vi,_Ge),e(vi,See),e(See,bGe),e(vi,vGe),e(vi,Ree),e(Ree,FGe),e(vi,TGe),e(Er,MGe),e(Er,A),e(A,Tf),e(Tf,Pee),e(Pee,EGe),e(Tf,CGe),e(Tf,P$),e(P$,wGe),e(Tf,AGe),e(A,yGe),e(A,Mf),e(Mf,Bee),e(Bee,LGe),e(Mf,xGe),e(Mf,B$),e(B$,$Ge),e(Mf,kGe),e(A,SGe),e(A,Ef),e(Ef,Iee),e(Iee,RGe),e(Ef,PGe),e(Ef,I$),e(I$,BGe),e(Ef,IGe),e(A,qGe),e(A,Cf),e(Cf,qee),e(qee,NGe),e(Cf,jGe),e(Cf,q$),e(q$,DGe),e(Cf,GGe),e(A,OGe),e(A,wf),e(wf,Nee),e(Nee,VGe),e(wf,XGe),e(wf,N$),e(N$,zGe),e(wf,WGe),e(A,QGe),e(A,Af),e(Af,jee),e(jee,HGe),e(Af,UGe),e(Af,j$),e(j$,JGe),e(Af,YGe),e(A,KGe),e(A,yf),e(yf,Dee),e(Dee,ZGe),e(yf,eOe),e(yf,D$),e(D$,oOe),e(yf,rOe),e(A,tOe),e(A,Lf),e(Lf,Gee),e(Gee,aOe),e(Lf,nOe),e(Lf,G$),e(G$,sOe),e(Lf,lOe),e(A,iOe),e(A,xf),e(xf,Oee),e(Oee,dOe),e(xf,cOe),e(xf,O$),e(O$,fOe),e(xf,mOe),e(A,gOe),e(A,$f),e($f,Vee),e(Vee,hOe),e($f,pOe),e($f,V$),e(V$,uOe),e($f,_Oe),e(A,bOe),e(A,kf),e(kf,Xee),e(Xee,vOe),e(kf,FOe),e(kf,X$),e(X$,TOe),e(kf,MOe),e(A,EOe),e(A,Sf),e(Sf,zee),e(zee,COe),e(Sf,wOe),e(Sf,z$),e(z$,AOe),e(Sf,yOe),e(A,LOe),e(A,Rf),e(Rf,Wee),e(Wee,xOe),e(Rf,$Oe),e(Rf,W$),e(W$,kOe),e(Rf,SOe),e(A,ROe),e(A,Pf),e(Pf,Qee),e(Qee,POe),e(Pf,BOe),e(Pf,Q$),e(Q$,IOe),e(Pf,qOe),e(A,NOe),e(A,Bf),e(Bf,Hee),e(Hee,jOe),e(Bf,DOe),e(Bf,H$),e(H$,GOe),e(Bf,OOe),e(A,VOe),e(A,If),e(If,Uee),e(Uee,XOe),e(If,zOe),e(If,U$),e(U$,WOe),e(If,QOe),e(A,HOe),e(A,qf),e(qf,Jee),e(Jee,UOe),e(qf,JOe),e(qf,J$),e(J$,YOe),e(qf,KOe),e(A,ZOe),e(A,Nf),e(Nf,Yee),e(Yee,eVe),e(Nf,oVe),e(Nf,Y$),e(Y$,rVe),e(Nf,tVe),e(A,aVe),e(A,jf),e(jf,Kee),e(Kee,nVe),e(jf,sVe),e(jf,K$),e(K$,lVe),e(jf,iVe),e(A,dVe),e(A,Df),e(Df,Zee),e(Zee,cVe),e(Df,fVe),e(Df,Z$),e(Z$,mVe),e(Df,gVe),e(A,hVe),e(A,Gf),e(Gf,eoe),e(eoe,pVe),e(Gf,uVe),e(Gf,ek),e(ek,_Ve),e(Gf,bVe),e(A,vVe),e(A,Of),e(Of,ooe),e(ooe,FVe),e(Of,TVe),e(Of,ok),e(ok,MVe),e(Of,EVe),e(A,CVe),e(A,Vf),e(Vf,roe),e(roe,wVe),e(Vf,AVe),e(Vf,rk),e(rk,yVe),e(Vf,LVe),e(A,xVe),e(A,Xf),e(Xf,toe),e(toe,$Ve),e(Xf,kVe),e(Xf,tk),e(tk,SVe),e(Xf,RVe),e(A,PVe),e(A,zf),e(zf,aoe),e(aoe,BVe),e(zf,IVe),e(zf,ak),e(ak,qVe),e(zf,NVe),e(A,jVe),e(A,Wf),e(Wf,noe),e(noe,DVe),e(Wf,GVe),e(Wf,nk),e(nk,OVe),e(Wf,VVe),e(A,XVe),e(A,Qf),e(Qf,soe),e(soe,zVe),e(Qf,WVe),e(Qf,sk),e(sk,QVe),e(Qf,HVe),e(A,UVe),e(A,Hf),e(Hf,loe),e(loe,JVe),e(Hf,YVe),e(Hf,lk),e(lk,KVe),e(Hf,ZVe),e(A,eXe),e(A,Uf),e(Uf,ioe),e(ioe,oXe),e(Uf,rXe),e(Uf,ik),e(ik,tXe),e(Uf,aXe),e(A,nXe),e(A,Jf),e(Jf,doe),e(doe,sXe),e(Jf,lXe),e(Jf,dk),e(dk,iXe),e(Jf,dXe),e(A,cXe),e(A,Yf),e(Yf,coe),e(coe,fXe),e(Yf,mXe),e(Yf,ck),e(ck,gXe),e(Yf,hXe),e(A,pXe),e(A,Kf),e(Kf,foe),e(foe,uXe),e(Kf,_Xe),e(Kf,fk),e(fk,bXe),e(Kf,vXe),e(A,FXe),e(A,Zf),e(Zf,moe),e(moe,TXe),e(Zf,MXe),e(Zf,mk),e(mk,EXe),e(Zf,CXe),e(A,wXe),e(A,em),e(em,goe),e(goe,AXe),e(em,yXe),e(em,gk),e(gk,LXe),e(em,xXe),e(A,$Xe),e(A,om),e(om,hoe),e(hoe,kXe),e(om,SXe),e(om,hk),e(hk,RXe),e(om,PXe),e(A,BXe),e(A,rm),e(rm,poe),e(poe,IXe),e(rm,qXe),e(rm,pk),e(pk,NXe),e(rm,jXe),e(A,DXe),e(A,tm),e(tm,uoe),e(uoe,GXe),e(tm,OXe),e(tm,uk),e(uk,VXe),e(tm,XXe),e(A,zXe),e(A,am),e(am,_oe),e(_oe,WXe),e(am,QXe),e(am,_k),e(_k,HXe),e(am,UXe),e(A,JXe),e(A,nm),e(nm,boe),e(boe,YXe),e(nm,KXe),e(nm,bk),e(bk,ZXe),e(nm,eze),e(A,oze),e(A,sm),e(sm,voe),e(voe,rze),e(sm,tze),e(sm,vk),e(vk,aze),e(sm,nze),e(A,sze),e(A,lm),e(lm,Foe),e(Foe,lze),e(lm,ize),e(lm,Fk),e(Fk,dze),e(lm,cze),e(A,fze),e(A,im),e(im,Toe),e(Toe,mze),e(im,gze),e(im,Tk),e(Tk,hze),e(im,pze),e(A,uze),e(A,dm),e(dm,Moe),e(Moe,_ze),e(dm,bze),e(dm,Mk),e(Mk,vze),e(dm,Fze),e(A,Tze),e(A,cm),e(cm,Eoe),e(Eoe,Mze),e(cm,Eze),e(cm,Ek),e(Ek,Cze),e(cm,wze),e(A,Aze),e(A,fm),e(fm,Coe),e(Coe,yze),e(fm,Lze),e(fm,Ck),e(Ck,xze),e(fm,$ze),e(A,kze),e(A,mm),e(mm,woe),e(woe,Sze),e(mm,Rze),e(mm,wk),e(wk,Pze),e(mm,Bze),e(A,Ize),e(A,gm),e(gm,Aoe),e(Aoe,qze),e(gm,Nze),e(gm,Ak),e(Ak,jze),e(gm,Dze),e(A,Gze),e(A,hm),e(hm,yoe),e(yoe,Oze),e(hm,Vze),e(hm,yk),e(yk,Xze),e(hm,zze),e(A,Wze),e(A,pm),e(pm,Loe),e(Loe,Qze),e(pm,Hze),e(pm,Lk),e(Lk,Uze),e(pm,Jze),e(A,Yze),e(A,um),e(um,xoe),e(xoe,Kze),e(um,Zze),e(um,xk),e(xk,eWe),e(um,oWe),e(A,rWe),e(A,_m),e(_m,$oe),e($oe,tWe),e(_m,aWe),e(_m,$k),e($k,nWe),e(_m,sWe),e(A,lWe),e(A,bm),e(bm,koe),e(koe,iWe),e(bm,dWe),e(bm,kk),e(kk,cWe),e(bm,fWe),e(A,mWe),e(A,vm),e(vm,Soe),e(Soe,gWe),e(vm,hWe),e(vm,Sk),e(Sk,pWe),e(vm,uWe),e(A,_We),e(A,Fm),e(Fm,Roe),e(Roe,bWe),e(Fm,vWe),e(Fm,Rk),e(Rk,FWe),e(Fm,TWe),e(A,MWe),e(A,Tm),e(Tm,Poe),e(Poe,EWe),e(Tm,CWe),e(Tm,Pk),e(Pk,wWe),e(Tm,AWe),e(A,yWe),e(A,Mm),e(Mm,Boe),e(Boe,LWe),e(Mm,xWe),e(Mm,Bk),e(Bk,$We),e(Mm,kWe),e(A,SWe),e(A,Em),e(Em,Ioe),e(Ioe,RWe),e(Em,PWe),e(Em,Ik),e(Ik,BWe),e(Em,IWe),e(A,qWe),e(A,Cm),e(Cm,qoe),e(qoe,NWe),e(Cm,jWe),e(Cm,qk),e(qk,DWe),e(Cm,GWe),e(A,OWe),e(A,wm),e(wm,Noe),e(Noe,VWe),e(wm,XWe),e(wm,Nk),e(Nk,zWe),e(wm,WWe),e(A,QWe),e(A,Am),e(Am,joe),e(joe,HWe),e(Am,UWe),e(Am,jk),e(jk,JWe),e(Am,YWe),e(A,KWe),e(A,ym),e(ym,Doe),e(Doe,ZWe),e(ym,eQe),e(ym,Dk),e(Dk,oQe),e(ym,rQe),e(A,tQe),e(A,Lm),e(Lm,Goe),e(Goe,aQe),e(Lm,nQe),e(Lm,Gk),e(Gk,sQe),e(Lm,lQe),e(A,iQe),e(A,xm),e(xm,Ooe),e(Ooe,dQe),e(xm,cQe),e(xm,Ok),e(Ok,fQe),e(xm,mQe),e(A,gQe),e(A,$m),e($m,Voe),e(Voe,hQe),e($m,pQe),e($m,Vk),e(Vk,uQe),e($m,_Qe),e(A,bQe),e(A,km),e(km,Xoe),e(Xoe,vQe),e(km,FQe),e(km,Xk),e(Xk,TQe),e(km,MQe),e(A,EQe),e(A,Sm),e(Sm,zoe),e(zoe,CQe),e(Sm,wQe),e(Sm,zk),e(zk,AQe),e(Sm,yQe),e(A,LQe),e(A,Rm),e(Rm,Woe),e(Woe,xQe),e(Rm,$Qe),e(Rm,Wk),e(Wk,kQe),e(Rm,SQe),e(A,RQe),e(A,Pm),e(Pm,Qoe),e(Qoe,PQe),e(Pm,BQe),e(Pm,Qk),e(Qk,IQe),e(Pm,qQe),e(A,NQe),e(A,Bm),e(Bm,Hoe),e(Hoe,jQe),e(Bm,DQe),e(Bm,Hk),e(Hk,GQe),e(Bm,OQe),e(A,VQe),e(A,Im),e(Im,Uoe),e(Uoe,XQe),e(Im,zQe),e(Im,Uk),e(Uk,WQe),e(Im,QQe),e(A,HQe),e(A,qm),e(qm,Joe),e(Joe,UQe),e(qm,JQe),e(qm,Jk),e(Jk,YQe),e(qm,KQe),e(A,ZQe),e(A,Nm),e(Nm,Yoe),e(Yoe,eHe),e(Nm,oHe),e(Nm,Yk),e(Yk,rHe),e(Nm,tHe),e(A,aHe),e(A,jm),e(jm,Koe),e(Koe,nHe),e(jm,sHe),e(jm,Kk),e(Kk,lHe),e(jm,iHe),e(A,dHe),e(A,Dm),e(Dm,Zoe),e(Zoe,cHe),e(Dm,fHe),e(Dm,Zk),e(Zk,mHe),e(Dm,gHe),e(A,hHe),e(A,Gm),e(Gm,ere),e(ere,pHe),e(Gm,uHe),e(Gm,eS),e(eS,_He),e(Gm,bHe),e(A,vHe),e(A,Om),e(Om,ore),e(ore,FHe),e(Om,THe),e(Om,oS),e(oS,MHe),e(Om,EHe),e(A,CHe),e(A,Vm),e(Vm,rre),e(rre,wHe),e(Vm,AHe),e(Vm,rS),e(rS,yHe),e(Vm,LHe),e(A,xHe),e(A,Xm),e(Xm,tre),e(tre,$He),e(Xm,kHe),e(Xm,tS),e(tS,SHe),e(Xm,RHe),e(A,PHe),e(A,zm),e(zm,are),e(are,BHe),e(zm,IHe),e(zm,aS),e(aS,qHe),e(zm,NHe),e(A,jHe),e(A,Wm),e(Wm,nre),e(nre,DHe),e(Wm,GHe),e(Wm,nS),e(nS,OHe),e(Wm,VHe),e(A,XHe),e(A,Qm),e(Qm,sre),e(sre,zHe),e(Qm,WHe),e(Qm,sS),e(sS,QHe),e(Qm,HHe),e(A,UHe),e(A,Hm),e(Hm,lre),e(lre,JHe),e(Hm,YHe),e(Hm,lS),e(lS,KHe),e(Hm,ZHe),e(A,eUe),e(A,Um),e(Um,ire),e(ire,oUe),e(Um,rUe),e(Um,iS),e(iS,tUe),e(Um,aUe),e(A,nUe),e(A,Jm),e(Jm,dre),e(dre,sUe),e(Jm,lUe),e(Jm,dS),e(dS,iUe),e(Jm,dUe),e(A,cUe),e(A,Ym),e(Ym,cre),e(cre,fUe),e(Ym,mUe),e(Ym,cS),e(cS,gUe),e(Ym,hUe),e(A,pUe),e(A,Km),e(Km,fre),e(fre,uUe),e(Km,_Ue),e(Km,fS),e(fS,bUe),e(Km,vUe),e(A,FUe),e(A,Zm),e(Zm,mre),e(mre,TUe),e(Zm,MUe),e(Zm,mS),e(mS,EUe),e(Zm,CUe),e(A,wUe),e(A,eg),e(eg,gre),e(gre,AUe),e(eg,yUe),e(eg,gS),e(gS,LUe),e(eg,xUe),e(A,$Ue),e(A,og),e(og,hre),e(hre,kUe),e(og,SUe),e(og,hS),e(hS,RUe),e(og,PUe),e(A,BUe),e(A,rg),e(rg,pre),e(pre,IUe),e(rg,qUe),e(rg,pS),e(pS,NUe),e(rg,jUe),e(A,DUe),e(A,tg),e(tg,ure),e(ure,GUe),e(tg,OUe),e(tg,uS),e(uS,VUe),e(tg,XUe),e(A,zUe),e(A,ag),e(ag,_re),e(_re,WUe),e(ag,QUe),e(ag,_S),e(_S,HUe),e(ag,UUe),e(A,JUe),e(A,ng),e(ng,bre),e(bre,YUe),e(ng,KUe),e(ng,bS),e(bS,ZUe),e(ng,eJe),e(A,oJe),e(A,sg),e(sg,vre),e(vre,rJe),e(sg,tJe),e(sg,vS),e(vS,aJe),e(sg,nJe),e(A,sJe),e(A,lg),e(lg,Fre),e(Fre,lJe),e(lg,iJe),e(lg,FS),e(FS,dJe),e(lg,cJe),e(A,fJe),e(A,ig),e(ig,Tre),e(Tre,mJe),e(ig,gJe),e(ig,TS),e(TS,hJe),e(ig,pJe),e(A,uJe),e(A,dg),e(dg,Mre),e(Mre,_Je),e(dg,bJe),e(dg,MS),e(MS,vJe),e(dg,FJe),e(A,TJe),e(A,cg),e(cg,Ere),e(Ere,MJe),e(cg,EJe),e(cg,ES),e(ES,CJe),e(cg,wJe),e(A,AJe),e(A,fg),e(fg,Cre),e(Cre,yJe),e(fg,LJe),e(fg,CS),e(CS,xJe),e(fg,$Je),e(A,kJe),e(A,mg),e(mg,wre),e(wre,SJe),e(mg,RJe),e(mg,wS),e(wS,PJe),e(mg,BJe),e(A,IJe),e(A,gg),e(gg,Are),e(Are,qJe),e(gg,NJe),e(gg,AS),e(AS,jJe),e(gg,DJe),e(A,GJe),e(A,hg),e(hg,yre),e(yre,OJe),e(hg,VJe),e(hg,yS),e(yS,XJe),e(hg,zJe),e(A,WJe),e(A,pg),e(pg,Lre),e(Lre,QJe),e(pg,HJe),e(pg,LS),e(LS,UJe),e(pg,JJe),e(A,YJe),e(A,ug),e(ug,xre),e(xre,KJe),e(ug,ZJe),e(ug,xS),e(xS,eYe),e(ug,oYe),e(A,rYe),e(A,_g),e(_g,$re),e($re,tYe),e(_g,aYe),e(_g,$S),e($S,nYe),e(_g,sYe),e(Er,lYe),M(bg,Er,null),e(Co,iYe),e(Co,vg),M(_6,vg,null),e(vg,dYe),e(vg,kre),e(kre,cYe),b(f,XIe,_),b(f,Fi,_),e(Fi,Fg),e(Fg,Sre),M(b6,Sre,null),e(Fi,fYe),e(Fi,Rre),e(Rre,mYe),b(f,zIe,_),b(f,wo,_),M(v6,wo,null),e(wo,gYe),e(wo,F6),e(F6,hYe),e(F6,kS),e(kS,pYe),e(F6,uYe),e(wo,_Ye),e(wo,T6),e(T6,bYe),e(T6,Pre),e(Pre,vYe),e(T6,FYe),e(wo,TYe),e(wo,Cr),M(M6,Cr,null),e(Cr,MYe),e(Cr,Bre),e(Bre,EYe),e(Cr,CYe),e(Cr,Aa),e(Aa,wYe),e(Aa,Ire),e(Ire,AYe),e(Aa,yYe),e(Aa,qre),e(qre,LYe),e(Aa,xYe),e(Aa,Nre),e(Nre,$Ye),e(Aa,kYe),e(Cr,SYe),e(Cr,k),e(k,Sn),e(Sn,jre),e(jre,RYe),e(Sn,PYe),e(Sn,SS),e(SS,BYe),e(Sn,IYe),e(Sn,RS),e(RS,qYe),e(Sn,NYe),e(k,jYe),e(k,Rn),e(Rn,Dre),e(Dre,DYe),e(Rn,GYe),e(Rn,PS),e(PS,OYe),e(Rn,VYe),e(Rn,BS),e(BS,XYe),e(Rn,zYe),e(k,WYe),e(k,Pn),e(Pn,Gre),e(Gre,QYe),e(Pn,HYe),e(Pn,IS),e(IS,UYe),e(Pn,JYe),e(Pn,qS),e(qS,YYe),e(Pn,KYe),e(k,ZYe),e(k,Tg),e(Tg,Ore),e(Ore,eKe),e(Tg,oKe),e(Tg,NS),e(NS,rKe),e(Tg,tKe),e(k,aKe),e(k,Bn),e(Bn,Vre),e(Vre,nKe),e(Bn,sKe),e(Bn,jS),e(jS,lKe),e(Bn,iKe),e(Bn,DS),e(DS,dKe),e(Bn,cKe),e(k,fKe),e(k,Mg),e(Mg,Xre),e(Xre,mKe),e(Mg,gKe),e(Mg,GS),e(GS,hKe),e(Mg,pKe),e(k,uKe),e(k,Eg),e(Eg,zre),e(zre,_Ke),e(Eg,bKe),e(Eg,OS),e(OS,vKe),e(Eg,FKe),e(k,TKe),e(k,Cg),e(Cg,Wre),e(Wre,MKe),e(Cg,EKe),e(Cg,VS),e(VS,CKe),e(Cg,wKe),e(k,AKe),e(k,In),e(In,Qre),e(Qre,yKe),e(In,LKe),e(In,XS),e(XS,xKe),e(In,$Ke),e(In,zS),e(zS,kKe),e(In,SKe),e(k,RKe),e(k,qn),e(qn,Hre),e(Hre,PKe),e(qn,BKe),e(qn,WS),e(WS,IKe),e(qn,qKe),e(qn,QS),e(QS,NKe),e(qn,jKe),e(k,DKe),e(k,Nn),e(Nn,Ure),e(Ure,GKe),e(Nn,OKe),e(Nn,HS),e(HS,VKe),e(Nn,XKe),e(Nn,US),e(US,zKe),e(Nn,WKe),e(k,QKe),e(k,wg),e(wg,Jre),e(Jre,HKe),e(wg,UKe),e(wg,JS),e(JS,JKe),e(wg,YKe),e(k,KKe),e(k,Ag),e(Ag,Yre),e(Yre,ZKe),e(Ag,eZe),e(Ag,YS),e(YS,oZe),e(Ag,rZe),e(k,tZe),e(k,jn),e(jn,Kre),e(Kre,aZe),e(jn,nZe),e(jn,KS),e(KS,sZe),e(jn,lZe),e(jn,ZS),e(ZS,iZe),e(jn,dZe),e(k,cZe),e(k,yg),e(yg,Zre),e(Zre,fZe),e(yg,mZe),e(yg,eR),e(eR,gZe),e(yg,hZe),e(k,pZe),e(k,Dn),e(Dn,ete),e(ete,uZe),e(Dn,_Ze),e(Dn,oR),e(oR,bZe),e(Dn,vZe),e(Dn,rR),e(rR,FZe),e(Dn,TZe),e(k,MZe),e(k,Gn),e(Gn,ote),e(ote,EZe),e(Gn,CZe),e(Gn,tR),e(tR,wZe),e(Gn,AZe),e(Gn,aR),e(aR,yZe),e(Gn,LZe),e(k,xZe),e(k,On),e(On,rte),e(rte,$Ze),e(On,kZe),e(On,nR),e(nR,SZe),e(On,RZe),e(On,sR),e(sR,PZe),e(On,BZe),e(k,IZe),e(k,Lg),e(Lg,tte),e(tte,qZe),e(Lg,NZe),e(Lg,lR),e(lR,jZe),e(Lg,DZe),e(k,GZe),e(k,Vn),e(Vn,ate),e(ate,OZe),e(Vn,VZe),e(Vn,iR),e(iR,XZe),e(Vn,zZe),e(Vn,dR),e(dR,WZe),e(Vn,QZe),e(k,HZe),e(k,Xn),e(Xn,nte),e(nte,UZe),e(Xn,JZe),e(Xn,cR),e(cR,YZe),e(Xn,KZe),e(Xn,fR),e(fR,ZZe),e(Xn,eeo),e(k,oeo),e(k,zn),e(zn,ste),e(ste,reo),e(zn,teo),e(zn,mR),e(mR,aeo),e(zn,neo),e(zn,gR),e(gR,seo),e(zn,leo),e(k,ieo),e(k,Wn),e(Wn,lte),e(lte,deo),e(Wn,ceo),e(Wn,hR),e(hR,feo),e(Wn,meo),e(Wn,pR),e(pR,geo),e(Wn,heo),e(k,peo),e(k,Qn),e(Qn,ite),e(ite,ueo),e(Qn,_eo),e(Qn,uR),e(uR,beo),e(Qn,veo),e(Qn,_R),e(_R,Feo),e(Qn,Teo),e(k,Meo),e(k,Hn),e(Hn,dte),e(dte,Eeo),e(Hn,Ceo),e(Hn,bR),e(bR,weo),e(Hn,Aeo),e(Hn,vR),e(vR,yeo),e(Hn,Leo),e(k,xeo),e(k,xg),e(xg,cte),e(cte,$eo),e(xg,keo),e(xg,FR),e(FR,Seo),e(xg,Reo),e(k,Peo),e(k,Un),e(Un,fte),e(fte,Beo),e(Un,Ieo),e(Un,TR),e(TR,qeo),e(Un,Neo),e(Un,MR),e(MR,jeo),e(Un,Deo),e(k,Geo),e(k,$g),e($g,mte),e(mte,Oeo),e($g,Veo),e($g,ER),e(ER,Xeo),e($g,zeo),e(k,Weo),e(k,Jn),e(Jn,gte),e(gte,Qeo),e(Jn,Heo),e(Jn,CR),e(CR,Ueo),e(Jn,Jeo),e(Jn,wR),e(wR,Yeo),e(Jn,Keo),e(k,Zeo),e(k,Yn),e(Yn,hte),e(hte,eoo),e(Yn,ooo),e(Yn,AR),e(AR,roo),e(Yn,too),e(Yn,yR),e(yR,aoo),e(Yn,noo),e(k,soo),e(k,Kn),e(Kn,pte),e(pte,loo),e(Kn,ioo),e(Kn,LR),e(LR,doo),e(Kn,coo),e(Kn,xR),e(xR,foo),e(Kn,moo),e(k,goo),e(k,Zn),e(Zn,ute),e(ute,hoo),e(Zn,poo),e(Zn,$R),e($R,uoo),e(Zn,_oo),e(Zn,kR),e(kR,boo),e(Zn,voo),e(k,Foo),e(k,es),e(es,_te),e(_te,Too),e(es,Moo),e(es,SR),e(SR,Eoo),e(es,Coo),e(es,RR),e(RR,woo),e(es,Aoo),e(k,yoo),e(k,kg),e(kg,bte),e(bte,Loo),e(kg,xoo),e(kg,PR),e(PR,$oo),e(kg,koo),e(k,Soo),e(k,os),e(os,vte),e(vte,Roo),e(os,Poo),e(os,BR),e(BR,Boo),e(os,Ioo),e(os,IR),e(IR,qoo),e(os,Noo),e(k,joo),e(k,rs),e(rs,Fte),e(Fte,Doo),e(rs,Goo),e(rs,qR),e(qR,Ooo),e(rs,Voo),e(rs,NR),e(NR,Xoo),e(rs,zoo),e(k,Woo),e(k,ts),e(ts,Tte),e(Tte,Qoo),e(ts,Hoo),e(ts,jR),e(jR,Uoo),e(ts,Joo),e(ts,DR),e(DR,Yoo),e(ts,Koo),e(k,Zoo),e(k,as),e(as,Mte),e(Mte,ero),e(as,oro),e(as,GR),e(GR,rro),e(as,tro),e(as,OR),e(OR,aro),e(as,nro),e(k,sro),e(k,ns),e(ns,Ete),e(Ete,lro),e(ns,iro),e(ns,VR),e(VR,dro),e(ns,cro),e(ns,XR),e(XR,fro),e(ns,mro),e(k,gro),e(k,ss),e(ss,Cte),e(Cte,hro),e(ss,pro),e(ss,zR),e(zR,uro),e(ss,_ro),e(ss,WR),e(WR,bro),e(ss,vro),e(k,Fro),e(k,Sg),e(Sg,wte),e(wte,Tro),e(Sg,Mro),e(Sg,QR),e(QR,Ero),e(Sg,Cro),e(k,wro),e(k,ls),e(ls,Ate),e(Ate,Aro),e(ls,yro),e(ls,HR),e(HR,Lro),e(ls,xro),e(ls,UR),e(UR,$ro),e(ls,kro),e(k,Sro),e(k,Rg),e(Rg,yte),e(yte,Rro),e(Rg,Pro),e(Rg,JR),e(JR,Bro),e(Rg,Iro),e(k,qro),e(k,Pg),e(Pg,Lte),e(Lte,Nro),e(Pg,jro),e(Pg,YR),e(YR,Dro),e(Pg,Gro),e(k,Oro),e(k,is),e(is,xte),e(xte,Vro),e(is,Xro),e(is,KR),e(KR,zro),e(is,Wro),e(is,ZR),e(ZR,Qro),e(is,Hro),e(k,Uro),e(k,ds),e(ds,$te),e($te,Jro),e(ds,Yro),e(ds,eP),e(eP,Kro),e(ds,Zro),e(ds,oP),e(oP,eto),e(ds,oto),e(k,rto),e(k,cs),e(cs,kte),e(kte,tto),e(cs,ato),e(cs,rP),e(rP,nto),e(cs,sto),e(cs,tP),e(tP,lto),e(cs,ito),e(k,dto),e(k,Bg),e(Bg,Ste),e(Ste,cto),e(Bg,fto),e(Bg,aP),e(aP,mto),e(Bg,gto),e(k,hto),e(k,fs),e(fs,Rte),e(Rte,pto),e(fs,uto),e(fs,nP),e(nP,_to),e(fs,bto),e(fs,sP),e(sP,vto),e(fs,Fto),e(k,Tto),e(k,ms),e(ms,Pte),e(Pte,Mto),e(ms,Eto),e(ms,lP),e(lP,Cto),e(ms,wto),e(ms,iP),e(iP,Ato),e(ms,yto),e(k,Lto),e(k,gs),e(gs,Bte),e(Bte,xto),e(gs,$to),e(gs,dP),e(dP,kto),e(gs,Sto),e(gs,cP),e(cP,Rto),e(gs,Pto),e(k,Bto),e(k,hs),e(hs,Ite),e(Ite,Ito),e(hs,qto),e(hs,fP),e(fP,Nto),e(hs,jto),e(hs,mP),e(mP,Dto),e(hs,Gto),e(k,Oto),e(k,ps),e(ps,qte),e(qte,Vto),e(ps,Xto),e(ps,gP),e(gP,zto),e(ps,Wto),e(ps,hP),e(hP,Qto),e(ps,Hto),e(k,Uto),e(k,Ig),e(Ig,Nte),e(Nte,Jto),e(Ig,Yto),e(Ig,pP),e(pP,Kto),e(Ig,Zto),e(k,eao),e(k,us),e(us,jte),e(jte,oao),e(us,rao),e(us,uP),e(uP,tao),e(us,aao),e(us,_P),e(_P,nao),e(us,sao),e(k,lao),e(k,qg),e(qg,Dte),e(Dte,iao),e(qg,dao),e(qg,bP),e(bP,cao),e(qg,fao),e(k,mao),e(k,Ng),e(Ng,Gte),e(Gte,gao),e(Ng,hao),e(Ng,vP),e(vP,pao),e(Ng,uao),e(k,_ao),e(k,jg),e(jg,Ote),e(Ote,bao),e(jg,vao),e(jg,FP),e(FP,Fao),e(jg,Tao),e(k,Mao),e(k,Dg),e(Dg,Vte),e(Vte,Eao),e(Dg,Cao),e(Dg,TP),e(TP,wao),e(Dg,Aao),e(k,yao),e(k,_s),e(_s,Xte),e(Xte,Lao),e(_s,xao),e(_s,MP),e(MP,$ao),e(_s,kao),e(_s,EP),e(EP,Sao),e(_s,Rao),e(k,Pao),e(k,Gg),e(Gg,zte),e(zte,Bao),e(Gg,Iao),e(Gg,CP),e(CP,qao),e(Gg,Nao),e(k,jao),e(k,bs),e(bs,Wte),e(Wte,Dao),e(bs,Gao),e(bs,wP),e(wP,Oao),e(bs,Vao),e(bs,AP),e(AP,Xao),e(bs,zao),e(k,Wao),e(k,vs),e(vs,Qte),e(Qte,Qao),e(vs,Hao),e(vs,yP),e(yP,Uao),e(vs,Jao),e(vs,LP),e(LP,Yao),e(vs,Kao),e(k,Zao),e(k,Fs),e(Fs,Hte),e(Hte,eno),e(Fs,ono),e(Fs,xP),e(xP,rno),e(Fs,tno),e(Fs,$P),e($P,ano),e(Fs,nno),e(k,sno),e(k,Ts),e(Ts,Ute),e(Ute,lno),e(Ts,ino),e(Ts,kP),e(kP,dno),e(Ts,cno),e(Ts,SP),e(SP,fno),e(Ts,mno),e(k,gno),e(k,Ms),e(Ms,Jte),e(Jte,hno),e(Ms,pno),e(Ms,RP),e(RP,uno),e(Ms,_no),e(Ms,PP),e(PP,bno),e(Ms,vno),e(k,Fno),e(k,Es),e(Es,Yte),e(Yte,Tno),e(Es,Mno),e(Es,BP),e(BP,Eno),e(Es,Cno),e(Es,IP),e(IP,wno),e(Es,Ano),e(k,yno),e(k,Og),e(Og,Kte),e(Kte,Lno),e(Og,xno),e(Og,qP),e(qP,$no),e(Og,kno),e(k,Sno),e(k,Vg),e(Vg,Zte),e(Zte,Rno),e(Vg,Pno),e(Vg,NP),e(NP,Bno),e(Vg,Ino),e(k,qno),e(k,Cs),e(Cs,eae),e(eae,Nno),e(Cs,jno),e(Cs,jP),e(jP,Dno),e(Cs,Gno),e(Cs,DP),e(DP,Ono),e(Cs,Vno),e(k,Xno),e(k,ws),e(ws,oae),e(oae,zno),e(ws,Wno),e(ws,GP),e(GP,Qno),e(ws,Hno),e(ws,OP),e(OP,Uno),e(ws,Jno),e(k,Yno),e(k,As),e(As,rae),e(rae,Kno),e(As,Zno),e(As,VP),e(VP,eso),e(As,oso),e(As,XP),e(XP,rso),e(As,tso),e(k,aso),e(k,Xg),e(Xg,tae),e(tae,nso),e(Xg,sso),e(Xg,zP),e(zP,lso),e(Xg,iso),e(k,dso),e(k,zg),e(zg,aae),e(aae,cso),e(zg,fso),e(zg,WP),e(WP,mso),e(zg,gso),e(k,hso),e(k,Wg),e(Wg,nae),e(nae,pso),e(Wg,uso),e(Wg,QP),e(QP,_so),e(Wg,bso),e(k,vso),e(k,ys),e(ys,sae),e(sae,Fso),e(ys,Tso),e(ys,HP),e(HP,Mso),e(ys,Eso),e(ys,UP),e(UP,Cso),e(ys,wso),e(k,Aso),e(k,Qg),e(Qg,lae),e(lae,yso),e(Qg,Lso),e(Qg,JP),e(JP,xso),e(Qg,$so),e(k,kso),e(k,Hg),e(Hg,iae),e(iae,Sso),e(Hg,Rso),e(Hg,YP),e(YP,Pso),e(Hg,Bso),e(k,Iso),e(k,Ug),e(Ug,dae),e(dae,qso),e(Ug,Nso),e(Ug,KP),e(KP,jso),e(Ug,Dso),e(k,Gso),e(k,Ls),e(Ls,cae),e(cae,Oso),e(Ls,Vso),e(Ls,ZP),e(ZP,Xso),e(Ls,zso),e(Ls,eB),e(eB,Wso),e(Ls,Qso),e(k,Hso),e(k,Jg),e(Jg,fae),e(fae,Uso),e(Jg,Jso),e(Jg,oB),e(oB,Yso),e(Jg,Kso),e(k,Zso),e(k,Yg),e(Yg,mae),e(mae,elo),e(Yg,olo),e(Yg,rB),e(rB,rlo),e(Yg,tlo),e(k,alo),e(k,xs),e(xs,gae),e(gae,nlo),e(xs,slo),e(xs,tB),e(tB,llo),e(xs,ilo),e(xs,aB),e(aB,dlo),e(xs,clo),e(k,flo),e(k,$s),e($s,hae),e(hae,mlo),e($s,glo),e($s,nB),e(nB,hlo),e($s,plo),e($s,sB),e(sB,ulo),e($s,_lo),e(k,blo),e(k,ks),e(ks,pae),e(pae,vlo),e(ks,Flo),e(ks,lB),e(lB,Tlo),e(ks,Mlo),e(ks,iB),e(iB,Elo),e(ks,Clo),e(k,wlo),e(k,Ss),e(Ss,uae),e(uae,Alo),e(Ss,ylo),e(Ss,dB),e(dB,Llo),e(Ss,xlo),e(Ss,cB),e(cB,$lo),e(Ss,klo),e(Cr,Slo),M(Kg,Cr,null),e(wo,Rlo),e(wo,Zg),M(E6,Zg,null),e(Zg,Plo),e(Zg,_ae),e(_ae,Blo),b(f,WIe,_),b(f,Ti,_),e(Ti,eh),e(eh,bae),M(C6,bae,null),e(Ti,Ilo),e(Ti,vae),e(vae,qlo),b(f,QIe,_),b(f,Ao,_),M(w6,Ao,null),e(Ao,Nlo),e(Ao,A6),e(A6,jlo),e(A6,fB),e(fB,Dlo),e(A6,Glo),e(Ao,Olo),e(Ao,y6),e(y6,Vlo),e(y6,Fae),e(Fae,Xlo),e(y6,zlo),e(Ao,Wlo),e(Ao,He),M(L6,He,null),e(He,Qlo),e(He,Tae),e(Tae,Hlo),e(He,Ulo),e(He,ya),e(ya,Jlo),e(ya,Mae),e(Mae,Ylo),e(ya,Klo),e(ya,Eae),e(Eae,Zlo),e(ya,eio),e(ya,Cae),e(Cae,oio),e(ya,rio),e(He,tio),e(He,Z),e(Z,oh),e(oh,wae),e(wae,aio),e(oh,nio),e(oh,mB),e(mB,sio),e(oh,lio),e(Z,iio),e(Z,rh),e(rh,Aae),e(Aae,dio),e(rh,cio),e(rh,gB),e(gB,fio),e(rh,mio),e(Z,gio),e(Z,th),e(th,yae),e(yae,hio),e(th,pio),e(th,hB),e(hB,uio),e(th,_io),e(Z,bio),e(Z,ah),e(ah,Lae),e(Lae,vio),e(ah,Fio),e(ah,pB),e(pB,Tio),e(ah,Mio),e(Z,Eio),e(Z,nh),e(nh,xae),e(xae,Cio),e(nh,wio),e(nh,uB),e(uB,Aio),e(nh,yio),e(Z,Lio),e(Z,sh),e(sh,$ae),e($ae,xio),e(sh,$io),e(sh,_B),e(_B,kio),e(sh,Sio),e(Z,Rio),e(Z,lh),e(lh,kae),e(kae,Pio),e(lh,Bio),e(lh,bB),e(bB,Iio),e(lh,qio),e(Z,Nio),e(Z,ih),e(ih,Sae),e(Sae,jio),e(ih,Dio),e(ih,vB),e(vB,Gio),e(ih,Oio),e(Z,Vio),e(Z,dh),e(dh,Rae),e(Rae,Xio),e(dh,zio),e(dh,FB),e(FB,Wio),e(dh,Qio),e(Z,Hio),e(Z,ch),e(ch,Pae),e(Pae,Uio),e(ch,Jio),e(ch,TB),e(TB,Yio),e(ch,Kio),e(Z,Zio),e(Z,fh),e(fh,Bae),e(Bae,edo),e(fh,odo),e(fh,MB),e(MB,rdo),e(fh,tdo),e(Z,ado),e(Z,mh),e(mh,Iae),e(Iae,ndo),e(mh,sdo),e(mh,EB),e(EB,ldo),e(mh,ido),e(Z,ddo),e(Z,gh),e(gh,qae),e(qae,cdo),e(gh,fdo),e(gh,CB),e(CB,mdo),e(gh,gdo),e(Z,hdo),e(Z,hh),e(hh,Nae),e(Nae,pdo),e(hh,udo),e(hh,wB),e(wB,_do),e(hh,bdo),e(Z,vdo),e(Z,ph),e(ph,jae),e(jae,Fdo),e(ph,Tdo),e(ph,AB),e(AB,Mdo),e(ph,Edo),e(Z,Cdo),e(Z,uh),e(uh,Dae),e(Dae,wdo),e(uh,Ado),e(uh,yB),e(yB,ydo),e(uh,Ldo),e(Z,xdo),e(Z,_h),e(_h,Gae),e(Gae,$do),e(_h,kdo),e(_h,LB),e(LB,Sdo),e(_h,Rdo),e(Z,Pdo),e(Z,bh),e(bh,Oae),e(Oae,Bdo),e(bh,Ido),e(bh,xB),e(xB,qdo),e(bh,Ndo),e(Z,jdo),e(Z,vh),e(vh,Vae),e(Vae,Ddo),e(vh,Gdo),e(vh,$B),e($B,Odo),e(vh,Vdo),e(Z,Xdo),e(Z,Fh),e(Fh,Xae),e(Xae,zdo),e(Fh,Wdo),e(Fh,kB),e(kB,Qdo),e(Fh,Hdo),e(Z,Udo),e(Z,Th),e(Th,zae),e(zae,Jdo),e(Th,Ydo),e(Th,SB),e(SB,Kdo),e(Th,Zdo),e(Z,eco),e(Z,Mh),e(Mh,Wae),e(Wae,oco),e(Mh,rco),e(Mh,RB),e(RB,tco),e(Mh,aco),e(Z,nco),e(Z,Eh),e(Eh,Qae),e(Qae,sco),e(Eh,lco),e(Eh,PB),e(PB,ico),e(Eh,dco),e(Z,cco),e(Z,Ch),e(Ch,Hae),e(Hae,fco),e(Ch,mco),e(Ch,BB),e(BB,gco),e(Ch,hco),e(Z,pco),e(Z,wh),e(wh,Uae),e(Uae,uco),e(wh,_co),e(wh,IB),e(IB,bco),e(wh,vco),e(Z,Fco),e(Z,Ah),e(Ah,Jae),e(Jae,Tco),e(Ah,Mco),e(Ah,qB),e(qB,Eco),e(Ah,Cco),e(He,wco),M(yh,He,null),e(He,Aco),M(Lh,He,null),e(Ao,yco),e(Ao,xh),M(x6,xh,null),e(xh,Lco),e(xh,Yae),e(Yae,xco),b(f,HIe,_),b(f,Mi,_),e(Mi,$h),e($h,Kae),M($6,Kae,null),e(Mi,$co),e(Mi,Zae),e(Zae,kco),b(f,UIe,_),b(f,yo,_),M(k6,yo,null),e(yo,Sco),e(yo,S6),e(S6,Rco),e(S6,NB),e(NB,Pco),e(S6,Bco),e(yo,Ico),e(yo,R6),e(R6,qco),e(R6,ene),e(ene,Nco),e(R6,jco),e(yo,Dco),e(yo,Ue),M(P6,Ue,null),e(Ue,Gco),e(Ue,one),e(one,Oco),e(Ue,Vco),e(Ue,Ei),e(Ei,Xco),e(Ei,rne),e(rne,zco),e(Ei,Wco),e(Ei,tne),e(tne,Qco),e(Ei,Hco),e(Ue,Uco),e(Ue,pe),e(pe,kh),e(kh,ane),e(ane,Jco),e(kh,Yco),e(kh,jB),e(jB,Kco),e(kh,Zco),e(pe,efo),e(pe,Sh),e(Sh,nne),e(nne,ofo),e(Sh,rfo),e(Sh,sne),e(sne,tfo),e(Sh,afo),e(pe,nfo),e(pe,Rh),e(Rh,lne),e(lne,sfo),e(Rh,lfo),e(Rh,DB),e(DB,ifo),e(Rh,dfo),e(pe,cfo),e(pe,Ph),e(Ph,ine),e(ine,ffo),e(Ph,mfo),e(Ph,GB),e(GB,gfo),e(Ph,hfo),e(pe,pfo),e(pe,Bh),e(Bh,dne),e(dne,ufo),e(Bh,_fo),e(Bh,OB),e(OB,bfo),e(Bh,vfo),e(pe,Ffo),e(pe,Ih),e(Ih,cne),e(cne,Tfo),e(Ih,Mfo),e(Ih,VB),e(VB,Efo),e(Ih,Cfo),e(pe,wfo),e(pe,qh),e(qh,fne),e(fne,Afo),e(qh,yfo),e(qh,XB),e(XB,Lfo),e(qh,xfo),e(pe,$fo),e(pe,Nh),e(Nh,mne),e(mne,kfo),e(Nh,Sfo),e(Nh,zB),e(zB,Rfo),e(Nh,Pfo),e(pe,Bfo),e(pe,jh),e(jh,gne),e(gne,Ifo),e(jh,qfo),e(jh,WB),e(WB,Nfo),e(jh,jfo),e(pe,Dfo),e(pe,Dh),e(Dh,hne),e(hne,Gfo),e(Dh,Ofo),e(Dh,QB),e(QB,Vfo),e(Dh,Xfo),e(pe,zfo),e(pe,Gh),e(Gh,pne),e(pne,Wfo),e(Gh,Qfo),e(Gh,HB),e(HB,Hfo),e(Gh,Ufo),e(pe,Jfo),e(pe,Oh),e(Oh,une),e(une,Yfo),e(Oh,Kfo),e(Oh,UB),e(UB,Zfo),e(Oh,emo),e(pe,omo),e(pe,Vh),e(Vh,_ne),e(_ne,rmo),e(Vh,tmo),e(Vh,JB),e(JB,amo),e(Vh,nmo),e(pe,smo),e(pe,Xh),e(Xh,bne),e(bne,lmo),e(Xh,imo),e(Xh,YB),e(YB,dmo),e(Xh,cmo),e(pe,fmo),e(pe,zh),e(zh,vne),e(vne,mmo),e(zh,gmo),e(zh,KB),e(KB,hmo),e(zh,pmo),e(pe,umo),e(pe,Wh),e(Wh,Fne),e(Fne,_mo),e(Wh,bmo),e(Wh,ZB),e(ZB,vmo),e(Wh,Fmo),e(Ue,Tmo),M(Qh,Ue,null),e(Ue,Mmo),M(Hh,Ue,null),e(yo,Emo),e(yo,Uh),M(B6,Uh,null),e(Uh,Cmo),e(Uh,Tne),e(Tne,wmo),b(f,JIe,_),b(f,Ci,_),e(Ci,Jh),e(Jh,Mne),M(I6,Mne,null),e(Ci,Amo),e(Ci,Ene),e(Ene,ymo),b(f,YIe,_),b(f,Lo,_),M(q6,Lo,null),e(Lo,Lmo),e(Lo,wi),e(wi,xmo),e(wi,eI),e(eI,$mo),e(wi,kmo),e(wi,oI),e(oI,Smo),e(wi,Rmo),e(Lo,Pmo),e(Lo,N6),e(N6,Bmo),e(N6,Cne),e(Cne,Imo),e(N6,qmo),e(Lo,Nmo),e(Lo,tt),M(j6,tt,null),e(tt,jmo),e(tt,wne),e(wne,Dmo),e(tt,Gmo),e(tt,Ai),e(Ai,Omo),e(Ai,Ane),e(Ane,Vmo),e(Ai,Xmo),e(Ai,rI),e(rI,zmo),e(Ai,Wmo),e(tt,Qmo),M(Yh,tt,null),e(Lo,Hmo),e(Lo,Je),M(D6,Je,null),e(Je,Umo),e(Je,yne),e(yne,Jmo),e(Je,Ymo),e(Je,La),e(La,Kmo),e(La,Lne),e(Lne,Zmo),e(La,ego),e(La,xne),e(xne,ogo),e(La,rgo),e(La,$ne),e($ne,tgo),e(La,ago),e(Je,ngo),e(Je,x),e(x,Kh),e(Kh,kne),e(kne,sgo),e(Kh,lgo),e(Kh,tI),e(tI,igo),e(Kh,dgo),e(x,cgo),e(x,Zh),e(Zh,Sne),e(Sne,fgo),e(Zh,mgo),e(Zh,aI),e(aI,ggo),e(Zh,hgo),e(x,pgo),e(x,ep),e(ep,Rne),e(Rne,ugo),e(ep,_go),e(ep,nI),e(nI,bgo),e(ep,vgo),e(x,Fgo),e(x,op),e(op,Pne),e(Pne,Tgo),e(op,Mgo),e(op,sI),e(sI,Ego),e(op,Cgo),e(x,wgo),e(x,rp),e(rp,Bne),e(Bne,Ago),e(rp,ygo),e(rp,lI),e(lI,Lgo),e(rp,xgo),e(x,$go),e(x,tp),e(tp,Ine),e(Ine,kgo),e(tp,Sgo),e(tp,iI),e(iI,Rgo),e(tp,Pgo),e(x,Bgo),e(x,ap),e(ap,qne),e(qne,Igo),e(ap,qgo),e(ap,dI),e(dI,Ngo),e(ap,jgo),e(x,Dgo),e(x,np),e(np,Nne),e(Nne,Ggo),e(np,Ogo),e(np,cI),e(cI,Vgo),e(np,Xgo),e(x,zgo),e(x,sp),e(sp,jne),e(jne,Wgo),e(sp,Qgo),e(sp,fI),e(fI,Hgo),e(sp,Ugo),e(x,Jgo),e(x,lp),e(lp,Dne),e(Dne,Ygo),e(lp,Kgo),e(lp,mI),e(mI,Zgo),e(lp,eho),e(x,oho),e(x,ip),e(ip,Gne),e(Gne,rho),e(ip,tho),e(ip,gI),e(gI,aho),e(ip,nho),e(x,sho),e(x,dp),e(dp,One),e(One,lho),e(dp,iho),e(dp,hI),e(hI,dho),e(dp,cho),e(x,fho),e(x,cp),e(cp,Vne),e(Vne,mho),e(cp,gho),e(cp,pI),e(pI,hho),e(cp,pho),e(x,uho),e(x,fp),e(fp,Xne),e(Xne,_ho),e(fp,bho),e(fp,uI),e(uI,vho),e(fp,Fho),e(x,Tho),e(x,mp),e(mp,zne),e(zne,Mho),e(mp,Eho),e(mp,_I),e(_I,Cho),e(mp,who),e(x,Aho),e(x,gp),e(gp,Wne),e(Wne,yho),e(gp,Lho),e(gp,bI),e(bI,xho),e(gp,$ho),e(x,kho),e(x,hp),e(hp,Qne),e(Qne,Sho),e(hp,Rho),e(hp,vI),e(vI,Pho),e(hp,Bho),e(x,Iho),e(x,pp),e(pp,Hne),e(Hne,qho),e(pp,Nho),e(pp,FI),e(FI,jho),e(pp,Dho),e(x,Gho),e(x,up),e(up,Une),e(Une,Oho),e(up,Vho),e(up,TI),e(TI,Xho),e(up,zho),e(x,Who),e(x,_p),e(_p,Jne),e(Jne,Qho),e(_p,Hho),e(_p,MI),e(MI,Uho),e(_p,Jho),e(x,Yho),e(x,bp),e(bp,Yne),e(Yne,Kho),e(bp,Zho),e(bp,EI),e(EI,epo),e(bp,opo),e(x,rpo),e(x,vp),e(vp,Kne),e(Kne,tpo),e(vp,apo),e(vp,CI),e(CI,npo),e(vp,spo),e(x,lpo),e(x,Fp),e(Fp,Zne),e(Zne,ipo),e(Fp,dpo),e(Fp,wI),e(wI,cpo),e(Fp,fpo),e(x,mpo),e(x,Tp),e(Tp,ese),e(ese,gpo),e(Tp,hpo),e(Tp,AI),e(AI,ppo),e(Tp,upo),e(x,_po),e(x,Mp),e(Mp,ose),e(ose,bpo),e(Mp,vpo),e(Mp,yI),e(yI,Fpo),e(Mp,Tpo),e(x,Mpo),e(x,Ep),e(Ep,rse),e(rse,Epo),e(Ep,Cpo),e(Ep,LI),e(LI,wpo),e(Ep,Apo),e(x,ypo),e(x,Cp),e(Cp,tse),e(tse,Lpo),e(Cp,xpo),e(Cp,xI),e(xI,$po),e(Cp,kpo),e(x,Spo),e(x,wp),e(wp,ase),e(ase,Rpo),e(wp,Ppo),e(wp,$I),e($I,Bpo),e(wp,Ipo),e(x,qpo),e(x,Ap),e(Ap,nse),e(nse,Npo),e(Ap,jpo),e(Ap,kI),e(kI,Dpo),e(Ap,Gpo),e(x,Opo),e(x,yp),e(yp,sse),e(sse,Vpo),e(yp,Xpo),e(yp,SI),e(SI,zpo),e(yp,Wpo),e(x,Qpo),e(x,Lp),e(Lp,lse),e(lse,Hpo),e(Lp,Upo),e(Lp,RI),e(RI,Jpo),e(Lp,Ypo),e(x,Kpo),e(x,Rs),e(Rs,ise),e(ise,Zpo),e(Rs,euo),e(Rs,PI),e(PI,ouo),e(Rs,ruo),e(Rs,BI),e(BI,tuo),e(Rs,auo),e(x,nuo),e(x,xp),e(xp,dse),e(dse,suo),e(xp,luo),e(xp,II),e(II,iuo),e(xp,duo),e(x,cuo),e(x,$p),e($p,cse),e(cse,fuo),e($p,muo),e($p,qI),e(qI,guo),e($p,huo),e(x,puo),e(x,kp),e(kp,fse),e(fse,uuo),e(kp,_uo),e(kp,NI),e(NI,buo),e(kp,vuo),e(x,Fuo),e(x,Sp),e(Sp,mse),e(mse,Tuo),e(Sp,Muo),e(Sp,jI),e(jI,Euo),e(Sp,Cuo),e(x,wuo),e(x,Rp),e(Rp,gse),e(gse,Auo),e(Rp,yuo),e(Rp,DI),e(DI,Luo),e(Rp,xuo),e(x,$uo),e(x,Pp),e(Pp,hse),e(hse,kuo),e(Pp,Suo),e(Pp,GI),e(GI,Ruo),e(Pp,Puo),e(x,Buo),e(x,Bp),e(Bp,pse),e(pse,Iuo),e(Bp,quo),e(Bp,OI),e(OI,Nuo),e(Bp,juo),e(x,Duo),e(x,Ip),e(Ip,use),e(use,Guo),e(Ip,Ouo),e(Ip,VI),e(VI,Vuo),e(Ip,Xuo),e(x,zuo),e(x,qp),e(qp,_se),e(_se,Wuo),e(qp,Quo),e(qp,XI),e(XI,Huo),e(qp,Uuo),e(x,Juo),e(x,Np),e(Np,bse),e(bse,Yuo),e(Np,Kuo),e(Np,zI),e(zI,Zuo),e(Np,e_o),e(x,o_o),e(x,jp),e(jp,vse),e(vse,r_o),e(jp,t_o),e(jp,WI),e(WI,a_o),e(jp,n_o),e(x,s_o),e(x,Dp),e(Dp,Fse),e(Fse,l_o),e(Dp,i_o),e(Dp,QI),e(QI,d_o),e(Dp,c_o),e(x,f_o),e(x,Gp),e(Gp,Tse),e(Tse,m_o),e(Gp,g_o),e(Gp,HI),e(HI,h_o),e(Gp,p_o),e(x,u_o),e(x,Op),e(Op,Mse),e(Mse,__o),e(Op,b_o),e(Op,UI),e(UI,v_o),e(Op,F_o),e(x,T_o),e(x,Vp),e(Vp,Ese),e(Ese,M_o),e(Vp,E_o),e(Vp,JI),e(JI,C_o),e(Vp,w_o),e(x,A_o),e(x,Xp),e(Xp,Cse),e(Cse,y_o),e(Xp,L_o),e(Xp,YI),e(YI,x_o),e(Xp,$_o),e(x,k_o),e(x,zp),e(zp,wse),e(wse,S_o),e(zp,R_o),e(zp,KI),e(KI,P_o),e(zp,B_o),e(x,I_o),e(x,Wp),e(Wp,Ase),e(Ase,q_o),e(Wp,N_o),e(Wp,ZI),e(ZI,j_o),e(Wp,D_o),e(x,G_o),e(x,Qp),e(Qp,yse),e(yse,O_o),e(Qp,V_o),e(Qp,eq),e(eq,X_o),e(Qp,z_o),e(x,W_o),e(x,Hp),e(Hp,Lse),e(Lse,Q_o),e(Hp,H_o),e(Hp,oq),e(oq,U_o),e(Hp,J_o),e(x,Y_o),e(x,Up),e(Up,xse),e(xse,K_o),e(Up,Z_o),e(Up,rq),e(rq,e2o),e(Up,o2o),e(x,r2o),e(x,Jp),e(Jp,$se),e($se,t2o),e(Jp,a2o),e(Jp,tq),e(tq,n2o),e(Jp,s2o),e(x,l2o),e(x,Yp),e(Yp,kse),e(kse,i2o),e(Yp,d2o),e(Yp,aq),e(aq,c2o),e(Yp,f2o),e(x,m2o),e(x,Kp),e(Kp,Sse),e(Sse,g2o),e(Kp,h2o),e(Kp,nq),e(nq,p2o),e(Kp,u2o),e(x,_2o),e(x,Zp),e(Zp,Rse),e(Rse,b2o),e(Zp,v2o),e(Zp,sq),e(sq,F2o),e(Zp,T2o),e(x,M2o),e(x,eu),e(eu,Pse),e(Pse,E2o),e(eu,C2o),e(eu,lq),e(lq,w2o),e(eu,A2o),e(x,y2o),e(x,ou),e(ou,Bse),e(Bse,L2o),e(ou,x2o),e(ou,iq),e(iq,$2o),e(ou,k2o),e(x,S2o),e(x,ru),e(ru,Ise),e(Ise,R2o),e(ru,P2o),e(ru,dq),e(dq,B2o),e(ru,I2o),e(x,q2o),e(x,tu),e(tu,qse),e(qse,N2o),e(tu,j2o),e(tu,cq),e(cq,D2o),e(tu,G2o),e(x,O2o),e(x,au),e(au,Nse),e(Nse,V2o),e(au,X2o),e(au,fq),e(fq,z2o),e(au,W2o),e(x,Q2o),e(x,nu),e(nu,jse),e(jse,H2o),e(nu,U2o),e(nu,mq),e(mq,J2o),e(nu,Y2o),e(x,K2o),e(x,su),e(su,Dse),e(Dse,Z2o),e(su,e1o),e(su,gq),e(gq,o1o),e(su,r1o),e(x,t1o),e(x,lu),e(lu,Gse),e(Gse,a1o),e(lu,n1o),e(lu,hq),e(hq,s1o),e(lu,l1o),e(x,i1o),e(x,iu),e(iu,Ose),e(Ose,d1o),e(iu,c1o),e(iu,pq),e(pq,f1o),e(iu,m1o),e(x,g1o),e(x,du),e(du,Vse),e(Vse,h1o),e(du,p1o),e(du,uq),e(uq,u1o),e(du,_1o),e(x,b1o),e(x,cu),e(cu,Xse),e(Xse,v1o),e(cu,F1o),e(cu,_q),e(_q,T1o),e(cu,M1o),e(x,E1o),e(x,fu),e(fu,zse),e(zse,C1o),e(fu,w1o),e(fu,bq),e(bq,A1o),e(fu,y1o),e(x,L1o),e(x,mu),e(mu,Wse),e(Wse,x1o),e(mu,$1o),e(mu,vq),e(vq,k1o),e(mu,S1o),e(x,R1o),e(x,gu),e(gu,Qse),e(Qse,P1o),e(gu,B1o),e(gu,Fq),e(Fq,I1o),e(gu,q1o),e(x,N1o),e(x,hu),e(hu,Hse),e(Hse,j1o),e(hu,D1o),e(hu,Tq),e(Tq,G1o),e(hu,O1o),e(x,V1o),e(x,pu),e(pu,Use),e(Use,X1o),e(pu,z1o),e(pu,Mq),e(Mq,W1o),e(pu,Q1o),e(x,H1o),e(x,uu),e(uu,Jse),e(Jse,U1o),e(uu,J1o),e(uu,Eq),e(Eq,Y1o),e(uu,K1o),e(x,Z1o),e(x,_u),e(_u,Yse),e(Yse,e7o),e(_u,o7o),e(_u,Cq),e(Cq,r7o),e(_u,t7o),e(x,a7o),e(x,bu),e(bu,Kse),e(Kse,n7o),e(bu,s7o),e(bu,wq),e(wq,l7o),e(bu,i7o),e(x,d7o),e(x,vu),e(vu,Zse),e(Zse,c7o),e(vu,f7o),e(vu,Aq),e(Aq,m7o),e(vu,g7o),e(x,h7o),e(x,Fu),e(Fu,ele),e(ele,p7o),e(Fu,u7o),e(Fu,yq),e(yq,_7o),e(Fu,b7o),e(x,v7o),e(x,Tu),e(Tu,ole),e(ole,F7o),e(Tu,T7o),e(Tu,Lq),e(Lq,M7o),e(Tu,E7o),e(x,C7o),e(x,Mu),e(Mu,rle),e(rle,w7o),e(Mu,A7o),e(Mu,xq),e(xq,y7o),e(Mu,L7o),e(x,x7o),e(x,Eu),e(Eu,tle),e(tle,$7o),e(Eu,k7o),e(Eu,$q),e($q,S7o),e(Eu,R7o),e(x,P7o),e(x,Cu),e(Cu,ale),e(ale,B7o),e(Cu,I7o),e(Cu,kq),e(kq,q7o),e(Cu,N7o),e(x,j7o),e(x,wu),e(wu,nle),e(nle,D7o),e(wu,G7o),e(wu,Sq),e(Sq,O7o),e(wu,V7o),e(x,X7o),e(x,Au),e(Au,sle),e(sle,z7o),e(Au,W7o),e(Au,Rq),e(Rq,Q7o),e(Au,H7o),e(x,U7o),e(x,yu),e(yu,lle),e(lle,J7o),e(yu,Y7o),e(yu,Pq),e(Pq,K7o),e(yu,Z7o),e(x,ebo),e(x,Lu),e(Lu,ile),e(ile,obo),e(Lu,rbo),e(Lu,Bq),e(Bq,tbo),e(Lu,abo),e(x,nbo),e(x,xu),e(xu,dle),e(dle,sbo),e(xu,lbo),e(xu,Iq),e(Iq,ibo),e(xu,dbo),e(x,cbo),e(x,$u),e($u,cle),e(cle,fbo),e($u,mbo),e($u,qq),e(qq,gbo),e($u,hbo),e(x,pbo),e(x,ku),e(ku,fle),e(fle,ubo),e(ku,_bo),e(ku,Nq),e(Nq,bbo),e(ku,vbo),e(x,Fbo),e(x,Su),e(Su,mle),e(mle,Tbo),e(Su,Mbo),e(Su,jq),e(jq,Ebo),e(Su,Cbo),e(x,wbo),e(x,Ru),e(Ru,gle),e(gle,Abo),e(Ru,ybo),e(Ru,Dq),e(Dq,Lbo),e(Ru,xbo),e(x,$bo),e(x,Pu),e(Pu,hle),e(hle,kbo),e(Pu,Sbo),e(Pu,Gq),e(Gq,Rbo),e(Pu,Pbo),e(x,Bbo),e(x,Bu),e(Bu,ple),e(ple,Ibo),e(Bu,qbo),e(Bu,Oq),e(Oq,Nbo),e(Bu,jbo),e(x,Dbo),e(x,Iu),e(Iu,ule),e(ule,Gbo),e(Iu,Obo),e(Iu,Vq),e(Vq,Vbo),e(Iu,Xbo),e(x,zbo),e(x,qu),e(qu,_le),e(_le,Wbo),e(qu,Qbo),e(qu,Xq),e(Xq,Hbo),e(qu,Ubo),e(x,Jbo),e(x,Nu),e(Nu,ble),e(ble,Ybo),e(Nu,Kbo),e(Nu,zq),e(zq,Zbo),e(Nu,evo),e(x,ovo),e(x,ju),e(ju,vle),e(vle,rvo),e(ju,tvo),e(ju,Wq),e(Wq,avo),e(ju,nvo),e(x,svo),e(x,Du),e(Du,Fle),e(Fle,lvo),e(Du,ivo),e(Du,Qq),e(Qq,dvo),e(Du,cvo),e(Je,fvo),e(Je,Gu),e(Gu,mvo),e(Gu,Tle),e(Tle,gvo),e(Gu,hvo),e(Gu,Mle),e(Mle,pvo),e(Je,uvo),M(Ou,Je,null),b(f,KIe,_),b(f,yi,_),e(yi,Vu),e(Vu,Ele),M(G6,Ele,null),e(yi,_vo),e(yi,Cle),e(Cle,bvo),b(f,ZIe,_),b(f,xo,_),M(O6,xo,null),e(xo,vvo),e(xo,Li),e(Li,Fvo),e(Li,Hq),e(Hq,Tvo),e(Li,Mvo),e(Li,Uq),e(Uq,Evo),e(Li,Cvo),e(xo,wvo),e(xo,V6),e(V6,Avo),e(V6,wle),e(wle,yvo),e(V6,Lvo),e(xo,xvo),e(xo,at),M(X6,at,null),e(at,$vo),e(at,Ale),e(Ale,kvo),e(at,Svo),e(at,xi),e(xi,Rvo),e(xi,yle),e(yle,Pvo),e(xi,Bvo),e(xi,Jq),e(Jq,Ivo),e(xi,qvo),e(at,Nvo),M(Xu,at,null),e(xo,jvo),e(xo,Ye),M(z6,Ye,null),e(Ye,Dvo),e(Ye,Lle),e(Lle,Gvo),e(Ye,Ovo),e(Ye,xa),e(xa,Vvo),e(xa,xle),e(xle,Xvo),e(xa,zvo),e(xa,$le),e($le,Wvo),e(xa,Qvo),e(xa,kle),e(kle,Hvo),e(xa,Uvo),e(Ye,Jvo),e(Ye,G),e(G,zu),e(zu,Sle),e(Sle,Yvo),e(zu,Kvo),e(zu,Yq),e(Yq,Zvo),e(zu,eFo),e(G,oFo),e(G,Wu),e(Wu,Rle),e(Rle,rFo),e(Wu,tFo),e(Wu,Kq),e(Kq,aFo),e(Wu,nFo),e(G,sFo),e(G,Qu),e(Qu,Ple),e(Ple,lFo),e(Qu,iFo),e(Qu,Zq),e(Zq,dFo),e(Qu,cFo),e(G,fFo),e(G,Hu),e(Hu,Ble),e(Ble,mFo),e(Hu,gFo),e(Hu,eN),e(eN,hFo),e(Hu,pFo),e(G,uFo),e(G,Uu),e(Uu,Ile),e(Ile,_Fo),e(Uu,bFo),e(Uu,oN),e(oN,vFo),e(Uu,FFo),e(G,TFo),e(G,Ju),e(Ju,qle),e(qle,MFo),e(Ju,EFo),e(Ju,rN),e(rN,CFo),e(Ju,wFo),e(G,AFo),e(G,Yu),e(Yu,Nle),e(Nle,yFo),e(Yu,LFo),e(Yu,tN),e(tN,xFo),e(Yu,$Fo),e(G,kFo),e(G,Ku),e(Ku,jle),e(jle,SFo),e(Ku,RFo),e(Ku,aN),e(aN,PFo),e(Ku,BFo),e(G,IFo),e(G,Zu),e(Zu,Dle),e(Dle,qFo),e(Zu,NFo),e(Zu,nN),e(nN,jFo),e(Zu,DFo),e(G,GFo),e(G,e_),e(e_,Gle),e(Gle,OFo),e(e_,VFo),e(e_,sN),e(sN,XFo),e(e_,zFo),e(G,WFo),e(G,o_),e(o_,Ole),e(Ole,QFo),e(o_,HFo),e(o_,lN),e(lN,UFo),e(o_,JFo),e(G,YFo),e(G,r_),e(r_,Vle),e(Vle,KFo),e(r_,ZFo),e(r_,iN),e(iN,eTo),e(r_,oTo),e(G,rTo),e(G,t_),e(t_,Xle),e(Xle,tTo),e(t_,aTo),e(t_,dN),e(dN,nTo),e(t_,sTo),e(G,lTo),e(G,a_),e(a_,zle),e(zle,iTo),e(a_,dTo),e(a_,cN),e(cN,cTo),e(a_,fTo),e(G,mTo),e(G,n_),e(n_,Wle),e(Wle,gTo),e(n_,hTo),e(n_,fN),e(fN,pTo),e(n_,uTo),e(G,_To),e(G,s_),e(s_,Qle),e(Qle,bTo),e(s_,vTo),e(s_,mN),e(mN,FTo),e(s_,TTo),e(G,MTo),e(G,l_),e(l_,Hle),e(Hle,ETo),e(l_,CTo),e(l_,gN),e(gN,wTo),e(l_,ATo),e(G,yTo),e(G,i_),e(i_,Ule),e(Ule,LTo),e(i_,xTo),e(i_,hN),e(hN,$To),e(i_,kTo),e(G,STo),e(G,d_),e(d_,Jle),e(Jle,RTo),e(d_,PTo),e(d_,pN),e(pN,BTo),e(d_,ITo),e(G,qTo),e(G,c_),e(c_,Yle),e(Yle,NTo),e(c_,jTo),e(c_,uN),e(uN,DTo),e(c_,GTo),e(G,OTo),e(G,f_),e(f_,Kle),e(Kle,VTo),e(f_,XTo),e(f_,_N),e(_N,zTo),e(f_,WTo),e(G,QTo),e(G,m_),e(m_,Zle),e(Zle,HTo),e(m_,UTo),e(m_,bN),e(bN,JTo),e(m_,YTo),e(G,KTo),e(G,g_),e(g_,eie),e(eie,ZTo),e(g_,eMo),e(g_,vN),e(vN,oMo),e(g_,rMo),e(G,tMo),e(G,h_),e(h_,oie),e(oie,aMo),e(h_,nMo),e(h_,FN),e(FN,sMo),e(h_,lMo),e(G,iMo),e(G,p_),e(p_,rie),e(rie,dMo),e(p_,cMo),e(p_,TN),e(TN,fMo),e(p_,mMo),e(G,gMo),e(G,u_),e(u_,tie),e(tie,hMo),e(u_,pMo),e(u_,MN),e(MN,uMo),e(u_,_Mo),e(G,bMo),e(G,__),e(__,aie),e(aie,vMo),e(__,FMo),e(__,EN),e(EN,TMo),e(__,MMo),e(G,EMo),e(G,b_),e(b_,nie),e(nie,CMo),e(b_,wMo),e(b_,CN),e(CN,AMo),e(b_,yMo),e(G,LMo),e(G,v_),e(v_,sie),e(sie,xMo),e(v_,$Mo),e(v_,wN),e(wN,kMo),e(v_,SMo),e(G,RMo),e(G,F_),e(F_,lie),e(lie,PMo),e(F_,BMo),e(F_,AN),e(AN,IMo),e(F_,qMo),e(G,NMo),e(G,T_),e(T_,iie),e(iie,jMo),e(T_,DMo),e(T_,yN),e(yN,GMo),e(T_,OMo),e(G,VMo),e(G,M_),e(M_,die),e(die,XMo),e(M_,zMo),e(M_,LN),e(LN,WMo),e(M_,QMo),e(G,HMo),e(G,E_),e(E_,cie),e(cie,UMo),e(E_,JMo),e(E_,xN),e(xN,YMo),e(E_,KMo),e(G,ZMo),e(G,C_),e(C_,fie),e(fie,e4o),e(C_,o4o),e(C_,$N),e($N,r4o),e(C_,t4o),e(G,a4o),e(G,w_),e(w_,mie),e(mie,n4o),e(w_,s4o),e(w_,kN),e(kN,l4o),e(w_,i4o),e(G,d4o),e(G,A_),e(A_,gie),e(gie,c4o),e(A_,f4o),e(A_,SN),e(SN,m4o),e(A_,g4o),e(G,h4o),e(G,y_),e(y_,hie),e(hie,p4o),e(y_,u4o),e(y_,RN),e(RN,_4o),e(y_,b4o),e(G,v4o),e(G,L_),e(L_,pie),e(pie,F4o),e(L_,T4o),e(L_,PN),e(PN,M4o),e(L_,E4o),e(G,C4o),e(G,x_),e(x_,uie),e(uie,w4o),e(x_,A4o),e(x_,BN),e(BN,y4o),e(x_,L4o),e(G,x4o),e(G,$_),e($_,_ie),e(_ie,$4o),e($_,k4o),e($_,IN),e(IN,S4o),e($_,R4o),e(G,P4o),e(G,k_),e(k_,bie),e(bie,B4o),e(k_,I4o),e(k_,qN),e(qN,q4o),e(k_,N4o),e(Ye,j4o),e(Ye,S_),e(S_,D4o),e(S_,vie),e(vie,G4o),e(S_,O4o),e(S_,Fie),e(Fie,V4o),e(Ye,X4o),M(R_,Ye,null),b(f,eqe,_),b(f,$i,_),e($i,P_),e(P_,Tie),M(W6,Tie,null),e($i,z4o),e($i,Mie),e(Mie,W4o),b(f,oqe,_),b(f,$o,_),M(Q6,$o,null),e($o,Q4o),e($o,ki),e(ki,H4o),e(ki,NN),e(NN,U4o),e(ki,J4o),e(ki,jN),e(jN,Y4o),e(ki,K4o),e($o,Z4o),e($o,H6),e(H6,eEo),e(H6,Eie),e(Eie,oEo),e(H6,rEo),e($o,tEo),e($o,nt),M(U6,nt,null),e(nt,aEo),e(nt,Cie),e(Cie,nEo),e(nt,sEo),e(nt,Si),e(Si,lEo),e(Si,wie),e(wie,iEo),e(Si,dEo),e(Si,DN),e(DN,cEo),e(Si,fEo),e(nt,mEo),M(B_,nt,null),e($o,gEo),e($o,Ke),M(J6,Ke,null),e(Ke,hEo),e(Ke,Aie),e(Aie,pEo),e(Ke,uEo),e(Ke,$a),e($a,_Eo),e($a,yie),e(yie,bEo),e($a,vEo),e($a,Lie),e(Lie,FEo),e($a,TEo),e($a,xie),e(xie,MEo),e($a,EEo),e(Ke,CEo),e(Ke,z),e(z,I_),e(I_,$ie),e($ie,wEo),e(I_,AEo),e(I_,GN),e(GN,yEo),e(I_,LEo),e(z,xEo),e(z,q_),e(q_,kie),e(kie,$Eo),e(q_,kEo),e(q_,ON),e(ON,SEo),e(q_,REo),e(z,PEo),e(z,N_),e(N_,Sie),e(Sie,BEo),e(N_,IEo),e(N_,VN),e(VN,qEo),e(N_,NEo),e(z,jEo),e(z,j_),e(j_,Rie),e(Rie,DEo),e(j_,GEo),e(j_,XN),e(XN,OEo),e(j_,VEo),e(z,XEo),e(z,D_),e(D_,Pie),e(Pie,zEo),e(D_,WEo),e(D_,zN),e(zN,QEo),e(D_,HEo),e(z,UEo),e(z,G_),e(G_,Bie),e(Bie,JEo),e(G_,YEo),e(G_,WN),e(WN,KEo),e(G_,ZEo),e(z,eCo),e(z,O_),e(O_,Iie),e(Iie,oCo),e(O_,rCo),e(O_,QN),e(QN,tCo),e(O_,aCo),e(z,nCo),e(z,V_),e(V_,qie),e(qie,sCo),e(V_,lCo),e(V_,HN),e(HN,iCo),e(V_,dCo),e(z,cCo),e(z,X_),e(X_,Nie),e(Nie,fCo),e(X_,mCo),e(X_,UN),e(UN,gCo),e(X_,hCo),e(z,pCo),e(z,z_),e(z_,jie),e(jie,uCo),e(z_,_Co),e(z_,JN),e(JN,bCo),e(z_,vCo),e(z,FCo),e(z,W_),e(W_,Die),e(Die,TCo),e(W_,MCo),e(W_,YN),e(YN,ECo),e(W_,CCo),e(z,wCo),e(z,Q_),e(Q_,Gie),e(Gie,ACo),e(Q_,yCo),e(Q_,KN),e(KN,LCo),e(Q_,xCo),e(z,$Co),e(z,H_),e(H_,Oie),e(Oie,kCo),e(H_,SCo),e(H_,ZN),e(ZN,RCo),e(H_,PCo),e(z,BCo),e(z,U_),e(U_,Vie),e(Vie,ICo),e(U_,qCo),e(U_,ej),e(ej,NCo),e(U_,jCo),e(z,DCo),e(z,J_),e(J_,Xie),e(Xie,GCo),e(J_,OCo),e(J_,oj),e(oj,VCo),e(J_,XCo),e(z,zCo),e(z,Y_),e(Y_,zie),e(zie,WCo),e(Y_,QCo),e(Y_,rj),e(rj,HCo),e(Y_,UCo),e(z,JCo),e(z,K_),e(K_,Wie),e(Wie,YCo),e(K_,KCo),e(K_,tj),e(tj,ZCo),e(K_,e5o),e(z,o5o),e(z,Z_),e(Z_,Qie),e(Qie,r5o),e(Z_,t5o),e(Z_,aj),e(aj,a5o),e(Z_,n5o),e(z,s5o),e(z,e2),e(e2,Hie),e(Hie,l5o),e(e2,i5o),e(e2,nj),e(nj,d5o),e(e2,c5o),e(z,f5o),e(z,o2),e(o2,Uie),e(Uie,m5o),e(o2,g5o),e(o2,sj),e(sj,h5o),e(o2,p5o),e(z,u5o),e(z,r2),e(r2,Jie),e(Jie,_5o),e(r2,b5o),e(r2,lj),e(lj,v5o),e(r2,F5o),e(z,T5o),e(z,t2),e(t2,Yie),e(Yie,M5o),e(t2,E5o),e(t2,ij),e(ij,C5o),e(t2,w5o),e(z,A5o),e(z,a2),e(a2,Kie),e(Kie,y5o),e(a2,L5o),e(a2,dj),e(dj,x5o),e(a2,$5o),e(z,k5o),e(z,n2),e(n2,Zie),e(Zie,S5o),e(n2,R5o),e(n2,cj),e(cj,P5o),e(n2,B5o),e(z,I5o),e(z,s2),e(s2,ede),e(ede,q5o),e(s2,N5o),e(s2,fj),e(fj,j5o),e(s2,D5o),e(z,G5o),e(z,l2),e(l2,ode),e(ode,O5o),e(l2,V5o),e(l2,mj),e(mj,X5o),e(l2,z5o),e(z,W5o),e(z,i2),e(i2,rde),e(rde,Q5o),e(i2,H5o),e(i2,gj),e(gj,U5o),e(i2,J5o),e(z,Y5o),e(z,d2),e(d2,tde),e(tde,K5o),e(d2,Z5o),e(d2,hj),e(hj,e3o),e(d2,o3o),e(z,r3o),e(z,c2),e(c2,ade),e(ade,t3o),e(c2,a3o),e(c2,pj),e(pj,n3o),e(c2,s3o),e(z,l3o),e(z,f2),e(f2,nde),e(nde,i3o),e(f2,d3o),e(f2,uj),e(uj,c3o),e(f2,f3o),e(z,m3o),e(z,m2),e(m2,sde),e(sde,g3o),e(m2,h3o),e(m2,_j),e(_j,p3o),e(m2,u3o),e(z,_3o),e(z,g2),e(g2,lde),e(lde,b3o),e(g2,v3o),e(g2,bj),e(bj,F3o),e(g2,T3o),e(z,M3o),e(z,h2),e(h2,ide),e(ide,E3o),e(h2,C3o),e(h2,vj),e(vj,w3o),e(h2,A3o),e(z,y3o),e(z,p2),e(p2,dde),e(dde,L3o),e(p2,x3o),e(p2,Fj),e(Fj,$3o),e(p2,k3o),e(z,S3o),e(z,u2),e(u2,cde),e(cde,R3o),e(u2,P3o),e(u2,Tj),e(Tj,B3o),e(u2,I3o),e(z,q3o),e(z,_2),e(_2,fde),e(fde,N3o),e(_2,j3o),e(_2,Mj),e(Mj,D3o),e(_2,G3o),e(Ke,O3o),e(Ke,b2),e(b2,V3o),e(b2,mde),e(mde,X3o),e(b2,z3o),e(b2,gde),e(gde,W3o),e(Ke,Q3o),M(v2,Ke,null),b(f,rqe,_),b(f,Ri,_),e(Ri,F2),e(F2,hde),M(Y6,hde,null),e(Ri,H3o),e(Ri,pde),e(pde,U3o),b(f,tqe,_),b(f,ko,_),M(K6,ko,null),e(ko,J3o),e(ko,Pi),e(Pi,Y3o),e(Pi,Ej),e(Ej,K3o),e(Pi,Z3o),e(Pi,Cj),e(Cj,ewo),e(Pi,owo),e(ko,rwo),e(ko,Z6),e(Z6,two),e(Z6,ude),e(ude,awo),e(Z6,nwo),e(ko,swo),e(ko,st),M(ey,st,null),e(st,lwo),e(st,_de),e(_de,iwo),e(st,dwo),e(st,Bi),e(Bi,cwo),e(Bi,bde),e(bde,fwo),e(Bi,mwo),e(Bi,wj),e(wj,gwo),e(Bi,hwo),e(st,pwo),M(T2,st,null),e(ko,uwo),e(ko,Ze),M(oy,Ze,null),e(Ze,_wo),e(Ze,vde),e(vde,bwo),e(Ze,vwo),e(Ze,ka),e(ka,Fwo),e(ka,Fde),e(Fde,Two),e(ka,Mwo),e(ka,Tde),e(Tde,Ewo),e(ka,Cwo),e(ka,Mde),e(Mde,wwo),e(ka,Awo),e(Ze,ywo),e(Ze,W),e(W,M2),e(M2,Ede),e(Ede,Lwo),e(M2,xwo),e(M2,Aj),e(Aj,$wo),e(M2,kwo),e(W,Swo),e(W,E2),e(E2,Cde),e(Cde,Rwo),e(E2,Pwo),e(E2,yj),e(yj,Bwo),e(E2,Iwo),e(W,qwo),e(W,C2),e(C2,wde),e(wde,Nwo),e(C2,jwo),e(C2,Lj),e(Lj,Dwo),e(C2,Gwo),e(W,Owo),e(W,w2),e(w2,Ade),e(Ade,Vwo),e(w2,Xwo),e(w2,xj),e(xj,zwo),e(w2,Wwo),e(W,Qwo),e(W,A2),e(A2,yde),e(yde,Hwo),e(A2,Uwo),e(A2,$j),e($j,Jwo),e(A2,Ywo),e(W,Kwo),e(W,y2),e(y2,Lde),e(Lde,Zwo),e(y2,eAo),e(y2,kj),e(kj,oAo),e(y2,rAo),e(W,tAo),e(W,L2),e(L2,xde),e(xde,aAo),e(L2,nAo),e(L2,Sj),e(Sj,sAo),e(L2,lAo),e(W,iAo),e(W,x2),e(x2,$de),e($de,dAo),e(x2,cAo),e(x2,Rj),e(Rj,fAo),e(x2,mAo),e(W,gAo),e(W,$2),e($2,kde),e(kde,hAo),e($2,pAo),e($2,Pj),e(Pj,uAo),e($2,_Ao),e(W,bAo),e(W,k2),e(k2,Sde),e(Sde,vAo),e(k2,FAo),e(k2,Bj),e(Bj,TAo),e(k2,MAo),e(W,EAo),e(W,S2),e(S2,Rde),e(Rde,CAo),e(S2,wAo),e(S2,Ij),e(Ij,AAo),e(S2,yAo),e(W,LAo),e(W,R2),e(R2,Pde),e(Pde,xAo),e(R2,$Ao),e(R2,qj),e(qj,kAo),e(R2,SAo),e(W,RAo),e(W,P2),e(P2,Bde),e(Bde,PAo),e(P2,BAo),e(P2,Nj),e(Nj,IAo),e(P2,qAo),e(W,NAo),e(W,B2),e(B2,Ide),e(Ide,jAo),e(B2,DAo),e(B2,jj),e(jj,GAo),e(B2,OAo),e(W,VAo),e(W,I2),e(I2,qde),e(qde,XAo),e(I2,zAo),e(I2,Dj),e(Dj,WAo),e(I2,QAo),e(W,HAo),e(W,q2),e(q2,Nde),e(Nde,UAo),e(q2,JAo),e(q2,Gj),e(Gj,YAo),e(q2,KAo),e(W,ZAo),e(W,N2),e(N2,jde),e(jde,e0o),e(N2,o0o),e(N2,Oj),e(Oj,r0o),e(N2,t0o),e(W,a0o),e(W,j2),e(j2,Dde),e(Dde,n0o),e(j2,s0o),e(j2,Vj),e(Vj,l0o),e(j2,i0o),e(W,d0o),e(W,D2),e(D2,Gde),e(Gde,c0o),e(D2,f0o),e(D2,Xj),e(Xj,m0o),e(D2,g0o),e(W,h0o),e(W,G2),e(G2,Ode),e(Ode,p0o),e(G2,u0o),e(G2,zj),e(zj,_0o),e(G2,b0o),e(W,v0o),e(W,O2),e(O2,Vde),e(Vde,F0o),e(O2,T0o),e(O2,Wj),e(Wj,M0o),e(O2,E0o),e(W,C0o),e(W,V2),e(V2,Xde),e(Xde,w0o),e(V2,A0o),e(V2,Qj),e(Qj,y0o),e(V2,L0o),e(W,x0o),e(W,X2),e(X2,zde),e(zde,$0o),e(X2,k0o),e(X2,Hj),e(Hj,S0o),e(X2,R0o),e(W,P0o),e(W,z2),e(z2,Wde),e(Wde,B0o),e(z2,I0o),e(z2,Uj),e(Uj,q0o),e(z2,N0o),e(W,j0o),e(W,W2),e(W2,Qde),e(Qde,D0o),e(W2,G0o),e(W2,Jj),e(Jj,O0o),e(W2,V0o),e(W,X0o),e(W,Q2),e(Q2,Hde),e(Hde,z0o),e(Q2,W0o),e(Q2,Yj),e(Yj,Q0o),e(Q2,H0o),e(W,U0o),e(W,H2),e(H2,Ude),e(Ude,J0o),e(H2,Y0o),e(H2,Kj),e(Kj,K0o),e(H2,Z0o),e(W,e6o),e(W,U2),e(U2,Jde),e(Jde,o6o),e(U2,r6o),e(U2,Zj),e(Zj,t6o),e(U2,a6o),e(W,n6o),e(W,J2),e(J2,Yde),e(Yde,s6o),e(J2,l6o),e(J2,eD),e(eD,i6o),e(J2,d6o),e(W,c6o),e(W,Y2),e(Y2,Kde),e(Kde,f6o),e(Y2,m6o),e(Y2,oD),e(oD,g6o),e(Y2,h6o),e(W,p6o),e(W,K2),e(K2,Zde),e(Zde,u6o),e(K2,_6o),e(K2,ece),e(ece,b6o),e(K2,v6o),e(W,F6o),e(W,Z2),e(Z2,oce),e(oce,T6o),e(Z2,M6o),e(Z2,rD),e(rD,E6o),e(Z2,C6o),e(W,w6o),e(W,e1),e(e1,rce),e(rce,A6o),e(e1,y6o),e(e1,tD),e(tD,L6o),e(e1,x6o),e(W,$6o),e(W,o1),e(o1,tce),e(tce,k6o),e(o1,S6o),e(o1,aD),e(aD,R6o),e(o1,P6o),e(W,B6o),e(W,r1),e(r1,ace),e(ace,I6o),e(r1,q6o),e(r1,nD),e(nD,N6o),e(r1,j6o),e(Ze,D6o),e(Ze,t1),e(t1,G6o),e(t1,nce),e(nce,O6o),e(t1,V6o),e(t1,sce),e(sce,X6o),e(Ze,z6o),M(a1,Ze,null),b(f,aqe,_),b(f,Ii,_),e(Ii,n1),e(n1,lce),M(ry,lce,null),e(Ii,W6o),e(Ii,ice),e(ice,Q6o),b(f,nqe,_),b(f,So,_),M(ty,So,null),e(So,H6o),e(So,qi),e(qi,U6o),e(qi,sD),e(sD,J6o),e(qi,Y6o),e(qi,lD),e(lD,K6o),e(qi,Z6o),e(So,eyo),e(So,ay),e(ay,oyo),e(ay,dce),e(dce,ryo),e(ay,tyo),e(So,ayo),e(So,lt),M(ny,lt,null),e(lt,nyo),e(lt,cce),e(cce,syo),e(lt,lyo),e(lt,Ni),e(Ni,iyo),e(Ni,fce),e(fce,dyo),e(Ni,cyo),e(Ni,iD),e(iD,fyo),e(Ni,myo),e(lt,gyo),M(s1,lt,null),e(So,hyo),e(So,eo),M(sy,eo,null),e(eo,pyo),e(eo,mce),e(mce,uyo),e(eo,_yo),e(eo,Sa),e(Sa,byo),e(Sa,gce),e(gce,vyo),e(Sa,Fyo),e(Sa,hce),e(hce,Tyo),e(Sa,Myo),e(Sa,pce),e(pce,Eyo),e(Sa,Cyo),e(eo,wyo),e(eo,ue),e(ue,l1),e(l1,uce),e(uce,Ayo),e(l1,yyo),e(l1,dD),e(dD,Lyo),e(l1,xyo),e(ue,$yo),e(ue,i1),e(i1,_ce),e(_ce,kyo),e(i1,Syo),e(i1,cD),e(cD,Ryo),e(i1,Pyo),e(ue,Byo),e(ue,d1),e(d1,bce),e(bce,Iyo),e(d1,qyo),e(d1,fD),e(fD,Nyo),e(d1,jyo),e(ue,Dyo),e(ue,c1),e(c1,vce),e(vce,Gyo),e(c1,Oyo),e(c1,mD),e(mD,Vyo),e(c1,Xyo),e(ue,zyo),e(ue,f1),e(f1,Fce),e(Fce,Wyo),e(f1,Qyo),e(f1,gD),e(gD,Hyo),e(f1,Uyo),e(ue,Jyo),e(ue,m1),e(m1,Tce),e(Tce,Yyo),e(m1,Kyo),e(m1,hD),e(hD,Zyo),e(m1,eLo),e(ue,oLo),e(ue,g1),e(g1,Mce),e(Mce,rLo),e(g1,tLo),e(g1,pD),e(pD,aLo),e(g1,nLo),e(ue,sLo),e(ue,h1),e(h1,Ece),e(Ece,lLo),e(h1,iLo),e(h1,uD),e(uD,dLo),e(h1,cLo),e(ue,fLo),e(ue,p1),e(p1,Cce),e(Cce,mLo),e(p1,gLo),e(p1,_D),e(_D,hLo),e(p1,pLo),e(ue,uLo),e(ue,u1),e(u1,wce),e(wce,_Lo),e(u1,bLo),e(u1,bD),e(bD,vLo),e(u1,FLo),e(ue,TLo),e(ue,_1),e(_1,Ace),e(Ace,MLo),e(_1,ELo),e(_1,vD),e(vD,CLo),e(_1,wLo),e(ue,ALo),e(ue,b1),e(b1,yce),e(yce,yLo),e(b1,LLo),e(b1,FD),e(FD,xLo),e(b1,$Lo),e(ue,kLo),e(ue,v1),e(v1,Lce),e(Lce,SLo),e(v1,RLo),e(v1,TD),e(TD,PLo),e(v1,BLo),e(ue,ILo),e(ue,F1),e(F1,xce),e(xce,qLo),e(F1,NLo),e(F1,MD),e(MD,jLo),e(F1,DLo),e(ue,GLo),e(ue,T1),e(T1,$ce),e($ce,OLo),e(T1,VLo),e(T1,ED),e(ED,XLo),e(T1,zLo),e(ue,WLo),e(ue,M1),e(M1,kce),e(kce,QLo),e(M1,HLo),e(M1,CD),e(CD,ULo),e(M1,JLo),e(eo,YLo),e(eo,E1),e(E1,KLo),e(E1,Sce),e(Sce,ZLo),e(E1,e8o),e(E1,Rce),e(Rce,o8o),e(eo,r8o),M(C1,eo,null),b(f,sqe,_),b(f,ji,_),e(ji,w1),e(w1,Pce),M(ly,Pce,null),e(ji,t8o),e(ji,Bce),e(Bce,a8o),b(f,lqe,_),b(f,Ro,_),M(iy,Ro,null),e(Ro,n8o),e(Ro,Di),e(Di,s8o),e(Di,wD),e(wD,l8o),e(Di,i8o),e(Di,AD),e(AD,d8o),e(Di,c8o),e(Ro,f8o),e(Ro,dy),e(dy,m8o),e(dy,Ice),e(Ice,g8o),e(dy,h8o),e(Ro,p8o),e(Ro,it),M(cy,it,null),e(it,u8o),e(it,qce),e(qce,_8o),e(it,b8o),e(it,Gi),e(Gi,v8o),e(Gi,Nce),e(Nce,F8o),e(Gi,T8o),e(Gi,yD),e(yD,M8o),e(Gi,E8o),e(it,C8o),M(A1,it,null),e(Ro,w8o),e(Ro,oo),M(fy,oo,null),e(oo,A8o),e(oo,jce),e(jce,y8o),e(oo,L8o),e(oo,Ra),e(Ra,x8o),e(Ra,Dce),e(Dce,$8o),e(Ra,k8o),e(Ra,Gce),e(Gce,S8o),e(Ra,R8o),e(Ra,Oce),e(Oce,P8o),e(Ra,B8o),e(oo,I8o),e(oo,N),e(N,y1),e(y1,Vce),e(Vce,q8o),e(y1,N8o),e(y1,LD),e(LD,j8o),e(y1,D8o),e(N,G8o),e(N,L1),e(L1,Xce),e(Xce,O8o),e(L1,V8o),e(L1,xD),e(xD,X8o),e(L1,z8o),e(N,W8o),e(N,x1),e(x1,zce),e(zce,Q8o),e(x1,H8o),e(x1,$D),e($D,U8o),e(x1,J8o),e(N,Y8o),e(N,$1),e($1,Wce),e(Wce,K8o),e($1,Z8o),e($1,kD),e(kD,exo),e($1,oxo),e(N,rxo),e(N,k1),e(k1,Qce),e(Qce,txo),e(k1,axo),e(k1,SD),e(SD,nxo),e(k1,sxo),e(N,lxo),e(N,S1),e(S1,Hce),e(Hce,ixo),e(S1,dxo),e(S1,RD),e(RD,cxo),e(S1,fxo),e(N,mxo),e(N,R1),e(R1,Uce),e(Uce,gxo),e(R1,hxo),e(R1,PD),e(PD,pxo),e(R1,uxo),e(N,_xo),e(N,P1),e(P1,Jce),e(Jce,bxo),e(P1,vxo),e(P1,BD),e(BD,Fxo),e(P1,Txo),e(N,Mxo),e(N,B1),e(B1,Yce),e(Yce,Exo),e(B1,Cxo),e(B1,ID),e(ID,wxo),e(B1,Axo),e(N,yxo),e(N,I1),e(I1,Kce),e(Kce,Lxo),e(I1,xxo),e(I1,qD),e(qD,$xo),e(I1,kxo),e(N,Sxo),e(N,q1),e(q1,Zce),e(Zce,Rxo),e(q1,Pxo),e(q1,ND),e(ND,Bxo),e(q1,Ixo),e(N,qxo),e(N,N1),e(N1,efe),e(efe,Nxo),e(N1,jxo),e(N1,jD),e(jD,Dxo),e(N1,Gxo),e(N,Oxo),e(N,j1),e(j1,ofe),e(ofe,Vxo),e(j1,Xxo),e(j1,DD),e(DD,zxo),e(j1,Wxo),e(N,Qxo),e(N,D1),e(D1,rfe),e(rfe,Hxo),e(D1,Uxo),e(D1,GD),e(GD,Jxo),e(D1,Yxo),e(N,Kxo),e(N,G1),e(G1,tfe),e(tfe,Zxo),e(G1,e9o),e(G1,OD),e(OD,o9o),e(G1,r9o),e(N,t9o),e(N,O1),e(O1,afe),e(afe,a9o),e(O1,n9o),e(O1,VD),e(VD,s9o),e(O1,l9o),e(N,i9o),e(N,V1),e(V1,nfe),e(nfe,d9o),e(V1,c9o),e(V1,XD),e(XD,f9o),e(V1,m9o),e(N,g9o),e(N,X1),e(X1,sfe),e(sfe,h9o),e(X1,p9o),e(X1,zD),e(zD,u9o),e(X1,_9o),e(N,b9o),e(N,z1),e(z1,lfe),e(lfe,v9o),e(z1,F9o),e(z1,WD),e(WD,T9o),e(z1,M9o),e(N,E9o),e(N,W1),e(W1,ife),e(ife,C9o),e(W1,w9o),e(W1,QD),e(QD,A9o),e(W1,y9o),e(N,L9o),e(N,Q1),e(Q1,dfe),e(dfe,x9o),e(Q1,$9o),e(Q1,HD),e(HD,k9o),e(Q1,S9o),e(N,R9o),e(N,H1),e(H1,cfe),e(cfe,P9o),e(H1,B9o),e(H1,UD),e(UD,I9o),e(H1,q9o),e(N,N9o),e(N,U1),e(U1,ffe),e(ffe,j9o),e(U1,D9o),e(U1,JD),e(JD,G9o),e(U1,O9o),e(N,V9o),e(N,J1),e(J1,mfe),e(mfe,X9o),e(J1,z9o),e(J1,YD),e(YD,W9o),e(J1,Q9o),e(N,H9o),e(N,Y1),e(Y1,gfe),e(gfe,U9o),e(Y1,J9o),e(Y1,KD),e(KD,Y9o),e(Y1,K9o),e(N,Z9o),e(N,K1),e(K1,hfe),e(hfe,e$o),e(K1,o$o),e(K1,ZD),e(ZD,r$o),e(K1,t$o),e(N,a$o),e(N,Z1),e(Z1,pfe),e(pfe,n$o),e(Z1,s$o),e(Z1,eG),e(eG,l$o),e(Z1,i$o),e(N,d$o),e(N,e7),e(e7,ufe),e(ufe,c$o),e(e7,f$o),e(e7,oG),e(oG,m$o),e(e7,g$o),e(N,h$o),e(N,o7),e(o7,_fe),e(_fe,p$o),e(o7,u$o),e(o7,rG),e(rG,_$o),e(o7,b$o),e(N,v$o),e(N,r7),e(r7,bfe),e(bfe,F$o),e(r7,T$o),e(r7,tG),e(tG,M$o),e(r7,E$o),e(N,C$o),e(N,t7),e(t7,vfe),e(vfe,w$o),e(t7,A$o),e(t7,aG),e(aG,y$o),e(t7,L$o),e(N,x$o),e(N,a7),e(a7,Ffe),e(Ffe,$$o),e(a7,k$o),e(a7,nG),e(nG,S$o),e(a7,R$o),e(N,P$o),e(N,n7),e(n7,Tfe),e(Tfe,B$o),e(n7,I$o),e(n7,sG),e(sG,q$o),e(n7,N$o),e(N,j$o),e(N,s7),e(s7,Mfe),e(Mfe,D$o),e(s7,G$o),e(s7,lG),e(lG,O$o),e(s7,V$o),e(N,X$o),e(N,l7),e(l7,Efe),e(Efe,z$o),e(l7,W$o),e(l7,iG),e(iG,Q$o),e(l7,H$o),e(N,U$o),e(N,i7),e(i7,Cfe),e(Cfe,J$o),e(i7,Y$o),e(i7,dG),e(dG,K$o),e(i7,Z$o),e(N,eko),e(N,d7),e(d7,wfe),e(wfe,oko),e(d7,rko),e(d7,cG),e(cG,tko),e(d7,ako),e(N,nko),e(N,c7),e(c7,Afe),e(Afe,sko),e(c7,lko),e(c7,fG),e(fG,iko),e(c7,dko),e(N,cko),e(N,f7),e(f7,yfe),e(yfe,fko),e(f7,mko),e(f7,mG),e(mG,gko),e(f7,hko),e(N,pko),e(N,m7),e(m7,Lfe),e(Lfe,uko),e(m7,_ko),e(m7,gG),e(gG,bko),e(m7,vko),e(N,Fko),e(N,g7),e(g7,xfe),e(xfe,Tko),e(g7,Mko),e(g7,hG),e(hG,Eko),e(g7,Cko),e(N,wko),e(N,h7),e(h7,$fe),e($fe,Ako),e(h7,yko),e(h7,pG),e(pG,Lko),e(h7,xko),e(N,$ko),e(N,p7),e(p7,kfe),e(kfe,kko),e(p7,Sko),e(p7,uG),e(uG,Rko),e(p7,Pko),e(N,Bko),e(N,u7),e(u7,Sfe),e(Sfe,Iko),e(u7,qko),e(u7,_G),e(_G,Nko),e(u7,jko),e(N,Dko),e(N,_7),e(_7,Rfe),e(Rfe,Gko),e(_7,Oko),e(_7,bG),e(bG,Vko),e(_7,Xko),e(N,zko),e(N,b7),e(b7,Pfe),e(Pfe,Wko),e(b7,Qko),e(b7,vG),e(vG,Hko),e(b7,Uko),e(oo,Jko),e(oo,v7),e(v7,Yko),e(v7,Bfe),e(Bfe,Kko),e(v7,Zko),e(v7,Ife),e(Ife,eSo),e(oo,oSo),M(F7,oo,null),b(f,iqe,_),b(f,Oi,_),e(Oi,T7),e(T7,qfe),M(my,qfe,null),e(Oi,rSo),e(Oi,Nfe),e(Nfe,tSo),b(f,dqe,_),b(f,Po,_),M(gy,Po,null),e(Po,aSo),e(Po,Vi),e(Vi,nSo),e(Vi,FG),e(FG,sSo),e(Vi,lSo),e(Vi,TG),e(TG,iSo),e(Vi,dSo),e(Po,cSo),e(Po,hy),e(hy,fSo),e(hy,jfe),e(jfe,mSo),e(hy,gSo),e(Po,hSo),e(Po,dt),M(py,dt,null),e(dt,pSo),e(dt,Dfe),e(Dfe,uSo),e(dt,_So),e(dt,Xi),e(Xi,bSo),e(Xi,Gfe),e(Gfe,vSo),e(Xi,FSo),e(Xi,MG),e(MG,TSo),e(Xi,MSo),e(dt,ESo),M(M7,dt,null),e(Po,CSo),e(Po,ro),M(uy,ro,null),e(ro,wSo),e(ro,Ofe),e(Ofe,ASo),e(ro,ySo),e(ro,Pa),e(Pa,LSo),e(Pa,Vfe),e(Vfe,xSo),e(Pa,$So),e(Pa,Xfe),e(Xfe,kSo),e(Pa,SSo),e(Pa,zfe),e(zfe,RSo),e(Pa,PSo),e(ro,BSo),e(ro,Y),e(Y,E7),e(E7,Wfe),e(Wfe,ISo),e(E7,qSo),e(E7,EG),e(EG,NSo),e(E7,jSo),e(Y,DSo),e(Y,C7),e(C7,Qfe),e(Qfe,GSo),e(C7,OSo),e(C7,CG),e(CG,VSo),e(C7,XSo),e(Y,zSo),e(Y,w7),e(w7,Hfe),e(Hfe,WSo),e(w7,QSo),e(w7,wG),e(wG,HSo),e(w7,USo),e(Y,JSo),e(Y,A7),e(A7,Ufe),e(Ufe,YSo),e(A7,KSo),e(A7,AG),e(AG,ZSo),e(A7,eRo),e(Y,oRo),e(Y,y7),e(y7,Jfe),e(Jfe,rRo),e(y7,tRo),e(y7,yG),e(yG,aRo),e(y7,nRo),e(Y,sRo),e(Y,L7),e(L7,Yfe),e(Yfe,lRo),e(L7,iRo),e(L7,LG),e(LG,dRo),e(L7,cRo),e(Y,fRo),e(Y,x7),e(x7,Kfe),e(Kfe,mRo),e(x7,gRo),e(x7,xG),e(xG,hRo),e(x7,pRo),e(Y,uRo),e(Y,$7),e($7,Zfe),e(Zfe,_Ro),e($7,bRo),e($7,$G),e($G,vRo),e($7,FRo),e(Y,TRo),e(Y,k7),e(k7,eme),e(eme,MRo),e(k7,ERo),e(k7,kG),e(kG,CRo),e(k7,wRo),e(Y,ARo),e(Y,S7),e(S7,ome),e(ome,yRo),e(S7,LRo),e(S7,SG),e(SG,xRo),e(S7,$Ro),e(Y,kRo),e(Y,R7),e(R7,rme),e(rme,SRo),e(R7,RRo),e(R7,RG),e(RG,PRo),e(R7,BRo),e(Y,IRo),e(Y,P7),e(P7,tme),e(tme,qRo),e(P7,NRo),e(P7,PG),e(PG,jRo),e(P7,DRo),e(Y,GRo),e(Y,B7),e(B7,ame),e(ame,ORo),e(B7,VRo),e(B7,BG),e(BG,XRo),e(B7,zRo),e(Y,WRo),e(Y,I7),e(I7,nme),e(nme,QRo),e(I7,HRo),e(I7,IG),e(IG,URo),e(I7,JRo),e(Y,YRo),e(Y,q7),e(q7,sme),e(sme,KRo),e(q7,ZRo),e(q7,qG),e(qG,ePo),e(q7,oPo),e(Y,rPo),e(Y,N7),e(N7,lme),e(lme,tPo),e(N7,aPo),e(N7,NG),e(NG,nPo),e(N7,sPo),e(Y,lPo),e(Y,j7),e(j7,ime),e(ime,iPo),e(j7,dPo),e(j7,jG),e(jG,cPo),e(j7,fPo),e(Y,mPo),e(Y,D7),e(D7,dme),e(dme,gPo),e(D7,hPo),e(D7,DG),e(DG,pPo),e(D7,uPo),e(Y,_Po),e(Y,G7),e(G7,cme),e(cme,bPo),e(G7,vPo),e(G7,GG),e(GG,FPo),e(G7,TPo),e(Y,MPo),e(Y,O7),e(O7,fme),e(fme,EPo),e(O7,CPo),e(O7,OG),e(OG,wPo),e(O7,APo),e(Y,yPo),e(Y,V7),e(V7,mme),e(mme,LPo),e(V7,xPo),e(V7,VG),e(VG,$Po),e(V7,kPo),e(Y,SPo),e(Y,X7),e(X7,gme),e(gme,RPo),e(X7,PPo),e(X7,XG),e(XG,BPo),e(X7,IPo),e(Y,qPo),e(Y,z7),e(z7,hme),e(hme,NPo),e(z7,jPo),e(z7,zG),e(zG,DPo),e(z7,GPo),e(Y,OPo),e(Y,W7),e(W7,pme),e(pme,VPo),e(W7,XPo),e(W7,WG),e(WG,zPo),e(W7,WPo),e(Y,QPo),e(Y,Q7),e(Q7,ume),e(ume,HPo),e(Q7,UPo),e(Q7,QG),e(QG,JPo),e(Q7,YPo),e(Y,KPo),e(Y,H7),e(H7,_me),e(_me,ZPo),e(H7,eBo),e(H7,HG),e(HG,oBo),e(H7,rBo),e(Y,tBo),e(Y,U7),e(U7,bme),e(bme,aBo),e(U7,nBo),e(U7,UG),e(UG,sBo),e(U7,lBo),e(Y,iBo),e(Y,J7),e(J7,vme),e(vme,dBo),e(J7,cBo),e(J7,JG),e(JG,fBo),e(J7,mBo),e(Y,gBo),e(Y,Y7),e(Y7,Fme),e(Fme,hBo),e(Y7,pBo),e(Y7,YG),e(YG,uBo),e(Y7,_Bo),e(ro,bBo),e(ro,K7),e(K7,vBo),e(K7,Tme),e(Tme,FBo),e(K7,TBo),e(K7,Mme),e(Mme,MBo),e(ro,EBo),M(Z7,ro,null),b(f,cqe,_),b(f,zi,_),e(zi,eb),e(eb,Eme),M(_y,Eme,null),e(zi,CBo),e(zi,Cme),e(Cme,wBo),b(f,fqe,_),b(f,Bo,_),M(by,Bo,null),e(Bo,ABo),e(Bo,Wi),e(Wi,yBo),e(Wi,KG),e(KG,LBo),e(Wi,xBo),e(Wi,ZG),e(ZG,$Bo),e(Wi,kBo),e(Bo,SBo),e(Bo,vy),e(vy,RBo),e(vy,wme),e(wme,PBo),e(vy,BBo),e(Bo,IBo),e(Bo,ct),M(Fy,ct,null),e(ct,qBo),e(ct,Ame),e(Ame,NBo),e(ct,jBo),e(ct,Qi),e(Qi,DBo),e(Qi,yme),e(yme,GBo),e(Qi,OBo),e(Qi,eO),e(eO,VBo),e(Qi,XBo),e(ct,zBo),M(ob,ct,null),e(Bo,WBo),e(Bo,to),M(Ty,to,null),e(to,QBo),e(to,Lme),e(Lme,HBo),e(to,UBo),e(to,Ba),e(Ba,JBo),e(Ba,xme),e(xme,YBo),e(Ba,KBo),e(Ba,$me),e($me,ZBo),e(Ba,eIo),e(Ba,kme),e(kme,oIo),e(Ba,rIo),e(to,tIo),e(to,Yr),e(Yr,rb),e(rb,Sme),e(Sme,aIo),e(rb,nIo),e(rb,oO),e(oO,sIo),e(rb,lIo),e(Yr,iIo),e(Yr,tb),e(tb,Rme),e(Rme,dIo),e(tb,cIo),e(tb,rO),e(rO,fIo),e(tb,mIo),e(Yr,gIo),e(Yr,ab),e(ab,Pme),e(Pme,hIo),e(ab,pIo),e(ab,tO),e(tO,uIo),e(ab,_Io),e(Yr,bIo),e(Yr,nb),e(nb,Bme),e(Bme,vIo),e(nb,FIo),e(nb,aO),e(aO,TIo),e(nb,MIo),e(Yr,EIo),e(Yr,sb),e(sb,Ime),e(Ime,CIo),e(sb,wIo),e(sb,nO),e(nO,AIo),e(sb,yIo),e(to,LIo),e(to,lb),e(lb,xIo),e(lb,qme),e(qme,$Io),e(lb,kIo),e(lb,Nme),e(Nme,SIo),e(to,RIo),M(ib,to,null),b(f,mqe,_),b(f,Hi,_),e(Hi,db),e(db,jme),M(My,jme,null),e(Hi,PIo),e(Hi,Dme),e(Dme,BIo),b(f,gqe,_),b(f,Io,_),M(Ey,Io,null),e(Io,IIo),e(Io,Ui),e(Ui,qIo),e(Ui,sO),e(sO,NIo),e(Ui,jIo),e(Ui,lO),e(lO,DIo),e(Ui,GIo),e(Io,OIo),e(Io,Cy),e(Cy,VIo),e(Cy,Gme),e(Gme,XIo),e(Cy,zIo),e(Io,WIo),e(Io,ft),M(wy,ft,null),e(ft,QIo),e(ft,Ome),e(Ome,HIo),e(ft,UIo),e(ft,Ji),e(Ji,JIo),e(Ji,Vme),e(Vme,YIo),e(Ji,KIo),e(Ji,iO),e(iO,ZIo),e(Ji,eqo),e(ft,oqo),M(cb,ft,null),e(Io,rqo),e(Io,ao),M(Ay,ao,null),e(ao,tqo),e(ao,Xme),e(Xme,aqo),e(ao,nqo),e(ao,Ia),e(Ia,sqo),e(Ia,zme),e(zme,lqo),e(Ia,iqo),e(Ia,Wme),e(Wme,dqo),e(Ia,cqo),e(Ia,Qme),e(Qme,fqo),e(Ia,mqo),e(ao,gqo),e(ao,U),e(U,fb),e(fb,Hme),e(Hme,hqo),e(fb,pqo),e(fb,dO),e(dO,uqo),e(fb,_qo),e(U,bqo),e(U,mb),e(mb,Ume),e(Ume,vqo),e(mb,Fqo),e(mb,cO),e(cO,Tqo),e(mb,Mqo),e(U,Eqo),e(U,gb),e(gb,Jme),e(Jme,Cqo),e(gb,wqo),e(gb,fO),e(fO,Aqo),e(gb,yqo),e(U,Lqo),e(U,hb),e(hb,Yme),e(Yme,xqo),e(hb,$qo),e(hb,mO),e(mO,kqo),e(hb,Sqo),e(U,Rqo),e(U,pb),e(pb,Kme),e(Kme,Pqo),e(pb,Bqo),e(pb,gO),e(gO,Iqo),e(pb,qqo),e(U,Nqo),e(U,ub),e(ub,Zme),e(Zme,jqo),e(ub,Dqo),e(ub,hO),e(hO,Gqo),e(ub,Oqo),e(U,Vqo),e(U,_b),e(_b,ege),e(ege,Xqo),e(_b,zqo),e(_b,pO),e(pO,Wqo),e(_b,Qqo),e(U,Hqo),e(U,bb),e(bb,oge),e(oge,Uqo),e(bb,Jqo),e(bb,uO),e(uO,Yqo),e(bb,Kqo),e(U,Zqo),e(U,vb),e(vb,rge),e(rge,eNo),e(vb,oNo),e(vb,_O),e(_O,rNo),e(vb,tNo),e(U,aNo),e(U,Fb),e(Fb,tge),e(tge,nNo),e(Fb,sNo),e(Fb,bO),e(bO,lNo),e(Fb,iNo),e(U,dNo),e(U,Tb),e(Tb,age),e(age,cNo),e(Tb,fNo),e(Tb,vO),e(vO,mNo),e(Tb,gNo),e(U,hNo),e(U,Mb),e(Mb,nge),e(nge,pNo),e(Mb,uNo),e(Mb,FO),e(FO,_No),e(Mb,bNo),e(U,vNo),e(U,Eb),e(Eb,sge),e(sge,FNo),e(Eb,TNo),e(Eb,TO),e(TO,MNo),e(Eb,ENo),e(U,CNo),e(U,Cb),e(Cb,lge),e(lge,wNo),e(Cb,ANo),e(Cb,MO),e(MO,yNo),e(Cb,LNo),e(U,xNo),e(U,wb),e(wb,ige),e(ige,$No),e(wb,kNo),e(wb,EO),e(EO,SNo),e(wb,RNo),e(U,PNo),e(U,Ab),e(Ab,dge),e(dge,BNo),e(Ab,INo),e(Ab,CO),e(CO,qNo),e(Ab,NNo),e(U,jNo),e(U,yb),e(yb,cge),e(cge,DNo),e(yb,GNo),e(yb,wO),e(wO,ONo),e(yb,VNo),e(U,XNo),e(U,Lb),e(Lb,fge),e(fge,zNo),e(Lb,WNo),e(Lb,AO),e(AO,QNo),e(Lb,HNo),e(U,UNo),e(U,xb),e(xb,mge),e(mge,JNo),e(xb,YNo),e(xb,yO),e(yO,KNo),e(xb,ZNo),e(U,ejo),e(U,$b),e($b,gge),e(gge,ojo),e($b,rjo),e($b,LO),e(LO,tjo),e($b,ajo),e(U,njo),e(U,kb),e(kb,hge),e(hge,sjo),e(kb,ljo),e(kb,xO),e(xO,ijo),e(kb,djo),e(U,cjo),e(U,Sb),e(Sb,pge),e(pge,fjo),e(Sb,mjo),e(Sb,$O),e($O,gjo),e(Sb,hjo),e(U,pjo),e(U,Rb),e(Rb,uge),e(uge,ujo),e(Rb,_jo),e(Rb,kO),e(kO,bjo),e(Rb,vjo),e(U,Fjo),e(U,Pb),e(Pb,_ge),e(_ge,Tjo),e(Pb,Mjo),e(Pb,SO),e(SO,Ejo),e(Pb,Cjo),e(U,wjo),e(U,Bb),e(Bb,bge),e(bge,Ajo),e(Bb,yjo),e(Bb,RO),e(RO,Ljo),e(Bb,xjo),e(U,$jo),e(U,Ib),e(Ib,vge),e(vge,kjo),e(Ib,Sjo),e(Ib,PO),e(PO,Rjo),e(Ib,Pjo),e(U,Bjo),e(U,qb),e(qb,Fge),e(Fge,Ijo),e(qb,qjo),e(qb,BO),e(BO,Njo),e(qb,jjo),e(U,Djo),e(U,Nb),e(Nb,Tge),e(Tge,Gjo),e(Nb,Ojo),e(Nb,IO),e(IO,Vjo),e(Nb,Xjo),e(U,zjo),e(U,jb),e(jb,Mge),e(Mge,Wjo),e(jb,Qjo),e(jb,qO),e(qO,Hjo),e(jb,Ujo),e(U,Jjo),e(U,Db),e(Db,Ege),e(Ege,Yjo),e(Db,Kjo),e(Db,NO),e(NO,Zjo),e(Db,eDo),e(U,oDo),e(U,Gb),e(Gb,Cge),e(Cge,rDo),e(Gb,tDo),e(Gb,jO),e(jO,aDo),e(Gb,nDo),e(U,sDo),e(U,Ob),e(Ob,wge),e(wge,lDo),e(Ob,iDo),e(Ob,DO),e(DO,dDo),e(Ob,cDo),e(U,fDo),e(U,Vb),e(Vb,Age),e(Age,mDo),e(Vb,gDo),e(Vb,GO),e(GO,hDo),e(Vb,pDo),e(ao,uDo),e(ao,Xb),e(Xb,_Do),e(Xb,yge),e(yge,bDo),e(Xb,vDo),e(Xb,Lge),e(Lge,FDo),e(ao,TDo),M(zb,ao,null),b(f,hqe,_),b(f,Yi,_),e(Yi,Wb),e(Wb,xge),M(yy,xge,null),e(Yi,MDo),e(Yi,$ge),e($ge,EDo),b(f,pqe,_),b(f,qo,_),M(Ly,qo,null),e(qo,CDo),e(qo,Ki),e(Ki,wDo),e(Ki,OO),e(OO,ADo),e(Ki,yDo),e(Ki,VO),e(VO,LDo),e(Ki,xDo),e(qo,$Do),e(qo,xy),e(xy,kDo),e(xy,kge),e(kge,SDo),e(xy,RDo),e(qo,PDo),e(qo,mt),M($y,mt,null),e(mt,BDo),e(mt,Sge),e(Sge,IDo),e(mt,qDo),e(mt,Zi),e(Zi,NDo),e(Zi,Rge),e(Rge,jDo),e(Zi,DDo),e(Zi,XO),e(XO,GDo),e(Zi,ODo),e(mt,VDo),M(Qb,mt,null),e(qo,XDo),e(qo,no),M(ky,no,null),e(no,zDo),e(no,Pge),e(Pge,WDo),e(no,QDo),e(no,qa),e(qa,HDo),e(qa,Bge),e(Bge,UDo),e(qa,JDo),e(qa,Ige),e(Ige,YDo),e(qa,KDo),e(qa,qge),e(qge,ZDo),e(qa,eGo),e(no,oGo),e(no,V),e(V,Hb),e(Hb,Nge),e(Nge,rGo),e(Hb,tGo),e(Hb,zO),e(zO,aGo),e(Hb,nGo),e(V,sGo),e(V,Ub),e(Ub,jge),e(jge,lGo),e(Ub,iGo),e(Ub,WO),e(WO,dGo),e(Ub,cGo),e(V,fGo),e(V,Jb),e(Jb,Dge),e(Dge,mGo),e(Jb,gGo),e(Jb,QO),e(QO,hGo),e(Jb,pGo),e(V,uGo),e(V,Yb),e(Yb,Gge),e(Gge,_Go),e(Yb,bGo),e(Yb,HO),e(HO,vGo),e(Yb,FGo),e(V,TGo),e(V,Kb),e(Kb,Oge),e(Oge,MGo),e(Kb,EGo),e(Kb,UO),e(UO,CGo),e(Kb,wGo),e(V,AGo),e(V,Zb),e(Zb,Vge),e(Vge,yGo),e(Zb,LGo),e(Zb,JO),e(JO,xGo),e(Zb,$Go),e(V,kGo),e(V,ev),e(ev,Xge),e(Xge,SGo),e(ev,RGo),e(ev,YO),e(YO,PGo),e(ev,BGo),e(V,IGo),e(V,ov),e(ov,zge),e(zge,qGo),e(ov,NGo),e(ov,KO),e(KO,jGo),e(ov,DGo),e(V,GGo),e(V,rv),e(rv,Wge),e(Wge,OGo),e(rv,VGo),e(rv,ZO),e(ZO,XGo),e(rv,zGo),e(V,WGo),e(V,tv),e(tv,Qge),e(Qge,QGo),e(tv,HGo),e(tv,eV),e(eV,UGo),e(tv,JGo),e(V,YGo),e(V,av),e(av,Hge),e(Hge,KGo),e(av,ZGo),e(av,oV),e(oV,eOo),e(av,oOo),e(V,rOo),e(V,nv),e(nv,Uge),e(Uge,tOo),e(nv,aOo),e(nv,rV),e(rV,nOo),e(nv,sOo),e(V,lOo),e(V,sv),e(sv,Jge),e(Jge,iOo),e(sv,dOo),e(sv,tV),e(tV,cOo),e(sv,fOo),e(V,mOo),e(V,lv),e(lv,Yge),e(Yge,gOo),e(lv,hOo),e(lv,aV),e(aV,pOo),e(lv,uOo),e(V,_Oo),e(V,iv),e(iv,Kge),e(Kge,bOo),e(iv,vOo),e(iv,nV),e(nV,FOo),e(iv,TOo),e(V,MOo),e(V,dv),e(dv,Zge),e(Zge,EOo),e(dv,COo),e(dv,sV),e(sV,wOo),e(dv,AOo),e(V,yOo),e(V,cv),e(cv,ehe),e(ehe,LOo),e(cv,xOo),e(cv,lV),e(lV,$Oo),e(cv,kOo),e(V,SOo),e(V,fv),e(fv,ohe),e(ohe,ROo),e(fv,POo),e(fv,iV),e(iV,BOo),e(fv,IOo),e(V,qOo),e(V,mv),e(mv,rhe),e(rhe,NOo),e(mv,jOo),e(mv,dV),e(dV,DOo),e(mv,GOo),e(V,OOo),e(V,gv),e(gv,the),e(the,VOo),e(gv,XOo),e(gv,cV),e(cV,zOo),e(gv,WOo),e(V,QOo),e(V,hv),e(hv,ahe),e(ahe,HOo),e(hv,UOo),e(hv,fV),e(fV,JOo),e(hv,YOo),e(V,KOo),e(V,pv),e(pv,nhe),e(nhe,ZOo),e(pv,eVo),e(pv,mV),e(mV,oVo),e(pv,rVo),e(V,tVo),e(V,uv),e(uv,she),e(she,aVo),e(uv,nVo),e(uv,gV),e(gV,sVo),e(uv,lVo),e(V,iVo),e(V,_v),e(_v,lhe),e(lhe,dVo),e(_v,cVo),e(_v,hV),e(hV,fVo),e(_v,mVo),e(V,gVo),e(V,bv),e(bv,ihe),e(ihe,hVo),e(bv,pVo),e(bv,pV),e(pV,uVo),e(bv,_Vo),e(V,bVo),e(V,vv),e(vv,dhe),e(dhe,vVo),e(vv,FVo),e(vv,uV),e(uV,TVo),e(vv,MVo),e(V,EVo),e(V,Fv),e(Fv,che),e(che,CVo),e(Fv,wVo),e(Fv,_V),e(_V,AVo),e(Fv,yVo),e(V,LVo),e(V,Tv),e(Tv,fhe),e(fhe,xVo),e(Tv,$Vo),e(Tv,bV),e(bV,kVo),e(Tv,SVo),e(V,RVo),e(V,Mv),e(Mv,mhe),e(mhe,PVo),e(Mv,BVo),e(Mv,vV),e(vV,IVo),e(Mv,qVo),e(V,NVo),e(V,Ev),e(Ev,ghe),e(ghe,jVo),e(Ev,DVo),e(Ev,FV),e(FV,GVo),e(Ev,OVo),e(V,VVo),e(V,Cv),e(Cv,hhe),e(hhe,XVo),e(Cv,zVo),e(Cv,TV),e(TV,WVo),e(Cv,QVo),e(V,HVo),e(V,wv),e(wv,phe),e(phe,UVo),e(wv,JVo),e(wv,MV),e(MV,YVo),e(wv,KVo),e(V,ZVo),e(V,Av),e(Av,uhe),e(uhe,eXo),e(Av,oXo),e(Av,EV),e(EV,rXo),e(Av,tXo),e(V,aXo),e(V,yv),e(yv,_he),e(_he,nXo),e(yv,sXo),e(yv,CV),e(CV,lXo),e(yv,iXo),e(V,dXo),e(V,Lv),e(Lv,bhe),e(bhe,cXo),e(Lv,fXo),e(Lv,wV),e(wV,mXo),e(Lv,gXo),e(V,hXo),e(V,xv),e(xv,vhe),e(vhe,pXo),e(xv,uXo),e(xv,AV),e(AV,_Xo),e(xv,bXo),e(V,vXo),e(V,$v),e($v,Fhe),e(Fhe,FXo),e($v,TXo),e($v,yV),e(yV,MXo),e($v,EXo),e(V,CXo),e(V,kv),e(kv,The),e(The,wXo),e(kv,AXo),e(kv,LV),e(LV,yXo),e(kv,LXo),e(V,xXo),e(V,Sv),e(Sv,Mhe),e(Mhe,$Xo),e(Sv,kXo),e(Sv,xV),e(xV,SXo),e(Sv,RXo),e(no,PXo),e(no,Rv),e(Rv,BXo),e(Rv,Ehe),e(Ehe,IXo),e(Rv,qXo),e(Rv,Che),e(Che,NXo),e(no,jXo),M(Pv,no,null),b(f,uqe,_),b(f,ed,_),e(ed,Bv),e(Bv,whe),M(Sy,whe,null),e(ed,DXo),e(ed,Ahe),e(Ahe,GXo),b(f,_qe,_),b(f,No,_),M(Ry,No,null),e(No,OXo),e(No,od),e(od,VXo),e(od,$V),e($V,XXo),e(od,zXo),e(od,kV),e(kV,WXo),e(od,QXo),e(No,HXo),e(No,Py),e(Py,UXo),e(Py,yhe),e(yhe,JXo),e(Py,YXo),e(No,KXo),e(No,gt),M(By,gt,null),e(gt,ZXo),e(gt,Lhe),e(Lhe,ezo),e(gt,ozo),e(gt,rd),e(rd,rzo),e(rd,xhe),e(xhe,tzo),e(rd,azo),e(rd,SV),e(SV,nzo),e(rd,szo),e(gt,lzo),M(Iv,gt,null),e(No,izo),e(No,so),M(Iy,so,null),e(so,dzo),e(so,$he),e($he,czo),e(so,fzo),e(so,Na),e(Na,mzo),e(Na,khe),e(khe,gzo),e(Na,hzo),e(Na,She),e(She,pzo),e(Na,uzo),e(Na,Rhe),e(Rhe,_zo),e(Na,bzo),e(so,vzo),e(so,Phe),e(Phe,qv),e(qv,Bhe),e(Bhe,Fzo),e(qv,Tzo),e(qv,RV),e(RV,Mzo),e(qv,Ezo),e(so,Czo),e(so,Nv),e(Nv,wzo),e(Nv,Ihe),e(Ihe,Azo),e(Nv,yzo),e(Nv,qhe),e(qhe,Lzo),e(so,xzo),M(jv,so,null),b(f,bqe,_),b(f,td,_),e(td,Dv),e(Dv,Nhe),M(qy,Nhe,null),e(td,$zo),e(td,jhe),e(jhe,kzo),b(f,vqe,_),b(f,jo,_),M(Ny,jo,null),e(jo,Szo),e(jo,ad),e(ad,Rzo),e(ad,PV),e(PV,Pzo),e(ad,Bzo),e(ad,BV),e(BV,Izo),e(ad,qzo),e(jo,Nzo),e(jo,jy),e(jy,jzo),e(jy,Dhe),e(Dhe,Dzo),e(jy,Gzo),e(jo,Ozo),e(jo,ht),M(Dy,ht,null),e(ht,Vzo),e(ht,Ghe),e(Ghe,Xzo),e(ht,zzo),e(ht,nd),e(nd,Wzo),e(nd,Ohe),e(Ohe,Qzo),e(nd,Hzo),e(nd,IV),e(IV,Uzo),e(nd,Jzo),e(ht,Yzo),M(Gv,ht,null),e(jo,Kzo),e(jo,lo),M(Gy,lo,null),e(lo,Zzo),e(lo,Vhe),e(Vhe,eWo),e(lo,oWo),e(lo,ja),e(ja,rWo),e(ja,Xhe),e(Xhe,tWo),e(ja,aWo),e(ja,zhe),e(zhe,nWo),e(ja,sWo),e(ja,Whe),e(Whe,lWo),e(ja,iWo),e(lo,dWo),e(lo,Fe),e(Fe,Ov),e(Ov,Qhe),e(Qhe,cWo),e(Ov,fWo),e(Ov,qV),e(qV,mWo),e(Ov,gWo),e(Fe,hWo),e(Fe,Vv),e(Vv,Hhe),e(Hhe,pWo),e(Vv,uWo),e(Vv,NV),e(NV,_Wo),e(Vv,bWo),e(Fe,vWo),e(Fe,Xv),e(Xv,Uhe),e(Uhe,FWo),e(Xv,TWo),e(Xv,jV),e(jV,MWo),e(Xv,EWo),e(Fe,CWo),e(Fe,Ps),e(Ps,Jhe),e(Jhe,wWo),e(Ps,AWo),e(Ps,DV),e(DV,yWo),e(Ps,LWo),e(Ps,GV),e(GV,xWo),e(Ps,$Wo),e(Fe,kWo),e(Fe,zv),e(zv,Yhe),e(Yhe,SWo),e(zv,RWo),e(zv,OV),e(OV,PWo),e(zv,BWo),e(Fe,IWo),e(Fe,pt),e(pt,Khe),e(Khe,qWo),e(pt,NWo),e(pt,VV),e(VV,jWo),e(pt,DWo),e(pt,XV),e(XV,GWo),e(pt,OWo),e(pt,zV),e(zV,VWo),e(pt,XWo),e(Fe,zWo),e(Fe,Wv),e(Wv,Zhe),e(Zhe,WWo),e(Wv,QWo),e(Wv,WV),e(WV,HWo),e(Wv,UWo),e(Fe,JWo),e(Fe,Qv),e(Qv,epe),e(epe,YWo),e(Qv,KWo),e(Qv,QV),e(QV,ZWo),e(Qv,eQo),e(Fe,oQo),e(Fe,Hv),e(Hv,ope),e(ope,rQo),e(Hv,tQo),e(Hv,HV),e(HV,aQo),e(Hv,nQo),e(Fe,sQo),e(Fe,Uv),e(Uv,rpe),e(rpe,lQo),e(Uv,iQo),e(Uv,UV),e(UV,dQo),e(Uv,cQo),e(Fe,fQo),e(Fe,Jv),e(Jv,tpe),e(tpe,mQo),e(Jv,gQo),e(Jv,JV),e(JV,hQo),e(Jv,pQo),e(Fe,uQo),e(Fe,Yv),e(Yv,ape),e(ape,_Qo),e(Yv,bQo),e(Yv,YV),e(YV,vQo),e(Yv,FQo),e(Fe,TQo),e(Fe,Kv),e(Kv,npe),e(npe,MQo),e(Kv,EQo),e(Kv,KV),e(KV,CQo),e(Kv,wQo),e(lo,AQo),e(lo,Zv),e(Zv,yQo),e(Zv,spe),e(spe,LQo),e(Zv,xQo),e(Zv,lpe),e(lpe,$Qo),e(lo,kQo),M(eF,lo,null),b(f,Fqe,_),b(f,sd,_),e(sd,oF),e(oF,ipe),M(Oy,ipe,null),e(sd,SQo),e(sd,dpe),e(dpe,RQo),b(f,Tqe,_),b(f,Do,_),M(Vy,Do,null),e(Do,PQo),e(Do,ld),e(ld,BQo),e(ld,ZV),e(ZV,IQo),e(ld,qQo),e(ld,eX),e(eX,NQo),e(ld,jQo),e(Do,DQo),e(Do,Xy),e(Xy,GQo),e(Xy,cpe),e(cpe,OQo),e(Xy,VQo),e(Do,XQo),e(Do,ut),M(zy,ut,null),e(ut,zQo),e(ut,fpe),e(fpe,WQo),e(ut,QQo),e(ut,id),e(id,HQo),e(id,mpe),e(mpe,UQo),e(id,JQo),e(id,oX),e(oX,YQo),e(id,KQo),e(ut,ZQo),M(rF,ut,null),e(Do,eHo),e(Do,io),M(Wy,io,null),e(io,oHo),e(io,gpe),e(gpe,rHo),e(io,tHo),e(io,Da),e(Da,aHo),e(Da,hpe),e(hpe,nHo),e(Da,sHo),e(Da,ppe),e(ppe,lHo),e(Da,iHo),e(Da,upe),e(upe,dHo),e(Da,cHo),e(io,fHo),e(io,_pe),e(_pe,tF),e(tF,bpe),e(bpe,mHo),e(tF,gHo),e(tF,rX),e(rX,hHo),e(tF,pHo),e(io,uHo),e(io,aF),e(aF,_Ho),e(aF,vpe),e(vpe,bHo),e(aF,vHo),e(aF,Fpe),e(Fpe,FHo),e(io,THo),M(nF,io,null),b(f,Mqe,_),b(f,dd,_),e(dd,sF),e(sF,Tpe),M(Qy,Tpe,null),e(dd,MHo),e(dd,Mpe),e(Mpe,EHo),b(f,Eqe,_),b(f,Go,_),M(Hy,Go,null),e(Go,CHo),e(Go,cd),e(cd,wHo),e(cd,tX),e(tX,AHo),e(cd,yHo),e(cd,aX),e(aX,LHo),e(cd,xHo),e(Go,$Ho),e(Go,Uy),e(Uy,kHo),e(Uy,Epe),e(Epe,SHo),e(Uy,RHo),e(Go,PHo),e(Go,_t),M(Jy,_t,null),e(_t,BHo),e(_t,Cpe),e(Cpe,IHo),e(_t,qHo),e(_t,fd),e(fd,NHo),e(fd,wpe),e(wpe,jHo),e(fd,DHo),e(fd,nX),e(nX,GHo),e(fd,OHo),e(_t,VHo),M(lF,_t,null),e(Go,XHo),e(Go,co),M(Yy,co,null),e(co,zHo),e(co,Ape),e(Ape,WHo),e(co,QHo),e(co,Ga),e(Ga,HHo),e(Ga,ype),e(ype,UHo),e(Ga,JHo),e(Ga,Lpe),e(Lpe,YHo),e(Ga,KHo),e(Ga,xpe),e(xpe,ZHo),e(Ga,eUo),e(co,oUo),e(co,Se),e(Se,iF),e(iF,$pe),e($pe,rUo),e(iF,tUo),e(iF,sX),e(sX,aUo),e(iF,nUo),e(Se,sUo),e(Se,dF),e(dF,kpe),e(kpe,lUo),e(dF,iUo),e(dF,lX),e(lX,dUo),e(dF,cUo),e(Se,fUo),e(Se,cF),e(cF,Spe),e(Spe,mUo),e(cF,gUo),e(cF,iX),e(iX,hUo),e(cF,pUo),e(Se,uUo),e(Se,fF),e(fF,Rpe),e(Rpe,_Uo),e(fF,bUo),e(fF,dX),e(dX,vUo),e(fF,FUo),e(Se,TUo),e(Se,mF),e(mF,Ppe),e(Ppe,MUo),e(mF,EUo),e(mF,cX),e(cX,CUo),e(mF,wUo),e(Se,AUo),e(Se,gF),e(gF,Bpe),e(Bpe,yUo),e(gF,LUo),e(gF,fX),e(fX,xUo),e(gF,$Uo),e(Se,kUo),e(Se,hF),e(hF,Ipe),e(Ipe,SUo),e(hF,RUo),e(hF,mX),e(mX,PUo),e(hF,BUo),e(Se,IUo),e(Se,pF),e(pF,qpe),e(qpe,qUo),e(pF,NUo),e(pF,gX),e(gX,jUo),e(pF,DUo),e(Se,GUo),e(Se,uF),e(uF,Npe),e(Npe,OUo),e(uF,VUo),e(uF,hX),e(hX,XUo),e(uF,zUo),e(co,WUo),e(co,_F),e(_F,QUo),e(_F,jpe),e(jpe,HUo),e(_F,UUo),e(_F,Dpe),e(Dpe,JUo),e(co,YUo),M(bF,co,null),b(f,Cqe,_),b(f,md,_),e(md,vF),e(vF,Gpe),M(Ky,Gpe,null),e(md,KUo),e(md,Ope),e(Ope,ZUo),b(f,wqe,_),b(f,Oo,_),M(Zy,Oo,null),e(Oo,eJo),e(Oo,gd),e(gd,oJo),e(gd,pX),e(pX,rJo),e(gd,tJo),e(gd,uX),e(uX,aJo),e(gd,nJo),e(Oo,sJo),e(Oo,eL),e(eL,lJo),e(eL,Vpe),e(Vpe,iJo),e(eL,dJo),e(Oo,cJo),e(Oo,bt),M(oL,bt,null),e(bt,fJo),e(bt,Xpe),e(Xpe,mJo),e(bt,gJo),e(bt,hd),e(hd,hJo),e(hd,zpe),e(zpe,pJo),e(hd,uJo),e(hd,_X),e(_X,_Jo),e(hd,bJo),e(bt,vJo),M(FF,bt,null),e(Oo,FJo),e(Oo,fo),M(rL,fo,null),e(fo,TJo),e(fo,Wpe),e(Wpe,MJo),e(fo,EJo),e(fo,Oa),e(Oa,CJo),e(Oa,Qpe),e(Qpe,wJo),e(Oa,AJo),e(Oa,Hpe),e(Hpe,yJo),e(Oa,LJo),e(Oa,Upe),e(Upe,xJo),e(Oa,$Jo),e(fo,kJo),e(fo,Kr),e(Kr,TF),e(TF,Jpe),e(Jpe,SJo),e(TF,RJo),e(TF,bX),e(bX,PJo),e(TF,BJo),e(Kr,IJo),e(Kr,MF),e(MF,Ype),e(Ype,qJo),e(MF,NJo),e(MF,vX),e(vX,jJo),e(MF,DJo),e(Kr,GJo),e(Kr,EF),e(EF,Kpe),e(Kpe,OJo),e(EF,VJo),e(EF,FX),e(FX,XJo),e(EF,zJo),e(Kr,WJo),e(Kr,CF),e(CF,Zpe),e(Zpe,QJo),e(CF,HJo),e(CF,TX),e(TX,UJo),e(CF,JJo),e(Kr,YJo),e(Kr,wF),e(wF,eue),e(eue,KJo),e(wF,ZJo),e(wF,MX),e(MX,eYo),e(wF,oYo),e(fo,rYo),e(fo,AF),e(AF,tYo),e(AF,oue),e(oue,aYo),e(AF,nYo),e(AF,rue),e(rue,sYo),e(fo,lYo),M(yF,fo,null),b(f,Aqe,_),b(f,pd,_),e(pd,LF),e(LF,tue),M(tL,tue,null),e(pd,iYo),e(pd,aue),e(aue,dYo),b(f,yqe,_),b(f,Vo,_),M(aL,Vo,null),e(Vo,cYo),e(Vo,ud),e(ud,fYo),e(ud,EX),e(EX,mYo),e(ud,gYo),e(ud,CX),e(CX,hYo),e(ud,pYo),e(Vo,uYo),e(Vo,nL),e(nL,_Yo),e(nL,nue),e(nue,bYo),e(nL,vYo),e(Vo,FYo),e(Vo,vt),M(sL,vt,null),e(vt,TYo),e(vt,sue),e(sue,MYo),e(vt,EYo),e(vt,_d),e(_d,CYo),e(_d,lue),e(lue,wYo),e(_d,AYo),e(_d,wX),e(wX,yYo),e(_d,LYo),e(vt,xYo),M(xF,vt,null),e(Vo,$Yo),e(Vo,mo),M(lL,mo,null),e(mo,kYo),e(mo,iue),e(iue,SYo),e(mo,RYo),e(mo,Va),e(Va,PYo),e(Va,due),e(due,BYo),e(Va,IYo),e(Va,cue),e(cue,qYo),e(Va,NYo),e(Va,fue),e(fue,jYo),e(Va,DYo),e(mo,GYo),e(mo,Re),e(Re,$F),e($F,mue),e(mue,OYo),e($F,VYo),e($F,AX),e(AX,XYo),e($F,zYo),e(Re,WYo),e(Re,kF),e(kF,gue),e(gue,QYo),e(kF,HYo),e(kF,yX),e(yX,UYo),e(kF,JYo),e(Re,YYo),e(Re,SF),e(SF,hue),e(hue,KYo),e(SF,ZYo),e(SF,LX),e(LX,eKo),e(SF,oKo),e(Re,rKo),e(Re,RF),e(RF,pue),e(pue,tKo),e(RF,aKo),e(RF,xX),e(xX,nKo),e(RF,sKo),e(Re,lKo),e(Re,PF),e(PF,uue),e(uue,iKo),e(PF,dKo),e(PF,$X),e($X,cKo),e(PF,fKo),e(Re,mKo),e(Re,BF),e(BF,_ue),e(_ue,gKo),e(BF,hKo),e(BF,kX),e(kX,pKo),e(BF,uKo),e(Re,_Ko),e(Re,IF),e(IF,bue),e(bue,bKo),e(IF,vKo),e(IF,SX),e(SX,FKo),e(IF,TKo),e(Re,MKo),e(Re,qF),e(qF,vue),e(vue,EKo),e(qF,CKo),e(qF,RX),e(RX,wKo),e(qF,AKo),e(Re,yKo),e(Re,NF),e(NF,Fue),e(Fue,LKo),e(NF,xKo),e(NF,PX),e(PX,$Ko),e(NF,kKo),e(mo,SKo),e(mo,jF),e(jF,RKo),e(jF,Tue),e(Tue,PKo),e(jF,BKo),e(jF,Mue),e(Mue,IKo),e(mo,qKo),M(DF,mo,null),b(f,Lqe,_),b(f,bd,_),e(bd,GF),e(GF,Eue),M(iL,Eue,null),e(bd,NKo),e(bd,Cue),e(Cue,jKo),b(f,xqe,_),b(f,Xo,_),M(dL,Xo,null),e(Xo,DKo),e(Xo,vd),e(vd,GKo),e(vd,BX),e(BX,OKo),e(vd,VKo),e(vd,IX),e(IX,XKo),e(vd,zKo),e(Xo,WKo),e(Xo,cL),e(cL,QKo),e(cL,wue),e(wue,HKo),e(cL,UKo),e(Xo,JKo),e(Xo,Ft),M(fL,Ft,null),e(Ft,YKo),e(Ft,Aue),e(Aue,KKo),e(Ft,ZKo),e(Ft,Fd),e(Fd,eZo),e(Fd,yue),e(yue,oZo),e(Fd,rZo),e(Fd,qX),e(qX,tZo),e(Fd,aZo),e(Ft,nZo),M(OF,Ft,null),e(Xo,sZo),e(Xo,go),M(mL,go,null),e(go,lZo),e(go,Lue),e(Lue,iZo),e(go,dZo),e(go,Xa),e(Xa,cZo),e(Xa,xue),e(xue,fZo),e(Xa,mZo),e(Xa,$ue),e($ue,gZo),e(Xa,hZo),e(Xa,kue),e(kue,pZo),e(Xa,uZo),e(go,_Zo),e(go,gL),e(gL,VF),e(VF,Sue),e(Sue,bZo),e(VF,vZo),e(VF,NX),e(NX,FZo),e(VF,TZo),e(gL,MZo),e(gL,XF),e(XF,Rue),e(Rue,EZo),e(XF,CZo),e(XF,jX),e(jX,wZo),e(XF,AZo),e(go,yZo),e(go,zF),e(zF,LZo),e(zF,Pue),e(Pue,xZo),e(zF,$Zo),e(zF,Bue),e(Bue,kZo),e(go,SZo),M(WF,go,null),b(f,$qe,_),b(f,Td,_),e(Td,QF),e(QF,Iue),M(hL,Iue,null),e(Td,RZo),e(Td,que),e(que,PZo),b(f,kqe,_),b(f,zo,_),M(pL,zo,null),e(zo,BZo),e(zo,Md),e(Md,IZo),e(Md,DX),e(DX,qZo),e(Md,NZo),e(Md,GX),e(GX,jZo),e(Md,DZo),e(zo,GZo),e(zo,uL),e(uL,OZo),e(uL,Nue),e(Nue,VZo),e(uL,XZo),e(zo,zZo),e(zo,Tt),M(_L,Tt,null),e(Tt,WZo),e(Tt,jue),e(jue,QZo),e(Tt,HZo),e(Tt,Ed),e(Ed,UZo),e(Ed,Due),e(Due,JZo),e(Ed,YZo),e(Ed,OX),e(OX,KZo),e(Ed,ZZo),e(Tt,eer),M(HF,Tt,null),e(zo,oer),e(zo,ho),M(bL,ho,null),e(ho,rer),e(ho,Gue),e(Gue,ter),e(ho,aer),e(ho,za),e(za,ner),e(za,Oue),e(Oue,ser),e(za,ler),e(za,Vue),e(Vue,ier),e(za,der),e(za,Xue),e(Xue,cer),e(za,fer),e(ho,mer),e(ho,Zr),e(Zr,UF),e(UF,zue),e(zue,ger),e(UF,her),e(UF,VX),e(VX,per),e(UF,uer),e(Zr,_er),e(Zr,JF),e(JF,Wue),e(Wue,ber),e(JF,ver),e(JF,XX),e(XX,Fer),e(JF,Ter),e(Zr,Mer),e(Zr,YF),e(YF,Que),e(Que,Eer),e(YF,Cer),e(YF,zX),e(zX,wer),e(YF,Aer),e(Zr,yer),e(Zr,KF),e(KF,Hue),e(Hue,Ler),e(KF,xer),e(KF,WX),e(WX,$er),e(KF,ker),e(Zr,Ser),e(Zr,ZF),e(ZF,Uue),e(Uue,Rer),e(ZF,Per),e(ZF,QX),e(QX,Ber),e(ZF,Ier),e(ho,qer),e(ho,eT),e(eT,Ner),e(eT,Jue),e(Jue,jer),e(eT,Der),e(eT,Yue),e(Yue,Ger),e(ho,Oer),M(oT,ho,null),b(f,Sqe,_),b(f,Cd,_),e(Cd,rT),e(rT,Kue),M(vL,Kue,null),e(Cd,Ver),e(Cd,Zue),e(Zue,Xer),b(f,Rqe,_),b(f,Wo,_),M(FL,Wo,null),e(Wo,zer),e(Wo,wd),e(wd,Wer),e(wd,HX),e(HX,Qer),e(wd,Her),e(wd,UX),e(UX,Uer),e(wd,Jer),e(Wo,Yer),e(Wo,TL),e(TL,Ker),e(TL,e_e),e(e_e,Zer),e(TL,eor),e(Wo,oor),e(Wo,Mt),M(ML,Mt,null),e(Mt,ror),e(Mt,o_e),e(o_e,tor),e(Mt,aor),e(Mt,Ad),e(Ad,nor),e(Ad,r_e),e(r_e,sor),e(Ad,lor),e(Ad,JX),e(JX,ior),e(Ad,dor),e(Mt,cor),M(tT,Mt,null),e(Wo,mor),e(Wo,po),M(EL,po,null),e(po,gor),e(po,t_e),e(t_e,hor),e(po,por),e(po,Wa),e(Wa,uor),e(Wa,a_e),e(a_e,_or),e(Wa,bor),e(Wa,n_e),e(n_e,vor),e(Wa,For),e(Wa,s_e),e(s_e,Tor),e(Wa,Mor),e(po,Eor),e(po,yd),e(yd,aT),e(aT,l_e),e(l_e,Cor),e(aT,wor),e(aT,YX),e(YX,Aor),e(aT,yor),e(yd,Lor),e(yd,nT),e(nT,i_e),e(i_e,xor),e(nT,$or),e(nT,KX),e(KX,kor),e(nT,Sor),e(yd,Ror),e(yd,sT),e(sT,d_e),e(d_e,Por),e(sT,Bor),e(sT,ZX),e(ZX,Ior),e(sT,qor),e(po,Nor),e(po,lT),e(lT,jor),e(lT,c_e),e(c_e,Dor),e(lT,Gor),e(lT,f_e),e(f_e,Oor),e(po,Vor),M(iT,po,null),b(f,Pqe,_),b(f,Ld,_),e(Ld,dT),e(dT,m_e),M(CL,m_e,null),e(Ld,Xor),e(Ld,g_e),e(g_e,zor),b(f,Bqe,_),b(f,Qo,_),M(wL,Qo,null),e(Qo,Wor),e(Qo,xd),e(xd,Qor),e(xd,ez),e(ez,Hor),e(xd,Uor),e(xd,oz),e(oz,Jor),e(xd,Yor),e(Qo,Kor),e(Qo,AL),e(AL,Zor),e(AL,h_e),e(h_e,err),e(AL,orr),e(Qo,rrr),e(Qo,Et),M(yL,Et,null),e(Et,trr),e(Et,p_e),e(p_e,arr),e(Et,nrr),e(Et,$d),e($d,srr),e($d,u_e),e(u_e,lrr),e($d,irr),e($d,rz),e(rz,drr),e($d,crr),e(Et,frr),M(cT,Et,null),e(Qo,mrr),e(Qo,uo),M(LL,uo,null),e(uo,grr),e(uo,__e),e(__e,hrr),e(uo,prr),e(uo,Qa),e(Qa,urr),e(Qa,b_e),e(b_e,_rr),e(Qa,brr),e(Qa,v_e),e(v_e,vrr),e(Qa,Frr),e(Qa,F_e),e(F_e,Trr),e(Qa,Mrr),e(uo,Err),e(uo,xL),e(xL,fT),e(fT,T_e),e(T_e,Crr),e(fT,wrr),e(fT,tz),e(tz,Arr),e(fT,yrr),e(xL,Lrr),e(xL,mT),e(mT,M_e),e(M_e,xrr),e(mT,$rr),e(mT,az),e(az,krr),e(mT,Srr),e(uo,Rrr),e(uo,gT),e(gT,Prr),e(gT,E_e),e(E_e,Brr),e(gT,Irr),e(gT,C_e),e(C_e,qrr),e(uo,Nrr),M(hT,uo,null),b(f,Iqe,_),b(f,kd,_),e(kd,pT),e(pT,w_e),M($L,w_e,null),e(kd,jrr),e(kd,A_e),e(A_e,Drr),b(f,qqe,_),b(f,Ho,_),M(kL,Ho,null),e(Ho,Grr),e(Ho,Sd),e(Sd,Orr),e(Sd,nz),e(nz,Vrr),e(Sd,Xrr),e(Sd,sz),e(sz,zrr),e(Sd,Wrr),e(Ho,Qrr),e(Ho,SL),e(SL,Hrr),e(SL,y_e),e(y_e,Urr),e(SL,Jrr),e(Ho,Yrr),e(Ho,Ct),M(RL,Ct,null),e(Ct,Krr),e(Ct,L_e),e(L_e,Zrr),e(Ct,etr),e(Ct,Rd),e(Rd,otr),e(Rd,x_e),e(x_e,rtr),e(Rd,ttr),e(Rd,lz),e(lz,atr),e(Rd,ntr),e(Ct,str),M(uT,Ct,null),e(Ho,ltr),e(Ho,_o),M(PL,_o,null),e(_o,itr),e(_o,$_e),e($_e,dtr),e(_o,ctr),e(_o,Ha),e(Ha,ftr),e(Ha,k_e),e(k_e,mtr),e(Ha,gtr),e(Ha,S_e),e(S_e,htr),e(Ha,ptr),e(Ha,R_e),e(R_e,utr),e(Ha,_tr),e(_o,btr),e(_o,P_e),e(P_e,_T),e(_T,B_e),e(B_e,vtr),e(_T,Ftr),e(_T,iz),e(iz,Ttr),e(_T,Mtr),e(_o,Etr),e(_o,bT),e(bT,Ctr),e(bT,I_e),e(I_e,wtr),e(bT,Atr),e(bT,q_e),e(q_e,ytr),e(_o,Ltr),M(vT,_o,null),b(f,Nqe,_),b(f,Pd,_),e(Pd,FT),e(FT,N_e),M(BL,N_e,null),e(Pd,xtr),e(Pd,j_e),e(j_e,$tr),b(f,jqe,_),b(f,Uo,_),M(IL,Uo,null),e(Uo,ktr),e(Uo,Bd),e(Bd,Str),e(Bd,dz),e(dz,Rtr),e(Bd,Ptr),e(Bd,cz),e(cz,Btr),e(Bd,Itr),e(Uo,qtr),e(Uo,qL),e(qL,Ntr),e(qL,D_e),e(D_e,jtr),e(qL,Dtr),e(Uo,Gtr),e(Uo,wt),M(NL,wt,null),e(wt,Otr),e(wt,G_e),e(G_e,Vtr),e(wt,Xtr),e(wt,Id),e(Id,ztr),e(Id,O_e),e(O_e,Wtr),e(Id,Qtr),e(Id,fz),e(fz,Htr),e(Id,Utr),e(wt,Jtr),M(TT,wt,null),e(Uo,Ytr),e(Uo,bo),M(jL,bo,null),e(bo,Ktr),e(bo,V_e),e(V_e,Ztr),e(bo,ear),e(bo,Ua),e(Ua,oar),e(Ua,X_e),e(X_e,rar),e(Ua,tar),e(Ua,z_e),e(z_e,aar),e(Ua,nar),e(Ua,W_e),e(W_e,sar),e(Ua,lar),e(bo,iar),e(bo,Ja),e(Ja,MT),e(MT,Q_e),e(Q_e,dar),e(MT,car),e(MT,mz),e(mz,far),e(MT,mar),e(Ja,gar),e(Ja,ET),e(ET,H_e),e(H_e,har),e(ET,par),e(ET,gz),e(gz,uar),e(ET,_ar),e(Ja,bar),e(Ja,CT),e(CT,U_e),e(U_e,Far),e(CT,Tar),e(CT,hz),e(hz,Mar),e(CT,Ear),e(Ja,Car),e(Ja,wT),e(wT,J_e),e(J_e,war),e(wT,Aar),e(wT,pz),e(pz,yar),e(wT,Lar),e(bo,xar),e(bo,AT),e(AT,$ar),e(AT,Y_e),e(Y_e,kar),e(AT,Sar),e(AT,K_e),e(K_e,Rar),e(bo,Par),M(yT,bo,null),b(f,Dqe,_),b(f,qd,_),e(qd,LT),e(LT,Z_e),M(DL,Z_e,null),e(qd,Bar),e(qd,e2e),e(e2e,Iar),b(f,Gqe,_),b(f,Jo,_),M(GL,Jo,null),e(Jo,qar),e(Jo,Nd),e(Nd,Nar),e(Nd,uz),e(uz,jar),e(Nd,Dar),e(Nd,_z),e(_z,Gar),e(Nd,Oar),e(Jo,Var),e(Jo,OL),e(OL,Xar),e(OL,o2e),e(o2e,zar),e(OL,War),e(Jo,Qar),e(Jo,At),M(VL,At,null),e(At,Har),e(At,r2e),e(r2e,Uar),e(At,Jar),e(At,jd),e(jd,Yar),e(jd,t2e),e(t2e,Kar),e(jd,Zar),e(jd,bz),e(bz,enr),e(jd,onr),e(At,rnr),M(xT,At,null),e(Jo,tnr),e(Jo,vo),M(XL,vo,null),e(vo,anr),e(vo,a2e),e(a2e,nnr),e(vo,snr),e(vo,Ya),e(Ya,lnr),e(Ya,n2e),e(n2e,inr),e(Ya,dnr),e(Ya,s2e),e(s2e,cnr),e(Ya,fnr),e(Ya,l2e),e(l2e,mnr),e(Ya,gnr),e(vo,hnr),e(vo,i2e),e(i2e,$T),e($T,d2e),e(d2e,pnr),e($T,unr),e($T,vz),e(vz,_nr),e($T,bnr),e(vo,vnr),e(vo,kT),e(kT,Fnr),e(kT,c2e),e(c2e,Tnr),e(kT,Mnr),e(kT,f2e),e(f2e,Enr),e(vo,Cnr),M(ST,vo,null),b(f,Oqe,_),b(f,Dd,_),e(Dd,RT),e(RT,m2e),M(zL,m2e,null),e(Dd,wnr),e(Dd,g2e),e(g2e,Anr),b(f,Vqe,_),b(f,Yo,_),M(WL,Yo,null),e(Yo,ynr),e(Yo,Gd),e(Gd,Lnr),e(Gd,Fz),e(Fz,xnr),e(Gd,$nr),e(Gd,Tz),e(Tz,knr),e(Gd,Snr),e(Yo,Rnr),e(Yo,QL),e(QL,Pnr),e(QL,h2e),e(h2e,Bnr),e(QL,Inr),e(Yo,qnr),e(Yo,yt),M(HL,yt,null),e(yt,Nnr),e(yt,p2e),e(p2e,jnr),e(yt,Dnr),e(yt,Od),e(Od,Gnr),e(Od,u2e),e(u2e,Onr),e(Od,Vnr),e(Od,Mz),e(Mz,Xnr),e(Od,znr),e(yt,Wnr),M(PT,yt,null),e(Yo,Qnr),e(Yo,wr),M(UL,wr,null),e(wr,Hnr),e(wr,_2e),e(_2e,Unr),e(wr,Jnr),e(wr,Ka),e(Ka,Ynr),e(Ka,b2e),e(b2e,Knr),e(Ka,Znr),e(Ka,v2e),e(v2e,esr),e(Ka,osr),e(Ka,F2e),e(F2e,rsr),e(Ka,tsr),e(wr,asr),e(wr,q),e(q,BT),e(BT,T2e),e(T2e,nsr),e(BT,ssr),e(BT,Ez),e(Ez,lsr),e(BT,isr),e(q,dsr),e(q,IT),e(IT,M2e),e(M2e,csr),e(IT,fsr),e(IT,Cz),e(Cz,msr),e(IT,gsr),e(q,hsr),e(q,qT),e(qT,E2e),e(E2e,psr),e(qT,usr),e(qT,wz),e(wz,_sr),e(qT,bsr),e(q,vsr),e(q,NT),e(NT,C2e),e(C2e,Fsr),e(NT,Tsr),e(NT,Az),e(Az,Msr),e(NT,Esr),e(q,Csr),e(q,jT),e(jT,w2e),e(w2e,wsr),e(jT,Asr),e(jT,yz),e(yz,ysr),e(jT,Lsr),e(q,xsr),e(q,DT),e(DT,A2e),e(A2e,$sr),e(DT,ksr),e(DT,Lz),e(Lz,Ssr),e(DT,Rsr),e(q,Psr),e(q,GT),e(GT,y2e),e(y2e,Bsr),e(GT,Isr),e(GT,xz),e(xz,qsr),e(GT,Nsr),e(q,jsr),e(q,OT),e(OT,L2e),e(L2e,Dsr),e(OT,Gsr),e(OT,$z),e($z,Osr),e(OT,Vsr),e(q,Xsr),e(q,VT),e(VT,x2e),e(x2e,zsr),e(VT,Wsr),e(VT,kz),e(kz,Qsr),e(VT,Hsr),e(q,Usr),e(q,XT),e(XT,$2e),e($2e,Jsr),e(XT,Ysr),e(XT,Sz),e(Sz,Ksr),e(XT,Zsr),e(q,elr),e(q,zT),e(zT,k2e),e(k2e,olr),e(zT,rlr),e(zT,Rz),e(Rz,tlr),e(zT,alr),e(q,nlr),e(q,WT),e(WT,S2e),e(S2e,slr),e(WT,llr),e(WT,Pz),e(Pz,ilr),e(WT,dlr),e(q,clr),e(q,QT),e(QT,R2e),e(R2e,flr),e(QT,mlr),e(QT,Bz),e(Bz,glr),e(QT,hlr),e(q,plr),e(q,HT),e(HT,P2e),e(P2e,ulr),e(HT,_lr),e(HT,Iz),e(Iz,blr),e(HT,vlr),e(q,Flr),e(q,UT),e(UT,B2e),e(B2e,Tlr),e(UT,Mlr),e(UT,qz),e(qz,Elr),e(UT,Clr),e(q,wlr),e(q,JT),e(JT,I2e),e(I2e,Alr),e(JT,ylr),e(JT,Nz),e(Nz,Llr),e(JT,xlr),e(q,$lr),e(q,YT),e(YT,q2e),e(q2e,klr),e(YT,Slr),e(YT,jz),e(jz,Rlr),e(YT,Plr),e(q,Blr),e(q,Bs),e(Bs,N2e),e(N2e,Ilr),e(Bs,qlr),e(Bs,Dz),e(Dz,Nlr),e(Bs,jlr),e(Bs,Gz),e(Gz,Dlr),e(Bs,Glr),e(q,Olr),e(q,KT),e(KT,j2e),e(j2e,Vlr),e(KT,Xlr),e(KT,Oz),e(Oz,zlr),e(KT,Wlr),e(q,Qlr),e(q,ZT),e(ZT,D2e),e(D2e,Hlr),e(ZT,Ulr),e(ZT,Vz),e(Vz,Jlr),e(ZT,Ylr),e(q,Klr),e(q,eM),e(eM,G2e),e(G2e,Zlr),e(eM,eir),e(eM,Xz),e(Xz,oir),e(eM,rir),e(q,tir),e(q,oM),e(oM,O2e),e(O2e,air),e(oM,nir),e(oM,zz),e(zz,sir),e(oM,lir),e(q,iir),e(q,rM),e(rM,V2e),e(V2e,dir),e(rM,cir),e(rM,Wz),e(Wz,fir),e(rM,mir),e(q,gir),e(q,tM),e(tM,X2e),e(X2e,hir),e(tM,pir),e(tM,Qz),e(Qz,uir),e(tM,_ir),e(q,bir),e(q,aM),e(aM,z2e),e(z2e,vir),e(aM,Fir),e(aM,Hz),e(Hz,Tir),e(aM,Mir),e(q,Eir),e(q,nM),e(nM,W2e),e(W2e,Cir),e(nM,wir),e(nM,Uz),e(Uz,Air),e(nM,yir),e(q,Lir),e(q,sM),e(sM,Q2e),e(Q2e,xir),e(sM,$ir),e(sM,Jz),e(Jz,kir),e(sM,Sir),e(q,Rir),e(q,lM),e(lM,H2e),e(H2e,Pir),e(lM,Bir),e(lM,Yz),e(Yz,Iir),e(lM,qir),e(q,Nir),e(q,iM),e(iM,U2e),e(U2e,jir),e(iM,Dir),e(iM,Kz),e(Kz,Gir),e(iM,Oir),e(q,Vir),e(q,dM),e(dM,J2e),e(J2e,Xir),e(dM,zir),e(dM,Zz),e(Zz,Wir),e(dM,Qir),e(q,Hir),e(q,cM),e(cM,Y2e),e(Y2e,Uir),e(cM,Jir),e(cM,eW),e(eW,Yir),e(cM,Kir),e(q,Zir),e(q,fM),e(fM,K2e),e(K2e,edr),e(fM,odr),e(fM,oW),e(oW,rdr),e(fM,tdr),e(q,adr),e(q,mM),e(mM,Z2e),e(Z2e,ndr),e(mM,sdr),e(mM,rW),e(rW,ldr),e(mM,idr),e(q,ddr),e(q,gM),e(gM,e1e),e(e1e,cdr),e(gM,fdr),e(gM,tW),e(tW,mdr),e(gM,gdr),e(q,hdr),e(q,hM),e(hM,o1e),e(o1e,pdr),e(hM,udr),e(hM,aW),e(aW,_dr),e(hM,bdr),e(q,vdr),e(q,pM),e(pM,r1e),e(r1e,Fdr),e(pM,Tdr),e(pM,nW),e(nW,Mdr),e(pM,Edr),e(q,Cdr),e(q,uM),e(uM,t1e),e(t1e,wdr),e(uM,Adr),e(uM,sW),e(sW,ydr),e(uM,Ldr),e(q,xdr),e(q,_M),e(_M,a1e),e(a1e,$dr),e(_M,kdr),e(_M,lW),e(lW,Sdr),e(_M,Rdr),e(q,Pdr),e(q,bM),e(bM,n1e),e(n1e,Bdr),e(bM,Idr),e(bM,iW),e(iW,qdr),e(bM,Ndr),e(q,jdr),e(q,vM),e(vM,s1e),e(s1e,Ddr),e(vM,Gdr),e(vM,dW),e(dW,Odr),e(vM,Vdr),e(q,Xdr),e(q,FM),e(FM,l1e),e(l1e,zdr),e(FM,Wdr),e(FM,cW),e(cW,Qdr),e(FM,Hdr),e(q,Udr),e(q,TM),e(TM,i1e),e(i1e,Jdr),e(TM,Ydr),e(TM,fW),e(fW,Kdr),e(TM,Zdr),e(q,ecr),e(q,MM),e(MM,d1e),e(d1e,ocr),e(MM,rcr),e(MM,mW),e(mW,tcr),e(MM,acr),e(q,ncr),e(q,EM),e(EM,c1e),e(c1e,scr),e(EM,lcr),e(EM,gW),e(gW,icr),e(EM,dcr),e(q,ccr),e(q,CM),e(CM,f1e),e(f1e,fcr),e(CM,mcr),e(CM,hW),e(hW,gcr),e(CM,hcr),e(q,pcr),e(q,wM),e(wM,m1e),e(m1e,ucr),e(wM,_cr),e(wM,pW),e(pW,bcr),e(wM,vcr),e(q,Fcr),e(q,AM),e(AM,g1e),e(g1e,Tcr),e(AM,Mcr),e(AM,uW),e(uW,Ecr),e(AM,Ccr),e(wr,wcr),M(yM,wr,null),b(f,Xqe,_),b(f,Vd,_),e(Vd,LM),e(LM,h1e),M(JL,h1e,null),e(Vd,Acr),e(Vd,p1e),e(p1e,ycr),b(f,zqe,_),b(f,Ko,_),M(YL,Ko,null),e(Ko,Lcr),e(Ko,Xd),e(Xd,xcr),e(Xd,_W),e(_W,$cr),e(Xd,kcr),e(Xd,bW),e(bW,Scr),e(Xd,Rcr),e(Ko,Pcr),e(Ko,KL),e(KL,Bcr),e(KL,u1e),e(u1e,Icr),e(KL,qcr),e(Ko,Ncr),e(Ko,Lt),M(ZL,Lt,null),e(Lt,jcr),e(Lt,_1e),e(_1e,Dcr),e(Lt,Gcr),e(Lt,zd),e(zd,Ocr),e(zd,b1e),e(b1e,Vcr),e(zd,Xcr),e(zd,vW),e(vW,zcr),e(zd,Wcr),e(Lt,Qcr),M(xM,Lt,null),e(Ko,Hcr),e(Ko,Ar),M(e8,Ar,null),e(Ar,Ucr),e(Ar,v1e),e(v1e,Jcr),e(Ar,Ycr),e(Ar,Za),e(Za,Kcr),e(Za,F1e),e(F1e,Zcr),e(Za,efr),e(Za,T1e),e(T1e,ofr),e(Za,rfr),e(Za,M1e),e(M1e,tfr),e(Za,afr),e(Ar,nfr),e(Ar,se),e(se,$M),e($M,E1e),e(E1e,sfr),e($M,lfr),e($M,FW),e(FW,ifr),e($M,dfr),e(se,cfr),e(se,kM),e(kM,C1e),e(C1e,ffr),e(kM,mfr),e(kM,TW),e(TW,gfr),e(kM,hfr),e(se,pfr),e(se,SM),e(SM,w1e),e(w1e,ufr),e(SM,_fr),e(SM,MW),e(MW,bfr),e(SM,vfr),e(se,Ffr),e(se,RM),e(RM,A1e),e(A1e,Tfr),e(RM,Mfr),e(RM,EW),e(EW,Efr),e(RM,Cfr),e(se,wfr),e(se,PM),e(PM,y1e),e(y1e,Afr),e(PM,yfr),e(PM,CW),e(CW,Lfr),e(PM,xfr),e(se,$fr),e(se,BM),e(BM,L1e),e(L1e,kfr),e(BM,Sfr),e(BM,wW),e(wW,Rfr),e(BM,Pfr),e(se,Bfr),e(se,IM),e(IM,x1e),e(x1e,Ifr),e(IM,qfr),e(IM,AW),e(AW,Nfr),e(IM,jfr),e(se,Dfr),e(se,qM),e(qM,$1e),e($1e,Gfr),e(qM,Ofr),e(qM,yW),e(yW,Vfr),e(qM,Xfr),e(se,zfr),e(se,NM),e(NM,k1e),e(k1e,Wfr),e(NM,Qfr),e(NM,LW),e(LW,Hfr),e(NM,Ufr),e(se,Jfr),e(se,jM),e(jM,S1e),e(S1e,Yfr),e(jM,Kfr),e(jM,xW),e(xW,Zfr),e(jM,emr),e(se,omr),e(se,DM),e(DM,R1e),e(R1e,rmr),e(DM,tmr),e(DM,$W),e($W,amr),e(DM,nmr),e(se,smr),e(se,GM),e(GM,P1e),e(P1e,lmr),e(GM,imr),e(GM,kW),e(kW,dmr),e(GM,cmr),e(se,fmr),e(se,OM),e(OM,B1e),e(B1e,mmr),e(OM,gmr),e(OM,SW),e(SW,hmr),e(OM,pmr),e(se,umr),e(se,VM),e(VM,I1e),e(I1e,_mr),e(VM,bmr),e(VM,RW),e(RW,vmr),e(VM,Fmr),e(se,Tmr),e(se,XM),e(XM,q1e),e(q1e,Mmr),e(XM,Emr),e(XM,PW),e(PW,Cmr),e(XM,wmr),e(se,Amr),e(se,zM),e(zM,N1e),e(N1e,ymr),e(zM,Lmr),e(zM,BW),e(BW,xmr),e(zM,$mr),e(se,kmr),e(se,WM),e(WM,j1e),e(j1e,Smr),e(WM,Rmr),e(WM,IW),e(IW,Pmr),e(WM,Bmr),e(se,Imr),e(se,QM),e(QM,D1e),e(D1e,qmr),e(QM,Nmr),e(QM,qW),e(qW,jmr),e(QM,Dmr),e(se,Gmr),e(se,HM),e(HM,G1e),e(G1e,Omr),e(HM,Vmr),e(HM,NW),e(NW,Xmr),e(HM,zmr),e(se,Wmr),e(se,UM),e(UM,O1e),e(O1e,Qmr),e(UM,Hmr),e(UM,jW),e(jW,Umr),e(UM,Jmr),e(se,Ymr),e(se,JM),e(JM,V1e),e(V1e,Kmr),e(JM,Zmr),e(JM,DW),e(DW,egr),e(JM,ogr),e(se,rgr),e(se,YM),e(YM,X1e),e(X1e,tgr),e(YM,agr),e(YM,GW),e(GW,ngr),e(YM,sgr),e(se,lgr),e(se,KM),e(KM,z1e),e(z1e,igr),e(KM,dgr),e(KM,OW),e(OW,cgr),e(KM,fgr),e(Ar,mgr),M(ZM,Ar,null),b(f,Wqe,_),b(f,Wd,_),e(Wd,e4),e(e4,W1e),M(o8,W1e,null),e(Wd,ggr),e(Wd,Q1e),e(Q1e,hgr),b(f,Qqe,_),b(f,Zo,_),M(r8,Zo,null),e(Zo,pgr),e(Zo,Qd),e(Qd,ugr),e(Qd,VW),e(VW,_gr),e(Qd,bgr),e(Qd,XW),e(XW,vgr),e(Qd,Fgr),e(Zo,Tgr),e(Zo,t8),e(t8,Mgr),e(t8,H1e),e(H1e,Egr),e(t8,Cgr),e(Zo,wgr),e(Zo,xt),M(a8,xt,null),e(xt,Agr),e(xt,U1e),e(U1e,ygr),e(xt,Lgr),e(xt,Hd),e(Hd,xgr),e(Hd,J1e),e(J1e,$gr),e(Hd,kgr),e(Hd,zW),e(zW,Sgr),e(Hd,Rgr),e(xt,Pgr),M(o4,xt,null),e(Zo,Bgr),e(Zo,yr),M(n8,yr,null),e(yr,Igr),e(yr,Y1e),e(Y1e,qgr),e(yr,Ngr),e(yr,en),e(en,jgr),e(en,K1e),e(K1e,Dgr),e(en,Ggr),e(en,Z1e),e(Z1e,Ogr),e(en,Vgr),e(en,e7e),e(e7e,Xgr),e(en,zgr),e(yr,Wgr),e(yr,Te),e(Te,r4),e(r4,o7e),e(o7e,Qgr),e(r4,Hgr),e(r4,WW),e(WW,Ugr),e(r4,Jgr),e(Te,Ygr),e(Te,t4),e(t4,r7e),e(r7e,Kgr),e(t4,Zgr),e(t4,QW),e(QW,ehr),e(t4,ohr),e(Te,rhr),e(Te,a4),e(a4,t7e),e(t7e,thr),e(a4,ahr),e(a4,HW),e(HW,nhr),e(a4,shr),e(Te,lhr),e(Te,n4),e(n4,a7e),e(a7e,ihr),e(n4,dhr),e(n4,UW),e(UW,chr),e(n4,fhr),e(Te,mhr),e(Te,s4),e(s4,n7e),e(n7e,ghr),e(s4,hhr),e(s4,JW),e(JW,phr),e(s4,uhr),e(Te,_hr),e(Te,l4),e(l4,s7e),e(s7e,bhr),e(l4,vhr),e(l4,YW),e(YW,Fhr),e(l4,Thr),e(Te,Mhr),e(Te,i4),e(i4,l7e),e(l7e,Ehr),e(i4,Chr),e(i4,KW),e(KW,whr),e(i4,Ahr),e(Te,yhr),e(Te,d4),e(d4,i7e),e(i7e,Lhr),e(d4,xhr),e(d4,ZW),e(ZW,$hr),e(d4,khr),e(Te,Shr),e(Te,c4),e(c4,d7e),e(d7e,Rhr),e(c4,Phr),e(c4,eQ),e(eQ,Bhr),e(c4,Ihr),e(Te,qhr),e(Te,f4),e(f4,c7e),e(c7e,Nhr),e(f4,jhr),e(f4,oQ),e(oQ,Dhr),e(f4,Ghr),e(Te,Ohr),e(Te,m4),e(m4,f7e),e(f7e,Vhr),e(m4,Xhr),e(m4,rQ),e(rQ,zhr),e(m4,Whr),e(Te,Qhr),e(Te,g4),e(g4,m7e),e(m7e,Hhr),e(g4,Uhr),e(g4,tQ),e(tQ,Jhr),e(g4,Yhr),e(yr,Khr),M(h4,yr,null),b(f,Hqe,_),b(f,Ud,_),e(Ud,p4),e(p4,g7e),M(s8,g7e,null),e(Ud,Zhr),e(Ud,h7e),e(h7e,epr),b(f,Uqe,_),b(f,er,_),M(l8,er,null),e(er,opr),e(er,Jd),e(Jd,rpr),e(Jd,aQ),e(aQ,tpr),e(Jd,apr),e(Jd,nQ),e(nQ,npr),e(Jd,spr),e(er,lpr),e(er,i8),e(i8,ipr),e(i8,p7e),e(p7e,dpr),e(i8,cpr),e(er,fpr),e(er,$t),M(d8,$t,null),e($t,mpr),e($t,u7e),e(u7e,gpr),e($t,hpr),e($t,Yd),e(Yd,ppr),e(Yd,_7e),e(_7e,upr),e(Yd,_pr),e(Yd,sQ),e(sQ,bpr),e(Yd,vpr),e($t,Fpr),M(u4,$t,null),e(er,Tpr),e(er,Lr),M(c8,Lr,null),e(Lr,Mpr),e(Lr,b7e),e(b7e,Epr),e(Lr,Cpr),e(Lr,on),e(on,wpr),e(on,v7e),e(v7e,Apr),e(on,ypr),e(on,F7e),e(F7e,Lpr),e(on,xpr),e(on,T7e),e(T7e,$pr),e(on,kpr),e(Lr,Spr),e(Lr,rn),e(rn,_4),e(_4,M7e),e(M7e,Rpr),e(_4,Ppr),e(_4,lQ),e(lQ,Bpr),e(_4,Ipr),e(rn,qpr),e(rn,b4),e(b4,E7e),e(E7e,Npr),e(b4,jpr),e(b4,iQ),e(iQ,Dpr),e(b4,Gpr),e(rn,Opr),e(rn,v4),e(v4,C7e),e(C7e,Vpr),e(v4,Xpr),e(v4,dQ),e(dQ,zpr),e(v4,Wpr),e(rn,Qpr),e(rn,F4),e(F4,w7e),e(w7e,Hpr),e(F4,Upr),e(F4,cQ),e(cQ,Jpr),e(F4,Ypr),e(Lr,Kpr),M(T4,Lr,null),b(f,Jqe,_),b(f,Kd,_),e(Kd,M4),e(M4,A7e),M(f8,A7e,null),e(Kd,Zpr),e(Kd,y7e),e(y7e,eur),b(f,Yqe,_),b(f,or,_),M(m8,or,null),e(or,our),e(or,Zd),e(Zd,rur),e(Zd,fQ),e(fQ,tur),e(Zd,aur),e(Zd,mQ),e(mQ,nur),e(Zd,sur),e(or,lur),e(or,g8),e(g8,iur),e(g8,L7e),e(L7e,dur),e(g8,cur),e(or,fur),e(or,kt),M(h8,kt,null),e(kt,mur),e(kt,x7e),e(x7e,gur),e(kt,hur),e(kt,ec),e(ec,pur),e(ec,$7e),e($7e,uur),e(ec,_ur),e(ec,gQ),e(gQ,bur),e(ec,vur),e(kt,Fur),M(E4,kt,null),e(or,Tur),e(or,xr),M(p8,xr,null),e(xr,Mur),e(xr,k7e),e(k7e,Eur),e(xr,Cur),e(xr,tn),e(tn,wur),e(tn,S7e),e(S7e,Aur),e(tn,yur),e(tn,R7e),e(R7e,Lur),e(tn,xur),e(tn,P7e),e(P7e,$ur),e(tn,kur),e(xr,Sur),e(xr,ie),e(ie,C4),e(C4,B7e),e(B7e,Rur),e(C4,Pur),e(C4,hQ),e(hQ,Bur),e(C4,Iur),e(ie,qur),e(ie,w4),e(w4,I7e),e(I7e,Nur),e(w4,jur),e(w4,pQ),e(pQ,Dur),e(w4,Gur),e(ie,Our),e(ie,A4),e(A4,q7e),e(q7e,Vur),e(A4,Xur),e(A4,uQ),e(uQ,zur),e(A4,Wur),e(ie,Qur),e(ie,y4),e(y4,N7e),e(N7e,Hur),e(y4,Uur),e(y4,_Q),e(_Q,Jur),e(y4,Yur),e(ie,Kur),e(ie,L4),e(L4,j7e),e(j7e,Zur),e(L4,e_r),e(L4,bQ),e(bQ,o_r),e(L4,r_r),e(ie,t_r),e(ie,x4),e(x4,D7e),e(D7e,a_r),e(x4,n_r),e(x4,vQ),e(vQ,s_r),e(x4,l_r),e(ie,i_r),e(ie,$4),e($4,G7e),e(G7e,d_r),e($4,c_r),e($4,FQ),e(FQ,f_r),e($4,m_r),e(ie,g_r),e(ie,k4),e(k4,O7e),e(O7e,h_r),e(k4,p_r),e(k4,TQ),e(TQ,u_r),e(k4,__r),e(ie,b_r),e(ie,S4),e(S4,V7e),e(V7e,v_r),e(S4,F_r),e(S4,MQ),e(MQ,T_r),e(S4,M_r),e(ie,E_r),e(ie,R4),e(R4,X7e),e(X7e,C_r),e(R4,w_r),e(R4,EQ),e(EQ,A_r),e(R4,y_r),e(ie,L_r),e(ie,P4),e(P4,z7e),e(z7e,x_r),e(P4,$_r),e(P4,CQ),e(CQ,k_r),e(P4,S_r),e(ie,R_r),e(ie,B4),e(B4,W7e),e(W7e,P_r),e(B4,B_r),e(B4,wQ),e(wQ,I_r),e(B4,q_r),e(ie,N_r),e(ie,I4),e(I4,Q7e),e(Q7e,j_r),e(I4,D_r),e(I4,AQ),e(AQ,G_r),e(I4,O_r),e(ie,V_r),e(ie,q4),e(q4,H7e),e(H7e,X_r),e(q4,z_r),e(q4,yQ),e(yQ,W_r),e(q4,Q_r),e(ie,H_r),e(ie,N4),e(N4,U7e),e(U7e,U_r),e(N4,J_r),e(N4,LQ),e(LQ,Y_r),e(N4,K_r),e(ie,Z_r),e(ie,j4),e(j4,J7e),e(J7e,e2r),e(j4,o2r),e(j4,xQ),e(xQ,r2r),e(j4,t2r),e(ie,a2r),e(ie,D4),e(D4,Y7e),e(Y7e,n2r),e(D4,s2r),e(D4,$Q),e($Q,l2r),e(D4,i2r),e(ie,d2r),e(ie,G4),e(G4,K7e),e(K7e,c2r),e(G4,f2r),e(G4,kQ),e(kQ,m2r),e(G4,g2r),e(ie,h2r),e(ie,O4),e(O4,Z7e),e(Z7e,p2r),e(O4,u2r),e(O4,SQ),e(SQ,_2r),e(O4,b2r),e(ie,v2r),e(ie,V4),e(V4,ebe),e(ebe,F2r),e(V4,T2r),e(V4,RQ),e(RQ,M2r),e(V4,E2r),e(xr,C2r),M(X4,xr,null),b(f,Kqe,_),b(f,oc,_),e(oc,z4),e(z4,obe),M(u8,obe,null),e(oc,w2r),e(oc,rbe),e(rbe,A2r),b(f,Zqe,_),b(f,rr,_),M(_8,rr,null),e(rr,y2r),e(rr,rc),e(rc,L2r),e(rc,PQ),e(PQ,x2r),e(rc,$2r),e(rc,BQ),e(BQ,k2r),e(rc,S2r),e(rr,R2r),e(rr,b8),e(b8,P2r),e(b8,tbe),e(tbe,B2r),e(b8,I2r),e(rr,q2r),e(rr,St),M(v8,St,null),e(St,N2r),e(St,abe),e(abe,j2r),e(St,D2r),e(St,tc),e(tc,G2r),e(tc,nbe),e(nbe,O2r),e(tc,V2r),e(tc,IQ),e(IQ,X2r),e(tc,z2r),e(St,W2r),M(W4,St,null),e(rr,Q2r),e(rr,$r),M(F8,$r,null),e($r,H2r),e($r,sbe),e(sbe,U2r),e($r,J2r),e($r,an),e(an,Y2r),e(an,lbe),e(lbe,K2r),e(an,Z2r),e(an,ibe),e(ibe,e1r),e(an,o1r),e(an,dbe),e(dbe,r1r),e(an,t1r),e($r,a1r),e($r,ye),e(ye,Q4),e(Q4,cbe),e(cbe,n1r),e(Q4,s1r),e(Q4,qQ),e(qQ,l1r),e(Q4,i1r),e(ye,d1r),e(ye,H4),e(H4,fbe),e(fbe,c1r),e(H4,f1r),e(H4,NQ),e(NQ,m1r),e(H4,g1r),e(ye,h1r),e(ye,U4),e(U4,mbe),e(mbe,p1r),e(U4,u1r),e(U4,jQ),e(jQ,_1r),e(U4,b1r),e(ye,v1r),e(ye,J4),e(J4,gbe),e(gbe,F1r),e(J4,T1r),e(J4,DQ),e(DQ,M1r),e(J4,E1r),e(ye,C1r),e(ye,Y4),e(Y4,hbe),e(hbe,w1r),e(Y4,A1r),e(Y4,GQ),e(GQ,y1r),e(Y4,L1r),e(ye,x1r),e(ye,K4),e(K4,pbe),e(pbe,$1r),e(K4,k1r),e(K4,OQ),e(OQ,S1r),e(K4,R1r),e(ye,P1r),e(ye,Z4),e(Z4,ube),e(ube,B1r),e(Z4,I1r),e(Z4,VQ),e(VQ,q1r),e(Z4,N1r),e(ye,j1r),e(ye,eE),e(eE,_be),e(_be,D1r),e(eE,G1r),e(eE,XQ),e(XQ,O1r),e(eE,V1r),e(ye,X1r),e(ye,oE),e(oE,bbe),e(bbe,z1r),e(oE,W1r),e(oE,zQ),e(zQ,Q1r),e(oE,H1r),e(ye,U1r),e(ye,rE),e(rE,vbe),e(vbe,J1r),e(rE,Y1r),e(rE,WQ),e(WQ,K1r),e(rE,Z1r),e($r,e7r),M(tE,$r,null),b(f,eNe,_),b(f,ac,_),e(ac,aE),e(aE,Fbe),M(T8,Fbe,null),e(ac,o7r),e(ac,Tbe),e(Tbe,r7r),b(f,oNe,_),b(f,tr,_),M(M8,tr,null),e(tr,t7r),e(tr,nc),e(nc,a7r),e(nc,QQ),e(QQ,n7r),e(nc,s7r),e(nc,HQ),e(HQ,l7r),e(nc,i7r),e(tr,d7r),e(tr,E8),e(E8,c7r),e(E8,Mbe),e(Mbe,f7r),e(E8,m7r),e(tr,g7r),e(tr,Rt),M(C8,Rt,null),e(Rt,h7r),e(Rt,Ebe),e(Ebe,p7r),e(Rt,u7r),e(Rt,sc),e(sc,_7r),e(sc,Cbe),e(Cbe,b7r),e(sc,v7r),e(sc,UQ),e(UQ,F7r),e(sc,T7r),e(Rt,M7r),M(nE,Rt,null),e(tr,E7r),e(tr,kr),M(w8,kr,null),e(kr,C7r),e(kr,wbe),e(wbe,w7r),e(kr,A7r),e(kr,nn),e(nn,y7r),e(nn,Abe),e(Abe,L7r),e(nn,x7r),e(nn,ybe),e(ybe,$7r),e(nn,k7r),e(nn,Lbe),e(Lbe,S7r),e(nn,R7r),e(kr,P7r),e(kr,ee),e(ee,sE),e(sE,xbe),e(xbe,B7r),e(sE,I7r),e(sE,JQ),e(JQ,q7r),e(sE,N7r),e(ee,j7r),e(ee,lE),e(lE,$be),e($be,D7r),e(lE,G7r),e(lE,YQ),e(YQ,O7r),e(lE,V7r),e(ee,X7r),e(ee,iE),e(iE,kbe),e(kbe,z7r),e(iE,W7r),e(iE,KQ),e(KQ,Q7r),e(iE,H7r),e(ee,U7r),e(ee,dE),e(dE,Sbe),e(Sbe,J7r),e(dE,Y7r),e(dE,ZQ),e(ZQ,K7r),e(dE,Z7r),e(ee,ebr),e(ee,cE),e(cE,Rbe),e(Rbe,obr),e(cE,rbr),e(cE,eH),e(eH,tbr),e(cE,abr),e(ee,nbr),e(ee,fE),e(fE,Pbe),e(Pbe,sbr),e(fE,lbr),e(fE,oH),e(oH,ibr),e(fE,dbr),e(ee,cbr),e(ee,mE),e(mE,Bbe),e(Bbe,fbr),e(mE,mbr),e(mE,rH),e(rH,gbr),e(mE,hbr),e(ee,pbr),e(ee,gE),e(gE,Ibe),e(Ibe,ubr),e(gE,_br),e(gE,tH),e(tH,bbr),e(gE,vbr),e(ee,Fbr),e(ee,hE),e(hE,qbe),e(qbe,Tbr),e(hE,Mbr),e(hE,aH),e(aH,Ebr),e(hE,Cbr),e(ee,wbr),e(ee,pE),e(pE,Nbe),e(Nbe,Abr),e(pE,ybr),e(pE,nH),e(nH,Lbr),e(pE,xbr),e(ee,$br),e(ee,uE),e(uE,jbe),e(jbe,kbr),e(uE,Sbr),e(uE,sH),e(sH,Rbr),e(uE,Pbr),e(ee,Bbr),e(ee,_E),e(_E,Dbe),e(Dbe,Ibr),e(_E,qbr),e(_E,lH),e(lH,Nbr),e(_E,jbr),e(ee,Dbr),e(ee,bE),e(bE,Gbe),e(Gbe,Gbr),e(bE,Obr),e(bE,iH),e(iH,Vbr),e(bE,Xbr),e(ee,zbr),e(ee,vE),e(vE,Obe),e(Obe,Wbr),e(vE,Qbr),e(vE,dH),e(dH,Hbr),e(vE,Ubr),e(ee,Jbr),e(ee,FE),e(FE,Vbe),e(Vbe,Ybr),e(FE,Kbr),e(FE,cH),e(cH,Zbr),e(FE,evr),e(ee,ovr),e(ee,TE),e(TE,Xbe),e(Xbe,rvr),e(TE,tvr),e(TE,fH),e(fH,avr),e(TE,nvr),e(ee,svr),e(ee,ME),e(ME,zbe),e(zbe,lvr),e(ME,ivr),e(ME,mH),e(mH,dvr),e(ME,cvr),e(ee,fvr),e(ee,EE),e(EE,Wbe),e(Wbe,mvr),e(EE,gvr),e(EE,gH),e(gH,hvr),e(EE,pvr),e(ee,uvr),e(ee,CE),e(CE,Qbe),e(Qbe,_vr),e(CE,bvr),e(CE,hH),e(hH,vvr),e(CE,Fvr),e(ee,Tvr),e(ee,wE),e(wE,Hbe),e(Hbe,Mvr),e(wE,Evr),e(wE,pH),e(pH,Cvr),e(wE,wvr),e(ee,Avr),e(ee,AE),e(AE,Ube),e(Ube,yvr),e(AE,Lvr),e(AE,uH),e(uH,xvr),e(AE,$vr),e(ee,kvr),e(ee,yE),e(yE,Jbe),e(Jbe,Svr),e(yE,Rvr),e(yE,_H),e(_H,Pvr),e(yE,Bvr),e(ee,Ivr),e(ee,LE),e(LE,Ybe),e(Ybe,qvr),e(LE,Nvr),e(LE,bH),e(bH,jvr),e(LE,Dvr),e(ee,Gvr),e(ee,xE),e(xE,Kbe),e(Kbe,Ovr),e(xE,Vvr),e(xE,vH),e(vH,Xvr),e(xE,zvr),e(ee,Wvr),e(ee,$E),e($E,Zbe),e(Zbe,Qvr),e($E,Hvr),e($E,FH),e(FH,Uvr),e($E,Jvr),e(ee,Yvr),e(ee,kE),e(kE,eve),e(eve,Kvr),e(kE,Zvr),e(kE,TH),e(TH,eFr),e(kE,oFr),e(kr,rFr),M(SE,kr,null),b(f,rNe,_),b(f,lc,_),e(lc,RE),e(RE,ove),M(A8,ove,null),e(lc,tFr),e(lc,rve),e(rve,aFr),b(f,tNe,_),b(f,ar,_),M(y8,ar,null),e(ar,nFr),e(ar,ic),e(ic,sFr),e(ic,MH),e(MH,lFr),e(ic,iFr),e(ic,EH),e(EH,dFr),e(ic,cFr),e(ar,fFr),e(ar,L8),e(L8,mFr),e(L8,tve),e(tve,gFr),e(L8,hFr),e(ar,pFr),e(ar,Pt),M(x8,Pt,null),e(Pt,uFr),e(Pt,ave),e(ave,_Fr),e(Pt,bFr),e(Pt,dc),e(dc,vFr),e(dc,nve),e(nve,FFr),e(dc,TFr),e(dc,CH),e(CH,MFr),e(dc,EFr),e(Pt,CFr),M(PE,Pt,null),e(ar,wFr),e(ar,Sr),M($8,Sr,null),e(Sr,AFr),e(Sr,sve),e(sve,yFr),e(Sr,LFr),e(Sr,sn),e(sn,xFr),e(sn,lve),e(lve,$Fr),e(sn,kFr),e(sn,ive),e(ive,SFr),e(sn,RFr),e(sn,dve),e(dve,PFr),e(sn,BFr),e(Sr,IFr),e(Sr,he),e(he,BE),e(BE,cve),e(cve,qFr),e(BE,NFr),e(BE,wH),e(wH,jFr),e(BE,DFr),e(he,GFr),e(he,IE),e(IE,fve),e(fve,OFr),e(IE,VFr),e(IE,AH),e(AH,XFr),e(IE,zFr),e(he,WFr),e(he,qE),e(qE,mve),e(mve,QFr),e(qE,HFr),e(qE,yH),e(yH,UFr),e(qE,JFr),e(he,YFr),e(he,NE),e(NE,gve),e(gve,KFr),e(NE,ZFr),e(NE,LH),e(LH,eTr),e(NE,oTr),e(he,rTr),e(he,jE),e(jE,hve),e(hve,tTr),e(jE,aTr),e(jE,xH),e(xH,nTr),e(jE,sTr),e(he,lTr),e(he,DE),e(DE,pve),e(pve,iTr),e(DE,dTr),e(DE,$H),e($H,cTr),e(DE,fTr),e(he,mTr),e(he,GE),e(GE,uve),e(uve,gTr),e(GE,hTr),e(GE,kH),e(kH,pTr),e(GE,uTr),e(he,_Tr),e(he,OE),e(OE,_ve),e(_ve,bTr),e(OE,vTr),e(OE,SH),e(SH,FTr),e(OE,TTr),e(he,MTr),e(he,VE),e(VE,bve),e(bve,ETr),e(VE,CTr),e(VE,RH),e(RH,wTr),e(VE,ATr),e(he,yTr),e(he,XE),e(XE,vve),e(vve,LTr),e(XE,xTr),e(XE,PH),e(PH,$Tr),e(XE,kTr),e(he,STr),e(he,zE),e(zE,Fve),e(Fve,RTr),e(zE,PTr),e(zE,BH),e(BH,BTr),e(zE,ITr),e(he,qTr),e(he,WE),e(WE,Tve),e(Tve,NTr),e(WE,jTr),e(WE,IH),e(IH,DTr),e(WE,GTr),e(he,OTr),e(he,QE),e(QE,Mve),e(Mve,VTr),e(QE,XTr),e(QE,qH),e(qH,zTr),e(QE,WTr),e(he,QTr),e(he,HE),e(HE,Eve),e(Eve,HTr),e(HE,UTr),e(HE,NH),e(NH,JTr),e(HE,YTr),e(he,KTr),e(he,UE),e(UE,Cve),e(Cve,ZTr),e(UE,eMr),e(UE,jH),e(jH,oMr),e(UE,rMr),e(he,tMr),e(he,JE),e(JE,wve),e(wve,aMr),e(JE,nMr),e(JE,DH),e(DH,sMr),e(JE,lMr),e(he,iMr),e(he,YE),e(YE,Ave),e(Ave,dMr),e(YE,cMr),e(YE,GH),e(GH,fMr),e(YE,mMr),e(Sr,gMr),M(KE,Sr,null),b(f,aNe,_),b(f,cc,_),e(cc,ZE),e(ZE,yve),M(k8,yve,null),e(cc,hMr),e(cc,Lve),e(Lve,pMr),b(f,nNe,_),b(f,nr,_),M(S8,nr,null),e(nr,uMr),e(nr,fc),e(fc,_Mr),e(fc,OH),e(OH,bMr),e(fc,vMr),e(fc,VH),e(VH,FMr),e(fc,TMr),e(nr,MMr),e(nr,R8),e(R8,EMr),e(R8,xve),e(xve,CMr),e(R8,wMr),e(nr,AMr),e(nr,Bt),M(P8,Bt,null),e(Bt,yMr),e(Bt,$ve),e($ve,LMr),e(Bt,xMr),e(Bt,mc),e(mc,$Mr),e(mc,kve),e(kve,kMr),e(mc,SMr),e(mc,XH),e(XH,RMr),e(mc,PMr),e(Bt,BMr),M(eC,Bt,null),e(nr,IMr),e(nr,Rr),M(B8,Rr,null),e(Rr,qMr),e(Rr,Sve),e(Sve,NMr),e(Rr,jMr),e(Rr,ln),e(ln,DMr),e(ln,Rve),e(Rve,GMr),e(ln,OMr),e(ln,Pve),e(Pve,VMr),e(ln,XMr),e(ln,Bve),e(Bve,zMr),e(ln,WMr),e(Rr,QMr),e(Rr,I8),e(I8,oC),e(oC,Ive),e(Ive,HMr),e(oC,UMr),e(oC,zH),e(zH,JMr),e(oC,YMr),e(I8,KMr),e(I8,rC),e(rC,qve),e(qve,ZMr),e(rC,e4r),e(rC,WH),e(WH,o4r),e(rC,r4r),e(Rr,t4r),M(tC,Rr,null),b(f,sNe,_),b(f,gc,_),e(gc,aC),e(aC,Nve),M(q8,Nve,null),e(gc,a4r),e(gc,jve),e(jve,n4r),b(f,lNe,_),b(f,sr,_),M(N8,sr,null),e(sr,s4r),e(sr,hc),e(hc,l4r),e(hc,QH),e(QH,i4r),e(hc,d4r),e(hc,HH),e(HH,c4r),e(hc,f4r),e(sr,m4r),e(sr,j8),e(j8,g4r),e(j8,Dve),e(Dve,h4r),e(j8,p4r),e(sr,u4r),e(sr,It),M(D8,It,null),e(It,_4r),e(It,Gve),e(Gve,b4r),e(It,v4r),e(It,pc),e(pc,F4r),e(pc,Ove),e(Ove,T4r),e(pc,M4r),e(pc,UH),e(UH,E4r),e(pc,C4r),e(It,w4r),M(nC,It,null),e(sr,A4r),e(sr,Pr),M(G8,Pr,null),e(Pr,y4r),e(Pr,Vve),e(Vve,L4r),e(Pr,x4r),e(Pr,dn),e(dn,$4r),e(dn,Xve),e(Xve,k4r),e(dn,S4r),e(dn,zve),e(zve,R4r),e(dn,P4r),e(dn,Wve),e(Wve,B4r),e(dn,I4r),e(Pr,q4r),e(Pr,Qve),e(Qve,sC),e(sC,Hve),e(Hve,N4r),e(sC,j4r),e(sC,JH),e(JH,D4r),e(sC,G4r),e(Pr,O4r),M(lC,Pr,null),b(f,iNe,_),b(f,uc,_),e(uc,iC),e(iC,Uve),M(O8,Uve,null),e(uc,V4r),e(uc,Jve),e(Jve,X4r),b(f,dNe,_),b(f,lr,_),M(V8,lr,null),e(lr,z4r),e(lr,_c),e(_c,W4r),e(_c,YH),e(YH,Q4r),e(_c,H4r),e(_c,KH),e(KH,U4r),e(_c,J4r),e(lr,Y4r),e(lr,X8),e(X8,K4r),e(X8,Yve),e(Yve,Z4r),e(X8,eEr),e(lr,oEr),e(lr,qt),M(z8,qt,null),e(qt,rEr),e(qt,Kve),e(Kve,tEr),e(qt,aEr),e(qt,bc),e(bc,nEr),e(bc,Zve),e(Zve,sEr),e(bc,lEr),e(bc,ZH),e(ZH,iEr),e(bc,dEr),e(qt,cEr),M(dC,qt,null),e(lr,fEr),e(lr,Br),M(W8,Br,null),e(Br,mEr),e(Br,eFe),e(eFe,gEr),e(Br,hEr),e(Br,cn),e(cn,pEr),e(cn,oFe),e(oFe,uEr),e(cn,_Er),e(cn,rFe),e(rFe,bEr),e(cn,vEr),e(cn,tFe),e(tFe,FEr),e(cn,TEr),e(Br,MEr),e(Br,de),e(de,cC),e(cC,aFe),e(aFe,EEr),e(cC,CEr),e(cC,eU),e(eU,wEr),e(cC,AEr),e(de,yEr),e(de,fC),e(fC,nFe),e(nFe,LEr),e(fC,xEr),e(fC,oU),e(oU,$Er),e(fC,kEr),e(de,SEr),e(de,mC),e(mC,sFe),e(sFe,REr),e(mC,PEr),e(mC,rU),e(rU,BEr),e(mC,IEr),e(de,qEr),e(de,gC),e(gC,lFe),e(lFe,NEr),e(gC,jEr),e(gC,tU),e(tU,DEr),e(gC,GEr),e(de,OEr),e(de,hC),e(hC,iFe),e(iFe,VEr),e(hC,XEr),e(hC,aU),e(aU,zEr),e(hC,WEr),e(de,QEr),e(de,pC),e(pC,dFe),e(dFe,HEr),e(pC,UEr),e(pC,nU),e(nU,JEr),e(pC,YEr),e(de,KEr),e(de,uC),e(uC,cFe),e(cFe,ZEr),e(uC,eCr),e(uC,sU),e(sU,oCr),e(uC,rCr),e(de,tCr),e(de,_C),e(_C,fFe),e(fFe,aCr),e(_C,nCr),e(_C,lU),e(lU,sCr),e(_C,lCr),e(de,iCr),e(de,bC),e(bC,mFe),e(mFe,dCr),e(bC,cCr),e(bC,iU),e(iU,fCr),e(bC,mCr),e(de,gCr),e(de,vC),e(vC,gFe),e(gFe,hCr),e(vC,pCr),e(vC,dU),e(dU,uCr),e(vC,_Cr),e(de,bCr),e(de,FC),e(FC,hFe),e(hFe,vCr),e(FC,FCr),e(FC,cU),e(cU,TCr),e(FC,MCr),e(de,ECr),e(de,TC),e(TC,pFe),e(pFe,CCr),e(TC,wCr),e(TC,fU),e(fU,ACr),e(TC,yCr),e(de,LCr),e(de,MC),e(MC,uFe),e(uFe,xCr),e(MC,$Cr),e(MC,mU),e(mU,kCr),e(MC,SCr),e(de,RCr),e(de,EC),e(EC,_Fe),e(_Fe,PCr),e(EC,BCr),e(EC,gU),e(gU,ICr),e(EC,qCr),e(de,NCr),e(de,CC),e(CC,bFe),e(bFe,jCr),e(CC,DCr),e(CC,hU),e(hU,GCr),e(CC,OCr),e(de,VCr),e(de,wC),e(wC,vFe),e(vFe,XCr),e(wC,zCr),e(wC,pU),e(pU,WCr),e(wC,QCr),e(de,HCr),e(de,AC),e(AC,FFe),e(FFe,UCr),e(AC,JCr),e(AC,uU),e(uU,YCr),e(AC,KCr),e(de,ZCr),e(de,yC),e(yC,TFe),e(TFe,e5r),e(yC,o5r),e(yC,_U),e(_U,r5r),e(yC,t5r),e(de,a5r),e(de,LC),e(LC,MFe),e(MFe,n5r),e(LC,s5r),e(LC,bU),e(bU,l5r),e(LC,i5r),e(de,d5r),e(de,xC),e(xC,EFe),e(EFe,c5r),e(xC,f5r),e(xC,vU),e(vU,m5r),e(xC,g5r),e(Br,h5r),M($C,Br,null),b(f,cNe,_),b(f,vc,_),e(vc,kC),e(kC,CFe),M(Q8,CFe,null),e(vc,p5r),e(vc,wFe),e(wFe,u5r),b(f,fNe,_),b(f,ir,_),M(H8,ir,null),e(ir,_5r),e(ir,Fc),e(Fc,b5r),e(Fc,FU),e(FU,v5r),e(Fc,F5r),e(Fc,TU),e(TU,T5r),e(Fc,M5r),e(ir,E5r),e(ir,U8),e(U8,C5r),e(U8,AFe),e(AFe,w5r),e(U8,A5r),e(ir,y5r),e(ir,Nt),M(J8,Nt,null),e(Nt,L5r),e(Nt,yFe),e(yFe,x5r),e(Nt,$5r),e(Nt,Tc),e(Tc,k5r),e(Tc,LFe),e(LFe,S5r),e(Tc,R5r),e(Tc,MU),e(MU,P5r),e(Tc,B5r),e(Nt,I5r),M(SC,Nt,null),e(ir,q5r),e(ir,Ir),M(Y8,Ir,null),e(Ir,N5r),e(Ir,xFe),e(xFe,j5r),e(Ir,D5r),e(Ir,fn),e(fn,G5r),e(fn,$Fe),e($Fe,O5r),e(fn,V5r),e(fn,kFe),e(kFe,X5r),e(fn,z5r),e(fn,SFe),e(SFe,W5r),e(fn,Q5r),e(Ir,H5r),e(Ir,ce),e(ce,RC),e(RC,RFe),e(RFe,U5r),e(RC,J5r),e(RC,EU),e(EU,Y5r),e(RC,K5r),e(ce,Z5r),e(ce,PC),e(PC,PFe),e(PFe,e3r),e(PC,o3r),e(PC,CU),e(CU,r3r),e(PC,t3r),e(ce,a3r),e(ce,BC),e(BC,BFe),e(BFe,n3r),e(BC,s3r),e(BC,wU),e(wU,l3r),e(BC,i3r),e(ce,d3r),e(ce,IC),e(IC,IFe),e(IFe,c3r),e(IC,f3r),e(IC,AU),e(AU,m3r),e(IC,g3r),e(ce,h3r),e(ce,qC),e(qC,qFe),e(qFe,p3r),e(qC,u3r),e(qC,yU),e(yU,_3r),e(qC,b3r),e(ce,v3r),e(ce,NC),e(NC,NFe),e(NFe,F3r),e(NC,T3r),e(NC,LU),e(LU,M3r),e(NC,E3r),e(ce,C3r),e(ce,jC),e(jC,jFe),e(jFe,w3r),e(jC,A3r),e(jC,xU),e(xU,y3r),e(jC,L3r),e(ce,x3r),e(ce,DC),e(DC,DFe),e(DFe,$3r),e(DC,k3r),e(DC,$U),e($U,S3r),e(DC,R3r),e(ce,P3r),e(ce,GC),e(GC,GFe),e(GFe,B3r),e(GC,I3r),e(GC,kU),e(kU,q3r),e(GC,N3r),e(ce,j3r),e(ce,OC),e(OC,OFe),e(OFe,D3r),e(OC,G3r),e(OC,SU),e(SU,O3r),e(OC,V3r),e(ce,X3r),e(ce,VC),e(VC,VFe),e(VFe,z3r),e(VC,W3r),e(VC,RU),e(RU,Q3r),e(VC,H3r),e(ce,U3r),e(ce,XC),e(XC,XFe),e(XFe,J3r),e(XC,Y3r),e(XC,PU),e(PU,K3r),e(XC,Z3r),e(ce,ewr),e(ce,zC),e(zC,zFe),e(zFe,owr),e(zC,rwr),e(zC,BU),e(BU,twr),e(zC,awr),e(ce,nwr),e(ce,WC),e(WC,WFe),e(WFe,swr),e(WC,lwr),e(WC,IU),e(IU,iwr),e(WC,dwr),e(ce,cwr),e(ce,QC),e(QC,QFe),e(QFe,fwr),e(QC,mwr),e(QC,qU),e(qU,gwr),e(QC,hwr),e(ce,pwr),e(ce,HC),e(HC,HFe),e(HFe,uwr),e(HC,_wr),e(HC,NU),e(NU,bwr),e(HC,vwr),e(ce,Fwr),e(ce,UC),e(UC,UFe),e(UFe,Twr),e(UC,Mwr),e(UC,jU),e(jU,Ewr),e(UC,Cwr),e(ce,wwr),e(ce,JC),e(JC,JFe),e(JFe,Awr),e(JC,ywr),e(JC,DU),e(DU,Lwr),e(JC,xwr),e(ce,$wr),e(ce,YC),e(YC,YFe),e(YFe,kwr),e(YC,Swr),e(YC,GU),e(GU,Rwr),e(YC,Pwr),e(ce,Bwr),e(ce,KC),e(KC,KFe),e(KFe,Iwr),e(KC,qwr),e(KC,OU),e(OU,Nwr),e(KC,jwr),e(Ir,Dwr),M(ZC,Ir,null),b(f,mNe,_),b(f,Mc,_),e(Mc,e5),e(e5,ZFe),M(K8,ZFe,null),e(Mc,Gwr),e(Mc,eTe),e(eTe,Owr),b(f,gNe,_),b(f,dr,_),M(Z8,dr,null),e(dr,Vwr),e(dr,Ec),e(Ec,Xwr),e(Ec,VU),e(VU,zwr),e(Ec,Wwr),e(Ec,XU),e(XU,Qwr),e(Ec,Hwr),e(dr,Uwr),e(dr,ex),e(ex,Jwr),e(ex,oTe),e(oTe,Ywr),e(ex,Kwr),e(dr,Zwr),e(dr,jt),M(ox,jt,null),e(jt,eAr),e(jt,rTe),e(rTe,oAr),e(jt,rAr),e(jt,Cc),e(Cc,tAr),e(Cc,tTe),e(tTe,aAr),e(Cc,nAr),e(Cc,zU),e(zU,sAr),e(Cc,lAr),e(jt,iAr),M(o5,jt,null),e(dr,dAr),e(dr,qr),M(rx,qr,null),e(qr,cAr),e(qr,aTe),e(aTe,fAr),e(qr,mAr),e(qr,mn),e(mn,gAr),e(mn,nTe),e(nTe,hAr),e(mn,pAr),e(mn,sTe),e(sTe,uAr),e(mn,_Ar),e(mn,lTe),e(lTe,bAr),e(mn,vAr),e(qr,FAr),e(qr,iTe),e(iTe,r5),e(r5,dTe),e(dTe,TAr),e(r5,MAr),e(r5,WU),e(WU,EAr),e(r5,CAr),e(qr,wAr),M(t5,qr,null),b(f,hNe,_),b(f,wc,_),e(wc,a5),e(a5,cTe),M(tx,cTe,null),e(wc,AAr),e(wc,fTe),e(fTe,yAr),b(f,pNe,_),b(f,cr,_),M(ax,cr,null),e(cr,LAr),e(cr,Ac),e(Ac,xAr),e(Ac,QU),e(QU,$Ar),e(Ac,kAr),e(Ac,HU),e(HU,SAr),e(Ac,RAr),e(cr,PAr),e(cr,nx),e(nx,BAr),e(nx,mTe),e(mTe,IAr),e(nx,qAr),e(cr,NAr),e(cr,Dt),M(sx,Dt,null),e(Dt,jAr),e(Dt,gTe),e(gTe,DAr),e(Dt,GAr),e(Dt,yc),e(yc,OAr),e(yc,hTe),e(hTe,VAr),e(yc,XAr),e(yc,UU),e(UU,zAr),e(yc,WAr),e(Dt,QAr),M(n5,Dt,null),e(cr,HAr),e(cr,Nr),M(lx,Nr,null),e(Nr,UAr),e(Nr,pTe),e(pTe,JAr),e(Nr,YAr),e(Nr,gn),e(gn,KAr),e(gn,uTe),e(uTe,ZAr),e(gn,e0r),e(gn,_Te),e(_Te,o0r),e(gn,r0r),e(gn,bTe),e(bTe,t0r),e(gn,a0r),e(Nr,n0r),e(Nr,vTe),e(vTe,s5),e(s5,FTe),e(FTe,s0r),e(s5,l0r),e(s5,JU),e(JU,i0r),e(s5,d0r),e(Nr,c0r),M(l5,Nr,null),b(f,uNe,_),b(f,Lc,_),e(Lc,i5),e(i5,TTe),M(ix,TTe,null),e(Lc,f0r),e(Lc,MTe),e(MTe,m0r),b(f,_Ne,_),b(f,fr,_),M(dx,fr,null),e(fr,g0r),e(fr,xc),e(xc,h0r),e(xc,YU),e(YU,p0r),e(xc,u0r),e(xc,KU),e(KU,_0r),e(xc,b0r),e(fr,v0r),e(fr,cx),e(cx,F0r),e(cx,ETe),e(ETe,T0r),e(cx,M0r),e(fr,E0r),e(fr,Gt),M(fx,Gt,null),e(Gt,C0r),e(Gt,CTe),e(CTe,w0r),e(Gt,A0r),e(Gt,$c),e($c,y0r),e($c,wTe),e(wTe,L0r),e($c,x0r),e($c,ZU),e(ZU,$0r),e($c,k0r),e(Gt,S0r),M(d5,Gt,null),e(fr,R0r),e(fr,jr),M(mx,jr,null),e(jr,P0r),e(jr,ATe),e(ATe,B0r),e(jr,I0r),e(jr,hn),e(hn,q0r),e(hn,yTe),e(yTe,N0r),e(hn,j0r),e(hn,LTe),e(LTe,D0r),e(hn,G0r),e(hn,xTe),e(xTe,O0r),e(hn,V0r),e(jr,X0r),e(jr,oe),e(oe,c5),e(c5,$Te),e($Te,z0r),e(c5,W0r),e(c5,eJ),e(eJ,Q0r),e(c5,H0r),e(oe,U0r),e(oe,f5),e(f5,kTe),e(kTe,J0r),e(f5,Y0r),e(f5,oJ),e(oJ,K0r),e(f5,Z0r),e(oe,e6r),e(oe,m5),e(m5,STe),e(STe,o6r),e(m5,r6r),e(m5,rJ),e(rJ,t6r),e(m5,a6r),e(oe,n6r),e(oe,g5),e(g5,RTe),e(RTe,s6r),e(g5,l6r),e(g5,tJ),e(tJ,i6r),e(g5,d6r),e(oe,c6r),e(oe,h5),e(h5,PTe),e(PTe,f6r),e(h5,m6r),e(h5,aJ),e(aJ,g6r),e(h5,h6r),e(oe,p6r),e(oe,p5),e(p5,BTe),e(BTe,u6r),e(p5,_6r),e(p5,nJ),e(nJ,b6r),e(p5,v6r),e(oe,F6r),e(oe,u5),e(u5,ITe),e(ITe,T6r),e(u5,M6r),e(u5,sJ),e(sJ,E6r),e(u5,C6r),e(oe,w6r),e(oe,_5),e(_5,qTe),e(qTe,A6r),e(_5,y6r),e(_5,lJ),e(lJ,L6r),e(_5,x6r),e(oe,$6r),e(oe,b5),e(b5,NTe),e(NTe,k6r),e(b5,S6r),e(b5,iJ),e(iJ,R6r),e(b5,P6r),e(oe,B6r),e(oe,v5),e(v5,jTe),e(jTe,I6r),e(v5,q6r),e(v5,dJ),e(dJ,N6r),e(v5,j6r),e(oe,D6r),e(oe,F5),e(F5,DTe),e(DTe,G6r),e(F5,O6r),e(F5,cJ),e(cJ,V6r),e(F5,X6r),e(oe,z6r),e(oe,T5),e(T5,GTe),e(GTe,W6r),e(T5,Q6r),e(T5,fJ),e(fJ,H6r),e(T5,U6r),e(oe,J6r),e(oe,M5),e(M5,OTe),e(OTe,Y6r),e(M5,K6r),e(M5,mJ),e(mJ,Z6r),e(M5,eyr),e(oe,oyr),e(oe,E5),e(E5,VTe),e(VTe,ryr),e(E5,tyr),e(E5,gJ),e(gJ,ayr),e(E5,nyr),e(oe,syr),e(oe,C5),e(C5,XTe),e(XTe,lyr),e(C5,iyr),e(C5,hJ),e(hJ,dyr),e(C5,cyr),e(oe,fyr),e(oe,w5),e(w5,zTe),e(zTe,myr),e(w5,gyr),e(w5,pJ),e(pJ,hyr),e(w5,pyr),e(oe,uyr),e(oe,A5),e(A5,WTe),e(WTe,_yr),e(A5,byr),e(A5,uJ),e(uJ,vyr),e(A5,Fyr),e(oe,Tyr),e(oe,y5),e(y5,QTe),e(QTe,Myr),e(y5,Eyr),e(y5,_J),e(_J,Cyr),e(y5,wyr),e(oe,Ayr),e(oe,L5),e(L5,HTe),e(HTe,yyr),e(L5,Lyr),e(L5,bJ),e(bJ,xyr),e(L5,$yr),e(oe,kyr),e(oe,x5),e(x5,UTe),e(UTe,Syr),e(x5,Ryr),e(x5,vJ),e(vJ,Pyr),e(x5,Byr),e(oe,Iyr),e(oe,$5),e($5,JTe),e(JTe,qyr),e($5,Nyr),e($5,FJ),e(FJ,jyr),e($5,Dyr),e(oe,Gyr),e(oe,k5),e(k5,YTe),e(YTe,Oyr),e(k5,Vyr),e(k5,TJ),e(TJ,Xyr),e(k5,zyr),e(oe,Wyr),e(oe,S5),e(S5,KTe),e(KTe,Qyr),e(S5,Hyr),e(S5,MJ),e(MJ,Uyr),e(S5,Jyr),e(oe,Yyr),e(oe,R5),e(R5,ZTe),e(ZTe,Kyr),e(R5,Zyr),e(R5,EJ),e(EJ,eLr),e(R5,oLr),e(oe,rLr),e(oe,P5),e(P5,eMe),e(eMe,tLr),e(P5,aLr),e(P5,CJ),e(CJ,nLr),e(P5,sLr),e(oe,lLr),e(oe,B5),e(B5,oMe),e(oMe,iLr),e(B5,dLr),e(B5,wJ),e(wJ,cLr),e(B5,fLr),e(jr,mLr),M(I5,jr,null),b(f,bNe,_),b(f,kc,_),e(kc,q5),e(q5,rMe),M(gx,rMe,null),e(kc,gLr),e(kc,tMe),e(tMe,hLr),b(f,vNe,_),b(f,mr,_),M(hx,mr,null),e(mr,pLr),e(mr,Sc),e(Sc,uLr),e(Sc,AJ),e(AJ,_Lr),e(Sc,bLr),e(Sc,yJ),e(yJ,vLr),e(Sc,FLr),e(mr,TLr),e(mr,px),e(px,MLr),e(px,aMe),e(aMe,ELr),e(px,CLr),e(mr,wLr),e(mr,Ot),M(ux,Ot,null),e(Ot,ALr),e(Ot,nMe),e(nMe,yLr),e(Ot,LLr),e(Ot,Rc),e(Rc,xLr),e(Rc,sMe),e(sMe,$Lr),e(Rc,kLr),e(Rc,LJ),e(LJ,SLr),e(Rc,RLr),e(Ot,PLr),M(N5,Ot,null),e(mr,BLr),e(mr,Dr),M(_x,Dr,null),e(Dr,ILr),e(Dr,lMe),e(lMe,qLr),e(Dr,NLr),e(Dr,pn),e(pn,jLr),e(pn,iMe),e(iMe,DLr),e(pn,GLr),e(pn,dMe),e(dMe,OLr),e(pn,VLr),e(pn,cMe),e(cMe,XLr),e(pn,zLr),e(Dr,WLr),e(Dr,Le),e(Le,j5),e(j5,fMe),e(fMe,QLr),e(j5,HLr),e(j5,xJ),e(xJ,ULr),e(j5,JLr),e(Le,YLr),e(Le,D5),e(D5,mMe),e(mMe,KLr),e(D5,ZLr),e(D5,$J),e($J,e8r),e(D5,o8r),e(Le,r8r),e(Le,G5),e(G5,gMe),e(gMe,t8r),e(G5,a8r),e(G5,kJ),e(kJ,n8r),e(G5,s8r),e(Le,l8r),e(Le,O5),e(O5,hMe),e(hMe,i8r),e(O5,d8r),e(O5,SJ),e(SJ,c8r),e(O5,f8r),e(Le,m8r),e(Le,V5),e(V5,pMe),e(pMe,g8r),e(V5,h8r),e(V5,RJ),e(RJ,p8r),e(V5,u8r),e(Le,_8r),e(Le,X5),e(X5,uMe),e(uMe,b8r),e(X5,v8r),e(X5,PJ),e(PJ,F8r),e(X5,T8r),e(Le,M8r),e(Le,z5),e(z5,_Me),e(_Me,E8r),e(z5,C8r),e(z5,BJ),e(BJ,w8r),e(z5,A8r),e(Le,y8r),e(Le,W5),e(W5,bMe),e(bMe,L8r),e(W5,x8r),e(W5,IJ),e(IJ,$8r),e(W5,k8r),e(Le,S8r),e(Le,Q5),e(Q5,vMe),e(vMe,R8r),e(Q5,P8r),e(Q5,qJ),e(qJ,B8r),e(Q5,I8r),e(Le,q8r),e(Le,H5),e(H5,FMe),e(FMe,N8r),e(H5,j8r),e(H5,NJ),e(NJ,D8r),e(H5,G8r),e(Dr,O8r),M(U5,Dr,null),b(f,FNe,_),b(f,Pc,_),e(Pc,J5),e(J5,TMe),M(bx,TMe,null),e(Pc,V8r),e(Pc,MMe),e(MMe,X8r),b(f,TNe,_),b(f,gr,_),M(vx,gr,null),e(gr,z8r),e(gr,Bc),e(Bc,W8r),e(Bc,jJ),e(jJ,Q8r),e(Bc,H8r),e(Bc,DJ),e(DJ,U8r),e(Bc,J8r),e(gr,Y8r),e(gr,Fx),e(Fx,K8r),e(Fx,EMe),e(EMe,Z8r),e(Fx,exr),e(gr,oxr),e(gr,Vt),M(Tx,Vt,null),e(Vt,rxr),e(Vt,CMe),e(CMe,txr),e(Vt,axr),e(Vt,Ic),e(Ic,nxr),e(Ic,wMe),e(wMe,sxr),e(Ic,lxr),e(Ic,GJ),e(GJ,ixr),e(Ic,dxr),e(Vt,cxr),M(Y5,Vt,null),e(gr,fxr),e(gr,Gr),M(Mx,Gr,null),e(Gr,mxr),e(Gr,AMe),e(AMe,gxr),e(Gr,hxr),e(Gr,un),e(un,pxr),e(un,yMe),e(yMe,uxr),e(un,_xr),e(un,LMe),e(LMe,bxr),e(un,vxr),e(un,xMe),e(xMe,Fxr),e(un,Txr),e(Gr,Mxr),e(Gr,Me),e(Me,K5),e(K5,$Me),e($Me,Exr),e(K5,Cxr),e(K5,OJ),e(OJ,wxr),e(K5,Axr),e(Me,yxr),e(Me,Z5),e(Z5,kMe),e(kMe,Lxr),e(Z5,xxr),e(Z5,VJ),e(VJ,$xr),e(Z5,kxr),e(Me,Sxr),e(Me,e3),e(e3,SMe),e(SMe,Rxr),e(e3,Pxr),e(e3,XJ),e(XJ,Bxr),e(e3,Ixr),e(Me,qxr),e(Me,o3),e(o3,RMe),e(RMe,Nxr),e(o3,jxr),e(o3,zJ),e(zJ,Dxr),e(o3,Gxr),e(Me,Oxr),e(Me,r3),e(r3,PMe),e(PMe,Vxr),e(r3,Xxr),e(r3,WJ),e(WJ,zxr),e(r3,Wxr),e(Me,Qxr),e(Me,t3),e(t3,BMe),e(BMe,Hxr),e(t3,Uxr),e(t3,QJ),e(QJ,Jxr),e(t3,Yxr),e(Me,Kxr),e(Me,a3),e(a3,IMe),e(IMe,Zxr),e(a3,e9r),e(a3,HJ),e(HJ,o9r),e(a3,r9r),e(Me,t9r),e(Me,n3),e(n3,qMe),e(qMe,a9r),e(n3,n9r),e(n3,UJ),e(UJ,s9r),e(n3,l9r),e(Me,i9r),e(Me,s3),e(s3,NMe),e(NMe,d9r),e(s3,c9r),e(s3,JJ),e(JJ,f9r),e(s3,m9r),e(Me,g9r),e(Me,l3),e(l3,jMe),e(jMe,h9r),e(l3,p9r),e(l3,YJ),e(YJ,u9r),e(l3,_9r),e(Me,b9r),e(Me,i3),e(i3,DMe),e(DMe,v9r),e(i3,F9r),e(i3,KJ),e(KJ,T9r),e(i3,M9r),e(Me,E9r),e(Me,d3),e(d3,GMe),e(GMe,C9r),e(d3,w9r),e(d3,ZJ),e(ZJ,A9r),e(d3,y9r),e(Gr,L9r),M(c3,Gr,null),b(f,MNe,_),b(f,qc,_),e(qc,f3),e(f3,OMe),M(Ex,OMe,null),e(qc,x9r),e(qc,VMe),e(VMe,$9r),b(f,ENe,_),b(f,hr,_),M(Cx,hr,null),e(hr,k9r),e(hr,Nc),e(Nc,S9r),e(Nc,eY),e(eY,R9r),e(Nc,P9r),e(Nc,oY),e(oY,B9r),e(Nc,I9r),e(hr,q9r),e(hr,wx),e(wx,N9r),e(wx,XMe),e(XMe,j9r),e(wx,D9r),e(hr,G9r),e(hr,Xt),M(Ax,Xt,null),e(Xt,O9r),e(Xt,zMe),e(zMe,V9r),e(Xt,X9r),e(Xt,jc),e(jc,z9r),e(jc,WMe),e(WMe,W9r),e(jc,Q9r),e(jc,rY),e(rY,H9r),e(jc,U9r),e(Xt,J9r),M(m3,Xt,null),e(hr,Y9r),e(hr,Or),M(yx,Or,null),e(Or,K9r),e(Or,QMe),e(QMe,Z9r),e(Or,e$r),e(Or,_n),e(_n,o$r),e(_n,HMe),e(HMe,r$r),e(_n,t$r),e(_n,UMe),e(UMe,a$r),e(_n,n$r),e(_n,JMe),e(JMe,s$r),e(_n,l$r),e(Or,i$r),e(Or,xe),e(xe,g3),e(g3,YMe),e(YMe,d$r),e(g3,c$r),e(g3,tY),e(tY,f$r),e(g3,m$r),e(xe,g$r),e(xe,h3),e(h3,KMe),e(KMe,h$r),e(h3,p$r),e(h3,aY),e(aY,u$r),e(h3,_$r),e(xe,b$r),e(xe,p3),e(p3,ZMe),e(ZMe,v$r),e(p3,F$r),e(p3,nY),e(nY,T$r),e(p3,M$r),e(xe,E$r),e(xe,u3),e(u3,e4e),e(e4e,C$r),e(u3,w$r),e(u3,sY),e(sY,A$r),e(u3,y$r),e(xe,L$r),e(xe,_3),e(_3,o4e),e(o4e,x$r),e(_3,$$r),e(_3,lY),e(lY,k$r),e(_3,S$r),e(xe,R$r),e(xe,b3),e(b3,r4e),e(r4e,P$r),e(b3,B$r),e(b3,iY),e(iY,I$r),e(b3,q$r),e(xe,N$r),e(xe,v3),e(v3,t4e),e(t4e,j$r),e(v3,D$r),e(v3,dY),e(dY,G$r),e(v3,O$r),e(xe,V$r),e(xe,F3),e(F3,a4e),e(a4e,X$r),e(F3,z$r),e(F3,cY),e(cY,W$r),e(F3,Q$r),e(xe,H$r),e(xe,T3),e(T3,n4e),e(n4e,U$r),e(T3,J$r),e(T3,fY),e(fY,Y$r),e(T3,K$r),e(xe,Z$r),e(xe,M3),e(M3,s4e),e(s4e,ekr),e(M3,okr),e(M3,mY),e(mY,rkr),e(M3,tkr),e(Or,akr),M(E3,Or,null),b(f,CNe,_),b(f,Dc,_),e(Dc,C3),e(C3,l4e),M(Lx,l4e,null),e(Dc,nkr),e(Dc,i4e),e(i4e,skr),b(f,wNe,_),b(f,pr,_),M(xx,pr,null),e(pr,lkr),e(pr,Gc),e(Gc,ikr),e(Gc,gY),e(gY,dkr),e(Gc,ckr),e(Gc,hY),e(hY,fkr),e(Gc,mkr),e(pr,gkr),e(pr,$x),e($x,hkr),e($x,d4e),e(d4e,pkr),e($x,ukr),e(pr,_kr),e(pr,zt),M(kx,zt,null),e(zt,bkr),e(zt,c4e),e(c4e,vkr),e(zt,Fkr),e(zt,Oc),e(Oc,Tkr),e(Oc,f4e),e(f4e,Mkr),e(Oc,Ekr),e(Oc,pY),e(pY,Ckr),e(Oc,wkr),e(zt,Akr),M(w3,zt,null),e(pr,ykr),e(pr,Vr),M(Sx,Vr,null),e(Vr,Lkr),e(Vr,m4e),e(m4e,xkr),e(Vr,$kr),e(Vr,bn),e(bn,kkr),e(bn,g4e),e(g4e,Skr),e(bn,Rkr),e(bn,h4e),e(h4e,Pkr),e(bn,Bkr),e(bn,p4e),e(p4e,Ikr),e(bn,qkr),e(Vr,Nkr),e(Vr,Pe),e(Pe,A3),e(A3,u4e),e(u4e,jkr),e(A3,Dkr),e(A3,uY),e(uY,Gkr),e(A3,Okr),e(Pe,Vkr),e(Pe,y3),e(y3,_4e),e(_4e,Xkr),e(y3,zkr),e(y3,_Y),e(_Y,Wkr),e(y3,Qkr),e(Pe,Hkr),e(Pe,L3),e(L3,b4e),e(b4e,Ukr),e(L3,Jkr),e(L3,bY),e(bY,Ykr),e(L3,Kkr),e(Pe,Zkr),e(Pe,x3),e(x3,v4e),e(v4e,eSr),e(x3,oSr),e(x3,vY),e(vY,rSr),e(x3,tSr),e(Pe,aSr),e(Pe,$3),e($3,F4e),e(F4e,nSr),e($3,sSr),e($3,FY),e(FY,lSr),e($3,iSr),e(Pe,dSr),e(Pe,k3),e(k3,T4e),e(T4e,cSr),e(k3,fSr),e(k3,TY),e(TY,mSr),e(k3,gSr),e(Pe,hSr),e(Pe,S3),e(S3,M4e),e(M4e,pSr),e(S3,uSr),e(S3,MY),e(MY,_Sr),e(S3,bSr),e(Pe,vSr),e(Pe,R3),e(R3,E4e),e(E4e,FSr),e(R3,TSr),e(R3,EY),e(EY,MSr),e(R3,ESr),e(Pe,CSr),e(Pe,P3),e(P3,C4e),e(C4e,wSr),e(P3,ASr),e(P3,CY),e(CY,ySr),e(P3,LSr),e(Vr,xSr),M(B3,Vr,null),b(f,ANe,_),b(f,Vc,_),e(Vc,I3),e(I3,w4e),M(Rx,w4e,null),e(Vc,$Sr),e(Vc,A4e),e(A4e,kSr),b(f,yNe,_),b(f,ur,_),M(Px,ur,null),e(ur,SSr),e(ur,Xc),e(Xc,RSr),e(Xc,wY),e(wY,PSr),e(Xc,BSr),e(Xc,AY),e(AY,ISr),e(Xc,qSr),e(ur,NSr),e(ur,Bx),e(Bx,jSr),e(Bx,y4e),e(y4e,DSr),e(Bx,GSr),e(ur,OSr),e(ur,Wt),M(Ix,Wt,null),e(Wt,VSr),e(Wt,L4e),e(L4e,XSr),e(Wt,zSr),e(Wt,zc),e(zc,WSr),e(zc,x4e),e(x4e,QSr),e(zc,HSr),e(zc,yY),e(yY,USr),e(zc,JSr),e(Wt,YSr),M(q3,Wt,null),e(ur,KSr),e(ur,Xr),M(qx,Xr,null),e(Xr,ZSr),e(Xr,$4e),e($4e,eRr),e(Xr,oRr),e(Xr,vn),e(vn,rRr),e(vn,k4e),e(k4e,tRr),e(vn,aRr),e(vn,S4e),e(S4e,nRr),e(vn,sRr),e(vn,R4e),e(R4e,lRr),e(vn,iRr),e(Xr,dRr),e(Xr,$e),e($e,N3),e(N3,P4e),e(P4e,cRr),e(N3,fRr),e(N3,LY),e(LY,mRr),e(N3,gRr),e($e,hRr),e($e,j3),e(j3,B4e),e(B4e,pRr),e(j3,uRr),e(j3,xY),e(xY,_Rr),e(j3,bRr),e($e,vRr),e($e,D3),e(D3,I4e),e(I4e,FRr),e(D3,TRr),e(D3,$Y),e($Y,MRr),e(D3,ERr),e($e,CRr),e($e,G3),e(G3,q4e),e(q4e,wRr),e(G3,ARr),e(G3,kY),e(kY,yRr),e(G3,LRr),e($e,xRr),e($e,O3),e(O3,N4e),e(N4e,$Rr),e(O3,kRr),e(O3,SY),e(SY,SRr),e(O3,RRr),e($e,PRr),e($e,V3),e(V3,j4e),e(j4e,BRr),e(V3,IRr),e(V3,RY),e(RY,qRr),e(V3,NRr),e($e,jRr),e($e,X3),e(X3,D4e),e(D4e,DRr),e(X3,GRr),e(X3,PY),e(PY,ORr),e(X3,VRr),e($e,XRr),e($e,z3),e(z3,G4e),e(G4e,zRr),e(z3,WRr),e(z3,BY),e(BY,QRr),e(z3,HRr),e($e,URr),e($e,W3),e(W3,O4e),e(O4e,JRr),e(W3,YRr),e(W3,IY),e(IY,KRr),e(W3,ZRr),e($e,ePr),e($e,Q3),e(Q3,V4e),e(V4e,oPr),e(Q3,rPr),e(Q3,qY),e(qY,tPr),e(Q3,aPr),e(Xr,nPr),M(H3,Xr,null),b(f,LNe,_),b(f,Wc,_),e(Wc,U3),e(U3,X4e),M(Nx,X4e,null),e(Wc,sPr),e(Wc,z4e),e(z4e,lPr),b(f,xNe,_),b(f,_r,_),M(jx,_r,null),e(_r,iPr),e(_r,Qc),e(Qc,dPr),e(Qc,NY),e(NY,cPr),e(Qc,fPr),e(Qc,jY),e(jY,mPr),e(Qc,gPr),e(_r,hPr),e(_r,Dx),e(Dx,pPr),e(Dx,W4e),e(W4e,uPr),e(Dx,_Pr),e(_r,bPr),e(_r,Qt),M(Gx,Qt,null),e(Qt,vPr),e(Qt,Q4e),e(Q4e,FPr),e(Qt,TPr),e(Qt,Hc),e(Hc,MPr),e(Hc,H4e),e(H4e,EPr),e(Hc,CPr),e(Hc,DY),e(DY,wPr),e(Hc,APr),e(Qt,yPr),M(J3,Qt,null),e(_r,LPr),e(_r,zr),M(Ox,zr,null),e(zr,xPr),e(zr,U4e),e(U4e,$Pr),e(zr,kPr),e(zr,Fn),e(Fn,SPr),e(Fn,J4e),e(J4e,RPr),e(Fn,PPr),e(Fn,Y4e),e(Y4e,BPr),e(Fn,IPr),e(Fn,K4e),e(K4e,qPr),e(Fn,NPr),e(zr,jPr),e(zr,ke),e(ke,Y3),e(Y3,Z4e),e(Z4e,DPr),e(Y3,GPr),e(Y3,GY),e(GY,OPr),e(Y3,VPr),e(ke,XPr),e(ke,K3),e(K3,eEe),e(eEe,zPr),e(K3,WPr),e(K3,OY),e(OY,QPr),e(K3,HPr),e(ke,UPr),e(ke,Z3),e(Z3,oEe),e(oEe,JPr),e(Z3,YPr),e(Z3,VY),e(VY,KPr),e(Z3,ZPr),e(ke,eBr),e(ke,ew),e(ew,rEe),e(rEe,oBr),e(ew,rBr),e(ew,XY),e(XY,tBr),e(ew,aBr),e(ke,nBr),e(ke,ow),e(ow,tEe),e(tEe,sBr),e(ow,lBr),e(ow,zY),e(zY,iBr),e(ow,dBr),e(ke,cBr),e(ke,rw),e(rw,aEe),e(aEe,fBr),e(rw,mBr),e(rw,WY),e(WY,gBr),e(rw,hBr),e(ke,pBr),e(ke,tw),e(tw,nEe),e(nEe,uBr),e(tw,_Br),e(tw,QY),e(QY,bBr),e(tw,vBr),e(ke,FBr),e(ke,aw),e(aw,sEe),e(sEe,TBr),e(aw,MBr),e(aw,HY),e(HY,EBr),e(aw,CBr),e(ke,wBr),e(ke,nw),e(nw,lEe),e(lEe,ABr),e(nw,yBr),e(nw,UY),e(UY,LBr),e(nw,xBr),e(ke,$Br),e(ke,sw),e(sw,iEe),e(iEe,kBr),e(sw,SBr),e(sw,JY),e(JY,RBr),e(sw,PBr),e(zr,BBr),M(lw,zr,null),b(f,$Ne,_),b(f,Uc,_),e(Uc,iw),e(iw,dEe),M(Vx,dEe,null),e(Uc,IBr),e(Uc,cEe),e(cEe,qBr),b(f,kNe,_),b(f,br,_),M(Xx,br,null),e(br,NBr),e(br,Jc),e(Jc,jBr),e(Jc,YY),e(YY,DBr),e(Jc,GBr),e(Jc,KY),e(KY,OBr),e(Jc,VBr),e(br,XBr),e(br,zx),e(zx,zBr),e(zx,fEe),e(fEe,WBr),e(zx,QBr),e(br,HBr),e(br,Ht),M(Wx,Ht,null),e(Ht,UBr),e(Ht,mEe),e(mEe,JBr),e(Ht,YBr),e(Ht,Yc),e(Yc,KBr),e(Yc,gEe),e(gEe,ZBr),e(Yc,eIr),e(Yc,ZY),e(ZY,oIr),e(Yc,rIr),e(Ht,tIr),M(dw,Ht,null),e(br,aIr),e(br,Wr),M(Qx,Wr,null),e(Wr,nIr),e(Wr,hEe),e(hEe,sIr),e(Wr,lIr),e(Wr,Tn),e(Tn,iIr),e(Tn,pEe),e(pEe,dIr),e(Tn,cIr),e(Tn,uEe),e(uEe,fIr),e(Tn,mIr),e(Tn,_Ee),e(_Ee,gIr),e(Tn,hIr),e(Wr,pIr),e(Wr,Ge),e(Ge,cw),e(cw,bEe),e(bEe,uIr),e(cw,_Ir),e(cw,eK),e(eK,bIr),e(cw,vIr),e(Ge,FIr),e(Ge,fw),e(fw,vEe),e(vEe,TIr),e(fw,MIr),e(fw,oK),e(oK,EIr),e(fw,CIr),e(Ge,wIr),e(Ge,mw),e(mw,FEe),e(FEe,AIr),e(mw,yIr),e(mw,rK),e(rK,LIr),e(mw,xIr),e(Ge,$Ir),e(Ge,gw),e(gw,TEe),e(TEe,kIr),e(gw,SIr),e(gw,tK),e(tK,RIr),e(gw,PIr),e(Ge,BIr),e(Ge,hw),e(hw,MEe),e(MEe,IIr),e(hw,qIr),e(hw,aK),e(aK,NIr),e(hw,jIr),e(Ge,DIr),e(Ge,pw),e(pw,EEe),e(EEe,GIr),e(pw,OIr),e(pw,nK),e(nK,VIr),e(pw,XIr),e(Ge,zIr),e(Ge,uw),e(uw,CEe),e(CEe,WIr),e(uw,QIr),e(uw,sK),e(sK,HIr),e(uw,UIr),e(Ge,JIr),e(Ge,_w),e(_w,wEe),e(wEe,YIr),e(_w,KIr),e(_w,lK),e(lK,ZIr),e(_w,eqr),e(Wr,oqr),M(bw,Wr,null),b(f,SNe,_),b(f,Kc,_),e(Kc,vw),e(vw,AEe),M(Hx,AEe,null),e(Kc,rqr),e(Kc,yEe),e(yEe,tqr),b(f,RNe,_),b(f,vr,_),M(Ux,vr,null),e(vr,aqr),e(vr,Zc),e(Zc,nqr),e(Zc,iK),e(iK,sqr),e(Zc,lqr),e(Zc,dK),e(dK,iqr),e(Zc,dqr),e(vr,cqr),e(vr,Jx),e(Jx,fqr),e(Jx,LEe),e(LEe,mqr),e(Jx,gqr),e(vr,hqr),e(vr,Ut),M(Yx,Ut,null),e(Ut,pqr),e(Ut,xEe),e(xEe,uqr),e(Ut,_qr),e(Ut,ef),e(ef,bqr),e(ef,$Ee),e($Ee,vqr),e(ef,Fqr),e(ef,cK),e(cK,Tqr),e(ef,Mqr),e(Ut,Eqr),M(Fw,Ut,null),e(vr,Cqr),e(vr,Qr),M(Kx,Qr,null),e(Qr,wqr),e(Qr,kEe),e(kEe,Aqr),e(Qr,yqr),e(Qr,Mn),e(Mn,Lqr),e(Mn,SEe),e(SEe,xqr),e(Mn,$qr),e(Mn,REe),e(REe,kqr),e(Mn,Sqr),e(Mn,PEe),e(PEe,Rqr),e(Mn,Pqr),e(Qr,Bqr),e(Qr,Oe),e(Oe,Tw),e(Tw,BEe),e(BEe,Iqr),e(Tw,qqr),e(Tw,fK),e(fK,Nqr),e(Tw,jqr),e(Oe,Dqr),e(Oe,Mw),e(Mw,IEe),e(IEe,Gqr),e(Mw,Oqr),e(Mw,mK),e(mK,Vqr),e(Mw,Xqr),e(Oe,zqr),e(Oe,Ew),e(Ew,qEe),e(qEe,Wqr),e(Ew,Qqr),e(Ew,gK),e(gK,Hqr),e(Ew,Uqr),e(Oe,Jqr),e(Oe,Cw),e(Cw,NEe),e(NEe,Yqr),e(Cw,Kqr),e(Cw,hK),e(hK,Zqr),e(Cw,eNr),e(Oe,oNr),e(Oe,ww),e(ww,jEe),e(jEe,rNr),e(ww,tNr),e(ww,pK),e(pK,aNr),e(ww,nNr),e(Oe,sNr),e(Oe,Aw),e(Aw,DEe),e(DEe,lNr),e(Aw,iNr),e(Aw,uK),e(uK,dNr),e(Aw,cNr),e(Oe,fNr),e(Oe,yw),e(yw,GEe),e(GEe,mNr),e(yw,gNr),e(yw,_K),e(_K,hNr),e(yw,pNr),e(Oe,uNr),e(Oe,Lw),e(Lw,OEe),e(OEe,_Nr),e(Lw,bNr),e(Lw,bK),e(bK,vNr),e(Lw,FNr),e(Qr,TNr),M(xw,Qr,null),b(f,PNe,_),b(f,of,_),e(of,$w),e($w,VEe),M(Zx,VEe,null),e(of,MNr),e(of,XEe),e(XEe,ENr),b(f,BNe,_),b(f,Fr,_),M(e9,Fr,null),e(Fr,CNr),e(Fr,rf),e(rf,wNr),e(rf,vK),e(vK,ANr),e(rf,yNr),e(rf,FK),e(FK,LNr),e(rf,xNr),e(Fr,$Nr),e(Fr,o9),e(o9,kNr),e(o9,zEe),e(zEe,SNr),e(o9,RNr),e(Fr,PNr),e(Fr,Jt),M(r9,Jt,null),e(Jt,BNr),e(Jt,WEe),e(WEe,INr),e(Jt,qNr),e(Jt,tf),e(tf,NNr),e(tf,QEe),e(QEe,jNr),e(tf,DNr),e(tf,TK),e(TK,GNr),e(tf,ONr),e(Jt,VNr),M(kw,Jt,null),e(Fr,XNr),e(Fr,Hr),M(t9,Hr,null),e(Hr,zNr),e(Hr,HEe),e(HEe,WNr),e(Hr,QNr),e(Hr,En),e(En,HNr),e(En,UEe),e(UEe,UNr),e(En,JNr),e(En,JEe),e(JEe,YNr),e(En,KNr),e(En,YEe),e(YEe,ZNr),e(En,ejr),e(Hr,ojr),e(Hr,KEe),e(KEe,Sw),e(Sw,ZEe),e(ZEe,rjr),e(Sw,tjr),e(Sw,MK),e(MK,ajr),e(Sw,njr),e(Hr,sjr),M(Rw,Hr,null),b(f,INe,_),b(f,af,_),e(af,Pw),e(Pw,eCe),M(a9,eCe,null),e(af,ljr),e(af,oCe),e(oCe,ijr),b(f,qNe,_),b(f,Tr,_),M(n9,Tr,null),e(Tr,djr),e(Tr,nf),e(nf,cjr),e(nf,EK),e(EK,fjr),e(nf,mjr),e(nf,CK),e(CK,gjr),e(nf,hjr),e(Tr,pjr),e(Tr,s9),e(s9,ujr),e(s9,rCe),e(rCe,_jr),e(s9,bjr),e(Tr,vjr),e(Tr,Yt),M(l9,Yt,null),e(Yt,Fjr),e(Yt,tCe),e(tCe,Tjr),e(Yt,Mjr),e(Yt,sf),e(sf,Ejr),e(sf,aCe),e(aCe,Cjr),e(sf,wjr),e(sf,wK),e(wK,Ajr),e(sf,yjr),e(Yt,Ljr),M(Bw,Yt,null),e(Tr,xjr),e(Tr,Ur),M(i9,Ur,null),e(Ur,$jr),e(Ur,nCe),e(nCe,kjr),e(Ur,Sjr),e(Ur,Cn),e(Cn,Rjr),e(Cn,sCe),e(sCe,Pjr),e(Cn,Bjr),e(Cn,lCe),e(lCe,Ijr),e(Cn,qjr),e(Cn,iCe),e(iCe,Njr),e(Cn,jjr),e(Ur,Djr),e(Ur,d9),e(d9,Iw),e(Iw,dCe),e(dCe,Gjr),e(Iw,Ojr),e(Iw,AK),e(AK,Vjr),e(Iw,Xjr),e(d9,zjr),e(d9,qw),e(qw,cCe),e(cCe,Wjr),e(qw,Qjr),e(qw,yK),e(yK,Hjr),e(qw,Ujr),e(Ur,Jjr),M(Nw,Ur,null),b(f,NNe,_),b(f,lf,_),e(lf,jw),e(jw,fCe),M(c9,fCe,null),e(lf,Yjr),e(lf,mCe),e(mCe,Kjr),b(f,jNe,_),b(f,Mr,_),M(f9,Mr,null),e(Mr,Zjr),e(Mr,df),e(df,eDr),e(df,LK),e(LK,oDr),e(df,rDr),e(df,xK),e(xK,tDr),e(df,aDr),e(Mr,nDr),e(Mr,m9),e(m9,sDr),e(m9,gCe),e(gCe,lDr),e(m9,iDr),e(Mr,dDr),e(Mr,Kt),M(g9,Kt,null),e(Kt,cDr),e(Kt,hCe),e(hCe,fDr),e(Kt,mDr),e(Kt,cf),e(cf,gDr),e(cf,pCe),e(pCe,hDr),e(cf,pDr),e(cf,$K),e($K,uDr),e(cf,_Dr),e(Kt,bDr),M(Dw,Kt,null),e(Mr,vDr),e(Mr,Jr),M(h9,Jr,null),e(Jr,FDr),e(Jr,uCe),e(uCe,TDr),e(Jr,MDr),e(Jr,wn),e(wn,EDr),e(wn,_Ce),e(_Ce,CDr),e(wn,wDr),e(wn,bCe),e(bCe,ADr),e(wn,yDr),e(wn,vCe),e(vCe,LDr),e(wn,xDr),e(Jr,$Dr),e(Jr,FCe),e(FCe,Gw),e(Gw,TCe),e(TCe,kDr),e(Gw,SDr),e(Gw,kK),e(kK,RDr),e(Gw,PDr),e(Jr,BDr),M(Ow,Jr,null),DNe=!0},p(f,[_]){const p9={};_&2&&(p9.$$scope={dirty:_,ctx:f}),vf.$set(p9);const MCe={};_&2&&(MCe.$$scope={dirty:_,ctx:f}),bg.$set(MCe);const ECe={};_&2&&(ECe.$$scope={dirty:_,ctx:f}),Kg.$set(ECe);const CCe={};_&2&&(CCe.$$scope={dirty:_,ctx:f}),yh.$set(CCe);const u9={};_&2&&(u9.$$scope={dirty:_,ctx:f}),Lh.$set(u9);const wCe={};_&2&&(wCe.$$scope={dirty:_,ctx:f}),Qh.$set(wCe);const An={};_&2&&(An.$$scope={dirty:_,ctx:f}),Hh.$set(An);const ACe={};_&2&&(ACe.$$scope={dirty:_,ctx:f}),Yh.$set(ACe);const yCe={};_&2&&(yCe.$$scope={dirty:_,ctx:f}),Ou.$set(yCe);const LCe={};_&2&&(LCe.$$scope={dirty:_,ctx:f}),Xu.$set(LCe);const _9={};_&2&&(_9.$$scope={dirty:_,ctx:f}),R_.$set(_9);const xCe={};_&2&&(xCe.$$scope={dirty:_,ctx:f}),B_.$set(xCe);const b9={};_&2&&(b9.$$scope={dirty:_,ctx:f}),v2.$set(b9);const $Ce={};_&2&&($Ce.$$scope={dirty:_,ctx:f}),T2.$set($Ce);const v9={};_&2&&(v9.$$scope={dirty:_,ctx:f}),a1.$set(v9);const kCe={};_&2&&(kCe.$$scope={dirty:_,ctx:f}),s1.$set(kCe);const SCe={};_&2&&(SCe.$$scope={dirty:_,ctx:f}),C1.$set(SCe);const RCe={};_&2&&(RCe.$$scope={dirty:_,ctx:f}),A1.$set(RCe);const ff={};_&2&&(ff.$$scope={dirty:_,ctx:f}),F7.$set(ff);const PCe={};_&2&&(PCe.$$scope={dirty:_,ctx:f}),M7.$set(PCe);const BCe={};_&2&&(BCe.$$scope={dirty:_,ctx:f}),Z7.$set(BCe);const ICe={};_&2&&(ICe.$$scope={dirty:_,ctx:f}),ob.$set(ICe);const F9={};_&2&&(F9.$$scope={dirty:_,ctx:f}),ib.$set(F9);const qCe={};_&2&&(qCe.$$scope={dirty:_,ctx:f}),cb.$set(qCe);const NCe={};_&2&&(NCe.$$scope={dirty:_,ctx:f}),zb.$set(NCe);const jCe={};_&2&&(jCe.$$scope={dirty:_,ctx:f}),Qb.$set(jCe);const et={};_&2&&(et.$$scope={dirty:_,ctx:f}),Pv.$set(et);const T9={};_&2&&(T9.$$scope={dirty:_,ctx:f}),Iv.$set(T9);const DCe={};_&2&&(DCe.$$scope={dirty:_,ctx:f}),jv.$set(DCe);const M9={};_&2&&(M9.$$scope={dirty:_,ctx:f}),Gv.$set(M9);const GCe={};_&2&&(GCe.$$scope={dirty:_,ctx:f}),eF.$set(GCe);const ot={};_&2&&(ot.$$scope={dirty:_,ctx:f}),rF.$set(ot);const OCe={};_&2&&(OCe.$$scope={dirty:_,ctx:f}),nF.$set(OCe);const mf={};_&2&&(mf.$$scope={dirty:_,ctx:f}),lF.$set(mf);const VCe={};_&2&&(VCe.$$scope={dirty:_,ctx:f}),bF.$set(VCe);const XCe={};_&2&&(XCe.$$scope={dirty:_,ctx:f}),FF.$set(XCe);const y={};_&2&&(y.$$scope={dirty:_,ctx:f}),yF.$set(y);const Vw={};_&2&&(Vw.$$scope={dirty:_,ctx:f}),xF.$set(Vw);const zCe={};_&2&&(zCe.$$scope={dirty:_,ctx:f}),DF.$set(zCe);const WCe={};_&2&&(WCe.$$scope={dirty:_,ctx:f}),OF.$set(WCe);const Xw={};_&2&&(Xw.$$scope={dirty:_,ctx:f}),WF.$set(Xw);const QCe={};_&2&&(QCe.$$scope={dirty:_,ctx:f}),HF.$set(QCe);const HCe={};_&2&&(HCe.$$scope={dirty:_,ctx:f}),oT.$set(HCe);const zw={};_&2&&(zw.$$scope={dirty:_,ctx:f}),tT.$set(zw);const UCe={};_&2&&(UCe.$$scope={dirty:_,ctx:f}),iT.$set(UCe);const JCe={};_&2&&(JCe.$$scope={dirty:_,ctx:f}),cT.$set(JCe);const Ww={};_&2&&(Ww.$$scope={dirty:_,ctx:f}),hT.$set(Ww);const YCe={};_&2&&(YCe.$$scope={dirty:_,ctx:f}),uT.$set(YCe);const KCe={};_&2&&(KCe.$$scope={dirty:_,ctx:f}),vT.$set(KCe);const Qw={};_&2&&(Qw.$$scope={dirty:_,ctx:f}),TT.$set(Qw);const ZCe={};_&2&&(ZCe.$$scope={dirty:_,ctx:f}),yT.$set(ZCe);const e5e={};_&2&&(e5e.$$scope={dirty:_,ctx:f}),xT.$set(e5e);const Hw={};_&2&&(Hw.$$scope={dirty:_,ctx:f}),ST.$set(Hw);const o5e={};_&2&&(o5e.$$scope={dirty:_,ctx:f}),PT.$set(o5e);const r5e={};_&2&&(r5e.$$scope={dirty:_,ctx:f}),yM.$set(r5e);const Uw={};_&2&&(Uw.$$scope={dirty:_,ctx:f}),xM.$set(Uw);const t5e={};_&2&&(t5e.$$scope={dirty:_,ctx:f}),ZM.$set(t5e);const a5e={};_&2&&(a5e.$$scope={dirty:_,ctx:f}),o4.$set(a5e);const Jw={};_&2&&(Jw.$$scope={dirty:_,ctx:f}),h4.$set(Jw);const n5e={};_&2&&(n5e.$$scope={dirty:_,ctx:f}),u4.$set(n5e);const s5e={};_&2&&(s5e.$$scope={dirty:_,ctx:f}),T4.$set(s5e);const Yw={};_&2&&(Yw.$$scope={dirty:_,ctx:f}),E4.$set(Yw);const l5e={};_&2&&(l5e.$$scope={dirty:_,ctx:f}),X4.$set(l5e);const i5e={};_&2&&(i5e.$$scope={dirty:_,ctx:f}),W4.$set(i5e);const Kw={};_&2&&(Kw.$$scope={dirty:_,ctx:f}),tE.$set(Kw);const d5e={};_&2&&(d5e.$$scope={dirty:_,ctx:f}),nE.$set(d5e);const c5e={};_&2&&(c5e.$$scope={dirty:_,ctx:f}),SE.$set(c5e);const Zw={};_&2&&(Zw.$$scope={dirty:_,ctx:f}),PE.$set(Zw);const f5e={};_&2&&(f5e.$$scope={dirty:_,ctx:f}),KE.$set(f5e);const m5e={};_&2&&(m5e.$$scope={dirty:_,ctx:f}),eC.$set(m5e);const eA={};_&2&&(eA.$$scope={dirty:_,ctx:f}),tC.$set(eA);const g5e={};_&2&&(g5e.$$scope={dirty:_,ctx:f}),nC.$set(g5e);const h5e={};_&2&&(h5e.$$scope={dirty:_,ctx:f}),lC.$set(h5e);const oA={};_&2&&(oA.$$scope={dirty:_,ctx:f}),dC.$set(oA);const p5e={};_&2&&(p5e.$$scope={dirty:_,ctx:f}),$C.$set(p5e);const u5e={};_&2&&(u5e.$$scope={dirty:_,ctx:f}),SC.$set(u5e);const rA={};_&2&&(rA.$$scope={dirty:_,ctx:f}),ZC.$set(rA);const _5e={};_&2&&(_5e.$$scope={dirty:_,ctx:f}),o5.$set(_5e);const b5e={};_&2&&(b5e.$$scope={dirty:_,ctx:f}),t5.$set(b5e);const tA={};_&2&&(tA.$$scope={dirty:_,ctx:f}),n5.$set(tA);const v5e={};_&2&&(v5e.$$scope={dirty:_,ctx:f}),l5.$set(v5e);const F5e={};_&2&&(F5e.$$scope={dirty:_,ctx:f}),d5.$set(F5e);const aA={};_&2&&(aA.$$scope={dirty:_,ctx:f}),I5.$set(aA);const T5e={};_&2&&(T5e.$$scope={dirty:_,ctx:f}),N5.$set(T5e);const M5e={};_&2&&(M5e.$$scope={dirty:_,ctx:f}),U5.$set(M5e);const nA={};_&2&&(nA.$$scope={dirty:_,ctx:f}),Y5.$set(nA);const E5e={};_&2&&(E5e.$$scope={dirty:_,ctx:f}),c3.$set(E5e);const C5e={};_&2&&(C5e.$$scope={dirty:_,ctx:f}),m3.$set(C5e);const sA={};_&2&&(sA.$$scope={dirty:_,ctx:f}),E3.$set(sA);const w5e={};_&2&&(w5e.$$scope={dirty:_,ctx:f}),w3.$set(w5e);const A5e={};_&2&&(A5e.$$scope={dirty:_,ctx:f}),B3.$set(A5e);const lA={};_&2&&(lA.$$scope={dirty:_,ctx:f}),q3.$set(lA);const y5e={};_&2&&(y5e.$$scope={dirty:_,ctx:f}),H3.$set(y5e);const L5e={};_&2&&(L5e.$$scope={dirty:_,ctx:f}),J3.$set(L5e);const iA={};_&2&&(iA.$$scope={dirty:_,ctx:f}),lw.$set(iA);const x5e={};_&2&&(x5e.$$scope={dirty:_,ctx:f}),dw.$set(x5e);const $5e={};_&2&&($5e.$$scope={dirty:_,ctx:f}),bw.$set($5e);const dA={};_&2&&(dA.$$scope={dirty:_,ctx:f}),Fw.$set(dA);const k5e={};_&2&&(k5e.$$scope={dirty:_,ctx:f}),xw.$set(k5e);const S5e={};_&2&&(S5e.$$scope={dirty:_,ctx:f}),kw.$set(S5e);const cA={};_&2&&(cA.$$scope={dirty:_,ctx:f}),Rw.$set(cA);const R5e={};_&2&&(R5e.$$scope={dirty:_,ctx:f}),Bw.$set(R5e);const P5e={};_&2&&(P5e.$$scope={dirty:_,ctx:f}),Nw.$set(P5e);const fA={};_&2&&(fA.$$scope={dirty:_,ctx:f}),Dw.$set(fA);const B5e={};_&2&&(B5e.$$scope={dirty:_,ctx:f}),Ow.$set(B5e)},i(f){DNe||(E(d.$$.fragment,f),E(Ca.$$.fragment,f),E(c6.$$.fragment,f),E(f6.$$.fragment,f),E(vf.$$.fragment,f),E(m6.$$.fragment,f),E(g6.$$.fragment,f),E(u6.$$.fragment,f),E(bg.$$.fragment,f),E(_6.$$.fragment,f),E(b6.$$.fragment,f),E(v6.$$.fragment,f),E(M6.$$.fragment,f),E(Kg.$$.fragment,f),E(E6.$$.fragment,f),E(C6.$$.fragment,f),E(w6.$$.fragment,f),E(L6.$$.fragment,f),E(yh.$$.fragment,f),E(Lh.$$.fragment,f),E(x6.$$.fragment,f),E($6.$$.fragment,f),E(k6.$$.fragment,f),E(P6.$$.fragment,f),E(Qh.$$.fragment,f),E(Hh.$$.fragment,f),E(B6.$$.fragment,f),E(I6.$$.fragment,f),E(q6.$$.fragment,f),E(j6.$$.fragment,f),E(Yh.$$.fragment,f),E(D6.$$.fragment,f),E(Ou.$$.fragment,f),E(G6.$$.fragment,f),E(O6.$$.fragment,f),E(X6.$$.fragment,f),E(Xu.$$.fragment,f),E(z6.$$.fragment,f),E(R_.$$.fragment,f),E(W6.$$.fragment,f),E(Q6.$$.fragment,f),E(U6.$$.fragment,f),E(B_.$$.fragment,f),E(J6.$$.fragment,f),E(v2.$$.fragment,f),E(Y6.$$.fragment,f),E(K6.$$.fragment,f),E(ey.$$.fragment,f),E(T2.$$.fragment,f),E(oy.$$.fragment,f),E(a1.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(ny.$$.fragment,f),E(s1.$$.fragment,f),E(sy.$$.fragment,f),E(C1.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(cy.$$.fragment,f),E(A1.$$.fragment,f),E(fy.$$.fragment,f),E(F7.$$.fragment,f),E(my.$$.fragment,f),E(gy.$$.fragment,f),E(py.$$.fragment,f),E(M7.$$.fragment,f),E(uy.$$.fragment,f),E(Z7.$$.fragment,f),E(_y.$$.fragment,f),E(by.$$.fragment,f),E(Fy.$$.fragment,f),E(ob.$$.fragment,f),E(Ty.$$.fragment,f),E(ib.$$.fragment,f),E(My.$$.fragment,f),E(Ey.$$.fragment,f),E(wy.$$.fragment,f),E(cb.$$.fragment,f),E(Ay.$$.fragment,f),E(zb.$$.fragment,f),E(yy.$$.fragment,f),E(Ly.$$.fragment,f),E($y.$$.fragment,f),E(Qb.$$.fragment,f),E(ky.$$.fragment,f),E(Pv.$$.fragment,f),E(Sy.$$.fragment,f),E(Ry.$$.fragment,f),E(By.$$.fragment,f),E(Iv.$$.fragment,f),E(Iy.$$.fragment,f),E(jv.$$.fragment,f),E(qy.$$.fragment,f),E(Ny.$$.fragment,f),E(Dy.$$.fragment,f),E(Gv.$$.fragment,f),E(Gy.$$.fragment,f),E(eF.$$.fragment,f),E(Oy.$$.fragment,f),E(Vy.$$.fragment,f),E(zy.$$.fragment,f),E(rF.$$.fragment,f),E(Wy.$$.fragment,f),E(nF.$$.fragment,f),E(Qy.$$.fragment,f),E(Hy.$$.fragment,f),E(Jy.$$.fragment,f),E(lF.$$.fragment,f),E(Yy.$$.fragment,f),E(bF.$$.fragment,f),E(Ky.$$.fragment,f),E(Zy.$$.fragment,f),E(oL.$$.fragment,f),E(FF.$$.fragment,f),E(rL.$$.fragment,f),E(yF.$$.fragment,f),E(tL.$$.fragment,f),E(aL.$$.fragment,f),E(sL.$$.fragment,f),E(xF.$$.fragment,f),E(lL.$$.fragment,f),E(DF.$$.fragment,f),E(iL.$$.fragment,f),E(dL.$$.fragment,f),E(fL.$$.fragment,f),E(OF.$$.fragment,f),E(mL.$$.fragment,f),E(WF.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(_L.$$.fragment,f),E(HF.$$.fragment,f),E(bL.$$.fragment,f),E(oT.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(tT.$$.fragment,f),E(EL.$$.fragment,f),E(iT.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(yL.$$.fragment,f),E(cT.$$.fragment,f),E(LL.$$.fragment,f),E(hT.$$.fragment,f),E($L.$$.fragment,f),E(kL.$$.fragment,f),E(RL.$$.fragment,f),E(uT.$$.fragment,f),E(PL.$$.fragment,f),E(vT.$$.fragment,f),E(BL.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(TT.$$.fragment,f),E(jL.$$.fragment,f),E(yT.$$.fragment,f),E(DL.$$.fragment,f),E(GL.$$.fragment,f),E(VL.$$.fragment,f),E(xT.$$.fragment,f),E(XL.$$.fragment,f),E(ST.$$.fragment,f),E(zL.$$.fragment,f),E(WL.$$.fragment,f),E(HL.$$.fragment,f),E(PT.$$.fragment,f),E(UL.$$.fragment,f),E(yM.$$.fragment,f),E(JL.$$.fragment,f),E(YL.$$.fragment,f),E(ZL.$$.fragment,f),E(xM.$$.fragment,f),E(e8.$$.fragment,f),E(ZM.$$.fragment,f),E(o8.$$.fragment,f),E(r8.$$.fragment,f),E(a8.$$.fragment,f),E(o4.$$.fragment,f),E(n8.$$.fragment,f),E(h4.$$.fragment,f),E(s8.$$.fragment,f),E(l8.$$.fragment,f),E(d8.$$.fragment,f),E(u4.$$.fragment,f),E(c8.$$.fragment,f),E(T4.$$.fragment,f),E(f8.$$.fragment,f),E(m8.$$.fragment,f),E(h8.$$.fragment,f),E(E4.$$.fragment,f),E(p8.$$.fragment,f),E(X4.$$.fragment,f),E(u8.$$.fragment,f),E(_8.$$.fragment,f),E(v8.$$.fragment,f),E(W4.$$.fragment,f),E(F8.$$.fragment,f),E(tE.$$.fragment,f),E(T8.$$.fragment,f),E(M8.$$.fragment,f),E(C8.$$.fragment,f),E(nE.$$.fragment,f),E(w8.$$.fragment,f),E(SE.$$.fragment,f),E(A8.$$.fragment,f),E(y8.$$.fragment,f),E(x8.$$.fragment,f),E(PE.$$.fragment,f),E($8.$$.fragment,f),E(KE.$$.fragment,f),E(k8.$$.fragment,f),E(S8.$$.fragment,f),E(P8.$$.fragment,f),E(eC.$$.fragment,f),E(B8.$$.fragment,f),E(tC.$$.fragment,f),E(q8.$$.fragment,f),E(N8.$$.fragment,f),E(D8.$$.fragment,f),E(nC.$$.fragment,f),E(G8.$$.fragment,f),E(lC.$$.fragment,f),E(O8.$$.fragment,f),E(V8.$$.fragment,f),E(z8.$$.fragment,f),E(dC.$$.fragment,f),E(W8.$$.fragment,f),E($C.$$.fragment,f),E(Q8.$$.fragment,f),E(H8.$$.fragment,f),E(J8.$$.fragment,f),E(SC.$$.fragment,f),E(Y8.$$.fragment,f),E(ZC.$$.fragment,f),E(K8.$$.fragment,f),E(Z8.$$.fragment,f),E(ox.$$.fragment,f),E(o5.$$.fragment,f),E(rx.$$.fragment,f),E(t5.$$.fragment,f),E(tx.$$.fragment,f),E(ax.$$.fragment,f),E(sx.$$.fragment,f),E(n5.$$.fragment,f),E(lx.$$.fragment,f),E(l5.$$.fragment,f),E(ix.$$.fragment,f),E(dx.$$.fragment,f),E(fx.$$.fragment,f),E(d5.$$.fragment,f),E(mx.$$.fragment,f),E(I5.$$.fragment,f),E(gx.$$.fragment,f),E(hx.$$.fragment,f),E(ux.$$.fragment,f),E(N5.$$.fragment,f),E(_x.$$.fragment,f),E(U5.$$.fragment,f),E(bx.$$.fragment,f),E(vx.$$.fragment,f),E(Tx.$$.fragment,f),E(Y5.$$.fragment,f),E(Mx.$$.fragment,f),E(c3.$$.fragment,f),E(Ex.$$.fragment,f),E(Cx.$$.fragment,f),E(Ax.$$.fragment,f),E(m3.$$.fragment,f),E(yx.$$.fragment,f),E(E3.$$.fragment,f),E(Lx.$$.fragment,f),E(xx.$$.fragment,f),E(kx.$$.fragment,f),E(w3.$$.fragment,f),E(Sx.$$.fragment,f),E(B3.$$.fragment,f),E(Rx.$$.fragment,f),E(Px.$$.fragment,f),E(Ix.$$.fragment,f),E(q3.$$.fragment,f),E(qx.$$.fragment,f),E(H3.$$.fragment,f),E(Nx.$$.fragment,f),E(jx.$$.fragment,f),E(Gx.$$.fragment,f),E(J3.$$.fragment,f),E(Ox.$$.fragment,f),E(lw.$$.fragment,f),E(Vx.$$.fragment,f),E(Xx.$$.fragment,f),E(Wx.$$.fragment,f),E(dw.$$.fragment,f),E(Qx.$$.fragment,f),E(bw.$$.fragment,f),E(Hx.$$.fragment,f),E(Ux.$$.fragment,f),E(Yx.$$.fragment,f),E(Fw.$$.fragment,f),E(Kx.$$.fragment,f),E(xw.$$.fragment,f),E(Zx.$$.fragment,f),E(e9.$$.fragment,f),E(r9.$$.fragment,f),E(kw.$$.fragment,f),E(t9.$$.fragment,f),E(Rw.$$.fragment,f),E(a9.$$.fragment,f),E(n9.$$.fragment,f),E(l9.$$.fragment,f),E(Bw.$$.fragment,f),E(i9.$$.fragment,f),E(Nw.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(Dw.$$.fragment,f),E(h9.$$.fragment,f),E(Ow.$$.fragment,f),DNe=!0)},o(f){C(d.$$.fragment,f),C(Ca.$$.fragment,f),C(c6.$$.fragment,f),C(f6.$$.fragment,f),C(vf.$$.fragment,f),C(m6.$$.fragment,f),C(g6.$$.fragment,f),C(u6.$$.fragment,f),C(bg.$$.fragment,f),C(_6.$$.fragment,f),C(b6.$$.fragment,f),C(v6.$$.fragment,f),C(M6.$$.fragment,f),C(Kg.$$.fragment,f),C(E6.$$.fragment,f),C(C6.$$.fragment,f),C(w6.$$.fragment,f),C(L6.$$.fragment,f),C(yh.$$.fragment,f),C(Lh.$$.fragment,f),C(x6.$$.fragment,f),C($6.$$.fragment,f),C(k6.$$.fragment,f),C(P6.$$.fragment,f),C(Qh.$$.fragment,f),C(Hh.$$.fragment,f),C(B6.$$.fragment,f),C(I6.$$.fragment,f),C(q6.$$.fragment,f),C(j6.$$.fragment,f),C(Yh.$$.fragment,f),C(D6.$$.fragment,f),C(Ou.$$.fragment,f),C(G6.$$.fragment,f),C(O6.$$.fragment,f),C(X6.$$.fragment,f),C(Xu.$$.fragment,f),C(z6.$$.fragment,f),C(R_.$$.fragment,f),C(W6.$$.fragment,f),C(Q6.$$.fragment,f),C(U6.$$.fragment,f),C(B_.$$.fragment,f),C(J6.$$.fragment,f),C(v2.$$.fragment,f),C(Y6.$$.fragment,f),C(K6.$$.fragment,f),C(ey.$$.fragment,f),C(T2.$$.fragment,f),C(oy.$$.fragment,f),C(a1.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(ny.$$.fragment,f),C(s1.$$.fragment,f),C(sy.$$.fragment,f),C(C1.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(cy.$$.fragment,f),C(A1.$$.fragment,f),C(fy.$$.fragment,f),C(F7.$$.fragment,f),C(my.$$.fragment,f),C(gy.$$.fragment,f),C(py.$$.fragment,f),C(M7.$$.fragment,f),C(uy.$$.fragment,f),C(Z7.$$.fragment,f),C(_y.$$.fragment,f),C(by.$$.fragment,f),C(Fy.$$.fragment,f),C(ob.$$.fragment,f),C(Ty.$$.fragment,f),C(ib.$$.fragment,f),C(My.$$.fragment,f),C(Ey.$$.fragment,f),C(wy.$$.fragment,f),C(cb.$$.fragment,f),C(Ay.$$.fragment,f),C(zb.$$.fragment,f),C(yy.$$.fragment,f),C(Ly.$$.fragment,f),C($y.$$.fragment,f),C(Qb.$$.fragment,f),C(ky.$$.fragment,f),C(Pv.$$.fragment,f),C(Sy.$$.fragment,f),C(Ry.$$.fragment,f),C(By.$$.fragment,f),C(Iv.$$.fragment,f),C(Iy.$$.fragment,f),C(jv.$$.fragment,f),C(qy.$$.fragment,f),C(Ny.$$.fragment,f),C(Dy.$$.fragment,f),C(Gv.$$.fragment,f),C(Gy.$$.fragment,f),C(eF.$$.fragment,f),C(Oy.$$.fragment,f),C(Vy.$$.fragment,f),C(zy.$$.fragment,f),C(rF.$$.fragment,f),C(Wy.$$.fragment,f),C(nF.$$.fragment,f),C(Qy.$$.fragment,f),C(Hy.$$.fragment,f),C(Jy.$$.fragment,f),C(lF.$$.fragment,f),C(Yy.$$.fragment,f),C(bF.$$.fragment,f),C(Ky.$$.fragment,f),C(Zy.$$.fragment,f),C(oL.$$.fragment,f),C(FF.$$.fragment,f),C(rL.$$.fragment,f),C(yF.$$.fragment,f),C(tL.$$.fragment,f),C(aL.$$.fragment,f),C(sL.$$.fragment,f),C(xF.$$.fragment,f),C(lL.$$.fragment,f),C(DF.$$.fragment,f),C(iL.$$.fragment,f),C(dL.$$.fragment,f),C(fL.$$.fragment,f),C(OF.$$.fragment,f),C(mL.$$.fragment,f),C(WF.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(_L.$$.fragment,f),C(HF.$$.fragment,f),C(bL.$$.fragment,f),C(oT.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(tT.$$.fragment,f),C(EL.$$.fragment,f),C(iT.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(yL.$$.fragment,f),C(cT.$$.fragment,f),C(LL.$$.fragment,f),C(hT.$$.fragment,f),C($L.$$.fragment,f),C(kL.$$.fragment,f),C(RL.$$.fragment,f),C(uT.$$.fragment,f),C(PL.$$.fragment,f),C(vT.$$.fragment,f),C(BL.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(TT.$$.fragment,f),C(jL.$$.fragment,f),C(yT.$$.fragment,f),C(DL.$$.fragment,f),C(GL.$$.fragment,f),C(VL.$$.fragment,f),C(xT.$$.fragment,f),C(XL.$$.fragment,f),C(ST.$$.fragment,f),C(zL.$$.fragment,f),C(WL.$$.fragment,f),C(HL.$$.fragment,f),C(PT.$$.fragment,f),C(UL.$$.fragment,f),C(yM.$$.fragment,f),C(JL.$$.fragment,f),C(YL.$$.fragment,f),C(ZL.$$.fragment,f),C(xM.$$.fragment,f),C(e8.$$.fragment,f),C(ZM.$$.fragment,f),C(o8.$$.fragment,f),C(r8.$$.fragment,f),C(a8.$$.fragment,f),C(o4.$$.fragment,f),C(n8.$$.fragment,f),C(h4.$$.fragment,f),C(s8.$$.fragment,f),C(l8.$$.fragment,f),C(d8.$$.fragment,f),C(u4.$$.fragment,f),C(c8.$$.fragment,f),C(T4.$$.fragment,f),C(f8.$$.fragment,f),C(m8.$$.fragment,f),C(h8.$$.fragment,f),C(E4.$$.fragment,f),C(p8.$$.fragment,f),C(X4.$$.fragment,f),C(u8.$$.fragment,f),C(_8.$$.fragment,f),C(v8.$$.fragment,f),C(W4.$$.fragment,f),C(F8.$$.fragment,f),C(tE.$$.fragment,f),C(T8.$$.fragment,f),C(M8.$$.fragment,f),C(C8.$$.fragment,f),C(nE.$$.fragment,f),C(w8.$$.fragment,f),C(SE.$$.fragment,f),C(A8.$$.fragment,f),C(y8.$$.fragment,f),C(x8.$$.fragment,f),C(PE.$$.fragment,f),C($8.$$.fragment,f),C(KE.$$.fragment,f),C(k8.$$.fragment,f),C(S8.$$.fragment,f),C(P8.$$.fragment,f),C(eC.$$.fragment,f),C(B8.$$.fragment,f),C(tC.$$.fragment,f),C(q8.$$.fragment,f),C(N8.$$.fragment,f),C(D8.$$.fragment,f),C(nC.$$.fragment,f),C(G8.$$.fragment,f),C(lC.$$.fragment,f),C(O8.$$.fragment,f),C(V8.$$.fragment,f),C(z8.$$.fragment,f),C(dC.$$.fragment,f),C(W8.$$.fragment,f),C($C.$$.fragment,f),C(Q8.$$.fragment,f),C(H8.$$.fragment,f),C(J8.$$.fragment,f),C(SC.$$.fragment,f),C(Y8.$$.fragment,f),C(ZC.$$.fragment,f),C(K8.$$.fragment,f),C(Z8.$$.fragment,f),C(ox.$$.fragment,f),C(o5.$$.fragment,f),C(rx.$$.fragment,f),C(t5.$$.fragment,f),C(tx.$$.fragment,f),C(ax.$$.fragment,f),C(sx.$$.fragment,f),C(n5.$$.fragment,f),C(lx.$$.fragment,f),C(l5.$$.fragment,f),C(ix.$$.fragment,f),C(dx.$$.fragment,f),C(fx.$$.fragment,f),C(d5.$$.fragment,f),C(mx.$$.fragment,f),C(I5.$$.fragment,f),C(gx.$$.fragment,f),C(hx.$$.fragment,f),C(ux.$$.fragment,f),C(N5.$$.fragment,f),C(_x.$$.fragment,f),C(U5.$$.fragment,f),C(bx.$$.fragment,f),C(vx.$$.fragment,f),C(Tx.$$.fragment,f),C(Y5.$$.fragment,f),C(Mx.$$.fragment,f),C(c3.$$.fragment,f),C(Ex.$$.fragment,f),C(Cx.$$.fragment,f),C(Ax.$$.fragment,f),C(m3.$$.fragment,f),C(yx.$$.fragment,f),C(E3.$$.fragment,f),C(Lx.$$.fragment,f),C(xx.$$.fragment,f),C(kx.$$.fragment,f),C(w3.$$.fragment,f),C(Sx.$$.fragment,f),C(B3.$$.fragment,f),C(Rx.$$.fragment,f),C(Px.$$.fragment,f),C(Ix.$$.fragment,f),C(q3.$$.fragment,f),C(qx.$$.fragment,f),C(H3.$$.fragment,f),C(Nx.$$.fragment,f),C(jx.$$.fragment,f),C(Gx.$$.fragment,f),C(J3.$$.fragment,f),C(Ox.$$.fragment,f),C(lw.$$.fragment,f),C(Vx.$$.fragment,f),C(Xx.$$.fragment,f),C(Wx.$$.fragment,f),C(dw.$$.fragment,f),C(Qx.$$.fragment,f),C(bw.$$.fragment,f),C(Hx.$$.fragment,f),C(Ux.$$.fragment,f),C(Yx.$$.fragment,f),C(Fw.$$.fragment,f),C(Kx.$$.fragment,f),C(xw.$$.fragment,f),C(Zx.$$.fragment,f),C(e9.$$.fragment,f),C(r9.$$.fragment,f),C(kw.$$.fragment,f),C(t9.$$.fragment,f),C(Rw.$$.fragment,f),C(a9.$$.fragment,f),C(n9.$$.fragment,f),C(l9.$$.fragment,f),C(Bw.$$.fragment,f),C(i9.$$.fragment,f),C(Nw.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(Dw.$$.fragment,f),C(h9.$$.fragment,f),C(Ow.$$.fragment,f),DNe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(hf),f&&t(rt),f&&t(De),f&&t(We),f&&t(uf),w(Ca,f),f&&t(Qe),f&&t(Ae),f&&t(Eo),f&&t(wa),f&&t(qIe),f&&t(_i),w(c6),f&&t(NIe),f&&t(kn),f&&t(jIe),w(f6,f),f&&t(DIe),f&&t(S$),f&&t(GIe),w(vf,f),f&&t(OIe),f&&t(bi),w(m6),f&&t(VIe),f&&t(Co),w(g6),w(u6),w(bg),w(_6),f&&t(XIe),f&&t(Fi),w(b6),f&&t(zIe),f&&t(wo),w(v6),w(M6),w(Kg),w(E6),f&&t(WIe),f&&t(Ti),w(C6),f&&t(QIe),f&&t(Ao),w(w6),w(L6),w(yh),w(Lh),w(x6),f&&t(HIe),f&&t(Mi),w($6),f&&t(UIe),f&&t(yo),w(k6),w(P6),w(Qh),w(Hh),w(B6),f&&t(JIe),f&&t(Ci),w(I6),f&&t(YIe),f&&t(Lo),w(q6),w(j6),w(Yh),w(D6),w(Ou),f&&t(KIe),f&&t(yi),w(G6),f&&t(ZIe),f&&t(xo),w(O6),w(X6),w(Xu),w(z6),w(R_),f&&t(eqe),f&&t($i),w(W6),f&&t(oqe),f&&t($o),w(Q6),w(U6),w(B_),w(J6),w(v2),f&&t(rqe),f&&t(Ri),w(Y6),f&&t(tqe),f&&t(ko),w(K6),w(ey),w(T2),w(oy),w(a1),f&&t(aqe),f&&t(Ii),w(ry),f&&t(nqe),f&&t(So),w(ty),w(ny),w(s1),w(sy),w(C1),f&&t(sqe),f&&t(ji),w(ly),f&&t(lqe),f&&t(Ro),w(iy),w(cy),w(A1),w(fy),w(F7),f&&t(iqe),f&&t(Oi),w(my),f&&t(dqe),f&&t(Po),w(gy),w(py),w(M7),w(uy),w(Z7),f&&t(cqe),f&&t(zi),w(_y),f&&t(fqe),f&&t(Bo),w(by),w(Fy),w(ob),w(Ty),w(ib),f&&t(mqe),f&&t(Hi),w(My),f&&t(gqe),f&&t(Io),w(Ey),w(wy),w(cb),w(Ay),w(zb),f&&t(hqe),f&&t(Yi),w(yy),f&&t(pqe),f&&t(qo),w(Ly),w($y),w(Qb),w(ky),w(Pv),f&&t(uqe),f&&t(ed),w(Sy),f&&t(_qe),f&&t(No),w(Ry),w(By),w(Iv),w(Iy),w(jv),f&&t(bqe),f&&t(td),w(qy),f&&t(vqe),f&&t(jo),w(Ny),w(Dy),w(Gv),w(Gy),w(eF),f&&t(Fqe),f&&t(sd),w(Oy),f&&t(Tqe),f&&t(Do),w(Vy),w(zy),w(rF),w(Wy),w(nF),f&&t(Mqe),f&&t(dd),w(Qy),f&&t(Eqe),f&&t(Go),w(Hy),w(Jy),w(lF),w(Yy),w(bF),f&&t(Cqe),f&&t(md),w(Ky),f&&t(wqe),f&&t(Oo),w(Zy),w(oL),w(FF),w(rL),w(yF),f&&t(Aqe),f&&t(pd),w(tL),f&&t(yqe),f&&t(Vo),w(aL),w(sL),w(xF),w(lL),w(DF),f&&t(Lqe),f&&t(bd),w(iL),f&&t(xqe),f&&t(Xo),w(dL),w(fL),w(OF),w(mL),w(WF),f&&t($qe),f&&t(Td),w(hL),f&&t(kqe),f&&t(zo),w(pL),w(_L),w(HF),w(bL),w(oT),f&&t(Sqe),f&&t(Cd),w(vL),f&&t(Rqe),f&&t(Wo),w(FL),w(ML),w(tT),w(EL),w(iT),f&&t(Pqe),f&&t(Ld),w(CL),f&&t(Bqe),f&&t(Qo),w(wL),w(yL),w(cT),w(LL),w(hT),f&&t(Iqe),f&&t(kd),w($L),f&&t(qqe),f&&t(Ho),w(kL),w(RL),w(uT),w(PL),w(vT),f&&t(Nqe),f&&t(Pd),w(BL),f&&t(jqe),f&&t(Uo),w(IL),w(NL),w(TT),w(jL),w(yT),f&&t(Dqe),f&&t(qd),w(DL),f&&t(Gqe),f&&t(Jo),w(GL),w(VL),w(xT),w(XL),w(ST),f&&t(Oqe),f&&t(Dd),w(zL),f&&t(Vqe),f&&t(Yo),w(WL),w(HL),w(PT),w(UL),w(yM),f&&t(Xqe),f&&t(Vd),w(JL),f&&t(zqe),f&&t(Ko),w(YL),w(ZL),w(xM),w(e8),w(ZM),f&&t(Wqe),f&&t(Wd),w(o8),f&&t(Qqe),f&&t(Zo),w(r8),w(a8),w(o4),w(n8),w(h4),f&&t(Hqe),f&&t(Ud),w(s8),f&&t(Uqe),f&&t(er),w(l8),w(d8),w(u4),w(c8),w(T4),f&&t(Jqe),f&&t(Kd),w(f8),f&&t(Yqe),f&&t(or),w(m8),w(h8),w(E4),w(p8),w(X4),f&&t(Kqe),f&&t(oc),w(u8),f&&t(Zqe),f&&t(rr),w(_8),w(v8),w(W4),w(F8),w(tE),f&&t(eNe),f&&t(ac),w(T8),f&&t(oNe),f&&t(tr),w(M8),w(C8),w(nE),w(w8),w(SE),f&&t(rNe),f&&t(lc),w(A8),f&&t(tNe),f&&t(ar),w(y8),w(x8),w(PE),w($8),w(KE),f&&t(aNe),f&&t(cc),w(k8),f&&t(nNe),f&&t(nr),w(S8),w(P8),w(eC),w(B8),w(tC),f&&t(sNe),f&&t(gc),w(q8),f&&t(lNe),f&&t(sr),w(N8),w(D8),w(nC),w(G8),w(lC),f&&t(iNe),f&&t(uc),w(O8),f&&t(dNe),f&&t(lr),w(V8),w(z8),w(dC),w(W8),w($C),f&&t(cNe),f&&t(vc),w(Q8),f&&t(fNe),f&&t(ir),w(H8),w(J8),w(SC),w(Y8),w(ZC),f&&t(mNe),f&&t(Mc),w(K8),f&&t(gNe),f&&t(dr),w(Z8),w(ox),w(o5),w(rx),w(t5),f&&t(hNe),f&&t(wc),w(tx),f&&t(pNe),f&&t(cr),w(ax),w(sx),w(n5),w(lx),w(l5),f&&t(uNe),f&&t(Lc),w(ix),f&&t(_Ne),f&&t(fr),w(dx),w(fx),w(d5),w(mx),w(I5),f&&t(bNe),f&&t(kc),w(gx),f&&t(vNe),f&&t(mr),w(hx),w(ux),w(N5),w(_x),w(U5),f&&t(FNe),f&&t(Pc),w(bx),f&&t(TNe),f&&t(gr),w(vx),w(Tx),w(Y5),w(Mx),w(c3),f&&t(MNe),f&&t(qc),w(Ex),f&&t(ENe),f&&t(hr),w(Cx),w(Ax),w(m3),w(yx),w(E3),f&&t(CNe),f&&t(Dc),w(Lx),f&&t(wNe),f&&t(pr),w(xx),w(kx),w(w3),w(Sx),w(B3),f&&t(ANe),f&&t(Vc),w(Rx),f&&t(yNe),f&&t(ur),w(Px),w(Ix),w(q3),w(qx),w(H3),f&&t(LNe),f&&t(Wc),w(Nx),f&&t(xNe),f&&t(_r),w(jx),w(Gx),w(J3),w(Ox),w(lw),f&&t($Ne),f&&t(Uc),w(Vx),f&&t(kNe),f&&t(br),w(Xx),w(Wx),w(dw),w(Qx),w(bw),f&&t(SNe),f&&t(Kc),w(Hx),f&&t(RNe),f&&t(vr),w(Ux),w(Yx),w(Fw),w(Kx),w(xw),f&&t(PNe),f&&t(of),w(Zx),f&&t(BNe),f&&t(Fr),w(e9),w(r9),w(kw),w(t9),w(Rw),f&&t(INe),f&&t(af),w(a9),f&&t(qNe),f&&t(Tr),w(n9),w(l9),w(Bw),w(i9),w(Nw),f&&t(NNe),f&&t(lf),w(c9),f&&t(jNe),f&&t(Mr),w(f9),w(g9),w(Dw),w(h9),w(Ow)}}}const Pxt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Bxt(L){return BLt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Oxt extends kLt{constructor(g){super();SLt(this,g,Bxt,Rxt,RLt,{})}}export{Oxt as default,Pxt as metadata};
