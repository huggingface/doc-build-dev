import{S as c8t,i as f8t,s as m8t,e as a,k as l,w as F,t as o,M as g8t,c as n,d as t,m as i,a as s,x as T,h as r,b as c,F as e,g as b,y as M,q as E,o as C,B as w,v as h8t,L as I}from"../../chunks/vendor-6b77c823.js";import{T as dGr}from"../../chunks/Tip-39098574.js";import{D as R}from"../../chunks/Docstring-1088f2fb.js";import{C as P}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as re}from"../../chunks/IconCopyLink-7a11ce68.js";import{E as B}from"../../chunks/ExampleCodeBlock-5212b321.js";function p8t(L){let g,v,p,m,_,d,h,Mo,ci,hf,rt,fi,mi,d6,pf,De,We,gi,yn,c6,Ln,xn,f6,hi,$n,m6,pi,_f,Ca;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),ci=a("code"),hf=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),fi=a("code"),mi=o('"new-model"'),d6=o(")."),pf=l(),De=a("p"),We=o("Likewise, if your "),gi=a("code"),yn=o("NewModel"),c6=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),f6=o(`, make sure its
`),hi=a("code"),$n=o("config_class"),m6=o(` attribute is set to the same class you use when registering the model (here
`),pi=a("code"),_f=o("NewModelConfig"),Ca=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var $$=s(p);m=r($$,"NewModelConfig"),$$.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var _i=s(d);h=r(_i,"PretrainedConfig"),_i.forEach(t),Mo=r(Ae,`, make sure its
`),ci=n(Ae,"CODE",{});var k$=s(ci);hf=r(k$,"model_type"),k$.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),fi=n(Ae,"CODE",{});var S$=s(fi);mi=r(S$,'"new-model"'),S$.forEach(t),d6=r(Ae,")."),Ae.forEach(t),pf=i(Qe),De=n(Qe,"P",{});var Eo=s(De);We=r(Eo,"Likewise, if your "),gi=n(Eo,"CODE",{});var wa=s(gi);yn=r(wa,"NewModel"),wa.forEach(t),c6=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var R$=s(Ln);xn=r(R$,"PreTrainedModel"),R$.forEach(t),f6=r(Eo,`, make sure its
`),hi=n(Eo,"CODE",{});var uf=s(hi);$n=r(uf,"config_class"),uf.forEach(t),m6=r(Eo,` attribute is set to the same class you use when registering the model (here
`),pi=n(Eo,"CODE",{});var P$=s(pi);_f=r(P$,"NewModelConfig"),P$.forEach(t),Ca=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Mo),e(g,ci),e(ci,hf),e(g,rt),e(g,fi),e(fi,mi),e(g,d6),b(Qe,pf,Ae),b(Qe,De,Ae),e(De,We),e(De,gi),e(gi,yn),e(De,c6),e(De,Ln),e(Ln,xn),e(De,f6),e(De,hi),e(hi,$n),e(De,m6),e(De,pi),e(pi,_f),e(De,Ca)},d(Qe){Qe&&t(g),Qe&&t(pf),Qe&&t(De)}}}function _8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function u8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function b8t(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function v8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function F8t(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function T8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function M8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function E8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function C8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function w8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function A8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function y8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function L8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function x8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function k8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function S8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function R8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function P8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function B8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function I8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function q8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function N8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function j8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function D8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function G8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function O8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function V8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function X8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function z8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function W8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Q8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function H8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function U8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function J8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Y8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function K8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Z8t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ext(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function txt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function axt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ixt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _xt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Txt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ext(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Axt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $xt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ixt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Oxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zxt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function e9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function o9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function r9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function t9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function a9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function n9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function s9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function l9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function i9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function d9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function c9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function f9t(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function m9t(L){let g,v,p,m,_,d,h,Mo,ci,hf,rt,fi,mi,d6,pf,De,We,gi,yn,c6,Ln,xn,f6,hi,$n,m6,pi,_f,Ca,Qe,Ae,$$,_i,k$,S$,Eo,wa,R$,uf,P$,sGe,UIe,ui,bf,$ee,g6,lGe,kee,iGe,JIe,kn,dGe,See,cGe,fGe,Ree,mGe,gGe,YIe,h6,KIe,B$,hGe,ZIe,vf,eqe,bi,Ff,Pee,p6,pGe,Bee,_Ge,oqe,Co,_6,uGe,u6,bGe,I$,vGe,FGe,TGe,b6,MGe,Iee,EGe,CGe,wGe,Er,v6,AGe,qee,yGe,LGe,vi,xGe,Nee,$Ge,kGe,jee,SGe,RGe,PGe,A,Tf,Dee,BGe,IGe,q$,qGe,NGe,jGe,Mf,Gee,DGe,GGe,N$,OGe,VGe,XGe,Ef,Oee,zGe,WGe,j$,QGe,HGe,UGe,Cf,Vee,JGe,YGe,D$,KGe,ZGe,eOe,wf,Xee,oOe,rOe,G$,tOe,aOe,nOe,Af,zee,sOe,lOe,O$,iOe,dOe,cOe,yf,Wee,fOe,mOe,V$,gOe,hOe,pOe,Lf,Qee,_Oe,uOe,X$,bOe,vOe,FOe,xf,Hee,TOe,MOe,z$,EOe,COe,wOe,$f,Uee,AOe,yOe,W$,LOe,xOe,$Oe,kf,Jee,kOe,SOe,Q$,ROe,POe,BOe,Sf,Yee,IOe,qOe,H$,NOe,jOe,DOe,Rf,Kee,GOe,OOe,U$,VOe,XOe,zOe,Pf,Zee,WOe,QOe,J$,HOe,UOe,JOe,Bf,eoe,YOe,KOe,Y$,ZOe,eVe,oVe,If,ooe,rVe,tVe,K$,aVe,nVe,sVe,qf,roe,lVe,iVe,Z$,dVe,cVe,fVe,Nf,toe,mVe,gVe,ek,hVe,pVe,_Ve,jf,aoe,uVe,bVe,ok,vVe,FVe,TVe,Df,noe,MVe,EVe,rk,CVe,wVe,AVe,Gf,soe,yVe,LVe,tk,xVe,$Ve,kVe,Of,loe,SVe,RVe,ak,PVe,BVe,IVe,Vf,ioe,qVe,NVe,nk,jVe,DVe,GVe,Xf,doe,OVe,VVe,sk,XVe,zVe,WVe,zf,coe,QVe,HVe,lk,UVe,JVe,YVe,Wf,foe,KVe,ZVe,ik,eXe,oXe,rXe,Qf,moe,tXe,aXe,dk,nXe,sXe,lXe,Hf,goe,iXe,dXe,ck,cXe,fXe,mXe,Uf,hoe,gXe,hXe,fk,pXe,_Xe,uXe,Jf,poe,bXe,vXe,mk,FXe,TXe,MXe,Yf,_oe,EXe,CXe,gk,wXe,AXe,yXe,Kf,uoe,LXe,xXe,hk,$Xe,kXe,SXe,Zf,boe,RXe,PXe,pk,BXe,IXe,qXe,em,voe,NXe,jXe,_k,DXe,GXe,OXe,om,Foe,VXe,XXe,uk,zXe,WXe,QXe,rm,Toe,HXe,UXe,bk,JXe,YXe,KXe,tm,Moe,ZXe,eze,vk,oze,rze,tze,am,Eoe,aze,nze,Fk,sze,lze,ize,nm,Coe,dze,cze,Tk,fze,mze,gze,sm,woe,hze,pze,Mk,_ze,uze,bze,lm,Aoe,vze,Fze,Ek,Tze,Mze,Eze,im,yoe,Cze,wze,Ck,Aze,yze,Lze,dm,Loe,xze,$ze,wk,kze,Sze,Rze,cm,xoe,Pze,Bze,Ak,Ize,qze,Nze,fm,$oe,jze,Dze,yk,Gze,Oze,Vze,mm,koe,Xze,zze,Lk,Wze,Qze,Hze,gm,Soe,Uze,Jze,xk,Yze,Kze,Zze,hm,Roe,eWe,oWe,$k,rWe,tWe,aWe,pm,Poe,nWe,sWe,kk,lWe,iWe,dWe,_m,Boe,cWe,fWe,Sk,mWe,gWe,hWe,um,Ioe,pWe,_We,Rk,uWe,bWe,vWe,bm,qoe,FWe,TWe,Pk,MWe,EWe,CWe,vm,Noe,wWe,AWe,Bk,yWe,LWe,xWe,Fm,joe,$We,kWe,Ik,SWe,RWe,PWe,Tm,Doe,BWe,IWe,qk,qWe,NWe,jWe,Mm,Goe,DWe,GWe,Nk,OWe,VWe,XWe,Em,Ooe,zWe,WWe,jk,QWe,HWe,UWe,Cm,Voe,JWe,YWe,Dk,KWe,ZWe,eQe,wm,Xoe,oQe,rQe,Gk,tQe,aQe,nQe,Am,zoe,sQe,lQe,Ok,iQe,dQe,cQe,ym,Woe,fQe,mQe,Vk,gQe,hQe,pQe,Lm,Qoe,_Qe,uQe,Xk,bQe,vQe,FQe,xm,Hoe,TQe,MQe,zk,EQe,CQe,wQe,$m,Uoe,AQe,yQe,Wk,LQe,xQe,$Qe,km,Joe,kQe,SQe,Qk,RQe,PQe,BQe,Sm,Yoe,IQe,qQe,Hk,NQe,jQe,DQe,Rm,Koe,GQe,OQe,Uk,VQe,XQe,zQe,Pm,Zoe,WQe,QQe,Jk,HQe,UQe,JQe,Bm,ere,YQe,KQe,Yk,ZQe,eHe,oHe,Im,ore,rHe,tHe,Kk,aHe,nHe,sHe,qm,rre,lHe,iHe,Zk,dHe,cHe,fHe,Nm,tre,mHe,gHe,eS,hHe,pHe,_He,jm,are,uHe,bHe,oS,vHe,FHe,THe,Dm,nre,MHe,EHe,rS,CHe,wHe,AHe,Gm,sre,yHe,LHe,tS,xHe,$He,kHe,Om,lre,SHe,RHe,aS,PHe,BHe,IHe,Vm,ire,qHe,NHe,nS,jHe,DHe,GHe,Xm,dre,OHe,VHe,sS,XHe,zHe,WHe,zm,cre,QHe,HHe,lS,UHe,JHe,YHe,Wm,fre,KHe,ZHe,iS,eUe,oUe,rUe,Qm,mre,tUe,aUe,dS,nUe,sUe,lUe,Hm,gre,iUe,dUe,cS,cUe,fUe,mUe,Um,hre,gUe,hUe,fS,pUe,_Ue,uUe,Jm,pre,bUe,vUe,mS,FUe,TUe,MUe,Ym,_re,EUe,CUe,gS,wUe,AUe,yUe,Km,ure,LUe,xUe,hS,$Ue,kUe,SUe,Zm,bre,RUe,PUe,pS,BUe,IUe,qUe,eg,vre,NUe,jUe,_S,DUe,GUe,OUe,og,Fre,VUe,XUe,uS,zUe,WUe,QUe,rg,Tre,HUe,UUe,bS,JUe,YUe,KUe,tg,Mre,ZUe,eJe,vS,oJe,rJe,tJe,ag,Ere,aJe,nJe,FS,sJe,lJe,iJe,ng,Cre,dJe,cJe,TS,fJe,mJe,gJe,sg,wre,hJe,pJe,MS,_Je,uJe,bJe,lg,Are,vJe,FJe,ES,TJe,MJe,EJe,ig,yre,CJe,wJe,CS,AJe,yJe,LJe,dg,Lre,xJe,$Je,wS,kJe,SJe,RJe,cg,xre,PJe,BJe,AS,IJe,qJe,NJe,fg,$re,jJe,DJe,yS,GJe,OJe,VJe,mg,kre,XJe,zJe,LS,WJe,QJe,HJe,gg,Sre,UJe,JJe,xS,YJe,KJe,ZJe,hg,Rre,eYe,oYe,$S,rYe,tYe,aYe,pg,Pre,nYe,sYe,kS,lYe,iYe,dYe,_g,Bre,cYe,fYe,SS,mYe,gYe,hYe,ug,Ire,pYe,_Ye,RS,uYe,bYe,vYe,bg,qre,FYe,TYe,PS,MYe,EYe,CYe,vg,wYe,Fg,F6,AYe,Nre,yYe,rqe,Fi,Tg,jre,T6,LYe,Dre,xYe,tqe,wo,M6,$Ye,E6,kYe,BS,SYe,RYe,PYe,C6,BYe,Gre,IYe,qYe,NYe,Cr,w6,jYe,Ore,DYe,GYe,Aa,OYe,Vre,VYe,XYe,Xre,zYe,WYe,zre,QYe,HYe,UYe,k,Sn,Wre,JYe,YYe,IS,KYe,ZYe,qS,eKe,oKe,rKe,Rn,Qre,tKe,aKe,NS,nKe,sKe,jS,lKe,iKe,dKe,Pn,Hre,cKe,fKe,DS,mKe,gKe,GS,hKe,pKe,_Ke,Mg,Ure,uKe,bKe,OS,vKe,FKe,TKe,Bn,Jre,MKe,EKe,VS,CKe,wKe,XS,AKe,yKe,LKe,Eg,Yre,xKe,$Ke,zS,kKe,SKe,RKe,Cg,Kre,PKe,BKe,WS,IKe,qKe,NKe,wg,Zre,jKe,DKe,QS,GKe,OKe,VKe,In,ete,XKe,zKe,HS,WKe,QKe,US,HKe,UKe,JKe,qn,ote,YKe,KKe,JS,ZKe,eZe,YS,oZe,rZe,tZe,Nn,rte,aZe,nZe,KS,sZe,lZe,ZS,iZe,dZe,cZe,Ag,tte,fZe,mZe,eR,gZe,hZe,pZe,yg,ate,_Ze,uZe,oR,bZe,vZe,FZe,jn,nte,TZe,MZe,rR,EZe,CZe,tR,wZe,AZe,yZe,Lg,ste,LZe,xZe,aR,$Ze,kZe,SZe,Dn,lte,RZe,PZe,nR,BZe,IZe,sR,qZe,NZe,jZe,Gn,ite,DZe,GZe,lR,OZe,VZe,iR,XZe,zZe,WZe,On,dte,QZe,HZe,dR,UZe,JZe,cR,YZe,KZe,ZZe,xg,cte,eeo,oeo,fR,reo,teo,aeo,Vn,fte,neo,seo,mR,leo,ieo,gR,deo,ceo,feo,Xn,mte,meo,geo,hR,heo,peo,pR,_eo,ueo,beo,zn,gte,veo,Feo,_R,Teo,Meo,uR,Eeo,Ceo,weo,Wn,hte,Aeo,yeo,bR,Leo,xeo,vR,$eo,keo,Seo,Qn,pte,Reo,Peo,FR,Beo,Ieo,TR,qeo,Neo,jeo,Hn,_te,Deo,Geo,MR,Oeo,Veo,ER,Xeo,zeo,Weo,$g,ute,Qeo,Heo,CR,Ueo,Jeo,Yeo,Un,bte,Keo,Zeo,wR,eoo,ooo,AR,roo,too,aoo,kg,vte,noo,soo,yR,loo,ioo,doo,Jn,Fte,coo,foo,LR,moo,goo,xR,hoo,poo,_oo,Yn,Tte,uoo,boo,$R,voo,Foo,kR,Too,Moo,Eoo,Kn,Mte,Coo,woo,SR,Aoo,yoo,RR,Loo,xoo,$oo,Zn,Ete,koo,Soo,PR,Roo,Poo,BR,Boo,Ioo,qoo,es,Cte,Noo,joo,IR,Doo,Goo,qR,Ooo,Voo,Xoo,Sg,wte,zoo,Woo,NR,Qoo,Hoo,Uoo,os,Ate,Joo,Yoo,jR,Koo,Zoo,DR,ero,oro,rro,rs,yte,tro,aro,GR,nro,sro,OR,lro,iro,dro,ts,Lte,cro,fro,VR,mro,gro,XR,hro,pro,_ro,as,xte,uro,bro,zR,vro,Fro,WR,Tro,Mro,Ero,ns,$te,Cro,wro,QR,Aro,yro,HR,Lro,xro,$ro,ss,kte,kro,Sro,UR,Rro,Pro,JR,Bro,Iro,qro,Rg,Ste,Nro,jro,YR,Dro,Gro,Oro,ls,Rte,Vro,Xro,KR,zro,Wro,ZR,Qro,Hro,Uro,Pg,Pte,Jro,Yro,eP,Kro,Zro,eto,Bg,Bte,oto,rto,oP,tto,ato,nto,is,Ite,sto,lto,rP,ito,dto,tP,cto,fto,mto,ds,qte,gto,hto,aP,pto,_to,nP,uto,bto,vto,cs,Nte,Fto,Tto,sP,Mto,Eto,lP,Cto,wto,Ato,Ig,jte,yto,Lto,iP,xto,$to,kto,fs,Dte,Sto,Rto,dP,Pto,Bto,cP,Ito,qto,Nto,ms,Gte,jto,Dto,fP,Gto,Oto,mP,Vto,Xto,zto,gs,Ote,Wto,Qto,gP,Hto,Uto,hP,Jto,Yto,Kto,hs,Vte,Zto,eao,pP,oao,rao,_P,tao,aao,nao,ps,Xte,sao,lao,uP,iao,dao,bP,cao,fao,mao,qg,zte,gao,hao,vP,pao,_ao,uao,_s,Wte,bao,vao,FP,Fao,Tao,TP,Mao,Eao,Cao,Ng,Qte,wao,Aao,MP,yao,Lao,xao,jg,Hte,$ao,kao,EP,Sao,Rao,Pao,Dg,Ute,Bao,Iao,CP,qao,Nao,jao,Gg,Jte,Dao,Gao,wP,Oao,Vao,Xao,us,Yte,zao,Wao,AP,Qao,Hao,yP,Uao,Jao,Yao,Og,Kte,Kao,Zao,LP,eno,ono,rno,bs,Zte,tno,ano,xP,nno,sno,$P,lno,ino,dno,vs,eae,cno,fno,kP,mno,gno,SP,hno,pno,_no,Fs,oae,uno,bno,RP,vno,Fno,PP,Tno,Mno,Eno,Ts,rae,Cno,wno,BP,Ano,yno,IP,Lno,xno,$no,Ms,tae,kno,Sno,qP,Rno,Pno,NP,Bno,Ino,qno,Es,aae,Nno,jno,jP,Dno,Gno,DP,Ono,Vno,Xno,Vg,nae,zno,Wno,GP,Qno,Hno,Uno,Xg,sae,Jno,Yno,OP,Kno,Zno,eso,Cs,lae,oso,rso,VP,tso,aso,XP,nso,sso,lso,ws,iae,iso,dso,zP,cso,fso,WP,mso,gso,hso,As,dae,pso,_so,QP,uso,bso,HP,vso,Fso,Tso,zg,cae,Mso,Eso,UP,Cso,wso,Aso,Wg,fae,yso,Lso,JP,xso,$so,kso,Qg,mae,Sso,Rso,YP,Pso,Bso,Iso,ys,gae,qso,Nso,KP,jso,Dso,ZP,Gso,Oso,Vso,Hg,hae,Xso,zso,eB,Wso,Qso,Hso,Ug,pae,Uso,Jso,oB,Yso,Kso,Zso,Jg,_ae,elo,olo,rB,rlo,tlo,alo,Ls,uae,nlo,slo,tB,llo,ilo,aB,dlo,clo,flo,Yg,bae,mlo,glo,nB,hlo,plo,_lo,Kg,vae,ulo,blo,sB,vlo,Flo,Tlo,xs,Fae,Mlo,Elo,lB,Clo,wlo,iB,Alo,ylo,Llo,$s,Tae,xlo,$lo,dB,klo,Slo,cB,Rlo,Plo,Blo,ks,Mae,Ilo,qlo,fB,Nlo,jlo,mB,Dlo,Glo,Olo,Ss,Eae,Vlo,Xlo,gB,zlo,Wlo,hB,Qlo,Hlo,Ulo,Zg,Jlo,eh,A6,Ylo,Cae,Klo,aqe,Ti,oh,wae,y6,Zlo,Aae,eio,nqe,Ao,L6,oio,x6,rio,pB,tio,aio,nio,$6,sio,yae,lio,iio,dio,He,k6,cio,Lae,fio,mio,ya,gio,xae,hio,pio,$ae,_io,uio,kae,bio,vio,Fio,Z,rh,Sae,Tio,Mio,_B,Eio,Cio,wio,th,Rae,Aio,yio,uB,Lio,xio,$io,ah,Pae,kio,Sio,bB,Rio,Pio,Bio,nh,Bae,Iio,qio,vB,Nio,jio,Dio,sh,Iae,Gio,Oio,FB,Vio,Xio,zio,lh,qae,Wio,Qio,TB,Hio,Uio,Jio,ih,Nae,Yio,Kio,MB,Zio,edo,odo,dh,jae,rdo,tdo,EB,ado,ndo,sdo,ch,Dae,ldo,ido,CB,ddo,cdo,fdo,fh,Gae,mdo,gdo,wB,hdo,pdo,_do,mh,Oae,udo,bdo,AB,vdo,Fdo,Tdo,gh,Vae,Mdo,Edo,yB,Cdo,wdo,Ado,hh,Xae,ydo,Ldo,LB,xdo,$do,kdo,ph,zae,Sdo,Rdo,xB,Pdo,Bdo,Ido,_h,Wae,qdo,Ndo,$B,jdo,Ddo,Gdo,uh,Qae,Odo,Vdo,kB,Xdo,zdo,Wdo,bh,Hae,Qdo,Hdo,SB,Udo,Jdo,Ydo,vh,Uae,Kdo,Zdo,RB,eco,oco,rco,Fh,Jae,tco,aco,PB,nco,sco,lco,Th,Yae,ico,dco,BB,cco,fco,mco,Mh,Kae,gco,hco,IB,pco,_co,uco,Eh,Zae,bco,vco,qB,Fco,Tco,Mco,Ch,ene,Eco,Cco,NB,wco,Aco,yco,wh,one,Lco,xco,jB,$co,kco,Sco,Ah,rne,Rco,Pco,DB,Bco,Ico,qco,yh,tne,Nco,jco,GB,Dco,Gco,Oco,Lh,Vco,xh,Xco,$h,S6,zco,ane,Wco,sqe,Mi,kh,nne,R6,Qco,sne,Hco,lqe,yo,P6,Uco,B6,Jco,OB,Yco,Kco,Zco,I6,efo,lne,ofo,rfo,tfo,Ue,q6,afo,ine,nfo,sfo,Ei,lfo,dne,ifo,dfo,cne,cfo,ffo,mfo,pe,Sh,fne,gfo,hfo,VB,pfo,_fo,ufo,Rh,mne,bfo,vfo,gne,Ffo,Tfo,Mfo,Ph,hne,Efo,Cfo,XB,wfo,Afo,yfo,Bh,pne,Lfo,xfo,zB,$fo,kfo,Sfo,Ih,_ne,Rfo,Pfo,WB,Bfo,Ifo,qfo,qh,une,Nfo,jfo,QB,Dfo,Gfo,Ofo,Nh,bne,Vfo,Xfo,HB,zfo,Wfo,Qfo,jh,vne,Hfo,Ufo,UB,Jfo,Yfo,Kfo,Dh,Fne,Zfo,emo,JB,omo,rmo,tmo,Gh,Tne,amo,nmo,YB,smo,lmo,imo,Oh,Mne,dmo,cmo,KB,fmo,mmo,gmo,Vh,Ene,hmo,pmo,ZB,_mo,umo,bmo,Xh,Cne,vmo,Fmo,eI,Tmo,Mmo,Emo,zh,wne,Cmo,wmo,oI,Amo,ymo,Lmo,Wh,Ane,xmo,$mo,rI,kmo,Smo,Rmo,Qh,yne,Pmo,Bmo,tI,Imo,qmo,Nmo,Hh,jmo,Uh,Dmo,Jh,N6,Gmo,Lne,Omo,iqe,Ci,Yh,xne,j6,Vmo,$ne,Xmo,dqe,Lo,D6,zmo,wi,Wmo,aI,Qmo,Hmo,nI,Umo,Jmo,Ymo,G6,Kmo,kne,Zmo,ego,ogo,tt,O6,rgo,Sne,tgo,ago,Ai,ngo,Rne,sgo,lgo,sI,igo,dgo,cgo,Kh,fgo,Je,V6,mgo,Pne,ggo,hgo,La,pgo,Bne,_go,ugo,Ine,bgo,vgo,qne,Fgo,Tgo,Mgo,x,Zh,Nne,Ego,Cgo,lI,wgo,Ago,ygo,ep,jne,Lgo,xgo,iI,$go,kgo,Sgo,op,Dne,Rgo,Pgo,dI,Bgo,Igo,qgo,rp,Gne,Ngo,jgo,cI,Dgo,Ggo,Ogo,tp,One,Vgo,Xgo,fI,zgo,Wgo,Qgo,ap,Vne,Hgo,Ugo,mI,Jgo,Ygo,Kgo,np,Xne,Zgo,eho,gI,oho,rho,tho,sp,zne,aho,nho,hI,sho,lho,iho,lp,Wne,dho,cho,pI,fho,mho,gho,ip,Qne,hho,pho,_I,_ho,uho,bho,dp,Hne,vho,Fho,uI,Tho,Mho,Eho,cp,Une,Cho,who,bI,Aho,yho,Lho,fp,Jne,xho,$ho,vI,kho,Sho,Rho,mp,Yne,Pho,Bho,FI,Iho,qho,Nho,gp,Kne,jho,Dho,TI,Gho,Oho,Vho,hp,Zne,Xho,zho,MI,Who,Qho,Hho,pp,ese,Uho,Jho,EI,Yho,Kho,Zho,_p,ose,epo,opo,CI,rpo,tpo,apo,up,rse,npo,spo,wI,lpo,ipo,dpo,bp,tse,cpo,fpo,AI,mpo,gpo,hpo,vp,ase,ppo,_po,yI,upo,bpo,vpo,Fp,nse,Fpo,Tpo,LI,Mpo,Epo,Cpo,Tp,sse,wpo,Apo,xI,ypo,Lpo,xpo,Mp,lse,$po,kpo,$I,Spo,Rpo,Ppo,Ep,ise,Bpo,Ipo,kI,qpo,Npo,jpo,Cp,dse,Dpo,Gpo,SI,Opo,Vpo,Xpo,wp,cse,zpo,Wpo,RI,Qpo,Hpo,Upo,Ap,fse,Jpo,Ypo,PI,Kpo,Zpo,e_o,yp,mse,o_o,r_o,BI,t_o,a_o,n_o,Lp,gse,s_o,l_o,II,i_o,d_o,c_o,xp,hse,f_o,m_o,qI,g_o,h_o,p_o,Rs,pse,__o,u_o,NI,b_o,v_o,jI,F_o,T_o,M_o,$p,_se,E_o,C_o,DI,w_o,A_o,y_o,kp,use,L_o,x_o,GI,$_o,k_o,S_o,Sp,bse,R_o,P_o,OI,B_o,I_o,q_o,Rp,vse,N_o,j_o,VI,D_o,G_o,O_o,Pp,Fse,V_o,X_o,XI,z_o,W_o,Q_o,Bp,Tse,H_o,U_o,zI,J_o,Y_o,K_o,Ip,Mse,Z_o,euo,WI,ouo,ruo,tuo,qp,Ese,auo,nuo,QI,suo,luo,iuo,Np,Cse,duo,cuo,HI,fuo,muo,guo,jp,wse,huo,puo,UI,_uo,uuo,buo,Dp,Ase,vuo,Fuo,JI,Tuo,Muo,Euo,Gp,yse,Cuo,wuo,YI,Auo,yuo,Luo,Op,Lse,xuo,$uo,KI,kuo,Suo,Ruo,Vp,xse,Puo,Buo,ZI,Iuo,quo,Nuo,Xp,$se,juo,Duo,eq,Guo,Ouo,Vuo,zp,kse,Xuo,zuo,oq,Wuo,Quo,Huo,Wp,Sse,Uuo,Juo,rq,Yuo,Kuo,Zuo,Qp,Rse,e2o,o2o,tq,r2o,t2o,a2o,Hp,Pse,n2o,s2o,aq,l2o,i2o,d2o,Up,Bse,c2o,f2o,nq,m2o,g2o,h2o,Jp,Ise,p2o,_2o,sq,u2o,b2o,v2o,Yp,qse,F2o,T2o,lq,M2o,E2o,C2o,Kp,Nse,w2o,A2o,iq,y2o,L2o,x2o,Zp,jse,$2o,k2o,dq,S2o,R2o,P2o,e_,Dse,B2o,I2o,cq,q2o,N2o,j2o,o_,Gse,D2o,G2o,fq,O2o,V2o,X2o,r_,Ose,z2o,W2o,mq,Q2o,H2o,U2o,t_,Vse,J2o,Y2o,gq,K2o,Z2o,e1o,a_,Xse,o1o,r1o,hq,t1o,a1o,n1o,n_,zse,s1o,l1o,pq,i1o,d1o,c1o,s_,Wse,f1o,m1o,_q,g1o,h1o,p1o,l_,Qse,_1o,u1o,uq,b1o,v1o,F1o,i_,Hse,T1o,M1o,bq,E1o,C1o,w1o,d_,Use,A1o,y1o,vq,L1o,x1o,$1o,c_,Jse,k1o,S1o,Fq,R1o,P1o,B1o,f_,Yse,I1o,q1o,Tq,N1o,j1o,D1o,m_,Kse,G1o,O1o,Mq,V1o,X1o,z1o,g_,Zse,W1o,Q1o,Eq,H1o,U1o,J1o,h_,ele,Y1o,K1o,Cq,Z1o,e7o,o7o,p_,ole,r7o,t7o,wq,a7o,n7o,s7o,__,rle,l7o,i7o,Aq,d7o,c7o,f7o,u_,tle,m7o,g7o,yq,h7o,p7o,_7o,b_,ale,u7o,b7o,Lq,v7o,F7o,T7o,v_,nle,M7o,E7o,xq,C7o,w7o,A7o,F_,sle,y7o,L7o,$q,x7o,$7o,k7o,T_,lle,S7o,R7o,kq,P7o,B7o,I7o,M_,ile,q7o,N7o,Sq,j7o,D7o,G7o,E_,dle,O7o,V7o,Rq,X7o,z7o,W7o,C_,cle,Q7o,H7o,Pq,U7o,J7o,Y7o,w_,fle,K7o,Z7o,Bq,ebo,obo,rbo,A_,mle,tbo,abo,Iq,nbo,sbo,lbo,y_,gle,ibo,dbo,qq,cbo,fbo,mbo,L_,hle,gbo,hbo,Nq,pbo,_bo,ubo,x_,ple,bbo,vbo,jq,Fbo,Tbo,Mbo,$_,_le,Ebo,Cbo,Dq,wbo,Abo,ybo,k_,ule,Lbo,xbo,Gq,$bo,kbo,Sbo,S_,ble,Rbo,Pbo,Oq,Bbo,Ibo,qbo,R_,vle,Nbo,jbo,Vq,Dbo,Gbo,Obo,P_,Fle,Vbo,Xbo,Xq,zbo,Wbo,Qbo,B_,Tle,Hbo,Ubo,zq,Jbo,Ybo,Kbo,I_,Mle,Zbo,evo,Wq,ovo,rvo,tvo,q_,Ele,avo,nvo,Qq,svo,lvo,ivo,N_,Cle,dvo,cvo,Hq,fvo,mvo,gvo,j_,wle,hvo,pvo,Uq,_vo,uvo,bvo,D_,Ale,vvo,Fvo,Jq,Tvo,Mvo,Evo,G_,yle,Cvo,wvo,Yq,Avo,yvo,Lvo,O_,Lle,xvo,$vo,Kq,kvo,Svo,Rvo,V_,Pvo,xle,Bvo,Ivo,$le,qvo,Nvo,X_,cqe,yi,z_,kle,X6,jvo,Sle,Dvo,fqe,xo,z6,Gvo,Li,Ovo,Zq,Vvo,Xvo,eN,zvo,Wvo,Qvo,W6,Hvo,Rle,Uvo,Jvo,Yvo,at,Q6,Kvo,Ple,Zvo,eFo,xi,oFo,Ble,rFo,tFo,oN,aFo,nFo,sFo,W_,lFo,Ye,H6,iFo,Ile,dFo,cFo,xa,fFo,qle,mFo,gFo,Nle,hFo,pFo,jle,_Fo,uFo,bFo,G,Q_,Dle,vFo,FFo,rN,TFo,MFo,EFo,H_,Gle,CFo,wFo,tN,AFo,yFo,LFo,U_,Ole,xFo,$Fo,aN,kFo,SFo,RFo,J_,Vle,PFo,BFo,nN,IFo,qFo,NFo,Y_,Xle,jFo,DFo,sN,GFo,OFo,VFo,K_,zle,XFo,zFo,lN,WFo,QFo,HFo,Z_,Wle,UFo,JFo,iN,YFo,KFo,ZFo,eu,Qle,eTo,oTo,dN,rTo,tTo,aTo,ou,Hle,nTo,sTo,cN,lTo,iTo,dTo,ru,Ule,cTo,fTo,fN,mTo,gTo,hTo,tu,Jle,pTo,_To,mN,uTo,bTo,vTo,au,Yle,FTo,TTo,gN,MTo,ETo,CTo,nu,Kle,wTo,ATo,hN,yTo,LTo,xTo,su,Zle,$To,kTo,pN,STo,RTo,PTo,lu,eie,BTo,ITo,_N,qTo,NTo,jTo,iu,oie,DTo,GTo,uN,OTo,VTo,XTo,du,rie,zTo,WTo,bN,QTo,HTo,UTo,cu,tie,JTo,YTo,vN,KTo,ZTo,eMo,fu,aie,oMo,rMo,FN,tMo,aMo,nMo,mu,nie,sMo,lMo,TN,iMo,dMo,cMo,gu,sie,fMo,mMo,MN,gMo,hMo,pMo,hu,lie,_Mo,uMo,EN,bMo,vMo,FMo,pu,iie,TMo,MMo,CN,EMo,CMo,wMo,_u,die,AMo,yMo,wN,LMo,xMo,$Mo,uu,cie,kMo,SMo,AN,RMo,PMo,BMo,bu,fie,IMo,qMo,yN,NMo,jMo,DMo,vu,mie,GMo,OMo,LN,VMo,XMo,zMo,Fu,gie,WMo,QMo,xN,HMo,UMo,JMo,Tu,hie,YMo,KMo,$N,ZMo,e4o,o4o,Mu,pie,r4o,t4o,kN,a4o,n4o,s4o,Eu,_ie,l4o,i4o,SN,d4o,c4o,f4o,Cu,uie,m4o,g4o,RN,h4o,p4o,_4o,wu,bie,u4o,b4o,PN,v4o,F4o,T4o,Au,vie,M4o,E4o,BN,C4o,w4o,A4o,yu,Fie,y4o,L4o,IN,x4o,$4o,k4o,Lu,Tie,S4o,R4o,qN,P4o,B4o,I4o,xu,Mie,q4o,N4o,NN,j4o,D4o,G4o,$u,Eie,O4o,V4o,jN,X4o,z4o,W4o,ku,Cie,Q4o,H4o,DN,U4o,J4o,Y4o,Su,wie,K4o,Z4o,GN,eEo,oEo,rEo,Ru,Aie,tEo,aEo,ON,nEo,sEo,lEo,Pu,yie,iEo,dEo,VN,cEo,fEo,mEo,Bu,gEo,Lie,hEo,pEo,xie,_Eo,uEo,Iu,mqe,$i,qu,$ie,U6,bEo,kie,vEo,gqe,$o,J6,FEo,ki,TEo,XN,MEo,EEo,zN,CEo,wEo,AEo,Y6,yEo,Sie,LEo,xEo,$Eo,nt,K6,kEo,Rie,SEo,REo,Si,PEo,Pie,BEo,IEo,WN,qEo,NEo,jEo,Nu,DEo,Ke,Z6,GEo,Bie,OEo,VEo,$a,XEo,Iie,zEo,WEo,qie,QEo,HEo,Nie,UEo,JEo,YEo,z,ju,jie,KEo,ZEo,QN,eCo,oCo,rCo,Du,Die,tCo,aCo,HN,nCo,sCo,lCo,Gu,Gie,iCo,dCo,UN,cCo,fCo,mCo,Ou,Oie,gCo,hCo,JN,pCo,_Co,uCo,Vu,Vie,bCo,vCo,YN,FCo,TCo,MCo,Xu,Xie,ECo,CCo,KN,wCo,ACo,yCo,zu,zie,LCo,xCo,ZN,$Co,kCo,SCo,Wu,Wie,RCo,PCo,ej,BCo,ICo,qCo,Qu,Qie,NCo,jCo,oj,DCo,GCo,OCo,Hu,Hie,VCo,XCo,rj,zCo,WCo,QCo,Uu,Uie,HCo,UCo,tj,JCo,YCo,KCo,Ju,Jie,ZCo,e5o,aj,o5o,r5o,t5o,Yu,Yie,a5o,n5o,nj,s5o,l5o,i5o,Ku,Kie,d5o,c5o,sj,f5o,m5o,g5o,Zu,Zie,h5o,p5o,lj,_5o,u5o,b5o,e2,ede,v5o,F5o,ij,T5o,M5o,E5o,o2,ode,C5o,w5o,dj,A5o,y5o,L5o,r2,rde,x5o,$5o,cj,k5o,S5o,R5o,t2,tde,P5o,B5o,fj,I5o,q5o,N5o,a2,ade,j5o,D5o,mj,G5o,O5o,V5o,n2,nde,X5o,z5o,gj,W5o,Q5o,H5o,s2,sde,U5o,J5o,hj,Y5o,K5o,Z5o,l2,lde,e3o,o3o,pj,r3o,t3o,a3o,i2,ide,n3o,s3o,_j,l3o,i3o,d3o,d2,dde,c3o,f3o,uj,m3o,g3o,h3o,c2,cde,p3o,_3o,bj,u3o,b3o,v3o,f2,fde,F3o,T3o,vj,M3o,E3o,C3o,m2,mde,w3o,A3o,Fj,y3o,L3o,x3o,g2,gde,$3o,k3o,Tj,S3o,R3o,P3o,h2,hde,B3o,I3o,Mj,q3o,N3o,j3o,p2,pde,D3o,G3o,Ej,O3o,V3o,X3o,_2,_de,z3o,W3o,Cj,Q3o,H3o,U3o,u2,ude,J3o,Y3o,wj,K3o,Z3o,ewo,b2,bde,owo,rwo,Aj,two,awo,nwo,v2,vde,swo,lwo,yj,iwo,dwo,cwo,F2,Fde,fwo,mwo,Lj,gwo,hwo,pwo,T2,_wo,Tde,uwo,bwo,Mde,vwo,Fwo,M2,hqe,Ri,E2,Ede,ey,Two,Cde,Mwo,pqe,ko,oy,Ewo,Pi,Cwo,xj,wwo,Awo,$j,ywo,Lwo,xwo,ry,$wo,wde,kwo,Swo,Rwo,st,ty,Pwo,Ade,Bwo,Iwo,Bi,qwo,yde,Nwo,jwo,kj,Dwo,Gwo,Owo,C2,Vwo,Ze,ay,Xwo,Lde,zwo,Wwo,ka,Qwo,xde,Hwo,Uwo,$de,Jwo,Ywo,kde,Kwo,Zwo,e0o,W,w2,Sde,o0o,r0o,Sj,t0o,a0o,n0o,A2,Rde,s0o,l0o,Rj,i0o,d0o,c0o,y2,Pde,f0o,m0o,Pj,g0o,h0o,p0o,L2,Bde,_0o,u0o,Bj,b0o,v0o,F0o,x2,Ide,T0o,M0o,Ij,E0o,C0o,w0o,$2,qde,A0o,y0o,qj,L0o,x0o,$0o,k2,Nde,k0o,S0o,Nj,R0o,P0o,B0o,S2,jde,I0o,q0o,jj,N0o,j0o,D0o,R2,Dde,G0o,O0o,Dj,V0o,X0o,z0o,P2,Gde,W0o,Q0o,Gj,H0o,U0o,J0o,B2,Ode,Y0o,K0o,Oj,Z0o,eAo,oAo,I2,Vde,rAo,tAo,Vj,aAo,nAo,sAo,q2,Xde,lAo,iAo,Xj,dAo,cAo,fAo,N2,zde,mAo,gAo,zj,hAo,pAo,_Ao,j2,Wde,uAo,bAo,Wj,vAo,FAo,TAo,D2,Qde,MAo,EAo,Qj,CAo,wAo,AAo,G2,Hde,yAo,LAo,Hj,xAo,$Ao,kAo,O2,Ude,SAo,RAo,Uj,PAo,BAo,IAo,V2,Jde,qAo,NAo,Jj,jAo,DAo,GAo,X2,Yde,OAo,VAo,Yj,XAo,zAo,WAo,z2,Kde,QAo,HAo,Kj,UAo,JAo,YAo,W2,Zde,KAo,ZAo,Zj,e6o,o6o,r6o,Q2,ece,t6o,a6o,eD,n6o,s6o,l6o,H2,oce,i6o,d6o,oD,c6o,f6o,m6o,U2,rce,g6o,h6o,rD,p6o,_6o,u6o,J2,tce,b6o,v6o,tD,F6o,T6o,M6o,Y2,ace,E6o,C6o,aD,w6o,A6o,y6o,K2,nce,L6o,x6o,nD,$6o,k6o,S6o,Z2,sce,R6o,P6o,sD,B6o,I6o,q6o,e1,lce,N6o,j6o,lD,D6o,G6o,O6o,o1,ice,V6o,X6o,dce,z6o,W6o,Q6o,r1,cce,H6o,U6o,iD,J6o,Y6o,K6o,t1,fce,Z6o,eyo,dD,oyo,ryo,tyo,a1,mce,ayo,nyo,cD,syo,lyo,iyo,n1,gce,dyo,cyo,fD,fyo,myo,gyo,s1,hyo,hce,pyo,_yo,pce,uyo,byo,l1,_qe,Ii,i1,_ce,ny,vyo,uce,Fyo,uqe,So,sy,Tyo,qi,Myo,mD,Eyo,Cyo,gD,wyo,Ayo,yyo,ly,Lyo,bce,xyo,$yo,kyo,lt,iy,Syo,vce,Ryo,Pyo,Ni,Byo,Fce,Iyo,qyo,hD,Nyo,jyo,Dyo,d1,Gyo,eo,dy,Oyo,Tce,Vyo,Xyo,Sa,zyo,Mce,Wyo,Qyo,Ece,Hyo,Uyo,Cce,Jyo,Yyo,Kyo,_e,c1,wce,Zyo,eLo,pD,oLo,rLo,tLo,f1,Ace,aLo,nLo,_D,sLo,lLo,iLo,m1,yce,dLo,cLo,uD,fLo,mLo,gLo,g1,Lce,hLo,pLo,bD,_Lo,uLo,bLo,h1,xce,vLo,FLo,vD,TLo,MLo,ELo,p1,$ce,CLo,wLo,FD,ALo,yLo,LLo,_1,kce,xLo,$Lo,TD,kLo,SLo,RLo,u1,Sce,PLo,BLo,MD,ILo,qLo,NLo,b1,Rce,jLo,DLo,ED,GLo,OLo,VLo,v1,Pce,XLo,zLo,CD,WLo,QLo,HLo,F1,Bce,ULo,JLo,wD,YLo,KLo,ZLo,T1,Ice,e8o,o8o,AD,r8o,t8o,a8o,M1,qce,n8o,s8o,yD,l8o,i8o,d8o,E1,Nce,c8o,f8o,LD,m8o,g8o,h8o,C1,jce,p8o,_8o,xD,u8o,b8o,v8o,w1,Dce,F8o,T8o,$D,M8o,E8o,C8o,A1,w8o,Gce,A8o,y8o,Oce,L8o,x8o,y1,bqe,ji,L1,Vce,cy,$8o,Xce,k8o,vqe,Ro,fy,S8o,Di,R8o,kD,P8o,B8o,SD,I8o,q8o,N8o,my,j8o,zce,D8o,G8o,O8o,it,gy,V8o,Wce,X8o,z8o,Gi,W8o,Qce,Q8o,H8o,RD,U8o,J8o,Y8o,x1,K8o,oo,hy,Z8o,Hce,exo,oxo,Ra,rxo,Uce,txo,axo,Jce,nxo,sxo,Yce,lxo,ixo,dxo,N,$1,Kce,cxo,fxo,PD,mxo,gxo,hxo,k1,Zce,pxo,_xo,BD,uxo,bxo,vxo,S1,efe,Fxo,Txo,ID,Mxo,Exo,Cxo,R1,ofe,wxo,Axo,qD,yxo,Lxo,xxo,P1,rfe,$xo,kxo,ND,Sxo,Rxo,Pxo,B1,tfe,Bxo,Ixo,jD,qxo,Nxo,jxo,I1,afe,Dxo,Gxo,DD,Oxo,Vxo,Xxo,q1,nfe,zxo,Wxo,GD,Qxo,Hxo,Uxo,N1,sfe,Jxo,Yxo,OD,Kxo,Zxo,e9o,j1,lfe,o9o,r9o,VD,t9o,a9o,n9o,D1,ife,s9o,l9o,XD,i9o,d9o,c9o,G1,dfe,f9o,m9o,zD,g9o,h9o,p9o,O1,cfe,_9o,u9o,WD,b9o,v9o,F9o,V1,ffe,T9o,M9o,QD,E9o,C9o,w9o,X1,mfe,A9o,y9o,HD,L9o,x9o,$9o,z1,gfe,k9o,S9o,UD,R9o,P9o,B9o,W1,hfe,I9o,q9o,JD,N9o,j9o,D9o,Q1,pfe,G9o,O9o,YD,V9o,X9o,z9o,H1,_fe,W9o,Q9o,KD,H9o,U9o,J9o,U1,ufe,Y9o,K9o,ZD,Z9o,e$o,o$o,J1,bfe,r$o,t$o,eG,a$o,n$o,s$o,Y1,vfe,l$o,i$o,oG,d$o,c$o,f$o,K1,Ffe,m$o,g$o,rG,h$o,p$o,_$o,Z1,Tfe,u$o,b$o,tG,v$o,F$o,T$o,e7,Mfe,M$o,E$o,aG,C$o,w$o,A$o,o7,Efe,y$o,L$o,nG,x$o,$$o,k$o,r7,Cfe,S$o,R$o,sG,P$o,B$o,I$o,t7,wfe,q$o,N$o,lG,j$o,D$o,G$o,a7,Afe,O$o,V$o,iG,X$o,z$o,W$o,n7,yfe,Q$o,H$o,dG,U$o,J$o,Y$o,s7,Lfe,K$o,Z$o,cG,eko,oko,rko,l7,xfe,tko,ako,fG,nko,sko,lko,i7,$fe,iko,dko,mG,cko,fko,mko,d7,kfe,gko,hko,gG,pko,_ko,uko,c7,Sfe,bko,vko,hG,Fko,Tko,Mko,f7,Rfe,Eko,Cko,pG,wko,Ako,yko,m7,Pfe,Lko,xko,_G,$ko,kko,Sko,g7,Bfe,Rko,Pko,uG,Bko,Iko,qko,h7,Ife,Nko,jko,bG,Dko,Gko,Oko,p7,qfe,Vko,Xko,vG,zko,Wko,Qko,_7,Nfe,Hko,Uko,FG,Jko,Yko,Kko,u7,jfe,Zko,eSo,TG,oSo,rSo,tSo,b7,Dfe,aSo,nSo,MG,sSo,lSo,iSo,v7,Gfe,dSo,cSo,EG,fSo,mSo,gSo,F7,Ofe,hSo,pSo,CG,_So,uSo,bSo,T7,Vfe,vSo,FSo,wG,TSo,MSo,ESo,M7,CSo,Xfe,wSo,ASo,zfe,ySo,LSo,E7,Fqe,Oi,C7,Wfe,py,xSo,Qfe,$So,Tqe,Po,_y,kSo,Vi,SSo,AG,RSo,PSo,yG,BSo,ISo,qSo,uy,NSo,Hfe,jSo,DSo,GSo,dt,by,OSo,Ufe,VSo,XSo,Xi,zSo,Jfe,WSo,QSo,LG,HSo,USo,JSo,w7,YSo,ro,vy,KSo,Yfe,ZSo,eRo,Pa,oRo,Kfe,rRo,tRo,Zfe,aRo,nRo,eme,sRo,lRo,iRo,Y,A7,ome,dRo,cRo,xG,fRo,mRo,gRo,y7,rme,hRo,pRo,$G,_Ro,uRo,bRo,L7,tme,vRo,FRo,kG,TRo,MRo,ERo,x7,ame,CRo,wRo,SG,ARo,yRo,LRo,$7,nme,xRo,$Ro,RG,kRo,SRo,RRo,k7,sme,PRo,BRo,PG,IRo,qRo,NRo,S7,lme,jRo,DRo,BG,GRo,ORo,VRo,R7,ime,XRo,zRo,IG,WRo,QRo,HRo,P7,dme,URo,JRo,qG,YRo,KRo,ZRo,B7,cme,ePo,oPo,NG,rPo,tPo,aPo,I7,fme,nPo,sPo,jG,lPo,iPo,dPo,q7,mme,cPo,fPo,DG,mPo,gPo,hPo,N7,gme,pPo,_Po,GG,uPo,bPo,vPo,j7,hme,FPo,TPo,OG,MPo,EPo,CPo,D7,pme,wPo,APo,VG,yPo,LPo,xPo,G7,_me,$Po,kPo,XG,SPo,RPo,PPo,O7,ume,BPo,IPo,zG,qPo,NPo,jPo,V7,bme,DPo,GPo,WG,OPo,VPo,XPo,X7,vme,zPo,WPo,QG,QPo,HPo,UPo,z7,Fme,JPo,YPo,HG,KPo,ZPo,eBo,W7,Tme,oBo,rBo,UG,tBo,aBo,nBo,Q7,Mme,sBo,lBo,JG,iBo,dBo,cBo,H7,Eme,fBo,mBo,YG,gBo,hBo,pBo,U7,Cme,_Bo,uBo,KG,bBo,vBo,FBo,J7,wme,TBo,MBo,ZG,EBo,CBo,wBo,Y7,Ame,ABo,yBo,eO,LBo,xBo,$Bo,K7,yme,kBo,SBo,oO,RBo,PBo,BBo,Z7,Lme,IBo,qBo,rO,NBo,jBo,DBo,eb,xme,GBo,OBo,tO,VBo,XBo,zBo,ob,WBo,$me,QBo,HBo,kme,UBo,JBo,rb,Mqe,zi,tb,Sme,Fy,YBo,Rme,KBo,Eqe,Bo,Ty,ZBo,Wi,eIo,aO,oIo,rIo,nO,tIo,aIo,nIo,My,sIo,Pme,lIo,iIo,dIo,ct,Ey,cIo,Bme,fIo,mIo,Qi,gIo,Ime,hIo,pIo,sO,_Io,uIo,bIo,ab,vIo,to,Cy,FIo,qme,TIo,MIo,Ba,EIo,Nme,CIo,wIo,jme,AIo,yIo,Dme,LIo,xIo,$Io,Yr,nb,Gme,kIo,SIo,lO,RIo,PIo,BIo,sb,Ome,IIo,qIo,iO,NIo,jIo,DIo,lb,Vme,GIo,OIo,dO,VIo,XIo,zIo,ib,Xme,WIo,QIo,cO,HIo,UIo,JIo,db,zme,YIo,KIo,fO,ZIo,eqo,oqo,cb,rqo,Wme,tqo,aqo,Qme,nqo,sqo,fb,Cqe,Hi,mb,Hme,wy,lqo,Ume,iqo,wqe,Io,Ay,dqo,Ui,cqo,mO,fqo,mqo,gO,gqo,hqo,pqo,yy,_qo,Jme,uqo,bqo,vqo,ft,Ly,Fqo,Yme,Tqo,Mqo,Ji,Eqo,Kme,Cqo,wqo,hO,Aqo,yqo,Lqo,gb,xqo,ao,xy,$qo,Zme,kqo,Sqo,Ia,Rqo,ege,Pqo,Bqo,oge,Iqo,qqo,rge,Nqo,jqo,Dqo,U,hb,tge,Gqo,Oqo,pO,Vqo,Xqo,zqo,pb,age,Wqo,Qqo,_O,Hqo,Uqo,Jqo,_b,nge,Yqo,Kqo,uO,Zqo,eNo,oNo,ub,sge,rNo,tNo,bO,aNo,nNo,sNo,bb,lge,lNo,iNo,vO,dNo,cNo,fNo,vb,ige,mNo,gNo,FO,hNo,pNo,_No,Fb,dge,uNo,bNo,TO,vNo,FNo,TNo,Tb,cge,MNo,ENo,MO,CNo,wNo,ANo,Mb,fge,yNo,LNo,EO,xNo,$No,kNo,Eb,mge,SNo,RNo,CO,PNo,BNo,INo,Cb,gge,qNo,NNo,wO,jNo,DNo,GNo,wb,hge,ONo,VNo,AO,XNo,zNo,WNo,Ab,pge,QNo,HNo,yO,UNo,JNo,YNo,yb,_ge,KNo,ZNo,LO,ejo,ojo,rjo,Lb,uge,tjo,ajo,xO,njo,sjo,ljo,xb,bge,ijo,djo,$O,cjo,fjo,mjo,$b,vge,gjo,hjo,kO,pjo,_jo,ujo,kb,Fge,bjo,vjo,SO,Fjo,Tjo,Mjo,Sb,Tge,Ejo,Cjo,RO,wjo,Ajo,yjo,Rb,Mge,Ljo,xjo,PO,$jo,kjo,Sjo,Pb,Ege,Rjo,Pjo,BO,Bjo,Ijo,qjo,Bb,Cge,Njo,jjo,IO,Djo,Gjo,Ojo,Ib,wge,Vjo,Xjo,qO,zjo,Wjo,Qjo,qb,Age,Hjo,Ujo,NO,Jjo,Yjo,Kjo,Nb,yge,Zjo,eDo,jO,oDo,rDo,tDo,jb,Lge,aDo,nDo,DO,sDo,lDo,iDo,Db,xge,dDo,cDo,GO,fDo,mDo,gDo,Gb,$ge,hDo,pDo,OO,_Do,uDo,bDo,Ob,kge,vDo,FDo,VO,TDo,MDo,EDo,Vb,Sge,CDo,wDo,XO,ADo,yDo,LDo,Xb,Rge,xDo,$Do,zO,kDo,SDo,RDo,zb,Pge,PDo,BDo,WO,IDo,qDo,NDo,Wb,Bge,jDo,DDo,QO,GDo,ODo,VDo,Qb,XDo,Ige,zDo,WDo,qge,QDo,HDo,Hb,Aqe,Yi,Ub,Nge,$y,UDo,jge,JDo,yqe,qo,ky,YDo,Ki,KDo,HO,ZDo,eGo,UO,oGo,rGo,tGo,Sy,aGo,Dge,nGo,sGo,lGo,mt,Ry,iGo,Gge,dGo,cGo,Zi,fGo,Oge,mGo,gGo,JO,hGo,pGo,_Go,Jb,uGo,no,Py,bGo,Vge,vGo,FGo,qa,TGo,Xge,MGo,EGo,zge,CGo,wGo,Wge,AGo,yGo,LGo,V,Yb,Qge,xGo,$Go,YO,kGo,SGo,RGo,Kb,Hge,PGo,BGo,KO,IGo,qGo,NGo,Zb,Uge,jGo,DGo,ZO,GGo,OGo,VGo,ev,Jge,XGo,zGo,eV,WGo,QGo,HGo,ov,Yge,UGo,JGo,oV,YGo,KGo,ZGo,rv,Kge,eOo,oOo,rV,rOo,tOo,aOo,tv,Zge,nOo,sOo,tV,lOo,iOo,dOo,av,ehe,cOo,fOo,aV,mOo,gOo,hOo,nv,ohe,pOo,_Oo,nV,uOo,bOo,vOo,sv,rhe,FOo,TOo,sV,MOo,EOo,COo,lv,the,wOo,AOo,lV,yOo,LOo,xOo,iv,ahe,$Oo,kOo,iV,SOo,ROo,POo,dv,nhe,BOo,IOo,dV,qOo,NOo,jOo,cv,she,DOo,GOo,cV,OOo,VOo,XOo,fv,lhe,zOo,WOo,fV,QOo,HOo,UOo,mv,ihe,JOo,YOo,mV,KOo,ZOo,eVo,gv,dhe,oVo,rVo,gV,tVo,aVo,nVo,hv,che,sVo,lVo,hV,iVo,dVo,cVo,pv,fhe,fVo,mVo,pV,gVo,hVo,pVo,_v,mhe,_Vo,uVo,_V,bVo,vVo,FVo,uv,ghe,TVo,MVo,uV,EVo,CVo,wVo,bv,hhe,AVo,yVo,bV,LVo,xVo,$Vo,vv,phe,kVo,SVo,vV,RVo,PVo,BVo,Fv,_he,IVo,qVo,FV,NVo,jVo,DVo,Tv,uhe,GVo,OVo,TV,VVo,XVo,zVo,Mv,bhe,WVo,QVo,MV,HVo,UVo,JVo,Ev,vhe,YVo,KVo,EV,ZVo,eXo,oXo,Cv,Fhe,rXo,tXo,CV,aXo,nXo,sXo,wv,The,lXo,iXo,wV,dXo,cXo,fXo,Av,Mhe,mXo,gXo,AV,hXo,pXo,_Xo,yv,Ehe,uXo,bXo,yV,vXo,FXo,TXo,Lv,Che,MXo,EXo,LV,CXo,wXo,AXo,xv,whe,yXo,LXo,xV,xXo,$Xo,kXo,$v,Ahe,SXo,RXo,$V,PXo,BXo,IXo,kv,yhe,qXo,NXo,kV,jXo,DXo,GXo,Sv,Lhe,OXo,VXo,SV,XXo,zXo,WXo,Rv,xhe,QXo,HXo,RV,UXo,JXo,YXo,Pv,$he,KXo,ZXo,PV,ezo,ozo,rzo,Bv,khe,tzo,azo,BV,nzo,szo,lzo,Iv,izo,She,dzo,czo,Rhe,fzo,mzo,qv,Lqe,ed,Nv,Phe,By,gzo,Bhe,hzo,xqe,No,Iy,pzo,od,_zo,IV,uzo,bzo,qV,vzo,Fzo,Tzo,qy,Mzo,Ihe,Ezo,Czo,wzo,gt,Ny,Azo,qhe,yzo,Lzo,rd,xzo,Nhe,$zo,kzo,NV,Szo,Rzo,Pzo,jv,Bzo,so,jy,Izo,jhe,qzo,Nzo,Na,jzo,Dhe,Dzo,Gzo,Ghe,Ozo,Vzo,Ohe,Xzo,zzo,Wzo,Vhe,Dv,Xhe,Qzo,Hzo,jV,Uzo,Jzo,Yzo,Gv,Kzo,zhe,Zzo,eWo,Whe,oWo,rWo,Ov,$qe,td,Vv,Qhe,Dy,tWo,Hhe,aWo,kqe,jo,Gy,nWo,ad,sWo,DV,lWo,iWo,GV,dWo,cWo,fWo,Oy,mWo,Uhe,gWo,hWo,pWo,ht,Vy,_Wo,Jhe,uWo,bWo,nd,vWo,Yhe,FWo,TWo,OV,MWo,EWo,CWo,Xv,wWo,lo,Xy,AWo,Khe,yWo,LWo,ja,xWo,Zhe,$Wo,kWo,epe,SWo,RWo,ope,PWo,BWo,IWo,Fe,zv,rpe,qWo,NWo,VV,jWo,DWo,GWo,Wv,tpe,OWo,VWo,XV,XWo,zWo,WWo,Qv,ape,QWo,HWo,zV,UWo,JWo,YWo,Ps,npe,KWo,ZWo,WV,eQo,oQo,QV,rQo,tQo,aQo,Hv,spe,nQo,sQo,HV,lQo,iQo,dQo,pt,lpe,cQo,fQo,UV,mQo,gQo,JV,hQo,pQo,YV,_Qo,uQo,bQo,Uv,ipe,vQo,FQo,KV,TQo,MQo,EQo,Jv,dpe,CQo,wQo,ZV,AQo,yQo,LQo,Yv,cpe,xQo,$Qo,eX,kQo,SQo,RQo,Kv,fpe,PQo,BQo,oX,IQo,qQo,NQo,Zv,mpe,jQo,DQo,rX,GQo,OQo,VQo,eF,gpe,XQo,zQo,tX,WQo,QQo,HQo,oF,hpe,UQo,JQo,aX,YQo,KQo,ZQo,rF,eHo,ppe,oHo,rHo,_pe,tHo,aHo,tF,Sqe,sd,aF,upe,zy,nHo,bpe,sHo,Rqe,Do,Wy,lHo,ld,iHo,nX,dHo,cHo,sX,fHo,mHo,gHo,Qy,hHo,vpe,pHo,_Ho,uHo,_t,Hy,bHo,Fpe,vHo,FHo,id,THo,Tpe,MHo,EHo,lX,CHo,wHo,AHo,nF,yHo,io,Uy,LHo,Mpe,xHo,$Ho,Da,kHo,Epe,SHo,RHo,Cpe,PHo,BHo,wpe,IHo,qHo,NHo,Ape,sF,ype,jHo,DHo,iX,GHo,OHo,VHo,lF,XHo,Lpe,zHo,WHo,xpe,QHo,HHo,iF,Pqe,dd,dF,$pe,Jy,UHo,kpe,JHo,Bqe,Go,Yy,YHo,cd,KHo,dX,ZHo,eUo,cX,oUo,rUo,tUo,Ky,aUo,Spe,nUo,sUo,lUo,ut,Zy,iUo,Rpe,dUo,cUo,fd,fUo,Ppe,mUo,gUo,fX,hUo,pUo,_Uo,cF,uUo,co,eL,bUo,Bpe,vUo,FUo,Ga,TUo,Ipe,MUo,EUo,qpe,CUo,wUo,Npe,AUo,yUo,LUo,Se,fF,jpe,xUo,$Uo,mX,kUo,SUo,RUo,mF,Dpe,PUo,BUo,gX,IUo,qUo,NUo,gF,Gpe,jUo,DUo,hX,GUo,OUo,VUo,hF,Ope,XUo,zUo,pX,WUo,QUo,HUo,pF,Vpe,UUo,JUo,_X,YUo,KUo,ZUo,_F,Xpe,eJo,oJo,uX,rJo,tJo,aJo,uF,zpe,nJo,sJo,bX,lJo,iJo,dJo,bF,Wpe,cJo,fJo,vX,mJo,gJo,hJo,vF,Qpe,pJo,_Jo,FX,uJo,bJo,vJo,FF,FJo,Hpe,TJo,MJo,Upe,EJo,CJo,TF,Iqe,md,MF,Jpe,oL,wJo,Ype,AJo,qqe,Oo,rL,yJo,gd,LJo,TX,xJo,$Jo,MX,kJo,SJo,RJo,tL,PJo,Kpe,BJo,IJo,qJo,bt,aL,NJo,Zpe,jJo,DJo,hd,GJo,e_e,OJo,VJo,EX,XJo,zJo,WJo,EF,QJo,fo,nL,HJo,o_e,UJo,JJo,Oa,YJo,r_e,KJo,ZJo,t_e,eYo,oYo,a_e,rYo,tYo,aYo,Kr,CF,n_e,nYo,sYo,CX,lYo,iYo,dYo,wF,s_e,cYo,fYo,wX,mYo,gYo,hYo,AF,l_e,pYo,_Yo,AX,uYo,bYo,vYo,yF,i_e,FYo,TYo,yX,MYo,EYo,CYo,LF,d_e,wYo,AYo,LX,yYo,LYo,xYo,xF,$Yo,c_e,kYo,SYo,f_e,RYo,PYo,$F,Nqe,pd,kF,m_e,sL,BYo,g_e,IYo,jqe,Vo,lL,qYo,_d,NYo,xX,jYo,DYo,$X,GYo,OYo,VYo,iL,XYo,h_e,zYo,WYo,QYo,vt,dL,HYo,p_e,UYo,JYo,ud,YYo,__e,KYo,ZYo,kX,eKo,oKo,rKo,SF,tKo,mo,cL,aKo,u_e,nKo,sKo,Va,lKo,b_e,iKo,dKo,v_e,cKo,fKo,F_e,mKo,gKo,hKo,Re,RF,T_e,pKo,_Ko,SX,uKo,bKo,vKo,PF,M_e,FKo,TKo,RX,MKo,EKo,CKo,BF,E_e,wKo,AKo,PX,yKo,LKo,xKo,IF,C_e,$Ko,kKo,BX,SKo,RKo,PKo,qF,w_e,BKo,IKo,IX,qKo,NKo,jKo,NF,A_e,DKo,GKo,qX,OKo,VKo,XKo,jF,y_e,zKo,WKo,NX,QKo,HKo,UKo,DF,L_e,JKo,YKo,jX,KKo,ZKo,eZo,GF,x_e,oZo,rZo,DX,tZo,aZo,nZo,OF,sZo,$_e,lZo,iZo,k_e,dZo,cZo,VF,Dqe,bd,XF,S_e,fL,fZo,R_e,mZo,Gqe,Xo,mL,gZo,vd,hZo,GX,pZo,_Zo,OX,uZo,bZo,vZo,gL,FZo,P_e,TZo,MZo,EZo,Ft,hL,CZo,B_e,wZo,AZo,Fd,yZo,I_e,LZo,xZo,VX,$Zo,kZo,SZo,zF,RZo,go,pL,PZo,q_e,BZo,IZo,Xa,qZo,N_e,NZo,jZo,j_e,DZo,GZo,D_e,OZo,VZo,XZo,_L,WF,G_e,zZo,WZo,XX,QZo,HZo,UZo,QF,O_e,JZo,YZo,zX,KZo,ZZo,eer,HF,oer,V_e,rer,ter,X_e,aer,ner,UF,Oqe,Td,JF,z_e,uL,ser,W_e,ler,Vqe,zo,bL,ier,Md,der,WX,cer,fer,QX,mer,ger,her,vL,per,Q_e,_er,uer,ber,Tt,FL,ver,H_e,Fer,Ter,Ed,Mer,U_e,Eer,Cer,HX,wer,Aer,yer,YF,Ler,ho,TL,xer,J_e,$er,ker,za,Ser,Y_e,Rer,Per,K_e,Ber,Ier,Z_e,qer,Ner,jer,Zr,KF,eue,Der,Ger,UX,Oer,Ver,Xer,ZF,oue,zer,Wer,JX,Qer,Her,Uer,eT,rue,Jer,Yer,YX,Ker,Zer,eor,oT,tue,oor,ror,KX,tor,aor,nor,rT,aue,sor,lor,ZX,ior,dor,cor,tT,mor,nue,gor,hor,sue,por,_or,aT,Xqe,Cd,nT,lue,ML,uor,iue,bor,zqe,Wo,EL,vor,wd,For,ez,Tor,Mor,oz,Eor,Cor,wor,CL,Aor,due,yor,Lor,xor,Mt,wL,$or,cue,kor,Sor,Ad,Ror,fue,Por,Bor,rz,Ior,qor,Nor,sT,jor,po,AL,Dor,mue,Gor,Oor,Wa,Vor,gue,Xor,zor,hue,Wor,Qor,pue,Hor,Uor,Jor,yd,lT,_ue,Yor,Kor,tz,Zor,err,orr,iT,uue,rrr,trr,az,arr,nrr,srr,dT,bue,lrr,irr,nz,drr,crr,frr,cT,mrr,vue,grr,hrr,Fue,prr,_rr,fT,Wqe,Ld,mT,Tue,yL,urr,Mue,brr,Qqe,Qo,LL,vrr,xd,Frr,sz,Trr,Mrr,lz,Err,Crr,wrr,xL,Arr,Eue,yrr,Lrr,xrr,Et,$L,$rr,Cue,krr,Srr,$d,Rrr,wue,Prr,Brr,iz,Irr,qrr,Nrr,gT,jrr,_o,kL,Drr,Aue,Grr,Orr,Qa,Vrr,yue,Xrr,zrr,Lue,Wrr,Qrr,xue,Hrr,Urr,Jrr,SL,hT,$ue,Yrr,Krr,dz,Zrr,etr,otr,pT,kue,rtr,ttr,cz,atr,ntr,str,_T,ltr,Sue,itr,dtr,Rue,ctr,ftr,uT,Hqe,kd,bT,Pue,RL,mtr,Bue,gtr,Uqe,Ho,PL,htr,Sd,ptr,fz,_tr,utr,mz,btr,vtr,Ftr,BL,Ttr,Iue,Mtr,Etr,Ctr,Ct,IL,wtr,que,Atr,ytr,Rd,Ltr,Nue,xtr,$tr,gz,ktr,Str,Rtr,vT,Ptr,uo,qL,Btr,jue,Itr,qtr,Ha,Ntr,Due,jtr,Dtr,Gue,Gtr,Otr,Oue,Vtr,Xtr,ztr,Vue,FT,Xue,Wtr,Qtr,hz,Htr,Utr,Jtr,TT,Ytr,zue,Ktr,Ztr,Wue,ear,oar,MT,Jqe,Pd,ET,Que,NL,rar,Hue,tar,Yqe,Uo,jL,aar,Bd,nar,pz,sar,lar,_z,iar,dar,car,DL,far,Uue,mar,gar,har,wt,GL,par,Jue,_ar,uar,Id,bar,Yue,Far,Tar,uz,Mar,Ear,Car,CT,war,bo,OL,Aar,Kue,yar,Lar,Ua,xar,Zue,$ar,kar,e2e,Sar,Rar,o2e,Par,Bar,Iar,Ja,wT,r2e,qar,Nar,bz,jar,Dar,Gar,AT,t2e,Oar,Var,vz,Xar,zar,War,yT,a2e,Qar,Har,Fz,Uar,Jar,Yar,LT,n2e,Kar,Zar,Tz,enr,onr,rnr,xT,tnr,s2e,anr,nnr,l2e,snr,lnr,$T,Kqe,qd,kT,i2e,VL,inr,d2e,dnr,Zqe,Jo,XL,cnr,Nd,fnr,Mz,mnr,gnr,Ez,hnr,pnr,_nr,zL,unr,c2e,bnr,vnr,Fnr,At,WL,Tnr,f2e,Mnr,Enr,jd,Cnr,m2e,wnr,Anr,Cz,ynr,Lnr,xnr,ST,$nr,vo,QL,knr,g2e,Snr,Rnr,Ya,Pnr,h2e,Bnr,Inr,p2e,qnr,Nnr,_2e,jnr,Dnr,Gnr,u2e,RT,b2e,Onr,Vnr,wz,Xnr,znr,Wnr,PT,Qnr,v2e,Hnr,Unr,F2e,Jnr,Ynr,BT,eNe,Dd,IT,T2e,HL,Knr,M2e,Znr,oNe,Yo,UL,esr,Gd,osr,Az,rsr,tsr,yz,asr,nsr,ssr,JL,lsr,E2e,isr,dsr,csr,yt,YL,fsr,C2e,msr,gsr,Od,hsr,w2e,psr,_sr,Lz,usr,bsr,vsr,qT,Fsr,wr,KL,Tsr,A2e,Msr,Esr,Ka,Csr,y2e,wsr,Asr,L2e,ysr,Lsr,x2e,xsr,$sr,ksr,q,NT,$2e,Ssr,Rsr,xz,Psr,Bsr,Isr,jT,k2e,qsr,Nsr,$z,jsr,Dsr,Gsr,DT,S2e,Osr,Vsr,kz,Xsr,zsr,Wsr,GT,R2e,Qsr,Hsr,Sz,Usr,Jsr,Ysr,OT,P2e,Ksr,Zsr,Rz,elr,olr,rlr,VT,B2e,tlr,alr,Pz,nlr,slr,llr,XT,I2e,ilr,dlr,Bz,clr,flr,mlr,zT,q2e,glr,hlr,Iz,plr,_lr,ulr,WT,N2e,blr,vlr,qz,Flr,Tlr,Mlr,QT,j2e,Elr,Clr,Nz,wlr,Alr,ylr,HT,D2e,Llr,xlr,jz,$lr,klr,Slr,UT,G2e,Rlr,Plr,Dz,Blr,Ilr,qlr,JT,O2e,Nlr,jlr,Gz,Dlr,Glr,Olr,YT,V2e,Vlr,Xlr,Oz,zlr,Wlr,Qlr,KT,X2e,Hlr,Ulr,Vz,Jlr,Ylr,Klr,ZT,z2e,Zlr,eir,Xz,oir,rir,tir,eM,W2e,air,nir,zz,sir,lir,iir,Bs,Q2e,dir,cir,Wz,fir,mir,Qz,gir,hir,pir,oM,H2e,_ir,uir,Hz,bir,vir,Fir,rM,U2e,Tir,Mir,Uz,Eir,Cir,wir,tM,J2e,Air,yir,Jz,Lir,xir,$ir,aM,Y2e,kir,Sir,Yz,Rir,Pir,Bir,nM,K2e,Iir,qir,Kz,Nir,jir,Dir,sM,Z2e,Gir,Oir,Zz,Vir,Xir,zir,lM,e1e,Wir,Qir,eW,Hir,Uir,Jir,iM,o1e,Yir,Kir,oW,Zir,edr,odr,dM,r1e,rdr,tdr,rW,adr,ndr,sdr,cM,t1e,ldr,idr,tW,ddr,cdr,fdr,fM,a1e,mdr,gdr,aW,hdr,pdr,_dr,mM,n1e,udr,bdr,nW,vdr,Fdr,Tdr,gM,s1e,Mdr,Edr,sW,Cdr,wdr,Adr,hM,l1e,ydr,Ldr,lW,xdr,$dr,kdr,pM,i1e,Sdr,Rdr,iW,Pdr,Bdr,Idr,_M,d1e,qdr,Ndr,dW,jdr,Ddr,Gdr,uM,c1e,Odr,Vdr,cW,Xdr,zdr,Wdr,bM,f1e,Qdr,Hdr,fW,Udr,Jdr,Ydr,vM,m1e,Kdr,Zdr,mW,ecr,ocr,rcr,FM,g1e,tcr,acr,gW,ncr,scr,lcr,TM,h1e,icr,dcr,hW,ccr,fcr,mcr,MM,p1e,gcr,hcr,pW,pcr,_cr,ucr,EM,_1e,bcr,vcr,_W,Fcr,Tcr,Mcr,CM,u1e,Ecr,Ccr,uW,wcr,Acr,ycr,wM,b1e,Lcr,xcr,bW,$cr,kcr,Scr,AM,v1e,Rcr,Pcr,vW,Bcr,Icr,qcr,yM,F1e,Ncr,jcr,FW,Dcr,Gcr,Ocr,LM,T1e,Vcr,Xcr,TW,zcr,Wcr,Qcr,xM,M1e,Hcr,Ucr,MW,Jcr,Ycr,Kcr,$M,rNe,Vd,kM,E1e,ZL,Zcr,C1e,efr,tNe,Ko,e8,ofr,Xd,rfr,EW,tfr,afr,CW,nfr,sfr,lfr,o8,ifr,w1e,dfr,cfr,ffr,Lt,r8,mfr,A1e,gfr,hfr,zd,pfr,y1e,_fr,ufr,wW,bfr,vfr,Ffr,SM,Tfr,Ar,t8,Mfr,L1e,Efr,Cfr,Za,wfr,x1e,Afr,yfr,$1e,Lfr,xfr,k1e,$fr,kfr,Sfr,se,RM,S1e,Rfr,Pfr,AW,Bfr,Ifr,qfr,PM,R1e,Nfr,jfr,yW,Dfr,Gfr,Ofr,BM,P1e,Vfr,Xfr,LW,zfr,Wfr,Qfr,IM,B1e,Hfr,Ufr,xW,Jfr,Yfr,Kfr,qM,I1e,Zfr,emr,$W,omr,rmr,tmr,NM,q1e,amr,nmr,kW,smr,lmr,imr,jM,N1e,dmr,cmr,SW,fmr,mmr,gmr,DM,j1e,hmr,pmr,RW,_mr,umr,bmr,GM,D1e,vmr,Fmr,PW,Tmr,Mmr,Emr,OM,G1e,Cmr,wmr,BW,Amr,ymr,Lmr,VM,O1e,xmr,$mr,IW,kmr,Smr,Rmr,XM,V1e,Pmr,Bmr,qW,Imr,qmr,Nmr,zM,X1e,jmr,Dmr,NW,Gmr,Omr,Vmr,WM,z1e,Xmr,zmr,jW,Wmr,Qmr,Hmr,QM,W1e,Umr,Jmr,DW,Ymr,Kmr,Zmr,HM,Q1e,egr,ogr,GW,rgr,tgr,agr,UM,H1e,ngr,sgr,OW,lgr,igr,dgr,JM,U1e,cgr,fgr,VW,mgr,ggr,hgr,YM,J1e,pgr,_gr,XW,ugr,bgr,vgr,KM,Y1e,Fgr,Tgr,zW,Mgr,Egr,Cgr,ZM,K1e,wgr,Agr,WW,ygr,Lgr,xgr,e4,Z1e,$gr,kgr,QW,Sgr,Rgr,Pgr,o4,e7e,Bgr,Igr,HW,qgr,Ngr,jgr,r4,aNe,Wd,t4,o7e,a8,Dgr,r7e,Ggr,nNe,Zo,n8,Ogr,Qd,Vgr,UW,Xgr,zgr,JW,Wgr,Qgr,Hgr,s8,Ugr,t7e,Jgr,Ygr,Kgr,xt,l8,Zgr,a7e,ehr,ohr,Hd,rhr,n7e,thr,ahr,YW,nhr,shr,lhr,a4,ihr,yr,i8,dhr,s7e,chr,fhr,en,mhr,l7e,ghr,hhr,i7e,phr,_hr,d7e,uhr,bhr,vhr,Te,n4,c7e,Fhr,Thr,KW,Mhr,Ehr,Chr,s4,f7e,whr,Ahr,ZW,yhr,Lhr,xhr,l4,m7e,$hr,khr,eQ,Shr,Rhr,Phr,i4,g7e,Bhr,Ihr,oQ,qhr,Nhr,jhr,d4,h7e,Dhr,Ghr,rQ,Ohr,Vhr,Xhr,c4,p7e,zhr,Whr,tQ,Qhr,Hhr,Uhr,f4,_7e,Jhr,Yhr,aQ,Khr,Zhr,epr,m4,u7e,opr,rpr,nQ,tpr,apr,npr,g4,b7e,spr,lpr,sQ,ipr,dpr,cpr,h4,v7e,fpr,mpr,lQ,gpr,hpr,ppr,p4,F7e,_pr,upr,iQ,bpr,vpr,Fpr,_4,T7e,Tpr,Mpr,dQ,Epr,Cpr,wpr,u4,sNe,Ud,b4,M7e,d8,Apr,E7e,ypr,lNe,er,c8,Lpr,Jd,xpr,cQ,$pr,kpr,fQ,Spr,Rpr,Ppr,f8,Bpr,C7e,Ipr,qpr,Npr,$t,m8,jpr,w7e,Dpr,Gpr,Yd,Opr,A7e,Vpr,Xpr,mQ,zpr,Wpr,Qpr,v4,Hpr,Lr,g8,Upr,y7e,Jpr,Ypr,on,Kpr,L7e,Zpr,e_r,x7e,o_r,r_r,$7e,t_r,a_r,n_r,rn,F4,k7e,s_r,l_r,gQ,i_r,d_r,c_r,T4,S7e,f_r,m_r,hQ,g_r,h_r,p_r,M4,R7e,__r,u_r,pQ,b_r,v_r,F_r,E4,P7e,T_r,M_r,_Q,E_r,C_r,w_r,C4,iNe,Kd,w4,B7e,h8,A_r,I7e,y_r,dNe,or,p8,L_r,Zd,x_r,uQ,$_r,k_r,bQ,S_r,R_r,P_r,_8,B_r,q7e,I_r,q_r,N_r,kt,u8,j_r,N7e,D_r,G_r,ec,O_r,j7e,V_r,X_r,vQ,z_r,W_r,Q_r,A4,H_r,xr,b8,U_r,D7e,J_r,Y_r,tn,K_r,G7e,Z_r,eur,O7e,our,rur,V7e,tur,aur,nur,ie,y4,X7e,sur,lur,FQ,iur,dur,cur,L4,z7e,fur,mur,TQ,gur,hur,pur,x4,W7e,_ur,uur,MQ,bur,vur,Fur,$4,Q7e,Tur,Mur,EQ,Eur,Cur,wur,k4,H7e,Aur,yur,CQ,Lur,xur,$ur,S4,U7e,kur,Sur,wQ,Rur,Pur,Bur,R4,J7e,Iur,qur,AQ,Nur,jur,Dur,P4,Y7e,Gur,Our,yQ,Vur,Xur,zur,B4,K7e,Wur,Qur,LQ,Hur,Uur,Jur,I4,Z7e,Yur,Kur,xQ,Zur,e2r,o2r,q4,ebe,r2r,t2r,$Q,a2r,n2r,s2r,N4,obe,l2r,i2r,kQ,d2r,c2r,f2r,j4,rbe,m2r,g2r,SQ,h2r,p2r,_2r,D4,tbe,u2r,b2r,RQ,v2r,F2r,T2r,G4,abe,M2r,E2r,PQ,C2r,w2r,A2r,O4,nbe,y2r,L2r,BQ,x2r,$2r,k2r,V4,sbe,S2r,R2r,IQ,P2r,B2r,I2r,X4,lbe,q2r,N2r,qQ,j2r,D2r,G2r,z4,ibe,O2r,V2r,NQ,X2r,z2r,W2r,W4,dbe,Q2r,H2r,jQ,U2r,J2r,Y2r,Q4,cNe,oc,H4,cbe,v8,K2r,fbe,Z2r,fNe,rr,F8,e1r,rc,o1r,DQ,r1r,t1r,GQ,a1r,n1r,s1r,T8,l1r,mbe,i1r,d1r,c1r,St,M8,f1r,gbe,m1r,g1r,tc,h1r,hbe,p1r,_1r,OQ,u1r,b1r,v1r,U4,F1r,$r,E8,T1r,pbe,M1r,E1r,an,C1r,_be,w1r,A1r,ube,y1r,L1r,bbe,x1r,$1r,k1r,ye,J4,vbe,S1r,R1r,VQ,P1r,B1r,I1r,Y4,Fbe,q1r,N1r,XQ,j1r,D1r,G1r,K4,Tbe,O1r,V1r,zQ,X1r,z1r,W1r,Z4,Mbe,Q1r,H1r,WQ,U1r,J1r,Y1r,eE,Ebe,K1r,Z1r,QQ,e7r,o7r,r7r,oE,Cbe,t7r,a7r,HQ,n7r,s7r,l7r,rE,wbe,i7r,d7r,UQ,c7r,f7r,m7r,tE,Abe,g7r,h7r,JQ,p7r,_7r,u7r,aE,ybe,b7r,v7r,YQ,F7r,T7r,M7r,nE,Lbe,E7r,C7r,KQ,w7r,A7r,y7r,sE,mNe,ac,lE,xbe,C8,L7r,$be,x7r,gNe,tr,w8,$7r,nc,k7r,ZQ,S7r,R7r,eH,P7r,B7r,I7r,A8,q7r,kbe,N7r,j7r,D7r,Rt,y8,G7r,Sbe,O7r,V7r,sc,X7r,Rbe,z7r,W7r,oH,Q7r,H7r,U7r,iE,J7r,kr,L8,Y7r,Pbe,K7r,Z7r,nn,ebr,Bbe,obr,rbr,Ibe,tbr,abr,qbe,nbr,sbr,lbr,ee,dE,Nbe,ibr,dbr,rH,cbr,fbr,mbr,cE,jbe,gbr,hbr,tH,pbr,_br,ubr,fE,Dbe,bbr,vbr,aH,Fbr,Tbr,Mbr,mE,Gbe,Ebr,Cbr,nH,wbr,Abr,ybr,gE,Obe,Lbr,xbr,sH,$br,kbr,Sbr,hE,Vbe,Rbr,Pbr,lH,Bbr,Ibr,qbr,pE,Xbe,Nbr,jbr,iH,Dbr,Gbr,Obr,_E,zbe,Vbr,Xbr,dH,zbr,Wbr,Qbr,uE,Wbe,Hbr,Ubr,cH,Jbr,Ybr,Kbr,bE,Qbe,Zbr,evr,fH,ovr,rvr,tvr,vE,Hbe,avr,nvr,mH,svr,lvr,ivr,FE,Ube,dvr,cvr,gH,fvr,mvr,gvr,TE,Jbe,hvr,pvr,hH,_vr,uvr,bvr,ME,Ybe,vvr,Fvr,pH,Tvr,Mvr,Evr,EE,Kbe,Cvr,wvr,_H,Avr,yvr,Lvr,CE,Zbe,xvr,$vr,uH,kvr,Svr,Rvr,wE,eve,Pvr,Bvr,bH,Ivr,qvr,Nvr,AE,ove,jvr,Dvr,vH,Gvr,Ovr,Vvr,yE,rve,Xvr,zvr,FH,Wvr,Qvr,Hvr,LE,tve,Uvr,Jvr,TH,Yvr,Kvr,Zvr,xE,ave,eFr,oFr,MH,rFr,tFr,aFr,$E,nve,nFr,sFr,EH,lFr,iFr,dFr,kE,sve,cFr,fFr,CH,mFr,gFr,hFr,SE,lve,pFr,_Fr,wH,uFr,bFr,vFr,RE,ive,FFr,TFr,AH,MFr,EFr,CFr,PE,dve,wFr,AFr,yH,yFr,LFr,xFr,BE,hNe,lc,IE,cve,x8,$Fr,fve,kFr,pNe,ar,$8,SFr,ic,RFr,LH,PFr,BFr,xH,IFr,qFr,NFr,k8,jFr,mve,DFr,GFr,OFr,Pt,S8,VFr,gve,XFr,zFr,dc,WFr,hve,QFr,HFr,$H,UFr,JFr,YFr,qE,KFr,Sr,R8,ZFr,pve,eTr,oTr,sn,rTr,_ve,tTr,aTr,uve,nTr,sTr,bve,lTr,iTr,dTr,he,NE,vve,cTr,fTr,kH,mTr,gTr,hTr,jE,Fve,pTr,_Tr,SH,uTr,bTr,vTr,DE,Tve,FTr,TTr,RH,MTr,ETr,CTr,GE,Mve,wTr,ATr,PH,yTr,LTr,xTr,OE,Eve,$Tr,kTr,BH,STr,RTr,PTr,VE,Cve,BTr,ITr,IH,qTr,NTr,jTr,XE,wve,DTr,GTr,qH,OTr,VTr,XTr,zE,Ave,zTr,WTr,NH,QTr,HTr,UTr,WE,yve,JTr,YTr,jH,KTr,ZTr,eMr,QE,Lve,oMr,rMr,DH,tMr,aMr,nMr,HE,xve,sMr,lMr,GH,iMr,dMr,cMr,UE,$ve,fMr,mMr,OH,gMr,hMr,pMr,JE,kve,_Mr,uMr,VH,bMr,vMr,FMr,YE,Sve,TMr,MMr,XH,EMr,CMr,wMr,KE,Rve,AMr,yMr,zH,LMr,xMr,$Mr,ZE,Pve,kMr,SMr,WH,RMr,PMr,BMr,eC,Bve,IMr,qMr,QH,NMr,jMr,DMr,oC,_Ne,cc,rC,Ive,P8,GMr,qve,OMr,uNe,nr,B8,VMr,fc,XMr,HH,zMr,WMr,UH,QMr,HMr,UMr,I8,JMr,Nve,YMr,KMr,ZMr,Bt,q8,e4r,jve,o4r,r4r,mc,t4r,Dve,a4r,n4r,JH,s4r,l4r,i4r,tC,d4r,Rr,N8,c4r,Gve,f4r,m4r,ln,g4r,Ove,h4r,p4r,Vve,_4r,u4r,Xve,b4r,v4r,F4r,j8,aC,zve,T4r,M4r,YH,E4r,C4r,w4r,nC,Wve,A4r,y4r,KH,L4r,x4r,$4r,sC,bNe,gc,lC,Qve,D8,k4r,Hve,S4r,vNe,sr,G8,R4r,hc,P4r,ZH,B4r,I4r,eU,q4r,N4r,j4r,O8,D4r,Uve,G4r,O4r,V4r,It,V8,X4r,Jve,z4r,W4r,pc,Q4r,Yve,H4r,U4r,oU,J4r,Y4r,K4r,iC,Z4r,Pr,X8,eEr,Kve,oEr,rEr,dn,tEr,Zve,aEr,nEr,eFe,sEr,lEr,oFe,iEr,dEr,cEr,rFe,dC,tFe,fEr,mEr,rU,gEr,hEr,pEr,cC,FNe,_c,fC,aFe,z8,_Er,nFe,uEr,TNe,lr,W8,bEr,uc,vEr,tU,FEr,TEr,aU,MEr,EEr,CEr,Q8,wEr,sFe,AEr,yEr,LEr,qt,H8,xEr,lFe,$Er,kEr,bc,SEr,iFe,REr,PEr,nU,BEr,IEr,qEr,mC,NEr,Br,U8,jEr,dFe,DEr,GEr,cn,OEr,cFe,VEr,XEr,fFe,zEr,WEr,mFe,QEr,HEr,UEr,de,gC,gFe,JEr,YEr,sU,KEr,ZEr,eCr,hC,hFe,oCr,rCr,lU,tCr,aCr,nCr,pC,pFe,sCr,lCr,iU,iCr,dCr,cCr,_C,_Fe,fCr,mCr,dU,gCr,hCr,pCr,uC,uFe,_Cr,uCr,cU,bCr,vCr,FCr,bC,bFe,TCr,MCr,fU,ECr,CCr,wCr,vC,vFe,ACr,yCr,mU,LCr,xCr,$Cr,FC,FFe,kCr,SCr,gU,RCr,PCr,BCr,TC,TFe,ICr,qCr,hU,NCr,jCr,DCr,MC,MFe,GCr,OCr,pU,VCr,XCr,zCr,EC,EFe,WCr,QCr,_U,HCr,UCr,JCr,CC,CFe,YCr,KCr,uU,ZCr,e5r,o5r,wC,wFe,r5r,t5r,bU,a5r,n5r,s5r,AC,AFe,l5r,i5r,vU,d5r,c5r,f5r,yC,yFe,m5r,g5r,FU,h5r,p5r,_5r,LC,LFe,u5r,b5r,TU,v5r,F5r,T5r,xC,xFe,M5r,E5r,MU,C5r,w5r,A5r,$C,$Fe,y5r,L5r,EU,x5r,$5r,k5r,kC,kFe,S5r,R5r,CU,P5r,B5r,I5r,SC,SFe,q5r,N5r,wU,j5r,D5r,G5r,RC,MNe,vc,PC,RFe,J8,O5r,PFe,V5r,ENe,ir,Y8,X5r,Fc,z5r,AU,W5r,Q5r,yU,H5r,U5r,J5r,K8,Y5r,BFe,K5r,Z5r,e3r,Nt,Z8,o3r,IFe,r3r,t3r,Tc,a3r,qFe,n3r,s3r,LU,l3r,i3r,d3r,BC,c3r,Ir,ex,f3r,NFe,m3r,g3r,fn,h3r,jFe,p3r,_3r,DFe,u3r,b3r,GFe,v3r,F3r,T3r,ce,IC,OFe,M3r,E3r,xU,C3r,w3r,A3r,qC,VFe,y3r,L3r,$U,x3r,$3r,k3r,NC,XFe,S3r,R3r,kU,P3r,B3r,I3r,jC,zFe,q3r,N3r,SU,j3r,D3r,G3r,DC,WFe,O3r,V3r,RU,X3r,z3r,W3r,GC,QFe,Q3r,H3r,PU,U3r,J3r,Y3r,OC,HFe,K3r,Z3r,BU,ewr,owr,rwr,VC,UFe,twr,awr,IU,nwr,swr,lwr,XC,JFe,iwr,dwr,qU,cwr,fwr,mwr,zC,YFe,gwr,hwr,NU,pwr,_wr,uwr,WC,KFe,bwr,vwr,jU,Fwr,Twr,Mwr,QC,ZFe,Ewr,Cwr,DU,wwr,Awr,ywr,HC,eTe,Lwr,xwr,GU,$wr,kwr,Swr,UC,oTe,Rwr,Pwr,OU,Bwr,Iwr,qwr,JC,rTe,Nwr,jwr,VU,Dwr,Gwr,Owr,YC,tTe,Vwr,Xwr,XU,zwr,Wwr,Qwr,KC,aTe,Hwr,Uwr,zU,Jwr,Ywr,Kwr,ZC,nTe,Zwr,e0r,WU,o0r,r0r,t0r,e5,sTe,a0r,n0r,QU,s0r,l0r,i0r,o5,lTe,d0r,c0r,HU,f0r,m0r,g0r,r5,CNe,Mc,t5,iTe,ox,h0r,dTe,p0r,wNe,dr,rx,_0r,Ec,u0r,UU,b0r,v0r,JU,F0r,T0r,M0r,tx,E0r,cTe,C0r,w0r,A0r,jt,ax,y0r,fTe,L0r,x0r,Cc,$0r,mTe,k0r,S0r,YU,R0r,P0r,B0r,a5,I0r,qr,nx,q0r,gTe,N0r,j0r,mn,D0r,hTe,G0r,O0r,pTe,V0r,X0r,_Te,z0r,W0r,Q0r,uTe,n5,bTe,H0r,U0r,KU,J0r,Y0r,K0r,s5,ANe,wc,l5,vTe,sx,Z0r,FTe,eAr,yNe,cr,lx,oAr,Ac,rAr,ZU,tAr,aAr,eJ,nAr,sAr,lAr,ix,iAr,TTe,dAr,cAr,fAr,Dt,dx,mAr,MTe,gAr,hAr,yc,pAr,ETe,_Ar,uAr,oJ,bAr,vAr,FAr,i5,TAr,Nr,cx,MAr,CTe,EAr,CAr,gn,wAr,wTe,AAr,yAr,ATe,LAr,xAr,yTe,$Ar,kAr,SAr,LTe,d5,xTe,RAr,PAr,rJ,BAr,IAr,qAr,c5,LNe,Lc,f5,$Te,fx,NAr,kTe,jAr,xNe,fr,mx,DAr,xc,GAr,tJ,OAr,VAr,aJ,XAr,zAr,WAr,gx,QAr,STe,HAr,UAr,JAr,Gt,hx,YAr,RTe,KAr,ZAr,$c,e6r,PTe,o6r,r6r,nJ,t6r,a6r,n6r,m5,s6r,jr,px,l6r,BTe,i6r,d6r,hn,c6r,ITe,f6r,m6r,qTe,g6r,h6r,NTe,p6r,_6r,u6r,oe,g5,jTe,b6r,v6r,sJ,F6r,T6r,M6r,h5,DTe,E6r,C6r,lJ,w6r,A6r,y6r,p5,GTe,L6r,x6r,iJ,$6r,k6r,S6r,_5,OTe,R6r,P6r,dJ,B6r,I6r,q6r,u5,VTe,N6r,j6r,cJ,D6r,G6r,O6r,b5,XTe,V6r,X6r,fJ,z6r,W6r,Q6r,v5,zTe,H6r,U6r,mJ,J6r,Y6r,K6r,F5,WTe,Z6r,eyr,gJ,oyr,ryr,tyr,T5,QTe,ayr,nyr,hJ,syr,lyr,iyr,M5,HTe,dyr,cyr,pJ,fyr,myr,gyr,E5,UTe,hyr,pyr,_J,_yr,uyr,byr,C5,JTe,vyr,Fyr,uJ,Tyr,Myr,Eyr,w5,YTe,Cyr,wyr,bJ,Ayr,yyr,Lyr,A5,KTe,xyr,$yr,vJ,kyr,Syr,Ryr,y5,ZTe,Pyr,Byr,FJ,Iyr,qyr,Nyr,L5,eMe,jyr,Dyr,TJ,Gyr,Oyr,Vyr,x5,oMe,Xyr,zyr,MJ,Wyr,Qyr,Hyr,$5,rMe,Uyr,Jyr,EJ,Yyr,Kyr,Zyr,k5,tMe,eLr,oLr,CJ,rLr,tLr,aLr,S5,aMe,nLr,sLr,wJ,lLr,iLr,dLr,R5,nMe,cLr,fLr,AJ,mLr,gLr,hLr,P5,sMe,pLr,_Lr,yJ,uLr,bLr,vLr,B5,lMe,FLr,TLr,LJ,MLr,ELr,CLr,I5,iMe,wLr,ALr,xJ,yLr,LLr,xLr,q5,dMe,$Lr,kLr,$J,SLr,RLr,PLr,N5,cMe,BLr,ILr,kJ,qLr,NLr,jLr,j5,$Ne,kc,D5,fMe,_x,DLr,mMe,GLr,kNe,mr,ux,OLr,Sc,VLr,SJ,XLr,zLr,RJ,WLr,QLr,HLr,bx,ULr,gMe,JLr,YLr,KLr,Ot,vx,ZLr,hMe,e8r,o8r,Rc,r8r,pMe,t8r,a8r,PJ,n8r,s8r,l8r,G5,i8r,Dr,Fx,d8r,_Me,c8r,f8r,pn,m8r,uMe,g8r,h8r,bMe,p8r,_8r,vMe,u8r,b8r,v8r,Le,O5,FMe,F8r,T8r,BJ,M8r,E8r,C8r,V5,TMe,w8r,A8r,IJ,y8r,L8r,x8r,X5,MMe,$8r,k8r,qJ,S8r,R8r,P8r,z5,EMe,B8r,I8r,NJ,q8r,N8r,j8r,W5,CMe,D8r,G8r,jJ,O8r,V8r,X8r,Q5,wMe,z8r,W8r,DJ,Q8r,H8r,U8r,H5,AMe,J8r,Y8r,GJ,K8r,Z8r,exr,U5,yMe,oxr,rxr,OJ,txr,axr,nxr,J5,LMe,sxr,lxr,VJ,ixr,dxr,cxr,Y5,xMe,fxr,mxr,XJ,gxr,hxr,pxr,K5,SNe,Pc,Z5,$Me,Tx,_xr,kMe,uxr,RNe,gr,Mx,bxr,Bc,vxr,zJ,Fxr,Txr,WJ,Mxr,Exr,Cxr,Ex,wxr,SMe,Axr,yxr,Lxr,Vt,Cx,xxr,RMe,$xr,kxr,Ic,Sxr,PMe,Rxr,Pxr,QJ,Bxr,Ixr,qxr,e3,Nxr,Gr,wx,jxr,BMe,Dxr,Gxr,_n,Oxr,IMe,Vxr,Xxr,qMe,zxr,Wxr,NMe,Qxr,Hxr,Uxr,Me,o3,jMe,Jxr,Yxr,HJ,Kxr,Zxr,e9r,r3,DMe,o9r,r9r,UJ,t9r,a9r,n9r,t3,GMe,s9r,l9r,JJ,i9r,d9r,c9r,a3,OMe,f9r,m9r,YJ,g9r,h9r,p9r,n3,VMe,_9r,u9r,KJ,b9r,v9r,F9r,s3,XMe,T9r,M9r,ZJ,E9r,C9r,w9r,l3,zMe,A9r,y9r,eY,L9r,x9r,$9r,i3,WMe,k9r,S9r,oY,R9r,P9r,B9r,d3,QMe,I9r,q9r,rY,N9r,j9r,D9r,c3,HMe,G9r,O9r,tY,V9r,X9r,z9r,f3,UMe,W9r,Q9r,aY,H9r,U9r,J9r,m3,JMe,Y9r,K9r,nY,Z9r,e$r,o$r,g3,PNe,qc,h3,YMe,Ax,r$r,KMe,t$r,BNe,hr,yx,a$r,Nc,n$r,sY,s$r,l$r,lY,i$r,d$r,c$r,Lx,f$r,ZMe,m$r,g$r,h$r,Xt,xx,p$r,e4e,_$r,u$r,jc,b$r,o4e,v$r,F$r,iY,T$r,M$r,E$r,p3,C$r,Or,$x,w$r,r4e,A$r,y$r,un,L$r,t4e,x$r,$$r,a4e,k$r,S$r,n4e,R$r,P$r,B$r,xe,_3,s4e,I$r,q$r,dY,N$r,j$r,D$r,u3,l4e,G$r,O$r,cY,V$r,X$r,z$r,b3,i4e,W$r,Q$r,fY,H$r,U$r,J$r,v3,d4e,Y$r,K$r,mY,Z$r,ekr,okr,F3,c4e,rkr,tkr,gY,akr,nkr,skr,T3,f4e,lkr,ikr,hY,dkr,ckr,fkr,M3,m4e,mkr,gkr,pY,hkr,pkr,_kr,E3,g4e,ukr,bkr,_Y,vkr,Fkr,Tkr,C3,h4e,Mkr,Ekr,uY,Ckr,wkr,Akr,w3,p4e,ykr,Lkr,bY,xkr,$kr,kkr,A3,INe,Dc,y3,_4e,kx,Skr,u4e,Rkr,qNe,pr,Sx,Pkr,Gc,Bkr,vY,Ikr,qkr,FY,Nkr,jkr,Dkr,Rx,Gkr,b4e,Okr,Vkr,Xkr,zt,Px,zkr,v4e,Wkr,Qkr,Oc,Hkr,F4e,Ukr,Jkr,TY,Ykr,Kkr,Zkr,L3,eSr,Vr,Bx,oSr,T4e,rSr,tSr,bn,aSr,M4e,nSr,sSr,E4e,lSr,iSr,C4e,dSr,cSr,fSr,Pe,x3,w4e,mSr,gSr,MY,hSr,pSr,_Sr,$3,A4e,uSr,bSr,EY,vSr,FSr,TSr,k3,y4e,MSr,ESr,CY,CSr,wSr,ASr,S3,L4e,ySr,LSr,wY,xSr,$Sr,kSr,R3,x4e,SSr,RSr,AY,PSr,BSr,ISr,P3,$4e,qSr,NSr,yY,jSr,DSr,GSr,B3,k4e,OSr,VSr,LY,XSr,zSr,WSr,I3,S4e,QSr,HSr,xY,USr,JSr,YSr,q3,R4e,KSr,ZSr,$Y,eRr,oRr,rRr,N3,NNe,Vc,j3,P4e,Ix,tRr,B4e,aRr,jNe,_r,qx,nRr,Xc,sRr,kY,lRr,iRr,SY,dRr,cRr,fRr,Nx,mRr,I4e,gRr,hRr,pRr,Wt,jx,_Rr,q4e,uRr,bRr,zc,vRr,N4e,FRr,TRr,RY,MRr,ERr,CRr,D3,wRr,Xr,Dx,ARr,j4e,yRr,LRr,vn,xRr,D4e,$Rr,kRr,G4e,SRr,RRr,O4e,PRr,BRr,IRr,$e,G3,V4e,qRr,NRr,PY,jRr,DRr,GRr,O3,X4e,ORr,VRr,BY,XRr,zRr,WRr,V3,z4e,QRr,HRr,IY,URr,JRr,YRr,X3,W4e,KRr,ZRr,qY,ePr,oPr,rPr,z3,Q4e,tPr,aPr,NY,nPr,sPr,lPr,W3,H4e,iPr,dPr,jY,cPr,fPr,mPr,Q3,U4e,gPr,hPr,DY,pPr,_Pr,uPr,H3,J4e,bPr,vPr,GY,FPr,TPr,MPr,U3,Y4e,EPr,CPr,OY,wPr,APr,yPr,J3,K4e,LPr,xPr,VY,$Pr,kPr,SPr,Y3,DNe,Wc,K3,Z4e,Gx,RPr,eEe,PPr,GNe,ur,Ox,BPr,Qc,IPr,XY,qPr,NPr,zY,jPr,DPr,GPr,Vx,OPr,oEe,VPr,XPr,zPr,Qt,Xx,WPr,rEe,QPr,HPr,Hc,UPr,tEe,JPr,YPr,WY,KPr,ZPr,eBr,Z3,oBr,zr,zx,rBr,aEe,tBr,aBr,Fn,nBr,nEe,sBr,lBr,sEe,iBr,dBr,lEe,cBr,fBr,mBr,ke,ew,iEe,gBr,hBr,QY,pBr,_Br,uBr,ow,dEe,bBr,vBr,HY,FBr,TBr,MBr,rw,cEe,EBr,CBr,UY,wBr,ABr,yBr,tw,fEe,LBr,xBr,JY,$Br,kBr,SBr,aw,mEe,RBr,PBr,YY,BBr,IBr,qBr,nw,gEe,NBr,jBr,KY,DBr,GBr,OBr,sw,hEe,VBr,XBr,ZY,zBr,WBr,QBr,lw,pEe,HBr,UBr,eK,JBr,YBr,KBr,iw,_Ee,ZBr,eIr,oK,oIr,rIr,tIr,dw,uEe,aIr,nIr,rK,sIr,lIr,iIr,cw,ONe,Uc,fw,bEe,Wx,dIr,vEe,cIr,VNe,br,Qx,fIr,Jc,mIr,tK,gIr,hIr,aK,pIr,_Ir,uIr,Hx,bIr,FEe,vIr,FIr,TIr,Ht,Ux,MIr,TEe,EIr,CIr,Yc,wIr,MEe,AIr,yIr,nK,LIr,xIr,$Ir,mw,kIr,Wr,Jx,SIr,EEe,RIr,PIr,Tn,BIr,CEe,IIr,qIr,wEe,NIr,jIr,AEe,DIr,GIr,OIr,Ge,gw,yEe,VIr,XIr,sK,zIr,WIr,QIr,hw,LEe,HIr,UIr,lK,JIr,YIr,KIr,pw,xEe,ZIr,eqr,iK,oqr,rqr,tqr,_w,$Ee,aqr,nqr,dK,sqr,lqr,iqr,uw,kEe,dqr,cqr,cK,fqr,mqr,gqr,bw,SEe,hqr,pqr,fK,_qr,uqr,bqr,vw,REe,vqr,Fqr,mK,Tqr,Mqr,Eqr,Fw,PEe,Cqr,wqr,gK,Aqr,yqr,Lqr,Tw,XNe,Kc,Mw,BEe,Yx,xqr,IEe,$qr,zNe,vr,Kx,kqr,Zc,Sqr,hK,Rqr,Pqr,pK,Bqr,Iqr,qqr,Zx,Nqr,qEe,jqr,Dqr,Gqr,Ut,e9,Oqr,NEe,Vqr,Xqr,ef,zqr,jEe,Wqr,Qqr,_K,Hqr,Uqr,Jqr,Ew,Yqr,Qr,o9,Kqr,DEe,Zqr,eNr,Mn,oNr,GEe,rNr,tNr,OEe,aNr,nNr,VEe,sNr,lNr,iNr,Oe,Cw,XEe,dNr,cNr,uK,fNr,mNr,gNr,ww,zEe,hNr,pNr,bK,_Nr,uNr,bNr,Aw,WEe,vNr,FNr,vK,TNr,MNr,ENr,yw,QEe,CNr,wNr,FK,ANr,yNr,LNr,Lw,HEe,xNr,$Nr,TK,kNr,SNr,RNr,xw,UEe,PNr,BNr,MK,INr,qNr,NNr,$w,JEe,jNr,DNr,EK,GNr,ONr,VNr,kw,YEe,XNr,zNr,CK,WNr,QNr,HNr,Sw,WNe,of,Rw,KEe,r9,UNr,ZEe,JNr,QNe,Fr,t9,YNr,rf,KNr,wK,ZNr,ejr,AK,ojr,rjr,tjr,a9,ajr,eCe,njr,sjr,ljr,Jt,n9,ijr,oCe,djr,cjr,tf,fjr,rCe,mjr,gjr,yK,hjr,pjr,_jr,Pw,ujr,Hr,s9,bjr,tCe,vjr,Fjr,En,Tjr,aCe,Mjr,Ejr,nCe,Cjr,wjr,sCe,Ajr,yjr,Ljr,lCe,Bw,iCe,xjr,$jr,LK,kjr,Sjr,Rjr,Iw,HNe,af,qw,dCe,l9,Pjr,cCe,Bjr,UNe,Tr,i9,Ijr,nf,qjr,xK,Njr,jjr,$K,Djr,Gjr,Ojr,d9,Vjr,fCe,Xjr,zjr,Wjr,Yt,c9,Qjr,mCe,Hjr,Ujr,sf,Jjr,gCe,Yjr,Kjr,kK,Zjr,eDr,oDr,Nw,rDr,Ur,f9,tDr,hCe,aDr,nDr,Cn,sDr,pCe,lDr,iDr,_Ce,dDr,cDr,uCe,fDr,mDr,gDr,m9,jw,bCe,hDr,pDr,SK,_Dr,uDr,bDr,Dw,vCe,vDr,FDr,RK,TDr,MDr,EDr,Gw,JNe,lf,Ow,FCe,g9,CDr,TCe,wDr,YNe,Mr,h9,ADr,df,yDr,PK,LDr,xDr,BK,$Dr,kDr,SDr,p9,RDr,MCe,PDr,BDr,IDr,Kt,_9,qDr,ECe,NDr,jDr,cf,DDr,CCe,GDr,ODr,IK,VDr,XDr,zDr,Vw,WDr,Jr,u9,QDr,wCe,HDr,UDr,wn,JDr,ACe,YDr,KDr,yCe,ZDr,eGr,LCe,oGr,rGr,tGr,xCe,Xw,$Ce,aGr,nGr,qK,sGr,lGr,iGr,zw,KNe;return d=new re({}),Ca=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),g6=new re({}),h6=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),vf=new dGr({props:{warning:!0,$$slots:{default:[p8t]},$$scope:{ctx:L}}}),p6=new re({}),_6=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/configuration_auto.py#L575"}}),v6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/configuration_auto.py#L598"}}),vg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[_8t]},$$scope:{ctx:L}}}),F6=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/configuration_auto.py#L721"}}),T6=new re({}),M6=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/tokenization_auto.py#L388"}}),w6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17227/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/tokenization_auto.py#L402"}}),Zg=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[u8t]},$$scope:{ctx:L}}}),A6=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/tokenization_auto.py#L598"}}),y6=new re({}),L6=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/feature_extraction_auto.py#L187"}}),k6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17227/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/feature_extraction_auto.py#L201"}}),Lh=new dGr({props:{$$slots:{default:[b8t]},$$scope:{ctx:L}}}),xh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[v8t]},$$scope:{ctx:L}}}),S6=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/feature_extraction_auto.py#L328"}}),R6=new re({}),P6=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/processing_auto.py#L87"}}),q6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/processing_auto.py#L101"}}),Hh=new dGr({props:{$$slots:{default:[F8t]},$$scope:{ctx:L}}}),Uh=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[T8t]},$$scope:{ctx:L}}}),N6=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/processing_auto.py#L254"}}),j6=new re({}),D6=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L727"}}),O6=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Kh=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[M8t]},$$scope:{ctx:L}}}),V6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),X_=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[E8t]},$$scope:{ctx:L}}}),X6=new re({}),z6=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L734"}}),Q6=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),W_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[C8t]},$$scope:{ctx:L}}}),H6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Iu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[w8t]},$$scope:{ctx:L}}}),U6=new re({}),J6=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L749"}}),K6=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Nu=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[A8t]},$$scope:{ctx:L}}}),Z6=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),M2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[y8t]},$$scope:{ctx:L}}}),ey=new re({}),oy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L756"}}),ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),C2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[L8t]},$$scope:{ctx:L}}}),ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),l1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[x8t]},$$scope:{ctx:L}}}),ny=new re({}),sy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L763"}}),iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),d1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[$8t]},$$scope:{ctx:L}}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),y1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[k8t]},$$scope:{ctx:L}}}),cy=new re({}),fy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L772"}}),gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),x1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[S8t]},$$scope:{ctx:L}}}),hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[R8t]},$$scope:{ctx:L}}}),py=new re({}),_y=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L806"}}),by=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[P8t]},$$scope:{ctx:L}}}),vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),rb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[B8t]},$$scope:{ctx:L}}}),Fy=new re({}),Ty=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L813"}}),Ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),ab=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[I8t]},$$scope:{ctx:L}}}),Cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),fb=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[q8t]},$$scope:{ctx:L}}}),wy=new re({}),Ay=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L799"}}),Ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),gb=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[N8t]},$$scope:{ctx:L}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Hb=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[j8t]},$$scope:{ctx:L}}}),$y=new re({}),ky=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L781"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Jb=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[D8t]},$$scope:{ctx:L}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),qv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[G8t]},$$scope:{ctx:L}}}),By=new re({}),Iy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L788"}}),Ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),jv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[O8t]},$$scope:{ctx:L}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Ov=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[V8t]},$$scope:{ctx:L}}}),Dy=new re({}),Gy=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L822"}}),Vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Xv=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[X8t]},$$scope:{ctx:L}}}),Xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),tF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[z8t]},$$scope:{ctx:L}}}),zy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L861"}}),Hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),nF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[W8t]},$$scope:{ctx:L}}}),Uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),iF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Q8t]},$$scope:{ctx:L}}}),Jy=new re({}),Yy=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L868"}}),Zy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),cF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[H8t]},$$scope:{ctx:L}}}),eL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),TF=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[U8t]},$$scope:{ctx:L}}}),oL=new re({}),rL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L891"}}),aL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),EF=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[J8t]},$$scope:{ctx:L}}}),nL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),$F=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Y8t]},$$scope:{ctx:L}}}),sL=new re({}),lL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L875"}}),dL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),SF=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[K8t]},$$scope:{ctx:L}}}),cL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),VF=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Z8t]},$$scope:{ctx:L}}}),fL=new re({}),mL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L882"}}),hL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),zF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[ext]},$$scope:{ctx:L}}}),pL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),UF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[oxt]},$$scope:{ctx:L}}}),uL=new re({}),bL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L900"}}),FL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),YF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[rxt]},$$scope:{ctx:L}}}),TL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),aT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[txt]},$$scope:{ctx:L}}}),ML=new re({}),EL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L907"}}),wL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),sT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[axt]},$$scope:{ctx:L}}}),AL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),fT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[nxt]},$$scope:{ctx:L}}}),yL=new re({}),LL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L854"}}),$L=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),gT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[sxt]},$$scope:{ctx:L}}}),kL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),uT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[lxt]},$$scope:{ctx:L}}}),RL=new re({}),PL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L829"}}),IL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),vT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[ixt]},$$scope:{ctx:L}}}),qL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),MT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[dxt]},$$scope:{ctx:L}}}),NL=new re({}),jL=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L836"}}),GL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),CT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[cxt]},$$scope:{ctx:L}}}),OL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),$T=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[fxt]},$$scope:{ctx:L}}}),VL=new re({}),XL=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_auto.py#L845"}}),WL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),ST=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[mxt]},$$scope:{ctx:L}}}),QL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),BT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[gxt]},$$scope:{ctx:L}}}),HL=new re({}),UL=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L395"}}),YL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),qT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[hxt]},$$scope:{ctx:L}}}),KL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),$M=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[pxt]},$$scope:{ctx:L}}}),ZL=new re({}),e8=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L402"}}),r8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),SM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[_xt]},$$scope:{ctx:L}}}),t8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),r4=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[uxt]},$$scope:{ctx:L}}}),a8=new re({}),n8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L417"}}),l8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),a4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[bxt]},$$scope:{ctx:L}}}),i8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),u4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[vxt]},$$scope:{ctx:L}}}),d8=new re({}),c8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),m8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),v4=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[Fxt]},$$scope:{ctx:L}}}),g8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),C4=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Txt]},$$scope:{ctx:L}}}),h8=new re({}),p8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L449"}}),u8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),A4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Mxt]},$$scope:{ctx:L}}}),b8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Q4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Ext]},$$scope:{ctx:L}}}),v8=new re({}),F8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),M8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),U4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Cxt]},$$scope:{ctx:L}}}),E8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),sE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[wxt]},$$scope:{ctx:L}}}),C8=new re({}),w8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L465"}}),y8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),iE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Axt]},$$scope:{ctx:L}}}),L8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),BE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[yxt]},$$scope:{ctx:L}}}),x8=new re({}),$8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),S8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),qE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Lxt]},$$scope:{ctx:L}}}),R8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),oC=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[xxt]},$$scope:{ctx:L}}}),P8=new re({}),B8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L508"}}),q8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),tC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[$xt]},$$scope:{ctx:L}}}),N8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),sC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[kxt]},$$scope:{ctx:L}}}),D8=new re({}),G8=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),V8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),iC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Sxt]},$$scope:{ctx:L}}}),X8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),cC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Rxt]},$$scope:{ctx:L}}}),z8=new re({}),W8=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L492"}}),H8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[Pxt]},$$scope:{ctx:L}}}),U8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),RC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Bxt]},$$scope:{ctx:L}}}),J8=new re({}),Y8=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L474"}}),Z8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Ixt]},$$scope:{ctx:L}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),r5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[qxt]},$$scope:{ctx:L}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L442"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),a5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Nxt]},$$scope:{ctx:L}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[jxt]},$$scope:{ctx:L}}}),sx=new re({}),lx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_tf_auto.py#L517"}}),dx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Dxt]},$$scope:{ctx:L}}}),cx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),c5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Gxt]},$$scope:{ctx:L}}}),fx=new re({}),mx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L243"}}),hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),m5=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Oxt]},$$scope:{ctx:L}}}),px=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),j5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Vxt]},$$scope:{ctx:L}}}),_x=new re({}),ux=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L257"}}),vx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),G5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Xxt]},$$scope:{ctx:L}}}),Fx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),K5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[zxt]},$$scope:{ctx:L}}}),Tx=new re({}),Mx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L250"}}),Cx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),e3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Wxt]},$$scope:{ctx:L}}}),wx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),g3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Qxt]},$$scope:{ctx:L}}}),Ax=new re({}),yx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),xx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),p3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Hxt]},$$scope:{ctx:L}}}),$x=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),A3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Uxt]},$$scope:{ctx:L}}}),kx=new re({}),Sx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L271"}}),Px=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),L3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Jxt]},$$scope:{ctx:L}}}),Bx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Yxt]},$$scope:{ctx:L}}}),Ix=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L280"}}),jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),D3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Kxt]},$$scope:{ctx:L}}}),Dx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Y3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Zxt]},$$scope:{ctx:L}}}),Gx=new re({}),Ox=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L289"}}),Xx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Z3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[e9t]},$$scope:{ctx:L}}}),zx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),cw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[o9t]},$$scope:{ctx:L}}}),Wx=new re({}),Qx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L296"}}),Ux=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),mw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[r9t]},$$scope:{ctx:L}}}),Jx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Tw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[t9t]},$$scope:{ctx:L}}}),Yx=new re({}),Kx=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L305"}}),e9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Ew=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[a9t]},$$scope:{ctx:L}}}),o9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Sw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[n9t]},$$scope:{ctx:L}}}),r9=new re({}),t9=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L312"}}),n9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Pw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[s9t]},$$scope:{ctx:L}}}),s9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[l9t]},$$scope:{ctx:L}}}),l9=new re({}),i9=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L321"}}),c9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Nw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[i9t]},$$scope:{ctx:L}}}),f9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),Gw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[d9t]},$$scope:{ctx:L}}}),g9=new re({}),h9=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/modeling_flax_auto.py#L330"}}),_9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L389"}}),Vw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[c9t]},$$scope:{ctx:L}}}),u9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17227/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17227/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17227/src/transformers/models/auto/auto_factory.py#L417"}}),zw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[f9t]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),ci=o("Auto Classes"),hf=l(),rt=a("p"),fi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),mi=a("code"),d6=o("from_pretrained()"),pf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),De=l(),We=a("p"),gi=o("Instantiating one of "),yn=a("a"),c6=o("AutoConfig"),Ln=o(", "),xn=a("a"),f6=o("AutoModel"),hi=o(`, and
`),$n=a("a"),m6=o("AutoTokenizer"),pi=o(" will directly create a class of the relevant architecture. For instance"),_f=l(),F(Ca.$$.fragment),Qe=l(),Ae=a("p"),$$=o("will create a model that is an instance of "),_i=a("a"),k$=o("BertModel"),S$=o("."),Eo=l(),wa=a("p"),R$=o("There is one class of "),uf=a("code"),P$=o("AutoModel"),sGe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),UIe=l(),ui=a("h2"),bf=a("a"),$ee=a("span"),F(g6.$$.fragment),lGe=l(),kee=a("span"),iGe=o("Extending the Auto Classes"),JIe=l(),kn=a("p"),dGe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),See=a("code"),cGe=o("NewModel"),fGe=o(", make sure you have a "),Ree=a("code"),mGe=o("NewModelConfig"),gGe=o(` then you can add those to the auto
classes like this:`),YIe=l(),F(h6.$$.fragment),KIe=l(),B$=a("p"),hGe=o("You will then be able to use the auto classes like you would usually do!"),ZIe=l(),F(vf.$$.fragment),eqe=l(),bi=a("h2"),Ff=a("a"),Pee=a("span"),F(p6.$$.fragment),pGe=l(),Bee=a("span"),_Ge=o("AutoConfig"),oqe=l(),Co=a("div"),F(_6.$$.fragment),uGe=l(),u6=a("p"),bGe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),I$=a("a"),vGe=o("from_pretrained()"),FGe=o(" class method."),TGe=l(),b6=a("p"),MGe=o("This class cannot be instantiated directly using "),Iee=a("code"),EGe=o("__init__()"),CGe=o(" (throws an error)."),wGe=l(),Er=a("div"),F(v6.$$.fragment),AGe=l(),qee=a("p"),yGe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),LGe=l(),vi=a("p"),xGe=o("The configuration class to instantiate is selected based on the "),Nee=a("code"),$Ge=o("model_type"),kGe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),jee=a("code"),SGe=o("pretrained_model_name_or_path"),RGe=o(":"),PGe=l(),A=a("ul"),Tf=a("li"),Dee=a("strong"),BGe=o("albert"),IGe=o(" \u2014 "),q$=a("a"),qGe=o("AlbertConfig"),NGe=o(" (ALBERT model)"),jGe=l(),Mf=a("li"),Gee=a("strong"),DGe=o("bart"),GGe=o(" \u2014 "),N$=a("a"),OGe=o("BartConfig"),VGe=o(" (BART model)"),XGe=l(),Ef=a("li"),Oee=a("strong"),zGe=o("beit"),WGe=o(" \u2014 "),j$=a("a"),QGe=o("BeitConfig"),HGe=o(" (BEiT model)"),UGe=l(),Cf=a("li"),Vee=a("strong"),JGe=o("bert"),YGe=o(" \u2014 "),D$=a("a"),KGe=o("BertConfig"),ZGe=o(" (BERT model)"),eOe=l(),wf=a("li"),Xee=a("strong"),oOe=o("bert-generation"),rOe=o(" \u2014 "),G$=a("a"),tOe=o("BertGenerationConfig"),aOe=o(" (Bert Generation model)"),nOe=l(),Af=a("li"),zee=a("strong"),sOe=o("big_bird"),lOe=o(" \u2014 "),O$=a("a"),iOe=o("BigBirdConfig"),dOe=o(" (BigBird model)"),cOe=l(),yf=a("li"),Wee=a("strong"),fOe=o("bigbird_pegasus"),mOe=o(" \u2014 "),V$=a("a"),gOe=o("BigBirdPegasusConfig"),hOe=o(" (BigBirdPegasus model)"),pOe=l(),Lf=a("li"),Qee=a("strong"),_Oe=o("blenderbot"),uOe=o(" \u2014 "),X$=a("a"),bOe=o("BlenderbotConfig"),vOe=o(" (Blenderbot model)"),FOe=l(),xf=a("li"),Hee=a("strong"),TOe=o("blenderbot-small"),MOe=o(" \u2014 "),z$=a("a"),EOe=o("BlenderbotSmallConfig"),COe=o(" (BlenderbotSmall model)"),wOe=l(),$f=a("li"),Uee=a("strong"),AOe=o("camembert"),yOe=o(" \u2014 "),W$=a("a"),LOe=o("CamembertConfig"),xOe=o(" (CamemBERT model)"),$Oe=l(),kf=a("li"),Jee=a("strong"),kOe=o("canine"),SOe=o(" \u2014 "),Q$=a("a"),ROe=o("CanineConfig"),POe=o(" (Canine model)"),BOe=l(),Sf=a("li"),Yee=a("strong"),IOe=o("clip"),qOe=o(" \u2014 "),H$=a("a"),NOe=o("CLIPConfig"),jOe=o(" (CLIP model)"),DOe=l(),Rf=a("li"),Kee=a("strong"),GOe=o("convbert"),OOe=o(" \u2014 "),U$=a("a"),VOe=o("ConvBertConfig"),XOe=o(" (ConvBERT model)"),zOe=l(),Pf=a("li"),Zee=a("strong"),WOe=o("convnext"),QOe=o(" \u2014 "),J$=a("a"),HOe=o("ConvNextConfig"),UOe=o(" (ConvNext model)"),JOe=l(),Bf=a("li"),eoe=a("strong"),YOe=o("ctrl"),KOe=o(" \u2014 "),Y$=a("a"),ZOe=o("CTRLConfig"),eVe=o(" (CTRL model)"),oVe=l(),If=a("li"),ooe=a("strong"),rVe=o("data2vec-audio"),tVe=o(" \u2014 "),K$=a("a"),aVe=o("Data2VecAudioConfig"),nVe=o(" (Data2VecAudio model)"),sVe=l(),qf=a("li"),roe=a("strong"),lVe=o("data2vec-text"),iVe=o(" \u2014 "),Z$=a("a"),dVe=o("Data2VecTextConfig"),cVe=o(" (Data2VecText model)"),fVe=l(),Nf=a("li"),toe=a("strong"),mVe=o("data2vec-vision"),gVe=o(" \u2014 "),ek=a("a"),hVe=o("Data2VecVisionConfig"),pVe=o(" (Data2VecVision model)"),_Ve=l(),jf=a("li"),aoe=a("strong"),uVe=o("deberta"),bVe=o(" \u2014 "),ok=a("a"),vVe=o("DebertaConfig"),FVe=o(" (DeBERTa model)"),TVe=l(),Df=a("li"),noe=a("strong"),MVe=o("deberta-v2"),EVe=o(" \u2014 "),rk=a("a"),CVe=o("DebertaV2Config"),wVe=o(" (DeBERTa-v2 model)"),AVe=l(),Gf=a("li"),soe=a("strong"),yVe=o("decision_transformer"),LVe=o(" \u2014 "),tk=a("a"),xVe=o("DecisionTransformerConfig"),$Ve=o(" (Decision Transformer model)"),kVe=l(),Of=a("li"),loe=a("strong"),SVe=o("deit"),RVe=o(" \u2014 "),ak=a("a"),PVe=o("DeiTConfig"),BVe=o(" (DeiT model)"),IVe=l(),Vf=a("li"),ioe=a("strong"),qVe=o("detr"),NVe=o(" \u2014 "),nk=a("a"),jVe=o("DetrConfig"),DVe=o(" (DETR model)"),GVe=l(),Xf=a("li"),doe=a("strong"),OVe=o("distilbert"),VVe=o(" \u2014 "),sk=a("a"),XVe=o("DistilBertConfig"),zVe=o(" (DistilBERT model)"),WVe=l(),zf=a("li"),coe=a("strong"),QVe=o("dpr"),HVe=o(" \u2014 "),lk=a("a"),UVe=o("DPRConfig"),JVe=o(" (DPR model)"),YVe=l(),Wf=a("li"),foe=a("strong"),KVe=o("dpt"),ZVe=o(" \u2014 "),ik=a("a"),eXe=o("DPTConfig"),oXe=o(" (DPT model)"),rXe=l(),Qf=a("li"),moe=a("strong"),tXe=o("electra"),aXe=o(" \u2014 "),dk=a("a"),nXe=o("ElectraConfig"),sXe=o(" (ELECTRA model)"),lXe=l(),Hf=a("li"),goe=a("strong"),iXe=o("encoder-decoder"),dXe=o(" \u2014 "),ck=a("a"),cXe=o("EncoderDecoderConfig"),fXe=o(" (Encoder decoder model)"),mXe=l(),Uf=a("li"),hoe=a("strong"),gXe=o("flaubert"),hXe=o(" \u2014 "),fk=a("a"),pXe=o("FlaubertConfig"),_Xe=o(" (FlauBERT model)"),uXe=l(),Jf=a("li"),poe=a("strong"),bXe=o("flava"),vXe=o(" \u2014 "),mk=a("a"),FXe=o("FlavaConfig"),TXe=o(" (Flava model)"),MXe=l(),Yf=a("li"),_oe=a("strong"),EXe=o("fnet"),CXe=o(" \u2014 "),gk=a("a"),wXe=o("FNetConfig"),AXe=o(" (FNet model)"),yXe=l(),Kf=a("li"),uoe=a("strong"),LXe=o("fsmt"),xXe=o(" \u2014 "),hk=a("a"),$Xe=o("FSMTConfig"),kXe=o(" (FairSeq Machine-Translation model)"),SXe=l(),Zf=a("li"),boe=a("strong"),RXe=o("funnel"),PXe=o(" \u2014 "),pk=a("a"),BXe=o("FunnelConfig"),IXe=o(" (Funnel Transformer model)"),qXe=l(),em=a("li"),voe=a("strong"),NXe=o("glpn"),jXe=o(" \u2014 "),_k=a("a"),DXe=o("GLPNConfig"),GXe=o(" (GLPN model)"),OXe=l(),om=a("li"),Foe=a("strong"),VXe=o("gpt2"),XXe=o(" \u2014 "),uk=a("a"),zXe=o("GPT2Config"),WXe=o(" (OpenAI GPT-2 model)"),QXe=l(),rm=a("li"),Toe=a("strong"),HXe=o("gpt_neo"),UXe=o(" \u2014 "),bk=a("a"),JXe=o("GPTNeoConfig"),YXe=o(" (GPT Neo model)"),KXe=l(),tm=a("li"),Moe=a("strong"),ZXe=o("gptj"),eze=o(" \u2014 "),vk=a("a"),oze=o("GPTJConfig"),rze=o(" (GPT-J model)"),tze=l(),am=a("li"),Eoe=a("strong"),aze=o("hubert"),nze=o(" \u2014 "),Fk=a("a"),sze=o("HubertConfig"),lze=o(" (Hubert model)"),ize=l(),nm=a("li"),Coe=a("strong"),dze=o("ibert"),cze=o(" \u2014 "),Tk=a("a"),fze=o("IBertConfig"),mze=o(" (I-BERT model)"),gze=l(),sm=a("li"),woe=a("strong"),hze=o("imagegpt"),pze=o(" \u2014 "),Mk=a("a"),_ze=o("ImageGPTConfig"),uze=o(" (ImageGPT model)"),bze=l(),lm=a("li"),Aoe=a("strong"),vze=o("layoutlm"),Fze=o(" \u2014 "),Ek=a("a"),Tze=o("LayoutLMConfig"),Mze=o(" (LayoutLM model)"),Eze=l(),im=a("li"),yoe=a("strong"),Cze=o("layoutlmv2"),wze=o(" \u2014 "),Ck=a("a"),Aze=o("LayoutLMv2Config"),yze=o(" (LayoutLMv2 model)"),Lze=l(),dm=a("li"),Loe=a("strong"),xze=o("led"),$ze=o(" \u2014 "),wk=a("a"),kze=o("LEDConfig"),Sze=o(" (LED model)"),Rze=l(),cm=a("li"),xoe=a("strong"),Pze=o("longformer"),Bze=o(" \u2014 "),Ak=a("a"),Ize=o("LongformerConfig"),qze=o(" (Longformer model)"),Nze=l(),fm=a("li"),$oe=a("strong"),jze=o("luke"),Dze=o(" \u2014 "),yk=a("a"),Gze=o("LukeConfig"),Oze=o(" (LUKE model)"),Vze=l(),mm=a("li"),koe=a("strong"),Xze=o("lxmert"),zze=o(" \u2014 "),Lk=a("a"),Wze=o("LxmertConfig"),Qze=o(" (LXMERT model)"),Hze=l(),gm=a("li"),Soe=a("strong"),Uze=o("m2m_100"),Jze=o(" \u2014 "),xk=a("a"),Yze=o("M2M100Config"),Kze=o(" (M2M100 model)"),Zze=l(),hm=a("li"),Roe=a("strong"),eWe=o("marian"),oWe=o(" \u2014 "),$k=a("a"),rWe=o("MarianConfig"),tWe=o(" (Marian model)"),aWe=l(),pm=a("li"),Poe=a("strong"),nWe=o("maskformer"),sWe=o(" \u2014 "),kk=a("a"),lWe=o("MaskFormerConfig"),iWe=o(" (MaskFormer model)"),dWe=l(),_m=a("li"),Boe=a("strong"),cWe=o("mbart"),fWe=o(" \u2014 "),Sk=a("a"),mWe=o("MBartConfig"),gWe=o(" (mBART model)"),hWe=l(),um=a("li"),Ioe=a("strong"),pWe=o("megatron-bert"),_We=o(" \u2014 "),Rk=a("a"),uWe=o("MegatronBertConfig"),bWe=o(" (MegatronBert model)"),vWe=l(),bm=a("li"),qoe=a("strong"),FWe=o("mobilebert"),TWe=o(" \u2014 "),Pk=a("a"),MWe=o("MobileBertConfig"),EWe=o(" (MobileBERT model)"),CWe=l(),vm=a("li"),Noe=a("strong"),wWe=o("mpnet"),AWe=o(" \u2014 "),Bk=a("a"),yWe=o("MPNetConfig"),LWe=o(" (MPNet model)"),xWe=l(),Fm=a("li"),joe=a("strong"),$We=o("mt5"),kWe=o(" \u2014 "),Ik=a("a"),SWe=o("MT5Config"),RWe=o(" (mT5 model)"),PWe=l(),Tm=a("li"),Doe=a("strong"),BWe=o("nystromformer"),IWe=o(" \u2014 "),qk=a("a"),qWe=o("NystromformerConfig"),NWe=o(" (Nystromformer model)"),jWe=l(),Mm=a("li"),Goe=a("strong"),DWe=o("openai-gpt"),GWe=o(" \u2014 "),Nk=a("a"),OWe=o("OpenAIGPTConfig"),VWe=o(" (OpenAI GPT model)"),XWe=l(),Em=a("li"),Ooe=a("strong"),zWe=o("opt"),WWe=o(" \u2014 "),jk=a("a"),QWe=o("OPTConfig"),HWe=o(" (OPT model)"),UWe=l(),Cm=a("li"),Voe=a("strong"),JWe=o("pegasus"),YWe=o(" \u2014 "),Dk=a("a"),KWe=o("PegasusConfig"),ZWe=o(" (Pegasus model)"),eQe=l(),wm=a("li"),Xoe=a("strong"),oQe=o("perceiver"),rQe=o(" \u2014 "),Gk=a("a"),tQe=o("PerceiverConfig"),aQe=o(" (Perceiver model)"),nQe=l(),Am=a("li"),zoe=a("strong"),sQe=o("plbart"),lQe=o(" \u2014 "),Ok=a("a"),iQe=o("PLBartConfig"),dQe=o(" (PLBart model)"),cQe=l(),ym=a("li"),Woe=a("strong"),fQe=o("poolformer"),mQe=o(" \u2014 "),Vk=a("a"),gQe=o("PoolFormerConfig"),hQe=o(" (PoolFormer model)"),pQe=l(),Lm=a("li"),Qoe=a("strong"),_Qe=o("prophetnet"),uQe=o(" \u2014 "),Xk=a("a"),bQe=o("ProphetNetConfig"),vQe=o(" (ProphetNet model)"),FQe=l(),xm=a("li"),Hoe=a("strong"),TQe=o("qdqbert"),MQe=o(" \u2014 "),zk=a("a"),EQe=o("QDQBertConfig"),CQe=o(" (QDQBert model)"),wQe=l(),$m=a("li"),Uoe=a("strong"),AQe=o("rag"),yQe=o(" \u2014 "),Wk=a("a"),LQe=o("RagConfig"),xQe=o(" (RAG model)"),$Qe=l(),km=a("li"),Joe=a("strong"),kQe=o("realm"),SQe=o(" \u2014 "),Qk=a("a"),RQe=o("RealmConfig"),PQe=o(" (Realm model)"),BQe=l(),Sm=a("li"),Yoe=a("strong"),IQe=o("reformer"),qQe=o(" \u2014 "),Hk=a("a"),NQe=o("ReformerConfig"),jQe=o(" (Reformer model)"),DQe=l(),Rm=a("li"),Koe=a("strong"),GQe=o("regnet"),OQe=o(" \u2014 "),Uk=a("a"),VQe=o("RegNetConfig"),XQe=o(" (RegNet model)"),zQe=l(),Pm=a("li"),Zoe=a("strong"),WQe=o("rembert"),QQe=o(" \u2014 "),Jk=a("a"),HQe=o("RemBertConfig"),UQe=o(" (RemBERT model)"),JQe=l(),Bm=a("li"),ere=a("strong"),YQe=o("resnet"),KQe=o(" \u2014 "),Yk=a("a"),ZQe=o("ResNetConfig"),eHe=o(" (ResNet model)"),oHe=l(),Im=a("li"),ore=a("strong"),rHe=o("retribert"),tHe=o(" \u2014 "),Kk=a("a"),aHe=o("RetriBertConfig"),nHe=o(" (RetriBERT model)"),sHe=l(),qm=a("li"),rre=a("strong"),lHe=o("roberta"),iHe=o(" \u2014 "),Zk=a("a"),dHe=o("RobertaConfig"),cHe=o(" (RoBERTa model)"),fHe=l(),Nm=a("li"),tre=a("strong"),mHe=o("roformer"),gHe=o(" \u2014 "),eS=a("a"),hHe=o("RoFormerConfig"),pHe=o(" (RoFormer model)"),_He=l(),jm=a("li"),are=a("strong"),uHe=o("segformer"),bHe=o(" \u2014 "),oS=a("a"),vHe=o("SegformerConfig"),FHe=o(" (SegFormer model)"),THe=l(),Dm=a("li"),nre=a("strong"),MHe=o("sew"),EHe=o(" \u2014 "),rS=a("a"),CHe=o("SEWConfig"),wHe=o(" (SEW model)"),AHe=l(),Gm=a("li"),sre=a("strong"),yHe=o("sew-d"),LHe=o(" \u2014 "),tS=a("a"),xHe=o("SEWDConfig"),$He=o(" (SEW-D model)"),kHe=l(),Om=a("li"),lre=a("strong"),SHe=o("speech-encoder-decoder"),RHe=o(" \u2014 "),aS=a("a"),PHe=o("SpeechEncoderDecoderConfig"),BHe=o(" (Speech Encoder decoder model)"),IHe=l(),Vm=a("li"),ire=a("strong"),qHe=o("speech_to_text"),NHe=o(" \u2014 "),nS=a("a"),jHe=o("Speech2TextConfig"),DHe=o(" (Speech2Text model)"),GHe=l(),Xm=a("li"),dre=a("strong"),OHe=o("speech_to_text_2"),VHe=o(" \u2014 "),sS=a("a"),XHe=o("Speech2Text2Config"),zHe=o(" (Speech2Text2 model)"),WHe=l(),zm=a("li"),cre=a("strong"),QHe=o("splinter"),HHe=o(" \u2014 "),lS=a("a"),UHe=o("SplinterConfig"),JHe=o(" (Splinter model)"),YHe=l(),Wm=a("li"),fre=a("strong"),KHe=o("squeezebert"),ZHe=o(" \u2014 "),iS=a("a"),eUe=o("SqueezeBertConfig"),oUe=o(" (SqueezeBERT model)"),rUe=l(),Qm=a("li"),mre=a("strong"),tUe=o("swin"),aUe=o(" \u2014 "),dS=a("a"),nUe=o("SwinConfig"),sUe=o(" (Swin model)"),lUe=l(),Hm=a("li"),gre=a("strong"),iUe=o("t5"),dUe=o(" \u2014 "),cS=a("a"),cUe=o("T5Config"),fUe=o(" (T5 model)"),mUe=l(),Um=a("li"),hre=a("strong"),gUe=o("tapas"),hUe=o(" \u2014 "),fS=a("a"),pUe=o("TapasConfig"),_Ue=o(" (TAPAS model)"),uUe=l(),Jm=a("li"),pre=a("strong"),bUe=o("trajectory_transformer"),vUe=o(" \u2014 "),mS=a("a"),FUe=o("TrajectoryTransformerConfig"),TUe=o(" (Trajectory Transformer model)"),MUe=l(),Ym=a("li"),_re=a("strong"),EUe=o("transfo-xl"),CUe=o(" \u2014 "),gS=a("a"),wUe=o("TransfoXLConfig"),AUe=o(" (Transformer-XL model)"),yUe=l(),Km=a("li"),ure=a("strong"),LUe=o("trocr"),xUe=o(" \u2014 "),hS=a("a"),$Ue=o("TrOCRConfig"),kUe=o(" (TrOCR model)"),SUe=l(),Zm=a("li"),bre=a("strong"),RUe=o("unispeech"),PUe=o(" \u2014 "),pS=a("a"),BUe=o("UniSpeechConfig"),IUe=o(" (UniSpeech model)"),qUe=l(),eg=a("li"),vre=a("strong"),NUe=o("unispeech-sat"),jUe=o(" \u2014 "),_S=a("a"),DUe=o("UniSpeechSatConfig"),GUe=o(" (UniSpeechSat model)"),OUe=l(),og=a("li"),Fre=a("strong"),VUe=o("van"),XUe=o(" \u2014 "),uS=a("a"),zUe=o("VanConfig"),WUe=o(" (VAN model)"),QUe=l(),rg=a("li"),Tre=a("strong"),HUe=o("vilt"),UUe=o(" \u2014 "),bS=a("a"),JUe=o("ViltConfig"),YUe=o(" (ViLT model)"),KUe=l(),tg=a("li"),Mre=a("strong"),ZUe=o("vision-encoder-decoder"),eJe=o(" \u2014 "),vS=a("a"),oJe=o("VisionEncoderDecoderConfig"),rJe=o(" (Vision Encoder decoder model)"),tJe=l(),ag=a("li"),Ere=a("strong"),aJe=o("vision-text-dual-encoder"),nJe=o(" \u2014 "),FS=a("a"),sJe=o("VisionTextDualEncoderConfig"),lJe=o(" (VisionTextDualEncoder model)"),iJe=l(),ng=a("li"),Cre=a("strong"),dJe=o("visual_bert"),cJe=o(" \u2014 "),TS=a("a"),fJe=o("VisualBertConfig"),mJe=o(" (VisualBert model)"),gJe=l(),sg=a("li"),wre=a("strong"),hJe=o("vit"),pJe=o(" \u2014 "),MS=a("a"),_Je=o("ViTConfig"),uJe=o(" (ViT model)"),bJe=l(),lg=a("li"),Are=a("strong"),vJe=o("vit_mae"),FJe=o(" \u2014 "),ES=a("a"),TJe=o("ViTMAEConfig"),MJe=o(" (ViTMAE model)"),EJe=l(),ig=a("li"),yre=a("strong"),CJe=o("wav2vec2"),wJe=o(" \u2014 "),CS=a("a"),AJe=o("Wav2Vec2Config"),yJe=o(" (Wav2Vec2 model)"),LJe=l(),dg=a("li"),Lre=a("strong"),xJe=o("wav2vec2-conformer"),$Je=o(" \u2014 "),wS=a("a"),kJe=o("Wav2Vec2ConformerConfig"),SJe=o(" (Wav2Vec2-Conformer model)"),RJe=l(),cg=a("li"),xre=a("strong"),PJe=o("wavlm"),BJe=o(" \u2014 "),AS=a("a"),IJe=o("WavLMConfig"),qJe=o(" (WavLM model)"),NJe=l(),fg=a("li"),$re=a("strong"),jJe=o("xglm"),DJe=o(" \u2014 "),yS=a("a"),GJe=o("XGLMConfig"),OJe=o(" (XGLM model)"),VJe=l(),mg=a("li"),kre=a("strong"),XJe=o("xlm"),zJe=o(" \u2014 "),LS=a("a"),WJe=o("XLMConfig"),QJe=o(" (XLM model)"),HJe=l(),gg=a("li"),Sre=a("strong"),UJe=o("xlm-prophetnet"),JJe=o(" \u2014 "),xS=a("a"),YJe=o("XLMProphetNetConfig"),KJe=o(" (XLMProphetNet model)"),ZJe=l(),hg=a("li"),Rre=a("strong"),eYe=o("xlm-roberta"),oYe=o(" \u2014 "),$S=a("a"),rYe=o("XLMRobertaConfig"),tYe=o(" (XLM-RoBERTa model)"),aYe=l(),pg=a("li"),Pre=a("strong"),nYe=o("xlm-roberta-xl"),sYe=o(" \u2014 "),kS=a("a"),lYe=o("XLMRobertaXLConfig"),iYe=o(" (XLM-RoBERTa-XL model)"),dYe=l(),_g=a("li"),Bre=a("strong"),cYe=o("xlnet"),fYe=o(" \u2014 "),SS=a("a"),mYe=o("XLNetConfig"),gYe=o(" (XLNet model)"),hYe=l(),ug=a("li"),Ire=a("strong"),pYe=o("yolos"),_Ye=o(" \u2014 "),RS=a("a"),uYe=o("YolosConfig"),bYe=o(" (YOLOS model)"),vYe=l(),bg=a("li"),qre=a("strong"),FYe=o("yoso"),TYe=o(" \u2014 "),PS=a("a"),MYe=o("YosoConfig"),EYe=o(" (YOSO model)"),CYe=l(),F(vg.$$.fragment),wYe=l(),Fg=a("div"),F(F6.$$.fragment),AYe=l(),Nre=a("p"),yYe=o("Register a new configuration for this class."),rqe=l(),Fi=a("h2"),Tg=a("a"),jre=a("span"),F(T6.$$.fragment),LYe=l(),Dre=a("span"),xYe=o("AutoTokenizer"),tqe=l(),wo=a("div"),F(M6.$$.fragment),$Ye=l(),E6=a("p"),kYe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),BS=a("a"),SYe=o("AutoTokenizer.from_pretrained()"),RYe=o(" class method."),PYe=l(),C6=a("p"),BYe=o("This class cannot be instantiated directly using "),Gre=a("code"),IYe=o("__init__()"),qYe=o(" (throws an error)."),NYe=l(),Cr=a("div"),F(w6.$$.fragment),jYe=l(),Ore=a("p"),DYe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),GYe=l(),Aa=a("p"),OYe=o("The tokenizer class to instantiate is selected based on the "),Vre=a("code"),VYe=o("model_type"),XYe=o(` property of the config object (either
passed as an argument or loaded from `),Xre=a("code"),zYe=o("pretrained_model_name_or_path"),WYe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zre=a("code"),QYe=o("pretrained_model_name_or_path"),HYe=o(":"),UYe=l(),k=a("ul"),Sn=a("li"),Wre=a("strong"),JYe=o("albert"),YYe=o(" \u2014 "),IS=a("a"),KYe=o("AlbertTokenizer"),ZYe=o(" or "),qS=a("a"),eKe=o("AlbertTokenizerFast"),oKe=o(" (ALBERT model)"),rKe=l(),Rn=a("li"),Qre=a("strong"),tKe=o("bart"),aKe=o(" \u2014 "),NS=a("a"),nKe=o("BartTokenizer"),sKe=o(" or "),jS=a("a"),lKe=o("BartTokenizerFast"),iKe=o(" (BART model)"),dKe=l(),Pn=a("li"),Hre=a("strong"),cKe=o("barthez"),fKe=o(" \u2014 "),DS=a("a"),mKe=o("BarthezTokenizer"),gKe=o(" or "),GS=a("a"),hKe=o("BarthezTokenizerFast"),pKe=o(" (BARThez model)"),_Ke=l(),Mg=a("li"),Ure=a("strong"),uKe=o("bartpho"),bKe=o(" \u2014 "),OS=a("a"),vKe=o("BartphoTokenizer"),FKe=o(" (BARTpho model)"),TKe=l(),Bn=a("li"),Jre=a("strong"),MKe=o("bert"),EKe=o(" \u2014 "),VS=a("a"),CKe=o("BertTokenizer"),wKe=o(" or "),XS=a("a"),AKe=o("BertTokenizerFast"),yKe=o(" (BERT model)"),LKe=l(),Eg=a("li"),Yre=a("strong"),xKe=o("bert-generation"),$Ke=o(" \u2014 "),zS=a("a"),kKe=o("BertGenerationTokenizer"),SKe=o(" (Bert Generation model)"),RKe=l(),Cg=a("li"),Kre=a("strong"),PKe=o("bert-japanese"),BKe=o(" \u2014 "),WS=a("a"),IKe=o("BertJapaneseTokenizer"),qKe=o(" (BertJapanese model)"),NKe=l(),wg=a("li"),Zre=a("strong"),jKe=o("bertweet"),DKe=o(" \u2014 "),QS=a("a"),GKe=o("BertweetTokenizer"),OKe=o(" (Bertweet model)"),VKe=l(),In=a("li"),ete=a("strong"),XKe=o("big_bird"),zKe=o(" \u2014 "),HS=a("a"),WKe=o("BigBirdTokenizer"),QKe=o(" or "),US=a("a"),HKe=o("BigBirdTokenizerFast"),UKe=o(" (BigBird model)"),JKe=l(),qn=a("li"),ote=a("strong"),YKe=o("bigbird_pegasus"),KKe=o(" \u2014 "),JS=a("a"),ZKe=o("PegasusTokenizer"),eZe=o(" or "),YS=a("a"),oZe=o("PegasusTokenizerFast"),rZe=o(" (BigBirdPegasus model)"),tZe=l(),Nn=a("li"),rte=a("strong"),aZe=o("blenderbot"),nZe=o(" \u2014 "),KS=a("a"),sZe=o("BlenderbotTokenizer"),lZe=o(" or "),ZS=a("a"),iZe=o("BlenderbotTokenizerFast"),dZe=o(" (Blenderbot model)"),cZe=l(),Ag=a("li"),tte=a("strong"),fZe=o("blenderbot-small"),mZe=o(" \u2014 "),eR=a("a"),gZe=o("BlenderbotSmallTokenizer"),hZe=o(" (BlenderbotSmall model)"),pZe=l(),yg=a("li"),ate=a("strong"),_Ze=o("byt5"),uZe=o(" \u2014 "),oR=a("a"),bZe=o("ByT5Tokenizer"),vZe=o(" (ByT5 model)"),FZe=l(),jn=a("li"),nte=a("strong"),TZe=o("camembert"),MZe=o(" \u2014 "),rR=a("a"),EZe=o("CamembertTokenizer"),CZe=o(" or "),tR=a("a"),wZe=o("CamembertTokenizerFast"),AZe=o(" (CamemBERT model)"),yZe=l(),Lg=a("li"),ste=a("strong"),LZe=o("canine"),xZe=o(" \u2014 "),aR=a("a"),$Ze=o("CanineTokenizer"),kZe=o(" (Canine model)"),SZe=l(),Dn=a("li"),lte=a("strong"),RZe=o("clip"),PZe=o(" \u2014 "),nR=a("a"),BZe=o("CLIPTokenizer"),IZe=o(" or "),sR=a("a"),qZe=o("CLIPTokenizerFast"),NZe=o(" (CLIP model)"),jZe=l(),Gn=a("li"),ite=a("strong"),DZe=o("convbert"),GZe=o(" \u2014 "),lR=a("a"),OZe=o("ConvBertTokenizer"),VZe=o(" or "),iR=a("a"),XZe=o("ConvBertTokenizerFast"),zZe=o(" (ConvBERT model)"),WZe=l(),On=a("li"),dte=a("strong"),QZe=o("cpm"),HZe=o(" \u2014 "),dR=a("a"),UZe=o("CpmTokenizer"),JZe=o(" or "),cR=a("a"),YZe=o("CpmTokenizerFast"),KZe=o(" (CPM model)"),ZZe=l(),xg=a("li"),cte=a("strong"),eeo=o("ctrl"),oeo=o(" \u2014 "),fR=a("a"),reo=o("CTRLTokenizer"),teo=o(" (CTRL model)"),aeo=l(),Vn=a("li"),fte=a("strong"),neo=o("data2vec-text"),seo=o(" \u2014 "),mR=a("a"),leo=o("RobertaTokenizer"),ieo=o(" or "),gR=a("a"),deo=o("RobertaTokenizerFast"),ceo=o(" (Data2VecText model)"),feo=l(),Xn=a("li"),mte=a("strong"),meo=o("deberta"),geo=o(" \u2014 "),hR=a("a"),heo=o("DebertaTokenizer"),peo=o(" or "),pR=a("a"),_eo=o("DebertaTokenizerFast"),ueo=o(" (DeBERTa model)"),beo=l(),zn=a("li"),gte=a("strong"),veo=o("deberta-v2"),Feo=o(" \u2014 "),_R=a("a"),Teo=o("DebertaV2Tokenizer"),Meo=o(" or "),uR=a("a"),Eeo=o("DebertaV2TokenizerFast"),Ceo=o(" (DeBERTa-v2 model)"),weo=l(),Wn=a("li"),hte=a("strong"),Aeo=o("distilbert"),yeo=o(" \u2014 "),bR=a("a"),Leo=o("DistilBertTokenizer"),xeo=o(" or "),vR=a("a"),$eo=o("DistilBertTokenizerFast"),keo=o(" (DistilBERT model)"),Seo=l(),Qn=a("li"),pte=a("strong"),Reo=o("dpr"),Peo=o(" \u2014 "),FR=a("a"),Beo=o("DPRQuestionEncoderTokenizer"),Ieo=o(" or "),TR=a("a"),qeo=o("DPRQuestionEncoderTokenizerFast"),Neo=o(" (DPR model)"),jeo=l(),Hn=a("li"),_te=a("strong"),Deo=o("electra"),Geo=o(" \u2014 "),MR=a("a"),Oeo=o("ElectraTokenizer"),Veo=o(" or "),ER=a("a"),Xeo=o("ElectraTokenizerFast"),zeo=o(" (ELECTRA model)"),Weo=l(),$g=a("li"),ute=a("strong"),Qeo=o("flaubert"),Heo=o(" \u2014 "),CR=a("a"),Ueo=o("FlaubertTokenizer"),Jeo=o(" (FlauBERT model)"),Yeo=l(),Un=a("li"),bte=a("strong"),Keo=o("fnet"),Zeo=o(" \u2014 "),wR=a("a"),eoo=o("FNetTokenizer"),ooo=o(" or "),AR=a("a"),roo=o("FNetTokenizerFast"),too=o(" (FNet model)"),aoo=l(),kg=a("li"),vte=a("strong"),noo=o("fsmt"),soo=o(" \u2014 "),yR=a("a"),loo=o("FSMTTokenizer"),ioo=o(" (FairSeq Machine-Translation model)"),doo=l(),Jn=a("li"),Fte=a("strong"),coo=o("funnel"),foo=o(" \u2014 "),LR=a("a"),moo=o("FunnelTokenizer"),goo=o(" or "),xR=a("a"),hoo=o("FunnelTokenizerFast"),poo=o(" (Funnel Transformer model)"),_oo=l(),Yn=a("li"),Tte=a("strong"),uoo=o("gpt2"),boo=o(" \u2014 "),$R=a("a"),voo=o("GPT2Tokenizer"),Foo=o(" or "),kR=a("a"),Too=o("GPT2TokenizerFast"),Moo=o(" (OpenAI GPT-2 model)"),Eoo=l(),Kn=a("li"),Mte=a("strong"),Coo=o("gpt_neo"),woo=o(" \u2014 "),SR=a("a"),Aoo=o("GPT2Tokenizer"),yoo=o(" or "),RR=a("a"),Loo=o("GPT2TokenizerFast"),xoo=o(" (GPT Neo model)"),$oo=l(),Zn=a("li"),Ete=a("strong"),koo=o("gptj"),Soo=o(" \u2014 "),PR=a("a"),Roo=o("GPT2Tokenizer"),Poo=o(" or "),BR=a("a"),Boo=o("GPT2TokenizerFast"),Ioo=o(" (GPT-J model)"),qoo=l(),es=a("li"),Cte=a("strong"),Noo=o("herbert"),joo=o(" \u2014 "),IR=a("a"),Doo=o("HerbertTokenizer"),Goo=o(" or "),qR=a("a"),Ooo=o("HerbertTokenizerFast"),Voo=o(" (HerBERT model)"),Xoo=l(),Sg=a("li"),wte=a("strong"),zoo=o("hubert"),Woo=o(" \u2014 "),NR=a("a"),Qoo=o("Wav2Vec2CTCTokenizer"),Hoo=o(" (Hubert model)"),Uoo=l(),os=a("li"),Ate=a("strong"),Joo=o("ibert"),Yoo=o(" \u2014 "),jR=a("a"),Koo=o("RobertaTokenizer"),Zoo=o(" or "),DR=a("a"),ero=o("RobertaTokenizerFast"),oro=o(" (I-BERT model)"),rro=l(),rs=a("li"),yte=a("strong"),tro=o("layoutlm"),aro=o(" \u2014 "),GR=a("a"),nro=o("LayoutLMTokenizer"),sro=o(" or "),OR=a("a"),lro=o("LayoutLMTokenizerFast"),iro=o(" (LayoutLM model)"),dro=l(),ts=a("li"),Lte=a("strong"),cro=o("layoutlmv2"),fro=o(" \u2014 "),VR=a("a"),mro=o("LayoutLMv2Tokenizer"),gro=o(" or "),XR=a("a"),hro=o("LayoutLMv2TokenizerFast"),pro=o(" (LayoutLMv2 model)"),_ro=l(),as=a("li"),xte=a("strong"),uro=o("layoutxlm"),bro=o(" \u2014 "),zR=a("a"),vro=o("LayoutXLMTokenizer"),Fro=o(" or "),WR=a("a"),Tro=o("LayoutXLMTokenizerFast"),Mro=o(" (LayoutXLM model)"),Ero=l(),ns=a("li"),$te=a("strong"),Cro=o("led"),wro=o(" \u2014 "),QR=a("a"),Aro=o("LEDTokenizer"),yro=o(" or "),HR=a("a"),Lro=o("LEDTokenizerFast"),xro=o(" (LED model)"),$ro=l(),ss=a("li"),kte=a("strong"),kro=o("longformer"),Sro=o(" \u2014 "),UR=a("a"),Rro=o("LongformerTokenizer"),Pro=o(" or "),JR=a("a"),Bro=o("LongformerTokenizerFast"),Iro=o(" (Longformer model)"),qro=l(),Rg=a("li"),Ste=a("strong"),Nro=o("luke"),jro=o(" \u2014 "),YR=a("a"),Dro=o("LukeTokenizer"),Gro=o(" (LUKE model)"),Oro=l(),ls=a("li"),Rte=a("strong"),Vro=o("lxmert"),Xro=o(" \u2014 "),KR=a("a"),zro=o("LxmertTokenizer"),Wro=o(" or "),ZR=a("a"),Qro=o("LxmertTokenizerFast"),Hro=o(" (LXMERT model)"),Uro=l(),Pg=a("li"),Pte=a("strong"),Jro=o("m2m_100"),Yro=o(" \u2014 "),eP=a("a"),Kro=o("M2M100Tokenizer"),Zro=o(" (M2M100 model)"),eto=l(),Bg=a("li"),Bte=a("strong"),oto=o("marian"),rto=o(" \u2014 "),oP=a("a"),tto=o("MarianTokenizer"),ato=o(" (Marian model)"),nto=l(),is=a("li"),Ite=a("strong"),sto=o("mbart"),lto=o(" \u2014 "),rP=a("a"),ito=o("MBartTokenizer"),dto=o(" or "),tP=a("a"),cto=o("MBartTokenizerFast"),fto=o(" (mBART model)"),mto=l(),ds=a("li"),qte=a("strong"),gto=o("mbart50"),hto=o(" \u2014 "),aP=a("a"),pto=o("MBart50Tokenizer"),_to=o(" or "),nP=a("a"),uto=o("MBart50TokenizerFast"),bto=o(" (mBART-50 model)"),vto=l(),cs=a("li"),Nte=a("strong"),Fto=o("megatron-bert"),Tto=o(" \u2014 "),sP=a("a"),Mto=o("BertTokenizer"),Eto=o(" or "),lP=a("a"),Cto=o("BertTokenizerFast"),wto=o(" (MegatronBert model)"),Ato=l(),Ig=a("li"),jte=a("strong"),yto=o("mluke"),Lto=o(" \u2014 "),iP=a("a"),xto=o("MLukeTokenizer"),$to=o(" (mLUKE model)"),kto=l(),fs=a("li"),Dte=a("strong"),Sto=o("mobilebert"),Rto=o(" \u2014 "),dP=a("a"),Pto=o("MobileBertTokenizer"),Bto=o(" or "),cP=a("a"),Ito=o("MobileBertTokenizerFast"),qto=o(" (MobileBERT model)"),Nto=l(),ms=a("li"),Gte=a("strong"),jto=o("mpnet"),Dto=o(" \u2014 "),fP=a("a"),Gto=o("MPNetTokenizer"),Oto=o(" or "),mP=a("a"),Vto=o("MPNetTokenizerFast"),Xto=o(" (MPNet model)"),zto=l(),gs=a("li"),Ote=a("strong"),Wto=o("mt5"),Qto=o(" \u2014 "),gP=a("a"),Hto=o("MT5Tokenizer"),Uto=o(" or "),hP=a("a"),Jto=o("MT5TokenizerFast"),Yto=o(" (mT5 model)"),Kto=l(),hs=a("li"),Vte=a("strong"),Zto=o("nystromformer"),eao=o(" \u2014 "),pP=a("a"),oao=o("AlbertTokenizer"),rao=o(" or "),_P=a("a"),tao=o("AlbertTokenizerFast"),aao=o(" (Nystromformer model)"),nao=l(),ps=a("li"),Xte=a("strong"),sao=o("openai-gpt"),lao=o(" \u2014 "),uP=a("a"),iao=o("OpenAIGPTTokenizer"),dao=o(" or "),bP=a("a"),cao=o("OpenAIGPTTokenizerFast"),fao=o(" (OpenAI GPT model)"),mao=l(),qg=a("li"),zte=a("strong"),gao=o("opt"),hao=o(" \u2014 "),vP=a("a"),pao=o("GPT2Tokenizer"),_ao=o(" (OPT model)"),uao=l(),_s=a("li"),Wte=a("strong"),bao=o("pegasus"),vao=o(" \u2014 "),FP=a("a"),Fao=o("PegasusTokenizer"),Tao=o(" or "),TP=a("a"),Mao=o("PegasusTokenizerFast"),Eao=o(" (Pegasus model)"),Cao=l(),Ng=a("li"),Qte=a("strong"),wao=o("perceiver"),Aao=o(" \u2014 "),MP=a("a"),yao=o("PerceiverTokenizer"),Lao=o(" (Perceiver model)"),xao=l(),jg=a("li"),Hte=a("strong"),$ao=o("phobert"),kao=o(" \u2014 "),EP=a("a"),Sao=o("PhobertTokenizer"),Rao=o(" (PhoBERT model)"),Pao=l(),Dg=a("li"),Ute=a("strong"),Bao=o("plbart"),Iao=o(" \u2014 "),CP=a("a"),qao=o("PLBartTokenizer"),Nao=o(" (PLBart model)"),jao=l(),Gg=a("li"),Jte=a("strong"),Dao=o("prophetnet"),Gao=o(" \u2014 "),wP=a("a"),Oao=o("ProphetNetTokenizer"),Vao=o(" (ProphetNet model)"),Xao=l(),us=a("li"),Yte=a("strong"),zao=o("qdqbert"),Wao=o(" \u2014 "),AP=a("a"),Qao=o("BertTokenizer"),Hao=o(" or "),yP=a("a"),Uao=o("BertTokenizerFast"),Jao=o(" (QDQBert model)"),Yao=l(),Og=a("li"),Kte=a("strong"),Kao=o("rag"),Zao=o(" \u2014 "),LP=a("a"),eno=o("RagTokenizer"),ono=o(" (RAG model)"),rno=l(),bs=a("li"),Zte=a("strong"),tno=o("realm"),ano=o(" \u2014 "),xP=a("a"),nno=o("RealmTokenizer"),sno=o(" or "),$P=a("a"),lno=o("RealmTokenizerFast"),ino=o(" (Realm model)"),dno=l(),vs=a("li"),eae=a("strong"),cno=o("reformer"),fno=o(" \u2014 "),kP=a("a"),mno=o("ReformerTokenizer"),gno=o(" or "),SP=a("a"),hno=o("ReformerTokenizerFast"),pno=o(" (Reformer model)"),_no=l(),Fs=a("li"),oae=a("strong"),uno=o("rembert"),bno=o(" \u2014 "),RP=a("a"),vno=o("RemBertTokenizer"),Fno=o(" or "),PP=a("a"),Tno=o("RemBertTokenizerFast"),Mno=o(" (RemBERT model)"),Eno=l(),Ts=a("li"),rae=a("strong"),Cno=o("retribert"),wno=o(" \u2014 "),BP=a("a"),Ano=o("RetriBertTokenizer"),yno=o(" or "),IP=a("a"),Lno=o("RetriBertTokenizerFast"),xno=o(" (RetriBERT model)"),$no=l(),Ms=a("li"),tae=a("strong"),kno=o("roberta"),Sno=o(" \u2014 "),qP=a("a"),Rno=o("RobertaTokenizer"),Pno=o(" or "),NP=a("a"),Bno=o("RobertaTokenizerFast"),Ino=o(" (RoBERTa model)"),qno=l(),Es=a("li"),aae=a("strong"),Nno=o("roformer"),jno=o(" \u2014 "),jP=a("a"),Dno=o("RoFormerTokenizer"),Gno=o(" or "),DP=a("a"),Ono=o("RoFormerTokenizerFast"),Vno=o(" (RoFormer model)"),Xno=l(),Vg=a("li"),nae=a("strong"),zno=o("speech_to_text"),Wno=o(" \u2014 "),GP=a("a"),Qno=o("Speech2TextTokenizer"),Hno=o(" (Speech2Text model)"),Uno=l(),Xg=a("li"),sae=a("strong"),Jno=o("speech_to_text_2"),Yno=o(" \u2014 "),OP=a("a"),Kno=o("Speech2Text2Tokenizer"),Zno=o(" (Speech2Text2 model)"),eso=l(),Cs=a("li"),lae=a("strong"),oso=o("splinter"),rso=o(" \u2014 "),VP=a("a"),tso=o("SplinterTokenizer"),aso=o(" or "),XP=a("a"),nso=o("SplinterTokenizerFast"),sso=o(" (Splinter model)"),lso=l(),ws=a("li"),iae=a("strong"),iso=o("squeezebert"),dso=o(" \u2014 "),zP=a("a"),cso=o("SqueezeBertTokenizer"),fso=o(" or "),WP=a("a"),mso=o("SqueezeBertTokenizerFast"),gso=o(" (SqueezeBERT model)"),hso=l(),As=a("li"),dae=a("strong"),pso=o("t5"),_so=o(" \u2014 "),QP=a("a"),uso=o("T5Tokenizer"),bso=o(" or "),HP=a("a"),vso=o("T5TokenizerFast"),Fso=o(" (T5 model)"),Tso=l(),zg=a("li"),cae=a("strong"),Mso=o("tapas"),Eso=o(" \u2014 "),UP=a("a"),Cso=o("TapasTokenizer"),wso=o(" (TAPAS model)"),Aso=l(),Wg=a("li"),fae=a("strong"),yso=o("tapex"),Lso=o(" \u2014 "),JP=a("a"),xso=o("TapexTokenizer"),$so=o(" (TAPEX model)"),kso=l(),Qg=a("li"),mae=a("strong"),Sso=o("transfo-xl"),Rso=o(" \u2014 "),YP=a("a"),Pso=o("TransfoXLTokenizer"),Bso=o(" (Transformer-XL model)"),Iso=l(),ys=a("li"),gae=a("strong"),qso=o("visual_bert"),Nso=o(" \u2014 "),KP=a("a"),jso=o("BertTokenizer"),Dso=o(" or "),ZP=a("a"),Gso=o("BertTokenizerFast"),Oso=o(" (VisualBert model)"),Vso=l(),Hg=a("li"),hae=a("strong"),Xso=o("wav2vec2"),zso=o(" \u2014 "),eB=a("a"),Wso=o("Wav2Vec2CTCTokenizer"),Qso=o(" (Wav2Vec2 model)"),Hso=l(),Ug=a("li"),pae=a("strong"),Uso=o("wav2vec2-conformer"),Jso=o(" \u2014 "),oB=a("a"),Yso=o("Wav2Vec2CTCTokenizer"),Kso=o(" (Wav2Vec2-Conformer model)"),Zso=l(),Jg=a("li"),_ae=a("strong"),elo=o("wav2vec2_phoneme"),olo=o(" \u2014 "),rB=a("a"),rlo=o("Wav2Vec2PhonemeCTCTokenizer"),tlo=o(" (Wav2Vec2Phoneme model)"),alo=l(),Ls=a("li"),uae=a("strong"),nlo=o("xglm"),slo=o(" \u2014 "),tB=a("a"),llo=o("XGLMTokenizer"),ilo=o(" or "),aB=a("a"),dlo=o("XGLMTokenizerFast"),clo=o(" (XGLM model)"),flo=l(),Yg=a("li"),bae=a("strong"),mlo=o("xlm"),glo=o(" \u2014 "),nB=a("a"),hlo=o("XLMTokenizer"),plo=o(" (XLM model)"),_lo=l(),Kg=a("li"),vae=a("strong"),ulo=o("xlm-prophetnet"),blo=o(" \u2014 "),sB=a("a"),vlo=o("XLMProphetNetTokenizer"),Flo=o(" (XLMProphetNet model)"),Tlo=l(),xs=a("li"),Fae=a("strong"),Mlo=o("xlm-roberta"),Elo=o(" \u2014 "),lB=a("a"),Clo=o("XLMRobertaTokenizer"),wlo=o(" or "),iB=a("a"),Alo=o("XLMRobertaTokenizerFast"),ylo=o(" (XLM-RoBERTa model)"),Llo=l(),$s=a("li"),Tae=a("strong"),xlo=o("xlm-roberta-xl"),$lo=o(" \u2014 "),dB=a("a"),klo=o("RobertaTokenizer"),Slo=o(" or "),cB=a("a"),Rlo=o("RobertaTokenizerFast"),Plo=o(" (XLM-RoBERTa-XL model)"),Blo=l(),ks=a("li"),Mae=a("strong"),Ilo=o("xlnet"),qlo=o(" \u2014 "),fB=a("a"),Nlo=o("XLNetTokenizer"),jlo=o(" or "),mB=a("a"),Dlo=o("XLNetTokenizerFast"),Glo=o(" (XLNet model)"),Olo=l(),Ss=a("li"),Eae=a("strong"),Vlo=o("yoso"),Xlo=o(" \u2014 "),gB=a("a"),zlo=o("AlbertTokenizer"),Wlo=o(" or "),hB=a("a"),Qlo=o("AlbertTokenizerFast"),Hlo=o(" (YOSO model)"),Ulo=l(),F(Zg.$$.fragment),Jlo=l(),eh=a("div"),F(A6.$$.fragment),Ylo=l(),Cae=a("p"),Klo=o("Register a new tokenizer in this mapping."),aqe=l(),Ti=a("h2"),oh=a("a"),wae=a("span"),F(y6.$$.fragment),Zlo=l(),Aae=a("span"),eio=o("AutoFeatureExtractor"),nqe=l(),Ao=a("div"),F(L6.$$.fragment),oio=l(),x6=a("p"),rio=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),pB=a("a"),tio=o("AutoFeatureExtractor.from_pretrained()"),aio=o(" class method."),nio=l(),$6=a("p"),sio=o("This class cannot be instantiated directly using "),yae=a("code"),lio=o("__init__()"),iio=o(" (throws an error)."),dio=l(),He=a("div"),F(k6.$$.fragment),cio=l(),Lae=a("p"),fio=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),mio=l(),ya=a("p"),gio=o("The feature extractor class to instantiate is selected based on the "),xae=a("code"),hio=o("model_type"),pio=o(` property of the config object
(either passed as an argument or loaded from `),$ae=a("code"),_io=o("pretrained_model_name_or_path"),uio=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),kae=a("code"),bio=o("pretrained_model_name_or_path"),vio=o(":"),Fio=l(),Z=a("ul"),rh=a("li"),Sae=a("strong"),Tio=o("beit"),Mio=o(" \u2014 "),_B=a("a"),Eio=o("BeitFeatureExtractor"),Cio=o(" (BEiT model)"),wio=l(),th=a("li"),Rae=a("strong"),Aio=o("clip"),yio=o(" \u2014 "),uB=a("a"),Lio=o("CLIPFeatureExtractor"),xio=o(" (CLIP model)"),$io=l(),ah=a("li"),Pae=a("strong"),kio=o("convnext"),Sio=o(" \u2014 "),bB=a("a"),Rio=o("ConvNextFeatureExtractor"),Pio=o(" (ConvNext model)"),Bio=l(),nh=a("li"),Bae=a("strong"),Iio=o("data2vec-audio"),qio=o(" \u2014 "),vB=a("a"),Nio=o("Wav2Vec2FeatureExtractor"),jio=o(" (Data2VecAudio model)"),Dio=l(),sh=a("li"),Iae=a("strong"),Gio=o("data2vec-vision"),Oio=o(" \u2014 "),FB=a("a"),Vio=o("BeitFeatureExtractor"),Xio=o(" (Data2VecVision model)"),zio=l(),lh=a("li"),qae=a("strong"),Wio=o("deit"),Qio=o(" \u2014 "),TB=a("a"),Hio=o("DeiTFeatureExtractor"),Uio=o(" (DeiT model)"),Jio=l(),ih=a("li"),Nae=a("strong"),Yio=o("detr"),Kio=o(" \u2014 "),MB=a("a"),Zio=o("DetrFeatureExtractor"),edo=o(" (DETR model)"),odo=l(),dh=a("li"),jae=a("strong"),rdo=o("dpt"),tdo=o(" \u2014 "),EB=a("a"),ado=o("DPTFeatureExtractor"),ndo=o(" (DPT model)"),sdo=l(),ch=a("li"),Dae=a("strong"),ldo=o("flava"),ido=o(" \u2014 "),CB=a("a"),ddo=o("FlavaFeatureExtractor"),cdo=o(" (Flava model)"),fdo=l(),fh=a("li"),Gae=a("strong"),mdo=o("glpn"),gdo=o(" \u2014 "),wB=a("a"),hdo=o("GLPNFeatureExtractor"),pdo=o(" (GLPN model)"),_do=l(),mh=a("li"),Oae=a("strong"),udo=o("hubert"),bdo=o(" \u2014 "),AB=a("a"),vdo=o("Wav2Vec2FeatureExtractor"),Fdo=o(" (Hubert model)"),Tdo=l(),gh=a("li"),Vae=a("strong"),Mdo=o("layoutlmv2"),Edo=o(" \u2014 "),yB=a("a"),Cdo=o("LayoutLMv2FeatureExtractor"),wdo=o(" (LayoutLMv2 model)"),Ado=l(),hh=a("li"),Xae=a("strong"),ydo=o("maskformer"),Ldo=o(" \u2014 "),LB=a("a"),xdo=o("MaskFormerFeatureExtractor"),$do=o(" (MaskFormer model)"),kdo=l(),ph=a("li"),zae=a("strong"),Sdo=o("perceiver"),Rdo=o(" \u2014 "),xB=a("a"),Pdo=o("PerceiverFeatureExtractor"),Bdo=o(" (Perceiver model)"),Ido=l(),_h=a("li"),Wae=a("strong"),qdo=o("poolformer"),Ndo=o(" \u2014 "),$B=a("a"),jdo=o("PoolFormerFeatureExtractor"),Ddo=o(" (PoolFormer model)"),Gdo=l(),uh=a("li"),Qae=a("strong"),Odo=o("regnet"),Vdo=o(" \u2014 "),kB=a("a"),Xdo=o("ConvNextFeatureExtractor"),zdo=o(" (RegNet model)"),Wdo=l(),bh=a("li"),Hae=a("strong"),Qdo=o("resnet"),Hdo=o(" \u2014 "),SB=a("a"),Udo=o("ConvNextFeatureExtractor"),Jdo=o(" (ResNet model)"),Ydo=l(),vh=a("li"),Uae=a("strong"),Kdo=o("segformer"),Zdo=o(" \u2014 "),RB=a("a"),eco=o("SegformerFeatureExtractor"),oco=o(" (SegFormer model)"),rco=l(),Fh=a("li"),Jae=a("strong"),tco=o("speech_to_text"),aco=o(" \u2014 "),PB=a("a"),nco=o("Speech2TextFeatureExtractor"),sco=o(" (Speech2Text model)"),lco=l(),Th=a("li"),Yae=a("strong"),ico=o("swin"),dco=o(" \u2014 "),BB=a("a"),cco=o("ViTFeatureExtractor"),fco=o(" (Swin model)"),mco=l(),Mh=a("li"),Kae=a("strong"),gco=o("van"),hco=o(" \u2014 "),IB=a("a"),pco=o("ConvNextFeatureExtractor"),_co=o(" (VAN model)"),uco=l(),Eh=a("li"),Zae=a("strong"),bco=o("vit"),vco=o(" \u2014 "),qB=a("a"),Fco=o("ViTFeatureExtractor"),Tco=o(" (ViT model)"),Mco=l(),Ch=a("li"),ene=a("strong"),Eco=o("vit_mae"),Cco=o(" \u2014 "),NB=a("a"),wco=o("ViTFeatureExtractor"),Aco=o(" (ViTMAE model)"),yco=l(),wh=a("li"),one=a("strong"),Lco=o("wav2vec2"),xco=o(" \u2014 "),jB=a("a"),$co=o("Wav2Vec2FeatureExtractor"),kco=o(" (Wav2Vec2 model)"),Sco=l(),Ah=a("li"),rne=a("strong"),Rco=o("wav2vec2-conformer"),Pco=o(" \u2014 "),DB=a("a"),Bco=o("Wav2Vec2FeatureExtractor"),Ico=o(" (Wav2Vec2-Conformer model)"),qco=l(),yh=a("li"),tne=a("strong"),Nco=o("yolos"),jco=o(" \u2014 "),GB=a("a"),Dco=o("YolosFeatureExtractor"),Gco=o(" (YOLOS model)"),Oco=l(),F(Lh.$$.fragment),Vco=l(),F(xh.$$.fragment),Xco=l(),$h=a("div"),F(S6.$$.fragment),zco=l(),ane=a("p"),Wco=o("Register a new feature extractor for this class."),sqe=l(),Mi=a("h2"),kh=a("a"),nne=a("span"),F(R6.$$.fragment),Qco=l(),sne=a("span"),Hco=o("AutoProcessor"),lqe=l(),yo=a("div"),F(P6.$$.fragment),Uco=l(),B6=a("p"),Jco=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),OB=a("a"),Yco=o("AutoProcessor.from_pretrained()"),Kco=o(" class method."),Zco=l(),I6=a("p"),efo=o("This class cannot be instantiated directly using "),lne=a("code"),ofo=o("__init__()"),rfo=o(" (throws an error)."),tfo=l(),Ue=a("div"),F(q6.$$.fragment),afo=l(),ine=a("p"),nfo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),sfo=l(),Ei=a("p"),lfo=o("The processor class to instantiate is selected based on the "),dne=a("code"),ifo=o("model_type"),dfo=o(` property of the config object (either
passed as an argument or loaded from `),cne=a("code"),cfo=o("pretrained_model_name_or_path"),ffo=o(" if possible):"),mfo=l(),pe=a("ul"),Sh=a("li"),fne=a("strong"),gfo=o("clip"),hfo=o(" \u2014 "),VB=a("a"),pfo=o("CLIPProcessor"),_fo=o(" (CLIP model)"),ufo=l(),Rh=a("li"),mne=a("strong"),bfo=o("flava"),vfo=o(" \u2014 "),gne=a("code"),Ffo=o("FLAVAProcessor"),Tfo=o(" (Flava model)"),Mfo=l(),Ph=a("li"),hne=a("strong"),Efo=o("layoutlmv2"),Cfo=o(" \u2014 "),XB=a("a"),wfo=o("LayoutLMv2Processor"),Afo=o(" (LayoutLMv2 model)"),yfo=l(),Bh=a("li"),pne=a("strong"),Lfo=o("layoutxlm"),xfo=o(" \u2014 "),zB=a("a"),$fo=o("LayoutXLMProcessor"),kfo=o(" (LayoutXLM model)"),Sfo=l(),Ih=a("li"),_ne=a("strong"),Rfo=o("sew"),Pfo=o(" \u2014 "),WB=a("a"),Bfo=o("Wav2Vec2Processor"),Ifo=o(" (SEW model)"),qfo=l(),qh=a("li"),une=a("strong"),Nfo=o("sew-d"),jfo=o(" \u2014 "),QB=a("a"),Dfo=o("Wav2Vec2Processor"),Gfo=o(" (SEW-D model)"),Ofo=l(),Nh=a("li"),bne=a("strong"),Vfo=o("speech_to_text"),Xfo=o(" \u2014 "),HB=a("a"),zfo=o("Speech2TextProcessor"),Wfo=o(" (Speech2Text model)"),Qfo=l(),jh=a("li"),vne=a("strong"),Hfo=o("speech_to_text_2"),Ufo=o(" \u2014 "),UB=a("a"),Jfo=o("Speech2Text2Processor"),Yfo=o(" (Speech2Text2 model)"),Kfo=l(),Dh=a("li"),Fne=a("strong"),Zfo=o("trocr"),emo=o(" \u2014 "),JB=a("a"),omo=o("TrOCRProcessor"),rmo=o(" (TrOCR model)"),tmo=l(),Gh=a("li"),Tne=a("strong"),amo=o("unispeech"),nmo=o(" \u2014 "),YB=a("a"),smo=o("Wav2Vec2Processor"),lmo=o(" (UniSpeech model)"),imo=l(),Oh=a("li"),Mne=a("strong"),dmo=o("unispeech-sat"),cmo=o(" \u2014 "),KB=a("a"),fmo=o("Wav2Vec2Processor"),mmo=o(" (UniSpeechSat model)"),gmo=l(),Vh=a("li"),Ene=a("strong"),hmo=o("vilt"),pmo=o(" \u2014 "),ZB=a("a"),_mo=o("ViltProcessor"),umo=o(" (ViLT model)"),bmo=l(),Xh=a("li"),Cne=a("strong"),vmo=o("vision-text-dual-encoder"),Fmo=o(" \u2014 "),eI=a("a"),Tmo=o("VisionTextDualEncoderProcessor"),Mmo=o(" (VisionTextDualEncoder model)"),Emo=l(),zh=a("li"),wne=a("strong"),Cmo=o("wav2vec2"),wmo=o(" \u2014 "),oI=a("a"),Amo=o("Wav2Vec2Processor"),ymo=o(" (Wav2Vec2 model)"),Lmo=l(),Wh=a("li"),Ane=a("strong"),xmo=o("wav2vec2-conformer"),$mo=o(" \u2014 "),rI=a("a"),kmo=o("Wav2Vec2Processor"),Smo=o(" (Wav2Vec2-Conformer model)"),Rmo=l(),Qh=a("li"),yne=a("strong"),Pmo=o("wavlm"),Bmo=o(" \u2014 "),tI=a("a"),Imo=o("Wav2Vec2Processor"),qmo=o(" (WavLM model)"),Nmo=l(),F(Hh.$$.fragment),jmo=l(),F(Uh.$$.fragment),Dmo=l(),Jh=a("div"),F(N6.$$.fragment),Gmo=l(),Lne=a("p"),Omo=o("Register a new processor for this class."),iqe=l(),Ci=a("h2"),Yh=a("a"),xne=a("span"),F(j6.$$.fragment),Vmo=l(),$ne=a("span"),Xmo=o("AutoModel"),dqe=l(),Lo=a("div"),F(D6.$$.fragment),zmo=l(),wi=a("p"),Wmo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),aI=a("a"),Qmo=o("from_pretrained()"),Hmo=o(" class method or the "),nI=a("a"),Umo=o("from_config()"),Jmo=o(` class
method.`),Ymo=l(),G6=a("p"),Kmo=o("This class cannot be instantiated directly using "),kne=a("code"),Zmo=o("__init__()"),ego=o(" (throws an error)."),ogo=l(),tt=a("div"),F(O6.$$.fragment),rgo=l(),Sne=a("p"),tgo=o("Instantiates one of the base model classes of the library from a configuration."),ago=l(),Ai=a("p"),ngo=o(`Note:
Loading a model from its configuration file does `),Rne=a("strong"),sgo=o("not"),lgo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sI=a("a"),igo=o("from_pretrained()"),dgo=o(" to load the model weights."),cgo=l(),F(Kh.$$.fragment),fgo=l(),Je=a("div"),F(V6.$$.fragment),mgo=l(),Pne=a("p"),ggo=o("Instantiate one of the base model classes of the library from a pretrained model."),hgo=l(),La=a("p"),pgo=o("The model class to instantiate is selected based on the "),Bne=a("code"),_go=o("model_type"),ugo=o(` property of the config object (either
passed as an argument or loaded from `),Ine=a("code"),bgo=o("pretrained_model_name_or_path"),vgo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qne=a("code"),Fgo=o("pretrained_model_name_or_path"),Tgo=o(":"),Mgo=l(),x=a("ul"),Zh=a("li"),Nne=a("strong"),Ego=o("albert"),Cgo=o(" \u2014 "),lI=a("a"),wgo=o("AlbertModel"),Ago=o(" (ALBERT model)"),ygo=l(),ep=a("li"),jne=a("strong"),Lgo=o("bart"),xgo=o(" \u2014 "),iI=a("a"),$go=o("BartModel"),kgo=o(" (BART model)"),Sgo=l(),op=a("li"),Dne=a("strong"),Rgo=o("beit"),Pgo=o(" \u2014 "),dI=a("a"),Bgo=o("BeitModel"),Igo=o(" (BEiT model)"),qgo=l(),rp=a("li"),Gne=a("strong"),Ngo=o("bert"),jgo=o(" \u2014 "),cI=a("a"),Dgo=o("BertModel"),Ggo=o(" (BERT model)"),Ogo=l(),tp=a("li"),One=a("strong"),Vgo=o("bert-generation"),Xgo=o(" \u2014 "),fI=a("a"),zgo=o("BertGenerationEncoder"),Wgo=o(" (Bert Generation model)"),Qgo=l(),ap=a("li"),Vne=a("strong"),Hgo=o("big_bird"),Ugo=o(" \u2014 "),mI=a("a"),Jgo=o("BigBirdModel"),Ygo=o(" (BigBird model)"),Kgo=l(),np=a("li"),Xne=a("strong"),Zgo=o("bigbird_pegasus"),eho=o(" \u2014 "),gI=a("a"),oho=o("BigBirdPegasusModel"),rho=o(" (BigBirdPegasus model)"),tho=l(),sp=a("li"),zne=a("strong"),aho=o("blenderbot"),nho=o(" \u2014 "),hI=a("a"),sho=o("BlenderbotModel"),lho=o(" (Blenderbot model)"),iho=l(),lp=a("li"),Wne=a("strong"),dho=o("blenderbot-small"),cho=o(" \u2014 "),pI=a("a"),fho=o("BlenderbotSmallModel"),mho=o(" (BlenderbotSmall model)"),gho=l(),ip=a("li"),Qne=a("strong"),hho=o("camembert"),pho=o(" \u2014 "),_I=a("a"),_ho=o("CamembertModel"),uho=o(" (CamemBERT model)"),bho=l(),dp=a("li"),Hne=a("strong"),vho=o("canine"),Fho=o(" \u2014 "),uI=a("a"),Tho=o("CanineModel"),Mho=o(" (Canine model)"),Eho=l(),cp=a("li"),Une=a("strong"),Cho=o("clip"),who=o(" \u2014 "),bI=a("a"),Aho=o("CLIPModel"),yho=o(" (CLIP model)"),Lho=l(),fp=a("li"),Jne=a("strong"),xho=o("convbert"),$ho=o(" \u2014 "),vI=a("a"),kho=o("ConvBertModel"),Sho=o(" (ConvBERT model)"),Rho=l(),mp=a("li"),Yne=a("strong"),Pho=o("convnext"),Bho=o(" \u2014 "),FI=a("a"),Iho=o("ConvNextModel"),qho=o(" (ConvNext model)"),Nho=l(),gp=a("li"),Kne=a("strong"),jho=o("ctrl"),Dho=o(" \u2014 "),TI=a("a"),Gho=o("CTRLModel"),Oho=o(" (CTRL model)"),Vho=l(),hp=a("li"),Zne=a("strong"),Xho=o("data2vec-audio"),zho=o(" \u2014 "),MI=a("a"),Who=o("Data2VecAudioModel"),Qho=o(" (Data2VecAudio model)"),Hho=l(),pp=a("li"),ese=a("strong"),Uho=o("data2vec-text"),Jho=o(" \u2014 "),EI=a("a"),Yho=o("Data2VecTextModel"),Kho=o(" (Data2VecText model)"),Zho=l(),_p=a("li"),ose=a("strong"),epo=o("data2vec-vision"),opo=o(" \u2014 "),CI=a("a"),rpo=o("Data2VecVisionModel"),tpo=o(" (Data2VecVision model)"),apo=l(),up=a("li"),rse=a("strong"),npo=o("deberta"),spo=o(" \u2014 "),wI=a("a"),lpo=o("DebertaModel"),ipo=o(" (DeBERTa model)"),dpo=l(),bp=a("li"),tse=a("strong"),cpo=o("deberta-v2"),fpo=o(" \u2014 "),AI=a("a"),mpo=o("DebertaV2Model"),gpo=o(" (DeBERTa-v2 model)"),hpo=l(),vp=a("li"),ase=a("strong"),ppo=o("decision_transformer"),_po=o(" \u2014 "),yI=a("a"),upo=o("DecisionTransformerModel"),bpo=o(" (Decision Transformer model)"),vpo=l(),Fp=a("li"),nse=a("strong"),Fpo=o("deit"),Tpo=o(" \u2014 "),LI=a("a"),Mpo=o("DeiTModel"),Epo=o(" (DeiT model)"),Cpo=l(),Tp=a("li"),sse=a("strong"),wpo=o("detr"),Apo=o(" \u2014 "),xI=a("a"),ypo=o("DetrModel"),Lpo=o(" (DETR model)"),xpo=l(),Mp=a("li"),lse=a("strong"),$po=o("distilbert"),kpo=o(" \u2014 "),$I=a("a"),Spo=o("DistilBertModel"),Rpo=o(" (DistilBERT model)"),Ppo=l(),Ep=a("li"),ise=a("strong"),Bpo=o("dpr"),Ipo=o(" \u2014 "),kI=a("a"),qpo=o("DPRQuestionEncoder"),Npo=o(" (DPR model)"),jpo=l(),Cp=a("li"),dse=a("strong"),Dpo=o("dpt"),Gpo=o(" \u2014 "),SI=a("a"),Opo=o("DPTModel"),Vpo=o(" (DPT model)"),Xpo=l(),wp=a("li"),cse=a("strong"),zpo=o("electra"),Wpo=o(" \u2014 "),RI=a("a"),Qpo=o("ElectraModel"),Hpo=o(" (ELECTRA model)"),Upo=l(),Ap=a("li"),fse=a("strong"),Jpo=o("flaubert"),Ypo=o(" \u2014 "),PI=a("a"),Kpo=o("FlaubertModel"),Zpo=o(" (FlauBERT model)"),e_o=l(),yp=a("li"),mse=a("strong"),o_o=o("flava"),r_o=o(" \u2014 "),BI=a("a"),t_o=o("FlavaModel"),a_o=o(" (Flava model)"),n_o=l(),Lp=a("li"),gse=a("strong"),s_o=o("fnet"),l_o=o(" \u2014 "),II=a("a"),i_o=o("FNetModel"),d_o=o(" (FNet model)"),c_o=l(),xp=a("li"),hse=a("strong"),f_o=o("fsmt"),m_o=o(" \u2014 "),qI=a("a"),g_o=o("FSMTModel"),h_o=o(" (FairSeq Machine-Translation model)"),p_o=l(),Rs=a("li"),pse=a("strong"),__o=o("funnel"),u_o=o(" \u2014 "),NI=a("a"),b_o=o("FunnelModel"),v_o=o(" or "),jI=a("a"),F_o=o("FunnelBaseModel"),T_o=o(" (Funnel Transformer model)"),M_o=l(),$p=a("li"),_se=a("strong"),E_o=o("glpn"),C_o=o(" \u2014 "),DI=a("a"),w_o=o("GLPNModel"),A_o=o(" (GLPN model)"),y_o=l(),kp=a("li"),use=a("strong"),L_o=o("gpt2"),x_o=o(" \u2014 "),GI=a("a"),$_o=o("GPT2Model"),k_o=o(" (OpenAI GPT-2 model)"),S_o=l(),Sp=a("li"),bse=a("strong"),R_o=o("gpt_neo"),P_o=o(" \u2014 "),OI=a("a"),B_o=o("GPTNeoModel"),I_o=o(" (GPT Neo model)"),q_o=l(),Rp=a("li"),vse=a("strong"),N_o=o("gptj"),j_o=o(" \u2014 "),VI=a("a"),D_o=o("GPTJModel"),G_o=o(" (GPT-J model)"),O_o=l(),Pp=a("li"),Fse=a("strong"),V_o=o("hubert"),X_o=o(" \u2014 "),XI=a("a"),z_o=o("HubertModel"),W_o=o(" (Hubert model)"),Q_o=l(),Bp=a("li"),Tse=a("strong"),H_o=o("ibert"),U_o=o(" \u2014 "),zI=a("a"),J_o=o("IBertModel"),Y_o=o(" (I-BERT model)"),K_o=l(),Ip=a("li"),Mse=a("strong"),Z_o=o("imagegpt"),euo=o(" \u2014 "),WI=a("a"),ouo=o("ImageGPTModel"),ruo=o(" (ImageGPT model)"),tuo=l(),qp=a("li"),Ese=a("strong"),auo=o("layoutlm"),nuo=o(" \u2014 "),QI=a("a"),suo=o("LayoutLMModel"),luo=o(" (LayoutLM model)"),iuo=l(),Np=a("li"),Cse=a("strong"),duo=o("layoutlmv2"),cuo=o(" \u2014 "),HI=a("a"),fuo=o("LayoutLMv2Model"),muo=o(" (LayoutLMv2 model)"),guo=l(),jp=a("li"),wse=a("strong"),huo=o("led"),puo=o(" \u2014 "),UI=a("a"),_uo=o("LEDModel"),uuo=o(" (LED model)"),buo=l(),Dp=a("li"),Ase=a("strong"),vuo=o("longformer"),Fuo=o(" \u2014 "),JI=a("a"),Tuo=o("LongformerModel"),Muo=o(" (Longformer model)"),Euo=l(),Gp=a("li"),yse=a("strong"),Cuo=o("luke"),wuo=o(" \u2014 "),YI=a("a"),Auo=o("LukeModel"),yuo=o(" (LUKE model)"),Luo=l(),Op=a("li"),Lse=a("strong"),xuo=o("lxmert"),$uo=o(" \u2014 "),KI=a("a"),kuo=o("LxmertModel"),Suo=o(" (LXMERT model)"),Ruo=l(),Vp=a("li"),xse=a("strong"),Puo=o("m2m_100"),Buo=o(" \u2014 "),ZI=a("a"),Iuo=o("M2M100Model"),quo=o(" (M2M100 model)"),Nuo=l(),Xp=a("li"),$se=a("strong"),juo=o("marian"),Duo=o(" \u2014 "),eq=a("a"),Guo=o("MarianModel"),Ouo=o(" (Marian model)"),Vuo=l(),zp=a("li"),kse=a("strong"),Xuo=o("maskformer"),zuo=o(" \u2014 "),oq=a("a"),Wuo=o("MaskFormerModel"),Quo=o(" (MaskFormer model)"),Huo=l(),Wp=a("li"),Sse=a("strong"),Uuo=o("mbart"),Juo=o(" \u2014 "),rq=a("a"),Yuo=o("MBartModel"),Kuo=o(" (mBART model)"),Zuo=l(),Qp=a("li"),Rse=a("strong"),e2o=o("megatron-bert"),o2o=o(" \u2014 "),tq=a("a"),r2o=o("MegatronBertModel"),t2o=o(" (MegatronBert model)"),a2o=l(),Hp=a("li"),Pse=a("strong"),n2o=o("mobilebert"),s2o=o(" \u2014 "),aq=a("a"),l2o=o("MobileBertModel"),i2o=o(" (MobileBERT model)"),d2o=l(),Up=a("li"),Bse=a("strong"),c2o=o("mpnet"),f2o=o(" \u2014 "),nq=a("a"),m2o=o("MPNetModel"),g2o=o(" (MPNet model)"),h2o=l(),Jp=a("li"),Ise=a("strong"),p2o=o("mt5"),_2o=o(" \u2014 "),sq=a("a"),u2o=o("MT5Model"),b2o=o(" (mT5 model)"),v2o=l(),Yp=a("li"),qse=a("strong"),F2o=o("nystromformer"),T2o=o(" \u2014 "),lq=a("a"),M2o=o("NystromformerModel"),E2o=o(" (Nystromformer model)"),C2o=l(),Kp=a("li"),Nse=a("strong"),w2o=o("openai-gpt"),A2o=o(" \u2014 "),iq=a("a"),y2o=o("OpenAIGPTModel"),L2o=o(" (OpenAI GPT model)"),x2o=l(),Zp=a("li"),jse=a("strong"),$2o=o("opt"),k2o=o(" \u2014 "),dq=a("a"),S2o=o("OPTModel"),R2o=o(" (OPT model)"),P2o=l(),e_=a("li"),Dse=a("strong"),B2o=o("pegasus"),I2o=o(" \u2014 "),cq=a("a"),q2o=o("PegasusModel"),N2o=o(" (Pegasus model)"),j2o=l(),o_=a("li"),Gse=a("strong"),D2o=o("perceiver"),G2o=o(" \u2014 "),fq=a("a"),O2o=o("PerceiverModel"),V2o=o(" (Perceiver model)"),X2o=l(),r_=a("li"),Ose=a("strong"),z2o=o("plbart"),W2o=o(" \u2014 "),mq=a("a"),Q2o=o("PLBartModel"),H2o=o(" (PLBart model)"),U2o=l(),t_=a("li"),Vse=a("strong"),J2o=o("poolformer"),Y2o=o(" \u2014 "),gq=a("a"),K2o=o("PoolFormerModel"),Z2o=o(" (PoolFormer model)"),e1o=l(),a_=a("li"),Xse=a("strong"),o1o=o("prophetnet"),r1o=o(" \u2014 "),hq=a("a"),t1o=o("ProphetNetModel"),a1o=o(" (ProphetNet model)"),n1o=l(),n_=a("li"),zse=a("strong"),s1o=o("qdqbert"),l1o=o(" \u2014 "),pq=a("a"),i1o=o("QDQBertModel"),d1o=o(" (QDQBert model)"),c1o=l(),s_=a("li"),Wse=a("strong"),f1o=o("reformer"),m1o=o(" \u2014 "),_q=a("a"),g1o=o("ReformerModel"),h1o=o(" (Reformer model)"),p1o=l(),l_=a("li"),Qse=a("strong"),_1o=o("regnet"),u1o=o(" \u2014 "),uq=a("a"),b1o=o("RegNetModel"),v1o=o(" (RegNet model)"),F1o=l(),i_=a("li"),Hse=a("strong"),T1o=o("rembert"),M1o=o(" \u2014 "),bq=a("a"),E1o=o("RemBertModel"),C1o=o(" (RemBERT model)"),w1o=l(),d_=a("li"),Use=a("strong"),A1o=o("resnet"),y1o=o(" \u2014 "),vq=a("a"),L1o=o("ResNetModel"),x1o=o(" (ResNet model)"),$1o=l(),c_=a("li"),Jse=a("strong"),k1o=o("retribert"),S1o=o(" \u2014 "),Fq=a("a"),R1o=o("RetriBertModel"),P1o=o(" (RetriBERT model)"),B1o=l(),f_=a("li"),Yse=a("strong"),I1o=o("roberta"),q1o=o(" \u2014 "),Tq=a("a"),N1o=o("RobertaModel"),j1o=o(" (RoBERTa model)"),D1o=l(),m_=a("li"),Kse=a("strong"),G1o=o("roformer"),O1o=o(" \u2014 "),Mq=a("a"),V1o=o("RoFormerModel"),X1o=o(" (RoFormer model)"),z1o=l(),g_=a("li"),Zse=a("strong"),W1o=o("segformer"),Q1o=o(" \u2014 "),Eq=a("a"),H1o=o("SegformerModel"),U1o=o(" (SegFormer model)"),J1o=l(),h_=a("li"),ele=a("strong"),Y1o=o("sew"),K1o=o(" \u2014 "),Cq=a("a"),Z1o=o("SEWModel"),e7o=o(" (SEW model)"),o7o=l(),p_=a("li"),ole=a("strong"),r7o=o("sew-d"),t7o=o(" \u2014 "),wq=a("a"),a7o=o("SEWDModel"),n7o=o(" (SEW-D model)"),s7o=l(),__=a("li"),rle=a("strong"),l7o=o("speech_to_text"),i7o=o(" \u2014 "),Aq=a("a"),d7o=o("Speech2TextModel"),c7o=o(" (Speech2Text model)"),f7o=l(),u_=a("li"),tle=a("strong"),m7o=o("splinter"),g7o=o(" \u2014 "),yq=a("a"),h7o=o("SplinterModel"),p7o=o(" (Splinter model)"),_7o=l(),b_=a("li"),ale=a("strong"),u7o=o("squeezebert"),b7o=o(" \u2014 "),Lq=a("a"),v7o=o("SqueezeBertModel"),F7o=o(" (SqueezeBERT model)"),T7o=l(),v_=a("li"),nle=a("strong"),M7o=o("swin"),E7o=o(" \u2014 "),xq=a("a"),C7o=o("SwinModel"),w7o=o(" (Swin model)"),A7o=l(),F_=a("li"),sle=a("strong"),y7o=o("t5"),L7o=o(" \u2014 "),$q=a("a"),x7o=o("T5Model"),$7o=o(" (T5 model)"),k7o=l(),T_=a("li"),lle=a("strong"),S7o=o("tapas"),R7o=o(" \u2014 "),kq=a("a"),P7o=o("TapasModel"),B7o=o(" (TAPAS model)"),I7o=l(),M_=a("li"),ile=a("strong"),q7o=o("trajectory_transformer"),N7o=o(" \u2014 "),Sq=a("a"),j7o=o("TrajectoryTransformerModel"),D7o=o(" (Trajectory Transformer model)"),G7o=l(),E_=a("li"),dle=a("strong"),O7o=o("transfo-xl"),V7o=o(" \u2014 "),Rq=a("a"),X7o=o("TransfoXLModel"),z7o=o(" (Transformer-XL model)"),W7o=l(),C_=a("li"),cle=a("strong"),Q7o=o("unispeech"),H7o=o(" \u2014 "),Pq=a("a"),U7o=o("UniSpeechModel"),J7o=o(" (UniSpeech model)"),Y7o=l(),w_=a("li"),fle=a("strong"),K7o=o("unispeech-sat"),Z7o=o(" \u2014 "),Bq=a("a"),ebo=o("UniSpeechSatModel"),obo=o(" (UniSpeechSat model)"),rbo=l(),A_=a("li"),mle=a("strong"),tbo=o("van"),abo=o(" \u2014 "),Iq=a("a"),nbo=o("VanModel"),sbo=o(" (VAN model)"),lbo=l(),y_=a("li"),gle=a("strong"),ibo=o("vilt"),dbo=o(" \u2014 "),qq=a("a"),cbo=o("ViltModel"),fbo=o(" (ViLT model)"),mbo=l(),L_=a("li"),hle=a("strong"),gbo=o("vision-text-dual-encoder"),hbo=o(" \u2014 "),Nq=a("a"),pbo=o("VisionTextDualEncoderModel"),_bo=o(" (VisionTextDualEncoder model)"),ubo=l(),x_=a("li"),ple=a("strong"),bbo=o("visual_bert"),vbo=o(" \u2014 "),jq=a("a"),Fbo=o("VisualBertModel"),Tbo=o(" (VisualBert model)"),Mbo=l(),$_=a("li"),_le=a("strong"),Ebo=o("vit"),Cbo=o(" \u2014 "),Dq=a("a"),wbo=o("ViTModel"),Abo=o(" (ViT model)"),ybo=l(),k_=a("li"),ule=a("strong"),Lbo=o("vit_mae"),xbo=o(" \u2014 "),Gq=a("a"),$bo=o("ViTMAEModel"),kbo=o(" (ViTMAE model)"),Sbo=l(),S_=a("li"),ble=a("strong"),Rbo=o("wav2vec2"),Pbo=o(" \u2014 "),Oq=a("a"),Bbo=o("Wav2Vec2Model"),Ibo=o(" (Wav2Vec2 model)"),qbo=l(),R_=a("li"),vle=a("strong"),Nbo=o("wav2vec2-conformer"),jbo=o(" \u2014 "),Vq=a("a"),Dbo=o("Wav2Vec2ConformerModel"),Gbo=o(" (Wav2Vec2-Conformer model)"),Obo=l(),P_=a("li"),Fle=a("strong"),Vbo=o("wavlm"),Xbo=o(" \u2014 "),Xq=a("a"),zbo=o("WavLMModel"),Wbo=o(" (WavLM model)"),Qbo=l(),B_=a("li"),Tle=a("strong"),Hbo=o("xglm"),Ubo=o(" \u2014 "),zq=a("a"),Jbo=o("XGLMModel"),Ybo=o(" (XGLM model)"),Kbo=l(),I_=a("li"),Mle=a("strong"),Zbo=o("xlm"),evo=o(" \u2014 "),Wq=a("a"),ovo=o("XLMModel"),rvo=o(" (XLM model)"),tvo=l(),q_=a("li"),Ele=a("strong"),avo=o("xlm-prophetnet"),nvo=o(" \u2014 "),Qq=a("a"),svo=o("XLMProphetNetModel"),lvo=o(" (XLMProphetNet model)"),ivo=l(),N_=a("li"),Cle=a("strong"),dvo=o("xlm-roberta"),cvo=o(" \u2014 "),Hq=a("a"),fvo=o("XLMRobertaModel"),mvo=o(" (XLM-RoBERTa model)"),gvo=l(),j_=a("li"),wle=a("strong"),hvo=o("xlm-roberta-xl"),pvo=o(" \u2014 "),Uq=a("a"),_vo=o("XLMRobertaXLModel"),uvo=o(" (XLM-RoBERTa-XL model)"),bvo=l(),D_=a("li"),Ale=a("strong"),vvo=o("xlnet"),Fvo=o(" \u2014 "),Jq=a("a"),Tvo=o("XLNetModel"),Mvo=o(" (XLNet model)"),Evo=l(),G_=a("li"),yle=a("strong"),Cvo=o("yolos"),wvo=o(" \u2014 "),Yq=a("a"),Avo=o("YolosModel"),yvo=o(" (YOLOS model)"),Lvo=l(),O_=a("li"),Lle=a("strong"),xvo=o("yoso"),$vo=o(" \u2014 "),Kq=a("a"),kvo=o("YosoModel"),Svo=o(" (YOSO model)"),Rvo=l(),V_=a("p"),Pvo=o("The model is set in evaluation mode by default using "),xle=a("code"),Bvo=o("model.eval()"),Ivo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$le=a("code"),qvo=o("model.train()"),Nvo=l(),F(X_.$$.fragment),cqe=l(),yi=a("h2"),z_=a("a"),kle=a("span"),F(X6.$$.fragment),jvo=l(),Sle=a("span"),Dvo=o("AutoModelForPreTraining"),fqe=l(),xo=a("div"),F(z6.$$.fragment),Gvo=l(),Li=a("p"),Ovo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Zq=a("a"),Vvo=o("from_pretrained()"),Xvo=o(" class method or the "),eN=a("a"),zvo=o("from_config()"),Wvo=o(` class
method.`),Qvo=l(),W6=a("p"),Hvo=o("This class cannot be instantiated directly using "),Rle=a("code"),Uvo=o("__init__()"),Jvo=o(" (throws an error)."),Yvo=l(),at=a("div"),F(Q6.$$.fragment),Kvo=l(),Ple=a("p"),Zvo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),eFo=l(),xi=a("p"),oFo=o(`Note:
Loading a model from its configuration file does `),Ble=a("strong"),rFo=o("not"),tFo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oN=a("a"),aFo=o("from_pretrained()"),nFo=o(" to load the model weights."),sFo=l(),F(W_.$$.fragment),lFo=l(),Ye=a("div"),F(H6.$$.fragment),iFo=l(),Ile=a("p"),dFo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),cFo=l(),xa=a("p"),fFo=o("The model class to instantiate is selected based on the "),qle=a("code"),mFo=o("model_type"),gFo=o(` property of the config object (either
passed as an argument or loaded from `),Nle=a("code"),hFo=o("pretrained_model_name_or_path"),pFo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jle=a("code"),_Fo=o("pretrained_model_name_or_path"),uFo=o(":"),bFo=l(),G=a("ul"),Q_=a("li"),Dle=a("strong"),vFo=o("albert"),FFo=o(" \u2014 "),rN=a("a"),TFo=o("AlbertForPreTraining"),MFo=o(" (ALBERT model)"),EFo=l(),H_=a("li"),Gle=a("strong"),CFo=o("bart"),wFo=o(" \u2014 "),tN=a("a"),AFo=o("BartForConditionalGeneration"),yFo=o(" (BART model)"),LFo=l(),U_=a("li"),Ole=a("strong"),xFo=o("bert"),$Fo=o(" \u2014 "),aN=a("a"),kFo=o("BertForPreTraining"),SFo=o(" (BERT model)"),RFo=l(),J_=a("li"),Vle=a("strong"),PFo=o("big_bird"),BFo=o(" \u2014 "),nN=a("a"),IFo=o("BigBirdForPreTraining"),qFo=o(" (BigBird model)"),NFo=l(),Y_=a("li"),Xle=a("strong"),jFo=o("camembert"),DFo=o(" \u2014 "),sN=a("a"),GFo=o("CamembertForMaskedLM"),OFo=o(" (CamemBERT model)"),VFo=l(),K_=a("li"),zle=a("strong"),XFo=o("ctrl"),zFo=o(" \u2014 "),lN=a("a"),WFo=o("CTRLLMHeadModel"),QFo=o(" (CTRL model)"),HFo=l(),Z_=a("li"),Wle=a("strong"),UFo=o("data2vec-text"),JFo=o(" \u2014 "),iN=a("a"),YFo=o("Data2VecTextForMaskedLM"),KFo=o(" (Data2VecText model)"),ZFo=l(),eu=a("li"),Qle=a("strong"),eTo=o("deberta"),oTo=o(" \u2014 "),dN=a("a"),rTo=o("DebertaForMaskedLM"),tTo=o(" (DeBERTa model)"),aTo=l(),ou=a("li"),Hle=a("strong"),nTo=o("deberta-v2"),sTo=o(" \u2014 "),cN=a("a"),lTo=o("DebertaV2ForMaskedLM"),iTo=o(" (DeBERTa-v2 model)"),dTo=l(),ru=a("li"),Ule=a("strong"),cTo=o("distilbert"),fTo=o(" \u2014 "),fN=a("a"),mTo=o("DistilBertForMaskedLM"),gTo=o(" (DistilBERT model)"),hTo=l(),tu=a("li"),Jle=a("strong"),pTo=o("electra"),_To=o(" \u2014 "),mN=a("a"),uTo=o("ElectraForPreTraining"),bTo=o(" (ELECTRA model)"),vTo=l(),au=a("li"),Yle=a("strong"),FTo=o("flaubert"),TTo=o(" \u2014 "),gN=a("a"),MTo=o("FlaubertWithLMHeadModel"),ETo=o(" (FlauBERT model)"),CTo=l(),nu=a("li"),Kle=a("strong"),wTo=o("flava"),ATo=o(" \u2014 "),hN=a("a"),yTo=o("FlavaForPreTraining"),LTo=o(" (Flava model)"),xTo=l(),su=a("li"),Zle=a("strong"),$To=o("fnet"),kTo=o(" \u2014 "),pN=a("a"),STo=o("FNetForPreTraining"),RTo=o(" (FNet model)"),PTo=l(),lu=a("li"),eie=a("strong"),BTo=o("fsmt"),ITo=o(" \u2014 "),_N=a("a"),qTo=o("FSMTForConditionalGeneration"),NTo=o(" (FairSeq Machine-Translation model)"),jTo=l(),iu=a("li"),oie=a("strong"),DTo=o("funnel"),GTo=o(" \u2014 "),uN=a("a"),OTo=o("FunnelForPreTraining"),VTo=o(" (Funnel Transformer model)"),XTo=l(),du=a("li"),rie=a("strong"),zTo=o("gpt2"),WTo=o(" \u2014 "),bN=a("a"),QTo=o("GPT2LMHeadModel"),HTo=o(" (OpenAI GPT-2 model)"),UTo=l(),cu=a("li"),tie=a("strong"),JTo=o("ibert"),YTo=o(" \u2014 "),vN=a("a"),KTo=o("IBertForMaskedLM"),ZTo=o(" (I-BERT model)"),eMo=l(),fu=a("li"),aie=a("strong"),oMo=o("layoutlm"),rMo=o(" \u2014 "),FN=a("a"),tMo=o("LayoutLMForMaskedLM"),aMo=o(" (LayoutLM model)"),nMo=l(),mu=a("li"),nie=a("strong"),sMo=o("longformer"),lMo=o(" \u2014 "),TN=a("a"),iMo=o("LongformerForMaskedLM"),dMo=o(" (Longformer model)"),cMo=l(),gu=a("li"),sie=a("strong"),fMo=o("lxmert"),mMo=o(" \u2014 "),MN=a("a"),gMo=o("LxmertForPreTraining"),hMo=o(" (LXMERT model)"),pMo=l(),hu=a("li"),lie=a("strong"),_Mo=o("megatron-bert"),uMo=o(" \u2014 "),EN=a("a"),bMo=o("MegatronBertForPreTraining"),vMo=o(" (MegatronBert model)"),FMo=l(),pu=a("li"),iie=a("strong"),TMo=o("mobilebert"),MMo=o(" \u2014 "),CN=a("a"),EMo=o("MobileBertForPreTraining"),CMo=o(" (MobileBERT model)"),wMo=l(),_u=a("li"),die=a("strong"),AMo=o("mpnet"),yMo=o(" \u2014 "),wN=a("a"),LMo=o("MPNetForMaskedLM"),xMo=o(" (MPNet model)"),$Mo=l(),uu=a("li"),cie=a("strong"),kMo=o("openai-gpt"),SMo=o(" \u2014 "),AN=a("a"),RMo=o("OpenAIGPTLMHeadModel"),PMo=o(" (OpenAI GPT model)"),BMo=l(),bu=a("li"),fie=a("strong"),IMo=o("retribert"),qMo=o(" \u2014 "),yN=a("a"),NMo=o("RetriBertModel"),jMo=o(" (RetriBERT model)"),DMo=l(),vu=a("li"),mie=a("strong"),GMo=o("roberta"),OMo=o(" \u2014 "),LN=a("a"),VMo=o("RobertaForMaskedLM"),XMo=o(" (RoBERTa model)"),zMo=l(),Fu=a("li"),gie=a("strong"),WMo=o("splinter"),QMo=o(" \u2014 "),xN=a("a"),HMo=o("SplinterForPreTraining"),UMo=o(" (Splinter model)"),JMo=l(),Tu=a("li"),hie=a("strong"),YMo=o("squeezebert"),KMo=o(" \u2014 "),$N=a("a"),ZMo=o("SqueezeBertForMaskedLM"),e4o=o(" (SqueezeBERT model)"),o4o=l(),Mu=a("li"),pie=a("strong"),r4o=o("t5"),t4o=o(" \u2014 "),kN=a("a"),a4o=o("T5ForConditionalGeneration"),n4o=o(" (T5 model)"),s4o=l(),Eu=a("li"),_ie=a("strong"),l4o=o("tapas"),i4o=o(" \u2014 "),SN=a("a"),d4o=o("TapasForMaskedLM"),c4o=o(" (TAPAS model)"),f4o=l(),Cu=a("li"),uie=a("strong"),m4o=o("transfo-xl"),g4o=o(" \u2014 "),RN=a("a"),h4o=o("TransfoXLLMHeadModel"),p4o=o(" (Transformer-XL model)"),_4o=l(),wu=a("li"),bie=a("strong"),u4o=o("unispeech"),b4o=o(" \u2014 "),PN=a("a"),v4o=o("UniSpeechForPreTraining"),F4o=o(" (UniSpeech model)"),T4o=l(),Au=a("li"),vie=a("strong"),M4o=o("unispeech-sat"),E4o=o(" \u2014 "),BN=a("a"),C4o=o("UniSpeechSatForPreTraining"),w4o=o(" (UniSpeechSat model)"),A4o=l(),yu=a("li"),Fie=a("strong"),y4o=o("visual_bert"),L4o=o(" \u2014 "),IN=a("a"),x4o=o("VisualBertForPreTraining"),$4o=o(" (VisualBert model)"),k4o=l(),Lu=a("li"),Tie=a("strong"),S4o=o("vit_mae"),R4o=o(" \u2014 "),qN=a("a"),P4o=o("ViTMAEForPreTraining"),B4o=o(" (ViTMAE model)"),I4o=l(),xu=a("li"),Mie=a("strong"),q4o=o("wav2vec2"),N4o=o(" \u2014 "),NN=a("a"),j4o=o("Wav2Vec2ForPreTraining"),D4o=o(" (Wav2Vec2 model)"),G4o=l(),$u=a("li"),Eie=a("strong"),O4o=o("wav2vec2-conformer"),V4o=o(" \u2014 "),jN=a("a"),X4o=o("Wav2Vec2ConformerForPreTraining"),z4o=o(" (Wav2Vec2-Conformer model)"),W4o=l(),ku=a("li"),Cie=a("strong"),Q4o=o("xlm"),H4o=o(" \u2014 "),DN=a("a"),U4o=o("XLMWithLMHeadModel"),J4o=o(" (XLM model)"),Y4o=l(),Su=a("li"),wie=a("strong"),K4o=o("xlm-roberta"),Z4o=o(" \u2014 "),GN=a("a"),eEo=o("XLMRobertaForMaskedLM"),oEo=o(" (XLM-RoBERTa model)"),rEo=l(),Ru=a("li"),Aie=a("strong"),tEo=o("xlm-roberta-xl"),aEo=o(" \u2014 "),ON=a("a"),nEo=o("XLMRobertaXLForMaskedLM"),sEo=o(" (XLM-RoBERTa-XL model)"),lEo=l(),Pu=a("li"),yie=a("strong"),iEo=o("xlnet"),dEo=o(" \u2014 "),VN=a("a"),cEo=o("XLNetLMHeadModel"),fEo=o(" (XLNet model)"),mEo=l(),Bu=a("p"),gEo=o("The model is set in evaluation mode by default using "),Lie=a("code"),hEo=o("model.eval()"),pEo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xie=a("code"),_Eo=o("model.train()"),uEo=l(),F(Iu.$$.fragment),mqe=l(),$i=a("h2"),qu=a("a"),$ie=a("span"),F(U6.$$.fragment),bEo=l(),kie=a("span"),vEo=o("AutoModelForCausalLM"),gqe=l(),$o=a("div"),F(J6.$$.fragment),FEo=l(),ki=a("p"),TEo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),XN=a("a"),MEo=o("from_pretrained()"),EEo=o(" class method or the "),zN=a("a"),CEo=o("from_config()"),wEo=o(` class
method.`),AEo=l(),Y6=a("p"),yEo=o("This class cannot be instantiated directly using "),Sie=a("code"),LEo=o("__init__()"),xEo=o(" (throws an error)."),$Eo=l(),nt=a("div"),F(K6.$$.fragment),kEo=l(),Rie=a("p"),SEo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),REo=l(),Si=a("p"),PEo=o(`Note:
Loading a model from its configuration file does `),Pie=a("strong"),BEo=o("not"),IEo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WN=a("a"),qEo=o("from_pretrained()"),NEo=o(" to load the model weights."),jEo=l(),F(Nu.$$.fragment),DEo=l(),Ke=a("div"),F(Z6.$$.fragment),GEo=l(),Bie=a("p"),OEo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),VEo=l(),$a=a("p"),XEo=o("The model class to instantiate is selected based on the "),Iie=a("code"),zEo=o("model_type"),WEo=o(` property of the config object (either
passed as an argument or loaded from `),qie=a("code"),QEo=o("pretrained_model_name_or_path"),HEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nie=a("code"),UEo=o("pretrained_model_name_or_path"),JEo=o(":"),YEo=l(),z=a("ul"),ju=a("li"),jie=a("strong"),KEo=o("bart"),ZEo=o(" \u2014 "),QN=a("a"),eCo=o("BartForCausalLM"),oCo=o(" (BART model)"),rCo=l(),Du=a("li"),Die=a("strong"),tCo=o("bert"),aCo=o(" \u2014 "),HN=a("a"),nCo=o("BertLMHeadModel"),sCo=o(" (BERT model)"),lCo=l(),Gu=a("li"),Gie=a("strong"),iCo=o("bert-generation"),dCo=o(" \u2014 "),UN=a("a"),cCo=o("BertGenerationDecoder"),fCo=o(" (Bert Generation model)"),mCo=l(),Ou=a("li"),Oie=a("strong"),gCo=o("big_bird"),hCo=o(" \u2014 "),JN=a("a"),pCo=o("BigBirdForCausalLM"),_Co=o(" (BigBird model)"),uCo=l(),Vu=a("li"),Vie=a("strong"),bCo=o("bigbird_pegasus"),vCo=o(" \u2014 "),YN=a("a"),FCo=o("BigBirdPegasusForCausalLM"),TCo=o(" (BigBirdPegasus model)"),MCo=l(),Xu=a("li"),Xie=a("strong"),ECo=o("blenderbot"),CCo=o(" \u2014 "),KN=a("a"),wCo=o("BlenderbotForCausalLM"),ACo=o(" (Blenderbot model)"),yCo=l(),zu=a("li"),zie=a("strong"),LCo=o("blenderbot-small"),xCo=o(" \u2014 "),ZN=a("a"),$Co=o("BlenderbotSmallForCausalLM"),kCo=o(" (BlenderbotSmall model)"),SCo=l(),Wu=a("li"),Wie=a("strong"),RCo=o("camembert"),PCo=o(" \u2014 "),ej=a("a"),BCo=o("CamembertForCausalLM"),ICo=o(" (CamemBERT model)"),qCo=l(),Qu=a("li"),Qie=a("strong"),NCo=o("ctrl"),jCo=o(" \u2014 "),oj=a("a"),DCo=o("CTRLLMHeadModel"),GCo=o(" (CTRL model)"),OCo=l(),Hu=a("li"),Hie=a("strong"),VCo=o("data2vec-text"),XCo=o(" \u2014 "),rj=a("a"),zCo=o("Data2VecTextForCausalLM"),WCo=o(" (Data2VecText model)"),QCo=l(),Uu=a("li"),Uie=a("strong"),HCo=o("electra"),UCo=o(" \u2014 "),tj=a("a"),JCo=o("ElectraForCausalLM"),YCo=o(" (ELECTRA model)"),KCo=l(),Ju=a("li"),Jie=a("strong"),ZCo=o("gpt2"),e5o=o(" \u2014 "),aj=a("a"),o5o=o("GPT2LMHeadModel"),r5o=o(" (OpenAI GPT-2 model)"),t5o=l(),Yu=a("li"),Yie=a("strong"),a5o=o("gpt_neo"),n5o=o(" \u2014 "),nj=a("a"),s5o=o("GPTNeoForCausalLM"),l5o=o(" (GPT Neo model)"),i5o=l(),Ku=a("li"),Kie=a("strong"),d5o=o("gptj"),c5o=o(" \u2014 "),sj=a("a"),f5o=o("GPTJForCausalLM"),m5o=o(" (GPT-J model)"),g5o=l(),Zu=a("li"),Zie=a("strong"),h5o=o("marian"),p5o=o(" \u2014 "),lj=a("a"),_5o=o("MarianForCausalLM"),u5o=o(" (Marian model)"),b5o=l(),e2=a("li"),ede=a("strong"),v5o=o("mbart"),F5o=o(" \u2014 "),ij=a("a"),T5o=o("MBartForCausalLM"),M5o=o(" (mBART model)"),E5o=l(),o2=a("li"),ode=a("strong"),C5o=o("megatron-bert"),w5o=o(" \u2014 "),dj=a("a"),A5o=o("MegatronBertForCausalLM"),y5o=o(" (MegatronBert model)"),L5o=l(),r2=a("li"),rde=a("strong"),x5o=o("openai-gpt"),$5o=o(" \u2014 "),cj=a("a"),k5o=o("OpenAIGPTLMHeadModel"),S5o=o(" (OpenAI GPT model)"),R5o=l(),t2=a("li"),tde=a("strong"),P5o=o("opt"),B5o=o(" \u2014 "),fj=a("a"),I5o=o("OPTForCausalLM"),q5o=o(" (OPT model)"),N5o=l(),a2=a("li"),ade=a("strong"),j5o=o("pegasus"),D5o=o(" \u2014 "),mj=a("a"),G5o=o("PegasusForCausalLM"),O5o=o(" (Pegasus model)"),V5o=l(),n2=a("li"),nde=a("strong"),X5o=o("plbart"),z5o=o(" \u2014 "),gj=a("a"),W5o=o("PLBartForCausalLM"),Q5o=o(" (PLBart model)"),H5o=l(),s2=a("li"),sde=a("strong"),U5o=o("prophetnet"),J5o=o(" \u2014 "),hj=a("a"),Y5o=o("ProphetNetForCausalLM"),K5o=o(" (ProphetNet model)"),Z5o=l(),l2=a("li"),lde=a("strong"),e3o=o("qdqbert"),o3o=o(" \u2014 "),pj=a("a"),r3o=o("QDQBertLMHeadModel"),t3o=o(" (QDQBert model)"),a3o=l(),i2=a("li"),ide=a("strong"),n3o=o("reformer"),s3o=o(" \u2014 "),_j=a("a"),l3o=o("ReformerModelWithLMHead"),i3o=o(" (Reformer model)"),d3o=l(),d2=a("li"),dde=a("strong"),c3o=o("rembert"),f3o=o(" \u2014 "),uj=a("a"),m3o=o("RemBertForCausalLM"),g3o=o(" (RemBERT model)"),h3o=l(),c2=a("li"),cde=a("strong"),p3o=o("roberta"),_3o=o(" \u2014 "),bj=a("a"),u3o=o("RobertaForCausalLM"),b3o=o(" (RoBERTa model)"),v3o=l(),f2=a("li"),fde=a("strong"),F3o=o("roformer"),T3o=o(" \u2014 "),vj=a("a"),M3o=o("RoFormerForCausalLM"),E3o=o(" (RoFormer model)"),C3o=l(),m2=a("li"),mde=a("strong"),w3o=o("speech_to_text_2"),A3o=o(" \u2014 "),Fj=a("a"),y3o=o("Speech2Text2ForCausalLM"),L3o=o(" (Speech2Text2 model)"),x3o=l(),g2=a("li"),gde=a("strong"),$3o=o("transfo-xl"),k3o=o(" \u2014 "),Tj=a("a"),S3o=o("TransfoXLLMHeadModel"),R3o=o(" (Transformer-XL model)"),P3o=l(),h2=a("li"),hde=a("strong"),B3o=o("trocr"),I3o=o(" \u2014 "),Mj=a("a"),q3o=o("TrOCRForCausalLM"),N3o=o(" (TrOCR model)"),j3o=l(),p2=a("li"),pde=a("strong"),D3o=o("xglm"),G3o=o(" \u2014 "),Ej=a("a"),O3o=o("XGLMForCausalLM"),V3o=o(" (XGLM model)"),X3o=l(),_2=a("li"),_de=a("strong"),z3o=o("xlm"),W3o=o(" \u2014 "),Cj=a("a"),Q3o=o("XLMWithLMHeadModel"),H3o=o(" (XLM model)"),U3o=l(),u2=a("li"),ude=a("strong"),J3o=o("xlm-prophetnet"),Y3o=o(" \u2014 "),wj=a("a"),K3o=o("XLMProphetNetForCausalLM"),Z3o=o(" (XLMProphetNet model)"),ewo=l(),b2=a("li"),bde=a("strong"),owo=o("xlm-roberta"),rwo=o(" \u2014 "),Aj=a("a"),two=o("XLMRobertaForCausalLM"),awo=o(" (XLM-RoBERTa model)"),nwo=l(),v2=a("li"),vde=a("strong"),swo=o("xlm-roberta-xl"),lwo=o(" \u2014 "),yj=a("a"),iwo=o("XLMRobertaXLForCausalLM"),dwo=o(" (XLM-RoBERTa-XL model)"),cwo=l(),F2=a("li"),Fde=a("strong"),fwo=o("xlnet"),mwo=o(" \u2014 "),Lj=a("a"),gwo=o("XLNetLMHeadModel"),hwo=o(" (XLNet model)"),pwo=l(),T2=a("p"),_wo=o("The model is set in evaluation mode by default using "),Tde=a("code"),uwo=o("model.eval()"),bwo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mde=a("code"),vwo=o("model.train()"),Fwo=l(),F(M2.$$.fragment),hqe=l(),Ri=a("h2"),E2=a("a"),Ede=a("span"),F(ey.$$.fragment),Two=l(),Cde=a("span"),Mwo=o("AutoModelForMaskedLM"),pqe=l(),ko=a("div"),F(oy.$$.fragment),Ewo=l(),Pi=a("p"),Cwo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),xj=a("a"),wwo=o("from_pretrained()"),Awo=o(" class method or the "),$j=a("a"),ywo=o("from_config()"),Lwo=o(` class
method.`),xwo=l(),ry=a("p"),$wo=o("This class cannot be instantiated directly using "),wde=a("code"),kwo=o("__init__()"),Swo=o(" (throws an error)."),Rwo=l(),st=a("div"),F(ty.$$.fragment),Pwo=l(),Ade=a("p"),Bwo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Iwo=l(),Bi=a("p"),qwo=o(`Note:
Loading a model from its configuration file does `),yde=a("strong"),Nwo=o("not"),jwo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kj=a("a"),Dwo=o("from_pretrained()"),Gwo=o(" to load the model weights."),Owo=l(),F(C2.$$.fragment),Vwo=l(),Ze=a("div"),F(ay.$$.fragment),Xwo=l(),Lde=a("p"),zwo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Wwo=l(),ka=a("p"),Qwo=o("The model class to instantiate is selected based on the "),xde=a("code"),Hwo=o("model_type"),Uwo=o(` property of the config object (either
passed as an argument or loaded from `),$de=a("code"),Jwo=o("pretrained_model_name_or_path"),Ywo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kde=a("code"),Kwo=o("pretrained_model_name_or_path"),Zwo=o(":"),e0o=l(),W=a("ul"),w2=a("li"),Sde=a("strong"),o0o=o("albert"),r0o=o(" \u2014 "),Sj=a("a"),t0o=o("AlbertForMaskedLM"),a0o=o(" (ALBERT model)"),n0o=l(),A2=a("li"),Rde=a("strong"),s0o=o("bart"),l0o=o(" \u2014 "),Rj=a("a"),i0o=o("BartForConditionalGeneration"),d0o=o(" (BART model)"),c0o=l(),y2=a("li"),Pde=a("strong"),f0o=o("bert"),m0o=o(" \u2014 "),Pj=a("a"),g0o=o("BertForMaskedLM"),h0o=o(" (BERT model)"),p0o=l(),L2=a("li"),Bde=a("strong"),_0o=o("big_bird"),u0o=o(" \u2014 "),Bj=a("a"),b0o=o("BigBirdForMaskedLM"),v0o=o(" (BigBird model)"),F0o=l(),x2=a("li"),Ide=a("strong"),T0o=o("camembert"),M0o=o(" \u2014 "),Ij=a("a"),E0o=o("CamembertForMaskedLM"),C0o=o(" (CamemBERT model)"),w0o=l(),$2=a("li"),qde=a("strong"),A0o=o("convbert"),y0o=o(" \u2014 "),qj=a("a"),L0o=o("ConvBertForMaskedLM"),x0o=o(" (ConvBERT model)"),$0o=l(),k2=a("li"),Nde=a("strong"),k0o=o("data2vec-text"),S0o=o(" \u2014 "),Nj=a("a"),R0o=o("Data2VecTextForMaskedLM"),P0o=o(" (Data2VecText model)"),B0o=l(),S2=a("li"),jde=a("strong"),I0o=o("deberta"),q0o=o(" \u2014 "),jj=a("a"),N0o=o("DebertaForMaskedLM"),j0o=o(" (DeBERTa model)"),D0o=l(),R2=a("li"),Dde=a("strong"),G0o=o("deberta-v2"),O0o=o(" \u2014 "),Dj=a("a"),V0o=o("DebertaV2ForMaskedLM"),X0o=o(" (DeBERTa-v2 model)"),z0o=l(),P2=a("li"),Gde=a("strong"),W0o=o("distilbert"),Q0o=o(" \u2014 "),Gj=a("a"),H0o=o("DistilBertForMaskedLM"),U0o=o(" (DistilBERT model)"),J0o=l(),B2=a("li"),Ode=a("strong"),Y0o=o("electra"),K0o=o(" \u2014 "),Oj=a("a"),Z0o=o("ElectraForMaskedLM"),eAo=o(" (ELECTRA model)"),oAo=l(),I2=a("li"),Vde=a("strong"),rAo=o("flaubert"),tAo=o(" \u2014 "),Vj=a("a"),aAo=o("FlaubertWithLMHeadModel"),nAo=o(" (FlauBERT model)"),sAo=l(),q2=a("li"),Xde=a("strong"),lAo=o("fnet"),iAo=o(" \u2014 "),Xj=a("a"),dAo=o("FNetForMaskedLM"),cAo=o(" (FNet model)"),fAo=l(),N2=a("li"),zde=a("strong"),mAo=o("funnel"),gAo=o(" \u2014 "),zj=a("a"),hAo=o("FunnelForMaskedLM"),pAo=o(" (Funnel Transformer model)"),_Ao=l(),j2=a("li"),Wde=a("strong"),uAo=o("ibert"),bAo=o(" \u2014 "),Wj=a("a"),vAo=o("IBertForMaskedLM"),FAo=o(" (I-BERT model)"),TAo=l(),D2=a("li"),Qde=a("strong"),MAo=o("layoutlm"),EAo=o(" \u2014 "),Qj=a("a"),CAo=o("LayoutLMForMaskedLM"),wAo=o(" (LayoutLM model)"),AAo=l(),G2=a("li"),Hde=a("strong"),yAo=o("longformer"),LAo=o(" \u2014 "),Hj=a("a"),xAo=o("LongformerForMaskedLM"),$Ao=o(" (Longformer model)"),kAo=l(),O2=a("li"),Ude=a("strong"),SAo=o("mbart"),RAo=o(" \u2014 "),Uj=a("a"),PAo=o("MBartForConditionalGeneration"),BAo=o(" (mBART model)"),IAo=l(),V2=a("li"),Jde=a("strong"),qAo=o("megatron-bert"),NAo=o(" \u2014 "),Jj=a("a"),jAo=o("MegatronBertForMaskedLM"),DAo=o(" (MegatronBert model)"),GAo=l(),X2=a("li"),Yde=a("strong"),OAo=o("mobilebert"),VAo=o(" \u2014 "),Yj=a("a"),XAo=o("MobileBertForMaskedLM"),zAo=o(" (MobileBERT model)"),WAo=l(),z2=a("li"),Kde=a("strong"),QAo=o("mpnet"),HAo=o(" \u2014 "),Kj=a("a"),UAo=o("MPNetForMaskedLM"),JAo=o(" (MPNet model)"),YAo=l(),W2=a("li"),Zde=a("strong"),KAo=o("nystromformer"),ZAo=o(" \u2014 "),Zj=a("a"),e6o=o("NystromformerForMaskedLM"),o6o=o(" (Nystromformer model)"),r6o=l(),Q2=a("li"),ece=a("strong"),t6o=o("perceiver"),a6o=o(" \u2014 "),eD=a("a"),n6o=o("PerceiverForMaskedLM"),s6o=o(" (Perceiver model)"),l6o=l(),H2=a("li"),oce=a("strong"),i6o=o("qdqbert"),d6o=o(" \u2014 "),oD=a("a"),c6o=o("QDQBertForMaskedLM"),f6o=o(" (QDQBert model)"),m6o=l(),U2=a("li"),rce=a("strong"),g6o=o("reformer"),h6o=o(" \u2014 "),rD=a("a"),p6o=o("ReformerForMaskedLM"),_6o=o(" (Reformer model)"),u6o=l(),J2=a("li"),tce=a("strong"),b6o=o("rembert"),v6o=o(" \u2014 "),tD=a("a"),F6o=o("RemBertForMaskedLM"),T6o=o(" (RemBERT model)"),M6o=l(),Y2=a("li"),ace=a("strong"),E6o=o("roberta"),C6o=o(" \u2014 "),aD=a("a"),w6o=o("RobertaForMaskedLM"),A6o=o(" (RoBERTa model)"),y6o=l(),K2=a("li"),nce=a("strong"),L6o=o("roformer"),x6o=o(" \u2014 "),nD=a("a"),$6o=o("RoFormerForMaskedLM"),k6o=o(" (RoFormer model)"),S6o=l(),Z2=a("li"),sce=a("strong"),R6o=o("squeezebert"),P6o=o(" \u2014 "),sD=a("a"),B6o=o("SqueezeBertForMaskedLM"),I6o=o(" (SqueezeBERT model)"),q6o=l(),e1=a("li"),lce=a("strong"),N6o=o("tapas"),j6o=o(" \u2014 "),lD=a("a"),D6o=o("TapasForMaskedLM"),G6o=o(" (TAPAS model)"),O6o=l(),o1=a("li"),ice=a("strong"),V6o=o("wav2vec2"),X6o=o(" \u2014 "),dce=a("code"),z6o=o("Wav2Vec2ForMaskedLM"),W6o=o(" (Wav2Vec2 model)"),Q6o=l(),r1=a("li"),cce=a("strong"),H6o=o("xlm"),U6o=o(" \u2014 "),iD=a("a"),J6o=o("XLMWithLMHeadModel"),Y6o=o(" (XLM model)"),K6o=l(),t1=a("li"),fce=a("strong"),Z6o=o("xlm-roberta"),eyo=o(" \u2014 "),dD=a("a"),oyo=o("XLMRobertaForMaskedLM"),ryo=o(" (XLM-RoBERTa model)"),tyo=l(),a1=a("li"),mce=a("strong"),ayo=o("xlm-roberta-xl"),nyo=o(" \u2014 "),cD=a("a"),syo=o("XLMRobertaXLForMaskedLM"),lyo=o(" (XLM-RoBERTa-XL model)"),iyo=l(),n1=a("li"),gce=a("strong"),dyo=o("yoso"),cyo=o(" \u2014 "),fD=a("a"),fyo=o("YosoForMaskedLM"),myo=o(" (YOSO model)"),gyo=l(),s1=a("p"),hyo=o("The model is set in evaluation mode by default using "),hce=a("code"),pyo=o("model.eval()"),_yo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pce=a("code"),uyo=o("model.train()"),byo=l(),F(l1.$$.fragment),_qe=l(),Ii=a("h2"),i1=a("a"),_ce=a("span"),F(ny.$$.fragment),vyo=l(),uce=a("span"),Fyo=o("AutoModelForSeq2SeqLM"),uqe=l(),So=a("div"),F(sy.$$.fragment),Tyo=l(),qi=a("p"),Myo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),mD=a("a"),Eyo=o("from_pretrained()"),Cyo=o(" class method or the "),gD=a("a"),wyo=o("from_config()"),Ayo=o(` class
method.`),yyo=l(),ly=a("p"),Lyo=o("This class cannot be instantiated directly using "),bce=a("code"),xyo=o("__init__()"),$yo=o(" (throws an error)."),kyo=l(),lt=a("div"),F(iy.$$.fragment),Syo=l(),vce=a("p"),Ryo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Pyo=l(),Ni=a("p"),Byo=o(`Note:
Loading a model from its configuration file does `),Fce=a("strong"),Iyo=o("not"),qyo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hD=a("a"),Nyo=o("from_pretrained()"),jyo=o(" to load the model weights."),Dyo=l(),F(d1.$$.fragment),Gyo=l(),eo=a("div"),F(dy.$$.fragment),Oyo=l(),Tce=a("p"),Vyo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Xyo=l(),Sa=a("p"),zyo=o("The model class to instantiate is selected based on the "),Mce=a("code"),Wyo=o("model_type"),Qyo=o(` property of the config object (either
passed as an argument or loaded from `),Ece=a("code"),Hyo=o("pretrained_model_name_or_path"),Uyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cce=a("code"),Jyo=o("pretrained_model_name_or_path"),Yyo=o(":"),Kyo=l(),_e=a("ul"),c1=a("li"),wce=a("strong"),Zyo=o("bart"),eLo=o(" \u2014 "),pD=a("a"),oLo=o("BartForConditionalGeneration"),rLo=o(" (BART model)"),tLo=l(),f1=a("li"),Ace=a("strong"),aLo=o("bigbird_pegasus"),nLo=o(" \u2014 "),_D=a("a"),sLo=o("BigBirdPegasusForConditionalGeneration"),lLo=o(" (BigBirdPegasus model)"),iLo=l(),m1=a("li"),yce=a("strong"),dLo=o("blenderbot"),cLo=o(" \u2014 "),uD=a("a"),fLo=o("BlenderbotForConditionalGeneration"),mLo=o(" (Blenderbot model)"),gLo=l(),g1=a("li"),Lce=a("strong"),hLo=o("blenderbot-small"),pLo=o(" \u2014 "),bD=a("a"),_Lo=o("BlenderbotSmallForConditionalGeneration"),uLo=o(" (BlenderbotSmall model)"),bLo=l(),h1=a("li"),xce=a("strong"),vLo=o("encoder-decoder"),FLo=o(" \u2014 "),vD=a("a"),TLo=o("EncoderDecoderModel"),MLo=o(" (Encoder decoder model)"),ELo=l(),p1=a("li"),$ce=a("strong"),CLo=o("fsmt"),wLo=o(" \u2014 "),FD=a("a"),ALo=o("FSMTForConditionalGeneration"),yLo=o(" (FairSeq Machine-Translation model)"),LLo=l(),_1=a("li"),kce=a("strong"),xLo=o("led"),$Lo=o(" \u2014 "),TD=a("a"),kLo=o("LEDForConditionalGeneration"),SLo=o(" (LED model)"),RLo=l(),u1=a("li"),Sce=a("strong"),PLo=o("m2m_100"),BLo=o(" \u2014 "),MD=a("a"),ILo=o("M2M100ForConditionalGeneration"),qLo=o(" (M2M100 model)"),NLo=l(),b1=a("li"),Rce=a("strong"),jLo=o("marian"),DLo=o(" \u2014 "),ED=a("a"),GLo=o("MarianMTModel"),OLo=o(" (Marian model)"),VLo=l(),v1=a("li"),Pce=a("strong"),XLo=o("mbart"),zLo=o(" \u2014 "),CD=a("a"),WLo=o("MBartForConditionalGeneration"),QLo=o(" (mBART model)"),HLo=l(),F1=a("li"),Bce=a("strong"),ULo=o("mt5"),JLo=o(" \u2014 "),wD=a("a"),YLo=o("MT5ForConditionalGeneration"),KLo=o(" (mT5 model)"),ZLo=l(),T1=a("li"),Ice=a("strong"),e8o=o("pegasus"),o8o=o(" \u2014 "),AD=a("a"),r8o=o("PegasusForConditionalGeneration"),t8o=o(" (Pegasus model)"),a8o=l(),M1=a("li"),qce=a("strong"),n8o=o("plbart"),s8o=o(" \u2014 "),yD=a("a"),l8o=o("PLBartForConditionalGeneration"),i8o=o(" (PLBart model)"),d8o=l(),E1=a("li"),Nce=a("strong"),c8o=o("prophetnet"),f8o=o(" \u2014 "),LD=a("a"),m8o=o("ProphetNetForConditionalGeneration"),g8o=o(" (ProphetNet model)"),h8o=l(),C1=a("li"),jce=a("strong"),p8o=o("t5"),_8o=o(" \u2014 "),xD=a("a"),u8o=o("T5ForConditionalGeneration"),b8o=o(" (T5 model)"),v8o=l(),w1=a("li"),Dce=a("strong"),F8o=o("xlm-prophetnet"),T8o=o(" \u2014 "),$D=a("a"),M8o=o("XLMProphetNetForConditionalGeneration"),E8o=o(" (XLMProphetNet model)"),C8o=l(),A1=a("p"),w8o=o("The model is set in evaluation mode by default using "),Gce=a("code"),A8o=o("model.eval()"),y8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oce=a("code"),L8o=o("model.train()"),x8o=l(),F(y1.$$.fragment),bqe=l(),ji=a("h2"),L1=a("a"),Vce=a("span"),F(cy.$$.fragment),$8o=l(),Xce=a("span"),k8o=o("AutoModelForSequenceClassification"),vqe=l(),Ro=a("div"),F(fy.$$.fragment),S8o=l(),Di=a("p"),R8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),kD=a("a"),P8o=o("from_pretrained()"),B8o=o(" class method or the "),SD=a("a"),I8o=o("from_config()"),q8o=o(` class
method.`),N8o=l(),my=a("p"),j8o=o("This class cannot be instantiated directly using "),zce=a("code"),D8o=o("__init__()"),G8o=o(" (throws an error)."),O8o=l(),it=a("div"),F(gy.$$.fragment),V8o=l(),Wce=a("p"),X8o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),z8o=l(),Gi=a("p"),W8o=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),Q8o=o("not"),H8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RD=a("a"),U8o=o("from_pretrained()"),J8o=o(" to load the model weights."),Y8o=l(),F(x1.$$.fragment),K8o=l(),oo=a("div"),F(hy.$$.fragment),Z8o=l(),Hce=a("p"),exo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oxo=l(),Ra=a("p"),rxo=o("The model class to instantiate is selected based on the "),Uce=a("code"),txo=o("model_type"),axo=o(` property of the config object (either
passed as an argument or loaded from `),Jce=a("code"),nxo=o("pretrained_model_name_or_path"),sxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yce=a("code"),lxo=o("pretrained_model_name_or_path"),ixo=o(":"),dxo=l(),N=a("ul"),$1=a("li"),Kce=a("strong"),cxo=o("albert"),fxo=o(" \u2014 "),PD=a("a"),mxo=o("AlbertForSequenceClassification"),gxo=o(" (ALBERT model)"),hxo=l(),k1=a("li"),Zce=a("strong"),pxo=o("bart"),_xo=o(" \u2014 "),BD=a("a"),uxo=o("BartForSequenceClassification"),bxo=o(" (BART model)"),vxo=l(),S1=a("li"),efe=a("strong"),Fxo=o("bert"),Txo=o(" \u2014 "),ID=a("a"),Mxo=o("BertForSequenceClassification"),Exo=o(" (BERT model)"),Cxo=l(),R1=a("li"),ofe=a("strong"),wxo=o("big_bird"),Axo=o(" \u2014 "),qD=a("a"),yxo=o("BigBirdForSequenceClassification"),Lxo=o(" (BigBird model)"),xxo=l(),P1=a("li"),rfe=a("strong"),$xo=o("bigbird_pegasus"),kxo=o(" \u2014 "),ND=a("a"),Sxo=o("BigBirdPegasusForSequenceClassification"),Rxo=o(" (BigBirdPegasus model)"),Pxo=l(),B1=a("li"),tfe=a("strong"),Bxo=o("camembert"),Ixo=o(" \u2014 "),jD=a("a"),qxo=o("CamembertForSequenceClassification"),Nxo=o(" (CamemBERT model)"),jxo=l(),I1=a("li"),afe=a("strong"),Dxo=o("canine"),Gxo=o(" \u2014 "),DD=a("a"),Oxo=o("CanineForSequenceClassification"),Vxo=o(" (Canine model)"),Xxo=l(),q1=a("li"),nfe=a("strong"),zxo=o("convbert"),Wxo=o(" \u2014 "),GD=a("a"),Qxo=o("ConvBertForSequenceClassification"),Hxo=o(" (ConvBERT model)"),Uxo=l(),N1=a("li"),sfe=a("strong"),Jxo=o("ctrl"),Yxo=o(" \u2014 "),OD=a("a"),Kxo=o("CTRLForSequenceClassification"),Zxo=o(" (CTRL model)"),e9o=l(),j1=a("li"),lfe=a("strong"),o9o=o("data2vec-text"),r9o=o(" \u2014 "),VD=a("a"),t9o=o("Data2VecTextForSequenceClassification"),a9o=o(" (Data2VecText model)"),n9o=l(),D1=a("li"),ife=a("strong"),s9o=o("deberta"),l9o=o(" \u2014 "),XD=a("a"),i9o=o("DebertaForSequenceClassification"),d9o=o(" (DeBERTa model)"),c9o=l(),G1=a("li"),dfe=a("strong"),f9o=o("deberta-v2"),m9o=o(" \u2014 "),zD=a("a"),g9o=o("DebertaV2ForSequenceClassification"),h9o=o(" (DeBERTa-v2 model)"),p9o=l(),O1=a("li"),cfe=a("strong"),_9o=o("distilbert"),u9o=o(" \u2014 "),WD=a("a"),b9o=o("DistilBertForSequenceClassification"),v9o=o(" (DistilBERT model)"),F9o=l(),V1=a("li"),ffe=a("strong"),T9o=o("electra"),M9o=o(" \u2014 "),QD=a("a"),E9o=o("ElectraForSequenceClassification"),C9o=o(" (ELECTRA model)"),w9o=l(),X1=a("li"),mfe=a("strong"),A9o=o("flaubert"),y9o=o(" \u2014 "),HD=a("a"),L9o=o("FlaubertForSequenceClassification"),x9o=o(" (FlauBERT model)"),$9o=l(),z1=a("li"),gfe=a("strong"),k9o=o("fnet"),S9o=o(" \u2014 "),UD=a("a"),R9o=o("FNetForSequenceClassification"),P9o=o(" (FNet model)"),B9o=l(),W1=a("li"),hfe=a("strong"),I9o=o("funnel"),q9o=o(" \u2014 "),JD=a("a"),N9o=o("FunnelForSequenceClassification"),j9o=o(" (Funnel Transformer model)"),D9o=l(),Q1=a("li"),pfe=a("strong"),G9o=o("gpt2"),O9o=o(" \u2014 "),YD=a("a"),V9o=o("GPT2ForSequenceClassification"),X9o=o(" (OpenAI GPT-2 model)"),z9o=l(),H1=a("li"),_fe=a("strong"),W9o=o("gpt_neo"),Q9o=o(" \u2014 "),KD=a("a"),H9o=o("GPTNeoForSequenceClassification"),U9o=o(" (GPT Neo model)"),J9o=l(),U1=a("li"),ufe=a("strong"),Y9o=o("gptj"),K9o=o(" \u2014 "),ZD=a("a"),Z9o=o("GPTJForSequenceClassification"),e$o=o(" (GPT-J model)"),o$o=l(),J1=a("li"),bfe=a("strong"),r$o=o("ibert"),t$o=o(" \u2014 "),eG=a("a"),a$o=o("IBertForSequenceClassification"),n$o=o(" (I-BERT model)"),s$o=l(),Y1=a("li"),vfe=a("strong"),l$o=o("layoutlm"),i$o=o(" \u2014 "),oG=a("a"),d$o=o("LayoutLMForSequenceClassification"),c$o=o(" (LayoutLM model)"),f$o=l(),K1=a("li"),Ffe=a("strong"),m$o=o("layoutlmv2"),g$o=o(" \u2014 "),rG=a("a"),h$o=o("LayoutLMv2ForSequenceClassification"),p$o=o(" (LayoutLMv2 model)"),_$o=l(),Z1=a("li"),Tfe=a("strong"),u$o=o("led"),b$o=o(" \u2014 "),tG=a("a"),v$o=o("LEDForSequenceClassification"),F$o=o(" (LED model)"),T$o=l(),e7=a("li"),Mfe=a("strong"),M$o=o("longformer"),E$o=o(" \u2014 "),aG=a("a"),C$o=o("LongformerForSequenceClassification"),w$o=o(" (Longformer model)"),A$o=l(),o7=a("li"),Efe=a("strong"),y$o=o("mbart"),L$o=o(" \u2014 "),nG=a("a"),x$o=o("MBartForSequenceClassification"),$$o=o(" (mBART model)"),k$o=l(),r7=a("li"),Cfe=a("strong"),S$o=o("megatron-bert"),R$o=o(" \u2014 "),sG=a("a"),P$o=o("MegatronBertForSequenceClassification"),B$o=o(" (MegatronBert model)"),I$o=l(),t7=a("li"),wfe=a("strong"),q$o=o("mobilebert"),N$o=o(" \u2014 "),lG=a("a"),j$o=o("MobileBertForSequenceClassification"),D$o=o(" (MobileBERT model)"),G$o=l(),a7=a("li"),Afe=a("strong"),O$o=o("mpnet"),V$o=o(" \u2014 "),iG=a("a"),X$o=o("MPNetForSequenceClassification"),z$o=o(" (MPNet model)"),W$o=l(),n7=a("li"),yfe=a("strong"),Q$o=o("nystromformer"),H$o=o(" \u2014 "),dG=a("a"),U$o=o("NystromformerForSequenceClassification"),J$o=o(" (Nystromformer model)"),Y$o=l(),s7=a("li"),Lfe=a("strong"),K$o=o("openai-gpt"),Z$o=o(" \u2014 "),cG=a("a"),eko=o("OpenAIGPTForSequenceClassification"),oko=o(" (OpenAI GPT model)"),rko=l(),l7=a("li"),xfe=a("strong"),tko=o("perceiver"),ako=o(" \u2014 "),fG=a("a"),nko=o("PerceiverForSequenceClassification"),sko=o(" (Perceiver model)"),lko=l(),i7=a("li"),$fe=a("strong"),iko=o("plbart"),dko=o(" \u2014 "),mG=a("a"),cko=o("PLBartForSequenceClassification"),fko=o(" (PLBart model)"),mko=l(),d7=a("li"),kfe=a("strong"),gko=o("qdqbert"),hko=o(" \u2014 "),gG=a("a"),pko=o("QDQBertForSequenceClassification"),_ko=o(" (QDQBert model)"),uko=l(),c7=a("li"),Sfe=a("strong"),bko=o("reformer"),vko=o(" \u2014 "),hG=a("a"),Fko=o("ReformerForSequenceClassification"),Tko=o(" (Reformer model)"),Mko=l(),f7=a("li"),Rfe=a("strong"),Eko=o("rembert"),Cko=o(" \u2014 "),pG=a("a"),wko=o("RemBertForSequenceClassification"),Ako=o(" (RemBERT model)"),yko=l(),m7=a("li"),Pfe=a("strong"),Lko=o("roberta"),xko=o(" \u2014 "),_G=a("a"),$ko=o("RobertaForSequenceClassification"),kko=o(" (RoBERTa model)"),Sko=l(),g7=a("li"),Bfe=a("strong"),Rko=o("roformer"),Pko=o(" \u2014 "),uG=a("a"),Bko=o("RoFormerForSequenceClassification"),Iko=o(" (RoFormer model)"),qko=l(),h7=a("li"),Ife=a("strong"),Nko=o("squeezebert"),jko=o(" \u2014 "),bG=a("a"),Dko=o("SqueezeBertForSequenceClassification"),Gko=o(" (SqueezeBERT model)"),Oko=l(),p7=a("li"),qfe=a("strong"),Vko=o("tapas"),Xko=o(" \u2014 "),vG=a("a"),zko=o("TapasForSequenceClassification"),Wko=o(" (TAPAS model)"),Qko=l(),_7=a("li"),Nfe=a("strong"),Hko=o("transfo-xl"),Uko=o(" \u2014 "),FG=a("a"),Jko=o("TransfoXLForSequenceClassification"),Yko=o(" (Transformer-XL model)"),Kko=l(),u7=a("li"),jfe=a("strong"),Zko=o("xlm"),eSo=o(" \u2014 "),TG=a("a"),oSo=o("XLMForSequenceClassification"),rSo=o(" (XLM model)"),tSo=l(),b7=a("li"),Dfe=a("strong"),aSo=o("xlm-roberta"),nSo=o(" \u2014 "),MG=a("a"),sSo=o("XLMRobertaForSequenceClassification"),lSo=o(" (XLM-RoBERTa model)"),iSo=l(),v7=a("li"),Gfe=a("strong"),dSo=o("xlm-roberta-xl"),cSo=o(" \u2014 "),EG=a("a"),fSo=o("XLMRobertaXLForSequenceClassification"),mSo=o(" (XLM-RoBERTa-XL model)"),gSo=l(),F7=a("li"),Ofe=a("strong"),hSo=o("xlnet"),pSo=o(" \u2014 "),CG=a("a"),_So=o("XLNetForSequenceClassification"),uSo=o(" (XLNet model)"),bSo=l(),T7=a("li"),Vfe=a("strong"),vSo=o("yoso"),FSo=o(" \u2014 "),wG=a("a"),TSo=o("YosoForSequenceClassification"),MSo=o(" (YOSO model)"),ESo=l(),M7=a("p"),CSo=o("The model is set in evaluation mode by default using "),Xfe=a("code"),wSo=o("model.eval()"),ASo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=a("code"),ySo=o("model.train()"),LSo=l(),F(E7.$$.fragment),Fqe=l(),Oi=a("h2"),C7=a("a"),Wfe=a("span"),F(py.$$.fragment),xSo=l(),Qfe=a("span"),$So=o("AutoModelForMultipleChoice"),Tqe=l(),Po=a("div"),F(_y.$$.fragment),kSo=l(),Vi=a("p"),SSo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),AG=a("a"),RSo=o("from_pretrained()"),PSo=o(" class method or the "),yG=a("a"),BSo=o("from_config()"),ISo=o(` class
method.`),qSo=l(),uy=a("p"),NSo=o("This class cannot be instantiated directly using "),Hfe=a("code"),jSo=o("__init__()"),DSo=o(" (throws an error)."),GSo=l(),dt=a("div"),F(by.$$.fragment),OSo=l(),Ufe=a("p"),VSo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),XSo=l(),Xi=a("p"),zSo=o(`Note:
Loading a model from its configuration file does `),Jfe=a("strong"),WSo=o("not"),QSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LG=a("a"),HSo=o("from_pretrained()"),USo=o(" to load the model weights."),JSo=l(),F(w7.$$.fragment),YSo=l(),ro=a("div"),F(vy.$$.fragment),KSo=l(),Yfe=a("p"),ZSo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),eRo=l(),Pa=a("p"),oRo=o("The model class to instantiate is selected based on the "),Kfe=a("code"),rRo=o("model_type"),tRo=o(` property of the config object (either
passed as an argument or loaded from `),Zfe=a("code"),aRo=o("pretrained_model_name_or_path"),nRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eme=a("code"),sRo=o("pretrained_model_name_or_path"),lRo=o(":"),iRo=l(),Y=a("ul"),A7=a("li"),ome=a("strong"),dRo=o("albert"),cRo=o(" \u2014 "),xG=a("a"),fRo=o("AlbertForMultipleChoice"),mRo=o(" (ALBERT model)"),gRo=l(),y7=a("li"),rme=a("strong"),hRo=o("bert"),pRo=o(" \u2014 "),$G=a("a"),_Ro=o("BertForMultipleChoice"),uRo=o(" (BERT model)"),bRo=l(),L7=a("li"),tme=a("strong"),vRo=o("big_bird"),FRo=o(" \u2014 "),kG=a("a"),TRo=o("BigBirdForMultipleChoice"),MRo=o(" (BigBird model)"),ERo=l(),x7=a("li"),ame=a("strong"),CRo=o("camembert"),wRo=o(" \u2014 "),SG=a("a"),ARo=o("CamembertForMultipleChoice"),yRo=o(" (CamemBERT model)"),LRo=l(),$7=a("li"),nme=a("strong"),xRo=o("canine"),$Ro=o(" \u2014 "),RG=a("a"),kRo=o("CanineForMultipleChoice"),SRo=o(" (Canine model)"),RRo=l(),k7=a("li"),sme=a("strong"),PRo=o("convbert"),BRo=o(" \u2014 "),PG=a("a"),IRo=o("ConvBertForMultipleChoice"),qRo=o(" (ConvBERT model)"),NRo=l(),S7=a("li"),lme=a("strong"),jRo=o("data2vec-text"),DRo=o(" \u2014 "),BG=a("a"),GRo=o("Data2VecTextForMultipleChoice"),ORo=o(" (Data2VecText model)"),VRo=l(),R7=a("li"),ime=a("strong"),XRo=o("deberta-v2"),zRo=o(" \u2014 "),IG=a("a"),WRo=o("DebertaV2ForMultipleChoice"),QRo=o(" (DeBERTa-v2 model)"),HRo=l(),P7=a("li"),dme=a("strong"),URo=o("distilbert"),JRo=o(" \u2014 "),qG=a("a"),YRo=o("DistilBertForMultipleChoice"),KRo=o(" (DistilBERT model)"),ZRo=l(),B7=a("li"),cme=a("strong"),ePo=o("electra"),oPo=o(" \u2014 "),NG=a("a"),rPo=o("ElectraForMultipleChoice"),tPo=o(" (ELECTRA model)"),aPo=l(),I7=a("li"),fme=a("strong"),nPo=o("flaubert"),sPo=o(" \u2014 "),jG=a("a"),lPo=o("FlaubertForMultipleChoice"),iPo=o(" (FlauBERT model)"),dPo=l(),q7=a("li"),mme=a("strong"),cPo=o("fnet"),fPo=o(" \u2014 "),DG=a("a"),mPo=o("FNetForMultipleChoice"),gPo=o(" (FNet model)"),hPo=l(),N7=a("li"),gme=a("strong"),pPo=o("funnel"),_Po=o(" \u2014 "),GG=a("a"),uPo=o("FunnelForMultipleChoice"),bPo=o(" (Funnel Transformer model)"),vPo=l(),j7=a("li"),hme=a("strong"),FPo=o("ibert"),TPo=o(" \u2014 "),OG=a("a"),MPo=o("IBertForMultipleChoice"),EPo=o(" (I-BERT model)"),CPo=l(),D7=a("li"),pme=a("strong"),wPo=o("longformer"),APo=o(" \u2014 "),VG=a("a"),yPo=o("LongformerForMultipleChoice"),LPo=o(" (Longformer model)"),xPo=l(),G7=a("li"),_me=a("strong"),$Po=o("megatron-bert"),kPo=o(" \u2014 "),XG=a("a"),SPo=o("MegatronBertForMultipleChoice"),RPo=o(" (MegatronBert model)"),PPo=l(),O7=a("li"),ume=a("strong"),BPo=o("mobilebert"),IPo=o(" \u2014 "),zG=a("a"),qPo=o("MobileBertForMultipleChoice"),NPo=o(" (MobileBERT model)"),jPo=l(),V7=a("li"),bme=a("strong"),DPo=o("mpnet"),GPo=o(" \u2014 "),WG=a("a"),OPo=o("MPNetForMultipleChoice"),VPo=o(" (MPNet model)"),XPo=l(),X7=a("li"),vme=a("strong"),zPo=o("nystromformer"),WPo=o(" \u2014 "),QG=a("a"),QPo=o("NystromformerForMultipleChoice"),HPo=o(" (Nystromformer model)"),UPo=l(),z7=a("li"),Fme=a("strong"),JPo=o("qdqbert"),YPo=o(" \u2014 "),HG=a("a"),KPo=o("QDQBertForMultipleChoice"),ZPo=o(" (QDQBert model)"),eBo=l(),W7=a("li"),Tme=a("strong"),oBo=o("rembert"),rBo=o(" \u2014 "),UG=a("a"),tBo=o("RemBertForMultipleChoice"),aBo=o(" (RemBERT model)"),nBo=l(),Q7=a("li"),Mme=a("strong"),sBo=o("roberta"),lBo=o(" \u2014 "),JG=a("a"),iBo=o("RobertaForMultipleChoice"),dBo=o(" (RoBERTa model)"),cBo=l(),H7=a("li"),Eme=a("strong"),fBo=o("roformer"),mBo=o(" \u2014 "),YG=a("a"),gBo=o("RoFormerForMultipleChoice"),hBo=o(" (RoFormer model)"),pBo=l(),U7=a("li"),Cme=a("strong"),_Bo=o("squeezebert"),uBo=o(" \u2014 "),KG=a("a"),bBo=o("SqueezeBertForMultipleChoice"),vBo=o(" (SqueezeBERT model)"),FBo=l(),J7=a("li"),wme=a("strong"),TBo=o("xlm"),MBo=o(" \u2014 "),ZG=a("a"),EBo=o("XLMForMultipleChoice"),CBo=o(" (XLM model)"),wBo=l(),Y7=a("li"),Ame=a("strong"),ABo=o("xlm-roberta"),yBo=o(" \u2014 "),eO=a("a"),LBo=o("XLMRobertaForMultipleChoice"),xBo=o(" (XLM-RoBERTa model)"),$Bo=l(),K7=a("li"),yme=a("strong"),kBo=o("xlm-roberta-xl"),SBo=o(" \u2014 "),oO=a("a"),RBo=o("XLMRobertaXLForMultipleChoice"),PBo=o(" (XLM-RoBERTa-XL model)"),BBo=l(),Z7=a("li"),Lme=a("strong"),IBo=o("xlnet"),qBo=o(" \u2014 "),rO=a("a"),NBo=o("XLNetForMultipleChoice"),jBo=o(" (XLNet model)"),DBo=l(),eb=a("li"),xme=a("strong"),GBo=o("yoso"),OBo=o(" \u2014 "),tO=a("a"),VBo=o("YosoForMultipleChoice"),XBo=o(" (YOSO model)"),zBo=l(),ob=a("p"),WBo=o("The model is set in evaluation mode by default using "),$me=a("code"),QBo=o("model.eval()"),HBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kme=a("code"),UBo=o("model.train()"),JBo=l(),F(rb.$$.fragment),Mqe=l(),zi=a("h2"),tb=a("a"),Sme=a("span"),F(Fy.$$.fragment),YBo=l(),Rme=a("span"),KBo=o("AutoModelForNextSentencePrediction"),Eqe=l(),Bo=a("div"),F(Ty.$$.fragment),ZBo=l(),Wi=a("p"),eIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),aO=a("a"),oIo=o("from_pretrained()"),rIo=o(" class method or the "),nO=a("a"),tIo=o("from_config()"),aIo=o(` class
method.`),nIo=l(),My=a("p"),sIo=o("This class cannot be instantiated directly using "),Pme=a("code"),lIo=o("__init__()"),iIo=o(" (throws an error)."),dIo=l(),ct=a("div"),F(Ey.$$.fragment),cIo=l(),Bme=a("p"),fIo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),mIo=l(),Qi=a("p"),gIo=o(`Note:
Loading a model from its configuration file does `),Ime=a("strong"),hIo=o("not"),pIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sO=a("a"),_Io=o("from_pretrained()"),uIo=o(" to load the model weights."),bIo=l(),F(ab.$$.fragment),vIo=l(),to=a("div"),F(Cy.$$.fragment),FIo=l(),qme=a("p"),TIo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),MIo=l(),Ba=a("p"),EIo=o("The model class to instantiate is selected based on the "),Nme=a("code"),CIo=o("model_type"),wIo=o(` property of the config object (either
passed as an argument or loaded from `),jme=a("code"),AIo=o("pretrained_model_name_or_path"),yIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dme=a("code"),LIo=o("pretrained_model_name_or_path"),xIo=o(":"),$Io=l(),Yr=a("ul"),nb=a("li"),Gme=a("strong"),kIo=o("bert"),SIo=o(" \u2014 "),lO=a("a"),RIo=o("BertForNextSentencePrediction"),PIo=o(" (BERT model)"),BIo=l(),sb=a("li"),Ome=a("strong"),IIo=o("fnet"),qIo=o(" \u2014 "),iO=a("a"),NIo=o("FNetForNextSentencePrediction"),jIo=o(" (FNet model)"),DIo=l(),lb=a("li"),Vme=a("strong"),GIo=o("megatron-bert"),OIo=o(" \u2014 "),dO=a("a"),VIo=o("MegatronBertForNextSentencePrediction"),XIo=o(" (MegatronBert model)"),zIo=l(),ib=a("li"),Xme=a("strong"),WIo=o("mobilebert"),QIo=o(" \u2014 "),cO=a("a"),HIo=o("MobileBertForNextSentencePrediction"),UIo=o(" (MobileBERT model)"),JIo=l(),db=a("li"),zme=a("strong"),YIo=o("qdqbert"),KIo=o(" \u2014 "),fO=a("a"),ZIo=o("QDQBertForNextSentencePrediction"),eqo=o(" (QDQBert model)"),oqo=l(),cb=a("p"),rqo=o("The model is set in evaluation mode by default using "),Wme=a("code"),tqo=o("model.eval()"),aqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qme=a("code"),nqo=o("model.train()"),sqo=l(),F(fb.$$.fragment),Cqe=l(),Hi=a("h2"),mb=a("a"),Hme=a("span"),F(wy.$$.fragment),lqo=l(),Ume=a("span"),iqo=o("AutoModelForTokenClassification"),wqe=l(),Io=a("div"),F(Ay.$$.fragment),dqo=l(),Ui=a("p"),cqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mO=a("a"),fqo=o("from_pretrained()"),mqo=o(" class method or the "),gO=a("a"),gqo=o("from_config()"),hqo=o(` class
method.`),pqo=l(),yy=a("p"),_qo=o("This class cannot be instantiated directly using "),Jme=a("code"),uqo=o("__init__()"),bqo=o(" (throws an error)."),vqo=l(),ft=a("div"),F(Ly.$$.fragment),Fqo=l(),Yme=a("p"),Tqo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Mqo=l(),Ji=a("p"),Eqo=o(`Note:
Loading a model from its configuration file does `),Kme=a("strong"),Cqo=o("not"),wqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=a("a"),Aqo=o("from_pretrained()"),yqo=o(" to load the model weights."),Lqo=l(),F(gb.$$.fragment),xqo=l(),ao=a("div"),F(xy.$$.fragment),$qo=l(),Zme=a("p"),kqo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Sqo=l(),Ia=a("p"),Rqo=o("The model class to instantiate is selected based on the "),ege=a("code"),Pqo=o("model_type"),Bqo=o(` property of the config object (either
passed as an argument or loaded from `),oge=a("code"),Iqo=o("pretrained_model_name_or_path"),qqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rge=a("code"),Nqo=o("pretrained_model_name_or_path"),jqo=o(":"),Dqo=l(),U=a("ul"),hb=a("li"),tge=a("strong"),Gqo=o("albert"),Oqo=o(" \u2014 "),pO=a("a"),Vqo=o("AlbertForTokenClassification"),Xqo=o(" (ALBERT model)"),zqo=l(),pb=a("li"),age=a("strong"),Wqo=o("bert"),Qqo=o(" \u2014 "),_O=a("a"),Hqo=o("BertForTokenClassification"),Uqo=o(" (BERT model)"),Jqo=l(),_b=a("li"),nge=a("strong"),Yqo=o("big_bird"),Kqo=o(" \u2014 "),uO=a("a"),Zqo=o("BigBirdForTokenClassification"),eNo=o(" (BigBird model)"),oNo=l(),ub=a("li"),sge=a("strong"),rNo=o("camembert"),tNo=o(" \u2014 "),bO=a("a"),aNo=o("CamembertForTokenClassification"),nNo=o(" (CamemBERT model)"),sNo=l(),bb=a("li"),lge=a("strong"),lNo=o("canine"),iNo=o(" \u2014 "),vO=a("a"),dNo=o("CanineForTokenClassification"),cNo=o(" (Canine model)"),fNo=l(),vb=a("li"),ige=a("strong"),mNo=o("convbert"),gNo=o(" \u2014 "),FO=a("a"),hNo=o("ConvBertForTokenClassification"),pNo=o(" (ConvBERT model)"),_No=l(),Fb=a("li"),dge=a("strong"),uNo=o("data2vec-text"),bNo=o(" \u2014 "),TO=a("a"),vNo=o("Data2VecTextForTokenClassification"),FNo=o(" (Data2VecText model)"),TNo=l(),Tb=a("li"),cge=a("strong"),MNo=o("deberta"),ENo=o(" \u2014 "),MO=a("a"),CNo=o("DebertaForTokenClassification"),wNo=o(" (DeBERTa model)"),ANo=l(),Mb=a("li"),fge=a("strong"),yNo=o("deberta-v2"),LNo=o(" \u2014 "),EO=a("a"),xNo=o("DebertaV2ForTokenClassification"),$No=o(" (DeBERTa-v2 model)"),kNo=l(),Eb=a("li"),mge=a("strong"),SNo=o("distilbert"),RNo=o(" \u2014 "),CO=a("a"),PNo=o("DistilBertForTokenClassification"),BNo=o(" (DistilBERT model)"),INo=l(),Cb=a("li"),gge=a("strong"),qNo=o("electra"),NNo=o(" \u2014 "),wO=a("a"),jNo=o("ElectraForTokenClassification"),DNo=o(" (ELECTRA model)"),GNo=l(),wb=a("li"),hge=a("strong"),ONo=o("flaubert"),VNo=o(" \u2014 "),AO=a("a"),XNo=o("FlaubertForTokenClassification"),zNo=o(" (FlauBERT model)"),WNo=l(),Ab=a("li"),pge=a("strong"),QNo=o("fnet"),HNo=o(" \u2014 "),yO=a("a"),UNo=o("FNetForTokenClassification"),JNo=o(" (FNet model)"),YNo=l(),yb=a("li"),_ge=a("strong"),KNo=o("funnel"),ZNo=o(" \u2014 "),LO=a("a"),ejo=o("FunnelForTokenClassification"),ojo=o(" (Funnel Transformer model)"),rjo=l(),Lb=a("li"),uge=a("strong"),tjo=o("gpt2"),ajo=o(" \u2014 "),xO=a("a"),njo=o("GPT2ForTokenClassification"),sjo=o(" (OpenAI GPT-2 model)"),ljo=l(),xb=a("li"),bge=a("strong"),ijo=o("ibert"),djo=o(" \u2014 "),$O=a("a"),cjo=o("IBertForTokenClassification"),fjo=o(" (I-BERT model)"),mjo=l(),$b=a("li"),vge=a("strong"),gjo=o("layoutlm"),hjo=o(" \u2014 "),kO=a("a"),pjo=o("LayoutLMForTokenClassification"),_jo=o(" (LayoutLM model)"),ujo=l(),kb=a("li"),Fge=a("strong"),bjo=o("layoutlmv2"),vjo=o(" \u2014 "),SO=a("a"),Fjo=o("LayoutLMv2ForTokenClassification"),Tjo=o(" (LayoutLMv2 model)"),Mjo=l(),Sb=a("li"),Tge=a("strong"),Ejo=o("longformer"),Cjo=o(" \u2014 "),RO=a("a"),wjo=o("LongformerForTokenClassification"),Ajo=o(" (Longformer model)"),yjo=l(),Rb=a("li"),Mge=a("strong"),Ljo=o("megatron-bert"),xjo=o(" \u2014 "),PO=a("a"),$jo=o("MegatronBertForTokenClassification"),kjo=o(" (MegatronBert model)"),Sjo=l(),Pb=a("li"),Ege=a("strong"),Rjo=o("mobilebert"),Pjo=o(" \u2014 "),BO=a("a"),Bjo=o("MobileBertForTokenClassification"),Ijo=o(" (MobileBERT model)"),qjo=l(),Bb=a("li"),Cge=a("strong"),Njo=o("mpnet"),jjo=o(" \u2014 "),IO=a("a"),Djo=o("MPNetForTokenClassification"),Gjo=o(" (MPNet model)"),Ojo=l(),Ib=a("li"),wge=a("strong"),Vjo=o("nystromformer"),Xjo=o(" \u2014 "),qO=a("a"),zjo=o("NystromformerForTokenClassification"),Wjo=o(" (Nystromformer model)"),Qjo=l(),qb=a("li"),Age=a("strong"),Hjo=o("qdqbert"),Ujo=o(" \u2014 "),NO=a("a"),Jjo=o("QDQBertForTokenClassification"),Yjo=o(" (QDQBert model)"),Kjo=l(),Nb=a("li"),yge=a("strong"),Zjo=o("rembert"),eDo=o(" \u2014 "),jO=a("a"),oDo=o("RemBertForTokenClassification"),rDo=o(" (RemBERT model)"),tDo=l(),jb=a("li"),Lge=a("strong"),aDo=o("roberta"),nDo=o(" \u2014 "),DO=a("a"),sDo=o("RobertaForTokenClassification"),lDo=o(" (RoBERTa model)"),iDo=l(),Db=a("li"),xge=a("strong"),dDo=o("roformer"),cDo=o(" \u2014 "),GO=a("a"),fDo=o("RoFormerForTokenClassification"),mDo=o(" (RoFormer model)"),gDo=l(),Gb=a("li"),$ge=a("strong"),hDo=o("squeezebert"),pDo=o(" \u2014 "),OO=a("a"),_Do=o("SqueezeBertForTokenClassification"),uDo=o(" (SqueezeBERT model)"),bDo=l(),Ob=a("li"),kge=a("strong"),vDo=o("xlm"),FDo=o(" \u2014 "),VO=a("a"),TDo=o("XLMForTokenClassification"),MDo=o(" (XLM model)"),EDo=l(),Vb=a("li"),Sge=a("strong"),CDo=o("xlm-roberta"),wDo=o(" \u2014 "),XO=a("a"),ADo=o("XLMRobertaForTokenClassification"),yDo=o(" (XLM-RoBERTa model)"),LDo=l(),Xb=a("li"),Rge=a("strong"),xDo=o("xlm-roberta-xl"),$Do=o(" \u2014 "),zO=a("a"),kDo=o("XLMRobertaXLForTokenClassification"),SDo=o(" (XLM-RoBERTa-XL model)"),RDo=l(),zb=a("li"),Pge=a("strong"),PDo=o("xlnet"),BDo=o(" \u2014 "),WO=a("a"),IDo=o("XLNetForTokenClassification"),qDo=o(" (XLNet model)"),NDo=l(),Wb=a("li"),Bge=a("strong"),jDo=o("yoso"),DDo=o(" \u2014 "),QO=a("a"),GDo=o("YosoForTokenClassification"),ODo=o(" (YOSO model)"),VDo=l(),Qb=a("p"),XDo=o("The model is set in evaluation mode by default using "),Ige=a("code"),zDo=o("model.eval()"),WDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qge=a("code"),QDo=o("model.train()"),HDo=l(),F(Hb.$$.fragment),Aqe=l(),Yi=a("h2"),Ub=a("a"),Nge=a("span"),F($y.$$.fragment),UDo=l(),jge=a("span"),JDo=o("AutoModelForQuestionAnswering"),yqe=l(),qo=a("div"),F(ky.$$.fragment),YDo=l(),Ki=a("p"),KDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),HO=a("a"),ZDo=o("from_pretrained()"),eGo=o(" class method or the "),UO=a("a"),oGo=o("from_config()"),rGo=o(` class
method.`),tGo=l(),Sy=a("p"),aGo=o("This class cannot be instantiated directly using "),Dge=a("code"),nGo=o("__init__()"),sGo=o(" (throws an error)."),lGo=l(),mt=a("div"),F(Ry.$$.fragment),iGo=l(),Gge=a("p"),dGo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cGo=l(),Zi=a("p"),fGo=o(`Note:
Loading a model from its configuration file does `),Oge=a("strong"),mGo=o("not"),gGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JO=a("a"),hGo=o("from_pretrained()"),pGo=o(" to load the model weights."),_Go=l(),F(Jb.$$.fragment),uGo=l(),no=a("div"),F(Py.$$.fragment),bGo=l(),Vge=a("p"),vGo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),FGo=l(),qa=a("p"),TGo=o("The model class to instantiate is selected based on the "),Xge=a("code"),MGo=o("model_type"),EGo=o(` property of the config object (either
passed as an argument or loaded from `),zge=a("code"),CGo=o("pretrained_model_name_or_path"),wGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wge=a("code"),AGo=o("pretrained_model_name_or_path"),yGo=o(":"),LGo=l(),V=a("ul"),Yb=a("li"),Qge=a("strong"),xGo=o("albert"),$Go=o(" \u2014 "),YO=a("a"),kGo=o("AlbertForQuestionAnswering"),SGo=o(" (ALBERT model)"),RGo=l(),Kb=a("li"),Hge=a("strong"),PGo=o("bart"),BGo=o(" \u2014 "),KO=a("a"),IGo=o("BartForQuestionAnswering"),qGo=o(" (BART model)"),NGo=l(),Zb=a("li"),Uge=a("strong"),jGo=o("bert"),DGo=o(" \u2014 "),ZO=a("a"),GGo=o("BertForQuestionAnswering"),OGo=o(" (BERT model)"),VGo=l(),ev=a("li"),Jge=a("strong"),XGo=o("big_bird"),zGo=o(" \u2014 "),eV=a("a"),WGo=o("BigBirdForQuestionAnswering"),QGo=o(" (BigBird model)"),HGo=l(),ov=a("li"),Yge=a("strong"),UGo=o("bigbird_pegasus"),JGo=o(" \u2014 "),oV=a("a"),YGo=o("BigBirdPegasusForQuestionAnswering"),KGo=o(" (BigBirdPegasus model)"),ZGo=l(),rv=a("li"),Kge=a("strong"),eOo=o("camembert"),oOo=o(" \u2014 "),rV=a("a"),rOo=o("CamembertForQuestionAnswering"),tOo=o(" (CamemBERT model)"),aOo=l(),tv=a("li"),Zge=a("strong"),nOo=o("canine"),sOo=o(" \u2014 "),tV=a("a"),lOo=o("CanineForQuestionAnswering"),iOo=o(" (Canine model)"),dOo=l(),av=a("li"),ehe=a("strong"),cOo=o("convbert"),fOo=o(" \u2014 "),aV=a("a"),mOo=o("ConvBertForQuestionAnswering"),gOo=o(" (ConvBERT model)"),hOo=l(),nv=a("li"),ohe=a("strong"),pOo=o("data2vec-text"),_Oo=o(" \u2014 "),nV=a("a"),uOo=o("Data2VecTextForQuestionAnswering"),bOo=o(" (Data2VecText model)"),vOo=l(),sv=a("li"),rhe=a("strong"),FOo=o("deberta"),TOo=o(" \u2014 "),sV=a("a"),MOo=o("DebertaForQuestionAnswering"),EOo=o(" (DeBERTa model)"),COo=l(),lv=a("li"),the=a("strong"),wOo=o("deberta-v2"),AOo=o(" \u2014 "),lV=a("a"),yOo=o("DebertaV2ForQuestionAnswering"),LOo=o(" (DeBERTa-v2 model)"),xOo=l(),iv=a("li"),ahe=a("strong"),$Oo=o("distilbert"),kOo=o(" \u2014 "),iV=a("a"),SOo=o("DistilBertForQuestionAnswering"),ROo=o(" (DistilBERT model)"),POo=l(),dv=a("li"),nhe=a("strong"),BOo=o("electra"),IOo=o(" \u2014 "),dV=a("a"),qOo=o("ElectraForQuestionAnswering"),NOo=o(" (ELECTRA model)"),jOo=l(),cv=a("li"),she=a("strong"),DOo=o("flaubert"),GOo=o(" \u2014 "),cV=a("a"),OOo=o("FlaubertForQuestionAnsweringSimple"),VOo=o(" (FlauBERT model)"),XOo=l(),fv=a("li"),lhe=a("strong"),zOo=o("fnet"),WOo=o(" \u2014 "),fV=a("a"),QOo=o("FNetForQuestionAnswering"),HOo=o(" (FNet model)"),UOo=l(),mv=a("li"),ihe=a("strong"),JOo=o("funnel"),YOo=o(" \u2014 "),mV=a("a"),KOo=o("FunnelForQuestionAnswering"),ZOo=o(" (Funnel Transformer model)"),eVo=l(),gv=a("li"),dhe=a("strong"),oVo=o("gptj"),rVo=o(" \u2014 "),gV=a("a"),tVo=o("GPTJForQuestionAnswering"),aVo=o(" (GPT-J model)"),nVo=l(),hv=a("li"),che=a("strong"),sVo=o("ibert"),lVo=o(" \u2014 "),hV=a("a"),iVo=o("IBertForQuestionAnswering"),dVo=o(" (I-BERT model)"),cVo=l(),pv=a("li"),fhe=a("strong"),fVo=o("layoutlmv2"),mVo=o(" \u2014 "),pV=a("a"),gVo=o("LayoutLMv2ForQuestionAnswering"),hVo=o(" (LayoutLMv2 model)"),pVo=l(),_v=a("li"),mhe=a("strong"),_Vo=o("led"),uVo=o(" \u2014 "),_V=a("a"),bVo=o("LEDForQuestionAnswering"),vVo=o(" (LED model)"),FVo=l(),uv=a("li"),ghe=a("strong"),TVo=o("longformer"),MVo=o(" \u2014 "),uV=a("a"),EVo=o("LongformerForQuestionAnswering"),CVo=o(" (Longformer model)"),wVo=l(),bv=a("li"),hhe=a("strong"),AVo=o("lxmert"),yVo=o(" \u2014 "),bV=a("a"),LVo=o("LxmertForQuestionAnswering"),xVo=o(" (LXMERT model)"),$Vo=l(),vv=a("li"),phe=a("strong"),kVo=o("mbart"),SVo=o(" \u2014 "),vV=a("a"),RVo=o("MBartForQuestionAnswering"),PVo=o(" (mBART model)"),BVo=l(),Fv=a("li"),_he=a("strong"),IVo=o("megatron-bert"),qVo=o(" \u2014 "),FV=a("a"),NVo=o("MegatronBertForQuestionAnswering"),jVo=o(" (MegatronBert model)"),DVo=l(),Tv=a("li"),uhe=a("strong"),GVo=o("mobilebert"),OVo=o(" \u2014 "),TV=a("a"),VVo=o("MobileBertForQuestionAnswering"),XVo=o(" (MobileBERT model)"),zVo=l(),Mv=a("li"),bhe=a("strong"),WVo=o("mpnet"),QVo=o(" \u2014 "),MV=a("a"),HVo=o("MPNetForQuestionAnswering"),UVo=o(" (MPNet model)"),JVo=l(),Ev=a("li"),vhe=a("strong"),YVo=o("nystromformer"),KVo=o(" \u2014 "),EV=a("a"),ZVo=o("NystromformerForQuestionAnswering"),eXo=o(" (Nystromformer model)"),oXo=l(),Cv=a("li"),Fhe=a("strong"),rXo=o("qdqbert"),tXo=o(" \u2014 "),CV=a("a"),aXo=o("QDQBertForQuestionAnswering"),nXo=o(" (QDQBert model)"),sXo=l(),wv=a("li"),The=a("strong"),lXo=o("reformer"),iXo=o(" \u2014 "),wV=a("a"),dXo=o("ReformerForQuestionAnswering"),cXo=o(" (Reformer model)"),fXo=l(),Av=a("li"),Mhe=a("strong"),mXo=o("rembert"),gXo=o(" \u2014 "),AV=a("a"),hXo=o("RemBertForQuestionAnswering"),pXo=o(" (RemBERT model)"),_Xo=l(),yv=a("li"),Ehe=a("strong"),uXo=o("roberta"),bXo=o(" \u2014 "),yV=a("a"),vXo=o("RobertaForQuestionAnswering"),FXo=o(" (RoBERTa model)"),TXo=l(),Lv=a("li"),Che=a("strong"),MXo=o("roformer"),EXo=o(" \u2014 "),LV=a("a"),CXo=o("RoFormerForQuestionAnswering"),wXo=o(" (RoFormer model)"),AXo=l(),xv=a("li"),whe=a("strong"),yXo=o("splinter"),LXo=o(" \u2014 "),xV=a("a"),xXo=o("SplinterForQuestionAnswering"),$Xo=o(" (Splinter model)"),kXo=l(),$v=a("li"),Ahe=a("strong"),SXo=o("squeezebert"),RXo=o(" \u2014 "),$V=a("a"),PXo=o("SqueezeBertForQuestionAnswering"),BXo=o(" (SqueezeBERT model)"),IXo=l(),kv=a("li"),yhe=a("strong"),qXo=o("xlm"),NXo=o(" \u2014 "),kV=a("a"),jXo=o("XLMForQuestionAnsweringSimple"),DXo=o(" (XLM model)"),GXo=l(),Sv=a("li"),Lhe=a("strong"),OXo=o("xlm-roberta"),VXo=o(" \u2014 "),SV=a("a"),XXo=o("XLMRobertaForQuestionAnswering"),zXo=o(" (XLM-RoBERTa model)"),WXo=l(),Rv=a("li"),xhe=a("strong"),QXo=o("xlm-roberta-xl"),HXo=o(" \u2014 "),RV=a("a"),UXo=o("XLMRobertaXLForQuestionAnswering"),JXo=o(" (XLM-RoBERTa-XL model)"),YXo=l(),Pv=a("li"),$he=a("strong"),KXo=o("xlnet"),ZXo=o(" \u2014 "),PV=a("a"),ezo=o("XLNetForQuestionAnsweringSimple"),ozo=o(" (XLNet model)"),rzo=l(),Bv=a("li"),khe=a("strong"),tzo=o("yoso"),azo=o(" \u2014 "),BV=a("a"),nzo=o("YosoForQuestionAnswering"),szo=o(" (YOSO model)"),lzo=l(),Iv=a("p"),izo=o("The model is set in evaluation mode by default using "),She=a("code"),dzo=o("model.eval()"),czo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rhe=a("code"),fzo=o("model.train()"),mzo=l(),F(qv.$$.fragment),Lqe=l(),ed=a("h2"),Nv=a("a"),Phe=a("span"),F(By.$$.fragment),gzo=l(),Bhe=a("span"),hzo=o("AutoModelForTableQuestionAnswering"),xqe=l(),No=a("div"),F(Iy.$$.fragment),pzo=l(),od=a("p"),_zo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),IV=a("a"),uzo=o("from_pretrained()"),bzo=o(" class method or the "),qV=a("a"),vzo=o("from_config()"),Fzo=o(` class
method.`),Tzo=l(),qy=a("p"),Mzo=o("This class cannot be instantiated directly using "),Ihe=a("code"),Ezo=o("__init__()"),Czo=o(" (throws an error)."),wzo=l(),gt=a("div"),F(Ny.$$.fragment),Azo=l(),qhe=a("p"),yzo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Lzo=l(),rd=a("p"),xzo=o(`Note:
Loading a model from its configuration file does `),Nhe=a("strong"),$zo=o("not"),kzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=a("a"),Szo=o("from_pretrained()"),Rzo=o(" to load the model weights."),Pzo=l(),F(jv.$$.fragment),Bzo=l(),so=a("div"),F(jy.$$.fragment),Izo=l(),jhe=a("p"),qzo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Nzo=l(),Na=a("p"),jzo=o("The model class to instantiate is selected based on the "),Dhe=a("code"),Dzo=o("model_type"),Gzo=o(` property of the config object (either
passed as an argument or loaded from `),Ghe=a("code"),Ozo=o("pretrained_model_name_or_path"),Vzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ohe=a("code"),Xzo=o("pretrained_model_name_or_path"),zzo=o(":"),Wzo=l(),Vhe=a("ul"),Dv=a("li"),Xhe=a("strong"),Qzo=o("tapas"),Hzo=o(" \u2014 "),jV=a("a"),Uzo=o("TapasForQuestionAnswering"),Jzo=o(" (TAPAS model)"),Yzo=l(),Gv=a("p"),Kzo=o("The model is set in evaluation mode by default using "),zhe=a("code"),Zzo=o("model.eval()"),eWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Whe=a("code"),oWo=o("model.train()"),rWo=l(),F(Ov.$$.fragment),$qe=l(),td=a("h2"),Vv=a("a"),Qhe=a("span"),F(Dy.$$.fragment),tWo=l(),Hhe=a("span"),aWo=o("AutoModelForImageClassification"),kqe=l(),jo=a("div"),F(Gy.$$.fragment),nWo=l(),ad=a("p"),sWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),DV=a("a"),lWo=o("from_pretrained()"),iWo=o(" class method or the "),GV=a("a"),dWo=o("from_config()"),cWo=o(` class
method.`),fWo=l(),Oy=a("p"),mWo=o("This class cannot be instantiated directly using "),Uhe=a("code"),gWo=o("__init__()"),hWo=o(" (throws an error)."),pWo=l(),ht=a("div"),F(Vy.$$.fragment),_Wo=l(),Jhe=a("p"),uWo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),bWo=l(),nd=a("p"),vWo=o(`Note:
Loading a model from its configuration file does `),Yhe=a("strong"),FWo=o("not"),TWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OV=a("a"),MWo=o("from_pretrained()"),EWo=o(" to load the model weights."),CWo=l(),F(Xv.$$.fragment),wWo=l(),lo=a("div"),F(Xy.$$.fragment),AWo=l(),Khe=a("p"),yWo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),LWo=l(),ja=a("p"),xWo=o("The model class to instantiate is selected based on the "),Zhe=a("code"),$Wo=o("model_type"),kWo=o(` property of the config object (either
passed as an argument or loaded from `),epe=a("code"),SWo=o("pretrained_model_name_or_path"),RWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ope=a("code"),PWo=o("pretrained_model_name_or_path"),BWo=o(":"),IWo=l(),Fe=a("ul"),zv=a("li"),rpe=a("strong"),qWo=o("beit"),NWo=o(" \u2014 "),VV=a("a"),jWo=o("BeitForImageClassification"),DWo=o(" (BEiT model)"),GWo=l(),Wv=a("li"),tpe=a("strong"),OWo=o("convnext"),VWo=o(" \u2014 "),XV=a("a"),XWo=o("ConvNextForImageClassification"),zWo=o(" (ConvNext model)"),WWo=l(),Qv=a("li"),ape=a("strong"),QWo=o("data2vec-vision"),HWo=o(" \u2014 "),zV=a("a"),UWo=o("Data2VecVisionForImageClassification"),JWo=o(" (Data2VecVision model)"),YWo=l(),Ps=a("li"),npe=a("strong"),KWo=o("deit"),ZWo=o(" \u2014 "),WV=a("a"),eQo=o("DeiTForImageClassification"),oQo=o(" or "),QV=a("a"),rQo=o("DeiTForImageClassificationWithTeacher"),tQo=o(" (DeiT model)"),aQo=l(),Hv=a("li"),spe=a("strong"),nQo=o("imagegpt"),sQo=o(" \u2014 "),HV=a("a"),lQo=o("ImageGPTForImageClassification"),iQo=o(" (ImageGPT model)"),dQo=l(),pt=a("li"),lpe=a("strong"),cQo=o("perceiver"),fQo=o(" \u2014 "),UV=a("a"),mQo=o("PerceiverForImageClassificationLearned"),gQo=o(" or "),JV=a("a"),hQo=o("PerceiverForImageClassificationFourier"),pQo=o(" or "),YV=a("a"),_Qo=o("PerceiverForImageClassificationConvProcessing"),uQo=o(" (Perceiver model)"),bQo=l(),Uv=a("li"),ipe=a("strong"),vQo=o("poolformer"),FQo=o(" \u2014 "),KV=a("a"),TQo=o("PoolFormerForImageClassification"),MQo=o(" (PoolFormer model)"),EQo=l(),Jv=a("li"),dpe=a("strong"),CQo=o("regnet"),wQo=o(" \u2014 "),ZV=a("a"),AQo=o("RegNetForImageClassification"),yQo=o(" (RegNet model)"),LQo=l(),Yv=a("li"),cpe=a("strong"),xQo=o("resnet"),$Qo=o(" \u2014 "),eX=a("a"),kQo=o("ResNetForImageClassification"),SQo=o(" (ResNet model)"),RQo=l(),Kv=a("li"),fpe=a("strong"),PQo=o("segformer"),BQo=o(" \u2014 "),oX=a("a"),IQo=o("SegformerForImageClassification"),qQo=o(" (SegFormer model)"),NQo=l(),Zv=a("li"),mpe=a("strong"),jQo=o("swin"),DQo=o(" \u2014 "),rX=a("a"),GQo=o("SwinForImageClassification"),OQo=o(" (Swin model)"),VQo=l(),eF=a("li"),gpe=a("strong"),XQo=o("van"),zQo=o(" \u2014 "),tX=a("a"),WQo=o("VanForImageClassification"),QQo=o(" (VAN model)"),HQo=l(),oF=a("li"),hpe=a("strong"),UQo=o("vit"),JQo=o(" \u2014 "),aX=a("a"),YQo=o("ViTForImageClassification"),KQo=o(" (ViT model)"),ZQo=l(),rF=a("p"),eHo=o("The model is set in evaluation mode by default using "),ppe=a("code"),oHo=o("model.eval()"),rHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_pe=a("code"),tHo=o("model.train()"),aHo=l(),F(tF.$$.fragment),Sqe=l(),sd=a("h2"),aF=a("a"),upe=a("span"),F(zy.$$.fragment),nHo=l(),bpe=a("span"),sHo=o("AutoModelForVision2Seq"),Rqe=l(),Do=a("div"),F(Wy.$$.fragment),lHo=l(),ld=a("p"),iHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nX=a("a"),dHo=o("from_pretrained()"),cHo=o(" class method or the "),sX=a("a"),fHo=o("from_config()"),mHo=o(` class
method.`),gHo=l(),Qy=a("p"),hHo=o("This class cannot be instantiated directly using "),vpe=a("code"),pHo=o("__init__()"),_Ho=o(" (throws an error)."),uHo=l(),_t=a("div"),F(Hy.$$.fragment),bHo=l(),Fpe=a("p"),vHo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),FHo=l(),id=a("p"),THo=o(`Note:
Loading a model from its configuration file does `),Tpe=a("strong"),MHo=o("not"),EHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lX=a("a"),CHo=o("from_pretrained()"),wHo=o(" to load the model weights."),AHo=l(),F(nF.$$.fragment),yHo=l(),io=a("div"),F(Uy.$$.fragment),LHo=l(),Mpe=a("p"),xHo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),$Ho=l(),Da=a("p"),kHo=o("The model class to instantiate is selected based on the "),Epe=a("code"),SHo=o("model_type"),RHo=o(` property of the config object (either
passed as an argument or loaded from `),Cpe=a("code"),PHo=o("pretrained_model_name_or_path"),BHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wpe=a("code"),IHo=o("pretrained_model_name_or_path"),qHo=o(":"),NHo=l(),Ape=a("ul"),sF=a("li"),ype=a("strong"),jHo=o("vision-encoder-decoder"),DHo=o(" \u2014 "),iX=a("a"),GHo=o("VisionEncoderDecoderModel"),OHo=o(" (Vision Encoder decoder model)"),VHo=l(),lF=a("p"),XHo=o("The model is set in evaluation mode by default using "),Lpe=a("code"),zHo=o("model.eval()"),WHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xpe=a("code"),QHo=o("model.train()"),HHo=l(),F(iF.$$.fragment),Pqe=l(),dd=a("h2"),dF=a("a"),$pe=a("span"),F(Jy.$$.fragment),UHo=l(),kpe=a("span"),JHo=o("AutoModelForAudioClassification"),Bqe=l(),Go=a("div"),F(Yy.$$.fragment),YHo=l(),cd=a("p"),KHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),dX=a("a"),ZHo=o("from_pretrained()"),eUo=o(" class method or the "),cX=a("a"),oUo=o("from_config()"),rUo=o(` class
method.`),tUo=l(),Ky=a("p"),aUo=o("This class cannot be instantiated directly using "),Spe=a("code"),nUo=o("__init__()"),sUo=o(" (throws an error)."),lUo=l(),ut=a("div"),F(Zy.$$.fragment),iUo=l(),Rpe=a("p"),dUo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),cUo=l(),fd=a("p"),fUo=o(`Note:
Loading a model from its configuration file does `),Ppe=a("strong"),mUo=o("not"),gUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fX=a("a"),hUo=o("from_pretrained()"),pUo=o(" to load the model weights."),_Uo=l(),F(cF.$$.fragment),uUo=l(),co=a("div"),F(eL.$$.fragment),bUo=l(),Bpe=a("p"),vUo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),FUo=l(),Ga=a("p"),TUo=o("The model class to instantiate is selected based on the "),Ipe=a("code"),MUo=o("model_type"),EUo=o(` property of the config object (either
passed as an argument or loaded from `),qpe=a("code"),CUo=o("pretrained_model_name_or_path"),wUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Npe=a("code"),AUo=o("pretrained_model_name_or_path"),yUo=o(":"),LUo=l(),Se=a("ul"),fF=a("li"),jpe=a("strong"),xUo=o("data2vec-audio"),$Uo=o(" \u2014 "),mX=a("a"),kUo=o("Data2VecAudioForSequenceClassification"),SUo=o(" (Data2VecAudio model)"),RUo=l(),mF=a("li"),Dpe=a("strong"),PUo=o("hubert"),BUo=o(" \u2014 "),gX=a("a"),IUo=o("HubertForSequenceClassification"),qUo=o(" (Hubert model)"),NUo=l(),gF=a("li"),Gpe=a("strong"),jUo=o("sew"),DUo=o(" \u2014 "),hX=a("a"),GUo=o("SEWForSequenceClassification"),OUo=o(" (SEW model)"),VUo=l(),hF=a("li"),Ope=a("strong"),XUo=o("sew-d"),zUo=o(" \u2014 "),pX=a("a"),WUo=o("SEWDForSequenceClassification"),QUo=o(" (SEW-D model)"),HUo=l(),pF=a("li"),Vpe=a("strong"),UUo=o("unispeech"),JUo=o(" \u2014 "),_X=a("a"),YUo=o("UniSpeechForSequenceClassification"),KUo=o(" (UniSpeech model)"),ZUo=l(),_F=a("li"),Xpe=a("strong"),eJo=o("unispeech-sat"),oJo=o(" \u2014 "),uX=a("a"),rJo=o("UniSpeechSatForSequenceClassification"),tJo=o(" (UniSpeechSat model)"),aJo=l(),uF=a("li"),zpe=a("strong"),nJo=o("wav2vec2"),sJo=o(" \u2014 "),bX=a("a"),lJo=o("Wav2Vec2ForSequenceClassification"),iJo=o(" (Wav2Vec2 model)"),dJo=l(),bF=a("li"),Wpe=a("strong"),cJo=o("wav2vec2-conformer"),fJo=o(" \u2014 "),vX=a("a"),mJo=o("Wav2Vec2ConformerForSequenceClassification"),gJo=o(" (Wav2Vec2-Conformer model)"),hJo=l(),vF=a("li"),Qpe=a("strong"),pJo=o("wavlm"),_Jo=o(" \u2014 "),FX=a("a"),uJo=o("WavLMForSequenceClassification"),bJo=o(" (WavLM model)"),vJo=l(),FF=a("p"),FJo=o("The model is set in evaluation mode by default using "),Hpe=a("code"),TJo=o("model.eval()"),MJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Upe=a("code"),EJo=o("model.train()"),CJo=l(),F(TF.$$.fragment),Iqe=l(),md=a("h2"),MF=a("a"),Jpe=a("span"),F(oL.$$.fragment),wJo=l(),Ype=a("span"),AJo=o("AutoModelForAudioFrameClassification"),qqe=l(),Oo=a("div"),F(rL.$$.fragment),yJo=l(),gd=a("p"),LJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),TX=a("a"),xJo=o("from_pretrained()"),$Jo=o(" class method or the "),MX=a("a"),kJo=o("from_config()"),SJo=o(` class
method.`),RJo=l(),tL=a("p"),PJo=o("This class cannot be instantiated directly using "),Kpe=a("code"),BJo=o("__init__()"),IJo=o(" (throws an error)."),qJo=l(),bt=a("div"),F(aL.$$.fragment),NJo=l(),Zpe=a("p"),jJo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),DJo=l(),hd=a("p"),GJo=o(`Note:
Loading a model from its configuration file does `),e_e=a("strong"),OJo=o("not"),VJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=a("a"),XJo=o("from_pretrained()"),zJo=o(" to load the model weights."),WJo=l(),F(EF.$$.fragment),QJo=l(),fo=a("div"),F(nL.$$.fragment),HJo=l(),o_e=a("p"),UJo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),JJo=l(),Oa=a("p"),YJo=o("The model class to instantiate is selected based on the "),r_e=a("code"),KJo=o("model_type"),ZJo=o(` property of the config object (either
passed as an argument or loaded from `),t_e=a("code"),eYo=o("pretrained_model_name_or_path"),oYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a_e=a("code"),rYo=o("pretrained_model_name_or_path"),tYo=o(":"),aYo=l(),Kr=a("ul"),CF=a("li"),n_e=a("strong"),nYo=o("data2vec-audio"),sYo=o(" \u2014 "),CX=a("a"),lYo=o("Data2VecAudioForAudioFrameClassification"),iYo=o(" (Data2VecAudio model)"),dYo=l(),wF=a("li"),s_e=a("strong"),cYo=o("unispeech-sat"),fYo=o(" \u2014 "),wX=a("a"),mYo=o("UniSpeechSatForAudioFrameClassification"),gYo=o(" (UniSpeechSat model)"),hYo=l(),AF=a("li"),l_e=a("strong"),pYo=o("wav2vec2"),_Yo=o(" \u2014 "),AX=a("a"),uYo=o("Wav2Vec2ForAudioFrameClassification"),bYo=o(" (Wav2Vec2 model)"),vYo=l(),yF=a("li"),i_e=a("strong"),FYo=o("wav2vec2-conformer"),TYo=o(" \u2014 "),yX=a("a"),MYo=o("Wav2Vec2ConformerForAudioFrameClassification"),EYo=o(" (Wav2Vec2-Conformer model)"),CYo=l(),LF=a("li"),d_e=a("strong"),wYo=o("wavlm"),AYo=o(" \u2014 "),LX=a("a"),yYo=o("WavLMForAudioFrameClassification"),LYo=o(" (WavLM model)"),xYo=l(),xF=a("p"),$Yo=o("The model is set in evaluation mode by default using "),c_e=a("code"),kYo=o("model.eval()"),SYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f_e=a("code"),RYo=o("model.train()"),PYo=l(),F($F.$$.fragment),Nqe=l(),pd=a("h2"),kF=a("a"),m_e=a("span"),F(sL.$$.fragment),BYo=l(),g_e=a("span"),IYo=o("AutoModelForCTC"),jqe=l(),Vo=a("div"),F(lL.$$.fragment),qYo=l(),_d=a("p"),NYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),xX=a("a"),jYo=o("from_pretrained()"),DYo=o(" class method or the "),$X=a("a"),GYo=o("from_config()"),OYo=o(` class
method.`),VYo=l(),iL=a("p"),XYo=o("This class cannot be instantiated directly using "),h_e=a("code"),zYo=o("__init__()"),WYo=o(" (throws an error)."),QYo=l(),vt=a("div"),F(dL.$$.fragment),HYo=l(),p_e=a("p"),UYo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),JYo=l(),ud=a("p"),YYo=o(`Note:
Loading a model from its configuration file does `),__e=a("strong"),KYo=o("not"),ZYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),eKo=o("from_pretrained()"),oKo=o(" to load the model weights."),rKo=l(),F(SF.$$.fragment),tKo=l(),mo=a("div"),F(cL.$$.fragment),aKo=l(),u_e=a("p"),nKo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),sKo=l(),Va=a("p"),lKo=o("The model class to instantiate is selected based on the "),b_e=a("code"),iKo=o("model_type"),dKo=o(` property of the config object (either
passed as an argument or loaded from `),v_e=a("code"),cKo=o("pretrained_model_name_or_path"),fKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F_e=a("code"),mKo=o("pretrained_model_name_or_path"),gKo=o(":"),hKo=l(),Re=a("ul"),RF=a("li"),T_e=a("strong"),pKo=o("data2vec-audio"),_Ko=o(" \u2014 "),SX=a("a"),uKo=o("Data2VecAudioForCTC"),bKo=o(" (Data2VecAudio model)"),vKo=l(),PF=a("li"),M_e=a("strong"),FKo=o("hubert"),TKo=o(" \u2014 "),RX=a("a"),MKo=o("HubertForCTC"),EKo=o(" (Hubert model)"),CKo=l(),BF=a("li"),E_e=a("strong"),wKo=o("sew"),AKo=o(" \u2014 "),PX=a("a"),yKo=o("SEWForCTC"),LKo=o(" (SEW model)"),xKo=l(),IF=a("li"),C_e=a("strong"),$Ko=o("sew-d"),kKo=o(" \u2014 "),BX=a("a"),SKo=o("SEWDForCTC"),RKo=o(" (SEW-D model)"),PKo=l(),qF=a("li"),w_e=a("strong"),BKo=o("unispeech"),IKo=o(" \u2014 "),IX=a("a"),qKo=o("UniSpeechForCTC"),NKo=o(" (UniSpeech model)"),jKo=l(),NF=a("li"),A_e=a("strong"),DKo=o("unispeech-sat"),GKo=o(" \u2014 "),qX=a("a"),OKo=o("UniSpeechSatForCTC"),VKo=o(" (UniSpeechSat model)"),XKo=l(),jF=a("li"),y_e=a("strong"),zKo=o("wav2vec2"),WKo=o(" \u2014 "),NX=a("a"),QKo=o("Wav2Vec2ForCTC"),HKo=o(" (Wav2Vec2 model)"),UKo=l(),DF=a("li"),L_e=a("strong"),JKo=o("wav2vec2-conformer"),YKo=o(" \u2014 "),jX=a("a"),KKo=o("Wav2Vec2ConformerForCTC"),ZKo=o(" (Wav2Vec2-Conformer model)"),eZo=l(),GF=a("li"),x_e=a("strong"),oZo=o("wavlm"),rZo=o(" \u2014 "),DX=a("a"),tZo=o("WavLMForCTC"),aZo=o(" (WavLM model)"),nZo=l(),OF=a("p"),sZo=o("The model is set in evaluation mode by default using "),$_e=a("code"),lZo=o("model.eval()"),iZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k_e=a("code"),dZo=o("model.train()"),cZo=l(),F(VF.$$.fragment),Dqe=l(),bd=a("h2"),XF=a("a"),S_e=a("span"),F(fL.$$.fragment),fZo=l(),R_e=a("span"),mZo=o("AutoModelForSpeechSeq2Seq"),Gqe=l(),Xo=a("div"),F(mL.$$.fragment),gZo=l(),vd=a("p"),hZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),GX=a("a"),pZo=o("from_pretrained()"),_Zo=o(" class method or the "),OX=a("a"),uZo=o("from_config()"),bZo=o(` class
method.`),vZo=l(),gL=a("p"),FZo=o("This class cannot be instantiated directly using "),P_e=a("code"),TZo=o("__init__()"),MZo=o(" (throws an error)."),EZo=l(),Ft=a("div"),F(hL.$$.fragment),CZo=l(),B_e=a("p"),wZo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),AZo=l(),Fd=a("p"),yZo=o(`Note:
Loading a model from its configuration file does `),I_e=a("strong"),LZo=o("not"),xZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VX=a("a"),$Zo=o("from_pretrained()"),kZo=o(" to load the model weights."),SZo=l(),F(zF.$$.fragment),RZo=l(),go=a("div"),F(pL.$$.fragment),PZo=l(),q_e=a("p"),BZo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),IZo=l(),Xa=a("p"),qZo=o("The model class to instantiate is selected based on the "),N_e=a("code"),NZo=o("model_type"),jZo=o(` property of the config object (either
passed as an argument or loaded from `),j_e=a("code"),DZo=o("pretrained_model_name_or_path"),GZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D_e=a("code"),OZo=o("pretrained_model_name_or_path"),VZo=o(":"),XZo=l(),_L=a("ul"),WF=a("li"),G_e=a("strong"),zZo=o("speech-encoder-decoder"),WZo=o(" \u2014 "),XX=a("a"),QZo=o("SpeechEncoderDecoderModel"),HZo=o(" (Speech Encoder decoder model)"),UZo=l(),QF=a("li"),O_e=a("strong"),JZo=o("speech_to_text"),YZo=o(" \u2014 "),zX=a("a"),KZo=o("Speech2TextForConditionalGeneration"),ZZo=o(" (Speech2Text model)"),eer=l(),HF=a("p"),oer=o("The model is set in evaluation mode by default using "),V_e=a("code"),rer=o("model.eval()"),ter=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X_e=a("code"),aer=o("model.train()"),ner=l(),F(UF.$$.fragment),Oqe=l(),Td=a("h2"),JF=a("a"),z_e=a("span"),F(uL.$$.fragment),ser=l(),W_e=a("span"),ler=o("AutoModelForAudioXVector"),Vqe=l(),zo=a("div"),F(bL.$$.fragment),ier=l(),Md=a("p"),der=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),WX=a("a"),cer=o("from_pretrained()"),fer=o(" class method or the "),QX=a("a"),mer=o("from_config()"),ger=o(` class
method.`),her=l(),vL=a("p"),per=o("This class cannot be instantiated directly using "),Q_e=a("code"),_er=o("__init__()"),uer=o(" (throws an error)."),ber=l(),Tt=a("div"),F(FL.$$.fragment),ver=l(),H_e=a("p"),Fer=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Ter=l(),Ed=a("p"),Mer=o(`Note:
Loading a model from its configuration file does `),U_e=a("strong"),Eer=o("not"),Cer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HX=a("a"),wer=o("from_pretrained()"),Aer=o(" to load the model weights."),yer=l(),F(YF.$$.fragment),Ler=l(),ho=a("div"),F(TL.$$.fragment),xer=l(),J_e=a("p"),$er=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),ker=l(),za=a("p"),Ser=o("The model class to instantiate is selected based on the "),Y_e=a("code"),Rer=o("model_type"),Per=o(` property of the config object (either
passed as an argument or loaded from `),K_e=a("code"),Ber=o("pretrained_model_name_or_path"),Ier=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z_e=a("code"),qer=o("pretrained_model_name_or_path"),Ner=o(":"),jer=l(),Zr=a("ul"),KF=a("li"),eue=a("strong"),Der=o("data2vec-audio"),Ger=o(" \u2014 "),UX=a("a"),Oer=o("Data2VecAudioForXVector"),Ver=o(" (Data2VecAudio model)"),Xer=l(),ZF=a("li"),oue=a("strong"),zer=o("unispeech-sat"),Wer=o(" \u2014 "),JX=a("a"),Qer=o("UniSpeechSatForXVector"),Her=o(" (UniSpeechSat model)"),Uer=l(),eT=a("li"),rue=a("strong"),Jer=o("wav2vec2"),Yer=o(" \u2014 "),YX=a("a"),Ker=o("Wav2Vec2ForXVector"),Zer=o(" (Wav2Vec2 model)"),eor=l(),oT=a("li"),tue=a("strong"),oor=o("wav2vec2-conformer"),ror=o(" \u2014 "),KX=a("a"),tor=o("Wav2Vec2ConformerForXVector"),aor=o(" (Wav2Vec2-Conformer model)"),nor=l(),rT=a("li"),aue=a("strong"),sor=o("wavlm"),lor=o(" \u2014 "),ZX=a("a"),ior=o("WavLMForXVector"),dor=o(" (WavLM model)"),cor=l(),tT=a("p"),mor=o("The model is set in evaluation mode by default using "),nue=a("code"),gor=o("model.eval()"),hor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sue=a("code"),por=o("model.train()"),_or=l(),F(aT.$$.fragment),Xqe=l(),Cd=a("h2"),nT=a("a"),lue=a("span"),F(ML.$$.fragment),uor=l(),iue=a("span"),bor=o("AutoModelForMaskedImageModeling"),zqe=l(),Wo=a("div"),F(EL.$$.fragment),vor=l(),wd=a("p"),For=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),ez=a("a"),Tor=o("from_pretrained()"),Mor=o(" class method or the "),oz=a("a"),Eor=o("from_config()"),Cor=o(` class
method.`),wor=l(),CL=a("p"),Aor=o("This class cannot be instantiated directly using "),due=a("code"),yor=o("__init__()"),Lor=o(" (throws an error)."),xor=l(),Mt=a("div"),F(wL.$$.fragment),$or=l(),cue=a("p"),kor=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Sor=l(),Ad=a("p"),Ror=o(`Note:
Loading a model from its configuration file does `),fue=a("strong"),Por=o("not"),Bor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rz=a("a"),Ior=o("from_pretrained()"),qor=o(" to load the model weights."),Nor=l(),F(sT.$$.fragment),jor=l(),po=a("div"),F(AL.$$.fragment),Dor=l(),mue=a("p"),Gor=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Oor=l(),Wa=a("p"),Vor=o("The model class to instantiate is selected based on the "),gue=a("code"),Xor=o("model_type"),zor=o(` property of the config object (either
passed as an argument or loaded from `),hue=a("code"),Wor=o("pretrained_model_name_or_path"),Qor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pue=a("code"),Hor=o("pretrained_model_name_or_path"),Uor=o(":"),Jor=l(),yd=a("ul"),lT=a("li"),_ue=a("strong"),Yor=o("deit"),Kor=o(" \u2014 "),tz=a("a"),Zor=o("DeiTForMaskedImageModeling"),err=o(" (DeiT model)"),orr=l(),iT=a("li"),uue=a("strong"),rrr=o("swin"),trr=o(" \u2014 "),az=a("a"),arr=o("SwinForMaskedImageModeling"),nrr=o(" (Swin model)"),srr=l(),dT=a("li"),bue=a("strong"),lrr=o("vit"),irr=o(" \u2014 "),nz=a("a"),drr=o("ViTForMaskedImageModeling"),crr=o(" (ViT model)"),frr=l(),cT=a("p"),mrr=o("The model is set in evaluation mode by default using "),vue=a("code"),grr=o("model.eval()"),hrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fue=a("code"),prr=o("model.train()"),_rr=l(),F(fT.$$.fragment),Wqe=l(),Ld=a("h2"),mT=a("a"),Tue=a("span"),F(yL.$$.fragment),urr=l(),Mue=a("span"),brr=o("AutoModelForObjectDetection"),Qqe=l(),Qo=a("div"),F(LL.$$.fragment),vrr=l(),xd=a("p"),Frr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),sz=a("a"),Trr=o("from_pretrained()"),Mrr=o(" class method or the "),lz=a("a"),Err=o("from_config()"),Crr=o(` class
method.`),wrr=l(),xL=a("p"),Arr=o("This class cannot be instantiated directly using "),Eue=a("code"),yrr=o("__init__()"),Lrr=o(" (throws an error)."),xrr=l(),Et=a("div"),F($L.$$.fragment),$rr=l(),Cue=a("p"),krr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Srr=l(),$d=a("p"),Rrr=o(`Note:
Loading a model from its configuration file does `),wue=a("strong"),Prr=o("not"),Brr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=a("a"),Irr=o("from_pretrained()"),qrr=o(" to load the model weights."),Nrr=l(),F(gT.$$.fragment),jrr=l(),_o=a("div"),F(kL.$$.fragment),Drr=l(),Aue=a("p"),Grr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Orr=l(),Qa=a("p"),Vrr=o("The model class to instantiate is selected based on the "),yue=a("code"),Xrr=o("model_type"),zrr=o(` property of the config object (either
passed as an argument or loaded from `),Lue=a("code"),Wrr=o("pretrained_model_name_or_path"),Qrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xue=a("code"),Hrr=o("pretrained_model_name_or_path"),Urr=o(":"),Jrr=l(),SL=a("ul"),hT=a("li"),$ue=a("strong"),Yrr=o("detr"),Krr=o(" \u2014 "),dz=a("a"),Zrr=o("DetrForObjectDetection"),etr=o(" (DETR model)"),otr=l(),pT=a("li"),kue=a("strong"),rtr=o("yolos"),ttr=o(" \u2014 "),cz=a("a"),atr=o("YolosForObjectDetection"),ntr=o(" (YOLOS model)"),str=l(),_T=a("p"),ltr=o("The model is set in evaluation mode by default using "),Sue=a("code"),itr=o("model.eval()"),dtr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rue=a("code"),ctr=o("model.train()"),ftr=l(),F(uT.$$.fragment),Hqe=l(),kd=a("h2"),bT=a("a"),Pue=a("span"),F(RL.$$.fragment),mtr=l(),Bue=a("span"),gtr=o("AutoModelForImageSegmentation"),Uqe=l(),Ho=a("div"),F(PL.$$.fragment),htr=l(),Sd=a("p"),ptr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),fz=a("a"),_tr=o("from_pretrained()"),utr=o(" class method or the "),mz=a("a"),btr=o("from_config()"),vtr=o(` class
method.`),Ftr=l(),BL=a("p"),Ttr=o("This class cannot be instantiated directly using "),Iue=a("code"),Mtr=o("__init__()"),Etr=o(" (throws an error)."),Ctr=l(),Ct=a("div"),F(IL.$$.fragment),wtr=l(),que=a("p"),Atr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),ytr=l(),Rd=a("p"),Ltr=o(`Note:
Loading a model from its configuration file does `),Nue=a("strong"),xtr=o("not"),$tr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gz=a("a"),ktr=o("from_pretrained()"),Str=o(" to load the model weights."),Rtr=l(),F(vT.$$.fragment),Ptr=l(),uo=a("div"),F(qL.$$.fragment),Btr=l(),jue=a("p"),Itr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),qtr=l(),Ha=a("p"),Ntr=o("The model class to instantiate is selected based on the "),Due=a("code"),jtr=o("model_type"),Dtr=o(` property of the config object (either
passed as an argument or loaded from `),Gue=a("code"),Gtr=o("pretrained_model_name_or_path"),Otr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oue=a("code"),Vtr=o("pretrained_model_name_or_path"),Xtr=o(":"),ztr=l(),Vue=a("ul"),FT=a("li"),Xue=a("strong"),Wtr=o("detr"),Qtr=o(" \u2014 "),hz=a("a"),Htr=o("DetrForSegmentation"),Utr=o(" (DETR model)"),Jtr=l(),TT=a("p"),Ytr=o("The model is set in evaluation mode by default using "),zue=a("code"),Ktr=o("model.eval()"),Ztr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wue=a("code"),ear=o("model.train()"),oar=l(),F(MT.$$.fragment),Jqe=l(),Pd=a("h2"),ET=a("a"),Que=a("span"),F(NL.$$.fragment),rar=l(),Hue=a("span"),tar=o("AutoModelForSemanticSegmentation"),Yqe=l(),Uo=a("div"),F(jL.$$.fragment),aar=l(),Bd=a("p"),nar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pz=a("a"),sar=o("from_pretrained()"),lar=o(" class method or the "),_z=a("a"),iar=o("from_config()"),dar=o(` class
method.`),car=l(),DL=a("p"),far=o("This class cannot be instantiated directly using "),Uue=a("code"),mar=o("__init__()"),gar=o(" (throws an error)."),har=l(),wt=a("div"),F(GL.$$.fragment),par=l(),Jue=a("p"),_ar=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),uar=l(),Id=a("p"),bar=o(`Note:
Loading a model from its configuration file does `),Yue=a("strong"),Far=o("not"),Tar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uz=a("a"),Mar=o("from_pretrained()"),Ear=o(" to load the model weights."),Car=l(),F(CT.$$.fragment),war=l(),bo=a("div"),F(OL.$$.fragment),Aar=l(),Kue=a("p"),yar=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Lar=l(),Ua=a("p"),xar=o("The model class to instantiate is selected based on the "),Zue=a("code"),$ar=o("model_type"),kar=o(` property of the config object (either
passed as an argument or loaded from `),e2e=a("code"),Sar=o("pretrained_model_name_or_path"),Rar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=a("code"),Par=o("pretrained_model_name_or_path"),Bar=o(":"),Iar=l(),Ja=a("ul"),wT=a("li"),r2e=a("strong"),qar=o("beit"),Nar=o(" \u2014 "),bz=a("a"),jar=o("BeitForSemanticSegmentation"),Dar=o(" (BEiT model)"),Gar=l(),AT=a("li"),t2e=a("strong"),Oar=o("data2vec-vision"),Var=o(" \u2014 "),vz=a("a"),Xar=o("Data2VecVisionForSemanticSegmentation"),zar=o(" (Data2VecVision model)"),War=l(),yT=a("li"),a2e=a("strong"),Qar=o("dpt"),Har=o(" \u2014 "),Fz=a("a"),Uar=o("DPTForSemanticSegmentation"),Jar=o(" (DPT model)"),Yar=l(),LT=a("li"),n2e=a("strong"),Kar=o("segformer"),Zar=o(" \u2014 "),Tz=a("a"),enr=o("SegformerForSemanticSegmentation"),onr=o(" (SegFormer model)"),rnr=l(),xT=a("p"),tnr=o("The model is set in evaluation mode by default using "),s2e=a("code"),anr=o("model.eval()"),nnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l2e=a("code"),snr=o("model.train()"),lnr=l(),F($T.$$.fragment),Kqe=l(),qd=a("h2"),kT=a("a"),i2e=a("span"),F(VL.$$.fragment),inr=l(),d2e=a("span"),dnr=o("AutoModelForInstanceSegmentation"),Zqe=l(),Jo=a("div"),F(XL.$$.fragment),cnr=l(),Nd=a("p"),fnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Mz=a("a"),mnr=o("from_pretrained()"),gnr=o(" class method or the "),Ez=a("a"),hnr=o("from_config()"),pnr=o(` class
method.`),_nr=l(),zL=a("p"),unr=o("This class cannot be instantiated directly using "),c2e=a("code"),bnr=o("__init__()"),vnr=o(" (throws an error)."),Fnr=l(),At=a("div"),F(WL.$$.fragment),Tnr=l(),f2e=a("p"),Mnr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Enr=l(),jd=a("p"),Cnr=o(`Note:
Loading a model from its configuration file does `),m2e=a("strong"),wnr=o("not"),Anr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cz=a("a"),ynr=o("from_pretrained()"),Lnr=o(" to load the model weights."),xnr=l(),F(ST.$$.fragment),$nr=l(),vo=a("div"),F(QL.$$.fragment),knr=l(),g2e=a("p"),Snr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Rnr=l(),Ya=a("p"),Pnr=o("The model class to instantiate is selected based on the "),h2e=a("code"),Bnr=o("model_type"),Inr=o(` property of the config object (either
passed as an argument or loaded from `),p2e=a("code"),qnr=o("pretrained_model_name_or_path"),Nnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_2e=a("code"),jnr=o("pretrained_model_name_or_path"),Dnr=o(":"),Gnr=l(),u2e=a("ul"),RT=a("li"),b2e=a("strong"),Onr=o("maskformer"),Vnr=o(" \u2014 "),wz=a("a"),Xnr=o("MaskFormerForInstanceSegmentation"),znr=o(" (MaskFormer model)"),Wnr=l(),PT=a("p"),Qnr=o("The model is set in evaluation mode by default using "),v2e=a("code"),Hnr=o("model.eval()"),Unr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F2e=a("code"),Jnr=o("model.train()"),Ynr=l(),F(BT.$$.fragment),eNe=l(),Dd=a("h2"),IT=a("a"),T2e=a("span"),F(HL.$$.fragment),Knr=l(),M2e=a("span"),Znr=o("TFAutoModel"),oNe=l(),Yo=a("div"),F(UL.$$.fragment),esr=l(),Gd=a("p"),osr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Az=a("a"),rsr=o("from_pretrained()"),tsr=o(" class method or the "),yz=a("a"),asr=o("from_config()"),nsr=o(` class
method.`),ssr=l(),JL=a("p"),lsr=o("This class cannot be instantiated directly using "),E2e=a("code"),isr=o("__init__()"),dsr=o(" (throws an error)."),csr=l(),yt=a("div"),F(YL.$$.fragment),fsr=l(),C2e=a("p"),msr=o("Instantiates one of the base model classes of the library from a configuration."),gsr=l(),Od=a("p"),hsr=o(`Note:
Loading a model from its configuration file does `),w2e=a("strong"),psr=o("not"),_sr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=a("a"),usr=o("from_pretrained()"),bsr=o(" to load the model weights."),vsr=l(),F(qT.$$.fragment),Fsr=l(),wr=a("div"),F(KL.$$.fragment),Tsr=l(),A2e=a("p"),Msr=o("Instantiate one of the base model classes of the library from a pretrained model."),Esr=l(),Ka=a("p"),Csr=o("The model class to instantiate is selected based on the "),y2e=a("code"),wsr=o("model_type"),Asr=o(` property of the config object (either
passed as an argument or loaded from `),L2e=a("code"),ysr=o("pretrained_model_name_or_path"),Lsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x2e=a("code"),xsr=o("pretrained_model_name_or_path"),$sr=o(":"),ksr=l(),q=a("ul"),NT=a("li"),$2e=a("strong"),Ssr=o("albert"),Rsr=o(" \u2014 "),xz=a("a"),Psr=o("TFAlbertModel"),Bsr=o(" (ALBERT model)"),Isr=l(),jT=a("li"),k2e=a("strong"),qsr=o("bart"),Nsr=o(" \u2014 "),$z=a("a"),jsr=o("TFBartModel"),Dsr=o(" (BART model)"),Gsr=l(),DT=a("li"),S2e=a("strong"),Osr=o("bert"),Vsr=o(" \u2014 "),kz=a("a"),Xsr=o("TFBertModel"),zsr=o(" (BERT model)"),Wsr=l(),GT=a("li"),R2e=a("strong"),Qsr=o("blenderbot"),Hsr=o(" \u2014 "),Sz=a("a"),Usr=o("TFBlenderbotModel"),Jsr=o(" (Blenderbot model)"),Ysr=l(),OT=a("li"),P2e=a("strong"),Ksr=o("blenderbot-small"),Zsr=o(" \u2014 "),Rz=a("a"),elr=o("TFBlenderbotSmallModel"),olr=o(" (BlenderbotSmall model)"),rlr=l(),VT=a("li"),B2e=a("strong"),tlr=o("camembert"),alr=o(" \u2014 "),Pz=a("a"),nlr=o("TFCamembertModel"),slr=o(" (CamemBERT model)"),llr=l(),XT=a("li"),I2e=a("strong"),ilr=o("clip"),dlr=o(" \u2014 "),Bz=a("a"),clr=o("TFCLIPModel"),flr=o(" (CLIP model)"),mlr=l(),zT=a("li"),q2e=a("strong"),glr=o("convbert"),hlr=o(" \u2014 "),Iz=a("a"),plr=o("TFConvBertModel"),_lr=o(" (ConvBERT model)"),ulr=l(),WT=a("li"),N2e=a("strong"),blr=o("convnext"),vlr=o(" \u2014 "),qz=a("a"),Flr=o("TFConvNextModel"),Tlr=o(" (ConvNext model)"),Mlr=l(),QT=a("li"),j2e=a("strong"),Elr=o("ctrl"),Clr=o(" \u2014 "),Nz=a("a"),wlr=o("TFCTRLModel"),Alr=o(" (CTRL model)"),ylr=l(),HT=a("li"),D2e=a("strong"),Llr=o("data2vec-vision"),xlr=o(" \u2014 "),jz=a("a"),$lr=o("TFData2VecVisionModel"),klr=o(" (Data2VecVision model)"),Slr=l(),UT=a("li"),G2e=a("strong"),Rlr=o("deberta"),Plr=o(" \u2014 "),Dz=a("a"),Blr=o("TFDebertaModel"),Ilr=o(" (DeBERTa model)"),qlr=l(),JT=a("li"),O2e=a("strong"),Nlr=o("deberta-v2"),jlr=o(" \u2014 "),Gz=a("a"),Dlr=o("TFDebertaV2Model"),Glr=o(" (DeBERTa-v2 model)"),Olr=l(),YT=a("li"),V2e=a("strong"),Vlr=o("distilbert"),Xlr=o(" \u2014 "),Oz=a("a"),zlr=o("TFDistilBertModel"),Wlr=o(" (DistilBERT model)"),Qlr=l(),KT=a("li"),X2e=a("strong"),Hlr=o("dpr"),Ulr=o(" \u2014 "),Vz=a("a"),Jlr=o("TFDPRQuestionEncoder"),Ylr=o(" (DPR model)"),Klr=l(),ZT=a("li"),z2e=a("strong"),Zlr=o("electra"),eir=o(" \u2014 "),Xz=a("a"),oir=o("TFElectraModel"),rir=o(" (ELECTRA model)"),tir=l(),eM=a("li"),W2e=a("strong"),air=o("flaubert"),nir=o(" \u2014 "),zz=a("a"),sir=o("TFFlaubertModel"),lir=o(" (FlauBERT model)"),iir=l(),Bs=a("li"),Q2e=a("strong"),dir=o("funnel"),cir=o(" \u2014 "),Wz=a("a"),fir=o("TFFunnelModel"),mir=o(" or "),Qz=a("a"),gir=o("TFFunnelBaseModel"),hir=o(" (Funnel Transformer model)"),pir=l(),oM=a("li"),H2e=a("strong"),_ir=o("gpt2"),uir=o(" \u2014 "),Hz=a("a"),bir=o("TFGPT2Model"),vir=o(" (OpenAI GPT-2 model)"),Fir=l(),rM=a("li"),U2e=a("strong"),Tir=o("gptj"),Mir=o(" \u2014 "),Uz=a("a"),Eir=o("TFGPTJModel"),Cir=o(" (GPT-J model)"),wir=l(),tM=a("li"),J2e=a("strong"),Air=o("hubert"),yir=o(" \u2014 "),Jz=a("a"),Lir=o("TFHubertModel"),xir=o(" (Hubert model)"),$ir=l(),aM=a("li"),Y2e=a("strong"),kir=o("layoutlm"),Sir=o(" \u2014 "),Yz=a("a"),Rir=o("TFLayoutLMModel"),Pir=o(" (LayoutLM model)"),Bir=l(),nM=a("li"),K2e=a("strong"),Iir=o("led"),qir=o(" \u2014 "),Kz=a("a"),Nir=o("TFLEDModel"),jir=o(" (LED model)"),Dir=l(),sM=a("li"),Z2e=a("strong"),Gir=o("longformer"),Oir=o(" \u2014 "),Zz=a("a"),Vir=o("TFLongformerModel"),Xir=o(" (Longformer model)"),zir=l(),lM=a("li"),e1e=a("strong"),Wir=o("lxmert"),Qir=o(" \u2014 "),eW=a("a"),Hir=o("TFLxmertModel"),Uir=o(" (LXMERT model)"),Jir=l(),iM=a("li"),o1e=a("strong"),Yir=o("marian"),Kir=o(" \u2014 "),oW=a("a"),Zir=o("TFMarianModel"),edr=o(" (Marian model)"),odr=l(),dM=a("li"),r1e=a("strong"),rdr=o("mbart"),tdr=o(" \u2014 "),rW=a("a"),adr=o("TFMBartModel"),ndr=o(" (mBART model)"),sdr=l(),cM=a("li"),t1e=a("strong"),ldr=o("mobilebert"),idr=o(" \u2014 "),tW=a("a"),ddr=o("TFMobileBertModel"),cdr=o(" (MobileBERT model)"),fdr=l(),fM=a("li"),a1e=a("strong"),mdr=o("mpnet"),gdr=o(" \u2014 "),aW=a("a"),hdr=o("TFMPNetModel"),pdr=o(" (MPNet model)"),_dr=l(),mM=a("li"),n1e=a("strong"),udr=o("mt5"),bdr=o(" \u2014 "),nW=a("a"),vdr=o("TFMT5Model"),Fdr=o(" (mT5 model)"),Tdr=l(),gM=a("li"),s1e=a("strong"),Mdr=o("openai-gpt"),Edr=o(" \u2014 "),sW=a("a"),Cdr=o("TFOpenAIGPTModel"),wdr=o(" (OpenAI GPT model)"),Adr=l(),hM=a("li"),l1e=a("strong"),ydr=o("opt"),Ldr=o(" \u2014 "),lW=a("a"),xdr=o("TFOPTModel"),$dr=o(" (OPT model)"),kdr=l(),pM=a("li"),i1e=a("strong"),Sdr=o("pegasus"),Rdr=o(" \u2014 "),iW=a("a"),Pdr=o("TFPegasusModel"),Bdr=o(" (Pegasus model)"),Idr=l(),_M=a("li"),d1e=a("strong"),qdr=o("rembert"),Ndr=o(" \u2014 "),dW=a("a"),jdr=o("TFRemBertModel"),Ddr=o(" (RemBERT model)"),Gdr=l(),uM=a("li"),c1e=a("strong"),Odr=o("roberta"),Vdr=o(" \u2014 "),cW=a("a"),Xdr=o("TFRobertaModel"),zdr=o(" (RoBERTa model)"),Wdr=l(),bM=a("li"),f1e=a("strong"),Qdr=o("roformer"),Hdr=o(" \u2014 "),fW=a("a"),Udr=o("TFRoFormerModel"),Jdr=o(" (RoFormer model)"),Ydr=l(),vM=a("li"),m1e=a("strong"),Kdr=o("speech_to_text"),Zdr=o(" \u2014 "),mW=a("a"),ecr=o("TFSpeech2TextModel"),ocr=o(" (Speech2Text model)"),rcr=l(),FM=a("li"),g1e=a("strong"),tcr=o("swin"),acr=o(" \u2014 "),gW=a("a"),ncr=o("TFSwinModel"),scr=o(" (Swin model)"),lcr=l(),TM=a("li"),h1e=a("strong"),icr=o("t5"),dcr=o(" \u2014 "),hW=a("a"),ccr=o("TFT5Model"),fcr=o(" (T5 model)"),mcr=l(),MM=a("li"),p1e=a("strong"),gcr=o("tapas"),hcr=o(" \u2014 "),pW=a("a"),pcr=o("TFTapasModel"),_cr=o(" (TAPAS model)"),ucr=l(),EM=a("li"),_1e=a("strong"),bcr=o("transfo-xl"),vcr=o(" \u2014 "),_W=a("a"),Fcr=o("TFTransfoXLModel"),Tcr=o(" (Transformer-XL model)"),Mcr=l(),CM=a("li"),u1e=a("strong"),Ecr=o("vit"),Ccr=o(" \u2014 "),uW=a("a"),wcr=o("TFViTModel"),Acr=o(" (ViT model)"),ycr=l(),wM=a("li"),b1e=a("strong"),Lcr=o("vit_mae"),xcr=o(" \u2014 "),bW=a("a"),$cr=o("TFViTMAEModel"),kcr=o(" (ViTMAE model)"),Scr=l(),AM=a("li"),v1e=a("strong"),Rcr=o("wav2vec2"),Pcr=o(" \u2014 "),vW=a("a"),Bcr=o("TFWav2Vec2Model"),Icr=o(" (Wav2Vec2 model)"),qcr=l(),yM=a("li"),F1e=a("strong"),Ncr=o("xlm"),jcr=o(" \u2014 "),FW=a("a"),Dcr=o("TFXLMModel"),Gcr=o(" (XLM model)"),Ocr=l(),LM=a("li"),T1e=a("strong"),Vcr=o("xlm-roberta"),Xcr=o(" \u2014 "),TW=a("a"),zcr=o("TFXLMRobertaModel"),Wcr=o(" (XLM-RoBERTa model)"),Qcr=l(),xM=a("li"),M1e=a("strong"),Hcr=o("xlnet"),Ucr=o(" \u2014 "),MW=a("a"),Jcr=o("TFXLNetModel"),Ycr=o(" (XLNet model)"),Kcr=l(),F($M.$$.fragment),rNe=l(),Vd=a("h2"),kM=a("a"),E1e=a("span"),F(ZL.$$.fragment),Zcr=l(),C1e=a("span"),efr=o("TFAutoModelForPreTraining"),tNe=l(),Ko=a("div"),F(e8.$$.fragment),ofr=l(),Xd=a("p"),rfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EW=a("a"),tfr=o("from_pretrained()"),afr=o(" class method or the "),CW=a("a"),nfr=o("from_config()"),sfr=o(` class
method.`),lfr=l(),o8=a("p"),ifr=o("This class cannot be instantiated directly using "),w1e=a("code"),dfr=o("__init__()"),cfr=o(" (throws an error)."),ffr=l(),Lt=a("div"),F(r8.$$.fragment),mfr=l(),A1e=a("p"),gfr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),hfr=l(),zd=a("p"),pfr=o(`Note:
Loading a model from its configuration file does `),y1e=a("strong"),_fr=o("not"),ufr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wW=a("a"),bfr=o("from_pretrained()"),vfr=o(" to load the model weights."),Ffr=l(),F(SM.$$.fragment),Tfr=l(),Ar=a("div"),F(t8.$$.fragment),Mfr=l(),L1e=a("p"),Efr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Cfr=l(),Za=a("p"),wfr=o("The model class to instantiate is selected based on the "),x1e=a("code"),Afr=o("model_type"),yfr=o(` property of the config object (either
passed as an argument or loaded from `),$1e=a("code"),Lfr=o("pretrained_model_name_or_path"),xfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k1e=a("code"),$fr=o("pretrained_model_name_or_path"),kfr=o(":"),Sfr=l(),se=a("ul"),RM=a("li"),S1e=a("strong"),Rfr=o("albert"),Pfr=o(" \u2014 "),AW=a("a"),Bfr=o("TFAlbertForPreTraining"),Ifr=o(" (ALBERT model)"),qfr=l(),PM=a("li"),R1e=a("strong"),Nfr=o("bart"),jfr=o(" \u2014 "),yW=a("a"),Dfr=o("TFBartForConditionalGeneration"),Gfr=o(" (BART model)"),Ofr=l(),BM=a("li"),P1e=a("strong"),Vfr=o("bert"),Xfr=o(" \u2014 "),LW=a("a"),zfr=o("TFBertForPreTraining"),Wfr=o(" (BERT model)"),Qfr=l(),IM=a("li"),B1e=a("strong"),Hfr=o("camembert"),Ufr=o(" \u2014 "),xW=a("a"),Jfr=o("TFCamembertForMaskedLM"),Yfr=o(" (CamemBERT model)"),Kfr=l(),qM=a("li"),I1e=a("strong"),Zfr=o("ctrl"),emr=o(" \u2014 "),$W=a("a"),omr=o("TFCTRLLMHeadModel"),rmr=o(" (CTRL model)"),tmr=l(),NM=a("li"),q1e=a("strong"),amr=o("distilbert"),nmr=o(" \u2014 "),kW=a("a"),smr=o("TFDistilBertForMaskedLM"),lmr=o(" (DistilBERT model)"),imr=l(),jM=a("li"),N1e=a("strong"),dmr=o("electra"),cmr=o(" \u2014 "),SW=a("a"),fmr=o("TFElectraForPreTraining"),mmr=o(" (ELECTRA model)"),gmr=l(),DM=a("li"),j1e=a("strong"),hmr=o("flaubert"),pmr=o(" \u2014 "),RW=a("a"),_mr=o("TFFlaubertWithLMHeadModel"),umr=o(" (FlauBERT model)"),bmr=l(),GM=a("li"),D1e=a("strong"),vmr=o("funnel"),Fmr=o(" \u2014 "),PW=a("a"),Tmr=o("TFFunnelForPreTraining"),Mmr=o(" (Funnel Transformer model)"),Emr=l(),OM=a("li"),G1e=a("strong"),Cmr=o("gpt2"),wmr=o(" \u2014 "),BW=a("a"),Amr=o("TFGPT2LMHeadModel"),ymr=o(" (OpenAI GPT-2 model)"),Lmr=l(),VM=a("li"),O1e=a("strong"),xmr=o("layoutlm"),$mr=o(" \u2014 "),IW=a("a"),kmr=o("TFLayoutLMForMaskedLM"),Smr=o(" (LayoutLM model)"),Rmr=l(),XM=a("li"),V1e=a("strong"),Pmr=o("lxmert"),Bmr=o(" \u2014 "),qW=a("a"),Imr=o("TFLxmertForPreTraining"),qmr=o(" (LXMERT model)"),Nmr=l(),zM=a("li"),X1e=a("strong"),jmr=o("mobilebert"),Dmr=o(" \u2014 "),NW=a("a"),Gmr=o("TFMobileBertForPreTraining"),Omr=o(" (MobileBERT model)"),Vmr=l(),WM=a("li"),z1e=a("strong"),Xmr=o("mpnet"),zmr=o(" \u2014 "),jW=a("a"),Wmr=o("TFMPNetForMaskedLM"),Qmr=o(" (MPNet model)"),Hmr=l(),QM=a("li"),W1e=a("strong"),Umr=o("openai-gpt"),Jmr=o(" \u2014 "),DW=a("a"),Ymr=o("TFOpenAIGPTLMHeadModel"),Kmr=o(" (OpenAI GPT model)"),Zmr=l(),HM=a("li"),Q1e=a("strong"),egr=o("roberta"),ogr=o(" \u2014 "),GW=a("a"),rgr=o("TFRobertaForMaskedLM"),tgr=o(" (RoBERTa model)"),agr=l(),UM=a("li"),H1e=a("strong"),ngr=o("t5"),sgr=o(" \u2014 "),OW=a("a"),lgr=o("TFT5ForConditionalGeneration"),igr=o(" (T5 model)"),dgr=l(),JM=a("li"),U1e=a("strong"),cgr=o("tapas"),fgr=o(" \u2014 "),VW=a("a"),mgr=o("TFTapasForMaskedLM"),ggr=o(" (TAPAS model)"),hgr=l(),YM=a("li"),J1e=a("strong"),pgr=o("transfo-xl"),_gr=o(" \u2014 "),XW=a("a"),ugr=o("TFTransfoXLLMHeadModel"),bgr=o(" (Transformer-XL model)"),vgr=l(),KM=a("li"),Y1e=a("strong"),Fgr=o("vit_mae"),Tgr=o(" \u2014 "),zW=a("a"),Mgr=o("TFViTMAEForPreTraining"),Egr=o(" (ViTMAE model)"),Cgr=l(),ZM=a("li"),K1e=a("strong"),wgr=o("xlm"),Agr=o(" \u2014 "),WW=a("a"),ygr=o("TFXLMWithLMHeadModel"),Lgr=o(" (XLM model)"),xgr=l(),e4=a("li"),Z1e=a("strong"),$gr=o("xlm-roberta"),kgr=o(" \u2014 "),QW=a("a"),Sgr=o("TFXLMRobertaForMaskedLM"),Rgr=o(" (XLM-RoBERTa model)"),Pgr=l(),o4=a("li"),e7e=a("strong"),Bgr=o("xlnet"),Igr=o(" \u2014 "),HW=a("a"),qgr=o("TFXLNetLMHeadModel"),Ngr=o(" (XLNet model)"),jgr=l(),F(r4.$$.fragment),aNe=l(),Wd=a("h2"),t4=a("a"),o7e=a("span"),F(a8.$$.fragment),Dgr=l(),r7e=a("span"),Ggr=o("TFAutoModelForCausalLM"),nNe=l(),Zo=a("div"),F(n8.$$.fragment),Ogr=l(),Qd=a("p"),Vgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),UW=a("a"),Xgr=o("from_pretrained()"),zgr=o(" class method or the "),JW=a("a"),Wgr=o("from_config()"),Qgr=o(` class
method.`),Hgr=l(),s8=a("p"),Ugr=o("This class cannot be instantiated directly using "),t7e=a("code"),Jgr=o("__init__()"),Ygr=o(" (throws an error)."),Kgr=l(),xt=a("div"),F(l8.$$.fragment),Zgr=l(),a7e=a("p"),ehr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ohr=l(),Hd=a("p"),rhr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),thr=o("not"),ahr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),nhr=o("from_pretrained()"),shr=o(" to load the model weights."),lhr=l(),F(a4.$$.fragment),ihr=l(),yr=a("div"),F(i8.$$.fragment),dhr=l(),s7e=a("p"),chr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),fhr=l(),en=a("p"),mhr=o("The model class to instantiate is selected based on the "),l7e=a("code"),ghr=o("model_type"),hhr=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),phr=o("pretrained_model_name_or_path"),_hr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),uhr=o("pretrained_model_name_or_path"),bhr=o(":"),vhr=l(),Te=a("ul"),n4=a("li"),c7e=a("strong"),Fhr=o("bert"),Thr=o(" \u2014 "),KW=a("a"),Mhr=o("TFBertLMHeadModel"),Ehr=o(" (BERT model)"),Chr=l(),s4=a("li"),f7e=a("strong"),whr=o("camembert"),Ahr=o(" \u2014 "),ZW=a("a"),yhr=o("TFCamembertForCausalLM"),Lhr=o(" (CamemBERT model)"),xhr=l(),l4=a("li"),m7e=a("strong"),$hr=o("ctrl"),khr=o(" \u2014 "),eQ=a("a"),Shr=o("TFCTRLLMHeadModel"),Rhr=o(" (CTRL model)"),Phr=l(),i4=a("li"),g7e=a("strong"),Bhr=o("gpt2"),Ihr=o(" \u2014 "),oQ=a("a"),qhr=o("TFGPT2LMHeadModel"),Nhr=o(" (OpenAI GPT-2 model)"),jhr=l(),d4=a("li"),h7e=a("strong"),Dhr=o("gptj"),Ghr=o(" \u2014 "),rQ=a("a"),Ohr=o("TFGPTJForCausalLM"),Vhr=o(" (GPT-J model)"),Xhr=l(),c4=a("li"),p7e=a("strong"),zhr=o("openai-gpt"),Whr=o(" \u2014 "),tQ=a("a"),Qhr=o("TFOpenAIGPTLMHeadModel"),Hhr=o(" (OpenAI GPT model)"),Uhr=l(),f4=a("li"),_7e=a("strong"),Jhr=o("rembert"),Yhr=o(" \u2014 "),aQ=a("a"),Khr=o("TFRemBertForCausalLM"),Zhr=o(" (RemBERT model)"),epr=l(),m4=a("li"),u7e=a("strong"),opr=o("roberta"),rpr=o(" \u2014 "),nQ=a("a"),tpr=o("TFRobertaForCausalLM"),apr=o(" (RoBERTa model)"),npr=l(),g4=a("li"),b7e=a("strong"),spr=o("roformer"),lpr=o(" \u2014 "),sQ=a("a"),ipr=o("TFRoFormerForCausalLM"),dpr=o(" (RoFormer model)"),cpr=l(),h4=a("li"),v7e=a("strong"),fpr=o("transfo-xl"),mpr=o(" \u2014 "),lQ=a("a"),gpr=o("TFTransfoXLLMHeadModel"),hpr=o(" (Transformer-XL model)"),ppr=l(),p4=a("li"),F7e=a("strong"),_pr=o("xlm"),upr=o(" \u2014 "),iQ=a("a"),bpr=o("TFXLMWithLMHeadModel"),vpr=o(" (XLM model)"),Fpr=l(),_4=a("li"),T7e=a("strong"),Tpr=o("xlnet"),Mpr=o(" \u2014 "),dQ=a("a"),Epr=o("TFXLNetLMHeadModel"),Cpr=o(" (XLNet model)"),wpr=l(),F(u4.$$.fragment),sNe=l(),Ud=a("h2"),b4=a("a"),M7e=a("span"),F(d8.$$.fragment),Apr=l(),E7e=a("span"),ypr=o("TFAutoModelForImageClassification"),lNe=l(),er=a("div"),F(c8.$$.fragment),Lpr=l(),Jd=a("p"),xpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),cQ=a("a"),$pr=o("from_pretrained()"),kpr=o(" class method or the "),fQ=a("a"),Spr=o("from_config()"),Rpr=o(` class
method.`),Ppr=l(),f8=a("p"),Bpr=o("This class cannot be instantiated directly using "),C7e=a("code"),Ipr=o("__init__()"),qpr=o(" (throws an error)."),Npr=l(),$t=a("div"),F(m8.$$.fragment),jpr=l(),w7e=a("p"),Dpr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Gpr=l(),Yd=a("p"),Opr=o(`Note:
Loading a model from its configuration file does `),A7e=a("strong"),Vpr=o("not"),Xpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mQ=a("a"),zpr=o("from_pretrained()"),Wpr=o(" to load the model weights."),Qpr=l(),F(v4.$$.fragment),Hpr=l(),Lr=a("div"),F(g8.$$.fragment),Upr=l(),y7e=a("p"),Jpr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ypr=l(),on=a("p"),Kpr=o("The model class to instantiate is selected based on the "),L7e=a("code"),Zpr=o("model_type"),e_r=o(` property of the config object (either
passed as an argument or loaded from `),x7e=a("code"),o_r=o("pretrained_model_name_or_path"),r_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$7e=a("code"),t_r=o("pretrained_model_name_or_path"),a_r=o(":"),n_r=l(),rn=a("ul"),F4=a("li"),k7e=a("strong"),s_r=o("convnext"),l_r=o(" \u2014 "),gQ=a("a"),i_r=o("TFConvNextForImageClassification"),d_r=o(" (ConvNext model)"),c_r=l(),T4=a("li"),S7e=a("strong"),f_r=o("data2vec-vision"),m_r=o(" \u2014 "),hQ=a("a"),g_r=o("TFData2VecVisionForImageClassification"),h_r=o(" (Data2VecVision model)"),p_r=l(),M4=a("li"),R7e=a("strong"),__r=o("swin"),u_r=o(" \u2014 "),pQ=a("a"),b_r=o("TFSwinForImageClassification"),v_r=o(" (Swin model)"),F_r=l(),E4=a("li"),P7e=a("strong"),T_r=o("vit"),M_r=o(" \u2014 "),_Q=a("a"),E_r=o("TFViTForImageClassification"),C_r=o(" (ViT model)"),w_r=l(),F(C4.$$.fragment),iNe=l(),Kd=a("h2"),w4=a("a"),B7e=a("span"),F(h8.$$.fragment),A_r=l(),I7e=a("span"),y_r=o("TFAutoModelForMaskedLM"),dNe=l(),or=a("div"),F(p8.$$.fragment),L_r=l(),Zd=a("p"),x_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uQ=a("a"),$_r=o("from_pretrained()"),k_r=o(" class method or the "),bQ=a("a"),S_r=o("from_config()"),R_r=o(` class
method.`),P_r=l(),_8=a("p"),B_r=o("This class cannot be instantiated directly using "),q7e=a("code"),I_r=o("__init__()"),q_r=o(" (throws an error)."),N_r=l(),kt=a("div"),F(u8.$$.fragment),j_r=l(),N7e=a("p"),D_r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),G_r=l(),ec=a("p"),O_r=o(`Note:
Loading a model from its configuration file does `),j7e=a("strong"),V_r=o("not"),X_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vQ=a("a"),z_r=o("from_pretrained()"),W_r=o(" to load the model weights."),Q_r=l(),F(A4.$$.fragment),H_r=l(),xr=a("div"),F(b8.$$.fragment),U_r=l(),D7e=a("p"),J_r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Y_r=l(),tn=a("p"),K_r=o("The model class to instantiate is selected based on the "),G7e=a("code"),Z_r=o("model_type"),eur=o(` property of the config object (either
passed as an argument or loaded from `),O7e=a("code"),our=o("pretrained_model_name_or_path"),rur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V7e=a("code"),tur=o("pretrained_model_name_or_path"),aur=o(":"),nur=l(),ie=a("ul"),y4=a("li"),X7e=a("strong"),sur=o("albert"),lur=o(" \u2014 "),FQ=a("a"),iur=o("TFAlbertForMaskedLM"),dur=o(" (ALBERT model)"),cur=l(),L4=a("li"),z7e=a("strong"),fur=o("bert"),mur=o(" \u2014 "),TQ=a("a"),gur=o("TFBertForMaskedLM"),hur=o(" (BERT model)"),pur=l(),x4=a("li"),W7e=a("strong"),_ur=o("camembert"),uur=o(" \u2014 "),MQ=a("a"),bur=o("TFCamembertForMaskedLM"),vur=o(" (CamemBERT model)"),Fur=l(),$4=a("li"),Q7e=a("strong"),Tur=o("convbert"),Mur=o(" \u2014 "),EQ=a("a"),Eur=o("TFConvBertForMaskedLM"),Cur=o(" (ConvBERT model)"),wur=l(),k4=a("li"),H7e=a("strong"),Aur=o("deberta"),yur=o(" \u2014 "),CQ=a("a"),Lur=o("TFDebertaForMaskedLM"),xur=o(" (DeBERTa model)"),$ur=l(),S4=a("li"),U7e=a("strong"),kur=o("deberta-v2"),Sur=o(" \u2014 "),wQ=a("a"),Rur=o("TFDebertaV2ForMaskedLM"),Pur=o(" (DeBERTa-v2 model)"),Bur=l(),R4=a("li"),J7e=a("strong"),Iur=o("distilbert"),qur=o(" \u2014 "),AQ=a("a"),Nur=o("TFDistilBertForMaskedLM"),jur=o(" (DistilBERT model)"),Dur=l(),P4=a("li"),Y7e=a("strong"),Gur=o("electra"),Our=o(" \u2014 "),yQ=a("a"),Vur=o("TFElectraForMaskedLM"),Xur=o(" (ELECTRA model)"),zur=l(),B4=a("li"),K7e=a("strong"),Wur=o("flaubert"),Qur=o(" \u2014 "),LQ=a("a"),Hur=o("TFFlaubertWithLMHeadModel"),Uur=o(" (FlauBERT model)"),Jur=l(),I4=a("li"),Z7e=a("strong"),Yur=o("funnel"),Kur=o(" \u2014 "),xQ=a("a"),Zur=o("TFFunnelForMaskedLM"),e2r=o(" (Funnel Transformer model)"),o2r=l(),q4=a("li"),ebe=a("strong"),r2r=o("layoutlm"),t2r=o(" \u2014 "),$Q=a("a"),a2r=o("TFLayoutLMForMaskedLM"),n2r=o(" (LayoutLM model)"),s2r=l(),N4=a("li"),obe=a("strong"),l2r=o("longformer"),i2r=o(" \u2014 "),kQ=a("a"),d2r=o("TFLongformerForMaskedLM"),c2r=o(" (Longformer model)"),f2r=l(),j4=a("li"),rbe=a("strong"),m2r=o("mobilebert"),g2r=o(" \u2014 "),SQ=a("a"),h2r=o("TFMobileBertForMaskedLM"),p2r=o(" (MobileBERT model)"),_2r=l(),D4=a("li"),tbe=a("strong"),u2r=o("mpnet"),b2r=o(" \u2014 "),RQ=a("a"),v2r=o("TFMPNetForMaskedLM"),F2r=o(" (MPNet model)"),T2r=l(),G4=a("li"),abe=a("strong"),M2r=o("rembert"),E2r=o(" \u2014 "),PQ=a("a"),C2r=o("TFRemBertForMaskedLM"),w2r=o(" (RemBERT model)"),A2r=l(),O4=a("li"),nbe=a("strong"),y2r=o("roberta"),L2r=o(" \u2014 "),BQ=a("a"),x2r=o("TFRobertaForMaskedLM"),$2r=o(" (RoBERTa model)"),k2r=l(),V4=a("li"),sbe=a("strong"),S2r=o("roformer"),R2r=o(" \u2014 "),IQ=a("a"),P2r=o("TFRoFormerForMaskedLM"),B2r=o(" (RoFormer model)"),I2r=l(),X4=a("li"),lbe=a("strong"),q2r=o("tapas"),N2r=o(" \u2014 "),qQ=a("a"),j2r=o("TFTapasForMaskedLM"),D2r=o(" (TAPAS model)"),G2r=l(),z4=a("li"),ibe=a("strong"),O2r=o("xlm"),V2r=o(" \u2014 "),NQ=a("a"),X2r=o("TFXLMWithLMHeadModel"),z2r=o(" (XLM model)"),W2r=l(),W4=a("li"),dbe=a("strong"),Q2r=o("xlm-roberta"),H2r=o(" \u2014 "),jQ=a("a"),U2r=o("TFXLMRobertaForMaskedLM"),J2r=o(" (XLM-RoBERTa model)"),Y2r=l(),F(Q4.$$.fragment),cNe=l(),oc=a("h2"),H4=a("a"),cbe=a("span"),F(v8.$$.fragment),K2r=l(),fbe=a("span"),Z2r=o("TFAutoModelForSeq2SeqLM"),fNe=l(),rr=a("div"),F(F8.$$.fragment),e1r=l(),rc=a("p"),o1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),DQ=a("a"),r1r=o("from_pretrained()"),t1r=o(" class method or the "),GQ=a("a"),a1r=o("from_config()"),n1r=o(` class
method.`),s1r=l(),T8=a("p"),l1r=o("This class cannot be instantiated directly using "),mbe=a("code"),i1r=o("__init__()"),d1r=o(" (throws an error)."),c1r=l(),St=a("div"),F(M8.$$.fragment),f1r=l(),gbe=a("p"),m1r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),g1r=l(),tc=a("p"),h1r=o(`Note:
Loading a model from its configuration file does `),hbe=a("strong"),p1r=o("not"),_1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OQ=a("a"),u1r=o("from_pretrained()"),b1r=o(" to load the model weights."),v1r=l(),F(U4.$$.fragment),F1r=l(),$r=a("div"),F(E8.$$.fragment),T1r=l(),pbe=a("p"),M1r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),E1r=l(),an=a("p"),C1r=o("The model class to instantiate is selected based on the "),_be=a("code"),w1r=o("model_type"),A1r=o(` property of the config object (either
passed as an argument or loaded from `),ube=a("code"),y1r=o("pretrained_model_name_or_path"),L1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bbe=a("code"),x1r=o("pretrained_model_name_or_path"),$1r=o(":"),k1r=l(),ye=a("ul"),J4=a("li"),vbe=a("strong"),S1r=o("bart"),R1r=o(" \u2014 "),VQ=a("a"),P1r=o("TFBartForConditionalGeneration"),B1r=o(" (BART model)"),I1r=l(),Y4=a("li"),Fbe=a("strong"),q1r=o("blenderbot"),N1r=o(" \u2014 "),XQ=a("a"),j1r=o("TFBlenderbotForConditionalGeneration"),D1r=o(" (Blenderbot model)"),G1r=l(),K4=a("li"),Tbe=a("strong"),O1r=o("blenderbot-small"),V1r=o(" \u2014 "),zQ=a("a"),X1r=o("TFBlenderbotSmallForConditionalGeneration"),z1r=o(" (BlenderbotSmall model)"),W1r=l(),Z4=a("li"),Mbe=a("strong"),Q1r=o("encoder-decoder"),H1r=o(" \u2014 "),WQ=a("a"),U1r=o("TFEncoderDecoderModel"),J1r=o(" (Encoder decoder model)"),Y1r=l(),eE=a("li"),Ebe=a("strong"),K1r=o("led"),Z1r=o(" \u2014 "),QQ=a("a"),e7r=o("TFLEDForConditionalGeneration"),o7r=o(" (LED model)"),r7r=l(),oE=a("li"),Cbe=a("strong"),t7r=o("marian"),a7r=o(" \u2014 "),HQ=a("a"),n7r=o("TFMarianMTModel"),s7r=o(" (Marian model)"),l7r=l(),rE=a("li"),wbe=a("strong"),i7r=o("mbart"),d7r=o(" \u2014 "),UQ=a("a"),c7r=o("TFMBartForConditionalGeneration"),f7r=o(" (mBART model)"),m7r=l(),tE=a("li"),Abe=a("strong"),g7r=o("mt5"),h7r=o(" \u2014 "),JQ=a("a"),p7r=o("TFMT5ForConditionalGeneration"),_7r=o(" (mT5 model)"),u7r=l(),aE=a("li"),ybe=a("strong"),b7r=o("pegasus"),v7r=o(" \u2014 "),YQ=a("a"),F7r=o("TFPegasusForConditionalGeneration"),T7r=o(" (Pegasus model)"),M7r=l(),nE=a("li"),Lbe=a("strong"),E7r=o("t5"),C7r=o(" \u2014 "),KQ=a("a"),w7r=o("TFT5ForConditionalGeneration"),A7r=o(" (T5 model)"),y7r=l(),F(sE.$$.fragment),mNe=l(),ac=a("h2"),lE=a("a"),xbe=a("span"),F(C8.$$.fragment),L7r=l(),$be=a("span"),x7r=o("TFAutoModelForSequenceClassification"),gNe=l(),tr=a("div"),F(w8.$$.fragment),$7r=l(),nc=a("p"),k7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ZQ=a("a"),S7r=o("from_pretrained()"),R7r=o(" class method or the "),eH=a("a"),P7r=o("from_config()"),B7r=o(` class
method.`),I7r=l(),A8=a("p"),q7r=o("This class cannot be instantiated directly using "),kbe=a("code"),N7r=o("__init__()"),j7r=o(" (throws an error)."),D7r=l(),Rt=a("div"),F(y8.$$.fragment),G7r=l(),Sbe=a("p"),O7r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),V7r=l(),sc=a("p"),X7r=o(`Note:
Loading a model from its configuration file does `),Rbe=a("strong"),z7r=o("not"),W7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oH=a("a"),Q7r=o("from_pretrained()"),H7r=o(" to load the model weights."),U7r=l(),F(iE.$$.fragment),J7r=l(),kr=a("div"),F(L8.$$.fragment),Y7r=l(),Pbe=a("p"),K7r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Z7r=l(),nn=a("p"),ebr=o("The model class to instantiate is selected based on the "),Bbe=a("code"),obr=o("model_type"),rbr=o(` property of the config object (either
passed as an argument or loaded from `),Ibe=a("code"),tbr=o("pretrained_model_name_or_path"),abr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qbe=a("code"),nbr=o("pretrained_model_name_or_path"),sbr=o(":"),lbr=l(),ee=a("ul"),dE=a("li"),Nbe=a("strong"),ibr=o("albert"),dbr=o(" \u2014 "),rH=a("a"),cbr=o("TFAlbertForSequenceClassification"),fbr=o(" (ALBERT model)"),mbr=l(),cE=a("li"),jbe=a("strong"),gbr=o("bert"),hbr=o(" \u2014 "),tH=a("a"),pbr=o("TFBertForSequenceClassification"),_br=o(" (BERT model)"),ubr=l(),fE=a("li"),Dbe=a("strong"),bbr=o("camembert"),vbr=o(" \u2014 "),aH=a("a"),Fbr=o("TFCamembertForSequenceClassification"),Tbr=o(" (CamemBERT model)"),Mbr=l(),mE=a("li"),Gbe=a("strong"),Ebr=o("convbert"),Cbr=o(" \u2014 "),nH=a("a"),wbr=o("TFConvBertForSequenceClassification"),Abr=o(" (ConvBERT model)"),ybr=l(),gE=a("li"),Obe=a("strong"),Lbr=o("ctrl"),xbr=o(" \u2014 "),sH=a("a"),$br=o("TFCTRLForSequenceClassification"),kbr=o(" (CTRL model)"),Sbr=l(),hE=a("li"),Vbe=a("strong"),Rbr=o("deberta"),Pbr=o(" \u2014 "),lH=a("a"),Bbr=o("TFDebertaForSequenceClassification"),Ibr=o(" (DeBERTa model)"),qbr=l(),pE=a("li"),Xbe=a("strong"),Nbr=o("deberta-v2"),jbr=o(" \u2014 "),iH=a("a"),Dbr=o("TFDebertaV2ForSequenceClassification"),Gbr=o(" (DeBERTa-v2 model)"),Obr=l(),_E=a("li"),zbe=a("strong"),Vbr=o("distilbert"),Xbr=o(" \u2014 "),dH=a("a"),zbr=o("TFDistilBertForSequenceClassification"),Wbr=o(" (DistilBERT model)"),Qbr=l(),uE=a("li"),Wbe=a("strong"),Hbr=o("electra"),Ubr=o(" \u2014 "),cH=a("a"),Jbr=o("TFElectraForSequenceClassification"),Ybr=o(" (ELECTRA model)"),Kbr=l(),bE=a("li"),Qbe=a("strong"),Zbr=o("flaubert"),evr=o(" \u2014 "),fH=a("a"),ovr=o("TFFlaubertForSequenceClassification"),rvr=o(" (FlauBERT model)"),tvr=l(),vE=a("li"),Hbe=a("strong"),avr=o("funnel"),nvr=o(" \u2014 "),mH=a("a"),svr=o("TFFunnelForSequenceClassification"),lvr=o(" (Funnel Transformer model)"),ivr=l(),FE=a("li"),Ube=a("strong"),dvr=o("gpt2"),cvr=o(" \u2014 "),gH=a("a"),fvr=o("TFGPT2ForSequenceClassification"),mvr=o(" (OpenAI GPT-2 model)"),gvr=l(),TE=a("li"),Jbe=a("strong"),hvr=o("gptj"),pvr=o(" \u2014 "),hH=a("a"),_vr=o("TFGPTJForSequenceClassification"),uvr=o(" (GPT-J model)"),bvr=l(),ME=a("li"),Ybe=a("strong"),vvr=o("layoutlm"),Fvr=o(" \u2014 "),pH=a("a"),Tvr=o("TFLayoutLMForSequenceClassification"),Mvr=o(" (LayoutLM model)"),Evr=l(),EE=a("li"),Kbe=a("strong"),Cvr=o("longformer"),wvr=o(" \u2014 "),_H=a("a"),Avr=o("TFLongformerForSequenceClassification"),yvr=o(" (Longformer model)"),Lvr=l(),CE=a("li"),Zbe=a("strong"),xvr=o("mobilebert"),$vr=o(" \u2014 "),uH=a("a"),kvr=o("TFMobileBertForSequenceClassification"),Svr=o(" (MobileBERT model)"),Rvr=l(),wE=a("li"),eve=a("strong"),Pvr=o("mpnet"),Bvr=o(" \u2014 "),bH=a("a"),Ivr=o("TFMPNetForSequenceClassification"),qvr=o(" (MPNet model)"),Nvr=l(),AE=a("li"),ove=a("strong"),jvr=o("openai-gpt"),Dvr=o(" \u2014 "),vH=a("a"),Gvr=o("TFOpenAIGPTForSequenceClassification"),Ovr=o(" (OpenAI GPT model)"),Vvr=l(),yE=a("li"),rve=a("strong"),Xvr=o("rembert"),zvr=o(" \u2014 "),FH=a("a"),Wvr=o("TFRemBertForSequenceClassification"),Qvr=o(" (RemBERT model)"),Hvr=l(),LE=a("li"),tve=a("strong"),Uvr=o("roberta"),Jvr=o(" \u2014 "),TH=a("a"),Yvr=o("TFRobertaForSequenceClassification"),Kvr=o(" (RoBERTa model)"),Zvr=l(),xE=a("li"),ave=a("strong"),eFr=o("roformer"),oFr=o(" \u2014 "),MH=a("a"),rFr=o("TFRoFormerForSequenceClassification"),tFr=o(" (RoFormer model)"),aFr=l(),$E=a("li"),nve=a("strong"),nFr=o("tapas"),sFr=o(" \u2014 "),EH=a("a"),lFr=o("TFTapasForSequenceClassification"),iFr=o(" (TAPAS model)"),dFr=l(),kE=a("li"),sve=a("strong"),cFr=o("transfo-xl"),fFr=o(" \u2014 "),CH=a("a"),mFr=o("TFTransfoXLForSequenceClassification"),gFr=o(" (Transformer-XL model)"),hFr=l(),SE=a("li"),lve=a("strong"),pFr=o("xlm"),_Fr=o(" \u2014 "),wH=a("a"),uFr=o("TFXLMForSequenceClassification"),bFr=o(" (XLM model)"),vFr=l(),RE=a("li"),ive=a("strong"),FFr=o("xlm-roberta"),TFr=o(" \u2014 "),AH=a("a"),MFr=o("TFXLMRobertaForSequenceClassification"),EFr=o(" (XLM-RoBERTa model)"),CFr=l(),PE=a("li"),dve=a("strong"),wFr=o("xlnet"),AFr=o(" \u2014 "),yH=a("a"),yFr=o("TFXLNetForSequenceClassification"),LFr=o(" (XLNet model)"),xFr=l(),F(BE.$$.fragment),hNe=l(),lc=a("h2"),IE=a("a"),cve=a("span"),F(x8.$$.fragment),$Fr=l(),fve=a("span"),kFr=o("TFAutoModelForMultipleChoice"),pNe=l(),ar=a("div"),F($8.$$.fragment),SFr=l(),ic=a("p"),RFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),LH=a("a"),PFr=o("from_pretrained()"),BFr=o(" class method or the "),xH=a("a"),IFr=o("from_config()"),qFr=o(` class
method.`),NFr=l(),k8=a("p"),jFr=o("This class cannot be instantiated directly using "),mve=a("code"),DFr=o("__init__()"),GFr=o(" (throws an error)."),OFr=l(),Pt=a("div"),F(S8.$$.fragment),VFr=l(),gve=a("p"),XFr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),zFr=l(),dc=a("p"),WFr=o(`Note:
Loading a model from its configuration file does `),hve=a("strong"),QFr=o("not"),HFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=a("a"),UFr=o("from_pretrained()"),JFr=o(" to load the model weights."),YFr=l(),F(qE.$$.fragment),KFr=l(),Sr=a("div"),F(R8.$$.fragment),ZFr=l(),pve=a("p"),eTr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),oTr=l(),sn=a("p"),rTr=o("The model class to instantiate is selected based on the "),_ve=a("code"),tTr=o("model_type"),aTr=o(` property of the config object (either
passed as an argument or loaded from `),uve=a("code"),nTr=o("pretrained_model_name_or_path"),sTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bve=a("code"),lTr=o("pretrained_model_name_or_path"),iTr=o(":"),dTr=l(),he=a("ul"),NE=a("li"),vve=a("strong"),cTr=o("albert"),fTr=o(" \u2014 "),kH=a("a"),mTr=o("TFAlbertForMultipleChoice"),gTr=o(" (ALBERT model)"),hTr=l(),jE=a("li"),Fve=a("strong"),pTr=o("bert"),_Tr=o(" \u2014 "),SH=a("a"),uTr=o("TFBertForMultipleChoice"),bTr=o(" (BERT model)"),vTr=l(),DE=a("li"),Tve=a("strong"),FTr=o("camembert"),TTr=o(" \u2014 "),RH=a("a"),MTr=o("TFCamembertForMultipleChoice"),ETr=o(" (CamemBERT model)"),CTr=l(),GE=a("li"),Mve=a("strong"),wTr=o("convbert"),ATr=o(" \u2014 "),PH=a("a"),yTr=o("TFConvBertForMultipleChoice"),LTr=o(" (ConvBERT model)"),xTr=l(),OE=a("li"),Eve=a("strong"),$Tr=o("distilbert"),kTr=o(" \u2014 "),BH=a("a"),STr=o("TFDistilBertForMultipleChoice"),RTr=o(" (DistilBERT model)"),PTr=l(),VE=a("li"),Cve=a("strong"),BTr=o("electra"),ITr=o(" \u2014 "),IH=a("a"),qTr=o("TFElectraForMultipleChoice"),NTr=o(" (ELECTRA model)"),jTr=l(),XE=a("li"),wve=a("strong"),DTr=o("flaubert"),GTr=o(" \u2014 "),qH=a("a"),OTr=o("TFFlaubertForMultipleChoice"),VTr=o(" (FlauBERT model)"),XTr=l(),zE=a("li"),Ave=a("strong"),zTr=o("funnel"),WTr=o(" \u2014 "),NH=a("a"),QTr=o("TFFunnelForMultipleChoice"),HTr=o(" (Funnel Transformer model)"),UTr=l(),WE=a("li"),yve=a("strong"),JTr=o("longformer"),YTr=o(" \u2014 "),jH=a("a"),KTr=o("TFLongformerForMultipleChoice"),ZTr=o(" (Longformer model)"),eMr=l(),QE=a("li"),Lve=a("strong"),oMr=o("mobilebert"),rMr=o(" \u2014 "),DH=a("a"),tMr=o("TFMobileBertForMultipleChoice"),aMr=o(" (MobileBERT model)"),nMr=l(),HE=a("li"),xve=a("strong"),sMr=o("mpnet"),lMr=o(" \u2014 "),GH=a("a"),iMr=o("TFMPNetForMultipleChoice"),dMr=o(" (MPNet model)"),cMr=l(),UE=a("li"),$ve=a("strong"),fMr=o("rembert"),mMr=o(" \u2014 "),OH=a("a"),gMr=o("TFRemBertForMultipleChoice"),hMr=o(" (RemBERT model)"),pMr=l(),JE=a("li"),kve=a("strong"),_Mr=o("roberta"),uMr=o(" \u2014 "),VH=a("a"),bMr=o("TFRobertaForMultipleChoice"),vMr=o(" (RoBERTa model)"),FMr=l(),YE=a("li"),Sve=a("strong"),TMr=o("roformer"),MMr=o(" \u2014 "),XH=a("a"),EMr=o("TFRoFormerForMultipleChoice"),CMr=o(" (RoFormer model)"),wMr=l(),KE=a("li"),Rve=a("strong"),AMr=o("xlm"),yMr=o(" \u2014 "),zH=a("a"),LMr=o("TFXLMForMultipleChoice"),xMr=o(" (XLM model)"),$Mr=l(),ZE=a("li"),Pve=a("strong"),kMr=o("xlm-roberta"),SMr=o(" \u2014 "),WH=a("a"),RMr=o("TFXLMRobertaForMultipleChoice"),PMr=o(" (XLM-RoBERTa model)"),BMr=l(),eC=a("li"),Bve=a("strong"),IMr=o("xlnet"),qMr=o(" \u2014 "),QH=a("a"),NMr=o("TFXLNetForMultipleChoice"),jMr=o(" (XLNet model)"),DMr=l(),F(oC.$$.fragment),_Ne=l(),cc=a("h2"),rC=a("a"),Ive=a("span"),F(P8.$$.fragment),GMr=l(),qve=a("span"),OMr=o("TFAutoModelForNextSentencePrediction"),uNe=l(),nr=a("div"),F(B8.$$.fragment),VMr=l(),fc=a("p"),XMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),HH=a("a"),zMr=o("from_pretrained()"),WMr=o(" class method or the "),UH=a("a"),QMr=o("from_config()"),HMr=o(` class
method.`),UMr=l(),I8=a("p"),JMr=o("This class cannot be instantiated directly using "),Nve=a("code"),YMr=o("__init__()"),KMr=o(" (throws an error)."),ZMr=l(),Bt=a("div"),F(q8.$$.fragment),e4r=l(),jve=a("p"),o4r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),r4r=l(),mc=a("p"),t4r=o(`Note:
Loading a model from its configuration file does `),Dve=a("strong"),a4r=o("not"),n4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JH=a("a"),s4r=o("from_pretrained()"),l4r=o(" to load the model weights."),i4r=l(),F(tC.$$.fragment),d4r=l(),Rr=a("div"),F(N8.$$.fragment),c4r=l(),Gve=a("p"),f4r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),m4r=l(),ln=a("p"),g4r=o("The model class to instantiate is selected based on the "),Ove=a("code"),h4r=o("model_type"),p4r=o(` property of the config object (either
passed as an argument or loaded from `),Vve=a("code"),_4r=o("pretrained_model_name_or_path"),u4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xve=a("code"),b4r=o("pretrained_model_name_or_path"),v4r=o(":"),F4r=l(),j8=a("ul"),aC=a("li"),zve=a("strong"),T4r=o("bert"),M4r=o(" \u2014 "),YH=a("a"),E4r=o("TFBertForNextSentencePrediction"),C4r=o(" (BERT model)"),w4r=l(),nC=a("li"),Wve=a("strong"),A4r=o("mobilebert"),y4r=o(" \u2014 "),KH=a("a"),L4r=o("TFMobileBertForNextSentencePrediction"),x4r=o(" (MobileBERT model)"),$4r=l(),F(sC.$$.fragment),bNe=l(),gc=a("h2"),lC=a("a"),Qve=a("span"),F(D8.$$.fragment),k4r=l(),Hve=a("span"),S4r=o("TFAutoModelForTableQuestionAnswering"),vNe=l(),sr=a("div"),F(G8.$$.fragment),R4r=l(),hc=a("p"),P4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),ZH=a("a"),B4r=o("from_pretrained()"),I4r=o(" class method or the "),eU=a("a"),q4r=o("from_config()"),N4r=o(` class
method.`),j4r=l(),O8=a("p"),D4r=o("This class cannot be instantiated directly using "),Uve=a("code"),G4r=o("__init__()"),O4r=o(" (throws an error)."),V4r=l(),It=a("div"),F(V8.$$.fragment),X4r=l(),Jve=a("p"),z4r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),W4r=l(),pc=a("p"),Q4r=o(`Note:
Loading a model from its configuration file does `),Yve=a("strong"),H4r=o("not"),U4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=a("a"),J4r=o("from_pretrained()"),Y4r=o(" to load the model weights."),K4r=l(),F(iC.$$.fragment),Z4r=l(),Pr=a("div"),F(X8.$$.fragment),eEr=l(),Kve=a("p"),oEr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),rEr=l(),dn=a("p"),tEr=o("The model class to instantiate is selected based on the "),Zve=a("code"),aEr=o("model_type"),nEr=o(` property of the config object (either
passed as an argument or loaded from `),eFe=a("code"),sEr=o("pretrained_model_name_or_path"),lEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=a("code"),iEr=o("pretrained_model_name_or_path"),dEr=o(":"),cEr=l(),rFe=a("ul"),dC=a("li"),tFe=a("strong"),fEr=o("tapas"),mEr=o(" \u2014 "),rU=a("a"),gEr=o("TFTapasForQuestionAnswering"),hEr=o(" (TAPAS model)"),pEr=l(),F(cC.$$.fragment),FNe=l(),_c=a("h2"),fC=a("a"),aFe=a("span"),F(z8.$$.fragment),_Er=l(),nFe=a("span"),uEr=o("TFAutoModelForTokenClassification"),TNe=l(),lr=a("div"),F(W8.$$.fragment),bEr=l(),uc=a("p"),vEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),tU=a("a"),FEr=o("from_pretrained()"),TEr=o(" class method or the "),aU=a("a"),MEr=o("from_config()"),EEr=o(` class
method.`),CEr=l(),Q8=a("p"),wEr=o("This class cannot be instantiated directly using "),sFe=a("code"),AEr=o("__init__()"),yEr=o(" (throws an error)."),LEr=l(),qt=a("div"),F(H8.$$.fragment),xEr=l(),lFe=a("p"),$Er=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),kEr=l(),bc=a("p"),SEr=o(`Note:
Loading a model from its configuration file does `),iFe=a("strong"),REr=o("not"),PEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=a("a"),BEr=o("from_pretrained()"),IEr=o(" to load the model weights."),qEr=l(),F(mC.$$.fragment),NEr=l(),Br=a("div"),F(U8.$$.fragment),jEr=l(),dFe=a("p"),DEr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),GEr=l(),cn=a("p"),OEr=o("The model class to instantiate is selected based on the "),cFe=a("code"),VEr=o("model_type"),XEr=o(` property of the config object (either
passed as an argument or loaded from `),fFe=a("code"),zEr=o("pretrained_model_name_or_path"),WEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mFe=a("code"),QEr=o("pretrained_model_name_or_path"),HEr=o(":"),UEr=l(),de=a("ul"),gC=a("li"),gFe=a("strong"),JEr=o("albert"),YEr=o(" \u2014 "),sU=a("a"),KEr=o("TFAlbertForTokenClassification"),ZEr=o(" (ALBERT model)"),eCr=l(),hC=a("li"),hFe=a("strong"),oCr=o("bert"),rCr=o(" \u2014 "),lU=a("a"),tCr=o("TFBertForTokenClassification"),aCr=o(" (BERT model)"),nCr=l(),pC=a("li"),pFe=a("strong"),sCr=o("camembert"),lCr=o(" \u2014 "),iU=a("a"),iCr=o("TFCamembertForTokenClassification"),dCr=o(" (CamemBERT model)"),cCr=l(),_C=a("li"),_Fe=a("strong"),fCr=o("convbert"),mCr=o(" \u2014 "),dU=a("a"),gCr=o("TFConvBertForTokenClassification"),hCr=o(" (ConvBERT model)"),pCr=l(),uC=a("li"),uFe=a("strong"),_Cr=o("deberta"),uCr=o(" \u2014 "),cU=a("a"),bCr=o("TFDebertaForTokenClassification"),vCr=o(" (DeBERTa model)"),FCr=l(),bC=a("li"),bFe=a("strong"),TCr=o("deberta-v2"),MCr=o(" \u2014 "),fU=a("a"),ECr=o("TFDebertaV2ForTokenClassification"),CCr=o(" (DeBERTa-v2 model)"),wCr=l(),vC=a("li"),vFe=a("strong"),ACr=o("distilbert"),yCr=o(" \u2014 "),mU=a("a"),LCr=o("TFDistilBertForTokenClassification"),xCr=o(" (DistilBERT model)"),$Cr=l(),FC=a("li"),FFe=a("strong"),kCr=o("electra"),SCr=o(" \u2014 "),gU=a("a"),RCr=o("TFElectraForTokenClassification"),PCr=o(" (ELECTRA model)"),BCr=l(),TC=a("li"),TFe=a("strong"),ICr=o("flaubert"),qCr=o(" \u2014 "),hU=a("a"),NCr=o("TFFlaubertForTokenClassification"),jCr=o(" (FlauBERT model)"),DCr=l(),MC=a("li"),MFe=a("strong"),GCr=o("funnel"),OCr=o(" \u2014 "),pU=a("a"),VCr=o("TFFunnelForTokenClassification"),XCr=o(" (Funnel Transformer model)"),zCr=l(),EC=a("li"),EFe=a("strong"),WCr=o("layoutlm"),QCr=o(" \u2014 "),_U=a("a"),HCr=o("TFLayoutLMForTokenClassification"),UCr=o(" (LayoutLM model)"),JCr=l(),CC=a("li"),CFe=a("strong"),YCr=o("longformer"),KCr=o(" \u2014 "),uU=a("a"),ZCr=o("TFLongformerForTokenClassification"),e5r=o(" (Longformer model)"),o5r=l(),wC=a("li"),wFe=a("strong"),r5r=o("mobilebert"),t5r=o(" \u2014 "),bU=a("a"),a5r=o("TFMobileBertForTokenClassification"),n5r=o(" (MobileBERT model)"),s5r=l(),AC=a("li"),AFe=a("strong"),l5r=o("mpnet"),i5r=o(" \u2014 "),vU=a("a"),d5r=o("TFMPNetForTokenClassification"),c5r=o(" (MPNet model)"),f5r=l(),yC=a("li"),yFe=a("strong"),m5r=o("rembert"),g5r=o(" \u2014 "),FU=a("a"),h5r=o("TFRemBertForTokenClassification"),p5r=o(" (RemBERT model)"),_5r=l(),LC=a("li"),LFe=a("strong"),u5r=o("roberta"),b5r=o(" \u2014 "),TU=a("a"),v5r=o("TFRobertaForTokenClassification"),F5r=o(" (RoBERTa model)"),T5r=l(),xC=a("li"),xFe=a("strong"),M5r=o("roformer"),E5r=o(" \u2014 "),MU=a("a"),C5r=o("TFRoFormerForTokenClassification"),w5r=o(" (RoFormer model)"),A5r=l(),$C=a("li"),$Fe=a("strong"),y5r=o("xlm"),L5r=o(" \u2014 "),EU=a("a"),x5r=o("TFXLMForTokenClassification"),$5r=o(" (XLM model)"),k5r=l(),kC=a("li"),kFe=a("strong"),S5r=o("xlm-roberta"),R5r=o(" \u2014 "),CU=a("a"),P5r=o("TFXLMRobertaForTokenClassification"),B5r=o(" (XLM-RoBERTa model)"),I5r=l(),SC=a("li"),SFe=a("strong"),q5r=o("xlnet"),N5r=o(" \u2014 "),wU=a("a"),j5r=o("TFXLNetForTokenClassification"),D5r=o(" (XLNet model)"),G5r=l(),F(RC.$$.fragment),MNe=l(),vc=a("h2"),PC=a("a"),RFe=a("span"),F(J8.$$.fragment),O5r=l(),PFe=a("span"),V5r=o("TFAutoModelForQuestionAnswering"),ENe=l(),ir=a("div"),F(Y8.$$.fragment),X5r=l(),Fc=a("p"),z5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),AU=a("a"),W5r=o("from_pretrained()"),Q5r=o(" class method or the "),yU=a("a"),H5r=o("from_config()"),U5r=o(` class
method.`),J5r=l(),K8=a("p"),Y5r=o("This class cannot be instantiated directly using "),BFe=a("code"),K5r=o("__init__()"),Z5r=o(" (throws an error)."),e3r=l(),Nt=a("div"),F(Z8.$$.fragment),o3r=l(),IFe=a("p"),r3r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),t3r=l(),Tc=a("p"),a3r=o(`Note:
Loading a model from its configuration file does `),qFe=a("strong"),n3r=o("not"),s3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),l3r=o("from_pretrained()"),i3r=o(" to load the model weights."),d3r=l(),F(BC.$$.fragment),c3r=l(),Ir=a("div"),F(ex.$$.fragment),f3r=l(),NFe=a("p"),m3r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),g3r=l(),fn=a("p"),h3r=o("The model class to instantiate is selected based on the "),jFe=a("code"),p3r=o("model_type"),_3r=o(` property of the config object (either
passed as an argument or loaded from `),DFe=a("code"),u3r=o("pretrained_model_name_or_path"),b3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GFe=a("code"),v3r=o("pretrained_model_name_or_path"),F3r=o(":"),T3r=l(),ce=a("ul"),IC=a("li"),OFe=a("strong"),M3r=o("albert"),E3r=o(" \u2014 "),xU=a("a"),C3r=o("TFAlbertForQuestionAnswering"),w3r=o(" (ALBERT model)"),A3r=l(),qC=a("li"),VFe=a("strong"),y3r=o("bert"),L3r=o(" \u2014 "),$U=a("a"),x3r=o("TFBertForQuestionAnswering"),$3r=o(" (BERT model)"),k3r=l(),NC=a("li"),XFe=a("strong"),S3r=o("camembert"),R3r=o(" \u2014 "),kU=a("a"),P3r=o("TFCamembertForQuestionAnswering"),B3r=o(" (CamemBERT model)"),I3r=l(),jC=a("li"),zFe=a("strong"),q3r=o("convbert"),N3r=o(" \u2014 "),SU=a("a"),j3r=o("TFConvBertForQuestionAnswering"),D3r=o(" (ConvBERT model)"),G3r=l(),DC=a("li"),WFe=a("strong"),O3r=o("deberta"),V3r=o(" \u2014 "),RU=a("a"),X3r=o("TFDebertaForQuestionAnswering"),z3r=o(" (DeBERTa model)"),W3r=l(),GC=a("li"),QFe=a("strong"),Q3r=o("deberta-v2"),H3r=o(" \u2014 "),PU=a("a"),U3r=o("TFDebertaV2ForQuestionAnswering"),J3r=o(" (DeBERTa-v2 model)"),Y3r=l(),OC=a("li"),HFe=a("strong"),K3r=o("distilbert"),Z3r=o(" \u2014 "),BU=a("a"),ewr=o("TFDistilBertForQuestionAnswering"),owr=o(" (DistilBERT model)"),rwr=l(),VC=a("li"),UFe=a("strong"),twr=o("electra"),awr=o(" \u2014 "),IU=a("a"),nwr=o("TFElectraForQuestionAnswering"),swr=o(" (ELECTRA model)"),lwr=l(),XC=a("li"),JFe=a("strong"),iwr=o("flaubert"),dwr=o(" \u2014 "),qU=a("a"),cwr=o("TFFlaubertForQuestionAnsweringSimple"),fwr=o(" (FlauBERT model)"),mwr=l(),zC=a("li"),YFe=a("strong"),gwr=o("funnel"),hwr=o(" \u2014 "),NU=a("a"),pwr=o("TFFunnelForQuestionAnswering"),_wr=o(" (Funnel Transformer model)"),uwr=l(),WC=a("li"),KFe=a("strong"),bwr=o("gptj"),vwr=o(" \u2014 "),jU=a("a"),Fwr=o("TFGPTJForQuestionAnswering"),Twr=o(" (GPT-J model)"),Mwr=l(),QC=a("li"),ZFe=a("strong"),Ewr=o("longformer"),Cwr=o(" \u2014 "),DU=a("a"),wwr=o("TFLongformerForQuestionAnswering"),Awr=o(" (Longformer model)"),ywr=l(),HC=a("li"),eTe=a("strong"),Lwr=o("mobilebert"),xwr=o(" \u2014 "),GU=a("a"),$wr=o("TFMobileBertForQuestionAnswering"),kwr=o(" (MobileBERT model)"),Swr=l(),UC=a("li"),oTe=a("strong"),Rwr=o("mpnet"),Pwr=o(" \u2014 "),OU=a("a"),Bwr=o("TFMPNetForQuestionAnswering"),Iwr=o(" (MPNet model)"),qwr=l(),JC=a("li"),rTe=a("strong"),Nwr=o("rembert"),jwr=o(" \u2014 "),VU=a("a"),Dwr=o("TFRemBertForQuestionAnswering"),Gwr=o(" (RemBERT model)"),Owr=l(),YC=a("li"),tTe=a("strong"),Vwr=o("roberta"),Xwr=o(" \u2014 "),XU=a("a"),zwr=o("TFRobertaForQuestionAnswering"),Wwr=o(" (RoBERTa model)"),Qwr=l(),KC=a("li"),aTe=a("strong"),Hwr=o("roformer"),Uwr=o(" \u2014 "),zU=a("a"),Jwr=o("TFRoFormerForQuestionAnswering"),Ywr=o(" (RoFormer model)"),Kwr=l(),ZC=a("li"),nTe=a("strong"),Zwr=o("xlm"),e0r=o(" \u2014 "),WU=a("a"),o0r=o("TFXLMForQuestionAnsweringSimple"),r0r=o(" (XLM model)"),t0r=l(),e5=a("li"),sTe=a("strong"),a0r=o("xlm-roberta"),n0r=o(" \u2014 "),QU=a("a"),s0r=o("TFXLMRobertaForQuestionAnswering"),l0r=o(" (XLM-RoBERTa model)"),i0r=l(),o5=a("li"),lTe=a("strong"),d0r=o("xlnet"),c0r=o(" \u2014 "),HU=a("a"),f0r=o("TFXLNetForQuestionAnsweringSimple"),m0r=o(" (XLNet model)"),g0r=l(),F(r5.$$.fragment),CNe=l(),Mc=a("h2"),t5=a("a"),iTe=a("span"),F(ox.$$.fragment),h0r=l(),dTe=a("span"),p0r=o("TFAutoModelForVision2Seq"),wNe=l(),dr=a("div"),F(rx.$$.fragment),_0r=l(),Ec=a("p"),u0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),UU=a("a"),b0r=o("from_pretrained()"),v0r=o(" class method or the "),JU=a("a"),F0r=o("from_config()"),T0r=o(` class
method.`),M0r=l(),tx=a("p"),E0r=o("This class cannot be instantiated directly using "),cTe=a("code"),C0r=o("__init__()"),w0r=o(" (throws an error)."),A0r=l(),jt=a("div"),F(ax.$$.fragment),y0r=l(),fTe=a("p"),L0r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),x0r=l(),Cc=a("p"),$0r=o(`Note:
Loading a model from its configuration file does `),mTe=a("strong"),k0r=o("not"),S0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YU=a("a"),R0r=o("from_pretrained()"),P0r=o(" to load the model weights."),B0r=l(),F(a5.$$.fragment),I0r=l(),qr=a("div"),F(nx.$$.fragment),q0r=l(),gTe=a("p"),N0r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),j0r=l(),mn=a("p"),D0r=o("The model class to instantiate is selected based on the "),hTe=a("code"),G0r=o("model_type"),O0r=o(` property of the config object (either
passed as an argument or loaded from `),pTe=a("code"),V0r=o("pretrained_model_name_or_path"),X0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Te=a("code"),z0r=o("pretrained_model_name_or_path"),W0r=o(":"),Q0r=l(),uTe=a("ul"),n5=a("li"),bTe=a("strong"),H0r=o("vision-encoder-decoder"),U0r=o(" \u2014 "),KU=a("a"),J0r=o("TFVisionEncoderDecoderModel"),Y0r=o(" (Vision Encoder decoder model)"),K0r=l(),F(s5.$$.fragment),ANe=l(),wc=a("h2"),l5=a("a"),vTe=a("span"),F(sx.$$.fragment),Z0r=l(),FTe=a("span"),eAr=o("TFAutoModelForSpeechSeq2Seq"),yNe=l(),cr=a("div"),F(lx.$$.fragment),oAr=l(),Ac=a("p"),rAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ZU=a("a"),tAr=o("from_pretrained()"),aAr=o(" class method or the "),eJ=a("a"),nAr=o("from_config()"),sAr=o(` class
method.`),lAr=l(),ix=a("p"),iAr=o("This class cannot be instantiated directly using "),TTe=a("code"),dAr=o("__init__()"),cAr=o(" (throws an error)."),fAr=l(),Dt=a("div"),F(dx.$$.fragment),mAr=l(),MTe=a("p"),gAr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),hAr=l(),yc=a("p"),pAr=o(`Note:
Loading a model from its configuration file does `),ETe=a("strong"),_Ar=o("not"),uAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=a("a"),bAr=o("from_pretrained()"),vAr=o(" to load the model weights."),FAr=l(),F(i5.$$.fragment),TAr=l(),Nr=a("div"),F(cx.$$.fragment),MAr=l(),CTe=a("p"),EAr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),CAr=l(),gn=a("p"),wAr=o("The model class to instantiate is selected based on the "),wTe=a("code"),AAr=o("model_type"),yAr=o(` property of the config object (either
passed as an argument or loaded from `),ATe=a("code"),LAr=o("pretrained_model_name_or_path"),xAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yTe=a("code"),$Ar=o("pretrained_model_name_or_path"),kAr=o(":"),SAr=l(),LTe=a("ul"),d5=a("li"),xTe=a("strong"),RAr=o("speech_to_text"),PAr=o(" \u2014 "),rJ=a("a"),BAr=o("TFSpeech2TextForConditionalGeneration"),IAr=o(" (Speech2Text model)"),qAr=l(),F(c5.$$.fragment),LNe=l(),Lc=a("h2"),f5=a("a"),$Te=a("span"),F(fx.$$.fragment),NAr=l(),kTe=a("span"),jAr=o("FlaxAutoModel"),xNe=l(),fr=a("div"),F(mx.$$.fragment),DAr=l(),xc=a("p"),GAr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tJ=a("a"),OAr=o("from_pretrained()"),VAr=o(" class method or the "),aJ=a("a"),XAr=o("from_config()"),zAr=o(` class
method.`),WAr=l(),gx=a("p"),QAr=o("This class cannot be instantiated directly using "),STe=a("code"),HAr=o("__init__()"),UAr=o(" (throws an error)."),JAr=l(),Gt=a("div"),F(hx.$$.fragment),YAr=l(),RTe=a("p"),KAr=o("Instantiates one of the base model classes of the library from a configuration."),ZAr=l(),$c=a("p"),e6r=o(`Note:
Loading a model from its configuration file does `),PTe=a("strong"),o6r=o("not"),r6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nJ=a("a"),t6r=o("from_pretrained()"),a6r=o(" to load the model weights."),n6r=l(),F(m5.$$.fragment),s6r=l(),jr=a("div"),F(px.$$.fragment),l6r=l(),BTe=a("p"),i6r=o("Instantiate one of the base model classes of the library from a pretrained model."),d6r=l(),hn=a("p"),c6r=o("The model class to instantiate is selected based on the "),ITe=a("code"),f6r=o("model_type"),m6r=o(` property of the config object (either
passed as an argument or loaded from `),qTe=a("code"),g6r=o("pretrained_model_name_or_path"),h6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=a("code"),p6r=o("pretrained_model_name_or_path"),_6r=o(":"),u6r=l(),oe=a("ul"),g5=a("li"),jTe=a("strong"),b6r=o("albert"),v6r=o(" \u2014 "),sJ=a("a"),F6r=o("FlaxAlbertModel"),T6r=o(" (ALBERT model)"),M6r=l(),h5=a("li"),DTe=a("strong"),E6r=o("bart"),C6r=o(" \u2014 "),lJ=a("a"),w6r=o("FlaxBartModel"),A6r=o(" (BART model)"),y6r=l(),p5=a("li"),GTe=a("strong"),L6r=o("beit"),x6r=o(" \u2014 "),iJ=a("a"),$6r=o("FlaxBeitModel"),k6r=o(" (BEiT model)"),S6r=l(),_5=a("li"),OTe=a("strong"),R6r=o("bert"),P6r=o(" \u2014 "),dJ=a("a"),B6r=o("FlaxBertModel"),I6r=o(" (BERT model)"),q6r=l(),u5=a("li"),VTe=a("strong"),N6r=o("big_bird"),j6r=o(" \u2014 "),cJ=a("a"),D6r=o("FlaxBigBirdModel"),G6r=o(" (BigBird model)"),O6r=l(),b5=a("li"),XTe=a("strong"),V6r=o("blenderbot"),X6r=o(" \u2014 "),fJ=a("a"),z6r=o("FlaxBlenderbotModel"),W6r=o(" (Blenderbot model)"),Q6r=l(),v5=a("li"),zTe=a("strong"),H6r=o("blenderbot-small"),U6r=o(" \u2014 "),mJ=a("a"),J6r=o("FlaxBlenderbotSmallModel"),Y6r=o(" (BlenderbotSmall model)"),K6r=l(),F5=a("li"),WTe=a("strong"),Z6r=o("clip"),eyr=o(" \u2014 "),gJ=a("a"),oyr=o("FlaxCLIPModel"),ryr=o(" (CLIP model)"),tyr=l(),T5=a("li"),QTe=a("strong"),ayr=o("distilbert"),nyr=o(" \u2014 "),hJ=a("a"),syr=o("FlaxDistilBertModel"),lyr=o(" (DistilBERT model)"),iyr=l(),M5=a("li"),HTe=a("strong"),dyr=o("electra"),cyr=o(" \u2014 "),pJ=a("a"),fyr=o("FlaxElectraModel"),myr=o(" (ELECTRA model)"),gyr=l(),E5=a("li"),UTe=a("strong"),hyr=o("gpt2"),pyr=o(" \u2014 "),_J=a("a"),_yr=o("FlaxGPT2Model"),uyr=o(" (OpenAI GPT-2 model)"),byr=l(),C5=a("li"),JTe=a("strong"),vyr=o("gpt_neo"),Fyr=o(" \u2014 "),uJ=a("a"),Tyr=o("FlaxGPTNeoModel"),Myr=o(" (GPT Neo model)"),Eyr=l(),w5=a("li"),YTe=a("strong"),Cyr=o("gptj"),wyr=o(" \u2014 "),bJ=a("a"),Ayr=o("FlaxGPTJModel"),yyr=o(" (GPT-J model)"),Lyr=l(),A5=a("li"),KTe=a("strong"),xyr=o("marian"),$yr=o(" \u2014 "),vJ=a("a"),kyr=o("FlaxMarianModel"),Syr=o(" (Marian model)"),Ryr=l(),y5=a("li"),ZTe=a("strong"),Pyr=o("mbart"),Byr=o(" \u2014 "),FJ=a("a"),Iyr=o("FlaxMBartModel"),qyr=o(" (mBART model)"),Nyr=l(),L5=a("li"),eMe=a("strong"),jyr=o("mt5"),Dyr=o(" \u2014 "),TJ=a("a"),Gyr=o("FlaxMT5Model"),Oyr=o(" (mT5 model)"),Vyr=l(),x5=a("li"),oMe=a("strong"),Xyr=o("opt"),zyr=o(" \u2014 "),MJ=a("a"),Wyr=o("FlaxOPTModel"),Qyr=o(" (OPT model)"),Hyr=l(),$5=a("li"),rMe=a("strong"),Uyr=o("pegasus"),Jyr=o(" \u2014 "),EJ=a("a"),Yyr=o("FlaxPegasusModel"),Kyr=o(" (Pegasus model)"),Zyr=l(),k5=a("li"),tMe=a("strong"),eLr=o("roberta"),oLr=o(" \u2014 "),CJ=a("a"),rLr=o("FlaxRobertaModel"),tLr=o(" (RoBERTa model)"),aLr=l(),S5=a("li"),aMe=a("strong"),nLr=o("roformer"),sLr=o(" \u2014 "),wJ=a("a"),lLr=o("FlaxRoFormerModel"),iLr=o(" (RoFormer model)"),dLr=l(),R5=a("li"),nMe=a("strong"),cLr=o("t5"),fLr=o(" \u2014 "),AJ=a("a"),mLr=o("FlaxT5Model"),gLr=o(" (T5 model)"),hLr=l(),P5=a("li"),sMe=a("strong"),pLr=o("vision-text-dual-encoder"),_Lr=o(" \u2014 "),yJ=a("a"),uLr=o("FlaxVisionTextDualEncoderModel"),bLr=o(" (VisionTextDualEncoder model)"),vLr=l(),B5=a("li"),lMe=a("strong"),FLr=o("vit"),TLr=o(" \u2014 "),LJ=a("a"),MLr=o("FlaxViTModel"),ELr=o(" (ViT model)"),CLr=l(),I5=a("li"),iMe=a("strong"),wLr=o("wav2vec2"),ALr=o(" \u2014 "),xJ=a("a"),yLr=o("FlaxWav2Vec2Model"),LLr=o(" (Wav2Vec2 model)"),xLr=l(),q5=a("li"),dMe=a("strong"),$Lr=o("xglm"),kLr=o(" \u2014 "),$J=a("a"),SLr=o("FlaxXGLMModel"),RLr=o(" (XGLM model)"),PLr=l(),N5=a("li"),cMe=a("strong"),BLr=o("xlm-roberta"),ILr=o(" \u2014 "),kJ=a("a"),qLr=o("FlaxXLMRobertaModel"),NLr=o(" (XLM-RoBERTa model)"),jLr=l(),F(j5.$$.fragment),$Ne=l(),kc=a("h2"),D5=a("a"),fMe=a("span"),F(_x.$$.fragment),DLr=l(),mMe=a("span"),GLr=o("FlaxAutoModelForCausalLM"),kNe=l(),mr=a("div"),F(ux.$$.fragment),OLr=l(),Sc=a("p"),VLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),SJ=a("a"),XLr=o("from_pretrained()"),zLr=o(" class method or the "),RJ=a("a"),WLr=o("from_config()"),QLr=o(` class
method.`),HLr=l(),bx=a("p"),ULr=o("This class cannot be instantiated directly using "),gMe=a("code"),JLr=o("__init__()"),YLr=o(" (throws an error)."),KLr=l(),Ot=a("div"),F(vx.$$.fragment),ZLr=l(),hMe=a("p"),e8r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),o8r=l(),Rc=a("p"),r8r=o(`Note:
Loading a model from its configuration file does `),pMe=a("strong"),t8r=o("not"),a8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PJ=a("a"),n8r=o("from_pretrained()"),s8r=o(" to load the model weights."),l8r=l(),F(G5.$$.fragment),i8r=l(),Dr=a("div"),F(Fx.$$.fragment),d8r=l(),_Me=a("p"),c8r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),f8r=l(),pn=a("p"),m8r=o("The model class to instantiate is selected based on the "),uMe=a("code"),g8r=o("model_type"),h8r=o(` property of the config object (either
passed as an argument or loaded from `),bMe=a("code"),p8r=o("pretrained_model_name_or_path"),_8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vMe=a("code"),u8r=o("pretrained_model_name_or_path"),b8r=o(":"),v8r=l(),Le=a("ul"),O5=a("li"),FMe=a("strong"),F8r=o("bart"),T8r=o(" \u2014 "),BJ=a("a"),M8r=o("FlaxBartForCausalLM"),E8r=o(" (BART model)"),C8r=l(),V5=a("li"),TMe=a("strong"),w8r=o("bert"),A8r=o(" \u2014 "),IJ=a("a"),y8r=o("FlaxBertForCausalLM"),L8r=o(" (BERT model)"),x8r=l(),X5=a("li"),MMe=a("strong"),$8r=o("big_bird"),k8r=o(" \u2014 "),qJ=a("a"),S8r=o("FlaxBigBirdForCausalLM"),R8r=o(" (BigBird model)"),P8r=l(),z5=a("li"),EMe=a("strong"),B8r=o("electra"),I8r=o(" \u2014 "),NJ=a("a"),q8r=o("FlaxElectraForCausalLM"),N8r=o(" (ELECTRA model)"),j8r=l(),W5=a("li"),CMe=a("strong"),D8r=o("gpt2"),G8r=o(" \u2014 "),jJ=a("a"),O8r=o("FlaxGPT2LMHeadModel"),V8r=o(" (OpenAI GPT-2 model)"),X8r=l(),Q5=a("li"),wMe=a("strong"),z8r=o("gpt_neo"),W8r=o(" \u2014 "),DJ=a("a"),Q8r=o("FlaxGPTNeoForCausalLM"),H8r=o(" (GPT Neo model)"),U8r=l(),H5=a("li"),AMe=a("strong"),J8r=o("gptj"),Y8r=o(" \u2014 "),GJ=a("a"),K8r=o("FlaxGPTJForCausalLM"),Z8r=o(" (GPT-J model)"),exr=l(),U5=a("li"),yMe=a("strong"),oxr=o("opt"),rxr=o(" \u2014 "),OJ=a("a"),txr=o("FlaxOPTForCausalLM"),axr=o(" (OPT model)"),nxr=l(),J5=a("li"),LMe=a("strong"),sxr=o("roberta"),lxr=o(" \u2014 "),VJ=a("a"),ixr=o("FlaxRobertaForCausalLM"),dxr=o(" (RoBERTa model)"),cxr=l(),Y5=a("li"),xMe=a("strong"),fxr=o("xglm"),mxr=o(" \u2014 "),XJ=a("a"),gxr=o("FlaxXGLMForCausalLM"),hxr=o(" (XGLM model)"),pxr=l(),F(K5.$$.fragment),SNe=l(),Pc=a("h2"),Z5=a("a"),$Me=a("span"),F(Tx.$$.fragment),_xr=l(),kMe=a("span"),uxr=o("FlaxAutoModelForPreTraining"),RNe=l(),gr=a("div"),F(Mx.$$.fragment),bxr=l(),Bc=a("p"),vxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),zJ=a("a"),Fxr=o("from_pretrained()"),Txr=o(" class method or the "),WJ=a("a"),Mxr=o("from_config()"),Exr=o(` class
method.`),Cxr=l(),Ex=a("p"),wxr=o("This class cannot be instantiated directly using "),SMe=a("code"),Axr=o("__init__()"),yxr=o(" (throws an error)."),Lxr=l(),Vt=a("div"),F(Cx.$$.fragment),xxr=l(),RMe=a("p"),$xr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),kxr=l(),Ic=a("p"),Sxr=o(`Note:
Loading a model from its configuration file does `),PMe=a("strong"),Rxr=o("not"),Pxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),Bxr=o("from_pretrained()"),Ixr=o(" to load the model weights."),qxr=l(),F(e3.$$.fragment),Nxr=l(),Gr=a("div"),F(wx.$$.fragment),jxr=l(),BMe=a("p"),Dxr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Gxr=l(),_n=a("p"),Oxr=o("The model class to instantiate is selected based on the "),IMe=a("code"),Vxr=o("model_type"),Xxr=o(` property of the config object (either
passed as an argument or loaded from `),qMe=a("code"),zxr=o("pretrained_model_name_or_path"),Wxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NMe=a("code"),Qxr=o("pretrained_model_name_or_path"),Hxr=o(":"),Uxr=l(),Me=a("ul"),o3=a("li"),jMe=a("strong"),Jxr=o("albert"),Yxr=o(" \u2014 "),HJ=a("a"),Kxr=o("FlaxAlbertForPreTraining"),Zxr=o(" (ALBERT model)"),e9r=l(),r3=a("li"),DMe=a("strong"),o9r=o("bart"),r9r=o(" \u2014 "),UJ=a("a"),t9r=o("FlaxBartForConditionalGeneration"),a9r=o(" (BART model)"),n9r=l(),t3=a("li"),GMe=a("strong"),s9r=o("bert"),l9r=o(" \u2014 "),JJ=a("a"),i9r=o("FlaxBertForPreTraining"),d9r=o(" (BERT model)"),c9r=l(),a3=a("li"),OMe=a("strong"),f9r=o("big_bird"),m9r=o(" \u2014 "),YJ=a("a"),g9r=o("FlaxBigBirdForPreTraining"),h9r=o(" (BigBird model)"),p9r=l(),n3=a("li"),VMe=a("strong"),_9r=o("electra"),u9r=o(" \u2014 "),KJ=a("a"),b9r=o("FlaxElectraForPreTraining"),v9r=o(" (ELECTRA model)"),F9r=l(),s3=a("li"),XMe=a("strong"),T9r=o("mbart"),M9r=o(" \u2014 "),ZJ=a("a"),E9r=o("FlaxMBartForConditionalGeneration"),C9r=o(" (mBART model)"),w9r=l(),l3=a("li"),zMe=a("strong"),A9r=o("mt5"),y9r=o(" \u2014 "),eY=a("a"),L9r=o("FlaxMT5ForConditionalGeneration"),x9r=o(" (mT5 model)"),$9r=l(),i3=a("li"),WMe=a("strong"),k9r=o("roberta"),S9r=o(" \u2014 "),oY=a("a"),R9r=o("FlaxRobertaForMaskedLM"),P9r=o(" (RoBERTa model)"),B9r=l(),d3=a("li"),QMe=a("strong"),I9r=o("roformer"),q9r=o(" \u2014 "),rY=a("a"),N9r=o("FlaxRoFormerForMaskedLM"),j9r=o(" (RoFormer model)"),D9r=l(),c3=a("li"),HMe=a("strong"),G9r=o("t5"),O9r=o(" \u2014 "),tY=a("a"),V9r=o("FlaxT5ForConditionalGeneration"),X9r=o(" (T5 model)"),z9r=l(),f3=a("li"),UMe=a("strong"),W9r=o("wav2vec2"),Q9r=o(" \u2014 "),aY=a("a"),H9r=o("FlaxWav2Vec2ForPreTraining"),U9r=o(" (Wav2Vec2 model)"),J9r=l(),m3=a("li"),JMe=a("strong"),Y9r=o("xlm-roberta"),K9r=o(" \u2014 "),nY=a("a"),Z9r=o("FlaxXLMRobertaForMaskedLM"),e$r=o(" (XLM-RoBERTa model)"),o$r=l(),F(g3.$$.fragment),PNe=l(),qc=a("h2"),h3=a("a"),YMe=a("span"),F(Ax.$$.fragment),r$r=l(),KMe=a("span"),t$r=o("FlaxAutoModelForMaskedLM"),BNe=l(),hr=a("div"),F(yx.$$.fragment),a$r=l(),Nc=a("p"),n$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sY=a("a"),s$r=o("from_pretrained()"),l$r=o(" class method or the "),lY=a("a"),i$r=o("from_config()"),d$r=o(` class
method.`),c$r=l(),Lx=a("p"),f$r=o("This class cannot be instantiated directly using "),ZMe=a("code"),m$r=o("__init__()"),g$r=o(" (throws an error)."),h$r=l(),Xt=a("div"),F(xx.$$.fragment),p$r=l(),e4e=a("p"),_$r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),u$r=l(),jc=a("p"),b$r=o(`Note:
Loading a model from its configuration file does `),o4e=a("strong"),v$r=o("not"),F$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=a("a"),T$r=o("from_pretrained()"),M$r=o(" to load the model weights."),E$r=l(),F(p3.$$.fragment),C$r=l(),Or=a("div"),F($x.$$.fragment),w$r=l(),r4e=a("p"),A$r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),y$r=l(),un=a("p"),L$r=o("The model class to instantiate is selected based on the "),t4e=a("code"),x$r=o("model_type"),$$r=o(` property of the config object (either
passed as an argument or loaded from `),a4e=a("code"),k$r=o("pretrained_model_name_or_path"),S$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n4e=a("code"),R$r=o("pretrained_model_name_or_path"),P$r=o(":"),B$r=l(),xe=a("ul"),_3=a("li"),s4e=a("strong"),I$r=o("albert"),q$r=o(" \u2014 "),dY=a("a"),N$r=o("FlaxAlbertForMaskedLM"),j$r=o(" (ALBERT model)"),D$r=l(),u3=a("li"),l4e=a("strong"),G$r=o("bart"),O$r=o(" \u2014 "),cY=a("a"),V$r=o("FlaxBartForConditionalGeneration"),X$r=o(" (BART model)"),z$r=l(),b3=a("li"),i4e=a("strong"),W$r=o("bert"),Q$r=o(" \u2014 "),fY=a("a"),H$r=o("FlaxBertForMaskedLM"),U$r=o(" (BERT model)"),J$r=l(),v3=a("li"),d4e=a("strong"),Y$r=o("big_bird"),K$r=o(" \u2014 "),mY=a("a"),Z$r=o("FlaxBigBirdForMaskedLM"),ekr=o(" (BigBird model)"),okr=l(),F3=a("li"),c4e=a("strong"),rkr=o("distilbert"),tkr=o(" \u2014 "),gY=a("a"),akr=o("FlaxDistilBertForMaskedLM"),nkr=o(" (DistilBERT model)"),skr=l(),T3=a("li"),f4e=a("strong"),lkr=o("electra"),ikr=o(" \u2014 "),hY=a("a"),dkr=o("FlaxElectraForMaskedLM"),ckr=o(" (ELECTRA model)"),fkr=l(),M3=a("li"),m4e=a("strong"),mkr=o("mbart"),gkr=o(" \u2014 "),pY=a("a"),hkr=o("FlaxMBartForConditionalGeneration"),pkr=o(" (mBART model)"),_kr=l(),E3=a("li"),g4e=a("strong"),ukr=o("roberta"),bkr=o(" \u2014 "),_Y=a("a"),vkr=o("FlaxRobertaForMaskedLM"),Fkr=o(" (RoBERTa model)"),Tkr=l(),C3=a("li"),h4e=a("strong"),Mkr=o("roformer"),Ekr=o(" \u2014 "),uY=a("a"),Ckr=o("FlaxRoFormerForMaskedLM"),wkr=o(" (RoFormer model)"),Akr=l(),w3=a("li"),p4e=a("strong"),ykr=o("xlm-roberta"),Lkr=o(" \u2014 "),bY=a("a"),xkr=o("FlaxXLMRobertaForMaskedLM"),$kr=o(" (XLM-RoBERTa model)"),kkr=l(),F(A3.$$.fragment),INe=l(),Dc=a("h2"),y3=a("a"),_4e=a("span"),F(kx.$$.fragment),Skr=l(),u4e=a("span"),Rkr=o("FlaxAutoModelForSeq2SeqLM"),qNe=l(),pr=a("div"),F(Sx.$$.fragment),Pkr=l(),Gc=a("p"),Bkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),vY=a("a"),Ikr=o("from_pretrained()"),qkr=o(" class method or the "),FY=a("a"),Nkr=o("from_config()"),jkr=o(` class
method.`),Dkr=l(),Rx=a("p"),Gkr=o("This class cannot be instantiated directly using "),b4e=a("code"),Okr=o("__init__()"),Vkr=o(" (throws an error)."),Xkr=l(),zt=a("div"),F(Px.$$.fragment),zkr=l(),v4e=a("p"),Wkr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qkr=l(),Oc=a("p"),Hkr=o(`Note:
Loading a model from its configuration file does `),F4e=a("strong"),Ukr=o("not"),Jkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TY=a("a"),Ykr=o("from_pretrained()"),Kkr=o(" to load the model weights."),Zkr=l(),F(L3.$$.fragment),eSr=l(),Vr=a("div"),F(Bx.$$.fragment),oSr=l(),T4e=a("p"),rSr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),tSr=l(),bn=a("p"),aSr=o("The model class to instantiate is selected based on the "),M4e=a("code"),nSr=o("model_type"),sSr=o(` property of the config object (either
passed as an argument or loaded from `),E4e=a("code"),lSr=o("pretrained_model_name_or_path"),iSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C4e=a("code"),dSr=o("pretrained_model_name_or_path"),cSr=o(":"),fSr=l(),Pe=a("ul"),x3=a("li"),w4e=a("strong"),mSr=o("bart"),gSr=o(" \u2014 "),MY=a("a"),hSr=o("FlaxBartForConditionalGeneration"),pSr=o(" (BART model)"),_Sr=l(),$3=a("li"),A4e=a("strong"),uSr=o("blenderbot"),bSr=o(" \u2014 "),EY=a("a"),vSr=o("FlaxBlenderbotForConditionalGeneration"),FSr=o(" (Blenderbot model)"),TSr=l(),k3=a("li"),y4e=a("strong"),MSr=o("blenderbot-small"),ESr=o(" \u2014 "),CY=a("a"),CSr=o("FlaxBlenderbotSmallForConditionalGeneration"),wSr=o(" (BlenderbotSmall model)"),ASr=l(),S3=a("li"),L4e=a("strong"),ySr=o("encoder-decoder"),LSr=o(" \u2014 "),wY=a("a"),xSr=o("FlaxEncoderDecoderModel"),$Sr=o(" (Encoder decoder model)"),kSr=l(),R3=a("li"),x4e=a("strong"),SSr=o("marian"),RSr=o(" \u2014 "),AY=a("a"),PSr=o("FlaxMarianMTModel"),BSr=o(" (Marian model)"),ISr=l(),P3=a("li"),$4e=a("strong"),qSr=o("mbart"),NSr=o(" \u2014 "),yY=a("a"),jSr=o("FlaxMBartForConditionalGeneration"),DSr=o(" (mBART model)"),GSr=l(),B3=a("li"),k4e=a("strong"),OSr=o("mt5"),VSr=o(" \u2014 "),LY=a("a"),XSr=o("FlaxMT5ForConditionalGeneration"),zSr=o(" (mT5 model)"),WSr=l(),I3=a("li"),S4e=a("strong"),QSr=o("pegasus"),HSr=o(" \u2014 "),xY=a("a"),USr=o("FlaxPegasusForConditionalGeneration"),JSr=o(" (Pegasus model)"),YSr=l(),q3=a("li"),R4e=a("strong"),KSr=o("t5"),ZSr=o(" \u2014 "),$Y=a("a"),eRr=o("FlaxT5ForConditionalGeneration"),oRr=o(" (T5 model)"),rRr=l(),F(N3.$$.fragment),NNe=l(),Vc=a("h2"),j3=a("a"),P4e=a("span"),F(Ix.$$.fragment),tRr=l(),B4e=a("span"),aRr=o("FlaxAutoModelForSequenceClassification"),jNe=l(),_r=a("div"),F(qx.$$.fragment),nRr=l(),Xc=a("p"),sRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),kY=a("a"),lRr=o("from_pretrained()"),iRr=o(" class method or the "),SY=a("a"),dRr=o("from_config()"),cRr=o(` class
method.`),fRr=l(),Nx=a("p"),mRr=o("This class cannot be instantiated directly using "),I4e=a("code"),gRr=o("__init__()"),hRr=o(" (throws an error)."),pRr=l(),Wt=a("div"),F(jx.$$.fragment),_Rr=l(),q4e=a("p"),uRr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),bRr=l(),zc=a("p"),vRr=o(`Note:
Loading a model from its configuration file does `),N4e=a("strong"),FRr=o("not"),TRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=a("a"),MRr=o("from_pretrained()"),ERr=o(" to load the model weights."),CRr=l(),F(D3.$$.fragment),wRr=l(),Xr=a("div"),F(Dx.$$.fragment),ARr=l(),j4e=a("p"),yRr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),LRr=l(),vn=a("p"),xRr=o("The model class to instantiate is selected based on the "),D4e=a("code"),$Rr=o("model_type"),kRr=o(` property of the config object (either
passed as an argument or loaded from `),G4e=a("code"),SRr=o("pretrained_model_name_or_path"),RRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O4e=a("code"),PRr=o("pretrained_model_name_or_path"),BRr=o(":"),IRr=l(),$e=a("ul"),G3=a("li"),V4e=a("strong"),qRr=o("albert"),NRr=o(" \u2014 "),PY=a("a"),jRr=o("FlaxAlbertForSequenceClassification"),DRr=o(" (ALBERT model)"),GRr=l(),O3=a("li"),X4e=a("strong"),ORr=o("bart"),VRr=o(" \u2014 "),BY=a("a"),XRr=o("FlaxBartForSequenceClassification"),zRr=o(" (BART model)"),WRr=l(),V3=a("li"),z4e=a("strong"),QRr=o("bert"),HRr=o(" \u2014 "),IY=a("a"),URr=o("FlaxBertForSequenceClassification"),JRr=o(" (BERT model)"),YRr=l(),X3=a("li"),W4e=a("strong"),KRr=o("big_bird"),ZRr=o(" \u2014 "),qY=a("a"),ePr=o("FlaxBigBirdForSequenceClassification"),oPr=o(" (BigBird model)"),rPr=l(),z3=a("li"),Q4e=a("strong"),tPr=o("distilbert"),aPr=o(" \u2014 "),NY=a("a"),nPr=o("FlaxDistilBertForSequenceClassification"),sPr=o(" (DistilBERT model)"),lPr=l(),W3=a("li"),H4e=a("strong"),iPr=o("electra"),dPr=o(" \u2014 "),jY=a("a"),cPr=o("FlaxElectraForSequenceClassification"),fPr=o(" (ELECTRA model)"),mPr=l(),Q3=a("li"),U4e=a("strong"),gPr=o("mbart"),hPr=o(" \u2014 "),DY=a("a"),pPr=o("FlaxMBartForSequenceClassification"),_Pr=o(" (mBART model)"),uPr=l(),H3=a("li"),J4e=a("strong"),bPr=o("roberta"),vPr=o(" \u2014 "),GY=a("a"),FPr=o("FlaxRobertaForSequenceClassification"),TPr=o(" (RoBERTa model)"),MPr=l(),U3=a("li"),Y4e=a("strong"),EPr=o("roformer"),CPr=o(" \u2014 "),OY=a("a"),wPr=o("FlaxRoFormerForSequenceClassification"),APr=o(" (RoFormer model)"),yPr=l(),J3=a("li"),K4e=a("strong"),LPr=o("xlm-roberta"),xPr=o(" \u2014 "),VY=a("a"),$Pr=o("FlaxXLMRobertaForSequenceClassification"),kPr=o(" (XLM-RoBERTa model)"),SPr=l(),F(Y3.$$.fragment),DNe=l(),Wc=a("h2"),K3=a("a"),Z4e=a("span"),F(Gx.$$.fragment),RPr=l(),eEe=a("span"),PPr=o("FlaxAutoModelForQuestionAnswering"),GNe=l(),ur=a("div"),F(Ox.$$.fragment),BPr=l(),Qc=a("p"),IPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),XY=a("a"),qPr=o("from_pretrained()"),NPr=o(" class method or the "),zY=a("a"),jPr=o("from_config()"),DPr=o(` class
method.`),GPr=l(),Vx=a("p"),OPr=o("This class cannot be instantiated directly using "),oEe=a("code"),VPr=o("__init__()"),XPr=o(" (throws an error)."),zPr=l(),Qt=a("div"),F(Xx.$$.fragment),WPr=l(),rEe=a("p"),QPr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),HPr=l(),Hc=a("p"),UPr=o(`Note:
Loading a model from its configuration file does `),tEe=a("strong"),JPr=o("not"),YPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WY=a("a"),KPr=o("from_pretrained()"),ZPr=o(" to load the model weights."),eBr=l(),F(Z3.$$.fragment),oBr=l(),zr=a("div"),F(zx.$$.fragment),rBr=l(),aEe=a("p"),tBr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),aBr=l(),Fn=a("p"),nBr=o("The model class to instantiate is selected based on the "),nEe=a("code"),sBr=o("model_type"),lBr=o(` property of the config object (either
passed as an argument or loaded from `),sEe=a("code"),iBr=o("pretrained_model_name_or_path"),dBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lEe=a("code"),cBr=o("pretrained_model_name_or_path"),fBr=o(":"),mBr=l(),ke=a("ul"),ew=a("li"),iEe=a("strong"),gBr=o("albert"),hBr=o(" \u2014 "),QY=a("a"),pBr=o("FlaxAlbertForQuestionAnswering"),_Br=o(" (ALBERT model)"),uBr=l(),ow=a("li"),dEe=a("strong"),bBr=o("bart"),vBr=o(" \u2014 "),HY=a("a"),FBr=o("FlaxBartForQuestionAnswering"),TBr=o(" (BART model)"),MBr=l(),rw=a("li"),cEe=a("strong"),EBr=o("bert"),CBr=o(" \u2014 "),UY=a("a"),wBr=o("FlaxBertForQuestionAnswering"),ABr=o(" (BERT model)"),yBr=l(),tw=a("li"),fEe=a("strong"),LBr=o("big_bird"),xBr=o(" \u2014 "),JY=a("a"),$Br=o("FlaxBigBirdForQuestionAnswering"),kBr=o(" (BigBird model)"),SBr=l(),aw=a("li"),mEe=a("strong"),RBr=o("distilbert"),PBr=o(" \u2014 "),YY=a("a"),BBr=o("FlaxDistilBertForQuestionAnswering"),IBr=o(" (DistilBERT model)"),qBr=l(),nw=a("li"),gEe=a("strong"),NBr=o("electra"),jBr=o(" \u2014 "),KY=a("a"),DBr=o("FlaxElectraForQuestionAnswering"),GBr=o(" (ELECTRA model)"),OBr=l(),sw=a("li"),hEe=a("strong"),VBr=o("mbart"),XBr=o(" \u2014 "),ZY=a("a"),zBr=o("FlaxMBartForQuestionAnswering"),WBr=o(" (mBART model)"),QBr=l(),lw=a("li"),pEe=a("strong"),HBr=o("roberta"),UBr=o(" \u2014 "),eK=a("a"),JBr=o("FlaxRobertaForQuestionAnswering"),YBr=o(" (RoBERTa model)"),KBr=l(),iw=a("li"),_Ee=a("strong"),ZBr=o("roformer"),eIr=o(" \u2014 "),oK=a("a"),oIr=o("FlaxRoFormerForQuestionAnswering"),rIr=o(" (RoFormer model)"),tIr=l(),dw=a("li"),uEe=a("strong"),aIr=o("xlm-roberta"),nIr=o(" \u2014 "),rK=a("a"),sIr=o("FlaxXLMRobertaForQuestionAnswering"),lIr=o(" (XLM-RoBERTa model)"),iIr=l(),F(cw.$$.fragment),ONe=l(),Uc=a("h2"),fw=a("a"),bEe=a("span"),F(Wx.$$.fragment),dIr=l(),vEe=a("span"),cIr=o("FlaxAutoModelForTokenClassification"),VNe=l(),br=a("div"),F(Qx.$$.fragment),fIr=l(),Jc=a("p"),mIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),tK=a("a"),gIr=o("from_pretrained()"),hIr=o(" class method or the "),aK=a("a"),pIr=o("from_config()"),_Ir=o(` class
method.`),uIr=l(),Hx=a("p"),bIr=o("This class cannot be instantiated directly using "),FEe=a("code"),vIr=o("__init__()"),FIr=o(" (throws an error)."),TIr=l(),Ht=a("div"),F(Ux.$$.fragment),MIr=l(),TEe=a("p"),EIr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),CIr=l(),Yc=a("p"),wIr=o(`Note:
Loading a model from its configuration file does `),MEe=a("strong"),AIr=o("not"),yIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),LIr=o("from_pretrained()"),xIr=o(" to load the model weights."),$Ir=l(),F(mw.$$.fragment),kIr=l(),Wr=a("div"),F(Jx.$$.fragment),SIr=l(),EEe=a("p"),RIr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),PIr=l(),Tn=a("p"),BIr=o("The model class to instantiate is selected based on the "),CEe=a("code"),IIr=o("model_type"),qIr=o(` property of the config object (either
passed as an argument or loaded from `),wEe=a("code"),NIr=o("pretrained_model_name_or_path"),jIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AEe=a("code"),DIr=o("pretrained_model_name_or_path"),GIr=o(":"),OIr=l(),Ge=a("ul"),gw=a("li"),yEe=a("strong"),VIr=o("albert"),XIr=o(" \u2014 "),sK=a("a"),zIr=o("FlaxAlbertForTokenClassification"),WIr=o(" (ALBERT model)"),QIr=l(),hw=a("li"),LEe=a("strong"),HIr=o("bert"),UIr=o(" \u2014 "),lK=a("a"),JIr=o("FlaxBertForTokenClassification"),YIr=o(" (BERT model)"),KIr=l(),pw=a("li"),xEe=a("strong"),ZIr=o("big_bird"),eqr=o(" \u2014 "),iK=a("a"),oqr=o("FlaxBigBirdForTokenClassification"),rqr=o(" (BigBird model)"),tqr=l(),_w=a("li"),$Ee=a("strong"),aqr=o("distilbert"),nqr=o(" \u2014 "),dK=a("a"),sqr=o("FlaxDistilBertForTokenClassification"),lqr=o(" (DistilBERT model)"),iqr=l(),uw=a("li"),kEe=a("strong"),dqr=o("electra"),cqr=o(" \u2014 "),cK=a("a"),fqr=o("FlaxElectraForTokenClassification"),mqr=o(" (ELECTRA model)"),gqr=l(),bw=a("li"),SEe=a("strong"),hqr=o("roberta"),pqr=o(" \u2014 "),fK=a("a"),_qr=o("FlaxRobertaForTokenClassification"),uqr=o(" (RoBERTa model)"),bqr=l(),vw=a("li"),REe=a("strong"),vqr=o("roformer"),Fqr=o(" \u2014 "),mK=a("a"),Tqr=o("FlaxRoFormerForTokenClassification"),Mqr=o(" (RoFormer model)"),Eqr=l(),Fw=a("li"),PEe=a("strong"),Cqr=o("xlm-roberta"),wqr=o(" \u2014 "),gK=a("a"),Aqr=o("FlaxXLMRobertaForTokenClassification"),yqr=o(" (XLM-RoBERTa model)"),Lqr=l(),F(Tw.$$.fragment),XNe=l(),Kc=a("h2"),Mw=a("a"),BEe=a("span"),F(Yx.$$.fragment),xqr=l(),IEe=a("span"),$qr=o("FlaxAutoModelForMultipleChoice"),zNe=l(),vr=a("div"),F(Kx.$$.fragment),kqr=l(),Zc=a("p"),Sqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),hK=a("a"),Rqr=o("from_pretrained()"),Pqr=o(" class method or the "),pK=a("a"),Bqr=o("from_config()"),Iqr=o(` class
method.`),qqr=l(),Zx=a("p"),Nqr=o("This class cannot be instantiated directly using "),qEe=a("code"),jqr=o("__init__()"),Dqr=o(" (throws an error)."),Gqr=l(),Ut=a("div"),F(e9.$$.fragment),Oqr=l(),NEe=a("p"),Vqr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Xqr=l(),ef=a("p"),zqr=o(`Note:
Loading a model from its configuration file does `),jEe=a("strong"),Wqr=o("not"),Qqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=a("a"),Hqr=o("from_pretrained()"),Uqr=o(" to load the model weights."),Jqr=l(),F(Ew.$$.fragment),Yqr=l(),Qr=a("div"),F(o9.$$.fragment),Kqr=l(),DEe=a("p"),Zqr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),eNr=l(),Mn=a("p"),oNr=o("The model class to instantiate is selected based on the "),GEe=a("code"),rNr=o("model_type"),tNr=o(` property of the config object (either
passed as an argument or loaded from `),OEe=a("code"),aNr=o("pretrained_model_name_or_path"),nNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VEe=a("code"),sNr=o("pretrained_model_name_or_path"),lNr=o(":"),iNr=l(),Oe=a("ul"),Cw=a("li"),XEe=a("strong"),dNr=o("albert"),cNr=o(" \u2014 "),uK=a("a"),fNr=o("FlaxAlbertForMultipleChoice"),mNr=o(" (ALBERT model)"),gNr=l(),ww=a("li"),zEe=a("strong"),hNr=o("bert"),pNr=o(" \u2014 "),bK=a("a"),_Nr=o("FlaxBertForMultipleChoice"),uNr=o(" (BERT model)"),bNr=l(),Aw=a("li"),WEe=a("strong"),vNr=o("big_bird"),FNr=o(" \u2014 "),vK=a("a"),TNr=o("FlaxBigBirdForMultipleChoice"),MNr=o(" (BigBird model)"),ENr=l(),yw=a("li"),QEe=a("strong"),CNr=o("distilbert"),wNr=o(" \u2014 "),FK=a("a"),ANr=o("FlaxDistilBertForMultipleChoice"),yNr=o(" (DistilBERT model)"),LNr=l(),Lw=a("li"),HEe=a("strong"),xNr=o("electra"),$Nr=o(" \u2014 "),TK=a("a"),kNr=o("FlaxElectraForMultipleChoice"),SNr=o(" (ELECTRA model)"),RNr=l(),xw=a("li"),UEe=a("strong"),PNr=o("roberta"),BNr=o(" \u2014 "),MK=a("a"),INr=o("FlaxRobertaForMultipleChoice"),qNr=o(" (RoBERTa model)"),NNr=l(),$w=a("li"),JEe=a("strong"),jNr=o("roformer"),DNr=o(" \u2014 "),EK=a("a"),GNr=o("FlaxRoFormerForMultipleChoice"),ONr=o(" (RoFormer model)"),VNr=l(),kw=a("li"),YEe=a("strong"),XNr=o("xlm-roberta"),zNr=o(" \u2014 "),CK=a("a"),WNr=o("FlaxXLMRobertaForMultipleChoice"),QNr=o(" (XLM-RoBERTa model)"),HNr=l(),F(Sw.$$.fragment),WNe=l(),of=a("h2"),Rw=a("a"),KEe=a("span"),F(r9.$$.fragment),UNr=l(),ZEe=a("span"),JNr=o("FlaxAutoModelForNextSentencePrediction"),QNe=l(),Fr=a("div"),F(t9.$$.fragment),YNr=l(),rf=a("p"),KNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wK=a("a"),ZNr=o("from_pretrained()"),ejr=o(" class method or the "),AK=a("a"),ojr=o("from_config()"),rjr=o(` class
method.`),tjr=l(),a9=a("p"),ajr=o("This class cannot be instantiated directly using "),eCe=a("code"),njr=o("__init__()"),sjr=o(" (throws an error)."),ljr=l(),Jt=a("div"),F(n9.$$.fragment),ijr=l(),oCe=a("p"),djr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),cjr=l(),tf=a("p"),fjr=o(`Note:
Loading a model from its configuration file does `),rCe=a("strong"),mjr=o("not"),gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),hjr=o("from_pretrained()"),pjr=o(" to load the model weights."),_jr=l(),F(Pw.$$.fragment),ujr=l(),Hr=a("div"),F(s9.$$.fragment),bjr=l(),tCe=a("p"),vjr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Fjr=l(),En=a("p"),Tjr=o("The model class to instantiate is selected based on the "),aCe=a("code"),Mjr=o("model_type"),Ejr=o(` property of the config object (either
passed as an argument or loaded from `),nCe=a("code"),Cjr=o("pretrained_model_name_or_path"),wjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sCe=a("code"),Ajr=o("pretrained_model_name_or_path"),yjr=o(":"),Ljr=l(),lCe=a("ul"),Bw=a("li"),iCe=a("strong"),xjr=o("bert"),$jr=o(" \u2014 "),LK=a("a"),kjr=o("FlaxBertForNextSentencePrediction"),Sjr=o(" (BERT model)"),Rjr=l(),F(Iw.$$.fragment),HNe=l(),af=a("h2"),qw=a("a"),dCe=a("span"),F(l9.$$.fragment),Pjr=l(),cCe=a("span"),Bjr=o("FlaxAutoModelForImageClassification"),UNe=l(),Tr=a("div"),F(i9.$$.fragment),Ijr=l(),nf=a("p"),qjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),xK=a("a"),Njr=o("from_pretrained()"),jjr=o(" class method or the "),$K=a("a"),Djr=o("from_config()"),Gjr=o(` class
method.`),Ojr=l(),d9=a("p"),Vjr=o("This class cannot be instantiated directly using "),fCe=a("code"),Xjr=o("__init__()"),zjr=o(" (throws an error)."),Wjr=l(),Yt=a("div"),F(c9.$$.fragment),Qjr=l(),mCe=a("p"),Hjr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Ujr=l(),sf=a("p"),Jjr=o(`Note:
Loading a model from its configuration file does `),gCe=a("strong"),Yjr=o("not"),Kjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),Zjr=o("from_pretrained()"),eDr=o(" to load the model weights."),oDr=l(),F(Nw.$$.fragment),rDr=l(),Ur=a("div"),F(f9.$$.fragment),tDr=l(),hCe=a("p"),aDr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),nDr=l(),Cn=a("p"),sDr=o("The model class to instantiate is selected based on the "),pCe=a("code"),lDr=o("model_type"),iDr=o(` property of the config object (either
passed as an argument or loaded from `),_Ce=a("code"),dDr=o("pretrained_model_name_or_path"),cDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=a("code"),fDr=o("pretrained_model_name_or_path"),mDr=o(":"),gDr=l(),m9=a("ul"),jw=a("li"),bCe=a("strong"),hDr=o("beit"),pDr=o(" \u2014 "),SK=a("a"),_Dr=o("FlaxBeitForImageClassification"),uDr=o(" (BEiT model)"),bDr=l(),Dw=a("li"),vCe=a("strong"),vDr=o("vit"),FDr=o(" \u2014 "),RK=a("a"),TDr=o("FlaxViTForImageClassification"),MDr=o(" (ViT model)"),EDr=l(),F(Gw.$$.fragment),JNe=l(),lf=a("h2"),Ow=a("a"),FCe=a("span"),F(g9.$$.fragment),CDr=l(),TCe=a("span"),wDr=o("FlaxAutoModelForVision2Seq"),YNe=l(),Mr=a("div"),F(h9.$$.fragment),ADr=l(),df=a("p"),yDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),PK=a("a"),LDr=o("from_pretrained()"),xDr=o(" class method or the "),BK=a("a"),$Dr=o("from_config()"),kDr=o(` class
method.`),SDr=l(),p9=a("p"),RDr=o("This class cannot be instantiated directly using "),MCe=a("code"),PDr=o("__init__()"),BDr=o(" (throws an error)."),IDr=l(),Kt=a("div"),F(_9.$$.fragment),qDr=l(),ECe=a("p"),NDr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),jDr=l(),cf=a("p"),DDr=o(`Note:
Loading a model from its configuration file does `),CCe=a("strong"),GDr=o("not"),ODr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),VDr=o("from_pretrained()"),XDr=o(" to load the model weights."),zDr=l(),F(Vw.$$.fragment),WDr=l(),Jr=a("div"),F(u9.$$.fragment),QDr=l(),wCe=a("p"),HDr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),UDr=l(),wn=a("p"),JDr=o("The model class to instantiate is selected based on the "),ACe=a("code"),YDr=o("model_type"),KDr=o(` property of the config object (either
passed as an argument or loaded from `),yCe=a("code"),ZDr=o("pretrained_model_name_or_path"),eGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=a("code"),oGr=o("pretrained_model_name_or_path"),rGr=o(":"),tGr=l(),xCe=a("ul"),Xw=a("li"),$Ce=a("strong"),aGr=o("vision-encoder-decoder"),nGr=o(" \u2014 "),qK=a("a"),sGr=o("FlaxVisionEncoderDecoderModel"),lGr=o(" (Vision Encoder decoder model)"),iGr=l(),F(zw.$$.fragment),this.h()},l(f){const u=g8t('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var b9=s(p);m=n(b9,"A",{id:!0,class:!0,href:!0});var kCe=s(m);_=n(kCe,"SPAN",{});var SCe=s(_);T(d.$$.fragment,SCe),SCe.forEach(t),kCe.forEach(t),h=i(b9),Mo=n(b9,"SPAN",{});var RCe=s(Mo);ci=r(RCe,"Auto Classes"),RCe.forEach(t),b9.forEach(t),hf=i(f),rt=n(f,"P",{});var v9=s(rt);fi=r(v9,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),mi=n(v9,"CODE",{});var PCe=s(mi);d6=r(PCe,"from_pretrained()"),PCe.forEach(t),pf=r(v9,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),v9.forEach(t),De=i(f),We=n(f,"P",{});var An=s(We);gi=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var BCe=s(yn);c6=r(BCe,"AutoConfig"),BCe.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var ICe=s(xn);f6=r(ICe,"AutoModel"),ICe.forEach(t),hi=r(An,`, and
`),$n=n(An,"A",{href:!0});var qCe=s($n);m6=r(qCe,"AutoTokenizer"),qCe.forEach(t),pi=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),_f=i(f),T(Ca.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var F9=s(Ae);$$=r(F9,"will create a model that is an instance of "),_i=n(F9,"A",{href:!0});var NCe=s(_i);k$=r(NCe,"BertModel"),NCe.forEach(t),S$=r(F9,"."),F9.forEach(t),Eo=i(f),wa=n(f,"P",{});var T9=s(wa);R$=r(T9,"There is one class of "),uf=n(T9,"CODE",{});var jCe=s(uf);P$=r(jCe,"AutoModel"),jCe.forEach(t),sGe=r(T9," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),T9.forEach(t),UIe=i(f),ui=n(f,"H2",{class:!0});var M9=s(ui);bf=n(M9,"A",{id:!0,class:!0,href:!0});var DCe=s(bf);$ee=n(DCe,"SPAN",{});var GCe=s($ee);T(g6.$$.fragment,GCe),GCe.forEach(t),DCe.forEach(t),lGe=i(M9),kee=n(M9,"SPAN",{});var OCe=s(kee);iGe=r(OCe,"Extending the Auto Classes"),OCe.forEach(t),M9.forEach(t),JIe=i(f),kn=n(f,"P",{});var ff=s(kn);dGe=r(ff,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),See=n(ff,"CODE",{});var VCe=s(See);cGe=r(VCe,"NewModel"),VCe.forEach(t),fGe=r(ff,", make sure you have a "),Ree=n(ff,"CODE",{});var XCe=s(Ree);mGe=r(XCe,"NewModelConfig"),XCe.forEach(t),gGe=r(ff,` then you can add those to the auto
classes like this:`),ff.forEach(t),YIe=i(f),T(h6.$$.fragment,f),KIe=i(f),B$=n(f,"P",{});var zCe=s(B$);hGe=r(zCe,"You will then be able to use the auto classes like you would usually do!"),zCe.forEach(t),ZIe=i(f),T(vf.$$.fragment,f),eqe=i(f),bi=n(f,"H2",{class:!0});var E9=s(bi);Ff=n(E9,"A",{id:!0,class:!0,href:!0});var WCe=s(Ff);Pee=n(WCe,"SPAN",{});var QCe=s(Pee);T(p6.$$.fragment,QCe),QCe.forEach(t),WCe.forEach(t),pGe=i(E9),Bee=n(E9,"SPAN",{});var HCe=s(Bee);_Ge=r(HCe,"AutoConfig"),HCe.forEach(t),E9.forEach(t),oqe=i(f),Co=n(f,"DIV",{class:!0});var et=s(Co);T(_6.$$.fragment,et),uGe=i(et),u6=n(et,"P",{});var C9=s(u6);bGe=r(C9,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),I$=n(C9,"A",{href:!0});var UCe=s(I$);vGe=r(UCe,"from_pretrained()"),UCe.forEach(t),FGe=r(C9," class method."),C9.forEach(t),TGe=i(et),b6=n(et,"P",{});var w9=s(b6);MGe=r(w9,"This class cannot be instantiated directly using "),Iee=n(w9,"CODE",{});var JCe=s(Iee);EGe=r(JCe,"__init__()"),JCe.forEach(t),CGe=r(w9," (throws an error)."),w9.forEach(t),wGe=i(et),Er=n(et,"DIV",{class:!0});var ot=s(Er);T(v6.$$.fragment,ot),AGe=i(ot),qee=n(ot,"P",{});var YCe=s(qee);yGe=r(YCe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),YCe.forEach(t),LGe=i(ot),vi=n(ot,"P",{});var mf=s(vi);xGe=r(mf,"The configuration class to instantiate is selected based on the "),Nee=n(mf,"CODE",{});var KCe=s(Nee);$Ge=r(KCe,"model_type"),KCe.forEach(t),kGe=r(mf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),jee=n(mf,"CODE",{});var ZCe=s(jee);SGe=r(ZCe,"pretrained_model_name_or_path"),ZCe.forEach(t),RGe=r(mf,":"),mf.forEach(t),PGe=i(ot),A=n(ot,"UL",{});var y=s(A);Tf=n(y,"LI",{});var Ww=s(Tf);Dee=n(Ww,"STRONG",{});var e5e=s(Dee);BGe=r(e5e,"albert"),e5e.forEach(t),IGe=r(Ww," \u2014 "),q$=n(Ww,"A",{href:!0});var o5e=s(q$);qGe=r(o5e,"AlbertConfig"),o5e.forEach(t),NGe=r(Ww," (ALBERT model)"),Ww.forEach(t),jGe=i(y),Mf=n(y,"LI",{});var Qw=s(Mf);Gee=n(Qw,"STRONG",{});var r5e=s(Gee);DGe=r(r5e,"bart"),r5e.forEach(t),GGe=r(Qw," \u2014 "),N$=n(Qw,"A",{href:!0});var t5e=s(N$);OGe=r(t5e,"BartConfig"),t5e.forEach(t),VGe=r(Qw," (BART model)"),Qw.forEach(t),XGe=i(y),Ef=n(y,"LI",{});var Hw=s(Ef);Oee=n(Hw,"STRONG",{});var a5e=s(Oee);zGe=r(a5e,"beit"),a5e.forEach(t),WGe=r(Hw," \u2014 "),j$=n(Hw,"A",{href:!0});var n5e=s(j$);QGe=r(n5e,"BeitConfig"),n5e.forEach(t),HGe=r(Hw," (BEiT model)"),Hw.forEach(t),UGe=i(y),Cf=n(y,"LI",{});var Uw=s(Cf);Vee=n(Uw,"STRONG",{});var s5e=s(Vee);JGe=r(s5e,"bert"),s5e.forEach(t),YGe=r(Uw," \u2014 "),D$=n(Uw,"A",{href:!0});var l5e=s(D$);KGe=r(l5e,"BertConfig"),l5e.forEach(t),ZGe=r(Uw," (BERT model)"),Uw.forEach(t),eOe=i(y),wf=n(y,"LI",{});var Jw=s(wf);Xee=n(Jw,"STRONG",{});var i5e=s(Xee);oOe=r(i5e,"bert-generation"),i5e.forEach(t),rOe=r(Jw," \u2014 "),G$=n(Jw,"A",{href:!0});var d5e=s(G$);tOe=r(d5e,"BertGenerationConfig"),d5e.forEach(t),aOe=r(Jw," (Bert Generation model)"),Jw.forEach(t),nOe=i(y),Af=n(y,"LI",{});var Yw=s(Af);zee=n(Yw,"STRONG",{});var c5e=s(zee);sOe=r(c5e,"big_bird"),c5e.forEach(t),lOe=r(Yw," \u2014 "),O$=n(Yw,"A",{href:!0});var f5e=s(O$);iOe=r(f5e,"BigBirdConfig"),f5e.forEach(t),dOe=r(Yw," (BigBird model)"),Yw.forEach(t),cOe=i(y),yf=n(y,"LI",{});var Kw=s(yf);Wee=n(Kw,"STRONG",{});var m5e=s(Wee);fOe=r(m5e,"bigbird_pegasus"),m5e.forEach(t),mOe=r(Kw," \u2014 "),V$=n(Kw,"A",{href:!0});var g5e=s(V$);gOe=r(g5e,"BigBirdPegasusConfig"),g5e.forEach(t),hOe=r(Kw," (BigBirdPegasus model)"),Kw.forEach(t),pOe=i(y),Lf=n(y,"LI",{});var Zw=s(Lf);Qee=n(Zw,"STRONG",{});var h5e=s(Qee);_Oe=r(h5e,"blenderbot"),h5e.forEach(t),uOe=r(Zw," \u2014 "),X$=n(Zw,"A",{href:!0});var p5e=s(X$);bOe=r(p5e,"BlenderbotConfig"),p5e.forEach(t),vOe=r(Zw," (Blenderbot model)"),Zw.forEach(t),FOe=i(y),xf=n(y,"LI",{});var e0=s(xf);Hee=n(e0,"STRONG",{});var _5e=s(Hee);TOe=r(_5e,"blenderbot-small"),_5e.forEach(t),MOe=r(e0," \u2014 "),z$=n(e0,"A",{href:!0});var u5e=s(z$);EOe=r(u5e,"BlenderbotSmallConfig"),u5e.forEach(t),COe=r(e0," (BlenderbotSmall model)"),e0.forEach(t),wOe=i(y),$f=n(y,"LI",{});var o0=s($f);Uee=n(o0,"STRONG",{});var b5e=s(Uee);AOe=r(b5e,"camembert"),b5e.forEach(t),yOe=r(o0," \u2014 "),W$=n(o0,"A",{href:!0});var v5e=s(W$);LOe=r(v5e,"CamembertConfig"),v5e.forEach(t),xOe=r(o0," (CamemBERT model)"),o0.forEach(t),$Oe=i(y),kf=n(y,"LI",{});var r0=s(kf);Jee=n(r0,"STRONG",{});var F5e=s(Jee);kOe=r(F5e,"canine"),F5e.forEach(t),SOe=r(r0," \u2014 "),Q$=n(r0,"A",{href:!0});var T5e=s(Q$);ROe=r(T5e,"CanineConfig"),T5e.forEach(t),POe=r(r0," (Canine model)"),r0.forEach(t),BOe=i(y),Sf=n(y,"LI",{});var t0=s(Sf);Yee=n(t0,"STRONG",{});var M5e=s(Yee);IOe=r(M5e,"clip"),M5e.forEach(t),qOe=r(t0," \u2014 "),H$=n(t0,"A",{href:!0});var E5e=s(H$);NOe=r(E5e,"CLIPConfig"),E5e.forEach(t),jOe=r(t0," (CLIP model)"),t0.forEach(t),DOe=i(y),Rf=n(y,"LI",{});var a0=s(Rf);Kee=n(a0,"STRONG",{});var C5e=s(Kee);GOe=r(C5e,"convbert"),C5e.forEach(t),OOe=r(a0," \u2014 "),U$=n(a0,"A",{href:!0});var w5e=s(U$);VOe=r(w5e,"ConvBertConfig"),w5e.forEach(t),XOe=r(a0," (ConvBERT model)"),a0.forEach(t),zOe=i(y),Pf=n(y,"LI",{});var n0=s(Pf);Zee=n(n0,"STRONG",{});var A5e=s(Zee);WOe=r(A5e,"convnext"),A5e.forEach(t),QOe=r(n0," \u2014 "),J$=n(n0,"A",{href:!0});var y5e=s(J$);HOe=r(y5e,"ConvNextConfig"),y5e.forEach(t),UOe=r(n0," (ConvNext model)"),n0.forEach(t),JOe=i(y),Bf=n(y,"LI",{});var s0=s(Bf);eoe=n(s0,"STRONG",{});var L5e=s(eoe);YOe=r(L5e,"ctrl"),L5e.forEach(t),KOe=r(s0," \u2014 "),Y$=n(s0,"A",{href:!0});var x5e=s(Y$);ZOe=r(x5e,"CTRLConfig"),x5e.forEach(t),eVe=r(s0," (CTRL model)"),s0.forEach(t),oVe=i(y),If=n(y,"LI",{});var l0=s(If);ooe=n(l0,"STRONG",{});var $5e=s(ooe);rVe=r($5e,"data2vec-audio"),$5e.forEach(t),tVe=r(l0," \u2014 "),K$=n(l0,"A",{href:!0});var k5e=s(K$);aVe=r(k5e,"Data2VecAudioConfig"),k5e.forEach(t),nVe=r(l0," (Data2VecAudio model)"),l0.forEach(t),sVe=i(y),qf=n(y,"LI",{});var i0=s(qf);roe=n(i0,"STRONG",{});var S5e=s(roe);lVe=r(S5e,"data2vec-text"),S5e.forEach(t),iVe=r(i0," \u2014 "),Z$=n(i0,"A",{href:!0});var R5e=s(Z$);dVe=r(R5e,"Data2VecTextConfig"),R5e.forEach(t),cVe=r(i0," (Data2VecText model)"),i0.forEach(t),fVe=i(y),Nf=n(y,"LI",{});var d0=s(Nf);toe=n(d0,"STRONG",{});var P5e=s(toe);mVe=r(P5e,"data2vec-vision"),P5e.forEach(t),gVe=r(d0," \u2014 "),ek=n(d0,"A",{href:!0});var B5e=s(ek);hVe=r(B5e,"Data2VecVisionConfig"),B5e.forEach(t),pVe=r(d0," (Data2VecVision model)"),d0.forEach(t),_Ve=i(y),jf=n(y,"LI",{});var c0=s(jf);aoe=n(c0,"STRONG",{});var I5e=s(aoe);uVe=r(I5e,"deberta"),I5e.forEach(t),bVe=r(c0," \u2014 "),ok=n(c0,"A",{href:!0});var q5e=s(ok);vVe=r(q5e,"DebertaConfig"),q5e.forEach(t),FVe=r(c0," (DeBERTa model)"),c0.forEach(t),TVe=i(y),Df=n(y,"LI",{});var f0=s(Df);noe=n(f0,"STRONG",{});var N5e=s(noe);MVe=r(N5e,"deberta-v2"),N5e.forEach(t),EVe=r(f0," \u2014 "),rk=n(f0,"A",{href:!0});var j5e=s(rk);CVe=r(j5e,"DebertaV2Config"),j5e.forEach(t),wVe=r(f0," (DeBERTa-v2 model)"),f0.forEach(t),AVe=i(y),Gf=n(y,"LI",{});var m0=s(Gf);soe=n(m0,"STRONG",{});var D5e=s(soe);yVe=r(D5e,"decision_transformer"),D5e.forEach(t),LVe=r(m0," \u2014 "),tk=n(m0,"A",{href:!0});var G5e=s(tk);xVe=r(G5e,"DecisionTransformerConfig"),G5e.forEach(t),$Ve=r(m0," (Decision Transformer model)"),m0.forEach(t),kVe=i(y),Of=n(y,"LI",{});var g0=s(Of);loe=n(g0,"STRONG",{});var O5e=s(loe);SVe=r(O5e,"deit"),O5e.forEach(t),RVe=r(g0," \u2014 "),ak=n(g0,"A",{href:!0});var V5e=s(ak);PVe=r(V5e,"DeiTConfig"),V5e.forEach(t),BVe=r(g0," (DeiT model)"),g0.forEach(t),IVe=i(y),Vf=n(y,"LI",{});var h0=s(Vf);ioe=n(h0,"STRONG",{});var X5e=s(ioe);qVe=r(X5e,"detr"),X5e.forEach(t),NVe=r(h0," \u2014 "),nk=n(h0,"A",{href:!0});var cGr=s(nk);jVe=r(cGr,"DetrConfig"),cGr.forEach(t),DVe=r(h0," (DETR model)"),h0.forEach(t),GVe=i(y),Xf=n(y,"LI",{});var z5e=s(Xf);doe=n(z5e,"STRONG",{});var fGr=s(doe);OVe=r(fGr,"distilbert"),fGr.forEach(t),VVe=r(z5e," \u2014 "),sk=n(z5e,"A",{href:!0});var mGr=s(sk);XVe=r(mGr,"DistilBertConfig"),mGr.forEach(t),zVe=r(z5e," (DistilBERT model)"),z5e.forEach(t),WVe=i(y),zf=n(y,"LI",{});var W5e=s(zf);coe=n(W5e,"STRONG",{});var gGr=s(coe);QVe=r(gGr,"dpr"),gGr.forEach(t),HVe=r(W5e," \u2014 "),lk=n(W5e,"A",{href:!0});var hGr=s(lk);UVe=r(hGr,"DPRConfig"),hGr.forEach(t),JVe=r(W5e," (DPR model)"),W5e.forEach(t),YVe=i(y),Wf=n(y,"LI",{});var Q5e=s(Wf);foe=n(Q5e,"STRONG",{});var pGr=s(foe);KVe=r(pGr,"dpt"),pGr.forEach(t),ZVe=r(Q5e," \u2014 "),ik=n(Q5e,"A",{href:!0});var _Gr=s(ik);eXe=r(_Gr,"DPTConfig"),_Gr.forEach(t),oXe=r(Q5e," (DPT model)"),Q5e.forEach(t),rXe=i(y),Qf=n(y,"LI",{});var H5e=s(Qf);moe=n(H5e,"STRONG",{});var uGr=s(moe);tXe=r(uGr,"electra"),uGr.forEach(t),aXe=r(H5e," \u2014 "),dk=n(H5e,"A",{href:!0});var bGr=s(dk);nXe=r(bGr,"ElectraConfig"),bGr.forEach(t),sXe=r(H5e," (ELECTRA model)"),H5e.forEach(t),lXe=i(y),Hf=n(y,"LI",{});var U5e=s(Hf);goe=n(U5e,"STRONG",{});var vGr=s(goe);iXe=r(vGr,"encoder-decoder"),vGr.forEach(t),dXe=r(U5e," \u2014 "),ck=n(U5e,"A",{href:!0});var FGr=s(ck);cXe=r(FGr,"EncoderDecoderConfig"),FGr.forEach(t),fXe=r(U5e," (Encoder decoder model)"),U5e.forEach(t),mXe=i(y),Uf=n(y,"LI",{});var J5e=s(Uf);hoe=n(J5e,"STRONG",{});var TGr=s(hoe);gXe=r(TGr,"flaubert"),TGr.forEach(t),hXe=r(J5e," \u2014 "),fk=n(J5e,"A",{href:!0});var MGr=s(fk);pXe=r(MGr,"FlaubertConfig"),MGr.forEach(t),_Xe=r(J5e," (FlauBERT model)"),J5e.forEach(t),uXe=i(y),Jf=n(y,"LI",{});var Y5e=s(Jf);poe=n(Y5e,"STRONG",{});var EGr=s(poe);bXe=r(EGr,"flava"),EGr.forEach(t),vXe=r(Y5e," \u2014 "),mk=n(Y5e,"A",{href:!0});var CGr=s(mk);FXe=r(CGr,"FlavaConfig"),CGr.forEach(t),TXe=r(Y5e," (Flava model)"),Y5e.forEach(t),MXe=i(y),Yf=n(y,"LI",{});var K5e=s(Yf);_oe=n(K5e,"STRONG",{});var wGr=s(_oe);EXe=r(wGr,"fnet"),wGr.forEach(t),CXe=r(K5e," \u2014 "),gk=n(K5e,"A",{href:!0});var AGr=s(gk);wXe=r(AGr,"FNetConfig"),AGr.forEach(t),AXe=r(K5e," (FNet model)"),K5e.forEach(t),yXe=i(y),Kf=n(y,"LI",{});var Z5e=s(Kf);uoe=n(Z5e,"STRONG",{});var yGr=s(uoe);LXe=r(yGr,"fsmt"),yGr.forEach(t),xXe=r(Z5e," \u2014 "),hk=n(Z5e,"A",{href:!0});var LGr=s(hk);$Xe=r(LGr,"FSMTConfig"),LGr.forEach(t),kXe=r(Z5e," (FairSeq Machine-Translation model)"),Z5e.forEach(t),SXe=i(y),Zf=n(y,"LI",{});var e3e=s(Zf);boe=n(e3e,"STRONG",{});var xGr=s(boe);RXe=r(xGr,"funnel"),xGr.forEach(t),PXe=r(e3e," \u2014 "),pk=n(e3e,"A",{href:!0});var $Gr=s(pk);BXe=r($Gr,"FunnelConfig"),$Gr.forEach(t),IXe=r(e3e," (Funnel Transformer model)"),e3e.forEach(t),qXe=i(y),em=n(y,"LI",{});var o3e=s(em);voe=n(o3e,"STRONG",{});var kGr=s(voe);NXe=r(kGr,"glpn"),kGr.forEach(t),jXe=r(o3e," \u2014 "),_k=n(o3e,"A",{href:!0});var SGr=s(_k);DXe=r(SGr,"GLPNConfig"),SGr.forEach(t),GXe=r(o3e," (GLPN model)"),o3e.forEach(t),OXe=i(y),om=n(y,"LI",{});var r3e=s(om);Foe=n(r3e,"STRONG",{});var RGr=s(Foe);VXe=r(RGr,"gpt2"),RGr.forEach(t),XXe=r(r3e," \u2014 "),uk=n(r3e,"A",{href:!0});var PGr=s(uk);zXe=r(PGr,"GPT2Config"),PGr.forEach(t),WXe=r(r3e," (OpenAI GPT-2 model)"),r3e.forEach(t),QXe=i(y),rm=n(y,"LI",{});var t3e=s(rm);Toe=n(t3e,"STRONG",{});var BGr=s(Toe);HXe=r(BGr,"gpt_neo"),BGr.forEach(t),UXe=r(t3e," \u2014 "),bk=n(t3e,"A",{href:!0});var IGr=s(bk);JXe=r(IGr,"GPTNeoConfig"),IGr.forEach(t),YXe=r(t3e," (GPT Neo model)"),t3e.forEach(t),KXe=i(y),tm=n(y,"LI",{});var a3e=s(tm);Moe=n(a3e,"STRONG",{});var qGr=s(Moe);ZXe=r(qGr,"gptj"),qGr.forEach(t),eze=r(a3e," \u2014 "),vk=n(a3e,"A",{href:!0});var NGr=s(vk);oze=r(NGr,"GPTJConfig"),NGr.forEach(t),rze=r(a3e," (GPT-J model)"),a3e.forEach(t),tze=i(y),am=n(y,"LI",{});var n3e=s(am);Eoe=n(n3e,"STRONG",{});var jGr=s(Eoe);aze=r(jGr,"hubert"),jGr.forEach(t),nze=r(n3e," \u2014 "),Fk=n(n3e,"A",{href:!0});var DGr=s(Fk);sze=r(DGr,"HubertConfig"),DGr.forEach(t),lze=r(n3e," (Hubert model)"),n3e.forEach(t),ize=i(y),nm=n(y,"LI",{});var s3e=s(nm);Coe=n(s3e,"STRONG",{});var GGr=s(Coe);dze=r(GGr,"ibert"),GGr.forEach(t),cze=r(s3e," \u2014 "),Tk=n(s3e,"A",{href:!0});var OGr=s(Tk);fze=r(OGr,"IBertConfig"),OGr.forEach(t),mze=r(s3e," (I-BERT model)"),s3e.forEach(t),gze=i(y),sm=n(y,"LI",{});var l3e=s(sm);woe=n(l3e,"STRONG",{});var VGr=s(woe);hze=r(VGr,"imagegpt"),VGr.forEach(t),pze=r(l3e," \u2014 "),Mk=n(l3e,"A",{href:!0});var XGr=s(Mk);_ze=r(XGr,"ImageGPTConfig"),XGr.forEach(t),uze=r(l3e," (ImageGPT model)"),l3e.forEach(t),bze=i(y),lm=n(y,"LI",{});var i3e=s(lm);Aoe=n(i3e,"STRONG",{});var zGr=s(Aoe);vze=r(zGr,"layoutlm"),zGr.forEach(t),Fze=r(i3e," \u2014 "),Ek=n(i3e,"A",{href:!0});var WGr=s(Ek);Tze=r(WGr,"LayoutLMConfig"),WGr.forEach(t),Mze=r(i3e," (LayoutLM model)"),i3e.forEach(t),Eze=i(y),im=n(y,"LI",{});var d3e=s(im);yoe=n(d3e,"STRONG",{});var QGr=s(yoe);Cze=r(QGr,"layoutlmv2"),QGr.forEach(t),wze=r(d3e," \u2014 "),Ck=n(d3e,"A",{href:!0});var HGr=s(Ck);Aze=r(HGr,"LayoutLMv2Config"),HGr.forEach(t),yze=r(d3e," (LayoutLMv2 model)"),d3e.forEach(t),Lze=i(y),dm=n(y,"LI",{});var c3e=s(dm);Loe=n(c3e,"STRONG",{});var UGr=s(Loe);xze=r(UGr,"led"),UGr.forEach(t),$ze=r(c3e," \u2014 "),wk=n(c3e,"A",{href:!0});var JGr=s(wk);kze=r(JGr,"LEDConfig"),JGr.forEach(t),Sze=r(c3e," (LED model)"),c3e.forEach(t),Rze=i(y),cm=n(y,"LI",{});var f3e=s(cm);xoe=n(f3e,"STRONG",{});var YGr=s(xoe);Pze=r(YGr,"longformer"),YGr.forEach(t),Bze=r(f3e," \u2014 "),Ak=n(f3e,"A",{href:!0});var KGr=s(Ak);Ize=r(KGr,"LongformerConfig"),KGr.forEach(t),qze=r(f3e," (Longformer model)"),f3e.forEach(t),Nze=i(y),fm=n(y,"LI",{});var m3e=s(fm);$oe=n(m3e,"STRONG",{});var ZGr=s($oe);jze=r(ZGr,"luke"),ZGr.forEach(t),Dze=r(m3e," \u2014 "),yk=n(m3e,"A",{href:!0});var eOr=s(yk);Gze=r(eOr,"LukeConfig"),eOr.forEach(t),Oze=r(m3e," (LUKE model)"),m3e.forEach(t),Vze=i(y),mm=n(y,"LI",{});var g3e=s(mm);koe=n(g3e,"STRONG",{});var oOr=s(koe);Xze=r(oOr,"lxmert"),oOr.forEach(t),zze=r(g3e," \u2014 "),Lk=n(g3e,"A",{href:!0});var rOr=s(Lk);Wze=r(rOr,"LxmertConfig"),rOr.forEach(t),Qze=r(g3e," (LXMERT model)"),g3e.forEach(t),Hze=i(y),gm=n(y,"LI",{});var h3e=s(gm);Soe=n(h3e,"STRONG",{});var tOr=s(Soe);Uze=r(tOr,"m2m_100"),tOr.forEach(t),Jze=r(h3e," \u2014 "),xk=n(h3e,"A",{href:!0});var aOr=s(xk);Yze=r(aOr,"M2M100Config"),aOr.forEach(t),Kze=r(h3e," (M2M100 model)"),h3e.forEach(t),Zze=i(y),hm=n(y,"LI",{});var p3e=s(hm);Roe=n(p3e,"STRONG",{});var nOr=s(Roe);eWe=r(nOr,"marian"),nOr.forEach(t),oWe=r(p3e," \u2014 "),$k=n(p3e,"A",{href:!0});var sOr=s($k);rWe=r(sOr,"MarianConfig"),sOr.forEach(t),tWe=r(p3e," (Marian model)"),p3e.forEach(t),aWe=i(y),pm=n(y,"LI",{});var _3e=s(pm);Poe=n(_3e,"STRONG",{});var lOr=s(Poe);nWe=r(lOr,"maskformer"),lOr.forEach(t),sWe=r(_3e," \u2014 "),kk=n(_3e,"A",{href:!0});var iOr=s(kk);lWe=r(iOr,"MaskFormerConfig"),iOr.forEach(t),iWe=r(_3e," (MaskFormer model)"),_3e.forEach(t),dWe=i(y),_m=n(y,"LI",{});var u3e=s(_m);Boe=n(u3e,"STRONG",{});var dOr=s(Boe);cWe=r(dOr,"mbart"),dOr.forEach(t),fWe=r(u3e," \u2014 "),Sk=n(u3e,"A",{href:!0});var cOr=s(Sk);mWe=r(cOr,"MBartConfig"),cOr.forEach(t),gWe=r(u3e," (mBART model)"),u3e.forEach(t),hWe=i(y),um=n(y,"LI",{});var b3e=s(um);Ioe=n(b3e,"STRONG",{});var fOr=s(Ioe);pWe=r(fOr,"megatron-bert"),fOr.forEach(t),_We=r(b3e," \u2014 "),Rk=n(b3e,"A",{href:!0});var mOr=s(Rk);uWe=r(mOr,"MegatronBertConfig"),mOr.forEach(t),bWe=r(b3e," (MegatronBert model)"),b3e.forEach(t),vWe=i(y),bm=n(y,"LI",{});var v3e=s(bm);qoe=n(v3e,"STRONG",{});var gOr=s(qoe);FWe=r(gOr,"mobilebert"),gOr.forEach(t),TWe=r(v3e," \u2014 "),Pk=n(v3e,"A",{href:!0});var hOr=s(Pk);MWe=r(hOr,"MobileBertConfig"),hOr.forEach(t),EWe=r(v3e," (MobileBERT model)"),v3e.forEach(t),CWe=i(y),vm=n(y,"LI",{});var F3e=s(vm);Noe=n(F3e,"STRONG",{});var pOr=s(Noe);wWe=r(pOr,"mpnet"),pOr.forEach(t),AWe=r(F3e," \u2014 "),Bk=n(F3e,"A",{href:!0});var _Or=s(Bk);yWe=r(_Or,"MPNetConfig"),_Or.forEach(t),LWe=r(F3e," (MPNet model)"),F3e.forEach(t),xWe=i(y),Fm=n(y,"LI",{});var T3e=s(Fm);joe=n(T3e,"STRONG",{});var uOr=s(joe);$We=r(uOr,"mt5"),uOr.forEach(t),kWe=r(T3e," \u2014 "),Ik=n(T3e,"A",{href:!0});var bOr=s(Ik);SWe=r(bOr,"MT5Config"),bOr.forEach(t),RWe=r(T3e," (mT5 model)"),T3e.forEach(t),PWe=i(y),Tm=n(y,"LI",{});var M3e=s(Tm);Doe=n(M3e,"STRONG",{});var vOr=s(Doe);BWe=r(vOr,"nystromformer"),vOr.forEach(t),IWe=r(M3e," \u2014 "),qk=n(M3e,"A",{href:!0});var FOr=s(qk);qWe=r(FOr,"NystromformerConfig"),FOr.forEach(t),NWe=r(M3e," (Nystromformer model)"),M3e.forEach(t),jWe=i(y),Mm=n(y,"LI",{});var E3e=s(Mm);Goe=n(E3e,"STRONG",{});var TOr=s(Goe);DWe=r(TOr,"openai-gpt"),TOr.forEach(t),GWe=r(E3e," \u2014 "),Nk=n(E3e,"A",{href:!0});var MOr=s(Nk);OWe=r(MOr,"OpenAIGPTConfig"),MOr.forEach(t),VWe=r(E3e," (OpenAI GPT model)"),E3e.forEach(t),XWe=i(y),Em=n(y,"LI",{});var C3e=s(Em);Ooe=n(C3e,"STRONG",{});var EOr=s(Ooe);zWe=r(EOr,"opt"),EOr.forEach(t),WWe=r(C3e," \u2014 "),jk=n(C3e,"A",{href:!0});var COr=s(jk);QWe=r(COr,"OPTConfig"),COr.forEach(t),HWe=r(C3e," (OPT model)"),C3e.forEach(t),UWe=i(y),Cm=n(y,"LI",{});var w3e=s(Cm);Voe=n(w3e,"STRONG",{});var wOr=s(Voe);JWe=r(wOr,"pegasus"),wOr.forEach(t),YWe=r(w3e," \u2014 "),Dk=n(w3e,"A",{href:!0});var AOr=s(Dk);KWe=r(AOr,"PegasusConfig"),AOr.forEach(t),ZWe=r(w3e," (Pegasus model)"),w3e.forEach(t),eQe=i(y),wm=n(y,"LI",{});var A3e=s(wm);Xoe=n(A3e,"STRONG",{});var yOr=s(Xoe);oQe=r(yOr,"perceiver"),yOr.forEach(t),rQe=r(A3e," \u2014 "),Gk=n(A3e,"A",{href:!0});var LOr=s(Gk);tQe=r(LOr,"PerceiverConfig"),LOr.forEach(t),aQe=r(A3e," (Perceiver model)"),A3e.forEach(t),nQe=i(y),Am=n(y,"LI",{});var y3e=s(Am);zoe=n(y3e,"STRONG",{});var xOr=s(zoe);sQe=r(xOr,"plbart"),xOr.forEach(t),lQe=r(y3e," \u2014 "),Ok=n(y3e,"A",{href:!0});var $Or=s(Ok);iQe=r($Or,"PLBartConfig"),$Or.forEach(t),dQe=r(y3e," (PLBart model)"),y3e.forEach(t),cQe=i(y),ym=n(y,"LI",{});var L3e=s(ym);Woe=n(L3e,"STRONG",{});var kOr=s(Woe);fQe=r(kOr,"poolformer"),kOr.forEach(t),mQe=r(L3e," \u2014 "),Vk=n(L3e,"A",{href:!0});var SOr=s(Vk);gQe=r(SOr,"PoolFormerConfig"),SOr.forEach(t),hQe=r(L3e," (PoolFormer model)"),L3e.forEach(t),pQe=i(y),Lm=n(y,"LI",{});var x3e=s(Lm);Qoe=n(x3e,"STRONG",{});var ROr=s(Qoe);_Qe=r(ROr,"prophetnet"),ROr.forEach(t),uQe=r(x3e," \u2014 "),Xk=n(x3e,"A",{href:!0});var POr=s(Xk);bQe=r(POr,"ProphetNetConfig"),POr.forEach(t),vQe=r(x3e," (ProphetNet model)"),x3e.forEach(t),FQe=i(y),xm=n(y,"LI",{});var $3e=s(xm);Hoe=n($3e,"STRONG",{});var BOr=s(Hoe);TQe=r(BOr,"qdqbert"),BOr.forEach(t),MQe=r($3e," \u2014 "),zk=n($3e,"A",{href:!0});var IOr=s(zk);EQe=r(IOr,"QDQBertConfig"),IOr.forEach(t),CQe=r($3e," (QDQBert model)"),$3e.forEach(t),wQe=i(y),$m=n(y,"LI",{});var k3e=s($m);Uoe=n(k3e,"STRONG",{});var qOr=s(Uoe);AQe=r(qOr,"rag"),qOr.forEach(t),yQe=r(k3e," \u2014 "),Wk=n(k3e,"A",{href:!0});var NOr=s(Wk);LQe=r(NOr,"RagConfig"),NOr.forEach(t),xQe=r(k3e," (RAG model)"),k3e.forEach(t),$Qe=i(y),km=n(y,"LI",{});var S3e=s(km);Joe=n(S3e,"STRONG",{});var jOr=s(Joe);kQe=r(jOr,"realm"),jOr.forEach(t),SQe=r(S3e," \u2014 "),Qk=n(S3e,"A",{href:!0});var DOr=s(Qk);RQe=r(DOr,"RealmConfig"),DOr.forEach(t),PQe=r(S3e," (Realm model)"),S3e.forEach(t),BQe=i(y),Sm=n(y,"LI",{});var R3e=s(Sm);Yoe=n(R3e,"STRONG",{});var GOr=s(Yoe);IQe=r(GOr,"reformer"),GOr.forEach(t),qQe=r(R3e," \u2014 "),Hk=n(R3e,"A",{href:!0});var OOr=s(Hk);NQe=r(OOr,"ReformerConfig"),OOr.forEach(t),jQe=r(R3e," (Reformer model)"),R3e.forEach(t),DQe=i(y),Rm=n(y,"LI",{});var P3e=s(Rm);Koe=n(P3e,"STRONG",{});var VOr=s(Koe);GQe=r(VOr,"regnet"),VOr.forEach(t),OQe=r(P3e," \u2014 "),Uk=n(P3e,"A",{href:!0});var XOr=s(Uk);VQe=r(XOr,"RegNetConfig"),XOr.forEach(t),XQe=r(P3e," (RegNet model)"),P3e.forEach(t),zQe=i(y),Pm=n(y,"LI",{});var B3e=s(Pm);Zoe=n(B3e,"STRONG",{});var zOr=s(Zoe);WQe=r(zOr,"rembert"),zOr.forEach(t),QQe=r(B3e," \u2014 "),Jk=n(B3e,"A",{href:!0});var WOr=s(Jk);HQe=r(WOr,"RemBertConfig"),WOr.forEach(t),UQe=r(B3e," (RemBERT model)"),B3e.forEach(t),JQe=i(y),Bm=n(y,"LI",{});var I3e=s(Bm);ere=n(I3e,"STRONG",{});var QOr=s(ere);YQe=r(QOr,"resnet"),QOr.forEach(t),KQe=r(I3e," \u2014 "),Yk=n(I3e,"A",{href:!0});var HOr=s(Yk);ZQe=r(HOr,"ResNetConfig"),HOr.forEach(t),eHe=r(I3e," (ResNet model)"),I3e.forEach(t),oHe=i(y),Im=n(y,"LI",{});var q3e=s(Im);ore=n(q3e,"STRONG",{});var UOr=s(ore);rHe=r(UOr,"retribert"),UOr.forEach(t),tHe=r(q3e," \u2014 "),Kk=n(q3e,"A",{href:!0});var JOr=s(Kk);aHe=r(JOr,"RetriBertConfig"),JOr.forEach(t),nHe=r(q3e," (RetriBERT model)"),q3e.forEach(t),sHe=i(y),qm=n(y,"LI",{});var N3e=s(qm);rre=n(N3e,"STRONG",{});var YOr=s(rre);lHe=r(YOr,"roberta"),YOr.forEach(t),iHe=r(N3e," \u2014 "),Zk=n(N3e,"A",{href:!0});var KOr=s(Zk);dHe=r(KOr,"RobertaConfig"),KOr.forEach(t),cHe=r(N3e," (RoBERTa model)"),N3e.forEach(t),fHe=i(y),Nm=n(y,"LI",{});var j3e=s(Nm);tre=n(j3e,"STRONG",{});var ZOr=s(tre);mHe=r(ZOr,"roformer"),ZOr.forEach(t),gHe=r(j3e," \u2014 "),eS=n(j3e,"A",{href:!0});var eVr=s(eS);hHe=r(eVr,"RoFormerConfig"),eVr.forEach(t),pHe=r(j3e," (RoFormer model)"),j3e.forEach(t),_He=i(y),jm=n(y,"LI",{});var D3e=s(jm);are=n(D3e,"STRONG",{});var oVr=s(are);uHe=r(oVr,"segformer"),oVr.forEach(t),bHe=r(D3e," \u2014 "),oS=n(D3e,"A",{href:!0});var rVr=s(oS);vHe=r(rVr,"SegformerConfig"),rVr.forEach(t),FHe=r(D3e," (SegFormer model)"),D3e.forEach(t),THe=i(y),Dm=n(y,"LI",{});var G3e=s(Dm);nre=n(G3e,"STRONG",{});var tVr=s(nre);MHe=r(tVr,"sew"),tVr.forEach(t),EHe=r(G3e," \u2014 "),rS=n(G3e,"A",{href:!0});var aVr=s(rS);CHe=r(aVr,"SEWConfig"),aVr.forEach(t),wHe=r(G3e," (SEW model)"),G3e.forEach(t),AHe=i(y),Gm=n(y,"LI",{});var O3e=s(Gm);sre=n(O3e,"STRONG",{});var nVr=s(sre);yHe=r(nVr,"sew-d"),nVr.forEach(t),LHe=r(O3e," \u2014 "),tS=n(O3e,"A",{href:!0});var sVr=s(tS);xHe=r(sVr,"SEWDConfig"),sVr.forEach(t),$He=r(O3e," (SEW-D model)"),O3e.forEach(t),kHe=i(y),Om=n(y,"LI",{});var V3e=s(Om);lre=n(V3e,"STRONG",{});var lVr=s(lre);SHe=r(lVr,"speech-encoder-decoder"),lVr.forEach(t),RHe=r(V3e," \u2014 "),aS=n(V3e,"A",{href:!0});var iVr=s(aS);PHe=r(iVr,"SpeechEncoderDecoderConfig"),iVr.forEach(t),BHe=r(V3e," (Speech Encoder decoder model)"),V3e.forEach(t),IHe=i(y),Vm=n(y,"LI",{});var X3e=s(Vm);ire=n(X3e,"STRONG",{});var dVr=s(ire);qHe=r(dVr,"speech_to_text"),dVr.forEach(t),NHe=r(X3e," \u2014 "),nS=n(X3e,"A",{href:!0});var cVr=s(nS);jHe=r(cVr,"Speech2TextConfig"),cVr.forEach(t),DHe=r(X3e," (Speech2Text model)"),X3e.forEach(t),GHe=i(y),Xm=n(y,"LI",{});var z3e=s(Xm);dre=n(z3e,"STRONG",{});var fVr=s(dre);OHe=r(fVr,"speech_to_text_2"),fVr.forEach(t),VHe=r(z3e," \u2014 "),sS=n(z3e,"A",{href:!0});var mVr=s(sS);XHe=r(mVr,"Speech2Text2Config"),mVr.forEach(t),zHe=r(z3e," (Speech2Text2 model)"),z3e.forEach(t),WHe=i(y),zm=n(y,"LI",{});var W3e=s(zm);cre=n(W3e,"STRONG",{});var gVr=s(cre);QHe=r(gVr,"splinter"),gVr.forEach(t),HHe=r(W3e," \u2014 "),lS=n(W3e,"A",{href:!0});var hVr=s(lS);UHe=r(hVr,"SplinterConfig"),hVr.forEach(t),JHe=r(W3e," (Splinter model)"),W3e.forEach(t),YHe=i(y),Wm=n(y,"LI",{});var Q3e=s(Wm);fre=n(Q3e,"STRONG",{});var pVr=s(fre);KHe=r(pVr,"squeezebert"),pVr.forEach(t),ZHe=r(Q3e," \u2014 "),iS=n(Q3e,"A",{href:!0});var _Vr=s(iS);eUe=r(_Vr,"SqueezeBertConfig"),_Vr.forEach(t),oUe=r(Q3e," (SqueezeBERT model)"),Q3e.forEach(t),rUe=i(y),Qm=n(y,"LI",{});var H3e=s(Qm);mre=n(H3e,"STRONG",{});var uVr=s(mre);tUe=r(uVr,"swin"),uVr.forEach(t),aUe=r(H3e," \u2014 "),dS=n(H3e,"A",{href:!0});var bVr=s(dS);nUe=r(bVr,"SwinConfig"),bVr.forEach(t),sUe=r(H3e," (Swin model)"),H3e.forEach(t),lUe=i(y),Hm=n(y,"LI",{});var U3e=s(Hm);gre=n(U3e,"STRONG",{});var vVr=s(gre);iUe=r(vVr,"t5"),vVr.forEach(t),dUe=r(U3e," \u2014 "),cS=n(U3e,"A",{href:!0});var FVr=s(cS);cUe=r(FVr,"T5Config"),FVr.forEach(t),fUe=r(U3e," (T5 model)"),U3e.forEach(t),mUe=i(y),Um=n(y,"LI",{});var J3e=s(Um);hre=n(J3e,"STRONG",{});var TVr=s(hre);gUe=r(TVr,"tapas"),TVr.forEach(t),hUe=r(J3e," \u2014 "),fS=n(J3e,"A",{href:!0});var MVr=s(fS);pUe=r(MVr,"TapasConfig"),MVr.forEach(t),_Ue=r(J3e," (TAPAS model)"),J3e.forEach(t),uUe=i(y),Jm=n(y,"LI",{});var Y3e=s(Jm);pre=n(Y3e,"STRONG",{});var EVr=s(pre);bUe=r(EVr,"trajectory_transformer"),EVr.forEach(t),vUe=r(Y3e," \u2014 "),mS=n(Y3e,"A",{href:!0});var CVr=s(mS);FUe=r(CVr,"TrajectoryTransformerConfig"),CVr.forEach(t),TUe=r(Y3e," (Trajectory Transformer model)"),Y3e.forEach(t),MUe=i(y),Ym=n(y,"LI",{});var K3e=s(Ym);_re=n(K3e,"STRONG",{});var wVr=s(_re);EUe=r(wVr,"transfo-xl"),wVr.forEach(t),CUe=r(K3e," \u2014 "),gS=n(K3e,"A",{href:!0});var AVr=s(gS);wUe=r(AVr,"TransfoXLConfig"),AVr.forEach(t),AUe=r(K3e," (Transformer-XL model)"),K3e.forEach(t),yUe=i(y),Km=n(y,"LI",{});var Z3e=s(Km);ure=n(Z3e,"STRONG",{});var yVr=s(ure);LUe=r(yVr,"trocr"),yVr.forEach(t),xUe=r(Z3e," \u2014 "),hS=n(Z3e,"A",{href:!0});var LVr=s(hS);$Ue=r(LVr,"TrOCRConfig"),LVr.forEach(t),kUe=r(Z3e," (TrOCR model)"),Z3e.forEach(t),SUe=i(y),Zm=n(y,"LI",{});var ewe=s(Zm);bre=n(ewe,"STRONG",{});var xVr=s(bre);RUe=r(xVr,"unispeech"),xVr.forEach(t),PUe=r(ewe," \u2014 "),pS=n(ewe,"A",{href:!0});var $Vr=s(pS);BUe=r($Vr,"UniSpeechConfig"),$Vr.forEach(t),IUe=r(ewe," (UniSpeech model)"),ewe.forEach(t),qUe=i(y),eg=n(y,"LI",{});var owe=s(eg);vre=n(owe,"STRONG",{});var kVr=s(vre);NUe=r(kVr,"unispeech-sat"),kVr.forEach(t),jUe=r(owe," \u2014 "),_S=n(owe,"A",{href:!0});var SVr=s(_S);DUe=r(SVr,"UniSpeechSatConfig"),SVr.forEach(t),GUe=r(owe," (UniSpeechSat model)"),owe.forEach(t),OUe=i(y),og=n(y,"LI",{});var rwe=s(og);Fre=n(rwe,"STRONG",{});var RVr=s(Fre);VUe=r(RVr,"van"),RVr.forEach(t),XUe=r(rwe," \u2014 "),uS=n(rwe,"A",{href:!0});var PVr=s(uS);zUe=r(PVr,"VanConfig"),PVr.forEach(t),WUe=r(rwe," (VAN model)"),rwe.forEach(t),QUe=i(y),rg=n(y,"LI",{});var twe=s(rg);Tre=n(twe,"STRONG",{});var BVr=s(Tre);HUe=r(BVr,"vilt"),BVr.forEach(t),UUe=r(twe," \u2014 "),bS=n(twe,"A",{href:!0});var IVr=s(bS);JUe=r(IVr,"ViltConfig"),IVr.forEach(t),YUe=r(twe," (ViLT model)"),twe.forEach(t),KUe=i(y),tg=n(y,"LI",{});var awe=s(tg);Mre=n(awe,"STRONG",{});var qVr=s(Mre);ZUe=r(qVr,"vision-encoder-decoder"),qVr.forEach(t),eJe=r(awe," \u2014 "),vS=n(awe,"A",{href:!0});var NVr=s(vS);oJe=r(NVr,"VisionEncoderDecoderConfig"),NVr.forEach(t),rJe=r(awe," (Vision Encoder decoder model)"),awe.forEach(t),tJe=i(y),ag=n(y,"LI",{});var nwe=s(ag);Ere=n(nwe,"STRONG",{});var jVr=s(Ere);aJe=r(jVr,"vision-text-dual-encoder"),jVr.forEach(t),nJe=r(nwe," \u2014 "),FS=n(nwe,"A",{href:!0});var DVr=s(FS);sJe=r(DVr,"VisionTextDualEncoderConfig"),DVr.forEach(t),lJe=r(nwe," (VisionTextDualEncoder model)"),nwe.forEach(t),iJe=i(y),ng=n(y,"LI",{});var swe=s(ng);Cre=n(swe,"STRONG",{});var GVr=s(Cre);dJe=r(GVr,"visual_bert"),GVr.forEach(t),cJe=r(swe," \u2014 "),TS=n(swe,"A",{href:!0});var OVr=s(TS);fJe=r(OVr,"VisualBertConfig"),OVr.forEach(t),mJe=r(swe," (VisualBert model)"),swe.forEach(t),gJe=i(y),sg=n(y,"LI",{});var lwe=s(sg);wre=n(lwe,"STRONG",{});var VVr=s(wre);hJe=r(VVr,"vit"),VVr.forEach(t),pJe=r(lwe," \u2014 "),MS=n(lwe,"A",{href:!0});var XVr=s(MS);_Je=r(XVr,"ViTConfig"),XVr.forEach(t),uJe=r(lwe," (ViT model)"),lwe.forEach(t),bJe=i(y),lg=n(y,"LI",{});var iwe=s(lg);Are=n(iwe,"STRONG",{});var zVr=s(Are);vJe=r(zVr,"vit_mae"),zVr.forEach(t),FJe=r(iwe," \u2014 "),ES=n(iwe,"A",{href:!0});var WVr=s(ES);TJe=r(WVr,"ViTMAEConfig"),WVr.forEach(t),MJe=r(iwe," (ViTMAE model)"),iwe.forEach(t),EJe=i(y),ig=n(y,"LI",{});var dwe=s(ig);yre=n(dwe,"STRONG",{});var QVr=s(yre);CJe=r(QVr,"wav2vec2"),QVr.forEach(t),wJe=r(dwe," \u2014 "),CS=n(dwe,"A",{href:!0});var HVr=s(CS);AJe=r(HVr,"Wav2Vec2Config"),HVr.forEach(t),yJe=r(dwe," (Wav2Vec2 model)"),dwe.forEach(t),LJe=i(y),dg=n(y,"LI",{});var cwe=s(dg);Lre=n(cwe,"STRONG",{});var UVr=s(Lre);xJe=r(UVr,"wav2vec2-conformer"),UVr.forEach(t),$Je=r(cwe," \u2014 "),wS=n(cwe,"A",{href:!0});var JVr=s(wS);kJe=r(JVr,"Wav2Vec2ConformerConfig"),JVr.forEach(t),SJe=r(cwe," (Wav2Vec2-Conformer model)"),cwe.forEach(t),RJe=i(y),cg=n(y,"LI",{});var fwe=s(cg);xre=n(fwe,"STRONG",{});var YVr=s(xre);PJe=r(YVr,"wavlm"),YVr.forEach(t),BJe=r(fwe," \u2014 "),AS=n(fwe,"A",{href:!0});var KVr=s(AS);IJe=r(KVr,"WavLMConfig"),KVr.forEach(t),qJe=r(fwe," (WavLM model)"),fwe.forEach(t),NJe=i(y),fg=n(y,"LI",{});var mwe=s(fg);$re=n(mwe,"STRONG",{});var ZVr=s($re);jJe=r(ZVr,"xglm"),ZVr.forEach(t),DJe=r(mwe," \u2014 "),yS=n(mwe,"A",{href:!0});var eXr=s(yS);GJe=r(eXr,"XGLMConfig"),eXr.forEach(t),OJe=r(mwe," (XGLM model)"),mwe.forEach(t),VJe=i(y),mg=n(y,"LI",{});var gwe=s(mg);kre=n(gwe,"STRONG",{});var oXr=s(kre);XJe=r(oXr,"xlm"),oXr.forEach(t),zJe=r(gwe," \u2014 "),LS=n(gwe,"A",{href:!0});var rXr=s(LS);WJe=r(rXr,"XLMConfig"),rXr.forEach(t),QJe=r(gwe," (XLM model)"),gwe.forEach(t),HJe=i(y),gg=n(y,"LI",{});var hwe=s(gg);Sre=n(hwe,"STRONG",{});var tXr=s(Sre);UJe=r(tXr,"xlm-prophetnet"),tXr.forEach(t),JJe=r(hwe," \u2014 "),xS=n(hwe,"A",{href:!0});var aXr=s(xS);YJe=r(aXr,"XLMProphetNetConfig"),aXr.forEach(t),KJe=r(hwe," (XLMProphetNet model)"),hwe.forEach(t),ZJe=i(y),hg=n(y,"LI",{});var pwe=s(hg);Rre=n(pwe,"STRONG",{});var nXr=s(Rre);eYe=r(nXr,"xlm-roberta"),nXr.forEach(t),oYe=r(pwe," \u2014 "),$S=n(pwe,"A",{href:!0});var sXr=s($S);rYe=r(sXr,"XLMRobertaConfig"),sXr.forEach(t),tYe=r(pwe," (XLM-RoBERTa model)"),pwe.forEach(t),aYe=i(y),pg=n(y,"LI",{});var _we=s(pg);Pre=n(_we,"STRONG",{});var lXr=s(Pre);nYe=r(lXr,"xlm-roberta-xl"),lXr.forEach(t),sYe=r(_we," \u2014 "),kS=n(_we,"A",{href:!0});var iXr=s(kS);lYe=r(iXr,"XLMRobertaXLConfig"),iXr.forEach(t),iYe=r(_we," (XLM-RoBERTa-XL model)"),_we.forEach(t),dYe=i(y),_g=n(y,"LI",{});var uwe=s(_g);Bre=n(uwe,"STRONG",{});var dXr=s(Bre);cYe=r(dXr,"xlnet"),dXr.forEach(t),fYe=r(uwe," \u2014 "),SS=n(uwe,"A",{href:!0});var cXr=s(SS);mYe=r(cXr,"XLNetConfig"),cXr.forEach(t),gYe=r(uwe," (XLNet model)"),uwe.forEach(t),hYe=i(y),ug=n(y,"LI",{});var bwe=s(ug);Ire=n(bwe,"STRONG",{});var fXr=s(Ire);pYe=r(fXr,"yolos"),fXr.forEach(t),_Ye=r(bwe," \u2014 "),RS=n(bwe,"A",{href:!0});var mXr=s(RS);uYe=r(mXr,"YolosConfig"),mXr.forEach(t),bYe=r(bwe," (YOLOS model)"),bwe.forEach(t),vYe=i(y),bg=n(y,"LI",{});var vwe=s(bg);qre=n(vwe,"STRONG",{});var gXr=s(qre);FYe=r(gXr,"yoso"),gXr.forEach(t),TYe=r(vwe," \u2014 "),PS=n(vwe,"A",{href:!0});var hXr=s(PS);MYe=r(hXr,"YosoConfig"),hXr.forEach(t),EYe=r(vwe," (YOSO model)"),vwe.forEach(t),y.forEach(t),CYe=i(ot),T(vg.$$.fragment,ot),ot.forEach(t),wYe=i(et),Fg=n(et,"DIV",{class:!0});var ZNe=s(Fg);T(F6.$$.fragment,ZNe),AYe=i(ZNe),Nre=n(ZNe,"P",{});var pXr=s(Nre);yYe=r(pXr,"Register a new configuration for this class."),pXr.forEach(t),ZNe.forEach(t),et.forEach(t),rqe=i(f),Fi=n(f,"H2",{class:!0});var eje=s(Fi);Tg=n(eje,"A",{id:!0,class:!0,href:!0});var _Xr=s(Tg);jre=n(_Xr,"SPAN",{});var uXr=s(jre);T(T6.$$.fragment,uXr),uXr.forEach(t),_Xr.forEach(t),LYe=i(eje),Dre=n(eje,"SPAN",{});var bXr=s(Dre);xYe=r(bXr,"AutoTokenizer"),bXr.forEach(t),eje.forEach(t),tqe=i(f),wo=n(f,"DIV",{class:!0});var Is=s(wo);T(M6.$$.fragment,Is),$Ye=i(Is),E6=n(Is,"P",{});var oje=s(E6);kYe=r(oje,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),BS=n(oje,"A",{href:!0});var vXr=s(BS);SYe=r(vXr,"AutoTokenizer.from_pretrained()"),vXr.forEach(t),RYe=r(oje," class method."),oje.forEach(t),PYe=i(Is),C6=n(Is,"P",{});var rje=s(C6);BYe=r(rje,"This class cannot be instantiated directly using "),Gre=n(rje,"CODE",{});var FXr=s(Gre);IYe=r(FXr,"__init__()"),FXr.forEach(t),qYe=r(rje," (throws an error)."),rje.forEach(t),NYe=i(Is),Cr=n(Is,"DIV",{class:!0});var qs=s(Cr);T(w6.$$.fragment,qs),jYe=i(qs),Ore=n(qs,"P",{});var TXr=s(Ore);DYe=r(TXr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),TXr.forEach(t),GYe=i(qs),Aa=n(qs,"P",{});var p0=s(Aa);OYe=r(p0,"The tokenizer class to instantiate is selected based on the "),Vre=n(p0,"CODE",{});var MXr=s(Vre);VYe=r(MXr,"model_type"),MXr.forEach(t),XYe=r(p0,` property of the config object (either
passed as an argument or loaded from `),Xre=n(p0,"CODE",{});var EXr=s(Xre);zYe=r(EXr,"pretrained_model_name_or_path"),EXr.forEach(t),WYe=r(p0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zre=n(p0,"CODE",{});var CXr=s(zre);QYe=r(CXr,"pretrained_model_name_or_path"),CXr.forEach(t),HYe=r(p0,":"),p0.forEach(t),UYe=i(qs),k=n(qs,"UL",{});var S=s(k);Sn=n(S,"LI",{});var A9=s(Sn);Wre=n(A9,"STRONG",{});var wXr=s(Wre);JYe=r(wXr,"albert"),wXr.forEach(t),YYe=r(A9," \u2014 "),IS=n(A9,"A",{href:!0});var AXr=s(IS);KYe=r(AXr,"AlbertTokenizer"),AXr.forEach(t),ZYe=r(A9," or "),qS=n(A9,"A",{href:!0});var yXr=s(qS);eKe=r(yXr,"AlbertTokenizerFast"),yXr.forEach(t),oKe=r(A9," (ALBERT model)"),A9.forEach(t),rKe=i(S),Rn=n(S,"LI",{});var y9=s(Rn);Qre=n(y9,"STRONG",{});var LXr=s(Qre);tKe=r(LXr,"bart"),LXr.forEach(t),aKe=r(y9," \u2014 "),NS=n(y9,"A",{href:!0});var xXr=s(NS);nKe=r(xXr,"BartTokenizer"),xXr.forEach(t),sKe=r(y9," or "),jS=n(y9,"A",{href:!0});var $Xr=s(jS);lKe=r($Xr,"BartTokenizerFast"),$Xr.forEach(t),iKe=r(y9," (BART model)"),y9.forEach(t),dKe=i(S),Pn=n(S,"LI",{});var L9=s(Pn);Hre=n(L9,"STRONG",{});var kXr=s(Hre);cKe=r(kXr,"barthez"),kXr.forEach(t),fKe=r(L9," \u2014 "),DS=n(L9,"A",{href:!0});var SXr=s(DS);mKe=r(SXr,"BarthezTokenizer"),SXr.forEach(t),gKe=r(L9," or "),GS=n(L9,"A",{href:!0});var RXr=s(GS);hKe=r(RXr,"BarthezTokenizerFast"),RXr.forEach(t),pKe=r(L9," (BARThez model)"),L9.forEach(t),_Ke=i(S),Mg=n(S,"LI",{});var Fwe=s(Mg);Ure=n(Fwe,"STRONG",{});var PXr=s(Ure);uKe=r(PXr,"bartpho"),PXr.forEach(t),bKe=r(Fwe," \u2014 "),OS=n(Fwe,"A",{href:!0});var BXr=s(OS);vKe=r(BXr,"BartphoTokenizer"),BXr.forEach(t),FKe=r(Fwe," (BARTpho model)"),Fwe.forEach(t),TKe=i(S),Bn=n(S,"LI",{});var x9=s(Bn);Jre=n(x9,"STRONG",{});var IXr=s(Jre);MKe=r(IXr,"bert"),IXr.forEach(t),EKe=r(x9," \u2014 "),VS=n(x9,"A",{href:!0});var qXr=s(VS);CKe=r(qXr,"BertTokenizer"),qXr.forEach(t),wKe=r(x9," or "),XS=n(x9,"A",{href:!0});var NXr=s(XS);AKe=r(NXr,"BertTokenizerFast"),NXr.forEach(t),yKe=r(x9," (BERT model)"),x9.forEach(t),LKe=i(S),Eg=n(S,"LI",{});var Twe=s(Eg);Yre=n(Twe,"STRONG",{});var jXr=s(Yre);xKe=r(jXr,"bert-generation"),jXr.forEach(t),$Ke=r(Twe," \u2014 "),zS=n(Twe,"A",{href:!0});var DXr=s(zS);kKe=r(DXr,"BertGenerationTokenizer"),DXr.forEach(t),SKe=r(Twe," (Bert Generation model)"),Twe.forEach(t),RKe=i(S),Cg=n(S,"LI",{});var Mwe=s(Cg);Kre=n(Mwe,"STRONG",{});var GXr=s(Kre);PKe=r(GXr,"bert-japanese"),GXr.forEach(t),BKe=r(Mwe," \u2014 "),WS=n(Mwe,"A",{href:!0});var OXr=s(WS);IKe=r(OXr,"BertJapaneseTokenizer"),OXr.forEach(t),qKe=r(Mwe," (BertJapanese model)"),Mwe.forEach(t),NKe=i(S),wg=n(S,"LI",{});var Ewe=s(wg);Zre=n(Ewe,"STRONG",{});var VXr=s(Zre);jKe=r(VXr,"bertweet"),VXr.forEach(t),DKe=r(Ewe," \u2014 "),QS=n(Ewe,"A",{href:!0});var XXr=s(QS);GKe=r(XXr,"BertweetTokenizer"),XXr.forEach(t),OKe=r(Ewe," (Bertweet model)"),Ewe.forEach(t),VKe=i(S),In=n(S,"LI",{});var $9=s(In);ete=n($9,"STRONG",{});var zXr=s(ete);XKe=r(zXr,"big_bird"),zXr.forEach(t),zKe=r($9," \u2014 "),HS=n($9,"A",{href:!0});var WXr=s(HS);WKe=r(WXr,"BigBirdTokenizer"),WXr.forEach(t),QKe=r($9," or "),US=n($9,"A",{href:!0});var QXr=s(US);HKe=r(QXr,"BigBirdTokenizerFast"),QXr.forEach(t),UKe=r($9," (BigBird model)"),$9.forEach(t),JKe=i(S),qn=n(S,"LI",{});var k9=s(qn);ote=n(k9,"STRONG",{});var HXr=s(ote);YKe=r(HXr,"bigbird_pegasus"),HXr.forEach(t),KKe=r(k9," \u2014 "),JS=n(k9,"A",{href:!0});var UXr=s(JS);ZKe=r(UXr,"PegasusTokenizer"),UXr.forEach(t),eZe=r(k9," or "),YS=n(k9,"A",{href:!0});var JXr=s(YS);oZe=r(JXr,"PegasusTokenizerFast"),JXr.forEach(t),rZe=r(k9," (BigBirdPegasus model)"),k9.forEach(t),tZe=i(S),Nn=n(S,"LI",{});var S9=s(Nn);rte=n(S9,"STRONG",{});var YXr=s(rte);aZe=r(YXr,"blenderbot"),YXr.forEach(t),nZe=r(S9," \u2014 "),KS=n(S9,"A",{href:!0});var KXr=s(KS);sZe=r(KXr,"BlenderbotTokenizer"),KXr.forEach(t),lZe=r(S9," or "),ZS=n(S9,"A",{href:!0});var ZXr=s(ZS);iZe=r(ZXr,"BlenderbotTokenizerFast"),ZXr.forEach(t),dZe=r(S9," (Blenderbot model)"),S9.forEach(t),cZe=i(S),Ag=n(S,"LI",{});var Cwe=s(Ag);tte=n(Cwe,"STRONG",{});var ezr=s(tte);fZe=r(ezr,"blenderbot-small"),ezr.forEach(t),mZe=r(Cwe," \u2014 "),eR=n(Cwe,"A",{href:!0});var ozr=s(eR);gZe=r(ozr,"BlenderbotSmallTokenizer"),ozr.forEach(t),hZe=r(Cwe," (BlenderbotSmall model)"),Cwe.forEach(t),pZe=i(S),yg=n(S,"LI",{});var wwe=s(yg);ate=n(wwe,"STRONG",{});var rzr=s(ate);_Ze=r(rzr,"byt5"),rzr.forEach(t),uZe=r(wwe," \u2014 "),oR=n(wwe,"A",{href:!0});var tzr=s(oR);bZe=r(tzr,"ByT5Tokenizer"),tzr.forEach(t),vZe=r(wwe," (ByT5 model)"),wwe.forEach(t),FZe=i(S),jn=n(S,"LI",{});var R9=s(jn);nte=n(R9,"STRONG",{});var azr=s(nte);TZe=r(azr,"camembert"),azr.forEach(t),MZe=r(R9," \u2014 "),rR=n(R9,"A",{href:!0});var nzr=s(rR);EZe=r(nzr,"CamembertTokenizer"),nzr.forEach(t),CZe=r(R9," or "),tR=n(R9,"A",{href:!0});var szr=s(tR);wZe=r(szr,"CamembertTokenizerFast"),szr.forEach(t),AZe=r(R9," (CamemBERT model)"),R9.forEach(t),yZe=i(S),Lg=n(S,"LI",{});var Awe=s(Lg);ste=n(Awe,"STRONG",{});var lzr=s(ste);LZe=r(lzr,"canine"),lzr.forEach(t),xZe=r(Awe," \u2014 "),aR=n(Awe,"A",{href:!0});var izr=s(aR);$Ze=r(izr,"CanineTokenizer"),izr.forEach(t),kZe=r(Awe," (Canine model)"),Awe.forEach(t),SZe=i(S),Dn=n(S,"LI",{});var P9=s(Dn);lte=n(P9,"STRONG",{});var dzr=s(lte);RZe=r(dzr,"clip"),dzr.forEach(t),PZe=r(P9," \u2014 "),nR=n(P9,"A",{href:!0});var czr=s(nR);BZe=r(czr,"CLIPTokenizer"),czr.forEach(t),IZe=r(P9," or "),sR=n(P9,"A",{href:!0});var fzr=s(sR);qZe=r(fzr,"CLIPTokenizerFast"),fzr.forEach(t),NZe=r(P9," (CLIP model)"),P9.forEach(t),jZe=i(S),Gn=n(S,"LI",{});var B9=s(Gn);ite=n(B9,"STRONG",{});var mzr=s(ite);DZe=r(mzr,"convbert"),mzr.forEach(t),GZe=r(B9," \u2014 "),lR=n(B9,"A",{href:!0});var gzr=s(lR);OZe=r(gzr,"ConvBertTokenizer"),gzr.forEach(t),VZe=r(B9," or "),iR=n(B9,"A",{href:!0});var hzr=s(iR);XZe=r(hzr,"ConvBertTokenizerFast"),hzr.forEach(t),zZe=r(B9," (ConvBERT model)"),B9.forEach(t),WZe=i(S),On=n(S,"LI",{});var I9=s(On);dte=n(I9,"STRONG",{});var pzr=s(dte);QZe=r(pzr,"cpm"),pzr.forEach(t),HZe=r(I9," \u2014 "),dR=n(I9,"A",{href:!0});var _zr=s(dR);UZe=r(_zr,"CpmTokenizer"),_zr.forEach(t),JZe=r(I9," or "),cR=n(I9,"A",{href:!0});var uzr=s(cR);YZe=r(uzr,"CpmTokenizerFast"),uzr.forEach(t),KZe=r(I9," (CPM model)"),I9.forEach(t),ZZe=i(S),xg=n(S,"LI",{});var ywe=s(xg);cte=n(ywe,"STRONG",{});var bzr=s(cte);eeo=r(bzr,"ctrl"),bzr.forEach(t),oeo=r(ywe," \u2014 "),fR=n(ywe,"A",{href:!0});var vzr=s(fR);reo=r(vzr,"CTRLTokenizer"),vzr.forEach(t),teo=r(ywe," (CTRL model)"),ywe.forEach(t),aeo=i(S),Vn=n(S,"LI",{});var q9=s(Vn);fte=n(q9,"STRONG",{});var Fzr=s(fte);neo=r(Fzr,"data2vec-text"),Fzr.forEach(t),seo=r(q9," \u2014 "),mR=n(q9,"A",{href:!0});var Tzr=s(mR);leo=r(Tzr,"RobertaTokenizer"),Tzr.forEach(t),ieo=r(q9," or "),gR=n(q9,"A",{href:!0});var Mzr=s(gR);deo=r(Mzr,"RobertaTokenizerFast"),Mzr.forEach(t),ceo=r(q9," (Data2VecText model)"),q9.forEach(t),feo=i(S),Xn=n(S,"LI",{});var N9=s(Xn);mte=n(N9,"STRONG",{});var Ezr=s(mte);meo=r(Ezr,"deberta"),Ezr.forEach(t),geo=r(N9," \u2014 "),hR=n(N9,"A",{href:!0});var Czr=s(hR);heo=r(Czr,"DebertaTokenizer"),Czr.forEach(t),peo=r(N9," or "),pR=n(N9,"A",{href:!0});var wzr=s(pR);_eo=r(wzr,"DebertaTokenizerFast"),wzr.forEach(t),ueo=r(N9," (DeBERTa model)"),N9.forEach(t),beo=i(S),zn=n(S,"LI",{});var j9=s(zn);gte=n(j9,"STRONG",{});var Azr=s(gte);veo=r(Azr,"deberta-v2"),Azr.forEach(t),Feo=r(j9," \u2014 "),_R=n(j9,"A",{href:!0});var yzr=s(_R);Teo=r(yzr,"DebertaV2Tokenizer"),yzr.forEach(t),Meo=r(j9," or "),uR=n(j9,"A",{href:!0});var Lzr=s(uR);Eeo=r(Lzr,"DebertaV2TokenizerFast"),Lzr.forEach(t),Ceo=r(j9," (DeBERTa-v2 model)"),j9.forEach(t),weo=i(S),Wn=n(S,"LI",{});var D9=s(Wn);hte=n(D9,"STRONG",{});var xzr=s(hte);Aeo=r(xzr,"distilbert"),xzr.forEach(t),yeo=r(D9," \u2014 "),bR=n(D9,"A",{href:!0});var $zr=s(bR);Leo=r($zr,"DistilBertTokenizer"),$zr.forEach(t),xeo=r(D9," or "),vR=n(D9,"A",{href:!0});var kzr=s(vR);$eo=r(kzr,"DistilBertTokenizerFast"),kzr.forEach(t),keo=r(D9," (DistilBERT model)"),D9.forEach(t),Seo=i(S),Qn=n(S,"LI",{});var G9=s(Qn);pte=n(G9,"STRONG",{});var Szr=s(pte);Reo=r(Szr,"dpr"),Szr.forEach(t),Peo=r(G9," \u2014 "),FR=n(G9,"A",{href:!0});var Rzr=s(FR);Beo=r(Rzr,"DPRQuestionEncoderTokenizer"),Rzr.forEach(t),Ieo=r(G9," or "),TR=n(G9,"A",{href:!0});var Pzr=s(TR);qeo=r(Pzr,"DPRQuestionEncoderTokenizerFast"),Pzr.forEach(t),Neo=r(G9," (DPR model)"),G9.forEach(t),jeo=i(S),Hn=n(S,"LI",{});var O9=s(Hn);_te=n(O9,"STRONG",{});var Bzr=s(_te);Deo=r(Bzr,"electra"),Bzr.forEach(t),Geo=r(O9," \u2014 "),MR=n(O9,"A",{href:!0});var Izr=s(MR);Oeo=r(Izr,"ElectraTokenizer"),Izr.forEach(t),Veo=r(O9," or "),ER=n(O9,"A",{href:!0});var qzr=s(ER);Xeo=r(qzr,"ElectraTokenizerFast"),qzr.forEach(t),zeo=r(O9," (ELECTRA model)"),O9.forEach(t),Weo=i(S),$g=n(S,"LI",{});var Lwe=s($g);ute=n(Lwe,"STRONG",{});var Nzr=s(ute);Qeo=r(Nzr,"flaubert"),Nzr.forEach(t),Heo=r(Lwe," \u2014 "),CR=n(Lwe,"A",{href:!0});var jzr=s(CR);Ueo=r(jzr,"FlaubertTokenizer"),jzr.forEach(t),Jeo=r(Lwe," (FlauBERT model)"),Lwe.forEach(t),Yeo=i(S),Un=n(S,"LI",{});var V9=s(Un);bte=n(V9,"STRONG",{});var Dzr=s(bte);Keo=r(Dzr,"fnet"),Dzr.forEach(t),Zeo=r(V9," \u2014 "),wR=n(V9,"A",{href:!0});var Gzr=s(wR);eoo=r(Gzr,"FNetTokenizer"),Gzr.forEach(t),ooo=r(V9," or "),AR=n(V9,"A",{href:!0});var Ozr=s(AR);roo=r(Ozr,"FNetTokenizerFast"),Ozr.forEach(t),too=r(V9," (FNet model)"),V9.forEach(t),aoo=i(S),kg=n(S,"LI",{});var xwe=s(kg);vte=n(xwe,"STRONG",{});var Vzr=s(vte);noo=r(Vzr,"fsmt"),Vzr.forEach(t),soo=r(xwe," \u2014 "),yR=n(xwe,"A",{href:!0});var Xzr=s(yR);loo=r(Xzr,"FSMTTokenizer"),Xzr.forEach(t),ioo=r(xwe," (FairSeq Machine-Translation model)"),xwe.forEach(t),doo=i(S),Jn=n(S,"LI",{});var X9=s(Jn);Fte=n(X9,"STRONG",{});var zzr=s(Fte);coo=r(zzr,"funnel"),zzr.forEach(t),foo=r(X9," \u2014 "),LR=n(X9,"A",{href:!0});var Wzr=s(LR);moo=r(Wzr,"FunnelTokenizer"),Wzr.forEach(t),goo=r(X9," or "),xR=n(X9,"A",{href:!0});var Qzr=s(xR);hoo=r(Qzr,"FunnelTokenizerFast"),Qzr.forEach(t),poo=r(X9," (Funnel Transformer model)"),X9.forEach(t),_oo=i(S),Yn=n(S,"LI",{});var z9=s(Yn);Tte=n(z9,"STRONG",{});var Hzr=s(Tte);uoo=r(Hzr,"gpt2"),Hzr.forEach(t),boo=r(z9," \u2014 "),$R=n(z9,"A",{href:!0});var Uzr=s($R);voo=r(Uzr,"GPT2Tokenizer"),Uzr.forEach(t),Foo=r(z9," or "),kR=n(z9,"A",{href:!0});var Jzr=s(kR);Too=r(Jzr,"GPT2TokenizerFast"),Jzr.forEach(t),Moo=r(z9," (OpenAI GPT-2 model)"),z9.forEach(t),Eoo=i(S),Kn=n(S,"LI",{});var W9=s(Kn);Mte=n(W9,"STRONG",{});var Yzr=s(Mte);Coo=r(Yzr,"gpt_neo"),Yzr.forEach(t),woo=r(W9," \u2014 "),SR=n(W9,"A",{href:!0});var Kzr=s(SR);Aoo=r(Kzr,"GPT2Tokenizer"),Kzr.forEach(t),yoo=r(W9," or "),RR=n(W9,"A",{href:!0});var Zzr=s(RR);Loo=r(Zzr,"GPT2TokenizerFast"),Zzr.forEach(t),xoo=r(W9," (GPT Neo model)"),W9.forEach(t),$oo=i(S),Zn=n(S,"LI",{});var Q9=s(Zn);Ete=n(Q9,"STRONG",{});var eWr=s(Ete);koo=r(eWr,"gptj"),eWr.forEach(t),Soo=r(Q9," \u2014 "),PR=n(Q9,"A",{href:!0});var oWr=s(PR);Roo=r(oWr,"GPT2Tokenizer"),oWr.forEach(t),Poo=r(Q9," or "),BR=n(Q9,"A",{href:!0});var rWr=s(BR);Boo=r(rWr,"GPT2TokenizerFast"),rWr.forEach(t),Ioo=r(Q9," (GPT-J model)"),Q9.forEach(t),qoo=i(S),es=n(S,"LI",{});var H9=s(es);Cte=n(H9,"STRONG",{});var tWr=s(Cte);Noo=r(tWr,"herbert"),tWr.forEach(t),joo=r(H9," \u2014 "),IR=n(H9,"A",{href:!0});var aWr=s(IR);Doo=r(aWr,"HerbertTokenizer"),aWr.forEach(t),Goo=r(H9," or "),qR=n(H9,"A",{href:!0});var nWr=s(qR);Ooo=r(nWr,"HerbertTokenizerFast"),nWr.forEach(t),Voo=r(H9," (HerBERT model)"),H9.forEach(t),Xoo=i(S),Sg=n(S,"LI",{});var $we=s(Sg);wte=n($we,"STRONG",{});var sWr=s(wte);zoo=r(sWr,"hubert"),sWr.forEach(t),Woo=r($we," \u2014 "),NR=n($we,"A",{href:!0});var lWr=s(NR);Qoo=r(lWr,"Wav2Vec2CTCTokenizer"),lWr.forEach(t),Hoo=r($we," (Hubert model)"),$we.forEach(t),Uoo=i(S),os=n(S,"LI",{});var U9=s(os);Ate=n(U9,"STRONG",{});var iWr=s(Ate);Joo=r(iWr,"ibert"),iWr.forEach(t),Yoo=r(U9," \u2014 "),jR=n(U9,"A",{href:!0});var dWr=s(jR);Koo=r(dWr,"RobertaTokenizer"),dWr.forEach(t),Zoo=r(U9," or "),DR=n(U9,"A",{href:!0});var cWr=s(DR);ero=r(cWr,"RobertaTokenizerFast"),cWr.forEach(t),oro=r(U9," (I-BERT model)"),U9.forEach(t),rro=i(S),rs=n(S,"LI",{});var J9=s(rs);yte=n(J9,"STRONG",{});var fWr=s(yte);tro=r(fWr,"layoutlm"),fWr.forEach(t),aro=r(J9," \u2014 "),GR=n(J9,"A",{href:!0});var mWr=s(GR);nro=r(mWr,"LayoutLMTokenizer"),mWr.forEach(t),sro=r(J9," or "),OR=n(J9,"A",{href:!0});var gWr=s(OR);lro=r(gWr,"LayoutLMTokenizerFast"),gWr.forEach(t),iro=r(J9," (LayoutLM model)"),J9.forEach(t),dro=i(S),ts=n(S,"LI",{});var Y9=s(ts);Lte=n(Y9,"STRONG",{});var hWr=s(Lte);cro=r(hWr,"layoutlmv2"),hWr.forEach(t),fro=r(Y9," \u2014 "),VR=n(Y9,"A",{href:!0});var pWr=s(VR);mro=r(pWr,"LayoutLMv2Tokenizer"),pWr.forEach(t),gro=r(Y9," or "),XR=n(Y9,"A",{href:!0});var _Wr=s(XR);hro=r(_Wr,"LayoutLMv2TokenizerFast"),_Wr.forEach(t),pro=r(Y9," (LayoutLMv2 model)"),Y9.forEach(t),_ro=i(S),as=n(S,"LI",{});var K9=s(as);xte=n(K9,"STRONG",{});var uWr=s(xte);uro=r(uWr,"layoutxlm"),uWr.forEach(t),bro=r(K9," \u2014 "),zR=n(K9,"A",{href:!0});var bWr=s(zR);vro=r(bWr,"LayoutXLMTokenizer"),bWr.forEach(t),Fro=r(K9," or "),WR=n(K9,"A",{href:!0});var vWr=s(WR);Tro=r(vWr,"LayoutXLMTokenizerFast"),vWr.forEach(t),Mro=r(K9," (LayoutXLM model)"),K9.forEach(t),Ero=i(S),ns=n(S,"LI",{});var Z9=s(ns);$te=n(Z9,"STRONG",{});var FWr=s($te);Cro=r(FWr,"led"),FWr.forEach(t),wro=r(Z9," \u2014 "),QR=n(Z9,"A",{href:!0});var TWr=s(QR);Aro=r(TWr,"LEDTokenizer"),TWr.forEach(t),yro=r(Z9," or "),HR=n(Z9,"A",{href:!0});var MWr=s(HR);Lro=r(MWr,"LEDTokenizerFast"),MWr.forEach(t),xro=r(Z9," (LED model)"),Z9.forEach(t),$ro=i(S),ss=n(S,"LI",{});var e$=s(ss);kte=n(e$,"STRONG",{});var EWr=s(kte);kro=r(EWr,"longformer"),EWr.forEach(t),Sro=r(e$," \u2014 "),UR=n(e$,"A",{href:!0});var CWr=s(UR);Rro=r(CWr,"LongformerTokenizer"),CWr.forEach(t),Pro=r(e$," or "),JR=n(e$,"A",{href:!0});var wWr=s(JR);Bro=r(wWr,"LongformerTokenizerFast"),wWr.forEach(t),Iro=r(e$," (Longformer model)"),e$.forEach(t),qro=i(S),Rg=n(S,"LI",{});var kwe=s(Rg);Ste=n(kwe,"STRONG",{});var AWr=s(Ste);Nro=r(AWr,"luke"),AWr.forEach(t),jro=r(kwe," \u2014 "),YR=n(kwe,"A",{href:!0});var yWr=s(YR);Dro=r(yWr,"LukeTokenizer"),yWr.forEach(t),Gro=r(kwe," (LUKE model)"),kwe.forEach(t),Oro=i(S),ls=n(S,"LI",{});var o$=s(ls);Rte=n(o$,"STRONG",{});var LWr=s(Rte);Vro=r(LWr,"lxmert"),LWr.forEach(t),Xro=r(o$," \u2014 "),KR=n(o$,"A",{href:!0});var xWr=s(KR);zro=r(xWr,"LxmertTokenizer"),xWr.forEach(t),Wro=r(o$," or "),ZR=n(o$,"A",{href:!0});var $Wr=s(ZR);Qro=r($Wr,"LxmertTokenizerFast"),$Wr.forEach(t),Hro=r(o$," (LXMERT model)"),o$.forEach(t),Uro=i(S),Pg=n(S,"LI",{});var Swe=s(Pg);Pte=n(Swe,"STRONG",{});var kWr=s(Pte);Jro=r(kWr,"m2m_100"),kWr.forEach(t),Yro=r(Swe," \u2014 "),eP=n(Swe,"A",{href:!0});var SWr=s(eP);Kro=r(SWr,"M2M100Tokenizer"),SWr.forEach(t),Zro=r(Swe," (M2M100 model)"),Swe.forEach(t),eto=i(S),Bg=n(S,"LI",{});var Rwe=s(Bg);Bte=n(Rwe,"STRONG",{});var RWr=s(Bte);oto=r(RWr,"marian"),RWr.forEach(t),rto=r(Rwe," \u2014 "),oP=n(Rwe,"A",{href:!0});var PWr=s(oP);tto=r(PWr,"MarianTokenizer"),PWr.forEach(t),ato=r(Rwe," (Marian model)"),Rwe.forEach(t),nto=i(S),is=n(S,"LI",{});var r$=s(is);Ite=n(r$,"STRONG",{});var BWr=s(Ite);sto=r(BWr,"mbart"),BWr.forEach(t),lto=r(r$," \u2014 "),rP=n(r$,"A",{href:!0});var IWr=s(rP);ito=r(IWr,"MBartTokenizer"),IWr.forEach(t),dto=r(r$," or "),tP=n(r$,"A",{href:!0});var qWr=s(tP);cto=r(qWr,"MBartTokenizerFast"),qWr.forEach(t),fto=r(r$," (mBART model)"),r$.forEach(t),mto=i(S),ds=n(S,"LI",{});var t$=s(ds);qte=n(t$,"STRONG",{});var NWr=s(qte);gto=r(NWr,"mbart50"),NWr.forEach(t),hto=r(t$," \u2014 "),aP=n(t$,"A",{href:!0});var jWr=s(aP);pto=r(jWr,"MBart50Tokenizer"),jWr.forEach(t),_to=r(t$," or "),nP=n(t$,"A",{href:!0});var DWr=s(nP);uto=r(DWr,"MBart50TokenizerFast"),DWr.forEach(t),bto=r(t$," (mBART-50 model)"),t$.forEach(t),vto=i(S),cs=n(S,"LI",{});var a$=s(cs);Nte=n(a$,"STRONG",{});var GWr=s(Nte);Fto=r(GWr,"megatron-bert"),GWr.forEach(t),Tto=r(a$," \u2014 "),sP=n(a$,"A",{href:!0});var OWr=s(sP);Mto=r(OWr,"BertTokenizer"),OWr.forEach(t),Eto=r(a$," or "),lP=n(a$,"A",{href:!0});var VWr=s(lP);Cto=r(VWr,"BertTokenizerFast"),VWr.forEach(t),wto=r(a$," (MegatronBert model)"),a$.forEach(t),Ato=i(S),Ig=n(S,"LI",{});var Pwe=s(Ig);jte=n(Pwe,"STRONG",{});var XWr=s(jte);yto=r(XWr,"mluke"),XWr.forEach(t),Lto=r(Pwe," \u2014 "),iP=n(Pwe,"A",{href:!0});var zWr=s(iP);xto=r(zWr,"MLukeTokenizer"),zWr.forEach(t),$to=r(Pwe," (mLUKE model)"),Pwe.forEach(t),kto=i(S),fs=n(S,"LI",{});var n$=s(fs);Dte=n(n$,"STRONG",{});var WWr=s(Dte);Sto=r(WWr,"mobilebert"),WWr.forEach(t),Rto=r(n$," \u2014 "),dP=n(n$,"A",{href:!0});var QWr=s(dP);Pto=r(QWr,"MobileBertTokenizer"),QWr.forEach(t),Bto=r(n$," or "),cP=n(n$,"A",{href:!0});var HWr=s(cP);Ito=r(HWr,"MobileBertTokenizerFast"),HWr.forEach(t),qto=r(n$," (MobileBERT model)"),n$.forEach(t),Nto=i(S),ms=n(S,"LI",{});var s$=s(ms);Gte=n(s$,"STRONG",{});var UWr=s(Gte);jto=r(UWr,"mpnet"),UWr.forEach(t),Dto=r(s$," \u2014 "),fP=n(s$,"A",{href:!0});var JWr=s(fP);Gto=r(JWr,"MPNetTokenizer"),JWr.forEach(t),Oto=r(s$," or "),mP=n(s$,"A",{href:!0});var YWr=s(mP);Vto=r(YWr,"MPNetTokenizerFast"),YWr.forEach(t),Xto=r(s$," (MPNet model)"),s$.forEach(t),zto=i(S),gs=n(S,"LI",{});var l$=s(gs);Ote=n(l$,"STRONG",{});var KWr=s(Ote);Wto=r(KWr,"mt5"),KWr.forEach(t),Qto=r(l$," \u2014 "),gP=n(l$,"A",{href:!0});var ZWr=s(gP);Hto=r(ZWr,"MT5Tokenizer"),ZWr.forEach(t),Uto=r(l$," or "),hP=n(l$,"A",{href:!0});var eQr=s(hP);Jto=r(eQr,"MT5TokenizerFast"),eQr.forEach(t),Yto=r(l$," (mT5 model)"),l$.forEach(t),Kto=i(S),hs=n(S,"LI",{});var i$=s(hs);Vte=n(i$,"STRONG",{});var oQr=s(Vte);Zto=r(oQr,"nystromformer"),oQr.forEach(t),eao=r(i$," \u2014 "),pP=n(i$,"A",{href:!0});var rQr=s(pP);oao=r(rQr,"AlbertTokenizer"),rQr.forEach(t),rao=r(i$," or "),_P=n(i$,"A",{href:!0});var tQr=s(_P);tao=r(tQr,"AlbertTokenizerFast"),tQr.forEach(t),aao=r(i$," (Nystromformer model)"),i$.forEach(t),nao=i(S),ps=n(S,"LI",{});var d$=s(ps);Xte=n(d$,"STRONG",{});var aQr=s(Xte);sao=r(aQr,"openai-gpt"),aQr.forEach(t),lao=r(d$," \u2014 "),uP=n(d$,"A",{href:!0});var nQr=s(uP);iao=r(nQr,"OpenAIGPTTokenizer"),nQr.forEach(t),dao=r(d$," or "),bP=n(d$,"A",{href:!0});var sQr=s(bP);cao=r(sQr,"OpenAIGPTTokenizerFast"),sQr.forEach(t),fao=r(d$," (OpenAI GPT model)"),d$.forEach(t),mao=i(S),qg=n(S,"LI",{});var Bwe=s(qg);zte=n(Bwe,"STRONG",{});var lQr=s(zte);gao=r(lQr,"opt"),lQr.forEach(t),hao=r(Bwe," \u2014 "),vP=n(Bwe,"A",{href:!0});var iQr=s(vP);pao=r(iQr,"GPT2Tokenizer"),iQr.forEach(t),_ao=r(Bwe," (OPT model)"),Bwe.forEach(t),uao=i(S),_s=n(S,"LI",{});var c$=s(_s);Wte=n(c$,"STRONG",{});var dQr=s(Wte);bao=r(dQr,"pegasus"),dQr.forEach(t),vao=r(c$," \u2014 "),FP=n(c$,"A",{href:!0});var cQr=s(FP);Fao=r(cQr,"PegasusTokenizer"),cQr.forEach(t),Tao=r(c$," or "),TP=n(c$,"A",{href:!0});var fQr=s(TP);Mao=r(fQr,"PegasusTokenizerFast"),fQr.forEach(t),Eao=r(c$," (Pegasus model)"),c$.forEach(t),Cao=i(S),Ng=n(S,"LI",{});var Iwe=s(Ng);Qte=n(Iwe,"STRONG",{});var mQr=s(Qte);wao=r(mQr,"perceiver"),mQr.forEach(t),Aao=r(Iwe," \u2014 "),MP=n(Iwe,"A",{href:!0});var gQr=s(MP);yao=r(gQr,"PerceiverTokenizer"),gQr.forEach(t),Lao=r(Iwe," (Perceiver model)"),Iwe.forEach(t),xao=i(S),jg=n(S,"LI",{});var qwe=s(jg);Hte=n(qwe,"STRONG",{});var hQr=s(Hte);$ao=r(hQr,"phobert"),hQr.forEach(t),kao=r(qwe," \u2014 "),EP=n(qwe,"A",{href:!0});var pQr=s(EP);Sao=r(pQr,"PhobertTokenizer"),pQr.forEach(t),Rao=r(qwe," (PhoBERT model)"),qwe.forEach(t),Pao=i(S),Dg=n(S,"LI",{});var Nwe=s(Dg);Ute=n(Nwe,"STRONG",{});var _Qr=s(Ute);Bao=r(_Qr,"plbart"),_Qr.forEach(t),Iao=r(Nwe," \u2014 "),CP=n(Nwe,"A",{href:!0});var uQr=s(CP);qao=r(uQr,"PLBartTokenizer"),uQr.forEach(t),Nao=r(Nwe," (PLBart model)"),Nwe.forEach(t),jao=i(S),Gg=n(S,"LI",{});var jwe=s(Gg);Jte=n(jwe,"STRONG",{});var bQr=s(Jte);Dao=r(bQr,"prophetnet"),bQr.forEach(t),Gao=r(jwe," \u2014 "),wP=n(jwe,"A",{href:!0});var vQr=s(wP);Oao=r(vQr,"ProphetNetTokenizer"),vQr.forEach(t),Vao=r(jwe," (ProphetNet model)"),jwe.forEach(t),Xao=i(S),us=n(S,"LI",{});var f$=s(us);Yte=n(f$,"STRONG",{});var FQr=s(Yte);zao=r(FQr,"qdqbert"),FQr.forEach(t),Wao=r(f$," \u2014 "),AP=n(f$,"A",{href:!0});var TQr=s(AP);Qao=r(TQr,"BertTokenizer"),TQr.forEach(t),Hao=r(f$," or "),yP=n(f$,"A",{href:!0});var MQr=s(yP);Uao=r(MQr,"BertTokenizerFast"),MQr.forEach(t),Jao=r(f$," (QDQBert model)"),f$.forEach(t),Yao=i(S),Og=n(S,"LI",{});var Dwe=s(Og);Kte=n(Dwe,"STRONG",{});var EQr=s(Kte);Kao=r(EQr,"rag"),EQr.forEach(t),Zao=r(Dwe," \u2014 "),LP=n(Dwe,"A",{href:!0});var CQr=s(LP);eno=r(CQr,"RagTokenizer"),CQr.forEach(t),ono=r(Dwe," (RAG model)"),Dwe.forEach(t),rno=i(S),bs=n(S,"LI",{});var m$=s(bs);Zte=n(m$,"STRONG",{});var wQr=s(Zte);tno=r(wQr,"realm"),wQr.forEach(t),ano=r(m$," \u2014 "),xP=n(m$,"A",{href:!0});var AQr=s(xP);nno=r(AQr,"RealmTokenizer"),AQr.forEach(t),sno=r(m$," or "),$P=n(m$,"A",{href:!0});var yQr=s($P);lno=r(yQr,"RealmTokenizerFast"),yQr.forEach(t),ino=r(m$," (Realm model)"),m$.forEach(t),dno=i(S),vs=n(S,"LI",{});var g$=s(vs);eae=n(g$,"STRONG",{});var LQr=s(eae);cno=r(LQr,"reformer"),LQr.forEach(t),fno=r(g$," \u2014 "),kP=n(g$,"A",{href:!0});var xQr=s(kP);mno=r(xQr,"ReformerTokenizer"),xQr.forEach(t),gno=r(g$," or "),SP=n(g$,"A",{href:!0});var $Qr=s(SP);hno=r($Qr,"ReformerTokenizerFast"),$Qr.forEach(t),pno=r(g$," (Reformer model)"),g$.forEach(t),_no=i(S),Fs=n(S,"LI",{});var h$=s(Fs);oae=n(h$,"STRONG",{});var kQr=s(oae);uno=r(kQr,"rembert"),kQr.forEach(t),bno=r(h$," \u2014 "),RP=n(h$,"A",{href:!0});var SQr=s(RP);vno=r(SQr,"RemBertTokenizer"),SQr.forEach(t),Fno=r(h$," or "),PP=n(h$,"A",{href:!0});var RQr=s(PP);Tno=r(RQr,"RemBertTokenizerFast"),RQr.forEach(t),Mno=r(h$," (RemBERT model)"),h$.forEach(t),Eno=i(S),Ts=n(S,"LI",{});var p$=s(Ts);rae=n(p$,"STRONG",{});var PQr=s(rae);Cno=r(PQr,"retribert"),PQr.forEach(t),wno=r(p$," \u2014 "),BP=n(p$,"A",{href:!0});var BQr=s(BP);Ano=r(BQr,"RetriBertTokenizer"),BQr.forEach(t),yno=r(p$," or "),IP=n(p$,"A",{href:!0});var IQr=s(IP);Lno=r(IQr,"RetriBertTokenizerFast"),IQr.forEach(t),xno=r(p$," (RetriBERT model)"),p$.forEach(t),$no=i(S),Ms=n(S,"LI",{});var _$=s(Ms);tae=n(_$,"STRONG",{});var qQr=s(tae);kno=r(qQr,"roberta"),qQr.forEach(t),Sno=r(_$," \u2014 "),qP=n(_$,"A",{href:!0});var NQr=s(qP);Rno=r(NQr,"RobertaTokenizer"),NQr.forEach(t),Pno=r(_$," or "),NP=n(_$,"A",{href:!0});var jQr=s(NP);Bno=r(jQr,"RobertaTokenizerFast"),jQr.forEach(t),Ino=r(_$," (RoBERTa model)"),_$.forEach(t),qno=i(S),Es=n(S,"LI",{});var u$=s(Es);aae=n(u$,"STRONG",{});var DQr=s(aae);Nno=r(DQr,"roformer"),DQr.forEach(t),jno=r(u$," \u2014 "),jP=n(u$,"A",{href:!0});var GQr=s(jP);Dno=r(GQr,"RoFormerTokenizer"),GQr.forEach(t),Gno=r(u$," or "),DP=n(u$,"A",{href:!0});var OQr=s(DP);Ono=r(OQr,"RoFormerTokenizerFast"),OQr.forEach(t),Vno=r(u$," (RoFormer model)"),u$.forEach(t),Xno=i(S),Vg=n(S,"LI",{});var Gwe=s(Vg);nae=n(Gwe,"STRONG",{});var VQr=s(nae);zno=r(VQr,"speech_to_text"),VQr.forEach(t),Wno=r(Gwe," \u2014 "),GP=n(Gwe,"A",{href:!0});var XQr=s(GP);Qno=r(XQr,"Speech2TextTokenizer"),XQr.forEach(t),Hno=r(Gwe," (Speech2Text model)"),Gwe.forEach(t),Uno=i(S),Xg=n(S,"LI",{});var Owe=s(Xg);sae=n(Owe,"STRONG",{});var zQr=s(sae);Jno=r(zQr,"speech_to_text_2"),zQr.forEach(t),Yno=r(Owe," \u2014 "),OP=n(Owe,"A",{href:!0});var WQr=s(OP);Kno=r(WQr,"Speech2Text2Tokenizer"),WQr.forEach(t),Zno=r(Owe," (Speech2Text2 model)"),Owe.forEach(t),eso=i(S),Cs=n(S,"LI",{});var b$=s(Cs);lae=n(b$,"STRONG",{});var QQr=s(lae);oso=r(QQr,"splinter"),QQr.forEach(t),rso=r(b$," \u2014 "),VP=n(b$,"A",{href:!0});var HQr=s(VP);tso=r(HQr,"SplinterTokenizer"),HQr.forEach(t),aso=r(b$," or "),XP=n(b$,"A",{href:!0});var UQr=s(XP);nso=r(UQr,"SplinterTokenizerFast"),UQr.forEach(t),sso=r(b$," (Splinter model)"),b$.forEach(t),lso=i(S),ws=n(S,"LI",{});var v$=s(ws);iae=n(v$,"STRONG",{});var JQr=s(iae);iso=r(JQr,"squeezebert"),JQr.forEach(t),dso=r(v$," \u2014 "),zP=n(v$,"A",{href:!0});var YQr=s(zP);cso=r(YQr,"SqueezeBertTokenizer"),YQr.forEach(t),fso=r(v$," or "),WP=n(v$,"A",{href:!0});var KQr=s(WP);mso=r(KQr,"SqueezeBertTokenizerFast"),KQr.forEach(t),gso=r(v$," (SqueezeBERT model)"),v$.forEach(t),hso=i(S),As=n(S,"LI",{});var F$=s(As);dae=n(F$,"STRONG",{});var ZQr=s(dae);pso=r(ZQr,"t5"),ZQr.forEach(t),_so=r(F$," \u2014 "),QP=n(F$,"A",{href:!0});var eHr=s(QP);uso=r(eHr,"T5Tokenizer"),eHr.forEach(t),bso=r(F$," or "),HP=n(F$,"A",{href:!0});var oHr=s(HP);vso=r(oHr,"T5TokenizerFast"),oHr.forEach(t),Fso=r(F$," (T5 model)"),F$.forEach(t),Tso=i(S),zg=n(S,"LI",{});var Vwe=s(zg);cae=n(Vwe,"STRONG",{});var rHr=s(cae);Mso=r(rHr,"tapas"),rHr.forEach(t),Eso=r(Vwe," \u2014 "),UP=n(Vwe,"A",{href:!0});var tHr=s(UP);Cso=r(tHr,"TapasTokenizer"),tHr.forEach(t),wso=r(Vwe," (TAPAS model)"),Vwe.forEach(t),Aso=i(S),Wg=n(S,"LI",{});var Xwe=s(Wg);fae=n(Xwe,"STRONG",{});var aHr=s(fae);yso=r(aHr,"tapex"),aHr.forEach(t),Lso=r(Xwe," \u2014 "),JP=n(Xwe,"A",{href:!0});var nHr=s(JP);xso=r(nHr,"TapexTokenizer"),nHr.forEach(t),$so=r(Xwe," (TAPEX model)"),Xwe.forEach(t),kso=i(S),Qg=n(S,"LI",{});var zwe=s(Qg);mae=n(zwe,"STRONG",{});var sHr=s(mae);Sso=r(sHr,"transfo-xl"),sHr.forEach(t),Rso=r(zwe," \u2014 "),YP=n(zwe,"A",{href:!0});var lHr=s(YP);Pso=r(lHr,"TransfoXLTokenizer"),lHr.forEach(t),Bso=r(zwe," (Transformer-XL model)"),zwe.forEach(t),Iso=i(S),ys=n(S,"LI",{});var T$=s(ys);gae=n(T$,"STRONG",{});var iHr=s(gae);qso=r(iHr,"visual_bert"),iHr.forEach(t),Nso=r(T$," \u2014 "),KP=n(T$,"A",{href:!0});var dHr=s(KP);jso=r(dHr,"BertTokenizer"),dHr.forEach(t),Dso=r(T$," or "),ZP=n(T$,"A",{href:!0});var cHr=s(ZP);Gso=r(cHr,"BertTokenizerFast"),cHr.forEach(t),Oso=r(T$," (VisualBert model)"),T$.forEach(t),Vso=i(S),Hg=n(S,"LI",{});var Wwe=s(Hg);hae=n(Wwe,"STRONG",{});var fHr=s(hae);Xso=r(fHr,"wav2vec2"),fHr.forEach(t),zso=r(Wwe," \u2014 "),eB=n(Wwe,"A",{href:!0});var mHr=s(eB);Wso=r(mHr,"Wav2Vec2CTCTokenizer"),mHr.forEach(t),Qso=r(Wwe," (Wav2Vec2 model)"),Wwe.forEach(t),Hso=i(S),Ug=n(S,"LI",{});var Qwe=s(Ug);pae=n(Qwe,"STRONG",{});var gHr=s(pae);Uso=r(gHr,"wav2vec2-conformer"),gHr.forEach(t),Jso=r(Qwe," \u2014 "),oB=n(Qwe,"A",{href:!0});var hHr=s(oB);Yso=r(hHr,"Wav2Vec2CTCTokenizer"),hHr.forEach(t),Kso=r(Qwe," (Wav2Vec2-Conformer model)"),Qwe.forEach(t),Zso=i(S),Jg=n(S,"LI",{});var Hwe=s(Jg);_ae=n(Hwe,"STRONG",{});var pHr=s(_ae);elo=r(pHr,"wav2vec2_phoneme"),pHr.forEach(t),olo=r(Hwe," \u2014 "),rB=n(Hwe,"A",{href:!0});var _Hr=s(rB);rlo=r(_Hr,"Wav2Vec2PhonemeCTCTokenizer"),_Hr.forEach(t),tlo=r(Hwe," (Wav2Vec2Phoneme model)"),Hwe.forEach(t),alo=i(S),Ls=n(S,"LI",{});var M$=s(Ls);uae=n(M$,"STRONG",{});var uHr=s(uae);nlo=r(uHr,"xglm"),uHr.forEach(t),slo=r(M$," \u2014 "),tB=n(M$,"A",{href:!0});var bHr=s(tB);llo=r(bHr,"XGLMTokenizer"),bHr.forEach(t),ilo=r(M$," or "),aB=n(M$,"A",{href:!0});var vHr=s(aB);dlo=r(vHr,"XGLMTokenizerFast"),vHr.forEach(t),clo=r(M$," (XGLM model)"),M$.forEach(t),flo=i(S),Yg=n(S,"LI",{});var Uwe=s(Yg);bae=n(Uwe,"STRONG",{});var FHr=s(bae);mlo=r(FHr,"xlm"),FHr.forEach(t),glo=r(Uwe," \u2014 "),nB=n(Uwe,"A",{href:!0});var THr=s(nB);hlo=r(THr,"XLMTokenizer"),THr.forEach(t),plo=r(Uwe," (XLM model)"),Uwe.forEach(t),_lo=i(S),Kg=n(S,"LI",{});var Jwe=s(Kg);vae=n(Jwe,"STRONG",{});var MHr=s(vae);ulo=r(MHr,"xlm-prophetnet"),MHr.forEach(t),blo=r(Jwe," \u2014 "),sB=n(Jwe,"A",{href:!0});var EHr=s(sB);vlo=r(EHr,"XLMProphetNetTokenizer"),EHr.forEach(t),Flo=r(Jwe," (XLMProphetNet model)"),Jwe.forEach(t),Tlo=i(S),xs=n(S,"LI",{});var E$=s(xs);Fae=n(E$,"STRONG",{});var CHr=s(Fae);Mlo=r(CHr,"xlm-roberta"),CHr.forEach(t),Elo=r(E$," \u2014 "),lB=n(E$,"A",{href:!0});var wHr=s(lB);Clo=r(wHr,"XLMRobertaTokenizer"),wHr.forEach(t),wlo=r(E$," or "),iB=n(E$,"A",{href:!0});var AHr=s(iB);Alo=r(AHr,"XLMRobertaTokenizerFast"),AHr.forEach(t),ylo=r(E$," (XLM-RoBERTa model)"),E$.forEach(t),Llo=i(S),$s=n(S,"LI",{});var C$=s($s);Tae=n(C$,"STRONG",{});var yHr=s(Tae);xlo=r(yHr,"xlm-roberta-xl"),yHr.forEach(t),$lo=r(C$," \u2014 "),dB=n(C$,"A",{href:!0});var LHr=s(dB);klo=r(LHr,"RobertaTokenizer"),LHr.forEach(t),Slo=r(C$," or "),cB=n(C$,"A",{href:!0});var xHr=s(cB);Rlo=r(xHr,"RobertaTokenizerFast"),xHr.forEach(t),Plo=r(C$," (XLM-RoBERTa-XL model)"),C$.forEach(t),Blo=i(S),ks=n(S,"LI",{});var w$=s(ks);Mae=n(w$,"STRONG",{});var $Hr=s(Mae);Ilo=r($Hr,"xlnet"),$Hr.forEach(t),qlo=r(w$," \u2014 "),fB=n(w$,"A",{href:!0});var kHr=s(fB);Nlo=r(kHr,"XLNetTokenizer"),kHr.forEach(t),jlo=r(w$," or "),mB=n(w$,"A",{href:!0});var SHr=s(mB);Dlo=r(SHr,"XLNetTokenizerFast"),SHr.forEach(t),Glo=r(w$," (XLNet model)"),w$.forEach(t),Olo=i(S),Ss=n(S,"LI",{});var A$=s(Ss);Eae=n(A$,"STRONG",{});var RHr=s(Eae);Vlo=r(RHr,"yoso"),RHr.forEach(t),Xlo=r(A$," \u2014 "),gB=n(A$,"A",{href:!0});var PHr=s(gB);zlo=r(PHr,"AlbertTokenizer"),PHr.forEach(t),Wlo=r(A$," or "),hB=n(A$,"A",{href:!0});var BHr=s(hB);Qlo=r(BHr,"AlbertTokenizerFast"),BHr.forEach(t),Hlo=r(A$," (YOSO model)"),A$.forEach(t),S.forEach(t),Ulo=i(qs),T(Zg.$$.fragment,qs),qs.forEach(t),Jlo=i(Is),eh=n(Is,"DIV",{class:!0});var tje=s(eh);T(A6.$$.fragment,tje),Ylo=i(tje),Cae=n(tje,"P",{});var IHr=s(Cae);Klo=r(IHr,"Register a new tokenizer in this mapping."),IHr.forEach(t),tje.forEach(t),Is.forEach(t),aqe=i(f),Ti=n(f,"H2",{class:!0});var aje=s(Ti);oh=n(aje,"A",{id:!0,class:!0,href:!0});var qHr=s(oh);wae=n(qHr,"SPAN",{});var NHr=s(wae);T(y6.$$.fragment,NHr),NHr.forEach(t),qHr.forEach(t),Zlo=i(aje),Aae=n(aje,"SPAN",{});var jHr=s(Aae);eio=r(jHr,"AutoFeatureExtractor"),jHr.forEach(t),aje.forEach(t),nqe=i(f),Ao=n(f,"DIV",{class:!0});var Ns=s(Ao);T(L6.$$.fragment,Ns),oio=i(Ns),x6=n(Ns,"P",{});var nje=s(x6);rio=r(nje,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),pB=n(nje,"A",{href:!0});var DHr=s(pB);tio=r(DHr,"AutoFeatureExtractor.from_pretrained()"),DHr.forEach(t),aio=r(nje," class method."),nje.forEach(t),nio=i(Ns),$6=n(Ns,"P",{});var sje=s($6);sio=r(sje,"This class cannot be instantiated directly using "),yae=n(sje,"CODE",{});var GHr=s(yae);lio=r(GHr,"__init__()"),GHr.forEach(t),iio=r(sje," (throws an error)."),sje.forEach(t),dio=i(Ns),He=n(Ns,"DIV",{class:!0});var Zt=s(He);T(k6.$$.fragment,Zt),cio=i(Zt),Lae=n(Zt,"P",{});var OHr=s(Lae);fio=r(OHr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),OHr.forEach(t),mio=i(Zt),ya=n(Zt,"P",{});var _0=s(ya);gio=r(_0,"The feature extractor class to instantiate is selected based on the "),xae=n(_0,"CODE",{});var VHr=s(xae);hio=r(VHr,"model_type"),VHr.forEach(t),pio=r(_0,` property of the config object
(either passed as an argument or loaded from `),$ae=n(_0,"CODE",{});var XHr=s($ae);_io=r(XHr,"pretrained_model_name_or_path"),XHr.forEach(t),uio=r(_0,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),kae=n(_0,"CODE",{});var zHr=s(kae);bio=r(zHr,"pretrained_model_name_or_path"),zHr.forEach(t),vio=r(_0,":"),_0.forEach(t),Fio=i(Zt),Z=n(Zt,"UL",{});var te=s(Z);rh=n(te,"LI",{});var Ywe=s(rh);Sae=n(Ywe,"STRONG",{});var WHr=s(Sae);Tio=r(WHr,"beit"),WHr.forEach(t),Mio=r(Ywe," \u2014 "),_B=n(Ywe,"A",{href:!0});var QHr=s(_B);Eio=r(QHr,"BeitFeatureExtractor"),QHr.forEach(t),Cio=r(Ywe," (BEiT model)"),Ywe.forEach(t),wio=i(te),th=n(te,"LI",{});var Kwe=s(th);Rae=n(Kwe,"STRONG",{});var HHr=s(Rae);Aio=r(HHr,"clip"),HHr.forEach(t),yio=r(Kwe," \u2014 "),uB=n(Kwe,"A",{href:!0});var UHr=s(uB);Lio=r(UHr,"CLIPFeatureExtractor"),UHr.forEach(t),xio=r(Kwe," (CLIP model)"),Kwe.forEach(t),$io=i(te),ah=n(te,"LI",{});var Zwe=s(ah);Pae=n(Zwe,"STRONG",{});var JHr=s(Pae);kio=r(JHr,"convnext"),JHr.forEach(t),Sio=r(Zwe," \u2014 "),bB=n(Zwe,"A",{href:!0});var YHr=s(bB);Rio=r(YHr,"ConvNextFeatureExtractor"),YHr.forEach(t),Pio=r(Zwe," (ConvNext model)"),Zwe.forEach(t),Bio=i(te),nh=n(te,"LI",{});var e0e=s(nh);Bae=n(e0e,"STRONG",{});var KHr=s(Bae);Iio=r(KHr,"data2vec-audio"),KHr.forEach(t),qio=r(e0e," \u2014 "),vB=n(e0e,"A",{href:!0});var ZHr=s(vB);Nio=r(ZHr,"Wav2Vec2FeatureExtractor"),ZHr.forEach(t),jio=r(e0e," (Data2VecAudio model)"),e0e.forEach(t),Dio=i(te),sh=n(te,"LI",{});var o0e=s(sh);Iae=n(o0e,"STRONG",{});var eUr=s(Iae);Gio=r(eUr,"data2vec-vision"),eUr.forEach(t),Oio=r(o0e," \u2014 "),FB=n(o0e,"A",{href:!0});var oUr=s(FB);Vio=r(oUr,"BeitFeatureExtractor"),oUr.forEach(t),Xio=r(o0e," (Data2VecVision model)"),o0e.forEach(t),zio=i(te),lh=n(te,"LI",{});var r0e=s(lh);qae=n(r0e,"STRONG",{});var rUr=s(qae);Wio=r(rUr,"deit"),rUr.forEach(t),Qio=r(r0e," \u2014 "),TB=n(r0e,"A",{href:!0});var tUr=s(TB);Hio=r(tUr,"DeiTFeatureExtractor"),tUr.forEach(t),Uio=r(r0e," (DeiT model)"),r0e.forEach(t),Jio=i(te),ih=n(te,"LI",{});var t0e=s(ih);Nae=n(t0e,"STRONG",{});var aUr=s(Nae);Yio=r(aUr,"detr"),aUr.forEach(t),Kio=r(t0e," \u2014 "),MB=n(t0e,"A",{href:!0});var nUr=s(MB);Zio=r(nUr,"DetrFeatureExtractor"),nUr.forEach(t),edo=r(t0e," (DETR model)"),t0e.forEach(t),odo=i(te),dh=n(te,"LI",{});var a0e=s(dh);jae=n(a0e,"STRONG",{});var sUr=s(jae);rdo=r(sUr,"dpt"),sUr.forEach(t),tdo=r(a0e," \u2014 "),EB=n(a0e,"A",{href:!0});var lUr=s(EB);ado=r(lUr,"DPTFeatureExtractor"),lUr.forEach(t),ndo=r(a0e," (DPT model)"),a0e.forEach(t),sdo=i(te),ch=n(te,"LI",{});var n0e=s(ch);Dae=n(n0e,"STRONG",{});var iUr=s(Dae);ldo=r(iUr,"flava"),iUr.forEach(t),ido=r(n0e," \u2014 "),CB=n(n0e,"A",{href:!0});var dUr=s(CB);ddo=r(dUr,"FlavaFeatureExtractor"),dUr.forEach(t),cdo=r(n0e," (Flava model)"),n0e.forEach(t),fdo=i(te),fh=n(te,"LI",{});var s0e=s(fh);Gae=n(s0e,"STRONG",{});var cUr=s(Gae);mdo=r(cUr,"glpn"),cUr.forEach(t),gdo=r(s0e," \u2014 "),wB=n(s0e,"A",{href:!0});var fUr=s(wB);hdo=r(fUr,"GLPNFeatureExtractor"),fUr.forEach(t),pdo=r(s0e," (GLPN model)"),s0e.forEach(t),_do=i(te),mh=n(te,"LI",{});var l0e=s(mh);Oae=n(l0e,"STRONG",{});var mUr=s(Oae);udo=r(mUr,"hubert"),mUr.forEach(t),bdo=r(l0e," \u2014 "),AB=n(l0e,"A",{href:!0});var gUr=s(AB);vdo=r(gUr,"Wav2Vec2FeatureExtractor"),gUr.forEach(t),Fdo=r(l0e," (Hubert model)"),l0e.forEach(t),Tdo=i(te),gh=n(te,"LI",{});var i0e=s(gh);Vae=n(i0e,"STRONG",{});var hUr=s(Vae);Mdo=r(hUr,"layoutlmv2"),hUr.forEach(t),Edo=r(i0e," \u2014 "),yB=n(i0e,"A",{href:!0});var pUr=s(yB);Cdo=r(pUr,"LayoutLMv2FeatureExtractor"),pUr.forEach(t),wdo=r(i0e," (LayoutLMv2 model)"),i0e.forEach(t),Ado=i(te),hh=n(te,"LI",{});var d0e=s(hh);Xae=n(d0e,"STRONG",{});var _Ur=s(Xae);ydo=r(_Ur,"maskformer"),_Ur.forEach(t),Ldo=r(d0e," \u2014 "),LB=n(d0e,"A",{href:!0});var uUr=s(LB);xdo=r(uUr,"MaskFormerFeatureExtractor"),uUr.forEach(t),$do=r(d0e," (MaskFormer model)"),d0e.forEach(t),kdo=i(te),ph=n(te,"LI",{});var c0e=s(ph);zae=n(c0e,"STRONG",{});var bUr=s(zae);Sdo=r(bUr,"perceiver"),bUr.forEach(t),Rdo=r(c0e," \u2014 "),xB=n(c0e,"A",{href:!0});var vUr=s(xB);Pdo=r(vUr,"PerceiverFeatureExtractor"),vUr.forEach(t),Bdo=r(c0e," (Perceiver model)"),c0e.forEach(t),Ido=i(te),_h=n(te,"LI",{});var f0e=s(_h);Wae=n(f0e,"STRONG",{});var FUr=s(Wae);qdo=r(FUr,"poolformer"),FUr.forEach(t),Ndo=r(f0e," \u2014 "),$B=n(f0e,"A",{href:!0});var TUr=s($B);jdo=r(TUr,"PoolFormerFeatureExtractor"),TUr.forEach(t),Ddo=r(f0e," (PoolFormer model)"),f0e.forEach(t),Gdo=i(te),uh=n(te,"LI",{});var m0e=s(uh);Qae=n(m0e,"STRONG",{});var MUr=s(Qae);Odo=r(MUr,"regnet"),MUr.forEach(t),Vdo=r(m0e," \u2014 "),kB=n(m0e,"A",{href:!0});var EUr=s(kB);Xdo=r(EUr,"ConvNextFeatureExtractor"),EUr.forEach(t),zdo=r(m0e," (RegNet model)"),m0e.forEach(t),Wdo=i(te),bh=n(te,"LI",{});var g0e=s(bh);Hae=n(g0e,"STRONG",{});var CUr=s(Hae);Qdo=r(CUr,"resnet"),CUr.forEach(t),Hdo=r(g0e," \u2014 "),SB=n(g0e,"A",{href:!0});var wUr=s(SB);Udo=r(wUr,"ConvNextFeatureExtractor"),wUr.forEach(t),Jdo=r(g0e," (ResNet model)"),g0e.forEach(t),Ydo=i(te),vh=n(te,"LI",{});var h0e=s(vh);Uae=n(h0e,"STRONG",{});var AUr=s(Uae);Kdo=r(AUr,"segformer"),AUr.forEach(t),Zdo=r(h0e," \u2014 "),RB=n(h0e,"A",{href:!0});var yUr=s(RB);eco=r(yUr,"SegformerFeatureExtractor"),yUr.forEach(t),oco=r(h0e," (SegFormer model)"),h0e.forEach(t),rco=i(te),Fh=n(te,"LI",{});var p0e=s(Fh);Jae=n(p0e,"STRONG",{});var LUr=s(Jae);tco=r(LUr,"speech_to_text"),LUr.forEach(t),aco=r(p0e," \u2014 "),PB=n(p0e,"A",{href:!0});var xUr=s(PB);nco=r(xUr,"Speech2TextFeatureExtractor"),xUr.forEach(t),sco=r(p0e," (Speech2Text model)"),p0e.forEach(t),lco=i(te),Th=n(te,"LI",{});var _0e=s(Th);Yae=n(_0e,"STRONG",{});var $Ur=s(Yae);ico=r($Ur,"swin"),$Ur.forEach(t),dco=r(_0e," \u2014 "),BB=n(_0e,"A",{href:!0});var kUr=s(BB);cco=r(kUr,"ViTFeatureExtractor"),kUr.forEach(t),fco=r(_0e," (Swin model)"),_0e.forEach(t),mco=i(te),Mh=n(te,"LI",{});var u0e=s(Mh);Kae=n(u0e,"STRONG",{});var SUr=s(Kae);gco=r(SUr,"van"),SUr.forEach(t),hco=r(u0e," \u2014 "),IB=n(u0e,"A",{href:!0});var RUr=s(IB);pco=r(RUr,"ConvNextFeatureExtractor"),RUr.forEach(t),_co=r(u0e," (VAN model)"),u0e.forEach(t),uco=i(te),Eh=n(te,"LI",{});var b0e=s(Eh);Zae=n(b0e,"STRONG",{});var PUr=s(Zae);bco=r(PUr,"vit"),PUr.forEach(t),vco=r(b0e," \u2014 "),qB=n(b0e,"A",{href:!0});var BUr=s(qB);Fco=r(BUr,"ViTFeatureExtractor"),BUr.forEach(t),Tco=r(b0e," (ViT model)"),b0e.forEach(t),Mco=i(te),Ch=n(te,"LI",{});var v0e=s(Ch);ene=n(v0e,"STRONG",{});var IUr=s(ene);Eco=r(IUr,"vit_mae"),IUr.forEach(t),Cco=r(v0e," \u2014 "),NB=n(v0e,"A",{href:!0});var qUr=s(NB);wco=r(qUr,"ViTFeatureExtractor"),qUr.forEach(t),Aco=r(v0e," (ViTMAE model)"),v0e.forEach(t),yco=i(te),wh=n(te,"LI",{});var F0e=s(wh);one=n(F0e,"STRONG",{});var NUr=s(one);Lco=r(NUr,"wav2vec2"),NUr.forEach(t),xco=r(F0e," \u2014 "),jB=n(F0e,"A",{href:!0});var jUr=s(jB);$co=r(jUr,"Wav2Vec2FeatureExtractor"),jUr.forEach(t),kco=r(F0e," (Wav2Vec2 model)"),F0e.forEach(t),Sco=i(te),Ah=n(te,"LI",{});var T0e=s(Ah);rne=n(T0e,"STRONG",{});var DUr=s(rne);Rco=r(DUr,"wav2vec2-conformer"),DUr.forEach(t),Pco=r(T0e," \u2014 "),DB=n(T0e,"A",{href:!0});var GUr=s(DB);Bco=r(GUr,"Wav2Vec2FeatureExtractor"),GUr.forEach(t),Ico=r(T0e," (Wav2Vec2-Conformer model)"),T0e.forEach(t),qco=i(te),yh=n(te,"LI",{});var M0e=s(yh);tne=n(M0e,"STRONG",{});var OUr=s(tne);Nco=r(OUr,"yolos"),OUr.forEach(t),jco=r(M0e," \u2014 "),GB=n(M0e,"A",{href:!0});var VUr=s(GB);Dco=r(VUr,"YolosFeatureExtractor"),VUr.forEach(t),Gco=r(M0e," (YOLOS model)"),M0e.forEach(t),te.forEach(t),Oco=i(Zt),T(Lh.$$.fragment,Zt),Vco=i(Zt),T(xh.$$.fragment,Zt),Zt.forEach(t),Xco=i(Ns),$h=n(Ns,"DIV",{class:!0});var lje=s($h);T(S6.$$.fragment,lje),zco=i(lje),ane=n(lje,"P",{});var XUr=s(ane);Wco=r(XUr,"Register a new feature extractor for this class."),XUr.forEach(t),lje.forEach(t),Ns.forEach(t),sqe=i(f),Mi=n(f,"H2",{class:!0});var ije=s(Mi);kh=n(ije,"A",{id:!0,class:!0,href:!0});var zUr=s(kh);nne=n(zUr,"SPAN",{});var WUr=s(nne);T(R6.$$.fragment,WUr),WUr.forEach(t),zUr.forEach(t),Qco=i(ije),sne=n(ije,"SPAN",{});var QUr=s(sne);Hco=r(QUr,"AutoProcessor"),QUr.forEach(t),ije.forEach(t),lqe=i(f),yo=n(f,"DIV",{class:!0});var js=s(yo);T(P6.$$.fragment,js),Uco=i(js),B6=n(js,"P",{});var dje=s(B6);Jco=r(dje,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),OB=n(dje,"A",{href:!0});var HUr=s(OB);Yco=r(HUr,"AutoProcessor.from_pretrained()"),HUr.forEach(t),Kco=r(dje," class method."),dje.forEach(t),Zco=i(js),I6=n(js,"P",{});var cje=s(I6);efo=r(cje,"This class cannot be instantiated directly using "),lne=n(cje,"CODE",{});var UUr=s(lne);ofo=r(UUr,"__init__()"),UUr.forEach(t),rfo=r(cje," (throws an error)."),cje.forEach(t),tfo=i(js),Ue=n(js,"DIV",{class:!0});var ea=s(Ue);T(q6.$$.fragment,ea),afo=i(ea),ine=n(ea,"P",{});var JUr=s(ine);nfo=r(JUr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),JUr.forEach(t),sfo=i(ea),Ei=n(ea,"P",{});var NK=s(Ei);lfo=r(NK,"The processor class to instantiate is selected based on the "),dne=n(NK,"CODE",{});var YUr=s(dne);ifo=r(YUr,"model_type"),YUr.forEach(t),dfo=r(NK,` property of the config object (either
passed as an argument or loaded from `),cne=n(NK,"CODE",{});var KUr=s(cne);cfo=r(KUr,"pretrained_model_name_or_path"),KUr.forEach(t),ffo=r(NK," if possible):"),NK.forEach(t),mfo=i(ea),pe=n(ea,"UL",{});var be=s(pe);Sh=n(be,"LI",{});var E0e=s(Sh);fne=n(E0e,"STRONG",{});var ZUr=s(fne);gfo=r(ZUr,"clip"),ZUr.forEach(t),hfo=r(E0e," \u2014 "),VB=n(E0e,"A",{href:!0});var eJr=s(VB);pfo=r(eJr,"CLIPProcessor"),eJr.forEach(t),_fo=r(E0e," (CLIP model)"),E0e.forEach(t),ufo=i(be),Rh=n(be,"LI",{});var C0e=s(Rh);mne=n(C0e,"STRONG",{});var oJr=s(mne);bfo=r(oJr,"flava"),oJr.forEach(t),vfo=r(C0e," \u2014 "),gne=n(C0e,"CODE",{});var rJr=s(gne);Ffo=r(rJr,"FLAVAProcessor"),rJr.forEach(t),Tfo=r(C0e," (Flava model)"),C0e.forEach(t),Mfo=i(be),Ph=n(be,"LI",{});var w0e=s(Ph);hne=n(w0e,"STRONG",{});var tJr=s(hne);Efo=r(tJr,"layoutlmv2"),tJr.forEach(t),Cfo=r(w0e," \u2014 "),XB=n(w0e,"A",{href:!0});var aJr=s(XB);wfo=r(aJr,"LayoutLMv2Processor"),aJr.forEach(t),Afo=r(w0e," (LayoutLMv2 model)"),w0e.forEach(t),yfo=i(be),Bh=n(be,"LI",{});var A0e=s(Bh);pne=n(A0e,"STRONG",{});var nJr=s(pne);Lfo=r(nJr,"layoutxlm"),nJr.forEach(t),xfo=r(A0e," \u2014 "),zB=n(A0e,"A",{href:!0});var sJr=s(zB);$fo=r(sJr,"LayoutXLMProcessor"),sJr.forEach(t),kfo=r(A0e," (LayoutXLM model)"),A0e.forEach(t),Sfo=i(be),Ih=n(be,"LI",{});var y0e=s(Ih);_ne=n(y0e,"STRONG",{});var lJr=s(_ne);Rfo=r(lJr,"sew"),lJr.forEach(t),Pfo=r(y0e," \u2014 "),WB=n(y0e,"A",{href:!0});var iJr=s(WB);Bfo=r(iJr,"Wav2Vec2Processor"),iJr.forEach(t),Ifo=r(y0e," (SEW model)"),y0e.forEach(t),qfo=i(be),qh=n(be,"LI",{});var L0e=s(qh);une=n(L0e,"STRONG",{});var dJr=s(une);Nfo=r(dJr,"sew-d"),dJr.forEach(t),jfo=r(L0e," \u2014 "),QB=n(L0e,"A",{href:!0});var cJr=s(QB);Dfo=r(cJr,"Wav2Vec2Processor"),cJr.forEach(t),Gfo=r(L0e," (SEW-D model)"),L0e.forEach(t),Ofo=i(be),Nh=n(be,"LI",{});var x0e=s(Nh);bne=n(x0e,"STRONG",{});var fJr=s(bne);Vfo=r(fJr,"speech_to_text"),fJr.forEach(t),Xfo=r(x0e," \u2014 "),HB=n(x0e,"A",{href:!0});var mJr=s(HB);zfo=r(mJr,"Speech2TextProcessor"),mJr.forEach(t),Wfo=r(x0e," (Speech2Text model)"),x0e.forEach(t),Qfo=i(be),jh=n(be,"LI",{});var $0e=s(jh);vne=n($0e,"STRONG",{});var gJr=s(vne);Hfo=r(gJr,"speech_to_text_2"),gJr.forEach(t),Ufo=r($0e," \u2014 "),UB=n($0e,"A",{href:!0});var hJr=s(UB);Jfo=r(hJr,"Speech2Text2Processor"),hJr.forEach(t),Yfo=r($0e," (Speech2Text2 model)"),$0e.forEach(t),Kfo=i(be),Dh=n(be,"LI",{});var k0e=s(Dh);Fne=n(k0e,"STRONG",{});var pJr=s(Fne);Zfo=r(pJr,"trocr"),pJr.forEach(t),emo=r(k0e," \u2014 "),JB=n(k0e,"A",{href:!0});var _Jr=s(JB);omo=r(_Jr,"TrOCRProcessor"),_Jr.forEach(t),rmo=r(k0e," (TrOCR model)"),k0e.forEach(t),tmo=i(be),Gh=n(be,"LI",{});var S0e=s(Gh);Tne=n(S0e,"STRONG",{});var uJr=s(Tne);amo=r(uJr,"unispeech"),uJr.forEach(t),nmo=r(S0e," \u2014 "),YB=n(S0e,"A",{href:!0});var bJr=s(YB);smo=r(bJr,"Wav2Vec2Processor"),bJr.forEach(t),lmo=r(S0e," (UniSpeech model)"),S0e.forEach(t),imo=i(be),Oh=n(be,"LI",{});var R0e=s(Oh);Mne=n(R0e,"STRONG",{});var vJr=s(Mne);dmo=r(vJr,"unispeech-sat"),vJr.forEach(t),cmo=r(R0e," \u2014 "),KB=n(R0e,"A",{href:!0});var FJr=s(KB);fmo=r(FJr,"Wav2Vec2Processor"),FJr.forEach(t),mmo=r(R0e," (UniSpeechSat model)"),R0e.forEach(t),gmo=i(be),Vh=n(be,"LI",{});var P0e=s(Vh);Ene=n(P0e,"STRONG",{});var TJr=s(Ene);hmo=r(TJr,"vilt"),TJr.forEach(t),pmo=r(P0e," \u2014 "),ZB=n(P0e,"A",{href:!0});var MJr=s(ZB);_mo=r(MJr,"ViltProcessor"),MJr.forEach(t),umo=r(P0e," (ViLT model)"),P0e.forEach(t),bmo=i(be),Xh=n(be,"LI",{});var B0e=s(Xh);Cne=n(B0e,"STRONG",{});var EJr=s(Cne);vmo=r(EJr,"vision-text-dual-encoder"),EJr.forEach(t),Fmo=r(B0e," \u2014 "),eI=n(B0e,"A",{href:!0});var CJr=s(eI);Tmo=r(CJr,"VisionTextDualEncoderProcessor"),CJr.forEach(t),Mmo=r(B0e," (VisionTextDualEncoder model)"),B0e.forEach(t),Emo=i(be),zh=n(be,"LI",{});var I0e=s(zh);wne=n(I0e,"STRONG",{});var wJr=s(wne);Cmo=r(wJr,"wav2vec2"),wJr.forEach(t),wmo=r(I0e," \u2014 "),oI=n(I0e,"A",{href:!0});var AJr=s(oI);Amo=r(AJr,"Wav2Vec2Processor"),AJr.forEach(t),ymo=r(I0e," (Wav2Vec2 model)"),I0e.forEach(t),Lmo=i(be),Wh=n(be,"LI",{});var q0e=s(Wh);Ane=n(q0e,"STRONG",{});var yJr=s(Ane);xmo=r(yJr,"wav2vec2-conformer"),yJr.forEach(t),$mo=r(q0e," \u2014 "),rI=n(q0e,"A",{href:!0});var LJr=s(rI);kmo=r(LJr,"Wav2Vec2Processor"),LJr.forEach(t),Smo=r(q0e," (Wav2Vec2-Conformer model)"),q0e.forEach(t),Rmo=i(be),Qh=n(be,"LI",{});var N0e=s(Qh);yne=n(N0e,"STRONG",{});var xJr=s(yne);Pmo=r(xJr,"wavlm"),xJr.forEach(t),Bmo=r(N0e," \u2014 "),tI=n(N0e,"A",{href:!0});var $Jr=s(tI);Imo=r($Jr,"Wav2Vec2Processor"),$Jr.forEach(t),qmo=r(N0e," (WavLM model)"),N0e.forEach(t),be.forEach(t),Nmo=i(ea),T(Hh.$$.fragment,ea),jmo=i(ea),T(Uh.$$.fragment,ea),ea.forEach(t),Dmo=i(js),Jh=n(js,"DIV",{class:!0});var fje=s(Jh);T(N6.$$.fragment,fje),Gmo=i(fje),Lne=n(fje,"P",{});var kJr=s(Lne);Omo=r(kJr,"Register a new processor for this class."),kJr.forEach(t),fje.forEach(t),js.forEach(t),iqe=i(f),Ci=n(f,"H2",{class:!0});var mje=s(Ci);Yh=n(mje,"A",{id:!0,class:!0,href:!0});var SJr=s(Yh);xne=n(SJr,"SPAN",{});var RJr=s(xne);T(j6.$$.fragment,RJr),RJr.forEach(t),SJr.forEach(t),Vmo=i(mje),$ne=n(mje,"SPAN",{});var PJr=s($ne);Xmo=r(PJr,"AutoModel"),PJr.forEach(t),mje.forEach(t),dqe=i(f),Lo=n(f,"DIV",{class:!0});var Ds=s(Lo);T(D6.$$.fragment,Ds),zmo=i(Ds),wi=n(Ds,"P",{});var jK=s(wi);Wmo=r(jK,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),aI=n(jK,"A",{href:!0});var BJr=s(aI);Qmo=r(BJr,"from_pretrained()"),BJr.forEach(t),Hmo=r(jK," class method or the "),nI=n(jK,"A",{href:!0});var IJr=s(nI);Umo=r(IJr,"from_config()"),IJr.forEach(t),Jmo=r(jK,` class
method.`),jK.forEach(t),Ymo=i(Ds),G6=n(Ds,"P",{});var gje=s(G6);Kmo=r(gje,"This class cannot be instantiated directly using "),kne=n(gje,"CODE",{});var qJr=s(kne);Zmo=r(qJr,"__init__()"),qJr.forEach(t),ego=r(gje," (throws an error)."),gje.forEach(t),ogo=i(Ds),tt=n(Ds,"DIV",{class:!0});var u0=s(tt);T(O6.$$.fragment,u0),rgo=i(u0),Sne=n(u0,"P",{});var NJr=s(Sne);tgo=r(NJr,"Instantiates one of the base model classes of the library from a configuration."),NJr.forEach(t),ago=i(u0),Ai=n(u0,"P",{});var DK=s(Ai);ngo=r(DK,`Note:
Loading a model from its configuration file does `),Rne=n(DK,"STRONG",{});var jJr=s(Rne);sgo=r(jJr,"not"),jJr.forEach(t),lgo=r(DK,` load the model weights. It only affects the
model\u2019s configuration. Use `),sI=n(DK,"A",{href:!0});var DJr=s(sI);igo=r(DJr,"from_pretrained()"),DJr.forEach(t),dgo=r(DK," to load the model weights."),DK.forEach(t),cgo=i(u0),T(Kh.$$.fragment,u0),u0.forEach(t),fgo=i(Ds),Je=n(Ds,"DIV",{class:!0});var oa=s(Je);T(V6.$$.fragment,oa),mgo=i(oa),Pne=n(oa,"P",{});var GJr=s(Pne);ggo=r(GJr,"Instantiate one of the base model classes of the library from a pretrained model."),GJr.forEach(t),hgo=i(oa),La=n(oa,"P",{});var b0=s(La);pgo=r(b0,"The model class to instantiate is selected based on the "),Bne=n(b0,"CODE",{});var OJr=s(Bne);_go=r(OJr,"model_type"),OJr.forEach(t),ugo=r(b0,` property of the config object (either
passed as an argument or loaded from `),Ine=n(b0,"CODE",{});var VJr=s(Ine);bgo=r(VJr,"pretrained_model_name_or_path"),VJr.forEach(t),vgo=r(b0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qne=n(b0,"CODE",{});var XJr=s(qne);Fgo=r(XJr,"pretrained_model_name_or_path"),XJr.forEach(t),Tgo=r(b0,":"),b0.forEach(t),Mgo=i(oa),x=n(oa,"UL",{});var $=s(x);Zh=n($,"LI",{});var j0e=s(Zh);Nne=n(j0e,"STRONG",{});var zJr=s(Nne);Ego=r(zJr,"albert"),zJr.forEach(t),Cgo=r(j0e," \u2014 "),lI=n(j0e,"A",{href:!0});var WJr=s(lI);wgo=r(WJr,"AlbertModel"),WJr.forEach(t),Ago=r(j0e," (ALBERT model)"),j0e.forEach(t),ygo=i($),ep=n($,"LI",{});var D0e=s(ep);jne=n(D0e,"STRONG",{});var QJr=s(jne);Lgo=r(QJr,"bart"),QJr.forEach(t),xgo=r(D0e," \u2014 "),iI=n(D0e,"A",{href:!0});var HJr=s(iI);$go=r(HJr,"BartModel"),HJr.forEach(t),kgo=r(D0e," (BART model)"),D0e.forEach(t),Sgo=i($),op=n($,"LI",{});var G0e=s(op);Dne=n(G0e,"STRONG",{});var UJr=s(Dne);Rgo=r(UJr,"beit"),UJr.forEach(t),Pgo=r(G0e," \u2014 "),dI=n(G0e,"A",{href:!0});var JJr=s(dI);Bgo=r(JJr,"BeitModel"),JJr.forEach(t),Igo=r(G0e," (BEiT model)"),G0e.forEach(t),qgo=i($),rp=n($,"LI",{});var O0e=s(rp);Gne=n(O0e,"STRONG",{});var YJr=s(Gne);Ngo=r(YJr,"bert"),YJr.forEach(t),jgo=r(O0e," \u2014 "),cI=n(O0e,"A",{href:!0});var KJr=s(cI);Dgo=r(KJr,"BertModel"),KJr.forEach(t),Ggo=r(O0e," (BERT model)"),O0e.forEach(t),Ogo=i($),tp=n($,"LI",{});var V0e=s(tp);One=n(V0e,"STRONG",{});var ZJr=s(One);Vgo=r(ZJr,"bert-generation"),ZJr.forEach(t),Xgo=r(V0e," \u2014 "),fI=n(V0e,"A",{href:!0});var eYr=s(fI);zgo=r(eYr,"BertGenerationEncoder"),eYr.forEach(t),Wgo=r(V0e," (Bert Generation model)"),V0e.forEach(t),Qgo=i($),ap=n($,"LI",{});var X0e=s(ap);Vne=n(X0e,"STRONG",{});var oYr=s(Vne);Hgo=r(oYr,"big_bird"),oYr.forEach(t),Ugo=r(X0e," \u2014 "),mI=n(X0e,"A",{href:!0});var rYr=s(mI);Jgo=r(rYr,"BigBirdModel"),rYr.forEach(t),Ygo=r(X0e," (BigBird model)"),X0e.forEach(t),Kgo=i($),np=n($,"LI",{});var z0e=s(np);Xne=n(z0e,"STRONG",{});var tYr=s(Xne);Zgo=r(tYr,"bigbird_pegasus"),tYr.forEach(t),eho=r(z0e," \u2014 "),gI=n(z0e,"A",{href:!0});var aYr=s(gI);oho=r(aYr,"BigBirdPegasusModel"),aYr.forEach(t),rho=r(z0e," (BigBirdPegasus model)"),z0e.forEach(t),tho=i($),sp=n($,"LI",{});var W0e=s(sp);zne=n(W0e,"STRONG",{});var nYr=s(zne);aho=r(nYr,"blenderbot"),nYr.forEach(t),nho=r(W0e," \u2014 "),hI=n(W0e,"A",{href:!0});var sYr=s(hI);sho=r(sYr,"BlenderbotModel"),sYr.forEach(t),lho=r(W0e," (Blenderbot model)"),W0e.forEach(t),iho=i($),lp=n($,"LI",{});var Q0e=s(lp);Wne=n(Q0e,"STRONG",{});var lYr=s(Wne);dho=r(lYr,"blenderbot-small"),lYr.forEach(t),cho=r(Q0e," \u2014 "),pI=n(Q0e,"A",{href:!0});var iYr=s(pI);fho=r(iYr,"BlenderbotSmallModel"),iYr.forEach(t),mho=r(Q0e," (BlenderbotSmall model)"),Q0e.forEach(t),gho=i($),ip=n($,"LI",{});var H0e=s(ip);Qne=n(H0e,"STRONG",{});var dYr=s(Qne);hho=r(dYr,"camembert"),dYr.forEach(t),pho=r(H0e," \u2014 "),_I=n(H0e,"A",{href:!0});var cYr=s(_I);_ho=r(cYr,"CamembertModel"),cYr.forEach(t),uho=r(H0e," (CamemBERT model)"),H0e.forEach(t),bho=i($),dp=n($,"LI",{});var U0e=s(dp);Hne=n(U0e,"STRONG",{});var fYr=s(Hne);vho=r(fYr,"canine"),fYr.forEach(t),Fho=r(U0e," \u2014 "),uI=n(U0e,"A",{href:!0});var mYr=s(uI);Tho=r(mYr,"CanineModel"),mYr.forEach(t),Mho=r(U0e," (Canine model)"),U0e.forEach(t),Eho=i($),cp=n($,"LI",{});var J0e=s(cp);Une=n(J0e,"STRONG",{});var gYr=s(Une);Cho=r(gYr,"clip"),gYr.forEach(t),who=r(J0e," \u2014 "),bI=n(J0e,"A",{href:!0});var hYr=s(bI);Aho=r(hYr,"CLIPModel"),hYr.forEach(t),yho=r(J0e," (CLIP model)"),J0e.forEach(t),Lho=i($),fp=n($,"LI",{});var Y0e=s(fp);Jne=n(Y0e,"STRONG",{});var pYr=s(Jne);xho=r(pYr,"convbert"),pYr.forEach(t),$ho=r(Y0e," \u2014 "),vI=n(Y0e,"A",{href:!0});var _Yr=s(vI);kho=r(_Yr,"ConvBertModel"),_Yr.forEach(t),Sho=r(Y0e," (ConvBERT model)"),Y0e.forEach(t),Rho=i($),mp=n($,"LI",{});var K0e=s(mp);Yne=n(K0e,"STRONG",{});var uYr=s(Yne);Pho=r(uYr,"convnext"),uYr.forEach(t),Bho=r(K0e," \u2014 "),FI=n(K0e,"A",{href:!0});var bYr=s(FI);Iho=r(bYr,"ConvNextModel"),bYr.forEach(t),qho=r(K0e," (ConvNext model)"),K0e.forEach(t),Nho=i($),gp=n($,"LI",{});var Z0e=s(gp);Kne=n(Z0e,"STRONG",{});var vYr=s(Kne);jho=r(vYr,"ctrl"),vYr.forEach(t),Dho=r(Z0e," \u2014 "),TI=n(Z0e,"A",{href:!0});var FYr=s(TI);Gho=r(FYr,"CTRLModel"),FYr.forEach(t),Oho=r(Z0e," (CTRL model)"),Z0e.forEach(t),Vho=i($),hp=n($,"LI",{});var eAe=s(hp);Zne=n(eAe,"STRONG",{});var TYr=s(Zne);Xho=r(TYr,"data2vec-audio"),TYr.forEach(t),zho=r(eAe," \u2014 "),MI=n(eAe,"A",{href:!0});var MYr=s(MI);Who=r(MYr,"Data2VecAudioModel"),MYr.forEach(t),Qho=r(eAe," (Data2VecAudio model)"),eAe.forEach(t),Hho=i($),pp=n($,"LI",{});var oAe=s(pp);ese=n(oAe,"STRONG",{});var EYr=s(ese);Uho=r(EYr,"data2vec-text"),EYr.forEach(t),Jho=r(oAe," \u2014 "),EI=n(oAe,"A",{href:!0});var CYr=s(EI);Yho=r(CYr,"Data2VecTextModel"),CYr.forEach(t),Kho=r(oAe," (Data2VecText model)"),oAe.forEach(t),Zho=i($),_p=n($,"LI",{});var rAe=s(_p);ose=n(rAe,"STRONG",{});var wYr=s(ose);epo=r(wYr,"data2vec-vision"),wYr.forEach(t),opo=r(rAe," \u2014 "),CI=n(rAe,"A",{href:!0});var AYr=s(CI);rpo=r(AYr,"Data2VecVisionModel"),AYr.forEach(t),tpo=r(rAe," (Data2VecVision model)"),rAe.forEach(t),apo=i($),up=n($,"LI",{});var tAe=s(up);rse=n(tAe,"STRONG",{});var yYr=s(rse);npo=r(yYr,"deberta"),yYr.forEach(t),spo=r(tAe," \u2014 "),wI=n(tAe,"A",{href:!0});var LYr=s(wI);lpo=r(LYr,"DebertaModel"),LYr.forEach(t),ipo=r(tAe," (DeBERTa model)"),tAe.forEach(t),dpo=i($),bp=n($,"LI",{});var aAe=s(bp);tse=n(aAe,"STRONG",{});var xYr=s(tse);cpo=r(xYr,"deberta-v2"),xYr.forEach(t),fpo=r(aAe," \u2014 "),AI=n(aAe,"A",{href:!0});var $Yr=s(AI);mpo=r($Yr,"DebertaV2Model"),$Yr.forEach(t),gpo=r(aAe," (DeBERTa-v2 model)"),aAe.forEach(t),hpo=i($),vp=n($,"LI",{});var nAe=s(vp);ase=n(nAe,"STRONG",{});var kYr=s(ase);ppo=r(kYr,"decision_transformer"),kYr.forEach(t),_po=r(nAe," \u2014 "),yI=n(nAe,"A",{href:!0});var SYr=s(yI);upo=r(SYr,"DecisionTransformerModel"),SYr.forEach(t),bpo=r(nAe," (Decision Transformer model)"),nAe.forEach(t),vpo=i($),Fp=n($,"LI",{});var sAe=s(Fp);nse=n(sAe,"STRONG",{});var RYr=s(nse);Fpo=r(RYr,"deit"),RYr.forEach(t),Tpo=r(sAe," \u2014 "),LI=n(sAe,"A",{href:!0});var PYr=s(LI);Mpo=r(PYr,"DeiTModel"),PYr.forEach(t),Epo=r(sAe," (DeiT model)"),sAe.forEach(t),Cpo=i($),Tp=n($,"LI",{});var lAe=s(Tp);sse=n(lAe,"STRONG",{});var BYr=s(sse);wpo=r(BYr,"detr"),BYr.forEach(t),Apo=r(lAe," \u2014 "),xI=n(lAe,"A",{href:!0});var IYr=s(xI);ypo=r(IYr,"DetrModel"),IYr.forEach(t),Lpo=r(lAe," (DETR model)"),lAe.forEach(t),xpo=i($),Mp=n($,"LI",{});var iAe=s(Mp);lse=n(iAe,"STRONG",{});var qYr=s(lse);$po=r(qYr,"distilbert"),qYr.forEach(t),kpo=r(iAe," \u2014 "),$I=n(iAe,"A",{href:!0});var NYr=s($I);Spo=r(NYr,"DistilBertModel"),NYr.forEach(t),Rpo=r(iAe," (DistilBERT model)"),iAe.forEach(t),Ppo=i($),Ep=n($,"LI",{});var dAe=s(Ep);ise=n(dAe,"STRONG",{});var jYr=s(ise);Bpo=r(jYr,"dpr"),jYr.forEach(t),Ipo=r(dAe," \u2014 "),kI=n(dAe,"A",{href:!0});var DYr=s(kI);qpo=r(DYr,"DPRQuestionEncoder"),DYr.forEach(t),Npo=r(dAe," (DPR model)"),dAe.forEach(t),jpo=i($),Cp=n($,"LI",{});var cAe=s(Cp);dse=n(cAe,"STRONG",{});var GYr=s(dse);Dpo=r(GYr,"dpt"),GYr.forEach(t),Gpo=r(cAe," \u2014 "),SI=n(cAe,"A",{href:!0});var OYr=s(SI);Opo=r(OYr,"DPTModel"),OYr.forEach(t),Vpo=r(cAe," (DPT model)"),cAe.forEach(t),Xpo=i($),wp=n($,"LI",{});var fAe=s(wp);cse=n(fAe,"STRONG",{});var VYr=s(cse);zpo=r(VYr,"electra"),VYr.forEach(t),Wpo=r(fAe," \u2014 "),RI=n(fAe,"A",{href:!0});var XYr=s(RI);Qpo=r(XYr,"ElectraModel"),XYr.forEach(t),Hpo=r(fAe," (ELECTRA model)"),fAe.forEach(t),Upo=i($),Ap=n($,"LI",{});var mAe=s(Ap);fse=n(mAe,"STRONG",{});var zYr=s(fse);Jpo=r(zYr,"flaubert"),zYr.forEach(t),Ypo=r(mAe," \u2014 "),PI=n(mAe,"A",{href:!0});var WYr=s(PI);Kpo=r(WYr,"FlaubertModel"),WYr.forEach(t),Zpo=r(mAe," (FlauBERT model)"),mAe.forEach(t),e_o=i($),yp=n($,"LI",{});var gAe=s(yp);mse=n(gAe,"STRONG",{});var QYr=s(mse);o_o=r(QYr,"flava"),QYr.forEach(t),r_o=r(gAe," \u2014 "),BI=n(gAe,"A",{href:!0});var HYr=s(BI);t_o=r(HYr,"FlavaModel"),HYr.forEach(t),a_o=r(gAe," (Flava model)"),gAe.forEach(t),n_o=i($),Lp=n($,"LI",{});var hAe=s(Lp);gse=n(hAe,"STRONG",{});var UYr=s(gse);s_o=r(UYr,"fnet"),UYr.forEach(t),l_o=r(hAe," \u2014 "),II=n(hAe,"A",{href:!0});var JYr=s(II);i_o=r(JYr,"FNetModel"),JYr.forEach(t),d_o=r(hAe," (FNet model)"),hAe.forEach(t),c_o=i($),xp=n($,"LI",{});var pAe=s(xp);hse=n(pAe,"STRONG",{});var YYr=s(hse);f_o=r(YYr,"fsmt"),YYr.forEach(t),m_o=r(pAe," \u2014 "),qI=n(pAe,"A",{href:!0});var KYr=s(qI);g_o=r(KYr,"FSMTModel"),KYr.forEach(t),h_o=r(pAe," (FairSeq Machine-Translation model)"),pAe.forEach(t),p_o=i($),Rs=n($,"LI",{});var y$=s(Rs);pse=n(y$,"STRONG",{});var ZYr=s(pse);__o=r(ZYr,"funnel"),ZYr.forEach(t),u_o=r(y$," \u2014 "),NI=n(y$,"A",{href:!0});var eKr=s(NI);b_o=r(eKr,"FunnelModel"),eKr.forEach(t),v_o=r(y$," or "),jI=n(y$,"A",{href:!0});var oKr=s(jI);F_o=r(oKr,"FunnelBaseModel"),oKr.forEach(t),T_o=r(y$," (Funnel Transformer model)"),y$.forEach(t),M_o=i($),$p=n($,"LI",{});var _Ae=s($p);_se=n(_Ae,"STRONG",{});var rKr=s(_se);E_o=r(rKr,"glpn"),rKr.forEach(t),C_o=r(_Ae," \u2014 "),DI=n(_Ae,"A",{href:!0});var tKr=s(DI);w_o=r(tKr,"GLPNModel"),tKr.forEach(t),A_o=r(_Ae," (GLPN model)"),_Ae.forEach(t),y_o=i($),kp=n($,"LI",{});var uAe=s(kp);use=n(uAe,"STRONG",{});var aKr=s(use);L_o=r(aKr,"gpt2"),aKr.forEach(t),x_o=r(uAe," \u2014 "),GI=n(uAe,"A",{href:!0});var nKr=s(GI);$_o=r(nKr,"GPT2Model"),nKr.forEach(t),k_o=r(uAe," (OpenAI GPT-2 model)"),uAe.forEach(t),S_o=i($),Sp=n($,"LI",{});var bAe=s(Sp);bse=n(bAe,"STRONG",{});var sKr=s(bse);R_o=r(sKr,"gpt_neo"),sKr.forEach(t),P_o=r(bAe," \u2014 "),OI=n(bAe,"A",{href:!0});var lKr=s(OI);B_o=r(lKr,"GPTNeoModel"),lKr.forEach(t),I_o=r(bAe," (GPT Neo model)"),bAe.forEach(t),q_o=i($),Rp=n($,"LI",{});var vAe=s(Rp);vse=n(vAe,"STRONG",{});var iKr=s(vse);N_o=r(iKr,"gptj"),iKr.forEach(t),j_o=r(vAe," \u2014 "),VI=n(vAe,"A",{href:!0});var dKr=s(VI);D_o=r(dKr,"GPTJModel"),dKr.forEach(t),G_o=r(vAe," (GPT-J model)"),vAe.forEach(t),O_o=i($),Pp=n($,"LI",{});var FAe=s(Pp);Fse=n(FAe,"STRONG",{});var cKr=s(Fse);V_o=r(cKr,"hubert"),cKr.forEach(t),X_o=r(FAe," \u2014 "),XI=n(FAe,"A",{href:!0});var fKr=s(XI);z_o=r(fKr,"HubertModel"),fKr.forEach(t),W_o=r(FAe," (Hubert model)"),FAe.forEach(t),Q_o=i($),Bp=n($,"LI",{});var TAe=s(Bp);Tse=n(TAe,"STRONG",{});var mKr=s(Tse);H_o=r(mKr,"ibert"),mKr.forEach(t),U_o=r(TAe," \u2014 "),zI=n(TAe,"A",{href:!0});var gKr=s(zI);J_o=r(gKr,"IBertModel"),gKr.forEach(t),Y_o=r(TAe," (I-BERT model)"),TAe.forEach(t),K_o=i($),Ip=n($,"LI",{});var MAe=s(Ip);Mse=n(MAe,"STRONG",{});var hKr=s(Mse);Z_o=r(hKr,"imagegpt"),hKr.forEach(t),euo=r(MAe," \u2014 "),WI=n(MAe,"A",{href:!0});var pKr=s(WI);ouo=r(pKr,"ImageGPTModel"),pKr.forEach(t),ruo=r(MAe," (ImageGPT model)"),MAe.forEach(t),tuo=i($),qp=n($,"LI",{});var EAe=s(qp);Ese=n(EAe,"STRONG",{});var _Kr=s(Ese);auo=r(_Kr,"layoutlm"),_Kr.forEach(t),nuo=r(EAe," \u2014 "),QI=n(EAe,"A",{href:!0});var uKr=s(QI);suo=r(uKr,"LayoutLMModel"),uKr.forEach(t),luo=r(EAe," (LayoutLM model)"),EAe.forEach(t),iuo=i($),Np=n($,"LI",{});var CAe=s(Np);Cse=n(CAe,"STRONG",{});var bKr=s(Cse);duo=r(bKr,"layoutlmv2"),bKr.forEach(t),cuo=r(CAe," \u2014 "),HI=n(CAe,"A",{href:!0});var vKr=s(HI);fuo=r(vKr,"LayoutLMv2Model"),vKr.forEach(t),muo=r(CAe," (LayoutLMv2 model)"),CAe.forEach(t),guo=i($),jp=n($,"LI",{});var wAe=s(jp);wse=n(wAe,"STRONG",{});var FKr=s(wse);huo=r(FKr,"led"),FKr.forEach(t),puo=r(wAe," \u2014 "),UI=n(wAe,"A",{href:!0});var TKr=s(UI);_uo=r(TKr,"LEDModel"),TKr.forEach(t),uuo=r(wAe," (LED model)"),wAe.forEach(t),buo=i($),Dp=n($,"LI",{});var AAe=s(Dp);Ase=n(AAe,"STRONG",{});var MKr=s(Ase);vuo=r(MKr,"longformer"),MKr.forEach(t),Fuo=r(AAe," \u2014 "),JI=n(AAe,"A",{href:!0});var EKr=s(JI);Tuo=r(EKr,"LongformerModel"),EKr.forEach(t),Muo=r(AAe," (Longformer model)"),AAe.forEach(t),Euo=i($),Gp=n($,"LI",{});var yAe=s(Gp);yse=n(yAe,"STRONG",{});var CKr=s(yse);Cuo=r(CKr,"luke"),CKr.forEach(t),wuo=r(yAe," \u2014 "),YI=n(yAe,"A",{href:!0});var wKr=s(YI);Auo=r(wKr,"LukeModel"),wKr.forEach(t),yuo=r(yAe," (LUKE model)"),yAe.forEach(t),Luo=i($),Op=n($,"LI",{});var LAe=s(Op);Lse=n(LAe,"STRONG",{});var AKr=s(Lse);xuo=r(AKr,"lxmert"),AKr.forEach(t),$uo=r(LAe," \u2014 "),KI=n(LAe,"A",{href:!0});var yKr=s(KI);kuo=r(yKr,"LxmertModel"),yKr.forEach(t),Suo=r(LAe," (LXMERT model)"),LAe.forEach(t),Ruo=i($),Vp=n($,"LI",{});var xAe=s(Vp);xse=n(xAe,"STRONG",{});var LKr=s(xse);Puo=r(LKr,"m2m_100"),LKr.forEach(t),Buo=r(xAe," \u2014 "),ZI=n(xAe,"A",{href:!0});var xKr=s(ZI);Iuo=r(xKr,"M2M100Model"),xKr.forEach(t),quo=r(xAe," (M2M100 model)"),xAe.forEach(t),Nuo=i($),Xp=n($,"LI",{});var $Ae=s(Xp);$se=n($Ae,"STRONG",{});var $Kr=s($se);juo=r($Kr,"marian"),$Kr.forEach(t),Duo=r($Ae," \u2014 "),eq=n($Ae,"A",{href:!0});var kKr=s(eq);Guo=r(kKr,"MarianModel"),kKr.forEach(t),Ouo=r($Ae," (Marian model)"),$Ae.forEach(t),Vuo=i($),zp=n($,"LI",{});var kAe=s(zp);kse=n(kAe,"STRONG",{});var SKr=s(kse);Xuo=r(SKr,"maskformer"),SKr.forEach(t),zuo=r(kAe," \u2014 "),oq=n(kAe,"A",{href:!0});var RKr=s(oq);Wuo=r(RKr,"MaskFormerModel"),RKr.forEach(t),Quo=r(kAe," (MaskFormer model)"),kAe.forEach(t),Huo=i($),Wp=n($,"LI",{});var SAe=s(Wp);Sse=n(SAe,"STRONG",{});var PKr=s(Sse);Uuo=r(PKr,"mbart"),PKr.forEach(t),Juo=r(SAe," \u2014 "),rq=n(SAe,"A",{href:!0});var BKr=s(rq);Yuo=r(BKr,"MBartModel"),BKr.forEach(t),Kuo=r(SAe," (mBART model)"),SAe.forEach(t),Zuo=i($),Qp=n($,"LI",{});var RAe=s(Qp);Rse=n(RAe,"STRONG",{});var IKr=s(Rse);e2o=r(IKr,"megatron-bert"),IKr.forEach(t),o2o=r(RAe," \u2014 "),tq=n(RAe,"A",{href:!0});var qKr=s(tq);r2o=r(qKr,"MegatronBertModel"),qKr.forEach(t),t2o=r(RAe," (MegatronBert model)"),RAe.forEach(t),a2o=i($),Hp=n($,"LI",{});var PAe=s(Hp);Pse=n(PAe,"STRONG",{});var NKr=s(Pse);n2o=r(NKr,"mobilebert"),NKr.forEach(t),s2o=r(PAe," \u2014 "),aq=n(PAe,"A",{href:!0});var jKr=s(aq);l2o=r(jKr,"MobileBertModel"),jKr.forEach(t),i2o=r(PAe," (MobileBERT model)"),PAe.forEach(t),d2o=i($),Up=n($,"LI",{});var BAe=s(Up);Bse=n(BAe,"STRONG",{});var DKr=s(Bse);c2o=r(DKr,"mpnet"),DKr.forEach(t),f2o=r(BAe," \u2014 "),nq=n(BAe,"A",{href:!0});var GKr=s(nq);m2o=r(GKr,"MPNetModel"),GKr.forEach(t),g2o=r(BAe," (MPNet model)"),BAe.forEach(t),h2o=i($),Jp=n($,"LI",{});var IAe=s(Jp);Ise=n(IAe,"STRONG",{});var OKr=s(Ise);p2o=r(OKr,"mt5"),OKr.forEach(t),_2o=r(IAe," \u2014 "),sq=n(IAe,"A",{href:!0});var VKr=s(sq);u2o=r(VKr,"MT5Model"),VKr.forEach(t),b2o=r(IAe," (mT5 model)"),IAe.forEach(t),v2o=i($),Yp=n($,"LI",{});var qAe=s(Yp);qse=n(qAe,"STRONG",{});var XKr=s(qse);F2o=r(XKr,"nystromformer"),XKr.forEach(t),T2o=r(qAe," \u2014 "),lq=n(qAe,"A",{href:!0});var zKr=s(lq);M2o=r(zKr,"NystromformerModel"),zKr.forEach(t),E2o=r(qAe," (Nystromformer model)"),qAe.forEach(t),C2o=i($),Kp=n($,"LI",{});var NAe=s(Kp);Nse=n(NAe,"STRONG",{});var WKr=s(Nse);w2o=r(WKr,"openai-gpt"),WKr.forEach(t),A2o=r(NAe," \u2014 "),iq=n(NAe,"A",{href:!0});var QKr=s(iq);y2o=r(QKr,"OpenAIGPTModel"),QKr.forEach(t),L2o=r(NAe," (OpenAI GPT model)"),NAe.forEach(t),x2o=i($),Zp=n($,"LI",{});var jAe=s(Zp);jse=n(jAe,"STRONG",{});var HKr=s(jse);$2o=r(HKr,"opt"),HKr.forEach(t),k2o=r(jAe," \u2014 "),dq=n(jAe,"A",{href:!0});var UKr=s(dq);S2o=r(UKr,"OPTModel"),UKr.forEach(t),R2o=r(jAe," (OPT model)"),jAe.forEach(t),P2o=i($),e_=n($,"LI",{});var DAe=s(e_);Dse=n(DAe,"STRONG",{});var JKr=s(Dse);B2o=r(JKr,"pegasus"),JKr.forEach(t),I2o=r(DAe," \u2014 "),cq=n(DAe,"A",{href:!0});var YKr=s(cq);q2o=r(YKr,"PegasusModel"),YKr.forEach(t),N2o=r(DAe," (Pegasus model)"),DAe.forEach(t),j2o=i($),o_=n($,"LI",{});var GAe=s(o_);Gse=n(GAe,"STRONG",{});var KKr=s(Gse);D2o=r(KKr,"perceiver"),KKr.forEach(t),G2o=r(GAe," \u2014 "),fq=n(GAe,"A",{href:!0});var ZKr=s(fq);O2o=r(ZKr,"PerceiverModel"),ZKr.forEach(t),V2o=r(GAe," (Perceiver model)"),GAe.forEach(t),X2o=i($),r_=n($,"LI",{});var OAe=s(r_);Ose=n(OAe,"STRONG",{});var eZr=s(Ose);z2o=r(eZr,"plbart"),eZr.forEach(t),W2o=r(OAe," \u2014 "),mq=n(OAe,"A",{href:!0});var oZr=s(mq);Q2o=r(oZr,"PLBartModel"),oZr.forEach(t),H2o=r(OAe," (PLBart model)"),OAe.forEach(t),U2o=i($),t_=n($,"LI",{});var VAe=s(t_);Vse=n(VAe,"STRONG",{});var rZr=s(Vse);J2o=r(rZr,"poolformer"),rZr.forEach(t),Y2o=r(VAe," \u2014 "),gq=n(VAe,"A",{href:!0});var tZr=s(gq);K2o=r(tZr,"PoolFormerModel"),tZr.forEach(t),Z2o=r(VAe," (PoolFormer model)"),VAe.forEach(t),e1o=i($),a_=n($,"LI",{});var XAe=s(a_);Xse=n(XAe,"STRONG",{});var aZr=s(Xse);o1o=r(aZr,"prophetnet"),aZr.forEach(t),r1o=r(XAe," \u2014 "),hq=n(XAe,"A",{href:!0});var nZr=s(hq);t1o=r(nZr,"ProphetNetModel"),nZr.forEach(t),a1o=r(XAe," (ProphetNet model)"),XAe.forEach(t),n1o=i($),n_=n($,"LI",{});var zAe=s(n_);zse=n(zAe,"STRONG",{});var sZr=s(zse);s1o=r(sZr,"qdqbert"),sZr.forEach(t),l1o=r(zAe," \u2014 "),pq=n(zAe,"A",{href:!0});var lZr=s(pq);i1o=r(lZr,"QDQBertModel"),lZr.forEach(t),d1o=r(zAe," (QDQBert model)"),zAe.forEach(t),c1o=i($),s_=n($,"LI",{});var WAe=s(s_);Wse=n(WAe,"STRONG",{});var iZr=s(Wse);f1o=r(iZr,"reformer"),iZr.forEach(t),m1o=r(WAe," \u2014 "),_q=n(WAe,"A",{href:!0});var dZr=s(_q);g1o=r(dZr,"ReformerModel"),dZr.forEach(t),h1o=r(WAe," (Reformer model)"),WAe.forEach(t),p1o=i($),l_=n($,"LI",{});var QAe=s(l_);Qse=n(QAe,"STRONG",{});var cZr=s(Qse);_1o=r(cZr,"regnet"),cZr.forEach(t),u1o=r(QAe," \u2014 "),uq=n(QAe,"A",{href:!0});var fZr=s(uq);b1o=r(fZr,"RegNetModel"),fZr.forEach(t),v1o=r(QAe," (RegNet model)"),QAe.forEach(t),F1o=i($),i_=n($,"LI",{});var HAe=s(i_);Hse=n(HAe,"STRONG",{});var mZr=s(Hse);T1o=r(mZr,"rembert"),mZr.forEach(t),M1o=r(HAe," \u2014 "),bq=n(HAe,"A",{href:!0});var gZr=s(bq);E1o=r(gZr,"RemBertModel"),gZr.forEach(t),C1o=r(HAe," (RemBERT model)"),HAe.forEach(t),w1o=i($),d_=n($,"LI",{});var UAe=s(d_);Use=n(UAe,"STRONG",{});var hZr=s(Use);A1o=r(hZr,"resnet"),hZr.forEach(t),y1o=r(UAe," \u2014 "),vq=n(UAe,"A",{href:!0});var pZr=s(vq);L1o=r(pZr,"ResNetModel"),pZr.forEach(t),x1o=r(UAe," (ResNet model)"),UAe.forEach(t),$1o=i($),c_=n($,"LI",{});var JAe=s(c_);Jse=n(JAe,"STRONG",{});var _Zr=s(Jse);k1o=r(_Zr,"retribert"),_Zr.forEach(t),S1o=r(JAe," \u2014 "),Fq=n(JAe,"A",{href:!0});var uZr=s(Fq);R1o=r(uZr,"RetriBertModel"),uZr.forEach(t),P1o=r(JAe," (RetriBERT model)"),JAe.forEach(t),B1o=i($),f_=n($,"LI",{});var YAe=s(f_);Yse=n(YAe,"STRONG",{});var bZr=s(Yse);I1o=r(bZr,"roberta"),bZr.forEach(t),q1o=r(YAe," \u2014 "),Tq=n(YAe,"A",{href:!0});var vZr=s(Tq);N1o=r(vZr,"RobertaModel"),vZr.forEach(t),j1o=r(YAe," (RoBERTa model)"),YAe.forEach(t),D1o=i($),m_=n($,"LI",{});var KAe=s(m_);Kse=n(KAe,"STRONG",{});var FZr=s(Kse);G1o=r(FZr,"roformer"),FZr.forEach(t),O1o=r(KAe," \u2014 "),Mq=n(KAe,"A",{href:!0});var TZr=s(Mq);V1o=r(TZr,"RoFormerModel"),TZr.forEach(t),X1o=r(KAe," (RoFormer model)"),KAe.forEach(t),z1o=i($),g_=n($,"LI",{});var ZAe=s(g_);Zse=n(ZAe,"STRONG",{});var MZr=s(Zse);W1o=r(MZr,"segformer"),MZr.forEach(t),Q1o=r(ZAe," \u2014 "),Eq=n(ZAe,"A",{href:!0});var EZr=s(Eq);H1o=r(EZr,"SegformerModel"),EZr.forEach(t),U1o=r(ZAe," (SegFormer model)"),ZAe.forEach(t),J1o=i($),h_=n($,"LI",{});var e6e=s(h_);ele=n(e6e,"STRONG",{});var CZr=s(ele);Y1o=r(CZr,"sew"),CZr.forEach(t),K1o=r(e6e," \u2014 "),Cq=n(e6e,"A",{href:!0});var wZr=s(Cq);Z1o=r(wZr,"SEWModel"),wZr.forEach(t),e7o=r(e6e," (SEW model)"),e6e.forEach(t),o7o=i($),p_=n($,"LI",{});var o6e=s(p_);ole=n(o6e,"STRONG",{});var AZr=s(ole);r7o=r(AZr,"sew-d"),AZr.forEach(t),t7o=r(o6e," \u2014 "),wq=n(o6e,"A",{href:!0});var yZr=s(wq);a7o=r(yZr,"SEWDModel"),yZr.forEach(t),n7o=r(o6e," (SEW-D model)"),o6e.forEach(t),s7o=i($),__=n($,"LI",{});var r6e=s(__);rle=n(r6e,"STRONG",{});var LZr=s(rle);l7o=r(LZr,"speech_to_text"),LZr.forEach(t),i7o=r(r6e," \u2014 "),Aq=n(r6e,"A",{href:!0});var xZr=s(Aq);d7o=r(xZr,"Speech2TextModel"),xZr.forEach(t),c7o=r(r6e," (Speech2Text model)"),r6e.forEach(t),f7o=i($),u_=n($,"LI",{});var t6e=s(u_);tle=n(t6e,"STRONG",{});var $Zr=s(tle);m7o=r($Zr,"splinter"),$Zr.forEach(t),g7o=r(t6e," \u2014 "),yq=n(t6e,"A",{href:!0});var kZr=s(yq);h7o=r(kZr,"SplinterModel"),kZr.forEach(t),p7o=r(t6e," (Splinter model)"),t6e.forEach(t),_7o=i($),b_=n($,"LI",{});var a6e=s(b_);ale=n(a6e,"STRONG",{});var SZr=s(ale);u7o=r(SZr,"squeezebert"),SZr.forEach(t),b7o=r(a6e," \u2014 "),Lq=n(a6e,"A",{href:!0});var RZr=s(Lq);v7o=r(RZr,"SqueezeBertModel"),RZr.forEach(t),F7o=r(a6e," (SqueezeBERT model)"),a6e.forEach(t),T7o=i($),v_=n($,"LI",{});var n6e=s(v_);nle=n(n6e,"STRONG",{});var PZr=s(nle);M7o=r(PZr,"swin"),PZr.forEach(t),E7o=r(n6e," \u2014 "),xq=n(n6e,"A",{href:!0});var BZr=s(xq);C7o=r(BZr,"SwinModel"),BZr.forEach(t),w7o=r(n6e," (Swin model)"),n6e.forEach(t),A7o=i($),F_=n($,"LI",{});var s6e=s(F_);sle=n(s6e,"STRONG",{});var IZr=s(sle);y7o=r(IZr,"t5"),IZr.forEach(t),L7o=r(s6e," \u2014 "),$q=n(s6e,"A",{href:!0});var qZr=s($q);x7o=r(qZr,"T5Model"),qZr.forEach(t),$7o=r(s6e," (T5 model)"),s6e.forEach(t),k7o=i($),T_=n($,"LI",{});var l6e=s(T_);lle=n(l6e,"STRONG",{});var NZr=s(lle);S7o=r(NZr,"tapas"),NZr.forEach(t),R7o=r(l6e," \u2014 "),kq=n(l6e,"A",{href:!0});var jZr=s(kq);P7o=r(jZr,"TapasModel"),jZr.forEach(t),B7o=r(l6e," (TAPAS model)"),l6e.forEach(t),I7o=i($),M_=n($,"LI",{});var i6e=s(M_);ile=n(i6e,"STRONG",{});var DZr=s(ile);q7o=r(DZr,"trajectory_transformer"),DZr.forEach(t),N7o=r(i6e," \u2014 "),Sq=n(i6e,"A",{href:!0});var GZr=s(Sq);j7o=r(GZr,"TrajectoryTransformerModel"),GZr.forEach(t),D7o=r(i6e," (Trajectory Transformer model)"),i6e.forEach(t),G7o=i($),E_=n($,"LI",{});var d6e=s(E_);dle=n(d6e,"STRONG",{});var OZr=s(dle);O7o=r(OZr,"transfo-xl"),OZr.forEach(t),V7o=r(d6e," \u2014 "),Rq=n(d6e,"A",{href:!0});var VZr=s(Rq);X7o=r(VZr,"TransfoXLModel"),VZr.forEach(t),z7o=r(d6e," (Transformer-XL model)"),d6e.forEach(t),W7o=i($),C_=n($,"LI",{});var c6e=s(C_);cle=n(c6e,"STRONG",{});var XZr=s(cle);Q7o=r(XZr,"unispeech"),XZr.forEach(t),H7o=r(c6e," \u2014 "),Pq=n(c6e,"A",{href:!0});var zZr=s(Pq);U7o=r(zZr,"UniSpeechModel"),zZr.forEach(t),J7o=r(c6e," (UniSpeech model)"),c6e.forEach(t),Y7o=i($),w_=n($,"LI",{});var f6e=s(w_);fle=n(f6e,"STRONG",{});var WZr=s(fle);K7o=r(WZr,"unispeech-sat"),WZr.forEach(t),Z7o=r(f6e," \u2014 "),Bq=n(f6e,"A",{href:!0});var QZr=s(Bq);ebo=r(QZr,"UniSpeechSatModel"),QZr.forEach(t),obo=r(f6e," (UniSpeechSat model)"),f6e.forEach(t),rbo=i($),A_=n($,"LI",{});var m6e=s(A_);mle=n(m6e,"STRONG",{});var HZr=s(mle);tbo=r(HZr,"van"),HZr.forEach(t),abo=r(m6e," \u2014 "),Iq=n(m6e,"A",{href:!0});var UZr=s(Iq);nbo=r(UZr,"VanModel"),UZr.forEach(t),sbo=r(m6e," (VAN model)"),m6e.forEach(t),lbo=i($),y_=n($,"LI",{});var g6e=s(y_);gle=n(g6e,"STRONG",{});var JZr=s(gle);ibo=r(JZr,"vilt"),JZr.forEach(t),dbo=r(g6e," \u2014 "),qq=n(g6e,"A",{href:!0});var YZr=s(qq);cbo=r(YZr,"ViltModel"),YZr.forEach(t),fbo=r(g6e," (ViLT model)"),g6e.forEach(t),mbo=i($),L_=n($,"LI",{});var h6e=s(L_);hle=n(h6e,"STRONG",{});var KZr=s(hle);gbo=r(KZr,"vision-text-dual-encoder"),KZr.forEach(t),hbo=r(h6e," \u2014 "),Nq=n(h6e,"A",{href:!0});var ZZr=s(Nq);pbo=r(ZZr,"VisionTextDualEncoderModel"),ZZr.forEach(t),_bo=r(h6e," (VisionTextDualEncoder model)"),h6e.forEach(t),ubo=i($),x_=n($,"LI",{});var p6e=s(x_);ple=n(p6e,"STRONG",{});var eet=s(ple);bbo=r(eet,"visual_bert"),eet.forEach(t),vbo=r(p6e," \u2014 "),jq=n(p6e,"A",{href:!0});var oet=s(jq);Fbo=r(oet,"VisualBertModel"),oet.forEach(t),Tbo=r(p6e," (VisualBert model)"),p6e.forEach(t),Mbo=i($),$_=n($,"LI",{});var _6e=s($_);_le=n(_6e,"STRONG",{});var ret=s(_le);Ebo=r(ret,"vit"),ret.forEach(t),Cbo=r(_6e," \u2014 "),Dq=n(_6e,"A",{href:!0});var tet=s(Dq);wbo=r(tet,"ViTModel"),tet.forEach(t),Abo=r(_6e," (ViT model)"),_6e.forEach(t),ybo=i($),k_=n($,"LI",{});var u6e=s(k_);ule=n(u6e,"STRONG",{});var aet=s(ule);Lbo=r(aet,"vit_mae"),aet.forEach(t),xbo=r(u6e," \u2014 "),Gq=n(u6e,"A",{href:!0});var net=s(Gq);$bo=r(net,"ViTMAEModel"),net.forEach(t),kbo=r(u6e," (ViTMAE model)"),u6e.forEach(t),Sbo=i($),S_=n($,"LI",{});var b6e=s(S_);ble=n(b6e,"STRONG",{});var set=s(ble);Rbo=r(set,"wav2vec2"),set.forEach(t),Pbo=r(b6e," \u2014 "),Oq=n(b6e,"A",{href:!0});var iet=s(Oq);Bbo=r(iet,"Wav2Vec2Model"),iet.forEach(t),Ibo=r(b6e," (Wav2Vec2 model)"),b6e.forEach(t),qbo=i($),R_=n($,"LI",{});var v6e=s(R_);vle=n(v6e,"STRONG",{});var det=s(vle);Nbo=r(det,"wav2vec2-conformer"),det.forEach(t),jbo=r(v6e," \u2014 "),Vq=n(v6e,"A",{href:!0});var cet=s(Vq);Dbo=r(cet,"Wav2Vec2ConformerModel"),cet.forEach(t),Gbo=r(v6e," (Wav2Vec2-Conformer model)"),v6e.forEach(t),Obo=i($),P_=n($,"LI",{});var F6e=s(P_);Fle=n(F6e,"STRONG",{});var fet=s(Fle);Vbo=r(fet,"wavlm"),fet.forEach(t),Xbo=r(F6e," \u2014 "),Xq=n(F6e,"A",{href:!0});var met=s(Xq);zbo=r(met,"WavLMModel"),met.forEach(t),Wbo=r(F6e," (WavLM model)"),F6e.forEach(t),Qbo=i($),B_=n($,"LI",{});var T6e=s(B_);Tle=n(T6e,"STRONG",{});var get=s(Tle);Hbo=r(get,"xglm"),get.forEach(t),Ubo=r(T6e," \u2014 "),zq=n(T6e,"A",{href:!0});var het=s(zq);Jbo=r(het,"XGLMModel"),het.forEach(t),Ybo=r(T6e," (XGLM model)"),T6e.forEach(t),Kbo=i($),I_=n($,"LI",{});var M6e=s(I_);Mle=n(M6e,"STRONG",{});var pet=s(Mle);Zbo=r(pet,"xlm"),pet.forEach(t),evo=r(M6e," \u2014 "),Wq=n(M6e,"A",{href:!0});var _et=s(Wq);ovo=r(_et,"XLMModel"),_et.forEach(t),rvo=r(M6e," (XLM model)"),M6e.forEach(t),tvo=i($),q_=n($,"LI",{});var E6e=s(q_);Ele=n(E6e,"STRONG",{});var uet=s(Ele);avo=r(uet,"xlm-prophetnet"),uet.forEach(t),nvo=r(E6e," \u2014 "),Qq=n(E6e,"A",{href:!0});var bet=s(Qq);svo=r(bet,"XLMProphetNetModel"),bet.forEach(t),lvo=r(E6e," (XLMProphetNet model)"),E6e.forEach(t),ivo=i($),N_=n($,"LI",{});var C6e=s(N_);Cle=n(C6e,"STRONG",{});var vet=s(Cle);dvo=r(vet,"xlm-roberta"),vet.forEach(t),cvo=r(C6e," \u2014 "),Hq=n(C6e,"A",{href:!0});var Fet=s(Hq);fvo=r(Fet,"XLMRobertaModel"),Fet.forEach(t),mvo=r(C6e," (XLM-RoBERTa model)"),C6e.forEach(t),gvo=i($),j_=n($,"LI",{});var w6e=s(j_);wle=n(w6e,"STRONG",{});var Tet=s(wle);hvo=r(Tet,"xlm-roberta-xl"),Tet.forEach(t),pvo=r(w6e," \u2014 "),Uq=n(w6e,"A",{href:!0});var Met=s(Uq);_vo=r(Met,"XLMRobertaXLModel"),Met.forEach(t),uvo=r(w6e," (XLM-RoBERTa-XL model)"),w6e.forEach(t),bvo=i($),D_=n($,"LI",{});var A6e=s(D_);Ale=n(A6e,"STRONG",{});var Eet=s(Ale);vvo=r(Eet,"xlnet"),Eet.forEach(t),Fvo=r(A6e," \u2014 "),Jq=n(A6e,"A",{href:!0});var Cet=s(Jq);Tvo=r(Cet,"XLNetModel"),Cet.forEach(t),Mvo=r(A6e," (XLNet model)"),A6e.forEach(t),Evo=i($),G_=n($,"LI",{});var y6e=s(G_);yle=n(y6e,"STRONG",{});var wet=s(yle);Cvo=r(wet,"yolos"),wet.forEach(t),wvo=r(y6e," \u2014 "),Yq=n(y6e,"A",{href:!0});var Aet=s(Yq);Avo=r(Aet,"YolosModel"),Aet.forEach(t),yvo=r(y6e," (YOLOS model)"),y6e.forEach(t),Lvo=i($),O_=n($,"LI",{});var L6e=s(O_);Lle=n(L6e,"STRONG",{});var yet=s(Lle);xvo=r(yet,"yoso"),yet.forEach(t),$vo=r(L6e," \u2014 "),Kq=n(L6e,"A",{href:!0});var Let=s(Kq);kvo=r(Let,"YosoModel"),Let.forEach(t),Svo=r(L6e," (YOSO model)"),L6e.forEach(t),$.forEach(t),Rvo=i(oa),V_=n(oa,"P",{});var x6e=s(V_);Pvo=r(x6e,"The model is set in evaluation mode by default using "),xle=n(x6e,"CODE",{});var xet=s(xle);Bvo=r(xet,"model.eval()"),xet.forEach(t),Ivo=r(x6e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$le=n(x6e,"CODE",{});var $et=s($le);qvo=r($et,"model.train()"),$et.forEach(t),x6e.forEach(t),Nvo=i(oa),T(X_.$$.fragment,oa),oa.forEach(t),Ds.forEach(t),cqe=i(f),yi=n(f,"H2",{class:!0});var hje=s(yi);z_=n(hje,"A",{id:!0,class:!0,href:!0});var ket=s(z_);kle=n(ket,"SPAN",{});var Set=s(kle);T(X6.$$.fragment,Set),Set.forEach(t),ket.forEach(t),jvo=i(hje),Sle=n(hje,"SPAN",{});var Ret=s(Sle);Dvo=r(Ret,"AutoModelForPreTraining"),Ret.forEach(t),hje.forEach(t),fqe=i(f),xo=n(f,"DIV",{class:!0});var Gs=s(xo);T(z6.$$.fragment,Gs),Gvo=i(Gs),Li=n(Gs,"P",{});var GK=s(Li);Ovo=r(GK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Zq=n(GK,"A",{href:!0});var Pet=s(Zq);Vvo=r(Pet,"from_pretrained()"),Pet.forEach(t),Xvo=r(GK," class method or the "),eN=n(GK,"A",{href:!0});var Bet=s(eN);zvo=r(Bet,"from_config()"),Bet.forEach(t),Wvo=r(GK,` class
method.`),GK.forEach(t),Qvo=i(Gs),W6=n(Gs,"P",{});var pje=s(W6);Hvo=r(pje,"This class cannot be instantiated directly using "),Rle=n(pje,"CODE",{});var Iet=s(Rle);Uvo=r(Iet,"__init__()"),Iet.forEach(t),Jvo=r(pje," (throws an error)."),pje.forEach(t),Yvo=i(Gs),at=n(Gs,"DIV",{class:!0});var v0=s(at);T(Q6.$$.fragment,v0),Kvo=i(v0),Ple=n(v0,"P",{});var qet=s(Ple);Zvo=r(qet,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),qet.forEach(t),eFo=i(v0),xi=n(v0,"P",{});var OK=s(xi);oFo=r(OK,`Note:
Loading a model from its configuration file does `),Ble=n(OK,"STRONG",{});var Net=s(Ble);rFo=r(Net,"not"),Net.forEach(t),tFo=r(OK,` load the model weights. It only affects the
model\u2019s configuration. Use `),oN=n(OK,"A",{href:!0});var jet=s(oN);aFo=r(jet,"from_pretrained()"),jet.forEach(t),nFo=r(OK," to load the model weights."),OK.forEach(t),sFo=i(v0),T(W_.$$.fragment,v0),v0.forEach(t),lFo=i(Gs),Ye=n(Gs,"DIV",{class:!0});var ra=s(Ye);T(H6.$$.fragment,ra),iFo=i(ra),Ile=n(ra,"P",{});var Det=s(Ile);dFo=r(Det,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Det.forEach(t),cFo=i(ra),xa=n(ra,"P",{});var F0=s(xa);fFo=r(F0,"The model class to instantiate is selected based on the "),qle=n(F0,"CODE",{});var Get=s(qle);mFo=r(Get,"model_type"),Get.forEach(t),gFo=r(F0,` property of the config object (either
passed as an argument or loaded from `),Nle=n(F0,"CODE",{});var Oet=s(Nle);hFo=r(Oet,"pretrained_model_name_or_path"),Oet.forEach(t),pFo=r(F0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jle=n(F0,"CODE",{});var Vet=s(jle);_Fo=r(Vet,"pretrained_model_name_or_path"),Vet.forEach(t),uFo=r(F0,":"),F0.forEach(t),bFo=i(ra),G=n(ra,"UL",{});var O=s(G);Q_=n(O,"LI",{});var $6e=s(Q_);Dle=n($6e,"STRONG",{});var Xet=s(Dle);vFo=r(Xet,"albert"),Xet.forEach(t),FFo=r($6e," \u2014 "),rN=n($6e,"A",{href:!0});var zet=s(rN);TFo=r(zet,"AlbertForPreTraining"),zet.forEach(t),MFo=r($6e," (ALBERT model)"),$6e.forEach(t),EFo=i(O),H_=n(O,"LI",{});var k6e=s(H_);Gle=n(k6e,"STRONG",{});var Wet=s(Gle);CFo=r(Wet,"bart"),Wet.forEach(t),wFo=r(k6e," \u2014 "),tN=n(k6e,"A",{href:!0});var Qet=s(tN);AFo=r(Qet,"BartForConditionalGeneration"),Qet.forEach(t),yFo=r(k6e," (BART model)"),k6e.forEach(t),LFo=i(O),U_=n(O,"LI",{});var S6e=s(U_);Ole=n(S6e,"STRONG",{});var Het=s(Ole);xFo=r(Het,"bert"),Het.forEach(t),$Fo=r(S6e," \u2014 "),aN=n(S6e,"A",{href:!0});var Uet=s(aN);kFo=r(Uet,"BertForPreTraining"),Uet.forEach(t),SFo=r(S6e," (BERT model)"),S6e.forEach(t),RFo=i(O),J_=n(O,"LI",{});var R6e=s(J_);Vle=n(R6e,"STRONG",{});var Jet=s(Vle);PFo=r(Jet,"big_bird"),Jet.forEach(t),BFo=r(R6e," \u2014 "),nN=n(R6e,"A",{href:!0});var Yet=s(nN);IFo=r(Yet,"BigBirdForPreTraining"),Yet.forEach(t),qFo=r(R6e," (BigBird model)"),R6e.forEach(t),NFo=i(O),Y_=n(O,"LI",{});var P6e=s(Y_);Xle=n(P6e,"STRONG",{});var Ket=s(Xle);jFo=r(Ket,"camembert"),Ket.forEach(t),DFo=r(P6e," \u2014 "),sN=n(P6e,"A",{href:!0});var Zet=s(sN);GFo=r(Zet,"CamembertForMaskedLM"),Zet.forEach(t),OFo=r(P6e," (CamemBERT model)"),P6e.forEach(t),VFo=i(O),K_=n(O,"LI",{});var B6e=s(K_);zle=n(B6e,"STRONG",{});var eot=s(zle);XFo=r(eot,"ctrl"),eot.forEach(t),zFo=r(B6e," \u2014 "),lN=n(B6e,"A",{href:!0});var oot=s(lN);WFo=r(oot,"CTRLLMHeadModel"),oot.forEach(t),QFo=r(B6e," (CTRL model)"),B6e.forEach(t),HFo=i(O),Z_=n(O,"LI",{});var I6e=s(Z_);Wle=n(I6e,"STRONG",{});var rot=s(Wle);UFo=r(rot,"data2vec-text"),rot.forEach(t),JFo=r(I6e," \u2014 "),iN=n(I6e,"A",{href:!0});var tot=s(iN);YFo=r(tot,"Data2VecTextForMaskedLM"),tot.forEach(t),KFo=r(I6e," (Data2VecText model)"),I6e.forEach(t),ZFo=i(O),eu=n(O,"LI",{});var q6e=s(eu);Qle=n(q6e,"STRONG",{});var aot=s(Qle);eTo=r(aot,"deberta"),aot.forEach(t),oTo=r(q6e," \u2014 "),dN=n(q6e,"A",{href:!0});var not=s(dN);rTo=r(not,"DebertaForMaskedLM"),not.forEach(t),tTo=r(q6e," (DeBERTa model)"),q6e.forEach(t),aTo=i(O),ou=n(O,"LI",{});var N6e=s(ou);Hle=n(N6e,"STRONG",{});var sot=s(Hle);nTo=r(sot,"deberta-v2"),sot.forEach(t),sTo=r(N6e," \u2014 "),cN=n(N6e,"A",{href:!0});var lot=s(cN);lTo=r(lot,"DebertaV2ForMaskedLM"),lot.forEach(t),iTo=r(N6e," (DeBERTa-v2 model)"),N6e.forEach(t),dTo=i(O),ru=n(O,"LI",{});var j6e=s(ru);Ule=n(j6e,"STRONG",{});var iot=s(Ule);cTo=r(iot,"distilbert"),iot.forEach(t),fTo=r(j6e," \u2014 "),fN=n(j6e,"A",{href:!0});var dot=s(fN);mTo=r(dot,"DistilBertForMaskedLM"),dot.forEach(t),gTo=r(j6e," (DistilBERT model)"),j6e.forEach(t),hTo=i(O),tu=n(O,"LI",{});var D6e=s(tu);Jle=n(D6e,"STRONG",{});var cot=s(Jle);pTo=r(cot,"electra"),cot.forEach(t),_To=r(D6e," \u2014 "),mN=n(D6e,"A",{href:!0});var fot=s(mN);uTo=r(fot,"ElectraForPreTraining"),fot.forEach(t),bTo=r(D6e," (ELECTRA model)"),D6e.forEach(t),vTo=i(O),au=n(O,"LI",{});var G6e=s(au);Yle=n(G6e,"STRONG",{});var mot=s(Yle);FTo=r(mot,"flaubert"),mot.forEach(t),TTo=r(G6e," \u2014 "),gN=n(G6e,"A",{href:!0});var got=s(gN);MTo=r(got,"FlaubertWithLMHeadModel"),got.forEach(t),ETo=r(G6e," (FlauBERT model)"),G6e.forEach(t),CTo=i(O),nu=n(O,"LI",{});var O6e=s(nu);Kle=n(O6e,"STRONG",{});var hot=s(Kle);wTo=r(hot,"flava"),hot.forEach(t),ATo=r(O6e," \u2014 "),hN=n(O6e,"A",{href:!0});var pot=s(hN);yTo=r(pot,"FlavaForPreTraining"),pot.forEach(t),LTo=r(O6e," (Flava model)"),O6e.forEach(t),xTo=i(O),su=n(O,"LI",{});var V6e=s(su);Zle=n(V6e,"STRONG",{});var _ot=s(Zle);$To=r(_ot,"fnet"),_ot.forEach(t),kTo=r(V6e," \u2014 "),pN=n(V6e,"A",{href:!0});var uot=s(pN);STo=r(uot,"FNetForPreTraining"),uot.forEach(t),RTo=r(V6e," (FNet model)"),V6e.forEach(t),PTo=i(O),lu=n(O,"LI",{});var X6e=s(lu);eie=n(X6e,"STRONG",{});var bot=s(eie);BTo=r(bot,"fsmt"),bot.forEach(t),ITo=r(X6e," \u2014 "),_N=n(X6e,"A",{href:!0});var vot=s(_N);qTo=r(vot,"FSMTForConditionalGeneration"),vot.forEach(t),NTo=r(X6e," (FairSeq Machine-Translation model)"),X6e.forEach(t),jTo=i(O),iu=n(O,"LI",{});var z6e=s(iu);oie=n(z6e,"STRONG",{});var Fot=s(oie);DTo=r(Fot,"funnel"),Fot.forEach(t),GTo=r(z6e," \u2014 "),uN=n(z6e,"A",{href:!0});var Tot=s(uN);OTo=r(Tot,"FunnelForPreTraining"),Tot.forEach(t),VTo=r(z6e," (Funnel Transformer model)"),z6e.forEach(t),XTo=i(O),du=n(O,"LI",{});var W6e=s(du);rie=n(W6e,"STRONG",{});var Mot=s(rie);zTo=r(Mot,"gpt2"),Mot.forEach(t),WTo=r(W6e," \u2014 "),bN=n(W6e,"A",{href:!0});var Eot=s(bN);QTo=r(Eot,"GPT2LMHeadModel"),Eot.forEach(t),HTo=r(W6e," (OpenAI GPT-2 model)"),W6e.forEach(t),UTo=i(O),cu=n(O,"LI",{});var Q6e=s(cu);tie=n(Q6e,"STRONG",{});var Cot=s(tie);JTo=r(Cot,"ibert"),Cot.forEach(t),YTo=r(Q6e," \u2014 "),vN=n(Q6e,"A",{href:!0});var wot=s(vN);KTo=r(wot,"IBertForMaskedLM"),wot.forEach(t),ZTo=r(Q6e," (I-BERT model)"),Q6e.forEach(t),eMo=i(O),fu=n(O,"LI",{});var H6e=s(fu);aie=n(H6e,"STRONG",{});var Aot=s(aie);oMo=r(Aot,"layoutlm"),Aot.forEach(t),rMo=r(H6e," \u2014 "),FN=n(H6e,"A",{href:!0});var yot=s(FN);tMo=r(yot,"LayoutLMForMaskedLM"),yot.forEach(t),aMo=r(H6e," (LayoutLM model)"),H6e.forEach(t),nMo=i(O),mu=n(O,"LI",{});var U6e=s(mu);nie=n(U6e,"STRONG",{});var Lot=s(nie);sMo=r(Lot,"longformer"),Lot.forEach(t),lMo=r(U6e," \u2014 "),TN=n(U6e,"A",{href:!0});var xot=s(TN);iMo=r(xot,"LongformerForMaskedLM"),xot.forEach(t),dMo=r(U6e," (Longformer model)"),U6e.forEach(t),cMo=i(O),gu=n(O,"LI",{});var J6e=s(gu);sie=n(J6e,"STRONG",{});var $ot=s(sie);fMo=r($ot,"lxmert"),$ot.forEach(t),mMo=r(J6e," \u2014 "),MN=n(J6e,"A",{href:!0});var kot=s(MN);gMo=r(kot,"LxmertForPreTraining"),kot.forEach(t),hMo=r(J6e," (LXMERT model)"),J6e.forEach(t),pMo=i(O),hu=n(O,"LI",{});var Y6e=s(hu);lie=n(Y6e,"STRONG",{});var Sot=s(lie);_Mo=r(Sot,"megatron-bert"),Sot.forEach(t),uMo=r(Y6e," \u2014 "),EN=n(Y6e,"A",{href:!0});var Rot=s(EN);bMo=r(Rot,"MegatronBertForPreTraining"),Rot.forEach(t),vMo=r(Y6e," (MegatronBert model)"),Y6e.forEach(t),FMo=i(O),pu=n(O,"LI",{});var K6e=s(pu);iie=n(K6e,"STRONG",{});var Pot=s(iie);TMo=r(Pot,"mobilebert"),Pot.forEach(t),MMo=r(K6e," \u2014 "),CN=n(K6e,"A",{href:!0});var Bot=s(CN);EMo=r(Bot,"MobileBertForPreTraining"),Bot.forEach(t),CMo=r(K6e," (MobileBERT model)"),K6e.forEach(t),wMo=i(O),_u=n(O,"LI",{});var Z6e=s(_u);die=n(Z6e,"STRONG",{});var Iot=s(die);AMo=r(Iot,"mpnet"),Iot.forEach(t),yMo=r(Z6e," \u2014 "),wN=n(Z6e,"A",{href:!0});var qot=s(wN);LMo=r(qot,"MPNetForMaskedLM"),qot.forEach(t),xMo=r(Z6e," (MPNet model)"),Z6e.forEach(t),$Mo=i(O),uu=n(O,"LI",{});var eye=s(uu);cie=n(eye,"STRONG",{});var Not=s(cie);kMo=r(Not,"openai-gpt"),Not.forEach(t),SMo=r(eye," \u2014 "),AN=n(eye,"A",{href:!0});var jot=s(AN);RMo=r(jot,"OpenAIGPTLMHeadModel"),jot.forEach(t),PMo=r(eye," (OpenAI GPT model)"),eye.forEach(t),BMo=i(O),bu=n(O,"LI",{});var oye=s(bu);fie=n(oye,"STRONG",{});var Dot=s(fie);IMo=r(Dot,"retribert"),Dot.forEach(t),qMo=r(oye," \u2014 "),yN=n(oye,"A",{href:!0});var Got=s(yN);NMo=r(Got,"RetriBertModel"),Got.forEach(t),jMo=r(oye," (RetriBERT model)"),oye.forEach(t),DMo=i(O),vu=n(O,"LI",{});var rye=s(vu);mie=n(rye,"STRONG",{});var Oot=s(mie);GMo=r(Oot,"roberta"),Oot.forEach(t),OMo=r(rye," \u2014 "),LN=n(rye,"A",{href:!0});var Vot=s(LN);VMo=r(Vot,"RobertaForMaskedLM"),Vot.forEach(t),XMo=r(rye," (RoBERTa model)"),rye.forEach(t),zMo=i(O),Fu=n(O,"LI",{});var tye=s(Fu);gie=n(tye,"STRONG",{});var Xot=s(gie);WMo=r(Xot,"splinter"),Xot.forEach(t),QMo=r(tye," \u2014 "),xN=n(tye,"A",{href:!0});var zot=s(xN);HMo=r(zot,"SplinterForPreTraining"),zot.forEach(t),UMo=r(tye," (Splinter model)"),tye.forEach(t),JMo=i(O),Tu=n(O,"LI",{});var aye=s(Tu);hie=n(aye,"STRONG",{});var Wot=s(hie);YMo=r(Wot,"squeezebert"),Wot.forEach(t),KMo=r(aye," \u2014 "),$N=n(aye,"A",{href:!0});var Qot=s($N);ZMo=r(Qot,"SqueezeBertForMaskedLM"),Qot.forEach(t),e4o=r(aye," (SqueezeBERT model)"),aye.forEach(t),o4o=i(O),Mu=n(O,"LI",{});var nye=s(Mu);pie=n(nye,"STRONG",{});var Hot=s(pie);r4o=r(Hot,"t5"),Hot.forEach(t),t4o=r(nye," \u2014 "),kN=n(nye,"A",{href:!0});var Uot=s(kN);a4o=r(Uot,"T5ForConditionalGeneration"),Uot.forEach(t),n4o=r(nye," (T5 model)"),nye.forEach(t),s4o=i(O),Eu=n(O,"LI",{});var sye=s(Eu);_ie=n(sye,"STRONG",{});var Jot=s(_ie);l4o=r(Jot,"tapas"),Jot.forEach(t),i4o=r(sye," \u2014 "),SN=n(sye,"A",{href:!0});var Yot=s(SN);d4o=r(Yot,"TapasForMaskedLM"),Yot.forEach(t),c4o=r(sye," (TAPAS model)"),sye.forEach(t),f4o=i(O),Cu=n(O,"LI",{});var lye=s(Cu);uie=n(lye,"STRONG",{});var Kot=s(uie);m4o=r(Kot,"transfo-xl"),Kot.forEach(t),g4o=r(lye," \u2014 "),RN=n(lye,"A",{href:!0});var Zot=s(RN);h4o=r(Zot,"TransfoXLLMHeadModel"),Zot.forEach(t),p4o=r(lye," (Transformer-XL model)"),lye.forEach(t),_4o=i(O),wu=n(O,"LI",{});var iye=s(wu);bie=n(iye,"STRONG",{});var ert=s(bie);u4o=r(ert,"unispeech"),ert.forEach(t),b4o=r(iye," \u2014 "),PN=n(iye,"A",{href:!0});var ort=s(PN);v4o=r(ort,"UniSpeechForPreTraining"),ort.forEach(t),F4o=r(iye," (UniSpeech model)"),iye.forEach(t),T4o=i(O),Au=n(O,"LI",{});var dye=s(Au);vie=n(dye,"STRONG",{});var rrt=s(vie);M4o=r(rrt,"unispeech-sat"),rrt.forEach(t),E4o=r(dye," \u2014 "),BN=n(dye,"A",{href:!0});var trt=s(BN);C4o=r(trt,"UniSpeechSatForPreTraining"),trt.forEach(t),w4o=r(dye," (UniSpeechSat model)"),dye.forEach(t),A4o=i(O),yu=n(O,"LI",{});var cye=s(yu);Fie=n(cye,"STRONG",{});var art=s(Fie);y4o=r(art,"visual_bert"),art.forEach(t),L4o=r(cye," \u2014 "),IN=n(cye,"A",{href:!0});var nrt=s(IN);x4o=r(nrt,"VisualBertForPreTraining"),nrt.forEach(t),$4o=r(cye," (VisualBert model)"),cye.forEach(t),k4o=i(O),Lu=n(O,"LI",{});var fye=s(Lu);Tie=n(fye,"STRONG",{});var srt=s(Tie);S4o=r(srt,"vit_mae"),srt.forEach(t),R4o=r(fye," \u2014 "),qN=n(fye,"A",{href:!0});var lrt=s(qN);P4o=r(lrt,"ViTMAEForPreTraining"),lrt.forEach(t),B4o=r(fye," (ViTMAE model)"),fye.forEach(t),I4o=i(O),xu=n(O,"LI",{});var mye=s(xu);Mie=n(mye,"STRONG",{});var irt=s(Mie);q4o=r(irt,"wav2vec2"),irt.forEach(t),N4o=r(mye," \u2014 "),NN=n(mye,"A",{href:!0});var drt=s(NN);j4o=r(drt,"Wav2Vec2ForPreTraining"),drt.forEach(t),D4o=r(mye," (Wav2Vec2 model)"),mye.forEach(t),G4o=i(O),$u=n(O,"LI",{});var gye=s($u);Eie=n(gye,"STRONG",{});var crt=s(Eie);O4o=r(crt,"wav2vec2-conformer"),crt.forEach(t),V4o=r(gye," \u2014 "),jN=n(gye,"A",{href:!0});var frt=s(jN);X4o=r(frt,"Wav2Vec2ConformerForPreTraining"),frt.forEach(t),z4o=r(gye," (Wav2Vec2-Conformer model)"),gye.forEach(t),W4o=i(O),ku=n(O,"LI",{});var hye=s(ku);Cie=n(hye,"STRONG",{});var mrt=s(Cie);Q4o=r(mrt,"xlm"),mrt.forEach(t),H4o=r(hye," \u2014 "),DN=n(hye,"A",{href:!0});var grt=s(DN);U4o=r(grt,"XLMWithLMHeadModel"),grt.forEach(t),J4o=r(hye," (XLM model)"),hye.forEach(t),Y4o=i(O),Su=n(O,"LI",{});var pye=s(Su);wie=n(pye,"STRONG",{});var hrt=s(wie);K4o=r(hrt,"xlm-roberta"),hrt.forEach(t),Z4o=r(pye," \u2014 "),GN=n(pye,"A",{href:!0});var prt=s(GN);eEo=r(prt,"XLMRobertaForMaskedLM"),prt.forEach(t),oEo=r(pye," (XLM-RoBERTa model)"),pye.forEach(t),rEo=i(O),Ru=n(O,"LI",{});var _ye=s(Ru);Aie=n(_ye,"STRONG",{});var _rt=s(Aie);tEo=r(_rt,"xlm-roberta-xl"),_rt.forEach(t),aEo=r(_ye," \u2014 "),ON=n(_ye,"A",{href:!0});var urt=s(ON);nEo=r(urt,"XLMRobertaXLForMaskedLM"),urt.forEach(t),sEo=r(_ye," (XLM-RoBERTa-XL model)"),_ye.forEach(t),lEo=i(O),Pu=n(O,"LI",{});var uye=s(Pu);yie=n(uye,"STRONG",{});var brt=s(yie);iEo=r(brt,"xlnet"),brt.forEach(t),dEo=r(uye," \u2014 "),VN=n(uye,"A",{href:!0});var vrt=s(VN);cEo=r(vrt,"XLNetLMHeadModel"),vrt.forEach(t),fEo=r(uye," (XLNet model)"),uye.forEach(t),O.forEach(t),mEo=i(ra),Bu=n(ra,"P",{});var bye=s(Bu);gEo=r(bye,"The model is set in evaluation mode by default using "),Lie=n(bye,"CODE",{});var Frt=s(Lie);hEo=r(Frt,"model.eval()"),Frt.forEach(t),pEo=r(bye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xie=n(bye,"CODE",{});var Trt=s(xie);_Eo=r(Trt,"model.train()"),Trt.forEach(t),bye.forEach(t),uEo=i(ra),T(Iu.$$.fragment,ra),ra.forEach(t),Gs.forEach(t),mqe=i(f),$i=n(f,"H2",{class:!0});var _je=s($i);qu=n(_je,"A",{id:!0,class:!0,href:!0});var Mrt=s(qu);$ie=n(Mrt,"SPAN",{});var Ert=s($ie);T(U6.$$.fragment,Ert),Ert.forEach(t),Mrt.forEach(t),bEo=i(_je),kie=n(_je,"SPAN",{});var Crt=s(kie);vEo=r(Crt,"AutoModelForCausalLM"),Crt.forEach(t),_je.forEach(t),gqe=i(f),$o=n(f,"DIV",{class:!0});var Os=s($o);T(J6.$$.fragment,Os),FEo=i(Os),ki=n(Os,"P",{});var VK=s(ki);TEo=r(VK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),XN=n(VK,"A",{href:!0});var wrt=s(XN);MEo=r(wrt,"from_pretrained()"),wrt.forEach(t),EEo=r(VK," class method or the "),zN=n(VK,"A",{href:!0});var Art=s(zN);CEo=r(Art,"from_config()"),Art.forEach(t),wEo=r(VK,` class
method.`),VK.forEach(t),AEo=i(Os),Y6=n(Os,"P",{});var uje=s(Y6);yEo=r(uje,"This class cannot be instantiated directly using "),Sie=n(uje,"CODE",{});var yrt=s(Sie);LEo=r(yrt,"__init__()"),yrt.forEach(t),xEo=r(uje," (throws an error)."),uje.forEach(t),$Eo=i(Os),nt=n(Os,"DIV",{class:!0});var T0=s(nt);T(K6.$$.fragment,T0),kEo=i(T0),Rie=n(T0,"P",{});var Lrt=s(Rie);SEo=r(Lrt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Lrt.forEach(t),REo=i(T0),Si=n(T0,"P",{});var XK=s(Si);PEo=r(XK,`Note:
Loading a model from its configuration file does `),Pie=n(XK,"STRONG",{});var xrt=s(Pie);BEo=r(xrt,"not"),xrt.forEach(t),IEo=r(XK,` load the model weights. It only affects the
model\u2019s configuration. Use `),WN=n(XK,"A",{href:!0});var $rt=s(WN);qEo=r($rt,"from_pretrained()"),$rt.forEach(t),NEo=r(XK," to load the model weights."),XK.forEach(t),jEo=i(T0),T(Nu.$$.fragment,T0),T0.forEach(t),DEo=i(Os),Ke=n(Os,"DIV",{class:!0});var ta=s(Ke);T(Z6.$$.fragment,ta),GEo=i(ta),Bie=n(ta,"P",{});var krt=s(Bie);OEo=r(krt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),krt.forEach(t),VEo=i(ta),$a=n(ta,"P",{});var M0=s($a);XEo=r(M0,"The model class to instantiate is selected based on the "),Iie=n(M0,"CODE",{});var Srt=s(Iie);zEo=r(Srt,"model_type"),Srt.forEach(t),WEo=r(M0,` property of the config object (either
passed as an argument or loaded from `),qie=n(M0,"CODE",{});var Rrt=s(qie);QEo=r(Rrt,"pretrained_model_name_or_path"),Rrt.forEach(t),HEo=r(M0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nie=n(M0,"CODE",{});var Prt=s(Nie);UEo=r(Prt,"pretrained_model_name_or_path"),Prt.forEach(t),JEo=r(M0,":"),M0.forEach(t),YEo=i(ta),z=n(ta,"UL",{});var Q=s(z);ju=n(Q,"LI",{});var vye=s(ju);jie=n(vye,"STRONG",{});var Brt=s(jie);KEo=r(Brt,"bart"),Brt.forEach(t),ZEo=r(vye," \u2014 "),QN=n(vye,"A",{href:!0});var Irt=s(QN);eCo=r(Irt,"BartForCausalLM"),Irt.forEach(t),oCo=r(vye," (BART model)"),vye.forEach(t),rCo=i(Q),Du=n(Q,"LI",{});var Fye=s(Du);Die=n(Fye,"STRONG",{});var qrt=s(Die);tCo=r(qrt,"bert"),qrt.forEach(t),aCo=r(Fye," \u2014 "),HN=n(Fye,"A",{href:!0});var Nrt=s(HN);nCo=r(Nrt,"BertLMHeadModel"),Nrt.forEach(t),sCo=r(Fye," (BERT model)"),Fye.forEach(t),lCo=i(Q),Gu=n(Q,"LI",{});var Tye=s(Gu);Gie=n(Tye,"STRONG",{});var jrt=s(Gie);iCo=r(jrt,"bert-generation"),jrt.forEach(t),dCo=r(Tye," \u2014 "),UN=n(Tye,"A",{href:!0});var Drt=s(UN);cCo=r(Drt,"BertGenerationDecoder"),Drt.forEach(t),fCo=r(Tye," (Bert Generation model)"),Tye.forEach(t),mCo=i(Q),Ou=n(Q,"LI",{});var Mye=s(Ou);Oie=n(Mye,"STRONG",{});var Grt=s(Oie);gCo=r(Grt,"big_bird"),Grt.forEach(t),hCo=r(Mye," \u2014 "),JN=n(Mye,"A",{href:!0});var Ort=s(JN);pCo=r(Ort,"BigBirdForCausalLM"),Ort.forEach(t),_Co=r(Mye," (BigBird model)"),Mye.forEach(t),uCo=i(Q),Vu=n(Q,"LI",{});var Eye=s(Vu);Vie=n(Eye,"STRONG",{});var Vrt=s(Vie);bCo=r(Vrt,"bigbird_pegasus"),Vrt.forEach(t),vCo=r(Eye," \u2014 "),YN=n(Eye,"A",{href:!0});var Xrt=s(YN);FCo=r(Xrt,"BigBirdPegasusForCausalLM"),Xrt.forEach(t),TCo=r(Eye," (BigBirdPegasus model)"),Eye.forEach(t),MCo=i(Q),Xu=n(Q,"LI",{});var Cye=s(Xu);Xie=n(Cye,"STRONG",{});var zrt=s(Xie);ECo=r(zrt,"blenderbot"),zrt.forEach(t),CCo=r(Cye," \u2014 "),KN=n(Cye,"A",{href:!0});var Wrt=s(KN);wCo=r(Wrt,"BlenderbotForCausalLM"),Wrt.forEach(t),ACo=r(Cye," (Blenderbot model)"),Cye.forEach(t),yCo=i(Q),zu=n(Q,"LI",{});var wye=s(zu);zie=n(wye,"STRONG",{});var Qrt=s(zie);LCo=r(Qrt,"blenderbot-small"),Qrt.forEach(t),xCo=r(wye," \u2014 "),ZN=n(wye,"A",{href:!0});var Hrt=s(ZN);$Co=r(Hrt,"BlenderbotSmallForCausalLM"),Hrt.forEach(t),kCo=r(wye," (BlenderbotSmall model)"),wye.forEach(t),SCo=i(Q),Wu=n(Q,"LI",{});var Aye=s(Wu);Wie=n(Aye,"STRONG",{});var Urt=s(Wie);RCo=r(Urt,"camembert"),Urt.forEach(t),PCo=r(Aye," \u2014 "),ej=n(Aye,"A",{href:!0});var Jrt=s(ej);BCo=r(Jrt,"CamembertForCausalLM"),Jrt.forEach(t),ICo=r(Aye," (CamemBERT model)"),Aye.forEach(t),qCo=i(Q),Qu=n(Q,"LI",{});var yye=s(Qu);Qie=n(yye,"STRONG",{});var Yrt=s(Qie);NCo=r(Yrt,"ctrl"),Yrt.forEach(t),jCo=r(yye," \u2014 "),oj=n(yye,"A",{href:!0});var Krt=s(oj);DCo=r(Krt,"CTRLLMHeadModel"),Krt.forEach(t),GCo=r(yye," (CTRL model)"),yye.forEach(t),OCo=i(Q),Hu=n(Q,"LI",{});var Lye=s(Hu);Hie=n(Lye,"STRONG",{});var Zrt=s(Hie);VCo=r(Zrt,"data2vec-text"),Zrt.forEach(t),XCo=r(Lye," \u2014 "),rj=n(Lye,"A",{href:!0});var ett=s(rj);zCo=r(ett,"Data2VecTextForCausalLM"),ett.forEach(t),WCo=r(Lye," (Data2VecText model)"),Lye.forEach(t),QCo=i(Q),Uu=n(Q,"LI",{});var xye=s(Uu);Uie=n(xye,"STRONG",{});var ott=s(Uie);HCo=r(ott,"electra"),ott.forEach(t),UCo=r(xye," \u2014 "),tj=n(xye,"A",{href:!0});var rtt=s(tj);JCo=r(rtt,"ElectraForCausalLM"),rtt.forEach(t),YCo=r(xye," (ELECTRA model)"),xye.forEach(t),KCo=i(Q),Ju=n(Q,"LI",{});var $ye=s(Ju);Jie=n($ye,"STRONG",{});var ttt=s(Jie);ZCo=r(ttt,"gpt2"),ttt.forEach(t),e5o=r($ye," \u2014 "),aj=n($ye,"A",{href:!0});var att=s(aj);o5o=r(att,"GPT2LMHeadModel"),att.forEach(t),r5o=r($ye," (OpenAI GPT-2 model)"),$ye.forEach(t),t5o=i(Q),Yu=n(Q,"LI",{});var kye=s(Yu);Yie=n(kye,"STRONG",{});var ntt=s(Yie);a5o=r(ntt,"gpt_neo"),ntt.forEach(t),n5o=r(kye," \u2014 "),nj=n(kye,"A",{href:!0});var stt=s(nj);s5o=r(stt,"GPTNeoForCausalLM"),stt.forEach(t),l5o=r(kye," (GPT Neo model)"),kye.forEach(t),i5o=i(Q),Ku=n(Q,"LI",{});var Sye=s(Ku);Kie=n(Sye,"STRONG",{});var ltt=s(Kie);d5o=r(ltt,"gptj"),ltt.forEach(t),c5o=r(Sye," \u2014 "),sj=n(Sye,"A",{href:!0});var itt=s(sj);f5o=r(itt,"GPTJForCausalLM"),itt.forEach(t),m5o=r(Sye," (GPT-J model)"),Sye.forEach(t),g5o=i(Q),Zu=n(Q,"LI",{});var Rye=s(Zu);Zie=n(Rye,"STRONG",{});var dtt=s(Zie);h5o=r(dtt,"marian"),dtt.forEach(t),p5o=r(Rye," \u2014 "),lj=n(Rye,"A",{href:!0});var ctt=s(lj);_5o=r(ctt,"MarianForCausalLM"),ctt.forEach(t),u5o=r(Rye," (Marian model)"),Rye.forEach(t),b5o=i(Q),e2=n(Q,"LI",{});var Pye=s(e2);ede=n(Pye,"STRONG",{});var ftt=s(ede);v5o=r(ftt,"mbart"),ftt.forEach(t),F5o=r(Pye," \u2014 "),ij=n(Pye,"A",{href:!0});var mtt=s(ij);T5o=r(mtt,"MBartForCausalLM"),mtt.forEach(t),M5o=r(Pye," (mBART model)"),Pye.forEach(t),E5o=i(Q),o2=n(Q,"LI",{});var Bye=s(o2);ode=n(Bye,"STRONG",{});var gtt=s(ode);C5o=r(gtt,"megatron-bert"),gtt.forEach(t),w5o=r(Bye," \u2014 "),dj=n(Bye,"A",{href:!0});var htt=s(dj);A5o=r(htt,"MegatronBertForCausalLM"),htt.forEach(t),y5o=r(Bye," (MegatronBert model)"),Bye.forEach(t),L5o=i(Q),r2=n(Q,"LI",{});var Iye=s(r2);rde=n(Iye,"STRONG",{});var ptt=s(rde);x5o=r(ptt,"openai-gpt"),ptt.forEach(t),$5o=r(Iye," \u2014 "),cj=n(Iye,"A",{href:!0});var _tt=s(cj);k5o=r(_tt,"OpenAIGPTLMHeadModel"),_tt.forEach(t),S5o=r(Iye," (OpenAI GPT model)"),Iye.forEach(t),R5o=i(Q),t2=n(Q,"LI",{});var qye=s(t2);tde=n(qye,"STRONG",{});var utt=s(tde);P5o=r(utt,"opt"),utt.forEach(t),B5o=r(qye," \u2014 "),fj=n(qye,"A",{href:!0});var btt=s(fj);I5o=r(btt,"OPTForCausalLM"),btt.forEach(t),q5o=r(qye," (OPT model)"),qye.forEach(t),N5o=i(Q),a2=n(Q,"LI",{});var Nye=s(a2);ade=n(Nye,"STRONG",{});var vtt=s(ade);j5o=r(vtt,"pegasus"),vtt.forEach(t),D5o=r(Nye," \u2014 "),mj=n(Nye,"A",{href:!0});var Ftt=s(mj);G5o=r(Ftt,"PegasusForCausalLM"),Ftt.forEach(t),O5o=r(Nye," (Pegasus model)"),Nye.forEach(t),V5o=i(Q),n2=n(Q,"LI",{});var jye=s(n2);nde=n(jye,"STRONG",{});var Ttt=s(nde);X5o=r(Ttt,"plbart"),Ttt.forEach(t),z5o=r(jye," \u2014 "),gj=n(jye,"A",{href:!0});var Mtt=s(gj);W5o=r(Mtt,"PLBartForCausalLM"),Mtt.forEach(t),Q5o=r(jye," (PLBart model)"),jye.forEach(t),H5o=i(Q),s2=n(Q,"LI",{});var Dye=s(s2);sde=n(Dye,"STRONG",{});var Ett=s(sde);U5o=r(Ett,"prophetnet"),Ett.forEach(t),J5o=r(Dye," \u2014 "),hj=n(Dye,"A",{href:!0});var Ctt=s(hj);Y5o=r(Ctt,"ProphetNetForCausalLM"),Ctt.forEach(t),K5o=r(Dye," (ProphetNet model)"),Dye.forEach(t),Z5o=i(Q),l2=n(Q,"LI",{});var Gye=s(l2);lde=n(Gye,"STRONG",{});var wtt=s(lde);e3o=r(wtt,"qdqbert"),wtt.forEach(t),o3o=r(Gye," \u2014 "),pj=n(Gye,"A",{href:!0});var Att=s(pj);r3o=r(Att,"QDQBertLMHeadModel"),Att.forEach(t),t3o=r(Gye," (QDQBert model)"),Gye.forEach(t),a3o=i(Q),i2=n(Q,"LI",{});var Oye=s(i2);ide=n(Oye,"STRONG",{});var ytt=s(ide);n3o=r(ytt,"reformer"),ytt.forEach(t),s3o=r(Oye," \u2014 "),_j=n(Oye,"A",{href:!0});var Ltt=s(_j);l3o=r(Ltt,"ReformerModelWithLMHead"),Ltt.forEach(t),i3o=r(Oye," (Reformer model)"),Oye.forEach(t),d3o=i(Q),d2=n(Q,"LI",{});var Vye=s(d2);dde=n(Vye,"STRONG",{});var xtt=s(dde);c3o=r(xtt,"rembert"),xtt.forEach(t),f3o=r(Vye," \u2014 "),uj=n(Vye,"A",{href:!0});var $tt=s(uj);m3o=r($tt,"RemBertForCausalLM"),$tt.forEach(t),g3o=r(Vye," (RemBERT model)"),Vye.forEach(t),h3o=i(Q),c2=n(Q,"LI",{});var Xye=s(c2);cde=n(Xye,"STRONG",{});var ktt=s(cde);p3o=r(ktt,"roberta"),ktt.forEach(t),_3o=r(Xye," \u2014 "),bj=n(Xye,"A",{href:!0});var Stt=s(bj);u3o=r(Stt,"RobertaForCausalLM"),Stt.forEach(t),b3o=r(Xye," (RoBERTa model)"),Xye.forEach(t),v3o=i(Q),f2=n(Q,"LI",{});var zye=s(f2);fde=n(zye,"STRONG",{});var Rtt=s(fde);F3o=r(Rtt,"roformer"),Rtt.forEach(t),T3o=r(zye," \u2014 "),vj=n(zye,"A",{href:!0});var Ptt=s(vj);M3o=r(Ptt,"RoFormerForCausalLM"),Ptt.forEach(t),E3o=r(zye," (RoFormer model)"),zye.forEach(t),C3o=i(Q),m2=n(Q,"LI",{});var Wye=s(m2);mde=n(Wye,"STRONG",{});var Btt=s(mde);w3o=r(Btt,"speech_to_text_2"),Btt.forEach(t),A3o=r(Wye," \u2014 "),Fj=n(Wye,"A",{href:!0});var Itt=s(Fj);y3o=r(Itt,"Speech2Text2ForCausalLM"),Itt.forEach(t),L3o=r(Wye," (Speech2Text2 model)"),Wye.forEach(t),x3o=i(Q),g2=n(Q,"LI",{});var Qye=s(g2);gde=n(Qye,"STRONG",{});var qtt=s(gde);$3o=r(qtt,"transfo-xl"),qtt.forEach(t),k3o=r(Qye," \u2014 "),Tj=n(Qye,"A",{href:!0});var Ntt=s(Tj);S3o=r(Ntt,"TransfoXLLMHeadModel"),Ntt.forEach(t),R3o=r(Qye," (Transformer-XL model)"),Qye.forEach(t),P3o=i(Q),h2=n(Q,"LI",{});var Hye=s(h2);hde=n(Hye,"STRONG",{});var jtt=s(hde);B3o=r(jtt,"trocr"),jtt.forEach(t),I3o=r(Hye," \u2014 "),Mj=n(Hye,"A",{href:!0});var Dtt=s(Mj);q3o=r(Dtt,"TrOCRForCausalLM"),Dtt.forEach(t),N3o=r(Hye," (TrOCR model)"),Hye.forEach(t),j3o=i(Q),p2=n(Q,"LI",{});var Uye=s(p2);pde=n(Uye,"STRONG",{});var Gtt=s(pde);D3o=r(Gtt,"xglm"),Gtt.forEach(t),G3o=r(Uye," \u2014 "),Ej=n(Uye,"A",{href:!0});var Ott=s(Ej);O3o=r(Ott,"XGLMForCausalLM"),Ott.forEach(t),V3o=r(Uye," (XGLM model)"),Uye.forEach(t),X3o=i(Q),_2=n(Q,"LI",{});var Jye=s(_2);_de=n(Jye,"STRONG",{});var Vtt=s(_de);z3o=r(Vtt,"xlm"),Vtt.forEach(t),W3o=r(Jye," \u2014 "),Cj=n(Jye,"A",{href:!0});var Xtt=s(Cj);Q3o=r(Xtt,"XLMWithLMHeadModel"),Xtt.forEach(t),H3o=r(Jye," (XLM model)"),Jye.forEach(t),U3o=i(Q),u2=n(Q,"LI",{});var Yye=s(u2);ude=n(Yye,"STRONG",{});var ztt=s(ude);J3o=r(ztt,"xlm-prophetnet"),ztt.forEach(t),Y3o=r(Yye," \u2014 "),wj=n(Yye,"A",{href:!0});var Wtt=s(wj);K3o=r(Wtt,"XLMProphetNetForCausalLM"),Wtt.forEach(t),Z3o=r(Yye," (XLMProphetNet model)"),Yye.forEach(t),ewo=i(Q),b2=n(Q,"LI",{});var Kye=s(b2);bde=n(Kye,"STRONG",{});var Qtt=s(bde);owo=r(Qtt,"xlm-roberta"),Qtt.forEach(t),rwo=r(Kye," \u2014 "),Aj=n(Kye,"A",{href:!0});var Htt=s(Aj);two=r(Htt,"XLMRobertaForCausalLM"),Htt.forEach(t),awo=r(Kye," (XLM-RoBERTa model)"),Kye.forEach(t),nwo=i(Q),v2=n(Q,"LI",{});var Zye=s(v2);vde=n(Zye,"STRONG",{});var Utt=s(vde);swo=r(Utt,"xlm-roberta-xl"),Utt.forEach(t),lwo=r(Zye," \u2014 "),yj=n(Zye,"A",{href:!0});var Jtt=s(yj);iwo=r(Jtt,"XLMRobertaXLForCausalLM"),Jtt.forEach(t),dwo=r(Zye," (XLM-RoBERTa-XL model)"),Zye.forEach(t),cwo=i(Q),F2=n(Q,"LI",{});var eLe=s(F2);Fde=n(eLe,"STRONG",{});var Ytt=s(Fde);fwo=r(Ytt,"xlnet"),Ytt.forEach(t),mwo=r(eLe," \u2014 "),Lj=n(eLe,"A",{href:!0});var Ktt=s(Lj);gwo=r(Ktt,"XLNetLMHeadModel"),Ktt.forEach(t),hwo=r(eLe," (XLNet model)"),eLe.forEach(t),Q.forEach(t),pwo=i(ta),T2=n(ta,"P",{});var oLe=s(T2);_wo=r(oLe,"The model is set in evaluation mode by default using "),Tde=n(oLe,"CODE",{});var Ztt=s(Tde);uwo=r(Ztt,"model.eval()"),Ztt.forEach(t),bwo=r(oLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mde=n(oLe,"CODE",{});var eat=s(Mde);vwo=r(eat,"model.train()"),eat.forEach(t),oLe.forEach(t),Fwo=i(ta),T(M2.$$.fragment,ta),ta.forEach(t),Os.forEach(t),hqe=i(f),Ri=n(f,"H2",{class:!0});var bje=s(Ri);E2=n(bje,"A",{id:!0,class:!0,href:!0});var oat=s(E2);Ede=n(oat,"SPAN",{});var rat=s(Ede);T(ey.$$.fragment,rat),rat.forEach(t),oat.forEach(t),Two=i(bje),Cde=n(bje,"SPAN",{});var tat=s(Cde);Mwo=r(tat,"AutoModelForMaskedLM"),tat.forEach(t),bje.forEach(t),pqe=i(f),ko=n(f,"DIV",{class:!0});var Vs=s(ko);T(oy.$$.fragment,Vs),Ewo=i(Vs),Pi=n(Vs,"P",{});var zK=s(Pi);Cwo=r(zK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),xj=n(zK,"A",{href:!0});var aat=s(xj);wwo=r(aat,"from_pretrained()"),aat.forEach(t),Awo=r(zK," class method or the "),$j=n(zK,"A",{href:!0});var nat=s($j);ywo=r(nat,"from_config()"),nat.forEach(t),Lwo=r(zK,` class
method.`),zK.forEach(t),xwo=i(Vs),ry=n(Vs,"P",{});var vje=s(ry);$wo=r(vje,"This class cannot be instantiated directly using "),wde=n(vje,"CODE",{});var sat=s(wde);kwo=r(sat,"__init__()"),sat.forEach(t),Swo=r(vje," (throws an error)."),vje.forEach(t),Rwo=i(Vs),st=n(Vs,"DIV",{class:!0});var E0=s(st);T(ty.$$.fragment,E0),Pwo=i(E0),Ade=n(E0,"P",{});var lat=s(Ade);Bwo=r(lat,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),lat.forEach(t),Iwo=i(E0),Bi=n(E0,"P",{});var WK=s(Bi);qwo=r(WK,`Note:
Loading a model from its configuration file does `),yde=n(WK,"STRONG",{});var iat=s(yde);Nwo=r(iat,"not"),iat.forEach(t),jwo=r(WK,` load the model weights. It only affects the
model\u2019s configuration. Use `),kj=n(WK,"A",{href:!0});var dat=s(kj);Dwo=r(dat,"from_pretrained()"),dat.forEach(t),Gwo=r(WK," to load the model weights."),WK.forEach(t),Owo=i(E0),T(C2.$$.fragment,E0),E0.forEach(t),Vwo=i(Vs),Ze=n(Vs,"DIV",{class:!0});var aa=s(Ze);T(ay.$$.fragment,aa),Xwo=i(aa),Lde=n(aa,"P",{});var cat=s(Lde);zwo=r(cat,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),cat.forEach(t),Wwo=i(aa),ka=n(aa,"P",{});var C0=s(ka);Qwo=r(C0,"The model class to instantiate is selected based on the "),xde=n(C0,"CODE",{});var fat=s(xde);Hwo=r(fat,"model_type"),fat.forEach(t),Uwo=r(C0,` property of the config object (either
passed as an argument or loaded from `),$de=n(C0,"CODE",{});var mat=s($de);Jwo=r(mat,"pretrained_model_name_or_path"),mat.forEach(t),Ywo=r(C0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kde=n(C0,"CODE",{});var gat=s(kde);Kwo=r(gat,"pretrained_model_name_or_path"),gat.forEach(t),Zwo=r(C0,":"),C0.forEach(t),e0o=i(aa),W=n(aa,"UL",{});var H=s(W);w2=n(H,"LI",{});var rLe=s(w2);Sde=n(rLe,"STRONG",{});var hat=s(Sde);o0o=r(hat,"albert"),hat.forEach(t),r0o=r(rLe," \u2014 "),Sj=n(rLe,"A",{href:!0});var pat=s(Sj);t0o=r(pat,"AlbertForMaskedLM"),pat.forEach(t),a0o=r(rLe," (ALBERT model)"),rLe.forEach(t),n0o=i(H),A2=n(H,"LI",{});var tLe=s(A2);Rde=n(tLe,"STRONG",{});var _at=s(Rde);s0o=r(_at,"bart"),_at.forEach(t),l0o=r(tLe," \u2014 "),Rj=n(tLe,"A",{href:!0});var uat=s(Rj);i0o=r(uat,"BartForConditionalGeneration"),uat.forEach(t),d0o=r(tLe," (BART model)"),tLe.forEach(t),c0o=i(H),y2=n(H,"LI",{});var aLe=s(y2);Pde=n(aLe,"STRONG",{});var bat=s(Pde);f0o=r(bat,"bert"),bat.forEach(t),m0o=r(aLe," \u2014 "),Pj=n(aLe,"A",{href:!0});var vat=s(Pj);g0o=r(vat,"BertForMaskedLM"),vat.forEach(t),h0o=r(aLe," (BERT model)"),aLe.forEach(t),p0o=i(H),L2=n(H,"LI",{});var nLe=s(L2);Bde=n(nLe,"STRONG",{});var Fat=s(Bde);_0o=r(Fat,"big_bird"),Fat.forEach(t),u0o=r(nLe," \u2014 "),Bj=n(nLe,"A",{href:!0});var Tat=s(Bj);b0o=r(Tat,"BigBirdForMaskedLM"),Tat.forEach(t),v0o=r(nLe," (BigBird model)"),nLe.forEach(t),F0o=i(H),x2=n(H,"LI",{});var sLe=s(x2);Ide=n(sLe,"STRONG",{});var Mat=s(Ide);T0o=r(Mat,"camembert"),Mat.forEach(t),M0o=r(sLe," \u2014 "),Ij=n(sLe,"A",{href:!0});var Eat=s(Ij);E0o=r(Eat,"CamembertForMaskedLM"),Eat.forEach(t),C0o=r(sLe," (CamemBERT model)"),sLe.forEach(t),w0o=i(H),$2=n(H,"LI",{});var lLe=s($2);qde=n(lLe,"STRONG",{});var Cat=s(qde);A0o=r(Cat,"convbert"),Cat.forEach(t),y0o=r(lLe," \u2014 "),qj=n(lLe,"A",{href:!0});var wat=s(qj);L0o=r(wat,"ConvBertForMaskedLM"),wat.forEach(t),x0o=r(lLe," (ConvBERT model)"),lLe.forEach(t),$0o=i(H),k2=n(H,"LI",{});var iLe=s(k2);Nde=n(iLe,"STRONG",{});var Aat=s(Nde);k0o=r(Aat,"data2vec-text"),Aat.forEach(t),S0o=r(iLe," \u2014 "),Nj=n(iLe,"A",{href:!0});var yat=s(Nj);R0o=r(yat,"Data2VecTextForMaskedLM"),yat.forEach(t),P0o=r(iLe," (Data2VecText model)"),iLe.forEach(t),B0o=i(H),S2=n(H,"LI",{});var dLe=s(S2);jde=n(dLe,"STRONG",{});var Lat=s(jde);I0o=r(Lat,"deberta"),Lat.forEach(t),q0o=r(dLe," \u2014 "),jj=n(dLe,"A",{href:!0});var xat=s(jj);N0o=r(xat,"DebertaForMaskedLM"),xat.forEach(t),j0o=r(dLe," (DeBERTa model)"),dLe.forEach(t),D0o=i(H),R2=n(H,"LI",{});var cLe=s(R2);Dde=n(cLe,"STRONG",{});var $at=s(Dde);G0o=r($at,"deberta-v2"),$at.forEach(t),O0o=r(cLe," \u2014 "),Dj=n(cLe,"A",{href:!0});var kat=s(Dj);V0o=r(kat,"DebertaV2ForMaskedLM"),kat.forEach(t),X0o=r(cLe," (DeBERTa-v2 model)"),cLe.forEach(t),z0o=i(H),P2=n(H,"LI",{});var fLe=s(P2);Gde=n(fLe,"STRONG",{});var Sat=s(Gde);W0o=r(Sat,"distilbert"),Sat.forEach(t),Q0o=r(fLe," \u2014 "),Gj=n(fLe,"A",{href:!0});var Rat=s(Gj);H0o=r(Rat,"DistilBertForMaskedLM"),Rat.forEach(t),U0o=r(fLe," (DistilBERT model)"),fLe.forEach(t),J0o=i(H),B2=n(H,"LI",{});var mLe=s(B2);Ode=n(mLe,"STRONG",{});var Pat=s(Ode);Y0o=r(Pat,"electra"),Pat.forEach(t),K0o=r(mLe," \u2014 "),Oj=n(mLe,"A",{href:!0});var Bat=s(Oj);Z0o=r(Bat,"ElectraForMaskedLM"),Bat.forEach(t),eAo=r(mLe," (ELECTRA model)"),mLe.forEach(t),oAo=i(H),I2=n(H,"LI",{});var gLe=s(I2);Vde=n(gLe,"STRONG",{});var Iat=s(Vde);rAo=r(Iat,"flaubert"),Iat.forEach(t),tAo=r(gLe," \u2014 "),Vj=n(gLe,"A",{href:!0});var qat=s(Vj);aAo=r(qat,"FlaubertWithLMHeadModel"),qat.forEach(t),nAo=r(gLe," (FlauBERT model)"),gLe.forEach(t),sAo=i(H),q2=n(H,"LI",{});var hLe=s(q2);Xde=n(hLe,"STRONG",{});var Nat=s(Xde);lAo=r(Nat,"fnet"),Nat.forEach(t),iAo=r(hLe," \u2014 "),Xj=n(hLe,"A",{href:!0});var jat=s(Xj);dAo=r(jat,"FNetForMaskedLM"),jat.forEach(t),cAo=r(hLe," (FNet model)"),hLe.forEach(t),fAo=i(H),N2=n(H,"LI",{});var pLe=s(N2);zde=n(pLe,"STRONG",{});var Dat=s(zde);mAo=r(Dat,"funnel"),Dat.forEach(t),gAo=r(pLe," \u2014 "),zj=n(pLe,"A",{href:!0});var Gat=s(zj);hAo=r(Gat,"FunnelForMaskedLM"),Gat.forEach(t),pAo=r(pLe," (Funnel Transformer model)"),pLe.forEach(t),_Ao=i(H),j2=n(H,"LI",{});var _Le=s(j2);Wde=n(_Le,"STRONG",{});var Oat=s(Wde);uAo=r(Oat,"ibert"),Oat.forEach(t),bAo=r(_Le," \u2014 "),Wj=n(_Le,"A",{href:!0});var Vat=s(Wj);vAo=r(Vat,"IBertForMaskedLM"),Vat.forEach(t),FAo=r(_Le," (I-BERT model)"),_Le.forEach(t),TAo=i(H),D2=n(H,"LI",{});var uLe=s(D2);Qde=n(uLe,"STRONG",{});var Xat=s(Qde);MAo=r(Xat,"layoutlm"),Xat.forEach(t),EAo=r(uLe," \u2014 "),Qj=n(uLe,"A",{href:!0});var zat=s(Qj);CAo=r(zat,"LayoutLMForMaskedLM"),zat.forEach(t),wAo=r(uLe," (LayoutLM model)"),uLe.forEach(t),AAo=i(H),G2=n(H,"LI",{});var bLe=s(G2);Hde=n(bLe,"STRONG",{});var Wat=s(Hde);yAo=r(Wat,"longformer"),Wat.forEach(t),LAo=r(bLe," \u2014 "),Hj=n(bLe,"A",{href:!0});var Qat=s(Hj);xAo=r(Qat,"LongformerForMaskedLM"),Qat.forEach(t),$Ao=r(bLe," (Longformer model)"),bLe.forEach(t),kAo=i(H),O2=n(H,"LI",{});var vLe=s(O2);Ude=n(vLe,"STRONG",{});var Hat=s(Ude);SAo=r(Hat,"mbart"),Hat.forEach(t),RAo=r(vLe," \u2014 "),Uj=n(vLe,"A",{href:!0});var Uat=s(Uj);PAo=r(Uat,"MBartForConditionalGeneration"),Uat.forEach(t),BAo=r(vLe," (mBART model)"),vLe.forEach(t),IAo=i(H),V2=n(H,"LI",{});var FLe=s(V2);Jde=n(FLe,"STRONG",{});var Jat=s(Jde);qAo=r(Jat,"megatron-bert"),Jat.forEach(t),NAo=r(FLe," \u2014 "),Jj=n(FLe,"A",{href:!0});var Yat=s(Jj);jAo=r(Yat,"MegatronBertForMaskedLM"),Yat.forEach(t),DAo=r(FLe," (MegatronBert model)"),FLe.forEach(t),GAo=i(H),X2=n(H,"LI",{});var TLe=s(X2);Yde=n(TLe,"STRONG",{});var Kat=s(Yde);OAo=r(Kat,"mobilebert"),Kat.forEach(t),VAo=r(TLe," \u2014 "),Yj=n(TLe,"A",{href:!0});var Zat=s(Yj);XAo=r(Zat,"MobileBertForMaskedLM"),Zat.forEach(t),zAo=r(TLe," (MobileBERT model)"),TLe.forEach(t),WAo=i(H),z2=n(H,"LI",{});var MLe=s(z2);Kde=n(MLe,"STRONG",{});var ent=s(Kde);QAo=r(ent,"mpnet"),ent.forEach(t),HAo=r(MLe," \u2014 "),Kj=n(MLe,"A",{href:!0});var ont=s(Kj);UAo=r(ont,"MPNetForMaskedLM"),ont.forEach(t),JAo=r(MLe," (MPNet model)"),MLe.forEach(t),YAo=i(H),W2=n(H,"LI",{});var ELe=s(W2);Zde=n(ELe,"STRONG",{});var rnt=s(Zde);KAo=r(rnt,"nystromformer"),rnt.forEach(t),ZAo=r(ELe," \u2014 "),Zj=n(ELe,"A",{href:!0});var tnt=s(Zj);e6o=r(tnt,"NystromformerForMaskedLM"),tnt.forEach(t),o6o=r(ELe," (Nystromformer model)"),ELe.forEach(t),r6o=i(H),Q2=n(H,"LI",{});var CLe=s(Q2);ece=n(CLe,"STRONG",{});var ant=s(ece);t6o=r(ant,"perceiver"),ant.forEach(t),a6o=r(CLe," \u2014 "),eD=n(CLe,"A",{href:!0});var nnt=s(eD);n6o=r(nnt,"PerceiverForMaskedLM"),nnt.forEach(t),s6o=r(CLe," (Perceiver model)"),CLe.forEach(t),l6o=i(H),H2=n(H,"LI",{});var wLe=s(H2);oce=n(wLe,"STRONG",{});var snt=s(oce);i6o=r(snt,"qdqbert"),snt.forEach(t),d6o=r(wLe," \u2014 "),oD=n(wLe,"A",{href:!0});var lnt=s(oD);c6o=r(lnt,"QDQBertForMaskedLM"),lnt.forEach(t),f6o=r(wLe," (QDQBert model)"),wLe.forEach(t),m6o=i(H),U2=n(H,"LI",{});var ALe=s(U2);rce=n(ALe,"STRONG",{});var int=s(rce);g6o=r(int,"reformer"),int.forEach(t),h6o=r(ALe," \u2014 "),rD=n(ALe,"A",{href:!0});var dnt=s(rD);p6o=r(dnt,"ReformerForMaskedLM"),dnt.forEach(t),_6o=r(ALe," (Reformer model)"),ALe.forEach(t),u6o=i(H),J2=n(H,"LI",{});var yLe=s(J2);tce=n(yLe,"STRONG",{});var cnt=s(tce);b6o=r(cnt,"rembert"),cnt.forEach(t),v6o=r(yLe," \u2014 "),tD=n(yLe,"A",{href:!0});var fnt=s(tD);F6o=r(fnt,"RemBertForMaskedLM"),fnt.forEach(t),T6o=r(yLe," (RemBERT model)"),yLe.forEach(t),M6o=i(H),Y2=n(H,"LI",{});var LLe=s(Y2);ace=n(LLe,"STRONG",{});var mnt=s(ace);E6o=r(mnt,"roberta"),mnt.forEach(t),C6o=r(LLe," \u2014 "),aD=n(LLe,"A",{href:!0});var gnt=s(aD);w6o=r(gnt,"RobertaForMaskedLM"),gnt.forEach(t),A6o=r(LLe," (RoBERTa model)"),LLe.forEach(t),y6o=i(H),K2=n(H,"LI",{});var xLe=s(K2);nce=n(xLe,"STRONG",{});var hnt=s(nce);L6o=r(hnt,"roformer"),hnt.forEach(t),x6o=r(xLe," \u2014 "),nD=n(xLe,"A",{href:!0});var pnt=s(nD);$6o=r(pnt,"RoFormerForMaskedLM"),pnt.forEach(t),k6o=r(xLe," (RoFormer model)"),xLe.forEach(t),S6o=i(H),Z2=n(H,"LI",{});var $Le=s(Z2);sce=n($Le,"STRONG",{});var _nt=s(sce);R6o=r(_nt,"squeezebert"),_nt.forEach(t),P6o=r($Le," \u2014 "),sD=n($Le,"A",{href:!0});var unt=s(sD);B6o=r(unt,"SqueezeBertForMaskedLM"),unt.forEach(t),I6o=r($Le," (SqueezeBERT model)"),$Le.forEach(t),q6o=i(H),e1=n(H,"LI",{});var kLe=s(e1);lce=n(kLe,"STRONG",{});var bnt=s(lce);N6o=r(bnt,"tapas"),bnt.forEach(t),j6o=r(kLe," \u2014 "),lD=n(kLe,"A",{href:!0});var vnt=s(lD);D6o=r(vnt,"TapasForMaskedLM"),vnt.forEach(t),G6o=r(kLe," (TAPAS model)"),kLe.forEach(t),O6o=i(H),o1=n(H,"LI",{});var SLe=s(o1);ice=n(SLe,"STRONG",{});var Fnt=s(ice);V6o=r(Fnt,"wav2vec2"),Fnt.forEach(t),X6o=r(SLe," \u2014 "),dce=n(SLe,"CODE",{});var Tnt=s(dce);z6o=r(Tnt,"Wav2Vec2ForMaskedLM"),Tnt.forEach(t),W6o=r(SLe," (Wav2Vec2 model)"),SLe.forEach(t),Q6o=i(H),r1=n(H,"LI",{});var RLe=s(r1);cce=n(RLe,"STRONG",{});var Mnt=s(cce);H6o=r(Mnt,"xlm"),Mnt.forEach(t),U6o=r(RLe," \u2014 "),iD=n(RLe,"A",{href:!0});var Ent=s(iD);J6o=r(Ent,"XLMWithLMHeadModel"),Ent.forEach(t),Y6o=r(RLe," (XLM model)"),RLe.forEach(t),K6o=i(H),t1=n(H,"LI",{});var PLe=s(t1);fce=n(PLe,"STRONG",{});var Cnt=s(fce);Z6o=r(Cnt,"xlm-roberta"),Cnt.forEach(t),eyo=r(PLe," \u2014 "),dD=n(PLe,"A",{href:!0});var wnt=s(dD);oyo=r(wnt,"XLMRobertaForMaskedLM"),wnt.forEach(t),ryo=r(PLe," (XLM-RoBERTa model)"),PLe.forEach(t),tyo=i(H),a1=n(H,"LI",{});var BLe=s(a1);mce=n(BLe,"STRONG",{});var Ant=s(mce);ayo=r(Ant,"xlm-roberta-xl"),Ant.forEach(t),nyo=r(BLe," \u2014 "),cD=n(BLe,"A",{href:!0});var ynt=s(cD);syo=r(ynt,"XLMRobertaXLForMaskedLM"),ynt.forEach(t),lyo=r(BLe," (XLM-RoBERTa-XL model)"),BLe.forEach(t),iyo=i(H),n1=n(H,"LI",{});var ILe=s(n1);gce=n(ILe,"STRONG",{});var Lnt=s(gce);dyo=r(Lnt,"yoso"),Lnt.forEach(t),cyo=r(ILe," \u2014 "),fD=n(ILe,"A",{href:!0});var xnt=s(fD);fyo=r(xnt,"YosoForMaskedLM"),xnt.forEach(t),myo=r(ILe," (YOSO model)"),ILe.forEach(t),H.forEach(t),gyo=i(aa),s1=n(aa,"P",{});var qLe=s(s1);hyo=r(qLe,"The model is set in evaluation mode by default using "),hce=n(qLe,"CODE",{});var $nt=s(hce);pyo=r($nt,"model.eval()"),$nt.forEach(t),_yo=r(qLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pce=n(qLe,"CODE",{});var knt=s(pce);uyo=r(knt,"model.train()"),knt.forEach(t),qLe.forEach(t),byo=i(aa),T(l1.$$.fragment,aa),aa.forEach(t),Vs.forEach(t),_qe=i(f),Ii=n(f,"H2",{class:!0});var Fje=s(Ii);i1=n(Fje,"A",{id:!0,class:!0,href:!0});var Snt=s(i1);_ce=n(Snt,"SPAN",{});var Rnt=s(_ce);T(ny.$$.fragment,Rnt),Rnt.forEach(t),Snt.forEach(t),vyo=i(Fje),uce=n(Fje,"SPAN",{});var Pnt=s(uce);Fyo=r(Pnt,"AutoModelForSeq2SeqLM"),Pnt.forEach(t),Fje.forEach(t),uqe=i(f),So=n(f,"DIV",{class:!0});var Xs=s(So);T(sy.$$.fragment,Xs),Tyo=i(Xs),qi=n(Xs,"P",{});var QK=s(qi);Myo=r(QK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),mD=n(QK,"A",{href:!0});var Bnt=s(mD);Eyo=r(Bnt,"from_pretrained()"),Bnt.forEach(t),Cyo=r(QK," class method or the "),gD=n(QK,"A",{href:!0});var Int=s(gD);wyo=r(Int,"from_config()"),Int.forEach(t),Ayo=r(QK,` class
method.`),QK.forEach(t),yyo=i(Xs),ly=n(Xs,"P",{});var Tje=s(ly);Lyo=r(Tje,"This class cannot be instantiated directly using "),bce=n(Tje,"CODE",{});var qnt=s(bce);xyo=r(qnt,"__init__()"),qnt.forEach(t),$yo=r(Tje," (throws an error)."),Tje.forEach(t),kyo=i(Xs),lt=n(Xs,"DIV",{class:!0});var w0=s(lt);T(iy.$$.fragment,w0),Syo=i(w0),vce=n(w0,"P",{});var Nnt=s(vce);Ryo=r(Nnt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Nnt.forEach(t),Pyo=i(w0),Ni=n(w0,"P",{});var HK=s(Ni);Byo=r(HK,`Note:
Loading a model from its configuration file does `),Fce=n(HK,"STRONG",{});var jnt=s(Fce);Iyo=r(jnt,"not"),jnt.forEach(t),qyo=r(HK,` load the model weights. It only affects the
model\u2019s configuration. Use `),hD=n(HK,"A",{href:!0});var Dnt=s(hD);Nyo=r(Dnt,"from_pretrained()"),Dnt.forEach(t),jyo=r(HK," to load the model weights."),HK.forEach(t),Dyo=i(w0),T(d1.$$.fragment,w0),w0.forEach(t),Gyo=i(Xs),eo=n(Xs,"DIV",{class:!0});var na=s(eo);T(dy.$$.fragment,na),Oyo=i(na),Tce=n(na,"P",{});var Gnt=s(Tce);Vyo=r(Gnt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Gnt.forEach(t),Xyo=i(na),Sa=n(na,"P",{});var A0=s(Sa);zyo=r(A0,"The model class to instantiate is selected based on the "),Mce=n(A0,"CODE",{});var Ont=s(Mce);Wyo=r(Ont,"model_type"),Ont.forEach(t),Qyo=r(A0,` property of the config object (either
passed as an argument or loaded from `),Ece=n(A0,"CODE",{});var Vnt=s(Ece);Hyo=r(Vnt,"pretrained_model_name_or_path"),Vnt.forEach(t),Uyo=r(A0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cce=n(A0,"CODE",{});var Xnt=s(Cce);Jyo=r(Xnt,"pretrained_model_name_or_path"),Xnt.forEach(t),Yyo=r(A0,":"),A0.forEach(t),Kyo=i(na),_e=n(na,"UL",{});var ve=s(_e);c1=n(ve,"LI",{});var NLe=s(c1);wce=n(NLe,"STRONG",{});var znt=s(wce);Zyo=r(znt,"bart"),znt.forEach(t),eLo=r(NLe," \u2014 "),pD=n(NLe,"A",{href:!0});var Wnt=s(pD);oLo=r(Wnt,"BartForConditionalGeneration"),Wnt.forEach(t),rLo=r(NLe," (BART model)"),NLe.forEach(t),tLo=i(ve),f1=n(ve,"LI",{});var jLe=s(f1);Ace=n(jLe,"STRONG",{});var Qnt=s(Ace);aLo=r(Qnt,"bigbird_pegasus"),Qnt.forEach(t),nLo=r(jLe," \u2014 "),_D=n(jLe,"A",{href:!0});var Hnt=s(_D);sLo=r(Hnt,"BigBirdPegasusForConditionalGeneration"),Hnt.forEach(t),lLo=r(jLe," (BigBirdPegasus model)"),jLe.forEach(t),iLo=i(ve),m1=n(ve,"LI",{});var DLe=s(m1);yce=n(DLe,"STRONG",{});var Unt=s(yce);dLo=r(Unt,"blenderbot"),Unt.forEach(t),cLo=r(DLe," \u2014 "),uD=n(DLe,"A",{href:!0});var Jnt=s(uD);fLo=r(Jnt,"BlenderbotForConditionalGeneration"),Jnt.forEach(t),mLo=r(DLe," (Blenderbot model)"),DLe.forEach(t),gLo=i(ve),g1=n(ve,"LI",{});var GLe=s(g1);Lce=n(GLe,"STRONG",{});var Ynt=s(Lce);hLo=r(Ynt,"blenderbot-small"),Ynt.forEach(t),pLo=r(GLe," \u2014 "),bD=n(GLe,"A",{href:!0});var Knt=s(bD);_Lo=r(Knt,"BlenderbotSmallForConditionalGeneration"),Knt.forEach(t),uLo=r(GLe," (BlenderbotSmall model)"),GLe.forEach(t),bLo=i(ve),h1=n(ve,"LI",{});var OLe=s(h1);xce=n(OLe,"STRONG",{});var Znt=s(xce);vLo=r(Znt,"encoder-decoder"),Znt.forEach(t),FLo=r(OLe," \u2014 "),vD=n(OLe,"A",{href:!0});var est=s(vD);TLo=r(est,"EncoderDecoderModel"),est.forEach(t),MLo=r(OLe," (Encoder decoder model)"),OLe.forEach(t),ELo=i(ve),p1=n(ve,"LI",{});var VLe=s(p1);$ce=n(VLe,"STRONG",{});var ost=s($ce);CLo=r(ost,"fsmt"),ost.forEach(t),wLo=r(VLe," \u2014 "),FD=n(VLe,"A",{href:!0});var rst=s(FD);ALo=r(rst,"FSMTForConditionalGeneration"),rst.forEach(t),yLo=r(VLe," (FairSeq Machine-Translation model)"),VLe.forEach(t),LLo=i(ve),_1=n(ve,"LI",{});var XLe=s(_1);kce=n(XLe,"STRONG",{});var tst=s(kce);xLo=r(tst,"led"),tst.forEach(t),$Lo=r(XLe," \u2014 "),TD=n(XLe,"A",{href:!0});var ast=s(TD);kLo=r(ast,"LEDForConditionalGeneration"),ast.forEach(t),SLo=r(XLe," (LED model)"),XLe.forEach(t),RLo=i(ve),u1=n(ve,"LI",{});var zLe=s(u1);Sce=n(zLe,"STRONG",{});var nst=s(Sce);PLo=r(nst,"m2m_100"),nst.forEach(t),BLo=r(zLe," \u2014 "),MD=n(zLe,"A",{href:!0});var sst=s(MD);ILo=r(sst,"M2M100ForConditionalGeneration"),sst.forEach(t),qLo=r(zLe," (M2M100 model)"),zLe.forEach(t),NLo=i(ve),b1=n(ve,"LI",{});var WLe=s(b1);Rce=n(WLe,"STRONG",{});var lst=s(Rce);jLo=r(lst,"marian"),lst.forEach(t),DLo=r(WLe," \u2014 "),ED=n(WLe,"A",{href:!0});var ist=s(ED);GLo=r(ist,"MarianMTModel"),ist.forEach(t),OLo=r(WLe," (Marian model)"),WLe.forEach(t),VLo=i(ve),v1=n(ve,"LI",{});var QLe=s(v1);Pce=n(QLe,"STRONG",{});var dst=s(Pce);XLo=r(dst,"mbart"),dst.forEach(t),zLo=r(QLe," \u2014 "),CD=n(QLe,"A",{href:!0});var cst=s(CD);WLo=r(cst,"MBartForConditionalGeneration"),cst.forEach(t),QLo=r(QLe," (mBART model)"),QLe.forEach(t),HLo=i(ve),F1=n(ve,"LI",{});var HLe=s(F1);Bce=n(HLe,"STRONG",{});var fst=s(Bce);ULo=r(fst,"mt5"),fst.forEach(t),JLo=r(HLe," \u2014 "),wD=n(HLe,"A",{href:!0});var mst=s(wD);YLo=r(mst,"MT5ForConditionalGeneration"),mst.forEach(t),KLo=r(HLe," (mT5 model)"),HLe.forEach(t),ZLo=i(ve),T1=n(ve,"LI",{});var ULe=s(T1);Ice=n(ULe,"STRONG",{});var gst=s(Ice);e8o=r(gst,"pegasus"),gst.forEach(t),o8o=r(ULe," \u2014 "),AD=n(ULe,"A",{href:!0});var hst=s(AD);r8o=r(hst,"PegasusForConditionalGeneration"),hst.forEach(t),t8o=r(ULe," (Pegasus model)"),ULe.forEach(t),a8o=i(ve),M1=n(ve,"LI",{});var JLe=s(M1);qce=n(JLe,"STRONG",{});var pst=s(qce);n8o=r(pst,"plbart"),pst.forEach(t),s8o=r(JLe," \u2014 "),yD=n(JLe,"A",{href:!0});var _st=s(yD);l8o=r(_st,"PLBartForConditionalGeneration"),_st.forEach(t),i8o=r(JLe," (PLBart model)"),JLe.forEach(t),d8o=i(ve),E1=n(ve,"LI",{});var YLe=s(E1);Nce=n(YLe,"STRONG",{});var ust=s(Nce);c8o=r(ust,"prophetnet"),ust.forEach(t),f8o=r(YLe," \u2014 "),LD=n(YLe,"A",{href:!0});var bst=s(LD);m8o=r(bst,"ProphetNetForConditionalGeneration"),bst.forEach(t),g8o=r(YLe," (ProphetNet model)"),YLe.forEach(t),h8o=i(ve),C1=n(ve,"LI",{});var KLe=s(C1);jce=n(KLe,"STRONG",{});var vst=s(jce);p8o=r(vst,"t5"),vst.forEach(t),_8o=r(KLe," \u2014 "),xD=n(KLe,"A",{href:!0});var Fst=s(xD);u8o=r(Fst,"T5ForConditionalGeneration"),Fst.forEach(t),b8o=r(KLe," (T5 model)"),KLe.forEach(t),v8o=i(ve),w1=n(ve,"LI",{});var ZLe=s(w1);Dce=n(ZLe,"STRONG",{});var Tst=s(Dce);F8o=r(Tst,"xlm-prophetnet"),Tst.forEach(t),T8o=r(ZLe," \u2014 "),$D=n(ZLe,"A",{href:!0});var Mst=s($D);M8o=r(Mst,"XLMProphetNetForConditionalGeneration"),Mst.forEach(t),E8o=r(ZLe," (XLMProphetNet model)"),ZLe.forEach(t),ve.forEach(t),C8o=i(na),A1=n(na,"P",{});var e8e=s(A1);w8o=r(e8e,"The model is set in evaluation mode by default using "),Gce=n(e8e,"CODE",{});var Est=s(Gce);A8o=r(Est,"model.eval()"),Est.forEach(t),y8o=r(e8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oce=n(e8e,"CODE",{});var Cst=s(Oce);L8o=r(Cst,"model.train()"),Cst.forEach(t),e8e.forEach(t),x8o=i(na),T(y1.$$.fragment,na),na.forEach(t),Xs.forEach(t),bqe=i(f),ji=n(f,"H2",{class:!0});var Mje=s(ji);L1=n(Mje,"A",{id:!0,class:!0,href:!0});var wst=s(L1);Vce=n(wst,"SPAN",{});var Ast=s(Vce);T(cy.$$.fragment,Ast),Ast.forEach(t),wst.forEach(t),$8o=i(Mje),Xce=n(Mje,"SPAN",{});var yst=s(Xce);k8o=r(yst,"AutoModelForSequenceClassification"),yst.forEach(t),Mje.forEach(t),vqe=i(f),Ro=n(f,"DIV",{class:!0});var zs=s(Ro);T(fy.$$.fragment,zs),S8o=i(zs),Di=n(zs,"P",{});var UK=s(Di);R8o=r(UK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),kD=n(UK,"A",{href:!0});var Lst=s(kD);P8o=r(Lst,"from_pretrained()"),Lst.forEach(t),B8o=r(UK," class method or the "),SD=n(UK,"A",{href:!0});var xst=s(SD);I8o=r(xst,"from_config()"),xst.forEach(t),q8o=r(UK,` class
method.`),UK.forEach(t),N8o=i(zs),my=n(zs,"P",{});var Eje=s(my);j8o=r(Eje,"This class cannot be instantiated directly using "),zce=n(Eje,"CODE",{});var $st=s(zce);D8o=r($st,"__init__()"),$st.forEach(t),G8o=r(Eje," (throws an error)."),Eje.forEach(t),O8o=i(zs),it=n(zs,"DIV",{class:!0});var y0=s(it);T(gy.$$.fragment,y0),V8o=i(y0),Wce=n(y0,"P",{});var kst=s(Wce);X8o=r(kst,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),kst.forEach(t),z8o=i(y0),Gi=n(y0,"P",{});var JK=s(Gi);W8o=r(JK,`Note:
Loading a model from its configuration file does `),Qce=n(JK,"STRONG",{});var Sst=s(Qce);Q8o=r(Sst,"not"),Sst.forEach(t),H8o=r(JK,` load the model weights. It only affects the
model\u2019s configuration. Use `),RD=n(JK,"A",{href:!0});var Rst=s(RD);U8o=r(Rst,"from_pretrained()"),Rst.forEach(t),J8o=r(JK," to load the model weights."),JK.forEach(t),Y8o=i(y0),T(x1.$$.fragment,y0),y0.forEach(t),K8o=i(zs),oo=n(zs,"DIV",{class:!0});var sa=s(oo);T(hy.$$.fragment,sa),Z8o=i(sa),Hce=n(sa,"P",{});var Pst=s(Hce);exo=r(Pst,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Pst.forEach(t),oxo=i(sa),Ra=n(sa,"P",{});var L0=s(Ra);rxo=r(L0,"The model class to instantiate is selected based on the "),Uce=n(L0,"CODE",{});var Bst=s(Uce);txo=r(Bst,"model_type"),Bst.forEach(t),axo=r(L0,` property of the config object (either
passed as an argument or loaded from `),Jce=n(L0,"CODE",{});var Ist=s(Jce);nxo=r(Ist,"pretrained_model_name_or_path"),Ist.forEach(t),sxo=r(L0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yce=n(L0,"CODE",{});var qst=s(Yce);lxo=r(qst,"pretrained_model_name_or_path"),qst.forEach(t),ixo=r(L0,":"),L0.forEach(t),dxo=i(sa),N=n(sa,"UL",{});var D=s(N);$1=n(D,"LI",{});var o8e=s($1);Kce=n(o8e,"STRONG",{});var Nst=s(Kce);cxo=r(Nst,"albert"),Nst.forEach(t),fxo=r(o8e," \u2014 "),PD=n(o8e,"A",{href:!0});var jst=s(PD);mxo=r(jst,"AlbertForSequenceClassification"),jst.forEach(t),gxo=r(o8e," (ALBERT model)"),o8e.forEach(t),hxo=i(D),k1=n(D,"LI",{});var r8e=s(k1);Zce=n(r8e,"STRONG",{});var Dst=s(Zce);pxo=r(Dst,"bart"),Dst.forEach(t),_xo=r(r8e," \u2014 "),BD=n(r8e,"A",{href:!0});var Gst=s(BD);uxo=r(Gst,"BartForSequenceClassification"),Gst.forEach(t),bxo=r(r8e," (BART model)"),r8e.forEach(t),vxo=i(D),S1=n(D,"LI",{});var t8e=s(S1);efe=n(t8e,"STRONG",{});var Ost=s(efe);Fxo=r(Ost,"bert"),Ost.forEach(t),Txo=r(t8e," \u2014 "),ID=n(t8e,"A",{href:!0});var Vst=s(ID);Mxo=r(Vst,"BertForSequenceClassification"),Vst.forEach(t),Exo=r(t8e," (BERT model)"),t8e.forEach(t),Cxo=i(D),R1=n(D,"LI",{});var a8e=s(R1);ofe=n(a8e,"STRONG",{});var Xst=s(ofe);wxo=r(Xst,"big_bird"),Xst.forEach(t),Axo=r(a8e," \u2014 "),qD=n(a8e,"A",{href:!0});var zst=s(qD);yxo=r(zst,"BigBirdForSequenceClassification"),zst.forEach(t),Lxo=r(a8e," (BigBird model)"),a8e.forEach(t),xxo=i(D),P1=n(D,"LI",{});var n8e=s(P1);rfe=n(n8e,"STRONG",{});var Wst=s(rfe);$xo=r(Wst,"bigbird_pegasus"),Wst.forEach(t),kxo=r(n8e," \u2014 "),ND=n(n8e,"A",{href:!0});var Qst=s(ND);Sxo=r(Qst,"BigBirdPegasusForSequenceClassification"),Qst.forEach(t),Rxo=r(n8e," (BigBirdPegasus model)"),n8e.forEach(t),Pxo=i(D),B1=n(D,"LI",{});var s8e=s(B1);tfe=n(s8e,"STRONG",{});var Hst=s(tfe);Bxo=r(Hst,"camembert"),Hst.forEach(t),Ixo=r(s8e," \u2014 "),jD=n(s8e,"A",{href:!0});var Ust=s(jD);qxo=r(Ust,"CamembertForSequenceClassification"),Ust.forEach(t),Nxo=r(s8e," (CamemBERT model)"),s8e.forEach(t),jxo=i(D),I1=n(D,"LI",{});var l8e=s(I1);afe=n(l8e,"STRONG",{});var Jst=s(afe);Dxo=r(Jst,"canine"),Jst.forEach(t),Gxo=r(l8e," \u2014 "),DD=n(l8e,"A",{href:!0});var Yst=s(DD);Oxo=r(Yst,"CanineForSequenceClassification"),Yst.forEach(t),Vxo=r(l8e," (Canine model)"),l8e.forEach(t),Xxo=i(D),q1=n(D,"LI",{});var i8e=s(q1);nfe=n(i8e,"STRONG",{});var Kst=s(nfe);zxo=r(Kst,"convbert"),Kst.forEach(t),Wxo=r(i8e," \u2014 "),GD=n(i8e,"A",{href:!0});var Zst=s(GD);Qxo=r(Zst,"ConvBertForSequenceClassification"),Zst.forEach(t),Hxo=r(i8e," (ConvBERT model)"),i8e.forEach(t),Uxo=i(D),N1=n(D,"LI",{});var d8e=s(N1);sfe=n(d8e,"STRONG",{});var elt=s(sfe);Jxo=r(elt,"ctrl"),elt.forEach(t),Yxo=r(d8e," \u2014 "),OD=n(d8e,"A",{href:!0});var olt=s(OD);Kxo=r(olt,"CTRLForSequenceClassification"),olt.forEach(t),Zxo=r(d8e," (CTRL model)"),d8e.forEach(t),e9o=i(D),j1=n(D,"LI",{});var c8e=s(j1);lfe=n(c8e,"STRONG",{});var rlt=s(lfe);o9o=r(rlt,"data2vec-text"),rlt.forEach(t),r9o=r(c8e," \u2014 "),VD=n(c8e,"A",{href:!0});var tlt=s(VD);t9o=r(tlt,"Data2VecTextForSequenceClassification"),tlt.forEach(t),a9o=r(c8e," (Data2VecText model)"),c8e.forEach(t),n9o=i(D),D1=n(D,"LI",{});var f8e=s(D1);ife=n(f8e,"STRONG",{});var alt=s(ife);s9o=r(alt,"deberta"),alt.forEach(t),l9o=r(f8e," \u2014 "),XD=n(f8e,"A",{href:!0});var nlt=s(XD);i9o=r(nlt,"DebertaForSequenceClassification"),nlt.forEach(t),d9o=r(f8e," (DeBERTa model)"),f8e.forEach(t),c9o=i(D),G1=n(D,"LI",{});var m8e=s(G1);dfe=n(m8e,"STRONG",{});var slt=s(dfe);f9o=r(slt,"deberta-v2"),slt.forEach(t),m9o=r(m8e," \u2014 "),zD=n(m8e,"A",{href:!0});var llt=s(zD);g9o=r(llt,"DebertaV2ForSequenceClassification"),llt.forEach(t),h9o=r(m8e," (DeBERTa-v2 model)"),m8e.forEach(t),p9o=i(D),O1=n(D,"LI",{});var g8e=s(O1);cfe=n(g8e,"STRONG",{});var ilt=s(cfe);_9o=r(ilt,"distilbert"),ilt.forEach(t),u9o=r(g8e," \u2014 "),WD=n(g8e,"A",{href:!0});var dlt=s(WD);b9o=r(dlt,"DistilBertForSequenceClassification"),dlt.forEach(t),v9o=r(g8e," (DistilBERT model)"),g8e.forEach(t),F9o=i(D),V1=n(D,"LI",{});var h8e=s(V1);ffe=n(h8e,"STRONG",{});var clt=s(ffe);T9o=r(clt,"electra"),clt.forEach(t),M9o=r(h8e," \u2014 "),QD=n(h8e,"A",{href:!0});var flt=s(QD);E9o=r(flt,"ElectraForSequenceClassification"),flt.forEach(t),C9o=r(h8e," (ELECTRA model)"),h8e.forEach(t),w9o=i(D),X1=n(D,"LI",{});var p8e=s(X1);mfe=n(p8e,"STRONG",{});var mlt=s(mfe);A9o=r(mlt,"flaubert"),mlt.forEach(t),y9o=r(p8e," \u2014 "),HD=n(p8e,"A",{href:!0});var glt=s(HD);L9o=r(glt,"FlaubertForSequenceClassification"),glt.forEach(t),x9o=r(p8e," (FlauBERT model)"),p8e.forEach(t),$9o=i(D),z1=n(D,"LI",{});var _8e=s(z1);gfe=n(_8e,"STRONG",{});var hlt=s(gfe);k9o=r(hlt,"fnet"),hlt.forEach(t),S9o=r(_8e," \u2014 "),UD=n(_8e,"A",{href:!0});var plt=s(UD);R9o=r(plt,"FNetForSequenceClassification"),plt.forEach(t),P9o=r(_8e," (FNet model)"),_8e.forEach(t),B9o=i(D),W1=n(D,"LI",{});var u8e=s(W1);hfe=n(u8e,"STRONG",{});var _lt=s(hfe);I9o=r(_lt,"funnel"),_lt.forEach(t),q9o=r(u8e," \u2014 "),JD=n(u8e,"A",{href:!0});var ult=s(JD);N9o=r(ult,"FunnelForSequenceClassification"),ult.forEach(t),j9o=r(u8e," (Funnel Transformer model)"),u8e.forEach(t),D9o=i(D),Q1=n(D,"LI",{});var b8e=s(Q1);pfe=n(b8e,"STRONG",{});var blt=s(pfe);G9o=r(blt,"gpt2"),blt.forEach(t),O9o=r(b8e," \u2014 "),YD=n(b8e,"A",{href:!0});var vlt=s(YD);V9o=r(vlt,"GPT2ForSequenceClassification"),vlt.forEach(t),X9o=r(b8e," (OpenAI GPT-2 model)"),b8e.forEach(t),z9o=i(D),H1=n(D,"LI",{});var v8e=s(H1);_fe=n(v8e,"STRONG",{});var Flt=s(_fe);W9o=r(Flt,"gpt_neo"),Flt.forEach(t),Q9o=r(v8e," \u2014 "),KD=n(v8e,"A",{href:!0});var Tlt=s(KD);H9o=r(Tlt,"GPTNeoForSequenceClassification"),Tlt.forEach(t),U9o=r(v8e," (GPT Neo model)"),v8e.forEach(t),J9o=i(D),U1=n(D,"LI",{});var F8e=s(U1);ufe=n(F8e,"STRONG",{});var Mlt=s(ufe);Y9o=r(Mlt,"gptj"),Mlt.forEach(t),K9o=r(F8e," \u2014 "),ZD=n(F8e,"A",{href:!0});var Elt=s(ZD);Z9o=r(Elt,"GPTJForSequenceClassification"),Elt.forEach(t),e$o=r(F8e," (GPT-J model)"),F8e.forEach(t),o$o=i(D),J1=n(D,"LI",{});var T8e=s(J1);bfe=n(T8e,"STRONG",{});var Clt=s(bfe);r$o=r(Clt,"ibert"),Clt.forEach(t),t$o=r(T8e," \u2014 "),eG=n(T8e,"A",{href:!0});var wlt=s(eG);a$o=r(wlt,"IBertForSequenceClassification"),wlt.forEach(t),n$o=r(T8e," (I-BERT model)"),T8e.forEach(t),s$o=i(D),Y1=n(D,"LI",{});var M8e=s(Y1);vfe=n(M8e,"STRONG",{});var Alt=s(vfe);l$o=r(Alt,"layoutlm"),Alt.forEach(t),i$o=r(M8e," \u2014 "),oG=n(M8e,"A",{href:!0});var ylt=s(oG);d$o=r(ylt,"LayoutLMForSequenceClassification"),ylt.forEach(t),c$o=r(M8e," (LayoutLM model)"),M8e.forEach(t),f$o=i(D),K1=n(D,"LI",{});var E8e=s(K1);Ffe=n(E8e,"STRONG",{});var Llt=s(Ffe);m$o=r(Llt,"layoutlmv2"),Llt.forEach(t),g$o=r(E8e," \u2014 "),rG=n(E8e,"A",{href:!0});var xlt=s(rG);h$o=r(xlt,"LayoutLMv2ForSequenceClassification"),xlt.forEach(t),p$o=r(E8e," (LayoutLMv2 model)"),E8e.forEach(t),_$o=i(D),Z1=n(D,"LI",{});var C8e=s(Z1);Tfe=n(C8e,"STRONG",{});var $lt=s(Tfe);u$o=r($lt,"led"),$lt.forEach(t),b$o=r(C8e," \u2014 "),tG=n(C8e,"A",{href:!0});var klt=s(tG);v$o=r(klt,"LEDForSequenceClassification"),klt.forEach(t),F$o=r(C8e," (LED model)"),C8e.forEach(t),T$o=i(D),e7=n(D,"LI",{});var w8e=s(e7);Mfe=n(w8e,"STRONG",{});var Slt=s(Mfe);M$o=r(Slt,"longformer"),Slt.forEach(t),E$o=r(w8e," \u2014 "),aG=n(w8e,"A",{href:!0});var Rlt=s(aG);C$o=r(Rlt,"LongformerForSequenceClassification"),Rlt.forEach(t),w$o=r(w8e," (Longformer model)"),w8e.forEach(t),A$o=i(D),o7=n(D,"LI",{});var A8e=s(o7);Efe=n(A8e,"STRONG",{});var Plt=s(Efe);y$o=r(Plt,"mbart"),Plt.forEach(t),L$o=r(A8e," \u2014 "),nG=n(A8e,"A",{href:!0});var Blt=s(nG);x$o=r(Blt,"MBartForSequenceClassification"),Blt.forEach(t),$$o=r(A8e," (mBART model)"),A8e.forEach(t),k$o=i(D),r7=n(D,"LI",{});var y8e=s(r7);Cfe=n(y8e,"STRONG",{});var Ilt=s(Cfe);S$o=r(Ilt,"megatron-bert"),Ilt.forEach(t),R$o=r(y8e," \u2014 "),sG=n(y8e,"A",{href:!0});var qlt=s(sG);P$o=r(qlt,"MegatronBertForSequenceClassification"),qlt.forEach(t),B$o=r(y8e," (MegatronBert model)"),y8e.forEach(t),I$o=i(D),t7=n(D,"LI",{});var L8e=s(t7);wfe=n(L8e,"STRONG",{});var Nlt=s(wfe);q$o=r(Nlt,"mobilebert"),Nlt.forEach(t),N$o=r(L8e," \u2014 "),lG=n(L8e,"A",{href:!0});var jlt=s(lG);j$o=r(jlt,"MobileBertForSequenceClassification"),jlt.forEach(t),D$o=r(L8e," (MobileBERT model)"),L8e.forEach(t),G$o=i(D),a7=n(D,"LI",{});var x8e=s(a7);Afe=n(x8e,"STRONG",{});var Dlt=s(Afe);O$o=r(Dlt,"mpnet"),Dlt.forEach(t),V$o=r(x8e," \u2014 "),iG=n(x8e,"A",{href:!0});var Glt=s(iG);X$o=r(Glt,"MPNetForSequenceClassification"),Glt.forEach(t),z$o=r(x8e," (MPNet model)"),x8e.forEach(t),W$o=i(D),n7=n(D,"LI",{});var $8e=s(n7);yfe=n($8e,"STRONG",{});var Olt=s(yfe);Q$o=r(Olt,"nystromformer"),Olt.forEach(t),H$o=r($8e," \u2014 "),dG=n($8e,"A",{href:!0});var Vlt=s(dG);U$o=r(Vlt,"NystromformerForSequenceClassification"),Vlt.forEach(t),J$o=r($8e," (Nystromformer model)"),$8e.forEach(t),Y$o=i(D),s7=n(D,"LI",{});var k8e=s(s7);Lfe=n(k8e,"STRONG",{});var Xlt=s(Lfe);K$o=r(Xlt,"openai-gpt"),Xlt.forEach(t),Z$o=r(k8e," \u2014 "),cG=n(k8e,"A",{href:!0});var zlt=s(cG);eko=r(zlt,"OpenAIGPTForSequenceClassification"),zlt.forEach(t),oko=r(k8e," (OpenAI GPT model)"),k8e.forEach(t),rko=i(D),l7=n(D,"LI",{});var S8e=s(l7);xfe=n(S8e,"STRONG",{});var Wlt=s(xfe);tko=r(Wlt,"perceiver"),Wlt.forEach(t),ako=r(S8e," \u2014 "),fG=n(S8e,"A",{href:!0});var Qlt=s(fG);nko=r(Qlt,"PerceiverForSequenceClassification"),Qlt.forEach(t),sko=r(S8e," (Perceiver model)"),S8e.forEach(t),lko=i(D),i7=n(D,"LI",{});var R8e=s(i7);$fe=n(R8e,"STRONG",{});var Hlt=s($fe);iko=r(Hlt,"plbart"),Hlt.forEach(t),dko=r(R8e," \u2014 "),mG=n(R8e,"A",{href:!0});var Ult=s(mG);cko=r(Ult,"PLBartForSequenceClassification"),Ult.forEach(t),fko=r(R8e," (PLBart model)"),R8e.forEach(t),mko=i(D),d7=n(D,"LI",{});var P8e=s(d7);kfe=n(P8e,"STRONG",{});var Jlt=s(kfe);gko=r(Jlt,"qdqbert"),Jlt.forEach(t),hko=r(P8e," \u2014 "),gG=n(P8e,"A",{href:!0});var Ylt=s(gG);pko=r(Ylt,"QDQBertForSequenceClassification"),Ylt.forEach(t),_ko=r(P8e," (QDQBert model)"),P8e.forEach(t),uko=i(D),c7=n(D,"LI",{});var B8e=s(c7);Sfe=n(B8e,"STRONG",{});var Klt=s(Sfe);bko=r(Klt,"reformer"),Klt.forEach(t),vko=r(B8e," \u2014 "),hG=n(B8e,"A",{href:!0});var Zlt=s(hG);Fko=r(Zlt,"ReformerForSequenceClassification"),Zlt.forEach(t),Tko=r(B8e," (Reformer model)"),B8e.forEach(t),Mko=i(D),f7=n(D,"LI",{});var I8e=s(f7);Rfe=n(I8e,"STRONG",{});var eit=s(Rfe);Eko=r(eit,"rembert"),eit.forEach(t),Cko=r(I8e," \u2014 "),pG=n(I8e,"A",{href:!0});var oit=s(pG);wko=r(oit,"RemBertForSequenceClassification"),oit.forEach(t),Ako=r(I8e," (RemBERT model)"),I8e.forEach(t),yko=i(D),m7=n(D,"LI",{});var q8e=s(m7);Pfe=n(q8e,"STRONG",{});var rit=s(Pfe);Lko=r(rit,"roberta"),rit.forEach(t),xko=r(q8e," \u2014 "),_G=n(q8e,"A",{href:!0});var tit=s(_G);$ko=r(tit,"RobertaForSequenceClassification"),tit.forEach(t),kko=r(q8e," (RoBERTa model)"),q8e.forEach(t),Sko=i(D),g7=n(D,"LI",{});var N8e=s(g7);Bfe=n(N8e,"STRONG",{});var ait=s(Bfe);Rko=r(ait,"roformer"),ait.forEach(t),Pko=r(N8e," \u2014 "),uG=n(N8e,"A",{href:!0});var nit=s(uG);Bko=r(nit,"RoFormerForSequenceClassification"),nit.forEach(t),Iko=r(N8e," (RoFormer model)"),N8e.forEach(t),qko=i(D),h7=n(D,"LI",{});var j8e=s(h7);Ife=n(j8e,"STRONG",{});var sit=s(Ife);Nko=r(sit,"squeezebert"),sit.forEach(t),jko=r(j8e," \u2014 "),bG=n(j8e,"A",{href:!0});var lit=s(bG);Dko=r(lit,"SqueezeBertForSequenceClassification"),lit.forEach(t),Gko=r(j8e," (SqueezeBERT model)"),j8e.forEach(t),Oko=i(D),p7=n(D,"LI",{});var D8e=s(p7);qfe=n(D8e,"STRONG",{});var iit=s(qfe);Vko=r(iit,"tapas"),iit.forEach(t),Xko=r(D8e," \u2014 "),vG=n(D8e,"A",{href:!0});var dit=s(vG);zko=r(dit,"TapasForSequenceClassification"),dit.forEach(t),Wko=r(D8e," (TAPAS model)"),D8e.forEach(t),Qko=i(D),_7=n(D,"LI",{});var G8e=s(_7);Nfe=n(G8e,"STRONG",{});var cit=s(Nfe);Hko=r(cit,"transfo-xl"),cit.forEach(t),Uko=r(G8e," \u2014 "),FG=n(G8e,"A",{href:!0});var fit=s(FG);Jko=r(fit,"TransfoXLForSequenceClassification"),fit.forEach(t),Yko=r(G8e," (Transformer-XL model)"),G8e.forEach(t),Kko=i(D),u7=n(D,"LI",{});var O8e=s(u7);jfe=n(O8e,"STRONG",{});var mit=s(jfe);Zko=r(mit,"xlm"),mit.forEach(t),eSo=r(O8e," \u2014 "),TG=n(O8e,"A",{href:!0});var git=s(TG);oSo=r(git,"XLMForSequenceClassification"),git.forEach(t),rSo=r(O8e," (XLM model)"),O8e.forEach(t),tSo=i(D),b7=n(D,"LI",{});var V8e=s(b7);Dfe=n(V8e,"STRONG",{});var hit=s(Dfe);aSo=r(hit,"xlm-roberta"),hit.forEach(t),nSo=r(V8e," \u2014 "),MG=n(V8e,"A",{href:!0});var pit=s(MG);sSo=r(pit,"XLMRobertaForSequenceClassification"),pit.forEach(t),lSo=r(V8e," (XLM-RoBERTa model)"),V8e.forEach(t),iSo=i(D),v7=n(D,"LI",{});var X8e=s(v7);Gfe=n(X8e,"STRONG",{});var _it=s(Gfe);dSo=r(_it,"xlm-roberta-xl"),_it.forEach(t),cSo=r(X8e," \u2014 "),EG=n(X8e,"A",{href:!0});var uit=s(EG);fSo=r(uit,"XLMRobertaXLForSequenceClassification"),uit.forEach(t),mSo=r(X8e," (XLM-RoBERTa-XL model)"),X8e.forEach(t),gSo=i(D),F7=n(D,"LI",{});var z8e=s(F7);Ofe=n(z8e,"STRONG",{});var bit=s(Ofe);hSo=r(bit,"xlnet"),bit.forEach(t),pSo=r(z8e," \u2014 "),CG=n(z8e,"A",{href:!0});var vit=s(CG);_So=r(vit,"XLNetForSequenceClassification"),vit.forEach(t),uSo=r(z8e," (XLNet model)"),z8e.forEach(t),bSo=i(D),T7=n(D,"LI",{});var W8e=s(T7);Vfe=n(W8e,"STRONG",{});var Fit=s(Vfe);vSo=r(Fit,"yoso"),Fit.forEach(t),FSo=r(W8e," \u2014 "),wG=n(W8e,"A",{href:!0});var Tit=s(wG);TSo=r(Tit,"YosoForSequenceClassification"),Tit.forEach(t),MSo=r(W8e," (YOSO model)"),W8e.forEach(t),D.forEach(t),ESo=i(sa),M7=n(sa,"P",{});var Q8e=s(M7);CSo=r(Q8e,"The model is set in evaluation mode by default using "),Xfe=n(Q8e,"CODE",{});var Mit=s(Xfe);wSo=r(Mit,"model.eval()"),Mit.forEach(t),ASo=r(Q8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=n(Q8e,"CODE",{});var Eit=s(zfe);ySo=r(Eit,"model.train()"),Eit.forEach(t),Q8e.forEach(t),LSo=i(sa),T(E7.$$.fragment,sa),sa.forEach(t),zs.forEach(t),Fqe=i(f),Oi=n(f,"H2",{class:!0});var Cje=s(Oi);C7=n(Cje,"A",{id:!0,class:!0,href:!0});var Cit=s(C7);Wfe=n(Cit,"SPAN",{});var wit=s(Wfe);T(py.$$.fragment,wit),wit.forEach(t),Cit.forEach(t),xSo=i(Cje),Qfe=n(Cje,"SPAN",{});var Ait=s(Qfe);$So=r(Ait,"AutoModelForMultipleChoice"),Ait.forEach(t),Cje.forEach(t),Tqe=i(f),Po=n(f,"DIV",{class:!0});var Ws=s(Po);T(_y.$$.fragment,Ws),kSo=i(Ws),Vi=n(Ws,"P",{});var YK=s(Vi);SSo=r(YK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),AG=n(YK,"A",{href:!0});var yit=s(AG);RSo=r(yit,"from_pretrained()"),yit.forEach(t),PSo=r(YK," class method or the "),yG=n(YK,"A",{href:!0});var Lit=s(yG);BSo=r(Lit,"from_config()"),Lit.forEach(t),ISo=r(YK,` class
method.`),YK.forEach(t),qSo=i(Ws),uy=n(Ws,"P",{});var wje=s(uy);NSo=r(wje,"This class cannot be instantiated directly using "),Hfe=n(wje,"CODE",{});var xit=s(Hfe);jSo=r(xit,"__init__()"),xit.forEach(t),DSo=r(wje," (throws an error)."),wje.forEach(t),GSo=i(Ws),dt=n(Ws,"DIV",{class:!0});var x0=s(dt);T(by.$$.fragment,x0),OSo=i(x0),Ufe=n(x0,"P",{});var $it=s(Ufe);VSo=r($it,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$it.forEach(t),XSo=i(x0),Xi=n(x0,"P",{});var KK=s(Xi);zSo=r(KK,`Note:
Loading a model from its configuration file does `),Jfe=n(KK,"STRONG",{});var kit=s(Jfe);WSo=r(kit,"not"),kit.forEach(t),QSo=r(KK,` load the model weights. It only affects the
model\u2019s configuration. Use `),LG=n(KK,"A",{href:!0});var Sit=s(LG);HSo=r(Sit,"from_pretrained()"),Sit.forEach(t),USo=r(KK," to load the model weights."),KK.forEach(t),JSo=i(x0),T(w7.$$.fragment,x0),x0.forEach(t),YSo=i(Ws),ro=n(Ws,"DIV",{class:!0});var la=s(ro);T(vy.$$.fragment,la),KSo=i(la),Yfe=n(la,"P",{});var Rit=s(Yfe);ZSo=r(Rit,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Rit.forEach(t),eRo=i(la),Pa=n(la,"P",{});var $0=s(Pa);oRo=r($0,"The model class to instantiate is selected based on the "),Kfe=n($0,"CODE",{});var Pit=s(Kfe);rRo=r(Pit,"model_type"),Pit.forEach(t),tRo=r($0,` property of the config object (either
passed as an argument or loaded from `),Zfe=n($0,"CODE",{});var Bit=s(Zfe);aRo=r(Bit,"pretrained_model_name_or_path"),Bit.forEach(t),nRo=r($0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eme=n($0,"CODE",{});var Iit=s(eme);sRo=r(Iit,"pretrained_model_name_or_path"),Iit.forEach(t),lRo=r($0,":"),$0.forEach(t),iRo=i(la),Y=n(la,"UL",{});var K=s(Y);A7=n(K,"LI",{});var H8e=s(A7);ome=n(H8e,"STRONG",{});var qit=s(ome);dRo=r(qit,"albert"),qit.forEach(t),cRo=r(H8e," \u2014 "),xG=n(H8e,"A",{href:!0});var Nit=s(xG);fRo=r(Nit,"AlbertForMultipleChoice"),Nit.forEach(t),mRo=r(H8e," (ALBERT model)"),H8e.forEach(t),gRo=i(K),y7=n(K,"LI",{});var U8e=s(y7);rme=n(U8e,"STRONG",{});var jit=s(rme);hRo=r(jit,"bert"),jit.forEach(t),pRo=r(U8e," \u2014 "),$G=n(U8e,"A",{href:!0});var Dit=s($G);_Ro=r(Dit,"BertForMultipleChoice"),Dit.forEach(t),uRo=r(U8e," (BERT model)"),U8e.forEach(t),bRo=i(K),L7=n(K,"LI",{});var J8e=s(L7);tme=n(J8e,"STRONG",{});var Git=s(tme);vRo=r(Git,"big_bird"),Git.forEach(t),FRo=r(J8e," \u2014 "),kG=n(J8e,"A",{href:!0});var Oit=s(kG);TRo=r(Oit,"BigBirdForMultipleChoice"),Oit.forEach(t),MRo=r(J8e," (BigBird model)"),J8e.forEach(t),ERo=i(K),x7=n(K,"LI",{});var Y8e=s(x7);ame=n(Y8e,"STRONG",{});var Vit=s(ame);CRo=r(Vit,"camembert"),Vit.forEach(t),wRo=r(Y8e," \u2014 "),SG=n(Y8e,"A",{href:!0});var Xit=s(SG);ARo=r(Xit,"CamembertForMultipleChoice"),Xit.forEach(t),yRo=r(Y8e," (CamemBERT model)"),Y8e.forEach(t),LRo=i(K),$7=n(K,"LI",{});var K8e=s($7);nme=n(K8e,"STRONG",{});var zit=s(nme);xRo=r(zit,"canine"),zit.forEach(t),$Ro=r(K8e," \u2014 "),RG=n(K8e,"A",{href:!0});var Wit=s(RG);kRo=r(Wit,"CanineForMultipleChoice"),Wit.forEach(t),SRo=r(K8e," (Canine model)"),K8e.forEach(t),RRo=i(K),k7=n(K,"LI",{});var Z8e=s(k7);sme=n(Z8e,"STRONG",{});var Qit=s(sme);PRo=r(Qit,"convbert"),Qit.forEach(t),BRo=r(Z8e," \u2014 "),PG=n(Z8e,"A",{href:!0});var Hit=s(PG);IRo=r(Hit,"ConvBertForMultipleChoice"),Hit.forEach(t),qRo=r(Z8e," (ConvBERT model)"),Z8e.forEach(t),NRo=i(K),S7=n(K,"LI",{});var exe=s(S7);lme=n(exe,"STRONG",{});var Uit=s(lme);jRo=r(Uit,"data2vec-text"),Uit.forEach(t),DRo=r(exe," \u2014 "),BG=n(exe,"A",{href:!0});var Jit=s(BG);GRo=r(Jit,"Data2VecTextForMultipleChoice"),Jit.forEach(t),ORo=r(exe," (Data2VecText model)"),exe.forEach(t),VRo=i(K),R7=n(K,"LI",{});var oxe=s(R7);ime=n(oxe,"STRONG",{});var Yit=s(ime);XRo=r(Yit,"deberta-v2"),Yit.forEach(t),zRo=r(oxe," \u2014 "),IG=n(oxe,"A",{href:!0});var Kit=s(IG);WRo=r(Kit,"DebertaV2ForMultipleChoice"),Kit.forEach(t),QRo=r(oxe," (DeBERTa-v2 model)"),oxe.forEach(t),HRo=i(K),P7=n(K,"LI",{});var rxe=s(P7);dme=n(rxe,"STRONG",{});var Zit=s(dme);URo=r(Zit,"distilbert"),Zit.forEach(t),JRo=r(rxe," \u2014 "),qG=n(rxe,"A",{href:!0});var edt=s(qG);YRo=r(edt,"DistilBertForMultipleChoice"),edt.forEach(t),KRo=r(rxe," (DistilBERT model)"),rxe.forEach(t),ZRo=i(K),B7=n(K,"LI",{});var txe=s(B7);cme=n(txe,"STRONG",{});var odt=s(cme);ePo=r(odt,"electra"),odt.forEach(t),oPo=r(txe," \u2014 "),NG=n(txe,"A",{href:!0});var rdt=s(NG);rPo=r(rdt,"ElectraForMultipleChoice"),rdt.forEach(t),tPo=r(txe," (ELECTRA model)"),txe.forEach(t),aPo=i(K),I7=n(K,"LI",{});var axe=s(I7);fme=n(axe,"STRONG",{});var tdt=s(fme);nPo=r(tdt,"flaubert"),tdt.forEach(t),sPo=r(axe," \u2014 "),jG=n(axe,"A",{href:!0});var adt=s(jG);lPo=r(adt,"FlaubertForMultipleChoice"),adt.forEach(t),iPo=r(axe," (FlauBERT model)"),axe.forEach(t),dPo=i(K),q7=n(K,"LI",{});var nxe=s(q7);mme=n(nxe,"STRONG",{});var ndt=s(mme);cPo=r(ndt,"fnet"),ndt.forEach(t),fPo=r(nxe," \u2014 "),DG=n(nxe,"A",{href:!0});var sdt=s(DG);mPo=r(sdt,"FNetForMultipleChoice"),sdt.forEach(t),gPo=r(nxe," (FNet model)"),nxe.forEach(t),hPo=i(K),N7=n(K,"LI",{});var sxe=s(N7);gme=n(sxe,"STRONG",{});var ldt=s(gme);pPo=r(ldt,"funnel"),ldt.forEach(t),_Po=r(sxe," \u2014 "),GG=n(sxe,"A",{href:!0});var idt=s(GG);uPo=r(idt,"FunnelForMultipleChoice"),idt.forEach(t),bPo=r(sxe," (Funnel Transformer model)"),sxe.forEach(t),vPo=i(K),j7=n(K,"LI",{});var lxe=s(j7);hme=n(lxe,"STRONG",{});var ddt=s(hme);FPo=r(ddt,"ibert"),ddt.forEach(t),TPo=r(lxe," \u2014 "),OG=n(lxe,"A",{href:!0});var cdt=s(OG);MPo=r(cdt,"IBertForMultipleChoice"),cdt.forEach(t),EPo=r(lxe," (I-BERT model)"),lxe.forEach(t),CPo=i(K),D7=n(K,"LI",{});var ixe=s(D7);pme=n(ixe,"STRONG",{});var fdt=s(pme);wPo=r(fdt,"longformer"),fdt.forEach(t),APo=r(ixe," \u2014 "),VG=n(ixe,"A",{href:!0});var mdt=s(VG);yPo=r(mdt,"LongformerForMultipleChoice"),mdt.forEach(t),LPo=r(ixe," (Longformer model)"),ixe.forEach(t),xPo=i(K),G7=n(K,"LI",{});var dxe=s(G7);_me=n(dxe,"STRONG",{});var gdt=s(_me);$Po=r(gdt,"megatron-bert"),gdt.forEach(t),kPo=r(dxe," \u2014 "),XG=n(dxe,"A",{href:!0});var hdt=s(XG);SPo=r(hdt,"MegatronBertForMultipleChoice"),hdt.forEach(t),RPo=r(dxe," (MegatronBert model)"),dxe.forEach(t),PPo=i(K),O7=n(K,"LI",{});var cxe=s(O7);ume=n(cxe,"STRONG",{});var pdt=s(ume);BPo=r(pdt,"mobilebert"),pdt.forEach(t),IPo=r(cxe," \u2014 "),zG=n(cxe,"A",{href:!0});var _dt=s(zG);qPo=r(_dt,"MobileBertForMultipleChoice"),_dt.forEach(t),NPo=r(cxe," (MobileBERT model)"),cxe.forEach(t),jPo=i(K),V7=n(K,"LI",{});var fxe=s(V7);bme=n(fxe,"STRONG",{});var udt=s(bme);DPo=r(udt,"mpnet"),udt.forEach(t),GPo=r(fxe," \u2014 "),WG=n(fxe,"A",{href:!0});var bdt=s(WG);OPo=r(bdt,"MPNetForMultipleChoice"),bdt.forEach(t),VPo=r(fxe," (MPNet model)"),fxe.forEach(t),XPo=i(K),X7=n(K,"LI",{});var mxe=s(X7);vme=n(mxe,"STRONG",{});var vdt=s(vme);zPo=r(vdt,"nystromformer"),vdt.forEach(t),WPo=r(mxe," \u2014 "),QG=n(mxe,"A",{href:!0});var Fdt=s(QG);QPo=r(Fdt,"NystromformerForMultipleChoice"),Fdt.forEach(t),HPo=r(mxe," (Nystromformer model)"),mxe.forEach(t),UPo=i(K),z7=n(K,"LI",{});var gxe=s(z7);Fme=n(gxe,"STRONG",{});var Tdt=s(Fme);JPo=r(Tdt,"qdqbert"),Tdt.forEach(t),YPo=r(gxe," \u2014 "),HG=n(gxe,"A",{href:!0});var Mdt=s(HG);KPo=r(Mdt,"QDQBertForMultipleChoice"),Mdt.forEach(t),ZPo=r(gxe," (QDQBert model)"),gxe.forEach(t),eBo=i(K),W7=n(K,"LI",{});var hxe=s(W7);Tme=n(hxe,"STRONG",{});var Edt=s(Tme);oBo=r(Edt,"rembert"),Edt.forEach(t),rBo=r(hxe," \u2014 "),UG=n(hxe,"A",{href:!0});var Cdt=s(UG);tBo=r(Cdt,"RemBertForMultipleChoice"),Cdt.forEach(t),aBo=r(hxe," (RemBERT model)"),hxe.forEach(t),nBo=i(K),Q7=n(K,"LI",{});var pxe=s(Q7);Mme=n(pxe,"STRONG",{});var wdt=s(Mme);sBo=r(wdt,"roberta"),wdt.forEach(t),lBo=r(pxe," \u2014 "),JG=n(pxe,"A",{href:!0});var Adt=s(JG);iBo=r(Adt,"RobertaForMultipleChoice"),Adt.forEach(t),dBo=r(pxe," (RoBERTa model)"),pxe.forEach(t),cBo=i(K),H7=n(K,"LI",{});var _xe=s(H7);Eme=n(_xe,"STRONG",{});var ydt=s(Eme);fBo=r(ydt,"roformer"),ydt.forEach(t),mBo=r(_xe," \u2014 "),YG=n(_xe,"A",{href:!0});var Ldt=s(YG);gBo=r(Ldt,"RoFormerForMultipleChoice"),Ldt.forEach(t),hBo=r(_xe," (RoFormer model)"),_xe.forEach(t),pBo=i(K),U7=n(K,"LI",{});var uxe=s(U7);Cme=n(uxe,"STRONG",{});var xdt=s(Cme);_Bo=r(xdt,"squeezebert"),xdt.forEach(t),uBo=r(uxe," \u2014 "),KG=n(uxe,"A",{href:!0});var $dt=s(KG);bBo=r($dt,"SqueezeBertForMultipleChoice"),$dt.forEach(t),vBo=r(uxe," (SqueezeBERT model)"),uxe.forEach(t),FBo=i(K),J7=n(K,"LI",{});var bxe=s(J7);wme=n(bxe,"STRONG",{});var kdt=s(wme);TBo=r(kdt,"xlm"),kdt.forEach(t),MBo=r(bxe," \u2014 "),ZG=n(bxe,"A",{href:!0});var Sdt=s(ZG);EBo=r(Sdt,"XLMForMultipleChoice"),Sdt.forEach(t),CBo=r(bxe," (XLM model)"),bxe.forEach(t),wBo=i(K),Y7=n(K,"LI",{});var vxe=s(Y7);Ame=n(vxe,"STRONG",{});var Rdt=s(Ame);ABo=r(Rdt,"xlm-roberta"),Rdt.forEach(t),yBo=r(vxe," \u2014 "),eO=n(vxe,"A",{href:!0});var Pdt=s(eO);LBo=r(Pdt,"XLMRobertaForMultipleChoice"),Pdt.forEach(t),xBo=r(vxe," (XLM-RoBERTa model)"),vxe.forEach(t),$Bo=i(K),K7=n(K,"LI",{});var Fxe=s(K7);yme=n(Fxe,"STRONG",{});var Bdt=s(yme);kBo=r(Bdt,"xlm-roberta-xl"),Bdt.forEach(t),SBo=r(Fxe," \u2014 "),oO=n(Fxe,"A",{href:!0});var Idt=s(oO);RBo=r(Idt,"XLMRobertaXLForMultipleChoice"),Idt.forEach(t),PBo=r(Fxe," (XLM-RoBERTa-XL model)"),Fxe.forEach(t),BBo=i(K),Z7=n(K,"LI",{});var Txe=s(Z7);Lme=n(Txe,"STRONG",{});var qdt=s(Lme);IBo=r(qdt,"xlnet"),qdt.forEach(t),qBo=r(Txe," \u2014 "),rO=n(Txe,"A",{href:!0});var Ndt=s(rO);NBo=r(Ndt,"XLNetForMultipleChoice"),Ndt.forEach(t),jBo=r(Txe," (XLNet model)"),Txe.forEach(t),DBo=i(K),eb=n(K,"LI",{});var Mxe=s(eb);xme=n(Mxe,"STRONG",{});var jdt=s(xme);GBo=r(jdt,"yoso"),jdt.forEach(t),OBo=r(Mxe," \u2014 "),tO=n(Mxe,"A",{href:!0});var Ddt=s(tO);VBo=r(Ddt,"YosoForMultipleChoice"),Ddt.forEach(t),XBo=r(Mxe," (YOSO model)"),Mxe.forEach(t),K.forEach(t),zBo=i(la),ob=n(la,"P",{});var Exe=s(ob);WBo=r(Exe,"The model is set in evaluation mode by default using "),$me=n(Exe,"CODE",{});var Gdt=s($me);QBo=r(Gdt,"model.eval()"),Gdt.forEach(t),HBo=r(Exe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kme=n(Exe,"CODE",{});var Odt=s(kme);UBo=r(Odt,"model.train()"),Odt.forEach(t),Exe.forEach(t),JBo=i(la),T(rb.$$.fragment,la),la.forEach(t),Ws.forEach(t),Mqe=i(f),zi=n(f,"H2",{class:!0});var Aje=s(zi);tb=n(Aje,"A",{id:!0,class:!0,href:!0});var Vdt=s(tb);Sme=n(Vdt,"SPAN",{});var Xdt=s(Sme);T(Fy.$$.fragment,Xdt),Xdt.forEach(t),Vdt.forEach(t),YBo=i(Aje),Rme=n(Aje,"SPAN",{});var zdt=s(Rme);KBo=r(zdt,"AutoModelForNextSentencePrediction"),zdt.forEach(t),Aje.forEach(t),Eqe=i(f),Bo=n(f,"DIV",{class:!0});var Qs=s(Bo);T(Ty.$$.fragment,Qs),ZBo=i(Qs),Wi=n(Qs,"P",{});var ZK=s(Wi);eIo=r(ZK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),aO=n(ZK,"A",{href:!0});var Wdt=s(aO);oIo=r(Wdt,"from_pretrained()"),Wdt.forEach(t),rIo=r(ZK," class method or the "),nO=n(ZK,"A",{href:!0});var Qdt=s(nO);tIo=r(Qdt,"from_config()"),Qdt.forEach(t),aIo=r(ZK,` class
method.`),ZK.forEach(t),nIo=i(Qs),My=n(Qs,"P",{});var yje=s(My);sIo=r(yje,"This class cannot be instantiated directly using "),Pme=n(yje,"CODE",{});var Hdt=s(Pme);lIo=r(Hdt,"__init__()"),Hdt.forEach(t),iIo=r(yje," (throws an error)."),yje.forEach(t),dIo=i(Qs),ct=n(Qs,"DIV",{class:!0});var k0=s(ct);T(Ey.$$.fragment,k0),cIo=i(k0),Bme=n(k0,"P",{});var Udt=s(Bme);fIo=r(Udt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Udt.forEach(t),mIo=i(k0),Qi=n(k0,"P",{});var eZ=s(Qi);gIo=r(eZ,`Note:
Loading a model from its configuration file does `),Ime=n(eZ,"STRONG",{});var Jdt=s(Ime);hIo=r(Jdt,"not"),Jdt.forEach(t),pIo=r(eZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),sO=n(eZ,"A",{href:!0});var Ydt=s(sO);_Io=r(Ydt,"from_pretrained()"),Ydt.forEach(t),uIo=r(eZ," to load the model weights."),eZ.forEach(t),bIo=i(k0),T(ab.$$.fragment,k0),k0.forEach(t),vIo=i(Qs),to=n(Qs,"DIV",{class:!0});var ia=s(to);T(Cy.$$.fragment,ia),FIo=i(ia),qme=n(ia,"P",{});var Kdt=s(qme);TIo=r(Kdt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Kdt.forEach(t),MIo=i(ia),Ba=n(ia,"P",{});var S0=s(Ba);EIo=r(S0,"The model class to instantiate is selected based on the "),Nme=n(S0,"CODE",{});var Zdt=s(Nme);CIo=r(Zdt,"model_type"),Zdt.forEach(t),wIo=r(S0,` property of the config object (either
passed as an argument or loaded from `),jme=n(S0,"CODE",{});var ect=s(jme);AIo=r(ect,"pretrained_model_name_or_path"),ect.forEach(t),yIo=r(S0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dme=n(S0,"CODE",{});var oct=s(Dme);LIo=r(oct,"pretrained_model_name_or_path"),oct.forEach(t),xIo=r(S0,":"),S0.forEach(t),$Io=i(ia),Yr=n(ia,"UL",{});var Hs=s(Yr);nb=n(Hs,"LI",{});var Cxe=s(nb);Gme=n(Cxe,"STRONG",{});var rct=s(Gme);kIo=r(rct,"bert"),rct.forEach(t),SIo=r(Cxe," \u2014 "),lO=n(Cxe,"A",{href:!0});var tct=s(lO);RIo=r(tct,"BertForNextSentencePrediction"),tct.forEach(t),PIo=r(Cxe," (BERT model)"),Cxe.forEach(t),BIo=i(Hs),sb=n(Hs,"LI",{});var wxe=s(sb);Ome=n(wxe,"STRONG",{});var act=s(Ome);IIo=r(act,"fnet"),act.forEach(t),qIo=r(wxe," \u2014 "),iO=n(wxe,"A",{href:!0});var nct=s(iO);NIo=r(nct,"FNetForNextSentencePrediction"),nct.forEach(t),jIo=r(wxe," (FNet model)"),wxe.forEach(t),DIo=i(Hs),lb=n(Hs,"LI",{});var Axe=s(lb);Vme=n(Axe,"STRONG",{});var sct=s(Vme);GIo=r(sct,"megatron-bert"),sct.forEach(t),OIo=r(Axe," \u2014 "),dO=n(Axe,"A",{href:!0});var lct=s(dO);VIo=r(lct,"MegatronBertForNextSentencePrediction"),lct.forEach(t),XIo=r(Axe," (MegatronBert model)"),Axe.forEach(t),zIo=i(Hs),ib=n(Hs,"LI",{});var yxe=s(ib);Xme=n(yxe,"STRONG",{});var ict=s(Xme);WIo=r(ict,"mobilebert"),ict.forEach(t),QIo=r(yxe," \u2014 "),cO=n(yxe,"A",{href:!0});var dct=s(cO);HIo=r(dct,"MobileBertForNextSentencePrediction"),dct.forEach(t),UIo=r(yxe," (MobileBERT model)"),yxe.forEach(t),JIo=i(Hs),db=n(Hs,"LI",{});var Lxe=s(db);zme=n(Lxe,"STRONG",{});var cct=s(zme);YIo=r(cct,"qdqbert"),cct.forEach(t),KIo=r(Lxe," \u2014 "),fO=n(Lxe,"A",{href:!0});var fct=s(fO);ZIo=r(fct,"QDQBertForNextSentencePrediction"),fct.forEach(t),eqo=r(Lxe," (QDQBert model)"),Lxe.forEach(t),Hs.forEach(t),oqo=i(ia),cb=n(ia,"P",{});var xxe=s(cb);rqo=r(xxe,"The model is set in evaluation mode by default using "),Wme=n(xxe,"CODE",{});var mct=s(Wme);tqo=r(mct,"model.eval()"),mct.forEach(t),aqo=r(xxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qme=n(xxe,"CODE",{});var gct=s(Qme);nqo=r(gct,"model.train()"),gct.forEach(t),xxe.forEach(t),sqo=i(ia),T(fb.$$.fragment,ia),ia.forEach(t),Qs.forEach(t),Cqe=i(f),Hi=n(f,"H2",{class:!0});var Lje=s(Hi);mb=n(Lje,"A",{id:!0,class:!0,href:!0});var hct=s(mb);Hme=n(hct,"SPAN",{});var pct=s(Hme);T(wy.$$.fragment,pct),pct.forEach(t),hct.forEach(t),lqo=i(Lje),Ume=n(Lje,"SPAN",{});var _ct=s(Ume);iqo=r(_ct,"AutoModelForTokenClassification"),_ct.forEach(t),Lje.forEach(t),wqe=i(f),Io=n(f,"DIV",{class:!0});var Us=s(Io);T(Ay.$$.fragment,Us),dqo=i(Us),Ui=n(Us,"P",{});var oZ=s(Ui);cqo=r(oZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mO=n(oZ,"A",{href:!0});var uct=s(mO);fqo=r(uct,"from_pretrained()"),uct.forEach(t),mqo=r(oZ," class method or the "),gO=n(oZ,"A",{href:!0});var bct=s(gO);gqo=r(bct,"from_config()"),bct.forEach(t),hqo=r(oZ,` class
method.`),oZ.forEach(t),pqo=i(Us),yy=n(Us,"P",{});var xje=s(yy);_qo=r(xje,"This class cannot be instantiated directly using "),Jme=n(xje,"CODE",{});var vct=s(Jme);uqo=r(vct,"__init__()"),vct.forEach(t),bqo=r(xje," (throws an error)."),xje.forEach(t),vqo=i(Us),ft=n(Us,"DIV",{class:!0});var R0=s(ft);T(Ly.$$.fragment,R0),Fqo=i(R0),Yme=n(R0,"P",{});var Fct=s(Yme);Tqo=r(Fct,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Fct.forEach(t),Mqo=i(R0),Ji=n(R0,"P",{});var rZ=s(Ji);Eqo=r(rZ,`Note:
Loading a model from its configuration file does `),Kme=n(rZ,"STRONG",{});var Tct=s(Kme);Cqo=r(Tct,"not"),Tct.forEach(t),wqo=r(rZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=n(rZ,"A",{href:!0});var Mct=s(hO);Aqo=r(Mct,"from_pretrained()"),Mct.forEach(t),yqo=r(rZ," to load the model weights."),rZ.forEach(t),Lqo=i(R0),T(gb.$$.fragment,R0),R0.forEach(t),xqo=i(Us),ao=n(Us,"DIV",{class:!0});var da=s(ao);T(xy.$$.fragment,da),$qo=i(da),Zme=n(da,"P",{});var Ect=s(Zme);kqo=r(Ect,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ect.forEach(t),Sqo=i(da),Ia=n(da,"P",{});var P0=s(Ia);Rqo=r(P0,"The model class to instantiate is selected based on the "),ege=n(P0,"CODE",{});var Cct=s(ege);Pqo=r(Cct,"model_type"),Cct.forEach(t),Bqo=r(P0,` property of the config object (either
passed as an argument or loaded from `),oge=n(P0,"CODE",{});var wct=s(oge);Iqo=r(wct,"pretrained_model_name_or_path"),wct.forEach(t),qqo=r(P0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rge=n(P0,"CODE",{});var Act=s(rge);Nqo=r(Act,"pretrained_model_name_or_path"),Act.forEach(t),jqo=r(P0,":"),P0.forEach(t),Dqo=i(da),U=n(da,"UL",{});var J=s(U);hb=n(J,"LI",{});var $xe=s(hb);tge=n($xe,"STRONG",{});var yct=s(tge);Gqo=r(yct,"albert"),yct.forEach(t),Oqo=r($xe," \u2014 "),pO=n($xe,"A",{href:!0});var Lct=s(pO);Vqo=r(Lct,"AlbertForTokenClassification"),Lct.forEach(t),Xqo=r($xe," (ALBERT model)"),$xe.forEach(t),zqo=i(J),pb=n(J,"LI",{});var kxe=s(pb);age=n(kxe,"STRONG",{});var xct=s(age);Wqo=r(xct,"bert"),xct.forEach(t),Qqo=r(kxe," \u2014 "),_O=n(kxe,"A",{href:!0});var $ct=s(_O);Hqo=r($ct,"BertForTokenClassification"),$ct.forEach(t),Uqo=r(kxe," (BERT model)"),kxe.forEach(t),Jqo=i(J),_b=n(J,"LI",{});var Sxe=s(_b);nge=n(Sxe,"STRONG",{});var kct=s(nge);Yqo=r(kct,"big_bird"),kct.forEach(t),Kqo=r(Sxe," \u2014 "),uO=n(Sxe,"A",{href:!0});var Sct=s(uO);Zqo=r(Sct,"BigBirdForTokenClassification"),Sct.forEach(t),eNo=r(Sxe," (BigBird model)"),Sxe.forEach(t),oNo=i(J),ub=n(J,"LI",{});var Rxe=s(ub);sge=n(Rxe,"STRONG",{});var Rct=s(sge);rNo=r(Rct,"camembert"),Rct.forEach(t),tNo=r(Rxe," \u2014 "),bO=n(Rxe,"A",{href:!0});var Pct=s(bO);aNo=r(Pct,"CamembertForTokenClassification"),Pct.forEach(t),nNo=r(Rxe," (CamemBERT model)"),Rxe.forEach(t),sNo=i(J),bb=n(J,"LI",{});var Pxe=s(bb);lge=n(Pxe,"STRONG",{});var Bct=s(lge);lNo=r(Bct,"canine"),Bct.forEach(t),iNo=r(Pxe," \u2014 "),vO=n(Pxe,"A",{href:!0});var Ict=s(vO);dNo=r(Ict,"CanineForTokenClassification"),Ict.forEach(t),cNo=r(Pxe," (Canine model)"),Pxe.forEach(t),fNo=i(J),vb=n(J,"LI",{});var Bxe=s(vb);ige=n(Bxe,"STRONG",{});var qct=s(ige);mNo=r(qct,"convbert"),qct.forEach(t),gNo=r(Bxe," \u2014 "),FO=n(Bxe,"A",{href:!0});var Nct=s(FO);hNo=r(Nct,"ConvBertForTokenClassification"),Nct.forEach(t),pNo=r(Bxe," (ConvBERT model)"),Bxe.forEach(t),_No=i(J),Fb=n(J,"LI",{});var Ixe=s(Fb);dge=n(Ixe,"STRONG",{});var jct=s(dge);uNo=r(jct,"data2vec-text"),jct.forEach(t),bNo=r(Ixe," \u2014 "),TO=n(Ixe,"A",{href:!0});var Dct=s(TO);vNo=r(Dct,"Data2VecTextForTokenClassification"),Dct.forEach(t),FNo=r(Ixe," (Data2VecText model)"),Ixe.forEach(t),TNo=i(J),Tb=n(J,"LI",{});var qxe=s(Tb);cge=n(qxe,"STRONG",{});var Gct=s(cge);MNo=r(Gct,"deberta"),Gct.forEach(t),ENo=r(qxe," \u2014 "),MO=n(qxe,"A",{href:!0});var Oct=s(MO);CNo=r(Oct,"DebertaForTokenClassification"),Oct.forEach(t),wNo=r(qxe," (DeBERTa model)"),qxe.forEach(t),ANo=i(J),Mb=n(J,"LI",{});var Nxe=s(Mb);fge=n(Nxe,"STRONG",{});var Vct=s(fge);yNo=r(Vct,"deberta-v2"),Vct.forEach(t),LNo=r(Nxe," \u2014 "),EO=n(Nxe,"A",{href:!0});var Xct=s(EO);xNo=r(Xct,"DebertaV2ForTokenClassification"),Xct.forEach(t),$No=r(Nxe," (DeBERTa-v2 model)"),Nxe.forEach(t),kNo=i(J),Eb=n(J,"LI",{});var jxe=s(Eb);mge=n(jxe,"STRONG",{});var zct=s(mge);SNo=r(zct,"distilbert"),zct.forEach(t),RNo=r(jxe," \u2014 "),CO=n(jxe,"A",{href:!0});var Wct=s(CO);PNo=r(Wct,"DistilBertForTokenClassification"),Wct.forEach(t),BNo=r(jxe," (DistilBERT model)"),jxe.forEach(t),INo=i(J),Cb=n(J,"LI",{});var Dxe=s(Cb);gge=n(Dxe,"STRONG",{});var Qct=s(gge);qNo=r(Qct,"electra"),Qct.forEach(t),NNo=r(Dxe," \u2014 "),wO=n(Dxe,"A",{href:!0});var Hct=s(wO);jNo=r(Hct,"ElectraForTokenClassification"),Hct.forEach(t),DNo=r(Dxe," (ELECTRA model)"),Dxe.forEach(t),GNo=i(J),wb=n(J,"LI",{});var Gxe=s(wb);hge=n(Gxe,"STRONG",{});var Uct=s(hge);ONo=r(Uct,"flaubert"),Uct.forEach(t),VNo=r(Gxe," \u2014 "),AO=n(Gxe,"A",{href:!0});var Jct=s(AO);XNo=r(Jct,"FlaubertForTokenClassification"),Jct.forEach(t),zNo=r(Gxe," (FlauBERT model)"),Gxe.forEach(t),WNo=i(J),Ab=n(J,"LI",{});var Oxe=s(Ab);pge=n(Oxe,"STRONG",{});var Yct=s(pge);QNo=r(Yct,"fnet"),Yct.forEach(t),HNo=r(Oxe," \u2014 "),yO=n(Oxe,"A",{href:!0});var Kct=s(yO);UNo=r(Kct,"FNetForTokenClassification"),Kct.forEach(t),JNo=r(Oxe," (FNet model)"),Oxe.forEach(t),YNo=i(J),yb=n(J,"LI",{});var Vxe=s(yb);_ge=n(Vxe,"STRONG",{});var Zct=s(_ge);KNo=r(Zct,"funnel"),Zct.forEach(t),ZNo=r(Vxe," \u2014 "),LO=n(Vxe,"A",{href:!0});var eft=s(LO);ejo=r(eft,"FunnelForTokenClassification"),eft.forEach(t),ojo=r(Vxe," (Funnel Transformer model)"),Vxe.forEach(t),rjo=i(J),Lb=n(J,"LI",{});var Xxe=s(Lb);uge=n(Xxe,"STRONG",{});var oft=s(uge);tjo=r(oft,"gpt2"),oft.forEach(t),ajo=r(Xxe," \u2014 "),xO=n(Xxe,"A",{href:!0});var rft=s(xO);njo=r(rft,"GPT2ForTokenClassification"),rft.forEach(t),sjo=r(Xxe," (OpenAI GPT-2 model)"),Xxe.forEach(t),ljo=i(J),xb=n(J,"LI",{});var zxe=s(xb);bge=n(zxe,"STRONG",{});var tft=s(bge);ijo=r(tft,"ibert"),tft.forEach(t),djo=r(zxe," \u2014 "),$O=n(zxe,"A",{href:!0});var aft=s($O);cjo=r(aft,"IBertForTokenClassification"),aft.forEach(t),fjo=r(zxe," (I-BERT model)"),zxe.forEach(t),mjo=i(J),$b=n(J,"LI",{});var Wxe=s($b);vge=n(Wxe,"STRONG",{});var nft=s(vge);gjo=r(nft,"layoutlm"),nft.forEach(t),hjo=r(Wxe," \u2014 "),kO=n(Wxe,"A",{href:!0});var sft=s(kO);pjo=r(sft,"LayoutLMForTokenClassification"),sft.forEach(t),_jo=r(Wxe," (LayoutLM model)"),Wxe.forEach(t),ujo=i(J),kb=n(J,"LI",{});var Qxe=s(kb);Fge=n(Qxe,"STRONG",{});var lft=s(Fge);bjo=r(lft,"layoutlmv2"),lft.forEach(t),vjo=r(Qxe," \u2014 "),SO=n(Qxe,"A",{href:!0});var ift=s(SO);Fjo=r(ift,"LayoutLMv2ForTokenClassification"),ift.forEach(t),Tjo=r(Qxe," (LayoutLMv2 model)"),Qxe.forEach(t),Mjo=i(J),Sb=n(J,"LI",{});var Hxe=s(Sb);Tge=n(Hxe,"STRONG",{});var dft=s(Tge);Ejo=r(dft,"longformer"),dft.forEach(t),Cjo=r(Hxe," \u2014 "),RO=n(Hxe,"A",{href:!0});var cft=s(RO);wjo=r(cft,"LongformerForTokenClassification"),cft.forEach(t),Ajo=r(Hxe," (Longformer model)"),Hxe.forEach(t),yjo=i(J),Rb=n(J,"LI",{});var Uxe=s(Rb);Mge=n(Uxe,"STRONG",{});var fft=s(Mge);Ljo=r(fft,"megatron-bert"),fft.forEach(t),xjo=r(Uxe," \u2014 "),PO=n(Uxe,"A",{href:!0});var mft=s(PO);$jo=r(mft,"MegatronBertForTokenClassification"),mft.forEach(t),kjo=r(Uxe," (MegatronBert model)"),Uxe.forEach(t),Sjo=i(J),Pb=n(J,"LI",{});var Jxe=s(Pb);Ege=n(Jxe,"STRONG",{});var gft=s(Ege);Rjo=r(gft,"mobilebert"),gft.forEach(t),Pjo=r(Jxe," \u2014 "),BO=n(Jxe,"A",{href:!0});var hft=s(BO);Bjo=r(hft,"MobileBertForTokenClassification"),hft.forEach(t),Ijo=r(Jxe," (MobileBERT model)"),Jxe.forEach(t),qjo=i(J),Bb=n(J,"LI",{});var Yxe=s(Bb);Cge=n(Yxe,"STRONG",{});var pft=s(Cge);Njo=r(pft,"mpnet"),pft.forEach(t),jjo=r(Yxe," \u2014 "),IO=n(Yxe,"A",{href:!0});var _ft=s(IO);Djo=r(_ft,"MPNetForTokenClassification"),_ft.forEach(t),Gjo=r(Yxe," (MPNet model)"),Yxe.forEach(t),Ojo=i(J),Ib=n(J,"LI",{});var Kxe=s(Ib);wge=n(Kxe,"STRONG",{});var uft=s(wge);Vjo=r(uft,"nystromformer"),uft.forEach(t),Xjo=r(Kxe," \u2014 "),qO=n(Kxe,"A",{href:!0});var bft=s(qO);zjo=r(bft,"NystromformerForTokenClassification"),bft.forEach(t),Wjo=r(Kxe," (Nystromformer model)"),Kxe.forEach(t),Qjo=i(J),qb=n(J,"LI",{});var Zxe=s(qb);Age=n(Zxe,"STRONG",{});var vft=s(Age);Hjo=r(vft,"qdqbert"),vft.forEach(t),Ujo=r(Zxe," \u2014 "),NO=n(Zxe,"A",{href:!0});var Fft=s(NO);Jjo=r(Fft,"QDQBertForTokenClassification"),Fft.forEach(t),Yjo=r(Zxe," (QDQBert model)"),Zxe.forEach(t),Kjo=i(J),Nb=n(J,"LI",{});var e9e=s(Nb);yge=n(e9e,"STRONG",{});var Tft=s(yge);Zjo=r(Tft,"rembert"),Tft.forEach(t),eDo=r(e9e," \u2014 "),jO=n(e9e,"A",{href:!0});var Mft=s(jO);oDo=r(Mft,"RemBertForTokenClassification"),Mft.forEach(t),rDo=r(e9e," (RemBERT model)"),e9e.forEach(t),tDo=i(J),jb=n(J,"LI",{});var o9e=s(jb);Lge=n(o9e,"STRONG",{});var Eft=s(Lge);aDo=r(Eft,"roberta"),Eft.forEach(t),nDo=r(o9e," \u2014 "),DO=n(o9e,"A",{href:!0});var Cft=s(DO);sDo=r(Cft,"RobertaForTokenClassification"),Cft.forEach(t),lDo=r(o9e," (RoBERTa model)"),o9e.forEach(t),iDo=i(J),Db=n(J,"LI",{});var r9e=s(Db);xge=n(r9e,"STRONG",{});var wft=s(xge);dDo=r(wft,"roformer"),wft.forEach(t),cDo=r(r9e," \u2014 "),GO=n(r9e,"A",{href:!0});var Aft=s(GO);fDo=r(Aft,"RoFormerForTokenClassification"),Aft.forEach(t),mDo=r(r9e," (RoFormer model)"),r9e.forEach(t),gDo=i(J),Gb=n(J,"LI",{});var t9e=s(Gb);$ge=n(t9e,"STRONG",{});var yft=s($ge);hDo=r(yft,"squeezebert"),yft.forEach(t),pDo=r(t9e," \u2014 "),OO=n(t9e,"A",{href:!0});var Lft=s(OO);_Do=r(Lft,"SqueezeBertForTokenClassification"),Lft.forEach(t),uDo=r(t9e," (SqueezeBERT model)"),t9e.forEach(t),bDo=i(J),Ob=n(J,"LI",{});var a9e=s(Ob);kge=n(a9e,"STRONG",{});var xft=s(kge);vDo=r(xft,"xlm"),xft.forEach(t),FDo=r(a9e," \u2014 "),VO=n(a9e,"A",{href:!0});var $ft=s(VO);TDo=r($ft,"XLMForTokenClassification"),$ft.forEach(t),MDo=r(a9e," (XLM model)"),a9e.forEach(t),EDo=i(J),Vb=n(J,"LI",{});var n9e=s(Vb);Sge=n(n9e,"STRONG",{});var kft=s(Sge);CDo=r(kft,"xlm-roberta"),kft.forEach(t),wDo=r(n9e," \u2014 "),XO=n(n9e,"A",{href:!0});var Sft=s(XO);ADo=r(Sft,"XLMRobertaForTokenClassification"),Sft.forEach(t),yDo=r(n9e," (XLM-RoBERTa model)"),n9e.forEach(t),LDo=i(J),Xb=n(J,"LI",{});var s9e=s(Xb);Rge=n(s9e,"STRONG",{});var Rft=s(Rge);xDo=r(Rft,"xlm-roberta-xl"),Rft.forEach(t),$Do=r(s9e," \u2014 "),zO=n(s9e,"A",{href:!0});var Pft=s(zO);kDo=r(Pft,"XLMRobertaXLForTokenClassification"),Pft.forEach(t),SDo=r(s9e," (XLM-RoBERTa-XL model)"),s9e.forEach(t),RDo=i(J),zb=n(J,"LI",{});var l9e=s(zb);Pge=n(l9e,"STRONG",{});var Bft=s(Pge);PDo=r(Bft,"xlnet"),Bft.forEach(t),BDo=r(l9e," \u2014 "),WO=n(l9e,"A",{href:!0});var Ift=s(WO);IDo=r(Ift,"XLNetForTokenClassification"),Ift.forEach(t),qDo=r(l9e," (XLNet model)"),l9e.forEach(t),NDo=i(J),Wb=n(J,"LI",{});var i9e=s(Wb);Bge=n(i9e,"STRONG",{});var qft=s(Bge);jDo=r(qft,"yoso"),qft.forEach(t),DDo=r(i9e," \u2014 "),QO=n(i9e,"A",{href:!0});var Nft=s(QO);GDo=r(Nft,"YosoForTokenClassification"),Nft.forEach(t),ODo=r(i9e," (YOSO model)"),i9e.forEach(t),J.forEach(t),VDo=i(da),Qb=n(da,"P",{});var d9e=s(Qb);XDo=r(d9e,"The model is set in evaluation mode by default using "),Ige=n(d9e,"CODE",{});var jft=s(Ige);zDo=r(jft,"model.eval()"),jft.forEach(t),WDo=r(d9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qge=n(d9e,"CODE",{});var Dft=s(qge);QDo=r(Dft,"model.train()"),Dft.forEach(t),d9e.forEach(t),HDo=i(da),T(Hb.$$.fragment,da),da.forEach(t),Us.forEach(t),Aqe=i(f),Yi=n(f,"H2",{class:!0});var $je=s(Yi);Ub=n($je,"A",{id:!0,class:!0,href:!0});var Gft=s(Ub);Nge=n(Gft,"SPAN",{});var Oft=s(Nge);T($y.$$.fragment,Oft),Oft.forEach(t),Gft.forEach(t),UDo=i($je),jge=n($je,"SPAN",{});var Vft=s(jge);JDo=r(Vft,"AutoModelForQuestionAnswering"),Vft.forEach(t),$je.forEach(t),yqe=i(f),qo=n(f,"DIV",{class:!0});var Js=s(qo);T(ky.$$.fragment,Js),YDo=i(Js),Ki=n(Js,"P",{});var tZ=s(Ki);KDo=r(tZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),HO=n(tZ,"A",{href:!0});var Xft=s(HO);ZDo=r(Xft,"from_pretrained()"),Xft.forEach(t),eGo=r(tZ," class method or the "),UO=n(tZ,"A",{href:!0});var zft=s(UO);oGo=r(zft,"from_config()"),zft.forEach(t),rGo=r(tZ,` class
method.`),tZ.forEach(t),tGo=i(Js),Sy=n(Js,"P",{});var kje=s(Sy);aGo=r(kje,"This class cannot be instantiated directly using "),Dge=n(kje,"CODE",{});var Wft=s(Dge);nGo=r(Wft,"__init__()"),Wft.forEach(t),sGo=r(kje," (throws an error)."),kje.forEach(t),lGo=i(Js),mt=n(Js,"DIV",{class:!0});var B0=s(mt);T(Ry.$$.fragment,B0),iGo=i(B0),Gge=n(B0,"P",{});var Qft=s(Gge);dGo=r(Qft,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Qft.forEach(t),cGo=i(B0),Zi=n(B0,"P",{});var aZ=s(Zi);fGo=r(aZ,`Note:
Loading a model from its configuration file does `),Oge=n(aZ,"STRONG",{});var Hft=s(Oge);mGo=r(Hft,"not"),Hft.forEach(t),gGo=r(aZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JO=n(aZ,"A",{href:!0});var Uft=s(JO);hGo=r(Uft,"from_pretrained()"),Uft.forEach(t),pGo=r(aZ," to load the model weights."),aZ.forEach(t),_Go=i(B0),T(Jb.$$.fragment,B0),B0.forEach(t),uGo=i(Js),no=n(Js,"DIV",{class:!0});var ca=s(no);T(Py.$$.fragment,ca),bGo=i(ca),Vge=n(ca,"P",{});var Jft=s(Vge);vGo=r(Jft,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Jft.forEach(t),FGo=i(ca),qa=n(ca,"P",{});var I0=s(qa);TGo=r(I0,"The model class to instantiate is selected based on the "),Xge=n(I0,"CODE",{});var Yft=s(Xge);MGo=r(Yft,"model_type"),Yft.forEach(t),EGo=r(I0,` property of the config object (either
passed as an argument or loaded from `),zge=n(I0,"CODE",{});var Kft=s(zge);CGo=r(Kft,"pretrained_model_name_or_path"),Kft.forEach(t),wGo=r(I0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wge=n(I0,"CODE",{});var Zft=s(Wge);AGo=r(Zft,"pretrained_model_name_or_path"),Zft.forEach(t),yGo=r(I0,":"),I0.forEach(t),LGo=i(ca),V=n(ca,"UL",{});var X=s(V);Yb=n(X,"LI",{});var c9e=s(Yb);Qge=n(c9e,"STRONG",{});var emt=s(Qge);xGo=r(emt,"albert"),emt.forEach(t),$Go=r(c9e," \u2014 "),YO=n(c9e,"A",{href:!0});var omt=s(YO);kGo=r(omt,"AlbertForQuestionAnswering"),omt.forEach(t),SGo=r(c9e," (ALBERT model)"),c9e.forEach(t),RGo=i(X),Kb=n(X,"LI",{});var f9e=s(Kb);Hge=n(f9e,"STRONG",{});var rmt=s(Hge);PGo=r(rmt,"bart"),rmt.forEach(t),BGo=r(f9e," \u2014 "),KO=n(f9e,"A",{href:!0});var tmt=s(KO);IGo=r(tmt,"BartForQuestionAnswering"),tmt.forEach(t),qGo=r(f9e," (BART model)"),f9e.forEach(t),NGo=i(X),Zb=n(X,"LI",{});var m9e=s(Zb);Uge=n(m9e,"STRONG",{});var amt=s(Uge);jGo=r(amt,"bert"),amt.forEach(t),DGo=r(m9e," \u2014 "),ZO=n(m9e,"A",{href:!0});var nmt=s(ZO);GGo=r(nmt,"BertForQuestionAnswering"),nmt.forEach(t),OGo=r(m9e," (BERT model)"),m9e.forEach(t),VGo=i(X),ev=n(X,"LI",{});var g9e=s(ev);Jge=n(g9e,"STRONG",{});var smt=s(Jge);XGo=r(smt,"big_bird"),smt.forEach(t),zGo=r(g9e," \u2014 "),eV=n(g9e,"A",{href:!0});var lmt=s(eV);WGo=r(lmt,"BigBirdForQuestionAnswering"),lmt.forEach(t),QGo=r(g9e," (BigBird model)"),g9e.forEach(t),HGo=i(X),ov=n(X,"LI",{});var h9e=s(ov);Yge=n(h9e,"STRONG",{});var imt=s(Yge);UGo=r(imt,"bigbird_pegasus"),imt.forEach(t),JGo=r(h9e," \u2014 "),oV=n(h9e,"A",{href:!0});var dmt=s(oV);YGo=r(dmt,"BigBirdPegasusForQuestionAnswering"),dmt.forEach(t),KGo=r(h9e," (BigBirdPegasus model)"),h9e.forEach(t),ZGo=i(X),rv=n(X,"LI",{});var p9e=s(rv);Kge=n(p9e,"STRONG",{});var cmt=s(Kge);eOo=r(cmt,"camembert"),cmt.forEach(t),oOo=r(p9e," \u2014 "),rV=n(p9e,"A",{href:!0});var fmt=s(rV);rOo=r(fmt,"CamembertForQuestionAnswering"),fmt.forEach(t),tOo=r(p9e," (CamemBERT model)"),p9e.forEach(t),aOo=i(X),tv=n(X,"LI",{});var _9e=s(tv);Zge=n(_9e,"STRONG",{});var mmt=s(Zge);nOo=r(mmt,"canine"),mmt.forEach(t),sOo=r(_9e," \u2014 "),tV=n(_9e,"A",{href:!0});var gmt=s(tV);lOo=r(gmt,"CanineForQuestionAnswering"),gmt.forEach(t),iOo=r(_9e," (Canine model)"),_9e.forEach(t),dOo=i(X),av=n(X,"LI",{});var u9e=s(av);ehe=n(u9e,"STRONG",{});var hmt=s(ehe);cOo=r(hmt,"convbert"),hmt.forEach(t),fOo=r(u9e," \u2014 "),aV=n(u9e,"A",{href:!0});var pmt=s(aV);mOo=r(pmt,"ConvBertForQuestionAnswering"),pmt.forEach(t),gOo=r(u9e," (ConvBERT model)"),u9e.forEach(t),hOo=i(X),nv=n(X,"LI",{});var b9e=s(nv);ohe=n(b9e,"STRONG",{});var _mt=s(ohe);pOo=r(_mt,"data2vec-text"),_mt.forEach(t),_Oo=r(b9e," \u2014 "),nV=n(b9e,"A",{href:!0});var umt=s(nV);uOo=r(umt,"Data2VecTextForQuestionAnswering"),umt.forEach(t),bOo=r(b9e," (Data2VecText model)"),b9e.forEach(t),vOo=i(X),sv=n(X,"LI",{});var v9e=s(sv);rhe=n(v9e,"STRONG",{});var bmt=s(rhe);FOo=r(bmt,"deberta"),bmt.forEach(t),TOo=r(v9e," \u2014 "),sV=n(v9e,"A",{href:!0});var vmt=s(sV);MOo=r(vmt,"DebertaForQuestionAnswering"),vmt.forEach(t),EOo=r(v9e," (DeBERTa model)"),v9e.forEach(t),COo=i(X),lv=n(X,"LI",{});var F9e=s(lv);the=n(F9e,"STRONG",{});var Fmt=s(the);wOo=r(Fmt,"deberta-v2"),Fmt.forEach(t),AOo=r(F9e," \u2014 "),lV=n(F9e,"A",{href:!0});var Tmt=s(lV);yOo=r(Tmt,"DebertaV2ForQuestionAnswering"),Tmt.forEach(t),LOo=r(F9e," (DeBERTa-v2 model)"),F9e.forEach(t),xOo=i(X),iv=n(X,"LI",{});var T9e=s(iv);ahe=n(T9e,"STRONG",{});var Mmt=s(ahe);$Oo=r(Mmt,"distilbert"),Mmt.forEach(t),kOo=r(T9e," \u2014 "),iV=n(T9e,"A",{href:!0});var Emt=s(iV);SOo=r(Emt,"DistilBertForQuestionAnswering"),Emt.forEach(t),ROo=r(T9e," (DistilBERT model)"),T9e.forEach(t),POo=i(X),dv=n(X,"LI",{});var M9e=s(dv);nhe=n(M9e,"STRONG",{});var Cmt=s(nhe);BOo=r(Cmt,"electra"),Cmt.forEach(t),IOo=r(M9e," \u2014 "),dV=n(M9e,"A",{href:!0});var wmt=s(dV);qOo=r(wmt,"ElectraForQuestionAnswering"),wmt.forEach(t),NOo=r(M9e," (ELECTRA model)"),M9e.forEach(t),jOo=i(X),cv=n(X,"LI",{});var E9e=s(cv);she=n(E9e,"STRONG",{});var Amt=s(she);DOo=r(Amt,"flaubert"),Amt.forEach(t),GOo=r(E9e," \u2014 "),cV=n(E9e,"A",{href:!0});var ymt=s(cV);OOo=r(ymt,"FlaubertForQuestionAnsweringSimple"),ymt.forEach(t),VOo=r(E9e," (FlauBERT model)"),E9e.forEach(t),XOo=i(X),fv=n(X,"LI",{});var C9e=s(fv);lhe=n(C9e,"STRONG",{});var Lmt=s(lhe);zOo=r(Lmt,"fnet"),Lmt.forEach(t),WOo=r(C9e," \u2014 "),fV=n(C9e,"A",{href:!0});var xmt=s(fV);QOo=r(xmt,"FNetForQuestionAnswering"),xmt.forEach(t),HOo=r(C9e," (FNet model)"),C9e.forEach(t),UOo=i(X),mv=n(X,"LI",{});var w9e=s(mv);ihe=n(w9e,"STRONG",{});var $mt=s(ihe);JOo=r($mt,"funnel"),$mt.forEach(t),YOo=r(w9e," \u2014 "),mV=n(w9e,"A",{href:!0});var kmt=s(mV);KOo=r(kmt,"FunnelForQuestionAnswering"),kmt.forEach(t),ZOo=r(w9e," (Funnel Transformer model)"),w9e.forEach(t),eVo=i(X),gv=n(X,"LI",{});var A9e=s(gv);dhe=n(A9e,"STRONG",{});var Smt=s(dhe);oVo=r(Smt,"gptj"),Smt.forEach(t),rVo=r(A9e," \u2014 "),gV=n(A9e,"A",{href:!0});var Rmt=s(gV);tVo=r(Rmt,"GPTJForQuestionAnswering"),Rmt.forEach(t),aVo=r(A9e," (GPT-J model)"),A9e.forEach(t),nVo=i(X),hv=n(X,"LI",{});var y9e=s(hv);che=n(y9e,"STRONG",{});var Pmt=s(che);sVo=r(Pmt,"ibert"),Pmt.forEach(t),lVo=r(y9e," \u2014 "),hV=n(y9e,"A",{href:!0});var Bmt=s(hV);iVo=r(Bmt,"IBertForQuestionAnswering"),Bmt.forEach(t),dVo=r(y9e," (I-BERT model)"),y9e.forEach(t),cVo=i(X),pv=n(X,"LI",{});var L9e=s(pv);fhe=n(L9e,"STRONG",{});var Imt=s(fhe);fVo=r(Imt,"layoutlmv2"),Imt.forEach(t),mVo=r(L9e," \u2014 "),pV=n(L9e,"A",{href:!0});var qmt=s(pV);gVo=r(qmt,"LayoutLMv2ForQuestionAnswering"),qmt.forEach(t),hVo=r(L9e," (LayoutLMv2 model)"),L9e.forEach(t),pVo=i(X),_v=n(X,"LI",{});var x9e=s(_v);mhe=n(x9e,"STRONG",{});var Nmt=s(mhe);_Vo=r(Nmt,"led"),Nmt.forEach(t),uVo=r(x9e," \u2014 "),_V=n(x9e,"A",{href:!0});var jmt=s(_V);bVo=r(jmt,"LEDForQuestionAnswering"),jmt.forEach(t),vVo=r(x9e," (LED model)"),x9e.forEach(t),FVo=i(X),uv=n(X,"LI",{});var $9e=s(uv);ghe=n($9e,"STRONG",{});var Dmt=s(ghe);TVo=r(Dmt,"longformer"),Dmt.forEach(t),MVo=r($9e," \u2014 "),uV=n($9e,"A",{href:!0});var Gmt=s(uV);EVo=r(Gmt,"LongformerForQuestionAnswering"),Gmt.forEach(t),CVo=r($9e," (Longformer model)"),$9e.forEach(t),wVo=i(X),bv=n(X,"LI",{});var k9e=s(bv);hhe=n(k9e,"STRONG",{});var Omt=s(hhe);AVo=r(Omt,"lxmert"),Omt.forEach(t),yVo=r(k9e," \u2014 "),bV=n(k9e,"A",{href:!0});var Vmt=s(bV);LVo=r(Vmt,"LxmertForQuestionAnswering"),Vmt.forEach(t),xVo=r(k9e," (LXMERT model)"),k9e.forEach(t),$Vo=i(X),vv=n(X,"LI",{});var S9e=s(vv);phe=n(S9e,"STRONG",{});var Xmt=s(phe);kVo=r(Xmt,"mbart"),Xmt.forEach(t),SVo=r(S9e," \u2014 "),vV=n(S9e,"A",{href:!0});var zmt=s(vV);RVo=r(zmt,"MBartForQuestionAnswering"),zmt.forEach(t),PVo=r(S9e," (mBART model)"),S9e.forEach(t),BVo=i(X),Fv=n(X,"LI",{});var R9e=s(Fv);_he=n(R9e,"STRONG",{});var Wmt=s(_he);IVo=r(Wmt,"megatron-bert"),Wmt.forEach(t),qVo=r(R9e," \u2014 "),FV=n(R9e,"A",{href:!0});var Qmt=s(FV);NVo=r(Qmt,"MegatronBertForQuestionAnswering"),Qmt.forEach(t),jVo=r(R9e," (MegatronBert model)"),R9e.forEach(t),DVo=i(X),Tv=n(X,"LI",{});var P9e=s(Tv);uhe=n(P9e,"STRONG",{});var Hmt=s(uhe);GVo=r(Hmt,"mobilebert"),Hmt.forEach(t),OVo=r(P9e," \u2014 "),TV=n(P9e,"A",{href:!0});var Umt=s(TV);VVo=r(Umt,"MobileBertForQuestionAnswering"),Umt.forEach(t),XVo=r(P9e," (MobileBERT model)"),P9e.forEach(t),zVo=i(X),Mv=n(X,"LI",{});var B9e=s(Mv);bhe=n(B9e,"STRONG",{});var Jmt=s(bhe);WVo=r(Jmt,"mpnet"),Jmt.forEach(t),QVo=r(B9e," \u2014 "),MV=n(B9e,"A",{href:!0});var Ymt=s(MV);HVo=r(Ymt,"MPNetForQuestionAnswering"),Ymt.forEach(t),UVo=r(B9e," (MPNet model)"),B9e.forEach(t),JVo=i(X),Ev=n(X,"LI",{});var I9e=s(Ev);vhe=n(I9e,"STRONG",{});var Kmt=s(vhe);YVo=r(Kmt,"nystromformer"),Kmt.forEach(t),KVo=r(I9e," \u2014 "),EV=n(I9e,"A",{href:!0});var Zmt=s(EV);ZVo=r(Zmt,"NystromformerForQuestionAnswering"),Zmt.forEach(t),eXo=r(I9e," (Nystromformer model)"),I9e.forEach(t),oXo=i(X),Cv=n(X,"LI",{});var q9e=s(Cv);Fhe=n(q9e,"STRONG",{});var egt=s(Fhe);rXo=r(egt,"qdqbert"),egt.forEach(t),tXo=r(q9e," \u2014 "),CV=n(q9e,"A",{href:!0});var ogt=s(CV);aXo=r(ogt,"QDQBertForQuestionAnswering"),ogt.forEach(t),nXo=r(q9e," (QDQBert model)"),q9e.forEach(t),sXo=i(X),wv=n(X,"LI",{});var N9e=s(wv);The=n(N9e,"STRONG",{});var rgt=s(The);lXo=r(rgt,"reformer"),rgt.forEach(t),iXo=r(N9e," \u2014 "),wV=n(N9e,"A",{href:!0});var tgt=s(wV);dXo=r(tgt,"ReformerForQuestionAnswering"),tgt.forEach(t),cXo=r(N9e," (Reformer model)"),N9e.forEach(t),fXo=i(X),Av=n(X,"LI",{});var j9e=s(Av);Mhe=n(j9e,"STRONG",{});var agt=s(Mhe);mXo=r(agt,"rembert"),agt.forEach(t),gXo=r(j9e," \u2014 "),AV=n(j9e,"A",{href:!0});var ngt=s(AV);hXo=r(ngt,"RemBertForQuestionAnswering"),ngt.forEach(t),pXo=r(j9e," (RemBERT model)"),j9e.forEach(t),_Xo=i(X),yv=n(X,"LI",{});var D9e=s(yv);Ehe=n(D9e,"STRONG",{});var sgt=s(Ehe);uXo=r(sgt,"roberta"),sgt.forEach(t),bXo=r(D9e," \u2014 "),yV=n(D9e,"A",{href:!0});var lgt=s(yV);vXo=r(lgt,"RobertaForQuestionAnswering"),lgt.forEach(t),FXo=r(D9e," (RoBERTa model)"),D9e.forEach(t),TXo=i(X),Lv=n(X,"LI",{});var G9e=s(Lv);Che=n(G9e,"STRONG",{});var igt=s(Che);MXo=r(igt,"roformer"),igt.forEach(t),EXo=r(G9e," \u2014 "),LV=n(G9e,"A",{href:!0});var dgt=s(LV);CXo=r(dgt,"RoFormerForQuestionAnswering"),dgt.forEach(t),wXo=r(G9e," (RoFormer model)"),G9e.forEach(t),AXo=i(X),xv=n(X,"LI",{});var O9e=s(xv);whe=n(O9e,"STRONG",{});var cgt=s(whe);yXo=r(cgt,"splinter"),cgt.forEach(t),LXo=r(O9e," \u2014 "),xV=n(O9e,"A",{href:!0});var fgt=s(xV);xXo=r(fgt,"SplinterForQuestionAnswering"),fgt.forEach(t),$Xo=r(O9e," (Splinter model)"),O9e.forEach(t),kXo=i(X),$v=n(X,"LI",{});var V9e=s($v);Ahe=n(V9e,"STRONG",{});var mgt=s(Ahe);SXo=r(mgt,"squeezebert"),mgt.forEach(t),RXo=r(V9e," \u2014 "),$V=n(V9e,"A",{href:!0});var ggt=s($V);PXo=r(ggt,"SqueezeBertForQuestionAnswering"),ggt.forEach(t),BXo=r(V9e," (SqueezeBERT model)"),V9e.forEach(t),IXo=i(X),kv=n(X,"LI",{});var X9e=s(kv);yhe=n(X9e,"STRONG",{});var hgt=s(yhe);qXo=r(hgt,"xlm"),hgt.forEach(t),NXo=r(X9e," \u2014 "),kV=n(X9e,"A",{href:!0});var pgt=s(kV);jXo=r(pgt,"XLMForQuestionAnsweringSimple"),pgt.forEach(t),DXo=r(X9e," (XLM model)"),X9e.forEach(t),GXo=i(X),Sv=n(X,"LI",{});var z9e=s(Sv);Lhe=n(z9e,"STRONG",{});var _gt=s(Lhe);OXo=r(_gt,"xlm-roberta"),_gt.forEach(t),VXo=r(z9e," \u2014 "),SV=n(z9e,"A",{href:!0});var ugt=s(SV);XXo=r(ugt,"XLMRobertaForQuestionAnswering"),ugt.forEach(t),zXo=r(z9e," (XLM-RoBERTa model)"),z9e.forEach(t),WXo=i(X),Rv=n(X,"LI",{});var W9e=s(Rv);xhe=n(W9e,"STRONG",{});var bgt=s(xhe);QXo=r(bgt,"xlm-roberta-xl"),bgt.forEach(t),HXo=r(W9e," \u2014 "),RV=n(W9e,"A",{href:!0});var vgt=s(RV);UXo=r(vgt,"XLMRobertaXLForQuestionAnswering"),vgt.forEach(t),JXo=r(W9e," (XLM-RoBERTa-XL model)"),W9e.forEach(t),YXo=i(X),Pv=n(X,"LI",{});var Q9e=s(Pv);$he=n(Q9e,"STRONG",{});var Fgt=s($he);KXo=r(Fgt,"xlnet"),Fgt.forEach(t),ZXo=r(Q9e," \u2014 "),PV=n(Q9e,"A",{href:!0});var Tgt=s(PV);ezo=r(Tgt,"XLNetForQuestionAnsweringSimple"),Tgt.forEach(t),ozo=r(Q9e," (XLNet model)"),Q9e.forEach(t),rzo=i(X),Bv=n(X,"LI",{});var H9e=s(Bv);khe=n(H9e,"STRONG",{});var Mgt=s(khe);tzo=r(Mgt,"yoso"),Mgt.forEach(t),azo=r(H9e," \u2014 "),BV=n(H9e,"A",{href:!0});var Egt=s(BV);nzo=r(Egt,"YosoForQuestionAnswering"),Egt.forEach(t),szo=r(H9e," (YOSO model)"),H9e.forEach(t),X.forEach(t),lzo=i(ca),Iv=n(ca,"P",{});var U9e=s(Iv);izo=r(U9e,"The model is set in evaluation mode by default using "),She=n(U9e,"CODE",{});var Cgt=s(She);dzo=r(Cgt,"model.eval()"),Cgt.forEach(t),czo=r(U9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rhe=n(U9e,"CODE",{});var wgt=s(Rhe);fzo=r(wgt,"model.train()"),wgt.forEach(t),U9e.forEach(t),mzo=i(ca),T(qv.$$.fragment,ca),ca.forEach(t),Js.forEach(t),Lqe=i(f),ed=n(f,"H2",{class:!0});var Sje=s(ed);Nv=n(Sje,"A",{id:!0,class:!0,href:!0});var Agt=s(Nv);Phe=n(Agt,"SPAN",{});var ygt=s(Phe);T(By.$$.fragment,ygt),ygt.forEach(t),Agt.forEach(t),gzo=i(Sje),Bhe=n(Sje,"SPAN",{});var Lgt=s(Bhe);hzo=r(Lgt,"AutoModelForTableQuestionAnswering"),Lgt.forEach(t),Sje.forEach(t),xqe=i(f),No=n(f,"DIV",{class:!0});var Ys=s(No);T(Iy.$$.fragment,Ys),pzo=i(Ys),od=n(Ys,"P",{});var nZ=s(od);_zo=r(nZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),IV=n(nZ,"A",{href:!0});var xgt=s(IV);uzo=r(xgt,"from_pretrained()"),xgt.forEach(t),bzo=r(nZ," class method or the "),qV=n(nZ,"A",{href:!0});var $gt=s(qV);vzo=r($gt,"from_config()"),$gt.forEach(t),Fzo=r(nZ,` class
method.`),nZ.forEach(t),Tzo=i(Ys),qy=n(Ys,"P",{});var Rje=s(qy);Mzo=r(Rje,"This class cannot be instantiated directly using "),Ihe=n(Rje,"CODE",{});var kgt=s(Ihe);Ezo=r(kgt,"__init__()"),kgt.forEach(t),Czo=r(Rje," (throws an error)."),Rje.forEach(t),wzo=i(Ys),gt=n(Ys,"DIV",{class:!0});var q0=s(gt);T(Ny.$$.fragment,q0),Azo=i(q0),qhe=n(q0,"P",{});var Sgt=s(qhe);yzo=r(Sgt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Sgt.forEach(t),Lzo=i(q0),rd=n(q0,"P",{});var sZ=s(rd);xzo=r(sZ,`Note:
Loading a model from its configuration file does `),Nhe=n(sZ,"STRONG",{});var Rgt=s(Nhe);$zo=r(Rgt,"not"),Rgt.forEach(t),kzo=r(sZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),NV=n(sZ,"A",{href:!0});var Pgt=s(NV);Szo=r(Pgt,"from_pretrained()"),Pgt.forEach(t),Rzo=r(sZ," to load the model weights."),sZ.forEach(t),Pzo=i(q0),T(jv.$$.fragment,q0),q0.forEach(t),Bzo=i(Ys),so=n(Ys,"DIV",{class:!0});var fa=s(so);T(jy.$$.fragment,fa),Izo=i(fa),jhe=n(fa,"P",{});var Bgt=s(jhe);qzo=r(Bgt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Bgt.forEach(t),Nzo=i(fa),Na=n(fa,"P",{});var N0=s(Na);jzo=r(N0,"The model class to instantiate is selected based on the "),Dhe=n(N0,"CODE",{});var Igt=s(Dhe);Dzo=r(Igt,"model_type"),Igt.forEach(t),Gzo=r(N0,` property of the config object (either
passed as an argument or loaded from `),Ghe=n(N0,"CODE",{});var qgt=s(Ghe);Ozo=r(qgt,"pretrained_model_name_or_path"),qgt.forEach(t),Vzo=r(N0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ohe=n(N0,"CODE",{});var Ngt=s(Ohe);Xzo=r(Ngt,"pretrained_model_name_or_path"),Ngt.forEach(t),zzo=r(N0,":"),N0.forEach(t),Wzo=i(fa),Vhe=n(fa,"UL",{});var jgt=s(Vhe);Dv=n(jgt,"LI",{});var J9e=s(Dv);Xhe=n(J9e,"STRONG",{});var Dgt=s(Xhe);Qzo=r(Dgt,"tapas"),Dgt.forEach(t),Hzo=r(J9e," \u2014 "),jV=n(J9e,"A",{href:!0});var Ggt=s(jV);Uzo=r(Ggt,"TapasForQuestionAnswering"),Ggt.forEach(t),Jzo=r(J9e," (TAPAS model)"),J9e.forEach(t),jgt.forEach(t),Yzo=i(fa),Gv=n(fa,"P",{});var Y9e=s(Gv);Kzo=r(Y9e,"The model is set in evaluation mode by default using "),zhe=n(Y9e,"CODE",{});var Ogt=s(zhe);Zzo=r(Ogt,"model.eval()"),Ogt.forEach(t),eWo=r(Y9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Whe=n(Y9e,"CODE",{});var Vgt=s(Whe);oWo=r(Vgt,"model.train()"),Vgt.forEach(t),Y9e.forEach(t),rWo=i(fa),T(Ov.$$.fragment,fa),fa.forEach(t),Ys.forEach(t),$qe=i(f),td=n(f,"H2",{class:!0});var Pje=s(td);Vv=n(Pje,"A",{id:!0,class:!0,href:!0});var Xgt=s(Vv);Qhe=n(Xgt,"SPAN",{});var zgt=s(Qhe);T(Dy.$$.fragment,zgt),zgt.forEach(t),Xgt.forEach(t),tWo=i(Pje),Hhe=n(Pje,"SPAN",{});var Wgt=s(Hhe);aWo=r(Wgt,"AutoModelForImageClassification"),Wgt.forEach(t),Pje.forEach(t),kqe=i(f),jo=n(f,"DIV",{class:!0});var Ks=s(jo);T(Gy.$$.fragment,Ks),nWo=i(Ks),ad=n(Ks,"P",{});var lZ=s(ad);sWo=r(lZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),DV=n(lZ,"A",{href:!0});var Qgt=s(DV);lWo=r(Qgt,"from_pretrained()"),Qgt.forEach(t),iWo=r(lZ," class method or the "),GV=n(lZ,"A",{href:!0});var Hgt=s(GV);dWo=r(Hgt,"from_config()"),Hgt.forEach(t),cWo=r(lZ,` class
method.`),lZ.forEach(t),fWo=i(Ks),Oy=n(Ks,"P",{});var Bje=s(Oy);mWo=r(Bje,"This class cannot be instantiated directly using "),Uhe=n(Bje,"CODE",{});var Ugt=s(Uhe);gWo=r(Ugt,"__init__()"),Ugt.forEach(t),hWo=r(Bje," (throws an error)."),Bje.forEach(t),pWo=i(Ks),ht=n(Ks,"DIV",{class:!0});var j0=s(ht);T(Vy.$$.fragment,j0),_Wo=i(j0),Jhe=n(j0,"P",{});var Jgt=s(Jhe);uWo=r(Jgt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jgt.forEach(t),bWo=i(j0),nd=n(j0,"P",{});var iZ=s(nd);vWo=r(iZ,`Note:
Loading a model from its configuration file does `),Yhe=n(iZ,"STRONG",{});var Ygt=s(Yhe);FWo=r(Ygt,"not"),Ygt.forEach(t),TWo=r(iZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),OV=n(iZ,"A",{href:!0});var Kgt=s(OV);MWo=r(Kgt,"from_pretrained()"),Kgt.forEach(t),EWo=r(iZ," to load the model weights."),iZ.forEach(t),CWo=i(j0),T(Xv.$$.fragment,j0),j0.forEach(t),wWo=i(Ks),lo=n(Ks,"DIV",{class:!0});var ma=s(lo);T(Xy.$$.fragment,ma),AWo=i(ma),Khe=n(ma,"P",{});var Zgt=s(Khe);yWo=r(Zgt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Zgt.forEach(t),LWo=i(ma),ja=n(ma,"P",{});var D0=s(ja);xWo=r(D0,"The model class to instantiate is selected based on the "),Zhe=n(D0,"CODE",{});var eht=s(Zhe);$Wo=r(eht,"model_type"),eht.forEach(t),kWo=r(D0,` property of the config object (either
passed as an argument or loaded from `),epe=n(D0,"CODE",{});var oht=s(epe);SWo=r(oht,"pretrained_model_name_or_path"),oht.forEach(t),RWo=r(D0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ope=n(D0,"CODE",{});var rht=s(ope);PWo=r(rht,"pretrained_model_name_or_path"),rht.forEach(t),BWo=r(D0,":"),D0.forEach(t),IWo=i(ma),Fe=n(ma,"UL",{});var Ee=s(Fe);zv=n(Ee,"LI",{});var K9e=s(zv);rpe=n(K9e,"STRONG",{});var tht=s(rpe);qWo=r(tht,"beit"),tht.forEach(t),NWo=r(K9e," \u2014 "),VV=n(K9e,"A",{href:!0});var aht=s(VV);jWo=r(aht,"BeitForImageClassification"),aht.forEach(t),DWo=r(K9e," (BEiT model)"),K9e.forEach(t),GWo=i(Ee),Wv=n(Ee,"LI",{});var Z9e=s(Wv);tpe=n(Z9e,"STRONG",{});var nht=s(tpe);OWo=r(nht,"convnext"),nht.forEach(t),VWo=r(Z9e," \u2014 "),XV=n(Z9e,"A",{href:!0});var sht=s(XV);XWo=r(sht,"ConvNextForImageClassification"),sht.forEach(t),zWo=r(Z9e," (ConvNext model)"),Z9e.forEach(t),WWo=i(Ee),Qv=n(Ee,"LI",{});var e$e=s(Qv);ape=n(e$e,"STRONG",{});var lht=s(ape);QWo=r(lht,"data2vec-vision"),lht.forEach(t),HWo=r(e$e," \u2014 "),zV=n(e$e,"A",{href:!0});var iht=s(zV);UWo=r(iht,"Data2VecVisionForImageClassification"),iht.forEach(t),JWo=r(e$e," (Data2VecVision model)"),e$e.forEach(t),YWo=i(Ee),Ps=n(Ee,"LI",{});var L$=s(Ps);npe=n(L$,"STRONG",{});var dht=s(npe);KWo=r(dht,"deit"),dht.forEach(t),ZWo=r(L$," \u2014 "),WV=n(L$,"A",{href:!0});var cht=s(WV);eQo=r(cht,"DeiTForImageClassification"),cht.forEach(t),oQo=r(L$," or "),QV=n(L$,"A",{href:!0});var fht=s(QV);rQo=r(fht,"DeiTForImageClassificationWithTeacher"),fht.forEach(t),tQo=r(L$," (DeiT model)"),L$.forEach(t),aQo=i(Ee),Hv=n(Ee,"LI",{});var o$e=s(Hv);spe=n(o$e,"STRONG",{});var mht=s(spe);nQo=r(mht,"imagegpt"),mht.forEach(t),sQo=r(o$e," \u2014 "),HV=n(o$e,"A",{href:!0});var ght=s(HV);lQo=r(ght,"ImageGPTForImageClassification"),ght.forEach(t),iQo=r(o$e," (ImageGPT model)"),o$e.forEach(t),dQo=i(Ee),pt=n(Ee,"LI",{});var gf=s(pt);lpe=n(gf,"STRONG",{});var hht=s(lpe);cQo=r(hht,"perceiver"),hht.forEach(t),fQo=r(gf," \u2014 "),UV=n(gf,"A",{href:!0});var pht=s(UV);mQo=r(pht,"PerceiverForImageClassificationLearned"),pht.forEach(t),gQo=r(gf," or "),JV=n(gf,"A",{href:!0});var _ht=s(JV);hQo=r(_ht,"PerceiverForImageClassificationFourier"),_ht.forEach(t),pQo=r(gf," or "),YV=n(gf,"A",{href:!0});var uht=s(YV);_Qo=r(uht,"PerceiverForImageClassificationConvProcessing"),uht.forEach(t),uQo=r(gf," (Perceiver model)"),gf.forEach(t),bQo=i(Ee),Uv=n(Ee,"LI",{});var r$e=s(Uv);ipe=n(r$e,"STRONG",{});var bht=s(ipe);vQo=r(bht,"poolformer"),bht.forEach(t),FQo=r(r$e," \u2014 "),KV=n(r$e,"A",{href:!0});var vht=s(KV);TQo=r(vht,"PoolFormerForImageClassification"),vht.forEach(t),MQo=r(r$e," (PoolFormer model)"),r$e.forEach(t),EQo=i(Ee),Jv=n(Ee,"LI",{});var t$e=s(Jv);dpe=n(t$e,"STRONG",{});var Fht=s(dpe);CQo=r(Fht,"regnet"),Fht.forEach(t),wQo=r(t$e," \u2014 "),ZV=n(t$e,"A",{href:!0});var Tht=s(ZV);AQo=r(Tht,"RegNetForImageClassification"),Tht.forEach(t),yQo=r(t$e," (RegNet model)"),t$e.forEach(t),LQo=i(Ee),Yv=n(Ee,"LI",{});var a$e=s(Yv);cpe=n(a$e,"STRONG",{});var Mht=s(cpe);xQo=r(Mht,"resnet"),Mht.forEach(t),$Qo=r(a$e," \u2014 "),eX=n(a$e,"A",{href:!0});var Eht=s(eX);kQo=r(Eht,"ResNetForImageClassification"),Eht.forEach(t),SQo=r(a$e," (ResNet model)"),a$e.forEach(t),RQo=i(Ee),Kv=n(Ee,"LI",{});var n$e=s(Kv);fpe=n(n$e,"STRONG",{});var Cht=s(fpe);PQo=r(Cht,"segformer"),Cht.forEach(t),BQo=r(n$e," \u2014 "),oX=n(n$e,"A",{href:!0});var wht=s(oX);IQo=r(wht,"SegformerForImageClassification"),wht.forEach(t),qQo=r(n$e," (SegFormer model)"),n$e.forEach(t),NQo=i(Ee),Zv=n(Ee,"LI",{});var s$e=s(Zv);mpe=n(s$e,"STRONG",{});var Aht=s(mpe);jQo=r(Aht,"swin"),Aht.forEach(t),DQo=r(s$e," \u2014 "),rX=n(s$e,"A",{href:!0});var yht=s(rX);GQo=r(yht,"SwinForImageClassification"),yht.forEach(t),OQo=r(s$e," (Swin model)"),s$e.forEach(t),VQo=i(Ee),eF=n(Ee,"LI",{});var l$e=s(eF);gpe=n(l$e,"STRONG",{});var Lht=s(gpe);XQo=r(Lht,"van"),Lht.forEach(t),zQo=r(l$e," \u2014 "),tX=n(l$e,"A",{href:!0});var xht=s(tX);WQo=r(xht,"VanForImageClassification"),xht.forEach(t),QQo=r(l$e," (VAN model)"),l$e.forEach(t),HQo=i(Ee),oF=n(Ee,"LI",{});var i$e=s(oF);hpe=n(i$e,"STRONG",{});var $ht=s(hpe);UQo=r($ht,"vit"),$ht.forEach(t),JQo=r(i$e," \u2014 "),aX=n(i$e,"A",{href:!0});var kht=s(aX);YQo=r(kht,"ViTForImageClassification"),kht.forEach(t),KQo=r(i$e," (ViT model)"),i$e.forEach(t),Ee.forEach(t),ZQo=i(ma),rF=n(ma,"P",{});var d$e=s(rF);eHo=r(d$e,"The model is set in evaluation mode by default using "),ppe=n(d$e,"CODE",{});var Sht=s(ppe);oHo=r(Sht,"model.eval()"),Sht.forEach(t),rHo=r(d$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_pe=n(d$e,"CODE",{});var Rht=s(_pe);tHo=r(Rht,"model.train()"),Rht.forEach(t),d$e.forEach(t),aHo=i(ma),T(tF.$$.fragment,ma),ma.forEach(t),Ks.forEach(t),Sqe=i(f),sd=n(f,"H2",{class:!0});var Ije=s(sd);aF=n(Ije,"A",{id:!0,class:!0,href:!0});var Pht=s(aF);upe=n(Pht,"SPAN",{});var Bht=s(upe);T(zy.$$.fragment,Bht),Bht.forEach(t),Pht.forEach(t),nHo=i(Ije),bpe=n(Ije,"SPAN",{});var Iht=s(bpe);sHo=r(Iht,"AutoModelForVision2Seq"),Iht.forEach(t),Ije.forEach(t),Rqe=i(f),Do=n(f,"DIV",{class:!0});var Zs=s(Do);T(Wy.$$.fragment,Zs),lHo=i(Zs),ld=n(Zs,"P",{});var dZ=s(ld);iHo=r(dZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nX=n(dZ,"A",{href:!0});var qht=s(nX);dHo=r(qht,"from_pretrained()"),qht.forEach(t),cHo=r(dZ," class method or the "),sX=n(dZ,"A",{href:!0});var Nht=s(sX);fHo=r(Nht,"from_config()"),Nht.forEach(t),mHo=r(dZ,` class
method.`),dZ.forEach(t),gHo=i(Zs),Qy=n(Zs,"P",{});var qje=s(Qy);hHo=r(qje,"This class cannot be instantiated directly using "),vpe=n(qje,"CODE",{});var jht=s(vpe);pHo=r(jht,"__init__()"),jht.forEach(t),_Ho=r(qje," (throws an error)."),qje.forEach(t),uHo=i(Zs),_t=n(Zs,"DIV",{class:!0});var G0=s(_t);T(Hy.$$.fragment,G0),bHo=i(G0),Fpe=n(G0,"P",{});var Dht=s(Fpe);vHo=r(Dht,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Dht.forEach(t),FHo=i(G0),id=n(G0,"P",{});var cZ=s(id);THo=r(cZ,`Note:
Loading a model from its configuration file does `),Tpe=n(cZ,"STRONG",{});var Ght=s(Tpe);MHo=r(Ght,"not"),Ght.forEach(t),EHo=r(cZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),lX=n(cZ,"A",{href:!0});var Oht=s(lX);CHo=r(Oht,"from_pretrained()"),Oht.forEach(t),wHo=r(cZ," to load the model weights."),cZ.forEach(t),AHo=i(G0),T(nF.$$.fragment,G0),G0.forEach(t),yHo=i(Zs),io=n(Zs,"DIV",{class:!0});var ga=s(io);T(Uy.$$.fragment,ga),LHo=i(ga),Mpe=n(ga,"P",{});var Vht=s(Mpe);xHo=r(Vht,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Vht.forEach(t),$Ho=i(ga),Da=n(ga,"P",{});var O0=s(Da);kHo=r(O0,"The model class to instantiate is selected based on the "),Epe=n(O0,"CODE",{});var Xht=s(Epe);SHo=r(Xht,"model_type"),Xht.forEach(t),RHo=r(O0,` property of the config object (either
passed as an argument or loaded from `),Cpe=n(O0,"CODE",{});var zht=s(Cpe);PHo=r(zht,"pretrained_model_name_or_path"),zht.forEach(t),BHo=r(O0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wpe=n(O0,"CODE",{});var Wht=s(wpe);IHo=r(Wht,"pretrained_model_name_or_path"),Wht.forEach(t),qHo=r(O0,":"),O0.forEach(t),NHo=i(ga),Ape=n(ga,"UL",{});var Qht=s(Ape);sF=n(Qht,"LI",{});var c$e=s(sF);ype=n(c$e,"STRONG",{});var Hht=s(ype);jHo=r(Hht,"vision-encoder-decoder"),Hht.forEach(t),DHo=r(c$e," \u2014 "),iX=n(c$e,"A",{href:!0});var Uht=s(iX);GHo=r(Uht,"VisionEncoderDecoderModel"),Uht.forEach(t),OHo=r(c$e," (Vision Encoder decoder model)"),c$e.forEach(t),Qht.forEach(t),VHo=i(ga),lF=n(ga,"P",{});var f$e=s(lF);XHo=r(f$e,"The model is set in evaluation mode by default using "),Lpe=n(f$e,"CODE",{});var Jht=s(Lpe);zHo=r(Jht,"model.eval()"),Jht.forEach(t),WHo=r(f$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xpe=n(f$e,"CODE",{});var Yht=s(xpe);QHo=r(Yht,"model.train()"),Yht.forEach(t),f$e.forEach(t),HHo=i(ga),T(iF.$$.fragment,ga),ga.forEach(t),Zs.forEach(t),Pqe=i(f),dd=n(f,"H2",{class:!0});var Nje=s(dd);dF=n(Nje,"A",{id:!0,class:!0,href:!0});var Kht=s(dF);$pe=n(Kht,"SPAN",{});var Zht=s($pe);T(Jy.$$.fragment,Zht),Zht.forEach(t),Kht.forEach(t),UHo=i(Nje),kpe=n(Nje,"SPAN",{});var ept=s(kpe);JHo=r(ept,"AutoModelForAudioClassification"),ept.forEach(t),Nje.forEach(t),Bqe=i(f),Go=n(f,"DIV",{class:!0});var el=s(Go);T(Yy.$$.fragment,el),YHo=i(el),cd=n(el,"P",{});var fZ=s(cd);KHo=r(fZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),dX=n(fZ,"A",{href:!0});var opt=s(dX);ZHo=r(opt,"from_pretrained()"),opt.forEach(t),eUo=r(fZ," class method or the "),cX=n(fZ,"A",{href:!0});var rpt=s(cX);oUo=r(rpt,"from_config()"),rpt.forEach(t),rUo=r(fZ,` class
method.`),fZ.forEach(t),tUo=i(el),Ky=n(el,"P",{});var jje=s(Ky);aUo=r(jje,"This class cannot be instantiated directly using "),Spe=n(jje,"CODE",{});var tpt=s(Spe);nUo=r(tpt,"__init__()"),tpt.forEach(t),sUo=r(jje," (throws an error)."),jje.forEach(t),lUo=i(el),ut=n(el,"DIV",{class:!0});var V0=s(ut);T(Zy.$$.fragment,V0),iUo=i(V0),Rpe=n(V0,"P",{});var apt=s(Rpe);dUo=r(apt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),apt.forEach(t),cUo=i(V0),fd=n(V0,"P",{});var mZ=s(fd);fUo=r(mZ,`Note:
Loading a model from its configuration file does `),Ppe=n(mZ,"STRONG",{});var npt=s(Ppe);mUo=r(npt,"not"),npt.forEach(t),gUo=r(mZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),fX=n(mZ,"A",{href:!0});var spt=s(fX);hUo=r(spt,"from_pretrained()"),spt.forEach(t),pUo=r(mZ," to load the model weights."),mZ.forEach(t),_Uo=i(V0),T(cF.$$.fragment,V0),V0.forEach(t),uUo=i(el),co=n(el,"DIV",{class:!0});var ha=s(co);T(eL.$$.fragment,ha),bUo=i(ha),Bpe=n(ha,"P",{});var lpt=s(Bpe);vUo=r(lpt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),lpt.forEach(t),FUo=i(ha),Ga=n(ha,"P",{});var X0=s(Ga);TUo=r(X0,"The model class to instantiate is selected based on the "),Ipe=n(X0,"CODE",{});var ipt=s(Ipe);MUo=r(ipt,"model_type"),ipt.forEach(t),EUo=r(X0,` property of the config object (either
passed as an argument or loaded from `),qpe=n(X0,"CODE",{});var dpt=s(qpe);CUo=r(dpt,"pretrained_model_name_or_path"),dpt.forEach(t),wUo=r(X0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Npe=n(X0,"CODE",{});var cpt=s(Npe);AUo=r(cpt,"pretrained_model_name_or_path"),cpt.forEach(t),yUo=r(X0,":"),X0.forEach(t),LUo=i(ha),Se=n(ha,"UL",{});var Ve=s(Se);fF=n(Ve,"LI",{});var m$e=s(fF);jpe=n(m$e,"STRONG",{});var fpt=s(jpe);xUo=r(fpt,"data2vec-audio"),fpt.forEach(t),$Uo=r(m$e," \u2014 "),mX=n(m$e,"A",{href:!0});var mpt=s(mX);kUo=r(mpt,"Data2VecAudioForSequenceClassification"),mpt.forEach(t),SUo=r(m$e," (Data2VecAudio model)"),m$e.forEach(t),RUo=i(Ve),mF=n(Ve,"LI",{});var g$e=s(mF);Dpe=n(g$e,"STRONG",{});var gpt=s(Dpe);PUo=r(gpt,"hubert"),gpt.forEach(t),BUo=r(g$e," \u2014 "),gX=n(g$e,"A",{href:!0});var hpt=s(gX);IUo=r(hpt,"HubertForSequenceClassification"),hpt.forEach(t),qUo=r(g$e," (Hubert model)"),g$e.forEach(t),NUo=i(Ve),gF=n(Ve,"LI",{});var h$e=s(gF);Gpe=n(h$e,"STRONG",{});var ppt=s(Gpe);jUo=r(ppt,"sew"),ppt.forEach(t),DUo=r(h$e," \u2014 "),hX=n(h$e,"A",{href:!0});var _pt=s(hX);GUo=r(_pt,"SEWForSequenceClassification"),_pt.forEach(t),OUo=r(h$e," (SEW model)"),h$e.forEach(t),VUo=i(Ve),hF=n(Ve,"LI",{});var p$e=s(hF);Ope=n(p$e,"STRONG",{});var upt=s(Ope);XUo=r(upt,"sew-d"),upt.forEach(t),zUo=r(p$e," \u2014 "),pX=n(p$e,"A",{href:!0});var bpt=s(pX);WUo=r(bpt,"SEWDForSequenceClassification"),bpt.forEach(t),QUo=r(p$e," (SEW-D model)"),p$e.forEach(t),HUo=i(Ve),pF=n(Ve,"LI",{});var _$e=s(pF);Vpe=n(_$e,"STRONG",{});var vpt=s(Vpe);UUo=r(vpt,"unispeech"),vpt.forEach(t),JUo=r(_$e," \u2014 "),_X=n(_$e,"A",{href:!0});var Fpt=s(_X);YUo=r(Fpt,"UniSpeechForSequenceClassification"),Fpt.forEach(t),KUo=r(_$e," (UniSpeech model)"),_$e.forEach(t),ZUo=i(Ve),_F=n(Ve,"LI",{});var u$e=s(_F);Xpe=n(u$e,"STRONG",{});var Tpt=s(Xpe);eJo=r(Tpt,"unispeech-sat"),Tpt.forEach(t),oJo=r(u$e," \u2014 "),uX=n(u$e,"A",{href:!0});var Mpt=s(uX);rJo=r(Mpt,"UniSpeechSatForSequenceClassification"),Mpt.forEach(t),tJo=r(u$e," (UniSpeechSat model)"),u$e.forEach(t),aJo=i(Ve),uF=n(Ve,"LI",{});var b$e=s(uF);zpe=n(b$e,"STRONG",{});var Ept=s(zpe);nJo=r(Ept,"wav2vec2"),Ept.forEach(t),sJo=r(b$e," \u2014 "),bX=n(b$e,"A",{href:!0});var Cpt=s(bX);lJo=r(Cpt,"Wav2Vec2ForSequenceClassification"),Cpt.forEach(t),iJo=r(b$e," (Wav2Vec2 model)"),b$e.forEach(t),dJo=i(Ve),bF=n(Ve,"LI",{});var v$e=s(bF);Wpe=n(v$e,"STRONG",{});var wpt=s(Wpe);cJo=r(wpt,"wav2vec2-conformer"),wpt.forEach(t),fJo=r(v$e," \u2014 "),vX=n(v$e,"A",{href:!0});var Apt=s(vX);mJo=r(Apt,"Wav2Vec2ConformerForSequenceClassification"),Apt.forEach(t),gJo=r(v$e," (Wav2Vec2-Conformer model)"),v$e.forEach(t),hJo=i(Ve),vF=n(Ve,"LI",{});var F$e=s(vF);Qpe=n(F$e,"STRONG",{});var ypt=s(Qpe);pJo=r(ypt,"wavlm"),ypt.forEach(t),_Jo=r(F$e," \u2014 "),FX=n(F$e,"A",{href:!0});var Lpt=s(FX);uJo=r(Lpt,"WavLMForSequenceClassification"),Lpt.forEach(t),bJo=r(F$e," (WavLM model)"),F$e.forEach(t),Ve.forEach(t),vJo=i(ha),FF=n(ha,"P",{});var T$e=s(FF);FJo=r(T$e,"The model is set in evaluation mode by default using "),Hpe=n(T$e,"CODE",{});var xpt=s(Hpe);TJo=r(xpt,"model.eval()"),xpt.forEach(t),MJo=r(T$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Upe=n(T$e,"CODE",{});var $pt=s(Upe);EJo=r($pt,"model.train()"),$pt.forEach(t),T$e.forEach(t),CJo=i(ha),T(TF.$$.fragment,ha),ha.forEach(t),el.forEach(t),Iqe=i(f),md=n(f,"H2",{class:!0});var Dje=s(md);MF=n(Dje,"A",{id:!0,class:!0,href:!0});var kpt=s(MF);Jpe=n(kpt,"SPAN",{});var Spt=s(Jpe);T(oL.$$.fragment,Spt),Spt.forEach(t),kpt.forEach(t),wJo=i(Dje),Ype=n(Dje,"SPAN",{});var Rpt=s(Ype);AJo=r(Rpt,"AutoModelForAudioFrameClassification"),Rpt.forEach(t),Dje.forEach(t),qqe=i(f),Oo=n(f,"DIV",{class:!0});var ol=s(Oo);T(rL.$$.fragment,ol),yJo=i(ol),gd=n(ol,"P",{});var gZ=s(gd);LJo=r(gZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),TX=n(gZ,"A",{href:!0});var Ppt=s(TX);xJo=r(Ppt,"from_pretrained()"),Ppt.forEach(t),$Jo=r(gZ," class method or the "),MX=n(gZ,"A",{href:!0});var Bpt=s(MX);kJo=r(Bpt,"from_config()"),Bpt.forEach(t),SJo=r(gZ,` class
method.`),gZ.forEach(t),RJo=i(ol),tL=n(ol,"P",{});var Gje=s(tL);PJo=r(Gje,"This class cannot be instantiated directly using "),Kpe=n(Gje,"CODE",{});var Ipt=s(Kpe);BJo=r(Ipt,"__init__()"),Ipt.forEach(t),IJo=r(Gje," (throws an error)."),Gje.forEach(t),qJo=i(ol),bt=n(ol,"DIV",{class:!0});var z0=s(bt);T(aL.$$.fragment,z0),NJo=i(z0),Zpe=n(z0,"P",{});var qpt=s(Zpe);jJo=r(qpt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),qpt.forEach(t),DJo=i(z0),hd=n(z0,"P",{});var hZ=s(hd);GJo=r(hZ,`Note:
Loading a model from its configuration file does `),e_e=n(hZ,"STRONG",{});var Npt=s(e_e);OJo=r(Npt,"not"),Npt.forEach(t),VJo=r(hZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),EX=n(hZ,"A",{href:!0});var jpt=s(EX);XJo=r(jpt,"from_pretrained()"),jpt.forEach(t),zJo=r(hZ," to load the model weights."),hZ.forEach(t),WJo=i(z0),T(EF.$$.fragment,z0),z0.forEach(t),QJo=i(ol),fo=n(ol,"DIV",{class:!0});var pa=s(fo);T(nL.$$.fragment,pa),HJo=i(pa),o_e=n(pa,"P",{});var Dpt=s(o_e);UJo=r(Dpt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Dpt.forEach(t),JJo=i(pa),Oa=n(pa,"P",{});var W0=s(Oa);YJo=r(W0,"The model class to instantiate is selected based on the "),r_e=n(W0,"CODE",{});var Gpt=s(r_e);KJo=r(Gpt,"model_type"),Gpt.forEach(t),ZJo=r(W0,` property of the config object (either
passed as an argument or loaded from `),t_e=n(W0,"CODE",{});var Opt=s(t_e);eYo=r(Opt,"pretrained_model_name_or_path"),Opt.forEach(t),oYo=r(W0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a_e=n(W0,"CODE",{});var Vpt=s(a_e);rYo=r(Vpt,"pretrained_model_name_or_path"),Vpt.forEach(t),tYo=r(W0,":"),W0.forEach(t),aYo=i(pa),Kr=n(pa,"UL",{});var rl=s(Kr);CF=n(rl,"LI",{});var M$e=s(CF);n_e=n(M$e,"STRONG",{});var Xpt=s(n_e);nYo=r(Xpt,"data2vec-audio"),Xpt.forEach(t),sYo=r(M$e," \u2014 "),CX=n(M$e,"A",{href:!0});var zpt=s(CX);lYo=r(zpt,"Data2VecAudioForAudioFrameClassification"),zpt.forEach(t),iYo=r(M$e," (Data2VecAudio model)"),M$e.forEach(t),dYo=i(rl),wF=n(rl,"LI",{});var E$e=s(wF);s_e=n(E$e,"STRONG",{});var Wpt=s(s_e);cYo=r(Wpt,"unispeech-sat"),Wpt.forEach(t),fYo=r(E$e," \u2014 "),wX=n(E$e,"A",{href:!0});var Qpt=s(wX);mYo=r(Qpt,"UniSpeechSatForAudioFrameClassification"),Qpt.forEach(t),gYo=r(E$e," (UniSpeechSat model)"),E$e.forEach(t),hYo=i(rl),AF=n(rl,"LI",{});var C$e=s(AF);l_e=n(C$e,"STRONG",{});var Hpt=s(l_e);pYo=r(Hpt,"wav2vec2"),Hpt.forEach(t),_Yo=r(C$e," \u2014 "),AX=n(C$e,"A",{href:!0});var Upt=s(AX);uYo=r(Upt,"Wav2Vec2ForAudioFrameClassification"),Upt.forEach(t),bYo=r(C$e," (Wav2Vec2 model)"),C$e.forEach(t),vYo=i(rl),yF=n(rl,"LI",{});var w$e=s(yF);i_e=n(w$e,"STRONG",{});var Jpt=s(i_e);FYo=r(Jpt,"wav2vec2-conformer"),Jpt.forEach(t),TYo=r(w$e," \u2014 "),yX=n(w$e,"A",{href:!0});var Ypt=s(yX);MYo=r(Ypt,"Wav2Vec2ConformerForAudioFrameClassification"),Ypt.forEach(t),EYo=r(w$e," (Wav2Vec2-Conformer model)"),w$e.forEach(t),CYo=i(rl),LF=n(rl,"LI",{});var A$e=s(LF);d_e=n(A$e,"STRONG",{});var Kpt=s(d_e);wYo=r(Kpt,"wavlm"),Kpt.forEach(t),AYo=r(A$e," \u2014 "),LX=n(A$e,"A",{href:!0});var Zpt=s(LX);yYo=r(Zpt,"WavLMForAudioFrameClassification"),Zpt.forEach(t),LYo=r(A$e," (WavLM model)"),A$e.forEach(t),rl.forEach(t),xYo=i(pa),xF=n(pa,"P",{});var y$e=s(xF);$Yo=r(y$e,"The model is set in evaluation mode by default using "),c_e=n(y$e,"CODE",{});var e_t=s(c_e);kYo=r(e_t,"model.eval()"),e_t.forEach(t),SYo=r(y$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f_e=n(y$e,"CODE",{});var o_t=s(f_e);RYo=r(o_t,"model.train()"),o_t.forEach(t),y$e.forEach(t),PYo=i(pa),T($F.$$.fragment,pa),pa.forEach(t),ol.forEach(t),Nqe=i(f),pd=n(f,"H2",{class:!0});var Oje=s(pd);kF=n(Oje,"A",{id:!0,class:!0,href:!0});var r_t=s(kF);m_e=n(r_t,"SPAN",{});var t_t=s(m_e);T(sL.$$.fragment,t_t),t_t.forEach(t),r_t.forEach(t),BYo=i(Oje),g_e=n(Oje,"SPAN",{});var a_t=s(g_e);IYo=r(a_t,"AutoModelForCTC"),a_t.forEach(t),Oje.forEach(t),jqe=i(f),Vo=n(f,"DIV",{class:!0});var tl=s(Vo);T(lL.$$.fragment,tl),qYo=i(tl),_d=n(tl,"P",{});var pZ=s(_d);NYo=r(pZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),xX=n(pZ,"A",{href:!0});var n_t=s(xX);jYo=r(n_t,"from_pretrained()"),n_t.forEach(t),DYo=r(pZ," class method or the "),$X=n(pZ,"A",{href:!0});var s_t=s($X);GYo=r(s_t,"from_config()"),s_t.forEach(t),OYo=r(pZ,` class
method.`),pZ.forEach(t),VYo=i(tl),iL=n(tl,"P",{});var Vje=s(iL);XYo=r(Vje,"This class cannot be instantiated directly using "),h_e=n(Vje,"CODE",{});var l_t=s(h_e);zYo=r(l_t,"__init__()"),l_t.forEach(t),WYo=r(Vje," (throws an error)."),Vje.forEach(t),QYo=i(tl),vt=n(tl,"DIV",{class:!0});var Q0=s(vt);T(dL.$$.fragment,Q0),HYo=i(Q0),p_e=n(Q0,"P",{});var i_t=s(p_e);UYo=r(i_t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),i_t.forEach(t),JYo=i(Q0),ud=n(Q0,"P",{});var _Z=s(ud);YYo=r(_Z,`Note:
Loading a model from its configuration file does `),__e=n(_Z,"STRONG",{});var d_t=s(__e);KYo=r(d_t,"not"),d_t.forEach(t),ZYo=r(_Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(_Z,"A",{href:!0});var c_t=s(kX);eKo=r(c_t,"from_pretrained()"),c_t.forEach(t),oKo=r(_Z," to load the model weights."),_Z.forEach(t),rKo=i(Q0),T(SF.$$.fragment,Q0),Q0.forEach(t),tKo=i(tl),mo=n(tl,"DIV",{class:!0});var _a=s(mo);T(cL.$$.fragment,_a),aKo=i(_a),u_e=n(_a,"P",{});var f_t=s(u_e);nKo=r(f_t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),f_t.forEach(t),sKo=i(_a),Va=n(_a,"P",{});var H0=s(Va);lKo=r(H0,"The model class to instantiate is selected based on the "),b_e=n(H0,"CODE",{});var m_t=s(b_e);iKo=r(m_t,"model_type"),m_t.forEach(t),dKo=r(H0,` property of the config object (either
passed as an argument or loaded from `),v_e=n(H0,"CODE",{});var g_t=s(v_e);cKo=r(g_t,"pretrained_model_name_or_path"),g_t.forEach(t),fKo=r(H0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F_e=n(H0,"CODE",{});var h_t=s(F_e);mKo=r(h_t,"pretrained_model_name_or_path"),h_t.forEach(t),gKo=r(H0,":"),H0.forEach(t),hKo=i(_a),Re=n(_a,"UL",{});var Xe=s(Re);RF=n(Xe,"LI",{});var L$e=s(RF);T_e=n(L$e,"STRONG",{});var p_t=s(T_e);pKo=r(p_t,"data2vec-audio"),p_t.forEach(t),_Ko=r(L$e," \u2014 "),SX=n(L$e,"A",{href:!0});var __t=s(SX);uKo=r(__t,"Data2VecAudioForCTC"),__t.forEach(t),bKo=r(L$e," (Data2VecAudio model)"),L$e.forEach(t),vKo=i(Xe),PF=n(Xe,"LI",{});var x$e=s(PF);M_e=n(x$e,"STRONG",{});var u_t=s(M_e);FKo=r(u_t,"hubert"),u_t.forEach(t),TKo=r(x$e," \u2014 "),RX=n(x$e,"A",{href:!0});var b_t=s(RX);MKo=r(b_t,"HubertForCTC"),b_t.forEach(t),EKo=r(x$e," (Hubert model)"),x$e.forEach(t),CKo=i(Xe),BF=n(Xe,"LI",{});var $$e=s(BF);E_e=n($$e,"STRONG",{});var v_t=s(E_e);wKo=r(v_t,"sew"),v_t.forEach(t),AKo=r($$e," \u2014 "),PX=n($$e,"A",{href:!0});var F_t=s(PX);yKo=r(F_t,"SEWForCTC"),F_t.forEach(t),LKo=r($$e," (SEW model)"),$$e.forEach(t),xKo=i(Xe),IF=n(Xe,"LI",{});var k$e=s(IF);C_e=n(k$e,"STRONG",{});var T_t=s(C_e);$Ko=r(T_t,"sew-d"),T_t.forEach(t),kKo=r(k$e," \u2014 "),BX=n(k$e,"A",{href:!0});var M_t=s(BX);SKo=r(M_t,"SEWDForCTC"),M_t.forEach(t),RKo=r(k$e," (SEW-D model)"),k$e.forEach(t),PKo=i(Xe),qF=n(Xe,"LI",{});var S$e=s(qF);w_e=n(S$e,"STRONG",{});var E_t=s(w_e);BKo=r(E_t,"unispeech"),E_t.forEach(t),IKo=r(S$e," \u2014 "),IX=n(S$e,"A",{href:!0});var C_t=s(IX);qKo=r(C_t,"UniSpeechForCTC"),C_t.forEach(t),NKo=r(S$e," (UniSpeech model)"),S$e.forEach(t),jKo=i(Xe),NF=n(Xe,"LI",{});var R$e=s(NF);A_e=n(R$e,"STRONG",{});var w_t=s(A_e);DKo=r(w_t,"unispeech-sat"),w_t.forEach(t),GKo=r(R$e," \u2014 "),qX=n(R$e,"A",{href:!0});var A_t=s(qX);OKo=r(A_t,"UniSpeechSatForCTC"),A_t.forEach(t),VKo=r(R$e," (UniSpeechSat model)"),R$e.forEach(t),XKo=i(Xe),jF=n(Xe,"LI",{});var P$e=s(jF);y_e=n(P$e,"STRONG",{});var y_t=s(y_e);zKo=r(y_t,"wav2vec2"),y_t.forEach(t),WKo=r(P$e," \u2014 "),NX=n(P$e,"A",{href:!0});var L_t=s(NX);QKo=r(L_t,"Wav2Vec2ForCTC"),L_t.forEach(t),HKo=r(P$e," (Wav2Vec2 model)"),P$e.forEach(t),UKo=i(Xe),DF=n(Xe,"LI",{});var B$e=s(DF);L_e=n(B$e,"STRONG",{});var x_t=s(L_e);JKo=r(x_t,"wav2vec2-conformer"),x_t.forEach(t),YKo=r(B$e," \u2014 "),jX=n(B$e,"A",{href:!0});var $_t=s(jX);KKo=r($_t,"Wav2Vec2ConformerForCTC"),$_t.forEach(t),ZKo=r(B$e," (Wav2Vec2-Conformer model)"),B$e.forEach(t),eZo=i(Xe),GF=n(Xe,"LI",{});var I$e=s(GF);x_e=n(I$e,"STRONG",{});var k_t=s(x_e);oZo=r(k_t,"wavlm"),k_t.forEach(t),rZo=r(I$e," \u2014 "),DX=n(I$e,"A",{href:!0});var S_t=s(DX);tZo=r(S_t,"WavLMForCTC"),S_t.forEach(t),aZo=r(I$e," (WavLM model)"),I$e.forEach(t),Xe.forEach(t),nZo=i(_a),OF=n(_a,"P",{});var q$e=s(OF);sZo=r(q$e,"The model is set in evaluation mode by default using "),$_e=n(q$e,"CODE",{});var R_t=s($_e);lZo=r(R_t,"model.eval()"),R_t.forEach(t),iZo=r(q$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k_e=n(q$e,"CODE",{});var P_t=s(k_e);dZo=r(P_t,"model.train()"),P_t.forEach(t),q$e.forEach(t),cZo=i(_a),T(VF.$$.fragment,_a),_a.forEach(t),tl.forEach(t),Dqe=i(f),bd=n(f,"H2",{class:!0});var Xje=s(bd);XF=n(Xje,"A",{id:!0,class:!0,href:!0});var B_t=s(XF);S_e=n(B_t,"SPAN",{});var I_t=s(S_e);T(fL.$$.fragment,I_t),I_t.forEach(t),B_t.forEach(t),fZo=i(Xje),R_e=n(Xje,"SPAN",{});var q_t=s(R_e);mZo=r(q_t,"AutoModelForSpeechSeq2Seq"),q_t.forEach(t),Xje.forEach(t),Gqe=i(f),Xo=n(f,"DIV",{class:!0});var al=s(Xo);T(mL.$$.fragment,al),gZo=i(al),vd=n(al,"P",{});var uZ=s(vd);hZo=r(uZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),GX=n(uZ,"A",{href:!0});var N_t=s(GX);pZo=r(N_t,"from_pretrained()"),N_t.forEach(t),_Zo=r(uZ," class method or the "),OX=n(uZ,"A",{href:!0});var j_t=s(OX);uZo=r(j_t,"from_config()"),j_t.forEach(t),bZo=r(uZ,` class
method.`),uZ.forEach(t),vZo=i(al),gL=n(al,"P",{});var zje=s(gL);FZo=r(zje,"This class cannot be instantiated directly using "),P_e=n(zje,"CODE",{});var D_t=s(P_e);TZo=r(D_t,"__init__()"),D_t.forEach(t),MZo=r(zje," (throws an error)."),zje.forEach(t),EZo=i(al),Ft=n(al,"DIV",{class:!0});var U0=s(Ft);T(hL.$$.fragment,U0),CZo=i(U0),B_e=n(U0,"P",{});var G_t=s(B_e);wZo=r(G_t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),G_t.forEach(t),AZo=i(U0),Fd=n(U0,"P",{});var bZ=s(Fd);yZo=r(bZ,`Note:
Loading a model from its configuration file does `),I_e=n(bZ,"STRONG",{});var O_t=s(I_e);LZo=r(O_t,"not"),O_t.forEach(t),xZo=r(bZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),VX=n(bZ,"A",{href:!0});var V_t=s(VX);$Zo=r(V_t,"from_pretrained()"),V_t.forEach(t),kZo=r(bZ," to load the model weights."),bZ.forEach(t),SZo=i(U0),T(zF.$$.fragment,U0),U0.forEach(t),RZo=i(al),go=n(al,"DIV",{class:!0});var ua=s(go);T(pL.$$.fragment,ua),PZo=i(ua),q_e=n(ua,"P",{});var X_t=s(q_e);BZo=r(X_t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),X_t.forEach(t),IZo=i(ua),Xa=n(ua,"P",{});var J0=s(Xa);qZo=r(J0,"The model class to instantiate is selected based on the "),N_e=n(J0,"CODE",{});var z_t=s(N_e);NZo=r(z_t,"model_type"),z_t.forEach(t),jZo=r(J0,` property of the config object (either
passed as an argument or loaded from `),j_e=n(J0,"CODE",{});var W_t=s(j_e);DZo=r(W_t,"pretrained_model_name_or_path"),W_t.forEach(t),GZo=r(J0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D_e=n(J0,"CODE",{});var Q_t=s(D_e);OZo=r(Q_t,"pretrained_model_name_or_path"),Q_t.forEach(t),VZo=r(J0,":"),J0.forEach(t),XZo=i(ua),_L=n(ua,"UL",{});var Wje=s(_L);WF=n(Wje,"LI",{});var N$e=s(WF);G_e=n(N$e,"STRONG",{});var H_t=s(G_e);zZo=r(H_t,"speech-encoder-decoder"),H_t.forEach(t),WZo=r(N$e," \u2014 "),XX=n(N$e,"A",{href:!0});var U_t=s(XX);QZo=r(U_t,"SpeechEncoderDecoderModel"),U_t.forEach(t),HZo=r(N$e," (Speech Encoder decoder model)"),N$e.forEach(t),UZo=i(Wje),QF=n(Wje,"LI",{});var j$e=s(QF);O_e=n(j$e,"STRONG",{});var J_t=s(O_e);JZo=r(J_t,"speech_to_text"),J_t.forEach(t),YZo=r(j$e," \u2014 "),zX=n(j$e,"A",{href:!0});var Y_t=s(zX);KZo=r(Y_t,"Speech2TextForConditionalGeneration"),Y_t.forEach(t),ZZo=r(j$e," (Speech2Text model)"),j$e.forEach(t),Wje.forEach(t),eer=i(ua),HF=n(ua,"P",{});var D$e=s(HF);oer=r(D$e,"The model is set in evaluation mode by default using "),V_e=n(D$e,"CODE",{});var K_t=s(V_e);rer=r(K_t,"model.eval()"),K_t.forEach(t),ter=r(D$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X_e=n(D$e,"CODE",{});var Z_t=s(X_e);aer=r(Z_t,"model.train()"),Z_t.forEach(t),D$e.forEach(t),ner=i(ua),T(UF.$$.fragment,ua),ua.forEach(t),al.forEach(t),Oqe=i(f),Td=n(f,"H2",{class:!0});var Qje=s(Td);JF=n(Qje,"A",{id:!0,class:!0,href:!0});var eut=s(JF);z_e=n(eut,"SPAN",{});var out=s(z_e);T(uL.$$.fragment,out),out.forEach(t),eut.forEach(t),ser=i(Qje),W_e=n(Qje,"SPAN",{});var rut=s(W_e);ler=r(rut,"AutoModelForAudioXVector"),rut.forEach(t),Qje.forEach(t),Vqe=i(f),zo=n(f,"DIV",{class:!0});var nl=s(zo);T(bL.$$.fragment,nl),ier=i(nl),Md=n(nl,"P",{});var vZ=s(Md);der=r(vZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),WX=n(vZ,"A",{href:!0});var tut=s(WX);cer=r(tut,"from_pretrained()"),tut.forEach(t),fer=r(vZ," class method or the "),QX=n(vZ,"A",{href:!0});var aut=s(QX);mer=r(aut,"from_config()"),aut.forEach(t),ger=r(vZ,` class
method.`),vZ.forEach(t),her=i(nl),vL=n(nl,"P",{});var Hje=s(vL);per=r(Hje,"This class cannot be instantiated directly using "),Q_e=n(Hje,"CODE",{});var nut=s(Q_e);_er=r(nut,"__init__()"),nut.forEach(t),uer=r(Hje," (throws an error)."),Hje.forEach(t),ber=i(nl),Tt=n(nl,"DIV",{class:!0});var Y0=s(Tt);T(FL.$$.fragment,Y0),ver=i(Y0),H_e=n(Y0,"P",{});var sut=s(H_e);Fer=r(sut,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),sut.forEach(t),Ter=i(Y0),Ed=n(Y0,"P",{});var FZ=s(Ed);Mer=r(FZ,`Note:
Loading a model from its configuration file does `),U_e=n(FZ,"STRONG",{});var lut=s(U_e);Eer=r(lut,"not"),lut.forEach(t),Cer=r(FZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),HX=n(FZ,"A",{href:!0});var iut=s(HX);wer=r(iut,"from_pretrained()"),iut.forEach(t),Aer=r(FZ," to load the model weights."),FZ.forEach(t),yer=i(Y0),T(YF.$$.fragment,Y0),Y0.forEach(t),Ler=i(nl),ho=n(nl,"DIV",{class:!0});var ba=s(ho);T(TL.$$.fragment,ba),xer=i(ba),J_e=n(ba,"P",{});var dut=s(J_e);$er=r(dut,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dut.forEach(t),ker=i(ba),za=n(ba,"P",{});var K0=s(za);Ser=r(K0,"The model class to instantiate is selected based on the "),Y_e=n(K0,"CODE",{});var cut=s(Y_e);Rer=r(cut,"model_type"),cut.forEach(t),Per=r(K0,` property of the config object (either
passed as an argument or loaded from `),K_e=n(K0,"CODE",{});var fut=s(K_e);Ber=r(fut,"pretrained_model_name_or_path"),fut.forEach(t),Ier=r(K0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z_e=n(K0,"CODE",{});var mut=s(Z_e);qer=r(mut,"pretrained_model_name_or_path"),mut.forEach(t),Ner=r(K0,":"),K0.forEach(t),jer=i(ba),Zr=n(ba,"UL",{});var sl=s(Zr);KF=n(sl,"LI",{});var G$e=s(KF);eue=n(G$e,"STRONG",{});var gut=s(eue);Der=r(gut,"data2vec-audio"),gut.forEach(t),Ger=r(G$e," \u2014 "),UX=n(G$e,"A",{href:!0});var hut=s(UX);Oer=r(hut,"Data2VecAudioForXVector"),hut.forEach(t),Ver=r(G$e," (Data2VecAudio model)"),G$e.forEach(t),Xer=i(sl),ZF=n(sl,"LI",{});var O$e=s(ZF);oue=n(O$e,"STRONG",{});var put=s(oue);zer=r(put,"unispeech-sat"),put.forEach(t),Wer=r(O$e," \u2014 "),JX=n(O$e,"A",{href:!0});var _ut=s(JX);Qer=r(_ut,"UniSpeechSatForXVector"),_ut.forEach(t),Her=r(O$e," (UniSpeechSat model)"),O$e.forEach(t),Uer=i(sl),eT=n(sl,"LI",{});var V$e=s(eT);rue=n(V$e,"STRONG",{});var uut=s(rue);Jer=r(uut,"wav2vec2"),uut.forEach(t),Yer=r(V$e," \u2014 "),YX=n(V$e,"A",{href:!0});var but=s(YX);Ker=r(but,"Wav2Vec2ForXVector"),but.forEach(t),Zer=r(V$e," (Wav2Vec2 model)"),V$e.forEach(t),eor=i(sl),oT=n(sl,"LI",{});var X$e=s(oT);tue=n(X$e,"STRONG",{});var vut=s(tue);oor=r(vut,"wav2vec2-conformer"),vut.forEach(t),ror=r(X$e," \u2014 "),KX=n(X$e,"A",{href:!0});var Fut=s(KX);tor=r(Fut,"Wav2Vec2ConformerForXVector"),Fut.forEach(t),aor=r(X$e," (Wav2Vec2-Conformer model)"),X$e.forEach(t),nor=i(sl),rT=n(sl,"LI",{});var z$e=s(rT);aue=n(z$e,"STRONG",{});var Tut=s(aue);sor=r(Tut,"wavlm"),Tut.forEach(t),lor=r(z$e," \u2014 "),ZX=n(z$e,"A",{href:!0});var Mut=s(ZX);ior=r(Mut,"WavLMForXVector"),Mut.forEach(t),dor=r(z$e," (WavLM model)"),z$e.forEach(t),sl.forEach(t),cor=i(ba),tT=n(ba,"P",{});var W$e=s(tT);mor=r(W$e,"The model is set in evaluation mode by default using "),nue=n(W$e,"CODE",{});var Eut=s(nue);gor=r(Eut,"model.eval()"),Eut.forEach(t),hor=r(W$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sue=n(W$e,"CODE",{});var Cut=s(sue);por=r(Cut,"model.train()"),Cut.forEach(t),W$e.forEach(t),_or=i(ba),T(aT.$$.fragment,ba),ba.forEach(t),nl.forEach(t),Xqe=i(f),Cd=n(f,"H2",{class:!0});var Uje=s(Cd);nT=n(Uje,"A",{id:!0,class:!0,href:!0});var wut=s(nT);lue=n(wut,"SPAN",{});var Aut=s(lue);T(ML.$$.fragment,Aut),Aut.forEach(t),wut.forEach(t),uor=i(Uje),iue=n(Uje,"SPAN",{});var yut=s(iue);bor=r(yut,"AutoModelForMaskedImageModeling"),yut.forEach(t),Uje.forEach(t),zqe=i(f),Wo=n(f,"DIV",{class:!0});var ll=s(Wo);T(EL.$$.fragment,ll),vor=i(ll),wd=n(ll,"P",{});var TZ=s(wd);For=r(TZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),ez=n(TZ,"A",{href:!0});var Lut=s(ez);Tor=r(Lut,"from_pretrained()"),Lut.forEach(t),Mor=r(TZ," class method or the "),oz=n(TZ,"A",{href:!0});var xut=s(oz);Eor=r(xut,"from_config()"),xut.forEach(t),Cor=r(TZ,` class
method.`),TZ.forEach(t),wor=i(ll),CL=n(ll,"P",{});var Jje=s(CL);Aor=r(Jje,"This class cannot be instantiated directly using "),due=n(Jje,"CODE",{});var $ut=s(due);yor=r($ut,"__init__()"),$ut.forEach(t),Lor=r(Jje," (throws an error)."),Jje.forEach(t),xor=i(ll),Mt=n(ll,"DIV",{class:!0});var Z0=s(Mt);T(wL.$$.fragment,Z0),$or=i(Z0),cue=n(Z0,"P",{});var kut=s(cue);kor=r(kut,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),kut.forEach(t),Sor=i(Z0),Ad=n(Z0,"P",{});var MZ=s(Ad);Ror=r(MZ,`Note:
Loading a model from its configuration file does `),fue=n(MZ,"STRONG",{});var Sut=s(fue);Por=r(Sut,"not"),Sut.forEach(t),Bor=r(MZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),rz=n(MZ,"A",{href:!0});var Rut=s(rz);Ior=r(Rut,"from_pretrained()"),Rut.forEach(t),qor=r(MZ," to load the model weights."),MZ.forEach(t),Nor=i(Z0),T(sT.$$.fragment,Z0),Z0.forEach(t),jor=i(ll),po=n(ll,"DIV",{class:!0});var va=s(po);T(AL.$$.fragment,va),Dor=i(va),mue=n(va,"P",{});var Put=s(mue);Gor=r(Put,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Put.forEach(t),Oor=i(va),Wa=n(va,"P",{});var eA=s(Wa);Vor=r(eA,"The model class to instantiate is selected based on the "),gue=n(eA,"CODE",{});var But=s(gue);Xor=r(But,"model_type"),But.forEach(t),zor=r(eA,` property of the config object (either
passed as an argument or loaded from `),hue=n(eA,"CODE",{});var Iut=s(hue);Wor=r(Iut,"pretrained_model_name_or_path"),Iut.forEach(t),Qor=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pue=n(eA,"CODE",{});var qut=s(pue);Hor=r(qut,"pretrained_model_name_or_path"),qut.forEach(t),Uor=r(eA,":"),eA.forEach(t),Jor=i(va),yd=n(va,"UL",{});var EZ=s(yd);lT=n(EZ,"LI",{});var Q$e=s(lT);_ue=n(Q$e,"STRONG",{});var Nut=s(_ue);Yor=r(Nut,"deit"),Nut.forEach(t),Kor=r(Q$e," \u2014 "),tz=n(Q$e,"A",{href:!0});var jut=s(tz);Zor=r(jut,"DeiTForMaskedImageModeling"),jut.forEach(t),err=r(Q$e," (DeiT model)"),Q$e.forEach(t),orr=i(EZ),iT=n(EZ,"LI",{});var H$e=s(iT);uue=n(H$e,"STRONG",{});var Dut=s(uue);rrr=r(Dut,"swin"),Dut.forEach(t),trr=r(H$e," \u2014 "),az=n(H$e,"A",{href:!0});var Gut=s(az);arr=r(Gut,"SwinForMaskedImageModeling"),Gut.forEach(t),nrr=r(H$e," (Swin model)"),H$e.forEach(t),srr=i(EZ),dT=n(EZ,"LI",{});var U$e=s(dT);bue=n(U$e,"STRONG",{});var Out=s(bue);lrr=r(Out,"vit"),Out.forEach(t),irr=r(U$e," \u2014 "),nz=n(U$e,"A",{href:!0});var Vut=s(nz);drr=r(Vut,"ViTForMaskedImageModeling"),Vut.forEach(t),crr=r(U$e," (ViT model)"),U$e.forEach(t),EZ.forEach(t),frr=i(va),cT=n(va,"P",{});var J$e=s(cT);mrr=r(J$e,"The model is set in evaluation mode by default using "),vue=n(J$e,"CODE",{});var Xut=s(vue);grr=r(Xut,"model.eval()"),Xut.forEach(t),hrr=r(J$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fue=n(J$e,"CODE",{});var zut=s(Fue);prr=r(zut,"model.train()"),zut.forEach(t),J$e.forEach(t),_rr=i(va),T(fT.$$.fragment,va),va.forEach(t),ll.forEach(t),Wqe=i(f),Ld=n(f,"H2",{class:!0});var Yje=s(Ld);mT=n(Yje,"A",{id:!0,class:!0,href:!0});var Wut=s(mT);Tue=n(Wut,"SPAN",{});var Qut=s(Tue);T(yL.$$.fragment,Qut),Qut.forEach(t),Wut.forEach(t),urr=i(Yje),Mue=n(Yje,"SPAN",{});var Hut=s(Mue);brr=r(Hut,"AutoModelForObjectDetection"),Hut.forEach(t),Yje.forEach(t),Qqe=i(f),Qo=n(f,"DIV",{class:!0});var il=s(Qo);T(LL.$$.fragment,il),vrr=i(il),xd=n(il,"P",{});var CZ=s(xd);Frr=r(CZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),sz=n(CZ,"A",{href:!0});var Uut=s(sz);Trr=r(Uut,"from_pretrained()"),Uut.forEach(t),Mrr=r(CZ," class method or the "),lz=n(CZ,"A",{href:!0});var Jut=s(lz);Err=r(Jut,"from_config()"),Jut.forEach(t),Crr=r(CZ,` class
method.`),CZ.forEach(t),wrr=i(il),xL=n(il,"P",{});var Kje=s(xL);Arr=r(Kje,"This class cannot be instantiated directly using "),Eue=n(Kje,"CODE",{});var Yut=s(Eue);yrr=r(Yut,"__init__()"),Yut.forEach(t),Lrr=r(Kje," (throws an error)."),Kje.forEach(t),xrr=i(il),Et=n(il,"DIV",{class:!0});var oA=s(Et);T($L.$$.fragment,oA),$rr=i(oA),Cue=n(oA,"P",{});var Kut=s(Cue);krr=r(Kut,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Kut.forEach(t),Srr=i(oA),$d=n(oA,"P",{});var wZ=s($d);Rrr=r(wZ,`Note:
Loading a model from its configuration file does `),wue=n(wZ,"STRONG",{});var Zut=s(wue);Prr=r(Zut,"not"),Zut.forEach(t),Brr=r(wZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=n(wZ,"A",{href:!0});var e2t=s(iz);Irr=r(e2t,"from_pretrained()"),e2t.forEach(t),qrr=r(wZ," to load the model weights."),wZ.forEach(t),Nrr=i(oA),T(gT.$$.fragment,oA),oA.forEach(t),jrr=i(il),_o=n(il,"DIV",{class:!0});var Fa=s(_o);T(kL.$$.fragment,Fa),Drr=i(Fa),Aue=n(Fa,"P",{});var o2t=s(Aue);Grr=r(o2t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),o2t.forEach(t),Orr=i(Fa),Qa=n(Fa,"P",{});var rA=s(Qa);Vrr=r(rA,"The model class to instantiate is selected based on the "),yue=n(rA,"CODE",{});var r2t=s(yue);Xrr=r(r2t,"model_type"),r2t.forEach(t),zrr=r(rA,` property of the config object (either
passed as an argument or loaded from `),Lue=n(rA,"CODE",{});var t2t=s(Lue);Wrr=r(t2t,"pretrained_model_name_or_path"),t2t.forEach(t),Qrr=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xue=n(rA,"CODE",{});var a2t=s(xue);Hrr=r(a2t,"pretrained_model_name_or_path"),a2t.forEach(t),Urr=r(rA,":"),rA.forEach(t),Jrr=i(Fa),SL=n(Fa,"UL",{});var Zje=s(SL);hT=n(Zje,"LI",{});var Y$e=s(hT);$ue=n(Y$e,"STRONG",{});var n2t=s($ue);Yrr=r(n2t,"detr"),n2t.forEach(t),Krr=r(Y$e," \u2014 "),dz=n(Y$e,"A",{href:!0});var s2t=s(dz);Zrr=r(s2t,"DetrForObjectDetection"),s2t.forEach(t),etr=r(Y$e," (DETR model)"),Y$e.forEach(t),otr=i(Zje),pT=n(Zje,"LI",{});var K$e=s(pT);kue=n(K$e,"STRONG",{});var l2t=s(kue);rtr=r(l2t,"yolos"),l2t.forEach(t),ttr=r(K$e," \u2014 "),cz=n(K$e,"A",{href:!0});var i2t=s(cz);atr=r(i2t,"YolosForObjectDetection"),i2t.forEach(t),ntr=r(K$e," (YOLOS model)"),K$e.forEach(t),Zje.forEach(t),str=i(Fa),_T=n(Fa,"P",{});var Z$e=s(_T);ltr=r(Z$e,"The model is set in evaluation mode by default using "),Sue=n(Z$e,"CODE",{});var d2t=s(Sue);itr=r(d2t,"model.eval()"),d2t.forEach(t),dtr=r(Z$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rue=n(Z$e,"CODE",{});var c2t=s(Rue);ctr=r(c2t,"model.train()"),c2t.forEach(t),Z$e.forEach(t),ftr=i(Fa),T(uT.$$.fragment,Fa),Fa.forEach(t),il.forEach(t),Hqe=i(f),kd=n(f,"H2",{class:!0});var eDe=s(kd);bT=n(eDe,"A",{id:!0,class:!0,href:!0});var f2t=s(bT);Pue=n(f2t,"SPAN",{});var m2t=s(Pue);T(RL.$$.fragment,m2t),m2t.forEach(t),f2t.forEach(t),mtr=i(eDe),Bue=n(eDe,"SPAN",{});var g2t=s(Bue);gtr=r(g2t,"AutoModelForImageSegmentation"),g2t.forEach(t),eDe.forEach(t),Uqe=i(f),Ho=n(f,"DIV",{class:!0});var dl=s(Ho);T(PL.$$.fragment,dl),htr=i(dl),Sd=n(dl,"P",{});var AZ=s(Sd);ptr=r(AZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),fz=n(AZ,"A",{href:!0});var h2t=s(fz);_tr=r(h2t,"from_pretrained()"),h2t.forEach(t),utr=r(AZ," class method or the "),mz=n(AZ,"A",{href:!0});var p2t=s(mz);btr=r(p2t,"from_config()"),p2t.forEach(t),vtr=r(AZ,` class
method.`),AZ.forEach(t),Ftr=i(dl),BL=n(dl,"P",{});var oDe=s(BL);Ttr=r(oDe,"This class cannot be instantiated directly using "),Iue=n(oDe,"CODE",{});var _2t=s(Iue);Mtr=r(_2t,"__init__()"),_2t.forEach(t),Etr=r(oDe," (throws an error)."),oDe.forEach(t),Ctr=i(dl),Ct=n(dl,"DIV",{class:!0});var tA=s(Ct);T(IL.$$.fragment,tA),wtr=i(tA),que=n(tA,"P",{});var u2t=s(que);Atr=r(u2t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),u2t.forEach(t),ytr=i(tA),Rd=n(tA,"P",{});var yZ=s(Rd);Ltr=r(yZ,`Note:
Loading a model from its configuration file does `),Nue=n(yZ,"STRONG",{});var b2t=s(Nue);xtr=r(b2t,"not"),b2t.forEach(t),$tr=r(yZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),gz=n(yZ,"A",{href:!0});var v2t=s(gz);ktr=r(v2t,"from_pretrained()"),v2t.forEach(t),Str=r(yZ," to load the model weights."),yZ.forEach(t),Rtr=i(tA),T(vT.$$.fragment,tA),tA.forEach(t),Ptr=i(dl),uo=n(dl,"DIV",{class:!0});var Ta=s(uo);T(qL.$$.fragment,Ta),Btr=i(Ta),jue=n(Ta,"P",{});var F2t=s(jue);Itr=r(F2t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),F2t.forEach(t),qtr=i(Ta),Ha=n(Ta,"P",{});var aA=s(Ha);Ntr=r(aA,"The model class to instantiate is selected based on the "),Due=n(aA,"CODE",{});var T2t=s(Due);jtr=r(T2t,"model_type"),T2t.forEach(t),Dtr=r(aA,` property of the config object (either
passed as an argument or loaded from `),Gue=n(aA,"CODE",{});var M2t=s(Gue);Gtr=r(M2t,"pretrained_model_name_or_path"),M2t.forEach(t),Otr=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oue=n(aA,"CODE",{});var E2t=s(Oue);Vtr=r(E2t,"pretrained_model_name_or_path"),E2t.forEach(t),Xtr=r(aA,":"),aA.forEach(t),ztr=i(Ta),Vue=n(Ta,"UL",{});var C2t=s(Vue);FT=n(C2t,"LI",{});var eke=s(FT);Xue=n(eke,"STRONG",{});var w2t=s(Xue);Wtr=r(w2t,"detr"),w2t.forEach(t),Qtr=r(eke," \u2014 "),hz=n(eke,"A",{href:!0});var A2t=s(hz);Htr=r(A2t,"DetrForSegmentation"),A2t.forEach(t),Utr=r(eke," (DETR model)"),eke.forEach(t),C2t.forEach(t),Jtr=i(Ta),TT=n(Ta,"P",{});var oke=s(TT);Ytr=r(oke,"The model is set in evaluation mode by default using "),zue=n(oke,"CODE",{});var y2t=s(zue);Ktr=r(y2t,"model.eval()"),y2t.forEach(t),Ztr=r(oke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wue=n(oke,"CODE",{});var L2t=s(Wue);ear=r(L2t,"model.train()"),L2t.forEach(t),oke.forEach(t),oar=i(Ta),T(MT.$$.fragment,Ta),Ta.forEach(t),dl.forEach(t),Jqe=i(f),Pd=n(f,"H2",{class:!0});var rDe=s(Pd);ET=n(rDe,"A",{id:!0,class:!0,href:!0});var x2t=s(ET);Que=n(x2t,"SPAN",{});var $2t=s(Que);T(NL.$$.fragment,$2t),$2t.forEach(t),x2t.forEach(t),rar=i(rDe),Hue=n(rDe,"SPAN",{});var k2t=s(Hue);tar=r(k2t,"AutoModelForSemanticSegmentation"),k2t.forEach(t),rDe.forEach(t),Yqe=i(f),Uo=n(f,"DIV",{class:!0});var cl=s(Uo);T(jL.$$.fragment,cl),aar=i(cl),Bd=n(cl,"P",{});var LZ=s(Bd);nar=r(LZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pz=n(LZ,"A",{href:!0});var S2t=s(pz);sar=r(S2t,"from_pretrained()"),S2t.forEach(t),lar=r(LZ," class method or the "),_z=n(LZ,"A",{href:!0});var R2t=s(_z);iar=r(R2t,"from_config()"),R2t.forEach(t),dar=r(LZ,` class
method.`),LZ.forEach(t),car=i(cl),DL=n(cl,"P",{});var tDe=s(DL);far=r(tDe,"This class cannot be instantiated directly using "),Uue=n(tDe,"CODE",{});var P2t=s(Uue);mar=r(P2t,"__init__()"),P2t.forEach(t),gar=r(tDe," (throws an error)."),tDe.forEach(t),har=i(cl),wt=n(cl,"DIV",{class:!0});var nA=s(wt);T(GL.$$.fragment,nA),par=i(nA),Jue=n(nA,"P",{});var B2t=s(Jue);_ar=r(B2t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),B2t.forEach(t),uar=i(nA),Id=n(nA,"P",{});var xZ=s(Id);bar=r(xZ,`Note:
Loading a model from its configuration file does `),Yue=n(xZ,"STRONG",{});var I2t=s(Yue);Far=r(I2t,"not"),I2t.forEach(t),Tar=r(xZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),uz=n(xZ,"A",{href:!0});var q2t=s(uz);Mar=r(q2t,"from_pretrained()"),q2t.forEach(t),Ear=r(xZ," to load the model weights."),xZ.forEach(t),Car=i(nA),T(CT.$$.fragment,nA),nA.forEach(t),war=i(cl),bo=n(cl,"DIV",{class:!0});var Ma=s(bo);T(OL.$$.fragment,Ma),Aar=i(Ma),Kue=n(Ma,"P",{});var N2t=s(Kue);yar=r(N2t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),N2t.forEach(t),Lar=i(Ma),Ua=n(Ma,"P",{});var sA=s(Ua);xar=r(sA,"The model class to instantiate is selected based on the "),Zue=n(sA,"CODE",{});var j2t=s(Zue);$ar=r(j2t,"model_type"),j2t.forEach(t),kar=r(sA,` property of the config object (either
passed as an argument or loaded from `),e2e=n(sA,"CODE",{});var D2t=s(e2e);Sar=r(D2t,"pretrained_model_name_or_path"),D2t.forEach(t),Rar=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=n(sA,"CODE",{});var G2t=s(o2e);Par=r(G2t,"pretrained_model_name_or_path"),G2t.forEach(t),Bar=r(sA,":"),sA.forEach(t),Iar=i(Ma),Ja=n(Ma,"UL",{});var lA=s(Ja);wT=n(lA,"LI",{});var rke=s(wT);r2e=n(rke,"STRONG",{});var O2t=s(r2e);qar=r(O2t,"beit"),O2t.forEach(t),Nar=r(rke," \u2014 "),bz=n(rke,"A",{href:!0});var V2t=s(bz);jar=r(V2t,"BeitForSemanticSegmentation"),V2t.forEach(t),Dar=r(rke," (BEiT model)"),rke.forEach(t),Gar=i(lA),AT=n(lA,"LI",{});var tke=s(AT);t2e=n(tke,"STRONG",{});var X2t=s(t2e);Oar=r(X2t,"data2vec-vision"),X2t.forEach(t),Var=r(tke," \u2014 "),vz=n(tke,"A",{href:!0});var z2t=s(vz);Xar=r(z2t,"Data2VecVisionForSemanticSegmentation"),z2t.forEach(t),zar=r(tke," (Data2VecVision model)"),tke.forEach(t),War=i(lA),yT=n(lA,"LI",{});var ake=s(yT);a2e=n(ake,"STRONG",{});var W2t=s(a2e);Qar=r(W2t,"dpt"),W2t.forEach(t),Har=r(ake," \u2014 "),Fz=n(ake,"A",{href:!0});var Q2t=s(Fz);Uar=r(Q2t,"DPTForSemanticSegmentation"),Q2t.forEach(t),Jar=r(ake," (DPT model)"),ake.forEach(t),Yar=i(lA),LT=n(lA,"LI",{});var nke=s(LT);n2e=n(nke,"STRONG",{});var H2t=s(n2e);Kar=r(H2t,"segformer"),H2t.forEach(t),Zar=r(nke," \u2014 "),Tz=n(nke,"A",{href:!0});var U2t=s(Tz);enr=r(U2t,"SegformerForSemanticSegmentation"),U2t.forEach(t),onr=r(nke," (SegFormer model)"),nke.forEach(t),lA.forEach(t),rnr=i(Ma),xT=n(Ma,"P",{});var ske=s(xT);tnr=r(ske,"The model is set in evaluation mode by default using "),s2e=n(ske,"CODE",{});var J2t=s(s2e);anr=r(J2t,"model.eval()"),J2t.forEach(t),nnr=r(ske,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l2e=n(ske,"CODE",{});var Y2t=s(l2e);snr=r(Y2t,"model.train()"),Y2t.forEach(t),ske.forEach(t),lnr=i(Ma),T($T.$$.fragment,Ma),Ma.forEach(t),cl.forEach(t),Kqe=i(f),qd=n(f,"H2",{class:!0});var aDe=s(qd);kT=n(aDe,"A",{id:!0,class:!0,href:!0});var K2t=s(kT);i2e=n(K2t,"SPAN",{});var Z2t=s(i2e);T(VL.$$.fragment,Z2t),Z2t.forEach(t),K2t.forEach(t),inr=i(aDe),d2e=n(aDe,"SPAN",{});var e1t=s(d2e);dnr=r(e1t,"AutoModelForInstanceSegmentation"),e1t.forEach(t),aDe.forEach(t),Zqe=i(f),Jo=n(f,"DIV",{class:!0});var fl=s(Jo);T(XL.$$.fragment,fl),cnr=i(fl),Nd=n(fl,"P",{});var $Z=s(Nd);fnr=r($Z,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Mz=n($Z,"A",{href:!0});var o1t=s(Mz);mnr=r(o1t,"from_pretrained()"),o1t.forEach(t),gnr=r($Z," class method or the "),Ez=n($Z,"A",{href:!0});var r1t=s(Ez);hnr=r(r1t,"from_config()"),r1t.forEach(t),pnr=r($Z,` class
method.`),$Z.forEach(t),_nr=i(fl),zL=n(fl,"P",{});var nDe=s(zL);unr=r(nDe,"This class cannot be instantiated directly using "),c2e=n(nDe,"CODE",{});var t1t=s(c2e);bnr=r(t1t,"__init__()"),t1t.forEach(t),vnr=r(nDe," (throws an error)."),nDe.forEach(t),Fnr=i(fl),At=n(fl,"DIV",{class:!0});var iA=s(At);T(WL.$$.fragment,iA),Tnr=i(iA),f2e=n(iA,"P",{});var a1t=s(f2e);Mnr=r(a1t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),a1t.forEach(t),Enr=i(iA),jd=n(iA,"P",{});var kZ=s(jd);Cnr=r(kZ,`Note:
Loading a model from its configuration file does `),m2e=n(kZ,"STRONG",{});var n1t=s(m2e);wnr=r(n1t,"not"),n1t.forEach(t),Anr=r(kZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cz=n(kZ,"A",{href:!0});var s1t=s(Cz);ynr=r(s1t,"from_pretrained()"),s1t.forEach(t),Lnr=r(kZ," to load the model weights."),kZ.forEach(t),xnr=i(iA),T(ST.$$.fragment,iA),iA.forEach(t),$nr=i(fl),vo=n(fl,"DIV",{class:!0});var Ea=s(vo);T(QL.$$.fragment,Ea),knr=i(Ea),g2e=n(Ea,"P",{});var l1t=s(g2e);Snr=r(l1t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),l1t.forEach(t),Rnr=i(Ea),Ya=n(Ea,"P",{});var dA=s(Ya);Pnr=r(dA,"The model class to instantiate is selected based on the "),h2e=n(dA,"CODE",{});var i1t=s(h2e);Bnr=r(i1t,"model_type"),i1t.forEach(t),Inr=r(dA,` property of the config object (either
passed as an argument or loaded from `),p2e=n(dA,"CODE",{});var d1t=s(p2e);qnr=r(d1t,"pretrained_model_name_or_path"),d1t.forEach(t),Nnr=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_2e=n(dA,"CODE",{});var c1t=s(_2e);jnr=r(c1t,"pretrained_model_name_or_path"),c1t.forEach(t),Dnr=r(dA,":"),dA.forEach(t),Gnr=i(Ea),u2e=n(Ea,"UL",{});var f1t=s(u2e);RT=n(f1t,"LI",{});var lke=s(RT);b2e=n(lke,"STRONG",{});var m1t=s(b2e);Onr=r(m1t,"maskformer"),m1t.forEach(t),Vnr=r(lke," \u2014 "),wz=n(lke,"A",{href:!0});var g1t=s(wz);Xnr=r(g1t,"MaskFormerForInstanceSegmentation"),g1t.forEach(t),znr=r(lke," (MaskFormer model)"),lke.forEach(t),f1t.forEach(t),Wnr=i(Ea),PT=n(Ea,"P",{});var ike=s(PT);Qnr=r(ike,"The model is set in evaluation mode by default using "),v2e=n(ike,"CODE",{});var h1t=s(v2e);Hnr=r(h1t,"model.eval()"),h1t.forEach(t),Unr=r(ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F2e=n(ike,"CODE",{});var p1t=s(F2e);Jnr=r(p1t,"model.train()"),p1t.forEach(t),ike.forEach(t),Ynr=i(Ea),T(BT.$$.fragment,Ea),Ea.forEach(t),fl.forEach(t),eNe=i(f),Dd=n(f,"H2",{class:!0});var sDe=s(Dd);IT=n(sDe,"A",{id:!0,class:!0,href:!0});var _1t=s(IT);T2e=n(_1t,"SPAN",{});var u1t=s(T2e);T(HL.$$.fragment,u1t),u1t.forEach(t),_1t.forEach(t),Knr=i(sDe),M2e=n(sDe,"SPAN",{});var b1t=s(M2e);Znr=r(b1t,"TFAutoModel"),b1t.forEach(t),sDe.forEach(t),oNe=i(f),Yo=n(f,"DIV",{class:!0});var ml=s(Yo);T(UL.$$.fragment,ml),esr=i(ml),Gd=n(ml,"P",{});var SZ=s(Gd);osr=r(SZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Az=n(SZ,"A",{href:!0});var v1t=s(Az);rsr=r(v1t,"from_pretrained()"),v1t.forEach(t),tsr=r(SZ," class method or the "),yz=n(SZ,"A",{href:!0});var F1t=s(yz);asr=r(F1t,"from_config()"),F1t.forEach(t),nsr=r(SZ,` class
method.`),SZ.forEach(t),ssr=i(ml),JL=n(ml,"P",{});var lDe=s(JL);lsr=r(lDe,"This class cannot be instantiated directly using "),E2e=n(lDe,"CODE",{});var T1t=s(E2e);isr=r(T1t,"__init__()"),T1t.forEach(t),dsr=r(lDe," (throws an error)."),lDe.forEach(t),csr=i(ml),yt=n(ml,"DIV",{class:!0});var cA=s(yt);T(YL.$$.fragment,cA),fsr=i(cA),C2e=n(cA,"P",{});var M1t=s(C2e);msr=r(M1t,"Instantiates one of the base model classes of the library from a configuration."),M1t.forEach(t),gsr=i(cA),Od=n(cA,"P",{});var RZ=s(Od);hsr=r(RZ,`Note:
Loading a model from its configuration file does `),w2e=n(RZ,"STRONG",{});var E1t=s(w2e);psr=r(E1t,"not"),E1t.forEach(t),_sr=r(RZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lz=n(RZ,"A",{href:!0});var C1t=s(Lz);usr=r(C1t,"from_pretrained()"),C1t.forEach(t),bsr=r(RZ," to load the model weights."),RZ.forEach(t),vsr=i(cA),T(qT.$$.fragment,cA),cA.forEach(t),Fsr=i(ml),wr=n(ml,"DIV",{class:!0});var gl=s(wr);T(KL.$$.fragment,gl),Tsr=i(gl),A2e=n(gl,"P",{});var w1t=s(A2e);Msr=r(w1t,"Instantiate one of the base model classes of the library from a pretrained model."),w1t.forEach(t),Esr=i(gl),Ka=n(gl,"P",{});var fA=s(Ka);Csr=r(fA,"The model class to instantiate is selected based on the "),y2e=n(fA,"CODE",{});var A1t=s(y2e);wsr=r(A1t,"model_type"),A1t.forEach(t),Asr=r(fA,` property of the config object (either
passed as an argument or loaded from `),L2e=n(fA,"CODE",{});var y1t=s(L2e);ysr=r(y1t,"pretrained_model_name_or_path"),y1t.forEach(t),Lsr=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x2e=n(fA,"CODE",{});var L1t=s(x2e);xsr=r(L1t,"pretrained_model_name_or_path"),L1t.forEach(t),$sr=r(fA,":"),fA.forEach(t),ksr=i(gl),q=n(gl,"UL",{});var j=s(q);NT=n(j,"LI",{});var dke=s(NT);$2e=n(dke,"STRONG",{});var x1t=s($2e);Ssr=r(x1t,"albert"),x1t.forEach(t),Rsr=r(dke," \u2014 "),xz=n(dke,"A",{href:!0});var $1t=s(xz);Psr=r($1t,"TFAlbertModel"),$1t.forEach(t),Bsr=r(dke," (ALBERT model)"),dke.forEach(t),Isr=i(j),jT=n(j,"LI",{});var cke=s(jT);k2e=n(cke,"STRONG",{});var k1t=s(k2e);qsr=r(k1t,"bart"),k1t.forEach(t),Nsr=r(cke," \u2014 "),$z=n(cke,"A",{href:!0});var S1t=s($z);jsr=r(S1t,"TFBartModel"),S1t.forEach(t),Dsr=r(cke," (BART model)"),cke.forEach(t),Gsr=i(j),DT=n(j,"LI",{});var fke=s(DT);S2e=n(fke,"STRONG",{});var R1t=s(S2e);Osr=r(R1t,"bert"),R1t.forEach(t),Vsr=r(fke," \u2014 "),kz=n(fke,"A",{href:!0});var P1t=s(kz);Xsr=r(P1t,"TFBertModel"),P1t.forEach(t),zsr=r(fke," (BERT model)"),fke.forEach(t),Wsr=i(j),GT=n(j,"LI",{});var mke=s(GT);R2e=n(mke,"STRONG",{});var B1t=s(R2e);Qsr=r(B1t,"blenderbot"),B1t.forEach(t),Hsr=r(mke," \u2014 "),Sz=n(mke,"A",{href:!0});var I1t=s(Sz);Usr=r(I1t,"TFBlenderbotModel"),I1t.forEach(t),Jsr=r(mke," (Blenderbot model)"),mke.forEach(t),Ysr=i(j),OT=n(j,"LI",{});var gke=s(OT);P2e=n(gke,"STRONG",{});var q1t=s(P2e);Ksr=r(q1t,"blenderbot-small"),q1t.forEach(t),Zsr=r(gke," \u2014 "),Rz=n(gke,"A",{href:!0});var N1t=s(Rz);elr=r(N1t,"TFBlenderbotSmallModel"),N1t.forEach(t),olr=r(gke," (BlenderbotSmall model)"),gke.forEach(t),rlr=i(j),VT=n(j,"LI",{});var hke=s(VT);B2e=n(hke,"STRONG",{});var j1t=s(B2e);tlr=r(j1t,"camembert"),j1t.forEach(t),alr=r(hke," \u2014 "),Pz=n(hke,"A",{href:!0});var D1t=s(Pz);nlr=r(D1t,"TFCamembertModel"),D1t.forEach(t),slr=r(hke," (CamemBERT model)"),hke.forEach(t),llr=i(j),XT=n(j,"LI",{});var pke=s(XT);I2e=n(pke,"STRONG",{});var G1t=s(I2e);ilr=r(G1t,"clip"),G1t.forEach(t),dlr=r(pke," \u2014 "),Bz=n(pke,"A",{href:!0});var O1t=s(Bz);clr=r(O1t,"TFCLIPModel"),O1t.forEach(t),flr=r(pke," (CLIP model)"),pke.forEach(t),mlr=i(j),zT=n(j,"LI",{});var _ke=s(zT);q2e=n(_ke,"STRONG",{});var V1t=s(q2e);glr=r(V1t,"convbert"),V1t.forEach(t),hlr=r(_ke," \u2014 "),Iz=n(_ke,"A",{href:!0});var X1t=s(Iz);plr=r(X1t,"TFConvBertModel"),X1t.forEach(t),_lr=r(_ke," (ConvBERT model)"),_ke.forEach(t),ulr=i(j),WT=n(j,"LI",{});var uke=s(WT);N2e=n(uke,"STRONG",{});var z1t=s(N2e);blr=r(z1t,"convnext"),z1t.forEach(t),vlr=r(uke," \u2014 "),qz=n(uke,"A",{href:!0});var W1t=s(qz);Flr=r(W1t,"TFConvNextModel"),W1t.forEach(t),Tlr=r(uke," (ConvNext model)"),uke.forEach(t),Mlr=i(j),QT=n(j,"LI",{});var bke=s(QT);j2e=n(bke,"STRONG",{});var Q1t=s(j2e);Elr=r(Q1t,"ctrl"),Q1t.forEach(t),Clr=r(bke," \u2014 "),Nz=n(bke,"A",{href:!0});var H1t=s(Nz);wlr=r(H1t,"TFCTRLModel"),H1t.forEach(t),Alr=r(bke," (CTRL model)"),bke.forEach(t),ylr=i(j),HT=n(j,"LI",{});var vke=s(HT);D2e=n(vke,"STRONG",{});var U1t=s(D2e);Llr=r(U1t,"data2vec-vision"),U1t.forEach(t),xlr=r(vke," \u2014 "),jz=n(vke,"A",{href:!0});var J1t=s(jz);$lr=r(J1t,"TFData2VecVisionModel"),J1t.forEach(t),klr=r(vke," (Data2VecVision model)"),vke.forEach(t),Slr=i(j),UT=n(j,"LI",{});var Fke=s(UT);G2e=n(Fke,"STRONG",{});var Y1t=s(G2e);Rlr=r(Y1t,"deberta"),Y1t.forEach(t),Plr=r(Fke," \u2014 "),Dz=n(Fke,"A",{href:!0});var K1t=s(Dz);Blr=r(K1t,"TFDebertaModel"),K1t.forEach(t),Ilr=r(Fke," (DeBERTa model)"),Fke.forEach(t),qlr=i(j),JT=n(j,"LI",{});var Tke=s(JT);O2e=n(Tke,"STRONG",{});var Z1t=s(O2e);Nlr=r(Z1t,"deberta-v2"),Z1t.forEach(t),jlr=r(Tke," \u2014 "),Gz=n(Tke,"A",{href:!0});var e7t=s(Gz);Dlr=r(e7t,"TFDebertaV2Model"),e7t.forEach(t),Glr=r(Tke," (DeBERTa-v2 model)"),Tke.forEach(t),Olr=i(j),YT=n(j,"LI",{});var Mke=s(YT);V2e=n(Mke,"STRONG",{});var o7t=s(V2e);Vlr=r(o7t,"distilbert"),o7t.forEach(t),Xlr=r(Mke," \u2014 "),Oz=n(Mke,"A",{href:!0});var r7t=s(Oz);zlr=r(r7t,"TFDistilBertModel"),r7t.forEach(t),Wlr=r(Mke," (DistilBERT model)"),Mke.forEach(t),Qlr=i(j),KT=n(j,"LI",{});var Eke=s(KT);X2e=n(Eke,"STRONG",{});var t7t=s(X2e);Hlr=r(t7t,"dpr"),t7t.forEach(t),Ulr=r(Eke," \u2014 "),Vz=n(Eke,"A",{href:!0});var a7t=s(Vz);Jlr=r(a7t,"TFDPRQuestionEncoder"),a7t.forEach(t),Ylr=r(Eke," (DPR model)"),Eke.forEach(t),Klr=i(j),ZT=n(j,"LI",{});var Cke=s(ZT);z2e=n(Cke,"STRONG",{});var n7t=s(z2e);Zlr=r(n7t,"electra"),n7t.forEach(t),eir=r(Cke," \u2014 "),Xz=n(Cke,"A",{href:!0});var s7t=s(Xz);oir=r(s7t,"TFElectraModel"),s7t.forEach(t),rir=r(Cke," (ELECTRA model)"),Cke.forEach(t),tir=i(j),eM=n(j,"LI",{});var wke=s(eM);W2e=n(wke,"STRONG",{});var l7t=s(W2e);air=r(l7t,"flaubert"),l7t.forEach(t),nir=r(wke," \u2014 "),zz=n(wke,"A",{href:!0});var i7t=s(zz);sir=r(i7t,"TFFlaubertModel"),i7t.forEach(t),lir=r(wke," (FlauBERT model)"),wke.forEach(t),iir=i(j),Bs=n(j,"LI",{});var x$=s(Bs);Q2e=n(x$,"STRONG",{});var d7t=s(Q2e);dir=r(d7t,"funnel"),d7t.forEach(t),cir=r(x$," \u2014 "),Wz=n(x$,"A",{href:!0});var c7t=s(Wz);fir=r(c7t,"TFFunnelModel"),c7t.forEach(t),mir=r(x$," or "),Qz=n(x$,"A",{href:!0});var f7t=s(Qz);gir=r(f7t,"TFFunnelBaseModel"),f7t.forEach(t),hir=r(x$," (Funnel Transformer model)"),x$.forEach(t),pir=i(j),oM=n(j,"LI",{});var Ake=s(oM);H2e=n(Ake,"STRONG",{});var m7t=s(H2e);_ir=r(m7t,"gpt2"),m7t.forEach(t),uir=r(Ake," \u2014 "),Hz=n(Ake,"A",{href:!0});var g7t=s(Hz);bir=r(g7t,"TFGPT2Model"),g7t.forEach(t),vir=r(Ake," (OpenAI GPT-2 model)"),Ake.forEach(t),Fir=i(j),rM=n(j,"LI",{});var yke=s(rM);U2e=n(yke,"STRONG",{});var h7t=s(U2e);Tir=r(h7t,"gptj"),h7t.forEach(t),Mir=r(yke," \u2014 "),Uz=n(yke,"A",{href:!0});var p7t=s(Uz);Eir=r(p7t,"TFGPTJModel"),p7t.forEach(t),Cir=r(yke," (GPT-J model)"),yke.forEach(t),wir=i(j),tM=n(j,"LI",{});var Lke=s(tM);J2e=n(Lke,"STRONG",{});var _7t=s(J2e);Air=r(_7t,"hubert"),_7t.forEach(t),yir=r(Lke," \u2014 "),Jz=n(Lke,"A",{href:!0});var u7t=s(Jz);Lir=r(u7t,"TFHubertModel"),u7t.forEach(t),xir=r(Lke," (Hubert model)"),Lke.forEach(t),$ir=i(j),aM=n(j,"LI",{});var xke=s(aM);Y2e=n(xke,"STRONG",{});var b7t=s(Y2e);kir=r(b7t,"layoutlm"),b7t.forEach(t),Sir=r(xke," \u2014 "),Yz=n(xke,"A",{href:!0});var v7t=s(Yz);Rir=r(v7t,"TFLayoutLMModel"),v7t.forEach(t),Pir=r(xke," (LayoutLM model)"),xke.forEach(t),Bir=i(j),nM=n(j,"LI",{});var $ke=s(nM);K2e=n($ke,"STRONG",{});var F7t=s(K2e);Iir=r(F7t,"led"),F7t.forEach(t),qir=r($ke," \u2014 "),Kz=n($ke,"A",{href:!0});var T7t=s(Kz);Nir=r(T7t,"TFLEDModel"),T7t.forEach(t),jir=r($ke," (LED model)"),$ke.forEach(t),Dir=i(j),sM=n(j,"LI",{});var kke=s(sM);Z2e=n(kke,"STRONG",{});var M7t=s(Z2e);Gir=r(M7t,"longformer"),M7t.forEach(t),Oir=r(kke," \u2014 "),Zz=n(kke,"A",{href:!0});var E7t=s(Zz);Vir=r(E7t,"TFLongformerModel"),E7t.forEach(t),Xir=r(kke," (Longformer model)"),kke.forEach(t),zir=i(j),lM=n(j,"LI",{});var Ske=s(lM);e1e=n(Ske,"STRONG",{});var C7t=s(e1e);Wir=r(C7t,"lxmert"),C7t.forEach(t),Qir=r(Ske," \u2014 "),eW=n(Ske,"A",{href:!0});var w7t=s(eW);Hir=r(w7t,"TFLxmertModel"),w7t.forEach(t),Uir=r(Ske," (LXMERT model)"),Ske.forEach(t),Jir=i(j),iM=n(j,"LI",{});var Rke=s(iM);o1e=n(Rke,"STRONG",{});var A7t=s(o1e);Yir=r(A7t,"marian"),A7t.forEach(t),Kir=r(Rke," \u2014 "),oW=n(Rke,"A",{href:!0});var y7t=s(oW);Zir=r(y7t,"TFMarianModel"),y7t.forEach(t),edr=r(Rke," (Marian model)"),Rke.forEach(t),odr=i(j),dM=n(j,"LI",{});var Pke=s(dM);r1e=n(Pke,"STRONG",{});var L7t=s(r1e);rdr=r(L7t,"mbart"),L7t.forEach(t),tdr=r(Pke," \u2014 "),rW=n(Pke,"A",{href:!0});var x7t=s(rW);adr=r(x7t,"TFMBartModel"),x7t.forEach(t),ndr=r(Pke," (mBART model)"),Pke.forEach(t),sdr=i(j),cM=n(j,"LI",{});var Bke=s(cM);t1e=n(Bke,"STRONG",{});var $7t=s(t1e);ldr=r($7t,"mobilebert"),$7t.forEach(t),idr=r(Bke," \u2014 "),tW=n(Bke,"A",{href:!0});var k7t=s(tW);ddr=r(k7t,"TFMobileBertModel"),k7t.forEach(t),cdr=r(Bke," (MobileBERT model)"),Bke.forEach(t),fdr=i(j),fM=n(j,"LI",{});var Ike=s(fM);a1e=n(Ike,"STRONG",{});var S7t=s(a1e);mdr=r(S7t,"mpnet"),S7t.forEach(t),gdr=r(Ike," \u2014 "),aW=n(Ike,"A",{href:!0});var R7t=s(aW);hdr=r(R7t,"TFMPNetModel"),R7t.forEach(t),pdr=r(Ike," (MPNet model)"),Ike.forEach(t),_dr=i(j),mM=n(j,"LI",{});var qke=s(mM);n1e=n(qke,"STRONG",{});var P7t=s(n1e);udr=r(P7t,"mt5"),P7t.forEach(t),bdr=r(qke," \u2014 "),nW=n(qke,"A",{href:!0});var B7t=s(nW);vdr=r(B7t,"TFMT5Model"),B7t.forEach(t),Fdr=r(qke," (mT5 model)"),qke.forEach(t),Tdr=i(j),gM=n(j,"LI",{});var Nke=s(gM);s1e=n(Nke,"STRONG",{});var I7t=s(s1e);Mdr=r(I7t,"openai-gpt"),I7t.forEach(t),Edr=r(Nke," \u2014 "),sW=n(Nke,"A",{href:!0});var q7t=s(sW);Cdr=r(q7t,"TFOpenAIGPTModel"),q7t.forEach(t),wdr=r(Nke," (OpenAI GPT model)"),Nke.forEach(t),Adr=i(j),hM=n(j,"LI",{});var jke=s(hM);l1e=n(jke,"STRONG",{});var N7t=s(l1e);ydr=r(N7t,"opt"),N7t.forEach(t),Ldr=r(jke," \u2014 "),lW=n(jke,"A",{href:!0});var j7t=s(lW);xdr=r(j7t,"TFOPTModel"),j7t.forEach(t),$dr=r(jke," (OPT model)"),jke.forEach(t),kdr=i(j),pM=n(j,"LI",{});var Dke=s(pM);i1e=n(Dke,"STRONG",{});var D7t=s(i1e);Sdr=r(D7t,"pegasus"),D7t.forEach(t),Rdr=r(Dke," \u2014 "),iW=n(Dke,"A",{href:!0});var G7t=s(iW);Pdr=r(G7t,"TFPegasusModel"),G7t.forEach(t),Bdr=r(Dke," (Pegasus model)"),Dke.forEach(t),Idr=i(j),_M=n(j,"LI",{});var Gke=s(_M);d1e=n(Gke,"STRONG",{});var O7t=s(d1e);qdr=r(O7t,"rembert"),O7t.forEach(t),Ndr=r(Gke," \u2014 "),dW=n(Gke,"A",{href:!0});var V7t=s(dW);jdr=r(V7t,"TFRemBertModel"),V7t.forEach(t),Ddr=r(Gke," (RemBERT model)"),Gke.forEach(t),Gdr=i(j),uM=n(j,"LI",{});var Oke=s(uM);c1e=n(Oke,"STRONG",{});var X7t=s(c1e);Odr=r(X7t,"roberta"),X7t.forEach(t),Vdr=r(Oke," \u2014 "),cW=n(Oke,"A",{href:!0});var z7t=s(cW);Xdr=r(z7t,"TFRobertaModel"),z7t.forEach(t),zdr=r(Oke," (RoBERTa model)"),Oke.forEach(t),Wdr=i(j),bM=n(j,"LI",{});var Vke=s(bM);f1e=n(Vke,"STRONG",{});var W7t=s(f1e);Qdr=r(W7t,"roformer"),W7t.forEach(t),Hdr=r(Vke," \u2014 "),fW=n(Vke,"A",{href:!0});var Q7t=s(fW);Udr=r(Q7t,"TFRoFormerModel"),Q7t.forEach(t),Jdr=r(Vke," (RoFormer model)"),Vke.forEach(t),Ydr=i(j),vM=n(j,"LI",{});var Xke=s(vM);m1e=n(Xke,"STRONG",{});var H7t=s(m1e);Kdr=r(H7t,"speech_to_text"),H7t.forEach(t),Zdr=r(Xke," \u2014 "),mW=n(Xke,"A",{href:!0});var U7t=s(mW);ecr=r(U7t,"TFSpeech2TextModel"),U7t.forEach(t),ocr=r(Xke," (Speech2Text model)"),Xke.forEach(t),rcr=i(j),FM=n(j,"LI",{});var zke=s(FM);g1e=n(zke,"STRONG",{});var J7t=s(g1e);tcr=r(J7t,"swin"),J7t.forEach(t),acr=r(zke," \u2014 "),gW=n(zke,"A",{href:!0});var Y7t=s(gW);ncr=r(Y7t,"TFSwinModel"),Y7t.forEach(t),scr=r(zke," (Swin model)"),zke.forEach(t),lcr=i(j),TM=n(j,"LI",{});var Wke=s(TM);h1e=n(Wke,"STRONG",{});var K7t=s(h1e);icr=r(K7t,"t5"),K7t.forEach(t),dcr=r(Wke," \u2014 "),hW=n(Wke,"A",{href:!0});var Z7t=s(hW);ccr=r(Z7t,"TFT5Model"),Z7t.forEach(t),fcr=r(Wke," (T5 model)"),Wke.forEach(t),mcr=i(j),MM=n(j,"LI",{});var Qke=s(MM);p1e=n(Qke,"STRONG",{});var ebt=s(p1e);gcr=r(ebt,"tapas"),ebt.forEach(t),hcr=r(Qke," \u2014 "),pW=n(Qke,"A",{href:!0});var obt=s(pW);pcr=r(obt,"TFTapasModel"),obt.forEach(t),_cr=r(Qke," (TAPAS model)"),Qke.forEach(t),ucr=i(j),EM=n(j,"LI",{});var Hke=s(EM);_1e=n(Hke,"STRONG",{});var rbt=s(_1e);bcr=r(rbt,"transfo-xl"),rbt.forEach(t),vcr=r(Hke," \u2014 "),_W=n(Hke,"A",{href:!0});var tbt=s(_W);Fcr=r(tbt,"TFTransfoXLModel"),tbt.forEach(t),Tcr=r(Hke," (Transformer-XL model)"),Hke.forEach(t),Mcr=i(j),CM=n(j,"LI",{});var Uke=s(CM);u1e=n(Uke,"STRONG",{});var abt=s(u1e);Ecr=r(abt,"vit"),abt.forEach(t),Ccr=r(Uke," \u2014 "),uW=n(Uke,"A",{href:!0});var nbt=s(uW);wcr=r(nbt,"TFViTModel"),nbt.forEach(t),Acr=r(Uke," (ViT model)"),Uke.forEach(t),ycr=i(j),wM=n(j,"LI",{});var Jke=s(wM);b1e=n(Jke,"STRONG",{});var sbt=s(b1e);Lcr=r(sbt,"vit_mae"),sbt.forEach(t),xcr=r(Jke," \u2014 "),bW=n(Jke,"A",{href:!0});var lbt=s(bW);$cr=r(lbt,"TFViTMAEModel"),lbt.forEach(t),kcr=r(Jke," (ViTMAE model)"),Jke.forEach(t),Scr=i(j),AM=n(j,"LI",{});var Yke=s(AM);v1e=n(Yke,"STRONG",{});var ibt=s(v1e);Rcr=r(ibt,"wav2vec2"),ibt.forEach(t),Pcr=r(Yke," \u2014 "),vW=n(Yke,"A",{href:!0});var dbt=s(vW);Bcr=r(dbt,"TFWav2Vec2Model"),dbt.forEach(t),Icr=r(Yke," (Wav2Vec2 model)"),Yke.forEach(t),qcr=i(j),yM=n(j,"LI",{});var Kke=s(yM);F1e=n(Kke,"STRONG",{});var cbt=s(F1e);Ncr=r(cbt,"xlm"),cbt.forEach(t),jcr=r(Kke," \u2014 "),FW=n(Kke,"A",{href:!0});var fbt=s(FW);Dcr=r(fbt,"TFXLMModel"),fbt.forEach(t),Gcr=r(Kke," (XLM model)"),Kke.forEach(t),Ocr=i(j),LM=n(j,"LI",{});var Zke=s(LM);T1e=n(Zke,"STRONG",{});var mbt=s(T1e);Vcr=r(mbt,"xlm-roberta"),mbt.forEach(t),Xcr=r(Zke," \u2014 "),TW=n(Zke,"A",{href:!0});var gbt=s(TW);zcr=r(gbt,"TFXLMRobertaModel"),gbt.forEach(t),Wcr=r(Zke," (XLM-RoBERTa model)"),Zke.forEach(t),Qcr=i(j),xM=n(j,"LI",{});var eSe=s(xM);M1e=n(eSe,"STRONG",{});var hbt=s(M1e);Hcr=r(hbt,"xlnet"),hbt.forEach(t),Ucr=r(eSe," \u2014 "),MW=n(eSe,"A",{href:!0});var pbt=s(MW);Jcr=r(pbt,"TFXLNetModel"),pbt.forEach(t),Ycr=r(eSe," (XLNet model)"),eSe.forEach(t),j.forEach(t),Kcr=i(gl),T($M.$$.fragment,gl),gl.forEach(t),ml.forEach(t),rNe=i(f),Vd=n(f,"H2",{class:!0});var iDe=s(Vd);kM=n(iDe,"A",{id:!0,class:!0,href:!0});var _bt=s(kM);E1e=n(_bt,"SPAN",{});var ubt=s(E1e);T(ZL.$$.fragment,ubt),ubt.forEach(t),_bt.forEach(t),Zcr=i(iDe),C1e=n(iDe,"SPAN",{});var bbt=s(C1e);efr=r(bbt,"TFAutoModelForPreTraining"),bbt.forEach(t),iDe.forEach(t),tNe=i(f),Ko=n(f,"DIV",{class:!0});var hl=s(Ko);T(e8.$$.fragment,hl),ofr=i(hl),Xd=n(hl,"P",{});var PZ=s(Xd);rfr=r(PZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EW=n(PZ,"A",{href:!0});var vbt=s(EW);tfr=r(vbt,"from_pretrained()"),vbt.forEach(t),afr=r(PZ," class method or the "),CW=n(PZ,"A",{href:!0});var Fbt=s(CW);nfr=r(Fbt,"from_config()"),Fbt.forEach(t),sfr=r(PZ,` class
method.`),PZ.forEach(t),lfr=i(hl),o8=n(hl,"P",{});var dDe=s(o8);ifr=r(dDe,"This class cannot be instantiated directly using "),w1e=n(dDe,"CODE",{});var Tbt=s(w1e);dfr=r(Tbt,"__init__()"),Tbt.forEach(t),cfr=r(dDe," (throws an error)."),dDe.forEach(t),ffr=i(hl),Lt=n(hl,"DIV",{class:!0});var mA=s(Lt);T(r8.$$.fragment,mA),mfr=i(mA),A1e=n(mA,"P",{});var Mbt=s(A1e);gfr=r(Mbt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Mbt.forEach(t),hfr=i(mA),zd=n(mA,"P",{});var BZ=s(zd);pfr=r(BZ,`Note:
Loading a model from its configuration file does `),y1e=n(BZ,"STRONG",{});var Ebt=s(y1e);_fr=r(Ebt,"not"),Ebt.forEach(t),ufr=r(BZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),wW=n(BZ,"A",{href:!0});var Cbt=s(wW);bfr=r(Cbt,"from_pretrained()"),Cbt.forEach(t),vfr=r(BZ," to load the model weights."),BZ.forEach(t),Ffr=i(mA),T(SM.$$.fragment,mA),mA.forEach(t),Tfr=i(hl),Ar=n(hl,"DIV",{class:!0});var pl=s(Ar);T(t8.$$.fragment,pl),Mfr=i(pl),L1e=n(pl,"P",{});var wbt=s(L1e);Efr=r(wbt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),wbt.forEach(t),Cfr=i(pl),Za=n(pl,"P",{});var gA=s(Za);wfr=r(gA,"The model class to instantiate is selected based on the "),x1e=n(gA,"CODE",{});var Abt=s(x1e);Afr=r(Abt,"model_type"),Abt.forEach(t),yfr=r(gA,` property of the config object (either
passed as an argument or loaded from `),$1e=n(gA,"CODE",{});var ybt=s($1e);Lfr=r(ybt,"pretrained_model_name_or_path"),ybt.forEach(t),xfr=r(gA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k1e=n(gA,"CODE",{});var Lbt=s(k1e);$fr=r(Lbt,"pretrained_model_name_or_path"),Lbt.forEach(t),kfr=r(gA,":"),gA.forEach(t),Sfr=i(pl),se=n(pl,"UL",{});var le=s(se);RM=n(le,"LI",{});var oSe=s(RM);S1e=n(oSe,"STRONG",{});var xbt=s(S1e);Rfr=r(xbt,"albert"),xbt.forEach(t),Pfr=r(oSe," \u2014 "),AW=n(oSe,"A",{href:!0});var $bt=s(AW);Bfr=r($bt,"TFAlbertForPreTraining"),$bt.forEach(t),Ifr=r(oSe," (ALBERT model)"),oSe.forEach(t),qfr=i(le),PM=n(le,"LI",{});var rSe=s(PM);R1e=n(rSe,"STRONG",{});var kbt=s(R1e);Nfr=r(kbt,"bart"),kbt.forEach(t),jfr=r(rSe," \u2014 "),yW=n(rSe,"A",{href:!0});var Sbt=s(yW);Dfr=r(Sbt,"TFBartForConditionalGeneration"),Sbt.forEach(t),Gfr=r(rSe," (BART model)"),rSe.forEach(t),Ofr=i(le),BM=n(le,"LI",{});var tSe=s(BM);P1e=n(tSe,"STRONG",{});var Rbt=s(P1e);Vfr=r(Rbt,"bert"),Rbt.forEach(t),Xfr=r(tSe," \u2014 "),LW=n(tSe,"A",{href:!0});var Pbt=s(LW);zfr=r(Pbt,"TFBertForPreTraining"),Pbt.forEach(t),Wfr=r(tSe," (BERT model)"),tSe.forEach(t),Qfr=i(le),IM=n(le,"LI",{});var aSe=s(IM);B1e=n(aSe,"STRONG",{});var Bbt=s(B1e);Hfr=r(Bbt,"camembert"),Bbt.forEach(t),Ufr=r(aSe," \u2014 "),xW=n(aSe,"A",{href:!0});var Ibt=s(xW);Jfr=r(Ibt,"TFCamembertForMaskedLM"),Ibt.forEach(t),Yfr=r(aSe," (CamemBERT model)"),aSe.forEach(t),Kfr=i(le),qM=n(le,"LI",{});var nSe=s(qM);I1e=n(nSe,"STRONG",{});var qbt=s(I1e);Zfr=r(qbt,"ctrl"),qbt.forEach(t),emr=r(nSe," \u2014 "),$W=n(nSe,"A",{href:!0});var Nbt=s($W);omr=r(Nbt,"TFCTRLLMHeadModel"),Nbt.forEach(t),rmr=r(nSe," (CTRL model)"),nSe.forEach(t),tmr=i(le),NM=n(le,"LI",{});var sSe=s(NM);q1e=n(sSe,"STRONG",{});var jbt=s(q1e);amr=r(jbt,"distilbert"),jbt.forEach(t),nmr=r(sSe," \u2014 "),kW=n(sSe,"A",{href:!0});var Dbt=s(kW);smr=r(Dbt,"TFDistilBertForMaskedLM"),Dbt.forEach(t),lmr=r(sSe," (DistilBERT model)"),sSe.forEach(t),imr=i(le),jM=n(le,"LI",{});var lSe=s(jM);N1e=n(lSe,"STRONG",{});var Gbt=s(N1e);dmr=r(Gbt,"electra"),Gbt.forEach(t),cmr=r(lSe," \u2014 "),SW=n(lSe,"A",{href:!0});var Obt=s(SW);fmr=r(Obt,"TFElectraForPreTraining"),Obt.forEach(t),mmr=r(lSe," (ELECTRA model)"),lSe.forEach(t),gmr=i(le),DM=n(le,"LI",{});var iSe=s(DM);j1e=n(iSe,"STRONG",{});var Vbt=s(j1e);hmr=r(Vbt,"flaubert"),Vbt.forEach(t),pmr=r(iSe," \u2014 "),RW=n(iSe,"A",{href:!0});var Xbt=s(RW);_mr=r(Xbt,"TFFlaubertWithLMHeadModel"),Xbt.forEach(t),umr=r(iSe," (FlauBERT model)"),iSe.forEach(t),bmr=i(le),GM=n(le,"LI",{});var dSe=s(GM);D1e=n(dSe,"STRONG",{});var zbt=s(D1e);vmr=r(zbt,"funnel"),zbt.forEach(t),Fmr=r(dSe," \u2014 "),PW=n(dSe,"A",{href:!0});var Wbt=s(PW);Tmr=r(Wbt,"TFFunnelForPreTraining"),Wbt.forEach(t),Mmr=r(dSe," (Funnel Transformer model)"),dSe.forEach(t),Emr=i(le),OM=n(le,"LI",{});var cSe=s(OM);G1e=n(cSe,"STRONG",{});var Qbt=s(G1e);Cmr=r(Qbt,"gpt2"),Qbt.forEach(t),wmr=r(cSe," \u2014 "),BW=n(cSe,"A",{href:!0});var Hbt=s(BW);Amr=r(Hbt,"TFGPT2LMHeadModel"),Hbt.forEach(t),ymr=r(cSe," (OpenAI GPT-2 model)"),cSe.forEach(t),Lmr=i(le),VM=n(le,"LI",{});var fSe=s(VM);O1e=n(fSe,"STRONG",{});var Ubt=s(O1e);xmr=r(Ubt,"layoutlm"),Ubt.forEach(t),$mr=r(fSe," \u2014 "),IW=n(fSe,"A",{href:!0});var Jbt=s(IW);kmr=r(Jbt,"TFLayoutLMForMaskedLM"),Jbt.forEach(t),Smr=r(fSe," (LayoutLM model)"),fSe.forEach(t),Rmr=i(le),XM=n(le,"LI",{});var mSe=s(XM);V1e=n(mSe,"STRONG",{});var Ybt=s(V1e);Pmr=r(Ybt,"lxmert"),Ybt.forEach(t),Bmr=r(mSe," \u2014 "),qW=n(mSe,"A",{href:!0});var Kbt=s(qW);Imr=r(Kbt,"TFLxmertForPreTraining"),Kbt.forEach(t),qmr=r(mSe," (LXMERT model)"),mSe.forEach(t),Nmr=i(le),zM=n(le,"LI",{});var gSe=s(zM);X1e=n(gSe,"STRONG",{});var Zbt=s(X1e);jmr=r(Zbt,"mobilebert"),Zbt.forEach(t),Dmr=r(gSe," \u2014 "),NW=n(gSe,"A",{href:!0});var evt=s(NW);Gmr=r(evt,"TFMobileBertForPreTraining"),evt.forEach(t),Omr=r(gSe," (MobileBERT model)"),gSe.forEach(t),Vmr=i(le),WM=n(le,"LI",{});var hSe=s(WM);z1e=n(hSe,"STRONG",{});var ovt=s(z1e);Xmr=r(ovt,"mpnet"),ovt.forEach(t),zmr=r(hSe," \u2014 "),jW=n(hSe,"A",{href:!0});var rvt=s(jW);Wmr=r(rvt,"TFMPNetForMaskedLM"),rvt.forEach(t),Qmr=r(hSe," (MPNet model)"),hSe.forEach(t),Hmr=i(le),QM=n(le,"LI",{});var pSe=s(QM);W1e=n(pSe,"STRONG",{});var tvt=s(W1e);Umr=r(tvt,"openai-gpt"),tvt.forEach(t),Jmr=r(pSe," \u2014 "),DW=n(pSe,"A",{href:!0});var avt=s(DW);Ymr=r(avt,"TFOpenAIGPTLMHeadModel"),avt.forEach(t),Kmr=r(pSe," (OpenAI GPT model)"),pSe.forEach(t),Zmr=i(le),HM=n(le,"LI",{});var _Se=s(HM);Q1e=n(_Se,"STRONG",{});var nvt=s(Q1e);egr=r(nvt,"roberta"),nvt.forEach(t),ogr=r(_Se," \u2014 "),GW=n(_Se,"A",{href:!0});var svt=s(GW);rgr=r(svt,"TFRobertaForMaskedLM"),svt.forEach(t),tgr=r(_Se," (RoBERTa model)"),_Se.forEach(t),agr=i(le),UM=n(le,"LI",{});var uSe=s(UM);H1e=n(uSe,"STRONG",{});var lvt=s(H1e);ngr=r(lvt,"t5"),lvt.forEach(t),sgr=r(uSe," \u2014 "),OW=n(uSe,"A",{href:!0});var ivt=s(OW);lgr=r(ivt,"TFT5ForConditionalGeneration"),ivt.forEach(t),igr=r(uSe," (T5 model)"),uSe.forEach(t),dgr=i(le),JM=n(le,"LI",{});var bSe=s(JM);U1e=n(bSe,"STRONG",{});var dvt=s(U1e);cgr=r(dvt,"tapas"),dvt.forEach(t),fgr=r(bSe," \u2014 "),VW=n(bSe,"A",{href:!0});var cvt=s(VW);mgr=r(cvt,"TFTapasForMaskedLM"),cvt.forEach(t),ggr=r(bSe," (TAPAS model)"),bSe.forEach(t),hgr=i(le),YM=n(le,"LI",{});var vSe=s(YM);J1e=n(vSe,"STRONG",{});var fvt=s(J1e);pgr=r(fvt,"transfo-xl"),fvt.forEach(t),_gr=r(vSe," \u2014 "),XW=n(vSe,"A",{href:!0});var mvt=s(XW);ugr=r(mvt,"TFTransfoXLLMHeadModel"),mvt.forEach(t),bgr=r(vSe," (Transformer-XL model)"),vSe.forEach(t),vgr=i(le),KM=n(le,"LI",{});var FSe=s(KM);Y1e=n(FSe,"STRONG",{});var gvt=s(Y1e);Fgr=r(gvt,"vit_mae"),gvt.forEach(t),Tgr=r(FSe," \u2014 "),zW=n(FSe,"A",{href:!0});var hvt=s(zW);Mgr=r(hvt,"TFViTMAEForPreTraining"),hvt.forEach(t),Egr=r(FSe," (ViTMAE model)"),FSe.forEach(t),Cgr=i(le),ZM=n(le,"LI",{});var TSe=s(ZM);K1e=n(TSe,"STRONG",{});var pvt=s(K1e);wgr=r(pvt,"xlm"),pvt.forEach(t),Agr=r(TSe," \u2014 "),WW=n(TSe,"A",{href:!0});var _vt=s(WW);ygr=r(_vt,"TFXLMWithLMHeadModel"),_vt.forEach(t),Lgr=r(TSe," (XLM model)"),TSe.forEach(t),xgr=i(le),e4=n(le,"LI",{});var MSe=s(e4);Z1e=n(MSe,"STRONG",{});var uvt=s(Z1e);$gr=r(uvt,"xlm-roberta"),uvt.forEach(t),kgr=r(MSe," \u2014 "),QW=n(MSe,"A",{href:!0});var bvt=s(QW);Sgr=r(bvt,"TFXLMRobertaForMaskedLM"),bvt.forEach(t),Rgr=r(MSe," (XLM-RoBERTa model)"),MSe.forEach(t),Pgr=i(le),o4=n(le,"LI",{});var ESe=s(o4);e7e=n(ESe,"STRONG",{});var vvt=s(e7e);Bgr=r(vvt,"xlnet"),vvt.forEach(t),Igr=r(ESe," \u2014 "),HW=n(ESe,"A",{href:!0});var Fvt=s(HW);qgr=r(Fvt,"TFXLNetLMHeadModel"),Fvt.forEach(t),Ngr=r(ESe," (XLNet model)"),ESe.forEach(t),le.forEach(t),jgr=i(pl),T(r4.$$.fragment,pl),pl.forEach(t),hl.forEach(t),aNe=i(f),Wd=n(f,"H2",{class:!0});var cDe=s(Wd);t4=n(cDe,"A",{id:!0,class:!0,href:!0});var Tvt=s(t4);o7e=n(Tvt,"SPAN",{});var Mvt=s(o7e);T(a8.$$.fragment,Mvt),Mvt.forEach(t),Tvt.forEach(t),Dgr=i(cDe),r7e=n(cDe,"SPAN",{});var Evt=s(r7e);Ggr=r(Evt,"TFAutoModelForCausalLM"),Evt.forEach(t),cDe.forEach(t),nNe=i(f),Zo=n(f,"DIV",{class:!0});var _l=s(Zo);T(n8.$$.fragment,_l),Ogr=i(_l),Qd=n(_l,"P",{});var IZ=s(Qd);Vgr=r(IZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),UW=n(IZ,"A",{href:!0});var Cvt=s(UW);Xgr=r(Cvt,"from_pretrained()"),Cvt.forEach(t),zgr=r(IZ," class method or the "),JW=n(IZ,"A",{href:!0});var wvt=s(JW);Wgr=r(wvt,"from_config()"),wvt.forEach(t),Qgr=r(IZ,` class
method.`),IZ.forEach(t),Hgr=i(_l),s8=n(_l,"P",{});var fDe=s(s8);Ugr=r(fDe,"This class cannot be instantiated directly using "),t7e=n(fDe,"CODE",{});var Avt=s(t7e);Jgr=r(Avt,"__init__()"),Avt.forEach(t),Ygr=r(fDe," (throws an error)."),fDe.forEach(t),Kgr=i(_l),xt=n(_l,"DIV",{class:!0});var hA=s(xt);T(l8.$$.fragment,hA),Zgr=i(hA),a7e=n(hA,"P",{});var yvt=s(a7e);ehr=r(yvt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yvt.forEach(t),ohr=i(hA),Hd=n(hA,"P",{});var qZ=s(Hd);rhr=r(qZ,`Note:
Loading a model from its configuration file does `),n7e=n(qZ,"STRONG",{});var Lvt=s(n7e);thr=r(Lvt,"not"),Lvt.forEach(t),ahr=r(qZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(qZ,"A",{href:!0});var xvt=s(YW);nhr=r(xvt,"from_pretrained()"),xvt.forEach(t),shr=r(qZ," to load the model weights."),qZ.forEach(t),lhr=i(hA),T(a4.$$.fragment,hA),hA.forEach(t),ihr=i(_l),yr=n(_l,"DIV",{class:!0});var ul=s(yr);T(i8.$$.fragment,ul),dhr=i(ul),s7e=n(ul,"P",{});var $vt=s(s7e);chr=r($vt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),$vt.forEach(t),fhr=i(ul),en=n(ul,"P",{});var pA=s(en);mhr=r(pA,"The model class to instantiate is selected based on the "),l7e=n(pA,"CODE",{});var kvt=s(l7e);ghr=r(kvt,"model_type"),kvt.forEach(t),hhr=r(pA,` property of the config object (either
passed as an argument or loaded from `),i7e=n(pA,"CODE",{});var Svt=s(i7e);phr=r(Svt,"pretrained_model_name_or_path"),Svt.forEach(t),_hr=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(pA,"CODE",{});var Rvt=s(d7e);uhr=r(Rvt,"pretrained_model_name_or_path"),Rvt.forEach(t),bhr=r(pA,":"),pA.forEach(t),vhr=i(ul),Te=n(ul,"UL",{});var Ce=s(Te);n4=n(Ce,"LI",{});var CSe=s(n4);c7e=n(CSe,"STRONG",{});var Pvt=s(c7e);Fhr=r(Pvt,"bert"),Pvt.forEach(t),Thr=r(CSe," \u2014 "),KW=n(CSe,"A",{href:!0});var Bvt=s(KW);Mhr=r(Bvt,"TFBertLMHeadModel"),Bvt.forEach(t),Ehr=r(CSe," (BERT model)"),CSe.forEach(t),Chr=i(Ce),s4=n(Ce,"LI",{});var wSe=s(s4);f7e=n(wSe,"STRONG",{});var Ivt=s(f7e);whr=r(Ivt,"camembert"),Ivt.forEach(t),Ahr=r(wSe," \u2014 "),ZW=n(wSe,"A",{href:!0});var qvt=s(ZW);yhr=r(qvt,"TFCamembertForCausalLM"),qvt.forEach(t),Lhr=r(wSe," (CamemBERT model)"),wSe.forEach(t),xhr=i(Ce),l4=n(Ce,"LI",{});var ASe=s(l4);m7e=n(ASe,"STRONG",{});var Nvt=s(m7e);$hr=r(Nvt,"ctrl"),Nvt.forEach(t),khr=r(ASe," \u2014 "),eQ=n(ASe,"A",{href:!0});var jvt=s(eQ);Shr=r(jvt,"TFCTRLLMHeadModel"),jvt.forEach(t),Rhr=r(ASe," (CTRL model)"),ASe.forEach(t),Phr=i(Ce),i4=n(Ce,"LI",{});var ySe=s(i4);g7e=n(ySe,"STRONG",{});var Dvt=s(g7e);Bhr=r(Dvt,"gpt2"),Dvt.forEach(t),Ihr=r(ySe," \u2014 "),oQ=n(ySe,"A",{href:!0});var Gvt=s(oQ);qhr=r(Gvt,"TFGPT2LMHeadModel"),Gvt.forEach(t),Nhr=r(ySe," (OpenAI GPT-2 model)"),ySe.forEach(t),jhr=i(Ce),d4=n(Ce,"LI",{});var LSe=s(d4);h7e=n(LSe,"STRONG",{});var Ovt=s(h7e);Dhr=r(Ovt,"gptj"),Ovt.forEach(t),Ghr=r(LSe," \u2014 "),rQ=n(LSe,"A",{href:!0});var Vvt=s(rQ);Ohr=r(Vvt,"TFGPTJForCausalLM"),Vvt.forEach(t),Vhr=r(LSe," (GPT-J model)"),LSe.forEach(t),Xhr=i(Ce),c4=n(Ce,"LI",{});var xSe=s(c4);p7e=n(xSe,"STRONG",{});var Xvt=s(p7e);zhr=r(Xvt,"openai-gpt"),Xvt.forEach(t),Whr=r(xSe," \u2014 "),tQ=n(xSe,"A",{href:!0});var zvt=s(tQ);Qhr=r(zvt,"TFOpenAIGPTLMHeadModel"),zvt.forEach(t),Hhr=r(xSe," (OpenAI GPT model)"),xSe.forEach(t),Uhr=i(Ce),f4=n(Ce,"LI",{});var $Se=s(f4);_7e=n($Se,"STRONG",{});var Wvt=s(_7e);Jhr=r(Wvt,"rembert"),Wvt.forEach(t),Yhr=r($Se," \u2014 "),aQ=n($Se,"A",{href:!0});var Qvt=s(aQ);Khr=r(Qvt,"TFRemBertForCausalLM"),Qvt.forEach(t),Zhr=r($Se," (RemBERT model)"),$Se.forEach(t),epr=i(Ce),m4=n(Ce,"LI",{});var kSe=s(m4);u7e=n(kSe,"STRONG",{});var Hvt=s(u7e);opr=r(Hvt,"roberta"),Hvt.forEach(t),rpr=r(kSe," \u2014 "),nQ=n(kSe,"A",{href:!0});var Uvt=s(nQ);tpr=r(Uvt,"TFRobertaForCausalLM"),Uvt.forEach(t),apr=r(kSe," (RoBERTa model)"),kSe.forEach(t),npr=i(Ce),g4=n(Ce,"LI",{});var SSe=s(g4);b7e=n(SSe,"STRONG",{});var Jvt=s(b7e);spr=r(Jvt,"roformer"),Jvt.forEach(t),lpr=r(SSe," \u2014 "),sQ=n(SSe,"A",{href:!0});var Yvt=s(sQ);ipr=r(Yvt,"TFRoFormerForCausalLM"),Yvt.forEach(t),dpr=r(SSe," (RoFormer model)"),SSe.forEach(t),cpr=i(Ce),h4=n(Ce,"LI",{});var RSe=s(h4);v7e=n(RSe,"STRONG",{});var Kvt=s(v7e);fpr=r(Kvt,"transfo-xl"),Kvt.forEach(t),mpr=r(RSe," \u2014 "),lQ=n(RSe,"A",{href:!0});var Zvt=s(lQ);gpr=r(Zvt,"TFTransfoXLLMHeadModel"),Zvt.forEach(t),hpr=r(RSe," (Transformer-XL model)"),RSe.forEach(t),ppr=i(Ce),p4=n(Ce,"LI",{});var PSe=s(p4);F7e=n(PSe,"STRONG",{});var eFt=s(F7e);_pr=r(eFt,"xlm"),eFt.forEach(t),upr=r(PSe," \u2014 "),iQ=n(PSe,"A",{href:!0});var oFt=s(iQ);bpr=r(oFt,"TFXLMWithLMHeadModel"),oFt.forEach(t),vpr=r(PSe," (XLM model)"),PSe.forEach(t),Fpr=i(Ce),_4=n(Ce,"LI",{});var BSe=s(_4);T7e=n(BSe,"STRONG",{});var rFt=s(T7e);Tpr=r(rFt,"xlnet"),rFt.forEach(t),Mpr=r(BSe," \u2014 "),dQ=n(BSe,"A",{href:!0});var tFt=s(dQ);Epr=r(tFt,"TFXLNetLMHeadModel"),tFt.forEach(t),Cpr=r(BSe," (XLNet model)"),BSe.forEach(t),Ce.forEach(t),wpr=i(ul),T(u4.$$.fragment,ul),ul.forEach(t),_l.forEach(t),sNe=i(f),Ud=n(f,"H2",{class:!0});var mDe=s(Ud);b4=n(mDe,"A",{id:!0,class:!0,href:!0});var aFt=s(b4);M7e=n(aFt,"SPAN",{});var nFt=s(M7e);T(d8.$$.fragment,nFt),nFt.forEach(t),aFt.forEach(t),Apr=i(mDe),E7e=n(mDe,"SPAN",{});var sFt=s(E7e);ypr=r(sFt,"TFAutoModelForImageClassification"),sFt.forEach(t),mDe.forEach(t),lNe=i(f),er=n(f,"DIV",{class:!0});var bl=s(er);T(c8.$$.fragment,bl),Lpr=i(bl),Jd=n(bl,"P",{});var NZ=s(Jd);xpr=r(NZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),cQ=n(NZ,"A",{href:!0});var lFt=s(cQ);$pr=r(lFt,"from_pretrained()"),lFt.forEach(t),kpr=r(NZ," class method or the "),fQ=n(NZ,"A",{href:!0});var iFt=s(fQ);Spr=r(iFt,"from_config()"),iFt.forEach(t),Rpr=r(NZ,` class
method.`),NZ.forEach(t),Ppr=i(bl),f8=n(bl,"P",{});var gDe=s(f8);Bpr=r(gDe,"This class cannot be instantiated directly using "),C7e=n(gDe,"CODE",{});var dFt=s(C7e);Ipr=r(dFt,"__init__()"),dFt.forEach(t),qpr=r(gDe," (throws an error)."),gDe.forEach(t),Npr=i(bl),$t=n(bl,"DIV",{class:!0});var _A=s($t);T(m8.$$.fragment,_A),jpr=i(_A),w7e=n(_A,"P",{});var cFt=s(w7e);Dpr=r(cFt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),cFt.forEach(t),Gpr=i(_A),Yd=n(_A,"P",{});var jZ=s(Yd);Opr=r(jZ,`Note:
Loading a model from its configuration file does `),A7e=n(jZ,"STRONG",{});var fFt=s(A7e);Vpr=r(fFt,"not"),fFt.forEach(t),Xpr=r(jZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),mQ=n(jZ,"A",{href:!0});var mFt=s(mQ);zpr=r(mFt,"from_pretrained()"),mFt.forEach(t),Wpr=r(jZ," to load the model weights."),jZ.forEach(t),Qpr=i(_A),T(v4.$$.fragment,_A),_A.forEach(t),Hpr=i(bl),Lr=n(bl,"DIV",{class:!0});var vl=s(Lr);T(g8.$$.fragment,vl),Upr=i(vl),y7e=n(vl,"P",{});var gFt=s(y7e);Jpr=r(gFt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gFt.forEach(t),Ypr=i(vl),on=n(vl,"P",{});var uA=s(on);Kpr=r(uA,"The model class to instantiate is selected based on the "),L7e=n(uA,"CODE",{});var hFt=s(L7e);Zpr=r(hFt,"model_type"),hFt.forEach(t),e_r=r(uA,` property of the config object (either
passed as an argument or loaded from `),x7e=n(uA,"CODE",{});var pFt=s(x7e);o_r=r(pFt,"pretrained_model_name_or_path"),pFt.forEach(t),r_r=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$7e=n(uA,"CODE",{});var _Ft=s($7e);t_r=r(_Ft,"pretrained_model_name_or_path"),_Ft.forEach(t),a_r=r(uA,":"),uA.forEach(t),n_r=i(vl),rn=n(vl,"UL",{});var bA=s(rn);F4=n(bA,"LI",{});var ISe=s(F4);k7e=n(ISe,"STRONG",{});var uFt=s(k7e);s_r=r(uFt,"convnext"),uFt.forEach(t),l_r=r(ISe," \u2014 "),gQ=n(ISe,"A",{href:!0});var bFt=s(gQ);i_r=r(bFt,"TFConvNextForImageClassification"),bFt.forEach(t),d_r=r(ISe," (ConvNext model)"),ISe.forEach(t),c_r=i(bA),T4=n(bA,"LI",{});var qSe=s(T4);S7e=n(qSe,"STRONG",{});var vFt=s(S7e);f_r=r(vFt,"data2vec-vision"),vFt.forEach(t),m_r=r(qSe," \u2014 "),hQ=n(qSe,"A",{href:!0});var FFt=s(hQ);g_r=r(FFt,"TFData2VecVisionForImageClassification"),FFt.forEach(t),h_r=r(qSe," (Data2VecVision model)"),qSe.forEach(t),p_r=i(bA),M4=n(bA,"LI",{});var NSe=s(M4);R7e=n(NSe,"STRONG",{});var TFt=s(R7e);__r=r(TFt,"swin"),TFt.forEach(t),u_r=r(NSe," \u2014 "),pQ=n(NSe,"A",{href:!0});var MFt=s(pQ);b_r=r(MFt,"TFSwinForImageClassification"),MFt.forEach(t),v_r=r(NSe," (Swin model)"),NSe.forEach(t),F_r=i(bA),E4=n(bA,"LI",{});var jSe=s(E4);P7e=n(jSe,"STRONG",{});var EFt=s(P7e);T_r=r(EFt,"vit"),EFt.forEach(t),M_r=r(jSe," \u2014 "),_Q=n(jSe,"A",{href:!0});var CFt=s(_Q);E_r=r(CFt,"TFViTForImageClassification"),CFt.forEach(t),C_r=r(jSe," (ViT model)"),jSe.forEach(t),bA.forEach(t),w_r=i(vl),T(C4.$$.fragment,vl),vl.forEach(t),bl.forEach(t),iNe=i(f),Kd=n(f,"H2",{class:!0});var hDe=s(Kd);w4=n(hDe,"A",{id:!0,class:!0,href:!0});var wFt=s(w4);B7e=n(wFt,"SPAN",{});var AFt=s(B7e);T(h8.$$.fragment,AFt),AFt.forEach(t),wFt.forEach(t),A_r=i(hDe),I7e=n(hDe,"SPAN",{});var yFt=s(I7e);y_r=r(yFt,"TFAutoModelForMaskedLM"),yFt.forEach(t),hDe.forEach(t),dNe=i(f),or=n(f,"DIV",{class:!0});var Fl=s(or);T(p8.$$.fragment,Fl),L_r=i(Fl),Zd=n(Fl,"P",{});var DZ=s(Zd);x_r=r(DZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uQ=n(DZ,"A",{href:!0});var LFt=s(uQ);$_r=r(LFt,"from_pretrained()"),LFt.forEach(t),k_r=r(DZ," class method or the "),bQ=n(DZ,"A",{href:!0});var xFt=s(bQ);S_r=r(xFt,"from_config()"),xFt.forEach(t),R_r=r(DZ,` class
method.`),DZ.forEach(t),P_r=i(Fl),_8=n(Fl,"P",{});var pDe=s(_8);B_r=r(pDe,"This class cannot be instantiated directly using "),q7e=n(pDe,"CODE",{});var $Ft=s(q7e);I_r=r($Ft,"__init__()"),$Ft.forEach(t),q_r=r(pDe," (throws an error)."),pDe.forEach(t),N_r=i(Fl),kt=n(Fl,"DIV",{class:!0});var vA=s(kt);T(u8.$$.fragment,vA),j_r=i(vA),N7e=n(vA,"P",{});var kFt=s(N7e);D_r=r(kFt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),kFt.forEach(t),G_r=i(vA),ec=n(vA,"P",{});var GZ=s(ec);O_r=r(GZ,`Note:
Loading a model from its configuration file does `),j7e=n(GZ,"STRONG",{});var SFt=s(j7e);V_r=r(SFt,"not"),SFt.forEach(t),X_r=r(GZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),vQ=n(GZ,"A",{href:!0});var RFt=s(vQ);z_r=r(RFt,"from_pretrained()"),RFt.forEach(t),W_r=r(GZ," to load the model weights."),GZ.forEach(t),Q_r=i(vA),T(A4.$$.fragment,vA),vA.forEach(t),H_r=i(Fl),xr=n(Fl,"DIV",{class:!0});var Tl=s(xr);T(b8.$$.fragment,Tl),U_r=i(Tl),D7e=n(Tl,"P",{});var PFt=s(D7e);J_r=r(PFt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),PFt.forEach(t),Y_r=i(Tl),tn=n(Tl,"P",{});var FA=s(tn);K_r=r(FA,"The model class to instantiate is selected based on the "),G7e=n(FA,"CODE",{});var BFt=s(G7e);Z_r=r(BFt,"model_type"),BFt.forEach(t),eur=r(FA,` property of the config object (either
passed as an argument or loaded from `),O7e=n(FA,"CODE",{});var IFt=s(O7e);our=r(IFt,"pretrained_model_name_or_path"),IFt.forEach(t),rur=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V7e=n(FA,"CODE",{});var qFt=s(V7e);tur=r(qFt,"pretrained_model_name_or_path"),qFt.forEach(t),aur=r(FA,":"),FA.forEach(t),nur=i(Tl),ie=n(Tl,"UL",{});var fe=s(ie);y4=n(fe,"LI",{});var DSe=s(y4);X7e=n(DSe,"STRONG",{});var NFt=s(X7e);sur=r(NFt,"albert"),NFt.forEach(t),lur=r(DSe," \u2014 "),FQ=n(DSe,"A",{href:!0});var jFt=s(FQ);iur=r(jFt,"TFAlbertForMaskedLM"),jFt.forEach(t),dur=r(DSe," (ALBERT model)"),DSe.forEach(t),cur=i(fe),L4=n(fe,"LI",{});var GSe=s(L4);z7e=n(GSe,"STRONG",{});var DFt=s(z7e);fur=r(DFt,"bert"),DFt.forEach(t),mur=r(GSe," \u2014 "),TQ=n(GSe,"A",{href:!0});var GFt=s(TQ);gur=r(GFt,"TFBertForMaskedLM"),GFt.forEach(t),hur=r(GSe," (BERT model)"),GSe.forEach(t),pur=i(fe),x4=n(fe,"LI",{});var OSe=s(x4);W7e=n(OSe,"STRONG",{});var OFt=s(W7e);_ur=r(OFt,"camembert"),OFt.forEach(t),uur=r(OSe," \u2014 "),MQ=n(OSe,"A",{href:!0});var VFt=s(MQ);bur=r(VFt,"TFCamembertForMaskedLM"),VFt.forEach(t),vur=r(OSe," (CamemBERT model)"),OSe.forEach(t),Fur=i(fe),$4=n(fe,"LI",{});var VSe=s($4);Q7e=n(VSe,"STRONG",{});var XFt=s(Q7e);Tur=r(XFt,"convbert"),XFt.forEach(t),Mur=r(VSe," \u2014 "),EQ=n(VSe,"A",{href:!0});var zFt=s(EQ);Eur=r(zFt,"TFConvBertForMaskedLM"),zFt.forEach(t),Cur=r(VSe," (ConvBERT model)"),VSe.forEach(t),wur=i(fe),k4=n(fe,"LI",{});var XSe=s(k4);H7e=n(XSe,"STRONG",{});var WFt=s(H7e);Aur=r(WFt,"deberta"),WFt.forEach(t),yur=r(XSe," \u2014 "),CQ=n(XSe,"A",{href:!0});var QFt=s(CQ);Lur=r(QFt,"TFDebertaForMaskedLM"),QFt.forEach(t),xur=r(XSe," (DeBERTa model)"),XSe.forEach(t),$ur=i(fe),S4=n(fe,"LI",{});var zSe=s(S4);U7e=n(zSe,"STRONG",{});var HFt=s(U7e);kur=r(HFt,"deberta-v2"),HFt.forEach(t),Sur=r(zSe," \u2014 "),wQ=n(zSe,"A",{href:!0});var UFt=s(wQ);Rur=r(UFt,"TFDebertaV2ForMaskedLM"),UFt.forEach(t),Pur=r(zSe," (DeBERTa-v2 model)"),zSe.forEach(t),Bur=i(fe),R4=n(fe,"LI",{});var WSe=s(R4);J7e=n(WSe,"STRONG",{});var JFt=s(J7e);Iur=r(JFt,"distilbert"),JFt.forEach(t),qur=r(WSe," \u2014 "),AQ=n(WSe,"A",{href:!0});var YFt=s(AQ);Nur=r(YFt,"TFDistilBertForMaskedLM"),YFt.forEach(t),jur=r(WSe," (DistilBERT model)"),WSe.forEach(t),Dur=i(fe),P4=n(fe,"LI",{});var QSe=s(P4);Y7e=n(QSe,"STRONG",{});var KFt=s(Y7e);Gur=r(KFt,"electra"),KFt.forEach(t),Our=r(QSe," \u2014 "),yQ=n(QSe,"A",{href:!0});var ZFt=s(yQ);Vur=r(ZFt,"TFElectraForMaskedLM"),ZFt.forEach(t),Xur=r(QSe," (ELECTRA model)"),QSe.forEach(t),zur=i(fe),B4=n(fe,"LI",{});var HSe=s(B4);K7e=n(HSe,"STRONG",{});var eTt=s(K7e);Wur=r(eTt,"flaubert"),eTt.forEach(t),Qur=r(HSe," \u2014 "),LQ=n(HSe,"A",{href:!0});var oTt=s(LQ);Hur=r(oTt,"TFFlaubertWithLMHeadModel"),oTt.forEach(t),Uur=r(HSe," (FlauBERT model)"),HSe.forEach(t),Jur=i(fe),I4=n(fe,"LI",{});var USe=s(I4);Z7e=n(USe,"STRONG",{});var rTt=s(Z7e);Yur=r(rTt,"funnel"),rTt.forEach(t),Kur=r(USe," \u2014 "),xQ=n(USe,"A",{href:!0});var tTt=s(xQ);Zur=r(tTt,"TFFunnelForMaskedLM"),tTt.forEach(t),e2r=r(USe," (Funnel Transformer model)"),USe.forEach(t),o2r=i(fe),q4=n(fe,"LI",{});var JSe=s(q4);ebe=n(JSe,"STRONG",{});var aTt=s(ebe);r2r=r(aTt,"layoutlm"),aTt.forEach(t),t2r=r(JSe," \u2014 "),$Q=n(JSe,"A",{href:!0});var nTt=s($Q);a2r=r(nTt,"TFLayoutLMForMaskedLM"),nTt.forEach(t),n2r=r(JSe," (LayoutLM model)"),JSe.forEach(t),s2r=i(fe),N4=n(fe,"LI",{});var YSe=s(N4);obe=n(YSe,"STRONG",{});var sTt=s(obe);l2r=r(sTt,"longformer"),sTt.forEach(t),i2r=r(YSe," \u2014 "),kQ=n(YSe,"A",{href:!0});var lTt=s(kQ);d2r=r(lTt,"TFLongformerForMaskedLM"),lTt.forEach(t),c2r=r(YSe," (Longformer model)"),YSe.forEach(t),f2r=i(fe),j4=n(fe,"LI",{});var KSe=s(j4);rbe=n(KSe,"STRONG",{});var iTt=s(rbe);m2r=r(iTt,"mobilebert"),iTt.forEach(t),g2r=r(KSe," \u2014 "),SQ=n(KSe,"A",{href:!0});var dTt=s(SQ);h2r=r(dTt,"TFMobileBertForMaskedLM"),dTt.forEach(t),p2r=r(KSe," (MobileBERT model)"),KSe.forEach(t),_2r=i(fe),D4=n(fe,"LI",{});var ZSe=s(D4);tbe=n(ZSe,"STRONG",{});var cTt=s(tbe);u2r=r(cTt,"mpnet"),cTt.forEach(t),b2r=r(ZSe," \u2014 "),RQ=n(ZSe,"A",{href:!0});var fTt=s(RQ);v2r=r(fTt,"TFMPNetForMaskedLM"),fTt.forEach(t),F2r=r(ZSe," (MPNet model)"),ZSe.forEach(t),T2r=i(fe),G4=n(fe,"LI",{});var eRe=s(G4);abe=n(eRe,"STRONG",{});var mTt=s(abe);M2r=r(mTt,"rembert"),mTt.forEach(t),E2r=r(eRe," \u2014 "),PQ=n(eRe,"A",{href:!0});var gTt=s(PQ);C2r=r(gTt,"TFRemBertForMaskedLM"),gTt.forEach(t),w2r=r(eRe," (RemBERT model)"),eRe.forEach(t),A2r=i(fe),O4=n(fe,"LI",{});var oRe=s(O4);nbe=n(oRe,"STRONG",{});var hTt=s(nbe);y2r=r(hTt,"roberta"),hTt.forEach(t),L2r=r(oRe," \u2014 "),BQ=n(oRe,"A",{href:!0});var pTt=s(BQ);x2r=r(pTt,"TFRobertaForMaskedLM"),pTt.forEach(t),$2r=r(oRe," (RoBERTa model)"),oRe.forEach(t),k2r=i(fe),V4=n(fe,"LI",{});var rRe=s(V4);sbe=n(rRe,"STRONG",{});var _Tt=s(sbe);S2r=r(_Tt,"roformer"),_Tt.forEach(t),R2r=r(rRe," \u2014 "),IQ=n(rRe,"A",{href:!0});var uTt=s(IQ);P2r=r(uTt,"TFRoFormerForMaskedLM"),uTt.forEach(t),B2r=r(rRe," (RoFormer model)"),rRe.forEach(t),I2r=i(fe),X4=n(fe,"LI",{});var tRe=s(X4);lbe=n(tRe,"STRONG",{});var bTt=s(lbe);q2r=r(bTt,"tapas"),bTt.forEach(t),N2r=r(tRe," \u2014 "),qQ=n(tRe,"A",{href:!0});var vTt=s(qQ);j2r=r(vTt,"TFTapasForMaskedLM"),vTt.forEach(t),D2r=r(tRe," (TAPAS model)"),tRe.forEach(t),G2r=i(fe),z4=n(fe,"LI",{});var aRe=s(z4);ibe=n(aRe,"STRONG",{});var FTt=s(ibe);O2r=r(FTt,"xlm"),FTt.forEach(t),V2r=r(aRe," \u2014 "),NQ=n(aRe,"A",{href:!0});var TTt=s(NQ);X2r=r(TTt,"TFXLMWithLMHeadModel"),TTt.forEach(t),z2r=r(aRe," (XLM model)"),aRe.forEach(t),W2r=i(fe),W4=n(fe,"LI",{});var nRe=s(W4);dbe=n(nRe,"STRONG",{});var MTt=s(dbe);Q2r=r(MTt,"xlm-roberta"),MTt.forEach(t),H2r=r(nRe," \u2014 "),jQ=n(nRe,"A",{href:!0});var ETt=s(jQ);U2r=r(ETt,"TFXLMRobertaForMaskedLM"),ETt.forEach(t),J2r=r(nRe," (XLM-RoBERTa model)"),nRe.forEach(t),fe.forEach(t),Y2r=i(Tl),T(Q4.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),cNe=i(f),oc=n(f,"H2",{class:!0});var _De=s(oc);H4=n(_De,"A",{id:!0,class:!0,href:!0});var CTt=s(H4);cbe=n(CTt,"SPAN",{});var wTt=s(cbe);T(v8.$$.fragment,wTt),wTt.forEach(t),CTt.forEach(t),K2r=i(_De),fbe=n(_De,"SPAN",{});var ATt=s(fbe);Z2r=r(ATt,"TFAutoModelForSeq2SeqLM"),ATt.forEach(t),_De.forEach(t),fNe=i(f),rr=n(f,"DIV",{class:!0});var Ml=s(rr);T(F8.$$.fragment,Ml),e1r=i(Ml),rc=n(Ml,"P",{});var OZ=s(rc);o1r=r(OZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),DQ=n(OZ,"A",{href:!0});var yTt=s(DQ);r1r=r(yTt,"from_pretrained()"),yTt.forEach(t),t1r=r(OZ," class method or the "),GQ=n(OZ,"A",{href:!0});var LTt=s(GQ);a1r=r(LTt,"from_config()"),LTt.forEach(t),n1r=r(OZ,` class
method.`),OZ.forEach(t),s1r=i(Ml),T8=n(Ml,"P",{});var uDe=s(T8);l1r=r(uDe,"This class cannot be instantiated directly using "),mbe=n(uDe,"CODE",{});var xTt=s(mbe);i1r=r(xTt,"__init__()"),xTt.forEach(t),d1r=r(uDe," (throws an error)."),uDe.forEach(t),c1r=i(Ml),St=n(Ml,"DIV",{class:!0});var TA=s(St);T(M8.$$.fragment,TA),f1r=i(TA),gbe=n(TA,"P",{});var $Tt=s(gbe);m1r=r($Tt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),$Tt.forEach(t),g1r=i(TA),tc=n(TA,"P",{});var VZ=s(tc);h1r=r(VZ,`Note:
Loading a model from its configuration file does `),hbe=n(VZ,"STRONG",{});var kTt=s(hbe);p1r=r(kTt,"not"),kTt.forEach(t),_1r=r(VZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),OQ=n(VZ,"A",{href:!0});var STt=s(OQ);u1r=r(STt,"from_pretrained()"),STt.forEach(t),b1r=r(VZ," to load the model weights."),VZ.forEach(t),v1r=i(TA),T(U4.$$.fragment,TA),TA.forEach(t),F1r=i(Ml),$r=n(Ml,"DIV",{class:!0});var El=s($r);T(E8.$$.fragment,El),T1r=i(El),pbe=n(El,"P",{});var RTt=s(pbe);M1r=r(RTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),RTt.forEach(t),E1r=i(El),an=n(El,"P",{});var MA=s(an);C1r=r(MA,"The model class to instantiate is selected based on the "),_be=n(MA,"CODE",{});var PTt=s(_be);w1r=r(PTt,"model_type"),PTt.forEach(t),A1r=r(MA,` property of the config object (either
passed as an argument or loaded from `),ube=n(MA,"CODE",{});var BTt=s(ube);y1r=r(BTt,"pretrained_model_name_or_path"),BTt.forEach(t),L1r=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bbe=n(MA,"CODE",{});var ITt=s(bbe);x1r=r(ITt,"pretrained_model_name_or_path"),ITt.forEach(t),$1r=r(MA,":"),MA.forEach(t),k1r=i(El),ye=n(El,"UL",{});var Be=s(ye);J4=n(Be,"LI",{});var sRe=s(J4);vbe=n(sRe,"STRONG",{});var qTt=s(vbe);S1r=r(qTt,"bart"),qTt.forEach(t),R1r=r(sRe," \u2014 "),VQ=n(sRe,"A",{href:!0});var NTt=s(VQ);P1r=r(NTt,"TFBartForConditionalGeneration"),NTt.forEach(t),B1r=r(sRe," (BART model)"),sRe.forEach(t),I1r=i(Be),Y4=n(Be,"LI",{});var lRe=s(Y4);Fbe=n(lRe,"STRONG",{});var jTt=s(Fbe);q1r=r(jTt,"blenderbot"),jTt.forEach(t),N1r=r(lRe," \u2014 "),XQ=n(lRe,"A",{href:!0});var DTt=s(XQ);j1r=r(DTt,"TFBlenderbotForConditionalGeneration"),DTt.forEach(t),D1r=r(lRe," (Blenderbot model)"),lRe.forEach(t),G1r=i(Be),K4=n(Be,"LI",{});var iRe=s(K4);Tbe=n(iRe,"STRONG",{});var GTt=s(Tbe);O1r=r(GTt,"blenderbot-small"),GTt.forEach(t),V1r=r(iRe," \u2014 "),zQ=n(iRe,"A",{href:!0});var OTt=s(zQ);X1r=r(OTt,"TFBlenderbotSmallForConditionalGeneration"),OTt.forEach(t),z1r=r(iRe," (BlenderbotSmall model)"),iRe.forEach(t),W1r=i(Be),Z4=n(Be,"LI",{});var dRe=s(Z4);Mbe=n(dRe,"STRONG",{});var VTt=s(Mbe);Q1r=r(VTt,"encoder-decoder"),VTt.forEach(t),H1r=r(dRe," \u2014 "),WQ=n(dRe,"A",{href:!0});var XTt=s(WQ);U1r=r(XTt,"TFEncoderDecoderModel"),XTt.forEach(t),J1r=r(dRe," (Encoder decoder model)"),dRe.forEach(t),Y1r=i(Be),eE=n(Be,"LI",{});var cRe=s(eE);Ebe=n(cRe,"STRONG",{});var zTt=s(Ebe);K1r=r(zTt,"led"),zTt.forEach(t),Z1r=r(cRe," \u2014 "),QQ=n(cRe,"A",{href:!0});var WTt=s(QQ);e7r=r(WTt,"TFLEDForConditionalGeneration"),WTt.forEach(t),o7r=r(cRe," (LED model)"),cRe.forEach(t),r7r=i(Be),oE=n(Be,"LI",{});var fRe=s(oE);Cbe=n(fRe,"STRONG",{});var QTt=s(Cbe);t7r=r(QTt,"marian"),QTt.forEach(t),a7r=r(fRe," \u2014 "),HQ=n(fRe,"A",{href:!0});var HTt=s(HQ);n7r=r(HTt,"TFMarianMTModel"),HTt.forEach(t),s7r=r(fRe," (Marian model)"),fRe.forEach(t),l7r=i(Be),rE=n(Be,"LI",{});var mRe=s(rE);wbe=n(mRe,"STRONG",{});var UTt=s(wbe);i7r=r(UTt,"mbart"),UTt.forEach(t),d7r=r(mRe," \u2014 "),UQ=n(mRe,"A",{href:!0});var JTt=s(UQ);c7r=r(JTt,"TFMBartForConditionalGeneration"),JTt.forEach(t),f7r=r(mRe," (mBART model)"),mRe.forEach(t),m7r=i(Be),tE=n(Be,"LI",{});var gRe=s(tE);Abe=n(gRe,"STRONG",{});var YTt=s(Abe);g7r=r(YTt,"mt5"),YTt.forEach(t),h7r=r(gRe," \u2014 "),JQ=n(gRe,"A",{href:!0});var KTt=s(JQ);p7r=r(KTt,"TFMT5ForConditionalGeneration"),KTt.forEach(t),_7r=r(gRe," (mT5 model)"),gRe.forEach(t),u7r=i(Be),aE=n(Be,"LI",{});var hRe=s(aE);ybe=n(hRe,"STRONG",{});var ZTt=s(ybe);b7r=r(ZTt,"pegasus"),ZTt.forEach(t),v7r=r(hRe," \u2014 "),YQ=n(hRe,"A",{href:!0});var eMt=s(YQ);F7r=r(eMt,"TFPegasusForConditionalGeneration"),eMt.forEach(t),T7r=r(hRe," (Pegasus model)"),hRe.forEach(t),M7r=i(Be),nE=n(Be,"LI",{});var pRe=s(nE);Lbe=n(pRe,"STRONG",{});var oMt=s(Lbe);E7r=r(oMt,"t5"),oMt.forEach(t),C7r=r(pRe," \u2014 "),KQ=n(pRe,"A",{href:!0});var rMt=s(KQ);w7r=r(rMt,"TFT5ForConditionalGeneration"),rMt.forEach(t),A7r=r(pRe," (T5 model)"),pRe.forEach(t),Be.forEach(t),y7r=i(El),T(sE.$$.fragment,El),El.forEach(t),Ml.forEach(t),mNe=i(f),ac=n(f,"H2",{class:!0});var bDe=s(ac);lE=n(bDe,"A",{id:!0,class:!0,href:!0});var tMt=s(lE);xbe=n(tMt,"SPAN",{});var aMt=s(xbe);T(C8.$$.fragment,aMt),aMt.forEach(t),tMt.forEach(t),L7r=i(bDe),$be=n(bDe,"SPAN",{});var nMt=s($be);x7r=r(nMt,"TFAutoModelForSequenceClassification"),nMt.forEach(t),bDe.forEach(t),gNe=i(f),tr=n(f,"DIV",{class:!0});var Cl=s(tr);T(w8.$$.fragment,Cl),$7r=i(Cl),nc=n(Cl,"P",{});var XZ=s(nc);k7r=r(XZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ZQ=n(XZ,"A",{href:!0});var sMt=s(ZQ);S7r=r(sMt,"from_pretrained()"),sMt.forEach(t),R7r=r(XZ," class method or the "),eH=n(XZ,"A",{href:!0});var lMt=s(eH);P7r=r(lMt,"from_config()"),lMt.forEach(t),B7r=r(XZ,` class
method.`),XZ.forEach(t),I7r=i(Cl),A8=n(Cl,"P",{});var vDe=s(A8);q7r=r(vDe,"This class cannot be instantiated directly using "),kbe=n(vDe,"CODE",{});var iMt=s(kbe);N7r=r(iMt,"__init__()"),iMt.forEach(t),j7r=r(vDe," (throws an error)."),vDe.forEach(t),D7r=i(Cl),Rt=n(Cl,"DIV",{class:!0});var EA=s(Rt);T(y8.$$.fragment,EA),G7r=i(EA),Sbe=n(EA,"P",{});var dMt=s(Sbe);O7r=r(dMt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),dMt.forEach(t),V7r=i(EA),sc=n(EA,"P",{});var zZ=s(sc);X7r=r(zZ,`Note:
Loading a model from its configuration file does `),Rbe=n(zZ,"STRONG",{});var cMt=s(Rbe);z7r=r(cMt,"not"),cMt.forEach(t),W7r=r(zZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),oH=n(zZ,"A",{href:!0});var fMt=s(oH);Q7r=r(fMt,"from_pretrained()"),fMt.forEach(t),H7r=r(zZ," to load the model weights."),zZ.forEach(t),U7r=i(EA),T(iE.$$.fragment,EA),EA.forEach(t),J7r=i(Cl),kr=n(Cl,"DIV",{class:!0});var wl=s(kr);T(L8.$$.fragment,wl),Y7r=i(wl),Pbe=n(wl,"P",{});var mMt=s(Pbe);K7r=r(mMt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),mMt.forEach(t),Z7r=i(wl),nn=n(wl,"P",{});var CA=s(nn);ebr=r(CA,"The model class to instantiate is selected based on the "),Bbe=n(CA,"CODE",{});var gMt=s(Bbe);obr=r(gMt,"model_type"),gMt.forEach(t),rbr=r(CA,` property of the config object (either
passed as an argument or loaded from `),Ibe=n(CA,"CODE",{});var hMt=s(Ibe);tbr=r(hMt,"pretrained_model_name_or_path"),hMt.forEach(t),abr=r(CA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qbe=n(CA,"CODE",{});var pMt=s(qbe);nbr=r(pMt,"pretrained_model_name_or_path"),pMt.forEach(t),sbr=r(CA,":"),CA.forEach(t),lbr=i(wl),ee=n(wl,"UL",{});var ae=s(ee);dE=n(ae,"LI",{});var _Re=s(dE);Nbe=n(_Re,"STRONG",{});var _Mt=s(Nbe);ibr=r(_Mt,"albert"),_Mt.forEach(t),dbr=r(_Re," \u2014 "),rH=n(_Re,"A",{href:!0});var uMt=s(rH);cbr=r(uMt,"TFAlbertForSequenceClassification"),uMt.forEach(t),fbr=r(_Re," (ALBERT model)"),_Re.forEach(t),mbr=i(ae),cE=n(ae,"LI",{});var uRe=s(cE);jbe=n(uRe,"STRONG",{});var bMt=s(jbe);gbr=r(bMt,"bert"),bMt.forEach(t),hbr=r(uRe," \u2014 "),tH=n(uRe,"A",{href:!0});var vMt=s(tH);pbr=r(vMt,"TFBertForSequenceClassification"),vMt.forEach(t),_br=r(uRe," (BERT model)"),uRe.forEach(t),ubr=i(ae),fE=n(ae,"LI",{});var bRe=s(fE);Dbe=n(bRe,"STRONG",{});var FMt=s(Dbe);bbr=r(FMt,"camembert"),FMt.forEach(t),vbr=r(bRe," \u2014 "),aH=n(bRe,"A",{href:!0});var TMt=s(aH);Fbr=r(TMt,"TFCamembertForSequenceClassification"),TMt.forEach(t),Tbr=r(bRe," (CamemBERT model)"),bRe.forEach(t),Mbr=i(ae),mE=n(ae,"LI",{});var vRe=s(mE);Gbe=n(vRe,"STRONG",{});var MMt=s(Gbe);Ebr=r(MMt,"convbert"),MMt.forEach(t),Cbr=r(vRe," \u2014 "),nH=n(vRe,"A",{href:!0});var EMt=s(nH);wbr=r(EMt,"TFConvBertForSequenceClassification"),EMt.forEach(t),Abr=r(vRe," (ConvBERT model)"),vRe.forEach(t),ybr=i(ae),gE=n(ae,"LI",{});var FRe=s(gE);Obe=n(FRe,"STRONG",{});var CMt=s(Obe);Lbr=r(CMt,"ctrl"),CMt.forEach(t),xbr=r(FRe," \u2014 "),sH=n(FRe,"A",{href:!0});var wMt=s(sH);$br=r(wMt,"TFCTRLForSequenceClassification"),wMt.forEach(t),kbr=r(FRe," (CTRL model)"),FRe.forEach(t),Sbr=i(ae),hE=n(ae,"LI",{});var TRe=s(hE);Vbe=n(TRe,"STRONG",{});var AMt=s(Vbe);Rbr=r(AMt,"deberta"),AMt.forEach(t),Pbr=r(TRe," \u2014 "),lH=n(TRe,"A",{href:!0});var yMt=s(lH);Bbr=r(yMt,"TFDebertaForSequenceClassification"),yMt.forEach(t),Ibr=r(TRe," (DeBERTa model)"),TRe.forEach(t),qbr=i(ae),pE=n(ae,"LI",{});var MRe=s(pE);Xbe=n(MRe,"STRONG",{});var LMt=s(Xbe);Nbr=r(LMt,"deberta-v2"),LMt.forEach(t),jbr=r(MRe," \u2014 "),iH=n(MRe,"A",{href:!0});var xMt=s(iH);Dbr=r(xMt,"TFDebertaV2ForSequenceClassification"),xMt.forEach(t),Gbr=r(MRe," (DeBERTa-v2 model)"),MRe.forEach(t),Obr=i(ae),_E=n(ae,"LI",{});var ERe=s(_E);zbe=n(ERe,"STRONG",{});var $Mt=s(zbe);Vbr=r($Mt,"distilbert"),$Mt.forEach(t),Xbr=r(ERe," \u2014 "),dH=n(ERe,"A",{href:!0});var kMt=s(dH);zbr=r(kMt,"TFDistilBertForSequenceClassification"),kMt.forEach(t),Wbr=r(ERe," (DistilBERT model)"),ERe.forEach(t),Qbr=i(ae),uE=n(ae,"LI",{});var CRe=s(uE);Wbe=n(CRe,"STRONG",{});var SMt=s(Wbe);Hbr=r(SMt,"electra"),SMt.forEach(t),Ubr=r(CRe," \u2014 "),cH=n(CRe,"A",{href:!0});var RMt=s(cH);Jbr=r(RMt,"TFElectraForSequenceClassification"),RMt.forEach(t),Ybr=r(CRe," (ELECTRA model)"),CRe.forEach(t),Kbr=i(ae),bE=n(ae,"LI",{});var wRe=s(bE);Qbe=n(wRe,"STRONG",{});var PMt=s(Qbe);Zbr=r(PMt,"flaubert"),PMt.forEach(t),evr=r(wRe," \u2014 "),fH=n(wRe,"A",{href:!0});var BMt=s(fH);ovr=r(BMt,"TFFlaubertForSequenceClassification"),BMt.forEach(t),rvr=r(wRe," (FlauBERT model)"),wRe.forEach(t),tvr=i(ae),vE=n(ae,"LI",{});var ARe=s(vE);Hbe=n(ARe,"STRONG",{});var IMt=s(Hbe);avr=r(IMt,"funnel"),IMt.forEach(t),nvr=r(ARe," \u2014 "),mH=n(ARe,"A",{href:!0});var qMt=s(mH);svr=r(qMt,"TFFunnelForSequenceClassification"),qMt.forEach(t),lvr=r(ARe," (Funnel Transformer model)"),ARe.forEach(t),ivr=i(ae),FE=n(ae,"LI",{});var yRe=s(FE);Ube=n(yRe,"STRONG",{});var NMt=s(Ube);dvr=r(NMt,"gpt2"),NMt.forEach(t),cvr=r(yRe," \u2014 "),gH=n(yRe,"A",{href:!0});var jMt=s(gH);fvr=r(jMt,"TFGPT2ForSequenceClassification"),jMt.forEach(t),mvr=r(yRe," (OpenAI GPT-2 model)"),yRe.forEach(t),gvr=i(ae),TE=n(ae,"LI",{});var LRe=s(TE);Jbe=n(LRe,"STRONG",{});var DMt=s(Jbe);hvr=r(DMt,"gptj"),DMt.forEach(t),pvr=r(LRe," \u2014 "),hH=n(LRe,"A",{href:!0});var GMt=s(hH);_vr=r(GMt,"TFGPTJForSequenceClassification"),GMt.forEach(t),uvr=r(LRe," (GPT-J model)"),LRe.forEach(t),bvr=i(ae),ME=n(ae,"LI",{});var xRe=s(ME);Ybe=n(xRe,"STRONG",{});var OMt=s(Ybe);vvr=r(OMt,"layoutlm"),OMt.forEach(t),Fvr=r(xRe," \u2014 "),pH=n(xRe,"A",{href:!0});var VMt=s(pH);Tvr=r(VMt,"TFLayoutLMForSequenceClassification"),VMt.forEach(t),Mvr=r(xRe," (LayoutLM model)"),xRe.forEach(t),Evr=i(ae),EE=n(ae,"LI",{});var $Re=s(EE);Kbe=n($Re,"STRONG",{});var XMt=s(Kbe);Cvr=r(XMt,"longformer"),XMt.forEach(t),wvr=r($Re," \u2014 "),_H=n($Re,"A",{href:!0});var zMt=s(_H);Avr=r(zMt,"TFLongformerForSequenceClassification"),zMt.forEach(t),yvr=r($Re," (Longformer model)"),$Re.forEach(t),Lvr=i(ae),CE=n(ae,"LI",{});var kRe=s(CE);Zbe=n(kRe,"STRONG",{});var WMt=s(Zbe);xvr=r(WMt,"mobilebert"),WMt.forEach(t),$vr=r(kRe," \u2014 "),uH=n(kRe,"A",{href:!0});var QMt=s(uH);kvr=r(QMt,"TFMobileBertForSequenceClassification"),QMt.forEach(t),Svr=r(kRe," (MobileBERT model)"),kRe.forEach(t),Rvr=i(ae),wE=n(ae,"LI",{});var SRe=s(wE);eve=n(SRe,"STRONG",{});var HMt=s(eve);Pvr=r(HMt,"mpnet"),HMt.forEach(t),Bvr=r(SRe," \u2014 "),bH=n(SRe,"A",{href:!0});var UMt=s(bH);Ivr=r(UMt,"TFMPNetForSequenceClassification"),UMt.forEach(t),qvr=r(SRe," (MPNet model)"),SRe.forEach(t),Nvr=i(ae),AE=n(ae,"LI",{});var RRe=s(AE);ove=n(RRe,"STRONG",{});var JMt=s(ove);jvr=r(JMt,"openai-gpt"),JMt.forEach(t),Dvr=r(RRe," \u2014 "),vH=n(RRe,"A",{href:!0});var YMt=s(vH);Gvr=r(YMt,"TFOpenAIGPTForSequenceClassification"),YMt.forEach(t),Ovr=r(RRe," (OpenAI GPT model)"),RRe.forEach(t),Vvr=i(ae),yE=n(ae,"LI",{});var PRe=s(yE);rve=n(PRe,"STRONG",{});var KMt=s(rve);Xvr=r(KMt,"rembert"),KMt.forEach(t),zvr=r(PRe," \u2014 "),FH=n(PRe,"A",{href:!0});var ZMt=s(FH);Wvr=r(ZMt,"TFRemBertForSequenceClassification"),ZMt.forEach(t),Qvr=r(PRe," (RemBERT model)"),PRe.forEach(t),Hvr=i(ae),LE=n(ae,"LI",{});var BRe=s(LE);tve=n(BRe,"STRONG",{});var e4t=s(tve);Uvr=r(e4t,"roberta"),e4t.forEach(t),Jvr=r(BRe," \u2014 "),TH=n(BRe,"A",{href:!0});var o4t=s(TH);Yvr=r(o4t,"TFRobertaForSequenceClassification"),o4t.forEach(t),Kvr=r(BRe," (RoBERTa model)"),BRe.forEach(t),Zvr=i(ae),xE=n(ae,"LI",{});var IRe=s(xE);ave=n(IRe,"STRONG",{});var r4t=s(ave);eFr=r(r4t,"roformer"),r4t.forEach(t),oFr=r(IRe," \u2014 "),MH=n(IRe,"A",{href:!0});var t4t=s(MH);rFr=r(t4t,"TFRoFormerForSequenceClassification"),t4t.forEach(t),tFr=r(IRe," (RoFormer model)"),IRe.forEach(t),aFr=i(ae),$E=n(ae,"LI",{});var qRe=s($E);nve=n(qRe,"STRONG",{});var a4t=s(nve);nFr=r(a4t,"tapas"),a4t.forEach(t),sFr=r(qRe," \u2014 "),EH=n(qRe,"A",{href:!0});var n4t=s(EH);lFr=r(n4t,"TFTapasForSequenceClassification"),n4t.forEach(t),iFr=r(qRe," (TAPAS model)"),qRe.forEach(t),dFr=i(ae),kE=n(ae,"LI",{});var NRe=s(kE);sve=n(NRe,"STRONG",{});var s4t=s(sve);cFr=r(s4t,"transfo-xl"),s4t.forEach(t),fFr=r(NRe," \u2014 "),CH=n(NRe,"A",{href:!0});var l4t=s(CH);mFr=r(l4t,"TFTransfoXLForSequenceClassification"),l4t.forEach(t),gFr=r(NRe," (Transformer-XL model)"),NRe.forEach(t),hFr=i(ae),SE=n(ae,"LI",{});var jRe=s(SE);lve=n(jRe,"STRONG",{});var i4t=s(lve);pFr=r(i4t,"xlm"),i4t.forEach(t),_Fr=r(jRe," \u2014 "),wH=n(jRe,"A",{href:!0});var d4t=s(wH);uFr=r(d4t,"TFXLMForSequenceClassification"),d4t.forEach(t),bFr=r(jRe," (XLM model)"),jRe.forEach(t),vFr=i(ae),RE=n(ae,"LI",{});var DRe=s(RE);ive=n(DRe,"STRONG",{});var c4t=s(ive);FFr=r(c4t,"xlm-roberta"),c4t.forEach(t),TFr=r(DRe," \u2014 "),AH=n(DRe,"A",{href:!0});var f4t=s(AH);MFr=r(f4t,"TFXLMRobertaForSequenceClassification"),f4t.forEach(t),EFr=r(DRe," (XLM-RoBERTa model)"),DRe.forEach(t),CFr=i(ae),PE=n(ae,"LI",{});var GRe=s(PE);dve=n(GRe,"STRONG",{});var m4t=s(dve);wFr=r(m4t,"xlnet"),m4t.forEach(t),AFr=r(GRe," \u2014 "),yH=n(GRe,"A",{href:!0});var g4t=s(yH);yFr=r(g4t,"TFXLNetForSequenceClassification"),g4t.forEach(t),LFr=r(GRe," (XLNet model)"),GRe.forEach(t),ae.forEach(t),xFr=i(wl),T(BE.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),hNe=i(f),lc=n(f,"H2",{class:!0});var FDe=s(lc);IE=n(FDe,"A",{id:!0,class:!0,href:!0});var h4t=s(IE);cve=n(h4t,"SPAN",{});var p4t=s(cve);T(x8.$$.fragment,p4t),p4t.forEach(t),h4t.forEach(t),$Fr=i(FDe),fve=n(FDe,"SPAN",{});var _4t=s(fve);kFr=r(_4t,"TFAutoModelForMultipleChoice"),_4t.forEach(t),FDe.forEach(t),pNe=i(f),ar=n(f,"DIV",{class:!0});var Al=s(ar);T($8.$$.fragment,Al),SFr=i(Al),ic=n(Al,"P",{});var WZ=s(ic);RFr=r(WZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),LH=n(WZ,"A",{href:!0});var u4t=s(LH);PFr=r(u4t,"from_pretrained()"),u4t.forEach(t),BFr=r(WZ," class method or the "),xH=n(WZ,"A",{href:!0});var b4t=s(xH);IFr=r(b4t,"from_config()"),b4t.forEach(t),qFr=r(WZ,` class
method.`),WZ.forEach(t),NFr=i(Al),k8=n(Al,"P",{});var TDe=s(k8);jFr=r(TDe,"This class cannot be instantiated directly using "),mve=n(TDe,"CODE",{});var v4t=s(mve);DFr=r(v4t,"__init__()"),v4t.forEach(t),GFr=r(TDe," (throws an error)."),TDe.forEach(t),OFr=i(Al),Pt=n(Al,"DIV",{class:!0});var wA=s(Pt);T(S8.$$.fragment,wA),VFr=i(wA),gve=n(wA,"P",{});var F4t=s(gve);XFr=r(F4t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),F4t.forEach(t),zFr=i(wA),dc=n(wA,"P",{});var QZ=s(dc);WFr=r(QZ,`Note:
Loading a model from its configuration file does `),hve=n(QZ,"STRONG",{});var T4t=s(hve);QFr=r(T4t,"not"),T4t.forEach(t),HFr=r(QZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=n(QZ,"A",{href:!0});var M4t=s($H);UFr=r(M4t,"from_pretrained()"),M4t.forEach(t),JFr=r(QZ," to load the model weights."),QZ.forEach(t),YFr=i(wA),T(qE.$$.fragment,wA),wA.forEach(t),KFr=i(Al),Sr=n(Al,"DIV",{class:!0});var yl=s(Sr);T(R8.$$.fragment,yl),ZFr=i(yl),pve=n(yl,"P",{});var E4t=s(pve);eTr=r(E4t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),E4t.forEach(t),oTr=i(yl),sn=n(yl,"P",{});var AA=s(sn);rTr=r(AA,"The model class to instantiate is selected based on the "),_ve=n(AA,"CODE",{});var C4t=s(_ve);tTr=r(C4t,"model_type"),C4t.forEach(t),aTr=r(AA,` property of the config object (either
passed as an argument or loaded from `),uve=n(AA,"CODE",{});var w4t=s(uve);nTr=r(w4t,"pretrained_model_name_or_path"),w4t.forEach(t),sTr=r(AA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bve=n(AA,"CODE",{});var A4t=s(bve);lTr=r(A4t,"pretrained_model_name_or_path"),A4t.forEach(t),iTr=r(AA,":"),AA.forEach(t),dTr=i(yl),he=n(yl,"UL",{});var ue=s(he);NE=n(ue,"LI",{});var ORe=s(NE);vve=n(ORe,"STRONG",{});var y4t=s(vve);cTr=r(y4t,"albert"),y4t.forEach(t),fTr=r(ORe," \u2014 "),kH=n(ORe,"A",{href:!0});var L4t=s(kH);mTr=r(L4t,"TFAlbertForMultipleChoice"),L4t.forEach(t),gTr=r(ORe," (ALBERT model)"),ORe.forEach(t),hTr=i(ue),jE=n(ue,"LI",{});var VRe=s(jE);Fve=n(VRe,"STRONG",{});var x4t=s(Fve);pTr=r(x4t,"bert"),x4t.forEach(t),_Tr=r(VRe," \u2014 "),SH=n(VRe,"A",{href:!0});var $4t=s(SH);uTr=r($4t,"TFBertForMultipleChoice"),$4t.forEach(t),bTr=r(VRe," (BERT model)"),VRe.forEach(t),vTr=i(ue),DE=n(ue,"LI",{});var XRe=s(DE);Tve=n(XRe,"STRONG",{});var k4t=s(Tve);FTr=r(k4t,"camembert"),k4t.forEach(t),TTr=r(XRe," \u2014 "),RH=n(XRe,"A",{href:!0});var S4t=s(RH);MTr=r(S4t,"TFCamembertForMultipleChoice"),S4t.forEach(t),ETr=r(XRe," (CamemBERT model)"),XRe.forEach(t),CTr=i(ue),GE=n(ue,"LI",{});var zRe=s(GE);Mve=n(zRe,"STRONG",{});var R4t=s(Mve);wTr=r(R4t,"convbert"),R4t.forEach(t),ATr=r(zRe," \u2014 "),PH=n(zRe,"A",{href:!0});var P4t=s(PH);yTr=r(P4t,"TFConvBertForMultipleChoice"),P4t.forEach(t),LTr=r(zRe," (ConvBERT model)"),zRe.forEach(t),xTr=i(ue),OE=n(ue,"LI",{});var WRe=s(OE);Eve=n(WRe,"STRONG",{});var B4t=s(Eve);$Tr=r(B4t,"distilbert"),B4t.forEach(t),kTr=r(WRe," \u2014 "),BH=n(WRe,"A",{href:!0});var I4t=s(BH);STr=r(I4t,"TFDistilBertForMultipleChoice"),I4t.forEach(t),RTr=r(WRe," (DistilBERT model)"),WRe.forEach(t),PTr=i(ue),VE=n(ue,"LI",{});var QRe=s(VE);Cve=n(QRe,"STRONG",{});var q4t=s(Cve);BTr=r(q4t,"electra"),q4t.forEach(t),ITr=r(QRe," \u2014 "),IH=n(QRe,"A",{href:!0});var N4t=s(IH);qTr=r(N4t,"TFElectraForMultipleChoice"),N4t.forEach(t),NTr=r(QRe," (ELECTRA model)"),QRe.forEach(t),jTr=i(ue),XE=n(ue,"LI",{});var HRe=s(XE);wve=n(HRe,"STRONG",{});var j4t=s(wve);DTr=r(j4t,"flaubert"),j4t.forEach(t),GTr=r(HRe," \u2014 "),qH=n(HRe,"A",{href:!0});var D4t=s(qH);OTr=r(D4t,"TFFlaubertForMultipleChoice"),D4t.forEach(t),VTr=r(HRe," (FlauBERT model)"),HRe.forEach(t),XTr=i(ue),zE=n(ue,"LI",{});var URe=s(zE);Ave=n(URe,"STRONG",{});var G4t=s(Ave);zTr=r(G4t,"funnel"),G4t.forEach(t),WTr=r(URe," \u2014 "),NH=n(URe,"A",{href:!0});var O4t=s(NH);QTr=r(O4t,"TFFunnelForMultipleChoice"),O4t.forEach(t),HTr=r(URe," (Funnel Transformer model)"),URe.forEach(t),UTr=i(ue),WE=n(ue,"LI",{});var JRe=s(WE);yve=n(JRe,"STRONG",{});var V4t=s(yve);JTr=r(V4t,"longformer"),V4t.forEach(t),YTr=r(JRe," \u2014 "),jH=n(JRe,"A",{href:!0});var X4t=s(jH);KTr=r(X4t,"TFLongformerForMultipleChoice"),X4t.forEach(t),ZTr=r(JRe," (Longformer model)"),JRe.forEach(t),eMr=i(ue),QE=n(ue,"LI",{});var YRe=s(QE);Lve=n(YRe,"STRONG",{});var z4t=s(Lve);oMr=r(z4t,"mobilebert"),z4t.forEach(t),rMr=r(YRe," \u2014 "),DH=n(YRe,"A",{href:!0});var W4t=s(DH);tMr=r(W4t,"TFMobileBertForMultipleChoice"),W4t.forEach(t),aMr=r(YRe," (MobileBERT model)"),YRe.forEach(t),nMr=i(ue),HE=n(ue,"LI",{});var KRe=s(HE);xve=n(KRe,"STRONG",{});var Q4t=s(xve);sMr=r(Q4t,"mpnet"),Q4t.forEach(t),lMr=r(KRe," \u2014 "),GH=n(KRe,"A",{href:!0});var H4t=s(GH);iMr=r(H4t,"TFMPNetForMultipleChoice"),H4t.forEach(t),dMr=r(KRe," (MPNet model)"),KRe.forEach(t),cMr=i(ue),UE=n(ue,"LI",{});var ZRe=s(UE);$ve=n(ZRe,"STRONG",{});var U4t=s($ve);fMr=r(U4t,"rembert"),U4t.forEach(t),mMr=r(ZRe," \u2014 "),OH=n(ZRe,"A",{href:!0});var J4t=s(OH);gMr=r(J4t,"TFRemBertForMultipleChoice"),J4t.forEach(t),hMr=r(ZRe," (RemBERT model)"),ZRe.forEach(t),pMr=i(ue),JE=n(ue,"LI",{});var ePe=s(JE);kve=n(ePe,"STRONG",{});var Y4t=s(kve);_Mr=r(Y4t,"roberta"),Y4t.forEach(t),uMr=r(ePe," \u2014 "),VH=n(ePe,"A",{href:!0});var K4t=s(VH);bMr=r(K4t,"TFRobertaForMultipleChoice"),K4t.forEach(t),vMr=r(ePe," (RoBERTa model)"),ePe.forEach(t),FMr=i(ue),YE=n(ue,"LI",{});var oPe=s(YE);Sve=n(oPe,"STRONG",{});var Z4t=s(Sve);TMr=r(Z4t,"roformer"),Z4t.forEach(t),MMr=r(oPe," \u2014 "),XH=n(oPe,"A",{href:!0});var eEt=s(XH);EMr=r(eEt,"TFRoFormerForMultipleChoice"),eEt.forEach(t),CMr=r(oPe," (RoFormer model)"),oPe.forEach(t),wMr=i(ue),KE=n(ue,"LI",{});var rPe=s(KE);Rve=n(rPe,"STRONG",{});var oEt=s(Rve);AMr=r(oEt,"xlm"),oEt.forEach(t),yMr=r(rPe," \u2014 "),zH=n(rPe,"A",{href:!0});var rEt=s(zH);LMr=r(rEt,"TFXLMForMultipleChoice"),rEt.forEach(t),xMr=r(rPe," (XLM model)"),rPe.forEach(t),$Mr=i(ue),ZE=n(ue,"LI",{});var tPe=s(ZE);Pve=n(tPe,"STRONG",{});var tEt=s(Pve);kMr=r(tEt,"xlm-roberta"),tEt.forEach(t),SMr=r(tPe," \u2014 "),WH=n(tPe,"A",{href:!0});var aEt=s(WH);RMr=r(aEt,"TFXLMRobertaForMultipleChoice"),aEt.forEach(t),PMr=r(tPe," (XLM-RoBERTa model)"),tPe.forEach(t),BMr=i(ue),eC=n(ue,"LI",{});var aPe=s(eC);Bve=n(aPe,"STRONG",{});var nEt=s(Bve);IMr=r(nEt,"xlnet"),nEt.forEach(t),qMr=r(aPe," \u2014 "),QH=n(aPe,"A",{href:!0});var sEt=s(QH);NMr=r(sEt,"TFXLNetForMultipleChoice"),sEt.forEach(t),jMr=r(aPe," (XLNet model)"),aPe.forEach(t),ue.forEach(t),DMr=i(yl),T(oC.$$.fragment,yl),yl.forEach(t),Al.forEach(t),_Ne=i(f),cc=n(f,"H2",{class:!0});var MDe=s(cc);rC=n(MDe,"A",{id:!0,class:!0,href:!0});var lEt=s(rC);Ive=n(lEt,"SPAN",{});var iEt=s(Ive);T(P8.$$.fragment,iEt),iEt.forEach(t),lEt.forEach(t),GMr=i(MDe),qve=n(MDe,"SPAN",{});var dEt=s(qve);OMr=r(dEt,"TFAutoModelForNextSentencePrediction"),dEt.forEach(t),MDe.forEach(t),uNe=i(f),nr=n(f,"DIV",{class:!0});var Ll=s(nr);T(B8.$$.fragment,Ll),VMr=i(Ll),fc=n(Ll,"P",{});var HZ=s(fc);XMr=r(HZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),HH=n(HZ,"A",{href:!0});var cEt=s(HH);zMr=r(cEt,"from_pretrained()"),cEt.forEach(t),WMr=r(HZ," class method or the "),UH=n(HZ,"A",{href:!0});var fEt=s(UH);QMr=r(fEt,"from_config()"),fEt.forEach(t),HMr=r(HZ,` class
method.`),HZ.forEach(t),UMr=i(Ll),I8=n(Ll,"P",{});var EDe=s(I8);JMr=r(EDe,"This class cannot be instantiated directly using "),Nve=n(EDe,"CODE",{});var mEt=s(Nve);YMr=r(mEt,"__init__()"),mEt.forEach(t),KMr=r(EDe," (throws an error)."),EDe.forEach(t),ZMr=i(Ll),Bt=n(Ll,"DIV",{class:!0});var yA=s(Bt);T(q8.$$.fragment,yA),e4r=i(yA),jve=n(yA,"P",{});var gEt=s(jve);o4r=r(gEt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gEt.forEach(t),r4r=i(yA),mc=n(yA,"P",{});var UZ=s(mc);t4r=r(UZ,`Note:
Loading a model from its configuration file does `),Dve=n(UZ,"STRONG",{});var hEt=s(Dve);a4r=r(hEt,"not"),hEt.forEach(t),n4r=r(UZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JH=n(UZ,"A",{href:!0});var pEt=s(JH);s4r=r(pEt,"from_pretrained()"),pEt.forEach(t),l4r=r(UZ," to load the model weights."),UZ.forEach(t),i4r=i(yA),T(tC.$$.fragment,yA),yA.forEach(t),d4r=i(Ll),Rr=n(Ll,"DIV",{class:!0});var xl=s(Rr);T(N8.$$.fragment,xl),c4r=i(xl),Gve=n(xl,"P",{});var _Et=s(Gve);f4r=r(_Et,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_Et.forEach(t),m4r=i(xl),ln=n(xl,"P",{});var LA=s(ln);g4r=r(LA,"The model class to instantiate is selected based on the "),Ove=n(LA,"CODE",{});var uEt=s(Ove);h4r=r(uEt,"model_type"),uEt.forEach(t),p4r=r(LA,` property of the config object (either
passed as an argument or loaded from `),Vve=n(LA,"CODE",{});var bEt=s(Vve);_4r=r(bEt,"pretrained_model_name_or_path"),bEt.forEach(t),u4r=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xve=n(LA,"CODE",{});var vEt=s(Xve);b4r=r(vEt,"pretrained_model_name_or_path"),vEt.forEach(t),v4r=r(LA,":"),LA.forEach(t),F4r=i(xl),j8=n(xl,"UL",{});var CDe=s(j8);aC=n(CDe,"LI",{});var nPe=s(aC);zve=n(nPe,"STRONG",{});var FEt=s(zve);T4r=r(FEt,"bert"),FEt.forEach(t),M4r=r(nPe," \u2014 "),YH=n(nPe,"A",{href:!0});var TEt=s(YH);E4r=r(TEt,"TFBertForNextSentencePrediction"),TEt.forEach(t),C4r=r(nPe," (BERT model)"),nPe.forEach(t),w4r=i(CDe),nC=n(CDe,"LI",{});var sPe=s(nC);Wve=n(sPe,"STRONG",{});var MEt=s(Wve);A4r=r(MEt,"mobilebert"),MEt.forEach(t),y4r=r(sPe," \u2014 "),KH=n(sPe,"A",{href:!0});var EEt=s(KH);L4r=r(EEt,"TFMobileBertForNextSentencePrediction"),EEt.forEach(t),x4r=r(sPe," (MobileBERT model)"),sPe.forEach(t),CDe.forEach(t),$4r=i(xl),T(sC.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),bNe=i(f),gc=n(f,"H2",{class:!0});var wDe=s(gc);lC=n(wDe,"A",{id:!0,class:!0,href:!0});var CEt=s(lC);Qve=n(CEt,"SPAN",{});var wEt=s(Qve);T(D8.$$.fragment,wEt),wEt.forEach(t),CEt.forEach(t),k4r=i(wDe),Hve=n(wDe,"SPAN",{});var AEt=s(Hve);S4r=r(AEt,"TFAutoModelForTableQuestionAnswering"),AEt.forEach(t),wDe.forEach(t),vNe=i(f),sr=n(f,"DIV",{class:!0});var $l=s(sr);T(G8.$$.fragment,$l),R4r=i($l),hc=n($l,"P",{});var JZ=s(hc);P4r=r(JZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),ZH=n(JZ,"A",{href:!0});var yEt=s(ZH);B4r=r(yEt,"from_pretrained()"),yEt.forEach(t),I4r=r(JZ," class method or the "),eU=n(JZ,"A",{href:!0});var LEt=s(eU);q4r=r(LEt,"from_config()"),LEt.forEach(t),N4r=r(JZ,` class
method.`),JZ.forEach(t),j4r=i($l),O8=n($l,"P",{});var ADe=s(O8);D4r=r(ADe,"This class cannot be instantiated directly using "),Uve=n(ADe,"CODE",{});var xEt=s(Uve);G4r=r(xEt,"__init__()"),xEt.forEach(t),O4r=r(ADe," (throws an error)."),ADe.forEach(t),V4r=i($l),It=n($l,"DIV",{class:!0});var xA=s(It);T(V8.$$.fragment,xA),X4r=i(xA),Jve=n(xA,"P",{});var $Et=s(Jve);z4r=r($Et,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$Et.forEach(t),W4r=i(xA),pc=n(xA,"P",{});var YZ=s(pc);Q4r=r(YZ,`Note:
Loading a model from its configuration file does `),Yve=n(YZ,"STRONG",{});var kEt=s(Yve);H4r=r(kEt,"not"),kEt.forEach(t),U4r=r(YZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=n(YZ,"A",{href:!0});var SEt=s(oU);J4r=r(SEt,"from_pretrained()"),SEt.forEach(t),Y4r=r(YZ," to load the model weights."),YZ.forEach(t),K4r=i(xA),T(iC.$$.fragment,xA),xA.forEach(t),Z4r=i($l),Pr=n($l,"DIV",{class:!0});var kl=s(Pr);T(X8.$$.fragment,kl),eEr=i(kl),Kve=n(kl,"P",{});var REt=s(Kve);oEr=r(REt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),REt.forEach(t),rEr=i(kl),dn=n(kl,"P",{});var $A=s(dn);tEr=r($A,"The model class to instantiate is selected based on the "),Zve=n($A,"CODE",{});var PEt=s(Zve);aEr=r(PEt,"model_type"),PEt.forEach(t),nEr=r($A,` property of the config object (either
passed as an argument or loaded from `),eFe=n($A,"CODE",{});var BEt=s(eFe);sEr=r(BEt,"pretrained_model_name_or_path"),BEt.forEach(t),lEr=r($A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=n($A,"CODE",{});var IEt=s(oFe);iEr=r(IEt,"pretrained_model_name_or_path"),IEt.forEach(t),dEr=r($A,":"),$A.forEach(t),cEr=i(kl),rFe=n(kl,"UL",{});var qEt=s(rFe);dC=n(qEt,"LI",{});var lPe=s(dC);tFe=n(lPe,"STRONG",{});var NEt=s(tFe);fEr=r(NEt,"tapas"),NEt.forEach(t),mEr=r(lPe," \u2014 "),rU=n(lPe,"A",{href:!0});var jEt=s(rU);gEr=r(jEt,"TFTapasForQuestionAnswering"),jEt.forEach(t),hEr=r(lPe," (TAPAS model)"),lPe.forEach(t),qEt.forEach(t),pEr=i(kl),T(cC.$$.fragment,kl),kl.forEach(t),$l.forEach(t),FNe=i(f),_c=n(f,"H2",{class:!0});var yDe=s(_c);fC=n(yDe,"A",{id:!0,class:!0,href:!0});var DEt=s(fC);aFe=n(DEt,"SPAN",{});var GEt=s(aFe);T(z8.$$.fragment,GEt),GEt.forEach(t),DEt.forEach(t),_Er=i(yDe),nFe=n(yDe,"SPAN",{});var OEt=s(nFe);uEr=r(OEt,"TFAutoModelForTokenClassification"),OEt.forEach(t),yDe.forEach(t),TNe=i(f),lr=n(f,"DIV",{class:!0});var Sl=s(lr);T(W8.$$.fragment,Sl),bEr=i(Sl),uc=n(Sl,"P",{});var KZ=s(uc);vEr=r(KZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),tU=n(KZ,"A",{href:!0});var VEt=s(tU);FEr=r(VEt,"from_pretrained()"),VEt.forEach(t),TEr=r(KZ," class method or the "),aU=n(KZ,"A",{href:!0});var XEt=s(aU);MEr=r(XEt,"from_config()"),XEt.forEach(t),EEr=r(KZ,` class
method.`),KZ.forEach(t),CEr=i(Sl),Q8=n(Sl,"P",{});var LDe=s(Q8);wEr=r(LDe,"This class cannot be instantiated directly using "),sFe=n(LDe,"CODE",{});var zEt=s(sFe);AEr=r(zEt,"__init__()"),zEt.forEach(t),yEr=r(LDe," (throws an error)."),LDe.forEach(t),LEr=i(Sl),qt=n(Sl,"DIV",{class:!0});var kA=s(qt);T(H8.$$.fragment,kA),xEr=i(kA),lFe=n(kA,"P",{});var WEt=s(lFe);$Er=r(WEt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),WEt.forEach(t),kEr=i(kA),bc=n(kA,"P",{});var ZZ=s(bc);SEr=r(ZZ,`Note:
Loading a model from its configuration file does `),iFe=n(ZZ,"STRONG",{});var QEt=s(iFe);REr=r(QEt,"not"),QEt.forEach(t),PEr=r(ZZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),nU=n(ZZ,"A",{href:!0});var HEt=s(nU);BEr=r(HEt,"from_pretrained()"),HEt.forEach(t),IEr=r(ZZ," to load the model weights."),ZZ.forEach(t),qEr=i(kA),T(mC.$$.fragment,kA),kA.forEach(t),NEr=i(Sl),Br=n(Sl,"DIV",{class:!0});var Rl=s(Br);T(U8.$$.fragment,Rl),jEr=i(Rl),dFe=n(Rl,"P",{});var UEt=s(dFe);DEr=r(UEt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),UEt.forEach(t),GEr=i(Rl),cn=n(Rl,"P",{});var SA=s(cn);OEr=r(SA,"The model class to instantiate is selected based on the "),cFe=n(SA,"CODE",{});var JEt=s(cFe);VEr=r(JEt,"model_type"),JEt.forEach(t),XEr=r(SA,` property of the config object (either
passed as an argument or loaded from `),fFe=n(SA,"CODE",{});var YEt=s(fFe);zEr=r(YEt,"pretrained_model_name_or_path"),YEt.forEach(t),WEr=r(SA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mFe=n(SA,"CODE",{});var KEt=s(mFe);QEr=r(KEt,"pretrained_model_name_or_path"),KEt.forEach(t),HEr=r(SA,":"),SA.forEach(t),UEr=i(Rl),de=n(Rl,"UL",{});var me=s(de);gC=n(me,"LI",{});var iPe=s(gC);gFe=n(iPe,"STRONG",{});var ZEt=s(gFe);JEr=r(ZEt,"albert"),ZEt.forEach(t),YEr=r(iPe," \u2014 "),sU=n(iPe,"A",{href:!0});var eCt=s(sU);KEr=r(eCt,"TFAlbertForTokenClassification"),eCt.forEach(t),ZEr=r(iPe," (ALBERT model)"),iPe.forEach(t),eCr=i(me),hC=n(me,"LI",{});var dPe=s(hC);hFe=n(dPe,"STRONG",{});var oCt=s(hFe);oCr=r(oCt,"bert"),oCt.forEach(t),rCr=r(dPe," \u2014 "),lU=n(dPe,"A",{href:!0});var rCt=s(lU);tCr=r(rCt,"TFBertForTokenClassification"),rCt.forEach(t),aCr=r(dPe," (BERT model)"),dPe.forEach(t),nCr=i(me),pC=n(me,"LI",{});var cPe=s(pC);pFe=n(cPe,"STRONG",{});var tCt=s(pFe);sCr=r(tCt,"camembert"),tCt.forEach(t),lCr=r(cPe," \u2014 "),iU=n(cPe,"A",{href:!0});var aCt=s(iU);iCr=r(aCt,"TFCamembertForTokenClassification"),aCt.forEach(t),dCr=r(cPe," (CamemBERT model)"),cPe.forEach(t),cCr=i(me),_C=n(me,"LI",{});var fPe=s(_C);_Fe=n(fPe,"STRONG",{});var nCt=s(_Fe);fCr=r(nCt,"convbert"),nCt.forEach(t),mCr=r(fPe," \u2014 "),dU=n(fPe,"A",{href:!0});var sCt=s(dU);gCr=r(sCt,"TFConvBertForTokenClassification"),sCt.forEach(t),hCr=r(fPe," (ConvBERT model)"),fPe.forEach(t),pCr=i(me),uC=n(me,"LI",{});var mPe=s(uC);uFe=n(mPe,"STRONG",{});var lCt=s(uFe);_Cr=r(lCt,"deberta"),lCt.forEach(t),uCr=r(mPe," \u2014 "),cU=n(mPe,"A",{href:!0});var iCt=s(cU);bCr=r(iCt,"TFDebertaForTokenClassification"),iCt.forEach(t),vCr=r(mPe," (DeBERTa model)"),mPe.forEach(t),FCr=i(me),bC=n(me,"LI",{});var gPe=s(bC);bFe=n(gPe,"STRONG",{});var dCt=s(bFe);TCr=r(dCt,"deberta-v2"),dCt.forEach(t),MCr=r(gPe," \u2014 "),fU=n(gPe,"A",{href:!0});var cCt=s(fU);ECr=r(cCt,"TFDebertaV2ForTokenClassification"),cCt.forEach(t),CCr=r(gPe," (DeBERTa-v2 model)"),gPe.forEach(t),wCr=i(me),vC=n(me,"LI",{});var hPe=s(vC);vFe=n(hPe,"STRONG",{});var fCt=s(vFe);ACr=r(fCt,"distilbert"),fCt.forEach(t),yCr=r(hPe," \u2014 "),mU=n(hPe,"A",{href:!0});var mCt=s(mU);LCr=r(mCt,"TFDistilBertForTokenClassification"),mCt.forEach(t),xCr=r(hPe," (DistilBERT model)"),hPe.forEach(t),$Cr=i(me),FC=n(me,"LI",{});var pPe=s(FC);FFe=n(pPe,"STRONG",{});var gCt=s(FFe);kCr=r(gCt,"electra"),gCt.forEach(t),SCr=r(pPe," \u2014 "),gU=n(pPe,"A",{href:!0});var hCt=s(gU);RCr=r(hCt,"TFElectraForTokenClassification"),hCt.forEach(t),PCr=r(pPe," (ELECTRA model)"),pPe.forEach(t),BCr=i(me),TC=n(me,"LI",{});var _Pe=s(TC);TFe=n(_Pe,"STRONG",{});var pCt=s(TFe);ICr=r(pCt,"flaubert"),pCt.forEach(t),qCr=r(_Pe," \u2014 "),hU=n(_Pe,"A",{href:!0});var _Ct=s(hU);NCr=r(_Ct,"TFFlaubertForTokenClassification"),_Ct.forEach(t),jCr=r(_Pe," (FlauBERT model)"),_Pe.forEach(t),DCr=i(me),MC=n(me,"LI",{});var uPe=s(MC);MFe=n(uPe,"STRONG",{});var uCt=s(MFe);GCr=r(uCt,"funnel"),uCt.forEach(t),OCr=r(uPe," \u2014 "),pU=n(uPe,"A",{href:!0});var bCt=s(pU);VCr=r(bCt,"TFFunnelForTokenClassification"),bCt.forEach(t),XCr=r(uPe," (Funnel Transformer model)"),uPe.forEach(t),zCr=i(me),EC=n(me,"LI",{});var bPe=s(EC);EFe=n(bPe,"STRONG",{});var vCt=s(EFe);WCr=r(vCt,"layoutlm"),vCt.forEach(t),QCr=r(bPe," \u2014 "),_U=n(bPe,"A",{href:!0});var FCt=s(_U);HCr=r(FCt,"TFLayoutLMForTokenClassification"),FCt.forEach(t),UCr=r(bPe," (LayoutLM model)"),bPe.forEach(t),JCr=i(me),CC=n(me,"LI",{});var vPe=s(CC);CFe=n(vPe,"STRONG",{});var TCt=s(CFe);YCr=r(TCt,"longformer"),TCt.forEach(t),KCr=r(vPe," \u2014 "),uU=n(vPe,"A",{href:!0});var MCt=s(uU);ZCr=r(MCt,"TFLongformerForTokenClassification"),MCt.forEach(t),e5r=r(vPe," (Longformer model)"),vPe.forEach(t),o5r=i(me),wC=n(me,"LI",{});var FPe=s(wC);wFe=n(FPe,"STRONG",{});var ECt=s(wFe);r5r=r(ECt,"mobilebert"),ECt.forEach(t),t5r=r(FPe," \u2014 "),bU=n(FPe,"A",{href:!0});var CCt=s(bU);a5r=r(CCt,"TFMobileBertForTokenClassification"),CCt.forEach(t),n5r=r(FPe," (MobileBERT model)"),FPe.forEach(t),s5r=i(me),AC=n(me,"LI",{});var TPe=s(AC);AFe=n(TPe,"STRONG",{});var wCt=s(AFe);l5r=r(wCt,"mpnet"),wCt.forEach(t),i5r=r(TPe," \u2014 "),vU=n(TPe,"A",{href:!0});var ACt=s(vU);d5r=r(ACt,"TFMPNetForTokenClassification"),ACt.forEach(t),c5r=r(TPe," (MPNet model)"),TPe.forEach(t),f5r=i(me),yC=n(me,"LI",{});var MPe=s(yC);yFe=n(MPe,"STRONG",{});var yCt=s(yFe);m5r=r(yCt,"rembert"),yCt.forEach(t),g5r=r(MPe," \u2014 "),FU=n(MPe,"A",{href:!0});var LCt=s(FU);h5r=r(LCt,"TFRemBertForTokenClassification"),LCt.forEach(t),p5r=r(MPe," (RemBERT model)"),MPe.forEach(t),_5r=i(me),LC=n(me,"LI",{});var EPe=s(LC);LFe=n(EPe,"STRONG",{});var xCt=s(LFe);u5r=r(xCt,"roberta"),xCt.forEach(t),b5r=r(EPe," \u2014 "),TU=n(EPe,"A",{href:!0});var $Ct=s(TU);v5r=r($Ct,"TFRobertaForTokenClassification"),$Ct.forEach(t),F5r=r(EPe," (RoBERTa model)"),EPe.forEach(t),T5r=i(me),xC=n(me,"LI",{});var CPe=s(xC);xFe=n(CPe,"STRONG",{});var kCt=s(xFe);M5r=r(kCt,"roformer"),kCt.forEach(t),E5r=r(CPe," \u2014 "),MU=n(CPe,"A",{href:!0});var SCt=s(MU);C5r=r(SCt,"TFRoFormerForTokenClassification"),SCt.forEach(t),w5r=r(CPe," (RoFormer model)"),CPe.forEach(t),A5r=i(me),$C=n(me,"LI",{});var wPe=s($C);$Fe=n(wPe,"STRONG",{});var RCt=s($Fe);y5r=r(RCt,"xlm"),RCt.forEach(t),L5r=r(wPe," \u2014 "),EU=n(wPe,"A",{href:!0});var PCt=s(EU);x5r=r(PCt,"TFXLMForTokenClassification"),PCt.forEach(t),$5r=r(wPe," (XLM model)"),wPe.forEach(t),k5r=i(me),kC=n(me,"LI",{});var APe=s(kC);kFe=n(APe,"STRONG",{});var BCt=s(kFe);S5r=r(BCt,"xlm-roberta"),BCt.forEach(t),R5r=r(APe," \u2014 "),CU=n(APe,"A",{href:!0});var ICt=s(CU);P5r=r(ICt,"TFXLMRobertaForTokenClassification"),ICt.forEach(t),B5r=r(APe," (XLM-RoBERTa model)"),APe.forEach(t),I5r=i(me),SC=n(me,"LI",{});var yPe=s(SC);SFe=n(yPe,"STRONG",{});var qCt=s(SFe);q5r=r(qCt,"xlnet"),qCt.forEach(t),N5r=r(yPe," \u2014 "),wU=n(yPe,"A",{href:!0});var NCt=s(wU);j5r=r(NCt,"TFXLNetForTokenClassification"),NCt.forEach(t),D5r=r(yPe," (XLNet model)"),yPe.forEach(t),me.forEach(t),G5r=i(Rl),T(RC.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),MNe=i(f),vc=n(f,"H2",{class:!0});var xDe=s(vc);PC=n(xDe,"A",{id:!0,class:!0,href:!0});var jCt=s(PC);RFe=n(jCt,"SPAN",{});var DCt=s(RFe);T(J8.$$.fragment,DCt),DCt.forEach(t),jCt.forEach(t),O5r=i(xDe),PFe=n(xDe,"SPAN",{});var GCt=s(PFe);V5r=r(GCt,"TFAutoModelForQuestionAnswering"),GCt.forEach(t),xDe.forEach(t),ENe=i(f),ir=n(f,"DIV",{class:!0});var Pl=s(ir);T(Y8.$$.fragment,Pl),X5r=i(Pl),Fc=n(Pl,"P",{});var eee=s(Fc);z5r=r(eee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),AU=n(eee,"A",{href:!0});var OCt=s(AU);W5r=r(OCt,"from_pretrained()"),OCt.forEach(t),Q5r=r(eee," class method or the "),yU=n(eee,"A",{href:!0});var VCt=s(yU);H5r=r(VCt,"from_config()"),VCt.forEach(t),U5r=r(eee,` class
method.`),eee.forEach(t),J5r=i(Pl),K8=n(Pl,"P",{});var $De=s(K8);Y5r=r($De,"This class cannot be instantiated directly using "),BFe=n($De,"CODE",{});var XCt=s(BFe);K5r=r(XCt,"__init__()"),XCt.forEach(t),Z5r=r($De," (throws an error)."),$De.forEach(t),e3r=i(Pl),Nt=n(Pl,"DIV",{class:!0});var RA=s(Nt);T(Z8.$$.fragment,RA),o3r=i(RA),IFe=n(RA,"P",{});var zCt=s(IFe);r3r=r(zCt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),zCt.forEach(t),t3r=i(RA),Tc=n(RA,"P",{});var oee=s(Tc);a3r=r(oee,`Note:
Loading a model from its configuration file does `),qFe=n(oee,"STRONG",{});var WCt=s(qFe);n3r=r(WCt,"not"),WCt.forEach(t),s3r=r(oee,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(oee,"A",{href:!0});var QCt=s(LU);l3r=r(QCt,"from_pretrained()"),QCt.forEach(t),i3r=r(oee," to load the model weights."),oee.forEach(t),d3r=i(RA),T(BC.$$.fragment,RA),RA.forEach(t),c3r=i(Pl),Ir=n(Pl,"DIV",{class:!0});var Bl=s(Ir);T(ex.$$.fragment,Bl),f3r=i(Bl),NFe=n(Bl,"P",{});var HCt=s(NFe);m3r=r(HCt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),HCt.forEach(t),g3r=i(Bl),fn=n(Bl,"P",{});var PA=s(fn);h3r=r(PA,"The model class to instantiate is selected based on the "),jFe=n(PA,"CODE",{});var UCt=s(jFe);p3r=r(UCt,"model_type"),UCt.forEach(t),_3r=r(PA,` property of the config object (either
passed as an argument or loaded from `),DFe=n(PA,"CODE",{});var JCt=s(DFe);u3r=r(JCt,"pretrained_model_name_or_path"),JCt.forEach(t),b3r=r(PA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GFe=n(PA,"CODE",{});var YCt=s(GFe);v3r=r(YCt,"pretrained_model_name_or_path"),YCt.forEach(t),F3r=r(PA,":"),PA.forEach(t),T3r=i(Bl),ce=n(Bl,"UL",{});var ge=s(ce);IC=n(ge,"LI",{});var LPe=s(IC);OFe=n(LPe,"STRONG",{});var KCt=s(OFe);M3r=r(KCt,"albert"),KCt.forEach(t),E3r=r(LPe," \u2014 "),xU=n(LPe,"A",{href:!0});var ZCt=s(xU);C3r=r(ZCt,"TFAlbertForQuestionAnswering"),ZCt.forEach(t),w3r=r(LPe," (ALBERT model)"),LPe.forEach(t),A3r=i(ge),qC=n(ge,"LI",{});var xPe=s(qC);VFe=n(xPe,"STRONG",{});var e5t=s(VFe);y3r=r(e5t,"bert"),e5t.forEach(t),L3r=r(xPe," \u2014 "),$U=n(xPe,"A",{href:!0});var o5t=s($U);x3r=r(o5t,"TFBertForQuestionAnswering"),o5t.forEach(t),$3r=r(xPe," (BERT model)"),xPe.forEach(t),k3r=i(ge),NC=n(ge,"LI",{});var $Pe=s(NC);XFe=n($Pe,"STRONG",{});var r5t=s(XFe);S3r=r(r5t,"camembert"),r5t.forEach(t),R3r=r($Pe," \u2014 "),kU=n($Pe,"A",{href:!0});var t5t=s(kU);P3r=r(t5t,"TFCamembertForQuestionAnswering"),t5t.forEach(t),B3r=r($Pe," (CamemBERT model)"),$Pe.forEach(t),I3r=i(ge),jC=n(ge,"LI",{});var kPe=s(jC);zFe=n(kPe,"STRONG",{});var a5t=s(zFe);q3r=r(a5t,"convbert"),a5t.forEach(t),N3r=r(kPe," \u2014 "),SU=n(kPe,"A",{href:!0});var n5t=s(SU);j3r=r(n5t,"TFConvBertForQuestionAnswering"),n5t.forEach(t),D3r=r(kPe," (ConvBERT model)"),kPe.forEach(t),G3r=i(ge),DC=n(ge,"LI",{});var SPe=s(DC);WFe=n(SPe,"STRONG",{});var s5t=s(WFe);O3r=r(s5t,"deberta"),s5t.forEach(t),V3r=r(SPe," \u2014 "),RU=n(SPe,"A",{href:!0});var l5t=s(RU);X3r=r(l5t,"TFDebertaForQuestionAnswering"),l5t.forEach(t),z3r=r(SPe," (DeBERTa model)"),SPe.forEach(t),W3r=i(ge),GC=n(ge,"LI",{});var RPe=s(GC);QFe=n(RPe,"STRONG",{});var i5t=s(QFe);Q3r=r(i5t,"deberta-v2"),i5t.forEach(t),H3r=r(RPe," \u2014 "),PU=n(RPe,"A",{href:!0});var d5t=s(PU);U3r=r(d5t,"TFDebertaV2ForQuestionAnswering"),d5t.forEach(t),J3r=r(RPe," (DeBERTa-v2 model)"),RPe.forEach(t),Y3r=i(ge),OC=n(ge,"LI",{});var PPe=s(OC);HFe=n(PPe,"STRONG",{});var c5t=s(HFe);K3r=r(c5t,"distilbert"),c5t.forEach(t),Z3r=r(PPe," \u2014 "),BU=n(PPe,"A",{href:!0});var f5t=s(BU);ewr=r(f5t,"TFDistilBertForQuestionAnswering"),f5t.forEach(t),owr=r(PPe," (DistilBERT model)"),PPe.forEach(t),rwr=i(ge),VC=n(ge,"LI",{});var BPe=s(VC);UFe=n(BPe,"STRONG",{});var m5t=s(UFe);twr=r(m5t,"electra"),m5t.forEach(t),awr=r(BPe," \u2014 "),IU=n(BPe,"A",{href:!0});var g5t=s(IU);nwr=r(g5t,"TFElectraForQuestionAnswering"),g5t.forEach(t),swr=r(BPe," (ELECTRA model)"),BPe.forEach(t),lwr=i(ge),XC=n(ge,"LI",{});var IPe=s(XC);JFe=n(IPe,"STRONG",{});var h5t=s(JFe);iwr=r(h5t,"flaubert"),h5t.forEach(t),dwr=r(IPe," \u2014 "),qU=n(IPe,"A",{href:!0});var p5t=s(qU);cwr=r(p5t,"TFFlaubertForQuestionAnsweringSimple"),p5t.forEach(t),fwr=r(IPe," (FlauBERT model)"),IPe.forEach(t),mwr=i(ge),zC=n(ge,"LI",{});var qPe=s(zC);YFe=n(qPe,"STRONG",{});var _5t=s(YFe);gwr=r(_5t,"funnel"),_5t.forEach(t),hwr=r(qPe," \u2014 "),NU=n(qPe,"A",{href:!0});var u5t=s(NU);pwr=r(u5t,"TFFunnelForQuestionAnswering"),u5t.forEach(t),_wr=r(qPe," (Funnel Transformer model)"),qPe.forEach(t),uwr=i(ge),WC=n(ge,"LI",{});var NPe=s(WC);KFe=n(NPe,"STRONG",{});var b5t=s(KFe);bwr=r(b5t,"gptj"),b5t.forEach(t),vwr=r(NPe," \u2014 "),jU=n(NPe,"A",{href:!0});var v5t=s(jU);Fwr=r(v5t,"TFGPTJForQuestionAnswering"),v5t.forEach(t),Twr=r(NPe," (GPT-J model)"),NPe.forEach(t),Mwr=i(ge),QC=n(ge,"LI",{});var jPe=s(QC);ZFe=n(jPe,"STRONG",{});var F5t=s(ZFe);Ewr=r(F5t,"longformer"),F5t.forEach(t),Cwr=r(jPe," \u2014 "),DU=n(jPe,"A",{href:!0});var T5t=s(DU);wwr=r(T5t,"TFLongformerForQuestionAnswering"),T5t.forEach(t),Awr=r(jPe," (Longformer model)"),jPe.forEach(t),ywr=i(ge),HC=n(ge,"LI",{});var DPe=s(HC);eTe=n(DPe,"STRONG",{});var M5t=s(eTe);Lwr=r(M5t,"mobilebert"),M5t.forEach(t),xwr=r(DPe," \u2014 "),GU=n(DPe,"A",{href:!0});var E5t=s(GU);$wr=r(E5t,"TFMobileBertForQuestionAnswering"),E5t.forEach(t),kwr=r(DPe," (MobileBERT model)"),DPe.forEach(t),Swr=i(ge),UC=n(ge,"LI",{});var GPe=s(UC);oTe=n(GPe,"STRONG",{});var C5t=s(oTe);Rwr=r(C5t,"mpnet"),C5t.forEach(t),Pwr=r(GPe," \u2014 "),OU=n(GPe,"A",{href:!0});var w5t=s(OU);Bwr=r(w5t,"TFMPNetForQuestionAnswering"),w5t.forEach(t),Iwr=r(GPe," (MPNet model)"),GPe.forEach(t),qwr=i(ge),JC=n(ge,"LI",{});var OPe=s(JC);rTe=n(OPe,"STRONG",{});var A5t=s(rTe);Nwr=r(A5t,"rembert"),A5t.forEach(t),jwr=r(OPe," \u2014 "),VU=n(OPe,"A",{href:!0});var y5t=s(VU);Dwr=r(y5t,"TFRemBertForQuestionAnswering"),y5t.forEach(t),Gwr=r(OPe," (RemBERT model)"),OPe.forEach(t),Owr=i(ge),YC=n(ge,"LI",{});var VPe=s(YC);tTe=n(VPe,"STRONG",{});var L5t=s(tTe);Vwr=r(L5t,"roberta"),L5t.forEach(t),Xwr=r(VPe," \u2014 "),XU=n(VPe,"A",{href:!0});var x5t=s(XU);zwr=r(x5t,"TFRobertaForQuestionAnswering"),x5t.forEach(t),Wwr=r(VPe," (RoBERTa model)"),VPe.forEach(t),Qwr=i(ge),KC=n(ge,"LI",{});var XPe=s(KC);aTe=n(XPe,"STRONG",{});var $5t=s(aTe);Hwr=r($5t,"roformer"),$5t.forEach(t),Uwr=r(XPe," \u2014 "),zU=n(XPe,"A",{href:!0});var k5t=s(zU);Jwr=r(k5t,"TFRoFormerForQuestionAnswering"),k5t.forEach(t),Ywr=r(XPe," (RoFormer model)"),XPe.forEach(t),Kwr=i(ge),ZC=n(ge,"LI",{});var zPe=s(ZC);nTe=n(zPe,"STRONG",{});var S5t=s(nTe);Zwr=r(S5t,"xlm"),S5t.forEach(t),e0r=r(zPe," \u2014 "),WU=n(zPe,"A",{href:!0});var R5t=s(WU);o0r=r(R5t,"TFXLMForQuestionAnsweringSimple"),R5t.forEach(t),r0r=r(zPe," (XLM model)"),zPe.forEach(t),t0r=i(ge),e5=n(ge,"LI",{});var WPe=s(e5);sTe=n(WPe,"STRONG",{});var P5t=s(sTe);a0r=r(P5t,"xlm-roberta"),P5t.forEach(t),n0r=r(WPe," \u2014 "),QU=n(WPe,"A",{href:!0});var B5t=s(QU);s0r=r(B5t,"TFXLMRobertaForQuestionAnswering"),B5t.forEach(t),l0r=r(WPe," (XLM-RoBERTa model)"),WPe.forEach(t),i0r=i(ge),o5=n(ge,"LI",{});var QPe=s(o5);lTe=n(QPe,"STRONG",{});var I5t=s(lTe);d0r=r(I5t,"xlnet"),I5t.forEach(t),c0r=r(QPe," \u2014 "),HU=n(QPe,"A",{href:!0});var q5t=s(HU);f0r=r(q5t,"TFXLNetForQuestionAnsweringSimple"),q5t.forEach(t),m0r=r(QPe," (XLNet model)"),QPe.forEach(t),ge.forEach(t),g0r=i(Bl),T(r5.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),CNe=i(f),Mc=n(f,"H2",{class:!0});var kDe=s(Mc);t5=n(kDe,"A",{id:!0,class:!0,href:!0});var N5t=s(t5);iTe=n(N5t,"SPAN",{});var j5t=s(iTe);T(ox.$$.fragment,j5t),j5t.forEach(t),N5t.forEach(t),h0r=i(kDe),dTe=n(kDe,"SPAN",{});var D5t=s(dTe);p0r=r(D5t,"TFAutoModelForVision2Seq"),D5t.forEach(t),kDe.forEach(t),wNe=i(f),dr=n(f,"DIV",{class:!0});var Il=s(dr);T(rx.$$.fragment,Il),_0r=i(Il),Ec=n(Il,"P",{});var ree=s(Ec);u0r=r(ree,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),UU=n(ree,"A",{href:!0});var G5t=s(UU);b0r=r(G5t,"from_pretrained()"),G5t.forEach(t),v0r=r(ree," class method or the "),JU=n(ree,"A",{href:!0});var O5t=s(JU);F0r=r(O5t,"from_config()"),O5t.forEach(t),T0r=r(ree,` class
method.`),ree.forEach(t),M0r=i(Il),tx=n(Il,"P",{});var SDe=s(tx);E0r=r(SDe,"This class cannot be instantiated directly using "),cTe=n(SDe,"CODE",{});var V5t=s(cTe);C0r=r(V5t,"__init__()"),V5t.forEach(t),w0r=r(SDe," (throws an error)."),SDe.forEach(t),A0r=i(Il),jt=n(Il,"DIV",{class:!0});var BA=s(jt);T(ax.$$.fragment,BA),y0r=i(BA),fTe=n(BA,"P",{});var X5t=s(fTe);L0r=r(X5t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),X5t.forEach(t),x0r=i(BA),Cc=n(BA,"P",{});var tee=s(Cc);$0r=r(tee,`Note:
Loading a model from its configuration file does `),mTe=n(tee,"STRONG",{});var z5t=s(mTe);k0r=r(z5t,"not"),z5t.forEach(t),S0r=r(tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),YU=n(tee,"A",{href:!0});var W5t=s(YU);R0r=r(W5t,"from_pretrained()"),W5t.forEach(t),P0r=r(tee," to load the model weights."),tee.forEach(t),B0r=i(BA),T(a5.$$.fragment,BA),BA.forEach(t),I0r=i(Il),qr=n(Il,"DIV",{class:!0});var ql=s(qr);T(nx.$$.fragment,ql),q0r=i(ql),gTe=n(ql,"P",{});var Q5t=s(gTe);N0r=r(Q5t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Q5t.forEach(t),j0r=i(ql),mn=n(ql,"P",{});var IA=s(mn);D0r=r(IA,"The model class to instantiate is selected based on the "),hTe=n(IA,"CODE",{});var H5t=s(hTe);G0r=r(H5t,"model_type"),H5t.forEach(t),O0r=r(IA,` property of the config object (either
passed as an argument or loaded from `),pTe=n(IA,"CODE",{});var U5t=s(pTe);V0r=r(U5t,"pretrained_model_name_or_path"),U5t.forEach(t),X0r=r(IA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Te=n(IA,"CODE",{});var J5t=s(_Te);z0r=r(J5t,"pretrained_model_name_or_path"),J5t.forEach(t),W0r=r(IA,":"),IA.forEach(t),Q0r=i(ql),uTe=n(ql,"UL",{});var Y5t=s(uTe);n5=n(Y5t,"LI",{});var HPe=s(n5);bTe=n(HPe,"STRONG",{});var K5t=s(bTe);H0r=r(K5t,"vision-encoder-decoder"),K5t.forEach(t),U0r=r(HPe," \u2014 "),KU=n(HPe,"A",{href:!0});var Z5t=s(KU);J0r=r(Z5t,"TFVisionEncoderDecoderModel"),Z5t.forEach(t),Y0r=r(HPe," (Vision Encoder decoder model)"),HPe.forEach(t),Y5t.forEach(t),K0r=i(ql),T(s5.$$.fragment,ql),ql.forEach(t),Il.forEach(t),ANe=i(f),wc=n(f,"H2",{class:!0});var RDe=s(wc);l5=n(RDe,"A",{id:!0,class:!0,href:!0});var e3t=s(l5);vTe=n(e3t,"SPAN",{});var o3t=s(vTe);T(sx.$$.fragment,o3t),o3t.forEach(t),e3t.forEach(t),Z0r=i(RDe),FTe=n(RDe,"SPAN",{});var r3t=s(FTe);eAr=r(r3t,"TFAutoModelForSpeechSeq2Seq"),r3t.forEach(t),RDe.forEach(t),yNe=i(f),cr=n(f,"DIV",{class:!0});var Nl=s(cr);T(lx.$$.fragment,Nl),oAr=i(Nl),Ac=n(Nl,"P",{});var aee=s(Ac);rAr=r(aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ZU=n(aee,"A",{href:!0});var t3t=s(ZU);tAr=r(t3t,"from_pretrained()"),t3t.forEach(t),aAr=r(aee," class method or the "),eJ=n(aee,"A",{href:!0});var a3t=s(eJ);nAr=r(a3t,"from_config()"),a3t.forEach(t),sAr=r(aee,` class
method.`),aee.forEach(t),lAr=i(Nl),ix=n(Nl,"P",{});var PDe=s(ix);iAr=r(PDe,"This class cannot be instantiated directly using "),TTe=n(PDe,"CODE",{});var n3t=s(TTe);dAr=r(n3t,"__init__()"),n3t.forEach(t),cAr=r(PDe," (throws an error)."),PDe.forEach(t),fAr=i(Nl),Dt=n(Nl,"DIV",{class:!0});var qA=s(Dt);T(dx.$$.fragment,qA),mAr=i(qA),MTe=n(qA,"P",{});var s3t=s(MTe);gAr=r(s3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),s3t.forEach(t),hAr=i(qA),yc=n(qA,"P",{});var nee=s(yc);pAr=r(nee,`Note:
Loading a model from its configuration file does `),ETe=n(nee,"STRONG",{});var l3t=s(ETe);_Ar=r(l3t,"not"),l3t.forEach(t),uAr=r(nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=n(nee,"A",{href:!0});var i3t=s(oJ);bAr=r(i3t,"from_pretrained()"),i3t.forEach(t),vAr=r(nee," to load the model weights."),nee.forEach(t),FAr=i(qA),T(i5.$$.fragment,qA),qA.forEach(t),TAr=i(Nl),Nr=n(Nl,"DIV",{class:!0});var jl=s(Nr);T(cx.$$.fragment,jl),MAr=i(jl),CTe=n(jl,"P",{});var d3t=s(CTe);EAr=r(d3t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),d3t.forEach(t),CAr=i(jl),gn=n(jl,"P",{});var NA=s(gn);wAr=r(NA,"The model class to instantiate is selected based on the "),wTe=n(NA,"CODE",{});var c3t=s(wTe);AAr=r(c3t,"model_type"),c3t.forEach(t),yAr=r(NA,` property of the config object (either
passed as an argument or loaded from `),ATe=n(NA,"CODE",{});var f3t=s(ATe);LAr=r(f3t,"pretrained_model_name_or_path"),f3t.forEach(t),xAr=r(NA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yTe=n(NA,"CODE",{});var m3t=s(yTe);$Ar=r(m3t,"pretrained_model_name_or_path"),m3t.forEach(t),kAr=r(NA,":"),NA.forEach(t),SAr=i(jl),LTe=n(jl,"UL",{});var g3t=s(LTe);d5=n(g3t,"LI",{});var UPe=s(d5);xTe=n(UPe,"STRONG",{});var h3t=s(xTe);RAr=r(h3t,"speech_to_text"),h3t.forEach(t),PAr=r(UPe," \u2014 "),rJ=n(UPe,"A",{href:!0});var p3t=s(rJ);BAr=r(p3t,"TFSpeech2TextForConditionalGeneration"),p3t.forEach(t),IAr=r(UPe," (Speech2Text model)"),UPe.forEach(t),g3t.forEach(t),qAr=i(jl),T(c5.$$.fragment,jl),jl.forEach(t),Nl.forEach(t),LNe=i(f),Lc=n(f,"H2",{class:!0});var BDe=s(Lc);f5=n(BDe,"A",{id:!0,class:!0,href:!0});var _3t=s(f5);$Te=n(_3t,"SPAN",{});var u3t=s($Te);T(fx.$$.fragment,u3t),u3t.forEach(t),_3t.forEach(t),NAr=i(BDe),kTe=n(BDe,"SPAN",{});var b3t=s(kTe);jAr=r(b3t,"FlaxAutoModel"),b3t.forEach(t),BDe.forEach(t),xNe=i(f),fr=n(f,"DIV",{class:!0});var Dl=s(fr);T(mx.$$.fragment,Dl),DAr=i(Dl),xc=n(Dl,"P",{});var see=s(xc);GAr=r(see,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tJ=n(see,"A",{href:!0});var v3t=s(tJ);OAr=r(v3t,"from_pretrained()"),v3t.forEach(t),VAr=r(see," class method or the "),aJ=n(see,"A",{href:!0});var F3t=s(aJ);XAr=r(F3t,"from_config()"),F3t.forEach(t),zAr=r(see,` class
method.`),see.forEach(t),WAr=i(Dl),gx=n(Dl,"P",{});var IDe=s(gx);QAr=r(IDe,"This class cannot be instantiated directly using "),STe=n(IDe,"CODE",{});var T3t=s(STe);HAr=r(T3t,"__init__()"),T3t.forEach(t),UAr=r(IDe," (throws an error)."),IDe.forEach(t),JAr=i(Dl),Gt=n(Dl,"DIV",{class:!0});var jA=s(Gt);T(hx.$$.fragment,jA),YAr=i(jA),RTe=n(jA,"P",{});var M3t=s(RTe);KAr=r(M3t,"Instantiates one of the base model classes of the library from a configuration."),M3t.forEach(t),ZAr=i(jA),$c=n(jA,"P",{});var lee=s($c);e6r=r(lee,`Note:
Loading a model from its configuration file does `),PTe=n(lee,"STRONG",{});var E3t=s(PTe);o6r=r(E3t,"not"),E3t.forEach(t),r6r=r(lee,` load the model weights. It only affects the
model\u2019s configuration. Use `),nJ=n(lee,"A",{href:!0});var C3t=s(nJ);t6r=r(C3t,"from_pretrained()"),C3t.forEach(t),a6r=r(lee," to load the model weights."),lee.forEach(t),n6r=i(jA),T(m5.$$.fragment,jA),jA.forEach(t),s6r=i(Dl),jr=n(Dl,"DIV",{class:!0});var Gl=s(jr);T(px.$$.fragment,Gl),l6r=i(Gl),BTe=n(Gl,"P",{});var w3t=s(BTe);i6r=r(w3t,"Instantiate one of the base model classes of the library from a pretrained model."),w3t.forEach(t),d6r=i(Gl),hn=n(Gl,"P",{});var DA=s(hn);c6r=r(DA,"The model class to instantiate is selected based on the "),ITe=n(DA,"CODE",{});var A3t=s(ITe);f6r=r(A3t,"model_type"),A3t.forEach(t),m6r=r(DA,` property of the config object (either
passed as an argument or loaded from `),qTe=n(DA,"CODE",{});var y3t=s(qTe);g6r=r(y3t,"pretrained_model_name_or_path"),y3t.forEach(t),h6r=r(DA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=n(DA,"CODE",{});var L3t=s(NTe);p6r=r(L3t,"pretrained_model_name_or_path"),L3t.forEach(t),_6r=r(DA,":"),DA.forEach(t),u6r=i(Gl),oe=n(Gl,"UL",{});var ne=s(oe);g5=n(ne,"LI",{});var JPe=s(g5);jTe=n(JPe,"STRONG",{});var x3t=s(jTe);b6r=r(x3t,"albert"),x3t.forEach(t),v6r=r(JPe," \u2014 "),sJ=n(JPe,"A",{href:!0});var $3t=s(sJ);F6r=r($3t,"FlaxAlbertModel"),$3t.forEach(t),T6r=r(JPe," (ALBERT model)"),JPe.forEach(t),M6r=i(ne),h5=n(ne,"LI",{});var YPe=s(h5);DTe=n(YPe,"STRONG",{});var k3t=s(DTe);E6r=r(k3t,"bart"),k3t.forEach(t),C6r=r(YPe," \u2014 "),lJ=n(YPe,"A",{href:!0});var S3t=s(lJ);w6r=r(S3t,"FlaxBartModel"),S3t.forEach(t),A6r=r(YPe," (BART model)"),YPe.forEach(t),y6r=i(ne),p5=n(ne,"LI",{});var KPe=s(p5);GTe=n(KPe,"STRONG",{});var R3t=s(GTe);L6r=r(R3t,"beit"),R3t.forEach(t),x6r=r(KPe," \u2014 "),iJ=n(KPe,"A",{href:!0});var P3t=s(iJ);$6r=r(P3t,"FlaxBeitModel"),P3t.forEach(t),k6r=r(KPe," (BEiT model)"),KPe.forEach(t),S6r=i(ne),_5=n(ne,"LI",{});var ZPe=s(_5);OTe=n(ZPe,"STRONG",{});var B3t=s(OTe);R6r=r(B3t,"bert"),B3t.forEach(t),P6r=r(ZPe," \u2014 "),dJ=n(ZPe,"A",{href:!0});var I3t=s(dJ);B6r=r(I3t,"FlaxBertModel"),I3t.forEach(t),I6r=r(ZPe," (BERT model)"),ZPe.forEach(t),q6r=i(ne),u5=n(ne,"LI",{});var eBe=s(u5);VTe=n(eBe,"STRONG",{});var q3t=s(VTe);N6r=r(q3t,"big_bird"),q3t.forEach(t),j6r=r(eBe," \u2014 "),cJ=n(eBe,"A",{href:!0});var N3t=s(cJ);D6r=r(N3t,"FlaxBigBirdModel"),N3t.forEach(t),G6r=r(eBe," (BigBird model)"),eBe.forEach(t),O6r=i(ne),b5=n(ne,"LI",{});var oBe=s(b5);XTe=n(oBe,"STRONG",{});var j3t=s(XTe);V6r=r(j3t,"blenderbot"),j3t.forEach(t),X6r=r(oBe," \u2014 "),fJ=n(oBe,"A",{href:!0});var D3t=s(fJ);z6r=r(D3t,"FlaxBlenderbotModel"),D3t.forEach(t),W6r=r(oBe," (Blenderbot model)"),oBe.forEach(t),Q6r=i(ne),v5=n(ne,"LI",{});var rBe=s(v5);zTe=n(rBe,"STRONG",{});var G3t=s(zTe);H6r=r(G3t,"blenderbot-small"),G3t.forEach(t),U6r=r(rBe," \u2014 "),mJ=n(rBe,"A",{href:!0});var O3t=s(mJ);J6r=r(O3t,"FlaxBlenderbotSmallModel"),O3t.forEach(t),Y6r=r(rBe," (BlenderbotSmall model)"),rBe.forEach(t),K6r=i(ne),F5=n(ne,"LI",{});var tBe=s(F5);WTe=n(tBe,"STRONG",{});var V3t=s(WTe);Z6r=r(V3t,"clip"),V3t.forEach(t),eyr=r(tBe," \u2014 "),gJ=n(tBe,"A",{href:!0});var X3t=s(gJ);oyr=r(X3t,"FlaxCLIPModel"),X3t.forEach(t),ryr=r(tBe," (CLIP model)"),tBe.forEach(t),tyr=i(ne),T5=n(ne,"LI",{});var aBe=s(T5);QTe=n(aBe,"STRONG",{});var z3t=s(QTe);ayr=r(z3t,"distilbert"),z3t.forEach(t),nyr=r(aBe," \u2014 "),hJ=n(aBe,"A",{href:!0});var W3t=s(hJ);syr=r(W3t,"FlaxDistilBertModel"),W3t.forEach(t),lyr=r(aBe," (DistilBERT model)"),aBe.forEach(t),iyr=i(ne),M5=n(ne,"LI",{});var nBe=s(M5);HTe=n(nBe,"STRONG",{});var Q3t=s(HTe);dyr=r(Q3t,"electra"),Q3t.forEach(t),cyr=r(nBe," \u2014 "),pJ=n(nBe,"A",{href:!0});var H3t=s(pJ);fyr=r(H3t,"FlaxElectraModel"),H3t.forEach(t),myr=r(nBe," (ELECTRA model)"),nBe.forEach(t),gyr=i(ne),E5=n(ne,"LI",{});var sBe=s(E5);UTe=n(sBe,"STRONG",{});var U3t=s(UTe);hyr=r(U3t,"gpt2"),U3t.forEach(t),pyr=r(sBe," \u2014 "),_J=n(sBe,"A",{href:!0});var J3t=s(_J);_yr=r(J3t,"FlaxGPT2Model"),J3t.forEach(t),uyr=r(sBe," (OpenAI GPT-2 model)"),sBe.forEach(t),byr=i(ne),C5=n(ne,"LI",{});var lBe=s(C5);JTe=n(lBe,"STRONG",{});var Y3t=s(JTe);vyr=r(Y3t,"gpt_neo"),Y3t.forEach(t),Fyr=r(lBe," \u2014 "),uJ=n(lBe,"A",{href:!0});var K3t=s(uJ);Tyr=r(K3t,"FlaxGPTNeoModel"),K3t.forEach(t),Myr=r(lBe," (GPT Neo model)"),lBe.forEach(t),Eyr=i(ne),w5=n(ne,"LI",{});var iBe=s(w5);YTe=n(iBe,"STRONG",{});var Z3t=s(YTe);Cyr=r(Z3t,"gptj"),Z3t.forEach(t),wyr=r(iBe," \u2014 "),bJ=n(iBe,"A",{href:!0});var ewt=s(bJ);Ayr=r(ewt,"FlaxGPTJModel"),ewt.forEach(t),yyr=r(iBe," (GPT-J model)"),iBe.forEach(t),Lyr=i(ne),A5=n(ne,"LI",{});var dBe=s(A5);KTe=n(dBe,"STRONG",{});var owt=s(KTe);xyr=r(owt,"marian"),owt.forEach(t),$yr=r(dBe," \u2014 "),vJ=n(dBe,"A",{href:!0});var rwt=s(vJ);kyr=r(rwt,"FlaxMarianModel"),rwt.forEach(t),Syr=r(dBe," (Marian model)"),dBe.forEach(t),Ryr=i(ne),y5=n(ne,"LI",{});var cBe=s(y5);ZTe=n(cBe,"STRONG",{});var twt=s(ZTe);Pyr=r(twt,"mbart"),twt.forEach(t),Byr=r(cBe," \u2014 "),FJ=n(cBe,"A",{href:!0});var awt=s(FJ);Iyr=r(awt,"FlaxMBartModel"),awt.forEach(t),qyr=r(cBe," (mBART model)"),cBe.forEach(t),Nyr=i(ne),L5=n(ne,"LI",{});var fBe=s(L5);eMe=n(fBe,"STRONG",{});var nwt=s(eMe);jyr=r(nwt,"mt5"),nwt.forEach(t),Dyr=r(fBe," \u2014 "),TJ=n(fBe,"A",{href:!0});var swt=s(TJ);Gyr=r(swt,"FlaxMT5Model"),swt.forEach(t),Oyr=r(fBe," (mT5 model)"),fBe.forEach(t),Vyr=i(ne),x5=n(ne,"LI",{});var mBe=s(x5);oMe=n(mBe,"STRONG",{});var lwt=s(oMe);Xyr=r(lwt,"opt"),lwt.forEach(t),zyr=r(mBe," \u2014 "),MJ=n(mBe,"A",{href:!0});var iwt=s(MJ);Wyr=r(iwt,"FlaxOPTModel"),iwt.forEach(t),Qyr=r(mBe," (OPT model)"),mBe.forEach(t),Hyr=i(ne),$5=n(ne,"LI",{});var gBe=s($5);rMe=n(gBe,"STRONG",{});var dwt=s(rMe);Uyr=r(dwt,"pegasus"),dwt.forEach(t),Jyr=r(gBe," \u2014 "),EJ=n(gBe,"A",{href:!0});var cwt=s(EJ);Yyr=r(cwt,"FlaxPegasusModel"),cwt.forEach(t),Kyr=r(gBe," (Pegasus model)"),gBe.forEach(t),Zyr=i(ne),k5=n(ne,"LI",{});var hBe=s(k5);tMe=n(hBe,"STRONG",{});var fwt=s(tMe);eLr=r(fwt,"roberta"),fwt.forEach(t),oLr=r(hBe," \u2014 "),CJ=n(hBe,"A",{href:!0});var mwt=s(CJ);rLr=r(mwt,"FlaxRobertaModel"),mwt.forEach(t),tLr=r(hBe," (RoBERTa model)"),hBe.forEach(t),aLr=i(ne),S5=n(ne,"LI",{});var pBe=s(S5);aMe=n(pBe,"STRONG",{});var gwt=s(aMe);nLr=r(gwt,"roformer"),gwt.forEach(t),sLr=r(pBe," \u2014 "),wJ=n(pBe,"A",{href:!0});var hwt=s(wJ);lLr=r(hwt,"FlaxRoFormerModel"),hwt.forEach(t),iLr=r(pBe," (RoFormer model)"),pBe.forEach(t),dLr=i(ne),R5=n(ne,"LI",{});var _Be=s(R5);nMe=n(_Be,"STRONG",{});var pwt=s(nMe);cLr=r(pwt,"t5"),pwt.forEach(t),fLr=r(_Be," \u2014 "),AJ=n(_Be,"A",{href:!0});var _wt=s(AJ);mLr=r(_wt,"FlaxT5Model"),_wt.forEach(t),gLr=r(_Be," (T5 model)"),_Be.forEach(t),hLr=i(ne),P5=n(ne,"LI",{});var uBe=s(P5);sMe=n(uBe,"STRONG",{});var uwt=s(sMe);pLr=r(uwt,"vision-text-dual-encoder"),uwt.forEach(t),_Lr=r(uBe," \u2014 "),yJ=n(uBe,"A",{href:!0});var bwt=s(yJ);uLr=r(bwt,"FlaxVisionTextDualEncoderModel"),bwt.forEach(t),bLr=r(uBe," (VisionTextDualEncoder model)"),uBe.forEach(t),vLr=i(ne),B5=n(ne,"LI",{});var bBe=s(B5);lMe=n(bBe,"STRONG",{});var vwt=s(lMe);FLr=r(vwt,"vit"),vwt.forEach(t),TLr=r(bBe," \u2014 "),LJ=n(bBe,"A",{href:!0});var Fwt=s(LJ);MLr=r(Fwt,"FlaxViTModel"),Fwt.forEach(t),ELr=r(bBe," (ViT model)"),bBe.forEach(t),CLr=i(ne),I5=n(ne,"LI",{});var vBe=s(I5);iMe=n(vBe,"STRONG",{});var Twt=s(iMe);wLr=r(Twt,"wav2vec2"),Twt.forEach(t),ALr=r(vBe," \u2014 "),xJ=n(vBe,"A",{href:!0});var Mwt=s(xJ);yLr=r(Mwt,"FlaxWav2Vec2Model"),Mwt.forEach(t),LLr=r(vBe," (Wav2Vec2 model)"),vBe.forEach(t),xLr=i(ne),q5=n(ne,"LI",{});var FBe=s(q5);dMe=n(FBe,"STRONG",{});var Ewt=s(dMe);$Lr=r(Ewt,"xglm"),Ewt.forEach(t),kLr=r(FBe," \u2014 "),$J=n(FBe,"A",{href:!0});var Cwt=s($J);SLr=r(Cwt,"FlaxXGLMModel"),Cwt.forEach(t),RLr=r(FBe," (XGLM model)"),FBe.forEach(t),PLr=i(ne),N5=n(ne,"LI",{});var TBe=s(N5);cMe=n(TBe,"STRONG",{});var wwt=s(cMe);BLr=r(wwt,"xlm-roberta"),wwt.forEach(t),ILr=r(TBe," \u2014 "),kJ=n(TBe,"A",{href:!0});var Awt=s(kJ);qLr=r(Awt,"FlaxXLMRobertaModel"),Awt.forEach(t),NLr=r(TBe," (XLM-RoBERTa model)"),TBe.forEach(t),ne.forEach(t),jLr=i(Gl),T(j5.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),$Ne=i(f),kc=n(f,"H2",{class:!0});var qDe=s(kc);D5=n(qDe,"A",{id:!0,class:!0,href:!0});var ywt=s(D5);fMe=n(ywt,"SPAN",{});var Lwt=s(fMe);T(_x.$$.fragment,Lwt),Lwt.forEach(t),ywt.forEach(t),DLr=i(qDe),mMe=n(qDe,"SPAN",{});var xwt=s(mMe);GLr=r(xwt,"FlaxAutoModelForCausalLM"),xwt.forEach(t),qDe.forEach(t),kNe=i(f),mr=n(f,"DIV",{class:!0});var Ol=s(mr);T(ux.$$.fragment,Ol),OLr=i(Ol),Sc=n(Ol,"P",{});var iee=s(Sc);VLr=r(iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),SJ=n(iee,"A",{href:!0});var $wt=s(SJ);XLr=r($wt,"from_pretrained()"),$wt.forEach(t),zLr=r(iee," class method or the "),RJ=n(iee,"A",{href:!0});var kwt=s(RJ);WLr=r(kwt,"from_config()"),kwt.forEach(t),QLr=r(iee,` class
method.`),iee.forEach(t),HLr=i(Ol),bx=n(Ol,"P",{});var NDe=s(bx);ULr=r(NDe,"This class cannot be instantiated directly using "),gMe=n(NDe,"CODE",{});var Swt=s(gMe);JLr=r(Swt,"__init__()"),Swt.forEach(t),YLr=r(NDe," (throws an error)."),NDe.forEach(t),KLr=i(Ol),Ot=n(Ol,"DIV",{class:!0});var GA=s(Ot);T(vx.$$.fragment,GA),ZLr=i(GA),hMe=n(GA,"P",{});var Rwt=s(hMe);e8r=r(Rwt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Rwt.forEach(t),o8r=i(GA),Rc=n(GA,"P",{});var dee=s(Rc);r8r=r(dee,`Note:
Loading a model from its configuration file does `),pMe=n(dee,"STRONG",{});var Pwt=s(pMe);t8r=r(Pwt,"not"),Pwt.forEach(t),a8r=r(dee,` load the model weights. It only affects the
model\u2019s configuration. Use `),PJ=n(dee,"A",{href:!0});var Bwt=s(PJ);n8r=r(Bwt,"from_pretrained()"),Bwt.forEach(t),s8r=r(dee," to load the model weights."),dee.forEach(t),l8r=i(GA),T(G5.$$.fragment,GA),GA.forEach(t),i8r=i(Ol),Dr=n(Ol,"DIV",{class:!0});var Vl=s(Dr);T(Fx.$$.fragment,Vl),d8r=i(Vl),_Me=n(Vl,"P",{});var Iwt=s(_Me);c8r=r(Iwt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Iwt.forEach(t),f8r=i(Vl),pn=n(Vl,"P",{});var OA=s(pn);m8r=r(OA,"The model class to instantiate is selected based on the "),uMe=n(OA,"CODE",{});var qwt=s(uMe);g8r=r(qwt,"model_type"),qwt.forEach(t),h8r=r(OA,` property of the config object (either
passed as an argument or loaded from `),bMe=n(OA,"CODE",{});var Nwt=s(bMe);p8r=r(Nwt,"pretrained_model_name_or_path"),Nwt.forEach(t),_8r=r(OA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vMe=n(OA,"CODE",{});var jwt=s(vMe);u8r=r(jwt,"pretrained_model_name_or_path"),jwt.forEach(t),b8r=r(OA,":"),OA.forEach(t),v8r=i(Vl),Le=n(Vl,"UL",{});var Ie=s(Le);O5=n(Ie,"LI",{});var MBe=s(O5);FMe=n(MBe,"STRONG",{});var Dwt=s(FMe);F8r=r(Dwt,"bart"),Dwt.forEach(t),T8r=r(MBe," \u2014 "),BJ=n(MBe,"A",{href:!0});var Gwt=s(BJ);M8r=r(Gwt,"FlaxBartForCausalLM"),Gwt.forEach(t),E8r=r(MBe," (BART model)"),MBe.forEach(t),C8r=i(Ie),V5=n(Ie,"LI",{});var EBe=s(V5);TMe=n(EBe,"STRONG",{});var Owt=s(TMe);w8r=r(Owt,"bert"),Owt.forEach(t),A8r=r(EBe," \u2014 "),IJ=n(EBe,"A",{href:!0});var Vwt=s(IJ);y8r=r(Vwt,"FlaxBertForCausalLM"),Vwt.forEach(t),L8r=r(EBe," (BERT model)"),EBe.forEach(t),x8r=i(Ie),X5=n(Ie,"LI",{});var CBe=s(X5);MMe=n(CBe,"STRONG",{});var Xwt=s(MMe);$8r=r(Xwt,"big_bird"),Xwt.forEach(t),k8r=r(CBe," \u2014 "),qJ=n(CBe,"A",{href:!0});var zwt=s(qJ);S8r=r(zwt,"FlaxBigBirdForCausalLM"),zwt.forEach(t),R8r=r(CBe," (BigBird model)"),CBe.forEach(t),P8r=i(Ie),z5=n(Ie,"LI",{});var wBe=s(z5);EMe=n(wBe,"STRONG",{});var Wwt=s(EMe);B8r=r(Wwt,"electra"),Wwt.forEach(t),I8r=r(wBe," \u2014 "),NJ=n(wBe,"A",{href:!0});var Qwt=s(NJ);q8r=r(Qwt,"FlaxElectraForCausalLM"),Qwt.forEach(t),N8r=r(wBe," (ELECTRA model)"),wBe.forEach(t),j8r=i(Ie),W5=n(Ie,"LI",{});var ABe=s(W5);CMe=n(ABe,"STRONG",{});var Hwt=s(CMe);D8r=r(Hwt,"gpt2"),Hwt.forEach(t),G8r=r(ABe," \u2014 "),jJ=n(ABe,"A",{href:!0});var Uwt=s(jJ);O8r=r(Uwt,"FlaxGPT2LMHeadModel"),Uwt.forEach(t),V8r=r(ABe," (OpenAI GPT-2 model)"),ABe.forEach(t),X8r=i(Ie),Q5=n(Ie,"LI",{});var yBe=s(Q5);wMe=n(yBe,"STRONG",{});var Jwt=s(wMe);z8r=r(Jwt,"gpt_neo"),Jwt.forEach(t),W8r=r(yBe," \u2014 "),DJ=n(yBe,"A",{href:!0});var Ywt=s(DJ);Q8r=r(Ywt,"FlaxGPTNeoForCausalLM"),Ywt.forEach(t),H8r=r(yBe," (GPT Neo model)"),yBe.forEach(t),U8r=i(Ie),H5=n(Ie,"LI",{});var LBe=s(H5);AMe=n(LBe,"STRONG",{});var Kwt=s(AMe);J8r=r(Kwt,"gptj"),Kwt.forEach(t),Y8r=r(LBe," \u2014 "),GJ=n(LBe,"A",{href:!0});var Zwt=s(GJ);K8r=r(Zwt,"FlaxGPTJForCausalLM"),Zwt.forEach(t),Z8r=r(LBe," (GPT-J model)"),LBe.forEach(t),exr=i(Ie),U5=n(Ie,"LI",{});var xBe=s(U5);yMe=n(xBe,"STRONG",{});var e0t=s(yMe);oxr=r(e0t,"opt"),e0t.forEach(t),rxr=r(xBe," \u2014 "),OJ=n(xBe,"A",{href:!0});var o0t=s(OJ);txr=r(o0t,"FlaxOPTForCausalLM"),o0t.forEach(t),axr=r(xBe," (OPT model)"),xBe.forEach(t),nxr=i(Ie),J5=n(Ie,"LI",{});var $Be=s(J5);LMe=n($Be,"STRONG",{});var r0t=s(LMe);sxr=r(r0t,"roberta"),r0t.forEach(t),lxr=r($Be," \u2014 "),VJ=n($Be,"A",{href:!0});var t0t=s(VJ);ixr=r(t0t,"FlaxRobertaForCausalLM"),t0t.forEach(t),dxr=r($Be," (RoBERTa model)"),$Be.forEach(t),cxr=i(Ie),Y5=n(Ie,"LI",{});var kBe=s(Y5);xMe=n(kBe,"STRONG",{});var a0t=s(xMe);fxr=r(a0t,"xglm"),a0t.forEach(t),mxr=r(kBe," \u2014 "),XJ=n(kBe,"A",{href:!0});var n0t=s(XJ);gxr=r(n0t,"FlaxXGLMForCausalLM"),n0t.forEach(t),hxr=r(kBe," (XGLM model)"),kBe.forEach(t),Ie.forEach(t),pxr=i(Vl),T(K5.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),SNe=i(f),Pc=n(f,"H2",{class:!0});var jDe=s(Pc);Z5=n(jDe,"A",{id:!0,class:!0,href:!0});var s0t=s(Z5);$Me=n(s0t,"SPAN",{});var l0t=s($Me);T(Tx.$$.fragment,l0t),l0t.forEach(t),s0t.forEach(t),_xr=i(jDe),kMe=n(jDe,"SPAN",{});var i0t=s(kMe);uxr=r(i0t,"FlaxAutoModelForPreTraining"),i0t.forEach(t),jDe.forEach(t),RNe=i(f),gr=n(f,"DIV",{class:!0});var Xl=s(gr);T(Mx.$$.fragment,Xl),bxr=i(Xl),Bc=n(Xl,"P",{});var cee=s(Bc);vxr=r(cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),zJ=n(cee,"A",{href:!0});var d0t=s(zJ);Fxr=r(d0t,"from_pretrained()"),d0t.forEach(t),Txr=r(cee," class method or the "),WJ=n(cee,"A",{href:!0});var c0t=s(WJ);Mxr=r(c0t,"from_config()"),c0t.forEach(t),Exr=r(cee,` class
method.`),cee.forEach(t),Cxr=i(Xl),Ex=n(Xl,"P",{});var DDe=s(Ex);wxr=r(DDe,"This class cannot be instantiated directly using "),SMe=n(DDe,"CODE",{});var f0t=s(SMe);Axr=r(f0t,"__init__()"),f0t.forEach(t),yxr=r(DDe," (throws an error)."),DDe.forEach(t),Lxr=i(Xl),Vt=n(Xl,"DIV",{class:!0});var VA=s(Vt);T(Cx.$$.fragment,VA),xxr=i(VA),RMe=n(VA,"P",{});var m0t=s(RMe);$xr=r(m0t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),m0t.forEach(t),kxr=i(VA),Ic=n(VA,"P",{});var fee=s(Ic);Sxr=r(fee,`Note:
Loading a model from its configuration file does `),PMe=n(fee,"STRONG",{});var g0t=s(PMe);Rxr=r(g0t,"not"),g0t.forEach(t),Pxr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(fee,"A",{href:!0});var h0t=s(QJ);Bxr=r(h0t,"from_pretrained()"),h0t.forEach(t),Ixr=r(fee," to load the model weights."),fee.forEach(t),qxr=i(VA),T(e3.$$.fragment,VA),VA.forEach(t),Nxr=i(Xl),Gr=n(Xl,"DIV",{class:!0});var zl=s(Gr);T(wx.$$.fragment,zl),jxr=i(zl),BMe=n(zl,"P",{});var p0t=s(BMe);Dxr=r(p0t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),p0t.forEach(t),Gxr=i(zl),_n=n(zl,"P",{});var XA=s(_n);Oxr=r(XA,"The model class to instantiate is selected based on the "),IMe=n(XA,"CODE",{});var _0t=s(IMe);Vxr=r(_0t,"model_type"),_0t.forEach(t),Xxr=r(XA,` property of the config object (either
passed as an argument or loaded from `),qMe=n(XA,"CODE",{});var u0t=s(qMe);zxr=r(u0t,"pretrained_model_name_or_path"),u0t.forEach(t),Wxr=r(XA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NMe=n(XA,"CODE",{});var b0t=s(NMe);Qxr=r(b0t,"pretrained_model_name_or_path"),b0t.forEach(t),Hxr=r(XA,":"),XA.forEach(t),Uxr=i(zl),Me=n(zl,"UL",{});var we=s(Me);o3=n(we,"LI",{});var SBe=s(o3);jMe=n(SBe,"STRONG",{});var v0t=s(jMe);Jxr=r(v0t,"albert"),v0t.forEach(t),Yxr=r(SBe," \u2014 "),HJ=n(SBe,"A",{href:!0});var F0t=s(HJ);Kxr=r(F0t,"FlaxAlbertForPreTraining"),F0t.forEach(t),Zxr=r(SBe," (ALBERT model)"),SBe.forEach(t),e9r=i(we),r3=n(we,"LI",{});var RBe=s(r3);DMe=n(RBe,"STRONG",{});var T0t=s(DMe);o9r=r(T0t,"bart"),T0t.forEach(t),r9r=r(RBe," \u2014 "),UJ=n(RBe,"A",{href:!0});var M0t=s(UJ);t9r=r(M0t,"FlaxBartForConditionalGeneration"),M0t.forEach(t),a9r=r(RBe," (BART model)"),RBe.forEach(t),n9r=i(we),t3=n(we,"LI",{});var PBe=s(t3);GMe=n(PBe,"STRONG",{});var E0t=s(GMe);s9r=r(E0t,"bert"),E0t.forEach(t),l9r=r(PBe," \u2014 "),JJ=n(PBe,"A",{href:!0});var C0t=s(JJ);i9r=r(C0t,"FlaxBertForPreTraining"),C0t.forEach(t),d9r=r(PBe," (BERT model)"),PBe.forEach(t),c9r=i(we),a3=n(we,"LI",{});var BBe=s(a3);OMe=n(BBe,"STRONG",{});var w0t=s(OMe);f9r=r(w0t,"big_bird"),w0t.forEach(t),m9r=r(BBe," \u2014 "),YJ=n(BBe,"A",{href:!0});var A0t=s(YJ);g9r=r(A0t,"FlaxBigBirdForPreTraining"),A0t.forEach(t),h9r=r(BBe," (BigBird model)"),BBe.forEach(t),p9r=i(we),n3=n(we,"LI",{});var IBe=s(n3);VMe=n(IBe,"STRONG",{});var y0t=s(VMe);_9r=r(y0t,"electra"),y0t.forEach(t),u9r=r(IBe," \u2014 "),KJ=n(IBe,"A",{href:!0});var L0t=s(KJ);b9r=r(L0t,"FlaxElectraForPreTraining"),L0t.forEach(t),v9r=r(IBe," (ELECTRA model)"),IBe.forEach(t),F9r=i(we),s3=n(we,"LI",{});var qBe=s(s3);XMe=n(qBe,"STRONG",{});var x0t=s(XMe);T9r=r(x0t,"mbart"),x0t.forEach(t),M9r=r(qBe," \u2014 "),ZJ=n(qBe,"A",{href:!0});var $0t=s(ZJ);E9r=r($0t,"FlaxMBartForConditionalGeneration"),$0t.forEach(t),C9r=r(qBe," (mBART model)"),qBe.forEach(t),w9r=i(we),l3=n(we,"LI",{});var NBe=s(l3);zMe=n(NBe,"STRONG",{});var k0t=s(zMe);A9r=r(k0t,"mt5"),k0t.forEach(t),y9r=r(NBe," \u2014 "),eY=n(NBe,"A",{href:!0});var S0t=s(eY);L9r=r(S0t,"FlaxMT5ForConditionalGeneration"),S0t.forEach(t),x9r=r(NBe," (mT5 model)"),NBe.forEach(t),$9r=i(we),i3=n(we,"LI",{});var jBe=s(i3);WMe=n(jBe,"STRONG",{});var R0t=s(WMe);k9r=r(R0t,"roberta"),R0t.forEach(t),S9r=r(jBe," \u2014 "),oY=n(jBe,"A",{href:!0});var P0t=s(oY);R9r=r(P0t,"FlaxRobertaForMaskedLM"),P0t.forEach(t),P9r=r(jBe," (RoBERTa model)"),jBe.forEach(t),B9r=i(we),d3=n(we,"LI",{});var DBe=s(d3);QMe=n(DBe,"STRONG",{});var B0t=s(QMe);I9r=r(B0t,"roformer"),B0t.forEach(t),q9r=r(DBe," \u2014 "),rY=n(DBe,"A",{href:!0});var I0t=s(rY);N9r=r(I0t,"FlaxRoFormerForMaskedLM"),I0t.forEach(t),j9r=r(DBe," (RoFormer model)"),DBe.forEach(t),D9r=i(we),c3=n(we,"LI",{});var GBe=s(c3);HMe=n(GBe,"STRONG",{});var q0t=s(HMe);G9r=r(q0t,"t5"),q0t.forEach(t),O9r=r(GBe," \u2014 "),tY=n(GBe,"A",{href:!0});var N0t=s(tY);V9r=r(N0t,"FlaxT5ForConditionalGeneration"),N0t.forEach(t),X9r=r(GBe," (T5 model)"),GBe.forEach(t),z9r=i(we),f3=n(we,"LI",{});var OBe=s(f3);UMe=n(OBe,"STRONG",{});var j0t=s(UMe);W9r=r(j0t,"wav2vec2"),j0t.forEach(t),Q9r=r(OBe," \u2014 "),aY=n(OBe,"A",{href:!0});var D0t=s(aY);H9r=r(D0t,"FlaxWav2Vec2ForPreTraining"),D0t.forEach(t),U9r=r(OBe," (Wav2Vec2 model)"),OBe.forEach(t),J9r=i(we),m3=n(we,"LI",{});var VBe=s(m3);JMe=n(VBe,"STRONG",{});var G0t=s(JMe);Y9r=r(G0t,"xlm-roberta"),G0t.forEach(t),K9r=r(VBe," \u2014 "),nY=n(VBe,"A",{href:!0});var O0t=s(nY);Z9r=r(O0t,"FlaxXLMRobertaForMaskedLM"),O0t.forEach(t),e$r=r(VBe," (XLM-RoBERTa model)"),VBe.forEach(t),we.forEach(t),o$r=i(zl),T(g3.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),PNe=i(f),qc=n(f,"H2",{class:!0});var GDe=s(qc);h3=n(GDe,"A",{id:!0,class:!0,href:!0});var V0t=s(h3);YMe=n(V0t,"SPAN",{});var X0t=s(YMe);T(Ax.$$.fragment,X0t),X0t.forEach(t),V0t.forEach(t),r$r=i(GDe),KMe=n(GDe,"SPAN",{});var z0t=s(KMe);t$r=r(z0t,"FlaxAutoModelForMaskedLM"),z0t.forEach(t),GDe.forEach(t),BNe=i(f),hr=n(f,"DIV",{class:!0});var Wl=s(hr);T(yx.$$.fragment,Wl),a$r=i(Wl),Nc=n(Wl,"P",{});var mee=s(Nc);n$r=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),sY=n(mee,"A",{href:!0});var W0t=s(sY);s$r=r(W0t,"from_pretrained()"),W0t.forEach(t),l$r=r(mee," class method or the "),lY=n(mee,"A",{href:!0});var Q0t=s(lY);i$r=r(Q0t,"from_config()"),Q0t.forEach(t),d$r=r(mee,` class
method.`),mee.forEach(t),c$r=i(Wl),Lx=n(Wl,"P",{});var ODe=s(Lx);f$r=r(ODe,"This class cannot be instantiated directly using "),ZMe=n(ODe,"CODE",{});var H0t=s(ZMe);m$r=r(H0t,"__init__()"),H0t.forEach(t),g$r=r(ODe," (throws an error)."),ODe.forEach(t),h$r=i(Wl),Xt=n(Wl,"DIV",{class:!0});var zA=s(Xt);T(xx.$$.fragment,zA),p$r=i(zA),e4e=n(zA,"P",{});var U0t=s(e4e);_$r=r(U0t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),U0t.forEach(t),u$r=i(zA),jc=n(zA,"P",{});var gee=s(jc);b$r=r(gee,`Note:
Loading a model from its configuration file does `),o4e=n(gee,"STRONG",{});var J0t=s(o4e);v$r=r(J0t,"not"),J0t.forEach(t),F$r=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=n(gee,"A",{href:!0});var Y0t=s(iY);T$r=r(Y0t,"from_pretrained()"),Y0t.forEach(t),M$r=r(gee," to load the model weights."),gee.forEach(t),E$r=i(zA),T(p3.$$.fragment,zA),zA.forEach(t),C$r=i(Wl),Or=n(Wl,"DIV",{class:!0});var Ql=s(Or);T($x.$$.fragment,Ql),w$r=i(Ql),r4e=n(Ql,"P",{});var K0t=s(r4e);A$r=r(K0t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),K0t.forEach(t),y$r=i(Ql),un=n(Ql,"P",{});var WA=s(un);L$r=r(WA,"The model class to instantiate is selected based on the "),t4e=n(WA,"CODE",{});var Z0t=s(t4e);x$r=r(Z0t,"model_type"),Z0t.forEach(t),$$r=r(WA,` property of the config object (either
passed as an argument or loaded from `),a4e=n(WA,"CODE",{});var eAt=s(a4e);k$r=r(eAt,"pretrained_model_name_or_path"),eAt.forEach(t),S$r=r(WA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n4e=n(WA,"CODE",{});var oAt=s(n4e);R$r=r(oAt,"pretrained_model_name_or_path"),oAt.forEach(t),P$r=r(WA,":"),WA.forEach(t),B$r=i(Ql),xe=n(Ql,"UL",{});var qe=s(xe);_3=n(qe,"LI",{});var XBe=s(_3);s4e=n(XBe,"STRONG",{});var rAt=s(s4e);I$r=r(rAt,"albert"),rAt.forEach(t),q$r=r(XBe," \u2014 "),dY=n(XBe,"A",{href:!0});var tAt=s(dY);N$r=r(tAt,"FlaxAlbertForMaskedLM"),tAt.forEach(t),j$r=r(XBe," (ALBERT model)"),XBe.forEach(t),D$r=i(qe),u3=n(qe,"LI",{});var zBe=s(u3);l4e=n(zBe,"STRONG",{});var aAt=s(l4e);G$r=r(aAt,"bart"),aAt.forEach(t),O$r=r(zBe," \u2014 "),cY=n(zBe,"A",{href:!0});var nAt=s(cY);V$r=r(nAt,"FlaxBartForConditionalGeneration"),nAt.forEach(t),X$r=r(zBe," (BART model)"),zBe.forEach(t),z$r=i(qe),b3=n(qe,"LI",{});var WBe=s(b3);i4e=n(WBe,"STRONG",{});var sAt=s(i4e);W$r=r(sAt,"bert"),sAt.forEach(t),Q$r=r(WBe," \u2014 "),fY=n(WBe,"A",{href:!0});var lAt=s(fY);H$r=r(lAt,"FlaxBertForMaskedLM"),lAt.forEach(t),U$r=r(WBe," (BERT model)"),WBe.forEach(t),J$r=i(qe),v3=n(qe,"LI",{});var QBe=s(v3);d4e=n(QBe,"STRONG",{});var iAt=s(d4e);Y$r=r(iAt,"big_bird"),iAt.forEach(t),K$r=r(QBe," \u2014 "),mY=n(QBe,"A",{href:!0});var dAt=s(mY);Z$r=r(dAt,"FlaxBigBirdForMaskedLM"),dAt.forEach(t),ekr=r(QBe," (BigBird model)"),QBe.forEach(t),okr=i(qe),F3=n(qe,"LI",{});var HBe=s(F3);c4e=n(HBe,"STRONG",{});var cAt=s(c4e);rkr=r(cAt,"distilbert"),cAt.forEach(t),tkr=r(HBe," \u2014 "),gY=n(HBe,"A",{href:!0});var fAt=s(gY);akr=r(fAt,"FlaxDistilBertForMaskedLM"),fAt.forEach(t),nkr=r(HBe," (DistilBERT model)"),HBe.forEach(t),skr=i(qe),T3=n(qe,"LI",{});var UBe=s(T3);f4e=n(UBe,"STRONG",{});var mAt=s(f4e);lkr=r(mAt,"electra"),mAt.forEach(t),ikr=r(UBe," \u2014 "),hY=n(UBe,"A",{href:!0});var gAt=s(hY);dkr=r(gAt,"FlaxElectraForMaskedLM"),gAt.forEach(t),ckr=r(UBe," (ELECTRA model)"),UBe.forEach(t),fkr=i(qe),M3=n(qe,"LI",{});var JBe=s(M3);m4e=n(JBe,"STRONG",{});var hAt=s(m4e);mkr=r(hAt,"mbart"),hAt.forEach(t),gkr=r(JBe," \u2014 "),pY=n(JBe,"A",{href:!0});var pAt=s(pY);hkr=r(pAt,"FlaxMBartForConditionalGeneration"),pAt.forEach(t),pkr=r(JBe," (mBART model)"),JBe.forEach(t),_kr=i(qe),E3=n(qe,"LI",{});var YBe=s(E3);g4e=n(YBe,"STRONG",{});var _At=s(g4e);ukr=r(_At,"roberta"),_At.forEach(t),bkr=r(YBe," \u2014 "),_Y=n(YBe,"A",{href:!0});var uAt=s(_Y);vkr=r(uAt,"FlaxRobertaForMaskedLM"),uAt.forEach(t),Fkr=r(YBe," (RoBERTa model)"),YBe.forEach(t),Tkr=i(qe),C3=n(qe,"LI",{});var KBe=s(C3);h4e=n(KBe,"STRONG",{});var bAt=s(h4e);Mkr=r(bAt,"roformer"),bAt.forEach(t),Ekr=r(KBe," \u2014 "),uY=n(KBe,"A",{href:!0});var vAt=s(uY);Ckr=r(vAt,"FlaxRoFormerForMaskedLM"),vAt.forEach(t),wkr=r(KBe," (RoFormer model)"),KBe.forEach(t),Akr=i(qe),w3=n(qe,"LI",{});var ZBe=s(w3);p4e=n(ZBe,"STRONG",{});var FAt=s(p4e);ykr=r(FAt,"xlm-roberta"),FAt.forEach(t),Lkr=r(ZBe," \u2014 "),bY=n(ZBe,"A",{href:!0});var TAt=s(bY);xkr=r(TAt,"FlaxXLMRobertaForMaskedLM"),TAt.forEach(t),$kr=r(ZBe," (XLM-RoBERTa model)"),ZBe.forEach(t),qe.forEach(t),kkr=i(Ql),T(A3.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),INe=i(f),Dc=n(f,"H2",{class:!0});var VDe=s(Dc);y3=n(VDe,"A",{id:!0,class:!0,href:!0});var MAt=s(y3);_4e=n(MAt,"SPAN",{});var EAt=s(_4e);T(kx.$$.fragment,EAt),EAt.forEach(t),MAt.forEach(t),Skr=i(VDe),u4e=n(VDe,"SPAN",{});var CAt=s(u4e);Rkr=r(CAt,"FlaxAutoModelForSeq2SeqLM"),CAt.forEach(t),VDe.forEach(t),qNe=i(f),pr=n(f,"DIV",{class:!0});var Hl=s(pr);T(Sx.$$.fragment,Hl),Pkr=i(Hl),Gc=n(Hl,"P",{});var hee=s(Gc);Bkr=r(hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),vY=n(hee,"A",{href:!0});var wAt=s(vY);Ikr=r(wAt,"from_pretrained()"),wAt.forEach(t),qkr=r(hee," class method or the "),FY=n(hee,"A",{href:!0});var AAt=s(FY);Nkr=r(AAt,"from_config()"),AAt.forEach(t),jkr=r(hee,` class
method.`),hee.forEach(t),Dkr=i(Hl),Rx=n(Hl,"P",{});var XDe=s(Rx);Gkr=r(XDe,"This class cannot be instantiated directly using "),b4e=n(XDe,"CODE",{});var yAt=s(b4e);Okr=r(yAt,"__init__()"),yAt.forEach(t),Vkr=r(XDe," (throws an error)."),XDe.forEach(t),Xkr=i(Hl),zt=n(Hl,"DIV",{class:!0});var QA=s(zt);T(Px.$$.fragment,QA),zkr=i(QA),v4e=n(QA,"P",{});var LAt=s(v4e);Wkr=r(LAt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),LAt.forEach(t),Qkr=i(QA),Oc=n(QA,"P",{});var pee=s(Oc);Hkr=r(pee,`Note:
Loading a model from its configuration file does `),F4e=n(pee,"STRONG",{});var xAt=s(F4e);Ukr=r(xAt,"not"),xAt.forEach(t),Jkr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),TY=n(pee,"A",{href:!0});var $At=s(TY);Ykr=r($At,"from_pretrained()"),$At.forEach(t),Kkr=r(pee," to load the model weights."),pee.forEach(t),Zkr=i(QA),T(L3.$$.fragment,QA),QA.forEach(t),eSr=i(Hl),Vr=n(Hl,"DIV",{class:!0});var Ul=s(Vr);T(Bx.$$.fragment,Ul),oSr=i(Ul),T4e=n(Ul,"P",{});var kAt=s(T4e);rSr=r(kAt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kAt.forEach(t),tSr=i(Ul),bn=n(Ul,"P",{});var HA=s(bn);aSr=r(HA,"The model class to instantiate is selected based on the "),M4e=n(HA,"CODE",{});var SAt=s(M4e);nSr=r(SAt,"model_type"),SAt.forEach(t),sSr=r(HA,` property of the config object (either
passed as an argument or loaded from `),E4e=n(HA,"CODE",{});var RAt=s(E4e);lSr=r(RAt,"pretrained_model_name_or_path"),RAt.forEach(t),iSr=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C4e=n(HA,"CODE",{});var PAt=s(C4e);dSr=r(PAt,"pretrained_model_name_or_path"),PAt.forEach(t),cSr=r(HA,":"),HA.forEach(t),fSr=i(Ul),Pe=n(Ul,"UL",{});var ze=s(Pe);x3=n(ze,"LI",{});var eIe=s(x3);w4e=n(eIe,"STRONG",{});var BAt=s(w4e);mSr=r(BAt,"bart"),BAt.forEach(t),gSr=r(eIe," \u2014 "),MY=n(eIe,"A",{href:!0});var IAt=s(MY);hSr=r(IAt,"FlaxBartForConditionalGeneration"),IAt.forEach(t),pSr=r(eIe," (BART model)"),eIe.forEach(t),_Sr=i(ze),$3=n(ze,"LI",{});var oIe=s($3);A4e=n(oIe,"STRONG",{});var qAt=s(A4e);uSr=r(qAt,"blenderbot"),qAt.forEach(t),bSr=r(oIe," \u2014 "),EY=n(oIe,"A",{href:!0});var NAt=s(EY);vSr=r(NAt,"FlaxBlenderbotForConditionalGeneration"),NAt.forEach(t),FSr=r(oIe," (Blenderbot model)"),oIe.forEach(t),TSr=i(ze),k3=n(ze,"LI",{});var rIe=s(k3);y4e=n(rIe,"STRONG",{});var jAt=s(y4e);MSr=r(jAt,"blenderbot-small"),jAt.forEach(t),ESr=r(rIe," \u2014 "),CY=n(rIe,"A",{href:!0});var DAt=s(CY);CSr=r(DAt,"FlaxBlenderbotSmallForConditionalGeneration"),DAt.forEach(t),wSr=r(rIe," (BlenderbotSmall model)"),rIe.forEach(t),ASr=i(ze),S3=n(ze,"LI",{});var tIe=s(S3);L4e=n(tIe,"STRONG",{});var GAt=s(L4e);ySr=r(GAt,"encoder-decoder"),GAt.forEach(t),LSr=r(tIe," \u2014 "),wY=n(tIe,"A",{href:!0});var OAt=s(wY);xSr=r(OAt,"FlaxEncoderDecoderModel"),OAt.forEach(t),$Sr=r(tIe," (Encoder decoder model)"),tIe.forEach(t),kSr=i(ze),R3=n(ze,"LI",{});var aIe=s(R3);x4e=n(aIe,"STRONG",{});var VAt=s(x4e);SSr=r(VAt,"marian"),VAt.forEach(t),RSr=r(aIe," \u2014 "),AY=n(aIe,"A",{href:!0});var XAt=s(AY);PSr=r(XAt,"FlaxMarianMTModel"),XAt.forEach(t),BSr=r(aIe," (Marian model)"),aIe.forEach(t),ISr=i(ze),P3=n(ze,"LI",{});var nIe=s(P3);$4e=n(nIe,"STRONG",{});var zAt=s($4e);qSr=r(zAt,"mbart"),zAt.forEach(t),NSr=r(nIe," \u2014 "),yY=n(nIe,"A",{href:!0});var WAt=s(yY);jSr=r(WAt,"FlaxMBartForConditionalGeneration"),WAt.forEach(t),DSr=r(nIe," (mBART model)"),nIe.forEach(t),GSr=i(ze),B3=n(ze,"LI",{});var sIe=s(B3);k4e=n(sIe,"STRONG",{});var QAt=s(k4e);OSr=r(QAt,"mt5"),QAt.forEach(t),VSr=r(sIe," \u2014 "),LY=n(sIe,"A",{href:!0});var HAt=s(LY);XSr=r(HAt,"FlaxMT5ForConditionalGeneration"),HAt.forEach(t),zSr=r(sIe," (mT5 model)"),sIe.forEach(t),WSr=i(ze),I3=n(ze,"LI",{});var lIe=s(I3);S4e=n(lIe,"STRONG",{});var UAt=s(S4e);QSr=r(UAt,"pegasus"),UAt.forEach(t),HSr=r(lIe," \u2014 "),xY=n(lIe,"A",{href:!0});var JAt=s(xY);USr=r(JAt,"FlaxPegasusForConditionalGeneration"),JAt.forEach(t),JSr=r(lIe," (Pegasus model)"),lIe.forEach(t),YSr=i(ze),q3=n(ze,"LI",{});var iIe=s(q3);R4e=n(iIe,"STRONG",{});var YAt=s(R4e);KSr=r(YAt,"t5"),YAt.forEach(t),ZSr=r(iIe," \u2014 "),$Y=n(iIe,"A",{href:!0});var KAt=s($Y);eRr=r(KAt,"FlaxT5ForConditionalGeneration"),KAt.forEach(t),oRr=r(iIe," (T5 model)"),iIe.forEach(t),ze.forEach(t),rRr=i(Ul),T(N3.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),NNe=i(f),Vc=n(f,"H2",{class:!0});var zDe=s(Vc);j3=n(zDe,"A",{id:!0,class:!0,href:!0});var ZAt=s(j3);P4e=n(ZAt,"SPAN",{});var e6t=s(P4e);T(Ix.$$.fragment,e6t),e6t.forEach(t),ZAt.forEach(t),tRr=i(zDe),B4e=n(zDe,"SPAN",{});var o6t=s(B4e);aRr=r(o6t,"FlaxAutoModelForSequenceClassification"),o6t.forEach(t),zDe.forEach(t),jNe=i(f),_r=n(f,"DIV",{class:!0});var Jl=s(_r);T(qx.$$.fragment,Jl),nRr=i(Jl),Xc=n(Jl,"P",{});var _ee=s(Xc);sRr=r(_ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),kY=n(_ee,"A",{href:!0});var r6t=s(kY);lRr=r(r6t,"from_pretrained()"),r6t.forEach(t),iRr=r(_ee," class method or the "),SY=n(_ee,"A",{href:!0});var t6t=s(SY);dRr=r(t6t,"from_config()"),t6t.forEach(t),cRr=r(_ee,` class
method.`),_ee.forEach(t),fRr=i(Jl),Nx=n(Jl,"P",{});var WDe=s(Nx);mRr=r(WDe,"This class cannot be instantiated directly using "),I4e=n(WDe,"CODE",{});var a6t=s(I4e);gRr=r(a6t,"__init__()"),a6t.forEach(t),hRr=r(WDe," (throws an error)."),WDe.forEach(t),pRr=i(Jl),Wt=n(Jl,"DIV",{class:!0});var UA=s(Wt);T(jx.$$.fragment,UA),_Rr=i(UA),q4e=n(UA,"P",{});var n6t=s(q4e);uRr=r(n6t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),n6t.forEach(t),bRr=i(UA),zc=n(UA,"P",{});var uee=s(zc);vRr=r(uee,`Note:
Loading a model from its configuration file does `),N4e=n(uee,"STRONG",{});var s6t=s(N4e);FRr=r(s6t,"not"),s6t.forEach(t),TRr=r(uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=n(uee,"A",{href:!0});var l6t=s(RY);MRr=r(l6t,"from_pretrained()"),l6t.forEach(t),ERr=r(uee," to load the model weights."),uee.forEach(t),CRr=i(UA),T(D3.$$.fragment,UA),UA.forEach(t),wRr=i(Jl),Xr=n(Jl,"DIV",{class:!0});var Yl=s(Xr);T(Dx.$$.fragment,Yl),ARr=i(Yl),j4e=n(Yl,"P",{});var i6t=s(j4e);yRr=r(i6t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),i6t.forEach(t),LRr=i(Yl),vn=n(Yl,"P",{});var JA=s(vn);xRr=r(JA,"The model class to instantiate is selected based on the "),D4e=n(JA,"CODE",{});var d6t=s(D4e);$Rr=r(d6t,"model_type"),d6t.forEach(t),kRr=r(JA,` property of the config object (either
passed as an argument or loaded from `),G4e=n(JA,"CODE",{});var c6t=s(G4e);SRr=r(c6t,"pretrained_model_name_or_path"),c6t.forEach(t),RRr=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O4e=n(JA,"CODE",{});var f6t=s(O4e);PRr=r(f6t,"pretrained_model_name_or_path"),f6t.forEach(t),BRr=r(JA,":"),JA.forEach(t),IRr=i(Yl),$e=n(Yl,"UL",{});var Ne=s($e);G3=n(Ne,"LI",{});var dIe=s(G3);V4e=n(dIe,"STRONG",{});var m6t=s(V4e);qRr=r(m6t,"albert"),m6t.forEach(t),NRr=r(dIe," \u2014 "),PY=n(dIe,"A",{href:!0});var g6t=s(PY);jRr=r(g6t,"FlaxAlbertForSequenceClassification"),g6t.forEach(t),DRr=r(dIe," (ALBERT model)"),dIe.forEach(t),GRr=i(Ne),O3=n(Ne,"LI",{});var cIe=s(O3);X4e=n(cIe,"STRONG",{});var h6t=s(X4e);ORr=r(h6t,"bart"),h6t.forEach(t),VRr=r(cIe," \u2014 "),BY=n(cIe,"A",{href:!0});var p6t=s(BY);XRr=r(p6t,"FlaxBartForSequenceClassification"),p6t.forEach(t),zRr=r(cIe," (BART model)"),cIe.forEach(t),WRr=i(Ne),V3=n(Ne,"LI",{});var fIe=s(V3);z4e=n(fIe,"STRONG",{});var _6t=s(z4e);QRr=r(_6t,"bert"),_6t.forEach(t),HRr=r(fIe," \u2014 "),IY=n(fIe,"A",{href:!0});var u6t=s(IY);URr=r(u6t,"FlaxBertForSequenceClassification"),u6t.forEach(t),JRr=r(fIe," (BERT model)"),fIe.forEach(t),YRr=i(Ne),X3=n(Ne,"LI",{});var mIe=s(X3);W4e=n(mIe,"STRONG",{});var b6t=s(W4e);KRr=r(b6t,"big_bird"),b6t.forEach(t),ZRr=r(mIe," \u2014 "),qY=n(mIe,"A",{href:!0});var v6t=s(qY);ePr=r(v6t,"FlaxBigBirdForSequenceClassification"),v6t.forEach(t),oPr=r(mIe," (BigBird model)"),mIe.forEach(t),rPr=i(Ne),z3=n(Ne,"LI",{});var gIe=s(z3);Q4e=n(gIe,"STRONG",{});var F6t=s(Q4e);tPr=r(F6t,"distilbert"),F6t.forEach(t),aPr=r(gIe," \u2014 "),NY=n(gIe,"A",{href:!0});var T6t=s(NY);nPr=r(T6t,"FlaxDistilBertForSequenceClassification"),T6t.forEach(t),sPr=r(gIe," (DistilBERT model)"),gIe.forEach(t),lPr=i(Ne),W3=n(Ne,"LI",{});var hIe=s(W3);H4e=n(hIe,"STRONG",{});var M6t=s(H4e);iPr=r(M6t,"electra"),M6t.forEach(t),dPr=r(hIe," \u2014 "),jY=n(hIe,"A",{href:!0});var E6t=s(jY);cPr=r(E6t,"FlaxElectraForSequenceClassification"),E6t.forEach(t),fPr=r(hIe," (ELECTRA model)"),hIe.forEach(t),mPr=i(Ne),Q3=n(Ne,"LI",{});var pIe=s(Q3);U4e=n(pIe,"STRONG",{});var C6t=s(U4e);gPr=r(C6t,"mbart"),C6t.forEach(t),hPr=r(pIe," \u2014 "),DY=n(pIe,"A",{href:!0});var w6t=s(DY);pPr=r(w6t,"FlaxMBartForSequenceClassification"),w6t.forEach(t),_Pr=r(pIe," (mBART model)"),pIe.forEach(t),uPr=i(Ne),H3=n(Ne,"LI",{});var _Ie=s(H3);J4e=n(_Ie,"STRONG",{});var A6t=s(J4e);bPr=r(A6t,"roberta"),A6t.forEach(t),vPr=r(_Ie," \u2014 "),GY=n(_Ie,"A",{href:!0});var y6t=s(GY);FPr=r(y6t,"FlaxRobertaForSequenceClassification"),y6t.forEach(t),TPr=r(_Ie," (RoBERTa model)"),_Ie.forEach(t),MPr=i(Ne),U3=n(Ne,"LI",{});var uIe=s(U3);Y4e=n(uIe,"STRONG",{});var L6t=s(Y4e);EPr=r(L6t,"roformer"),L6t.forEach(t),CPr=r(uIe," \u2014 "),OY=n(uIe,"A",{href:!0});var x6t=s(OY);wPr=r(x6t,"FlaxRoFormerForSequenceClassification"),x6t.forEach(t),APr=r(uIe," (RoFormer model)"),uIe.forEach(t),yPr=i(Ne),J3=n(Ne,"LI",{});var bIe=s(J3);K4e=n(bIe,"STRONG",{});var $6t=s(K4e);LPr=r($6t,"xlm-roberta"),$6t.forEach(t),xPr=r(bIe," \u2014 "),VY=n(bIe,"A",{href:!0});var k6t=s(VY);$Pr=r(k6t,"FlaxXLMRobertaForSequenceClassification"),k6t.forEach(t),kPr=r(bIe," (XLM-RoBERTa model)"),bIe.forEach(t),Ne.forEach(t),SPr=i(Yl),T(Y3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),DNe=i(f),Wc=n(f,"H2",{class:!0});var QDe=s(Wc);K3=n(QDe,"A",{id:!0,class:!0,href:!0});var S6t=s(K3);Z4e=n(S6t,"SPAN",{});var R6t=s(Z4e);T(Gx.$$.fragment,R6t),R6t.forEach(t),S6t.forEach(t),RPr=i(QDe),eEe=n(QDe,"SPAN",{});var P6t=s(eEe);PPr=r(P6t,"FlaxAutoModelForQuestionAnswering"),P6t.forEach(t),QDe.forEach(t),GNe=i(f),ur=n(f,"DIV",{class:!0});var Kl=s(ur);T(Ox.$$.fragment,Kl),BPr=i(Kl),Qc=n(Kl,"P",{});var bee=s(Qc);IPr=r(bee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),XY=n(bee,"A",{href:!0});var B6t=s(XY);qPr=r(B6t,"from_pretrained()"),B6t.forEach(t),NPr=r(bee," class method or the "),zY=n(bee,"A",{href:!0});var I6t=s(zY);jPr=r(I6t,"from_config()"),I6t.forEach(t),DPr=r(bee,` class
method.`),bee.forEach(t),GPr=i(Kl),Vx=n(Kl,"P",{});var HDe=s(Vx);OPr=r(HDe,"This class cannot be instantiated directly using "),oEe=n(HDe,"CODE",{});var q6t=s(oEe);VPr=r(q6t,"__init__()"),q6t.forEach(t),XPr=r(HDe," (throws an error)."),HDe.forEach(t),zPr=i(Kl),Qt=n(Kl,"DIV",{class:!0});var YA=s(Qt);T(Xx.$$.fragment,YA),WPr=i(YA),rEe=n(YA,"P",{});var N6t=s(rEe);QPr=r(N6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),N6t.forEach(t),HPr=i(YA),Hc=n(YA,"P",{});var vee=s(Hc);UPr=r(vee,`Note:
Loading a model from its configuration file does `),tEe=n(vee,"STRONG",{});var j6t=s(tEe);JPr=r(j6t,"not"),j6t.forEach(t),YPr=r(vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),WY=n(vee,"A",{href:!0});var D6t=s(WY);KPr=r(D6t,"from_pretrained()"),D6t.forEach(t),ZPr=r(vee," to load the model weights."),vee.forEach(t),eBr=i(YA),T(Z3.$$.fragment,YA),YA.forEach(t),oBr=i(Kl),zr=n(Kl,"DIV",{class:!0});var Zl=s(zr);T(zx.$$.fragment,Zl),rBr=i(Zl),aEe=n(Zl,"P",{});var G6t=s(aEe);tBr=r(G6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G6t.forEach(t),aBr=i(Zl),Fn=n(Zl,"P",{});var KA=s(Fn);nBr=r(KA,"The model class to instantiate is selected based on the "),nEe=n(KA,"CODE",{});var O6t=s(nEe);sBr=r(O6t,"model_type"),O6t.forEach(t),lBr=r(KA,` property of the config object (either
passed as an argument or loaded from `),sEe=n(KA,"CODE",{});var V6t=s(sEe);iBr=r(V6t,"pretrained_model_name_or_path"),V6t.forEach(t),dBr=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lEe=n(KA,"CODE",{});var X6t=s(lEe);cBr=r(X6t,"pretrained_model_name_or_path"),X6t.forEach(t),fBr=r(KA,":"),KA.forEach(t),mBr=i(Zl),ke=n(Zl,"UL",{});var je=s(ke);ew=n(je,"LI",{});var vIe=s(ew);iEe=n(vIe,"STRONG",{});var z6t=s(iEe);gBr=r(z6t,"albert"),z6t.forEach(t),hBr=r(vIe," \u2014 "),QY=n(vIe,"A",{href:!0});var W6t=s(QY);pBr=r(W6t,"FlaxAlbertForQuestionAnswering"),W6t.forEach(t),_Br=r(vIe," (ALBERT model)"),vIe.forEach(t),uBr=i(je),ow=n(je,"LI",{});var FIe=s(ow);dEe=n(FIe,"STRONG",{});var Q6t=s(dEe);bBr=r(Q6t,"bart"),Q6t.forEach(t),vBr=r(FIe," \u2014 "),HY=n(FIe,"A",{href:!0});var H6t=s(HY);FBr=r(H6t,"FlaxBartForQuestionAnswering"),H6t.forEach(t),TBr=r(FIe," (BART model)"),FIe.forEach(t),MBr=i(je),rw=n(je,"LI",{});var TIe=s(rw);cEe=n(TIe,"STRONG",{});var U6t=s(cEe);EBr=r(U6t,"bert"),U6t.forEach(t),CBr=r(TIe," \u2014 "),UY=n(TIe,"A",{href:!0});var J6t=s(UY);wBr=r(J6t,"FlaxBertForQuestionAnswering"),J6t.forEach(t),ABr=r(TIe," (BERT model)"),TIe.forEach(t),yBr=i(je),tw=n(je,"LI",{});var MIe=s(tw);fEe=n(MIe,"STRONG",{});var Y6t=s(fEe);LBr=r(Y6t,"big_bird"),Y6t.forEach(t),xBr=r(MIe," \u2014 "),JY=n(MIe,"A",{href:!0});var K6t=s(JY);$Br=r(K6t,"FlaxBigBirdForQuestionAnswering"),K6t.forEach(t),kBr=r(MIe," (BigBird model)"),MIe.forEach(t),SBr=i(je),aw=n(je,"LI",{});var EIe=s(aw);mEe=n(EIe,"STRONG",{});var Z6t=s(mEe);RBr=r(Z6t,"distilbert"),Z6t.forEach(t),PBr=r(EIe," \u2014 "),YY=n(EIe,"A",{href:!0});var eyt=s(YY);BBr=r(eyt,"FlaxDistilBertForQuestionAnswering"),eyt.forEach(t),IBr=r(EIe," (DistilBERT model)"),EIe.forEach(t),qBr=i(je),nw=n(je,"LI",{});var CIe=s(nw);gEe=n(CIe,"STRONG",{});var oyt=s(gEe);NBr=r(oyt,"electra"),oyt.forEach(t),jBr=r(CIe," \u2014 "),KY=n(CIe,"A",{href:!0});var ryt=s(KY);DBr=r(ryt,"FlaxElectraForQuestionAnswering"),ryt.forEach(t),GBr=r(CIe," (ELECTRA model)"),CIe.forEach(t),OBr=i(je),sw=n(je,"LI",{});var wIe=s(sw);hEe=n(wIe,"STRONG",{});var tyt=s(hEe);VBr=r(tyt,"mbart"),tyt.forEach(t),XBr=r(wIe," \u2014 "),ZY=n(wIe,"A",{href:!0});var ayt=s(ZY);zBr=r(ayt,"FlaxMBartForQuestionAnswering"),ayt.forEach(t),WBr=r(wIe," (mBART model)"),wIe.forEach(t),QBr=i(je),lw=n(je,"LI",{});var AIe=s(lw);pEe=n(AIe,"STRONG",{});var nyt=s(pEe);HBr=r(nyt,"roberta"),nyt.forEach(t),UBr=r(AIe," \u2014 "),eK=n(AIe,"A",{href:!0});var syt=s(eK);JBr=r(syt,"FlaxRobertaForQuestionAnswering"),syt.forEach(t),YBr=r(AIe," (RoBERTa model)"),AIe.forEach(t),KBr=i(je),iw=n(je,"LI",{});var yIe=s(iw);_Ee=n(yIe,"STRONG",{});var lyt=s(_Ee);ZBr=r(lyt,"roformer"),lyt.forEach(t),eIr=r(yIe," \u2014 "),oK=n(yIe,"A",{href:!0});var iyt=s(oK);oIr=r(iyt,"FlaxRoFormerForQuestionAnswering"),iyt.forEach(t),rIr=r(yIe," (RoFormer model)"),yIe.forEach(t),tIr=i(je),dw=n(je,"LI",{});var LIe=s(dw);uEe=n(LIe,"STRONG",{});var dyt=s(uEe);aIr=r(dyt,"xlm-roberta"),dyt.forEach(t),nIr=r(LIe," \u2014 "),rK=n(LIe,"A",{href:!0});var cyt=s(rK);sIr=r(cyt,"FlaxXLMRobertaForQuestionAnswering"),cyt.forEach(t),lIr=r(LIe," (XLM-RoBERTa model)"),LIe.forEach(t),je.forEach(t),iIr=i(Zl),T(cw.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),ONe=i(f),Uc=n(f,"H2",{class:!0});var UDe=s(Uc);fw=n(UDe,"A",{id:!0,class:!0,href:!0});var fyt=s(fw);bEe=n(fyt,"SPAN",{});var myt=s(bEe);T(Wx.$$.fragment,myt),myt.forEach(t),fyt.forEach(t),dIr=i(UDe),vEe=n(UDe,"SPAN",{});var gyt=s(vEe);cIr=r(gyt,"FlaxAutoModelForTokenClassification"),gyt.forEach(t),UDe.forEach(t),VNe=i(f),br=n(f,"DIV",{class:!0});var ei=s(br);T(Qx.$$.fragment,ei),fIr=i(ei),Jc=n(ei,"P",{});var Fee=s(Jc);mIr=r(Fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),tK=n(Fee,"A",{href:!0});var hyt=s(tK);gIr=r(hyt,"from_pretrained()"),hyt.forEach(t),hIr=r(Fee," class method or the "),aK=n(Fee,"A",{href:!0});var pyt=s(aK);pIr=r(pyt,"from_config()"),pyt.forEach(t),_Ir=r(Fee,` class
method.`),Fee.forEach(t),uIr=i(ei),Hx=n(ei,"P",{});var JDe=s(Hx);bIr=r(JDe,"This class cannot be instantiated directly using "),FEe=n(JDe,"CODE",{});var _yt=s(FEe);vIr=r(_yt,"__init__()"),_yt.forEach(t),FIr=r(JDe," (throws an error)."),JDe.forEach(t),TIr=i(ei),Ht=n(ei,"DIV",{class:!0});var ZA=s(Ht);T(Ux.$$.fragment,ZA),MIr=i(ZA),TEe=n(ZA,"P",{});var uyt=s(TEe);EIr=r(uyt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),uyt.forEach(t),CIr=i(ZA),Yc=n(ZA,"P",{});var Tee=s(Yc);wIr=r(Tee,`Note:
Loading a model from its configuration file does `),MEe=n(Tee,"STRONG",{});var byt=s(MEe);AIr=r(byt,"not"),byt.forEach(t),yIr=r(Tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(Tee,"A",{href:!0});var vyt=s(nK);LIr=r(vyt,"from_pretrained()"),vyt.forEach(t),xIr=r(Tee," to load the model weights."),Tee.forEach(t),$Ir=i(ZA),T(mw.$$.fragment,ZA),ZA.forEach(t),kIr=i(ei),Wr=n(ei,"DIV",{class:!0});var oi=s(Wr);T(Jx.$$.fragment,oi),SIr=i(oi),EEe=n(oi,"P",{});var Fyt=s(EEe);RIr=r(Fyt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Fyt.forEach(t),PIr=i(oi),Tn=n(oi,"P",{});var e6=s(Tn);BIr=r(e6,"The model class to instantiate is selected based on the "),CEe=n(e6,"CODE",{});var Tyt=s(CEe);IIr=r(Tyt,"model_type"),Tyt.forEach(t),qIr=r(e6,` property of the config object (either
passed as an argument or loaded from `),wEe=n(e6,"CODE",{});var Myt=s(wEe);NIr=r(Myt,"pretrained_model_name_or_path"),Myt.forEach(t),jIr=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AEe=n(e6,"CODE",{});var Eyt=s(AEe);DIr=r(Eyt,"pretrained_model_name_or_path"),Eyt.forEach(t),GIr=r(e6,":"),e6.forEach(t),OIr=i(oi),Ge=n(oi,"UL",{});var Fo=s(Ge);gw=n(Fo,"LI",{});var xIe=s(gw);yEe=n(xIe,"STRONG",{});var Cyt=s(yEe);VIr=r(Cyt,"albert"),Cyt.forEach(t),XIr=r(xIe," \u2014 "),sK=n(xIe,"A",{href:!0});var wyt=s(sK);zIr=r(wyt,"FlaxAlbertForTokenClassification"),wyt.forEach(t),WIr=r(xIe," (ALBERT model)"),xIe.forEach(t),QIr=i(Fo),hw=n(Fo,"LI",{});var $Ie=s(hw);LEe=n($Ie,"STRONG",{});var Ayt=s(LEe);HIr=r(Ayt,"bert"),Ayt.forEach(t),UIr=r($Ie," \u2014 "),lK=n($Ie,"A",{href:!0});var yyt=s(lK);JIr=r(yyt,"FlaxBertForTokenClassification"),yyt.forEach(t),YIr=r($Ie," (BERT model)"),$Ie.forEach(t),KIr=i(Fo),pw=n(Fo,"LI",{});var kIe=s(pw);xEe=n(kIe,"STRONG",{});var Lyt=s(xEe);ZIr=r(Lyt,"big_bird"),Lyt.forEach(t),eqr=r(kIe," \u2014 "),iK=n(kIe,"A",{href:!0});var xyt=s(iK);oqr=r(xyt,"FlaxBigBirdForTokenClassification"),xyt.forEach(t),rqr=r(kIe," (BigBird model)"),kIe.forEach(t),tqr=i(Fo),_w=n(Fo,"LI",{});var SIe=s(_w);$Ee=n(SIe,"STRONG",{});var $yt=s($Ee);aqr=r($yt,"distilbert"),$yt.forEach(t),nqr=r(SIe," \u2014 "),dK=n(SIe,"A",{href:!0});var kyt=s(dK);sqr=r(kyt,"FlaxDistilBertForTokenClassification"),kyt.forEach(t),lqr=r(SIe," (DistilBERT model)"),SIe.forEach(t),iqr=i(Fo),uw=n(Fo,"LI",{});var RIe=s(uw);kEe=n(RIe,"STRONG",{});var Syt=s(kEe);dqr=r(Syt,"electra"),Syt.forEach(t),cqr=r(RIe," \u2014 "),cK=n(RIe,"A",{href:!0});var Ryt=s(cK);fqr=r(Ryt,"FlaxElectraForTokenClassification"),Ryt.forEach(t),mqr=r(RIe," (ELECTRA model)"),RIe.forEach(t),gqr=i(Fo),bw=n(Fo,"LI",{});var PIe=s(bw);SEe=n(PIe,"STRONG",{});var Pyt=s(SEe);hqr=r(Pyt,"roberta"),Pyt.forEach(t),pqr=r(PIe," \u2014 "),fK=n(PIe,"A",{href:!0});var Byt=s(fK);_qr=r(Byt,"FlaxRobertaForTokenClassification"),Byt.forEach(t),uqr=r(PIe," (RoBERTa model)"),PIe.forEach(t),bqr=i(Fo),vw=n(Fo,"LI",{});var BIe=s(vw);REe=n(BIe,"STRONG",{});var Iyt=s(REe);vqr=r(Iyt,"roformer"),Iyt.forEach(t),Fqr=r(BIe," \u2014 "),mK=n(BIe,"A",{href:!0});var qyt=s(mK);Tqr=r(qyt,"FlaxRoFormerForTokenClassification"),qyt.forEach(t),Mqr=r(BIe," (RoFormer model)"),BIe.forEach(t),Eqr=i(Fo),Fw=n(Fo,"LI",{});var IIe=s(Fw);PEe=n(IIe,"STRONG",{});var Nyt=s(PEe);Cqr=r(Nyt,"xlm-roberta"),Nyt.forEach(t),wqr=r(IIe," \u2014 "),gK=n(IIe,"A",{href:!0});var jyt=s(gK);Aqr=r(jyt,"FlaxXLMRobertaForTokenClassification"),jyt.forEach(t),yqr=r(IIe," (XLM-RoBERTa model)"),IIe.forEach(t),Fo.forEach(t),Lqr=i(oi),T(Tw.$$.fragment,oi),oi.forEach(t),ei.forEach(t),XNe=i(f),Kc=n(f,"H2",{class:!0});var YDe=s(Kc);Mw=n(YDe,"A",{id:!0,class:!0,href:!0});var Dyt=s(Mw);BEe=n(Dyt,"SPAN",{});var Gyt=s(BEe);T(Yx.$$.fragment,Gyt),Gyt.forEach(t),Dyt.forEach(t),xqr=i(YDe),IEe=n(YDe,"SPAN",{});var Oyt=s(IEe);$qr=r(Oyt,"FlaxAutoModelForMultipleChoice"),Oyt.forEach(t),YDe.forEach(t),zNe=i(f),vr=n(f,"DIV",{class:!0});var ri=s(vr);T(Kx.$$.fragment,ri),kqr=i(ri),Zc=n(ri,"P",{});var Mee=s(Zc);Sqr=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),hK=n(Mee,"A",{href:!0});var Vyt=s(hK);Rqr=r(Vyt,"from_pretrained()"),Vyt.forEach(t),Pqr=r(Mee," class method or the "),pK=n(Mee,"A",{href:!0});var Xyt=s(pK);Bqr=r(Xyt,"from_config()"),Xyt.forEach(t),Iqr=r(Mee,` class
method.`),Mee.forEach(t),qqr=i(ri),Zx=n(ri,"P",{});var KDe=s(Zx);Nqr=r(KDe,"This class cannot be instantiated directly using "),qEe=n(KDe,"CODE",{});var zyt=s(qEe);jqr=r(zyt,"__init__()"),zyt.forEach(t),Dqr=r(KDe," (throws an error)."),KDe.forEach(t),Gqr=i(ri),Ut=n(ri,"DIV",{class:!0});var o6=s(Ut);T(e9.$$.fragment,o6),Oqr=i(o6),NEe=n(o6,"P",{});var Wyt=s(NEe);Vqr=r(Wyt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Wyt.forEach(t),Xqr=i(o6),ef=n(o6,"P",{});var Eee=s(ef);zqr=r(Eee,`Note:
Loading a model from its configuration file does `),jEe=n(Eee,"STRONG",{});var Qyt=s(jEe);Wqr=r(Qyt,"not"),Qyt.forEach(t),Qqr=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=n(Eee,"A",{href:!0});var Hyt=s(_K);Hqr=r(Hyt,"from_pretrained()"),Hyt.forEach(t),Uqr=r(Eee," to load the model weights."),Eee.forEach(t),Jqr=i(o6),T(Ew.$$.fragment,o6),o6.forEach(t),Yqr=i(ri),Qr=n(ri,"DIV",{class:!0});var ti=s(Qr);T(o9.$$.fragment,ti),Kqr=i(ti),DEe=n(ti,"P",{});var Uyt=s(DEe);Zqr=r(Uyt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Uyt.forEach(t),eNr=i(ti),Mn=n(ti,"P",{});var r6=s(Mn);oNr=r(r6,"The model class to instantiate is selected based on the "),GEe=n(r6,"CODE",{});var Jyt=s(GEe);rNr=r(Jyt,"model_type"),Jyt.forEach(t),tNr=r(r6,` property of the config object (either
passed as an argument or loaded from `),OEe=n(r6,"CODE",{});var Yyt=s(OEe);aNr=r(Yyt,"pretrained_model_name_or_path"),Yyt.forEach(t),nNr=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VEe=n(r6,"CODE",{});var Kyt=s(VEe);sNr=r(Kyt,"pretrained_model_name_or_path"),Kyt.forEach(t),lNr=r(r6,":"),r6.forEach(t),iNr=i(ti),Oe=n(ti,"UL",{});var To=s(Oe);Cw=n(To,"LI",{});var qIe=s(Cw);XEe=n(qIe,"STRONG",{});var Zyt=s(XEe);dNr=r(Zyt,"albert"),Zyt.forEach(t),cNr=r(qIe," \u2014 "),uK=n(qIe,"A",{href:!0});var eLt=s(uK);fNr=r(eLt,"FlaxAlbertForMultipleChoice"),eLt.forEach(t),mNr=r(qIe," (ALBERT model)"),qIe.forEach(t),gNr=i(To),ww=n(To,"LI",{});var NIe=s(ww);zEe=n(NIe,"STRONG",{});var oLt=s(zEe);hNr=r(oLt,"bert"),oLt.forEach(t),pNr=r(NIe," \u2014 "),bK=n(NIe,"A",{href:!0});var rLt=s(bK);_Nr=r(rLt,"FlaxBertForMultipleChoice"),rLt.forEach(t),uNr=r(NIe," (BERT model)"),NIe.forEach(t),bNr=i(To),Aw=n(To,"LI",{});var jIe=s(Aw);WEe=n(jIe,"STRONG",{});var tLt=s(WEe);vNr=r(tLt,"big_bird"),tLt.forEach(t),FNr=r(jIe," \u2014 "),vK=n(jIe,"A",{href:!0});var aLt=s(vK);TNr=r(aLt,"FlaxBigBirdForMultipleChoice"),aLt.forEach(t),MNr=r(jIe," (BigBird model)"),jIe.forEach(t),ENr=i(To),yw=n(To,"LI",{});var DIe=s(yw);QEe=n(DIe,"STRONG",{});var nLt=s(QEe);CNr=r(nLt,"distilbert"),nLt.forEach(t),wNr=r(DIe," \u2014 "),FK=n(DIe,"A",{href:!0});var sLt=s(FK);ANr=r(sLt,"FlaxDistilBertForMultipleChoice"),sLt.forEach(t),yNr=r(DIe," (DistilBERT model)"),DIe.forEach(t),LNr=i(To),Lw=n(To,"LI",{});var GIe=s(Lw);HEe=n(GIe,"STRONG",{});var lLt=s(HEe);xNr=r(lLt,"electra"),lLt.forEach(t),$Nr=r(GIe," \u2014 "),TK=n(GIe,"A",{href:!0});var iLt=s(TK);kNr=r(iLt,"FlaxElectraForMultipleChoice"),iLt.forEach(t),SNr=r(GIe," (ELECTRA model)"),GIe.forEach(t),RNr=i(To),xw=n(To,"LI",{});var OIe=s(xw);UEe=n(OIe,"STRONG",{});var dLt=s(UEe);PNr=r(dLt,"roberta"),dLt.forEach(t),BNr=r(OIe," \u2014 "),MK=n(OIe,"A",{href:!0});var cLt=s(MK);INr=r(cLt,"FlaxRobertaForMultipleChoice"),cLt.forEach(t),qNr=r(OIe," (RoBERTa model)"),OIe.forEach(t),NNr=i(To),$w=n(To,"LI",{});var VIe=s($w);JEe=n(VIe,"STRONG",{});var fLt=s(JEe);jNr=r(fLt,"roformer"),fLt.forEach(t),DNr=r(VIe," \u2014 "),EK=n(VIe,"A",{href:!0});var mLt=s(EK);GNr=r(mLt,"FlaxRoFormerForMultipleChoice"),mLt.forEach(t),ONr=r(VIe," (RoFormer model)"),VIe.forEach(t),VNr=i(To),kw=n(To,"LI",{});var XIe=s(kw);YEe=n(XIe,"STRONG",{});var gLt=s(YEe);XNr=r(gLt,"xlm-roberta"),gLt.forEach(t),zNr=r(XIe," \u2014 "),CK=n(XIe,"A",{href:!0});var hLt=s(CK);WNr=r(hLt,"FlaxXLMRobertaForMultipleChoice"),hLt.forEach(t),QNr=r(XIe," (XLM-RoBERTa model)"),XIe.forEach(t),To.forEach(t),HNr=i(ti),T(Sw.$$.fragment,ti),ti.forEach(t),ri.forEach(t),WNe=i(f),of=n(f,"H2",{class:!0});var ZDe=s(of);Rw=n(ZDe,"A",{id:!0,class:!0,href:!0});var pLt=s(Rw);KEe=n(pLt,"SPAN",{});var _Lt=s(KEe);T(r9.$$.fragment,_Lt),_Lt.forEach(t),pLt.forEach(t),UNr=i(ZDe),ZEe=n(ZDe,"SPAN",{});var uLt=s(ZEe);JNr=r(uLt,"FlaxAutoModelForNextSentencePrediction"),uLt.forEach(t),ZDe.forEach(t),QNe=i(f),Fr=n(f,"DIV",{class:!0});var ai=s(Fr);T(t9.$$.fragment,ai),YNr=i(ai),rf=n(ai,"P",{});var Cee=s(rf);KNr=r(Cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wK=n(Cee,"A",{href:!0});var bLt=s(wK);ZNr=r(bLt,"from_pretrained()"),bLt.forEach(t),ejr=r(Cee," class method or the "),AK=n(Cee,"A",{href:!0});var vLt=s(AK);ojr=r(vLt,"from_config()"),vLt.forEach(t),rjr=r(Cee,` class
method.`),Cee.forEach(t),tjr=i(ai),a9=n(ai,"P",{});var eGe=s(a9);ajr=r(eGe,"This class cannot be instantiated directly using "),eCe=n(eGe,"CODE",{});var FLt=s(eCe);njr=r(FLt,"__init__()"),FLt.forEach(t),sjr=r(eGe," (throws an error)."),eGe.forEach(t),ljr=i(ai),Jt=n(ai,"DIV",{class:!0});var t6=s(Jt);T(n9.$$.fragment,t6),ijr=i(t6),oCe=n(t6,"P",{});var TLt=s(oCe);djr=r(TLt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),TLt.forEach(t),cjr=i(t6),tf=n(t6,"P",{});var wee=s(tf);fjr=r(wee,`Note:
Loading a model from its configuration file does `),rCe=n(wee,"STRONG",{});var MLt=s(rCe);mjr=r(MLt,"not"),MLt.forEach(t),gjr=r(wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(wee,"A",{href:!0});var ELt=s(yK);hjr=r(ELt,"from_pretrained()"),ELt.forEach(t),pjr=r(wee," to load the model weights."),wee.forEach(t),_jr=i(t6),T(Pw.$$.fragment,t6),t6.forEach(t),ujr=i(ai),Hr=n(ai,"DIV",{class:!0});var ni=s(Hr);T(s9.$$.fragment,ni),bjr=i(ni),tCe=n(ni,"P",{});var CLt=s(tCe);vjr=r(CLt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),CLt.forEach(t),Fjr=i(ni),En=n(ni,"P",{});var a6=s(En);Tjr=r(a6,"The model class to instantiate is selected based on the "),aCe=n(a6,"CODE",{});var wLt=s(aCe);Mjr=r(wLt,"model_type"),wLt.forEach(t),Ejr=r(a6,` property of the config object (either
passed as an argument or loaded from `),nCe=n(a6,"CODE",{});var ALt=s(nCe);Cjr=r(ALt,"pretrained_model_name_or_path"),ALt.forEach(t),wjr=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sCe=n(a6,"CODE",{});var yLt=s(sCe);Ajr=r(yLt,"pretrained_model_name_or_path"),yLt.forEach(t),yjr=r(a6,":"),a6.forEach(t),Ljr=i(ni),lCe=n(ni,"UL",{});var LLt=s(lCe);Bw=n(LLt,"LI",{});var zIe=s(Bw);iCe=n(zIe,"STRONG",{});var xLt=s(iCe);xjr=r(xLt,"bert"),xLt.forEach(t),$jr=r(zIe," \u2014 "),LK=n(zIe,"A",{href:!0});var $Lt=s(LK);kjr=r($Lt,"FlaxBertForNextSentencePrediction"),$Lt.forEach(t),Sjr=r(zIe," (BERT model)"),zIe.forEach(t),LLt.forEach(t),Rjr=i(ni),T(Iw.$$.fragment,ni),ni.forEach(t),ai.forEach(t),HNe=i(f),af=n(f,"H2",{class:!0});var oGe=s(af);qw=n(oGe,"A",{id:!0,class:!0,href:!0});var kLt=s(qw);dCe=n(kLt,"SPAN",{});var SLt=s(dCe);T(l9.$$.fragment,SLt),SLt.forEach(t),kLt.forEach(t),Pjr=i(oGe),cCe=n(oGe,"SPAN",{});var RLt=s(cCe);Bjr=r(RLt,"FlaxAutoModelForImageClassification"),RLt.forEach(t),oGe.forEach(t),UNe=i(f),Tr=n(f,"DIV",{class:!0});var si=s(Tr);T(i9.$$.fragment,si),Ijr=i(si),nf=n(si,"P",{});var Aee=s(nf);qjr=r(Aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),xK=n(Aee,"A",{href:!0});var PLt=s(xK);Njr=r(PLt,"from_pretrained()"),PLt.forEach(t),jjr=r(Aee," class method or the "),$K=n(Aee,"A",{href:!0});var BLt=s($K);Djr=r(BLt,"from_config()"),BLt.forEach(t),Gjr=r(Aee,` class
method.`),Aee.forEach(t),Ojr=i(si),d9=n(si,"P",{});var rGe=s(d9);Vjr=r(rGe,"This class cannot be instantiated directly using "),fCe=n(rGe,"CODE",{});var ILt=s(fCe);Xjr=r(ILt,"__init__()"),ILt.forEach(t),zjr=r(rGe," (throws an error)."),rGe.forEach(t),Wjr=i(si),Yt=n(si,"DIV",{class:!0});var n6=s(Yt);T(c9.$$.fragment,n6),Qjr=i(n6),mCe=n(n6,"P",{});var qLt=s(mCe);Hjr=r(qLt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qLt.forEach(t),Ujr=i(n6),sf=n(n6,"P",{});var yee=s(sf);Jjr=r(yee,`Note:
Loading a model from its configuration file does `),gCe=n(yee,"STRONG",{});var NLt=s(gCe);Yjr=r(NLt,"not"),NLt.forEach(t),Kjr=r(yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(yee,"A",{href:!0});var jLt=s(kK);Zjr=r(jLt,"from_pretrained()"),jLt.forEach(t),eDr=r(yee," to load the model weights."),yee.forEach(t),oDr=i(n6),T(Nw.$$.fragment,n6),n6.forEach(t),rDr=i(si),Ur=n(si,"DIV",{class:!0});var li=s(Ur);T(f9.$$.fragment,li),tDr=i(li),hCe=n(li,"P",{});var DLt=s(hCe);aDr=r(DLt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),DLt.forEach(t),nDr=i(li),Cn=n(li,"P",{});var s6=s(Cn);sDr=r(s6,"The model class to instantiate is selected based on the "),pCe=n(s6,"CODE",{});var GLt=s(pCe);lDr=r(GLt,"model_type"),GLt.forEach(t),iDr=r(s6,` property of the config object (either
passed as an argument or loaded from `),_Ce=n(s6,"CODE",{});var OLt=s(_Ce);dDr=r(OLt,"pretrained_model_name_or_path"),OLt.forEach(t),cDr=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=n(s6,"CODE",{});var VLt=s(uCe);fDr=r(VLt,"pretrained_model_name_or_path"),VLt.forEach(t),mDr=r(s6,":"),s6.forEach(t),gDr=i(li),m9=n(li,"UL",{});var tGe=s(m9);jw=n(tGe,"LI",{});var WIe=s(jw);bCe=n(WIe,"STRONG",{});var XLt=s(bCe);hDr=r(XLt,"beit"),XLt.forEach(t),pDr=r(WIe," \u2014 "),SK=n(WIe,"A",{href:!0});var zLt=s(SK);_Dr=r(zLt,"FlaxBeitForImageClassification"),zLt.forEach(t),uDr=r(WIe," (BEiT model)"),WIe.forEach(t),bDr=i(tGe),Dw=n(tGe,"LI",{});var QIe=s(Dw);vCe=n(QIe,"STRONG",{});var WLt=s(vCe);vDr=r(WLt,"vit"),WLt.forEach(t),FDr=r(QIe," \u2014 "),RK=n(QIe,"A",{href:!0});var QLt=s(RK);TDr=r(QLt,"FlaxViTForImageClassification"),QLt.forEach(t),MDr=r(QIe," (ViT model)"),QIe.forEach(t),tGe.forEach(t),EDr=i(li),T(Gw.$$.fragment,li),li.forEach(t),si.forEach(t),JNe=i(f),lf=n(f,"H2",{class:!0});var aGe=s(lf);Ow=n(aGe,"A",{id:!0,class:!0,href:!0});var HLt=s(Ow);FCe=n(HLt,"SPAN",{});var ULt=s(FCe);T(g9.$$.fragment,ULt),ULt.forEach(t),HLt.forEach(t),CDr=i(aGe),TCe=n(aGe,"SPAN",{});var JLt=s(TCe);wDr=r(JLt,"FlaxAutoModelForVision2Seq"),JLt.forEach(t),aGe.forEach(t),YNe=i(f),Mr=n(f,"DIV",{class:!0});var ii=s(Mr);T(h9.$$.fragment,ii),ADr=i(ii),df=n(ii,"P",{});var Lee=s(df);yDr=r(Lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),PK=n(Lee,"A",{href:!0});var YLt=s(PK);LDr=r(YLt,"from_pretrained()"),YLt.forEach(t),xDr=r(Lee," class method or the "),BK=n(Lee,"A",{href:!0});var KLt=s(BK);$Dr=r(KLt,"from_config()"),KLt.forEach(t),kDr=r(Lee,` class
method.`),Lee.forEach(t),SDr=i(ii),p9=n(ii,"P",{});var nGe=s(p9);RDr=r(nGe,"This class cannot be instantiated directly using "),MCe=n(nGe,"CODE",{});var ZLt=s(MCe);PDr=r(ZLt,"__init__()"),ZLt.forEach(t),BDr=r(nGe," (throws an error)."),nGe.forEach(t),IDr=i(ii),Kt=n(ii,"DIV",{class:!0});var l6=s(Kt);T(_9.$$.fragment,l6),qDr=i(l6),ECe=n(l6,"P",{});var e8t=s(ECe);NDr=r(e8t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),e8t.forEach(t),jDr=i(l6),cf=n(l6,"P",{});var xee=s(cf);DDr=r(xee,`Note:
Loading a model from its configuration file does `),CCe=n(xee,"STRONG",{});var o8t=s(CCe);GDr=r(o8t,"not"),o8t.forEach(t),ODr=r(xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(xee,"A",{href:!0});var r8t=s(IK);VDr=r(r8t,"from_pretrained()"),r8t.forEach(t),XDr=r(xee," to load the model weights."),xee.forEach(t),zDr=i(l6),T(Vw.$$.fragment,l6),l6.forEach(t),WDr=i(ii),Jr=n(ii,"DIV",{class:!0});var di=s(Jr);T(u9.$$.fragment,di),QDr=i(di),wCe=n(di,"P",{});var t8t=s(wCe);HDr=r(t8t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),t8t.forEach(t),UDr=i(di),wn=n(di,"P",{});var i6=s(wn);JDr=r(i6,"The model class to instantiate is selected based on the "),ACe=n(i6,"CODE",{});var a8t=s(ACe);YDr=r(a8t,"model_type"),a8t.forEach(t),KDr=r(i6,` property of the config object (either
passed as an argument or loaded from `),yCe=n(i6,"CODE",{});var n8t=s(yCe);ZDr=r(n8t,"pretrained_model_name_or_path"),n8t.forEach(t),eGr=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=n(i6,"CODE",{});var s8t=s(LCe);oGr=r(s8t,"pretrained_model_name_or_path"),s8t.forEach(t),rGr=r(i6,":"),i6.forEach(t),tGr=i(di),xCe=n(di,"UL",{});var l8t=s(xCe);Xw=n(l8t,"LI",{});var HIe=s(Xw);$Ce=n(HIe,"STRONG",{});var i8t=s($Ce);aGr=r(i8t,"vision-encoder-decoder"),i8t.forEach(t),nGr=r(HIe," \u2014 "),qK=n(HIe,"A",{href:!0});var d8t=s(qK);sGr=r(d8t,"FlaxVisionEncoderDecoderModel"),d8t.forEach(t),lGr=r(HIe," (Vision Encoder decoder model)"),HIe.forEach(t),l8t.forEach(t),iGr=i(di),T(zw.$$.fragment,di),di.forEach(t),ii.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(g9t)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoTokenizer"),c(_i,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertModel"),c(bf,"id","extending-the-auto-classes"),c(bf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bf,"href","#extending-the-auto-classes"),c(ui,"class","relative group"),c(Ff,"id","transformers.AutoConfig"),c(Ff,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ff,"href","#transformers.AutoConfig"),c(bi,"class","relative group"),c(I$,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(q$,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertConfig"),c(N$,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartConfig"),c(j$,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitConfig"),c(D$,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertConfig"),c(G$,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(O$,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdConfig"),c(V$,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(X$,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(z$,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(W$,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertConfig"),c(Q$,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineConfig"),c(H$,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPConfig"),c(U$,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertConfig"),c(J$,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextConfig"),c(Y$,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLConfig"),c(K$,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(Z$,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(ek,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(ok,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaConfig"),c(rk,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(tk,"href","/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(ak,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTConfig"),c(nk,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrConfig"),c(sk,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertConfig"),c(lk,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRConfig"),c(ik,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTConfig"),c(dk,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraConfig"),c(ck,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(fk,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertConfig"),c(mk,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaConfig"),c(gk,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetConfig"),c(hk,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTConfig"),c(pk,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelConfig"),c(_k,"href","/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNConfig"),c(uk,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Config"),c(bk,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(vk,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJConfig"),c(Fk,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertConfig"),c(Tk,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertConfig"),c(Mk,"href","/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Ek,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Ck,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(wk,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDConfig"),c(Ak,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerConfig"),c(yk,"href","/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeConfig"),c(Lk,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertConfig"),c(xk,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Config"),c($k,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianConfig"),c(kk,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(Sk,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartConfig"),c(Rk,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(Pk,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(Bk,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetConfig"),c(Ik,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Config"),c(qk,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(Nk,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(jk,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTConfig"),c(Dk,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusConfig"),c(Gk,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverConfig"),c(Ok,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartConfig"),c(Vk,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(Xk,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(zk,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(Wk,"href","/docs/transformers/pr_17227/en/model_doc/rag#transformers.RagConfig"),c(Qk,"href","/docs/transformers/pr_17227/en/model_doc/realm#transformers.RealmConfig"),c(Hk,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerConfig"),c(Uk,"href","/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetConfig"),c(Jk,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertConfig"),c(Yk,"href","/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetConfig"),c(Kk,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertConfig"),c(Zk,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaConfig"),c(eS,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerConfig"),c(oS,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerConfig"),c(rS,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWConfig"),c(tS,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDConfig"),c(aS,"href","/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(nS,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(sS,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(lS,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterConfig"),c(iS,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(dS,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinConfig"),c(cS,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Config"),c(fS,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasConfig"),c(mS,"href","/docs/transformers/pr_17227/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(gS,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(hS,"href","/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRConfig"),c(pS,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(_S,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(uS,"href","/docs/transformers/pr_17227/en/model_doc/van#transformers.VanConfig"),c(bS,"href","/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltConfig"),c(vS,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(FS,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(TS,"href","/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(MS,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTConfig"),c(ES,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(CS,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(wS,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(AS,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMConfig"),c(yS,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMConfig"),c(LS,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMConfig"),c(xS,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c($S,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(kS,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(SS,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetConfig"),c(RS,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosConfig"),c(PS,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tg,"id","transformers.AutoTokenizer"),c(Tg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Tg,"href","#transformers.AutoTokenizer"),c(Fi,"class","relative group"),c(BS,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(IS,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizer"),c(qS,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(NS,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartTokenizer"),c(jS,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartTokenizerFast"),c(DS,"href","/docs/transformers/pr_17227/en/model_doc/barthez#transformers.BarthezTokenizer"),c(GS,"href","/docs/transformers/pr_17227/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(OS,"href","/docs/transformers/pr_17227/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(VS,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(XS,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(zS,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(WS,"href","/docs/transformers/pr_17227/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(QS,"href","/docs/transformers/pr_17227/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(HS,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(US,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(JS,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(YS,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(KS,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(ZS,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(eR,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(oR,"href","/docs/transformers/pr_17227/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(rR,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertTokenizer"),c(tR,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(aR,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineTokenizer"),c(nR,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPTokenizer"),c(sR,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(lR,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(iR,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(dR,"href","/docs/transformers/pr_17227/en/model_doc/cpm#transformers.CpmTokenizer"),c(cR,"href","/docs/transformers/pr_17227/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(fR,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(mR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(gR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(hR,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaTokenizer"),c(pR,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(_R,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(uR,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(bR,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(vR,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(FR,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(TR,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(MR,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraTokenizer"),c(ER,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(CR,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(wR,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetTokenizer"),c(AR,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(yR,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(LR,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelTokenizer"),c(xR,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c($R,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(kR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(SR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(RR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(PR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(BR,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(IR,"href","/docs/transformers/pr_17227/en/model_doc/herbert#transformers.HerbertTokenizer"),c(qR,"href","/docs/transformers/pr_17227/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(NR,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(jR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(DR,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(GR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(OR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(VR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(XR,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(zR,"href","/docs/transformers/pr_17227/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(WR,"href","/docs/transformers/pr_17227/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(QR,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDTokenizer"),c(HR,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDTokenizerFast"),c(UR,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerTokenizer"),c(JR,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(YR,"href","/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeTokenizer"),c(KR,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(ZR,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(eP,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(oP,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianTokenizer"),c(rP,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartTokenizer"),c(tP,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(aP,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(nP,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(sP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(lP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(iP,"href","/docs/transformers/pr_17227/en/model_doc/mluke#transformers.MLukeTokenizer"),c(dP,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(cP,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(fP,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(mP,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(gP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5Tokenizer"),c(hP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5TokenizerFast"),c(pP,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizer"),c(_P,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(uP,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(bP,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(vP,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(FP,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(TP,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(MP,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(EP,"href","/docs/transformers/pr_17227/en/model_doc/phobert#transformers.PhobertTokenizer"),c(CP,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartTokenizer"),c(wP,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(AP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(yP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(LP,"href","/docs/transformers/pr_17227/en/model_doc/rag#transformers.RagTokenizer"),c(xP,"href","/docs/transformers/pr_17227/en/model_doc/realm#transformers.RealmTokenizer"),c($P,"href","/docs/transformers/pr_17227/en/model_doc/realm#transformers.RealmTokenizerFast"),c(kP,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerTokenizer"),c(SP,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(RP,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertTokenizer"),c(PP,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(BP,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(IP,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(qP,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(NP,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(jP,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(DP,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(GP,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(OP,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(VP,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterTokenizer"),c(XP,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(zP,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(WP,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(QP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5Tokenizer"),c(HP,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.T5TokenizerFast"),c(UP,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasTokenizer"),c(JP,"href","/docs/transformers/pr_17227/en/model_doc/tapex#transformers.TapexTokenizer"),c(YP,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(KP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizer"),c(ZP,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertTokenizerFast"),c(eB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(oB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(rB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(tB,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMTokenizer"),c(aB,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(nB,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMTokenizer"),c(sB,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(lB,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(iB,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(dB,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizer"),c(cB,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(fB,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(mB,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(gB,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizer"),c(hB,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oh,"id","transformers.AutoFeatureExtractor"),c(oh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oh,"href","#transformers.AutoFeatureExtractor"),c(Ti,"class","relative group"),c(pB,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(_B,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(uB,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(bB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(vB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(FB,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(TB,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(MB,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(EB,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(CB,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(wB,"href","/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(AB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(yB,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(LB,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(xB,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c($B,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(kB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(RB,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(PB,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(BB,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(IB,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(qB,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(NB,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(jB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(DB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(GB,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kh,"id","transformers.AutoProcessor"),c(kh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kh,"href","#transformers.AutoProcessor"),c(Mi,"class","relative group"),c(OB,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(VB,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPProcessor"),c(XB,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(zB,"href","/docs/transformers/pr_17227/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(WB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(QB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(HB,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(UB,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(JB,"href","/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRProcessor"),c(YB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(KB,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZB,"href","/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltProcessor"),c(eI,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(oI,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(rI,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(tI,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yh,"id","transformers.AutoModel"),c(Yh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yh,"href","#transformers.AutoModel"),c(Ci,"class","relative group"),c(aI,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nI,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sI,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lI,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertModel"),c(iI,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartModel"),c(dI,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitModel"),c(cI,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertModel"),c(fI,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(mI,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdModel"),c(gI,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(hI,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(pI,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(_I,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertModel"),c(uI,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineModel"),c(bI,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.CLIPModel"),c(vI,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertModel"),c(FI,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextModel"),c(TI,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLModel"),c(MI,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(EI,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(CI,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(wI,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaModel"),c(AI,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(yI,"href","/docs/transformers/pr_17227/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(LI,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTModel"),c(xI,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrModel"),c($I,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertModel"),c(kI,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(SI,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTModel"),c(RI,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraModel"),c(PI,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertModel"),c(BI,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaModel"),c(II,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetModel"),c(qI,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTModel"),c(NI,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelModel"),c(jI,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelBaseModel"),c(DI,"href","/docs/transformers/pr_17227/en/model_doc/glpn#transformers.GLPNModel"),c(GI,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2Model"),c(OI,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(VI,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJModel"),c(XI,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertModel"),c(zI,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertModel"),c(WI,"href","/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(QI,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(HI,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(UI,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDModel"),c(JI,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerModel"),c(YI,"href","/docs/transformers/pr_17227/en/model_doc/luke#transformers.LukeModel"),c(KI,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertModel"),c(ZI,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100Model"),c(eq,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianModel"),c(oq,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerModel"),c(rq,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartModel"),c(tq,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(aq,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertModel"),c(nq,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetModel"),c(sq,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5Model"),c(lq,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerModel"),c(iq,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(dq,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTModel"),c(cq,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusModel"),c(fq,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverModel"),c(mq,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartModel"),c(gq,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerModel"),c(hq,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(pq,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertModel"),c(_q,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModel"),c(uq,"href","/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetModel"),c(bq,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertModel"),c(vq,"href","/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetModel"),c(Fq,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel"),c(Tq,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaModel"),c(Mq,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerModel"),c(Eq,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerModel"),c(Cq,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWModel"),c(wq,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDModel"),c(Aq,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(yq,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterModel"),c(Lq,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(xq,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinModel"),c($q,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5Model"),c(kq,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasModel"),c(Sq,"href","/docs/transformers/pr_17227/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(Rq,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Pq,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Bq,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Iq,"href","/docs/transformers/pr_17227/en/model_doc/van#transformers.VanModel"),c(qq,"href","/docs/transformers/pr_17227/en/model_doc/vilt#transformers.ViltModel"),c(Nq,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(jq,"href","/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Dq,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTModel"),c(Gq,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Oq,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Vq,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Xq,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMModel"),c(zq,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMModel"),c(Wq,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMModel"),c(Qq,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Hq,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(Uq,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Jq,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetModel"),c(Yq,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosModel"),c(Kq,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z_,"id","transformers.AutoModelForPreTraining"),c(z_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z_,"href","#transformers.AutoModelForPreTraining"),c(yi,"class","relative group"),c(Zq,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rN,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForPreTraining"),c(tN,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(aN,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForPreTraining"),c(nN,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(sN,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(lN,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(iN,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(dN,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(cN,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(fN,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(mN,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForPreTraining"),c(gN,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(hN,"href","/docs/transformers/pr_17227/en/model_doc/flava#transformers.FlavaForPreTraining"),c(pN,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForPreTraining"),c(_N,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(uN,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(bN,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(vN,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(FN,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(TN,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(MN,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(EN,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(CN,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(wN,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(AN,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(yN,"href","/docs/transformers/pr_17227/en/model_doc/retribert#transformers.RetriBertModel"),c(LN,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(xN,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterForPreTraining"),c($N,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(kN,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(SN,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(RN,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(PN,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(BN,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(IN,"href","/docs/transformers/pr_17227/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(qN,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(NN,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(jN,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(DN,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(GN,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(ON,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(VN,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qu,"id","transformers.AutoModelForCausalLM"),c(qu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qu,"href","#transformers.AutoModelForCausalLM"),c($i,"class","relative group"),c(XN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WN,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QN,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForCausalLM"),c(HN,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertLMHeadModel"),c(UN,"href","/docs/transformers/pr_17227/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(JN,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(YN,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(KN,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(ZN,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(ej,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(oj,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(rj,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(tj,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForCausalLM"),c(aj,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(nj,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(sj,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(lj,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianForCausalLM"),c(ij,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForCausalLM"),c(dj,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(cj,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(fj,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.OPTForCausalLM"),c(mj,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(gj,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(hj,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(pj,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(_j,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(uj,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(bj,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(vj,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(Fj,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(Tj,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(Mj,"href","/docs/transformers/pr_17227/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(Ej,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(Cj,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(wj,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(Aj,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(yj,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(Lj,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E2,"id","transformers.AutoModelForMaskedLM"),c(E2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E2,"href","#transformers.AutoModelForMaskedLM"),c(Ri,"class","relative group"),c(xj,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($j,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kj,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Sj,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(Rj,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Pj,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMaskedLM"),c(Bj,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(Ij,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(qj,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(Nj,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(jj,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Dj,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(Gj,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Oj,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(Vj,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Xj,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(zj,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(Wj,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(Qj,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(Hj,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(Uj,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(Jj,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(Yj,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(Kj,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(Zj,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(eD,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(oD,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(rD,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(tD,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(aD,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(nD,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(sD,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(lD,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(iD,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(dD,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(cD,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(fD,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i1,"id","transformers.AutoModelForSeq2SeqLM"),c(i1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Ii,"class","relative group"),c(mD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pD,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(_D,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(uD,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(bD,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(vD,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(FD,"href","/docs/transformers/pr_17227/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(TD,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(MD,"href","/docs/transformers/pr_17227/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.MarianMTModel"),c(CD,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(wD,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(AD,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(yD,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(LD,"href","/docs/transformers/pr_17227/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(xD,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c($D,"href","/docs/transformers/pr_17227/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L1,"id","transformers.AutoModelForSequenceClassification"),c(L1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L1,"href","#transformers.AutoModelForSequenceClassification"),c(ji,"class","relative group"),c(kD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RD,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PD,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(BD,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForSequenceClassification"),c(ID,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForSequenceClassification"),c(qD,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(ND,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(jD,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(DD,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(GD,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(OD,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(VD,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(XD,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(zD,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(WD,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(QD,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(HD,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(UD,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(JD,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(YD,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(KD,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(ZD,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(eG,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(oG,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(rG,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(tG,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForSequenceClassification"),c(aG,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(nG,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(sG,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(lG,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(iG,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(dG,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(cG,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(fG,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(mG,"href","/docs/transformers/pr_17227/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(gG,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(hG,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(pG,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(_G,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(uG,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(bG,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(vG,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(FG,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(TG,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(MG,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(EG,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(CG,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(wG,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C7,"id","transformers.AutoModelForMultipleChoice"),c(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C7,"href","#transformers.AutoModelForMultipleChoice"),c(Oi,"class","relative group"),c(AG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LG,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xG,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c($G,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForMultipleChoice"),c(kG,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(SG,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(RG,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(PG,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(BG,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(IG,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(qG,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(NG,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(jG,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(DG,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(GG,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(OG,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(VG,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(XG,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(zG,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(WG,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(QG,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(HG,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(UG,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(JG,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(YG,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(KG,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(ZG,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(eO,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(oO,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(rO,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(tO,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tb,"id","transformers.AutoModelForNextSentencePrediction"),c(tb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tb,"href","#transformers.AutoModelForNextSentencePrediction"),c(zi,"class","relative group"),c(aO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lO,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(iO,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(dO,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(cO,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(fO,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mb,"id","transformers.AutoModelForTokenClassification"),c(mb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mb,"href","#transformers.AutoModelForTokenClassification"),c(Hi,"class","relative group"),c(mO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pO,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(_O,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForTokenClassification"),c(uO,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(bO,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(vO,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForTokenClassification"),c(FO,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(TO,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(MO,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(EO,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(CO,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(wO,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(AO,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(yO,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(LO,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(xO,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c($O,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(kO,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(SO,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(RO,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(PO,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(BO,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(IO,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(qO,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(NO,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(jO,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(DO,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(GO,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(OO,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(VO,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(XO,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(zO,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(WO,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(QO,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ub,"id","transformers.AutoModelForQuestionAnswering"),c(Ub,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ub,"href","#transformers.AutoModelForQuestionAnswering"),c(Yi,"class","relative group"),c(HO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JO,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YO,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(KO,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(ZO,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(eV,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(oV,"href","/docs/transformers/pr_17227/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(rV,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(tV,"href","/docs/transformers/pr_17227/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(aV,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(nV,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(sV,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(lV,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(iV,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(dV,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(cV,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(fV,"href","/docs/transformers/pr_17227/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(mV,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(gV,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(hV,"href","/docs/transformers/pr_17227/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(pV,"href","/docs/transformers/pr_17227/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(_V,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(uV,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(bV,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(vV,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(FV,"href","/docs/transformers/pr_17227/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(TV,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(MV,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(EV,"href","/docs/transformers/pr_17227/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(CV,"href","/docs/transformers/pr_17227/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(wV,"href","/docs/transformers/pr_17227/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(AV,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(yV,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(LV,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(xV,"href","/docs/transformers/pr_17227/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c($V,"href","/docs/transformers/pr_17227/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(kV,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(SV,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(RV,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(PV,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(BV,"href","/docs/transformers/pr_17227/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nv,"id","transformers.AutoModelForTableQuestionAnswering"),c(Nv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nv,"href","#transformers.AutoModelForTableQuestionAnswering"),c(ed,"class","relative group"),c(IV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jV,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vv,"id","transformers.AutoModelForImageClassification"),c(Vv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vv,"href","#transformers.AutoModelForImageClassification"),c(td,"class","relative group"),c(DV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OV,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VV,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForImageClassification"),c(XV,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(zV,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(WV,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassification"),c(QV,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(HV,"href","/docs/transformers/pr_17227/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(UV,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(JV,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(YV,"href","/docs/transformers/pr_17227/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(KV,"href","/docs/transformers/pr_17227/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(ZV,"href","/docs/transformers/pr_17227/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(eX,"href","/docs/transformers/pr_17227/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(oX,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(rX,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForImageClassification"),c(tX,"href","/docs/transformers/pr_17227/en/model_doc/van#transformers.VanForImageClassification"),c(aX,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aF,"id","transformers.AutoModelForVision2Seq"),c(aF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aF,"href","#transformers.AutoModelForVision2Seq"),c(sd,"class","relative group"),c(nX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iX,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dF,"id","transformers.AutoModelForAudioClassification"),c(dF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dF,"href","#transformers.AutoModelForAudioClassification"),c(dd,"class","relative group"),c(dX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(gX,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(hX,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(pX,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(_X,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(uX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(bX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(vX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(FX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MF,"id","transformers.AutoModelForAudioFrameClassification"),c(MF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(MF,"href","#transformers.AutoModelForAudioFrameClassification"),c(md,"class","relative group"),c(TX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(wX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(AX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(yX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(LX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kF,"id","transformers.AutoModelForCTC"),c(kF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kF,"href","#transformers.AutoModelForCTC"),c(pd,"class","relative group"),c(xX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(RX,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.HubertForCTC"),c(PX,"href","/docs/transformers/pr_17227/en/model_doc/sew#transformers.SEWForCTC"),c(BX,"href","/docs/transformers/pr_17227/en/model_doc/sew-d#transformers.SEWDForCTC"),c(IX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(qX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(NX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(jX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(DX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForCTC"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(XF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(bd,"class","relative group"),c(GX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XX,"href","/docs/transformers/pr_17227/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(zX,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JF,"id","transformers.AutoModelForAudioXVector"),c(JF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(JF,"href","#transformers.AutoModelForAudioXVector"),c(Td,"class","relative group"),c(WX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HX,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UX,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(JX,"href","/docs/transformers/pr_17227/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(YX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(KX,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(ZX,"href","/docs/transformers/pr_17227/en/model_doc/wavlm#transformers.WavLMForXVector"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nT,"id","transformers.AutoModelForMaskedImageModeling"),c(nT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nT,"href","#transformers.AutoModelForMaskedImageModeling"),c(Cd,"class","relative group"),c(ez,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tz,"href","/docs/transformers/pr_17227/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(az,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(nz,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mT,"id","transformers.AutoModelForObjectDetection"),c(mT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mT,"href","#transformers.AutoModelForObjectDetection"),c(Ld,"class","relative group"),c(sz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dz,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForObjectDetection"),c(cz,"href","/docs/transformers/pr_17227/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bT,"id","transformers.AutoModelForImageSegmentation"),c(bT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bT,"href","#transformers.AutoModelForImageSegmentation"),c(kd,"class","relative group"),c(fz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hz,"href","/docs/transformers/pr_17227/en/model_doc/detr#transformers.DetrForSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ET,"id","transformers.AutoModelForSemanticSegmentation"),c(ET,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ET,"href","#transformers.AutoModelForSemanticSegmentation"),c(Pd,"class","relative group"),c(pz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_z,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bz,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(vz,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(Fz,"href","/docs/transformers/pr_17227/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(Tz,"href","/docs/transformers/pr_17227/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kT,"id","transformers.AutoModelForInstanceSegmentation"),c(kT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kT,"href","#transformers.AutoModelForInstanceSegmentation"),c(qd,"class","relative group"),c(Mz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ez,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Cz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wz,"href","/docs/transformers/pr_17227/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IT,"id","transformers.TFAutoModel"),c(IT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IT,"href","#transformers.TFAutoModel"),c(Dd,"class","relative group"),c(Az,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lz,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xz,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertModel"),c($z,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartModel"),c(kz,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertModel"),c(Sz,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(Rz,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(Pz,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertModel"),c(Bz,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.TFCLIPModel"),c(Iz,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertModel"),c(qz,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextModel"),c(Nz,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLModel"),c(jz,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(Dz,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaModel"),c(Gz,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(Oz,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(Vz,"href","/docs/transformers/pr_17227/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(Xz,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraModel"),c(zz,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(Wz,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelModel"),c(Qz,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(Hz,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2Model"),c(Uz,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJModel"),c(Jz,"href","/docs/transformers/pr_17227/en/model_doc/hubert#transformers.TFHubertModel"),c(Yz,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(Kz,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDModel"),c(Zz,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerModel"),c(eW,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertModel"),c(oW,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianModel"),c(rW,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartModel"),c(tW,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(aW,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetModel"),c(nW,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5Model"),c(sW,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(lW,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.TFOPTModel"),c(iW,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusModel"),c(dW,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertModel"),c(cW,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaModel"),c(fW,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerModel"),c(mW,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(gW,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinModel"),c(hW,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5Model"),c(pW,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasModel"),c(_W,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(uW,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTModel"),c(bW,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(vW,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(FW,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMModel"),c(TW,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(MW,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kM,"id","transformers.TFAutoModelForPreTraining"),c(kM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kM,"href","#transformers.TFAutoModelForPreTraining"),c(Vd,"class","relative group"),c(EW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AW,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(yW,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(LW,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForPreTraining"),c(xW,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c($W,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(kW,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(SW,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(RW,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(PW,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(BW,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(IW,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(qW,"href","/docs/transformers/pr_17227/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(NW,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(jW,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(DW,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(GW,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(OW,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(VW,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(XW,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(zW,"href","/docs/transformers/pr_17227/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(WW,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(QW,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(HW,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t4,"id","transformers.TFAutoModelForCausalLM"),c(t4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t4,"href","#transformers.TFAutoModelForCausalLM"),c(Wd,"class","relative group"),c(UW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YW,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KW,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(ZW,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(eQ,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(oQ,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(rQ,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(tQ,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(aQ,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(nQ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(sQ,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(lQ,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(iQ,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(dQ,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b4,"id","transformers.TFAutoModelForImageClassification"),c(b4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b4,"href","#transformers.TFAutoModelForImageClassification"),c(Ud,"class","relative group"),c(cQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gQ,"href","/docs/transformers/pr_17227/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(hQ,"href","/docs/transformers/pr_17227/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(pQ,"href","/docs/transformers/pr_17227/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(_Q,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w4,"id","transformers.TFAutoModelForMaskedLM"),c(w4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w4,"href","#transformers.TFAutoModelForMaskedLM"),c(Kd,"class","relative group"),c(uQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FQ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(TQ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(MQ,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(EQ,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(CQ,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(wQ,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(AQ,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(yQ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(LQ,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(xQ,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c($Q,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(kQ,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(SQ,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(RQ,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(PQ,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(BQ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(IQ,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(qQ,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(NQ,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(jQ,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H4,"id","transformers.TFAutoModelForSeq2SeqLM"),c(H4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(H4,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(oc,"class","relative group"),c(DQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VQ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(XQ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(zQ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(WQ,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(QQ,"href","/docs/transformers/pr_17227/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(HQ,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.TFMarianMTModel"),c(UQ,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(JQ,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(YQ,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(KQ,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lE,"id","transformers.TFAutoModelForSequenceClassification"),c(lE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lE,"href","#transformers.TFAutoModelForSequenceClassification"),c(ac,"class","relative group"),c(ZQ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rH,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(tH,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(aH,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(nH,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(sH,"href","/docs/transformers/pr_17227/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(lH,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(iH,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(dH,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(cH,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(fH,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(mH,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(gH,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(hH,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(pH,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(_H,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(uH,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(bH,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(vH,"href","/docs/transformers/pr_17227/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(FH,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(TH,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(MH,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(EH,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(CH,"href","/docs/transformers/pr_17227/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(wH,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(AH,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(yH,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IE,"id","transformers.TFAutoModelForMultipleChoice"),c(IE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IE,"href","#transformers.TFAutoModelForMultipleChoice"),c(lc,"class","relative group"),c(LH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($H,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kH,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(SH,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(RH,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(PH,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(BH,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(IH,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(qH,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(NH,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(jH,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(DH,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(GH,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(OH,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(VH,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(XH,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(zH,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(WH,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(QH,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rC,"id","transformers.TFAutoModelForNextSentencePrediction"),c(rC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rC,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(cc,"class","relative group"),c(HH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YH,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(KH,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lC,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(lC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(gc,"class","relative group"),c(ZH,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rU,"href","/docs/transformers/pr_17227/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fC,"id","transformers.TFAutoModelForTokenClassification"),c(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fC,"href","#transformers.TFAutoModelForTokenClassification"),c(_c,"class","relative group"),c(tU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sU,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(lU,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(iU,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(dU,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(cU,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(fU,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(mU,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(gU,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(hU,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(pU,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(_U,"href","/docs/transformers/pr_17227/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(uU,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(bU,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(vU,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(FU,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(TU,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(MU,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(EU,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(CU,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(wU,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PC,"id","transformers.TFAutoModelForQuestionAnswering"),c(PC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(vc,"class","relative group"),c(AU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xU,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c($U,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(kU,"href","/docs/transformers/pr_17227/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(SU,"href","/docs/transformers/pr_17227/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(RU,"href","/docs/transformers/pr_17227/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(PU,"href","/docs/transformers/pr_17227/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(BU,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(IU,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(qU,"href","/docs/transformers/pr_17227/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(NU,"href","/docs/transformers/pr_17227/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(jU,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(DU,"href","/docs/transformers/pr_17227/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(GU,"href","/docs/transformers/pr_17227/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(OU,"href","/docs/transformers/pr_17227/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(VU,"href","/docs/transformers/pr_17227/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(XU,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(zU,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(WU,"href","/docs/transformers/pr_17227/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(QU,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(HU,"href","/docs/transformers/pr_17227/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t5,"id","transformers.TFAutoModelForVision2Seq"),c(t5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t5,"href","#transformers.TFAutoModelForVision2Seq"),c(Mc,"class","relative group"),c(UU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KU,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(wc,"class","relative group"),c(ZU,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rJ,"href","/docs/transformers/pr_17227/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f5,"id","transformers.FlaxAutoModel"),c(f5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f5,"href","#transformers.FlaxAutoModel"),c(Lc,"class","relative group"),c(tJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sJ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertModel"),c(lJ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartModel"),c(iJ,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitModel"),c(dJ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertModel"),c(cJ,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(fJ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(mJ,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(gJ,"href","/docs/transformers/pr_17227/en/model_doc/clip#transformers.FlaxCLIPModel"),c(hJ,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(pJ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraModel"),c(_J,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(uJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(bJ,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(vJ,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianModel"),c(FJ,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartModel"),c(TJ,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5Model"),c(MJ,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTModel"),c(EJ,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(CJ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(wJ,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(AJ,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5Model"),c(yJ,"href","/docs/transformers/pr_17227/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(LJ,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTModel"),c(xJ,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c($J,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(kJ,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D5,"id","transformers.FlaxAutoModelForCausalLM"),c(D5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D5,"href","#transformers.FlaxAutoModelForCausalLM"),c(kc,"class","relative group"),c(SJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BJ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(IJ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(qJ,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(NJ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(jJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(DJ,"href","/docs/transformers/pr_17227/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(GJ,"href","/docs/transformers/pr_17227/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(OJ,"href","/docs/transformers/pr_17227/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(VJ,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(XJ,"href","/docs/transformers/pr_17227/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z5,"id","transformers.FlaxAutoModelForPreTraining"),c(Z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Pc,"class","relative group"),c(zJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HJ,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(UJ,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(JJ,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(YJ,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(KJ,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(ZJ,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(eY,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(oY,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(rY,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(tY,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(aY,"href","/docs/transformers/pr_17227/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(nY,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h3,"id","transformers.FlaxAutoModelForMaskedLM"),c(h3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h3,"href","#transformers.FlaxAutoModelForMaskedLM"),c(qc,"class","relative group"),c(sY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dY,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(cY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(fY,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(mY,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(gY,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(hY,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(pY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(_Y,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(uY,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(bY,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y3,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y3,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Dc,"class","relative group"),c(vY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(EY,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(CY,"href","/docs/transformers/pr_17227/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(wY,"href","/docs/transformers/pr_17227/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(AY,"href","/docs/transformers/pr_17227/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(yY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(LY,"href","/docs/transformers/pr_17227/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(xY,"href","/docs/transformers/pr_17227/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c($Y,"href","/docs/transformers/pr_17227/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(j3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Vc,"class","relative group"),c(kY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PY,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(BY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(IY,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(qY,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(NY,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(jY,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(DY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(GY,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(OY,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(VY,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K3,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(K3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Wc,"class","relative group"),c(XY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WY,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QY,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(HY,"href","/docs/transformers/pr_17227/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(UY,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(JY,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(YY,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(KY,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(ZY,"href","/docs/transformers/pr_17227/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(eK,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(oK,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(rK,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fw,"id","transformers.FlaxAutoModelForTokenClassification"),c(fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Uc,"class","relative group"),c(tK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(lK,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(iK,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(dK,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(cK,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(fK,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(mK,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(gK,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Mw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(Kc,"class","relative group"),c(hK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_K,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uK,"href","/docs/transformers/pr_17227/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(bK,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(vK,"href","/docs/transformers/pr_17227/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(FK,"href","/docs/transformers/pr_17227/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(TK,"href","/docs/transformers/pr_17227/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(MK,"href","/docs/transformers/pr_17227/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(EK,"href","/docs/transformers/pr_17227/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(CK,"href","/docs/transformers/pr_17227/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Rw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Rw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(of,"class","relative group"),c(wK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LK,"href","/docs/transformers/pr_17227/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qw,"id","transformers.FlaxAutoModelForImageClassification"),c(qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qw,"href","#transformers.FlaxAutoModelForImageClassification"),c(af,"class","relative group"),c(xK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($K,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SK,"href","/docs/transformers/pr_17227/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(RK,"href","/docs/transformers/pr_17227/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ow,"id","transformers.FlaxAutoModelForVision2Seq"),c(Ow,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ow,"href","#transformers.FlaxAutoModelForVision2Seq"),c(lf,"class","relative group"),c(PK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17227/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qK,"href","/docs/transformers/pr_17227/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Mo),e(Mo,ci),b(f,hf,u),b(f,rt,u),e(rt,fi),e(rt,mi),e(mi,d6),e(rt,pf),b(f,De,u),b(f,We,u),e(We,gi),e(We,yn),e(yn,c6),e(We,Ln),e(We,xn),e(xn,f6),e(We,hi),e(We,$n),e($n,m6),e(We,pi),b(f,_f,u),M(Ca,f,u),b(f,Qe,u),b(f,Ae,u),e(Ae,$$),e(Ae,_i),e(_i,k$),e(Ae,S$),b(f,Eo,u),b(f,wa,u),e(wa,R$),e(wa,uf),e(uf,P$),e(wa,sGe),b(f,UIe,u),b(f,ui,u),e(ui,bf),e(bf,$ee),M(g6,$ee,null),e(ui,lGe),e(ui,kee),e(kee,iGe),b(f,JIe,u),b(f,kn,u),e(kn,dGe),e(kn,See),e(See,cGe),e(kn,fGe),e(kn,Ree),e(Ree,mGe),e(kn,gGe),b(f,YIe,u),M(h6,f,u),b(f,KIe,u),b(f,B$,u),e(B$,hGe),b(f,ZIe,u),M(vf,f,u),b(f,eqe,u),b(f,bi,u),e(bi,Ff),e(Ff,Pee),M(p6,Pee,null),e(bi,pGe),e(bi,Bee),e(Bee,_Ge),b(f,oqe,u),b(f,Co,u),M(_6,Co,null),e(Co,uGe),e(Co,u6),e(u6,bGe),e(u6,I$),e(I$,vGe),e(u6,FGe),e(Co,TGe),e(Co,b6),e(b6,MGe),e(b6,Iee),e(Iee,EGe),e(b6,CGe),e(Co,wGe),e(Co,Er),M(v6,Er,null),e(Er,AGe),e(Er,qee),e(qee,yGe),e(Er,LGe),e(Er,vi),e(vi,xGe),e(vi,Nee),e(Nee,$Ge),e(vi,kGe),e(vi,jee),e(jee,SGe),e(vi,RGe),e(Er,PGe),e(Er,A),e(A,Tf),e(Tf,Dee),e(Dee,BGe),e(Tf,IGe),e(Tf,q$),e(q$,qGe),e(Tf,NGe),e(A,jGe),e(A,Mf),e(Mf,Gee),e(Gee,DGe),e(Mf,GGe),e(Mf,N$),e(N$,OGe),e(Mf,VGe),e(A,XGe),e(A,Ef),e(Ef,Oee),e(Oee,zGe),e(Ef,WGe),e(Ef,j$),e(j$,QGe),e(Ef,HGe),e(A,UGe),e(A,Cf),e(Cf,Vee),e(Vee,JGe),e(Cf,YGe),e(Cf,D$),e(D$,KGe),e(Cf,ZGe),e(A,eOe),e(A,wf),e(wf,Xee),e(Xee,oOe),e(wf,rOe),e(wf,G$),e(G$,tOe),e(wf,aOe),e(A,nOe),e(A,Af),e(Af,zee),e(zee,sOe),e(Af,lOe),e(Af,O$),e(O$,iOe),e(Af,dOe),e(A,cOe),e(A,yf),e(yf,Wee),e(Wee,fOe),e(yf,mOe),e(yf,V$),e(V$,gOe),e(yf,hOe),e(A,pOe),e(A,Lf),e(Lf,Qee),e(Qee,_Oe),e(Lf,uOe),e(Lf,X$),e(X$,bOe),e(Lf,vOe),e(A,FOe),e(A,xf),e(xf,Hee),e(Hee,TOe),e(xf,MOe),e(xf,z$),e(z$,EOe),e(xf,COe),e(A,wOe),e(A,$f),e($f,Uee),e(Uee,AOe),e($f,yOe),e($f,W$),e(W$,LOe),e($f,xOe),e(A,$Oe),e(A,kf),e(kf,Jee),e(Jee,kOe),e(kf,SOe),e(kf,Q$),e(Q$,ROe),e(kf,POe),e(A,BOe),e(A,Sf),e(Sf,Yee),e(Yee,IOe),e(Sf,qOe),e(Sf,H$),e(H$,NOe),e(Sf,jOe),e(A,DOe),e(A,Rf),e(Rf,Kee),e(Kee,GOe),e(Rf,OOe),e(Rf,U$),e(U$,VOe),e(Rf,XOe),e(A,zOe),e(A,Pf),e(Pf,Zee),e(Zee,WOe),e(Pf,QOe),e(Pf,J$),e(J$,HOe),e(Pf,UOe),e(A,JOe),e(A,Bf),e(Bf,eoe),e(eoe,YOe),e(Bf,KOe),e(Bf,Y$),e(Y$,ZOe),e(Bf,eVe),e(A,oVe),e(A,If),e(If,ooe),e(ooe,rVe),e(If,tVe),e(If,K$),e(K$,aVe),e(If,nVe),e(A,sVe),e(A,qf),e(qf,roe),e(roe,lVe),e(qf,iVe),e(qf,Z$),e(Z$,dVe),e(qf,cVe),e(A,fVe),e(A,Nf),e(Nf,toe),e(toe,mVe),e(Nf,gVe),e(Nf,ek),e(ek,hVe),e(Nf,pVe),e(A,_Ve),e(A,jf),e(jf,aoe),e(aoe,uVe),e(jf,bVe),e(jf,ok),e(ok,vVe),e(jf,FVe),e(A,TVe),e(A,Df),e(Df,noe),e(noe,MVe),e(Df,EVe),e(Df,rk),e(rk,CVe),e(Df,wVe),e(A,AVe),e(A,Gf),e(Gf,soe),e(soe,yVe),e(Gf,LVe),e(Gf,tk),e(tk,xVe),e(Gf,$Ve),e(A,kVe),e(A,Of),e(Of,loe),e(loe,SVe),e(Of,RVe),e(Of,ak),e(ak,PVe),e(Of,BVe),e(A,IVe),e(A,Vf),e(Vf,ioe),e(ioe,qVe),e(Vf,NVe),e(Vf,nk),e(nk,jVe),e(Vf,DVe),e(A,GVe),e(A,Xf),e(Xf,doe),e(doe,OVe),e(Xf,VVe),e(Xf,sk),e(sk,XVe),e(Xf,zVe),e(A,WVe),e(A,zf),e(zf,coe),e(coe,QVe),e(zf,HVe),e(zf,lk),e(lk,UVe),e(zf,JVe),e(A,YVe),e(A,Wf),e(Wf,foe),e(foe,KVe),e(Wf,ZVe),e(Wf,ik),e(ik,eXe),e(Wf,oXe),e(A,rXe),e(A,Qf),e(Qf,moe),e(moe,tXe),e(Qf,aXe),e(Qf,dk),e(dk,nXe),e(Qf,sXe),e(A,lXe),e(A,Hf),e(Hf,goe),e(goe,iXe),e(Hf,dXe),e(Hf,ck),e(ck,cXe),e(Hf,fXe),e(A,mXe),e(A,Uf),e(Uf,hoe),e(hoe,gXe),e(Uf,hXe),e(Uf,fk),e(fk,pXe),e(Uf,_Xe),e(A,uXe),e(A,Jf),e(Jf,poe),e(poe,bXe),e(Jf,vXe),e(Jf,mk),e(mk,FXe),e(Jf,TXe),e(A,MXe),e(A,Yf),e(Yf,_oe),e(_oe,EXe),e(Yf,CXe),e(Yf,gk),e(gk,wXe),e(Yf,AXe),e(A,yXe),e(A,Kf),e(Kf,uoe),e(uoe,LXe),e(Kf,xXe),e(Kf,hk),e(hk,$Xe),e(Kf,kXe),e(A,SXe),e(A,Zf),e(Zf,boe),e(boe,RXe),e(Zf,PXe),e(Zf,pk),e(pk,BXe),e(Zf,IXe),e(A,qXe),e(A,em),e(em,voe),e(voe,NXe),e(em,jXe),e(em,_k),e(_k,DXe),e(em,GXe),e(A,OXe),e(A,om),e(om,Foe),e(Foe,VXe),e(om,XXe),e(om,uk),e(uk,zXe),e(om,WXe),e(A,QXe),e(A,rm),e(rm,Toe),e(Toe,HXe),e(rm,UXe),e(rm,bk),e(bk,JXe),e(rm,YXe),e(A,KXe),e(A,tm),e(tm,Moe),e(Moe,ZXe),e(tm,eze),e(tm,vk),e(vk,oze),e(tm,rze),e(A,tze),e(A,am),e(am,Eoe),e(Eoe,aze),e(am,nze),e(am,Fk),e(Fk,sze),e(am,lze),e(A,ize),e(A,nm),e(nm,Coe),e(Coe,dze),e(nm,cze),e(nm,Tk),e(Tk,fze),e(nm,mze),e(A,gze),e(A,sm),e(sm,woe),e(woe,hze),e(sm,pze),e(sm,Mk),e(Mk,_ze),e(sm,uze),e(A,bze),e(A,lm),e(lm,Aoe),e(Aoe,vze),e(lm,Fze),e(lm,Ek),e(Ek,Tze),e(lm,Mze),e(A,Eze),e(A,im),e(im,yoe),e(yoe,Cze),e(im,wze),e(im,Ck),e(Ck,Aze),e(im,yze),e(A,Lze),e(A,dm),e(dm,Loe),e(Loe,xze),e(dm,$ze),e(dm,wk),e(wk,kze),e(dm,Sze),e(A,Rze),e(A,cm),e(cm,xoe),e(xoe,Pze),e(cm,Bze),e(cm,Ak),e(Ak,Ize),e(cm,qze),e(A,Nze),e(A,fm),e(fm,$oe),e($oe,jze),e(fm,Dze),e(fm,yk),e(yk,Gze),e(fm,Oze),e(A,Vze),e(A,mm),e(mm,koe),e(koe,Xze),e(mm,zze),e(mm,Lk),e(Lk,Wze),e(mm,Qze),e(A,Hze),e(A,gm),e(gm,Soe),e(Soe,Uze),e(gm,Jze),e(gm,xk),e(xk,Yze),e(gm,Kze),e(A,Zze),e(A,hm),e(hm,Roe),e(Roe,eWe),e(hm,oWe),e(hm,$k),e($k,rWe),e(hm,tWe),e(A,aWe),e(A,pm),e(pm,Poe),e(Poe,nWe),e(pm,sWe),e(pm,kk),e(kk,lWe),e(pm,iWe),e(A,dWe),e(A,_m),e(_m,Boe),e(Boe,cWe),e(_m,fWe),e(_m,Sk),e(Sk,mWe),e(_m,gWe),e(A,hWe),e(A,um),e(um,Ioe),e(Ioe,pWe),e(um,_We),e(um,Rk),e(Rk,uWe),e(um,bWe),e(A,vWe),e(A,bm),e(bm,qoe),e(qoe,FWe),e(bm,TWe),e(bm,Pk),e(Pk,MWe),e(bm,EWe),e(A,CWe),e(A,vm),e(vm,Noe),e(Noe,wWe),e(vm,AWe),e(vm,Bk),e(Bk,yWe),e(vm,LWe),e(A,xWe),e(A,Fm),e(Fm,joe),e(joe,$We),e(Fm,kWe),e(Fm,Ik),e(Ik,SWe),e(Fm,RWe),e(A,PWe),e(A,Tm),e(Tm,Doe),e(Doe,BWe),e(Tm,IWe),e(Tm,qk),e(qk,qWe),e(Tm,NWe),e(A,jWe),e(A,Mm),e(Mm,Goe),e(Goe,DWe),e(Mm,GWe),e(Mm,Nk),e(Nk,OWe),e(Mm,VWe),e(A,XWe),e(A,Em),e(Em,Ooe),e(Ooe,zWe),e(Em,WWe),e(Em,jk),e(jk,QWe),e(Em,HWe),e(A,UWe),e(A,Cm),e(Cm,Voe),e(Voe,JWe),e(Cm,YWe),e(Cm,Dk),e(Dk,KWe),e(Cm,ZWe),e(A,eQe),e(A,wm),e(wm,Xoe),e(Xoe,oQe),e(wm,rQe),e(wm,Gk),e(Gk,tQe),e(wm,aQe),e(A,nQe),e(A,Am),e(Am,zoe),e(zoe,sQe),e(Am,lQe),e(Am,Ok),e(Ok,iQe),e(Am,dQe),e(A,cQe),e(A,ym),e(ym,Woe),e(Woe,fQe),e(ym,mQe),e(ym,Vk),e(Vk,gQe),e(ym,hQe),e(A,pQe),e(A,Lm),e(Lm,Qoe),e(Qoe,_Qe),e(Lm,uQe),e(Lm,Xk),e(Xk,bQe),e(Lm,vQe),e(A,FQe),e(A,xm),e(xm,Hoe),e(Hoe,TQe),e(xm,MQe),e(xm,zk),e(zk,EQe),e(xm,CQe),e(A,wQe),e(A,$m),e($m,Uoe),e(Uoe,AQe),e($m,yQe),e($m,Wk),e(Wk,LQe),e($m,xQe),e(A,$Qe),e(A,km),e(km,Joe),e(Joe,kQe),e(km,SQe),e(km,Qk),e(Qk,RQe),e(km,PQe),e(A,BQe),e(A,Sm),e(Sm,Yoe),e(Yoe,IQe),e(Sm,qQe),e(Sm,Hk),e(Hk,NQe),e(Sm,jQe),e(A,DQe),e(A,Rm),e(Rm,Koe),e(Koe,GQe),e(Rm,OQe),e(Rm,Uk),e(Uk,VQe),e(Rm,XQe),e(A,zQe),e(A,Pm),e(Pm,Zoe),e(Zoe,WQe),e(Pm,QQe),e(Pm,Jk),e(Jk,HQe),e(Pm,UQe),e(A,JQe),e(A,Bm),e(Bm,ere),e(ere,YQe),e(Bm,KQe),e(Bm,Yk),e(Yk,ZQe),e(Bm,eHe),e(A,oHe),e(A,Im),e(Im,ore),e(ore,rHe),e(Im,tHe),e(Im,Kk),e(Kk,aHe),e(Im,nHe),e(A,sHe),e(A,qm),e(qm,rre),e(rre,lHe),e(qm,iHe),e(qm,Zk),e(Zk,dHe),e(qm,cHe),e(A,fHe),e(A,Nm),e(Nm,tre),e(tre,mHe),e(Nm,gHe),e(Nm,eS),e(eS,hHe),e(Nm,pHe),e(A,_He),e(A,jm),e(jm,are),e(are,uHe),e(jm,bHe),e(jm,oS),e(oS,vHe),e(jm,FHe),e(A,THe),e(A,Dm),e(Dm,nre),e(nre,MHe),e(Dm,EHe),e(Dm,rS),e(rS,CHe),e(Dm,wHe),e(A,AHe),e(A,Gm),e(Gm,sre),e(sre,yHe),e(Gm,LHe),e(Gm,tS),e(tS,xHe),e(Gm,$He),e(A,kHe),e(A,Om),e(Om,lre),e(lre,SHe),e(Om,RHe),e(Om,aS),e(aS,PHe),e(Om,BHe),e(A,IHe),e(A,Vm),e(Vm,ire),e(ire,qHe),e(Vm,NHe),e(Vm,nS),e(nS,jHe),e(Vm,DHe),e(A,GHe),e(A,Xm),e(Xm,dre),e(dre,OHe),e(Xm,VHe),e(Xm,sS),e(sS,XHe),e(Xm,zHe),e(A,WHe),e(A,zm),e(zm,cre),e(cre,QHe),e(zm,HHe),e(zm,lS),e(lS,UHe),e(zm,JHe),e(A,YHe),e(A,Wm),e(Wm,fre),e(fre,KHe),e(Wm,ZHe),e(Wm,iS),e(iS,eUe),e(Wm,oUe),e(A,rUe),e(A,Qm),e(Qm,mre),e(mre,tUe),e(Qm,aUe),e(Qm,dS),e(dS,nUe),e(Qm,sUe),e(A,lUe),e(A,Hm),e(Hm,gre),e(gre,iUe),e(Hm,dUe),e(Hm,cS),e(cS,cUe),e(Hm,fUe),e(A,mUe),e(A,Um),e(Um,hre),e(hre,gUe),e(Um,hUe),e(Um,fS),e(fS,pUe),e(Um,_Ue),e(A,uUe),e(A,Jm),e(Jm,pre),e(pre,bUe),e(Jm,vUe),e(Jm,mS),e(mS,FUe),e(Jm,TUe),e(A,MUe),e(A,Ym),e(Ym,_re),e(_re,EUe),e(Ym,CUe),e(Ym,gS),e(gS,wUe),e(Ym,AUe),e(A,yUe),e(A,Km),e(Km,ure),e(ure,LUe),e(Km,xUe),e(Km,hS),e(hS,$Ue),e(Km,kUe),e(A,SUe),e(A,Zm),e(Zm,bre),e(bre,RUe),e(Zm,PUe),e(Zm,pS),e(pS,BUe),e(Zm,IUe),e(A,qUe),e(A,eg),e(eg,vre),e(vre,NUe),e(eg,jUe),e(eg,_S),e(_S,DUe),e(eg,GUe),e(A,OUe),e(A,og),e(og,Fre),e(Fre,VUe),e(og,XUe),e(og,uS),e(uS,zUe),e(og,WUe),e(A,QUe),e(A,rg),e(rg,Tre),e(Tre,HUe),e(rg,UUe),e(rg,bS),e(bS,JUe),e(rg,YUe),e(A,KUe),e(A,tg),e(tg,Mre),e(Mre,ZUe),e(tg,eJe),e(tg,vS),e(vS,oJe),e(tg,rJe),e(A,tJe),e(A,ag),e(ag,Ere),e(Ere,aJe),e(ag,nJe),e(ag,FS),e(FS,sJe),e(ag,lJe),e(A,iJe),e(A,ng),e(ng,Cre),e(Cre,dJe),e(ng,cJe),e(ng,TS),e(TS,fJe),e(ng,mJe),e(A,gJe),e(A,sg),e(sg,wre),e(wre,hJe),e(sg,pJe),e(sg,MS),e(MS,_Je),e(sg,uJe),e(A,bJe),e(A,lg),e(lg,Are),e(Are,vJe),e(lg,FJe),e(lg,ES),e(ES,TJe),e(lg,MJe),e(A,EJe),e(A,ig),e(ig,yre),e(yre,CJe),e(ig,wJe),e(ig,CS),e(CS,AJe),e(ig,yJe),e(A,LJe),e(A,dg),e(dg,Lre),e(Lre,xJe),e(dg,$Je),e(dg,wS),e(wS,kJe),e(dg,SJe),e(A,RJe),e(A,cg),e(cg,xre),e(xre,PJe),e(cg,BJe),e(cg,AS),e(AS,IJe),e(cg,qJe),e(A,NJe),e(A,fg),e(fg,$re),e($re,jJe),e(fg,DJe),e(fg,yS),e(yS,GJe),e(fg,OJe),e(A,VJe),e(A,mg),e(mg,kre),e(kre,XJe),e(mg,zJe),e(mg,LS),e(LS,WJe),e(mg,QJe),e(A,HJe),e(A,gg),e(gg,Sre),e(Sre,UJe),e(gg,JJe),e(gg,xS),e(xS,YJe),e(gg,KJe),e(A,ZJe),e(A,hg),e(hg,Rre),e(Rre,eYe),e(hg,oYe),e(hg,$S),e($S,rYe),e(hg,tYe),e(A,aYe),e(A,pg),e(pg,Pre),e(Pre,nYe),e(pg,sYe),e(pg,kS),e(kS,lYe),e(pg,iYe),e(A,dYe),e(A,_g),e(_g,Bre),e(Bre,cYe),e(_g,fYe),e(_g,SS),e(SS,mYe),e(_g,gYe),e(A,hYe),e(A,ug),e(ug,Ire),e(Ire,pYe),e(ug,_Ye),e(ug,RS),e(RS,uYe),e(ug,bYe),e(A,vYe),e(A,bg),e(bg,qre),e(qre,FYe),e(bg,TYe),e(bg,PS),e(PS,MYe),e(bg,EYe),e(Er,CYe),M(vg,Er,null),e(Co,wYe),e(Co,Fg),M(F6,Fg,null),e(Fg,AYe),e(Fg,Nre),e(Nre,yYe),b(f,rqe,u),b(f,Fi,u),e(Fi,Tg),e(Tg,jre),M(T6,jre,null),e(Fi,LYe),e(Fi,Dre),e(Dre,xYe),b(f,tqe,u),b(f,wo,u),M(M6,wo,null),e(wo,$Ye),e(wo,E6),e(E6,kYe),e(E6,BS),e(BS,SYe),e(E6,RYe),e(wo,PYe),e(wo,C6),e(C6,BYe),e(C6,Gre),e(Gre,IYe),e(C6,qYe),e(wo,NYe),e(wo,Cr),M(w6,Cr,null),e(Cr,jYe),e(Cr,Ore),e(Ore,DYe),e(Cr,GYe),e(Cr,Aa),e(Aa,OYe),e(Aa,Vre),e(Vre,VYe),e(Aa,XYe),e(Aa,Xre),e(Xre,zYe),e(Aa,WYe),e(Aa,zre),e(zre,QYe),e(Aa,HYe),e(Cr,UYe),e(Cr,k),e(k,Sn),e(Sn,Wre),e(Wre,JYe),e(Sn,YYe),e(Sn,IS),e(IS,KYe),e(Sn,ZYe),e(Sn,qS),e(qS,eKe),e(Sn,oKe),e(k,rKe),e(k,Rn),e(Rn,Qre),e(Qre,tKe),e(Rn,aKe),e(Rn,NS),e(NS,nKe),e(Rn,sKe),e(Rn,jS),e(jS,lKe),e(Rn,iKe),e(k,dKe),e(k,Pn),e(Pn,Hre),e(Hre,cKe),e(Pn,fKe),e(Pn,DS),e(DS,mKe),e(Pn,gKe),e(Pn,GS),e(GS,hKe),e(Pn,pKe),e(k,_Ke),e(k,Mg),e(Mg,Ure),e(Ure,uKe),e(Mg,bKe),e(Mg,OS),e(OS,vKe),e(Mg,FKe),e(k,TKe),e(k,Bn),e(Bn,Jre),e(Jre,MKe),e(Bn,EKe),e(Bn,VS),e(VS,CKe),e(Bn,wKe),e(Bn,XS),e(XS,AKe),e(Bn,yKe),e(k,LKe),e(k,Eg),e(Eg,Yre),e(Yre,xKe),e(Eg,$Ke),e(Eg,zS),e(zS,kKe),e(Eg,SKe),e(k,RKe),e(k,Cg),e(Cg,Kre),e(Kre,PKe),e(Cg,BKe),e(Cg,WS),e(WS,IKe),e(Cg,qKe),e(k,NKe),e(k,wg),e(wg,Zre),e(Zre,jKe),e(wg,DKe),e(wg,QS),e(QS,GKe),e(wg,OKe),e(k,VKe),e(k,In),e(In,ete),e(ete,XKe),e(In,zKe),e(In,HS),e(HS,WKe),e(In,QKe),e(In,US),e(US,HKe),e(In,UKe),e(k,JKe),e(k,qn),e(qn,ote),e(ote,YKe),e(qn,KKe),e(qn,JS),e(JS,ZKe),e(qn,eZe),e(qn,YS),e(YS,oZe),e(qn,rZe),e(k,tZe),e(k,Nn),e(Nn,rte),e(rte,aZe),e(Nn,nZe),e(Nn,KS),e(KS,sZe),e(Nn,lZe),e(Nn,ZS),e(ZS,iZe),e(Nn,dZe),e(k,cZe),e(k,Ag),e(Ag,tte),e(tte,fZe),e(Ag,mZe),e(Ag,eR),e(eR,gZe),e(Ag,hZe),e(k,pZe),e(k,yg),e(yg,ate),e(ate,_Ze),e(yg,uZe),e(yg,oR),e(oR,bZe),e(yg,vZe),e(k,FZe),e(k,jn),e(jn,nte),e(nte,TZe),e(jn,MZe),e(jn,rR),e(rR,EZe),e(jn,CZe),e(jn,tR),e(tR,wZe),e(jn,AZe),e(k,yZe),e(k,Lg),e(Lg,ste),e(ste,LZe),e(Lg,xZe),e(Lg,aR),e(aR,$Ze),e(Lg,kZe),e(k,SZe),e(k,Dn),e(Dn,lte),e(lte,RZe),e(Dn,PZe),e(Dn,nR),e(nR,BZe),e(Dn,IZe),e(Dn,sR),e(sR,qZe),e(Dn,NZe),e(k,jZe),e(k,Gn),e(Gn,ite),e(ite,DZe),e(Gn,GZe),e(Gn,lR),e(lR,OZe),e(Gn,VZe),e(Gn,iR),e(iR,XZe),e(Gn,zZe),e(k,WZe),e(k,On),e(On,dte),e(dte,QZe),e(On,HZe),e(On,dR),e(dR,UZe),e(On,JZe),e(On,cR),e(cR,YZe),e(On,KZe),e(k,ZZe),e(k,xg),e(xg,cte),e(cte,eeo),e(xg,oeo),e(xg,fR),e(fR,reo),e(xg,teo),e(k,aeo),e(k,Vn),e(Vn,fte),e(fte,neo),e(Vn,seo),e(Vn,mR),e(mR,leo),e(Vn,ieo),e(Vn,gR),e(gR,deo),e(Vn,ceo),e(k,feo),e(k,Xn),e(Xn,mte),e(mte,meo),e(Xn,geo),e(Xn,hR),e(hR,heo),e(Xn,peo),e(Xn,pR),e(pR,_eo),e(Xn,ueo),e(k,beo),e(k,zn),e(zn,gte),e(gte,veo),e(zn,Feo),e(zn,_R),e(_R,Teo),e(zn,Meo),e(zn,uR),e(uR,Eeo),e(zn,Ceo),e(k,weo),e(k,Wn),e(Wn,hte),e(hte,Aeo),e(Wn,yeo),e(Wn,bR),e(bR,Leo),e(Wn,xeo),e(Wn,vR),e(vR,$eo),e(Wn,keo),e(k,Seo),e(k,Qn),e(Qn,pte),e(pte,Reo),e(Qn,Peo),e(Qn,FR),e(FR,Beo),e(Qn,Ieo),e(Qn,TR),e(TR,qeo),e(Qn,Neo),e(k,jeo),e(k,Hn),e(Hn,_te),e(_te,Deo),e(Hn,Geo),e(Hn,MR),e(MR,Oeo),e(Hn,Veo),e(Hn,ER),e(ER,Xeo),e(Hn,zeo),e(k,Weo),e(k,$g),e($g,ute),e(ute,Qeo),e($g,Heo),e($g,CR),e(CR,Ueo),e($g,Jeo),e(k,Yeo),e(k,Un),e(Un,bte),e(bte,Keo),e(Un,Zeo),e(Un,wR),e(wR,eoo),e(Un,ooo),e(Un,AR),e(AR,roo),e(Un,too),e(k,aoo),e(k,kg),e(kg,vte),e(vte,noo),e(kg,soo),e(kg,yR),e(yR,loo),e(kg,ioo),e(k,doo),e(k,Jn),e(Jn,Fte),e(Fte,coo),e(Jn,foo),e(Jn,LR),e(LR,moo),e(Jn,goo),e(Jn,xR),e(xR,hoo),e(Jn,poo),e(k,_oo),e(k,Yn),e(Yn,Tte),e(Tte,uoo),e(Yn,boo),e(Yn,$R),e($R,voo),e(Yn,Foo),e(Yn,kR),e(kR,Too),e(Yn,Moo),e(k,Eoo),e(k,Kn),e(Kn,Mte),e(Mte,Coo),e(Kn,woo),e(Kn,SR),e(SR,Aoo),e(Kn,yoo),e(Kn,RR),e(RR,Loo),e(Kn,xoo),e(k,$oo),e(k,Zn),e(Zn,Ete),e(Ete,koo),e(Zn,Soo),e(Zn,PR),e(PR,Roo),e(Zn,Poo),e(Zn,BR),e(BR,Boo),e(Zn,Ioo),e(k,qoo),e(k,es),e(es,Cte),e(Cte,Noo),e(es,joo),e(es,IR),e(IR,Doo),e(es,Goo),e(es,qR),e(qR,Ooo),e(es,Voo),e(k,Xoo),e(k,Sg),e(Sg,wte),e(wte,zoo),e(Sg,Woo),e(Sg,NR),e(NR,Qoo),e(Sg,Hoo),e(k,Uoo),e(k,os),e(os,Ate),e(Ate,Joo),e(os,Yoo),e(os,jR),e(jR,Koo),e(os,Zoo),e(os,DR),e(DR,ero),e(os,oro),e(k,rro),e(k,rs),e(rs,yte),e(yte,tro),e(rs,aro),e(rs,GR),e(GR,nro),e(rs,sro),e(rs,OR),e(OR,lro),e(rs,iro),e(k,dro),e(k,ts),e(ts,Lte),e(Lte,cro),e(ts,fro),e(ts,VR),e(VR,mro),e(ts,gro),e(ts,XR),e(XR,hro),e(ts,pro),e(k,_ro),e(k,as),e(as,xte),e(xte,uro),e(as,bro),e(as,zR),e(zR,vro),e(as,Fro),e(as,WR),e(WR,Tro),e(as,Mro),e(k,Ero),e(k,ns),e(ns,$te),e($te,Cro),e(ns,wro),e(ns,QR),e(QR,Aro),e(ns,yro),e(ns,HR),e(HR,Lro),e(ns,xro),e(k,$ro),e(k,ss),e(ss,kte),e(kte,kro),e(ss,Sro),e(ss,UR),e(UR,Rro),e(ss,Pro),e(ss,JR),e(JR,Bro),e(ss,Iro),e(k,qro),e(k,Rg),e(Rg,Ste),e(Ste,Nro),e(Rg,jro),e(Rg,YR),e(YR,Dro),e(Rg,Gro),e(k,Oro),e(k,ls),e(ls,Rte),e(Rte,Vro),e(ls,Xro),e(ls,KR),e(KR,zro),e(ls,Wro),e(ls,ZR),e(ZR,Qro),e(ls,Hro),e(k,Uro),e(k,Pg),e(Pg,Pte),e(Pte,Jro),e(Pg,Yro),e(Pg,eP),e(eP,Kro),e(Pg,Zro),e(k,eto),e(k,Bg),e(Bg,Bte),e(Bte,oto),e(Bg,rto),e(Bg,oP),e(oP,tto),e(Bg,ato),e(k,nto),e(k,is),e(is,Ite),e(Ite,sto),e(is,lto),e(is,rP),e(rP,ito),e(is,dto),e(is,tP),e(tP,cto),e(is,fto),e(k,mto),e(k,ds),e(ds,qte),e(qte,gto),e(ds,hto),e(ds,aP),e(aP,pto),e(ds,_to),e(ds,nP),e(nP,uto),e(ds,bto),e(k,vto),e(k,cs),e(cs,Nte),e(Nte,Fto),e(cs,Tto),e(cs,sP),e(sP,Mto),e(cs,Eto),e(cs,lP),e(lP,Cto),e(cs,wto),e(k,Ato),e(k,Ig),e(Ig,jte),e(jte,yto),e(Ig,Lto),e(Ig,iP),e(iP,xto),e(Ig,$to),e(k,kto),e(k,fs),e(fs,Dte),e(Dte,Sto),e(fs,Rto),e(fs,dP),e(dP,Pto),e(fs,Bto),e(fs,cP),e(cP,Ito),e(fs,qto),e(k,Nto),e(k,ms),e(ms,Gte),e(Gte,jto),e(ms,Dto),e(ms,fP),e(fP,Gto),e(ms,Oto),e(ms,mP),e(mP,Vto),e(ms,Xto),e(k,zto),e(k,gs),e(gs,Ote),e(Ote,Wto),e(gs,Qto),e(gs,gP),e(gP,Hto),e(gs,Uto),e(gs,hP),e(hP,Jto),e(gs,Yto),e(k,Kto),e(k,hs),e(hs,Vte),e(Vte,Zto),e(hs,eao),e(hs,pP),e(pP,oao),e(hs,rao),e(hs,_P),e(_P,tao),e(hs,aao),e(k,nao),e(k,ps),e(ps,Xte),e(Xte,sao),e(ps,lao),e(ps,uP),e(uP,iao),e(ps,dao),e(ps,bP),e(bP,cao),e(ps,fao),e(k,mao),e(k,qg),e(qg,zte),e(zte,gao),e(qg,hao),e(qg,vP),e(vP,pao),e(qg,_ao),e(k,uao),e(k,_s),e(_s,Wte),e(Wte,bao),e(_s,vao),e(_s,FP),e(FP,Fao),e(_s,Tao),e(_s,TP),e(TP,Mao),e(_s,Eao),e(k,Cao),e(k,Ng),e(Ng,Qte),e(Qte,wao),e(Ng,Aao),e(Ng,MP),e(MP,yao),e(Ng,Lao),e(k,xao),e(k,jg),e(jg,Hte),e(Hte,$ao),e(jg,kao),e(jg,EP),e(EP,Sao),e(jg,Rao),e(k,Pao),e(k,Dg),e(Dg,Ute),e(Ute,Bao),e(Dg,Iao),e(Dg,CP),e(CP,qao),e(Dg,Nao),e(k,jao),e(k,Gg),e(Gg,Jte),e(Jte,Dao),e(Gg,Gao),e(Gg,wP),e(wP,Oao),e(Gg,Vao),e(k,Xao),e(k,us),e(us,Yte),e(Yte,zao),e(us,Wao),e(us,AP),e(AP,Qao),e(us,Hao),e(us,yP),e(yP,Uao),e(us,Jao),e(k,Yao),e(k,Og),e(Og,Kte),e(Kte,Kao),e(Og,Zao),e(Og,LP),e(LP,eno),e(Og,ono),e(k,rno),e(k,bs),e(bs,Zte),e(Zte,tno),e(bs,ano),e(bs,xP),e(xP,nno),e(bs,sno),e(bs,$P),e($P,lno),e(bs,ino),e(k,dno),e(k,vs),e(vs,eae),e(eae,cno),e(vs,fno),e(vs,kP),e(kP,mno),e(vs,gno),e(vs,SP),e(SP,hno),e(vs,pno),e(k,_no),e(k,Fs),e(Fs,oae),e(oae,uno),e(Fs,bno),e(Fs,RP),e(RP,vno),e(Fs,Fno),e(Fs,PP),e(PP,Tno),e(Fs,Mno),e(k,Eno),e(k,Ts),e(Ts,rae),e(rae,Cno),e(Ts,wno),e(Ts,BP),e(BP,Ano),e(Ts,yno),e(Ts,IP),e(IP,Lno),e(Ts,xno),e(k,$no),e(k,Ms),e(Ms,tae),e(tae,kno),e(Ms,Sno),e(Ms,qP),e(qP,Rno),e(Ms,Pno),e(Ms,NP),e(NP,Bno),e(Ms,Ino),e(k,qno),e(k,Es),e(Es,aae),e(aae,Nno),e(Es,jno),e(Es,jP),e(jP,Dno),e(Es,Gno),e(Es,DP),e(DP,Ono),e(Es,Vno),e(k,Xno),e(k,Vg),e(Vg,nae),e(nae,zno),e(Vg,Wno),e(Vg,GP),e(GP,Qno),e(Vg,Hno),e(k,Uno),e(k,Xg),e(Xg,sae),e(sae,Jno),e(Xg,Yno),e(Xg,OP),e(OP,Kno),e(Xg,Zno),e(k,eso),e(k,Cs),e(Cs,lae),e(lae,oso),e(Cs,rso),e(Cs,VP),e(VP,tso),e(Cs,aso),e(Cs,XP),e(XP,nso),e(Cs,sso),e(k,lso),e(k,ws),e(ws,iae),e(iae,iso),e(ws,dso),e(ws,zP),e(zP,cso),e(ws,fso),e(ws,WP),e(WP,mso),e(ws,gso),e(k,hso),e(k,As),e(As,dae),e(dae,pso),e(As,_so),e(As,QP),e(QP,uso),e(As,bso),e(As,HP),e(HP,vso),e(As,Fso),e(k,Tso),e(k,zg),e(zg,cae),e(cae,Mso),e(zg,Eso),e(zg,UP),e(UP,Cso),e(zg,wso),e(k,Aso),e(k,Wg),e(Wg,fae),e(fae,yso),e(Wg,Lso),e(Wg,JP),e(JP,xso),e(Wg,$so),e(k,kso),e(k,Qg),e(Qg,mae),e(mae,Sso),e(Qg,Rso),e(Qg,YP),e(YP,Pso),e(Qg,Bso),e(k,Iso),e(k,ys),e(ys,gae),e(gae,qso),e(ys,Nso),e(ys,KP),e(KP,jso),e(ys,Dso),e(ys,ZP),e(ZP,Gso),e(ys,Oso),e(k,Vso),e(k,Hg),e(Hg,hae),e(hae,Xso),e(Hg,zso),e(Hg,eB),e(eB,Wso),e(Hg,Qso),e(k,Hso),e(k,Ug),e(Ug,pae),e(pae,Uso),e(Ug,Jso),e(Ug,oB),e(oB,Yso),e(Ug,Kso),e(k,Zso),e(k,Jg),e(Jg,_ae),e(_ae,elo),e(Jg,olo),e(Jg,rB),e(rB,rlo),e(Jg,tlo),e(k,alo),e(k,Ls),e(Ls,uae),e(uae,nlo),e(Ls,slo),e(Ls,tB),e(tB,llo),e(Ls,ilo),e(Ls,aB),e(aB,dlo),e(Ls,clo),e(k,flo),e(k,Yg),e(Yg,bae),e(bae,mlo),e(Yg,glo),e(Yg,nB),e(nB,hlo),e(Yg,plo),e(k,_lo),e(k,Kg),e(Kg,vae),e(vae,ulo),e(Kg,blo),e(Kg,sB),e(sB,vlo),e(Kg,Flo),e(k,Tlo),e(k,xs),e(xs,Fae),e(Fae,Mlo),e(xs,Elo),e(xs,lB),e(lB,Clo),e(xs,wlo),e(xs,iB),e(iB,Alo),e(xs,ylo),e(k,Llo),e(k,$s),e($s,Tae),e(Tae,xlo),e($s,$lo),e($s,dB),e(dB,klo),e($s,Slo),e($s,cB),e(cB,Rlo),e($s,Plo),e(k,Blo),e(k,ks),e(ks,Mae),e(Mae,Ilo),e(ks,qlo),e(ks,fB),e(fB,Nlo),e(ks,jlo),e(ks,mB),e(mB,Dlo),e(ks,Glo),e(k,Olo),e(k,Ss),e(Ss,Eae),e(Eae,Vlo),e(Ss,Xlo),e(Ss,gB),e(gB,zlo),e(Ss,Wlo),e(Ss,hB),e(hB,Qlo),e(Ss,Hlo),e(Cr,Ulo),M(Zg,Cr,null),e(wo,Jlo),e(wo,eh),M(A6,eh,null),e(eh,Ylo),e(eh,Cae),e(Cae,Klo),b(f,aqe,u),b(f,Ti,u),e(Ti,oh),e(oh,wae),M(y6,wae,null),e(Ti,Zlo),e(Ti,Aae),e(Aae,eio),b(f,nqe,u),b(f,Ao,u),M(L6,Ao,null),e(Ao,oio),e(Ao,x6),e(x6,rio),e(x6,pB),e(pB,tio),e(x6,aio),e(Ao,nio),e(Ao,$6),e($6,sio),e($6,yae),e(yae,lio),e($6,iio),e(Ao,dio),e(Ao,He),M(k6,He,null),e(He,cio),e(He,Lae),e(Lae,fio),e(He,mio),e(He,ya),e(ya,gio),e(ya,xae),e(xae,hio),e(ya,pio),e(ya,$ae),e($ae,_io),e(ya,uio),e(ya,kae),e(kae,bio),e(ya,vio),e(He,Fio),e(He,Z),e(Z,rh),e(rh,Sae),e(Sae,Tio),e(rh,Mio),e(rh,_B),e(_B,Eio),e(rh,Cio),e(Z,wio),e(Z,th),e(th,Rae),e(Rae,Aio),e(th,yio),e(th,uB),e(uB,Lio),e(th,xio),e(Z,$io),e(Z,ah),e(ah,Pae),e(Pae,kio),e(ah,Sio),e(ah,bB),e(bB,Rio),e(ah,Pio),e(Z,Bio),e(Z,nh),e(nh,Bae),e(Bae,Iio),e(nh,qio),e(nh,vB),e(vB,Nio),e(nh,jio),e(Z,Dio),e(Z,sh),e(sh,Iae),e(Iae,Gio),e(sh,Oio),e(sh,FB),e(FB,Vio),e(sh,Xio),e(Z,zio),e(Z,lh),e(lh,qae),e(qae,Wio),e(lh,Qio),e(lh,TB),e(TB,Hio),e(lh,Uio),e(Z,Jio),e(Z,ih),e(ih,Nae),e(Nae,Yio),e(ih,Kio),e(ih,MB),e(MB,Zio),e(ih,edo),e(Z,odo),e(Z,dh),e(dh,jae),e(jae,rdo),e(dh,tdo),e(dh,EB),e(EB,ado),e(dh,ndo),e(Z,sdo),e(Z,ch),e(ch,Dae),e(Dae,ldo),e(ch,ido),e(ch,CB),e(CB,ddo),e(ch,cdo),e(Z,fdo),e(Z,fh),e(fh,Gae),e(Gae,mdo),e(fh,gdo),e(fh,wB),e(wB,hdo),e(fh,pdo),e(Z,_do),e(Z,mh),e(mh,Oae),e(Oae,udo),e(mh,bdo),e(mh,AB),e(AB,vdo),e(mh,Fdo),e(Z,Tdo),e(Z,gh),e(gh,Vae),e(Vae,Mdo),e(gh,Edo),e(gh,yB),e(yB,Cdo),e(gh,wdo),e(Z,Ado),e(Z,hh),e(hh,Xae),e(Xae,ydo),e(hh,Ldo),e(hh,LB),e(LB,xdo),e(hh,$do),e(Z,kdo),e(Z,ph),e(ph,zae),e(zae,Sdo),e(ph,Rdo),e(ph,xB),e(xB,Pdo),e(ph,Bdo),e(Z,Ido),e(Z,_h),e(_h,Wae),e(Wae,qdo),e(_h,Ndo),e(_h,$B),e($B,jdo),e(_h,Ddo),e(Z,Gdo),e(Z,uh),e(uh,Qae),e(Qae,Odo),e(uh,Vdo),e(uh,kB),e(kB,Xdo),e(uh,zdo),e(Z,Wdo),e(Z,bh),e(bh,Hae),e(Hae,Qdo),e(bh,Hdo),e(bh,SB),e(SB,Udo),e(bh,Jdo),e(Z,Ydo),e(Z,vh),e(vh,Uae),e(Uae,Kdo),e(vh,Zdo),e(vh,RB),e(RB,eco),e(vh,oco),e(Z,rco),e(Z,Fh),e(Fh,Jae),e(Jae,tco),e(Fh,aco),e(Fh,PB),e(PB,nco),e(Fh,sco),e(Z,lco),e(Z,Th),e(Th,Yae),e(Yae,ico),e(Th,dco),e(Th,BB),e(BB,cco),e(Th,fco),e(Z,mco),e(Z,Mh),e(Mh,Kae),e(Kae,gco),e(Mh,hco),e(Mh,IB),e(IB,pco),e(Mh,_co),e(Z,uco),e(Z,Eh),e(Eh,Zae),e(Zae,bco),e(Eh,vco),e(Eh,qB),e(qB,Fco),e(Eh,Tco),e(Z,Mco),e(Z,Ch),e(Ch,ene),e(ene,Eco),e(Ch,Cco),e(Ch,NB),e(NB,wco),e(Ch,Aco),e(Z,yco),e(Z,wh),e(wh,one),e(one,Lco),e(wh,xco),e(wh,jB),e(jB,$co),e(wh,kco),e(Z,Sco),e(Z,Ah),e(Ah,rne),e(rne,Rco),e(Ah,Pco),e(Ah,DB),e(DB,Bco),e(Ah,Ico),e(Z,qco),e(Z,yh),e(yh,tne),e(tne,Nco),e(yh,jco),e(yh,GB),e(GB,Dco),e(yh,Gco),e(He,Oco),M(Lh,He,null),e(He,Vco),M(xh,He,null),e(Ao,Xco),e(Ao,$h),M(S6,$h,null),e($h,zco),e($h,ane),e(ane,Wco),b(f,sqe,u),b(f,Mi,u),e(Mi,kh),e(kh,nne),M(R6,nne,null),e(Mi,Qco),e(Mi,sne),e(sne,Hco),b(f,lqe,u),b(f,yo,u),M(P6,yo,null),e(yo,Uco),e(yo,B6),e(B6,Jco),e(B6,OB),e(OB,Yco),e(B6,Kco),e(yo,Zco),e(yo,I6),e(I6,efo),e(I6,lne),e(lne,ofo),e(I6,rfo),e(yo,tfo),e(yo,Ue),M(q6,Ue,null),e(Ue,afo),e(Ue,ine),e(ine,nfo),e(Ue,sfo),e(Ue,Ei),e(Ei,lfo),e(Ei,dne),e(dne,ifo),e(Ei,dfo),e(Ei,cne),e(cne,cfo),e(Ei,ffo),e(Ue,mfo),e(Ue,pe),e(pe,Sh),e(Sh,fne),e(fne,gfo),e(Sh,hfo),e(Sh,VB),e(VB,pfo),e(Sh,_fo),e(pe,ufo),e(pe,Rh),e(Rh,mne),e(mne,bfo),e(Rh,vfo),e(Rh,gne),e(gne,Ffo),e(Rh,Tfo),e(pe,Mfo),e(pe,Ph),e(Ph,hne),e(hne,Efo),e(Ph,Cfo),e(Ph,XB),e(XB,wfo),e(Ph,Afo),e(pe,yfo),e(pe,Bh),e(Bh,pne),e(pne,Lfo),e(Bh,xfo),e(Bh,zB),e(zB,$fo),e(Bh,kfo),e(pe,Sfo),e(pe,Ih),e(Ih,_ne),e(_ne,Rfo),e(Ih,Pfo),e(Ih,WB),e(WB,Bfo),e(Ih,Ifo),e(pe,qfo),e(pe,qh),e(qh,une),e(une,Nfo),e(qh,jfo),e(qh,QB),e(QB,Dfo),e(qh,Gfo),e(pe,Ofo),e(pe,Nh),e(Nh,bne),e(bne,Vfo),e(Nh,Xfo),e(Nh,HB),e(HB,zfo),e(Nh,Wfo),e(pe,Qfo),e(pe,jh),e(jh,vne),e(vne,Hfo),e(jh,Ufo),e(jh,UB),e(UB,Jfo),e(jh,Yfo),e(pe,Kfo),e(pe,Dh),e(Dh,Fne),e(Fne,Zfo),e(Dh,emo),e(Dh,JB),e(JB,omo),e(Dh,rmo),e(pe,tmo),e(pe,Gh),e(Gh,Tne),e(Tne,amo),e(Gh,nmo),e(Gh,YB),e(YB,smo),e(Gh,lmo),e(pe,imo),e(pe,Oh),e(Oh,Mne),e(Mne,dmo),e(Oh,cmo),e(Oh,KB),e(KB,fmo),e(Oh,mmo),e(pe,gmo),e(pe,Vh),e(Vh,Ene),e(Ene,hmo),e(Vh,pmo),e(Vh,ZB),e(ZB,_mo),e(Vh,umo),e(pe,bmo),e(pe,Xh),e(Xh,Cne),e(Cne,vmo),e(Xh,Fmo),e(Xh,eI),e(eI,Tmo),e(Xh,Mmo),e(pe,Emo),e(pe,zh),e(zh,wne),e(wne,Cmo),e(zh,wmo),e(zh,oI),e(oI,Amo),e(zh,ymo),e(pe,Lmo),e(pe,Wh),e(Wh,Ane),e(Ane,xmo),e(Wh,$mo),e(Wh,rI),e(rI,kmo),e(Wh,Smo),e(pe,Rmo),e(pe,Qh),e(Qh,yne),e(yne,Pmo),e(Qh,Bmo),e(Qh,tI),e(tI,Imo),e(Qh,qmo),e(Ue,Nmo),M(Hh,Ue,null),e(Ue,jmo),M(Uh,Ue,null),e(yo,Dmo),e(yo,Jh),M(N6,Jh,null),e(Jh,Gmo),e(Jh,Lne),e(Lne,Omo),b(f,iqe,u),b(f,Ci,u),e(Ci,Yh),e(Yh,xne),M(j6,xne,null),e(Ci,Vmo),e(Ci,$ne),e($ne,Xmo),b(f,dqe,u),b(f,Lo,u),M(D6,Lo,null),e(Lo,zmo),e(Lo,wi),e(wi,Wmo),e(wi,aI),e(aI,Qmo),e(wi,Hmo),e(wi,nI),e(nI,Umo),e(wi,Jmo),e(Lo,Ymo),e(Lo,G6),e(G6,Kmo),e(G6,kne),e(kne,Zmo),e(G6,ego),e(Lo,ogo),e(Lo,tt),M(O6,tt,null),e(tt,rgo),e(tt,Sne),e(Sne,tgo),e(tt,ago),e(tt,Ai),e(Ai,ngo),e(Ai,Rne),e(Rne,sgo),e(Ai,lgo),e(Ai,sI),e(sI,igo),e(Ai,dgo),e(tt,cgo),M(Kh,tt,null),e(Lo,fgo),e(Lo,Je),M(V6,Je,null),e(Je,mgo),e(Je,Pne),e(Pne,ggo),e(Je,hgo),e(Je,La),e(La,pgo),e(La,Bne),e(Bne,_go),e(La,ugo),e(La,Ine),e(Ine,bgo),e(La,vgo),e(La,qne),e(qne,Fgo),e(La,Tgo),e(Je,Mgo),e(Je,x),e(x,Zh),e(Zh,Nne),e(Nne,Ego),e(Zh,Cgo),e(Zh,lI),e(lI,wgo),e(Zh,Ago),e(x,ygo),e(x,ep),e(ep,jne),e(jne,Lgo),e(ep,xgo),e(ep,iI),e(iI,$go),e(ep,kgo),e(x,Sgo),e(x,op),e(op,Dne),e(Dne,Rgo),e(op,Pgo),e(op,dI),e(dI,Bgo),e(op,Igo),e(x,qgo),e(x,rp),e(rp,Gne),e(Gne,Ngo),e(rp,jgo),e(rp,cI),e(cI,Dgo),e(rp,Ggo),e(x,Ogo),e(x,tp),e(tp,One),e(One,Vgo),e(tp,Xgo),e(tp,fI),e(fI,zgo),e(tp,Wgo),e(x,Qgo),e(x,ap),e(ap,Vne),e(Vne,Hgo),e(ap,Ugo),e(ap,mI),e(mI,Jgo),e(ap,Ygo),e(x,Kgo),e(x,np),e(np,Xne),e(Xne,Zgo),e(np,eho),e(np,gI),e(gI,oho),e(np,rho),e(x,tho),e(x,sp),e(sp,zne),e(zne,aho),e(sp,nho),e(sp,hI),e(hI,sho),e(sp,lho),e(x,iho),e(x,lp),e(lp,Wne),e(Wne,dho),e(lp,cho),e(lp,pI),e(pI,fho),e(lp,mho),e(x,gho),e(x,ip),e(ip,Qne),e(Qne,hho),e(ip,pho),e(ip,_I),e(_I,_ho),e(ip,uho),e(x,bho),e(x,dp),e(dp,Hne),e(Hne,vho),e(dp,Fho),e(dp,uI),e(uI,Tho),e(dp,Mho),e(x,Eho),e(x,cp),e(cp,Une),e(Une,Cho),e(cp,who),e(cp,bI),e(bI,Aho),e(cp,yho),e(x,Lho),e(x,fp),e(fp,Jne),e(Jne,xho),e(fp,$ho),e(fp,vI),e(vI,kho),e(fp,Sho),e(x,Rho),e(x,mp),e(mp,Yne),e(Yne,Pho),e(mp,Bho),e(mp,FI),e(FI,Iho),e(mp,qho),e(x,Nho),e(x,gp),e(gp,Kne),e(Kne,jho),e(gp,Dho),e(gp,TI),e(TI,Gho),e(gp,Oho),e(x,Vho),e(x,hp),e(hp,Zne),e(Zne,Xho),e(hp,zho),e(hp,MI),e(MI,Who),e(hp,Qho),e(x,Hho),e(x,pp),e(pp,ese),e(ese,Uho),e(pp,Jho),e(pp,EI),e(EI,Yho),e(pp,Kho),e(x,Zho),e(x,_p),e(_p,ose),e(ose,epo),e(_p,opo),e(_p,CI),e(CI,rpo),e(_p,tpo),e(x,apo),e(x,up),e(up,rse),e(rse,npo),e(up,spo),e(up,wI),e(wI,lpo),e(up,ipo),e(x,dpo),e(x,bp),e(bp,tse),e(tse,cpo),e(bp,fpo),e(bp,AI),e(AI,mpo),e(bp,gpo),e(x,hpo),e(x,vp),e(vp,ase),e(ase,ppo),e(vp,_po),e(vp,yI),e(yI,upo),e(vp,bpo),e(x,vpo),e(x,Fp),e(Fp,nse),e(nse,Fpo),e(Fp,Tpo),e(Fp,LI),e(LI,Mpo),e(Fp,Epo),e(x,Cpo),e(x,Tp),e(Tp,sse),e(sse,wpo),e(Tp,Apo),e(Tp,xI),e(xI,ypo),e(Tp,Lpo),e(x,xpo),e(x,Mp),e(Mp,lse),e(lse,$po),e(Mp,kpo),e(Mp,$I),e($I,Spo),e(Mp,Rpo),e(x,Ppo),e(x,Ep),e(Ep,ise),e(ise,Bpo),e(Ep,Ipo),e(Ep,kI),e(kI,qpo),e(Ep,Npo),e(x,jpo),e(x,Cp),e(Cp,dse),e(dse,Dpo),e(Cp,Gpo),e(Cp,SI),e(SI,Opo),e(Cp,Vpo),e(x,Xpo),e(x,wp),e(wp,cse),e(cse,zpo),e(wp,Wpo),e(wp,RI),e(RI,Qpo),e(wp,Hpo),e(x,Upo),e(x,Ap),e(Ap,fse),e(fse,Jpo),e(Ap,Ypo),e(Ap,PI),e(PI,Kpo),e(Ap,Zpo),e(x,e_o),e(x,yp),e(yp,mse),e(mse,o_o),e(yp,r_o),e(yp,BI),e(BI,t_o),e(yp,a_o),e(x,n_o),e(x,Lp),e(Lp,gse),e(gse,s_o),e(Lp,l_o),e(Lp,II),e(II,i_o),e(Lp,d_o),e(x,c_o),e(x,xp),e(xp,hse),e(hse,f_o),e(xp,m_o),e(xp,qI),e(qI,g_o),e(xp,h_o),e(x,p_o),e(x,Rs),e(Rs,pse),e(pse,__o),e(Rs,u_o),e(Rs,NI),e(NI,b_o),e(Rs,v_o),e(Rs,jI),e(jI,F_o),e(Rs,T_o),e(x,M_o),e(x,$p),e($p,_se),e(_se,E_o),e($p,C_o),e($p,DI),e(DI,w_o),e($p,A_o),e(x,y_o),e(x,kp),e(kp,use),e(use,L_o),e(kp,x_o),e(kp,GI),e(GI,$_o),e(kp,k_o),e(x,S_o),e(x,Sp),e(Sp,bse),e(bse,R_o),e(Sp,P_o),e(Sp,OI),e(OI,B_o),e(Sp,I_o),e(x,q_o),e(x,Rp),e(Rp,vse),e(vse,N_o),e(Rp,j_o),e(Rp,VI),e(VI,D_o),e(Rp,G_o),e(x,O_o),e(x,Pp),e(Pp,Fse),e(Fse,V_o),e(Pp,X_o),e(Pp,XI),e(XI,z_o),e(Pp,W_o),e(x,Q_o),e(x,Bp),e(Bp,Tse),e(Tse,H_o),e(Bp,U_o),e(Bp,zI),e(zI,J_o),e(Bp,Y_o),e(x,K_o),e(x,Ip),e(Ip,Mse),e(Mse,Z_o),e(Ip,euo),e(Ip,WI),e(WI,ouo),e(Ip,ruo),e(x,tuo),e(x,qp),e(qp,Ese),e(Ese,auo),e(qp,nuo),e(qp,QI),e(QI,suo),e(qp,luo),e(x,iuo),e(x,Np),e(Np,Cse),e(Cse,duo),e(Np,cuo),e(Np,HI),e(HI,fuo),e(Np,muo),e(x,guo),e(x,jp),e(jp,wse),e(wse,huo),e(jp,puo),e(jp,UI),e(UI,_uo),e(jp,uuo),e(x,buo),e(x,Dp),e(Dp,Ase),e(Ase,vuo),e(Dp,Fuo),e(Dp,JI),e(JI,Tuo),e(Dp,Muo),e(x,Euo),e(x,Gp),e(Gp,yse),e(yse,Cuo),e(Gp,wuo),e(Gp,YI),e(YI,Auo),e(Gp,yuo),e(x,Luo),e(x,Op),e(Op,Lse),e(Lse,xuo),e(Op,$uo),e(Op,KI),e(KI,kuo),e(Op,Suo),e(x,Ruo),e(x,Vp),e(Vp,xse),e(xse,Puo),e(Vp,Buo),e(Vp,ZI),e(ZI,Iuo),e(Vp,quo),e(x,Nuo),e(x,Xp),e(Xp,$se),e($se,juo),e(Xp,Duo),e(Xp,eq),e(eq,Guo),e(Xp,Ouo),e(x,Vuo),e(x,zp),e(zp,kse),e(kse,Xuo),e(zp,zuo),e(zp,oq),e(oq,Wuo),e(zp,Quo),e(x,Huo),e(x,Wp),e(Wp,Sse),e(Sse,Uuo),e(Wp,Juo),e(Wp,rq),e(rq,Yuo),e(Wp,Kuo),e(x,Zuo),e(x,Qp),e(Qp,Rse),e(Rse,e2o),e(Qp,o2o),e(Qp,tq),e(tq,r2o),e(Qp,t2o),e(x,a2o),e(x,Hp),e(Hp,Pse),e(Pse,n2o),e(Hp,s2o),e(Hp,aq),e(aq,l2o),e(Hp,i2o),e(x,d2o),e(x,Up),e(Up,Bse),e(Bse,c2o),e(Up,f2o),e(Up,nq),e(nq,m2o),e(Up,g2o),e(x,h2o),e(x,Jp),e(Jp,Ise),e(Ise,p2o),e(Jp,_2o),e(Jp,sq),e(sq,u2o),e(Jp,b2o),e(x,v2o),e(x,Yp),e(Yp,qse),e(qse,F2o),e(Yp,T2o),e(Yp,lq),e(lq,M2o),e(Yp,E2o),e(x,C2o),e(x,Kp),e(Kp,Nse),e(Nse,w2o),e(Kp,A2o),e(Kp,iq),e(iq,y2o),e(Kp,L2o),e(x,x2o),e(x,Zp),e(Zp,jse),e(jse,$2o),e(Zp,k2o),e(Zp,dq),e(dq,S2o),e(Zp,R2o),e(x,P2o),e(x,e_),e(e_,Dse),e(Dse,B2o),e(e_,I2o),e(e_,cq),e(cq,q2o),e(e_,N2o),e(x,j2o),e(x,o_),e(o_,Gse),e(Gse,D2o),e(o_,G2o),e(o_,fq),e(fq,O2o),e(o_,V2o),e(x,X2o),e(x,r_),e(r_,Ose),e(Ose,z2o),e(r_,W2o),e(r_,mq),e(mq,Q2o),e(r_,H2o),e(x,U2o),e(x,t_),e(t_,Vse),e(Vse,J2o),e(t_,Y2o),e(t_,gq),e(gq,K2o),e(t_,Z2o),e(x,e1o),e(x,a_),e(a_,Xse),e(Xse,o1o),e(a_,r1o),e(a_,hq),e(hq,t1o),e(a_,a1o),e(x,n1o),e(x,n_),e(n_,zse),e(zse,s1o),e(n_,l1o),e(n_,pq),e(pq,i1o),e(n_,d1o),e(x,c1o),e(x,s_),e(s_,Wse),e(Wse,f1o),e(s_,m1o),e(s_,_q),e(_q,g1o),e(s_,h1o),e(x,p1o),e(x,l_),e(l_,Qse),e(Qse,_1o),e(l_,u1o),e(l_,uq),e(uq,b1o),e(l_,v1o),e(x,F1o),e(x,i_),e(i_,Hse),e(Hse,T1o),e(i_,M1o),e(i_,bq),e(bq,E1o),e(i_,C1o),e(x,w1o),e(x,d_),e(d_,Use),e(Use,A1o),e(d_,y1o),e(d_,vq),e(vq,L1o),e(d_,x1o),e(x,$1o),e(x,c_),e(c_,Jse),e(Jse,k1o),e(c_,S1o),e(c_,Fq),e(Fq,R1o),e(c_,P1o),e(x,B1o),e(x,f_),e(f_,Yse),e(Yse,I1o),e(f_,q1o),e(f_,Tq),e(Tq,N1o),e(f_,j1o),e(x,D1o),e(x,m_),e(m_,Kse),e(Kse,G1o),e(m_,O1o),e(m_,Mq),e(Mq,V1o),e(m_,X1o),e(x,z1o),e(x,g_),e(g_,Zse),e(Zse,W1o),e(g_,Q1o),e(g_,Eq),e(Eq,H1o),e(g_,U1o),e(x,J1o),e(x,h_),e(h_,ele),e(ele,Y1o),e(h_,K1o),e(h_,Cq),e(Cq,Z1o),e(h_,e7o),e(x,o7o),e(x,p_),e(p_,ole),e(ole,r7o),e(p_,t7o),e(p_,wq),e(wq,a7o),e(p_,n7o),e(x,s7o),e(x,__),e(__,rle),e(rle,l7o),e(__,i7o),e(__,Aq),e(Aq,d7o),e(__,c7o),e(x,f7o),e(x,u_),e(u_,tle),e(tle,m7o),e(u_,g7o),e(u_,yq),e(yq,h7o),e(u_,p7o),e(x,_7o),e(x,b_),e(b_,ale),e(ale,u7o),e(b_,b7o),e(b_,Lq),e(Lq,v7o),e(b_,F7o),e(x,T7o),e(x,v_),e(v_,nle),e(nle,M7o),e(v_,E7o),e(v_,xq),e(xq,C7o),e(v_,w7o),e(x,A7o),e(x,F_),e(F_,sle),e(sle,y7o),e(F_,L7o),e(F_,$q),e($q,x7o),e(F_,$7o),e(x,k7o),e(x,T_),e(T_,lle),e(lle,S7o),e(T_,R7o),e(T_,kq),e(kq,P7o),e(T_,B7o),e(x,I7o),e(x,M_),e(M_,ile),e(ile,q7o),e(M_,N7o),e(M_,Sq),e(Sq,j7o),e(M_,D7o),e(x,G7o),e(x,E_),e(E_,dle),e(dle,O7o),e(E_,V7o),e(E_,Rq),e(Rq,X7o),e(E_,z7o),e(x,W7o),e(x,C_),e(C_,cle),e(cle,Q7o),e(C_,H7o),e(C_,Pq),e(Pq,U7o),e(C_,J7o),e(x,Y7o),e(x,w_),e(w_,fle),e(fle,K7o),e(w_,Z7o),e(w_,Bq),e(Bq,ebo),e(w_,obo),e(x,rbo),e(x,A_),e(A_,mle),e(mle,tbo),e(A_,abo),e(A_,Iq),e(Iq,nbo),e(A_,sbo),e(x,lbo),e(x,y_),e(y_,gle),e(gle,ibo),e(y_,dbo),e(y_,qq),e(qq,cbo),e(y_,fbo),e(x,mbo),e(x,L_),e(L_,hle),e(hle,gbo),e(L_,hbo),e(L_,Nq),e(Nq,pbo),e(L_,_bo),e(x,ubo),e(x,x_),e(x_,ple),e(ple,bbo),e(x_,vbo),e(x_,jq),e(jq,Fbo),e(x_,Tbo),e(x,Mbo),e(x,$_),e($_,_le),e(_le,Ebo),e($_,Cbo),e($_,Dq),e(Dq,wbo),e($_,Abo),e(x,ybo),e(x,k_),e(k_,ule),e(ule,Lbo),e(k_,xbo),e(k_,Gq),e(Gq,$bo),e(k_,kbo),e(x,Sbo),e(x,S_),e(S_,ble),e(ble,Rbo),e(S_,Pbo),e(S_,Oq),e(Oq,Bbo),e(S_,Ibo),e(x,qbo),e(x,R_),e(R_,vle),e(vle,Nbo),e(R_,jbo),e(R_,Vq),e(Vq,Dbo),e(R_,Gbo),e(x,Obo),e(x,P_),e(P_,Fle),e(Fle,Vbo),e(P_,Xbo),e(P_,Xq),e(Xq,zbo),e(P_,Wbo),e(x,Qbo),e(x,B_),e(B_,Tle),e(Tle,Hbo),e(B_,Ubo),e(B_,zq),e(zq,Jbo),e(B_,Ybo),e(x,Kbo),e(x,I_),e(I_,Mle),e(Mle,Zbo),e(I_,evo),e(I_,Wq),e(Wq,ovo),e(I_,rvo),e(x,tvo),e(x,q_),e(q_,Ele),e(Ele,avo),e(q_,nvo),e(q_,Qq),e(Qq,svo),e(q_,lvo),e(x,ivo),e(x,N_),e(N_,Cle),e(Cle,dvo),e(N_,cvo),e(N_,Hq),e(Hq,fvo),e(N_,mvo),e(x,gvo),e(x,j_),e(j_,wle),e(wle,hvo),e(j_,pvo),e(j_,Uq),e(Uq,_vo),e(j_,uvo),e(x,bvo),e(x,D_),e(D_,Ale),e(Ale,vvo),e(D_,Fvo),e(D_,Jq),e(Jq,Tvo),e(D_,Mvo),e(x,Evo),e(x,G_),e(G_,yle),e(yle,Cvo),e(G_,wvo),e(G_,Yq),e(Yq,Avo),e(G_,yvo),e(x,Lvo),e(x,O_),e(O_,Lle),e(Lle,xvo),e(O_,$vo),e(O_,Kq),e(Kq,kvo),e(O_,Svo),e(Je,Rvo),e(Je,V_),e(V_,Pvo),e(V_,xle),e(xle,Bvo),e(V_,Ivo),e(V_,$le),e($le,qvo),e(Je,Nvo),M(X_,Je,null),b(f,cqe,u),b(f,yi,u),e(yi,z_),e(z_,kle),M(X6,kle,null),e(yi,jvo),e(yi,Sle),e(Sle,Dvo),b(f,fqe,u),b(f,xo,u),M(z6,xo,null),e(xo,Gvo),e(xo,Li),e(Li,Ovo),e(Li,Zq),e(Zq,Vvo),e(Li,Xvo),e(Li,eN),e(eN,zvo),e(Li,Wvo),e(xo,Qvo),e(xo,W6),e(W6,Hvo),e(W6,Rle),e(Rle,Uvo),e(W6,Jvo),e(xo,Yvo),e(xo,at),M(Q6,at,null),e(at,Kvo),e(at,Ple),e(Ple,Zvo),e(at,eFo),e(at,xi),e(xi,oFo),e(xi,Ble),e(Ble,rFo),e(xi,tFo),e(xi,oN),e(oN,aFo),e(xi,nFo),e(at,sFo),M(W_,at,null),e(xo,lFo),e(xo,Ye),M(H6,Ye,null),e(Ye,iFo),e(Ye,Ile),e(Ile,dFo),e(Ye,cFo),e(Ye,xa),e(xa,fFo),e(xa,qle),e(qle,mFo),e(xa,gFo),e(xa,Nle),e(Nle,hFo),e(xa,pFo),e(xa,jle),e(jle,_Fo),e(xa,uFo),e(Ye,bFo),e(Ye,G),e(G,Q_),e(Q_,Dle),e(Dle,vFo),e(Q_,FFo),e(Q_,rN),e(rN,TFo),e(Q_,MFo),e(G,EFo),e(G,H_),e(H_,Gle),e(Gle,CFo),e(H_,wFo),e(H_,tN),e(tN,AFo),e(H_,yFo),e(G,LFo),e(G,U_),e(U_,Ole),e(Ole,xFo),e(U_,$Fo),e(U_,aN),e(aN,kFo),e(U_,SFo),e(G,RFo),e(G,J_),e(J_,Vle),e(Vle,PFo),e(J_,BFo),e(J_,nN),e(nN,IFo),e(J_,qFo),e(G,NFo),e(G,Y_),e(Y_,Xle),e(Xle,jFo),e(Y_,DFo),e(Y_,sN),e(sN,GFo),e(Y_,OFo),e(G,VFo),e(G,K_),e(K_,zle),e(zle,XFo),e(K_,zFo),e(K_,lN),e(lN,WFo),e(K_,QFo),e(G,HFo),e(G,Z_),e(Z_,Wle),e(Wle,UFo),e(Z_,JFo),e(Z_,iN),e(iN,YFo),e(Z_,KFo),e(G,ZFo),e(G,eu),e(eu,Qle),e(Qle,eTo),e(eu,oTo),e(eu,dN),e(dN,rTo),e(eu,tTo),e(G,aTo),e(G,ou),e(ou,Hle),e(Hle,nTo),e(ou,sTo),e(ou,cN),e(cN,lTo),e(ou,iTo),e(G,dTo),e(G,ru),e(ru,Ule),e(Ule,cTo),e(ru,fTo),e(ru,fN),e(fN,mTo),e(ru,gTo),e(G,hTo),e(G,tu),e(tu,Jle),e(Jle,pTo),e(tu,_To),e(tu,mN),e(mN,uTo),e(tu,bTo),e(G,vTo),e(G,au),e(au,Yle),e(Yle,FTo),e(au,TTo),e(au,gN),e(gN,MTo),e(au,ETo),e(G,CTo),e(G,nu),e(nu,Kle),e(Kle,wTo),e(nu,ATo),e(nu,hN),e(hN,yTo),e(nu,LTo),e(G,xTo),e(G,su),e(su,Zle),e(Zle,$To),e(su,kTo),e(su,pN),e(pN,STo),e(su,RTo),e(G,PTo),e(G,lu),e(lu,eie),e(eie,BTo),e(lu,ITo),e(lu,_N),e(_N,qTo),e(lu,NTo),e(G,jTo),e(G,iu),e(iu,oie),e(oie,DTo),e(iu,GTo),e(iu,uN),e(uN,OTo),e(iu,VTo),e(G,XTo),e(G,du),e(du,rie),e(rie,zTo),e(du,WTo),e(du,bN),e(bN,QTo),e(du,HTo),e(G,UTo),e(G,cu),e(cu,tie),e(tie,JTo),e(cu,YTo),e(cu,vN),e(vN,KTo),e(cu,ZTo),e(G,eMo),e(G,fu),e(fu,aie),e(aie,oMo),e(fu,rMo),e(fu,FN),e(FN,tMo),e(fu,aMo),e(G,nMo),e(G,mu),e(mu,nie),e(nie,sMo),e(mu,lMo),e(mu,TN),e(TN,iMo),e(mu,dMo),e(G,cMo),e(G,gu),e(gu,sie),e(sie,fMo),e(gu,mMo),e(gu,MN),e(MN,gMo),e(gu,hMo),e(G,pMo),e(G,hu),e(hu,lie),e(lie,_Mo),e(hu,uMo),e(hu,EN),e(EN,bMo),e(hu,vMo),e(G,FMo),e(G,pu),e(pu,iie),e(iie,TMo),e(pu,MMo),e(pu,CN),e(CN,EMo),e(pu,CMo),e(G,wMo),e(G,_u),e(_u,die),e(die,AMo),e(_u,yMo),e(_u,wN),e(wN,LMo),e(_u,xMo),e(G,$Mo),e(G,uu),e(uu,cie),e(cie,kMo),e(uu,SMo),e(uu,AN),e(AN,RMo),e(uu,PMo),e(G,BMo),e(G,bu),e(bu,fie),e(fie,IMo),e(bu,qMo),e(bu,yN),e(yN,NMo),e(bu,jMo),e(G,DMo),e(G,vu),e(vu,mie),e(mie,GMo),e(vu,OMo),e(vu,LN),e(LN,VMo),e(vu,XMo),e(G,zMo),e(G,Fu),e(Fu,gie),e(gie,WMo),e(Fu,QMo),e(Fu,xN),e(xN,HMo),e(Fu,UMo),e(G,JMo),e(G,Tu),e(Tu,hie),e(hie,YMo),e(Tu,KMo),e(Tu,$N),e($N,ZMo),e(Tu,e4o),e(G,o4o),e(G,Mu),e(Mu,pie),e(pie,r4o),e(Mu,t4o),e(Mu,kN),e(kN,a4o),e(Mu,n4o),e(G,s4o),e(G,Eu),e(Eu,_ie),e(_ie,l4o),e(Eu,i4o),e(Eu,SN),e(SN,d4o),e(Eu,c4o),e(G,f4o),e(G,Cu),e(Cu,uie),e(uie,m4o),e(Cu,g4o),e(Cu,RN),e(RN,h4o),e(Cu,p4o),e(G,_4o),e(G,wu),e(wu,bie),e(bie,u4o),e(wu,b4o),e(wu,PN),e(PN,v4o),e(wu,F4o),e(G,T4o),e(G,Au),e(Au,vie),e(vie,M4o),e(Au,E4o),e(Au,BN),e(BN,C4o),e(Au,w4o),e(G,A4o),e(G,yu),e(yu,Fie),e(Fie,y4o),e(yu,L4o),e(yu,IN),e(IN,x4o),e(yu,$4o),e(G,k4o),e(G,Lu),e(Lu,Tie),e(Tie,S4o),e(Lu,R4o),e(Lu,qN),e(qN,P4o),e(Lu,B4o),e(G,I4o),e(G,xu),e(xu,Mie),e(Mie,q4o),e(xu,N4o),e(xu,NN),e(NN,j4o),e(xu,D4o),e(G,G4o),e(G,$u),e($u,Eie),e(Eie,O4o),e($u,V4o),e($u,jN),e(jN,X4o),e($u,z4o),e(G,W4o),e(G,ku),e(ku,Cie),e(Cie,Q4o),e(ku,H4o),e(ku,DN),e(DN,U4o),e(ku,J4o),e(G,Y4o),e(G,Su),e(Su,wie),e(wie,K4o),e(Su,Z4o),e(Su,GN),e(GN,eEo),e(Su,oEo),e(G,rEo),e(G,Ru),e(Ru,Aie),e(Aie,tEo),e(Ru,aEo),e(Ru,ON),e(ON,nEo),e(Ru,sEo),e(G,lEo),e(G,Pu),e(Pu,yie),e(yie,iEo),e(Pu,dEo),e(Pu,VN),e(VN,cEo),e(Pu,fEo),e(Ye,mEo),e(Ye,Bu),e(Bu,gEo),e(Bu,Lie),e(Lie,hEo),e(Bu,pEo),e(Bu,xie),e(xie,_Eo),e(Ye,uEo),M(Iu,Ye,null),b(f,mqe,u),b(f,$i,u),e($i,qu),e(qu,$ie),M(U6,$ie,null),e($i,bEo),e($i,kie),e(kie,vEo),b(f,gqe,u),b(f,$o,u),M(J6,$o,null),e($o,FEo),e($o,ki),e(ki,TEo),e(ki,XN),e(XN,MEo),e(ki,EEo),e(ki,zN),e(zN,CEo),e(ki,wEo),e($o,AEo),e($o,Y6),e(Y6,yEo),e(Y6,Sie),e(Sie,LEo),e(Y6,xEo),e($o,$Eo),e($o,nt),M(K6,nt,null),e(nt,kEo),e(nt,Rie),e(Rie,SEo),e(nt,REo),e(nt,Si),e(Si,PEo),e(Si,Pie),e(Pie,BEo),e(Si,IEo),e(Si,WN),e(WN,qEo),e(Si,NEo),e(nt,jEo),M(Nu,nt,null),e($o,DEo),e($o,Ke),M(Z6,Ke,null),e(Ke,GEo),e(Ke,Bie),e(Bie,OEo),e(Ke,VEo),e(Ke,$a),e($a,XEo),e($a,Iie),e(Iie,zEo),e($a,WEo),e($a,qie),e(qie,QEo),e($a,HEo),e($a,Nie),e(Nie,UEo),e($a,JEo),e(Ke,YEo),e(Ke,z),e(z,ju),e(ju,jie),e(jie,KEo),e(ju,ZEo),e(ju,QN),e(QN,eCo),e(ju,oCo),e(z,rCo),e(z,Du),e(Du,Die),e(Die,tCo),e(Du,aCo),e(Du,HN),e(HN,nCo),e(Du,sCo),e(z,lCo),e(z,Gu),e(Gu,Gie),e(Gie,iCo),e(Gu,dCo),e(Gu,UN),e(UN,cCo),e(Gu,fCo),e(z,mCo),e(z,Ou),e(Ou,Oie),e(Oie,gCo),e(Ou,hCo),e(Ou,JN),e(JN,pCo),e(Ou,_Co),e(z,uCo),e(z,Vu),e(Vu,Vie),e(Vie,bCo),e(Vu,vCo),e(Vu,YN),e(YN,FCo),e(Vu,TCo),e(z,MCo),e(z,Xu),e(Xu,Xie),e(Xie,ECo),e(Xu,CCo),e(Xu,KN),e(KN,wCo),e(Xu,ACo),e(z,yCo),e(z,zu),e(zu,zie),e(zie,LCo),e(zu,xCo),e(zu,ZN),e(ZN,$Co),e(zu,kCo),e(z,SCo),e(z,Wu),e(Wu,Wie),e(Wie,RCo),e(Wu,PCo),e(Wu,ej),e(ej,BCo),e(Wu,ICo),e(z,qCo),e(z,Qu),e(Qu,Qie),e(Qie,NCo),e(Qu,jCo),e(Qu,oj),e(oj,DCo),e(Qu,GCo),e(z,OCo),e(z,Hu),e(Hu,Hie),e(Hie,VCo),e(Hu,XCo),e(Hu,rj),e(rj,zCo),e(Hu,WCo),e(z,QCo),e(z,Uu),e(Uu,Uie),e(Uie,HCo),e(Uu,UCo),e(Uu,tj),e(tj,JCo),e(Uu,YCo),e(z,KCo),e(z,Ju),e(Ju,Jie),e(Jie,ZCo),e(Ju,e5o),e(Ju,aj),e(aj,o5o),e(Ju,r5o),e(z,t5o),e(z,Yu),e(Yu,Yie),e(Yie,a5o),e(Yu,n5o),e(Yu,nj),e(nj,s5o),e(Yu,l5o),e(z,i5o),e(z,Ku),e(Ku,Kie),e(Kie,d5o),e(Ku,c5o),e(Ku,sj),e(sj,f5o),e(Ku,m5o),e(z,g5o),e(z,Zu),e(Zu,Zie),e(Zie,h5o),e(Zu,p5o),e(Zu,lj),e(lj,_5o),e(Zu,u5o),e(z,b5o),e(z,e2),e(e2,ede),e(ede,v5o),e(e2,F5o),e(e2,ij),e(ij,T5o),e(e2,M5o),e(z,E5o),e(z,o2),e(o2,ode),e(ode,C5o),e(o2,w5o),e(o2,dj),e(dj,A5o),e(o2,y5o),e(z,L5o),e(z,r2),e(r2,rde),e(rde,x5o),e(r2,$5o),e(r2,cj),e(cj,k5o),e(r2,S5o),e(z,R5o),e(z,t2),e(t2,tde),e(tde,P5o),e(t2,B5o),e(t2,fj),e(fj,I5o),e(t2,q5o),e(z,N5o),e(z,a2),e(a2,ade),e(ade,j5o),e(a2,D5o),e(a2,mj),e(mj,G5o),e(a2,O5o),e(z,V5o),e(z,n2),e(n2,nde),e(nde,X5o),e(n2,z5o),e(n2,gj),e(gj,W5o),e(n2,Q5o),e(z,H5o),e(z,s2),e(s2,sde),e(sde,U5o),e(s2,J5o),e(s2,hj),e(hj,Y5o),e(s2,K5o),e(z,Z5o),e(z,l2),e(l2,lde),e(lde,e3o),e(l2,o3o),e(l2,pj),e(pj,r3o),e(l2,t3o),e(z,a3o),e(z,i2),e(i2,ide),e(ide,n3o),e(i2,s3o),e(i2,_j),e(_j,l3o),e(i2,i3o),e(z,d3o),e(z,d2),e(d2,dde),e(dde,c3o),e(d2,f3o),e(d2,uj),e(uj,m3o),e(d2,g3o),e(z,h3o),e(z,c2),e(c2,cde),e(cde,p3o),e(c2,_3o),e(c2,bj),e(bj,u3o),e(c2,b3o),e(z,v3o),e(z,f2),e(f2,fde),e(fde,F3o),e(f2,T3o),e(f2,vj),e(vj,M3o),e(f2,E3o),e(z,C3o),e(z,m2),e(m2,mde),e(mde,w3o),e(m2,A3o),e(m2,Fj),e(Fj,y3o),e(m2,L3o),e(z,x3o),e(z,g2),e(g2,gde),e(gde,$3o),e(g2,k3o),e(g2,Tj),e(Tj,S3o),e(g2,R3o),e(z,P3o),e(z,h2),e(h2,hde),e(hde,B3o),e(h2,I3o),e(h2,Mj),e(Mj,q3o),e(h2,N3o),e(z,j3o),e(z,p2),e(p2,pde),e(pde,D3o),e(p2,G3o),e(p2,Ej),e(Ej,O3o),e(p2,V3o),e(z,X3o),e(z,_2),e(_2,_de),e(_de,z3o),e(_2,W3o),e(_2,Cj),e(Cj,Q3o),e(_2,H3o),e(z,U3o),e(z,u2),e(u2,ude),e(ude,J3o),e(u2,Y3o),e(u2,wj),e(wj,K3o),e(u2,Z3o),e(z,ewo),e(z,b2),e(b2,bde),e(bde,owo),e(b2,rwo),e(b2,Aj),e(Aj,two),e(b2,awo),e(z,nwo),e(z,v2),e(v2,vde),e(vde,swo),e(v2,lwo),e(v2,yj),e(yj,iwo),e(v2,dwo),e(z,cwo),e(z,F2),e(F2,Fde),e(Fde,fwo),e(F2,mwo),e(F2,Lj),e(Lj,gwo),e(F2,hwo),e(Ke,pwo),e(Ke,T2),e(T2,_wo),e(T2,Tde),e(Tde,uwo),e(T2,bwo),e(T2,Mde),e(Mde,vwo),e(Ke,Fwo),M(M2,Ke,null),b(f,hqe,u),b(f,Ri,u),e(Ri,E2),e(E2,Ede),M(ey,Ede,null),e(Ri,Two),e(Ri,Cde),e(Cde,Mwo),b(f,pqe,u),b(f,ko,u),M(oy,ko,null),e(ko,Ewo),e(ko,Pi),e(Pi,Cwo),e(Pi,xj),e(xj,wwo),e(Pi,Awo),e(Pi,$j),e($j,ywo),e(Pi,Lwo),e(ko,xwo),e(ko,ry),e(ry,$wo),e(ry,wde),e(wde,kwo),e(ry,Swo),e(ko,Rwo),e(ko,st),M(ty,st,null),e(st,Pwo),e(st,Ade),e(Ade,Bwo),e(st,Iwo),e(st,Bi),e(Bi,qwo),e(Bi,yde),e(yde,Nwo),e(Bi,jwo),e(Bi,kj),e(kj,Dwo),e(Bi,Gwo),e(st,Owo),M(C2,st,null),e(ko,Vwo),e(ko,Ze),M(ay,Ze,null),e(Ze,Xwo),e(Ze,Lde),e(Lde,zwo),e(Ze,Wwo),e(Ze,ka),e(ka,Qwo),e(ka,xde),e(xde,Hwo),e(ka,Uwo),e(ka,$de),e($de,Jwo),e(ka,Ywo),e(ka,kde),e(kde,Kwo),e(ka,Zwo),e(Ze,e0o),e(Ze,W),e(W,w2),e(w2,Sde),e(Sde,o0o),e(w2,r0o),e(w2,Sj),e(Sj,t0o),e(w2,a0o),e(W,n0o),e(W,A2),e(A2,Rde),e(Rde,s0o),e(A2,l0o),e(A2,Rj),e(Rj,i0o),e(A2,d0o),e(W,c0o),e(W,y2),e(y2,Pde),e(Pde,f0o),e(y2,m0o),e(y2,Pj),e(Pj,g0o),e(y2,h0o),e(W,p0o),e(W,L2),e(L2,Bde),e(Bde,_0o),e(L2,u0o),e(L2,Bj),e(Bj,b0o),e(L2,v0o),e(W,F0o),e(W,x2),e(x2,Ide),e(Ide,T0o),e(x2,M0o),e(x2,Ij),e(Ij,E0o),e(x2,C0o),e(W,w0o),e(W,$2),e($2,qde),e(qde,A0o),e($2,y0o),e($2,qj),e(qj,L0o),e($2,x0o),e(W,$0o),e(W,k2),e(k2,Nde),e(Nde,k0o),e(k2,S0o),e(k2,Nj),e(Nj,R0o),e(k2,P0o),e(W,B0o),e(W,S2),e(S2,jde),e(jde,I0o),e(S2,q0o),e(S2,jj),e(jj,N0o),e(S2,j0o),e(W,D0o),e(W,R2),e(R2,Dde),e(Dde,G0o),e(R2,O0o),e(R2,Dj),e(Dj,V0o),e(R2,X0o),e(W,z0o),e(W,P2),e(P2,Gde),e(Gde,W0o),e(P2,Q0o),e(P2,Gj),e(Gj,H0o),e(P2,U0o),e(W,J0o),e(W,B2),e(B2,Ode),e(Ode,Y0o),e(B2,K0o),e(B2,Oj),e(Oj,Z0o),e(B2,eAo),e(W,oAo),e(W,I2),e(I2,Vde),e(Vde,rAo),e(I2,tAo),e(I2,Vj),e(Vj,aAo),e(I2,nAo),e(W,sAo),e(W,q2),e(q2,Xde),e(Xde,lAo),e(q2,iAo),e(q2,Xj),e(Xj,dAo),e(q2,cAo),e(W,fAo),e(W,N2),e(N2,zde),e(zde,mAo),e(N2,gAo),e(N2,zj),e(zj,hAo),e(N2,pAo),e(W,_Ao),e(W,j2),e(j2,Wde),e(Wde,uAo),e(j2,bAo),e(j2,Wj),e(Wj,vAo),e(j2,FAo),e(W,TAo),e(W,D2),e(D2,Qde),e(Qde,MAo),e(D2,EAo),e(D2,Qj),e(Qj,CAo),e(D2,wAo),e(W,AAo),e(W,G2),e(G2,Hde),e(Hde,yAo),e(G2,LAo),e(G2,Hj),e(Hj,xAo),e(G2,$Ao),e(W,kAo),e(W,O2),e(O2,Ude),e(Ude,SAo),e(O2,RAo),e(O2,Uj),e(Uj,PAo),e(O2,BAo),e(W,IAo),e(W,V2),e(V2,Jde),e(Jde,qAo),e(V2,NAo),e(V2,Jj),e(Jj,jAo),e(V2,DAo),e(W,GAo),e(W,X2),e(X2,Yde),e(Yde,OAo),e(X2,VAo),e(X2,Yj),e(Yj,XAo),e(X2,zAo),e(W,WAo),e(W,z2),e(z2,Kde),e(Kde,QAo),e(z2,HAo),e(z2,Kj),e(Kj,UAo),e(z2,JAo),e(W,YAo),e(W,W2),e(W2,Zde),e(Zde,KAo),e(W2,ZAo),e(W2,Zj),e(Zj,e6o),e(W2,o6o),e(W,r6o),e(W,Q2),e(Q2,ece),e(ece,t6o),e(Q2,a6o),e(Q2,eD),e(eD,n6o),e(Q2,s6o),e(W,l6o),e(W,H2),e(H2,oce),e(oce,i6o),e(H2,d6o),e(H2,oD),e(oD,c6o),e(H2,f6o),e(W,m6o),e(W,U2),e(U2,rce),e(rce,g6o),e(U2,h6o),e(U2,rD),e(rD,p6o),e(U2,_6o),e(W,u6o),e(W,J2),e(J2,tce),e(tce,b6o),e(J2,v6o),e(J2,tD),e(tD,F6o),e(J2,T6o),e(W,M6o),e(W,Y2),e(Y2,ace),e(ace,E6o),e(Y2,C6o),e(Y2,aD),e(aD,w6o),e(Y2,A6o),e(W,y6o),e(W,K2),e(K2,nce),e(nce,L6o),e(K2,x6o),e(K2,nD),e(nD,$6o),e(K2,k6o),e(W,S6o),e(W,Z2),e(Z2,sce),e(sce,R6o),e(Z2,P6o),e(Z2,sD),e(sD,B6o),e(Z2,I6o),e(W,q6o),e(W,e1),e(e1,lce),e(lce,N6o),e(e1,j6o),e(e1,lD),e(lD,D6o),e(e1,G6o),e(W,O6o),e(W,o1),e(o1,ice),e(ice,V6o),e(o1,X6o),e(o1,dce),e(dce,z6o),e(o1,W6o),e(W,Q6o),e(W,r1),e(r1,cce),e(cce,H6o),e(r1,U6o),e(r1,iD),e(iD,J6o),e(r1,Y6o),e(W,K6o),e(W,t1),e(t1,fce),e(fce,Z6o),e(t1,eyo),e(t1,dD),e(dD,oyo),e(t1,ryo),e(W,tyo),e(W,a1),e(a1,mce),e(mce,ayo),e(a1,nyo),e(a1,cD),e(cD,syo),e(a1,lyo),e(W,iyo),e(W,n1),e(n1,gce),e(gce,dyo),e(n1,cyo),e(n1,fD),e(fD,fyo),e(n1,myo),e(Ze,gyo),e(Ze,s1),e(s1,hyo),e(s1,hce),e(hce,pyo),e(s1,_yo),e(s1,pce),e(pce,uyo),e(Ze,byo),M(l1,Ze,null),b(f,_qe,u),b(f,Ii,u),e(Ii,i1),e(i1,_ce),M(ny,_ce,null),e(Ii,vyo),e(Ii,uce),e(uce,Fyo),b(f,uqe,u),b(f,So,u),M(sy,So,null),e(So,Tyo),e(So,qi),e(qi,Myo),e(qi,mD),e(mD,Eyo),e(qi,Cyo),e(qi,gD),e(gD,wyo),e(qi,Ayo),e(So,yyo),e(So,ly),e(ly,Lyo),e(ly,bce),e(bce,xyo),e(ly,$yo),e(So,kyo),e(So,lt),M(iy,lt,null),e(lt,Syo),e(lt,vce),e(vce,Ryo),e(lt,Pyo),e(lt,Ni),e(Ni,Byo),e(Ni,Fce),e(Fce,Iyo),e(Ni,qyo),e(Ni,hD),e(hD,Nyo),e(Ni,jyo),e(lt,Dyo),M(d1,lt,null),e(So,Gyo),e(So,eo),M(dy,eo,null),e(eo,Oyo),e(eo,Tce),e(Tce,Vyo),e(eo,Xyo),e(eo,Sa),e(Sa,zyo),e(Sa,Mce),e(Mce,Wyo),e(Sa,Qyo),e(Sa,Ece),e(Ece,Hyo),e(Sa,Uyo),e(Sa,Cce),e(Cce,Jyo),e(Sa,Yyo),e(eo,Kyo),e(eo,_e),e(_e,c1),e(c1,wce),e(wce,Zyo),e(c1,eLo),e(c1,pD),e(pD,oLo),e(c1,rLo),e(_e,tLo),e(_e,f1),e(f1,Ace),e(Ace,aLo),e(f1,nLo),e(f1,_D),e(_D,sLo),e(f1,lLo),e(_e,iLo),e(_e,m1),e(m1,yce),e(yce,dLo),e(m1,cLo),e(m1,uD),e(uD,fLo),e(m1,mLo),e(_e,gLo),e(_e,g1),e(g1,Lce),e(Lce,hLo),e(g1,pLo),e(g1,bD),e(bD,_Lo),e(g1,uLo),e(_e,bLo),e(_e,h1),e(h1,xce),e(xce,vLo),e(h1,FLo),e(h1,vD),e(vD,TLo),e(h1,MLo),e(_e,ELo),e(_e,p1),e(p1,$ce),e($ce,CLo),e(p1,wLo),e(p1,FD),e(FD,ALo),e(p1,yLo),e(_e,LLo),e(_e,_1),e(_1,kce),e(kce,xLo),e(_1,$Lo),e(_1,TD),e(TD,kLo),e(_1,SLo),e(_e,RLo),e(_e,u1),e(u1,Sce),e(Sce,PLo),e(u1,BLo),e(u1,MD),e(MD,ILo),e(u1,qLo),e(_e,NLo),e(_e,b1),e(b1,Rce),e(Rce,jLo),e(b1,DLo),e(b1,ED),e(ED,GLo),e(b1,OLo),e(_e,VLo),e(_e,v1),e(v1,Pce),e(Pce,XLo),e(v1,zLo),e(v1,CD),e(CD,WLo),e(v1,QLo),e(_e,HLo),e(_e,F1),e(F1,Bce),e(Bce,ULo),e(F1,JLo),e(F1,wD),e(wD,YLo),e(F1,KLo),e(_e,ZLo),e(_e,T1),e(T1,Ice),e(Ice,e8o),e(T1,o8o),e(T1,AD),e(AD,r8o),e(T1,t8o),e(_e,a8o),e(_e,M1),e(M1,qce),e(qce,n8o),e(M1,s8o),e(M1,yD),e(yD,l8o),e(M1,i8o),e(_e,d8o),e(_e,E1),e(E1,Nce),e(Nce,c8o),e(E1,f8o),e(E1,LD),e(LD,m8o),e(E1,g8o),e(_e,h8o),e(_e,C1),e(C1,jce),e(jce,p8o),e(C1,_8o),e(C1,xD),e(xD,u8o),e(C1,b8o),e(_e,v8o),e(_e,w1),e(w1,Dce),e(Dce,F8o),e(w1,T8o),e(w1,$D),e($D,M8o),e(w1,E8o),e(eo,C8o),e(eo,A1),e(A1,w8o),e(A1,Gce),e(Gce,A8o),e(A1,y8o),e(A1,Oce),e(Oce,L8o),e(eo,x8o),M(y1,eo,null),b(f,bqe,u),b(f,ji,u),e(ji,L1),e(L1,Vce),M(cy,Vce,null),e(ji,$8o),e(ji,Xce),e(Xce,k8o),b(f,vqe,u),b(f,Ro,u),M(fy,Ro,null),e(Ro,S8o),e(Ro,Di),e(Di,R8o),e(Di,kD),e(kD,P8o),e(Di,B8o),e(Di,SD),e(SD,I8o),e(Di,q8o),e(Ro,N8o),e(Ro,my),e(my,j8o),e(my,zce),e(zce,D8o),e(my,G8o),e(Ro,O8o),e(Ro,it),M(gy,it,null),e(it,V8o),e(it,Wce),e(Wce,X8o),e(it,z8o),e(it,Gi),e(Gi,W8o),e(Gi,Qce),e(Qce,Q8o),e(Gi,H8o),e(Gi,RD),e(RD,U8o),e(Gi,J8o),e(it,Y8o),M(x1,it,null),e(Ro,K8o),e(Ro,oo),M(hy,oo,null),e(oo,Z8o),e(oo,Hce),e(Hce,exo),e(oo,oxo),e(oo,Ra),e(Ra,rxo),e(Ra,Uce),e(Uce,txo),e(Ra,axo),e(Ra,Jce),e(Jce,nxo),e(Ra,sxo),e(Ra,Yce),e(Yce,lxo),e(Ra,ixo),e(oo,dxo),e(oo,N),e(N,$1),e($1,Kce),e(Kce,cxo),e($1,fxo),e($1,PD),e(PD,mxo),e($1,gxo),e(N,hxo),e(N,k1),e(k1,Zce),e(Zce,pxo),e(k1,_xo),e(k1,BD),e(BD,uxo),e(k1,bxo),e(N,vxo),e(N,S1),e(S1,efe),e(efe,Fxo),e(S1,Txo),e(S1,ID),e(ID,Mxo),e(S1,Exo),e(N,Cxo),e(N,R1),e(R1,ofe),e(ofe,wxo),e(R1,Axo),e(R1,qD),e(qD,yxo),e(R1,Lxo),e(N,xxo),e(N,P1),e(P1,rfe),e(rfe,$xo),e(P1,kxo),e(P1,ND),e(ND,Sxo),e(P1,Rxo),e(N,Pxo),e(N,B1),e(B1,tfe),e(tfe,Bxo),e(B1,Ixo),e(B1,jD),e(jD,qxo),e(B1,Nxo),e(N,jxo),e(N,I1),e(I1,afe),e(afe,Dxo),e(I1,Gxo),e(I1,DD),e(DD,Oxo),e(I1,Vxo),e(N,Xxo),e(N,q1),e(q1,nfe),e(nfe,zxo),e(q1,Wxo),e(q1,GD),e(GD,Qxo),e(q1,Hxo),e(N,Uxo),e(N,N1),e(N1,sfe),e(sfe,Jxo),e(N1,Yxo),e(N1,OD),e(OD,Kxo),e(N1,Zxo),e(N,e9o),e(N,j1),e(j1,lfe),e(lfe,o9o),e(j1,r9o),e(j1,VD),e(VD,t9o),e(j1,a9o),e(N,n9o),e(N,D1),e(D1,ife),e(ife,s9o),e(D1,l9o),e(D1,XD),e(XD,i9o),e(D1,d9o),e(N,c9o),e(N,G1),e(G1,dfe),e(dfe,f9o),e(G1,m9o),e(G1,zD),e(zD,g9o),e(G1,h9o),e(N,p9o),e(N,O1),e(O1,cfe),e(cfe,_9o),e(O1,u9o),e(O1,WD),e(WD,b9o),e(O1,v9o),e(N,F9o),e(N,V1),e(V1,ffe),e(ffe,T9o),e(V1,M9o),e(V1,QD),e(QD,E9o),e(V1,C9o),e(N,w9o),e(N,X1),e(X1,mfe),e(mfe,A9o),e(X1,y9o),e(X1,HD),e(HD,L9o),e(X1,x9o),e(N,$9o),e(N,z1),e(z1,gfe),e(gfe,k9o),e(z1,S9o),e(z1,UD),e(UD,R9o),e(z1,P9o),e(N,B9o),e(N,W1),e(W1,hfe),e(hfe,I9o),e(W1,q9o),e(W1,JD),e(JD,N9o),e(W1,j9o),e(N,D9o),e(N,Q1),e(Q1,pfe),e(pfe,G9o),e(Q1,O9o),e(Q1,YD),e(YD,V9o),e(Q1,X9o),e(N,z9o),e(N,H1),e(H1,_fe),e(_fe,W9o),e(H1,Q9o),e(H1,KD),e(KD,H9o),e(H1,U9o),e(N,J9o),e(N,U1),e(U1,ufe),e(ufe,Y9o),e(U1,K9o),e(U1,ZD),e(ZD,Z9o),e(U1,e$o),e(N,o$o),e(N,J1),e(J1,bfe),e(bfe,r$o),e(J1,t$o),e(J1,eG),e(eG,a$o),e(J1,n$o),e(N,s$o),e(N,Y1),e(Y1,vfe),e(vfe,l$o),e(Y1,i$o),e(Y1,oG),e(oG,d$o),e(Y1,c$o),e(N,f$o),e(N,K1),e(K1,Ffe),e(Ffe,m$o),e(K1,g$o),e(K1,rG),e(rG,h$o),e(K1,p$o),e(N,_$o),e(N,Z1),e(Z1,Tfe),e(Tfe,u$o),e(Z1,b$o),e(Z1,tG),e(tG,v$o),e(Z1,F$o),e(N,T$o),e(N,e7),e(e7,Mfe),e(Mfe,M$o),e(e7,E$o),e(e7,aG),e(aG,C$o),e(e7,w$o),e(N,A$o),e(N,o7),e(o7,Efe),e(Efe,y$o),e(o7,L$o),e(o7,nG),e(nG,x$o),e(o7,$$o),e(N,k$o),e(N,r7),e(r7,Cfe),e(Cfe,S$o),e(r7,R$o),e(r7,sG),e(sG,P$o),e(r7,B$o),e(N,I$o),e(N,t7),e(t7,wfe),e(wfe,q$o),e(t7,N$o),e(t7,lG),e(lG,j$o),e(t7,D$o),e(N,G$o),e(N,a7),e(a7,Afe),e(Afe,O$o),e(a7,V$o),e(a7,iG),e(iG,X$o),e(a7,z$o),e(N,W$o),e(N,n7),e(n7,yfe),e(yfe,Q$o),e(n7,H$o),e(n7,dG),e(dG,U$o),e(n7,J$o),e(N,Y$o),e(N,s7),e(s7,Lfe),e(Lfe,K$o),e(s7,Z$o),e(s7,cG),e(cG,eko),e(s7,oko),e(N,rko),e(N,l7),e(l7,xfe),e(xfe,tko),e(l7,ako),e(l7,fG),e(fG,nko),e(l7,sko),e(N,lko),e(N,i7),e(i7,$fe),e($fe,iko),e(i7,dko),e(i7,mG),e(mG,cko),e(i7,fko),e(N,mko),e(N,d7),e(d7,kfe),e(kfe,gko),e(d7,hko),e(d7,gG),e(gG,pko),e(d7,_ko),e(N,uko),e(N,c7),e(c7,Sfe),e(Sfe,bko),e(c7,vko),e(c7,hG),e(hG,Fko),e(c7,Tko),e(N,Mko),e(N,f7),e(f7,Rfe),e(Rfe,Eko),e(f7,Cko),e(f7,pG),e(pG,wko),e(f7,Ako),e(N,yko),e(N,m7),e(m7,Pfe),e(Pfe,Lko),e(m7,xko),e(m7,_G),e(_G,$ko),e(m7,kko),e(N,Sko),e(N,g7),e(g7,Bfe),e(Bfe,Rko),e(g7,Pko),e(g7,uG),e(uG,Bko),e(g7,Iko),e(N,qko),e(N,h7),e(h7,Ife),e(Ife,Nko),e(h7,jko),e(h7,bG),e(bG,Dko),e(h7,Gko),e(N,Oko),e(N,p7),e(p7,qfe),e(qfe,Vko),e(p7,Xko),e(p7,vG),e(vG,zko),e(p7,Wko),e(N,Qko),e(N,_7),e(_7,Nfe),e(Nfe,Hko),e(_7,Uko),e(_7,FG),e(FG,Jko),e(_7,Yko),e(N,Kko),e(N,u7),e(u7,jfe),e(jfe,Zko),e(u7,eSo),e(u7,TG),e(TG,oSo),e(u7,rSo),e(N,tSo),e(N,b7),e(b7,Dfe),e(Dfe,aSo),e(b7,nSo),e(b7,MG),e(MG,sSo),e(b7,lSo),e(N,iSo),e(N,v7),e(v7,Gfe),e(Gfe,dSo),e(v7,cSo),e(v7,EG),e(EG,fSo),e(v7,mSo),e(N,gSo),e(N,F7),e(F7,Ofe),e(Ofe,hSo),e(F7,pSo),e(F7,CG),e(CG,_So),e(F7,uSo),e(N,bSo),e(N,T7),e(T7,Vfe),e(Vfe,vSo),e(T7,FSo),e(T7,wG),e(wG,TSo),e(T7,MSo),e(oo,ESo),e(oo,M7),e(M7,CSo),e(M7,Xfe),e(Xfe,wSo),e(M7,ASo),e(M7,zfe),e(zfe,ySo),e(oo,LSo),M(E7,oo,null),b(f,Fqe,u),b(f,Oi,u),e(Oi,C7),e(C7,Wfe),M(py,Wfe,null),e(Oi,xSo),e(Oi,Qfe),e(Qfe,$So),b(f,Tqe,u),b(f,Po,u),M(_y,Po,null),e(Po,kSo),e(Po,Vi),e(Vi,SSo),e(Vi,AG),e(AG,RSo),e(Vi,PSo),e(Vi,yG),e(yG,BSo),e(Vi,ISo),e(Po,qSo),e(Po,uy),e(uy,NSo),e(uy,Hfe),e(Hfe,jSo),e(uy,DSo),e(Po,GSo),e(Po,dt),M(by,dt,null),e(dt,OSo),e(dt,Ufe),e(Ufe,VSo),e(dt,XSo),e(dt,Xi),e(Xi,zSo),e(Xi,Jfe),e(Jfe,WSo),e(Xi,QSo),e(Xi,LG),e(LG,HSo),e(Xi,USo),e(dt,JSo),M(w7,dt,null),e(Po,YSo),e(Po,ro),M(vy,ro,null),e(ro,KSo),e(ro,Yfe),e(Yfe,ZSo),e(ro,eRo),e(ro,Pa),e(Pa,oRo),e(Pa,Kfe),e(Kfe,rRo),e(Pa,tRo),e(Pa,Zfe),e(Zfe,aRo),e(Pa,nRo),e(Pa,eme),e(eme,sRo),e(Pa,lRo),e(ro,iRo),e(ro,Y),e(Y,A7),e(A7,ome),e(ome,dRo),e(A7,cRo),e(A7,xG),e(xG,fRo),e(A7,mRo),e(Y,gRo),e(Y,y7),e(y7,rme),e(rme,hRo),e(y7,pRo),e(y7,$G),e($G,_Ro),e(y7,uRo),e(Y,bRo),e(Y,L7),e(L7,tme),e(tme,vRo),e(L7,FRo),e(L7,kG),e(kG,TRo),e(L7,MRo),e(Y,ERo),e(Y,x7),e(x7,ame),e(ame,CRo),e(x7,wRo),e(x7,SG),e(SG,ARo),e(x7,yRo),e(Y,LRo),e(Y,$7),e($7,nme),e(nme,xRo),e($7,$Ro),e($7,RG),e(RG,kRo),e($7,SRo),e(Y,RRo),e(Y,k7),e(k7,sme),e(sme,PRo),e(k7,BRo),e(k7,PG),e(PG,IRo),e(k7,qRo),e(Y,NRo),e(Y,S7),e(S7,lme),e(lme,jRo),e(S7,DRo),e(S7,BG),e(BG,GRo),e(S7,ORo),e(Y,VRo),e(Y,R7),e(R7,ime),e(ime,XRo),e(R7,zRo),e(R7,IG),e(IG,WRo),e(R7,QRo),e(Y,HRo),e(Y,P7),e(P7,dme),e(dme,URo),e(P7,JRo),e(P7,qG),e(qG,YRo),e(P7,KRo),e(Y,ZRo),e(Y,B7),e(B7,cme),e(cme,ePo),e(B7,oPo),e(B7,NG),e(NG,rPo),e(B7,tPo),e(Y,aPo),e(Y,I7),e(I7,fme),e(fme,nPo),e(I7,sPo),e(I7,jG),e(jG,lPo),e(I7,iPo),e(Y,dPo),e(Y,q7),e(q7,mme),e(mme,cPo),e(q7,fPo),e(q7,DG),e(DG,mPo),e(q7,gPo),e(Y,hPo),e(Y,N7),e(N7,gme),e(gme,pPo),e(N7,_Po),e(N7,GG),e(GG,uPo),e(N7,bPo),e(Y,vPo),e(Y,j7),e(j7,hme),e(hme,FPo),e(j7,TPo),e(j7,OG),e(OG,MPo),e(j7,EPo),e(Y,CPo),e(Y,D7),e(D7,pme),e(pme,wPo),e(D7,APo),e(D7,VG),e(VG,yPo),e(D7,LPo),e(Y,xPo),e(Y,G7),e(G7,_me),e(_me,$Po),e(G7,kPo),e(G7,XG),e(XG,SPo),e(G7,RPo),e(Y,PPo),e(Y,O7),e(O7,ume),e(ume,BPo),e(O7,IPo),e(O7,zG),e(zG,qPo),e(O7,NPo),e(Y,jPo),e(Y,V7),e(V7,bme),e(bme,DPo),e(V7,GPo),e(V7,WG),e(WG,OPo),e(V7,VPo),e(Y,XPo),e(Y,X7),e(X7,vme),e(vme,zPo),e(X7,WPo),e(X7,QG),e(QG,QPo),e(X7,HPo),e(Y,UPo),e(Y,z7),e(z7,Fme),e(Fme,JPo),e(z7,YPo),e(z7,HG),e(HG,KPo),e(z7,ZPo),e(Y,eBo),e(Y,W7),e(W7,Tme),e(Tme,oBo),e(W7,rBo),e(W7,UG),e(UG,tBo),e(W7,aBo),e(Y,nBo),e(Y,Q7),e(Q7,Mme),e(Mme,sBo),e(Q7,lBo),e(Q7,JG),e(JG,iBo),e(Q7,dBo),e(Y,cBo),e(Y,H7),e(H7,Eme),e(Eme,fBo),e(H7,mBo),e(H7,YG),e(YG,gBo),e(H7,hBo),e(Y,pBo),e(Y,U7),e(U7,Cme),e(Cme,_Bo),e(U7,uBo),e(U7,KG),e(KG,bBo),e(U7,vBo),e(Y,FBo),e(Y,J7),e(J7,wme),e(wme,TBo),e(J7,MBo),e(J7,ZG),e(ZG,EBo),e(J7,CBo),e(Y,wBo),e(Y,Y7),e(Y7,Ame),e(Ame,ABo),e(Y7,yBo),e(Y7,eO),e(eO,LBo),e(Y7,xBo),e(Y,$Bo),e(Y,K7),e(K7,yme),e(yme,kBo),e(K7,SBo),e(K7,oO),e(oO,RBo),e(K7,PBo),e(Y,BBo),e(Y,Z7),e(Z7,Lme),e(Lme,IBo),e(Z7,qBo),e(Z7,rO),e(rO,NBo),e(Z7,jBo),e(Y,DBo),e(Y,eb),e(eb,xme),e(xme,GBo),e(eb,OBo),e(eb,tO),e(tO,VBo),e(eb,XBo),e(ro,zBo),e(ro,ob),e(ob,WBo),e(ob,$me),e($me,QBo),e(ob,HBo),e(ob,kme),e(kme,UBo),e(ro,JBo),M(rb,ro,null),b(f,Mqe,u),b(f,zi,u),e(zi,tb),e(tb,Sme),M(Fy,Sme,null),e(zi,YBo),e(zi,Rme),e(Rme,KBo),b(f,Eqe,u),b(f,Bo,u),M(Ty,Bo,null),e(Bo,ZBo),e(Bo,Wi),e(Wi,eIo),e(Wi,aO),e(aO,oIo),e(Wi,rIo),e(Wi,nO),e(nO,tIo),e(Wi,aIo),e(Bo,nIo),e(Bo,My),e(My,sIo),e(My,Pme),e(Pme,lIo),e(My,iIo),e(Bo,dIo),e(Bo,ct),M(Ey,ct,null),e(ct,cIo),e(ct,Bme),e(Bme,fIo),e(ct,mIo),e(ct,Qi),e(Qi,gIo),e(Qi,Ime),e(Ime,hIo),e(Qi,pIo),e(Qi,sO),e(sO,_Io),e(Qi,uIo),e(ct,bIo),M(ab,ct,null),e(Bo,vIo),e(Bo,to),M(Cy,to,null),e(to,FIo),e(to,qme),e(qme,TIo),e(to,MIo),e(to,Ba),e(Ba,EIo),e(Ba,Nme),e(Nme,CIo),e(Ba,wIo),e(Ba,jme),e(jme,AIo),e(Ba,yIo),e(Ba,Dme),e(Dme,LIo),e(Ba,xIo),e(to,$Io),e(to,Yr),e(Yr,nb),e(nb,Gme),e(Gme,kIo),e(nb,SIo),e(nb,lO),e(lO,RIo),e(nb,PIo),e(Yr,BIo),e(Yr,sb),e(sb,Ome),e(Ome,IIo),e(sb,qIo),e(sb,iO),e(iO,NIo),e(sb,jIo),e(Yr,DIo),e(Yr,lb),e(lb,Vme),e(Vme,GIo),e(lb,OIo),e(lb,dO),e(dO,VIo),e(lb,XIo),e(Yr,zIo),e(Yr,ib),e(ib,Xme),e(Xme,WIo),e(ib,QIo),e(ib,cO),e(cO,HIo),e(ib,UIo),e(Yr,JIo),e(Yr,db),e(db,zme),e(zme,YIo),e(db,KIo),e(db,fO),e(fO,ZIo),e(db,eqo),e(to,oqo),e(to,cb),e(cb,rqo),e(cb,Wme),e(Wme,tqo),e(cb,aqo),e(cb,Qme),e(Qme,nqo),e(to,sqo),M(fb,to,null),b(f,Cqe,u),b(f,Hi,u),e(Hi,mb),e(mb,Hme),M(wy,Hme,null),e(Hi,lqo),e(Hi,Ume),e(Ume,iqo),b(f,wqe,u),b(f,Io,u),M(Ay,Io,null),e(Io,dqo),e(Io,Ui),e(Ui,cqo),e(Ui,mO),e(mO,fqo),e(Ui,mqo),e(Ui,gO),e(gO,gqo),e(Ui,hqo),e(Io,pqo),e(Io,yy),e(yy,_qo),e(yy,Jme),e(Jme,uqo),e(yy,bqo),e(Io,vqo),e(Io,ft),M(Ly,ft,null),e(ft,Fqo),e(ft,Yme),e(Yme,Tqo),e(ft,Mqo),e(ft,Ji),e(Ji,Eqo),e(Ji,Kme),e(Kme,Cqo),e(Ji,wqo),e(Ji,hO),e(hO,Aqo),e(Ji,yqo),e(ft,Lqo),M(gb,ft,null),e(Io,xqo),e(Io,ao),M(xy,ao,null),e(ao,$qo),e(ao,Zme),e(Zme,kqo),e(ao,Sqo),e(ao,Ia),e(Ia,Rqo),e(Ia,ege),e(ege,Pqo),e(Ia,Bqo),e(Ia,oge),e(oge,Iqo),e(Ia,qqo),e(Ia,rge),e(rge,Nqo),e(Ia,jqo),e(ao,Dqo),e(ao,U),e(U,hb),e(hb,tge),e(tge,Gqo),e(hb,Oqo),e(hb,pO),e(pO,Vqo),e(hb,Xqo),e(U,zqo),e(U,pb),e(pb,age),e(age,Wqo),e(pb,Qqo),e(pb,_O),e(_O,Hqo),e(pb,Uqo),e(U,Jqo),e(U,_b),e(_b,nge),e(nge,Yqo),e(_b,Kqo),e(_b,uO),e(uO,Zqo),e(_b,eNo),e(U,oNo),e(U,ub),e(ub,sge),e(sge,rNo),e(ub,tNo),e(ub,bO),e(bO,aNo),e(ub,nNo),e(U,sNo),e(U,bb),e(bb,lge),e(lge,lNo),e(bb,iNo),e(bb,vO),e(vO,dNo),e(bb,cNo),e(U,fNo),e(U,vb),e(vb,ige),e(ige,mNo),e(vb,gNo),e(vb,FO),e(FO,hNo),e(vb,pNo),e(U,_No),e(U,Fb),e(Fb,dge),e(dge,uNo),e(Fb,bNo),e(Fb,TO),e(TO,vNo),e(Fb,FNo),e(U,TNo),e(U,Tb),e(Tb,cge),e(cge,MNo),e(Tb,ENo),e(Tb,MO),e(MO,CNo),e(Tb,wNo),e(U,ANo),e(U,Mb),e(Mb,fge),e(fge,yNo),e(Mb,LNo),e(Mb,EO),e(EO,xNo),e(Mb,$No),e(U,kNo),e(U,Eb),e(Eb,mge),e(mge,SNo),e(Eb,RNo),e(Eb,CO),e(CO,PNo),e(Eb,BNo),e(U,INo),e(U,Cb),e(Cb,gge),e(gge,qNo),e(Cb,NNo),e(Cb,wO),e(wO,jNo),e(Cb,DNo),e(U,GNo),e(U,wb),e(wb,hge),e(hge,ONo),e(wb,VNo),e(wb,AO),e(AO,XNo),e(wb,zNo),e(U,WNo),e(U,Ab),e(Ab,pge),e(pge,QNo),e(Ab,HNo),e(Ab,yO),e(yO,UNo),e(Ab,JNo),e(U,YNo),e(U,yb),e(yb,_ge),e(_ge,KNo),e(yb,ZNo),e(yb,LO),e(LO,ejo),e(yb,ojo),e(U,rjo),e(U,Lb),e(Lb,uge),e(uge,tjo),e(Lb,ajo),e(Lb,xO),e(xO,njo),e(Lb,sjo),e(U,ljo),e(U,xb),e(xb,bge),e(bge,ijo),e(xb,djo),e(xb,$O),e($O,cjo),e(xb,fjo),e(U,mjo),e(U,$b),e($b,vge),e(vge,gjo),e($b,hjo),e($b,kO),e(kO,pjo),e($b,_jo),e(U,ujo),e(U,kb),e(kb,Fge),e(Fge,bjo),e(kb,vjo),e(kb,SO),e(SO,Fjo),e(kb,Tjo),e(U,Mjo),e(U,Sb),e(Sb,Tge),e(Tge,Ejo),e(Sb,Cjo),e(Sb,RO),e(RO,wjo),e(Sb,Ajo),e(U,yjo),e(U,Rb),e(Rb,Mge),e(Mge,Ljo),e(Rb,xjo),e(Rb,PO),e(PO,$jo),e(Rb,kjo),e(U,Sjo),e(U,Pb),e(Pb,Ege),e(Ege,Rjo),e(Pb,Pjo),e(Pb,BO),e(BO,Bjo),e(Pb,Ijo),e(U,qjo),e(U,Bb),e(Bb,Cge),e(Cge,Njo),e(Bb,jjo),e(Bb,IO),e(IO,Djo),e(Bb,Gjo),e(U,Ojo),e(U,Ib),e(Ib,wge),e(wge,Vjo),e(Ib,Xjo),e(Ib,qO),e(qO,zjo),e(Ib,Wjo),e(U,Qjo),e(U,qb),e(qb,Age),e(Age,Hjo),e(qb,Ujo),e(qb,NO),e(NO,Jjo),e(qb,Yjo),e(U,Kjo),e(U,Nb),e(Nb,yge),e(yge,Zjo),e(Nb,eDo),e(Nb,jO),e(jO,oDo),e(Nb,rDo),e(U,tDo),e(U,jb),e(jb,Lge),e(Lge,aDo),e(jb,nDo),e(jb,DO),e(DO,sDo),e(jb,lDo),e(U,iDo),e(U,Db),e(Db,xge),e(xge,dDo),e(Db,cDo),e(Db,GO),e(GO,fDo),e(Db,mDo),e(U,gDo),e(U,Gb),e(Gb,$ge),e($ge,hDo),e(Gb,pDo),e(Gb,OO),e(OO,_Do),e(Gb,uDo),e(U,bDo),e(U,Ob),e(Ob,kge),e(kge,vDo),e(Ob,FDo),e(Ob,VO),e(VO,TDo),e(Ob,MDo),e(U,EDo),e(U,Vb),e(Vb,Sge),e(Sge,CDo),e(Vb,wDo),e(Vb,XO),e(XO,ADo),e(Vb,yDo),e(U,LDo),e(U,Xb),e(Xb,Rge),e(Rge,xDo),e(Xb,$Do),e(Xb,zO),e(zO,kDo),e(Xb,SDo),e(U,RDo),e(U,zb),e(zb,Pge),e(Pge,PDo),e(zb,BDo),e(zb,WO),e(WO,IDo),e(zb,qDo),e(U,NDo),e(U,Wb),e(Wb,Bge),e(Bge,jDo),e(Wb,DDo),e(Wb,QO),e(QO,GDo),e(Wb,ODo),e(ao,VDo),e(ao,Qb),e(Qb,XDo),e(Qb,Ige),e(Ige,zDo),e(Qb,WDo),e(Qb,qge),e(qge,QDo),e(ao,HDo),M(Hb,ao,null),b(f,Aqe,u),b(f,Yi,u),e(Yi,Ub),e(Ub,Nge),M($y,Nge,null),e(Yi,UDo),e(Yi,jge),e(jge,JDo),b(f,yqe,u),b(f,qo,u),M(ky,qo,null),e(qo,YDo),e(qo,Ki),e(Ki,KDo),e(Ki,HO),e(HO,ZDo),e(Ki,eGo),e(Ki,UO),e(UO,oGo),e(Ki,rGo),e(qo,tGo),e(qo,Sy),e(Sy,aGo),e(Sy,Dge),e(Dge,nGo),e(Sy,sGo),e(qo,lGo),e(qo,mt),M(Ry,mt,null),e(mt,iGo),e(mt,Gge),e(Gge,dGo),e(mt,cGo),e(mt,Zi),e(Zi,fGo),e(Zi,Oge),e(Oge,mGo),e(Zi,gGo),e(Zi,JO),e(JO,hGo),e(Zi,pGo),e(mt,_Go),M(Jb,mt,null),e(qo,uGo),e(qo,no),M(Py,no,null),e(no,bGo),e(no,Vge),e(Vge,vGo),e(no,FGo),e(no,qa),e(qa,TGo),e(qa,Xge),e(Xge,MGo),e(qa,EGo),e(qa,zge),e(zge,CGo),e(qa,wGo),e(qa,Wge),e(Wge,AGo),e(qa,yGo),e(no,LGo),e(no,V),e(V,Yb),e(Yb,Qge),e(Qge,xGo),e(Yb,$Go),e(Yb,YO),e(YO,kGo),e(Yb,SGo),e(V,RGo),e(V,Kb),e(Kb,Hge),e(Hge,PGo),e(Kb,BGo),e(Kb,KO),e(KO,IGo),e(Kb,qGo),e(V,NGo),e(V,Zb),e(Zb,Uge),e(Uge,jGo),e(Zb,DGo),e(Zb,ZO),e(ZO,GGo),e(Zb,OGo),e(V,VGo),e(V,ev),e(ev,Jge),e(Jge,XGo),e(ev,zGo),e(ev,eV),e(eV,WGo),e(ev,QGo),e(V,HGo),e(V,ov),e(ov,Yge),e(Yge,UGo),e(ov,JGo),e(ov,oV),e(oV,YGo),e(ov,KGo),e(V,ZGo),e(V,rv),e(rv,Kge),e(Kge,eOo),e(rv,oOo),e(rv,rV),e(rV,rOo),e(rv,tOo),e(V,aOo),e(V,tv),e(tv,Zge),e(Zge,nOo),e(tv,sOo),e(tv,tV),e(tV,lOo),e(tv,iOo),e(V,dOo),e(V,av),e(av,ehe),e(ehe,cOo),e(av,fOo),e(av,aV),e(aV,mOo),e(av,gOo),e(V,hOo),e(V,nv),e(nv,ohe),e(ohe,pOo),e(nv,_Oo),e(nv,nV),e(nV,uOo),e(nv,bOo),e(V,vOo),e(V,sv),e(sv,rhe),e(rhe,FOo),e(sv,TOo),e(sv,sV),e(sV,MOo),e(sv,EOo),e(V,COo),e(V,lv),e(lv,the),e(the,wOo),e(lv,AOo),e(lv,lV),e(lV,yOo),e(lv,LOo),e(V,xOo),e(V,iv),e(iv,ahe),e(ahe,$Oo),e(iv,kOo),e(iv,iV),e(iV,SOo),e(iv,ROo),e(V,POo),e(V,dv),e(dv,nhe),e(nhe,BOo),e(dv,IOo),e(dv,dV),e(dV,qOo),e(dv,NOo),e(V,jOo),e(V,cv),e(cv,she),e(she,DOo),e(cv,GOo),e(cv,cV),e(cV,OOo),e(cv,VOo),e(V,XOo),e(V,fv),e(fv,lhe),e(lhe,zOo),e(fv,WOo),e(fv,fV),e(fV,QOo),e(fv,HOo),e(V,UOo),e(V,mv),e(mv,ihe),e(ihe,JOo),e(mv,YOo),e(mv,mV),e(mV,KOo),e(mv,ZOo),e(V,eVo),e(V,gv),e(gv,dhe),e(dhe,oVo),e(gv,rVo),e(gv,gV),e(gV,tVo),e(gv,aVo),e(V,nVo),e(V,hv),e(hv,che),e(che,sVo),e(hv,lVo),e(hv,hV),e(hV,iVo),e(hv,dVo),e(V,cVo),e(V,pv),e(pv,fhe),e(fhe,fVo),e(pv,mVo),e(pv,pV),e(pV,gVo),e(pv,hVo),e(V,pVo),e(V,_v),e(_v,mhe),e(mhe,_Vo),e(_v,uVo),e(_v,_V),e(_V,bVo),e(_v,vVo),e(V,FVo),e(V,uv),e(uv,ghe),e(ghe,TVo),e(uv,MVo),e(uv,uV),e(uV,EVo),e(uv,CVo),e(V,wVo),e(V,bv),e(bv,hhe),e(hhe,AVo),e(bv,yVo),e(bv,bV),e(bV,LVo),e(bv,xVo),e(V,$Vo),e(V,vv),e(vv,phe),e(phe,kVo),e(vv,SVo),e(vv,vV),e(vV,RVo),e(vv,PVo),e(V,BVo),e(V,Fv),e(Fv,_he),e(_he,IVo),e(Fv,qVo),e(Fv,FV),e(FV,NVo),e(Fv,jVo),e(V,DVo),e(V,Tv),e(Tv,uhe),e(uhe,GVo),e(Tv,OVo),e(Tv,TV),e(TV,VVo),e(Tv,XVo),e(V,zVo),e(V,Mv),e(Mv,bhe),e(bhe,WVo),e(Mv,QVo),e(Mv,MV),e(MV,HVo),e(Mv,UVo),e(V,JVo),e(V,Ev),e(Ev,vhe),e(vhe,YVo),e(Ev,KVo),e(Ev,EV),e(EV,ZVo),e(Ev,eXo),e(V,oXo),e(V,Cv),e(Cv,Fhe),e(Fhe,rXo),e(Cv,tXo),e(Cv,CV),e(CV,aXo),e(Cv,nXo),e(V,sXo),e(V,wv),e(wv,The),e(The,lXo),e(wv,iXo),e(wv,wV),e(wV,dXo),e(wv,cXo),e(V,fXo),e(V,Av),e(Av,Mhe),e(Mhe,mXo),e(Av,gXo),e(Av,AV),e(AV,hXo),e(Av,pXo),e(V,_Xo),e(V,yv),e(yv,Ehe),e(Ehe,uXo),e(yv,bXo),e(yv,yV),e(yV,vXo),e(yv,FXo),e(V,TXo),e(V,Lv),e(Lv,Che),e(Che,MXo),e(Lv,EXo),e(Lv,LV),e(LV,CXo),e(Lv,wXo),e(V,AXo),e(V,xv),e(xv,whe),e(whe,yXo),e(xv,LXo),e(xv,xV),e(xV,xXo),e(xv,$Xo),e(V,kXo),e(V,$v),e($v,Ahe),e(Ahe,SXo),e($v,RXo),e($v,$V),e($V,PXo),e($v,BXo),e(V,IXo),e(V,kv),e(kv,yhe),e(yhe,qXo),e(kv,NXo),e(kv,kV),e(kV,jXo),e(kv,DXo),e(V,GXo),e(V,Sv),e(Sv,Lhe),e(Lhe,OXo),e(Sv,VXo),e(Sv,SV),e(SV,XXo),e(Sv,zXo),e(V,WXo),e(V,Rv),e(Rv,xhe),e(xhe,QXo),e(Rv,HXo),e(Rv,RV),e(RV,UXo),e(Rv,JXo),e(V,YXo),e(V,Pv),e(Pv,$he),e($he,KXo),e(Pv,ZXo),e(Pv,PV),e(PV,ezo),e(Pv,ozo),e(V,rzo),e(V,Bv),e(Bv,khe),e(khe,tzo),e(Bv,azo),e(Bv,BV),e(BV,nzo),e(Bv,szo),e(no,lzo),e(no,Iv),e(Iv,izo),e(Iv,She),e(She,dzo),e(Iv,czo),e(Iv,Rhe),e(Rhe,fzo),e(no,mzo),M(qv,no,null),b(f,Lqe,u),b(f,ed,u),e(ed,Nv),e(Nv,Phe),M(By,Phe,null),e(ed,gzo),e(ed,Bhe),e(Bhe,hzo),b(f,xqe,u),b(f,No,u),M(Iy,No,null),e(No,pzo),e(No,od),e(od,_zo),e(od,IV),e(IV,uzo),e(od,bzo),e(od,qV),e(qV,vzo),e(od,Fzo),e(No,Tzo),e(No,qy),e(qy,Mzo),e(qy,Ihe),e(Ihe,Ezo),e(qy,Czo),e(No,wzo),e(No,gt),M(Ny,gt,null),e(gt,Azo),e(gt,qhe),e(qhe,yzo),e(gt,Lzo),e(gt,rd),e(rd,xzo),e(rd,Nhe),e(Nhe,$zo),e(rd,kzo),e(rd,NV),e(NV,Szo),e(rd,Rzo),e(gt,Pzo),M(jv,gt,null),e(No,Bzo),e(No,so),M(jy,so,null),e(so,Izo),e(so,jhe),e(jhe,qzo),e(so,Nzo),e(so,Na),e(Na,jzo),e(Na,Dhe),e(Dhe,Dzo),e(Na,Gzo),e(Na,Ghe),e(Ghe,Ozo),e(Na,Vzo),e(Na,Ohe),e(Ohe,Xzo),e(Na,zzo),e(so,Wzo),e(so,Vhe),e(Vhe,Dv),e(Dv,Xhe),e(Xhe,Qzo),e(Dv,Hzo),e(Dv,jV),e(jV,Uzo),e(Dv,Jzo),e(so,Yzo),e(so,Gv),e(Gv,Kzo),e(Gv,zhe),e(zhe,Zzo),e(Gv,eWo),e(Gv,Whe),e(Whe,oWo),e(so,rWo),M(Ov,so,null),b(f,$qe,u),b(f,td,u),e(td,Vv),e(Vv,Qhe),M(Dy,Qhe,null),e(td,tWo),e(td,Hhe),e(Hhe,aWo),b(f,kqe,u),b(f,jo,u),M(Gy,jo,null),e(jo,nWo),e(jo,ad),e(ad,sWo),e(ad,DV),e(DV,lWo),e(ad,iWo),e(ad,GV),e(GV,dWo),e(ad,cWo),e(jo,fWo),e(jo,Oy),e(Oy,mWo),e(Oy,Uhe),e(Uhe,gWo),e(Oy,hWo),e(jo,pWo),e(jo,ht),M(Vy,ht,null),e(ht,_Wo),e(ht,Jhe),e(Jhe,uWo),e(ht,bWo),e(ht,nd),e(nd,vWo),e(nd,Yhe),e(Yhe,FWo),e(nd,TWo),e(nd,OV),e(OV,MWo),e(nd,EWo),e(ht,CWo),M(Xv,ht,null),e(jo,wWo),e(jo,lo),M(Xy,lo,null),e(lo,AWo),e(lo,Khe),e(Khe,yWo),e(lo,LWo),e(lo,ja),e(ja,xWo),e(ja,Zhe),e(Zhe,$Wo),e(ja,kWo),e(ja,epe),e(epe,SWo),e(ja,RWo),e(ja,ope),e(ope,PWo),e(ja,BWo),e(lo,IWo),e(lo,Fe),e(Fe,zv),e(zv,rpe),e(rpe,qWo),e(zv,NWo),e(zv,VV),e(VV,jWo),e(zv,DWo),e(Fe,GWo),e(Fe,Wv),e(Wv,tpe),e(tpe,OWo),e(Wv,VWo),e(Wv,XV),e(XV,XWo),e(Wv,zWo),e(Fe,WWo),e(Fe,Qv),e(Qv,ape),e(ape,QWo),e(Qv,HWo),e(Qv,zV),e(zV,UWo),e(Qv,JWo),e(Fe,YWo),e(Fe,Ps),e(Ps,npe),e(npe,KWo),e(Ps,ZWo),e(Ps,WV),e(WV,eQo),e(Ps,oQo),e(Ps,QV),e(QV,rQo),e(Ps,tQo),e(Fe,aQo),e(Fe,Hv),e(Hv,spe),e(spe,nQo),e(Hv,sQo),e(Hv,HV),e(HV,lQo),e(Hv,iQo),e(Fe,dQo),e(Fe,pt),e(pt,lpe),e(lpe,cQo),e(pt,fQo),e(pt,UV),e(UV,mQo),e(pt,gQo),e(pt,JV),e(JV,hQo),e(pt,pQo),e(pt,YV),e(YV,_Qo),e(pt,uQo),e(Fe,bQo),e(Fe,Uv),e(Uv,ipe),e(ipe,vQo),e(Uv,FQo),e(Uv,KV),e(KV,TQo),e(Uv,MQo),e(Fe,EQo),e(Fe,Jv),e(Jv,dpe),e(dpe,CQo),e(Jv,wQo),e(Jv,ZV),e(ZV,AQo),e(Jv,yQo),e(Fe,LQo),e(Fe,Yv),e(Yv,cpe),e(cpe,xQo),e(Yv,$Qo),e(Yv,eX),e(eX,kQo),e(Yv,SQo),e(Fe,RQo),e(Fe,Kv),e(Kv,fpe),e(fpe,PQo),e(Kv,BQo),e(Kv,oX),e(oX,IQo),e(Kv,qQo),e(Fe,NQo),e(Fe,Zv),e(Zv,mpe),e(mpe,jQo),e(Zv,DQo),e(Zv,rX),e(rX,GQo),e(Zv,OQo),e(Fe,VQo),e(Fe,eF),e(eF,gpe),e(gpe,XQo),e(eF,zQo),e(eF,tX),e(tX,WQo),e(eF,QQo),e(Fe,HQo),e(Fe,oF),e(oF,hpe),e(hpe,UQo),e(oF,JQo),e(oF,aX),e(aX,YQo),e(oF,KQo),e(lo,ZQo),e(lo,rF),e(rF,eHo),e(rF,ppe),e(ppe,oHo),e(rF,rHo),e(rF,_pe),e(_pe,tHo),e(lo,aHo),M(tF,lo,null),b(f,Sqe,u),b(f,sd,u),e(sd,aF),e(aF,upe),M(zy,upe,null),e(sd,nHo),e(sd,bpe),e(bpe,sHo),b(f,Rqe,u),b(f,Do,u),M(Wy,Do,null),e(Do,lHo),e(Do,ld),e(ld,iHo),e(ld,nX),e(nX,dHo),e(ld,cHo),e(ld,sX),e(sX,fHo),e(ld,mHo),e(Do,gHo),e(Do,Qy),e(Qy,hHo),e(Qy,vpe),e(vpe,pHo),e(Qy,_Ho),e(Do,uHo),e(Do,_t),M(Hy,_t,null),e(_t,bHo),e(_t,Fpe),e(Fpe,vHo),e(_t,FHo),e(_t,id),e(id,THo),e(id,Tpe),e(Tpe,MHo),e(id,EHo),e(id,lX),e(lX,CHo),e(id,wHo),e(_t,AHo),M(nF,_t,null),e(Do,yHo),e(Do,io),M(Uy,io,null),e(io,LHo),e(io,Mpe),e(Mpe,xHo),e(io,$Ho),e(io,Da),e(Da,kHo),e(Da,Epe),e(Epe,SHo),e(Da,RHo),e(Da,Cpe),e(Cpe,PHo),e(Da,BHo),e(Da,wpe),e(wpe,IHo),e(Da,qHo),e(io,NHo),e(io,Ape),e(Ape,sF),e(sF,ype),e(ype,jHo),e(sF,DHo),e(sF,iX),e(iX,GHo),e(sF,OHo),e(io,VHo),e(io,lF),e(lF,XHo),e(lF,Lpe),e(Lpe,zHo),e(lF,WHo),e(lF,xpe),e(xpe,QHo),e(io,HHo),M(iF,io,null),b(f,Pqe,u),b(f,dd,u),e(dd,dF),e(dF,$pe),M(Jy,$pe,null),e(dd,UHo),e(dd,kpe),e(kpe,JHo),b(f,Bqe,u),b(f,Go,u),M(Yy,Go,null),e(Go,YHo),e(Go,cd),e(cd,KHo),e(cd,dX),e(dX,ZHo),e(cd,eUo),e(cd,cX),e(cX,oUo),e(cd,rUo),e(Go,tUo),e(Go,Ky),e(Ky,aUo),e(Ky,Spe),e(Spe,nUo),e(Ky,sUo),e(Go,lUo),e(Go,ut),M(Zy,ut,null),e(ut,iUo),e(ut,Rpe),e(Rpe,dUo),e(ut,cUo),e(ut,fd),e(fd,fUo),e(fd,Ppe),e(Ppe,mUo),e(fd,gUo),e(fd,fX),e(fX,hUo),e(fd,pUo),e(ut,_Uo),M(cF,ut,null),e(Go,uUo),e(Go,co),M(eL,co,null),e(co,bUo),e(co,Bpe),e(Bpe,vUo),e(co,FUo),e(co,Ga),e(Ga,TUo),e(Ga,Ipe),e(Ipe,MUo),e(Ga,EUo),e(Ga,qpe),e(qpe,CUo),e(Ga,wUo),e(Ga,Npe),e(Npe,AUo),e(Ga,yUo),e(co,LUo),e(co,Se),e(Se,fF),e(fF,jpe),e(jpe,xUo),e(fF,$Uo),e(fF,mX),e(mX,kUo),e(fF,SUo),e(Se,RUo),e(Se,mF),e(mF,Dpe),e(Dpe,PUo),e(mF,BUo),e(mF,gX),e(gX,IUo),e(mF,qUo),e(Se,NUo),e(Se,gF),e(gF,Gpe),e(Gpe,jUo),e(gF,DUo),e(gF,hX),e(hX,GUo),e(gF,OUo),e(Se,VUo),e(Se,hF),e(hF,Ope),e(Ope,XUo),e(hF,zUo),e(hF,pX),e(pX,WUo),e(hF,QUo),e(Se,HUo),e(Se,pF),e(pF,Vpe),e(Vpe,UUo),e(pF,JUo),e(pF,_X),e(_X,YUo),e(pF,KUo),e(Se,ZUo),e(Se,_F),e(_F,Xpe),e(Xpe,eJo),e(_F,oJo),e(_F,uX),e(uX,rJo),e(_F,tJo),e(Se,aJo),e(Se,uF),e(uF,zpe),e(zpe,nJo),e(uF,sJo),e(uF,bX),e(bX,lJo),e(uF,iJo),e(Se,dJo),e(Se,bF),e(bF,Wpe),e(Wpe,cJo),e(bF,fJo),e(bF,vX),e(vX,mJo),e(bF,gJo),e(Se,hJo),e(Se,vF),e(vF,Qpe),e(Qpe,pJo),e(vF,_Jo),e(vF,FX),e(FX,uJo),e(vF,bJo),e(co,vJo),e(co,FF),e(FF,FJo),e(FF,Hpe),e(Hpe,TJo),e(FF,MJo),e(FF,Upe),e(Upe,EJo),e(co,CJo),M(TF,co,null),b(f,Iqe,u),b(f,md,u),e(md,MF),e(MF,Jpe),M(oL,Jpe,null),e(md,wJo),e(md,Ype),e(Ype,AJo),b(f,qqe,u),b(f,Oo,u),M(rL,Oo,null),e(Oo,yJo),e(Oo,gd),e(gd,LJo),e(gd,TX),e(TX,xJo),e(gd,$Jo),e(gd,MX),e(MX,kJo),e(gd,SJo),e(Oo,RJo),e(Oo,tL),e(tL,PJo),e(tL,Kpe),e(Kpe,BJo),e(tL,IJo),e(Oo,qJo),e(Oo,bt),M(aL,bt,null),e(bt,NJo),e(bt,Zpe),e(Zpe,jJo),e(bt,DJo),e(bt,hd),e(hd,GJo),e(hd,e_e),e(e_e,OJo),e(hd,VJo),e(hd,EX),e(EX,XJo),e(hd,zJo),e(bt,WJo),M(EF,bt,null),e(Oo,QJo),e(Oo,fo),M(nL,fo,null),e(fo,HJo),e(fo,o_e),e(o_e,UJo),e(fo,JJo),e(fo,Oa),e(Oa,YJo),e(Oa,r_e),e(r_e,KJo),e(Oa,ZJo),e(Oa,t_e),e(t_e,eYo),e(Oa,oYo),e(Oa,a_e),e(a_e,rYo),e(Oa,tYo),e(fo,aYo),e(fo,Kr),e(Kr,CF),e(CF,n_e),e(n_e,nYo),e(CF,sYo),e(CF,CX),e(CX,lYo),e(CF,iYo),e(Kr,dYo),e(Kr,wF),e(wF,s_e),e(s_e,cYo),e(wF,fYo),e(wF,wX),e(wX,mYo),e(wF,gYo),e(Kr,hYo),e(Kr,AF),e(AF,l_e),e(l_e,pYo),e(AF,_Yo),e(AF,AX),e(AX,uYo),e(AF,bYo),e(Kr,vYo),e(Kr,yF),e(yF,i_e),e(i_e,FYo),e(yF,TYo),e(yF,yX),e(yX,MYo),e(yF,EYo),e(Kr,CYo),e(Kr,LF),e(LF,d_e),e(d_e,wYo),e(LF,AYo),e(LF,LX),e(LX,yYo),e(LF,LYo),e(fo,xYo),e(fo,xF),e(xF,$Yo),e(xF,c_e),e(c_e,kYo),e(xF,SYo),e(xF,f_e),e(f_e,RYo),e(fo,PYo),M($F,fo,null),b(f,Nqe,u),b(f,pd,u),e(pd,kF),e(kF,m_e),M(sL,m_e,null),e(pd,BYo),e(pd,g_e),e(g_e,IYo),b(f,jqe,u),b(f,Vo,u),M(lL,Vo,null),e(Vo,qYo),e(Vo,_d),e(_d,NYo),e(_d,xX),e(xX,jYo),e(_d,DYo),e(_d,$X),e($X,GYo),e(_d,OYo),e(Vo,VYo),e(Vo,iL),e(iL,XYo),e(iL,h_e),e(h_e,zYo),e(iL,WYo),e(Vo,QYo),e(Vo,vt),M(dL,vt,null),e(vt,HYo),e(vt,p_e),e(p_e,UYo),e(vt,JYo),e(vt,ud),e(ud,YYo),e(ud,__e),e(__e,KYo),e(ud,ZYo),e(ud,kX),e(kX,eKo),e(ud,oKo),e(vt,rKo),M(SF,vt,null),e(Vo,tKo),e(Vo,mo),M(cL,mo,null),e(mo,aKo),e(mo,u_e),e(u_e,nKo),e(mo,sKo),e(mo,Va),e(Va,lKo),e(Va,b_e),e(b_e,iKo),e(Va,dKo),e(Va,v_e),e(v_e,cKo),e(Va,fKo),e(Va,F_e),e(F_e,mKo),e(Va,gKo),e(mo,hKo),e(mo,Re),e(Re,RF),e(RF,T_e),e(T_e,pKo),e(RF,_Ko),e(RF,SX),e(SX,uKo),e(RF,bKo),e(Re,vKo),e(Re,PF),e(PF,M_e),e(M_e,FKo),e(PF,TKo),e(PF,RX),e(RX,MKo),e(PF,EKo),e(Re,CKo),e(Re,BF),e(BF,E_e),e(E_e,wKo),e(BF,AKo),e(BF,PX),e(PX,yKo),e(BF,LKo),e(Re,xKo),e(Re,IF),e(IF,C_e),e(C_e,$Ko),e(IF,kKo),e(IF,BX),e(BX,SKo),e(IF,RKo),e(Re,PKo),e(Re,qF),e(qF,w_e),e(w_e,BKo),e(qF,IKo),e(qF,IX),e(IX,qKo),e(qF,NKo),e(Re,jKo),e(Re,NF),e(NF,A_e),e(A_e,DKo),e(NF,GKo),e(NF,qX),e(qX,OKo),e(NF,VKo),e(Re,XKo),e(Re,jF),e(jF,y_e),e(y_e,zKo),e(jF,WKo),e(jF,NX),e(NX,QKo),e(jF,HKo),e(Re,UKo),e(Re,DF),e(DF,L_e),e(L_e,JKo),e(DF,YKo),e(DF,jX),e(jX,KKo),e(DF,ZKo),e(Re,eZo),e(Re,GF),e(GF,x_e),e(x_e,oZo),e(GF,rZo),e(GF,DX),e(DX,tZo),e(GF,aZo),e(mo,nZo),e(mo,OF),e(OF,sZo),e(OF,$_e),e($_e,lZo),e(OF,iZo),e(OF,k_e),e(k_e,dZo),e(mo,cZo),M(VF,mo,null),b(f,Dqe,u),b(f,bd,u),e(bd,XF),e(XF,S_e),M(fL,S_e,null),e(bd,fZo),e(bd,R_e),e(R_e,mZo),b(f,Gqe,u),b(f,Xo,u),M(mL,Xo,null),e(Xo,gZo),e(Xo,vd),e(vd,hZo),e(vd,GX),e(GX,pZo),e(vd,_Zo),e(vd,OX),e(OX,uZo),e(vd,bZo),e(Xo,vZo),e(Xo,gL),e(gL,FZo),e(gL,P_e),e(P_e,TZo),e(gL,MZo),e(Xo,EZo),e(Xo,Ft),M(hL,Ft,null),e(Ft,CZo),e(Ft,B_e),e(B_e,wZo),e(Ft,AZo),e(Ft,Fd),e(Fd,yZo),e(Fd,I_e),e(I_e,LZo),e(Fd,xZo),e(Fd,VX),e(VX,$Zo),e(Fd,kZo),e(Ft,SZo),M(zF,Ft,null),e(Xo,RZo),e(Xo,go),M(pL,go,null),e(go,PZo),e(go,q_e),e(q_e,BZo),e(go,IZo),e(go,Xa),e(Xa,qZo),e(Xa,N_e),e(N_e,NZo),e(Xa,jZo),e(Xa,j_e),e(j_e,DZo),e(Xa,GZo),e(Xa,D_e),e(D_e,OZo),e(Xa,VZo),e(go,XZo),e(go,_L),e(_L,WF),e(WF,G_e),e(G_e,zZo),e(WF,WZo),e(WF,XX),e(XX,QZo),e(WF,HZo),e(_L,UZo),e(_L,QF),e(QF,O_e),e(O_e,JZo),e(QF,YZo),e(QF,zX),e(zX,KZo),e(QF,ZZo),e(go,eer),e(go,HF),e(HF,oer),e(HF,V_e),e(V_e,rer),e(HF,ter),e(HF,X_e),e(X_e,aer),e(go,ner),M(UF,go,null),b(f,Oqe,u),b(f,Td,u),e(Td,JF),e(JF,z_e),M(uL,z_e,null),e(Td,ser),e(Td,W_e),e(W_e,ler),b(f,Vqe,u),b(f,zo,u),M(bL,zo,null),e(zo,ier),e(zo,Md),e(Md,der),e(Md,WX),e(WX,cer),e(Md,fer),e(Md,QX),e(QX,mer),e(Md,ger),e(zo,her),e(zo,vL),e(vL,per),e(vL,Q_e),e(Q_e,_er),e(vL,uer),e(zo,ber),e(zo,Tt),M(FL,Tt,null),e(Tt,ver),e(Tt,H_e),e(H_e,Fer),e(Tt,Ter),e(Tt,Ed),e(Ed,Mer),e(Ed,U_e),e(U_e,Eer),e(Ed,Cer),e(Ed,HX),e(HX,wer),e(Ed,Aer),e(Tt,yer),M(YF,Tt,null),e(zo,Ler),e(zo,ho),M(TL,ho,null),e(ho,xer),e(ho,J_e),e(J_e,$er),e(ho,ker),e(ho,za),e(za,Ser),e(za,Y_e),e(Y_e,Rer),e(za,Per),e(za,K_e),e(K_e,Ber),e(za,Ier),e(za,Z_e),e(Z_e,qer),e(za,Ner),e(ho,jer),e(ho,Zr),e(Zr,KF),e(KF,eue),e(eue,Der),e(KF,Ger),e(KF,UX),e(UX,Oer),e(KF,Ver),e(Zr,Xer),e(Zr,ZF),e(ZF,oue),e(oue,zer),e(ZF,Wer),e(ZF,JX),e(JX,Qer),e(ZF,Her),e(Zr,Uer),e(Zr,eT),e(eT,rue),e(rue,Jer),e(eT,Yer),e(eT,YX),e(YX,Ker),e(eT,Zer),e(Zr,eor),e(Zr,oT),e(oT,tue),e(tue,oor),e(oT,ror),e(oT,KX),e(KX,tor),e(oT,aor),e(Zr,nor),e(Zr,rT),e(rT,aue),e(aue,sor),e(rT,lor),e(rT,ZX),e(ZX,ior),e(rT,dor),e(ho,cor),e(ho,tT),e(tT,mor),e(tT,nue),e(nue,gor),e(tT,hor),e(tT,sue),e(sue,por),e(ho,_or),M(aT,ho,null),b(f,Xqe,u),b(f,Cd,u),e(Cd,nT),e(nT,lue),M(ML,lue,null),e(Cd,uor),e(Cd,iue),e(iue,bor),b(f,zqe,u),b(f,Wo,u),M(EL,Wo,null),e(Wo,vor),e(Wo,wd),e(wd,For),e(wd,ez),e(ez,Tor),e(wd,Mor),e(wd,oz),e(oz,Eor),e(wd,Cor),e(Wo,wor),e(Wo,CL),e(CL,Aor),e(CL,due),e(due,yor),e(CL,Lor),e(Wo,xor),e(Wo,Mt),M(wL,Mt,null),e(Mt,$or),e(Mt,cue),e(cue,kor),e(Mt,Sor),e(Mt,Ad),e(Ad,Ror),e(Ad,fue),e(fue,Por),e(Ad,Bor),e(Ad,rz),e(rz,Ior),e(Ad,qor),e(Mt,Nor),M(sT,Mt,null),e(Wo,jor),e(Wo,po),M(AL,po,null),e(po,Dor),e(po,mue),e(mue,Gor),e(po,Oor),e(po,Wa),e(Wa,Vor),e(Wa,gue),e(gue,Xor),e(Wa,zor),e(Wa,hue),e(hue,Wor),e(Wa,Qor),e(Wa,pue),e(pue,Hor),e(Wa,Uor),e(po,Jor),e(po,yd),e(yd,lT),e(lT,_ue),e(_ue,Yor),e(lT,Kor),e(lT,tz),e(tz,Zor),e(lT,err),e(yd,orr),e(yd,iT),e(iT,uue),e(uue,rrr),e(iT,trr),e(iT,az),e(az,arr),e(iT,nrr),e(yd,srr),e(yd,dT),e(dT,bue),e(bue,lrr),e(dT,irr),e(dT,nz),e(nz,drr),e(dT,crr),e(po,frr),e(po,cT),e(cT,mrr),e(cT,vue),e(vue,grr),e(cT,hrr),e(cT,Fue),e(Fue,prr),e(po,_rr),M(fT,po,null),b(f,Wqe,u),b(f,Ld,u),e(Ld,mT),e(mT,Tue),M(yL,Tue,null),e(Ld,urr),e(Ld,Mue),e(Mue,brr),b(f,Qqe,u),b(f,Qo,u),M(LL,Qo,null),e(Qo,vrr),e(Qo,xd),e(xd,Frr),e(xd,sz),e(sz,Trr),e(xd,Mrr),e(xd,lz),e(lz,Err),e(xd,Crr),e(Qo,wrr),e(Qo,xL),e(xL,Arr),e(xL,Eue),e(Eue,yrr),e(xL,Lrr),e(Qo,xrr),e(Qo,Et),M($L,Et,null),e(Et,$rr),e(Et,Cue),e(Cue,krr),e(Et,Srr),e(Et,$d),e($d,Rrr),e($d,wue),e(wue,Prr),e($d,Brr),e($d,iz),e(iz,Irr),e($d,qrr),e(Et,Nrr),M(gT,Et,null),e(Qo,jrr),e(Qo,_o),M(kL,_o,null),e(_o,Drr),e(_o,Aue),e(Aue,Grr),e(_o,Orr),e(_o,Qa),e(Qa,Vrr),e(Qa,yue),e(yue,Xrr),e(Qa,zrr),e(Qa,Lue),e(Lue,Wrr),e(Qa,Qrr),e(Qa,xue),e(xue,Hrr),e(Qa,Urr),e(_o,Jrr),e(_o,SL),e(SL,hT),e(hT,$ue),e($ue,Yrr),e(hT,Krr),e(hT,dz),e(dz,Zrr),e(hT,etr),e(SL,otr),e(SL,pT),e(pT,kue),e(kue,rtr),e(pT,ttr),e(pT,cz),e(cz,atr),e(pT,ntr),e(_o,str),e(_o,_T),e(_T,ltr),e(_T,Sue),e(Sue,itr),e(_T,dtr),e(_T,Rue),e(Rue,ctr),e(_o,ftr),M(uT,_o,null),b(f,Hqe,u),b(f,kd,u),e(kd,bT),e(bT,Pue),M(RL,Pue,null),e(kd,mtr),e(kd,Bue),e(Bue,gtr),b(f,Uqe,u),b(f,Ho,u),M(PL,Ho,null),e(Ho,htr),e(Ho,Sd),e(Sd,ptr),e(Sd,fz),e(fz,_tr),e(Sd,utr),e(Sd,mz),e(mz,btr),e(Sd,vtr),e(Ho,Ftr),e(Ho,BL),e(BL,Ttr),e(BL,Iue),e(Iue,Mtr),e(BL,Etr),e(Ho,Ctr),e(Ho,Ct),M(IL,Ct,null),e(Ct,wtr),e(Ct,que),e(que,Atr),e(Ct,ytr),e(Ct,Rd),e(Rd,Ltr),e(Rd,Nue),e(Nue,xtr),e(Rd,$tr),e(Rd,gz),e(gz,ktr),e(Rd,Str),e(Ct,Rtr),M(vT,Ct,null),e(Ho,Ptr),e(Ho,uo),M(qL,uo,null),e(uo,Btr),e(uo,jue),e(jue,Itr),e(uo,qtr),e(uo,Ha),e(Ha,Ntr),e(Ha,Due),e(Due,jtr),e(Ha,Dtr),e(Ha,Gue),e(Gue,Gtr),e(Ha,Otr),e(Ha,Oue),e(Oue,Vtr),e(Ha,Xtr),e(uo,ztr),e(uo,Vue),e(Vue,FT),e(FT,Xue),e(Xue,Wtr),e(FT,Qtr),e(FT,hz),e(hz,Htr),e(FT,Utr),e(uo,Jtr),e(uo,TT),e(TT,Ytr),e(TT,zue),e(zue,Ktr),e(TT,Ztr),e(TT,Wue),e(Wue,ear),e(uo,oar),M(MT,uo,null),b(f,Jqe,u),b(f,Pd,u),e(Pd,ET),e(ET,Que),M(NL,Que,null),e(Pd,rar),e(Pd,Hue),e(Hue,tar),b(f,Yqe,u),b(f,Uo,u),M(jL,Uo,null),e(Uo,aar),e(Uo,Bd),e(Bd,nar),e(Bd,pz),e(pz,sar),e(Bd,lar),e(Bd,_z),e(_z,iar),e(Bd,dar),e(Uo,car),e(Uo,DL),e(DL,far),e(DL,Uue),e(Uue,mar),e(DL,gar),e(Uo,har),e(Uo,wt),M(GL,wt,null),e(wt,par),e(wt,Jue),e(Jue,_ar),e(wt,uar),e(wt,Id),e(Id,bar),e(Id,Yue),e(Yue,Far),e(Id,Tar),e(Id,uz),e(uz,Mar),e(Id,Ear),e(wt,Car),M(CT,wt,null),e(Uo,war),e(Uo,bo),M(OL,bo,null),e(bo,Aar),e(bo,Kue),e(Kue,yar),e(bo,Lar),e(bo,Ua),e(Ua,xar),e(Ua,Zue),e(Zue,$ar),e(Ua,kar),e(Ua,e2e),e(e2e,Sar),e(Ua,Rar),e(Ua,o2e),e(o2e,Par),e(Ua,Bar),e(bo,Iar),e(bo,Ja),e(Ja,wT),e(wT,r2e),e(r2e,qar),e(wT,Nar),e(wT,bz),e(bz,jar),e(wT,Dar),e(Ja,Gar),e(Ja,AT),e(AT,t2e),e(t2e,Oar),e(AT,Var),e(AT,vz),e(vz,Xar),e(AT,zar),e(Ja,War),e(Ja,yT),e(yT,a2e),e(a2e,Qar),e(yT,Har),e(yT,Fz),e(Fz,Uar),e(yT,Jar),e(Ja,Yar),e(Ja,LT),e(LT,n2e),e(n2e,Kar),e(LT,Zar),e(LT,Tz),e(Tz,enr),e(LT,onr),e(bo,rnr),e(bo,xT),e(xT,tnr),e(xT,s2e),e(s2e,anr),e(xT,nnr),e(xT,l2e),e(l2e,snr),e(bo,lnr),M($T,bo,null),b(f,Kqe,u),b(f,qd,u),e(qd,kT),e(kT,i2e),M(VL,i2e,null),e(qd,inr),e(qd,d2e),e(d2e,dnr),b(f,Zqe,u),b(f,Jo,u),M(XL,Jo,null),e(Jo,cnr),e(Jo,Nd),e(Nd,fnr),e(Nd,Mz),e(Mz,mnr),e(Nd,gnr),e(Nd,Ez),e(Ez,hnr),e(Nd,pnr),e(Jo,_nr),e(Jo,zL),e(zL,unr),e(zL,c2e),e(c2e,bnr),e(zL,vnr),e(Jo,Fnr),e(Jo,At),M(WL,At,null),e(At,Tnr),e(At,f2e),e(f2e,Mnr),e(At,Enr),e(At,jd),e(jd,Cnr),e(jd,m2e),e(m2e,wnr),e(jd,Anr),e(jd,Cz),e(Cz,ynr),e(jd,Lnr),e(At,xnr),M(ST,At,null),e(Jo,$nr),e(Jo,vo),M(QL,vo,null),e(vo,knr),e(vo,g2e),e(g2e,Snr),e(vo,Rnr),e(vo,Ya),e(Ya,Pnr),e(Ya,h2e),e(h2e,Bnr),e(Ya,Inr),e(Ya,p2e),e(p2e,qnr),e(Ya,Nnr),e(Ya,_2e),e(_2e,jnr),e(Ya,Dnr),e(vo,Gnr),e(vo,u2e),e(u2e,RT),e(RT,b2e),e(b2e,Onr),e(RT,Vnr),e(RT,wz),e(wz,Xnr),e(RT,znr),e(vo,Wnr),e(vo,PT),e(PT,Qnr),e(PT,v2e),e(v2e,Hnr),e(PT,Unr),e(PT,F2e),e(F2e,Jnr),e(vo,Ynr),M(BT,vo,null),b(f,eNe,u),b(f,Dd,u),e(Dd,IT),e(IT,T2e),M(HL,T2e,null),e(Dd,Knr),e(Dd,M2e),e(M2e,Znr),b(f,oNe,u),b(f,Yo,u),M(UL,Yo,null),e(Yo,esr),e(Yo,Gd),e(Gd,osr),e(Gd,Az),e(Az,rsr),e(Gd,tsr),e(Gd,yz),e(yz,asr),e(Gd,nsr),e(Yo,ssr),e(Yo,JL),e(JL,lsr),e(JL,E2e),e(E2e,isr),e(JL,dsr),e(Yo,csr),e(Yo,yt),M(YL,yt,null),e(yt,fsr),e(yt,C2e),e(C2e,msr),e(yt,gsr),e(yt,Od),e(Od,hsr),e(Od,w2e),e(w2e,psr),e(Od,_sr),e(Od,Lz),e(Lz,usr),e(Od,bsr),e(yt,vsr),M(qT,yt,null),e(Yo,Fsr),e(Yo,wr),M(KL,wr,null),e(wr,Tsr),e(wr,A2e),e(A2e,Msr),e(wr,Esr),e(wr,Ka),e(Ka,Csr),e(Ka,y2e),e(y2e,wsr),e(Ka,Asr),e(Ka,L2e),e(L2e,ysr),e(Ka,Lsr),e(Ka,x2e),e(x2e,xsr),e(Ka,$sr),e(wr,ksr),e(wr,q),e(q,NT),e(NT,$2e),e($2e,Ssr),e(NT,Rsr),e(NT,xz),e(xz,Psr),e(NT,Bsr),e(q,Isr),e(q,jT),e(jT,k2e),e(k2e,qsr),e(jT,Nsr),e(jT,$z),e($z,jsr),e(jT,Dsr),e(q,Gsr),e(q,DT),e(DT,S2e),e(S2e,Osr),e(DT,Vsr),e(DT,kz),e(kz,Xsr),e(DT,zsr),e(q,Wsr),e(q,GT),e(GT,R2e),e(R2e,Qsr),e(GT,Hsr),e(GT,Sz),e(Sz,Usr),e(GT,Jsr),e(q,Ysr),e(q,OT),e(OT,P2e),e(P2e,Ksr),e(OT,Zsr),e(OT,Rz),e(Rz,elr),e(OT,olr),e(q,rlr),e(q,VT),e(VT,B2e),e(B2e,tlr),e(VT,alr),e(VT,Pz),e(Pz,nlr),e(VT,slr),e(q,llr),e(q,XT),e(XT,I2e),e(I2e,ilr),e(XT,dlr),e(XT,Bz),e(Bz,clr),e(XT,flr),e(q,mlr),e(q,zT),e(zT,q2e),e(q2e,glr),e(zT,hlr),e(zT,Iz),e(Iz,plr),e(zT,_lr),e(q,ulr),e(q,WT),e(WT,N2e),e(N2e,blr),e(WT,vlr),e(WT,qz),e(qz,Flr),e(WT,Tlr),e(q,Mlr),e(q,QT),e(QT,j2e),e(j2e,Elr),e(QT,Clr),e(QT,Nz),e(Nz,wlr),e(QT,Alr),e(q,ylr),e(q,HT),e(HT,D2e),e(D2e,Llr),e(HT,xlr),e(HT,jz),e(jz,$lr),e(HT,klr),e(q,Slr),e(q,UT),e(UT,G2e),e(G2e,Rlr),e(UT,Plr),e(UT,Dz),e(Dz,Blr),e(UT,Ilr),e(q,qlr),e(q,JT),e(JT,O2e),e(O2e,Nlr),e(JT,jlr),e(JT,Gz),e(Gz,Dlr),e(JT,Glr),e(q,Olr),e(q,YT),e(YT,V2e),e(V2e,Vlr),e(YT,Xlr),e(YT,Oz),e(Oz,zlr),e(YT,Wlr),e(q,Qlr),e(q,KT),e(KT,X2e),e(X2e,Hlr),e(KT,Ulr),e(KT,Vz),e(Vz,Jlr),e(KT,Ylr),e(q,Klr),e(q,ZT),e(ZT,z2e),e(z2e,Zlr),e(ZT,eir),e(ZT,Xz),e(Xz,oir),e(ZT,rir),e(q,tir),e(q,eM),e(eM,W2e),e(W2e,air),e(eM,nir),e(eM,zz),e(zz,sir),e(eM,lir),e(q,iir),e(q,Bs),e(Bs,Q2e),e(Q2e,dir),e(Bs,cir),e(Bs,Wz),e(Wz,fir),e(Bs,mir),e(Bs,Qz),e(Qz,gir),e(Bs,hir),e(q,pir),e(q,oM),e(oM,H2e),e(H2e,_ir),e(oM,uir),e(oM,Hz),e(Hz,bir),e(oM,vir),e(q,Fir),e(q,rM),e(rM,U2e),e(U2e,Tir),e(rM,Mir),e(rM,Uz),e(Uz,Eir),e(rM,Cir),e(q,wir),e(q,tM),e(tM,J2e),e(J2e,Air),e(tM,yir),e(tM,Jz),e(Jz,Lir),e(tM,xir),e(q,$ir),e(q,aM),e(aM,Y2e),e(Y2e,kir),e(aM,Sir),e(aM,Yz),e(Yz,Rir),e(aM,Pir),e(q,Bir),e(q,nM),e(nM,K2e),e(K2e,Iir),e(nM,qir),e(nM,Kz),e(Kz,Nir),e(nM,jir),e(q,Dir),e(q,sM),e(sM,Z2e),e(Z2e,Gir),e(sM,Oir),e(sM,Zz),e(Zz,Vir),e(sM,Xir),e(q,zir),e(q,lM),e(lM,e1e),e(e1e,Wir),e(lM,Qir),e(lM,eW),e(eW,Hir),e(lM,Uir),e(q,Jir),e(q,iM),e(iM,o1e),e(o1e,Yir),e(iM,Kir),e(iM,oW),e(oW,Zir),e(iM,edr),e(q,odr),e(q,dM),e(dM,r1e),e(r1e,rdr),e(dM,tdr),e(dM,rW),e(rW,adr),e(dM,ndr),e(q,sdr),e(q,cM),e(cM,t1e),e(t1e,ldr),e(cM,idr),e(cM,tW),e(tW,ddr),e(cM,cdr),e(q,fdr),e(q,fM),e(fM,a1e),e(a1e,mdr),e(fM,gdr),e(fM,aW),e(aW,hdr),e(fM,pdr),e(q,_dr),e(q,mM),e(mM,n1e),e(n1e,udr),e(mM,bdr),e(mM,nW),e(nW,vdr),e(mM,Fdr),e(q,Tdr),e(q,gM),e(gM,s1e),e(s1e,Mdr),e(gM,Edr),e(gM,sW),e(sW,Cdr),e(gM,wdr),e(q,Adr),e(q,hM),e(hM,l1e),e(l1e,ydr),e(hM,Ldr),e(hM,lW),e(lW,xdr),e(hM,$dr),e(q,kdr),e(q,pM),e(pM,i1e),e(i1e,Sdr),e(pM,Rdr),e(pM,iW),e(iW,Pdr),e(pM,Bdr),e(q,Idr),e(q,_M),e(_M,d1e),e(d1e,qdr),e(_M,Ndr),e(_M,dW),e(dW,jdr),e(_M,Ddr),e(q,Gdr),e(q,uM),e(uM,c1e),e(c1e,Odr),e(uM,Vdr),e(uM,cW),e(cW,Xdr),e(uM,zdr),e(q,Wdr),e(q,bM),e(bM,f1e),e(f1e,Qdr),e(bM,Hdr),e(bM,fW),e(fW,Udr),e(bM,Jdr),e(q,Ydr),e(q,vM),e(vM,m1e),e(m1e,Kdr),e(vM,Zdr),e(vM,mW),e(mW,ecr),e(vM,ocr),e(q,rcr),e(q,FM),e(FM,g1e),e(g1e,tcr),e(FM,acr),e(FM,gW),e(gW,ncr),e(FM,scr),e(q,lcr),e(q,TM),e(TM,h1e),e(h1e,icr),e(TM,dcr),e(TM,hW),e(hW,ccr),e(TM,fcr),e(q,mcr),e(q,MM),e(MM,p1e),e(p1e,gcr),e(MM,hcr),e(MM,pW),e(pW,pcr),e(MM,_cr),e(q,ucr),e(q,EM),e(EM,_1e),e(_1e,bcr),e(EM,vcr),e(EM,_W),e(_W,Fcr),e(EM,Tcr),e(q,Mcr),e(q,CM),e(CM,u1e),e(u1e,Ecr),e(CM,Ccr),e(CM,uW),e(uW,wcr),e(CM,Acr),e(q,ycr),e(q,wM),e(wM,b1e),e(b1e,Lcr),e(wM,xcr),e(wM,bW),e(bW,$cr),e(wM,kcr),e(q,Scr),e(q,AM),e(AM,v1e),e(v1e,Rcr),e(AM,Pcr),e(AM,vW),e(vW,Bcr),e(AM,Icr),e(q,qcr),e(q,yM),e(yM,F1e),e(F1e,Ncr),e(yM,jcr),e(yM,FW),e(FW,Dcr),e(yM,Gcr),e(q,Ocr),e(q,LM),e(LM,T1e),e(T1e,Vcr),e(LM,Xcr),e(LM,TW),e(TW,zcr),e(LM,Wcr),e(q,Qcr),e(q,xM),e(xM,M1e),e(M1e,Hcr),e(xM,Ucr),e(xM,MW),e(MW,Jcr),e(xM,Ycr),e(wr,Kcr),M($M,wr,null),b(f,rNe,u),b(f,Vd,u),e(Vd,kM),e(kM,E1e),M(ZL,E1e,null),e(Vd,Zcr),e(Vd,C1e),e(C1e,efr),b(f,tNe,u),b(f,Ko,u),M(e8,Ko,null),e(Ko,ofr),e(Ko,Xd),e(Xd,rfr),e(Xd,EW),e(EW,tfr),e(Xd,afr),e(Xd,CW),e(CW,nfr),e(Xd,sfr),e(Ko,lfr),e(Ko,o8),e(o8,ifr),e(o8,w1e),e(w1e,dfr),e(o8,cfr),e(Ko,ffr),e(Ko,Lt),M(r8,Lt,null),e(Lt,mfr),e(Lt,A1e),e(A1e,gfr),e(Lt,hfr),e(Lt,zd),e(zd,pfr),e(zd,y1e),e(y1e,_fr),e(zd,ufr),e(zd,wW),e(wW,bfr),e(zd,vfr),e(Lt,Ffr),M(SM,Lt,null),e(Ko,Tfr),e(Ko,Ar),M(t8,Ar,null),e(Ar,Mfr),e(Ar,L1e),e(L1e,Efr),e(Ar,Cfr),e(Ar,Za),e(Za,wfr),e(Za,x1e),e(x1e,Afr),e(Za,yfr),e(Za,$1e),e($1e,Lfr),e(Za,xfr),e(Za,k1e),e(k1e,$fr),e(Za,kfr),e(Ar,Sfr),e(Ar,se),e(se,RM),e(RM,S1e),e(S1e,Rfr),e(RM,Pfr),e(RM,AW),e(AW,Bfr),e(RM,Ifr),e(se,qfr),e(se,PM),e(PM,R1e),e(R1e,Nfr),e(PM,jfr),e(PM,yW),e(yW,Dfr),e(PM,Gfr),e(se,Ofr),e(se,BM),e(BM,P1e),e(P1e,Vfr),e(BM,Xfr),e(BM,LW),e(LW,zfr),e(BM,Wfr),e(se,Qfr),e(se,IM),e(IM,B1e),e(B1e,Hfr),e(IM,Ufr),e(IM,xW),e(xW,Jfr),e(IM,Yfr),e(se,Kfr),e(se,qM),e(qM,I1e),e(I1e,Zfr),e(qM,emr),e(qM,$W),e($W,omr),e(qM,rmr),e(se,tmr),e(se,NM),e(NM,q1e),e(q1e,amr),e(NM,nmr),e(NM,kW),e(kW,smr),e(NM,lmr),e(se,imr),e(se,jM),e(jM,N1e),e(N1e,dmr),e(jM,cmr),e(jM,SW),e(SW,fmr),e(jM,mmr),e(se,gmr),e(se,DM),e(DM,j1e),e(j1e,hmr),e(DM,pmr),e(DM,RW),e(RW,_mr),e(DM,umr),e(se,bmr),e(se,GM),e(GM,D1e),e(D1e,vmr),e(GM,Fmr),e(GM,PW),e(PW,Tmr),e(GM,Mmr),e(se,Emr),e(se,OM),e(OM,G1e),e(G1e,Cmr),e(OM,wmr),e(OM,BW),e(BW,Amr),e(OM,ymr),e(se,Lmr),e(se,VM),e(VM,O1e),e(O1e,xmr),e(VM,$mr),e(VM,IW),e(IW,kmr),e(VM,Smr),e(se,Rmr),e(se,XM),e(XM,V1e),e(V1e,Pmr),e(XM,Bmr),e(XM,qW),e(qW,Imr),e(XM,qmr),e(se,Nmr),e(se,zM),e(zM,X1e),e(X1e,jmr),e(zM,Dmr),e(zM,NW),e(NW,Gmr),e(zM,Omr),e(se,Vmr),e(se,WM),e(WM,z1e),e(z1e,Xmr),e(WM,zmr),e(WM,jW),e(jW,Wmr),e(WM,Qmr),e(se,Hmr),e(se,QM),e(QM,W1e),e(W1e,Umr),e(QM,Jmr),e(QM,DW),e(DW,Ymr),e(QM,Kmr),e(se,Zmr),e(se,HM),e(HM,Q1e),e(Q1e,egr),e(HM,ogr),e(HM,GW),e(GW,rgr),e(HM,tgr),e(se,agr),e(se,UM),e(UM,H1e),e(H1e,ngr),e(UM,sgr),e(UM,OW),e(OW,lgr),e(UM,igr),e(se,dgr),e(se,JM),e(JM,U1e),e(U1e,cgr),e(JM,fgr),e(JM,VW),e(VW,mgr),e(JM,ggr),e(se,hgr),e(se,YM),e(YM,J1e),e(J1e,pgr),e(YM,_gr),e(YM,XW),e(XW,ugr),e(YM,bgr),e(se,vgr),e(se,KM),e(KM,Y1e),e(Y1e,Fgr),e(KM,Tgr),e(KM,zW),e(zW,Mgr),e(KM,Egr),e(se,Cgr),e(se,ZM),e(ZM,K1e),e(K1e,wgr),e(ZM,Agr),e(ZM,WW),e(WW,ygr),e(ZM,Lgr),e(se,xgr),e(se,e4),e(e4,Z1e),e(Z1e,$gr),e(e4,kgr),e(e4,QW),e(QW,Sgr),e(e4,Rgr),e(se,Pgr),e(se,o4),e(o4,e7e),e(e7e,Bgr),e(o4,Igr),e(o4,HW),e(HW,qgr),e(o4,Ngr),e(Ar,jgr),M(r4,Ar,null),b(f,aNe,u),b(f,Wd,u),e(Wd,t4),e(t4,o7e),M(a8,o7e,null),e(Wd,Dgr),e(Wd,r7e),e(r7e,Ggr),b(f,nNe,u),b(f,Zo,u),M(n8,Zo,null),e(Zo,Ogr),e(Zo,Qd),e(Qd,Vgr),e(Qd,UW),e(UW,Xgr),e(Qd,zgr),e(Qd,JW),e(JW,Wgr),e(Qd,Qgr),e(Zo,Hgr),e(Zo,s8),e(s8,Ugr),e(s8,t7e),e(t7e,Jgr),e(s8,Ygr),e(Zo,Kgr),e(Zo,xt),M(l8,xt,null),e(xt,Zgr),e(xt,a7e),e(a7e,ehr),e(xt,ohr),e(xt,Hd),e(Hd,rhr),e(Hd,n7e),e(n7e,thr),e(Hd,ahr),e(Hd,YW),e(YW,nhr),e(Hd,shr),e(xt,lhr),M(a4,xt,null),e(Zo,ihr),e(Zo,yr),M(i8,yr,null),e(yr,dhr),e(yr,s7e),e(s7e,chr),e(yr,fhr),e(yr,en),e(en,mhr),e(en,l7e),e(l7e,ghr),e(en,hhr),e(en,i7e),e(i7e,phr),e(en,_hr),e(en,d7e),e(d7e,uhr),e(en,bhr),e(yr,vhr),e(yr,Te),e(Te,n4),e(n4,c7e),e(c7e,Fhr),e(n4,Thr),e(n4,KW),e(KW,Mhr),e(n4,Ehr),e(Te,Chr),e(Te,s4),e(s4,f7e),e(f7e,whr),e(s4,Ahr),e(s4,ZW),e(ZW,yhr),e(s4,Lhr),e(Te,xhr),e(Te,l4),e(l4,m7e),e(m7e,$hr),e(l4,khr),e(l4,eQ),e(eQ,Shr),e(l4,Rhr),e(Te,Phr),e(Te,i4),e(i4,g7e),e(g7e,Bhr),e(i4,Ihr),e(i4,oQ),e(oQ,qhr),e(i4,Nhr),e(Te,jhr),e(Te,d4),e(d4,h7e),e(h7e,Dhr),e(d4,Ghr),e(d4,rQ),e(rQ,Ohr),e(d4,Vhr),e(Te,Xhr),e(Te,c4),e(c4,p7e),e(p7e,zhr),e(c4,Whr),e(c4,tQ),e(tQ,Qhr),e(c4,Hhr),e(Te,Uhr),e(Te,f4),e(f4,_7e),e(_7e,Jhr),e(f4,Yhr),e(f4,aQ),e(aQ,Khr),e(f4,Zhr),e(Te,epr),e(Te,m4),e(m4,u7e),e(u7e,opr),e(m4,rpr),e(m4,nQ),e(nQ,tpr),e(m4,apr),e(Te,npr),e(Te,g4),e(g4,b7e),e(b7e,spr),e(g4,lpr),e(g4,sQ),e(sQ,ipr),e(g4,dpr),e(Te,cpr),e(Te,h4),e(h4,v7e),e(v7e,fpr),e(h4,mpr),e(h4,lQ),e(lQ,gpr),e(h4,hpr),e(Te,ppr),e(Te,p4),e(p4,F7e),e(F7e,_pr),e(p4,upr),e(p4,iQ),e(iQ,bpr),e(p4,vpr),e(Te,Fpr),e(Te,_4),e(_4,T7e),e(T7e,Tpr),e(_4,Mpr),e(_4,dQ),e(dQ,Epr),e(_4,Cpr),e(yr,wpr),M(u4,yr,null),b(f,sNe,u),b(f,Ud,u),e(Ud,b4),e(b4,M7e),M(d8,M7e,null),e(Ud,Apr),e(Ud,E7e),e(E7e,ypr),b(f,lNe,u),b(f,er,u),M(c8,er,null),e(er,Lpr),e(er,Jd),e(Jd,xpr),e(Jd,cQ),e(cQ,$pr),e(Jd,kpr),e(Jd,fQ),e(fQ,Spr),e(Jd,Rpr),e(er,Ppr),e(er,f8),e(f8,Bpr),e(f8,C7e),e(C7e,Ipr),e(f8,qpr),e(er,Npr),e(er,$t),M(m8,$t,null),e($t,jpr),e($t,w7e),e(w7e,Dpr),e($t,Gpr),e($t,Yd),e(Yd,Opr),e(Yd,A7e),e(A7e,Vpr),e(Yd,Xpr),e(Yd,mQ),e(mQ,zpr),e(Yd,Wpr),e($t,Qpr),M(v4,$t,null),e(er,Hpr),e(er,Lr),M(g8,Lr,null),e(Lr,Upr),e(Lr,y7e),e(y7e,Jpr),e(Lr,Ypr),e(Lr,on),e(on,Kpr),e(on,L7e),e(L7e,Zpr),e(on,e_r),e(on,x7e),e(x7e,o_r),e(on,r_r),e(on,$7e),e($7e,t_r),e(on,a_r),e(Lr,n_r),e(Lr,rn),e(rn,F4),e(F4,k7e),e(k7e,s_r),e(F4,l_r),e(F4,gQ),e(gQ,i_r),e(F4,d_r),e(rn,c_r),e(rn,T4),e(T4,S7e),e(S7e,f_r),e(T4,m_r),e(T4,hQ),e(hQ,g_r),e(T4,h_r),e(rn,p_r),e(rn,M4),e(M4,R7e),e(R7e,__r),e(M4,u_r),e(M4,pQ),e(pQ,b_r),e(M4,v_r),e(rn,F_r),e(rn,E4),e(E4,P7e),e(P7e,T_r),e(E4,M_r),e(E4,_Q),e(_Q,E_r),e(E4,C_r),e(Lr,w_r),M(C4,Lr,null),b(f,iNe,u),b(f,Kd,u),e(Kd,w4),e(w4,B7e),M(h8,B7e,null),e(Kd,A_r),e(Kd,I7e),e(I7e,y_r),b(f,dNe,u),b(f,or,u),M(p8,or,null),e(or,L_r),e(or,Zd),e(Zd,x_r),e(Zd,uQ),e(uQ,$_r),e(Zd,k_r),e(Zd,bQ),e(bQ,S_r),e(Zd,R_r),e(or,P_r),e(or,_8),e(_8,B_r),e(_8,q7e),e(q7e,I_r),e(_8,q_r),e(or,N_r),e(or,kt),M(u8,kt,null),e(kt,j_r),e(kt,N7e),e(N7e,D_r),e(kt,G_r),e(kt,ec),e(ec,O_r),e(ec,j7e),e(j7e,V_r),e(ec,X_r),e(ec,vQ),e(vQ,z_r),e(ec,W_r),e(kt,Q_r),M(A4,kt,null),e(or,H_r),e(or,xr),M(b8,xr,null),e(xr,U_r),e(xr,D7e),e(D7e,J_r),e(xr,Y_r),e(xr,tn),e(tn,K_r),e(tn,G7e),e(G7e,Z_r),e(tn,eur),e(tn,O7e),e(O7e,our),e(tn,rur),e(tn,V7e),e(V7e,tur),e(tn,aur),e(xr,nur),e(xr,ie),e(ie,y4),e(y4,X7e),e(X7e,sur),e(y4,lur),e(y4,FQ),e(FQ,iur),e(y4,dur),e(ie,cur),e(ie,L4),e(L4,z7e),e(z7e,fur),e(L4,mur),e(L4,TQ),e(TQ,gur),e(L4,hur),e(ie,pur),e(ie,x4),e(x4,W7e),e(W7e,_ur),e(x4,uur),e(x4,MQ),e(MQ,bur),e(x4,vur),e(ie,Fur),e(ie,$4),e($4,Q7e),e(Q7e,Tur),e($4,Mur),e($4,EQ),e(EQ,Eur),e($4,Cur),e(ie,wur),e(ie,k4),e(k4,H7e),e(H7e,Aur),e(k4,yur),e(k4,CQ),e(CQ,Lur),e(k4,xur),e(ie,$ur),e(ie,S4),e(S4,U7e),e(U7e,kur),e(S4,Sur),e(S4,wQ),e(wQ,Rur),e(S4,Pur),e(ie,Bur),e(ie,R4),e(R4,J7e),e(J7e,Iur),e(R4,qur),e(R4,AQ),e(AQ,Nur),e(R4,jur),e(ie,Dur),e(ie,P4),e(P4,Y7e),e(Y7e,Gur),e(P4,Our),e(P4,yQ),e(yQ,Vur),e(P4,Xur),e(ie,zur),e(ie,B4),e(B4,K7e),e(K7e,Wur),e(B4,Qur),e(B4,LQ),e(LQ,Hur),e(B4,Uur),e(ie,Jur),e(ie,I4),e(I4,Z7e),e(Z7e,Yur),e(I4,Kur),e(I4,xQ),e(xQ,Zur),e(I4,e2r),e(ie,o2r),e(ie,q4),e(q4,ebe),e(ebe,r2r),e(q4,t2r),e(q4,$Q),e($Q,a2r),e(q4,n2r),e(ie,s2r),e(ie,N4),e(N4,obe),e(obe,l2r),e(N4,i2r),e(N4,kQ),e(kQ,d2r),e(N4,c2r),e(ie,f2r),e(ie,j4),e(j4,rbe),e(rbe,m2r),e(j4,g2r),e(j4,SQ),e(SQ,h2r),e(j4,p2r),e(ie,_2r),e(ie,D4),e(D4,tbe),e(tbe,u2r),e(D4,b2r),e(D4,RQ),e(RQ,v2r),e(D4,F2r),e(ie,T2r),e(ie,G4),e(G4,abe),e(abe,M2r),e(G4,E2r),e(G4,PQ),e(PQ,C2r),e(G4,w2r),e(ie,A2r),e(ie,O4),e(O4,nbe),e(nbe,y2r),e(O4,L2r),e(O4,BQ),e(BQ,x2r),e(O4,$2r),e(ie,k2r),e(ie,V4),e(V4,sbe),e(sbe,S2r),e(V4,R2r),e(V4,IQ),e(IQ,P2r),e(V4,B2r),e(ie,I2r),e(ie,X4),e(X4,lbe),e(lbe,q2r),e(X4,N2r),e(X4,qQ),e(qQ,j2r),e(X4,D2r),e(ie,G2r),e(ie,z4),e(z4,ibe),e(ibe,O2r),e(z4,V2r),e(z4,NQ),e(NQ,X2r),e(z4,z2r),e(ie,W2r),e(ie,W4),e(W4,dbe),e(dbe,Q2r),e(W4,H2r),e(W4,jQ),e(jQ,U2r),e(W4,J2r),e(xr,Y2r),M(Q4,xr,null),b(f,cNe,u),b(f,oc,u),e(oc,H4),e(H4,cbe),M(v8,cbe,null),e(oc,K2r),e(oc,fbe),e(fbe,Z2r),b(f,fNe,u),b(f,rr,u),M(F8,rr,null),e(rr,e1r),e(rr,rc),e(rc,o1r),e(rc,DQ),e(DQ,r1r),e(rc,t1r),e(rc,GQ),e(GQ,a1r),e(rc,n1r),e(rr,s1r),e(rr,T8),e(T8,l1r),e(T8,mbe),e(mbe,i1r),e(T8,d1r),e(rr,c1r),e(rr,St),M(M8,St,null),e(St,f1r),e(St,gbe),e(gbe,m1r),e(St,g1r),e(St,tc),e(tc,h1r),e(tc,hbe),e(hbe,p1r),e(tc,_1r),e(tc,OQ),e(OQ,u1r),e(tc,b1r),e(St,v1r),M(U4,St,null),e(rr,F1r),e(rr,$r),M(E8,$r,null),e($r,T1r),e($r,pbe),e(pbe,M1r),e($r,E1r),e($r,an),e(an,C1r),e(an,_be),e(_be,w1r),e(an,A1r),e(an,ube),e(ube,y1r),e(an,L1r),e(an,bbe),e(bbe,x1r),e(an,$1r),e($r,k1r),e($r,ye),e(ye,J4),e(J4,vbe),e(vbe,S1r),e(J4,R1r),e(J4,VQ),e(VQ,P1r),e(J4,B1r),e(ye,I1r),e(ye,Y4),e(Y4,Fbe),e(Fbe,q1r),e(Y4,N1r),e(Y4,XQ),e(XQ,j1r),e(Y4,D1r),e(ye,G1r),e(ye,K4),e(K4,Tbe),e(Tbe,O1r),e(K4,V1r),e(K4,zQ),e(zQ,X1r),e(K4,z1r),e(ye,W1r),e(ye,Z4),e(Z4,Mbe),e(Mbe,Q1r),e(Z4,H1r),e(Z4,WQ),e(WQ,U1r),e(Z4,J1r),e(ye,Y1r),e(ye,eE),e(eE,Ebe),e(Ebe,K1r),e(eE,Z1r),e(eE,QQ),e(QQ,e7r),e(eE,o7r),e(ye,r7r),e(ye,oE),e(oE,Cbe),e(Cbe,t7r),e(oE,a7r),e(oE,HQ),e(HQ,n7r),e(oE,s7r),e(ye,l7r),e(ye,rE),e(rE,wbe),e(wbe,i7r),e(rE,d7r),e(rE,UQ),e(UQ,c7r),e(rE,f7r),e(ye,m7r),e(ye,tE),e(tE,Abe),e(Abe,g7r),e(tE,h7r),e(tE,JQ),e(JQ,p7r),e(tE,_7r),e(ye,u7r),e(ye,aE),e(aE,ybe),e(ybe,b7r),e(aE,v7r),e(aE,YQ),e(YQ,F7r),e(aE,T7r),e(ye,M7r),e(ye,nE),e(nE,Lbe),e(Lbe,E7r),e(nE,C7r),e(nE,KQ),e(KQ,w7r),e(nE,A7r),e($r,y7r),M(sE,$r,null),b(f,mNe,u),b(f,ac,u),e(ac,lE),e(lE,xbe),M(C8,xbe,null),e(ac,L7r),e(ac,$be),e($be,x7r),b(f,gNe,u),b(f,tr,u),M(w8,tr,null),e(tr,$7r),e(tr,nc),e(nc,k7r),e(nc,ZQ),e(ZQ,S7r),e(nc,R7r),e(nc,eH),e(eH,P7r),e(nc,B7r),e(tr,I7r),e(tr,A8),e(A8,q7r),e(A8,kbe),e(kbe,N7r),e(A8,j7r),e(tr,D7r),e(tr,Rt),M(y8,Rt,null),e(Rt,G7r),e(Rt,Sbe),e(Sbe,O7r),e(Rt,V7r),e(Rt,sc),e(sc,X7r),e(sc,Rbe),e(Rbe,z7r),e(sc,W7r),e(sc,oH),e(oH,Q7r),e(sc,H7r),e(Rt,U7r),M(iE,Rt,null),e(tr,J7r),e(tr,kr),M(L8,kr,null),e(kr,Y7r),e(kr,Pbe),e(Pbe,K7r),e(kr,Z7r),e(kr,nn),e(nn,ebr),e(nn,Bbe),e(Bbe,obr),e(nn,rbr),e(nn,Ibe),e(Ibe,tbr),e(nn,abr),e(nn,qbe),e(qbe,nbr),e(nn,sbr),e(kr,lbr),e(kr,ee),e(ee,dE),e(dE,Nbe),e(Nbe,ibr),e(dE,dbr),e(dE,rH),e(rH,cbr),e(dE,fbr),e(ee,mbr),e(ee,cE),e(cE,jbe),e(jbe,gbr),e(cE,hbr),e(cE,tH),e(tH,pbr),e(cE,_br),e(ee,ubr),e(ee,fE),e(fE,Dbe),e(Dbe,bbr),e(fE,vbr),e(fE,aH),e(aH,Fbr),e(fE,Tbr),e(ee,Mbr),e(ee,mE),e(mE,Gbe),e(Gbe,Ebr),e(mE,Cbr),e(mE,nH),e(nH,wbr),e(mE,Abr),e(ee,ybr),e(ee,gE),e(gE,Obe),e(Obe,Lbr),e(gE,xbr),e(gE,sH),e(sH,$br),e(gE,kbr),e(ee,Sbr),e(ee,hE),e(hE,Vbe),e(Vbe,Rbr),e(hE,Pbr),e(hE,lH),e(lH,Bbr),e(hE,Ibr),e(ee,qbr),e(ee,pE),e(pE,Xbe),e(Xbe,Nbr),e(pE,jbr),e(pE,iH),e(iH,Dbr),e(pE,Gbr),e(ee,Obr),e(ee,_E),e(_E,zbe),e(zbe,Vbr),e(_E,Xbr),e(_E,dH),e(dH,zbr),e(_E,Wbr),e(ee,Qbr),e(ee,uE),e(uE,Wbe),e(Wbe,Hbr),e(uE,Ubr),e(uE,cH),e(cH,Jbr),e(uE,Ybr),e(ee,Kbr),e(ee,bE),e(bE,Qbe),e(Qbe,Zbr),e(bE,evr),e(bE,fH),e(fH,ovr),e(bE,rvr),e(ee,tvr),e(ee,vE),e(vE,Hbe),e(Hbe,avr),e(vE,nvr),e(vE,mH),e(mH,svr),e(vE,lvr),e(ee,ivr),e(ee,FE),e(FE,Ube),e(Ube,dvr),e(FE,cvr),e(FE,gH),e(gH,fvr),e(FE,mvr),e(ee,gvr),e(ee,TE),e(TE,Jbe),e(Jbe,hvr),e(TE,pvr),e(TE,hH),e(hH,_vr),e(TE,uvr),e(ee,bvr),e(ee,ME),e(ME,Ybe),e(Ybe,vvr),e(ME,Fvr),e(ME,pH),e(pH,Tvr),e(ME,Mvr),e(ee,Evr),e(ee,EE),e(EE,Kbe),e(Kbe,Cvr),e(EE,wvr),e(EE,_H),e(_H,Avr),e(EE,yvr),e(ee,Lvr),e(ee,CE),e(CE,Zbe),e(Zbe,xvr),e(CE,$vr),e(CE,uH),e(uH,kvr),e(CE,Svr),e(ee,Rvr),e(ee,wE),e(wE,eve),e(eve,Pvr),e(wE,Bvr),e(wE,bH),e(bH,Ivr),e(wE,qvr),e(ee,Nvr),e(ee,AE),e(AE,ove),e(ove,jvr),e(AE,Dvr),e(AE,vH),e(vH,Gvr),e(AE,Ovr),e(ee,Vvr),e(ee,yE),e(yE,rve),e(rve,Xvr),e(yE,zvr),e(yE,FH),e(FH,Wvr),e(yE,Qvr),e(ee,Hvr),e(ee,LE),e(LE,tve),e(tve,Uvr),e(LE,Jvr),e(LE,TH),e(TH,Yvr),e(LE,Kvr),e(ee,Zvr),e(ee,xE),e(xE,ave),e(ave,eFr),e(xE,oFr),e(xE,MH),e(MH,rFr),e(xE,tFr),e(ee,aFr),e(ee,$E),e($E,nve),e(nve,nFr),e($E,sFr),e($E,EH),e(EH,lFr),e($E,iFr),e(ee,dFr),e(ee,kE),e(kE,sve),e(sve,cFr),e(kE,fFr),e(kE,CH),e(CH,mFr),e(kE,gFr),e(ee,hFr),e(ee,SE),e(SE,lve),e(lve,pFr),e(SE,_Fr),e(SE,wH),e(wH,uFr),e(SE,bFr),e(ee,vFr),e(ee,RE),e(RE,ive),e(ive,FFr),e(RE,TFr),e(RE,AH),e(AH,MFr),e(RE,EFr),e(ee,CFr),e(ee,PE),e(PE,dve),e(dve,wFr),e(PE,AFr),e(PE,yH),e(yH,yFr),e(PE,LFr),e(kr,xFr),M(BE,kr,null),b(f,hNe,u),b(f,lc,u),e(lc,IE),e(IE,cve),M(x8,cve,null),e(lc,$Fr),e(lc,fve),e(fve,kFr),b(f,pNe,u),b(f,ar,u),M($8,ar,null),e(ar,SFr),e(ar,ic),e(ic,RFr),e(ic,LH),e(LH,PFr),e(ic,BFr),e(ic,xH),e(xH,IFr),e(ic,qFr),e(ar,NFr),e(ar,k8),e(k8,jFr),e(k8,mve),e(mve,DFr),e(k8,GFr),e(ar,OFr),e(ar,Pt),M(S8,Pt,null),e(Pt,VFr),e(Pt,gve),e(gve,XFr),e(Pt,zFr),e(Pt,dc),e(dc,WFr),e(dc,hve),e(hve,QFr),e(dc,HFr),e(dc,$H),e($H,UFr),e(dc,JFr),e(Pt,YFr),M(qE,Pt,null),e(ar,KFr),e(ar,Sr),M(R8,Sr,null),e(Sr,ZFr),e(Sr,pve),e(pve,eTr),e(Sr,oTr),e(Sr,sn),e(sn,rTr),e(sn,_ve),e(_ve,tTr),e(sn,aTr),e(sn,uve),e(uve,nTr),e(sn,sTr),e(sn,bve),e(bve,lTr),e(sn,iTr),e(Sr,dTr),e(Sr,he),e(he,NE),e(NE,vve),e(vve,cTr),e(NE,fTr),e(NE,kH),e(kH,mTr),e(NE,gTr),e(he,hTr),e(he,jE),e(jE,Fve),e(Fve,pTr),e(jE,_Tr),e(jE,SH),e(SH,uTr),e(jE,bTr),e(he,vTr),e(he,DE),e(DE,Tve),e(Tve,FTr),e(DE,TTr),e(DE,RH),e(RH,MTr),e(DE,ETr),e(he,CTr),e(he,GE),e(GE,Mve),e(Mve,wTr),e(GE,ATr),e(GE,PH),e(PH,yTr),e(GE,LTr),e(he,xTr),e(he,OE),e(OE,Eve),e(Eve,$Tr),e(OE,kTr),e(OE,BH),e(BH,STr),e(OE,RTr),e(he,PTr),e(he,VE),e(VE,Cve),e(Cve,BTr),e(VE,ITr),e(VE,IH),e(IH,qTr),e(VE,NTr),e(he,jTr),e(he,XE),e(XE,wve),e(wve,DTr),e(XE,GTr),e(XE,qH),e(qH,OTr),e(XE,VTr),e(he,XTr),e(he,zE),e(zE,Ave),e(Ave,zTr),e(zE,WTr),e(zE,NH),e(NH,QTr),e(zE,HTr),e(he,UTr),e(he,WE),e(WE,yve),e(yve,JTr),e(WE,YTr),e(WE,jH),e(jH,KTr),e(WE,ZTr),e(he,eMr),e(he,QE),e(QE,Lve),e(Lve,oMr),e(QE,rMr),e(QE,DH),e(DH,tMr),e(QE,aMr),e(he,nMr),e(he,HE),e(HE,xve),e(xve,sMr),e(HE,lMr),e(HE,GH),e(GH,iMr),e(HE,dMr),e(he,cMr),e(he,UE),e(UE,$ve),e($ve,fMr),e(UE,mMr),e(UE,OH),e(OH,gMr),e(UE,hMr),e(he,pMr),e(he,JE),e(JE,kve),e(kve,_Mr),e(JE,uMr),e(JE,VH),e(VH,bMr),e(JE,vMr),e(he,FMr),e(he,YE),e(YE,Sve),e(Sve,TMr),e(YE,MMr),e(YE,XH),e(XH,EMr),e(YE,CMr),e(he,wMr),e(he,KE),e(KE,Rve),e(Rve,AMr),e(KE,yMr),e(KE,zH),e(zH,LMr),e(KE,xMr),e(he,$Mr),e(he,ZE),e(ZE,Pve),e(Pve,kMr),e(ZE,SMr),e(ZE,WH),e(WH,RMr),e(ZE,PMr),e(he,BMr),e(he,eC),e(eC,Bve),e(Bve,IMr),e(eC,qMr),e(eC,QH),e(QH,NMr),e(eC,jMr),e(Sr,DMr),M(oC,Sr,null),b(f,_Ne,u),b(f,cc,u),e(cc,rC),e(rC,Ive),M(P8,Ive,null),e(cc,GMr),e(cc,qve),e(qve,OMr),b(f,uNe,u),b(f,nr,u),M(B8,nr,null),e(nr,VMr),e(nr,fc),e(fc,XMr),e(fc,HH),e(HH,zMr),e(fc,WMr),e(fc,UH),e(UH,QMr),e(fc,HMr),e(nr,UMr),e(nr,I8),e(I8,JMr),e(I8,Nve),e(Nve,YMr),e(I8,KMr),e(nr,ZMr),e(nr,Bt),M(q8,Bt,null),e(Bt,e4r),e(Bt,jve),e(jve,o4r),e(Bt,r4r),e(Bt,mc),e(mc,t4r),e(mc,Dve),e(Dve,a4r),e(mc,n4r),e(mc,JH),e(JH,s4r),e(mc,l4r),e(Bt,i4r),M(tC,Bt,null),e(nr,d4r),e(nr,Rr),M(N8,Rr,null),e(Rr,c4r),e(Rr,Gve),e(Gve,f4r),e(Rr,m4r),e(Rr,ln),e(ln,g4r),e(ln,Ove),e(Ove,h4r),e(ln,p4r),e(ln,Vve),e(Vve,_4r),e(ln,u4r),e(ln,Xve),e(Xve,b4r),e(ln,v4r),e(Rr,F4r),e(Rr,j8),e(j8,aC),e(aC,zve),e(zve,T4r),e(aC,M4r),e(aC,YH),e(YH,E4r),e(aC,C4r),e(j8,w4r),e(j8,nC),e(nC,Wve),e(Wve,A4r),e(nC,y4r),e(nC,KH),e(KH,L4r),e(nC,x4r),e(Rr,$4r),M(sC,Rr,null),b(f,bNe,u),b(f,gc,u),e(gc,lC),e(lC,Qve),M(D8,Qve,null),e(gc,k4r),e(gc,Hve),e(Hve,S4r),b(f,vNe,u),b(f,sr,u),M(G8,sr,null),e(sr,R4r),e(sr,hc),e(hc,P4r),e(hc,ZH),e(ZH,B4r),e(hc,I4r),e(hc,eU),e(eU,q4r),e(hc,N4r),e(sr,j4r),e(sr,O8),e(O8,D4r),e(O8,Uve),e(Uve,G4r),e(O8,O4r),e(sr,V4r),e(sr,It),M(V8,It,null),e(It,X4r),e(It,Jve),e(Jve,z4r),e(It,W4r),e(It,pc),e(pc,Q4r),e(pc,Yve),e(Yve,H4r),e(pc,U4r),e(pc,oU),e(oU,J4r),e(pc,Y4r),e(It,K4r),M(iC,It,null),e(sr,Z4r),e(sr,Pr),M(X8,Pr,null),e(Pr,eEr),e(Pr,Kve),e(Kve,oEr),e(Pr,rEr),e(Pr,dn),e(dn,tEr),e(dn,Zve),e(Zve,aEr),e(dn,nEr),e(dn,eFe),e(eFe,sEr),e(dn,lEr),e(dn,oFe),e(oFe,iEr),e(dn,dEr),e(Pr,cEr),e(Pr,rFe),e(rFe,dC),e(dC,tFe),e(tFe,fEr),e(dC,mEr),e(dC,rU),e(rU,gEr),e(dC,hEr),e(Pr,pEr),M(cC,Pr,null),b(f,FNe,u),b(f,_c,u),e(_c,fC),e(fC,aFe),M(z8,aFe,null),e(_c,_Er),e(_c,nFe),e(nFe,uEr),b(f,TNe,u),b(f,lr,u),M(W8,lr,null),e(lr,bEr),e(lr,uc),e(uc,vEr),e(uc,tU),e(tU,FEr),e(uc,TEr),e(uc,aU),e(aU,MEr),e(uc,EEr),e(lr,CEr),e(lr,Q8),e(Q8,wEr),e(Q8,sFe),e(sFe,AEr),e(Q8,yEr),e(lr,LEr),e(lr,qt),M(H8,qt,null),e(qt,xEr),e(qt,lFe),e(lFe,$Er),e(qt,kEr),e(qt,bc),e(bc,SEr),e(bc,iFe),e(iFe,REr),e(bc,PEr),e(bc,nU),e(nU,BEr),e(bc,IEr),e(qt,qEr),M(mC,qt,null),e(lr,NEr),e(lr,Br),M(U8,Br,null),e(Br,jEr),e(Br,dFe),e(dFe,DEr),e(Br,GEr),e(Br,cn),e(cn,OEr),e(cn,cFe),e(cFe,VEr),e(cn,XEr),e(cn,fFe),e(fFe,zEr),e(cn,WEr),e(cn,mFe),e(mFe,QEr),e(cn,HEr),e(Br,UEr),e(Br,de),e(de,gC),e(gC,gFe),e(gFe,JEr),e(gC,YEr),e(gC,sU),e(sU,KEr),e(gC,ZEr),e(de,eCr),e(de,hC),e(hC,hFe),e(hFe,oCr),e(hC,rCr),e(hC,lU),e(lU,tCr),e(hC,aCr),e(de,nCr),e(de,pC),e(pC,pFe),e(pFe,sCr),e(pC,lCr),e(pC,iU),e(iU,iCr),e(pC,dCr),e(de,cCr),e(de,_C),e(_C,_Fe),e(_Fe,fCr),e(_C,mCr),e(_C,dU),e(dU,gCr),e(_C,hCr),e(de,pCr),e(de,uC),e(uC,uFe),e(uFe,_Cr),e(uC,uCr),e(uC,cU),e(cU,bCr),e(uC,vCr),e(de,FCr),e(de,bC),e(bC,bFe),e(bFe,TCr),e(bC,MCr),e(bC,fU),e(fU,ECr),e(bC,CCr),e(de,wCr),e(de,vC),e(vC,vFe),e(vFe,ACr),e(vC,yCr),e(vC,mU),e(mU,LCr),e(vC,xCr),e(de,$Cr),e(de,FC),e(FC,FFe),e(FFe,kCr),e(FC,SCr),e(FC,gU),e(gU,RCr),e(FC,PCr),e(de,BCr),e(de,TC),e(TC,TFe),e(TFe,ICr),e(TC,qCr),e(TC,hU),e(hU,NCr),e(TC,jCr),e(de,DCr),e(de,MC),e(MC,MFe),e(MFe,GCr),e(MC,OCr),e(MC,pU),e(pU,VCr),e(MC,XCr),e(de,zCr),e(de,EC),e(EC,EFe),e(EFe,WCr),e(EC,QCr),e(EC,_U),e(_U,HCr),e(EC,UCr),e(de,JCr),e(de,CC),e(CC,CFe),e(CFe,YCr),e(CC,KCr),e(CC,uU),e(uU,ZCr),e(CC,e5r),e(de,o5r),e(de,wC),e(wC,wFe),e(wFe,r5r),e(wC,t5r),e(wC,bU),e(bU,a5r),e(wC,n5r),e(de,s5r),e(de,AC),e(AC,AFe),e(AFe,l5r),e(AC,i5r),e(AC,vU),e(vU,d5r),e(AC,c5r),e(de,f5r),e(de,yC),e(yC,yFe),e(yFe,m5r),e(yC,g5r),e(yC,FU),e(FU,h5r),e(yC,p5r),e(de,_5r),e(de,LC),e(LC,LFe),e(LFe,u5r),e(LC,b5r),e(LC,TU),e(TU,v5r),e(LC,F5r),e(de,T5r),e(de,xC),e(xC,xFe),e(xFe,M5r),e(xC,E5r),e(xC,MU),e(MU,C5r),e(xC,w5r),e(de,A5r),e(de,$C),e($C,$Fe),e($Fe,y5r),e($C,L5r),e($C,EU),e(EU,x5r),e($C,$5r),e(de,k5r),e(de,kC),e(kC,kFe),e(kFe,S5r),e(kC,R5r),e(kC,CU),e(CU,P5r),e(kC,B5r),e(de,I5r),e(de,SC),e(SC,SFe),e(SFe,q5r),e(SC,N5r),e(SC,wU),e(wU,j5r),e(SC,D5r),e(Br,G5r),M(RC,Br,null),b(f,MNe,u),b(f,vc,u),e(vc,PC),e(PC,RFe),M(J8,RFe,null),e(vc,O5r),e(vc,PFe),e(PFe,V5r),b(f,ENe,u),b(f,ir,u),M(Y8,ir,null),e(ir,X5r),e(ir,Fc),e(Fc,z5r),e(Fc,AU),e(AU,W5r),e(Fc,Q5r),e(Fc,yU),e(yU,H5r),e(Fc,U5r),e(ir,J5r),e(ir,K8),e(K8,Y5r),e(K8,BFe),e(BFe,K5r),e(K8,Z5r),e(ir,e3r),e(ir,Nt),M(Z8,Nt,null),e(Nt,o3r),e(Nt,IFe),e(IFe,r3r),e(Nt,t3r),e(Nt,Tc),e(Tc,a3r),e(Tc,qFe),e(qFe,n3r),e(Tc,s3r),e(Tc,LU),e(LU,l3r),e(Tc,i3r),e(Nt,d3r),M(BC,Nt,null),e(ir,c3r),e(ir,Ir),M(ex,Ir,null),e(Ir,f3r),e(Ir,NFe),e(NFe,m3r),e(Ir,g3r),e(Ir,fn),e(fn,h3r),e(fn,jFe),e(jFe,p3r),e(fn,_3r),e(fn,DFe),e(DFe,u3r),e(fn,b3r),e(fn,GFe),e(GFe,v3r),e(fn,F3r),e(Ir,T3r),e(Ir,ce),e(ce,IC),e(IC,OFe),e(OFe,M3r),e(IC,E3r),e(IC,xU),e(xU,C3r),e(IC,w3r),e(ce,A3r),e(ce,qC),e(qC,VFe),e(VFe,y3r),e(qC,L3r),e(qC,$U),e($U,x3r),e(qC,$3r),e(ce,k3r),e(ce,NC),e(NC,XFe),e(XFe,S3r),e(NC,R3r),e(NC,kU),e(kU,P3r),e(NC,B3r),e(ce,I3r),e(ce,jC),e(jC,zFe),e(zFe,q3r),e(jC,N3r),e(jC,SU),e(SU,j3r),e(jC,D3r),e(ce,G3r),e(ce,DC),e(DC,WFe),e(WFe,O3r),e(DC,V3r),e(DC,RU),e(RU,X3r),e(DC,z3r),e(ce,W3r),e(ce,GC),e(GC,QFe),e(QFe,Q3r),e(GC,H3r),e(GC,PU),e(PU,U3r),e(GC,J3r),e(ce,Y3r),e(ce,OC),e(OC,HFe),e(HFe,K3r),e(OC,Z3r),e(OC,BU),e(BU,ewr),e(OC,owr),e(ce,rwr),e(ce,VC),e(VC,UFe),e(UFe,twr),e(VC,awr),e(VC,IU),e(IU,nwr),e(VC,swr),e(ce,lwr),e(ce,XC),e(XC,JFe),e(JFe,iwr),e(XC,dwr),e(XC,qU),e(qU,cwr),e(XC,fwr),e(ce,mwr),e(ce,zC),e(zC,YFe),e(YFe,gwr),e(zC,hwr),e(zC,NU),e(NU,pwr),e(zC,_wr),e(ce,uwr),e(ce,WC),e(WC,KFe),e(KFe,bwr),e(WC,vwr),e(WC,jU),e(jU,Fwr),e(WC,Twr),e(ce,Mwr),e(ce,QC),e(QC,ZFe),e(ZFe,Ewr),e(QC,Cwr),e(QC,DU),e(DU,wwr),e(QC,Awr),e(ce,ywr),e(ce,HC),e(HC,eTe),e(eTe,Lwr),e(HC,xwr),e(HC,GU),e(GU,$wr),e(HC,kwr),e(ce,Swr),e(ce,UC),e(UC,oTe),e(oTe,Rwr),e(UC,Pwr),e(UC,OU),e(OU,Bwr),e(UC,Iwr),e(ce,qwr),e(ce,JC),e(JC,rTe),e(rTe,Nwr),e(JC,jwr),e(JC,VU),e(VU,Dwr),e(JC,Gwr),e(ce,Owr),e(ce,YC),e(YC,tTe),e(tTe,Vwr),e(YC,Xwr),e(YC,XU),e(XU,zwr),e(YC,Wwr),e(ce,Qwr),e(ce,KC),e(KC,aTe),e(aTe,Hwr),e(KC,Uwr),e(KC,zU),e(zU,Jwr),e(KC,Ywr),e(ce,Kwr),e(ce,ZC),e(ZC,nTe),e(nTe,Zwr),e(ZC,e0r),e(ZC,WU),e(WU,o0r),e(ZC,r0r),e(ce,t0r),e(ce,e5),e(e5,sTe),e(sTe,a0r),e(e5,n0r),e(e5,QU),e(QU,s0r),e(e5,l0r),e(ce,i0r),e(ce,o5),e(o5,lTe),e(lTe,d0r),e(o5,c0r),e(o5,HU),e(HU,f0r),e(o5,m0r),e(Ir,g0r),M(r5,Ir,null),b(f,CNe,u),b(f,Mc,u),e(Mc,t5),e(t5,iTe),M(ox,iTe,null),e(Mc,h0r),e(Mc,dTe),e(dTe,p0r),b(f,wNe,u),b(f,dr,u),M(rx,dr,null),e(dr,_0r),e(dr,Ec),e(Ec,u0r),e(Ec,UU),e(UU,b0r),e(Ec,v0r),e(Ec,JU),e(JU,F0r),e(Ec,T0r),e(dr,M0r),e(dr,tx),e(tx,E0r),e(tx,cTe),e(cTe,C0r),e(tx,w0r),e(dr,A0r),e(dr,jt),M(ax,jt,null),e(jt,y0r),e(jt,fTe),e(fTe,L0r),e(jt,x0r),e(jt,Cc),e(Cc,$0r),e(Cc,mTe),e(mTe,k0r),e(Cc,S0r),e(Cc,YU),e(YU,R0r),e(Cc,P0r),e(jt,B0r),M(a5,jt,null),e(dr,I0r),e(dr,qr),M(nx,qr,null),e(qr,q0r),e(qr,gTe),e(gTe,N0r),e(qr,j0r),e(qr,mn),e(mn,D0r),e(mn,hTe),e(hTe,G0r),e(mn,O0r),e(mn,pTe),e(pTe,V0r),e(mn,X0r),e(mn,_Te),e(_Te,z0r),e(mn,W0r),e(qr,Q0r),e(qr,uTe),e(uTe,n5),e(n5,bTe),e(bTe,H0r),e(n5,U0r),e(n5,KU),e(KU,J0r),e(n5,Y0r),e(qr,K0r),M(s5,qr,null),b(f,ANe,u),b(f,wc,u),e(wc,l5),e(l5,vTe),M(sx,vTe,null),e(wc,Z0r),e(wc,FTe),e(FTe,eAr),b(f,yNe,u),b(f,cr,u),M(lx,cr,null),e(cr,oAr),e(cr,Ac),e(Ac,rAr),e(Ac,ZU),e(ZU,tAr),e(Ac,aAr),e(Ac,eJ),e(eJ,nAr),e(Ac,sAr),e(cr,lAr),e(cr,ix),e(ix,iAr),e(ix,TTe),e(TTe,dAr),e(ix,cAr),e(cr,fAr),e(cr,Dt),M(dx,Dt,null),e(Dt,mAr),e(Dt,MTe),e(MTe,gAr),e(Dt,hAr),e(Dt,yc),e(yc,pAr),e(yc,ETe),e(ETe,_Ar),e(yc,uAr),e(yc,oJ),e(oJ,bAr),e(yc,vAr),e(Dt,FAr),M(i5,Dt,null),e(cr,TAr),e(cr,Nr),M(cx,Nr,null),e(Nr,MAr),e(Nr,CTe),e(CTe,EAr),e(Nr,CAr),e(Nr,gn),e(gn,wAr),e(gn,wTe),e(wTe,AAr),e(gn,yAr),e(gn,ATe),e(ATe,LAr),e(gn,xAr),e(gn,yTe),e(yTe,$Ar),e(gn,kAr),e(Nr,SAr),e(Nr,LTe),e(LTe,d5),e(d5,xTe),e(xTe,RAr),e(d5,PAr),e(d5,rJ),e(rJ,BAr),e(d5,IAr),e(Nr,qAr),M(c5,Nr,null),b(f,LNe,u),b(f,Lc,u),e(Lc,f5),e(f5,$Te),M(fx,$Te,null),e(Lc,NAr),e(Lc,kTe),e(kTe,jAr),b(f,xNe,u),b(f,fr,u),M(mx,fr,null),e(fr,DAr),e(fr,xc),e(xc,GAr),e(xc,tJ),e(tJ,OAr),e(xc,VAr),e(xc,aJ),e(aJ,XAr),e(xc,zAr),e(fr,WAr),e(fr,gx),e(gx,QAr),e(gx,STe),e(STe,HAr),e(gx,UAr),e(fr,JAr),e(fr,Gt),M(hx,Gt,null),e(Gt,YAr),e(Gt,RTe),e(RTe,KAr),e(Gt,ZAr),e(Gt,$c),e($c,e6r),e($c,PTe),e(PTe,o6r),e($c,r6r),e($c,nJ),e(nJ,t6r),e($c,a6r),e(Gt,n6r),M(m5,Gt,null),e(fr,s6r),e(fr,jr),M(px,jr,null),e(jr,l6r),e(jr,BTe),e(BTe,i6r),e(jr,d6r),e(jr,hn),e(hn,c6r),e(hn,ITe),e(ITe,f6r),e(hn,m6r),e(hn,qTe),e(qTe,g6r),e(hn,h6r),e(hn,NTe),e(NTe,p6r),e(hn,_6r),e(jr,u6r),e(jr,oe),e(oe,g5),e(g5,jTe),e(jTe,b6r),e(g5,v6r),e(g5,sJ),e(sJ,F6r),e(g5,T6r),e(oe,M6r),e(oe,h5),e(h5,DTe),e(DTe,E6r),e(h5,C6r),e(h5,lJ),e(lJ,w6r),e(h5,A6r),e(oe,y6r),e(oe,p5),e(p5,GTe),e(GTe,L6r),e(p5,x6r),e(p5,iJ),e(iJ,$6r),e(p5,k6r),e(oe,S6r),e(oe,_5),e(_5,OTe),e(OTe,R6r),e(_5,P6r),e(_5,dJ),e(dJ,B6r),e(_5,I6r),e(oe,q6r),e(oe,u5),e(u5,VTe),e(VTe,N6r),e(u5,j6r),e(u5,cJ),e(cJ,D6r),e(u5,G6r),e(oe,O6r),e(oe,b5),e(b5,XTe),e(XTe,V6r),e(b5,X6r),e(b5,fJ),e(fJ,z6r),e(b5,W6r),e(oe,Q6r),e(oe,v5),e(v5,zTe),e(zTe,H6r),e(v5,U6r),e(v5,mJ),e(mJ,J6r),e(v5,Y6r),e(oe,K6r),e(oe,F5),e(F5,WTe),e(WTe,Z6r),e(F5,eyr),e(F5,gJ),e(gJ,oyr),e(F5,ryr),e(oe,tyr),e(oe,T5),e(T5,QTe),e(QTe,ayr),e(T5,nyr),e(T5,hJ),e(hJ,syr),e(T5,lyr),e(oe,iyr),e(oe,M5),e(M5,HTe),e(HTe,dyr),e(M5,cyr),e(M5,pJ),e(pJ,fyr),e(M5,myr),e(oe,gyr),e(oe,E5),e(E5,UTe),e(UTe,hyr),e(E5,pyr),e(E5,_J),e(_J,_yr),e(E5,uyr),e(oe,byr),e(oe,C5),e(C5,JTe),e(JTe,vyr),e(C5,Fyr),e(C5,uJ),e(uJ,Tyr),e(C5,Myr),e(oe,Eyr),e(oe,w5),e(w5,YTe),e(YTe,Cyr),e(w5,wyr),e(w5,bJ),e(bJ,Ayr),e(w5,yyr),e(oe,Lyr),e(oe,A5),e(A5,KTe),e(KTe,xyr),e(A5,$yr),e(A5,vJ),e(vJ,kyr),e(A5,Syr),e(oe,Ryr),e(oe,y5),e(y5,ZTe),e(ZTe,Pyr),e(y5,Byr),e(y5,FJ),e(FJ,Iyr),e(y5,qyr),e(oe,Nyr),e(oe,L5),e(L5,eMe),e(eMe,jyr),e(L5,Dyr),e(L5,TJ),e(TJ,Gyr),e(L5,Oyr),e(oe,Vyr),e(oe,x5),e(x5,oMe),e(oMe,Xyr),e(x5,zyr),e(x5,MJ),e(MJ,Wyr),e(x5,Qyr),e(oe,Hyr),e(oe,$5),e($5,rMe),e(rMe,Uyr),e($5,Jyr),e($5,EJ),e(EJ,Yyr),e($5,Kyr),e(oe,Zyr),e(oe,k5),e(k5,tMe),e(tMe,eLr),e(k5,oLr),e(k5,CJ),e(CJ,rLr),e(k5,tLr),e(oe,aLr),e(oe,S5),e(S5,aMe),e(aMe,nLr),e(S5,sLr),e(S5,wJ),e(wJ,lLr),e(S5,iLr),e(oe,dLr),e(oe,R5),e(R5,nMe),e(nMe,cLr),e(R5,fLr),e(R5,AJ),e(AJ,mLr),e(R5,gLr),e(oe,hLr),e(oe,P5),e(P5,sMe),e(sMe,pLr),e(P5,_Lr),e(P5,yJ),e(yJ,uLr),e(P5,bLr),e(oe,vLr),e(oe,B5),e(B5,lMe),e(lMe,FLr),e(B5,TLr),e(B5,LJ),e(LJ,MLr),e(B5,ELr),e(oe,CLr),e(oe,I5),e(I5,iMe),e(iMe,wLr),e(I5,ALr),e(I5,xJ),e(xJ,yLr),e(I5,LLr),e(oe,xLr),e(oe,q5),e(q5,dMe),e(dMe,$Lr),e(q5,kLr),e(q5,$J),e($J,SLr),e(q5,RLr),e(oe,PLr),e(oe,N5),e(N5,cMe),e(cMe,BLr),e(N5,ILr),e(N5,kJ),e(kJ,qLr),e(N5,NLr),e(jr,jLr),M(j5,jr,null),b(f,$Ne,u),b(f,kc,u),e(kc,D5),e(D5,fMe),M(_x,fMe,null),e(kc,DLr),e(kc,mMe),e(mMe,GLr),b(f,kNe,u),b(f,mr,u),M(ux,mr,null),e(mr,OLr),e(mr,Sc),e(Sc,VLr),e(Sc,SJ),e(SJ,XLr),e(Sc,zLr),e(Sc,RJ),e(RJ,WLr),e(Sc,QLr),e(mr,HLr),e(mr,bx),e(bx,ULr),e(bx,gMe),e(gMe,JLr),e(bx,YLr),e(mr,KLr),e(mr,Ot),M(vx,Ot,null),e(Ot,ZLr),e(Ot,hMe),e(hMe,e8r),e(Ot,o8r),e(Ot,Rc),e(Rc,r8r),e(Rc,pMe),e(pMe,t8r),e(Rc,a8r),e(Rc,PJ),e(PJ,n8r),e(Rc,s8r),e(Ot,l8r),M(G5,Ot,null),e(mr,i8r),e(mr,Dr),M(Fx,Dr,null),e(Dr,d8r),e(Dr,_Me),e(_Me,c8r),e(Dr,f8r),e(Dr,pn),e(pn,m8r),e(pn,uMe),e(uMe,g8r),e(pn,h8r),e(pn,bMe),e(bMe,p8r),e(pn,_8r),e(pn,vMe),e(vMe,u8r),e(pn,b8r),e(Dr,v8r),e(Dr,Le),e(Le,O5),e(O5,FMe),e(FMe,F8r),e(O5,T8r),e(O5,BJ),e(BJ,M8r),e(O5,E8r),e(Le,C8r),e(Le,V5),e(V5,TMe),e(TMe,w8r),e(V5,A8r),e(V5,IJ),e(IJ,y8r),e(V5,L8r),e(Le,x8r),e(Le,X5),e(X5,MMe),e(MMe,$8r),e(X5,k8r),e(X5,qJ),e(qJ,S8r),e(X5,R8r),e(Le,P8r),e(Le,z5),e(z5,EMe),e(EMe,B8r),e(z5,I8r),e(z5,NJ),e(NJ,q8r),e(z5,N8r),e(Le,j8r),e(Le,W5),e(W5,CMe),e(CMe,D8r),e(W5,G8r),e(W5,jJ),e(jJ,O8r),e(W5,V8r),e(Le,X8r),e(Le,Q5),e(Q5,wMe),e(wMe,z8r),e(Q5,W8r),e(Q5,DJ),e(DJ,Q8r),e(Q5,H8r),e(Le,U8r),e(Le,H5),e(H5,AMe),e(AMe,J8r),e(H5,Y8r),e(H5,GJ),e(GJ,K8r),e(H5,Z8r),e(Le,exr),e(Le,U5),e(U5,yMe),e(yMe,oxr),e(U5,rxr),e(U5,OJ),e(OJ,txr),e(U5,axr),e(Le,nxr),e(Le,J5),e(J5,LMe),e(LMe,sxr),e(J5,lxr),e(J5,VJ),e(VJ,ixr),e(J5,dxr),e(Le,cxr),e(Le,Y5),e(Y5,xMe),e(xMe,fxr),e(Y5,mxr),e(Y5,XJ),e(XJ,gxr),e(Y5,hxr),e(Dr,pxr),M(K5,Dr,null),b(f,SNe,u),b(f,Pc,u),e(Pc,Z5),e(Z5,$Me),M(Tx,$Me,null),e(Pc,_xr),e(Pc,kMe),e(kMe,uxr),b(f,RNe,u),b(f,gr,u),M(Mx,gr,null),e(gr,bxr),e(gr,Bc),e(Bc,vxr),e(Bc,zJ),e(zJ,Fxr),e(Bc,Txr),e(Bc,WJ),e(WJ,Mxr),e(Bc,Exr),e(gr,Cxr),e(gr,Ex),e(Ex,wxr),e(Ex,SMe),e(SMe,Axr),e(Ex,yxr),e(gr,Lxr),e(gr,Vt),M(Cx,Vt,null),e(Vt,xxr),e(Vt,RMe),e(RMe,$xr),e(Vt,kxr),e(Vt,Ic),e(Ic,Sxr),e(Ic,PMe),e(PMe,Rxr),e(Ic,Pxr),e(Ic,QJ),e(QJ,Bxr),e(Ic,Ixr),e(Vt,qxr),M(e3,Vt,null),e(gr,Nxr),e(gr,Gr),M(wx,Gr,null),e(Gr,jxr),e(Gr,BMe),e(BMe,Dxr),e(Gr,Gxr),e(Gr,_n),e(_n,Oxr),e(_n,IMe),e(IMe,Vxr),e(_n,Xxr),e(_n,qMe),e(qMe,zxr),e(_n,Wxr),e(_n,NMe),e(NMe,Qxr),e(_n,Hxr),e(Gr,Uxr),e(Gr,Me),e(Me,o3),e(o3,jMe),e(jMe,Jxr),e(o3,Yxr),e(o3,HJ),e(HJ,Kxr),e(o3,Zxr),e(Me,e9r),e(Me,r3),e(r3,DMe),e(DMe,o9r),e(r3,r9r),e(r3,UJ),e(UJ,t9r),e(r3,a9r),e(Me,n9r),e(Me,t3),e(t3,GMe),e(GMe,s9r),e(t3,l9r),e(t3,JJ),e(JJ,i9r),e(t3,d9r),e(Me,c9r),e(Me,a3),e(a3,OMe),e(OMe,f9r),e(a3,m9r),e(a3,YJ),e(YJ,g9r),e(a3,h9r),e(Me,p9r),e(Me,n3),e(n3,VMe),e(VMe,_9r),e(n3,u9r),e(n3,KJ),e(KJ,b9r),e(n3,v9r),e(Me,F9r),e(Me,s3),e(s3,XMe),e(XMe,T9r),e(s3,M9r),e(s3,ZJ),e(ZJ,E9r),e(s3,C9r),e(Me,w9r),e(Me,l3),e(l3,zMe),e(zMe,A9r),e(l3,y9r),e(l3,eY),e(eY,L9r),e(l3,x9r),e(Me,$9r),e(Me,i3),e(i3,WMe),e(WMe,k9r),e(i3,S9r),e(i3,oY),e(oY,R9r),e(i3,P9r),e(Me,B9r),e(Me,d3),e(d3,QMe),e(QMe,I9r),e(d3,q9r),e(d3,rY),e(rY,N9r),e(d3,j9r),e(Me,D9r),e(Me,c3),e(c3,HMe),e(HMe,G9r),e(c3,O9r),e(c3,tY),e(tY,V9r),e(c3,X9r),e(Me,z9r),e(Me,f3),e(f3,UMe),e(UMe,W9r),e(f3,Q9r),e(f3,aY),e(aY,H9r),e(f3,U9r),e(Me,J9r),e(Me,m3),e(m3,JMe),e(JMe,Y9r),e(m3,K9r),e(m3,nY),e(nY,Z9r),e(m3,e$r),e(Gr,o$r),M(g3,Gr,null),b(f,PNe,u),b(f,qc,u),e(qc,h3),e(h3,YMe),M(Ax,YMe,null),e(qc,r$r),e(qc,KMe),e(KMe,t$r),b(f,BNe,u),b(f,hr,u),M(yx,hr,null),e(hr,a$r),e(hr,Nc),e(Nc,n$r),e(Nc,sY),e(sY,s$r),e(Nc,l$r),e(Nc,lY),e(lY,i$r),e(Nc,d$r),e(hr,c$r),e(hr,Lx),e(Lx,f$r),e(Lx,ZMe),e(ZMe,m$r),e(Lx,g$r),e(hr,h$r),e(hr,Xt),M(xx,Xt,null),e(Xt,p$r),e(Xt,e4e),e(e4e,_$r),e(Xt,u$r),e(Xt,jc),e(jc,b$r),e(jc,o4e),e(o4e,v$r),e(jc,F$r),e(jc,iY),e(iY,T$r),e(jc,M$r),e(Xt,E$r),M(p3,Xt,null),e(hr,C$r),e(hr,Or),M($x,Or,null),e(Or,w$r),e(Or,r4e),e(r4e,A$r),e(Or,y$r),e(Or,un),e(un,L$r),e(un,t4e),e(t4e,x$r),e(un,$$r),e(un,a4e),e(a4e,k$r),e(un,S$r),e(un,n4e),e(n4e,R$r),e(un,P$r),e(Or,B$r),e(Or,xe),e(xe,_3),e(_3,s4e),e(s4e,I$r),e(_3,q$r),e(_3,dY),e(dY,N$r),e(_3,j$r),e(xe,D$r),e(xe,u3),e(u3,l4e),e(l4e,G$r),e(u3,O$r),e(u3,cY),e(cY,V$r),e(u3,X$r),e(xe,z$r),e(xe,b3),e(b3,i4e),e(i4e,W$r),e(b3,Q$r),e(b3,fY),e(fY,H$r),e(b3,U$r),e(xe,J$r),e(xe,v3),e(v3,d4e),e(d4e,Y$r),e(v3,K$r),e(v3,mY),e(mY,Z$r),e(v3,ekr),e(xe,okr),e(xe,F3),e(F3,c4e),e(c4e,rkr),e(F3,tkr),e(F3,gY),e(gY,akr),e(F3,nkr),e(xe,skr),e(xe,T3),e(T3,f4e),e(f4e,lkr),e(T3,ikr),e(T3,hY),e(hY,dkr),e(T3,ckr),e(xe,fkr),e(xe,M3),e(M3,m4e),e(m4e,mkr),e(M3,gkr),e(M3,pY),e(pY,hkr),e(M3,pkr),e(xe,_kr),e(xe,E3),e(E3,g4e),e(g4e,ukr),e(E3,bkr),e(E3,_Y),e(_Y,vkr),e(E3,Fkr),e(xe,Tkr),e(xe,C3),e(C3,h4e),e(h4e,Mkr),e(C3,Ekr),e(C3,uY),e(uY,Ckr),e(C3,wkr),e(xe,Akr),e(xe,w3),e(w3,p4e),e(p4e,ykr),e(w3,Lkr),e(w3,bY),e(bY,xkr),e(w3,$kr),e(Or,kkr),M(A3,Or,null),b(f,INe,u),b(f,Dc,u),e(Dc,y3),e(y3,_4e),M(kx,_4e,null),e(Dc,Skr),e(Dc,u4e),e(u4e,Rkr),b(f,qNe,u),b(f,pr,u),M(Sx,pr,null),e(pr,Pkr),e(pr,Gc),e(Gc,Bkr),e(Gc,vY),e(vY,Ikr),e(Gc,qkr),e(Gc,FY),e(FY,Nkr),e(Gc,jkr),e(pr,Dkr),e(pr,Rx),e(Rx,Gkr),e(Rx,b4e),e(b4e,Okr),e(Rx,Vkr),e(pr,Xkr),e(pr,zt),M(Px,zt,null),e(zt,zkr),e(zt,v4e),e(v4e,Wkr),e(zt,Qkr),e(zt,Oc),e(Oc,Hkr),e(Oc,F4e),e(F4e,Ukr),e(Oc,Jkr),e(Oc,TY),e(TY,Ykr),e(Oc,Kkr),e(zt,Zkr),M(L3,zt,null),e(pr,eSr),e(pr,Vr),M(Bx,Vr,null),e(Vr,oSr),e(Vr,T4e),e(T4e,rSr),e(Vr,tSr),e(Vr,bn),e(bn,aSr),e(bn,M4e),e(M4e,nSr),e(bn,sSr),e(bn,E4e),e(E4e,lSr),e(bn,iSr),e(bn,C4e),e(C4e,dSr),e(bn,cSr),e(Vr,fSr),e(Vr,Pe),e(Pe,x3),e(x3,w4e),e(w4e,mSr),e(x3,gSr),e(x3,MY),e(MY,hSr),e(x3,pSr),e(Pe,_Sr),e(Pe,$3),e($3,A4e),e(A4e,uSr),e($3,bSr),e($3,EY),e(EY,vSr),e($3,FSr),e(Pe,TSr),e(Pe,k3),e(k3,y4e),e(y4e,MSr),e(k3,ESr),e(k3,CY),e(CY,CSr),e(k3,wSr),e(Pe,ASr),e(Pe,S3),e(S3,L4e),e(L4e,ySr),e(S3,LSr),e(S3,wY),e(wY,xSr),e(S3,$Sr),e(Pe,kSr),e(Pe,R3),e(R3,x4e),e(x4e,SSr),e(R3,RSr),e(R3,AY),e(AY,PSr),e(R3,BSr),e(Pe,ISr),e(Pe,P3),e(P3,$4e),e($4e,qSr),e(P3,NSr),e(P3,yY),e(yY,jSr),e(P3,DSr),e(Pe,GSr),e(Pe,B3),e(B3,k4e),e(k4e,OSr),e(B3,VSr),e(B3,LY),e(LY,XSr),e(B3,zSr),e(Pe,WSr),e(Pe,I3),e(I3,S4e),e(S4e,QSr),e(I3,HSr),e(I3,xY),e(xY,USr),e(I3,JSr),e(Pe,YSr),e(Pe,q3),e(q3,R4e),e(R4e,KSr),e(q3,ZSr),e(q3,$Y),e($Y,eRr),e(q3,oRr),e(Vr,rRr),M(N3,Vr,null),b(f,NNe,u),b(f,Vc,u),e(Vc,j3),e(j3,P4e),M(Ix,P4e,null),e(Vc,tRr),e(Vc,B4e),e(B4e,aRr),b(f,jNe,u),b(f,_r,u),M(qx,_r,null),e(_r,nRr),e(_r,Xc),e(Xc,sRr),e(Xc,kY),e(kY,lRr),e(Xc,iRr),e(Xc,SY),e(SY,dRr),e(Xc,cRr),e(_r,fRr),e(_r,Nx),e(Nx,mRr),e(Nx,I4e),e(I4e,gRr),e(Nx,hRr),e(_r,pRr),e(_r,Wt),M(jx,Wt,null),e(Wt,_Rr),e(Wt,q4e),e(q4e,uRr),e(Wt,bRr),e(Wt,zc),e(zc,vRr),e(zc,N4e),e(N4e,FRr),e(zc,TRr),e(zc,RY),e(RY,MRr),e(zc,ERr),e(Wt,CRr),M(D3,Wt,null),e(_r,wRr),e(_r,Xr),M(Dx,Xr,null),e(Xr,ARr),e(Xr,j4e),e(j4e,yRr),e(Xr,LRr),e(Xr,vn),e(vn,xRr),e(vn,D4e),e(D4e,$Rr),e(vn,kRr),e(vn,G4e),e(G4e,SRr),e(vn,RRr),e(vn,O4e),e(O4e,PRr),e(vn,BRr),e(Xr,IRr),e(Xr,$e),e($e,G3),e(G3,V4e),e(V4e,qRr),e(G3,NRr),e(G3,PY),e(PY,jRr),e(G3,DRr),e($e,GRr),e($e,O3),e(O3,X4e),e(X4e,ORr),e(O3,VRr),e(O3,BY),e(BY,XRr),e(O3,zRr),e($e,WRr),e($e,V3),e(V3,z4e),e(z4e,QRr),e(V3,HRr),e(V3,IY),e(IY,URr),e(V3,JRr),e($e,YRr),e($e,X3),e(X3,W4e),e(W4e,KRr),e(X3,ZRr),e(X3,qY),e(qY,ePr),e(X3,oPr),e($e,rPr),e($e,z3),e(z3,Q4e),e(Q4e,tPr),e(z3,aPr),e(z3,NY),e(NY,nPr),e(z3,sPr),e($e,lPr),e($e,W3),e(W3,H4e),e(H4e,iPr),e(W3,dPr),e(W3,jY),e(jY,cPr),e(W3,fPr),e($e,mPr),e($e,Q3),e(Q3,U4e),e(U4e,gPr),e(Q3,hPr),e(Q3,DY),e(DY,pPr),e(Q3,_Pr),e($e,uPr),e($e,H3),e(H3,J4e),e(J4e,bPr),e(H3,vPr),e(H3,GY),e(GY,FPr),e(H3,TPr),e($e,MPr),e($e,U3),e(U3,Y4e),e(Y4e,EPr),e(U3,CPr),e(U3,OY),e(OY,wPr),e(U3,APr),e($e,yPr),e($e,J3),e(J3,K4e),e(K4e,LPr),e(J3,xPr),e(J3,VY),e(VY,$Pr),e(J3,kPr),e(Xr,SPr),M(Y3,Xr,null),b(f,DNe,u),b(f,Wc,u),e(Wc,K3),e(K3,Z4e),M(Gx,Z4e,null),e(Wc,RPr),e(Wc,eEe),e(eEe,PPr),b(f,GNe,u),b(f,ur,u),M(Ox,ur,null),e(ur,BPr),e(ur,Qc),e(Qc,IPr),e(Qc,XY),e(XY,qPr),e(Qc,NPr),e(Qc,zY),e(zY,jPr),e(Qc,DPr),e(ur,GPr),e(ur,Vx),e(Vx,OPr),e(Vx,oEe),e(oEe,VPr),e(Vx,XPr),e(ur,zPr),e(ur,Qt),M(Xx,Qt,null),e(Qt,WPr),e(Qt,rEe),e(rEe,QPr),e(Qt,HPr),e(Qt,Hc),e(Hc,UPr),e(Hc,tEe),e(tEe,JPr),e(Hc,YPr),e(Hc,WY),e(WY,KPr),e(Hc,ZPr),e(Qt,eBr),M(Z3,Qt,null),e(ur,oBr),e(ur,zr),M(zx,zr,null),e(zr,rBr),e(zr,aEe),e(aEe,tBr),e(zr,aBr),e(zr,Fn),e(Fn,nBr),e(Fn,nEe),e(nEe,sBr),e(Fn,lBr),e(Fn,sEe),e(sEe,iBr),e(Fn,dBr),e(Fn,lEe),e(lEe,cBr),e(Fn,fBr),e(zr,mBr),e(zr,ke),e(ke,ew),e(ew,iEe),e(iEe,gBr),e(ew,hBr),e(ew,QY),e(QY,pBr),e(ew,_Br),e(ke,uBr),e(ke,ow),e(ow,dEe),e(dEe,bBr),e(ow,vBr),e(ow,HY),e(HY,FBr),e(ow,TBr),e(ke,MBr),e(ke,rw),e(rw,cEe),e(cEe,EBr),e(rw,CBr),e(rw,UY),e(UY,wBr),e(rw,ABr),e(ke,yBr),e(ke,tw),e(tw,fEe),e(fEe,LBr),e(tw,xBr),e(tw,JY),e(JY,$Br),e(tw,kBr),e(ke,SBr),e(ke,aw),e(aw,mEe),e(mEe,RBr),e(aw,PBr),e(aw,YY),e(YY,BBr),e(aw,IBr),e(ke,qBr),e(ke,nw),e(nw,gEe),e(gEe,NBr),e(nw,jBr),e(nw,KY),e(KY,DBr),e(nw,GBr),e(ke,OBr),e(ke,sw),e(sw,hEe),e(hEe,VBr),e(sw,XBr),e(sw,ZY),e(ZY,zBr),e(sw,WBr),e(ke,QBr),e(ke,lw),e(lw,pEe),e(pEe,HBr),e(lw,UBr),e(lw,eK),e(eK,JBr),e(lw,YBr),e(ke,KBr),e(ke,iw),e(iw,_Ee),e(_Ee,ZBr),e(iw,eIr),e(iw,oK),e(oK,oIr),e(iw,rIr),e(ke,tIr),e(ke,dw),e(dw,uEe),e(uEe,aIr),e(dw,nIr),e(dw,rK),e(rK,sIr),e(dw,lIr),e(zr,iIr),M(cw,zr,null),b(f,ONe,u),b(f,Uc,u),e(Uc,fw),e(fw,bEe),M(Wx,bEe,null),e(Uc,dIr),e(Uc,vEe),e(vEe,cIr),b(f,VNe,u),b(f,br,u),M(Qx,br,null),e(br,fIr),e(br,Jc),e(Jc,mIr),e(Jc,tK),e(tK,gIr),e(Jc,hIr),e(Jc,aK),e(aK,pIr),e(Jc,_Ir),e(br,uIr),e(br,Hx),e(Hx,bIr),e(Hx,FEe),e(FEe,vIr),e(Hx,FIr),e(br,TIr),e(br,Ht),M(Ux,Ht,null),e(Ht,MIr),e(Ht,TEe),e(TEe,EIr),e(Ht,CIr),e(Ht,Yc),e(Yc,wIr),e(Yc,MEe),e(MEe,AIr),e(Yc,yIr),e(Yc,nK),e(nK,LIr),e(Yc,xIr),e(Ht,$Ir),M(mw,Ht,null),e(br,kIr),e(br,Wr),M(Jx,Wr,null),e(Wr,SIr),e(Wr,EEe),e(EEe,RIr),e(Wr,PIr),e(Wr,Tn),e(Tn,BIr),e(Tn,CEe),e(CEe,IIr),e(Tn,qIr),e(Tn,wEe),e(wEe,NIr),e(Tn,jIr),e(Tn,AEe),e(AEe,DIr),e(Tn,GIr),e(Wr,OIr),e(Wr,Ge),e(Ge,gw),e(gw,yEe),e(yEe,VIr),e(gw,XIr),e(gw,sK),e(sK,zIr),e(gw,WIr),e(Ge,QIr),e(Ge,hw),e(hw,LEe),e(LEe,HIr),e(hw,UIr),e(hw,lK),e(lK,JIr),e(hw,YIr),e(Ge,KIr),e(Ge,pw),e(pw,xEe),e(xEe,ZIr),e(pw,eqr),e(pw,iK),e(iK,oqr),e(pw,rqr),e(Ge,tqr),e(Ge,_w),e(_w,$Ee),e($Ee,aqr),e(_w,nqr),e(_w,dK),e(dK,sqr),e(_w,lqr),e(Ge,iqr),e(Ge,uw),e(uw,kEe),e(kEe,dqr),e(uw,cqr),e(uw,cK),e(cK,fqr),e(uw,mqr),e(Ge,gqr),e(Ge,bw),e(bw,SEe),e(SEe,hqr),e(bw,pqr),e(bw,fK),e(fK,_qr),e(bw,uqr),e(Ge,bqr),e(Ge,vw),e(vw,REe),e(REe,vqr),e(vw,Fqr),e(vw,mK),e(mK,Tqr),e(vw,Mqr),e(Ge,Eqr),e(Ge,Fw),e(Fw,PEe),e(PEe,Cqr),e(Fw,wqr),e(Fw,gK),e(gK,Aqr),e(Fw,yqr),e(Wr,Lqr),M(Tw,Wr,null),b(f,XNe,u),b(f,Kc,u),e(Kc,Mw),e(Mw,BEe),M(Yx,BEe,null),e(Kc,xqr),e(Kc,IEe),e(IEe,$qr),b(f,zNe,u),b(f,vr,u),M(Kx,vr,null),e(vr,kqr),e(vr,Zc),e(Zc,Sqr),e(Zc,hK),e(hK,Rqr),e(Zc,Pqr),e(Zc,pK),e(pK,Bqr),e(Zc,Iqr),e(vr,qqr),e(vr,Zx),e(Zx,Nqr),e(Zx,qEe),e(qEe,jqr),e(Zx,Dqr),e(vr,Gqr),e(vr,Ut),M(e9,Ut,null),e(Ut,Oqr),e(Ut,NEe),e(NEe,Vqr),e(Ut,Xqr),e(Ut,ef),e(ef,zqr),e(ef,jEe),e(jEe,Wqr),e(ef,Qqr),e(ef,_K),e(_K,Hqr),e(ef,Uqr),e(Ut,Jqr),M(Ew,Ut,null),e(vr,Yqr),e(vr,Qr),M(o9,Qr,null),e(Qr,Kqr),e(Qr,DEe),e(DEe,Zqr),e(Qr,eNr),e(Qr,Mn),e(Mn,oNr),e(Mn,GEe),e(GEe,rNr),e(Mn,tNr),e(Mn,OEe),e(OEe,aNr),e(Mn,nNr),e(Mn,VEe),e(VEe,sNr),e(Mn,lNr),e(Qr,iNr),e(Qr,Oe),e(Oe,Cw),e(Cw,XEe),e(XEe,dNr),e(Cw,cNr),e(Cw,uK),e(uK,fNr),e(Cw,mNr),e(Oe,gNr),e(Oe,ww),e(ww,zEe),e(zEe,hNr),e(ww,pNr),e(ww,bK),e(bK,_Nr),e(ww,uNr),e(Oe,bNr),e(Oe,Aw),e(Aw,WEe),e(WEe,vNr),e(Aw,FNr),e(Aw,vK),e(vK,TNr),e(Aw,MNr),e(Oe,ENr),e(Oe,yw),e(yw,QEe),e(QEe,CNr),e(yw,wNr),e(yw,FK),e(FK,ANr),e(yw,yNr),e(Oe,LNr),e(Oe,Lw),e(Lw,HEe),e(HEe,xNr),e(Lw,$Nr),e(Lw,TK),e(TK,kNr),e(Lw,SNr),e(Oe,RNr),e(Oe,xw),e(xw,UEe),e(UEe,PNr),e(xw,BNr),e(xw,MK),e(MK,INr),e(xw,qNr),e(Oe,NNr),e(Oe,$w),e($w,JEe),e(JEe,jNr),e($w,DNr),e($w,EK),e(EK,GNr),e($w,ONr),e(Oe,VNr),e(Oe,kw),e(kw,YEe),e(YEe,XNr),e(kw,zNr),e(kw,CK),e(CK,WNr),e(kw,QNr),e(Qr,HNr),M(Sw,Qr,null),b(f,WNe,u),b(f,of,u),e(of,Rw),e(Rw,KEe),M(r9,KEe,null),e(of,UNr),e(of,ZEe),e(ZEe,JNr),b(f,QNe,u),b(f,Fr,u),M(t9,Fr,null),e(Fr,YNr),e(Fr,rf),e(rf,KNr),e(rf,wK),e(wK,ZNr),e(rf,ejr),e(rf,AK),e(AK,ojr),e(rf,rjr),e(Fr,tjr),e(Fr,a9),e(a9,ajr),e(a9,eCe),e(eCe,njr),e(a9,sjr),e(Fr,ljr),e(Fr,Jt),M(n9,Jt,null),e(Jt,ijr),e(Jt,oCe),e(oCe,djr),e(Jt,cjr),e(Jt,tf),e(tf,fjr),e(tf,rCe),e(rCe,mjr),e(tf,gjr),e(tf,yK),e(yK,hjr),e(tf,pjr),e(Jt,_jr),M(Pw,Jt,null),e(Fr,ujr),e(Fr,Hr),M(s9,Hr,null),e(Hr,bjr),e(Hr,tCe),e(tCe,vjr),e(Hr,Fjr),e(Hr,En),e(En,Tjr),e(En,aCe),e(aCe,Mjr),e(En,Ejr),e(En,nCe),e(nCe,Cjr),e(En,wjr),e(En,sCe),e(sCe,Ajr),e(En,yjr),e(Hr,Ljr),e(Hr,lCe),e(lCe,Bw),e(Bw,iCe),e(iCe,xjr),e(Bw,$jr),e(Bw,LK),e(LK,kjr),e(Bw,Sjr),e(Hr,Rjr),M(Iw,Hr,null),b(f,HNe,u),b(f,af,u),e(af,qw),e(qw,dCe),M(l9,dCe,null),e(af,Pjr),e(af,cCe),e(cCe,Bjr),b(f,UNe,u),b(f,Tr,u),M(i9,Tr,null),e(Tr,Ijr),e(Tr,nf),e(nf,qjr),e(nf,xK),e(xK,Njr),e(nf,jjr),e(nf,$K),e($K,Djr),e(nf,Gjr),e(Tr,Ojr),e(Tr,d9),e(d9,Vjr),e(d9,fCe),e(fCe,Xjr),e(d9,zjr),e(Tr,Wjr),e(Tr,Yt),M(c9,Yt,null),e(Yt,Qjr),e(Yt,mCe),e(mCe,Hjr),e(Yt,Ujr),e(Yt,sf),e(sf,Jjr),e(sf,gCe),e(gCe,Yjr),e(sf,Kjr),e(sf,kK),e(kK,Zjr),e(sf,eDr),e(Yt,oDr),M(Nw,Yt,null),e(Tr,rDr),e(Tr,Ur),M(f9,Ur,null),e(Ur,tDr),e(Ur,hCe),e(hCe,aDr),e(Ur,nDr),e(Ur,Cn),e(Cn,sDr),e(Cn,pCe),e(pCe,lDr),e(Cn,iDr),e(Cn,_Ce),e(_Ce,dDr),e(Cn,cDr),e(Cn,uCe),e(uCe,fDr),e(Cn,mDr),e(Ur,gDr),e(Ur,m9),e(m9,jw),e(jw,bCe),e(bCe,hDr),e(jw,pDr),e(jw,SK),e(SK,_Dr),e(jw,uDr),e(m9,bDr),e(m9,Dw),e(Dw,vCe),e(vCe,vDr),e(Dw,FDr),e(Dw,RK),e(RK,TDr),e(Dw,MDr),e(Ur,EDr),M(Gw,Ur,null),b(f,JNe,u),b(f,lf,u),e(lf,Ow),e(Ow,FCe),M(g9,FCe,null),e(lf,CDr),e(lf,TCe),e(TCe,wDr),b(f,YNe,u),b(f,Mr,u),M(h9,Mr,null),e(Mr,ADr),e(Mr,df),e(df,yDr),e(df,PK),e(PK,LDr),e(df,xDr),e(df,BK),e(BK,$Dr),e(df,kDr),e(Mr,SDr),e(Mr,p9),e(p9,RDr),e(p9,MCe),e(MCe,PDr),e(p9,BDr),e(Mr,IDr),e(Mr,Kt),M(_9,Kt,null),e(Kt,qDr),e(Kt,ECe),e(ECe,NDr),e(Kt,jDr),e(Kt,cf),e(cf,DDr),e(cf,CCe),e(CCe,GDr),e(cf,ODr),e(cf,IK),e(IK,VDr),e(cf,XDr),e(Kt,zDr),M(Vw,Kt,null),e(Mr,WDr),e(Mr,Jr),M(u9,Jr,null),e(Jr,QDr),e(Jr,wCe),e(wCe,HDr),e(Jr,UDr),e(Jr,wn),e(wn,JDr),e(wn,ACe),e(ACe,YDr),e(wn,KDr),e(wn,yCe),e(yCe,ZDr),e(wn,eGr),e(wn,LCe),e(LCe,oGr),e(wn,rGr),e(Jr,tGr),e(Jr,xCe),e(xCe,Xw),e(Xw,$Ce),e($Ce,aGr),e(Xw,nGr),e(Xw,qK),e(qK,sGr),e(Xw,lGr),e(Jr,iGr),M(zw,Jr,null),KNe=!0},p(f,[u]){const b9={};u&2&&(b9.$$scope={dirty:u,ctx:f}),vf.$set(b9);const kCe={};u&2&&(kCe.$$scope={dirty:u,ctx:f}),vg.$set(kCe);const SCe={};u&2&&(SCe.$$scope={dirty:u,ctx:f}),Zg.$set(SCe);const RCe={};u&2&&(RCe.$$scope={dirty:u,ctx:f}),Lh.$set(RCe);const v9={};u&2&&(v9.$$scope={dirty:u,ctx:f}),xh.$set(v9);const PCe={};u&2&&(PCe.$$scope={dirty:u,ctx:f}),Hh.$set(PCe);const An={};u&2&&(An.$$scope={dirty:u,ctx:f}),Uh.$set(An);const BCe={};u&2&&(BCe.$$scope={dirty:u,ctx:f}),Kh.$set(BCe);const ICe={};u&2&&(ICe.$$scope={dirty:u,ctx:f}),X_.$set(ICe);const qCe={};u&2&&(qCe.$$scope={dirty:u,ctx:f}),W_.$set(qCe);const F9={};u&2&&(F9.$$scope={dirty:u,ctx:f}),Iu.$set(F9);const NCe={};u&2&&(NCe.$$scope={dirty:u,ctx:f}),Nu.$set(NCe);const T9={};u&2&&(T9.$$scope={dirty:u,ctx:f}),M2.$set(T9);const jCe={};u&2&&(jCe.$$scope={dirty:u,ctx:f}),C2.$set(jCe);const M9={};u&2&&(M9.$$scope={dirty:u,ctx:f}),l1.$set(M9);const DCe={};u&2&&(DCe.$$scope={dirty:u,ctx:f}),d1.$set(DCe);const GCe={};u&2&&(GCe.$$scope={dirty:u,ctx:f}),y1.$set(GCe);const OCe={};u&2&&(OCe.$$scope={dirty:u,ctx:f}),x1.$set(OCe);const ff={};u&2&&(ff.$$scope={dirty:u,ctx:f}),E7.$set(ff);const VCe={};u&2&&(VCe.$$scope={dirty:u,ctx:f}),w7.$set(VCe);const XCe={};u&2&&(XCe.$$scope={dirty:u,ctx:f}),rb.$set(XCe);const zCe={};u&2&&(zCe.$$scope={dirty:u,ctx:f}),ab.$set(zCe);const E9={};u&2&&(E9.$$scope={dirty:u,ctx:f}),fb.$set(E9);const WCe={};u&2&&(WCe.$$scope={dirty:u,ctx:f}),gb.$set(WCe);const QCe={};u&2&&(QCe.$$scope={dirty:u,ctx:f}),Hb.$set(QCe);const HCe={};u&2&&(HCe.$$scope={dirty:u,ctx:f}),Jb.$set(HCe);const et={};u&2&&(et.$$scope={dirty:u,ctx:f}),qv.$set(et);const C9={};u&2&&(C9.$$scope={dirty:u,ctx:f}),jv.$set(C9);const UCe={};u&2&&(UCe.$$scope={dirty:u,ctx:f}),Ov.$set(UCe);const w9={};u&2&&(w9.$$scope={dirty:u,ctx:f}),Xv.$set(w9);const JCe={};u&2&&(JCe.$$scope={dirty:u,ctx:f}),tF.$set(JCe);const ot={};u&2&&(ot.$$scope={dirty:u,ctx:f}),nF.$set(ot);const YCe={};u&2&&(YCe.$$scope={dirty:u,ctx:f}),iF.$set(YCe);const mf={};u&2&&(mf.$$scope={dirty:u,ctx:f}),cF.$set(mf);const KCe={};u&2&&(KCe.$$scope={dirty:u,ctx:f}),TF.$set(KCe);const ZCe={};u&2&&(ZCe.$$scope={dirty:u,ctx:f}),EF.$set(ZCe);const y={};u&2&&(y.$$scope={dirty:u,ctx:f}),$F.$set(y);const Ww={};u&2&&(Ww.$$scope={dirty:u,ctx:f}),SF.$set(Ww);const e5e={};u&2&&(e5e.$$scope={dirty:u,ctx:f}),VF.$set(e5e);const o5e={};u&2&&(o5e.$$scope={dirty:u,ctx:f}),zF.$set(o5e);const Qw={};u&2&&(Qw.$$scope={dirty:u,ctx:f}),UF.$set(Qw);const r5e={};u&2&&(r5e.$$scope={dirty:u,ctx:f}),YF.$set(r5e);const t5e={};u&2&&(t5e.$$scope={dirty:u,ctx:f}),aT.$set(t5e);const Hw={};u&2&&(Hw.$$scope={dirty:u,ctx:f}),sT.$set(Hw);const a5e={};u&2&&(a5e.$$scope={dirty:u,ctx:f}),fT.$set(a5e);const n5e={};u&2&&(n5e.$$scope={dirty:u,ctx:f}),gT.$set(n5e);const Uw={};u&2&&(Uw.$$scope={dirty:u,ctx:f}),uT.$set(Uw);const s5e={};u&2&&(s5e.$$scope={dirty:u,ctx:f}),vT.$set(s5e);const l5e={};u&2&&(l5e.$$scope={dirty:u,ctx:f}),MT.$set(l5e);const Jw={};u&2&&(Jw.$$scope={dirty:u,ctx:f}),CT.$set(Jw);const i5e={};u&2&&(i5e.$$scope={dirty:u,ctx:f}),$T.$set(i5e);const d5e={};u&2&&(d5e.$$scope={dirty:u,ctx:f}),ST.$set(d5e);const Yw={};u&2&&(Yw.$$scope={dirty:u,ctx:f}),BT.$set(Yw);const c5e={};u&2&&(c5e.$$scope={dirty:u,ctx:f}),qT.$set(c5e);const f5e={};u&2&&(f5e.$$scope={dirty:u,ctx:f}),$M.$set(f5e);const Kw={};u&2&&(Kw.$$scope={dirty:u,ctx:f}),SM.$set(Kw);const m5e={};u&2&&(m5e.$$scope={dirty:u,ctx:f}),r4.$set(m5e);const g5e={};u&2&&(g5e.$$scope={dirty:u,ctx:f}),a4.$set(g5e);const Zw={};u&2&&(Zw.$$scope={dirty:u,ctx:f}),u4.$set(Zw);const h5e={};u&2&&(h5e.$$scope={dirty:u,ctx:f}),v4.$set(h5e);const p5e={};u&2&&(p5e.$$scope={dirty:u,ctx:f}),C4.$set(p5e);const e0={};u&2&&(e0.$$scope={dirty:u,ctx:f}),A4.$set(e0);const _5e={};u&2&&(_5e.$$scope={dirty:u,ctx:f}),Q4.$set(_5e);const u5e={};u&2&&(u5e.$$scope={dirty:u,ctx:f}),U4.$set(u5e);const o0={};u&2&&(o0.$$scope={dirty:u,ctx:f}),sE.$set(o0);const b5e={};u&2&&(b5e.$$scope={dirty:u,ctx:f}),iE.$set(b5e);const v5e={};u&2&&(v5e.$$scope={dirty:u,ctx:f}),BE.$set(v5e);const r0={};u&2&&(r0.$$scope={dirty:u,ctx:f}),qE.$set(r0);const F5e={};u&2&&(F5e.$$scope={dirty:u,ctx:f}),oC.$set(F5e);const T5e={};u&2&&(T5e.$$scope={dirty:u,ctx:f}),tC.$set(T5e);const t0={};u&2&&(t0.$$scope={dirty:u,ctx:f}),sC.$set(t0);const M5e={};u&2&&(M5e.$$scope={dirty:u,ctx:f}),iC.$set(M5e);const E5e={};u&2&&(E5e.$$scope={dirty:u,ctx:f}),cC.$set(E5e);const a0={};u&2&&(a0.$$scope={dirty:u,ctx:f}),mC.$set(a0);const C5e={};u&2&&(C5e.$$scope={dirty:u,ctx:f}),RC.$set(C5e);const w5e={};u&2&&(w5e.$$scope={dirty:u,ctx:f}),BC.$set(w5e);const n0={};u&2&&(n0.$$scope={dirty:u,ctx:f}),r5.$set(n0);const A5e={};u&2&&(A5e.$$scope={dirty:u,ctx:f}),a5.$set(A5e);const y5e={};u&2&&(y5e.$$scope={dirty:u,ctx:f}),s5.$set(y5e);const s0={};u&2&&(s0.$$scope={dirty:u,ctx:f}),i5.$set(s0);const L5e={};u&2&&(L5e.$$scope={dirty:u,ctx:f}),c5.$set(L5e);const x5e={};u&2&&(x5e.$$scope={dirty:u,ctx:f}),m5.$set(x5e);const l0={};u&2&&(l0.$$scope={dirty:u,ctx:f}),j5.$set(l0);const $5e={};u&2&&($5e.$$scope={dirty:u,ctx:f}),G5.$set($5e);const k5e={};u&2&&(k5e.$$scope={dirty:u,ctx:f}),K5.$set(k5e);const i0={};u&2&&(i0.$$scope={dirty:u,ctx:f}),e3.$set(i0);const S5e={};u&2&&(S5e.$$scope={dirty:u,ctx:f}),g3.$set(S5e);const R5e={};u&2&&(R5e.$$scope={dirty:u,ctx:f}),p3.$set(R5e);const d0={};u&2&&(d0.$$scope={dirty:u,ctx:f}),A3.$set(d0);const P5e={};u&2&&(P5e.$$scope={dirty:u,ctx:f}),L3.$set(P5e);const B5e={};u&2&&(B5e.$$scope={dirty:u,ctx:f}),N3.$set(B5e);const c0={};u&2&&(c0.$$scope={dirty:u,ctx:f}),D3.$set(c0);const I5e={};u&2&&(I5e.$$scope={dirty:u,ctx:f}),Y3.$set(I5e);const q5e={};u&2&&(q5e.$$scope={dirty:u,ctx:f}),Z3.$set(q5e);const f0={};u&2&&(f0.$$scope={dirty:u,ctx:f}),cw.$set(f0);const N5e={};u&2&&(N5e.$$scope={dirty:u,ctx:f}),mw.$set(N5e);const j5e={};u&2&&(j5e.$$scope={dirty:u,ctx:f}),Tw.$set(j5e);const m0={};u&2&&(m0.$$scope={dirty:u,ctx:f}),Ew.$set(m0);const D5e={};u&2&&(D5e.$$scope={dirty:u,ctx:f}),Sw.$set(D5e);const G5e={};u&2&&(G5e.$$scope={dirty:u,ctx:f}),Pw.$set(G5e);const g0={};u&2&&(g0.$$scope={dirty:u,ctx:f}),Iw.$set(g0);const O5e={};u&2&&(O5e.$$scope={dirty:u,ctx:f}),Nw.$set(O5e);const V5e={};u&2&&(V5e.$$scope={dirty:u,ctx:f}),Gw.$set(V5e);const h0={};u&2&&(h0.$$scope={dirty:u,ctx:f}),Vw.$set(h0);const X5e={};u&2&&(X5e.$$scope={dirty:u,ctx:f}),zw.$set(X5e)},i(f){KNe||(E(d.$$.fragment,f),E(Ca.$$.fragment,f),E(g6.$$.fragment,f),E(h6.$$.fragment,f),E(vf.$$.fragment,f),E(p6.$$.fragment,f),E(_6.$$.fragment,f),E(v6.$$.fragment,f),E(vg.$$.fragment,f),E(F6.$$.fragment,f),E(T6.$$.fragment,f),E(M6.$$.fragment,f),E(w6.$$.fragment,f),E(Zg.$$.fragment,f),E(A6.$$.fragment,f),E(y6.$$.fragment,f),E(L6.$$.fragment,f),E(k6.$$.fragment,f),E(Lh.$$.fragment,f),E(xh.$$.fragment,f),E(S6.$$.fragment,f),E(R6.$$.fragment,f),E(P6.$$.fragment,f),E(q6.$$.fragment,f),E(Hh.$$.fragment,f),E(Uh.$$.fragment,f),E(N6.$$.fragment,f),E(j6.$$.fragment,f),E(D6.$$.fragment,f),E(O6.$$.fragment,f),E(Kh.$$.fragment,f),E(V6.$$.fragment,f),E(X_.$$.fragment,f),E(X6.$$.fragment,f),E(z6.$$.fragment,f),E(Q6.$$.fragment,f),E(W_.$$.fragment,f),E(H6.$$.fragment,f),E(Iu.$$.fragment,f),E(U6.$$.fragment,f),E(J6.$$.fragment,f),E(K6.$$.fragment,f),E(Nu.$$.fragment,f),E(Z6.$$.fragment,f),E(M2.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ty.$$.fragment,f),E(C2.$$.fragment,f),E(ay.$$.fragment,f),E(l1.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(iy.$$.fragment,f),E(d1.$$.fragment,f),E(dy.$$.fragment,f),E(y1.$$.fragment,f),E(cy.$$.fragment,f),E(fy.$$.fragment,f),E(gy.$$.fragment,f),E(x1.$$.fragment,f),E(hy.$$.fragment,f),E(E7.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(by.$$.fragment,f),E(w7.$$.fragment,f),E(vy.$$.fragment,f),E(rb.$$.fragment,f),E(Fy.$$.fragment,f),E(Ty.$$.fragment,f),E(Ey.$$.fragment,f),E(ab.$$.fragment,f),E(Cy.$$.fragment,f),E(fb.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(Ly.$$.fragment,f),E(gb.$$.fragment,f),E(xy.$$.fragment,f),E(Hb.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(Jb.$$.fragment,f),E(Py.$$.fragment,f),E(qv.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(Ny.$$.fragment,f),E(jv.$$.fragment,f),E(jy.$$.fragment,f),E(Ov.$$.fragment,f),E(Dy.$$.fragment,f),E(Gy.$$.fragment,f),E(Vy.$$.fragment,f),E(Xv.$$.fragment,f),E(Xy.$$.fragment,f),E(tF.$$.fragment,f),E(zy.$$.fragment,f),E(Wy.$$.fragment,f),E(Hy.$$.fragment,f),E(nF.$$.fragment,f),E(Uy.$$.fragment,f),E(iF.$$.fragment,f),E(Jy.$$.fragment,f),E(Yy.$$.fragment,f),E(Zy.$$.fragment,f),E(cF.$$.fragment,f),E(eL.$$.fragment,f),E(TF.$$.fragment,f),E(oL.$$.fragment,f),E(rL.$$.fragment,f),E(aL.$$.fragment,f),E(EF.$$.fragment,f),E(nL.$$.fragment,f),E($F.$$.fragment,f),E(sL.$$.fragment,f),E(lL.$$.fragment,f),E(dL.$$.fragment,f),E(SF.$$.fragment,f),E(cL.$$.fragment,f),E(VF.$$.fragment,f),E(fL.$$.fragment,f),E(mL.$$.fragment,f),E(hL.$$.fragment,f),E(zF.$$.fragment,f),E(pL.$$.fragment,f),E(UF.$$.fragment,f),E(uL.$$.fragment,f),E(bL.$$.fragment,f),E(FL.$$.fragment,f),E(YF.$$.fragment,f),E(TL.$$.fragment,f),E(aT.$$.fragment,f),E(ML.$$.fragment,f),E(EL.$$.fragment,f),E(wL.$$.fragment,f),E(sT.$$.fragment,f),E(AL.$$.fragment,f),E(fT.$$.fragment,f),E(yL.$$.fragment,f),E(LL.$$.fragment,f),E($L.$$.fragment,f),E(gT.$$.fragment,f),E(kL.$$.fragment,f),E(uT.$$.fragment,f),E(RL.$$.fragment,f),E(PL.$$.fragment,f),E(IL.$$.fragment,f),E(vT.$$.fragment,f),E(qL.$$.fragment,f),E(MT.$$.fragment,f),E(NL.$$.fragment,f),E(jL.$$.fragment,f),E(GL.$$.fragment,f),E(CT.$$.fragment,f),E(OL.$$.fragment,f),E($T.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(WL.$$.fragment,f),E(ST.$$.fragment,f),E(QL.$$.fragment,f),E(BT.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(YL.$$.fragment,f),E(qT.$$.fragment,f),E(KL.$$.fragment,f),E($M.$$.fragment,f),E(ZL.$$.fragment,f),E(e8.$$.fragment,f),E(r8.$$.fragment,f),E(SM.$$.fragment,f),E(t8.$$.fragment,f),E(r4.$$.fragment,f),E(a8.$$.fragment,f),E(n8.$$.fragment,f),E(l8.$$.fragment,f),E(a4.$$.fragment,f),E(i8.$$.fragment,f),E(u4.$$.fragment,f),E(d8.$$.fragment,f),E(c8.$$.fragment,f),E(m8.$$.fragment,f),E(v4.$$.fragment,f),E(g8.$$.fragment,f),E(C4.$$.fragment,f),E(h8.$$.fragment,f),E(p8.$$.fragment,f),E(u8.$$.fragment,f),E(A4.$$.fragment,f),E(b8.$$.fragment,f),E(Q4.$$.fragment,f),E(v8.$$.fragment,f),E(F8.$$.fragment,f),E(M8.$$.fragment,f),E(U4.$$.fragment,f),E(E8.$$.fragment,f),E(sE.$$.fragment,f),E(C8.$$.fragment,f),E(w8.$$.fragment,f),E(y8.$$.fragment,f),E(iE.$$.fragment,f),E(L8.$$.fragment,f),E(BE.$$.fragment,f),E(x8.$$.fragment,f),E($8.$$.fragment,f),E(S8.$$.fragment,f),E(qE.$$.fragment,f),E(R8.$$.fragment,f),E(oC.$$.fragment,f),E(P8.$$.fragment,f),E(B8.$$.fragment,f),E(q8.$$.fragment,f),E(tC.$$.fragment,f),E(N8.$$.fragment,f),E(sC.$$.fragment,f),E(D8.$$.fragment,f),E(G8.$$.fragment,f),E(V8.$$.fragment,f),E(iC.$$.fragment,f),E(X8.$$.fragment,f),E(cC.$$.fragment,f),E(z8.$$.fragment,f),E(W8.$$.fragment,f),E(H8.$$.fragment,f),E(mC.$$.fragment,f),E(U8.$$.fragment,f),E(RC.$$.fragment,f),E(J8.$$.fragment,f),E(Y8.$$.fragment,f),E(Z8.$$.fragment,f),E(BC.$$.fragment,f),E(ex.$$.fragment,f),E(r5.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(a5.$$.fragment,f),E(nx.$$.fragment,f),E(s5.$$.fragment,f),E(sx.$$.fragment,f),E(lx.$$.fragment,f),E(dx.$$.fragment,f),E(i5.$$.fragment,f),E(cx.$$.fragment,f),E(c5.$$.fragment,f),E(fx.$$.fragment,f),E(mx.$$.fragment,f),E(hx.$$.fragment,f),E(m5.$$.fragment,f),E(px.$$.fragment,f),E(j5.$$.fragment,f),E(_x.$$.fragment,f),E(ux.$$.fragment,f),E(vx.$$.fragment,f),E(G5.$$.fragment,f),E(Fx.$$.fragment,f),E(K5.$$.fragment,f),E(Tx.$$.fragment,f),E(Mx.$$.fragment,f),E(Cx.$$.fragment,f),E(e3.$$.fragment,f),E(wx.$$.fragment,f),E(g3.$$.fragment,f),E(Ax.$$.fragment,f),E(yx.$$.fragment,f),E(xx.$$.fragment,f),E(p3.$$.fragment,f),E($x.$$.fragment,f),E(A3.$$.fragment,f),E(kx.$$.fragment,f),E(Sx.$$.fragment,f),E(Px.$$.fragment,f),E(L3.$$.fragment,f),E(Bx.$$.fragment,f),E(N3.$$.fragment,f),E(Ix.$$.fragment,f),E(qx.$$.fragment,f),E(jx.$$.fragment,f),E(D3.$$.fragment,f),E(Dx.$$.fragment,f),E(Y3.$$.fragment,f),E(Gx.$$.fragment,f),E(Ox.$$.fragment,f),E(Xx.$$.fragment,f),E(Z3.$$.fragment,f),E(zx.$$.fragment,f),E(cw.$$.fragment,f),E(Wx.$$.fragment,f),E(Qx.$$.fragment,f),E(Ux.$$.fragment,f),E(mw.$$.fragment,f),E(Jx.$$.fragment,f),E(Tw.$$.fragment,f),E(Yx.$$.fragment,f),E(Kx.$$.fragment,f),E(e9.$$.fragment,f),E(Ew.$$.fragment,f),E(o9.$$.fragment,f),E(Sw.$$.fragment,f),E(r9.$$.fragment,f),E(t9.$$.fragment,f),E(n9.$$.fragment,f),E(Pw.$$.fragment,f),E(s9.$$.fragment,f),E(Iw.$$.fragment,f),E(l9.$$.fragment,f),E(i9.$$.fragment,f),E(c9.$$.fragment,f),E(Nw.$$.fragment,f),E(f9.$$.fragment,f),E(Gw.$$.fragment,f),E(g9.$$.fragment,f),E(h9.$$.fragment,f),E(_9.$$.fragment,f),E(Vw.$$.fragment,f),E(u9.$$.fragment,f),E(zw.$$.fragment,f),KNe=!0)},o(f){C(d.$$.fragment,f),C(Ca.$$.fragment,f),C(g6.$$.fragment,f),C(h6.$$.fragment,f),C(vf.$$.fragment,f),C(p6.$$.fragment,f),C(_6.$$.fragment,f),C(v6.$$.fragment,f),C(vg.$$.fragment,f),C(F6.$$.fragment,f),C(T6.$$.fragment,f),C(M6.$$.fragment,f),C(w6.$$.fragment,f),C(Zg.$$.fragment,f),C(A6.$$.fragment,f),C(y6.$$.fragment,f),C(L6.$$.fragment,f),C(k6.$$.fragment,f),C(Lh.$$.fragment,f),C(xh.$$.fragment,f),C(S6.$$.fragment,f),C(R6.$$.fragment,f),C(P6.$$.fragment,f),C(q6.$$.fragment,f),C(Hh.$$.fragment,f),C(Uh.$$.fragment,f),C(N6.$$.fragment,f),C(j6.$$.fragment,f),C(D6.$$.fragment,f),C(O6.$$.fragment,f),C(Kh.$$.fragment,f),C(V6.$$.fragment,f),C(X_.$$.fragment,f),C(X6.$$.fragment,f),C(z6.$$.fragment,f),C(Q6.$$.fragment,f),C(W_.$$.fragment,f),C(H6.$$.fragment,f),C(Iu.$$.fragment,f),C(U6.$$.fragment,f),C(J6.$$.fragment,f),C(K6.$$.fragment,f),C(Nu.$$.fragment,f),C(Z6.$$.fragment,f),C(M2.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ty.$$.fragment,f),C(C2.$$.fragment,f),C(ay.$$.fragment,f),C(l1.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(iy.$$.fragment,f),C(d1.$$.fragment,f),C(dy.$$.fragment,f),C(y1.$$.fragment,f),C(cy.$$.fragment,f),C(fy.$$.fragment,f),C(gy.$$.fragment,f),C(x1.$$.fragment,f),C(hy.$$.fragment,f),C(E7.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(by.$$.fragment,f),C(w7.$$.fragment,f),C(vy.$$.fragment,f),C(rb.$$.fragment,f),C(Fy.$$.fragment,f),C(Ty.$$.fragment,f),C(Ey.$$.fragment,f),C(ab.$$.fragment,f),C(Cy.$$.fragment,f),C(fb.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(Ly.$$.fragment,f),C(gb.$$.fragment,f),C(xy.$$.fragment,f),C(Hb.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(Jb.$$.fragment,f),C(Py.$$.fragment,f),C(qv.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(Ny.$$.fragment,f),C(jv.$$.fragment,f),C(jy.$$.fragment,f),C(Ov.$$.fragment,f),C(Dy.$$.fragment,f),C(Gy.$$.fragment,f),C(Vy.$$.fragment,f),C(Xv.$$.fragment,f),C(Xy.$$.fragment,f),C(tF.$$.fragment,f),C(zy.$$.fragment,f),C(Wy.$$.fragment,f),C(Hy.$$.fragment,f),C(nF.$$.fragment,f),C(Uy.$$.fragment,f),C(iF.$$.fragment,f),C(Jy.$$.fragment,f),C(Yy.$$.fragment,f),C(Zy.$$.fragment,f),C(cF.$$.fragment,f),C(eL.$$.fragment,f),C(TF.$$.fragment,f),C(oL.$$.fragment,f),C(rL.$$.fragment,f),C(aL.$$.fragment,f),C(EF.$$.fragment,f),C(nL.$$.fragment,f),C($F.$$.fragment,f),C(sL.$$.fragment,f),C(lL.$$.fragment,f),C(dL.$$.fragment,f),C(SF.$$.fragment,f),C(cL.$$.fragment,f),C(VF.$$.fragment,f),C(fL.$$.fragment,f),C(mL.$$.fragment,f),C(hL.$$.fragment,f),C(zF.$$.fragment,f),C(pL.$$.fragment,f),C(UF.$$.fragment,f),C(uL.$$.fragment,f),C(bL.$$.fragment,f),C(FL.$$.fragment,f),C(YF.$$.fragment,f),C(TL.$$.fragment,f),C(aT.$$.fragment,f),C(ML.$$.fragment,f),C(EL.$$.fragment,f),C(wL.$$.fragment,f),C(sT.$$.fragment,f),C(AL.$$.fragment,f),C(fT.$$.fragment,f),C(yL.$$.fragment,f),C(LL.$$.fragment,f),C($L.$$.fragment,f),C(gT.$$.fragment,f),C(kL.$$.fragment,f),C(uT.$$.fragment,f),C(RL.$$.fragment,f),C(PL.$$.fragment,f),C(IL.$$.fragment,f),C(vT.$$.fragment,f),C(qL.$$.fragment,f),C(MT.$$.fragment,f),C(NL.$$.fragment,f),C(jL.$$.fragment,f),C(GL.$$.fragment,f),C(CT.$$.fragment,f),C(OL.$$.fragment,f),C($T.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(WL.$$.fragment,f),C(ST.$$.fragment,f),C(QL.$$.fragment,f),C(BT.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(YL.$$.fragment,f),C(qT.$$.fragment,f),C(KL.$$.fragment,f),C($M.$$.fragment,f),C(ZL.$$.fragment,f),C(e8.$$.fragment,f),C(r8.$$.fragment,f),C(SM.$$.fragment,f),C(t8.$$.fragment,f),C(r4.$$.fragment,f),C(a8.$$.fragment,f),C(n8.$$.fragment,f),C(l8.$$.fragment,f),C(a4.$$.fragment,f),C(i8.$$.fragment,f),C(u4.$$.fragment,f),C(d8.$$.fragment,f),C(c8.$$.fragment,f),C(m8.$$.fragment,f),C(v4.$$.fragment,f),C(g8.$$.fragment,f),C(C4.$$.fragment,f),C(h8.$$.fragment,f),C(p8.$$.fragment,f),C(u8.$$.fragment,f),C(A4.$$.fragment,f),C(b8.$$.fragment,f),C(Q4.$$.fragment,f),C(v8.$$.fragment,f),C(F8.$$.fragment,f),C(M8.$$.fragment,f),C(U4.$$.fragment,f),C(E8.$$.fragment,f),C(sE.$$.fragment,f),C(C8.$$.fragment,f),C(w8.$$.fragment,f),C(y8.$$.fragment,f),C(iE.$$.fragment,f),C(L8.$$.fragment,f),C(BE.$$.fragment,f),C(x8.$$.fragment,f),C($8.$$.fragment,f),C(S8.$$.fragment,f),C(qE.$$.fragment,f),C(R8.$$.fragment,f),C(oC.$$.fragment,f),C(P8.$$.fragment,f),C(B8.$$.fragment,f),C(q8.$$.fragment,f),C(tC.$$.fragment,f),C(N8.$$.fragment,f),C(sC.$$.fragment,f),C(D8.$$.fragment,f),C(G8.$$.fragment,f),C(V8.$$.fragment,f),C(iC.$$.fragment,f),C(X8.$$.fragment,f),C(cC.$$.fragment,f),C(z8.$$.fragment,f),C(W8.$$.fragment,f),C(H8.$$.fragment,f),C(mC.$$.fragment,f),C(U8.$$.fragment,f),C(RC.$$.fragment,f),C(J8.$$.fragment,f),C(Y8.$$.fragment,f),C(Z8.$$.fragment,f),C(BC.$$.fragment,f),C(ex.$$.fragment,f),C(r5.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(a5.$$.fragment,f),C(nx.$$.fragment,f),C(s5.$$.fragment,f),C(sx.$$.fragment,f),C(lx.$$.fragment,f),C(dx.$$.fragment,f),C(i5.$$.fragment,f),C(cx.$$.fragment,f),C(c5.$$.fragment,f),C(fx.$$.fragment,f),C(mx.$$.fragment,f),C(hx.$$.fragment,f),C(m5.$$.fragment,f),C(px.$$.fragment,f),C(j5.$$.fragment,f),C(_x.$$.fragment,f),C(ux.$$.fragment,f),C(vx.$$.fragment,f),C(G5.$$.fragment,f),C(Fx.$$.fragment,f),C(K5.$$.fragment,f),C(Tx.$$.fragment,f),C(Mx.$$.fragment,f),C(Cx.$$.fragment,f),C(e3.$$.fragment,f),C(wx.$$.fragment,f),C(g3.$$.fragment,f),C(Ax.$$.fragment,f),C(yx.$$.fragment,f),C(xx.$$.fragment,f),C(p3.$$.fragment,f),C($x.$$.fragment,f),C(A3.$$.fragment,f),C(kx.$$.fragment,f),C(Sx.$$.fragment,f),C(Px.$$.fragment,f),C(L3.$$.fragment,f),C(Bx.$$.fragment,f),C(N3.$$.fragment,f),C(Ix.$$.fragment,f),C(qx.$$.fragment,f),C(jx.$$.fragment,f),C(D3.$$.fragment,f),C(Dx.$$.fragment,f),C(Y3.$$.fragment,f),C(Gx.$$.fragment,f),C(Ox.$$.fragment,f),C(Xx.$$.fragment,f),C(Z3.$$.fragment,f),C(zx.$$.fragment,f),C(cw.$$.fragment,f),C(Wx.$$.fragment,f),C(Qx.$$.fragment,f),C(Ux.$$.fragment,f),C(mw.$$.fragment,f),C(Jx.$$.fragment,f),C(Tw.$$.fragment,f),C(Yx.$$.fragment,f),C(Kx.$$.fragment,f),C(e9.$$.fragment,f),C(Ew.$$.fragment,f),C(o9.$$.fragment,f),C(Sw.$$.fragment,f),C(r9.$$.fragment,f),C(t9.$$.fragment,f),C(n9.$$.fragment,f),C(Pw.$$.fragment,f),C(s9.$$.fragment,f),C(Iw.$$.fragment,f),C(l9.$$.fragment,f),C(i9.$$.fragment,f),C(c9.$$.fragment,f),C(Nw.$$.fragment,f),C(f9.$$.fragment,f),C(Gw.$$.fragment,f),C(g9.$$.fragment,f),C(h9.$$.fragment,f),C(_9.$$.fragment,f),C(Vw.$$.fragment,f),C(u9.$$.fragment,f),C(zw.$$.fragment,f),KNe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(hf),f&&t(rt),f&&t(De),f&&t(We),f&&t(_f),w(Ca,f),f&&t(Qe),f&&t(Ae),f&&t(Eo),f&&t(wa),f&&t(UIe),f&&t(ui),w(g6),f&&t(JIe),f&&t(kn),f&&t(YIe),w(h6,f),f&&t(KIe),f&&t(B$),f&&t(ZIe),w(vf,f),f&&t(eqe),f&&t(bi),w(p6),f&&t(oqe),f&&t(Co),w(_6),w(v6),w(vg),w(F6),f&&t(rqe),f&&t(Fi),w(T6),f&&t(tqe),f&&t(wo),w(M6),w(w6),w(Zg),w(A6),f&&t(aqe),f&&t(Ti),w(y6),f&&t(nqe),f&&t(Ao),w(L6),w(k6),w(Lh),w(xh),w(S6),f&&t(sqe),f&&t(Mi),w(R6),f&&t(lqe),f&&t(yo),w(P6),w(q6),w(Hh),w(Uh),w(N6),f&&t(iqe),f&&t(Ci),w(j6),f&&t(dqe),f&&t(Lo),w(D6),w(O6),w(Kh),w(V6),w(X_),f&&t(cqe),f&&t(yi),w(X6),f&&t(fqe),f&&t(xo),w(z6),w(Q6),w(W_),w(H6),w(Iu),f&&t(mqe),f&&t($i),w(U6),f&&t(gqe),f&&t($o),w(J6),w(K6),w(Nu),w(Z6),w(M2),f&&t(hqe),f&&t(Ri),w(ey),f&&t(pqe),f&&t(ko),w(oy),w(ty),w(C2),w(ay),w(l1),f&&t(_qe),f&&t(Ii),w(ny),f&&t(uqe),f&&t(So),w(sy),w(iy),w(d1),w(dy),w(y1),f&&t(bqe),f&&t(ji),w(cy),f&&t(vqe),f&&t(Ro),w(fy),w(gy),w(x1),w(hy),w(E7),f&&t(Fqe),f&&t(Oi),w(py),f&&t(Tqe),f&&t(Po),w(_y),w(by),w(w7),w(vy),w(rb),f&&t(Mqe),f&&t(zi),w(Fy),f&&t(Eqe),f&&t(Bo),w(Ty),w(Ey),w(ab),w(Cy),w(fb),f&&t(Cqe),f&&t(Hi),w(wy),f&&t(wqe),f&&t(Io),w(Ay),w(Ly),w(gb),w(xy),w(Hb),f&&t(Aqe),f&&t(Yi),w($y),f&&t(yqe),f&&t(qo),w(ky),w(Ry),w(Jb),w(Py),w(qv),f&&t(Lqe),f&&t(ed),w(By),f&&t(xqe),f&&t(No),w(Iy),w(Ny),w(jv),w(jy),w(Ov),f&&t($qe),f&&t(td),w(Dy),f&&t(kqe),f&&t(jo),w(Gy),w(Vy),w(Xv),w(Xy),w(tF),f&&t(Sqe),f&&t(sd),w(zy),f&&t(Rqe),f&&t(Do),w(Wy),w(Hy),w(nF),w(Uy),w(iF),f&&t(Pqe),f&&t(dd),w(Jy),f&&t(Bqe),f&&t(Go),w(Yy),w(Zy),w(cF),w(eL),w(TF),f&&t(Iqe),f&&t(md),w(oL),f&&t(qqe),f&&t(Oo),w(rL),w(aL),w(EF),w(nL),w($F),f&&t(Nqe),f&&t(pd),w(sL),f&&t(jqe),f&&t(Vo),w(lL),w(dL),w(SF),w(cL),w(VF),f&&t(Dqe),f&&t(bd),w(fL),f&&t(Gqe),f&&t(Xo),w(mL),w(hL),w(zF),w(pL),w(UF),f&&t(Oqe),f&&t(Td),w(uL),f&&t(Vqe),f&&t(zo),w(bL),w(FL),w(YF),w(TL),w(aT),f&&t(Xqe),f&&t(Cd),w(ML),f&&t(zqe),f&&t(Wo),w(EL),w(wL),w(sT),w(AL),w(fT),f&&t(Wqe),f&&t(Ld),w(yL),f&&t(Qqe),f&&t(Qo),w(LL),w($L),w(gT),w(kL),w(uT),f&&t(Hqe),f&&t(kd),w(RL),f&&t(Uqe),f&&t(Ho),w(PL),w(IL),w(vT),w(qL),w(MT),f&&t(Jqe),f&&t(Pd),w(NL),f&&t(Yqe),f&&t(Uo),w(jL),w(GL),w(CT),w(OL),w($T),f&&t(Kqe),f&&t(qd),w(VL),f&&t(Zqe),f&&t(Jo),w(XL),w(WL),w(ST),w(QL),w(BT),f&&t(eNe),f&&t(Dd),w(HL),f&&t(oNe),f&&t(Yo),w(UL),w(YL),w(qT),w(KL),w($M),f&&t(rNe),f&&t(Vd),w(ZL),f&&t(tNe),f&&t(Ko),w(e8),w(r8),w(SM),w(t8),w(r4),f&&t(aNe),f&&t(Wd),w(a8),f&&t(nNe),f&&t(Zo),w(n8),w(l8),w(a4),w(i8),w(u4),f&&t(sNe),f&&t(Ud),w(d8),f&&t(lNe),f&&t(er),w(c8),w(m8),w(v4),w(g8),w(C4),f&&t(iNe),f&&t(Kd),w(h8),f&&t(dNe),f&&t(or),w(p8),w(u8),w(A4),w(b8),w(Q4),f&&t(cNe),f&&t(oc),w(v8),f&&t(fNe),f&&t(rr),w(F8),w(M8),w(U4),w(E8),w(sE),f&&t(mNe),f&&t(ac),w(C8),f&&t(gNe),f&&t(tr),w(w8),w(y8),w(iE),w(L8),w(BE),f&&t(hNe),f&&t(lc),w(x8),f&&t(pNe),f&&t(ar),w($8),w(S8),w(qE),w(R8),w(oC),f&&t(_Ne),f&&t(cc),w(P8),f&&t(uNe),f&&t(nr),w(B8),w(q8),w(tC),w(N8),w(sC),f&&t(bNe),f&&t(gc),w(D8),f&&t(vNe),f&&t(sr),w(G8),w(V8),w(iC),w(X8),w(cC),f&&t(FNe),f&&t(_c),w(z8),f&&t(TNe),f&&t(lr),w(W8),w(H8),w(mC),w(U8),w(RC),f&&t(MNe),f&&t(vc),w(J8),f&&t(ENe),f&&t(ir),w(Y8),w(Z8),w(BC),w(ex),w(r5),f&&t(CNe),f&&t(Mc),w(ox),f&&t(wNe),f&&t(dr),w(rx),w(ax),w(a5),w(nx),w(s5),f&&t(ANe),f&&t(wc),w(sx),f&&t(yNe),f&&t(cr),w(lx),w(dx),w(i5),w(cx),w(c5),f&&t(LNe),f&&t(Lc),w(fx),f&&t(xNe),f&&t(fr),w(mx),w(hx),w(m5),w(px),w(j5),f&&t($Ne),f&&t(kc),w(_x),f&&t(kNe),f&&t(mr),w(ux),w(vx),w(G5),w(Fx),w(K5),f&&t(SNe),f&&t(Pc),w(Tx),f&&t(RNe),f&&t(gr),w(Mx),w(Cx),w(e3),w(wx),w(g3),f&&t(PNe),f&&t(qc),w(Ax),f&&t(BNe),f&&t(hr),w(yx),w(xx),w(p3),w($x),w(A3),f&&t(INe),f&&t(Dc),w(kx),f&&t(qNe),f&&t(pr),w(Sx),w(Px),w(L3),w(Bx),w(N3),f&&t(NNe),f&&t(Vc),w(Ix),f&&t(jNe),f&&t(_r),w(qx),w(jx),w(D3),w(Dx),w(Y3),f&&t(DNe),f&&t(Wc),w(Gx),f&&t(GNe),f&&t(ur),w(Ox),w(Xx),w(Z3),w(zx),w(cw),f&&t(ONe),f&&t(Uc),w(Wx),f&&t(VNe),f&&t(br),w(Qx),w(Ux),w(mw),w(Jx),w(Tw),f&&t(XNe),f&&t(Kc),w(Yx),f&&t(zNe),f&&t(vr),w(Kx),w(e9),w(Ew),w(o9),w(Sw),f&&t(WNe),f&&t(of),w(r9),f&&t(QNe),f&&t(Fr),w(t9),w(n9),w(Pw),w(s9),w(Iw),f&&t(HNe),f&&t(af),w(l9),f&&t(UNe),f&&t(Tr),w(i9),w(c9),w(Nw),w(f9),w(Gw),f&&t(JNe),f&&t(lf),w(g9),f&&t(YNe),f&&t(Mr),w(h9),w(_9),w(Vw),w(u9),w(zw)}}}const g9t={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function h9t(L){return h8t(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class T9t extends c8t{constructor(g){super();f8t(this,g,h9t,m9t,m8t,{})}}export{T9t as default,g9t as metadata};
