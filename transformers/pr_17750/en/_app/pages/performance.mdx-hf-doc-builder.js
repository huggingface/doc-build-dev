import{S as Hi,i as Mi,s as Ii,e as a,k as h,w as v,t as p,M as zi,c as i,d as t,m as f,a as o,x as d,h as u,b as s,N as qi,G as r,g as l,y as g,q as w,o as _,B as $,v as Wi}from"../chunks/vendor-hf-doc-builder.js";import{T as Bi}from"../chunks/Tip-hf-doc-builder.js";import{I as P}from"../chunks/IconCopyLink-hf-doc-builder.js";function Ri(yt){let c,I;return{c(){c=a("p"),I=p("Note: Most of the strategies introduced in the single GPU sections (such as mixed precision training or gradient accumulation) are generic and apply to training models in general so make sure to have a look at it before diving into the following sections such as multi-GPU or CPU training.")},l(m){c=i(m,"P",{});var y=o(c);I=u(y,"Note: Most of the strategies introduced in the single GPU sections (such as mixed precision training or gradient accumulation) are generic and apply to training models in general so make sure to have a look at it before diving into the following sections such as multi-GPU or CPU training."),y.forEach(t)},m(m,y){l(m,c,y),r(c,I)},d(m){m&&t(c)}}}function Di(yt){let c,I,m,y,Le,X,gr,Je,wr,Et,ue,_r,bt,ce,me,fa,Ut,ve,$r,kt,E,z,Oe,Y,Pr,je,yr,Gt,de,Er,At,q,St,b,W,Fe,Z,br,Ke,Ur,Ct,ge,kr,Nt,we,_e,Gr,Tt,U,B,Qe,ee,Ar,Ve,Sr,xt,$e,Cr,Ht,Pe,ye,Nr,Mt,k,R,Xe,te,Tr,Ye,xr,It,Ee,be,Hr,zt,G,D,Ze,re,Mr,et,Ir,qt,Ue,ke,tt,zr,Wt,A,L,rt,ae,qr,at,Wr,Bt,Ge,Ae,it,Br,Rt,S,J,ot,ie,Rr,nt,Dr,Dt,Se,Lr,Lt,C,O,st,oe,Jr,lt,Or,Jt,Ce,Ne,jr,Ot,N,j,ht,ne,Fr,ft,Kr,jt,Te,xe,pt,Qr,Ft,T,F,ut,se,Vr,ct,Xr,Kt,He,Me,mt,Yr,Qt,x,K,vt,le,Zr,dt,ea,Vt,Ie,ze,gt,ta,Xt,H,Q,wt,he,ra,_t,aa,Yt,qe,ia,Zt,We,Be,oa,er,M,V,$t,fe,na,Pt,sa,tr,Re,la,rr,De,ha,ar;return X=new P({}),Y=new P({}),q=new Bi({props:{$$slots:{default:[Ri]},$$scope:{ctx:yt}}}),Z=new P({}),ee=new P({}),te=new P({}),re=new P({}),ae=new P({}),ie=new P({}),oe=new P({}),ne=new P({}),se=new P({}),le=new P({}),he=new P({}),fe=new P({}),{c(){c=a("meta"),I=h(),m=a("h1"),y=a("a"),Le=a("span"),v(X.$$.fragment),gr=h(),Je=a("span"),wr=p("Performance and Scalability"),Et=h(),ue=a("p"),_r=p("Training larger and larger transformer models and deploying them to production comes with a range of challenges. During training your model can require more GPU memory than is available or be very slow to train and when you deploy it for inference it can be overwhelmed with the throughput that is required in the production environment. This documentation is designed to help you navigate these challenges and find the best setting for your use-case. We split the guides into training and inference as they come with different challenges and solutions. Then within each of them we have separate guides for different kinds of hardware setting (e.g. single vs. multi-GPU for training or CPU vs. GPU for infrence)."),bt=h(),ce=a("p"),me=a("img"),Ut=h(),ve=a("p"),$r=p("This document serves as an overview and entry point for the methods that could be useful for your scenario."),kt=h(),E=a("h2"),z=a("a"),Oe=a("span"),v(Y.$$.fragment),Pr=h(),je=a("span"),yr=p("Training"),Gt=h(),de=a("p"),Er=p("Training transformer models efficiently requires an accelerator such as a GPU or TPU. The most common case is where you only have a single GPU, but there is also a section about mutli-GPU and CPU training (with more coming soon)."),At=h(),v(q.$$.fragment),St=h(),b=a("h3"),W=a("a"),Fe=a("span"),v(Z.$$.fragment),br=h(),Ke=a("span"),Ur=p("Single GPU"),Ct=h(),ge=a("p"),kr=p("Training large models on a single GPU can be challenging but there are a number of tools and methods that make it feasible. In this section methods such as mixed precision training, gradient accumulation and checkpointing, efficient optimizers, as well as strategies to determine the best batch size are discussed."),Nt=h(),we=a("p"),_e=a("a"),Gr=p("Go to single GPU training section"),Tt=h(),U=a("h3"),B=a("a"),Qe=a("span"),v(ee.$$.fragment),Ar=h(),Ve=a("span"),Sr=p("Multi-GPU"),xt=h(),$e=a("p"),Cr=p("In some cases training on a single GPU is still too slow or won\u2019t fit the large model. Moving to a mutli-GPU setup is the logical step, but training on multiple GPUs at once comes with new decisions: does each GPU have a full copy of the model or is the model itself also distributed? In this section we look at data, tensor, and pipeline parallism."),Ht=h(),Pe=a("p"),ye=a("a"),Nr=p("Go to multi-GPU training section"),Mt=h(),k=a("h3"),R=a("a"),Xe=a("span"),v(te.$$.fragment),Tr=h(),Ye=a("span"),xr=p("CPU"),It=h(),Ee=a("p"),be=a("a"),Hr=p("Go to CPU training section"),zt=h(),G=a("h3"),D=a("a"),Ze=a("span"),v(re.$$.fragment),Mr=h(),et=a("span"),Ir=p("TPU"),qt=h(),Ue=a("p"),ke=a("a"),tt=a("em"),zr=p("Coming soon"),Wt=h(),A=a("h3"),L=a("a"),rt=a("span"),v(ae.$$.fragment),qr=h(),at=a("span"),Wr=p("Specialized Hardware"),Bt=h(),Ge=a("p"),Ae=a("a"),it=a("em"),Br=p("Coming soon"),Rt=h(),S=a("h2"),J=a("a"),ot=a("span"),v(ie.$$.fragment),Rr=h(),nt=a("span"),Dr=p("Inference"),Dt=h(),Se=a("p"),Lr=p("Efficient inference with large models in a production environment can be as challenging as training them. In the following sections we go through the steps to run inference on CPU and single/multi-GPU setups."),Lt=h(),C=a("h3"),O=a("a"),st=a("span"),v(oe.$$.fragment),Jr=h(),lt=a("span"),Or=p("CPU"),Jt=h(),Ce=a("p"),Ne=a("a"),jr=p("Go to CPU inference section"),Ot=h(),N=a("h3"),j=a("a"),ht=a("span"),v(ne.$$.fragment),Fr=h(),ft=a("span"),Kr=p("Single GPU"),jt=h(),Te=a("p"),xe=a("a"),pt=a("em"),Qr=p("Coming soon"),Ft=h(),T=a("h3"),F=a("a"),ut=a("span"),v(se.$$.fragment),Vr=h(),ct=a("span"),Xr=p("Multi-GPU"),Kt=h(),He=a("p"),Me=a("a"),mt=a("em"),Yr=p("Coming soon"),Qt=h(),x=a("h3"),K=a("a"),vt=a("span"),v(le.$$.fragment),Zr=h(),dt=a("span"),ea=p("Specialized Hardware"),Vt=h(),Ie=a("p"),ze=a("a"),gt=a("em"),ta=p("Coming soon"),Xt=h(),H=a("h2"),Q=a("a"),wt=a("span"),v(he.$$.fragment),ra=h(),_t=a("span"),aa=p("Hardware"),Yt=h(),qe=a("p"),ia=p("In the hardware section you can find tips and tricks when building your own deep learning rig."),Zt=h(),We=a("p"),Be=a("a"),oa=p("Go to hardware section"),er=h(),M=a("h2"),V=a("a"),$t=a("span"),v(fe.$$.fragment),na=h(),Pt=a("span"),sa=p("Contribute"),tr=h(),Re=a("p"),la=p("This document is far from being complete and a lot more needs to be added, so if you have additions or corrections to make please don\u2019t hesitate to open a PR or if you aren\u2019t sure start an Issue and we can discuss the details there."),rr=h(),De=a("p"),ha=p("When making contributions that A is better than B, please try to include a reproducible benchmark and/or a link to the source of that information (unless it comes directly from you)."),this.h()},l(e){const n=zi('[data-svelte="svelte-1phssyn"]',document.head);c=i(n,"META",{name:!0,content:!0}),n.forEach(t),I=f(e),m=i(e,"H1",{class:!0});var pe=o(m);y=i(pe,"A",{id:!0,class:!0,href:!0});var pa=o(y);Le=i(pa,"SPAN",{});var ua=o(Le);d(X.$$.fragment,ua),ua.forEach(t),pa.forEach(t),gr=f(pe),Je=i(pe,"SPAN",{});var ca=o(Je);wr=u(ca,"Performance and Scalability"),ca.forEach(t),pe.forEach(t),Et=f(e),ue=i(e,"P",{});var ma=o(ue);_r=u(ma,"Training larger and larger transformer models and deploying them to production comes with a range of challenges. During training your model can require more GPU memory than is available or be very slow to train and when you deploy it for inference it can be overwhelmed with the throughput that is required in the production environment. This documentation is designed to help you navigate these challenges and find the best setting for your use-case. We split the guides into training and inference as they come with different challenges and solutions. Then within each of them we have separate guides for different kinds of hardware setting (e.g. single vs. multi-GPU for training or CPU vs. GPU for infrence)."),ma.forEach(t),bt=f(e),ce=i(e,"P",{});var va=o(ce);me=i(va,"IMG",{src:!0,alt:!0}),va.forEach(t),Ut=f(e),ve=i(e,"P",{});var da=o(ve);$r=u(da,"This document serves as an overview and entry point for the methods that could be useful for your scenario."),da.forEach(t),kt=f(e),E=i(e,"H2",{class:!0});var ir=o(E);z=i(ir,"A",{id:!0,class:!0,href:!0});var ga=o(z);Oe=i(ga,"SPAN",{});var wa=o(Oe);d(Y.$$.fragment,wa),wa.forEach(t),ga.forEach(t),Pr=f(ir),je=i(ir,"SPAN",{});var _a=o(je);yr=u(_a,"Training"),_a.forEach(t),ir.forEach(t),Gt=f(e),de=i(e,"P",{});var $a=o(de);Er=u($a,"Training transformer models efficiently requires an accelerator such as a GPU or TPU. The most common case is where you only have a single GPU, but there is also a section about mutli-GPU and CPU training (with more coming soon)."),$a.forEach(t),At=f(e),d(q.$$.fragment,e),St=f(e),b=i(e,"H3",{class:!0});var or=o(b);W=i(or,"A",{id:!0,class:!0,href:!0});var Pa=o(W);Fe=i(Pa,"SPAN",{});var ya=o(Fe);d(Z.$$.fragment,ya),ya.forEach(t),Pa.forEach(t),br=f(or),Ke=i(or,"SPAN",{});var Ea=o(Ke);Ur=u(Ea,"Single GPU"),Ea.forEach(t),or.forEach(t),Ct=f(e),ge=i(e,"P",{});var ba=o(ge);kr=u(ba,"Training large models on a single GPU can be challenging but there are a number of tools and methods that make it feasible. In this section methods such as mixed precision training, gradient accumulation and checkpointing, efficient optimizers, as well as strategies to determine the best batch size are discussed."),ba.forEach(t),Nt=f(e),we=i(e,"P",{});var Ua=o(we);_e=i(Ua,"A",{href:!0});var ka=o(_e);Gr=u(ka,"Go to single GPU training section"),ka.forEach(t),Ua.forEach(t),Tt=f(e),U=i(e,"H3",{class:!0});var nr=o(U);B=i(nr,"A",{id:!0,class:!0,href:!0});var Ga=o(B);Qe=i(Ga,"SPAN",{});var Aa=o(Qe);d(ee.$$.fragment,Aa),Aa.forEach(t),Ga.forEach(t),Ar=f(nr),Ve=i(nr,"SPAN",{});var Sa=o(Ve);Sr=u(Sa,"Multi-GPU"),Sa.forEach(t),nr.forEach(t),xt=f(e),$e=i(e,"P",{});var Ca=o($e);Cr=u(Ca,"In some cases training on a single GPU is still too slow or won\u2019t fit the large model. Moving to a mutli-GPU setup is the logical step, but training on multiple GPUs at once comes with new decisions: does each GPU have a full copy of the model or is the model itself also distributed? In this section we look at data, tensor, and pipeline parallism."),Ca.forEach(t),Ht=f(e),Pe=i(e,"P",{});var Na=o(Pe);ye=i(Na,"A",{href:!0});var Ta=o(ye);Nr=u(Ta,"Go to multi-GPU training section"),Ta.forEach(t),Na.forEach(t),Mt=f(e),k=i(e,"H3",{class:!0});var sr=o(k);R=i(sr,"A",{id:!0,class:!0,href:!0});var xa=o(R);Xe=i(xa,"SPAN",{});var Ha=o(Xe);d(te.$$.fragment,Ha),Ha.forEach(t),xa.forEach(t),Tr=f(sr),Ye=i(sr,"SPAN",{});var Ma=o(Ye);xr=u(Ma,"CPU"),Ma.forEach(t),sr.forEach(t),It=f(e),Ee=i(e,"P",{});var Ia=o(Ee);be=i(Ia,"A",{href:!0});var za=o(be);Hr=u(za,"Go to CPU training section"),za.forEach(t),Ia.forEach(t),zt=f(e),G=i(e,"H3",{class:!0});var lr=o(G);D=i(lr,"A",{id:!0,class:!0,href:!0});var qa=o(D);Ze=i(qa,"SPAN",{});var Wa=o(Ze);d(re.$$.fragment,Wa),Wa.forEach(t),qa.forEach(t),Mr=f(lr),et=i(lr,"SPAN",{});var Ba=o(et);Ir=u(Ba,"TPU"),Ba.forEach(t),lr.forEach(t),qt=f(e),Ue=i(e,"P",{});var Ra=o(Ue);ke=i(Ra,"A",{href:!0});var Da=o(ke);tt=i(Da,"EM",{});var La=o(tt);zr=u(La,"Coming soon"),La.forEach(t),Da.forEach(t),Ra.forEach(t),Wt=f(e),A=i(e,"H3",{class:!0});var hr=o(A);L=i(hr,"A",{id:!0,class:!0,href:!0});var Ja=o(L);rt=i(Ja,"SPAN",{});var Oa=o(rt);d(ae.$$.fragment,Oa),Oa.forEach(t),Ja.forEach(t),qr=f(hr),at=i(hr,"SPAN",{});var ja=o(at);Wr=u(ja,"Specialized Hardware"),ja.forEach(t),hr.forEach(t),Bt=f(e),Ge=i(e,"P",{});var Fa=o(Ge);Ae=i(Fa,"A",{href:!0});var Ka=o(Ae);it=i(Ka,"EM",{});var Qa=o(it);Br=u(Qa,"Coming soon"),Qa.forEach(t),Ka.forEach(t),Fa.forEach(t),Rt=f(e),S=i(e,"H2",{class:!0});var fr=o(S);J=i(fr,"A",{id:!0,class:!0,href:!0});var Va=o(J);ot=i(Va,"SPAN",{});var Xa=o(ot);d(ie.$$.fragment,Xa),Xa.forEach(t),Va.forEach(t),Rr=f(fr),nt=i(fr,"SPAN",{});var Ya=o(nt);Dr=u(Ya,"Inference"),Ya.forEach(t),fr.forEach(t),Dt=f(e),Se=i(e,"P",{});var Za=o(Se);Lr=u(Za,"Efficient inference with large models in a production environment can be as challenging as training them. In the following sections we go through the steps to run inference on CPU and single/multi-GPU setups."),Za.forEach(t),Lt=f(e),C=i(e,"H3",{class:!0});var pr=o(C);O=i(pr,"A",{id:!0,class:!0,href:!0});var ei=o(O);st=i(ei,"SPAN",{});var ti=o(st);d(oe.$$.fragment,ti),ti.forEach(t),ei.forEach(t),Jr=f(pr),lt=i(pr,"SPAN",{});var ri=o(lt);Or=u(ri,"CPU"),ri.forEach(t),pr.forEach(t),Jt=f(e),Ce=i(e,"P",{});var ai=o(Ce);Ne=i(ai,"A",{href:!0});var ii=o(Ne);jr=u(ii,"Go to CPU inference section"),ii.forEach(t),ai.forEach(t),Ot=f(e),N=i(e,"H3",{class:!0});var ur=o(N);j=i(ur,"A",{id:!0,class:!0,href:!0});var oi=o(j);ht=i(oi,"SPAN",{});var ni=o(ht);d(ne.$$.fragment,ni),ni.forEach(t),oi.forEach(t),Fr=f(ur),ft=i(ur,"SPAN",{});var si=o(ft);Kr=u(si,"Single GPU"),si.forEach(t),ur.forEach(t),jt=f(e),Te=i(e,"P",{});var li=o(Te);xe=i(li,"A",{href:!0});var hi=o(xe);pt=i(hi,"EM",{});var fi=o(pt);Qr=u(fi,"Coming soon"),fi.forEach(t),hi.forEach(t),li.forEach(t),Ft=f(e),T=i(e,"H3",{class:!0});var cr=o(T);F=i(cr,"A",{id:!0,class:!0,href:!0});var pi=o(F);ut=i(pi,"SPAN",{});var ui=o(ut);d(se.$$.fragment,ui),ui.forEach(t),pi.forEach(t),Vr=f(cr),ct=i(cr,"SPAN",{});var ci=o(ct);Xr=u(ci,"Multi-GPU"),ci.forEach(t),cr.forEach(t),Kt=f(e),He=i(e,"P",{});var mi=o(He);Me=i(mi,"A",{href:!0});var vi=o(Me);mt=i(vi,"EM",{});var di=o(mt);Yr=u(di,"Coming soon"),di.forEach(t),vi.forEach(t),mi.forEach(t),Qt=f(e),x=i(e,"H3",{class:!0});var mr=o(x);K=i(mr,"A",{id:!0,class:!0,href:!0});var gi=o(K);vt=i(gi,"SPAN",{});var wi=o(vt);d(le.$$.fragment,wi),wi.forEach(t),gi.forEach(t),Zr=f(mr),dt=i(mr,"SPAN",{});var _i=o(dt);ea=u(_i,"Specialized Hardware"),_i.forEach(t),mr.forEach(t),Vt=f(e),Ie=i(e,"P",{});var $i=o(Ie);ze=i($i,"A",{href:!0});var Pi=o(ze);gt=i(Pi,"EM",{});var yi=o(gt);ta=u(yi,"Coming soon"),yi.forEach(t),Pi.forEach(t),$i.forEach(t),Xt=f(e),H=i(e,"H2",{class:!0});var vr=o(H);Q=i(vr,"A",{id:!0,class:!0,href:!0});var Ei=o(Q);wt=i(Ei,"SPAN",{});var bi=o(wt);d(he.$$.fragment,bi),bi.forEach(t),Ei.forEach(t),ra=f(vr),_t=i(vr,"SPAN",{});var Ui=o(_t);aa=u(Ui,"Hardware"),Ui.forEach(t),vr.forEach(t),Yt=f(e),qe=i(e,"P",{});var ki=o(qe);ia=u(ki,"In the hardware section you can find tips and tricks when building your own deep learning rig."),ki.forEach(t),Zt=f(e),We=i(e,"P",{});var Gi=o(We);Be=i(Gi,"A",{href:!0});var Ai=o(Be);oa=u(Ai,"Go to hardware section"),Ai.forEach(t),Gi.forEach(t),er=f(e),M=i(e,"H2",{class:!0});var dr=o(M);V=i(dr,"A",{id:!0,class:!0,href:!0});var Si=o(V);$t=i(Si,"SPAN",{});var Ci=o($t);d(fe.$$.fragment,Ci),Ci.forEach(t),Si.forEach(t),na=f(dr),Pt=i(dr,"SPAN",{});var Ni=o(Pt);sa=u(Ni,"Contribute"),Ni.forEach(t),dr.forEach(t),tr=f(e),Re=i(e,"P",{});var Ti=o(Re);la=u(Ti,"This document is far from being complete and a lot more needs to be added, so if you have additions or corrections to make please don\u2019t hesitate to open a PR or if you aren\u2019t sure start an Issue and we can discuss the details there."),Ti.forEach(t),rr=f(e),De=i(e,"P",{});var xi=o(De);ha=u(xi,"When making contributions that A is better than B, please try to include a reproducible benchmark and/or a link to the source of that information (unless it comes directly from you)."),xi.forEach(t),this.h()},h(){s(c,"name","hf:doc:metadata"),s(c,"content",JSON.stringify(Li)),s(y,"id","performance-and-scalability"),s(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(y,"href","#performance-and-scalability"),s(m,"class","relative group"),qi(me.src,fa="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/perf_overview.png")||s(me,"src",fa),s(me,"alt","perf_overview"),s(z,"id","training"),s(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(z,"href","#training"),s(E,"class","relative group"),s(W,"id","single-gpu"),s(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(W,"href","#single-gpu"),s(b,"class","relative group"),s(_e,"href","perf_train_gpu_one"),s(B,"id","multigpu"),s(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(B,"href","#multigpu"),s(U,"class","relative group"),s(ye,"href","perf_train_gpu_many"),s(R,"id","cpu"),s(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(R,"href","#cpu"),s(k,"class","relative group"),s(be,"href","perf_train_cpu"),s(D,"id","tpu"),s(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(D,"href","#tpu"),s(G,"class","relative group"),s(ke,"href","perf_train_tpu"),s(L,"id","specialized-hardware"),s(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(L,"href","#specialized-hardware"),s(A,"class","relative group"),s(Ae,"href","perf_train_special"),s(J,"id","inference"),s(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(J,"href","#inference"),s(S,"class","relative group"),s(O,"id","cpu"),s(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(O,"href","#cpu"),s(C,"class","relative group"),s(Ne,"href","perf_infer_cpu"),s(j,"id","single-gpu"),s(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(j,"href","#single-gpu"),s(N,"class","relative group"),s(xe,"href","perf_infer_gpu_one"),s(F,"id","multigpu"),s(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(F,"href","#multigpu"),s(T,"class","relative group"),s(Me,"href","perf_infer_gpu_many"),s(K,"id","specialized-hardware"),s(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(K,"href","#specialized-hardware"),s(x,"class","relative group"),s(ze,"href","perf_infer_special"),s(Q,"id","hardware"),s(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Q,"href","#hardware"),s(H,"class","relative group"),s(Be,"href","perf_hardware"),s(V,"id","contribute"),s(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(V,"href","#contribute"),s(M,"class","relative group")},m(e,n){r(document.head,c),l(e,I,n),l(e,m,n),r(m,y),r(y,Le),g(X,Le,null),r(m,gr),r(m,Je),r(Je,wr),l(e,Et,n),l(e,ue,n),r(ue,_r),l(e,bt,n),l(e,ce,n),r(ce,me),l(e,Ut,n),l(e,ve,n),r(ve,$r),l(e,kt,n),l(e,E,n),r(E,z),r(z,Oe),g(Y,Oe,null),r(E,Pr),r(E,je),r(je,yr),l(e,Gt,n),l(e,de,n),r(de,Er),l(e,At,n),g(q,e,n),l(e,St,n),l(e,b,n),r(b,W),r(W,Fe),g(Z,Fe,null),r(b,br),r(b,Ke),r(Ke,Ur),l(e,Ct,n),l(e,ge,n),r(ge,kr),l(e,Nt,n),l(e,we,n),r(we,_e),r(_e,Gr),l(e,Tt,n),l(e,U,n),r(U,B),r(B,Qe),g(ee,Qe,null),r(U,Ar),r(U,Ve),r(Ve,Sr),l(e,xt,n),l(e,$e,n),r($e,Cr),l(e,Ht,n),l(e,Pe,n),r(Pe,ye),r(ye,Nr),l(e,Mt,n),l(e,k,n),r(k,R),r(R,Xe),g(te,Xe,null),r(k,Tr),r(k,Ye),r(Ye,xr),l(e,It,n),l(e,Ee,n),r(Ee,be),r(be,Hr),l(e,zt,n),l(e,G,n),r(G,D),r(D,Ze),g(re,Ze,null),r(G,Mr),r(G,et),r(et,Ir),l(e,qt,n),l(e,Ue,n),r(Ue,ke),r(ke,tt),r(tt,zr),l(e,Wt,n),l(e,A,n),r(A,L),r(L,rt),g(ae,rt,null),r(A,qr),r(A,at),r(at,Wr),l(e,Bt,n),l(e,Ge,n),r(Ge,Ae),r(Ae,it),r(it,Br),l(e,Rt,n),l(e,S,n),r(S,J),r(J,ot),g(ie,ot,null),r(S,Rr),r(S,nt),r(nt,Dr),l(e,Dt,n),l(e,Se,n),r(Se,Lr),l(e,Lt,n),l(e,C,n),r(C,O),r(O,st),g(oe,st,null),r(C,Jr),r(C,lt),r(lt,Or),l(e,Jt,n),l(e,Ce,n),r(Ce,Ne),r(Ne,jr),l(e,Ot,n),l(e,N,n),r(N,j),r(j,ht),g(ne,ht,null),r(N,Fr),r(N,ft),r(ft,Kr),l(e,jt,n),l(e,Te,n),r(Te,xe),r(xe,pt),r(pt,Qr),l(e,Ft,n),l(e,T,n),r(T,F),r(F,ut),g(se,ut,null),r(T,Vr),r(T,ct),r(ct,Xr),l(e,Kt,n),l(e,He,n),r(He,Me),r(Me,mt),r(mt,Yr),l(e,Qt,n),l(e,x,n),r(x,K),r(K,vt),g(le,vt,null),r(x,Zr),r(x,dt),r(dt,ea),l(e,Vt,n),l(e,Ie,n),r(Ie,ze),r(ze,gt),r(gt,ta),l(e,Xt,n),l(e,H,n),r(H,Q),r(Q,wt),g(he,wt,null),r(H,ra),r(H,_t),r(_t,aa),l(e,Yt,n),l(e,qe,n),r(qe,ia),l(e,Zt,n),l(e,We,n),r(We,Be),r(Be,oa),l(e,er,n),l(e,M,n),r(M,V),r(V,$t),g(fe,$t,null),r(M,na),r(M,Pt),r(Pt,sa),l(e,tr,n),l(e,Re,n),r(Re,la),l(e,rr,n),l(e,De,n),r(De,ha),ar=!0},p(e,[n]){const pe={};n&2&&(pe.$$scope={dirty:n,ctx:e}),q.$set(pe)},i(e){ar||(w(X.$$.fragment,e),w(Y.$$.fragment,e),w(q.$$.fragment,e),w(Z.$$.fragment,e),w(ee.$$.fragment,e),w(te.$$.fragment,e),w(re.$$.fragment,e),w(ae.$$.fragment,e),w(ie.$$.fragment,e),w(oe.$$.fragment,e),w(ne.$$.fragment,e),w(se.$$.fragment,e),w(le.$$.fragment,e),w(he.$$.fragment,e),w(fe.$$.fragment,e),ar=!0)},o(e){_(X.$$.fragment,e),_(Y.$$.fragment,e),_(q.$$.fragment,e),_(Z.$$.fragment,e),_(ee.$$.fragment,e),_(te.$$.fragment,e),_(re.$$.fragment,e),_(ae.$$.fragment,e),_(ie.$$.fragment,e),_(oe.$$.fragment,e),_(ne.$$.fragment,e),_(se.$$.fragment,e),_(le.$$.fragment,e),_(he.$$.fragment,e),_(fe.$$.fragment,e),ar=!1},d(e){t(c),e&&t(I),e&&t(m),$(X),e&&t(Et),e&&t(ue),e&&t(bt),e&&t(ce),e&&t(Ut),e&&t(ve),e&&t(kt),e&&t(E),$(Y),e&&t(Gt),e&&t(de),e&&t(At),$(q,e),e&&t(St),e&&t(b),$(Z),e&&t(Ct),e&&t(ge),e&&t(Nt),e&&t(we),e&&t(Tt),e&&t(U),$(ee),e&&t(xt),e&&t($e),e&&t(Ht),e&&t(Pe),e&&t(Mt),e&&t(k),$(te),e&&t(It),e&&t(Ee),e&&t(zt),e&&t(G),$(re),e&&t(qt),e&&t(Ue),e&&t(Wt),e&&t(A),$(ae),e&&t(Bt),e&&t(Ge),e&&t(Rt),e&&t(S),$(ie),e&&t(Dt),e&&t(Se),e&&t(Lt),e&&t(C),$(oe),e&&t(Jt),e&&t(Ce),e&&t(Ot),e&&t(N),$(ne),e&&t(jt),e&&t(Te),e&&t(Ft),e&&t(T),$(se),e&&t(Kt),e&&t(He),e&&t(Qt),e&&t(x),$(le),e&&t(Vt),e&&t(Ie),e&&t(Xt),e&&t(H),$(he),e&&t(Yt),e&&t(qe),e&&t(Zt),e&&t(We),e&&t(er),e&&t(M),$(fe),e&&t(tr),e&&t(Re),e&&t(rr),e&&t(De)}}}const Li={local:"performance-and-scalability",sections:[{local:"training",sections:[{local:"single-gpu",title:"Single GPU"},{local:"multigpu",title:"Multi-GPU"},{local:"cpu",title:"CPU"},{local:"tpu",title:"TPU"},{local:"specialized-hardware",title:"Specialized Hardware"}],title:"Training"},{local:"inference",sections:[{local:"cpu",title:"CPU"},{local:"single-gpu",title:"Single GPU"},{local:"multigpu",title:"Multi-GPU"},{local:"specialized-hardware",title:"Specialized Hardware"}],title:"Inference"},{local:"hardware",title:"Hardware"},{local:"contribute",title:"Contribute"}],title:"Performance and Scalability"};function Ji(yt){return Wi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ki extends Hi{constructor(c){super();Mi(this,c,Ji,Di,Ii,{})}}export{Ki as default,Li as metadata};
