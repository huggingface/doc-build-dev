import{S as nl,i as ll,s as rl,e as r,k as f,w as m,t as n,M as il,c as i,d as s,m as c,a as o,x as u,h as l,b as h,N as ol,G as a,g as p,y as d,q as g,o as v,B as _,v as pl}from"../chunks/vendor-hf-doc-builder.js";import{T as hl}from"../chunks/Tip-hf-doc-builder.js";import{I as ns}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as y}from"../chunks/CodeBlock-hf-doc-builder.js";function fl(ks){let j,N,k,b,F;return{c(){j=r("p"),N=n("Take a look at the "),k=r("a"),b=n("pipeline()"),F=n(" documentation for a complete list of supported tasks."),this.h()},l(w){j=i(w,"P",{});var P=o(j);N=l(P,"Take a look at the "),k=i(P,"A",{href:!0});var H=o(k);b=l(H,"pipeline()"),H.forEach(s),F=l(P," documentation for a complete list of supported tasks."),P.forEach(s),this.h()},h(){h(k,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline")},m(w,P){p(w,j,P),a(j,N),a(j,k),a(k,b),a(j,F)},d(w){w&&s(j)}}}function cl(ks){let j,N,k,b,F,w,P,H,xa,$s,E,wa,Ae,ya,ba,se,Ea,qa,Pe,Aa,Pa,xs,T,ae,Ta,Te,Sa,Ma,Fa,ls,za,Ca,te,La,Se,Ia,Da,ws,R,ys,z,U,rs,ne,Na,is,Ha,bs,q,Ra,Me,Ua,Oa,Fe,Ka,Va,ze,Ga,Ba,Es,Ce,le,Qa,Le,Wa,Ja,qs,re,As,ie,oe,Xa,Ie,Ya,Za,Ps,pe,Ts,De,et,Ss,he,Ms,x,st,Ne,at,tt,os,nt,lt,He,rt,it,ps,ot,pt,Fs,fe,zs,C,O,hs,ce,ht,fs,ft,Cs,$,ct,Re,mt,ut,me,dt,gt,cs,vt,_t,Ue,jt,kt,Oe,$t,xt,Ls,ue,Is,K,wt,Ke,yt,bt,Ds,de,Ns,V,Et,Ve,qt,At,Hs,ge,Rs,L,G,ms,ve,Pt,us,Tt,Us,B,St,Ge,Mt,Ft,Os,Be,zt,Ks,_e,Vs,S,Ct,je,Lt,It,Qe,Dt,Nt,Gs,ke,Bs,Q,Ht,We,Rt,Ut,Qs,$e,Ws,I,W,ds,xe,Ot,gs,Kt,Js,J,Vt,Je,Gt,Bt,Xs,Xe,Qt,Ys,Ye,Ze,an,Zs,we,ea,D,X,vs,ye,Wt,_s,Jt,sa,es,Xt,aa,ss,Yt,ta,be,na,Y,Zt,js,en,sn,la,Ee,ra;return w=new ns({}),R=new hl({props:{$$slots:{default:[fl]},$$scope:{ctx:ks}}}),ne=new ns({}),re=new y({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>)`}}),pe=new y({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain&#x27;</span>}]`}}),he=new y({props:{code:`generator(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ]
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne&quot;</span>,
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),fe=new y({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
    num_return_sequences=2,
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>    num_return_sequences=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),ce=new ns({}),ue=new y({props:{code:`from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),de=new y({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation", model=model, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=model, tokenizer=tokenizer)`}}),ge=new y({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Dragon-lords (for them to rule in a world ruled by their rulers, and all who live within the realm&#x27;</span>}]`}}),ve=new ns({}),_e=new y({props:{code:`from datasets import load_dataset
import torch

torch.manual_seed(42)
ds = load_dataset("hf-internal-testing/librispeech_asr_demo", "clean", split="validation")
audio_file = ds[0]["audio"]["path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>torch.manual_seed(<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;hf-internal-testing/librispeech_asr_demo&quot;</span>, <span class="hljs-string">&quot;clean&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = ds[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`}}),ke=new y({props:{code:`from transformers import pipeline

audio_classifier = pipeline(
    task="audio-classification", model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier = pipeline(
<span class="hljs-meta">... </span>    task=<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),$e=new y({props:{code:`preds = audio_classifier(audio_file)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>preds = audio_classifier(audio_file)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1315</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;calm&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1307</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;neutral&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1274</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;sad&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1261</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;fearful&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1242</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;happy&#x27;</span>}]`}}),xe=new ns({}),we=new y({props:{code:`from transformers import pipeline

vision_classifier = pipeline(task="image-classification")
preds = vision_classifier(
    images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier = pipeline(task=<span class="hljs-string">&quot;image-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vision_classifier(
<span class="hljs-meta">... </span>    images=<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4335</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;lynx, catamount&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0348</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cougar, puma, catamount, mountain lion, painter, panther, Felis concolor&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0324</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;snow leopard, ounce, Panthera uncia&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0239</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;Egyptian cat&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0229</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;tiger cat&#x27;</span>}]`}}),ye=new ns({}),be=new y({props:{code:`image = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
question = "how chonky is this cat?"`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>image = <span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>question = <span class="hljs-string">&quot;how chonky is this cat?&quot;</span>`}}),Ee=new y({props:{code:`from transformers import pipeline

vqa = pipeline(task="vqa")
preds = vqa(image=image, question=question)
preds = [{"score": round(pred["score"], 4), "answer": pred["answer"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vqa = pipeline(task=<span class="hljs-string">&quot;vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vqa(image=image, question=question)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;answer&quot;</span>: pred[<span class="hljs-string">&quot;answer&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.43120142817497253</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;very&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.11782129853963852</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;not very&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.03669029846787453</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;not at all&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.024968842044472694</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;old&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.019012143835425377</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;medium&#x27;</span>}]`}}),{c(){j=r("meta"),N=f(),k=r("h1"),b=r("a"),F=r("span"),m(w.$$.fragment),P=f(),H=r("span"),xa=n("Pipelines for inference"),$s=f(),E=r("p"),wa=n("The "),Ae=r("a"),ya=n("pipeline()"),ba=n(" makes it simple to use any model from the "),se=r("a"),Ea=n("Model Hub"),qa=n(" for inference on a variety of tasks such as text generation, image segmentation, and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),Pe=r("a"),Aa=n("pipeline()"),Pa=n("! This tutorial will teach you to:"),xs=f(),T=r("ul"),ae=r("li"),Ta=n("Use a "),Te=r("a"),Sa=n("pipeline()"),Ma=n(" for inference."),Fa=f(),ls=r("li"),za=n("Use a specific tokenizer or model."),Ca=f(),te=r("li"),La=n("Use a "),Se=r("a"),Ia=n("pipeline()"),Da=n(" for audio, vision, and multimodal tasks."),ws=f(),m(R.$$.fragment),ys=f(),z=r("h2"),U=r("a"),rs=r("span"),m(ne.$$.fragment),Na=f(),is=r("span"),Ha=n("Pipeline usage"),bs=f(),q=r("p"),Ra=n("While each task has an associated "),Me=r("a"),Ua=n("pipeline()"),Oa=n(", it is simpler to use the general "),Fe=r("a"),Ka=n("pipeline()"),Va=n(" abstraction which contains all the specific task pipelines. The "),ze=r("a"),Ga=n("pipeline()"),Ba=n(" automatically loads a default model and tokenizer capable of inference for your task."),Es=f(),Ce=r("ol"),le=r("li"),Qa=n("Start by creating a "),Le=r("a"),Wa=n("pipeline()"),Ja=n(" and specify an inference task:"),qs=f(),m(re.$$.fragment),As=f(),ie=r("ol"),oe=r("li"),Xa=n("Pass your input text to the "),Ie=r("a"),Ya=n("pipeline()"),Za=n(":"),Ps=f(),m(pe.$$.fragment),Ts=f(),De=r("p"),et=n("If you have more than one input, pass your input as a list:"),Ss=f(),m(he.$$.fragment),Ms=f(),x=r("p"),st=n("Any additional parameters for your task can also be included in the "),Ne=r("a"),at=n("pipeline()"),tt=n(". The "),os=r("code"),nt=n("text-generation"),lt=n(" task has a "),He=r("a"),rt=n("generate()"),it=n(" method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),ps=r("code"),ot=n("num_return_sequences"),pt=n(" parameter:"),Fs=f(),m(fe.$$.fragment),zs=f(),C=r("h3"),O=r("a"),hs=r("span"),m(ce.$$.fragment),ht=f(),fs=r("span"),ft=n("Choose a model and tokenizer"),Cs=f(),$=r("p"),ct=n("The "),Re=r("a"),mt=n("pipeline()"),ut=n(" accepts any model from the "),me=r("a"),dt=n("Model Hub"),gt=n(". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),cs=r("code"),vt=n("AutoModelFor"),_t=n(" and "),Ue=r("a"),jt=n("AutoTokenizer"),kt=n(" class. For example, load the "),Oe=r("a"),$t=n("AutoModelForCausalLM"),xt=n(" class for a causal language modeling task:"),Ls=f(),m(ue.$$.fragment),Is=f(),K=r("p"),wt=n("Create a "),Ke=r("a"),yt=n("pipeline()"),bt=n(" for your task, and specify the model and tokenizer you\u2019ve loaded:"),Ds=f(),m(de.$$.fragment),Ns=f(),V=r("p"),Et=n("Pass your input text to the "),Ve=r("a"),qt=n("pipeline()"),At=n(" to generate some text:"),Hs=f(),m(ge.$$.fragment),Rs=f(),L=r("h2"),G=r("a"),ms=r("span"),m(ve.$$.fragment),Pt=f(),us=r("span"),Tt=n("Audio pipeline"),Us=f(),B=r("p"),St=n("The general "),Ge=r("a"),Mt=n("pipeline()"),Ft=n(" contains all available tasks which means it can also be extended to audio tasks."),Os=f(),Be=r("p"),zt=n("For example, let\u2019s classify the emotion in this audio clip:"),Ks=f(),m(_e.$$.fragment),Vs=f(),S=r("p"),Ct=n("Find an "),je=r("a"),Lt=n("audio classification"),It=n(" model on the Model Hub for emotion recognition and load it in the "),Qe=r("a"),Dt=n("pipeline()"),Nt=n(":"),Gs=f(),m(ke.$$.fragment),Bs=f(),Q=r("p"),Ht=n("Pass the audio file to the "),We=r("a"),Rt=n("pipeline()"),Ut=n(":"),Qs=f(),m($e.$$.fragment),Ws=f(),I=r("h2"),W=r("a"),ds=r("span"),m(xe.$$.fragment),Ot=f(),gs=r("span"),Kt=n("Vision pipeline"),Js=f(),J=r("p"),Vt=n("Using a "),Je=r("a"),Gt=n("pipeline()"),Bt=n(" for vision tasks is practically identical."),Xs=f(),Xe=r("p"),Qt=n("Specify your vision task and pass your image to the classifier. The image can be a link or a local path to the image. For example, what species of cat is shown below?"),Ys=f(),Ye=r("p"),Ze=r("img"),Zs=f(),m(we.$$.fragment),ea=f(),D=r("h2"),X=r("a"),vs=r("span"),m(ye.$$.fragment),Wt=f(),_s=r("span"),Jt=n("Multimodal pipeline"),sa=f(),es=r("p"),Xt=n("There are also pipelines that support more than one modality. For example, a visual question answering (VQA) task combines text and image. Feel free to use any image link you like, and a question you want to ask about the image. The image can be a URL or a local path to the image."),aa=f(),ss=r("p"),Yt=n("For example, if you use the same image from the vision pipeline above:"),ta=f(),m(be.$$.fragment),na=f(),Y=r("p"),Zt=n("Create a pipeline for "),js=r("code"),en=n("vqa"),sn=n(" and pass it the image and question:"),la=f(),m(Ee.$$.fragment),this.h()},l(e){const t=il('[data-svelte="svelte-1phssyn"]',document.head);j=i(t,"META",{name:!0,content:!0}),t.forEach(s),N=c(e),k=i(e,"H1",{class:!0});var qe=o(k);b=i(qe,"A",{id:!0,class:!0,href:!0});var tn=o(b);F=i(tn,"SPAN",{});var nn=o(F);u(w.$$.fragment,nn),nn.forEach(s),tn.forEach(s),P=c(qe),H=i(qe,"SPAN",{});var ln=o(H);xa=l(ln,"Pipelines for inference"),ln.forEach(s),qe.forEach(s),$s=c(e),E=i(e,"P",{});var Z=o(E);wa=l(Z,"The "),Ae=i(Z,"A",{href:!0});var rn=o(Ae);ya=l(rn,"pipeline()"),rn.forEach(s),ba=l(Z," makes it simple to use any model from the "),se=i(Z,"A",{href:!0,rel:!0});var on=o(se);Ea=l(on,"Model Hub"),on.forEach(s),qa=l(Z," for inference on a variety of tasks such as text generation, image segmentation, and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),Pe=i(Z,"A",{href:!0});var pn=o(Pe);Aa=l(pn,"pipeline()"),pn.forEach(s),Pa=l(Z,"! This tutorial will teach you to:"),Z.forEach(s),xs=c(e),T=i(e,"UL",{});var as=o(T);ae=i(as,"LI",{});var ia=o(ae);Ta=l(ia,"Use a "),Te=i(ia,"A",{href:!0});var hn=o(Te);Sa=l(hn,"pipeline()"),hn.forEach(s),Ma=l(ia," for inference."),ia.forEach(s),Fa=c(as),ls=i(as,"LI",{});var fn=o(ls);za=l(fn,"Use a specific tokenizer or model."),fn.forEach(s),Ca=c(as),te=i(as,"LI",{});var oa=o(te);La=l(oa,"Use a "),Se=i(oa,"A",{href:!0});var cn=o(Se);Ia=l(cn,"pipeline()"),cn.forEach(s),Da=l(oa," for audio, vision, and multimodal tasks."),oa.forEach(s),as.forEach(s),ws=c(e),u(R.$$.fragment,e),ys=c(e),z=i(e,"H2",{class:!0});var pa=o(z);U=i(pa,"A",{id:!0,class:!0,href:!0});var mn=o(U);rs=i(mn,"SPAN",{});var un=o(rs);u(ne.$$.fragment,un),un.forEach(s),mn.forEach(s),Na=c(pa),is=i(pa,"SPAN",{});var dn=o(is);Ha=l(dn,"Pipeline usage"),dn.forEach(s),pa.forEach(s),bs=c(e),q=i(e,"P",{});var ee=o(q);Ra=l(ee,"While each task has an associated "),Me=i(ee,"A",{href:!0});var gn=o(Me);Ua=l(gn,"pipeline()"),gn.forEach(s),Oa=l(ee,", it is simpler to use the general "),Fe=i(ee,"A",{href:!0});var vn=o(Fe);Ka=l(vn,"pipeline()"),vn.forEach(s),Va=l(ee," abstraction which contains all the specific task pipelines. The "),ze=i(ee,"A",{href:!0});var _n=o(ze);Ga=l(_n,"pipeline()"),_n.forEach(s),Ba=l(ee," automatically loads a default model and tokenizer capable of inference for your task."),ee.forEach(s),Es=c(e),Ce=i(e,"OL",{});var jn=o(Ce);le=i(jn,"LI",{});var ha=o(le);Qa=l(ha,"Start by creating a "),Le=i(ha,"A",{href:!0});var kn=o(Le);Wa=l(kn,"pipeline()"),kn.forEach(s),Ja=l(ha," and specify an inference task:"),ha.forEach(s),jn.forEach(s),qs=c(e),u(re.$$.fragment,e),As=c(e),ie=i(e,"OL",{start:!0});var $n=o(ie);oe=i($n,"LI",{});var fa=o(oe);Xa=l(fa,"Pass your input text to the "),Ie=i(fa,"A",{href:!0});var xn=o(Ie);Ya=l(xn,"pipeline()"),xn.forEach(s),Za=l(fa,":"),fa.forEach(s),$n.forEach(s),Ps=c(e),u(pe.$$.fragment,e),Ts=c(e),De=i(e,"P",{});var wn=o(De);et=l(wn,"If you have more than one input, pass your input as a list:"),wn.forEach(s),Ss=c(e),u(he.$$.fragment,e),Ms=c(e),x=i(e,"P",{});var M=o(x);st=l(M,"Any additional parameters for your task can also be included in the "),Ne=i(M,"A",{href:!0});var yn=o(Ne);at=l(yn,"pipeline()"),yn.forEach(s),tt=l(M,". The "),os=i(M,"CODE",{});var bn=o(os);nt=l(bn,"text-generation"),bn.forEach(s),lt=l(M," task has a "),He=i(M,"A",{href:!0});var En=o(He);rt=l(En,"generate()"),En.forEach(s),it=l(M," method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),ps=i(M,"CODE",{});var qn=o(ps);ot=l(qn,"num_return_sequences"),qn.forEach(s),pt=l(M," parameter:"),M.forEach(s),Fs=c(e),u(fe.$$.fragment,e),zs=c(e),C=i(e,"H3",{class:!0});var ca=o(C);O=i(ca,"A",{id:!0,class:!0,href:!0});var An=o(O);hs=i(An,"SPAN",{});var Pn=o(hs);u(ce.$$.fragment,Pn),Pn.forEach(s),An.forEach(s),ht=c(ca),fs=i(ca,"SPAN",{});var Tn=o(fs);ft=l(Tn,"Choose a model and tokenizer"),Tn.forEach(s),ca.forEach(s),Cs=c(e),$=i(e,"P",{});var A=o($);ct=l(A,"The "),Re=i(A,"A",{href:!0});var Sn=o(Re);mt=l(Sn,"pipeline()"),Sn.forEach(s),ut=l(A," accepts any model from the "),me=i(A,"A",{href:!0,rel:!0});var Mn=o(me);dt=l(Mn,"Model Hub"),Mn.forEach(s),gt=l(A,". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),cs=i(A,"CODE",{});var Fn=o(cs);vt=l(Fn,"AutoModelFor"),Fn.forEach(s),_t=l(A," and "),Ue=i(A,"A",{href:!0});var zn=o(Ue);jt=l(zn,"AutoTokenizer"),zn.forEach(s),kt=l(A," class. For example, load the "),Oe=i(A,"A",{href:!0});var Cn=o(Oe);$t=l(Cn,"AutoModelForCausalLM"),Cn.forEach(s),xt=l(A," class for a causal language modeling task:"),A.forEach(s),Ls=c(e),u(ue.$$.fragment,e),Is=c(e),K=i(e,"P",{});var ma=o(K);wt=l(ma,"Create a "),Ke=i(ma,"A",{href:!0});var Ln=o(Ke);yt=l(Ln,"pipeline()"),Ln.forEach(s),bt=l(ma," for your task, and specify the model and tokenizer you\u2019ve loaded:"),ma.forEach(s),Ds=c(e),u(de.$$.fragment,e),Ns=c(e),V=i(e,"P",{});var ua=o(V);Et=l(ua,"Pass your input text to the "),Ve=i(ua,"A",{href:!0});var In=o(Ve);qt=l(In,"pipeline()"),In.forEach(s),At=l(ua," to generate some text:"),ua.forEach(s),Hs=c(e),u(ge.$$.fragment,e),Rs=c(e),L=i(e,"H2",{class:!0});var da=o(L);G=i(da,"A",{id:!0,class:!0,href:!0});var Dn=o(G);ms=i(Dn,"SPAN",{});var Nn=o(ms);u(ve.$$.fragment,Nn),Nn.forEach(s),Dn.forEach(s),Pt=c(da),us=i(da,"SPAN",{});var Hn=o(us);Tt=l(Hn,"Audio pipeline"),Hn.forEach(s),da.forEach(s),Us=c(e),B=i(e,"P",{});var ga=o(B);St=l(ga,"The general "),Ge=i(ga,"A",{href:!0});var Rn=o(Ge);Mt=l(Rn,"pipeline()"),Rn.forEach(s),Ft=l(ga," contains all available tasks which means it can also be extended to audio tasks."),ga.forEach(s),Os=c(e),Be=i(e,"P",{});var Un=o(Be);zt=l(Un,"For example, let\u2019s classify the emotion in this audio clip:"),Un.forEach(s),Ks=c(e),u(_e.$$.fragment,e),Vs=c(e),S=i(e,"P",{});var ts=o(S);Ct=l(ts,"Find an "),je=i(ts,"A",{href:!0,rel:!0});var On=o(je);Lt=l(On,"audio classification"),On.forEach(s),It=l(ts," model on the Model Hub for emotion recognition and load it in the "),Qe=i(ts,"A",{href:!0});var Kn=o(Qe);Dt=l(Kn,"pipeline()"),Kn.forEach(s),Nt=l(ts,":"),ts.forEach(s),Gs=c(e),u(ke.$$.fragment,e),Bs=c(e),Q=i(e,"P",{});var va=o(Q);Ht=l(va,"Pass the audio file to the "),We=i(va,"A",{href:!0});var Vn=o(We);Rt=l(Vn,"pipeline()"),Vn.forEach(s),Ut=l(va,":"),va.forEach(s),Qs=c(e),u($e.$$.fragment,e),Ws=c(e),I=i(e,"H2",{class:!0});var _a=o(I);W=i(_a,"A",{id:!0,class:!0,href:!0});var Gn=o(W);ds=i(Gn,"SPAN",{});var Bn=o(ds);u(xe.$$.fragment,Bn),Bn.forEach(s),Gn.forEach(s),Ot=c(_a),gs=i(_a,"SPAN",{});var Qn=o(gs);Kt=l(Qn,"Vision pipeline"),Qn.forEach(s),_a.forEach(s),Js=c(e),J=i(e,"P",{});var ja=o(J);Vt=l(ja,"Using a "),Je=i(ja,"A",{href:!0});var Wn=o(Je);Gt=l(Wn,"pipeline()"),Wn.forEach(s),Bt=l(ja," for vision tasks is practically identical."),ja.forEach(s),Xs=c(e),Xe=i(e,"P",{});var Jn=o(Xe);Qt=l(Jn,"Specify your vision task and pass your image to the classifier. The image can be a link or a local path to the image. For example, what species of cat is shown below?"),Jn.forEach(s),Ys=c(e),Ye=i(e,"P",{});var Xn=o(Ye);Ze=i(Xn,"IMG",{src:!0,alt:!0}),Xn.forEach(s),Zs=c(e),u(we.$$.fragment,e),ea=c(e),D=i(e,"H2",{class:!0});var ka=o(D);X=i(ka,"A",{id:!0,class:!0,href:!0});var Yn=o(X);vs=i(Yn,"SPAN",{});var Zn=o(vs);u(ye.$$.fragment,Zn),Zn.forEach(s),Yn.forEach(s),Wt=c(ka),_s=i(ka,"SPAN",{});var el=o(_s);Jt=l(el,"Multimodal pipeline"),el.forEach(s),ka.forEach(s),sa=c(e),es=i(e,"P",{});var sl=o(es);Xt=l(sl,"There are also pipelines that support more than one modality. For example, a visual question answering (VQA) task combines text and image. Feel free to use any image link you like, and a question you want to ask about the image. The image can be a URL or a local path to the image."),sl.forEach(s),aa=c(e),ss=i(e,"P",{});var al=o(ss);Yt=l(al,"For example, if you use the same image from the vision pipeline above:"),al.forEach(s),ta=c(e),u(be.$$.fragment,e),na=c(e),Y=i(e,"P",{});var $a=o(Y);Zt=l($a,"Create a pipeline for "),js=i($a,"CODE",{});var tl=o(js);en=l(tl,"vqa"),tl.forEach(s),sn=l($a," and pass it the image and question:"),$a.forEach(s),la=c(e),u(Ee.$$.fragment,e),this.h()},h(){h(j,"name","hf:doc:metadata"),h(j,"content",JSON.stringify(ml)),h(b,"id","pipelines-for-inference"),h(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(b,"href","#pipelines-for-inference"),h(k,"class","relative group"),h(Ae,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(se,"href","https://huggingface.co/models"),h(se,"rel","nofollow"),h(Pe,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(Te,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(Se,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(U,"id","pipeline-usage"),h(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(U,"href","#pipeline-usage"),h(z,"class","relative group"),h(Me,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(Fe,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(ze,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(Le,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(Ie,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(ie,"start","2"),h(Ne,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(He,"href","/docs/transformers/pr_17907/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate"),h(O,"id","choose-a-model-and-tokenizer"),h(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(O,"href","#choose-a-model-and-tokenizer"),h(C,"class","relative group"),h(Re,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(me,"href","https://huggingface.co/models"),h(me,"rel","nofollow"),h(Ue,"href","/docs/transformers/pr_17907/en/model_doc/auto#transformers.AutoTokenizer"),h(Oe,"href","/docs/transformers/pr_17907/en/model_doc/auto#transformers.AutoModelForCausalLM"),h(Ke,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(Ve,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(G,"id","audio-pipeline"),h(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(G,"href","#audio-pipeline"),h(L,"class","relative group"),h(Ge,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(je,"href","https://huggingface.co/models?pipeline_tag=audio-classification"),h(je,"rel","nofollow"),h(Qe,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(We,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),h(W,"id","vision-pipeline"),h(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(W,"href","#vision-pipeline"),h(I,"class","relative group"),h(Je,"href","/docs/transformers/pr_17907/en/main_classes/pipelines#transformers.pipeline"),ol(Ze.src,an="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg")||h(Ze,"src",an),h(Ze,"alt","pipeline-cat-chonk"),h(X,"id","multimodal-pipeline"),h(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(X,"href","#multimodal-pipeline"),h(D,"class","relative group")},m(e,t){a(document.head,j),p(e,N,t),p(e,k,t),a(k,b),a(b,F),d(w,F,null),a(k,P),a(k,H),a(H,xa),p(e,$s,t),p(e,E,t),a(E,wa),a(E,Ae),a(Ae,ya),a(E,ba),a(E,se),a(se,Ea),a(E,qa),a(E,Pe),a(Pe,Aa),a(E,Pa),p(e,xs,t),p(e,T,t),a(T,ae),a(ae,Ta),a(ae,Te),a(Te,Sa),a(ae,Ma),a(T,Fa),a(T,ls),a(ls,za),a(T,Ca),a(T,te),a(te,La),a(te,Se),a(Se,Ia),a(te,Da),p(e,ws,t),d(R,e,t),p(e,ys,t),p(e,z,t),a(z,U),a(U,rs),d(ne,rs,null),a(z,Na),a(z,is),a(is,Ha),p(e,bs,t),p(e,q,t),a(q,Ra),a(q,Me),a(Me,Ua),a(q,Oa),a(q,Fe),a(Fe,Ka),a(q,Va),a(q,ze),a(ze,Ga),a(q,Ba),p(e,Es,t),p(e,Ce,t),a(Ce,le),a(le,Qa),a(le,Le),a(Le,Wa),a(le,Ja),p(e,qs,t),d(re,e,t),p(e,As,t),p(e,ie,t),a(ie,oe),a(oe,Xa),a(oe,Ie),a(Ie,Ya),a(oe,Za),p(e,Ps,t),d(pe,e,t),p(e,Ts,t),p(e,De,t),a(De,et),p(e,Ss,t),d(he,e,t),p(e,Ms,t),p(e,x,t),a(x,st),a(x,Ne),a(Ne,at),a(x,tt),a(x,os),a(os,nt),a(x,lt),a(x,He),a(He,rt),a(x,it),a(x,ps),a(ps,ot),a(x,pt),p(e,Fs,t),d(fe,e,t),p(e,zs,t),p(e,C,t),a(C,O),a(O,hs),d(ce,hs,null),a(C,ht),a(C,fs),a(fs,ft),p(e,Cs,t),p(e,$,t),a($,ct),a($,Re),a(Re,mt),a($,ut),a($,me),a(me,dt),a($,gt),a($,cs),a(cs,vt),a($,_t),a($,Ue),a(Ue,jt),a($,kt),a($,Oe),a(Oe,$t),a($,xt),p(e,Ls,t),d(ue,e,t),p(e,Is,t),p(e,K,t),a(K,wt),a(K,Ke),a(Ke,yt),a(K,bt),p(e,Ds,t),d(de,e,t),p(e,Ns,t),p(e,V,t),a(V,Et),a(V,Ve),a(Ve,qt),a(V,At),p(e,Hs,t),d(ge,e,t),p(e,Rs,t),p(e,L,t),a(L,G),a(G,ms),d(ve,ms,null),a(L,Pt),a(L,us),a(us,Tt),p(e,Us,t),p(e,B,t),a(B,St),a(B,Ge),a(Ge,Mt),a(B,Ft),p(e,Os,t),p(e,Be,t),a(Be,zt),p(e,Ks,t),d(_e,e,t),p(e,Vs,t),p(e,S,t),a(S,Ct),a(S,je),a(je,Lt),a(S,It),a(S,Qe),a(Qe,Dt),a(S,Nt),p(e,Gs,t),d(ke,e,t),p(e,Bs,t),p(e,Q,t),a(Q,Ht),a(Q,We),a(We,Rt),a(Q,Ut),p(e,Qs,t),d($e,e,t),p(e,Ws,t),p(e,I,t),a(I,W),a(W,ds),d(xe,ds,null),a(I,Ot),a(I,gs),a(gs,Kt),p(e,Js,t),p(e,J,t),a(J,Vt),a(J,Je),a(Je,Gt),a(J,Bt),p(e,Xs,t),p(e,Xe,t),a(Xe,Qt),p(e,Ys,t),p(e,Ye,t),a(Ye,Ze),p(e,Zs,t),d(we,e,t),p(e,ea,t),p(e,D,t),a(D,X),a(X,vs),d(ye,vs,null),a(D,Wt),a(D,_s),a(_s,Jt),p(e,sa,t),p(e,es,t),a(es,Xt),p(e,aa,t),p(e,ss,t),a(ss,Yt),p(e,ta,t),d(be,e,t),p(e,na,t),p(e,Y,t),a(Y,Zt),a(Y,js),a(js,en),a(Y,sn),p(e,la,t),d(Ee,e,t),ra=!0},p(e,[t]){const qe={};t&2&&(qe.$$scope={dirty:t,ctx:e}),R.$set(qe)},i(e){ra||(g(w.$$.fragment,e),g(R.$$.fragment,e),g(ne.$$.fragment,e),g(re.$$.fragment,e),g(pe.$$.fragment,e),g(he.$$.fragment,e),g(fe.$$.fragment,e),g(ce.$$.fragment,e),g(ue.$$.fragment,e),g(de.$$.fragment,e),g(ge.$$.fragment,e),g(ve.$$.fragment,e),g(_e.$$.fragment,e),g(ke.$$.fragment,e),g($e.$$.fragment,e),g(xe.$$.fragment,e),g(we.$$.fragment,e),g(ye.$$.fragment,e),g(be.$$.fragment,e),g(Ee.$$.fragment,e),ra=!0)},o(e){v(w.$$.fragment,e),v(R.$$.fragment,e),v(ne.$$.fragment,e),v(re.$$.fragment,e),v(pe.$$.fragment,e),v(he.$$.fragment,e),v(fe.$$.fragment,e),v(ce.$$.fragment,e),v(ue.$$.fragment,e),v(de.$$.fragment,e),v(ge.$$.fragment,e),v(ve.$$.fragment,e),v(_e.$$.fragment,e),v(ke.$$.fragment,e),v($e.$$.fragment,e),v(xe.$$.fragment,e),v(we.$$.fragment,e),v(ye.$$.fragment,e),v(be.$$.fragment,e),v(Ee.$$.fragment,e),ra=!1},d(e){s(j),e&&s(N),e&&s(k),_(w),e&&s($s),e&&s(E),e&&s(xs),e&&s(T),e&&s(ws),_(R,e),e&&s(ys),e&&s(z),_(ne),e&&s(bs),e&&s(q),e&&s(Es),e&&s(Ce),e&&s(qs),_(re,e),e&&s(As),e&&s(ie),e&&s(Ps),_(pe,e),e&&s(Ts),e&&s(De),e&&s(Ss),_(he,e),e&&s(Ms),e&&s(x),e&&s(Fs),_(fe,e),e&&s(zs),e&&s(C),_(ce),e&&s(Cs),e&&s($),e&&s(Ls),_(ue,e),e&&s(Is),e&&s(K),e&&s(Ds),_(de,e),e&&s(Ns),e&&s(V),e&&s(Hs),_(ge,e),e&&s(Rs),e&&s(L),_(ve),e&&s(Us),e&&s(B),e&&s(Os),e&&s(Be),e&&s(Ks),_(_e,e),e&&s(Vs),e&&s(S),e&&s(Gs),_(ke,e),e&&s(Bs),e&&s(Q),e&&s(Qs),_($e,e),e&&s(Ws),e&&s(I),_(xe),e&&s(Js),e&&s(J),e&&s(Xs),e&&s(Xe),e&&s(Ys),e&&s(Ye),e&&s(Zs),_(we,e),e&&s(ea),e&&s(D),_(ye),e&&s(sa),e&&s(es),e&&s(aa),e&&s(ss),e&&s(ta),_(be,e),e&&s(na),e&&s(Y),e&&s(la),_(Ee,e)}}}const ml={local:"pipelines-for-inference",sections:[{local:"pipeline-usage",sections:[{local:"choose-a-model-and-tokenizer",title:"Choose a model and tokenizer"}],title:"Pipeline usage"},{local:"audio-pipeline",title:"Audio pipeline"},{local:"vision-pipeline",title:"Vision pipeline"},{local:"multimodal-pipeline",title:"Multimodal pipeline"}],title:"Pipelines for inference"};function ul(ks){return pl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class jl extends nl{constructor(j){super();ll(this,j,ul,cl,rl,{})}}export{jl as default,ml as metadata};
