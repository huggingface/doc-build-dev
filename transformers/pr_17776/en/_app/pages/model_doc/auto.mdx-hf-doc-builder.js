import{S as vDt,i as FDt,s as TDt,e as a,k as l,w as F,t as o,M as MDt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as EDt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as KYr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function CDt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,wL,xf,Oe,Qe,Ci,Rn,AL,Pn,Bn,LL,wi,In,yL,Ai,$f,xa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),yf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),wL=o(")."),xf=l(),Oe=a("p"),Qe=o("Likewise, if your "),Ci=a("code"),Rn=o("NewModel"),AL=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),LL=o(`, make sure its
`),wi=a("code"),In=o("config_class"),yL=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),$f=o("NewModelConfig"),xa=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var rS=s(p);m=r(rS,"NewModelConfig"),rS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var tS=s(Ti);yf=r(tS,"model_type"),tS.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var aS=s(Mi);Ei=r(aS,'"new-model"'),aS.forEach(t),wL=r(Ae,")."),Ae.forEach(t),xf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var $a=s(Ci);Rn=r($a,"NewModel"),$a.forEach(t),AL=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var nS=s(Pn);Bn=r(nS,"PreTrainedModel"),nS.forEach(t),LL=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var kf=s(wi);In=r(kf,"config_class"),kf.forEach(t),yL=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var sS=s(Ai);$f=r(sS,"NewModelConfig"),sS.forEach(t),xa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,yf),e(g,at),e(g,Mi),e(Mi,Ei),e(g,wL),b(We,xf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Ci),e(Ci,Rn),e(Oe,AL),e(Oe,Pn),e(Pn,Bn),e(Oe,LL),e(Oe,wi),e(wi,In),e(Oe,yL),e(Oe,Ai),e(Ai,$f),e(Oe,xa)},d(We){We&&t(g),We&&t(xf),We&&t(Oe)}}}function wDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ADt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function yDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function $Dt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ODt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Ot(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EOt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,wL,xf,Oe,Qe,Ci,Rn,AL,Pn,Bn,LL,wi,In,yL,Ai,$f,xa,We,Ae,rS,Li,tS,aS,Co,$a,nS,kf,sS,eQe,jGe,yi,Sf,mte,xL,oQe,gte,rQe,DGe,Nn,tQe,hte,aQe,nQe,pte,sQe,lQe,GGe,$L,OGe,lS,iQe,VGe,Rf,XGe,xi,Pf,_te,kL,dQe,ute,cQe,zGe,wo,SL,fQe,RL,mQe,iS,gQe,hQe,pQe,PL,_Qe,bte,uQe,bQe,vQe,Ar,BL,FQe,vte,TQe,MQe,$i,EQe,Fte,CQe,wQe,Tte,AQe,LQe,yQe,A,Bf,Mte,xQe,$Qe,dS,kQe,SQe,RQe,If,Ete,PQe,BQe,cS,IQe,NQe,qQe,Nf,Cte,jQe,DQe,fS,GQe,OQe,VQe,qf,wte,XQe,zQe,mS,QQe,WQe,HQe,jf,Ate,UQe,JQe,gS,YQe,KQe,ZQe,Df,Lte,eWe,oWe,hS,rWe,tWe,aWe,Gf,yte,nWe,sWe,pS,lWe,iWe,dWe,Of,xte,cWe,fWe,_S,mWe,gWe,hWe,Vf,$te,pWe,_We,uS,uWe,bWe,vWe,Xf,kte,FWe,TWe,bS,MWe,EWe,CWe,zf,Ste,wWe,AWe,vS,LWe,yWe,xWe,Qf,Rte,$We,kWe,FS,SWe,RWe,PWe,Wf,Pte,BWe,IWe,TS,NWe,qWe,jWe,Hf,Bte,DWe,GWe,MS,OWe,VWe,XWe,Uf,Ite,zWe,QWe,ES,WWe,HWe,UWe,Jf,Nte,JWe,YWe,CS,KWe,ZWe,eHe,Yf,qte,oHe,rHe,wS,tHe,aHe,nHe,Kf,jte,sHe,lHe,AS,iHe,dHe,cHe,Zf,Dte,fHe,mHe,LS,gHe,hHe,pHe,em,Gte,_He,uHe,yS,bHe,vHe,FHe,om,Ote,THe,MHe,xS,EHe,CHe,wHe,rm,Vte,AHe,LHe,$S,yHe,xHe,$He,tm,Xte,kHe,SHe,kS,RHe,PHe,BHe,am,zte,IHe,NHe,SS,qHe,jHe,DHe,nm,Qte,GHe,OHe,RS,VHe,XHe,zHe,sm,Wte,QHe,WHe,PS,HHe,UHe,JHe,lm,Hte,YHe,KHe,BS,ZHe,eUe,oUe,im,Ute,rUe,tUe,IS,aUe,nUe,sUe,dm,Jte,lUe,iUe,NS,dUe,cUe,fUe,cm,Yte,mUe,gUe,qS,hUe,pUe,_Ue,fm,Kte,uUe,bUe,jS,vUe,FUe,TUe,mm,Zte,MUe,EUe,DS,CUe,wUe,AUe,gm,eae,LUe,yUe,GS,xUe,$Ue,kUe,hm,oae,SUe,RUe,OS,PUe,BUe,IUe,pm,rae,NUe,qUe,VS,jUe,DUe,GUe,_m,tae,OUe,VUe,XS,XUe,zUe,QUe,um,aae,WUe,HUe,zS,UUe,JUe,YUe,bm,nae,KUe,ZUe,QS,eJe,oJe,rJe,vm,sae,tJe,aJe,WS,nJe,sJe,lJe,Fm,lae,iJe,dJe,HS,cJe,fJe,mJe,Tm,iae,gJe,hJe,US,pJe,_Je,uJe,Mm,dae,bJe,vJe,JS,FJe,TJe,MJe,Em,cae,EJe,CJe,YS,wJe,AJe,LJe,Cm,fae,yJe,xJe,KS,$Je,kJe,SJe,wm,mae,RJe,PJe,ZS,BJe,IJe,NJe,Am,gae,qJe,jJe,eR,DJe,GJe,OJe,Lm,hae,VJe,XJe,oR,zJe,QJe,WJe,ym,pae,HJe,UJe,rR,JJe,YJe,KJe,xm,_ae,ZJe,eYe,tR,oYe,rYe,tYe,$m,uae,aYe,nYe,aR,sYe,lYe,iYe,km,bae,dYe,cYe,nR,fYe,mYe,gYe,Sm,vae,hYe,pYe,sR,_Ye,uYe,bYe,Rm,Fae,vYe,FYe,lR,TYe,MYe,EYe,Pm,Tae,CYe,wYe,iR,AYe,LYe,yYe,Bm,Mae,xYe,$Ye,dR,kYe,SYe,RYe,Im,Eae,PYe,BYe,cR,IYe,NYe,qYe,Nm,Cae,jYe,DYe,fR,GYe,OYe,VYe,qm,wae,XYe,zYe,mR,QYe,WYe,HYe,jm,Aae,UYe,JYe,gR,YYe,KYe,ZYe,Dm,Lae,eKe,oKe,hR,rKe,tKe,aKe,Gm,yae,nKe,sKe,pR,lKe,iKe,dKe,Om,xae,cKe,fKe,_R,mKe,gKe,hKe,Vm,$ae,pKe,_Ke,uR,uKe,bKe,vKe,Xm,kae,FKe,TKe,bR,MKe,EKe,CKe,zm,Sae,wKe,AKe,vR,LKe,yKe,xKe,Qm,Rae,$Ke,kKe,FR,SKe,RKe,PKe,Wm,Pae,BKe,IKe,TR,NKe,qKe,jKe,Hm,Bae,DKe,GKe,MR,OKe,VKe,XKe,Um,Iae,zKe,QKe,ER,WKe,HKe,UKe,Jm,Nae,JKe,YKe,CR,KKe,ZKe,eZe,Ym,qae,oZe,rZe,wR,tZe,aZe,nZe,Km,jae,sZe,lZe,AR,iZe,dZe,cZe,Zm,Dae,fZe,mZe,LR,gZe,hZe,pZe,eg,Gae,_Ze,uZe,yR,bZe,vZe,FZe,og,Oae,TZe,MZe,xR,EZe,CZe,wZe,rg,Vae,AZe,LZe,$R,yZe,xZe,$Ze,tg,Xae,kZe,SZe,kR,RZe,PZe,BZe,ag,zae,IZe,NZe,SR,qZe,jZe,DZe,ng,Qae,GZe,OZe,RR,VZe,XZe,zZe,sg,Wae,QZe,WZe,PR,HZe,UZe,JZe,lg,Hae,YZe,KZe,BR,ZZe,eeo,oeo,ig,Uae,reo,teo,IR,aeo,neo,seo,dg,Jae,leo,ieo,NR,deo,ceo,feo,cg,Yae,meo,geo,qR,heo,peo,_eo,fg,Kae,ueo,beo,jR,veo,Feo,Teo,mg,Zae,Meo,Eeo,DR,Ceo,weo,Aeo,gg,ene,Leo,yeo,GR,xeo,$eo,keo,hg,one,Seo,Reo,OR,Peo,Beo,Ieo,pg,rne,Neo,qeo,VR,jeo,Deo,Geo,_g,tne,Oeo,Veo,XR,Xeo,zeo,Qeo,ug,ane,Weo,Heo,zR,Ueo,Jeo,Yeo,bg,nne,Keo,Zeo,QR,eoo,ooo,roo,vg,sne,too,aoo,WR,noo,soo,loo,Fg,lne,ioo,doo,HR,coo,foo,moo,Tg,ine,goo,hoo,UR,poo,_oo,uoo,Mg,dne,boo,voo,JR,Foo,Too,Moo,Eg,cne,Eoo,Coo,YR,woo,Aoo,Loo,Cg,fne,yoo,xoo,KR,$oo,koo,Soo,wg,mne,Roo,Poo,ZR,Boo,Ioo,Noo,Ag,gne,qoo,joo,eP,Doo,Goo,Ooo,Lg,hne,Voo,Xoo,oP,zoo,Qoo,Woo,yg,pne,Hoo,Uoo,rP,Joo,Yoo,Koo,xg,_ne,Zoo,ero,tP,oro,rro,tro,$g,une,aro,nro,aP,sro,lro,iro,kg,bne,dro,cro,nP,fro,mro,gro,Sg,vne,hro,pro,sP,_ro,uro,bro,Rg,Fne,vro,Fro,lP,Tro,Mro,Ero,Pg,Tne,Cro,wro,iP,Aro,Lro,yro,Bg,Mne,xro,$ro,dP,kro,Sro,Rro,Ig,Ene,Pro,Bro,cP,Iro,Nro,qro,Ng,Cne,jro,Dro,fP,Gro,Oro,Vro,qg,wne,Xro,zro,mP,Qro,Wro,Hro,jg,Ane,Uro,Jro,gP,Yro,Kro,Zro,Dg,Lne,eto,oto,hP,rto,tto,ato,Gg,nto,Og,IL,sto,yne,lto,QGe,ki,Vg,xne,NL,ito,$ne,dto,WGe,Ao,qL,cto,jL,fto,pP,mto,gto,hto,DL,pto,kne,_to,uto,bto,Lr,GL,vto,Sne,Fto,Tto,ka,Mto,Rne,Eto,Cto,Pne,wto,Ato,Bne,Lto,yto,xto,k,qn,Ine,$to,kto,_P,Sto,Rto,uP,Pto,Bto,Ito,jn,Nne,Nto,qto,bP,jto,Dto,vP,Gto,Oto,Vto,Dn,qne,Xto,zto,FP,Qto,Wto,TP,Hto,Uto,Jto,Xg,jne,Yto,Kto,MP,Zto,eao,oao,Gn,Dne,rao,tao,EP,aao,nao,CP,sao,lao,iao,zg,Gne,dao,cao,wP,fao,mao,gao,Qg,One,hao,pao,AP,_ao,uao,bao,Wg,Vne,vao,Fao,LP,Tao,Mao,Eao,On,Xne,Cao,wao,yP,Aao,Lao,xP,yao,xao,$ao,Vn,zne,kao,Sao,$P,Rao,Pao,kP,Bao,Iao,Nao,Xn,Qne,qao,jao,SP,Dao,Gao,RP,Oao,Vao,Xao,Hg,Wne,zao,Qao,PP,Wao,Hao,Uao,Ug,Hne,Jao,Yao,BP,Kao,Zao,eno,Jg,Une,ono,rno,IP,tno,ano,nno,zn,Jne,sno,lno,NP,ino,dno,qP,cno,fno,mno,Yg,Yne,gno,hno,jP,pno,_no,uno,Qn,Kne,bno,vno,DP,Fno,Tno,GP,Mno,Eno,Cno,Wn,Zne,wno,Ano,OP,Lno,yno,VP,xno,$no,kno,Hn,ese,Sno,Rno,XP,Pno,Bno,zP,Ino,Nno,qno,Kg,ose,jno,Dno,QP,Gno,Ono,Vno,Un,rse,Xno,zno,WP,Qno,Wno,HP,Hno,Uno,Jno,Jn,tse,Yno,Kno,UP,Zno,eso,JP,oso,rso,tso,Yn,ase,aso,nso,YP,sso,lso,KP,iso,dso,cso,Kn,nse,fso,mso,ZP,gso,hso,eB,pso,_so,uso,Zn,sse,bso,vso,oB,Fso,Tso,rB,Mso,Eso,Cso,es,lse,wso,Aso,tB,Lso,yso,aB,xso,$so,kso,Zg,ise,Sso,Rso,nB,Pso,Bso,Iso,os,dse,Nso,qso,sB,jso,Dso,lB,Gso,Oso,Vso,eh,cse,Xso,zso,iB,Qso,Wso,Hso,rs,fse,Uso,Jso,dB,Yso,Kso,cB,Zso,elo,olo,ts,mse,rlo,tlo,fB,alo,nlo,mB,slo,llo,ilo,as,gse,dlo,clo,gB,flo,mlo,hB,glo,hlo,plo,oh,hse,_lo,ulo,pB,blo,vlo,Flo,ns,pse,Tlo,Mlo,_B,Elo,Clo,uB,wlo,Alo,Llo,ss,_se,ylo,xlo,bB,$lo,klo,vB,Slo,Rlo,Plo,rh,use,Blo,Ilo,FB,Nlo,qlo,jlo,ls,bse,Dlo,Glo,TB,Olo,Vlo,MB,Xlo,zlo,Qlo,is,vse,Wlo,Hlo,EB,Ulo,Jlo,CB,Ylo,Klo,Zlo,ds,Fse,eio,oio,wB,rio,tio,AB,aio,nio,sio,cs,Tse,lio,iio,LB,dio,cio,yB,fio,mio,gio,fs,Mse,hio,pio,xB,_io,uio,$B,bio,vio,Fio,ms,Ese,Tio,Mio,kB,Eio,Cio,SB,wio,Aio,Lio,gs,Cse,yio,xio,RB,$io,kio,PB,Sio,Rio,Pio,hs,wse,Bio,Iio,BB,Nio,qio,IB,jio,Dio,Gio,th,Ase,Oio,Vio,NB,Xio,zio,Qio,ps,Lse,Wio,Hio,qB,Uio,Jio,jB,Yio,Kio,Zio,ah,yse,edo,odo,DB,rdo,tdo,ado,nh,xse,ndo,sdo,GB,ldo,ido,ddo,_s,$se,cdo,fdo,OB,mdo,gdo,VB,hdo,pdo,_do,us,kse,udo,bdo,XB,vdo,Fdo,zB,Tdo,Mdo,Edo,bs,Sse,Cdo,wdo,QB,Ado,Ldo,WB,ydo,xdo,$do,sh,Rse,kdo,Sdo,HB,Rdo,Pdo,Bdo,vs,Pse,Ido,Ndo,UB,qdo,jdo,JB,Ddo,Gdo,Odo,Fs,Bse,Vdo,Xdo,YB,zdo,Qdo,KB,Wdo,Hdo,Udo,Ts,Ise,Jdo,Ydo,ZB,Kdo,Zdo,eI,eco,oco,rco,Ms,Nse,tco,aco,oI,nco,sco,rI,lco,ico,dco,Es,qse,cco,fco,tI,mco,gco,aI,hco,pco,_co,Cs,jse,uco,bco,nI,vco,Fco,sI,Tco,Mco,Eco,lh,Dse,Cco,wco,lI,Aco,Lco,yco,ws,Gse,xco,$co,iI,kco,Sco,dI,Rco,Pco,Bco,ih,Ose,Ico,Nco,cI,qco,jco,Dco,dh,Vse,Gco,Oco,fI,Vco,Xco,zco,ch,Xse,Qco,Wco,mI,Hco,Uco,Jco,fh,zse,Yco,Kco,gI,Zco,efo,ofo,As,Qse,rfo,tfo,hI,afo,nfo,pI,sfo,lfo,ifo,mh,Wse,dfo,cfo,_I,ffo,mfo,gfo,Ls,Hse,hfo,pfo,uI,_fo,ufo,bI,bfo,vfo,Ffo,ys,Use,Tfo,Mfo,vI,Efo,Cfo,FI,wfo,Afo,Lfo,xs,Jse,yfo,xfo,TI,$fo,kfo,MI,Sfo,Rfo,Pfo,$s,Yse,Bfo,Ifo,EI,Nfo,qfo,CI,jfo,Dfo,Gfo,ks,Kse,Ofo,Vfo,wI,Xfo,zfo,AI,Qfo,Wfo,Hfo,Ss,Zse,Ufo,Jfo,LI,Yfo,Kfo,yI,Zfo,emo,omo,gh,ele,rmo,tmo,xI,amo,nmo,smo,hh,ole,lmo,imo,$I,dmo,cmo,fmo,Rs,rle,mmo,gmo,kI,hmo,pmo,SI,_mo,umo,bmo,Ps,tle,vmo,Fmo,RI,Tmo,Mmo,PI,Emo,Cmo,wmo,Bs,ale,Amo,Lmo,BI,ymo,xmo,II,$mo,kmo,Smo,ph,nle,Rmo,Pmo,NI,Bmo,Imo,Nmo,_h,sle,qmo,jmo,qI,Dmo,Gmo,Omo,uh,lle,Vmo,Xmo,jI,zmo,Qmo,Wmo,Is,ile,Hmo,Umo,DI,Jmo,Ymo,GI,Kmo,Zmo,ego,Ns,dle,ogo,rgo,OI,tgo,ago,VI,ngo,sgo,lgo,bh,cle,igo,dgo,XI,cgo,fgo,mgo,vh,fle,ggo,hgo,zI,pgo,_go,ugo,Fh,mle,bgo,vgo,QI,Fgo,Tgo,Mgo,qs,gle,Ego,Cgo,WI,wgo,Ago,HI,Lgo,ygo,xgo,Th,hle,$go,kgo,UI,Sgo,Rgo,Pgo,Mh,ple,Bgo,Igo,JI,Ngo,qgo,jgo,js,_le,Dgo,Ggo,YI,Ogo,Vgo,KI,Xgo,zgo,Qgo,Ds,ule,Wgo,Hgo,ZI,Ugo,Jgo,eN,Ygo,Kgo,Zgo,Gs,ble,eho,oho,oN,rho,tho,rN,aho,nho,sho,Os,vle,lho,iho,tN,dho,cho,aN,fho,mho,gho,Eh,hho,Ch,OL,pho,Fle,_ho,HGe,Si,wh,Tle,VL,uho,Mle,bho,UGe,Lo,XL,vho,zL,Fho,nN,Tho,Mho,Eho,QL,Cho,Ele,who,Aho,Lho,He,WL,yho,Cle,xho,$ho,Sa,kho,wle,Sho,Rho,Ale,Pho,Bho,Lle,Iho,Nho,qho,Y,Ah,yle,jho,Dho,sN,Gho,Oho,Vho,Lh,xle,Xho,zho,lN,Qho,Who,Hho,yh,$le,Uho,Jho,iN,Yho,Kho,Zho,xh,kle,epo,opo,dN,rpo,tpo,apo,$h,Sle,npo,spo,cN,lpo,ipo,dpo,kh,Rle,cpo,fpo,fN,mpo,gpo,hpo,Sh,Ple,ppo,_po,mN,upo,bpo,vpo,Rh,Ble,Fpo,Tpo,gN,Mpo,Epo,Cpo,Ph,Ile,wpo,Apo,hN,Lpo,ypo,xpo,Bh,Nle,$po,kpo,pN,Spo,Rpo,Ppo,Ih,qle,Bpo,Ipo,_N,Npo,qpo,jpo,Nh,jle,Dpo,Gpo,uN,Opo,Vpo,Xpo,qh,Dle,zpo,Qpo,bN,Wpo,Hpo,Upo,jh,Gle,Jpo,Ypo,vN,Kpo,Zpo,e_o,Dh,Ole,o_o,r_o,FN,t_o,a_o,n_o,Gh,Vle,s_o,l_o,TN,i_o,d_o,c_o,Oh,Xle,f_o,m_o,MN,g_o,h_o,p_o,Vh,zle,__o,u_o,EN,b_o,v_o,F_o,Xh,Qle,T_o,M_o,CN,E_o,C_o,w_o,zh,Wle,A_o,L_o,wN,y_o,x_o,$_o,Qh,Hle,k_o,S_o,AN,R_o,P_o,B_o,Wh,Ule,I_o,N_o,LN,q_o,j_o,D_o,Hh,Jle,G_o,O_o,yN,V_o,X_o,z_o,Uh,Yle,Q_o,W_o,xN,H_o,U_o,J_o,Jh,Kle,Y_o,K_o,$N,Z_o,euo,ouo,Yh,Zle,ruo,tuo,kN,auo,nuo,suo,Kh,eie,luo,iuo,SN,duo,cuo,fuo,Zh,oie,muo,guo,RN,huo,puo,_uo,ep,rie,uuo,buo,PN,vuo,Fuo,Tuo,op,tie,Muo,Euo,BN,Cuo,wuo,Auo,rp,aie,Luo,yuo,IN,xuo,$uo,kuo,tp,nie,Suo,Ruo,NN,Puo,Buo,Iuo,ap,Nuo,np,quo,sp,HL,juo,sie,Duo,JGe,Ri,lp,lie,UL,Guo,iie,Ouo,YGe,yo,JL,Vuo,YL,Xuo,qN,zuo,Quo,Wuo,KL,Huo,die,Uuo,Juo,Yuo,Ue,ZL,Kuo,cie,Zuo,e7o,Pi,o7o,fie,r7o,t7o,mie,a7o,n7o,s7o,he,ip,gie,l7o,i7o,jN,d7o,c7o,f7o,dp,hie,m7o,g7o,pie,h7o,p7o,_7o,cp,_ie,u7o,b7o,DN,v7o,F7o,T7o,fp,uie,M7o,E7o,GN,C7o,w7o,A7o,mp,bie,L7o,y7o,ON,x7o,$7o,k7o,gp,vie,S7o,R7o,VN,P7o,B7o,I7o,hp,Fie,N7o,q7o,XN,j7o,D7o,G7o,pp,Tie,O7o,V7o,zN,X7o,z7o,Q7o,_p,Mie,W7o,H7o,QN,U7o,J7o,Y7o,up,Eie,K7o,Z7o,WN,e1o,o1o,r1o,bp,Cie,t1o,a1o,HN,n1o,s1o,l1o,vp,wie,i1o,d1o,UN,c1o,f1o,m1o,Fp,Aie,g1o,h1o,JN,p1o,_1o,u1o,Tp,Lie,b1o,v1o,YN,F1o,T1o,M1o,Mp,yie,E1o,C1o,KN,w1o,A1o,L1o,Ep,xie,y1o,x1o,ZN,$1o,k1o,S1o,Cp,$ie,R1o,P1o,eq,B1o,I1o,N1o,wp,q1o,Ap,j1o,Lp,ey,D1o,kie,G1o,KGe,Bi,yp,Sie,oy,O1o,Rie,V1o,ZGe,xo,ry,X1o,Ii,z1o,oq,Q1o,W1o,rq,H1o,U1o,J1o,ty,Y1o,Pie,K1o,Z1o,e2o,nt,ay,o2o,Bie,r2o,t2o,Ni,a2o,Iie,n2o,s2o,tq,l2o,i2o,d2o,xp,c2o,Je,ny,f2o,Nie,m2o,g2o,Ra,h2o,qie,p2o,_2o,jie,u2o,b2o,Die,v2o,F2o,T2o,y,$p,Gie,M2o,E2o,aq,C2o,w2o,A2o,kp,Oie,L2o,y2o,nq,x2o,$2o,k2o,Sp,Vie,S2o,R2o,sq,P2o,B2o,I2o,Rp,Xie,N2o,q2o,lq,j2o,D2o,G2o,Pp,zie,O2o,V2o,iq,X2o,z2o,Q2o,Bp,Qie,W2o,H2o,dq,U2o,J2o,Y2o,Ip,Wie,K2o,Z2o,cq,ebo,obo,rbo,Np,Hie,tbo,abo,fq,nbo,sbo,lbo,qp,Uie,ibo,dbo,mq,cbo,fbo,mbo,jp,Jie,gbo,hbo,gq,pbo,_bo,ubo,Dp,Yie,bbo,vbo,hq,Fbo,Tbo,Mbo,Gp,Kie,Ebo,Cbo,pq,wbo,Abo,Lbo,Op,Zie,ybo,xbo,_q,$bo,kbo,Sbo,Vp,ede,Rbo,Pbo,uq,Bbo,Ibo,Nbo,Xp,ode,qbo,jbo,bq,Dbo,Gbo,Obo,zp,rde,Vbo,Xbo,vq,zbo,Qbo,Wbo,Qp,tde,Hbo,Ubo,Fq,Jbo,Ybo,Kbo,Wp,ade,Zbo,evo,Tq,ovo,rvo,tvo,Hp,nde,avo,nvo,Mq,svo,lvo,ivo,Up,sde,dvo,cvo,Eq,fvo,mvo,gvo,Jp,lde,hvo,pvo,Cq,_vo,uvo,bvo,Yp,ide,vvo,Fvo,wq,Tvo,Mvo,Evo,Kp,dde,Cvo,wvo,Aq,Avo,Lvo,yvo,Zp,cde,xvo,$vo,Lq,kvo,Svo,Rvo,e_,fde,Pvo,Bvo,yq,Ivo,Nvo,qvo,o_,mde,jvo,Dvo,xq,Gvo,Ovo,Vvo,r_,gde,Xvo,zvo,$q,Qvo,Wvo,Hvo,t_,hde,Uvo,Jvo,kq,Yvo,Kvo,Zvo,a_,pde,eFo,oFo,Sq,rFo,tFo,aFo,n_,_de,nFo,sFo,Rq,lFo,iFo,dFo,s_,ude,cFo,fFo,Pq,mFo,gFo,hFo,l_,bde,pFo,_Fo,Bq,uFo,bFo,vFo,i_,vde,FFo,TFo,Iq,MFo,EFo,CFo,Vs,Fde,wFo,AFo,Nq,LFo,yFo,qq,xFo,$Fo,kFo,d_,Tde,SFo,RFo,jq,PFo,BFo,IFo,c_,Mde,NFo,qFo,Dq,jFo,DFo,GFo,f_,Ede,OFo,VFo,Gq,XFo,zFo,QFo,m_,Cde,WFo,HFo,Oq,UFo,JFo,YFo,g_,wde,KFo,ZFo,Vq,e6o,o6o,r6o,h_,Ade,t6o,a6o,Xq,n6o,s6o,l6o,p_,Lde,i6o,d6o,zq,c6o,f6o,m6o,__,yde,g6o,h6o,Qq,p6o,_6o,u6o,u_,xde,b6o,v6o,Wq,F6o,T6o,M6o,b_,$de,E6o,C6o,Hq,w6o,A6o,L6o,v_,kde,y6o,x6o,Uq,$6o,k6o,S6o,F_,Sde,R6o,P6o,Jq,B6o,I6o,N6o,T_,Rde,q6o,j6o,Yq,D6o,G6o,O6o,M_,Pde,V6o,X6o,Kq,z6o,Q6o,W6o,E_,Bde,H6o,U6o,Zq,J6o,Y6o,K6o,C_,Ide,Z6o,eTo,ej,oTo,rTo,tTo,w_,Nde,aTo,nTo,oj,sTo,lTo,iTo,A_,qde,dTo,cTo,rj,fTo,mTo,gTo,L_,jde,hTo,pTo,tj,_To,uTo,bTo,y_,Dde,vTo,FTo,aj,TTo,MTo,ETo,x_,Gde,CTo,wTo,nj,ATo,LTo,yTo,$_,Ode,xTo,$To,sj,kTo,STo,RTo,k_,Vde,PTo,BTo,lj,ITo,NTo,qTo,S_,Xde,jTo,DTo,ij,GTo,OTo,VTo,R_,zde,XTo,zTo,dj,QTo,WTo,HTo,P_,Qde,UTo,JTo,cj,YTo,KTo,ZTo,B_,Wde,eMo,oMo,fj,rMo,tMo,aMo,I_,Hde,nMo,sMo,mj,lMo,iMo,dMo,N_,Ude,cMo,fMo,gj,mMo,gMo,hMo,q_,Jde,pMo,_Mo,hj,uMo,bMo,vMo,j_,Yde,FMo,TMo,pj,MMo,EMo,CMo,D_,Kde,wMo,AMo,_j,LMo,yMo,xMo,G_,Zde,$Mo,kMo,uj,SMo,RMo,PMo,O_,ece,BMo,IMo,bj,NMo,qMo,jMo,V_,oce,DMo,GMo,vj,OMo,VMo,XMo,X_,rce,zMo,QMo,Fj,WMo,HMo,UMo,z_,tce,JMo,YMo,Tj,KMo,ZMo,eEo,Q_,ace,oEo,rEo,Mj,tEo,aEo,nEo,W_,nce,sEo,lEo,Ej,iEo,dEo,cEo,H_,sce,fEo,mEo,Cj,gEo,hEo,pEo,U_,lce,_Eo,uEo,wj,bEo,vEo,FEo,J_,ice,TEo,MEo,Aj,EEo,CEo,wEo,Y_,dce,AEo,LEo,Lj,yEo,xEo,$Eo,K_,cce,kEo,SEo,yj,REo,PEo,BEo,Z_,fce,IEo,NEo,xj,qEo,jEo,DEo,eu,mce,GEo,OEo,$j,VEo,XEo,zEo,ou,gce,QEo,WEo,kj,HEo,UEo,JEo,ru,hce,YEo,KEo,Sj,ZEo,e4o,o4o,tu,pce,r4o,t4o,Rj,a4o,n4o,s4o,au,_ce,l4o,i4o,Pj,d4o,c4o,f4o,nu,uce,m4o,g4o,Bj,h4o,p4o,_4o,su,bce,u4o,b4o,Ij,v4o,F4o,T4o,lu,vce,M4o,E4o,Nj,C4o,w4o,A4o,iu,Fce,L4o,y4o,qj,x4o,$4o,k4o,du,Tce,S4o,R4o,jj,P4o,B4o,I4o,cu,Mce,N4o,q4o,Dj,j4o,D4o,G4o,fu,Ece,O4o,V4o,Gj,X4o,z4o,Q4o,mu,Cce,W4o,H4o,Oj,U4o,J4o,Y4o,gu,wce,K4o,Z4o,Vj,eCo,oCo,rCo,hu,Ace,tCo,aCo,Xj,nCo,sCo,lCo,pu,Lce,iCo,dCo,zj,cCo,fCo,mCo,_u,yce,gCo,hCo,Qj,pCo,_Co,uCo,uu,xce,bCo,vCo,Wj,FCo,TCo,MCo,bu,$ce,ECo,CCo,Hj,wCo,ACo,LCo,vu,kce,yCo,xCo,Uj,$Co,kCo,SCo,Fu,Sce,RCo,PCo,Jj,BCo,ICo,NCo,Tu,Rce,qCo,jCo,Yj,DCo,GCo,OCo,Mu,Pce,VCo,XCo,Kj,zCo,QCo,WCo,Eu,Bce,HCo,UCo,Zj,JCo,YCo,KCo,Cu,Ice,ZCo,e5o,eD,o5o,r5o,t5o,wu,Nce,a5o,n5o,oD,s5o,l5o,i5o,Au,qce,d5o,c5o,rD,f5o,m5o,g5o,Lu,jce,h5o,p5o,tD,_5o,u5o,b5o,yu,v5o,Dce,F5o,T5o,Gce,M5o,E5o,xu,eOe,qi,$u,Oce,sy,C5o,Vce,w5o,oOe,$o,ly,A5o,ji,L5o,aD,y5o,x5o,nD,$5o,k5o,S5o,iy,R5o,Xce,P5o,B5o,I5o,st,dy,N5o,zce,q5o,j5o,Di,D5o,Qce,G5o,O5o,sD,V5o,X5o,z5o,ku,Q5o,Ye,cy,W5o,Wce,H5o,U5o,Pa,J5o,Hce,Y5o,K5o,Uce,Z5o,e3o,Jce,o3o,r3o,t3o,G,Su,Yce,a3o,n3o,lD,s3o,l3o,i3o,Ru,Kce,d3o,c3o,iD,f3o,m3o,g3o,Pu,Zce,h3o,p3o,dD,_3o,u3o,b3o,Bu,efe,v3o,F3o,cD,T3o,M3o,E3o,Iu,ofe,C3o,w3o,fD,A3o,L3o,y3o,Nu,rfe,x3o,$3o,mD,k3o,S3o,R3o,qu,tfe,P3o,B3o,gD,I3o,N3o,q3o,ju,afe,j3o,D3o,hD,G3o,O3o,V3o,Du,nfe,X3o,z3o,pD,Q3o,W3o,H3o,Gu,sfe,U3o,J3o,_D,Y3o,K3o,Z3o,Ou,lfe,e0o,o0o,uD,r0o,t0o,a0o,Vu,ife,n0o,s0o,bD,l0o,i0o,d0o,Xu,dfe,c0o,f0o,vD,m0o,g0o,h0o,zu,cfe,p0o,_0o,FD,u0o,b0o,v0o,Qu,ffe,F0o,T0o,TD,M0o,E0o,C0o,Wu,mfe,w0o,A0o,MD,L0o,y0o,x0o,Hu,gfe,$0o,k0o,ED,S0o,R0o,P0o,Uu,hfe,B0o,I0o,CD,N0o,q0o,j0o,Ju,pfe,D0o,G0o,wD,O0o,V0o,X0o,Yu,_fe,z0o,Q0o,AD,W0o,H0o,U0o,Ku,ufe,J0o,Y0o,LD,K0o,Z0o,ewo,Zu,bfe,owo,rwo,yD,two,awo,nwo,e7,vfe,swo,lwo,xD,iwo,dwo,cwo,o7,Ffe,fwo,mwo,$D,gwo,hwo,pwo,r7,Tfe,_wo,uwo,kD,bwo,vwo,Fwo,t7,Mfe,Two,Mwo,SD,Ewo,Cwo,wwo,a7,Efe,Awo,Lwo,RD,ywo,xwo,$wo,n7,Cfe,kwo,Swo,PD,Rwo,Pwo,Bwo,s7,wfe,Iwo,Nwo,BD,qwo,jwo,Dwo,l7,Afe,Gwo,Owo,ID,Vwo,Xwo,zwo,i7,Lfe,Qwo,Wwo,ND,Hwo,Uwo,Jwo,d7,yfe,Ywo,Kwo,qD,Zwo,eAo,oAo,c7,xfe,rAo,tAo,jD,aAo,nAo,sAo,f7,$fe,lAo,iAo,DD,dAo,cAo,fAo,m7,kfe,mAo,gAo,GD,hAo,pAo,_Ao,g7,Sfe,uAo,bAo,OD,vAo,FAo,TAo,h7,Rfe,MAo,EAo,VD,CAo,wAo,AAo,p7,Pfe,LAo,yAo,XD,xAo,$Ao,kAo,_7,Bfe,SAo,RAo,zD,PAo,BAo,IAo,u7,Ife,NAo,qAo,QD,jAo,DAo,GAo,b7,Nfe,OAo,VAo,WD,XAo,zAo,QAo,v7,qfe,WAo,HAo,HD,UAo,JAo,YAo,F7,jfe,KAo,ZAo,UD,eLo,oLo,rLo,T7,Dfe,tLo,aLo,JD,nLo,sLo,lLo,M7,iLo,Gfe,dLo,cLo,Ofe,fLo,mLo,E7,rOe,Gi,C7,Vfe,fy,gLo,Xfe,hLo,tOe,ko,my,pLo,Oi,_Lo,YD,uLo,bLo,KD,vLo,FLo,TLo,gy,MLo,zfe,ELo,CLo,wLo,lt,hy,ALo,Qfe,LLo,yLo,Vi,xLo,Wfe,$Lo,kLo,ZD,SLo,RLo,PLo,w7,BLo,Ke,py,ILo,Hfe,NLo,qLo,Ba,jLo,Ufe,DLo,GLo,Jfe,OLo,VLo,Yfe,XLo,zLo,QLo,z,A7,Kfe,WLo,HLo,eG,ULo,JLo,YLo,L7,Zfe,KLo,ZLo,oG,eyo,oyo,ryo,y7,eme,tyo,ayo,rG,nyo,syo,lyo,x7,ome,iyo,dyo,tG,cyo,fyo,myo,$7,rme,gyo,hyo,aG,pyo,_yo,uyo,k7,tme,byo,vyo,nG,Fyo,Tyo,Myo,S7,ame,Eyo,Cyo,sG,wyo,Ayo,Lyo,R7,nme,yyo,xyo,lG,$yo,kyo,Syo,P7,sme,Ryo,Pyo,iG,Byo,Iyo,Nyo,B7,lme,qyo,jyo,dG,Dyo,Gyo,Oyo,I7,ime,Vyo,Xyo,cG,zyo,Qyo,Wyo,N7,dme,Hyo,Uyo,fG,Jyo,Yyo,Kyo,q7,cme,Zyo,e8o,mG,o8o,r8o,t8o,j7,fme,a8o,n8o,gG,s8o,l8o,i8o,D7,mme,d8o,c8o,hG,f8o,m8o,g8o,G7,gme,h8o,p8o,pG,_8o,u8o,b8o,O7,hme,v8o,F8o,_G,T8o,M8o,E8o,V7,pme,C8o,w8o,uG,A8o,L8o,y8o,X7,_me,x8o,$8o,bG,k8o,S8o,R8o,z7,ume,P8o,B8o,vG,I8o,N8o,q8o,Q7,bme,j8o,D8o,FG,G8o,O8o,V8o,W7,vme,X8o,z8o,TG,Q8o,W8o,H8o,H7,Fme,U8o,J8o,MG,Y8o,K8o,Z8o,U7,Tme,e9o,o9o,EG,r9o,t9o,a9o,J7,Mme,n9o,s9o,CG,l9o,i9o,d9o,Y7,Eme,c9o,f9o,wG,m9o,g9o,h9o,K7,Cme,p9o,_9o,AG,u9o,b9o,v9o,Z7,wme,F9o,T9o,LG,M9o,E9o,C9o,e1,Ame,w9o,A9o,yG,L9o,y9o,x9o,o1,Lme,$9o,k9o,xG,S9o,R9o,P9o,r1,yme,B9o,I9o,$G,N9o,q9o,j9o,t1,xme,D9o,G9o,kG,O9o,V9o,X9o,a1,$me,z9o,Q9o,SG,W9o,H9o,U9o,n1,kme,J9o,Y9o,RG,K9o,Z9o,exo,s1,Sme,oxo,rxo,PG,txo,axo,nxo,l1,Rme,sxo,lxo,BG,ixo,dxo,cxo,i1,Pme,fxo,mxo,IG,gxo,hxo,pxo,d1,Bme,_xo,uxo,NG,bxo,vxo,Fxo,c1,Txo,Ime,Mxo,Exo,Nme,Cxo,wxo,f1,aOe,Xi,m1,qme,_y,Axo,jme,Lxo,nOe,So,uy,yxo,zi,xxo,qG,$xo,kxo,jG,Sxo,Rxo,Pxo,by,Bxo,Dme,Ixo,Nxo,qxo,it,vy,jxo,Gme,Dxo,Gxo,Qi,Oxo,Ome,Vxo,Xxo,DG,zxo,Qxo,Wxo,g1,Hxo,Ze,Fy,Uxo,Vme,Jxo,Yxo,Ia,Kxo,Xme,Zxo,e$o,zme,o$o,r$o,Qme,t$o,a$o,n$o,Q,h1,Wme,s$o,l$o,GG,i$o,d$o,c$o,p1,Hme,f$o,m$o,OG,g$o,h$o,p$o,_1,Ume,_$o,u$o,VG,b$o,v$o,F$o,u1,Jme,T$o,M$o,XG,E$o,C$o,w$o,b1,Yme,A$o,L$o,zG,y$o,x$o,$$o,v1,Kme,k$o,S$o,QG,R$o,P$o,B$o,F1,Zme,I$o,N$o,WG,q$o,j$o,D$o,T1,ege,G$o,O$o,HG,V$o,X$o,z$o,M1,oge,Q$o,W$o,UG,H$o,U$o,J$o,E1,rge,Y$o,K$o,JG,Z$o,eko,oko,C1,tge,rko,tko,YG,ako,nko,sko,w1,age,lko,iko,KG,dko,cko,fko,A1,nge,mko,gko,ZG,hko,pko,_ko,L1,sge,uko,bko,eO,vko,Fko,Tko,y1,lge,Mko,Eko,oO,Cko,wko,Ako,x1,ige,Lko,yko,rO,xko,$ko,kko,$1,dge,Sko,Rko,tO,Pko,Bko,Iko,k1,cge,Nko,qko,aO,jko,Dko,Gko,S1,fge,Oko,Vko,nO,Xko,zko,Qko,R1,mge,Wko,Hko,sO,Uko,Jko,Yko,P1,gge,Kko,Zko,lO,eSo,oSo,rSo,B1,hge,tSo,aSo,iO,nSo,sSo,lSo,I1,pge,iSo,dSo,dO,cSo,fSo,mSo,N1,_ge,gSo,hSo,cO,pSo,_So,uSo,q1,uge,bSo,vSo,fO,FSo,TSo,MSo,j1,bge,ESo,CSo,mO,wSo,ASo,LSo,D1,vge,ySo,xSo,gO,$So,kSo,SSo,G1,Fge,RSo,PSo,hO,BSo,ISo,NSo,O1,Tge,qSo,jSo,pO,DSo,GSo,OSo,V1,Mge,VSo,XSo,_O,zSo,QSo,WSo,X1,Ege,HSo,USo,uO,JSo,YSo,KSo,z1,Cge,ZSo,eRo,bO,oRo,rRo,tRo,Q1,wge,aRo,nRo,Age,sRo,lRo,iRo,W1,Lge,dRo,cRo,vO,fRo,mRo,gRo,H1,yge,hRo,pRo,FO,_Ro,uRo,bRo,U1,xge,vRo,FRo,TO,TRo,MRo,ERo,J1,$ge,CRo,wRo,MO,ARo,LRo,yRo,Y1,xRo,kge,$Ro,kRo,Sge,SRo,RRo,K1,sOe,Wi,Z1,Rge,Ty,PRo,Pge,BRo,lOe,Ro,My,IRo,Hi,NRo,EO,qRo,jRo,CO,DRo,GRo,ORo,Ey,VRo,Bge,XRo,zRo,QRo,dt,Cy,WRo,Ige,HRo,URo,Ui,JRo,Nge,YRo,KRo,wO,ZRo,ePo,oPo,e2,rPo,eo,wy,tPo,qge,aPo,nPo,Na,sPo,jge,lPo,iPo,Dge,dPo,cPo,Gge,fPo,mPo,gPo,pe,o2,Oge,hPo,pPo,AO,_Po,uPo,bPo,r2,Vge,vPo,FPo,LO,TPo,MPo,EPo,t2,Xge,CPo,wPo,yO,APo,LPo,yPo,a2,zge,xPo,$Po,xO,kPo,SPo,RPo,n2,Qge,PPo,BPo,$O,IPo,NPo,qPo,s2,Wge,jPo,DPo,kO,GPo,OPo,VPo,l2,Hge,XPo,zPo,SO,QPo,WPo,HPo,i2,Uge,UPo,JPo,RO,YPo,KPo,ZPo,d2,Jge,eBo,oBo,PO,rBo,tBo,aBo,c2,Yge,nBo,sBo,BO,lBo,iBo,dBo,f2,Kge,cBo,fBo,IO,mBo,gBo,hBo,m2,Zge,pBo,_Bo,NO,uBo,bBo,vBo,g2,ehe,FBo,TBo,qO,MBo,EBo,CBo,h2,ohe,wBo,ABo,jO,LBo,yBo,xBo,p2,rhe,$Bo,kBo,DO,SBo,RBo,PBo,_2,the,BBo,IBo,GO,NBo,qBo,jBo,u2,ahe,DBo,GBo,OO,OBo,VBo,XBo,b2,zBo,nhe,QBo,WBo,she,HBo,UBo,v2,iOe,Ji,F2,lhe,Ay,JBo,ihe,YBo,dOe,Po,Ly,KBo,Yi,ZBo,VO,eIo,oIo,XO,rIo,tIo,aIo,yy,nIo,dhe,sIo,lIo,iIo,ct,xy,dIo,che,cIo,fIo,Ki,mIo,fhe,gIo,hIo,zO,pIo,_Io,uIo,T2,bIo,oo,$y,vIo,mhe,FIo,TIo,qa,MIo,ghe,EIo,CIo,hhe,wIo,AIo,phe,LIo,yIo,xIo,N,M2,_he,$Io,kIo,QO,SIo,RIo,PIo,E2,uhe,BIo,IIo,WO,NIo,qIo,jIo,C2,bhe,DIo,GIo,HO,OIo,VIo,XIo,w2,vhe,zIo,QIo,UO,WIo,HIo,UIo,A2,Fhe,JIo,YIo,JO,KIo,ZIo,eNo,L2,The,oNo,rNo,YO,tNo,aNo,nNo,y2,Mhe,sNo,lNo,KO,iNo,dNo,cNo,x2,Ehe,fNo,mNo,ZO,gNo,hNo,pNo,$2,Che,_No,uNo,eV,bNo,vNo,FNo,k2,whe,TNo,MNo,oV,ENo,CNo,wNo,S2,Ahe,ANo,LNo,rV,yNo,xNo,$No,R2,Lhe,kNo,SNo,tV,RNo,PNo,BNo,P2,yhe,INo,NNo,aV,qNo,jNo,DNo,B2,xhe,GNo,ONo,nV,VNo,XNo,zNo,I2,$he,QNo,WNo,sV,HNo,UNo,JNo,N2,khe,YNo,KNo,lV,ZNo,eqo,oqo,q2,She,rqo,tqo,iV,aqo,nqo,sqo,j2,Rhe,lqo,iqo,dV,dqo,cqo,fqo,D2,Phe,mqo,gqo,cV,hqo,pqo,_qo,G2,Bhe,uqo,bqo,fV,vqo,Fqo,Tqo,O2,Ihe,Mqo,Eqo,mV,Cqo,wqo,Aqo,V2,Nhe,Lqo,yqo,gV,xqo,$qo,kqo,X2,qhe,Sqo,Rqo,hV,Pqo,Bqo,Iqo,z2,jhe,Nqo,qqo,pV,jqo,Dqo,Gqo,Q2,Dhe,Oqo,Vqo,_V,Xqo,zqo,Qqo,W2,Ghe,Wqo,Hqo,uV,Uqo,Jqo,Yqo,H2,Ohe,Kqo,Zqo,bV,ejo,ojo,rjo,U2,Vhe,tjo,ajo,vV,njo,sjo,ljo,J2,Xhe,ijo,djo,FV,cjo,fjo,mjo,Y2,zhe,gjo,hjo,TV,pjo,_jo,ujo,K2,Qhe,bjo,vjo,MV,Fjo,Tjo,Mjo,Z2,Whe,Ejo,Cjo,EV,wjo,Ajo,Ljo,eb,Hhe,yjo,xjo,CV,$jo,kjo,Sjo,ob,Uhe,Rjo,Pjo,wV,Bjo,Ijo,Njo,rb,Jhe,qjo,jjo,AV,Djo,Gjo,Ojo,tb,Yhe,Vjo,Xjo,LV,zjo,Qjo,Wjo,ab,Khe,Hjo,Ujo,yV,Jjo,Yjo,Kjo,nb,Zhe,Zjo,eDo,xV,oDo,rDo,tDo,sb,epe,aDo,nDo,$V,sDo,lDo,iDo,lb,ope,dDo,cDo,kV,fDo,mDo,gDo,ib,rpe,hDo,pDo,SV,_Do,uDo,bDo,db,tpe,vDo,FDo,RV,TDo,MDo,EDo,cb,ape,CDo,wDo,PV,ADo,LDo,yDo,fb,npe,xDo,$Do,BV,kDo,SDo,RDo,mb,spe,PDo,BDo,IV,IDo,NDo,qDo,gb,lpe,jDo,DDo,NV,GDo,ODo,VDo,hb,ipe,XDo,zDo,qV,QDo,WDo,HDo,pb,dpe,UDo,JDo,jV,YDo,KDo,ZDo,_b,cpe,eGo,oGo,DV,rGo,tGo,aGo,ub,nGo,fpe,sGo,lGo,mpe,iGo,dGo,bb,cOe,Zi,vb,gpe,ky,cGo,hpe,fGo,fOe,Bo,Sy,mGo,ed,gGo,GV,hGo,pGo,OV,_Go,uGo,bGo,Ry,vGo,ppe,FGo,TGo,MGo,ft,Py,EGo,_pe,CGo,wGo,od,AGo,upe,LGo,yGo,VV,xGo,$Go,kGo,Fb,SGo,ro,By,RGo,bpe,PGo,BGo,ja,IGo,vpe,NGo,qGo,Fpe,jGo,DGo,Tpe,GGo,OGo,VGo,Z,Tb,Mpe,XGo,zGo,XV,QGo,WGo,HGo,Mb,Epe,UGo,JGo,zV,YGo,KGo,ZGo,Eb,Cpe,eOo,oOo,QV,rOo,tOo,aOo,Cb,wpe,nOo,sOo,WV,lOo,iOo,dOo,wb,Ape,cOo,fOo,HV,mOo,gOo,hOo,Ab,Lpe,pOo,_Oo,UV,uOo,bOo,vOo,Lb,ype,FOo,TOo,JV,MOo,EOo,COo,yb,xpe,wOo,AOo,YV,LOo,yOo,xOo,xb,$pe,$Oo,kOo,KV,SOo,ROo,POo,$b,kpe,BOo,IOo,ZV,NOo,qOo,jOo,kb,Spe,DOo,GOo,eX,OOo,VOo,XOo,Sb,Rpe,zOo,QOo,oX,WOo,HOo,UOo,Rb,Ppe,JOo,YOo,rX,KOo,ZOo,eVo,Pb,Bpe,oVo,rVo,tX,tVo,aVo,nVo,Bb,Ipe,sVo,lVo,aX,iVo,dVo,cVo,Ib,Npe,fVo,mVo,nX,gVo,hVo,pVo,Nb,qpe,_Vo,uVo,sX,bVo,vVo,FVo,qb,jpe,TVo,MVo,lX,EVo,CVo,wVo,jb,Dpe,AVo,LVo,iX,yVo,xVo,$Vo,Db,Gpe,kVo,SVo,dX,RVo,PVo,BVo,Gb,Ope,IVo,NVo,cX,qVo,jVo,DVo,Ob,Vpe,GVo,OVo,fX,VVo,XVo,zVo,Vb,Xpe,QVo,WVo,mX,HVo,UVo,JVo,Xb,zpe,YVo,KVo,gX,ZVo,eXo,oXo,zb,Qpe,rXo,tXo,hX,aXo,nXo,sXo,Qb,Wpe,lXo,iXo,pX,dXo,cXo,fXo,Wb,Hpe,mXo,gXo,_X,hXo,pXo,_Xo,Hb,Upe,uXo,bXo,uX,vXo,FXo,TXo,Ub,Jpe,MXo,EXo,bX,CXo,wXo,AXo,Jb,Ype,LXo,yXo,vX,xXo,$Xo,kXo,Yb,SXo,Kpe,RXo,PXo,Zpe,BXo,IXo,Kb,mOe,rd,Zb,e_e,Iy,NXo,o_e,qXo,gOe,Io,Ny,jXo,td,DXo,FX,GXo,OXo,TX,VXo,XXo,zXo,qy,QXo,r_e,WXo,HXo,UXo,mt,jy,JXo,t_e,YXo,KXo,ad,ZXo,a_e,ezo,ozo,MX,rzo,tzo,azo,ev,nzo,to,Dy,szo,n_e,lzo,izo,Da,dzo,s_e,czo,fzo,l_e,mzo,gzo,i_e,hzo,pzo,_zo,No,ov,d_e,uzo,bzo,EX,vzo,Fzo,Tzo,rv,c_e,Mzo,Ezo,CX,Czo,wzo,Azo,tv,f_e,Lzo,yzo,wX,xzo,$zo,kzo,av,m_e,Szo,Rzo,AX,Pzo,Bzo,Izo,nv,g_e,Nzo,qzo,LX,jzo,Dzo,Gzo,sv,h_e,Ozo,Vzo,yX,Xzo,zzo,Qzo,lv,Wzo,p_e,Hzo,Uzo,__e,Jzo,Yzo,iv,hOe,nd,dv,u_e,Gy,Kzo,b_e,Zzo,pOe,qo,Oy,eQo,sd,oQo,xX,rQo,tQo,$X,aQo,nQo,sQo,Vy,lQo,v_e,iQo,dQo,cQo,gt,Xy,fQo,F_e,mQo,gQo,ld,hQo,T_e,pQo,_Qo,kX,uQo,bQo,vQo,cv,FQo,ao,zy,TQo,M_e,MQo,EQo,Ga,CQo,E_e,wQo,AQo,C_e,LQo,yQo,w_e,xQo,$Qo,kQo,H,fv,A_e,SQo,RQo,SX,PQo,BQo,IQo,mv,L_e,NQo,qQo,RX,jQo,DQo,GQo,gv,y_e,OQo,VQo,PX,XQo,zQo,QQo,hv,x_e,WQo,HQo,BX,UQo,JQo,YQo,pv,$_e,KQo,ZQo,IX,eWo,oWo,rWo,_v,k_e,tWo,aWo,NX,nWo,sWo,lWo,uv,S_e,iWo,dWo,qX,cWo,fWo,mWo,bv,R_e,gWo,hWo,jX,pWo,_Wo,uWo,vv,P_e,bWo,vWo,DX,FWo,TWo,MWo,Fv,B_e,EWo,CWo,GX,wWo,AWo,LWo,Tv,I_e,yWo,xWo,OX,$Wo,kWo,SWo,Mv,N_e,RWo,PWo,VX,BWo,IWo,NWo,Ev,q_e,qWo,jWo,XX,DWo,GWo,OWo,Cv,j_e,VWo,XWo,zX,zWo,QWo,WWo,wv,D_e,HWo,UWo,QX,JWo,YWo,KWo,Av,G_e,ZWo,eHo,WX,oHo,rHo,tHo,Lv,O_e,aHo,nHo,HX,sHo,lHo,iHo,yv,V_e,dHo,cHo,UX,fHo,mHo,gHo,xv,X_e,hHo,pHo,JX,_Ho,uHo,bHo,$v,z_e,vHo,FHo,YX,THo,MHo,EHo,kv,Q_e,CHo,wHo,KX,AHo,LHo,yHo,Sv,W_e,xHo,$Ho,ZX,kHo,SHo,RHo,Rv,H_e,PHo,BHo,ez,IHo,NHo,qHo,Pv,U_e,jHo,DHo,oz,GHo,OHo,VHo,Bv,J_e,XHo,zHo,rz,QHo,WHo,HHo,Iv,Y_e,UHo,JHo,tz,YHo,KHo,ZHo,Nv,K_e,eUo,oUo,az,rUo,tUo,aUo,qv,Z_e,nUo,sUo,nz,lUo,iUo,dUo,jv,eue,cUo,fUo,sz,mUo,gUo,hUo,Dv,oue,pUo,_Uo,lz,uUo,bUo,vUo,Gv,rue,FUo,TUo,iz,MUo,EUo,CUo,Ov,tue,wUo,AUo,dz,LUo,yUo,xUo,Vv,aue,$Uo,kUo,cz,SUo,RUo,PUo,Xv,nue,BUo,IUo,fz,NUo,qUo,jUo,zv,sue,DUo,GUo,mz,OUo,VUo,XUo,Qv,lue,zUo,QUo,gz,WUo,HUo,UUo,Wv,JUo,iue,YUo,KUo,due,ZUo,eJo,Hv,_Oe,id,Uv,cue,Qy,oJo,fue,rJo,uOe,jo,Wy,tJo,dd,aJo,hz,nJo,sJo,pz,lJo,iJo,dJo,Hy,cJo,mue,fJo,mJo,gJo,ht,Uy,hJo,gue,pJo,_Jo,cd,uJo,hue,bJo,vJo,_z,FJo,TJo,MJo,Jv,EJo,no,Jy,CJo,pue,wJo,AJo,Oa,LJo,_ue,yJo,xJo,uue,$Jo,kJo,bue,SJo,RJo,PJo,V,Yv,vue,BJo,IJo,uz,NJo,qJo,jJo,Kv,Fue,DJo,GJo,bz,OJo,VJo,XJo,Zv,Tue,zJo,QJo,vz,WJo,HJo,UJo,eF,Mue,JJo,YJo,Fz,KJo,ZJo,eYo,oF,Eue,oYo,rYo,Tz,tYo,aYo,nYo,rF,Cue,sYo,lYo,Mz,iYo,dYo,cYo,tF,wue,fYo,mYo,Ez,gYo,hYo,pYo,aF,Aue,_Yo,uYo,Cz,bYo,vYo,FYo,nF,Lue,TYo,MYo,wz,EYo,CYo,wYo,sF,yue,AYo,LYo,Az,yYo,xYo,$Yo,lF,xue,kYo,SYo,Lz,RYo,PYo,BYo,iF,$ue,IYo,NYo,yz,qYo,jYo,DYo,dF,kue,GYo,OYo,xz,VYo,XYo,zYo,cF,Sue,QYo,WYo,$z,HYo,UYo,JYo,fF,Rue,YYo,KYo,kz,ZYo,eKo,oKo,mF,Pue,rKo,tKo,Sz,aKo,nKo,sKo,gF,Bue,lKo,iKo,Rz,dKo,cKo,fKo,hF,Iue,mKo,gKo,Pz,hKo,pKo,_Ko,pF,Nue,uKo,bKo,Bz,vKo,FKo,TKo,_F,que,MKo,EKo,Iz,CKo,wKo,AKo,uF,jue,LKo,yKo,Nz,xKo,$Ko,kKo,bF,Due,SKo,RKo,qz,PKo,BKo,IKo,vF,Gue,NKo,qKo,jz,jKo,DKo,GKo,FF,Oue,OKo,VKo,Dz,XKo,zKo,QKo,TF,Vue,WKo,HKo,Gz,UKo,JKo,YKo,MF,Xue,KKo,ZKo,Oz,eZo,oZo,rZo,EF,zue,tZo,aZo,Vz,nZo,sZo,lZo,CF,Que,iZo,dZo,Xz,cZo,fZo,mZo,wF,Wue,gZo,hZo,zz,pZo,_Zo,uZo,AF,Hue,bZo,vZo,Qz,FZo,TZo,MZo,LF,Uue,EZo,CZo,Wz,wZo,AZo,LZo,yF,Jue,yZo,xZo,Hz,$Zo,kZo,SZo,xF,Yue,RZo,PZo,Uz,BZo,IZo,NZo,$F,Kue,qZo,jZo,Jz,DZo,GZo,OZo,kF,Zue,VZo,XZo,Yz,zZo,QZo,WZo,SF,e7e,HZo,UZo,Kz,JZo,YZo,KZo,RF,o7e,ZZo,eer,Zz,oer,rer,ter,PF,r7e,aer,ner,eQ,ser,ler,ier,BF,t7e,der,cer,oQ,fer,mer,ger,IF,a7e,her,per,rQ,_er,uer,ber,NF,n7e,ver,Fer,tQ,Ter,Mer,Eer,qF,Cer,s7e,wer,Aer,l7e,Ler,yer,jF,bOe,fd,DF,i7e,Yy,xer,d7e,$er,vOe,Do,Ky,ker,md,Ser,aQ,Rer,Per,nQ,Ber,Ier,Ner,Zy,qer,c7e,jer,Der,Ger,pt,e8,Oer,f7e,Ver,Xer,gd,zer,m7e,Qer,Wer,sQ,Her,Uer,Jer,GF,Yer,so,o8,Ker,g7e,Zer,eor,Va,oor,h7e,ror,tor,p7e,aor,nor,_7e,sor,lor,ior,u7e,OF,b7e,dor,cor,lQ,mor,gor,hor,VF,por,v7e,_or,uor,F7e,bor,vor,XF,FOe,hd,zF,T7e,r8,For,M7e,Tor,TOe,Go,t8,Mor,pd,Eor,iQ,Cor,wor,dQ,Aor,Lor,yor,a8,xor,E7e,$or,kor,Sor,_t,n8,Ror,C7e,Por,Bor,_d,Ior,w7e,Nor,qor,cQ,jor,Dor,Gor,QF,Oor,lo,s8,Vor,A7e,Xor,zor,Xa,Qor,L7e,Wor,Hor,y7e,Uor,Jor,x7e,Yor,Kor,Zor,Fe,WF,$7e,err,orr,fQ,rrr,trr,arr,HF,k7e,nrr,srr,mQ,lrr,irr,drr,UF,S7e,crr,frr,gQ,mrr,grr,hrr,JF,R7e,prr,_rr,hQ,urr,brr,vrr,Xs,P7e,Frr,Trr,pQ,Mrr,Err,_Q,Crr,wrr,Arr,YF,B7e,Lrr,yrr,uQ,xrr,$rr,krr,zs,I7e,Srr,Rrr,bQ,Prr,Brr,vQ,Irr,Nrr,qrr,ut,N7e,jrr,Drr,FQ,Grr,Orr,TQ,Vrr,Xrr,MQ,zrr,Qrr,Wrr,KF,q7e,Hrr,Urr,EQ,Jrr,Yrr,Krr,ZF,j7e,Zrr,etr,CQ,otr,rtr,ttr,e6,D7e,atr,ntr,wQ,str,ltr,itr,o6,G7e,dtr,ctr,AQ,ftr,mtr,gtr,r6,O7e,htr,ptr,LQ,_tr,utr,btr,t6,V7e,vtr,Ftr,yQ,Ttr,Mtr,Etr,a6,X7e,Ctr,wtr,xQ,Atr,Ltr,ytr,n6,xtr,z7e,$tr,ktr,Q7e,Str,Rtr,s6,MOe,ud,l6,W7e,l8,Ptr,H7e,Btr,EOe,Oo,i8,Itr,bd,Ntr,$Q,qtr,jtr,kQ,Dtr,Gtr,Otr,d8,Vtr,U7e,Xtr,ztr,Qtr,bt,c8,Wtr,J7e,Htr,Utr,vd,Jtr,Y7e,Ytr,Ktr,SQ,Ztr,ear,oar,i6,rar,io,f8,tar,K7e,aar,nar,za,sar,Z7e,lar,iar,e1e,dar,car,o1e,far,mar,gar,r1e,d6,t1e,har,par,RQ,_ar,uar,bar,c6,Far,a1e,Tar,Mar,n1e,Ear,Car,f6,COe,Fd,m6,s1e,m8,war,l1e,Aar,wOe,Vo,g8,Lar,Td,yar,PQ,xar,$ar,BQ,kar,Sar,Rar,h8,Par,i1e,Bar,Iar,Nar,vt,p8,qar,d1e,jar,Dar,Md,Gar,c1e,Oar,Var,IQ,Xar,zar,Qar,g6,War,co,_8,Har,f1e,Uar,Jar,Qa,Yar,m1e,Kar,Zar,g1e,enr,onr,h1e,rnr,tnr,anr,p1e,h6,_1e,nnr,snr,NQ,lnr,inr,dnr,p6,cnr,u1e,fnr,mnr,b1e,gnr,hnr,_6,AOe,Ed,u6,v1e,u8,pnr,F1e,_nr,LOe,Xo,b8,unr,Cd,bnr,qQ,vnr,Fnr,jQ,Tnr,Mnr,Enr,v8,Cnr,T1e,wnr,Anr,Lnr,Ft,F8,ynr,M1e,xnr,$nr,wd,knr,E1e,Snr,Rnr,DQ,Pnr,Bnr,Inr,b6,Nnr,fo,T8,qnr,C1e,jnr,Dnr,Wa,Gnr,w1e,Onr,Vnr,A1e,Xnr,znr,L1e,Qnr,Wnr,Hnr,Pe,v6,y1e,Unr,Jnr,GQ,Ynr,Knr,Znr,F6,x1e,esr,osr,OQ,rsr,tsr,asr,T6,$1e,nsr,ssr,VQ,lsr,isr,dsr,M6,k1e,csr,fsr,XQ,msr,gsr,hsr,E6,S1e,psr,_sr,zQ,usr,bsr,vsr,C6,R1e,Fsr,Tsr,QQ,Msr,Esr,Csr,w6,P1e,wsr,Asr,WQ,Lsr,ysr,xsr,A6,B1e,$sr,ksr,HQ,Ssr,Rsr,Psr,L6,I1e,Bsr,Isr,UQ,Nsr,qsr,jsr,y6,Dsr,N1e,Gsr,Osr,q1e,Vsr,Xsr,x6,yOe,Ad,$6,j1e,M8,zsr,D1e,Qsr,xOe,zo,E8,Wsr,Ld,Hsr,JQ,Usr,Jsr,YQ,Ysr,Ksr,Zsr,C8,elr,G1e,olr,rlr,tlr,Tt,w8,alr,O1e,nlr,slr,yd,llr,V1e,ilr,dlr,KQ,clr,flr,mlr,k6,glr,mo,A8,hlr,X1e,plr,_lr,Ha,ulr,z1e,blr,vlr,Q1e,Flr,Tlr,W1e,Mlr,Elr,Clr,et,S6,H1e,wlr,Alr,ZQ,Llr,ylr,xlr,R6,U1e,$lr,klr,eW,Slr,Rlr,Plr,P6,J1e,Blr,Ilr,oW,Nlr,qlr,jlr,B6,Y1e,Dlr,Glr,rW,Olr,Vlr,Xlr,I6,K1e,zlr,Qlr,tW,Wlr,Hlr,Ulr,N6,Jlr,Z1e,Ylr,Klr,e2e,Zlr,eir,q6,$Oe,xd,j6,o2e,L8,oir,r2e,rir,kOe,Qo,y8,tir,$d,air,aW,nir,sir,nW,lir,iir,dir,x8,cir,t2e,fir,mir,gir,Mt,$8,hir,a2e,pir,_ir,kd,uir,n2e,bir,vir,sW,Fir,Tir,Mir,D6,Eir,go,k8,Cir,s2e,wir,Air,Ua,Lir,l2e,yir,xir,i2e,$ir,kir,d2e,Sir,Rir,Pir,Le,G6,c2e,Bir,Iir,lW,Nir,qir,jir,O6,f2e,Dir,Gir,iW,Oir,Vir,Xir,V6,m2e,zir,Qir,dW,Wir,Hir,Uir,X6,g2e,Jir,Yir,cW,Kir,Zir,edr,z6,h2e,odr,rdr,fW,tdr,adr,ndr,Q6,p2e,sdr,ldr,mW,idr,ddr,cdr,W6,_2e,fdr,mdr,gW,gdr,hdr,pdr,H6,u2e,_dr,udr,hW,bdr,vdr,Fdr,U6,b2e,Tdr,Mdr,pW,Edr,Cdr,wdr,J6,v2e,Adr,Ldr,_W,ydr,xdr,$dr,Y6,kdr,F2e,Sdr,Rdr,T2e,Pdr,Bdr,K6,SOe,Sd,Z6,M2e,S8,Idr,E2e,Ndr,ROe,Wo,R8,qdr,Rd,jdr,uW,Ddr,Gdr,bW,Odr,Vdr,Xdr,P8,zdr,C2e,Qdr,Wdr,Hdr,Et,B8,Udr,w2e,Jdr,Ydr,Pd,Kdr,A2e,Zdr,ecr,vW,ocr,rcr,tcr,eT,acr,ho,I8,ncr,L2e,scr,lcr,Ja,icr,y2e,dcr,ccr,x2e,fcr,mcr,$2e,gcr,hcr,pcr,N8,oT,k2e,_cr,ucr,FW,bcr,vcr,Fcr,rT,S2e,Tcr,Mcr,TW,Ecr,Ccr,wcr,tT,Acr,R2e,Lcr,ycr,P2e,xcr,$cr,aT,POe,Bd,nT,B2e,q8,kcr,I2e,Scr,BOe,Ho,j8,Rcr,Id,Pcr,MW,Bcr,Icr,EW,Ncr,qcr,jcr,D8,Dcr,N2e,Gcr,Ocr,Vcr,Ct,G8,Xcr,q2e,zcr,Qcr,Nd,Wcr,j2e,Hcr,Ucr,CW,Jcr,Ycr,Kcr,sT,Zcr,po,O8,efr,D2e,ofr,rfr,Ya,tfr,G2e,afr,nfr,O2e,sfr,lfr,V2e,ifr,dfr,cfr,ot,lT,X2e,ffr,mfr,wW,gfr,hfr,pfr,iT,z2e,_fr,ufr,AW,bfr,vfr,Ffr,dT,Q2e,Tfr,Mfr,LW,Efr,Cfr,wfr,cT,W2e,Afr,Lfr,yW,yfr,xfr,$fr,fT,H2e,kfr,Sfr,xW,Rfr,Pfr,Bfr,mT,Ifr,U2e,Nfr,qfr,J2e,jfr,Dfr,gT,IOe,qd,hT,Y2e,V8,Gfr,K2e,Ofr,NOe,Uo,X8,Vfr,jd,Xfr,$W,zfr,Qfr,kW,Wfr,Hfr,Ufr,z8,Jfr,Z2e,Yfr,Kfr,Zfr,wt,Q8,emr,ebe,omr,rmr,Dd,tmr,obe,amr,nmr,SW,smr,lmr,imr,pT,dmr,_o,W8,cmr,rbe,fmr,mmr,Ka,gmr,tbe,hmr,pmr,abe,_mr,umr,nbe,bmr,vmr,Fmr,Gd,_T,sbe,Tmr,Mmr,RW,Emr,Cmr,wmr,uT,lbe,Amr,Lmr,PW,ymr,xmr,$mr,bT,ibe,kmr,Smr,BW,Rmr,Pmr,Bmr,vT,Imr,dbe,Nmr,qmr,cbe,jmr,Dmr,FT,qOe,Od,TT,fbe,H8,Gmr,mbe,Omr,jOe,Jo,U8,Vmr,Vd,Xmr,IW,zmr,Qmr,NW,Wmr,Hmr,Umr,J8,Jmr,gbe,Ymr,Kmr,Zmr,At,Y8,egr,hbe,ogr,rgr,Xd,tgr,pbe,agr,ngr,qW,sgr,lgr,igr,MT,dgr,uo,K8,cgr,_be,fgr,mgr,Za,ggr,ube,hgr,pgr,bbe,_gr,ugr,vbe,bgr,vgr,Fgr,Z8,ET,Fbe,Tgr,Mgr,jW,Egr,Cgr,wgr,CT,Tbe,Agr,Lgr,DW,ygr,xgr,$gr,wT,kgr,Mbe,Sgr,Rgr,Ebe,Pgr,Bgr,AT,DOe,zd,LT,Cbe,e9,Igr,wbe,Ngr,GOe,Yo,o9,qgr,Qd,jgr,GW,Dgr,Ggr,OW,Ogr,Vgr,Xgr,r9,zgr,Abe,Qgr,Wgr,Hgr,Lt,t9,Ugr,Lbe,Jgr,Ygr,Wd,Kgr,ybe,Zgr,ehr,VW,ohr,rhr,thr,yT,ahr,bo,a9,nhr,xbe,shr,lhr,en,ihr,$be,dhr,chr,kbe,fhr,mhr,Sbe,ghr,hhr,phr,Rbe,xT,Pbe,_hr,uhr,XW,bhr,vhr,Fhr,$T,Thr,Bbe,Mhr,Ehr,Ibe,Chr,whr,kT,OOe,Hd,ST,Nbe,n9,Ahr,qbe,Lhr,VOe,Ko,s9,yhr,Ud,xhr,zW,$hr,khr,QW,Shr,Rhr,Phr,l9,Bhr,jbe,Ihr,Nhr,qhr,yt,i9,jhr,Dbe,Dhr,Ghr,Jd,Ohr,Gbe,Vhr,Xhr,WW,zhr,Qhr,Whr,RT,Hhr,vo,d9,Uhr,Obe,Jhr,Yhr,on,Khr,Vbe,Zhr,epr,Xbe,opr,rpr,zbe,tpr,apr,npr,rn,PT,Qbe,spr,lpr,HW,ipr,dpr,cpr,BT,Wbe,fpr,mpr,UW,gpr,hpr,ppr,IT,Hbe,_pr,upr,JW,bpr,vpr,Fpr,NT,Ube,Tpr,Mpr,YW,Epr,Cpr,wpr,qT,Apr,Jbe,Lpr,ypr,Ybe,xpr,$pr,jT,XOe,Yd,DT,Kbe,c9,kpr,Zbe,Spr,zOe,Zo,f9,Rpr,Kd,Ppr,KW,Bpr,Ipr,ZW,Npr,qpr,jpr,m9,Dpr,eve,Gpr,Opr,Vpr,xt,g9,Xpr,ove,zpr,Qpr,Zd,Wpr,rve,Hpr,Upr,eH,Jpr,Ypr,Kpr,GT,Zpr,Fo,h9,e_r,tve,o_r,r_r,tn,t_r,ave,a_r,n_r,nve,s_r,l_r,sve,i_r,d_r,c_r,lve,OT,ive,f_r,m_r,oH,g_r,h_r,p_r,VT,__r,dve,u_r,b_r,cve,v_r,F_r,XT,QOe,ec,zT,fve,p9,T_r,mve,M_r,WOe,er,_9,E_r,oc,C_r,rH,w_r,A_r,tH,L_r,y_r,x_r,u9,$_r,gve,k_r,S_r,R_r,$t,b9,P_r,hve,B_r,I_r,rc,N_r,pve,q_r,j_r,aH,D_r,G_r,O_r,QT,V_r,yr,v9,X_r,_ve,z_r,Q_r,an,W_r,uve,H_r,U_r,bve,J_r,Y_r,vve,K_r,Z_r,eur,j,WT,Fve,our,rur,nH,tur,aur,nur,HT,Tve,sur,lur,sH,iur,dur,cur,UT,Mve,fur,mur,lH,gur,hur,pur,JT,Eve,_ur,uur,iH,bur,vur,Fur,YT,Cve,Tur,Mur,dH,Eur,Cur,wur,KT,wve,Aur,Lur,cH,yur,xur,$ur,ZT,Ave,kur,Sur,fH,Rur,Pur,Bur,eM,Lve,Iur,Nur,mH,qur,jur,Dur,oM,yve,Gur,Our,gH,Vur,Xur,zur,rM,xve,Qur,Wur,hH,Hur,Uur,Jur,tM,$ve,Yur,Kur,pH,Zur,e7r,o7r,aM,kve,r7r,t7r,_H,a7r,n7r,s7r,nM,Sve,l7r,i7r,uH,d7r,c7r,f7r,sM,Rve,m7r,g7r,bH,h7r,p7r,_7r,lM,Pve,u7r,b7r,vH,v7r,F7r,T7r,iM,Bve,M7r,E7r,FH,C7r,w7r,A7r,dM,Ive,L7r,y7r,TH,x7r,$7r,k7r,Qs,Nve,S7r,R7r,MH,P7r,B7r,EH,I7r,N7r,q7r,cM,qve,j7r,D7r,CH,G7r,O7r,V7r,fM,jve,X7r,z7r,wH,Q7r,W7r,H7r,mM,Dve,U7r,J7r,AH,Y7r,K7r,Z7r,gM,Gve,e1r,o1r,LH,r1r,t1r,a1r,hM,Ove,n1r,s1r,yH,l1r,i1r,d1r,pM,Vve,c1r,f1r,xH,m1r,g1r,h1r,_M,Xve,p1r,_1r,$H,u1r,b1r,v1r,uM,zve,F1r,T1r,kH,M1r,E1r,C1r,bM,Qve,w1r,A1r,SH,L1r,y1r,x1r,vM,Wve,$1r,k1r,RH,S1r,R1r,P1r,FM,Hve,B1r,I1r,PH,N1r,q1r,j1r,TM,Uve,D1r,G1r,BH,O1r,V1r,X1r,MM,Jve,z1r,Q1r,IH,W1r,H1r,U1r,EM,Yve,J1r,Y1r,NH,K1r,Z1r,e2r,CM,Kve,o2r,r2r,qH,t2r,a2r,n2r,wM,Zve,s2r,l2r,jH,i2r,d2r,c2r,AM,eFe,f2r,m2r,DH,g2r,h2r,p2r,LM,oFe,_2r,u2r,GH,b2r,v2r,F2r,yM,rFe,T2r,M2r,OH,E2r,C2r,w2r,xM,tFe,A2r,L2r,VH,y2r,x2r,$2r,$M,aFe,k2r,S2r,XH,R2r,P2r,B2r,kM,nFe,I2r,N2r,zH,q2r,j2r,D2r,SM,sFe,G2r,O2r,QH,V2r,X2r,z2r,RM,lFe,Q2r,W2r,WH,H2r,U2r,J2r,PM,iFe,Y2r,K2r,HH,Z2r,ebr,obr,BM,dFe,rbr,tbr,UH,abr,nbr,sbr,IM,cFe,lbr,ibr,JH,dbr,cbr,fbr,NM,fFe,mbr,gbr,YH,hbr,pbr,_br,qM,mFe,ubr,bbr,KH,vbr,Fbr,Tbr,jM,HOe,tc,DM,gFe,F9,Mbr,hFe,Ebr,UOe,or,T9,Cbr,ac,wbr,ZH,Abr,Lbr,eU,ybr,xbr,$br,M9,kbr,pFe,Sbr,Rbr,Pbr,kt,E9,Bbr,_Fe,Ibr,Nbr,nc,qbr,uFe,jbr,Dbr,oU,Gbr,Obr,Vbr,GM,Xbr,xr,C9,zbr,bFe,Qbr,Wbr,nn,Hbr,vFe,Ubr,Jbr,FFe,Ybr,Kbr,TFe,Zbr,evr,ovr,se,OM,MFe,rvr,tvr,rU,avr,nvr,svr,VM,EFe,lvr,ivr,tU,dvr,cvr,fvr,XM,CFe,mvr,gvr,aU,hvr,pvr,_vr,zM,wFe,uvr,bvr,nU,vvr,Fvr,Tvr,QM,AFe,Mvr,Evr,sU,Cvr,wvr,Avr,WM,LFe,Lvr,yvr,lU,xvr,$vr,kvr,HM,yFe,Svr,Rvr,iU,Pvr,Bvr,Ivr,UM,xFe,Nvr,qvr,dU,jvr,Dvr,Gvr,JM,$Fe,Ovr,Vvr,cU,Xvr,zvr,Qvr,YM,kFe,Wvr,Hvr,fU,Uvr,Jvr,Yvr,KM,SFe,Kvr,Zvr,mU,eFr,oFr,rFr,ZM,RFe,tFr,aFr,gU,nFr,sFr,lFr,eE,PFe,iFr,dFr,hU,cFr,fFr,mFr,oE,BFe,gFr,hFr,pU,pFr,_Fr,uFr,rE,IFe,bFr,vFr,_U,FFr,TFr,MFr,tE,NFe,EFr,CFr,uU,wFr,AFr,LFr,aE,qFe,yFr,xFr,bU,$Fr,kFr,SFr,nE,jFe,RFr,PFr,vU,BFr,IFr,NFr,sE,DFe,qFr,jFr,FU,DFr,GFr,OFr,lE,GFe,VFr,XFr,TU,zFr,QFr,WFr,iE,OFe,HFr,UFr,MU,JFr,YFr,KFr,dE,VFe,ZFr,e6r,EU,o6r,r6r,t6r,cE,XFe,a6r,n6r,CU,s6r,l6r,i6r,fE,JOe,sc,mE,zFe,w9,d6r,QFe,c6r,YOe,rr,A9,f6r,lc,m6r,wU,g6r,h6r,AU,p6r,_6r,u6r,L9,b6r,WFe,v6r,F6r,T6r,St,y9,M6r,HFe,E6r,C6r,ic,w6r,UFe,A6r,L6r,LU,y6r,x6r,$6r,gE,k6r,$r,x9,S6r,JFe,R6r,P6r,sn,B6r,YFe,I6r,N6r,KFe,q6r,j6r,ZFe,D6r,G6r,O6r,Me,hE,e6e,V6r,X6r,yU,z6r,Q6r,W6r,pE,o6e,H6r,U6r,xU,J6r,Y6r,K6r,_E,r6e,Z6r,eTr,$U,oTr,rTr,tTr,uE,t6e,aTr,nTr,kU,sTr,lTr,iTr,bE,a6e,dTr,cTr,SU,fTr,mTr,gTr,vE,n6e,hTr,pTr,RU,_Tr,uTr,bTr,FE,s6e,vTr,FTr,PU,TTr,MTr,ETr,TE,l6e,CTr,wTr,BU,ATr,LTr,yTr,ME,i6e,xTr,$Tr,IU,kTr,STr,RTr,EE,d6e,PTr,BTr,NU,ITr,NTr,qTr,CE,c6e,jTr,DTr,qU,GTr,OTr,VTr,wE,f6e,XTr,zTr,jU,QTr,WTr,HTr,AE,m6e,UTr,JTr,DU,YTr,KTr,ZTr,LE,KOe,dc,yE,g6e,$9,eMr,h6e,oMr,ZOe,tr,k9,rMr,cc,tMr,GU,aMr,nMr,OU,sMr,lMr,iMr,S9,dMr,p6e,cMr,fMr,mMr,Rt,R9,gMr,_6e,hMr,pMr,fc,_Mr,u6e,uMr,bMr,VU,vMr,FMr,TMr,xE,MMr,kr,P9,EMr,b6e,CMr,wMr,ln,AMr,v6e,LMr,yMr,F6e,xMr,$Mr,T6e,kMr,SMr,RMr,dn,$E,M6e,PMr,BMr,XU,IMr,NMr,qMr,kE,E6e,jMr,DMr,zU,GMr,OMr,VMr,SE,C6e,XMr,zMr,QU,QMr,WMr,HMr,RE,w6e,UMr,JMr,WU,YMr,KMr,ZMr,PE,eVe,mc,BE,A6e,B9,eEr,L6e,oEr,oVe,ar,I9,rEr,gc,tEr,HU,aEr,nEr,UU,sEr,lEr,iEr,N9,dEr,y6e,cEr,fEr,mEr,Pt,q9,gEr,x6e,hEr,pEr,hc,_Er,$6e,uEr,bEr,JU,vEr,FEr,TEr,IE,MEr,Sr,j9,EEr,k6e,CEr,wEr,cn,AEr,S6e,LEr,yEr,R6e,xEr,$Er,P6e,kEr,SEr,REr,ie,NE,B6e,PEr,BEr,YU,IEr,NEr,qEr,qE,I6e,jEr,DEr,KU,GEr,OEr,VEr,jE,N6e,XEr,zEr,ZU,QEr,WEr,HEr,DE,q6e,UEr,JEr,eJ,YEr,KEr,ZEr,GE,j6e,e4r,o4r,oJ,r4r,t4r,a4r,OE,D6e,n4r,s4r,rJ,l4r,i4r,d4r,VE,G6e,c4r,f4r,tJ,m4r,g4r,h4r,XE,O6e,p4r,_4r,aJ,u4r,b4r,v4r,zE,V6e,F4r,T4r,nJ,M4r,E4r,C4r,QE,X6e,w4r,A4r,sJ,L4r,y4r,x4r,WE,z6e,$4r,k4r,lJ,S4r,R4r,P4r,HE,Q6e,B4r,I4r,iJ,N4r,q4r,j4r,UE,W6e,D4r,G4r,dJ,O4r,V4r,X4r,JE,H6e,z4r,Q4r,cJ,W4r,H4r,U4r,YE,U6e,J4r,Y4r,fJ,K4r,Z4r,eCr,KE,J6e,oCr,rCr,mJ,tCr,aCr,nCr,ZE,Y6e,sCr,lCr,gJ,iCr,dCr,cCr,e4,K6e,fCr,mCr,hJ,gCr,hCr,pCr,o4,Z6e,_Cr,uCr,pJ,bCr,vCr,FCr,r4,eTe,TCr,MCr,_J,ECr,CCr,wCr,t4,rVe,pc,a4,oTe,D9,ACr,rTe,LCr,tVe,nr,G9,yCr,_c,xCr,uJ,$Cr,kCr,bJ,SCr,RCr,PCr,O9,BCr,tTe,ICr,NCr,qCr,Bt,V9,jCr,aTe,DCr,GCr,uc,OCr,nTe,VCr,XCr,vJ,zCr,QCr,WCr,n4,HCr,Rr,X9,UCr,sTe,JCr,YCr,fn,KCr,lTe,ZCr,e5r,iTe,o5r,r5r,dTe,t5r,a5r,n5r,ye,s4,cTe,s5r,l5r,FJ,i5r,d5r,c5r,l4,fTe,f5r,m5r,TJ,g5r,h5r,p5r,i4,mTe,_5r,u5r,MJ,b5r,v5r,F5r,d4,gTe,T5r,M5r,EJ,E5r,C5r,w5r,c4,hTe,A5r,L5r,CJ,y5r,x5r,$5r,f4,pTe,k5r,S5r,wJ,R5r,P5r,B5r,m4,_Te,I5r,N5r,AJ,q5r,j5r,D5r,g4,uTe,G5r,O5r,LJ,V5r,X5r,z5r,h4,bTe,Q5r,W5r,yJ,H5r,U5r,J5r,p4,vTe,Y5r,K5r,xJ,Z5r,e3r,o3r,_4,aVe,bc,u4,FTe,z9,r3r,TTe,t3r,nVe,sr,Q9,a3r,vc,n3r,$J,s3r,l3r,kJ,i3r,d3r,c3r,W9,f3r,MTe,m3r,g3r,h3r,It,H9,p3r,ETe,_3r,u3r,Fc,b3r,CTe,v3r,F3r,SJ,T3r,M3r,E3r,b4,C3r,Pr,U9,w3r,wTe,A3r,L3r,mn,y3r,ATe,x3r,$3r,LTe,k3r,S3r,yTe,R3r,P3r,B3r,te,v4,xTe,I3r,N3r,RJ,q3r,j3r,D3r,F4,$Te,G3r,O3r,PJ,V3r,X3r,z3r,T4,kTe,Q3r,W3r,BJ,H3r,U3r,J3r,M4,STe,Y3r,K3r,IJ,Z3r,e0r,o0r,E4,RTe,r0r,t0r,NJ,a0r,n0r,s0r,C4,PTe,l0r,i0r,qJ,d0r,c0r,f0r,w4,BTe,m0r,g0r,jJ,h0r,p0r,_0r,A4,ITe,u0r,b0r,DJ,v0r,F0r,T0r,L4,NTe,M0r,E0r,GJ,C0r,w0r,A0r,y4,qTe,L0r,y0r,OJ,x0r,$0r,k0r,x4,jTe,S0r,R0r,VJ,P0r,B0r,I0r,$4,DTe,N0r,q0r,XJ,j0r,D0r,G0r,k4,GTe,O0r,V0r,zJ,X0r,z0r,Q0r,S4,OTe,W0r,H0r,QJ,U0r,J0r,Y0r,R4,VTe,K0r,Z0r,WJ,ewr,owr,rwr,P4,XTe,twr,awr,HJ,nwr,swr,lwr,B4,zTe,iwr,dwr,UJ,cwr,fwr,mwr,I4,QTe,gwr,hwr,JJ,pwr,_wr,uwr,N4,WTe,bwr,vwr,YJ,Fwr,Twr,Mwr,q4,HTe,Ewr,Cwr,KJ,wwr,Awr,Lwr,j4,UTe,ywr,xwr,ZJ,$wr,kwr,Swr,D4,JTe,Rwr,Pwr,eY,Bwr,Iwr,Nwr,G4,YTe,qwr,jwr,oY,Dwr,Gwr,Owr,O4,KTe,Vwr,Xwr,rY,zwr,Qwr,Wwr,V4,ZTe,Hwr,Uwr,tY,Jwr,Ywr,Kwr,X4,eMe,Zwr,eAr,aY,oAr,rAr,tAr,z4,sVe,Tc,Q4,oMe,J9,aAr,rMe,nAr,lVe,lr,Y9,sAr,Mc,lAr,nY,iAr,dAr,sY,cAr,fAr,mAr,K9,gAr,tMe,hAr,pAr,_Ar,Nt,Z9,uAr,aMe,bAr,vAr,Ec,FAr,nMe,TAr,MAr,lY,EAr,CAr,wAr,W4,AAr,Br,ex,LAr,sMe,yAr,xAr,gn,$Ar,lMe,kAr,SAr,iMe,RAr,PAr,dMe,BAr,IAr,NAr,_e,H4,cMe,qAr,jAr,iY,DAr,GAr,OAr,U4,fMe,VAr,XAr,dY,zAr,QAr,WAr,J4,mMe,HAr,UAr,cY,JAr,YAr,KAr,Y4,gMe,ZAr,eLr,fY,oLr,rLr,tLr,K4,hMe,aLr,nLr,mY,sLr,lLr,iLr,Z4,pMe,dLr,cLr,gY,fLr,mLr,gLr,eC,_Me,hLr,pLr,hY,_Lr,uLr,bLr,oC,uMe,vLr,FLr,pY,TLr,MLr,ELr,rC,bMe,CLr,wLr,_Y,ALr,LLr,yLr,tC,vMe,xLr,$Lr,uY,kLr,SLr,RLr,aC,FMe,PLr,BLr,bY,ILr,NLr,qLr,nC,TMe,jLr,DLr,vY,GLr,OLr,VLr,sC,MMe,XLr,zLr,FY,QLr,WLr,HLr,lC,EMe,ULr,JLr,TY,YLr,KLr,ZLr,iC,CMe,eyr,oyr,MY,ryr,tyr,ayr,dC,wMe,nyr,syr,EY,lyr,iyr,dyr,cC,AMe,cyr,fyr,CY,myr,gyr,hyr,fC,iVe,Cc,mC,LMe,ox,pyr,yMe,_yr,dVe,ir,rx,uyr,wc,byr,wY,vyr,Fyr,AY,Tyr,Myr,Eyr,tx,Cyr,xMe,wyr,Ayr,Lyr,qt,ax,yyr,$Me,xyr,$yr,Ac,kyr,kMe,Syr,Ryr,LY,Pyr,Byr,Iyr,gC,Nyr,Ir,nx,qyr,SMe,jyr,Dyr,hn,Gyr,RMe,Oyr,Vyr,PMe,Xyr,zyr,BMe,Qyr,Wyr,Hyr,sx,hC,IMe,Uyr,Jyr,yY,Yyr,Kyr,Zyr,pC,NMe,e8r,o8r,xY,r8r,t8r,a8r,_C,cVe,Lc,uC,qMe,lx,n8r,jMe,s8r,fVe,dr,ix,l8r,yc,i8r,$Y,d8r,c8r,kY,f8r,m8r,g8r,dx,h8r,DMe,p8r,_8r,u8r,jt,cx,b8r,GMe,v8r,F8r,xc,T8r,OMe,M8r,E8r,SY,C8r,w8r,A8r,bC,L8r,Nr,fx,y8r,VMe,x8r,$8r,pn,k8r,XMe,S8r,R8r,zMe,P8r,B8r,QMe,I8r,N8r,q8r,WMe,vC,HMe,j8r,D8r,RY,G8r,O8r,V8r,FC,mVe,$c,TC,UMe,mx,X8r,JMe,z8r,gVe,cr,gx,Q8r,kc,W8r,PY,H8r,U8r,BY,J8r,Y8r,K8r,hx,Z8r,YMe,e9r,o9r,r9r,Dt,px,t9r,KMe,a9r,n9r,Sc,s9r,ZMe,l9r,i9r,IY,d9r,c9r,f9r,MC,m9r,qr,_x,g9r,eEe,h9r,p9r,_n,_9r,oEe,u9r,b9r,rEe,v9r,F9r,tEe,T9r,M9r,E9r,de,EC,aEe,C9r,w9r,NY,A9r,L9r,y9r,CC,nEe,x9r,$9r,qY,k9r,S9r,R9r,wC,sEe,P9r,B9r,jY,I9r,N9r,q9r,AC,lEe,j9r,D9r,DY,G9r,O9r,V9r,LC,iEe,X9r,z9r,GY,Q9r,W9r,H9r,yC,dEe,U9r,J9r,OY,Y9r,K9r,Z9r,xC,cEe,exr,oxr,VY,rxr,txr,axr,$C,fEe,nxr,sxr,XY,lxr,ixr,dxr,kC,mEe,cxr,fxr,zY,mxr,gxr,hxr,SC,gEe,pxr,_xr,QY,uxr,bxr,vxr,RC,hEe,Fxr,Txr,WY,Mxr,Exr,Cxr,PC,pEe,wxr,Axr,HY,Lxr,yxr,xxr,BC,_Ee,$xr,kxr,UY,Sxr,Rxr,Pxr,IC,uEe,Bxr,Ixr,JY,Nxr,qxr,jxr,NC,bEe,Dxr,Gxr,YY,Oxr,Vxr,Xxr,qC,vEe,zxr,Qxr,KY,Wxr,Hxr,Uxr,jC,FEe,Jxr,Yxr,ZY,Kxr,Zxr,e$r,DC,TEe,o$r,r$r,eK,t$r,a$r,n$r,GC,MEe,s$r,l$r,oK,i$r,d$r,c$r,OC,EEe,f$r,m$r,rK,g$r,h$r,p$r,VC,hVe,Rc,XC,CEe,ux,_$r,wEe,u$r,pVe,fr,bx,b$r,Pc,v$r,tK,F$r,T$r,aK,M$r,E$r,C$r,vx,w$r,AEe,A$r,L$r,y$r,Gt,Fx,x$r,LEe,$$r,k$r,Bc,S$r,yEe,R$r,P$r,nK,B$r,I$r,N$r,zC,q$r,jr,Tx,j$r,xEe,D$r,G$r,un,O$r,$Ee,V$r,X$r,kEe,z$r,Q$r,SEe,W$r,H$r,U$r,ce,QC,REe,J$r,Y$r,sK,K$r,Z$r,ekr,WC,PEe,okr,rkr,lK,tkr,akr,nkr,HC,BEe,skr,lkr,iK,ikr,dkr,ckr,UC,IEe,fkr,mkr,dK,gkr,hkr,pkr,JC,NEe,_kr,ukr,cK,bkr,vkr,Fkr,YC,qEe,Tkr,Mkr,fK,Ekr,Ckr,wkr,KC,jEe,Akr,Lkr,mK,ykr,xkr,$kr,ZC,DEe,kkr,Skr,gK,Rkr,Pkr,Bkr,e5,GEe,Ikr,Nkr,hK,qkr,jkr,Dkr,o5,OEe,Gkr,Okr,pK,Vkr,Xkr,zkr,r5,VEe,Qkr,Wkr,_K,Hkr,Ukr,Jkr,t5,XEe,Ykr,Kkr,uK,Zkr,eSr,oSr,a5,zEe,rSr,tSr,bK,aSr,nSr,sSr,n5,QEe,lSr,iSr,vK,dSr,cSr,fSr,s5,WEe,mSr,gSr,FK,hSr,pSr,_Sr,l5,HEe,uSr,bSr,TK,vSr,FSr,TSr,i5,UEe,MSr,ESr,MK,CSr,wSr,ASr,d5,JEe,LSr,ySr,EK,xSr,$Sr,kSr,c5,YEe,SSr,RSr,CK,PSr,BSr,ISr,f5,KEe,NSr,qSr,wK,jSr,DSr,GSr,m5,_Ve,Ic,g5,ZEe,Mx,OSr,e4e,VSr,uVe,mr,Ex,XSr,Nc,zSr,AK,QSr,WSr,LK,HSr,USr,JSr,Cx,YSr,o4e,KSr,ZSr,eRr,Ot,wx,oRr,r4e,rRr,tRr,qc,aRr,t4e,nRr,sRr,yK,lRr,iRr,dRr,h5,cRr,Dr,Ax,fRr,a4e,mRr,gRr,bn,hRr,n4e,pRr,_Rr,s4e,uRr,bRr,l4e,vRr,FRr,TRr,i4e,p5,d4e,MRr,ERr,xK,CRr,wRr,ARr,_5,bVe,jc,u5,c4e,Lx,LRr,f4e,yRr,vVe,gr,yx,xRr,Dc,$Rr,$K,kRr,SRr,kK,RRr,PRr,BRr,xx,IRr,m4e,NRr,qRr,jRr,Vt,$x,DRr,g4e,GRr,ORr,Gc,VRr,h4e,XRr,zRr,SK,QRr,WRr,HRr,b5,URr,Gr,kx,JRr,p4e,YRr,KRr,vn,ZRr,_4e,ePr,oPr,u4e,rPr,tPr,b4e,aPr,nPr,sPr,v4e,v5,F4e,lPr,iPr,RK,dPr,cPr,fPr,F5,FVe,Oc,T5,T4e,Sx,mPr,M4e,gPr,TVe,hr,Rx,hPr,Vc,pPr,PK,_Pr,uPr,BK,bPr,vPr,FPr,Px,TPr,E4e,MPr,EPr,CPr,Xt,Bx,wPr,C4e,APr,LPr,Xc,yPr,w4e,xPr,$Pr,IK,kPr,SPr,RPr,M5,PPr,Or,Ix,BPr,A4e,IPr,NPr,Fn,qPr,L4e,jPr,DPr,y4e,GPr,OPr,x4e,VPr,XPr,zPr,oe,E5,$4e,QPr,WPr,NK,HPr,UPr,JPr,C5,k4e,YPr,KPr,qK,ZPr,eBr,oBr,w5,S4e,rBr,tBr,jK,aBr,nBr,sBr,A5,R4e,lBr,iBr,DK,dBr,cBr,fBr,L5,P4e,mBr,gBr,GK,hBr,pBr,_Br,y5,B4e,uBr,bBr,OK,vBr,FBr,TBr,x5,I4e,MBr,EBr,VK,CBr,wBr,ABr,$5,N4e,LBr,yBr,XK,xBr,$Br,kBr,k5,q4e,SBr,RBr,zK,PBr,BBr,IBr,S5,j4e,NBr,qBr,QK,jBr,DBr,GBr,R5,D4e,OBr,VBr,WK,XBr,zBr,QBr,P5,G4e,WBr,HBr,HK,UBr,JBr,YBr,B5,O4e,KBr,ZBr,UK,eIr,oIr,rIr,I5,V4e,tIr,aIr,JK,nIr,sIr,lIr,N5,X4e,iIr,dIr,YK,cIr,fIr,mIr,q5,z4e,gIr,hIr,KK,pIr,_Ir,uIr,j5,Q4e,bIr,vIr,ZK,FIr,TIr,MIr,D5,W4e,EIr,CIr,eZ,wIr,AIr,LIr,G5,H4e,yIr,xIr,oZ,$Ir,kIr,SIr,O5,U4e,RIr,PIr,rZ,BIr,IIr,NIr,V5,J4e,qIr,jIr,tZ,DIr,GIr,OIr,X5,Y4e,VIr,XIr,aZ,zIr,QIr,WIr,z5,K4e,HIr,UIr,nZ,JIr,YIr,KIr,Q5,Z4e,ZIr,eNr,sZ,oNr,rNr,tNr,W5,eCe,aNr,nNr,lZ,sNr,lNr,iNr,H5,oCe,dNr,cNr,iZ,fNr,mNr,gNr,U5,rCe,hNr,pNr,dZ,_Nr,uNr,bNr,J5,MVe,zc,Y5,tCe,Nx,vNr,aCe,FNr,EVe,pr,qx,TNr,Qc,MNr,cZ,ENr,CNr,fZ,wNr,ANr,LNr,jx,yNr,nCe,xNr,$Nr,kNr,zt,Dx,SNr,sCe,RNr,PNr,Wc,BNr,lCe,INr,NNr,mZ,qNr,jNr,DNr,K5,GNr,Vr,Gx,ONr,iCe,VNr,XNr,Tn,zNr,dCe,QNr,WNr,cCe,HNr,UNr,fCe,JNr,YNr,KNr,xe,Z5,mCe,ZNr,eqr,gZ,oqr,rqr,tqr,e3,gCe,aqr,nqr,hZ,sqr,lqr,iqr,o3,hCe,dqr,cqr,pZ,fqr,mqr,gqr,r3,pCe,hqr,pqr,_Z,_qr,uqr,bqr,t3,_Ce,vqr,Fqr,uZ,Tqr,Mqr,Eqr,a3,uCe,Cqr,wqr,bZ,Aqr,Lqr,yqr,n3,bCe,xqr,$qr,vZ,kqr,Sqr,Rqr,s3,vCe,Pqr,Bqr,FZ,Iqr,Nqr,qqr,l3,FCe,jqr,Dqr,TZ,Gqr,Oqr,Vqr,i3,TCe,Xqr,zqr,MZ,Qqr,Wqr,Hqr,d3,CVe,Hc,c3,MCe,Ox,Uqr,ECe,Jqr,wVe,_r,Vx,Yqr,Uc,Kqr,EZ,Zqr,ejr,CZ,ojr,rjr,tjr,Xx,ajr,CCe,njr,sjr,ljr,Qt,zx,ijr,wCe,djr,cjr,Jc,fjr,ACe,mjr,gjr,wZ,hjr,pjr,_jr,f3,ujr,Xr,Qx,bjr,LCe,vjr,Fjr,Mn,Tjr,yCe,Mjr,Ejr,xCe,Cjr,wjr,$Ce,Ajr,Ljr,yjr,Ee,m3,kCe,xjr,$jr,AZ,kjr,Sjr,Rjr,g3,SCe,Pjr,Bjr,LZ,Ijr,Njr,qjr,h3,RCe,jjr,Djr,yZ,Gjr,Ojr,Vjr,p3,PCe,Xjr,zjr,xZ,Qjr,Wjr,Hjr,_3,BCe,Ujr,Jjr,$Z,Yjr,Kjr,Zjr,u3,ICe,eDr,oDr,kZ,rDr,tDr,aDr,b3,NCe,nDr,sDr,SZ,lDr,iDr,dDr,v3,qCe,cDr,fDr,RZ,mDr,gDr,hDr,F3,jCe,pDr,_Dr,PZ,uDr,bDr,vDr,T3,DCe,FDr,TDr,BZ,MDr,EDr,CDr,M3,GCe,wDr,ADr,IZ,LDr,yDr,xDr,E3,OCe,$Dr,kDr,NZ,SDr,RDr,PDr,C3,VCe,BDr,IDr,qZ,NDr,qDr,jDr,w3,AVe,Yc,A3,XCe,Wx,DDr,zCe,GDr,LVe,ur,Hx,ODr,Kc,VDr,jZ,XDr,zDr,DZ,QDr,WDr,HDr,Ux,UDr,QCe,JDr,YDr,KDr,Wt,Jx,ZDr,WCe,eGr,oGr,Zc,rGr,HCe,tGr,aGr,GZ,nGr,sGr,lGr,L3,iGr,zr,Yx,dGr,UCe,cGr,fGr,En,mGr,JCe,gGr,hGr,YCe,pGr,_Gr,KCe,uGr,bGr,vGr,$e,y3,ZCe,FGr,TGr,OZ,MGr,EGr,CGr,x3,e5e,wGr,AGr,VZ,LGr,yGr,xGr,$3,o5e,$Gr,kGr,XZ,SGr,RGr,PGr,k3,r5e,BGr,IGr,zZ,NGr,qGr,jGr,S3,t5e,DGr,GGr,QZ,OGr,VGr,XGr,R3,a5e,zGr,QGr,WZ,WGr,HGr,UGr,P3,n5e,JGr,YGr,HZ,KGr,ZGr,eOr,B3,s5e,oOr,rOr,UZ,tOr,aOr,nOr,I3,l5e,sOr,lOr,JZ,iOr,dOr,cOr,N3,i5e,fOr,mOr,YZ,gOr,hOr,pOr,q3,yVe,ef,j3,d5e,Kx,_Or,c5e,uOr,xVe,br,Zx,bOr,of,vOr,KZ,FOr,TOr,ZZ,MOr,EOr,COr,e$,wOr,f5e,AOr,LOr,yOr,Ht,o$,xOr,m5e,$Or,kOr,rf,SOr,g5e,ROr,POr,eee,BOr,IOr,NOr,D3,qOr,Qr,r$,jOr,h5e,DOr,GOr,Cn,OOr,p5e,VOr,XOr,_5e,zOr,QOr,u5e,WOr,HOr,UOr,ke,G3,b5e,JOr,YOr,oee,KOr,ZOr,eVr,O3,v5e,oVr,rVr,ree,tVr,aVr,nVr,V3,F5e,sVr,lVr,tee,iVr,dVr,cVr,X3,T5e,fVr,mVr,aee,gVr,hVr,pVr,z3,M5e,_Vr,uVr,nee,bVr,vVr,FVr,Q3,E5e,TVr,MVr,see,EVr,CVr,wVr,W3,C5e,AVr,LVr,lee,yVr,xVr,$Vr,H3,w5e,kVr,SVr,iee,RVr,PVr,BVr,U3,A5e,IVr,NVr,dee,qVr,jVr,DVr,J3,L5e,GVr,OVr,cee,VVr,XVr,zVr,Y3,$Ve,tf,K3,y5e,t$,QVr,x5e,WVr,kVe,vr,a$,HVr,af,UVr,fee,JVr,YVr,mee,KVr,ZVr,eXr,n$,oXr,$5e,rXr,tXr,aXr,Ut,s$,nXr,k5e,sXr,lXr,nf,iXr,S5e,dXr,cXr,gee,fXr,mXr,gXr,Z3,hXr,Wr,l$,pXr,R5e,_Xr,uXr,wn,bXr,P5e,vXr,FXr,B5e,TXr,MXr,I5e,EXr,CXr,wXr,Se,e0,N5e,AXr,LXr,hee,yXr,xXr,$Xr,o0,q5e,kXr,SXr,pee,RXr,PXr,BXr,r0,j5e,IXr,NXr,_ee,qXr,jXr,DXr,t0,D5e,GXr,OXr,uee,VXr,XXr,zXr,a0,G5e,QXr,WXr,bee,HXr,UXr,JXr,n0,O5e,YXr,KXr,vee,ZXr,ezr,ozr,s0,V5e,rzr,tzr,Fee,azr,nzr,szr,l0,X5e,lzr,izr,Tee,dzr,czr,fzr,i0,z5e,mzr,gzr,Mee,hzr,pzr,_zr,d0,Q5e,uzr,bzr,Eee,vzr,Fzr,Tzr,c0,SVe,sf,f0,W5e,i$,Mzr,H5e,Ezr,RVe,Fr,d$,Czr,lf,wzr,Cee,Azr,Lzr,wee,yzr,xzr,$zr,c$,kzr,U5e,Szr,Rzr,Pzr,Jt,f$,Bzr,J5e,Izr,Nzr,df,qzr,Y5e,jzr,Dzr,Aee,Gzr,Ozr,Vzr,m0,Xzr,Hr,m$,zzr,K5e,Qzr,Wzr,An,Hzr,Z5e,Uzr,Jzr,e3e,Yzr,Kzr,o3e,Zzr,eQr,oQr,Re,g0,r3e,rQr,tQr,Lee,aQr,nQr,sQr,h0,t3e,lQr,iQr,yee,dQr,cQr,fQr,p0,a3e,mQr,gQr,xee,hQr,pQr,_Qr,_0,n3e,uQr,bQr,$ee,vQr,FQr,TQr,u0,s3e,MQr,EQr,kee,CQr,wQr,AQr,b0,l3e,LQr,yQr,See,xQr,$Qr,kQr,v0,i3e,SQr,RQr,Ree,PQr,BQr,IQr,F0,d3e,NQr,qQr,Pee,jQr,DQr,GQr,T0,c3e,OQr,VQr,Bee,XQr,zQr,QQr,M0,f3e,WQr,HQr,Iee,UQr,JQr,YQr,E0,PVe,cf,C0,m3e,g$,KQr,g3e,ZQr,BVe,Tr,h$,eWr,ff,oWr,Nee,rWr,tWr,qee,aWr,nWr,sWr,p$,lWr,h3e,iWr,dWr,cWr,Yt,_$,fWr,p3e,mWr,gWr,mf,hWr,_3e,pWr,_Wr,jee,uWr,bWr,vWr,w0,FWr,Ur,u$,TWr,u3e,MWr,EWr,Ln,CWr,b3e,wWr,AWr,v3e,LWr,yWr,F3e,xWr,$Wr,kWr,Ve,A0,T3e,SWr,RWr,Dee,PWr,BWr,IWr,L0,M3e,NWr,qWr,Gee,jWr,DWr,GWr,y0,E3e,OWr,VWr,Oee,XWr,zWr,QWr,x0,C3e,WWr,HWr,Vee,UWr,JWr,YWr,$0,w3e,KWr,ZWr,Xee,eHr,oHr,rHr,k0,A3e,tHr,aHr,zee,nHr,sHr,lHr,S0,L3e,iHr,dHr,Qee,cHr,fHr,mHr,R0,y3e,gHr,hHr,Wee,pHr,_Hr,uHr,P0,IVe,gf,B0,x3e,b$,bHr,$3e,vHr,NVe,Mr,v$,FHr,hf,THr,Hee,MHr,EHr,Uee,CHr,wHr,AHr,F$,LHr,k3e,yHr,xHr,$Hr,Kt,T$,kHr,S3e,SHr,RHr,pf,PHr,R3e,BHr,IHr,Jee,NHr,qHr,jHr,I0,DHr,Jr,M$,GHr,P3e,OHr,VHr,yn,XHr,B3e,zHr,QHr,I3e,WHr,HHr,N3e,UHr,JHr,YHr,Xe,N0,q3e,KHr,ZHr,Yee,eUr,oUr,rUr,q0,j3e,tUr,aUr,Kee,nUr,sUr,lUr,j0,D3e,iUr,dUr,Zee,cUr,fUr,mUr,D0,G3e,gUr,hUr,eoe,pUr,_Ur,uUr,G0,O3e,bUr,vUr,ooe,FUr,TUr,MUr,O0,V3e,EUr,CUr,roe,wUr,AUr,LUr,V0,X3e,yUr,xUr,toe,$Ur,kUr,SUr,X0,z3e,RUr,PUr,aoe,BUr,IUr,NUr,z0,qVe,_f,Q0,Q3e,E$,qUr,W3e,jUr,jVe,Er,C$,DUr,uf,GUr,noe,OUr,VUr,soe,XUr,zUr,QUr,w$,WUr,H3e,HUr,UUr,JUr,Zt,A$,YUr,U3e,KUr,ZUr,bf,eJr,J3e,oJr,rJr,loe,tJr,aJr,nJr,W0,sJr,Yr,L$,lJr,Y3e,iJr,dJr,xn,cJr,K3e,fJr,mJr,Z3e,gJr,hJr,e0e,pJr,_Jr,uJr,o0e,H0,r0e,bJr,vJr,ioe,FJr,TJr,MJr,U0,DVe,vf,J0,t0e,y$,EJr,a0e,CJr,GVe,Cr,x$,wJr,Ff,AJr,doe,LJr,yJr,coe,xJr,$Jr,kJr,$$,SJr,n0e,RJr,PJr,BJr,ea,k$,IJr,s0e,NJr,qJr,Tf,jJr,l0e,DJr,GJr,foe,OJr,VJr,XJr,Y0,zJr,Kr,S$,QJr,i0e,WJr,HJr,$n,UJr,d0e,JJr,YJr,c0e,KJr,ZJr,f0e,eYr,oYr,rYr,R$,K0,m0e,tYr,aYr,moe,nYr,sYr,lYr,Z0,g0e,iYr,dYr,goe,cYr,fYr,mYr,ew,OVe,Mf,ow,h0e,P$,gYr,p0e,hYr,VVe,wr,B$,pYr,Ef,_Yr,hoe,uYr,bYr,poe,vYr,FYr,TYr,I$,MYr,_0e,EYr,CYr,wYr,oa,N$,AYr,u0e,LYr,yYr,Cf,xYr,b0e,$Yr,kYr,_oe,SYr,RYr,PYr,rw,BYr,Zr,q$,IYr,v0e,NYr,qYr,kn,jYr,F0e,DYr,GYr,T0e,OYr,VYr,M0e,XYr,zYr,QYr,E0e,tw,C0e,WYr,HYr,uoe,UYr,JYr,YYr,aw,XVe;return d=new re({}),xa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),xL=new re({}),$L=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Rf=new KYr({props:{warning:!0,$$slots:{default:[CDt]},$$scope:{ctx:x}}}),kL=new re({}),SL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/configuration_auto.py#L598"}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/configuration_auto.py#L621"}}),Gg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),IL=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/configuration_auto.py#L744"}}),NL=new re({}),qL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/tokenization_auto.py#L400"}}),GL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17776/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/tokenization_auto.py#L414"}}),Eh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),OL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/tokenization_auto.py#L613"}}),VL=new re({}),XL=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),WL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17776/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),ap=new KYr({props:{$$slots:{default:[LDt]},$$scope:{ctx:x}}}),np=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),HL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),UL=new re({}),JL=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/processing_auto.py#L88"}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/processing_auto.py#L102"}}),wp=new KYr({props:{$$slots:{default:[xDt]},$$scope:{ctx:x}}}),Ap=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),ey=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/processing_auto.py#L255"}}),oy=new re({}),ry=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L767"}}),ay=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),xp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),xu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),sy=new re({}),ly=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L774"}}),dy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),ku=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),E7=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),fy=new re({}),my=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L789"}}),hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),w7=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),f1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),_y=new re({}),uy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L796"}}),vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),g1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),Fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),K1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),Ty=new re({}),My=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L803"}}),Cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),e2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),v2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),Ay=new re({}),Ly=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L812"}}),xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),T2=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),$y=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),bb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),ky=new re({}),Sy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L857"}}),Py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),Fb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),By=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),Kb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),Iy=new re({}),Ny=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L864"}}),jy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),ev=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),Dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),iv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),Gy=new re({}),Oy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L850"}}),Xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),cv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),Hv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),Qy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L821"}}),Uy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),Jv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),Jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),Yy=new re({}),Ky=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L828"}}),e8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),o8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),XF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),r8=new re({}),t8=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L873"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),QF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),s6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),l8=new re({}),i8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L912"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),i6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),f8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),f6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),m8=new re({}),g8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L839"}}),p8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),g6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),_6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),u8=new re({}),b8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L919"}}),F8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),b6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),x6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),M8=new re({}),E8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L942"}}),w8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),k6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),q6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[iGt]},$$scope:{ctx:x}}}),L8=new re({}),y8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L926"}}),$8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),D6=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),K6=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),S8=new re({}),R8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L933"}}),B8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),eT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),aT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),q8=new re({}),j8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L951"}}),G8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),sT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),O8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),gT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),V8=new re({}),X8=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L958"}}),Q8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),pT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),FT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),H8=new re({}),U8=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L905"}}),Y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),MT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),K8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),AT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L880"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),yT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),kT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),n9=new re({}),s9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L887"}}),i9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),RT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[MGt]},$$scope:{ctx:x}}}),c9=new re({}),f9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_auto.py#L896"}}),g9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[EGt]},$$scope:{ctx:x}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),XT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[CGt]},$$scope:{ctx:x}}}),p9=new re({}),_9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),b9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),QT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[wGt]},$$scope:{ctx:x}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),jM=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[AGt]},$$scope:{ctx:x}}}),F9=new re({}),T9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),E9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),GM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[LGt]},$$scope:{ctx:x}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),fE=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[yGt]},$$scope:{ctx:x}}}),w9=new re({}),A9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),gE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[xGt]},$$scope:{ctx:x}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),LE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Gt]},$$scope:{ctx:x}}}),$9=new re({}),k9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),R9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),xE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[kGt]},$$scope:{ctx:x}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),PE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[SGt]},$$scope:{ctx:x}}}),B9=new re({}),I9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),IE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[RGt]},$$scope:{ctx:x}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),t4=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PGt]},$$scope:{ctx:x}}}),D9=new re({}),G9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),V9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),n4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BGt]},$$scope:{ctx:x}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),_4=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IGt]},$$scope:{ctx:x}}}),z9=new re({}),Q9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),H9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),b4=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NGt]},$$scope:{ctx:x}}}),U9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),z4=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qGt]},$$scope:{ctx:x}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),W4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[jGt]},$$scope:{ctx:x}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),fC=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[DGt]},$$scope:{ctx:x}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),gC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[GGt]},$$scope:{ctx:x}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),_C=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[OGt]},$$scope:{ctx:x}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),bC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VGt]},$$scope:{ctx:x}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XGt]},$$scope:{ctx:x}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),MC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[zGt]},$$scope:{ctx:x}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),VC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QGt]},$$scope:{ctx:x}}}),ux=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),zC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[WGt]},$$scope:{ctx:x}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[HGt]},$$scope:{ctx:x}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),h5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[UGt]},$$scope:{ctx:x}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),_5=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JGt]},$$scope:{ctx:x}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),b5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[YGt]},$$scope:{ctx:x}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),F5=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[KGt]},$$scope:{ctx:x}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),M5=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[ZGt]},$$scope:{ctx:x}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),J5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[eOt]},$$scope:{ctx:x}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),K5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[oOt]},$$scope:{ctx:x}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),d3=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[rOt]},$$scope:{ctx:x}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),f3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[tOt]},$$scope:{ctx:x}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),w3=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[aOt]},$$scope:{ctx:x}}}),Wx=new re({}),Hx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),L3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[nOt]},$$scope:{ctx:x}}}),Yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),q3=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[sOt]},$$scope:{ctx:x}}}),Kx=new re({}),Zx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),o$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),D3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[lOt]},$$scope:{ctx:x}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),Y3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[iOt]},$$scope:{ctx:x}}}),t$=new re({}),a$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),s$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),Z3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[dOt]},$$scope:{ctx:x}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),c0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[cOt]},$$scope:{ctx:x}}}),i$=new re({}),d$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),f$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),m0=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[fOt]},$$scope:{ctx:x}}}),m$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),E0=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[mOt]},$$scope:{ctx:x}}}),g$=new re({}),h$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),_$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),w0=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[gOt]},$$scope:{ctx:x}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),P0=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[hOt]},$$scope:{ctx:x}}}),b$=new re({}),v$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),T$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),I0=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[pOt]},$$scope:{ctx:x}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),z0=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[_Ot]},$$scope:{ctx:x}}}),E$=new re({}),C$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),A$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),W0=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[uOt]},$$scope:{ctx:x}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),U0=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bOt]},$$scope:{ctx:x}}}),y$=new re({}),x$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),k$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),Y0=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[vOt]},$$scope:{ctx:x}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),ew=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[FOt]},$$scope:{ctx:x}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L389"}}),rw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[TOt]},$$scope:{ctx:x}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17776/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17776/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17776/src/transformers/models/auto/auto_factory.py#L417"}}),aw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[MOt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),yf=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),wL=o("from_pretrained()"),xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Ci=o("Instantiating one of "),Rn=a("a"),AL=o("AutoConfig"),Pn=o(", "),Bn=a("a"),LL=o("AutoModel"),wi=o(`, and
`),In=a("a"),yL=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),$f=l(),F(xa.$$.fragment),We=l(),Ae=a("p"),rS=o("will create a model that is an instance of "),Li=a("a"),tS=o("BertModel"),aS=o("."),Co=l(),$a=a("p"),nS=o("There is one class of "),kf=a("code"),sS=o("AutoModel"),eQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jGe=l(),yi=a("h2"),Sf=a("a"),mte=a("span"),F(xL.$$.fragment),oQe=l(),gte=a("span"),rQe=o("Extending the Auto Classes"),DGe=l(),Nn=a("p"),tQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=a("code"),aQe=o("NewModel"),nQe=o(", make sure you have a "),pte=a("code"),sQe=o("NewModelConfig"),lQe=o(` then you can add those to the auto
classes like this:`),GGe=l(),F($L.$$.fragment),OGe=l(),lS=a("p"),iQe=o("You will then be able to use the auto classes like you would usually do!"),VGe=l(),F(Rf.$$.fragment),XGe=l(),xi=a("h2"),Pf=a("a"),_te=a("span"),F(kL.$$.fragment),dQe=l(),ute=a("span"),cQe=o("AutoConfig"),zGe=l(),wo=a("div"),F(SL.$$.fragment),fQe=l(),RL=a("p"),mQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=a("a"),gQe=o("from_pretrained()"),hQe=o(" class method."),pQe=l(),PL=a("p"),_Qe=o("This class cannot be instantiated directly using "),bte=a("code"),uQe=o("__init__()"),bQe=o(" (throws an error)."),vQe=l(),Ar=a("div"),F(BL.$$.fragment),FQe=l(),vte=a("p"),TQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),MQe=l(),$i=a("p"),EQe=o("The configuration class to instantiate is selected based on the "),Fte=a("code"),CQe=o("model_type"),wQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=a("code"),AQe=o("pretrained_model_name_or_path"),LQe=o(":"),yQe=l(),A=a("ul"),Bf=a("li"),Mte=a("strong"),xQe=o("albert"),$Qe=o(" \u2014 "),dS=a("a"),kQe=o("AlbertConfig"),SQe=o(" (ALBERT model)"),RQe=l(),If=a("li"),Ete=a("strong"),PQe=o("bart"),BQe=o(" \u2014 "),cS=a("a"),IQe=o("BartConfig"),NQe=o(" (BART model)"),qQe=l(),Nf=a("li"),Cte=a("strong"),jQe=o("beit"),DQe=o(" \u2014 "),fS=a("a"),GQe=o("BeitConfig"),OQe=o(" (BEiT model)"),VQe=l(),qf=a("li"),wte=a("strong"),XQe=o("bert"),zQe=o(" \u2014 "),mS=a("a"),QQe=o("BertConfig"),WQe=o(" (BERT model)"),HQe=l(),jf=a("li"),Ate=a("strong"),UQe=o("bert-generation"),JQe=o(" \u2014 "),gS=a("a"),YQe=o("BertGenerationConfig"),KQe=o(" (Bert Generation model)"),ZQe=l(),Df=a("li"),Lte=a("strong"),eWe=o("big_bird"),oWe=o(" \u2014 "),hS=a("a"),rWe=o("BigBirdConfig"),tWe=o(" (BigBird model)"),aWe=l(),Gf=a("li"),yte=a("strong"),nWe=o("bigbird_pegasus"),sWe=o(" \u2014 "),pS=a("a"),lWe=o("BigBirdPegasusConfig"),iWe=o(" (BigBird-Pegasus model)"),dWe=l(),Of=a("li"),xte=a("strong"),cWe=o("blenderbot"),fWe=o(" \u2014 "),_S=a("a"),mWe=o("BlenderbotConfig"),gWe=o(" (Blenderbot model)"),hWe=l(),Vf=a("li"),$te=a("strong"),pWe=o("blenderbot-small"),_We=o(" \u2014 "),uS=a("a"),uWe=o("BlenderbotSmallConfig"),bWe=o(" (BlenderbotSmall model)"),vWe=l(),Xf=a("li"),kte=a("strong"),FWe=o("bloom"),TWe=o(" \u2014 "),bS=a("a"),MWe=o("BloomConfig"),EWe=o(" (BLOOM model)"),CWe=l(),zf=a("li"),Ste=a("strong"),wWe=o("camembert"),AWe=o(" \u2014 "),vS=a("a"),LWe=o("CamembertConfig"),yWe=o(" (CamemBERT model)"),xWe=l(),Qf=a("li"),Rte=a("strong"),$We=o("canine"),kWe=o(" \u2014 "),FS=a("a"),SWe=o("CanineConfig"),RWe=o(" (CANINE model)"),PWe=l(),Wf=a("li"),Pte=a("strong"),BWe=o("clip"),IWe=o(" \u2014 "),TS=a("a"),NWe=o("CLIPConfig"),qWe=o(" (CLIP model)"),jWe=l(),Hf=a("li"),Bte=a("strong"),DWe=o("convbert"),GWe=o(" \u2014 "),MS=a("a"),OWe=o("ConvBertConfig"),VWe=o(" (ConvBERT model)"),XWe=l(),Uf=a("li"),Ite=a("strong"),zWe=o("convnext"),QWe=o(" \u2014 "),ES=a("a"),WWe=o("ConvNextConfig"),HWe=o(" (ConvNeXT model)"),UWe=l(),Jf=a("li"),Nte=a("strong"),JWe=o("ctrl"),YWe=o(" \u2014 "),CS=a("a"),KWe=o("CTRLConfig"),ZWe=o(" (CTRL model)"),eHe=l(),Yf=a("li"),qte=a("strong"),oHe=o("cvt"),rHe=o(" \u2014 "),wS=a("a"),tHe=o("CvtConfig"),aHe=o(" (CvT model)"),nHe=l(),Kf=a("li"),jte=a("strong"),sHe=o("data2vec-audio"),lHe=o(" \u2014 "),AS=a("a"),iHe=o("Data2VecAudioConfig"),dHe=o(" (Data2VecAudio model)"),cHe=l(),Zf=a("li"),Dte=a("strong"),fHe=o("data2vec-text"),mHe=o(" \u2014 "),LS=a("a"),gHe=o("Data2VecTextConfig"),hHe=o(" (Data2VecText model)"),pHe=l(),em=a("li"),Gte=a("strong"),_He=o("data2vec-vision"),uHe=o(" \u2014 "),yS=a("a"),bHe=o("Data2VecVisionConfig"),vHe=o(" (Data2VecVision model)"),FHe=l(),om=a("li"),Ote=a("strong"),THe=o("deberta"),MHe=o(" \u2014 "),xS=a("a"),EHe=o("DebertaConfig"),CHe=o(" (DeBERTa model)"),wHe=l(),rm=a("li"),Vte=a("strong"),AHe=o("deberta-v2"),LHe=o(" \u2014 "),$S=a("a"),yHe=o("DebertaV2Config"),xHe=o(" (DeBERTa-v2 model)"),$He=l(),tm=a("li"),Xte=a("strong"),kHe=o("decision_transformer"),SHe=o(" \u2014 "),kS=a("a"),RHe=o("DecisionTransformerConfig"),PHe=o(" (Decision Transformer model)"),BHe=l(),am=a("li"),zte=a("strong"),IHe=o("deit"),NHe=o(" \u2014 "),SS=a("a"),qHe=o("DeiTConfig"),jHe=o(" (DeiT model)"),DHe=l(),nm=a("li"),Qte=a("strong"),GHe=o("detr"),OHe=o(" \u2014 "),RS=a("a"),VHe=o("DetrConfig"),XHe=o(" (DETR model)"),zHe=l(),sm=a("li"),Wte=a("strong"),QHe=o("distilbert"),WHe=o(" \u2014 "),PS=a("a"),HHe=o("DistilBertConfig"),UHe=o(" (DistilBERT model)"),JHe=l(),lm=a("li"),Hte=a("strong"),YHe=o("dpr"),KHe=o(" \u2014 "),BS=a("a"),ZHe=o("DPRConfig"),eUe=o(" (DPR model)"),oUe=l(),im=a("li"),Ute=a("strong"),rUe=o("dpt"),tUe=o(" \u2014 "),IS=a("a"),aUe=o("DPTConfig"),nUe=o(" (DPT model)"),sUe=l(),dm=a("li"),Jte=a("strong"),lUe=o("electra"),iUe=o(" \u2014 "),NS=a("a"),dUe=o("ElectraConfig"),cUe=o(" (ELECTRA model)"),fUe=l(),cm=a("li"),Yte=a("strong"),mUe=o("encoder-decoder"),gUe=o(" \u2014 "),qS=a("a"),hUe=o("EncoderDecoderConfig"),pUe=o(" (Encoder decoder model)"),_Ue=l(),fm=a("li"),Kte=a("strong"),uUe=o("flaubert"),bUe=o(" \u2014 "),jS=a("a"),vUe=o("FlaubertConfig"),FUe=o(" (FlauBERT model)"),TUe=l(),mm=a("li"),Zte=a("strong"),MUe=o("flava"),EUe=o(" \u2014 "),DS=a("a"),CUe=o("FlavaConfig"),wUe=o(" (FLAVA model)"),AUe=l(),gm=a("li"),eae=a("strong"),LUe=o("fnet"),yUe=o(" \u2014 "),GS=a("a"),xUe=o("FNetConfig"),$Ue=o(" (FNet model)"),kUe=l(),hm=a("li"),oae=a("strong"),SUe=o("fsmt"),RUe=o(" \u2014 "),OS=a("a"),PUe=o("FSMTConfig"),BUe=o(" (FairSeq Machine-Translation model)"),IUe=l(),pm=a("li"),rae=a("strong"),NUe=o("funnel"),qUe=o(" \u2014 "),VS=a("a"),jUe=o("FunnelConfig"),DUe=o(" (Funnel Transformer model)"),GUe=l(),_m=a("li"),tae=a("strong"),OUe=o("glpn"),VUe=o(" \u2014 "),XS=a("a"),XUe=o("GLPNConfig"),zUe=o(" (GLPN model)"),QUe=l(),um=a("li"),aae=a("strong"),WUe=o("gpt2"),HUe=o(" \u2014 "),zS=a("a"),UUe=o("GPT2Config"),JUe=o(" (OpenAI GPT-2 model)"),YUe=l(),bm=a("li"),nae=a("strong"),KUe=o("gpt_neo"),ZUe=o(" \u2014 "),QS=a("a"),eJe=o("GPTNeoConfig"),oJe=o(" (GPT Neo model)"),rJe=l(),vm=a("li"),sae=a("strong"),tJe=o("gpt_neox"),aJe=o(" \u2014 "),WS=a("a"),nJe=o("GPTNeoXConfig"),sJe=o(" (GPT NeoX model)"),lJe=l(),Fm=a("li"),lae=a("strong"),iJe=o("gptj"),dJe=o(" \u2014 "),HS=a("a"),cJe=o("GPTJConfig"),fJe=o(" (GPT-J model)"),mJe=l(),Tm=a("li"),iae=a("strong"),gJe=o("hubert"),hJe=o(" \u2014 "),US=a("a"),pJe=o("HubertConfig"),_Je=o(" (Hubert model)"),uJe=l(),Mm=a("li"),dae=a("strong"),bJe=o("ibert"),vJe=o(" \u2014 "),JS=a("a"),FJe=o("IBertConfig"),TJe=o(" (I-BERT model)"),MJe=l(),Em=a("li"),cae=a("strong"),EJe=o("imagegpt"),CJe=o(" \u2014 "),YS=a("a"),wJe=o("ImageGPTConfig"),AJe=o(" (ImageGPT model)"),LJe=l(),Cm=a("li"),fae=a("strong"),yJe=o("layoutlm"),xJe=o(" \u2014 "),KS=a("a"),$Je=o("LayoutLMConfig"),kJe=o(" (LayoutLM model)"),SJe=l(),wm=a("li"),mae=a("strong"),RJe=o("layoutlmv2"),PJe=o(" \u2014 "),ZS=a("a"),BJe=o("LayoutLMv2Config"),IJe=o(" (LayoutLMv2 model)"),NJe=l(),Am=a("li"),gae=a("strong"),qJe=o("layoutlmv3"),jJe=o(" \u2014 "),eR=a("a"),DJe=o("LayoutLMv3Config"),GJe=o(" (LayoutLMv3 model)"),OJe=l(),Lm=a("li"),hae=a("strong"),VJe=o("led"),XJe=o(" \u2014 "),oR=a("a"),zJe=o("LEDConfig"),QJe=o(" (LED model)"),WJe=l(),ym=a("li"),pae=a("strong"),HJe=o("levit"),UJe=o(" \u2014 "),rR=a("a"),JJe=o("LevitConfig"),YJe=o(" (LeViT model)"),KJe=l(),xm=a("li"),_ae=a("strong"),ZJe=o("longformer"),eYe=o(" \u2014 "),tR=a("a"),oYe=o("LongformerConfig"),rYe=o(" (Longformer model)"),tYe=l(),$m=a("li"),uae=a("strong"),aYe=o("longt5"),nYe=o(" \u2014 "),aR=a("a"),sYe=o("LongT5Config"),lYe=o(" (LongT5 model)"),iYe=l(),km=a("li"),bae=a("strong"),dYe=o("luke"),cYe=o(" \u2014 "),nR=a("a"),fYe=o("LukeConfig"),mYe=o(" (LUKE model)"),gYe=l(),Sm=a("li"),vae=a("strong"),hYe=o("lxmert"),pYe=o(" \u2014 "),sR=a("a"),_Ye=o("LxmertConfig"),uYe=o(" (LXMERT model)"),bYe=l(),Rm=a("li"),Fae=a("strong"),vYe=o("m2m_100"),FYe=o(" \u2014 "),lR=a("a"),TYe=o("M2M100Config"),MYe=o(" (M2M100 model)"),EYe=l(),Pm=a("li"),Tae=a("strong"),CYe=o("marian"),wYe=o(" \u2014 "),iR=a("a"),AYe=o("MarianConfig"),LYe=o(" (Marian model)"),yYe=l(),Bm=a("li"),Mae=a("strong"),xYe=o("maskformer"),$Ye=o(" \u2014 "),dR=a("a"),kYe=o("MaskFormerConfig"),SYe=o(" (MaskFormer model)"),RYe=l(),Im=a("li"),Eae=a("strong"),PYe=o("mbart"),BYe=o(" \u2014 "),cR=a("a"),IYe=o("MBartConfig"),NYe=o(" (mBART model)"),qYe=l(),Nm=a("li"),Cae=a("strong"),jYe=o("mctct"),DYe=o(" \u2014 "),fR=a("a"),GYe=o("MCTCTConfig"),OYe=o(" (M-CTC-T model)"),VYe=l(),qm=a("li"),wae=a("strong"),XYe=o("megatron-bert"),zYe=o(" \u2014 "),mR=a("a"),QYe=o("MegatronBertConfig"),WYe=o(" (Megatron-BERT model)"),HYe=l(),jm=a("li"),Aae=a("strong"),UYe=o("mobilebert"),JYe=o(" \u2014 "),gR=a("a"),YYe=o("MobileBertConfig"),KYe=o(" (MobileBERT model)"),ZYe=l(),Dm=a("li"),Lae=a("strong"),eKe=o("mpnet"),oKe=o(" \u2014 "),hR=a("a"),rKe=o("MPNetConfig"),tKe=o(" (MPNet model)"),aKe=l(),Gm=a("li"),yae=a("strong"),nKe=o("mt5"),sKe=o(" \u2014 "),pR=a("a"),lKe=o("MT5Config"),iKe=o(" (MT5 model)"),dKe=l(),Om=a("li"),xae=a("strong"),cKe=o("nezha"),fKe=o(" \u2014 "),_R=a("a"),mKe=o("NezhaConfig"),gKe=o(" (Nezha model)"),hKe=l(),Vm=a("li"),$ae=a("strong"),pKe=o("nystromformer"),_Ke=o(" \u2014 "),uR=a("a"),uKe=o("NystromformerConfig"),bKe=o(" (Nystr\xF6mformer model)"),vKe=l(),Xm=a("li"),kae=a("strong"),FKe=o("openai-gpt"),TKe=o(" \u2014 "),bR=a("a"),MKe=o("OpenAIGPTConfig"),EKe=o(" (OpenAI GPT model)"),CKe=l(),zm=a("li"),Sae=a("strong"),wKe=o("opt"),AKe=o(" \u2014 "),vR=a("a"),LKe=o("OPTConfig"),yKe=o(" (OPT model)"),xKe=l(),Qm=a("li"),Rae=a("strong"),$Ke=o("pegasus"),kKe=o(" \u2014 "),FR=a("a"),SKe=o("PegasusConfig"),RKe=o(" (Pegasus model)"),PKe=l(),Wm=a("li"),Pae=a("strong"),BKe=o("perceiver"),IKe=o(" \u2014 "),TR=a("a"),NKe=o("PerceiverConfig"),qKe=o(" (Perceiver model)"),jKe=l(),Hm=a("li"),Bae=a("strong"),DKe=o("plbart"),GKe=o(" \u2014 "),MR=a("a"),OKe=o("PLBartConfig"),VKe=o(" (PLBart model)"),XKe=l(),Um=a("li"),Iae=a("strong"),zKe=o("poolformer"),QKe=o(" \u2014 "),ER=a("a"),WKe=o("PoolFormerConfig"),HKe=o(" (PoolFormer model)"),UKe=l(),Jm=a("li"),Nae=a("strong"),JKe=o("prophetnet"),YKe=o(" \u2014 "),CR=a("a"),KKe=o("ProphetNetConfig"),ZKe=o(" (ProphetNet model)"),eZe=l(),Ym=a("li"),qae=a("strong"),oZe=o("qdqbert"),rZe=o(" \u2014 "),wR=a("a"),tZe=o("QDQBertConfig"),aZe=o(" (QDQBert model)"),nZe=l(),Km=a("li"),jae=a("strong"),sZe=o("rag"),lZe=o(" \u2014 "),AR=a("a"),iZe=o("RagConfig"),dZe=o(" (RAG model)"),cZe=l(),Zm=a("li"),Dae=a("strong"),fZe=o("realm"),mZe=o(" \u2014 "),LR=a("a"),gZe=o("RealmConfig"),hZe=o(" (REALM model)"),pZe=l(),eg=a("li"),Gae=a("strong"),_Ze=o("reformer"),uZe=o(" \u2014 "),yR=a("a"),bZe=o("ReformerConfig"),vZe=o(" (Reformer model)"),FZe=l(),og=a("li"),Oae=a("strong"),TZe=o("regnet"),MZe=o(" \u2014 "),xR=a("a"),EZe=o("RegNetConfig"),CZe=o(" (RegNet model)"),wZe=l(),rg=a("li"),Vae=a("strong"),AZe=o("rembert"),LZe=o(" \u2014 "),$R=a("a"),yZe=o("RemBertConfig"),xZe=o(" (RemBERT model)"),$Ze=l(),tg=a("li"),Xae=a("strong"),kZe=o("resnet"),SZe=o(" \u2014 "),kR=a("a"),RZe=o("ResNetConfig"),PZe=o(" (ResNet model)"),BZe=l(),ag=a("li"),zae=a("strong"),IZe=o("retribert"),NZe=o(" \u2014 "),SR=a("a"),qZe=o("RetriBertConfig"),jZe=o(" (RetriBERT model)"),DZe=l(),ng=a("li"),Qae=a("strong"),GZe=o("roberta"),OZe=o(" \u2014 "),RR=a("a"),VZe=o("RobertaConfig"),XZe=o(" (RoBERTa model)"),zZe=l(),sg=a("li"),Wae=a("strong"),QZe=o("roformer"),WZe=o(" \u2014 "),PR=a("a"),HZe=o("RoFormerConfig"),UZe=o(" (RoFormer model)"),JZe=l(),lg=a("li"),Hae=a("strong"),YZe=o("segformer"),KZe=o(" \u2014 "),BR=a("a"),ZZe=o("SegformerConfig"),eeo=o(" (SegFormer model)"),oeo=l(),ig=a("li"),Uae=a("strong"),reo=o("sew"),teo=o(" \u2014 "),IR=a("a"),aeo=o("SEWConfig"),neo=o(" (SEW model)"),seo=l(),dg=a("li"),Jae=a("strong"),leo=o("sew-d"),ieo=o(" \u2014 "),NR=a("a"),deo=o("SEWDConfig"),ceo=o(" (SEW-D model)"),feo=l(),cg=a("li"),Yae=a("strong"),meo=o("speech-encoder-decoder"),geo=o(" \u2014 "),qR=a("a"),heo=o("SpeechEncoderDecoderConfig"),peo=o(" (Speech Encoder decoder model)"),_eo=l(),fg=a("li"),Kae=a("strong"),ueo=o("speech_to_text"),beo=o(" \u2014 "),jR=a("a"),veo=o("Speech2TextConfig"),Feo=o(" (Speech2Text model)"),Teo=l(),mg=a("li"),Zae=a("strong"),Meo=o("speech_to_text_2"),Eeo=o(" \u2014 "),DR=a("a"),Ceo=o("Speech2Text2Config"),weo=o(" (Speech2Text2 model)"),Aeo=l(),gg=a("li"),ene=a("strong"),Leo=o("splinter"),yeo=o(" \u2014 "),GR=a("a"),xeo=o("SplinterConfig"),$eo=o(" (Splinter model)"),keo=l(),hg=a("li"),one=a("strong"),Seo=o("squeezebert"),Reo=o(" \u2014 "),OR=a("a"),Peo=o("SqueezeBertConfig"),Beo=o(" (SqueezeBERT model)"),Ieo=l(),pg=a("li"),rne=a("strong"),Neo=o("swin"),qeo=o(" \u2014 "),VR=a("a"),jeo=o("SwinConfig"),Deo=o(" (Swin Transformer model)"),Geo=l(),_g=a("li"),tne=a("strong"),Oeo=o("t5"),Veo=o(" \u2014 "),XR=a("a"),Xeo=o("T5Config"),zeo=o(" (T5 model)"),Qeo=l(),ug=a("li"),ane=a("strong"),Weo=o("tapas"),Heo=o(" \u2014 "),zR=a("a"),Ueo=o("TapasConfig"),Jeo=o(" (TAPAS model)"),Yeo=l(),bg=a("li"),nne=a("strong"),Keo=o("trajectory_transformer"),Zeo=o(" \u2014 "),QR=a("a"),eoo=o("TrajectoryTransformerConfig"),ooo=o(" (Trajectory Transformer model)"),roo=l(),vg=a("li"),sne=a("strong"),too=o("transfo-xl"),aoo=o(" \u2014 "),WR=a("a"),noo=o("TransfoXLConfig"),soo=o(" (Transformer-XL model)"),loo=l(),Fg=a("li"),lne=a("strong"),ioo=o("trocr"),doo=o(" \u2014 "),HR=a("a"),coo=o("TrOCRConfig"),foo=o(" (TrOCR model)"),moo=l(),Tg=a("li"),ine=a("strong"),goo=o("unispeech"),hoo=o(" \u2014 "),UR=a("a"),poo=o("UniSpeechConfig"),_oo=o(" (UniSpeech model)"),uoo=l(),Mg=a("li"),dne=a("strong"),boo=o("unispeech-sat"),voo=o(" \u2014 "),JR=a("a"),Foo=o("UniSpeechSatConfig"),Too=o(" (UniSpeechSat model)"),Moo=l(),Eg=a("li"),cne=a("strong"),Eoo=o("van"),Coo=o(" \u2014 "),YR=a("a"),woo=o("VanConfig"),Aoo=o(" (VAN model)"),Loo=l(),Cg=a("li"),fne=a("strong"),yoo=o("vilt"),xoo=o(" \u2014 "),KR=a("a"),$oo=o("ViltConfig"),koo=o(" (ViLT model)"),Soo=l(),wg=a("li"),mne=a("strong"),Roo=o("vision-encoder-decoder"),Poo=o(" \u2014 "),ZR=a("a"),Boo=o("VisionEncoderDecoderConfig"),Ioo=o(" (Vision Encoder decoder model)"),Noo=l(),Ag=a("li"),gne=a("strong"),qoo=o("vision-text-dual-encoder"),joo=o(" \u2014 "),eP=a("a"),Doo=o("VisionTextDualEncoderConfig"),Goo=o(" (VisionTextDualEncoder model)"),Ooo=l(),Lg=a("li"),hne=a("strong"),Voo=o("visual_bert"),Xoo=o(" \u2014 "),oP=a("a"),zoo=o("VisualBertConfig"),Qoo=o(" (VisualBERT model)"),Woo=l(),yg=a("li"),pne=a("strong"),Hoo=o("vit"),Uoo=o(" \u2014 "),rP=a("a"),Joo=o("ViTConfig"),Yoo=o(" (ViT model)"),Koo=l(),xg=a("li"),_ne=a("strong"),Zoo=o("vit_mae"),ero=o(" \u2014 "),tP=a("a"),oro=o("ViTMAEConfig"),rro=o(" (ViTMAE model)"),tro=l(),$g=a("li"),une=a("strong"),aro=o("wav2vec2"),nro=o(" \u2014 "),aP=a("a"),sro=o("Wav2Vec2Config"),lro=o(" (Wav2Vec2 model)"),iro=l(),kg=a("li"),bne=a("strong"),dro=o("wav2vec2-conformer"),cro=o(" \u2014 "),nP=a("a"),fro=o("Wav2Vec2ConformerConfig"),mro=o(" (Wav2Vec2-Conformer model)"),gro=l(),Sg=a("li"),vne=a("strong"),hro=o("wavlm"),pro=o(" \u2014 "),sP=a("a"),_ro=o("WavLMConfig"),uro=o(" (WavLM model)"),bro=l(),Rg=a("li"),Fne=a("strong"),vro=o("xglm"),Fro=o(" \u2014 "),lP=a("a"),Tro=o("XGLMConfig"),Mro=o(" (XGLM model)"),Ero=l(),Pg=a("li"),Tne=a("strong"),Cro=o("xlm"),wro=o(" \u2014 "),iP=a("a"),Aro=o("XLMConfig"),Lro=o(" (XLM model)"),yro=l(),Bg=a("li"),Mne=a("strong"),xro=o("xlm-prophetnet"),$ro=o(" \u2014 "),dP=a("a"),kro=o("XLMProphetNetConfig"),Sro=o(" (XLM-ProphetNet model)"),Rro=l(),Ig=a("li"),Ene=a("strong"),Pro=o("xlm-roberta"),Bro=o(" \u2014 "),cP=a("a"),Iro=o("XLMRobertaConfig"),Nro=o(" (XLM-RoBERTa model)"),qro=l(),Ng=a("li"),Cne=a("strong"),jro=o("xlm-roberta-xl"),Dro=o(" \u2014 "),fP=a("a"),Gro=o("XLMRobertaXLConfig"),Oro=o(" (XLM-RoBERTa-XL model)"),Vro=l(),qg=a("li"),wne=a("strong"),Xro=o("xlnet"),zro=o(" \u2014 "),mP=a("a"),Qro=o("XLNetConfig"),Wro=o(" (XLNet model)"),Hro=l(),jg=a("li"),Ane=a("strong"),Uro=o("yolos"),Jro=o(" \u2014 "),gP=a("a"),Yro=o("YolosConfig"),Kro=o(" (YOLOS model)"),Zro=l(),Dg=a("li"),Lne=a("strong"),eto=o("yoso"),oto=o(" \u2014 "),hP=a("a"),rto=o("YosoConfig"),tto=o(" (YOSO model)"),ato=l(),F(Gg.$$.fragment),nto=l(),Og=a("div"),F(IL.$$.fragment),sto=l(),yne=a("p"),lto=o("Register a new configuration for this class."),QGe=l(),ki=a("h2"),Vg=a("a"),xne=a("span"),F(NL.$$.fragment),ito=l(),$ne=a("span"),dto=o("AutoTokenizer"),WGe=l(),Ao=a("div"),F(qL.$$.fragment),cto=l(),jL=a("p"),fto=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=a("a"),mto=o("AutoTokenizer.from_pretrained()"),gto=o(" class method."),hto=l(),DL=a("p"),pto=o("This class cannot be instantiated directly using "),kne=a("code"),_to=o("__init__()"),uto=o(" (throws an error)."),bto=l(),Lr=a("div"),F(GL.$$.fragment),vto=l(),Sne=a("p"),Fto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Tto=l(),ka=a("p"),Mto=o("The tokenizer class to instantiate is selected based on the "),Rne=a("code"),Eto=o("model_type"),Cto=o(` property of the config object (either
passed as an argument or loaded from `),Pne=a("code"),wto=o("pretrained_model_name_or_path"),Ato=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=a("code"),Lto=o("pretrained_model_name_or_path"),yto=o(":"),xto=l(),k=a("ul"),qn=a("li"),Ine=a("strong"),$to=o("albert"),kto=o(" \u2014 "),_P=a("a"),Sto=o("AlbertTokenizer"),Rto=o(" or "),uP=a("a"),Pto=o("AlbertTokenizerFast"),Bto=o(" (ALBERT model)"),Ito=l(),jn=a("li"),Nne=a("strong"),Nto=o("bart"),qto=o(" \u2014 "),bP=a("a"),jto=o("BartTokenizer"),Dto=o(" or "),vP=a("a"),Gto=o("BartTokenizerFast"),Oto=o(" (BART model)"),Vto=l(),Dn=a("li"),qne=a("strong"),Xto=o("barthez"),zto=o(" \u2014 "),FP=a("a"),Qto=o("BarthezTokenizer"),Wto=o(" or "),TP=a("a"),Hto=o("BarthezTokenizerFast"),Uto=o(" (BARThez model)"),Jto=l(),Xg=a("li"),jne=a("strong"),Yto=o("bartpho"),Kto=o(" \u2014 "),MP=a("a"),Zto=o("BartphoTokenizer"),eao=o(" (BARTpho model)"),oao=l(),Gn=a("li"),Dne=a("strong"),rao=o("bert"),tao=o(" \u2014 "),EP=a("a"),aao=o("BertTokenizer"),nao=o(" or "),CP=a("a"),sao=o("BertTokenizerFast"),lao=o(" (BERT model)"),iao=l(),zg=a("li"),Gne=a("strong"),dao=o("bert-generation"),cao=o(" \u2014 "),wP=a("a"),fao=o("BertGenerationTokenizer"),mao=o(" (Bert Generation model)"),gao=l(),Qg=a("li"),One=a("strong"),hao=o("bert-japanese"),pao=o(" \u2014 "),AP=a("a"),_ao=o("BertJapaneseTokenizer"),uao=o(" (BertJapanese model)"),bao=l(),Wg=a("li"),Vne=a("strong"),vao=o("bertweet"),Fao=o(" \u2014 "),LP=a("a"),Tao=o("BertweetTokenizer"),Mao=o(" (BERTweet model)"),Eao=l(),On=a("li"),Xne=a("strong"),Cao=o("big_bird"),wao=o(" \u2014 "),yP=a("a"),Aao=o("BigBirdTokenizer"),Lao=o(" or "),xP=a("a"),yao=o("BigBirdTokenizerFast"),xao=o(" (BigBird model)"),$ao=l(),Vn=a("li"),zne=a("strong"),kao=o("bigbird_pegasus"),Sao=o(" \u2014 "),$P=a("a"),Rao=o("PegasusTokenizer"),Pao=o(" or "),kP=a("a"),Bao=o("PegasusTokenizerFast"),Iao=o(" (BigBird-Pegasus model)"),Nao=l(),Xn=a("li"),Qne=a("strong"),qao=o("blenderbot"),jao=o(" \u2014 "),SP=a("a"),Dao=o("BlenderbotTokenizer"),Gao=o(" or "),RP=a("a"),Oao=o("BlenderbotTokenizerFast"),Vao=o(" (Blenderbot model)"),Xao=l(),Hg=a("li"),Wne=a("strong"),zao=o("blenderbot-small"),Qao=o(" \u2014 "),PP=a("a"),Wao=o("BlenderbotSmallTokenizer"),Hao=o(" (BlenderbotSmall model)"),Uao=l(),Ug=a("li"),Hne=a("strong"),Jao=o("bloom"),Yao=o(" \u2014 "),BP=a("a"),Kao=o("BloomTokenizerFast"),Zao=o(" (BLOOM model)"),eno=l(),Jg=a("li"),Une=a("strong"),ono=o("byt5"),rno=o(" \u2014 "),IP=a("a"),tno=o("ByT5Tokenizer"),ano=o(" (ByT5 model)"),nno=l(),zn=a("li"),Jne=a("strong"),sno=o("camembert"),lno=o(" \u2014 "),NP=a("a"),ino=o("CamembertTokenizer"),dno=o(" or "),qP=a("a"),cno=o("CamembertTokenizerFast"),fno=o(" (CamemBERT model)"),mno=l(),Yg=a("li"),Yne=a("strong"),gno=o("canine"),hno=o(" \u2014 "),jP=a("a"),pno=o("CanineTokenizer"),_no=o(" (CANINE model)"),uno=l(),Qn=a("li"),Kne=a("strong"),bno=o("clip"),vno=o(" \u2014 "),DP=a("a"),Fno=o("CLIPTokenizer"),Tno=o(" or "),GP=a("a"),Mno=o("CLIPTokenizerFast"),Eno=o(" (CLIP model)"),Cno=l(),Wn=a("li"),Zne=a("strong"),wno=o("convbert"),Ano=o(" \u2014 "),OP=a("a"),Lno=o("ConvBertTokenizer"),yno=o(" or "),VP=a("a"),xno=o("ConvBertTokenizerFast"),$no=o(" (ConvBERT model)"),kno=l(),Hn=a("li"),ese=a("strong"),Sno=o("cpm"),Rno=o(" \u2014 "),XP=a("a"),Pno=o("CpmTokenizer"),Bno=o(" or "),zP=a("a"),Ino=o("CpmTokenizerFast"),Nno=o(" (CPM model)"),qno=l(),Kg=a("li"),ose=a("strong"),jno=o("ctrl"),Dno=o(" \u2014 "),QP=a("a"),Gno=o("CTRLTokenizer"),Ono=o(" (CTRL model)"),Vno=l(),Un=a("li"),rse=a("strong"),Xno=o("data2vec-text"),zno=o(" \u2014 "),WP=a("a"),Qno=o("RobertaTokenizer"),Wno=o(" or "),HP=a("a"),Hno=o("RobertaTokenizerFast"),Uno=o(" (Data2VecText model)"),Jno=l(),Jn=a("li"),tse=a("strong"),Yno=o("deberta"),Kno=o(" \u2014 "),UP=a("a"),Zno=o("DebertaTokenizer"),eso=o(" or "),JP=a("a"),oso=o("DebertaTokenizerFast"),rso=o(" (DeBERTa model)"),tso=l(),Yn=a("li"),ase=a("strong"),aso=o("deberta-v2"),nso=o(" \u2014 "),YP=a("a"),sso=o("DebertaV2Tokenizer"),lso=o(" or "),KP=a("a"),iso=o("DebertaV2TokenizerFast"),dso=o(" (DeBERTa-v2 model)"),cso=l(),Kn=a("li"),nse=a("strong"),fso=o("distilbert"),mso=o(" \u2014 "),ZP=a("a"),gso=o("DistilBertTokenizer"),hso=o(" or "),eB=a("a"),pso=o("DistilBertTokenizerFast"),_so=o(" (DistilBERT model)"),uso=l(),Zn=a("li"),sse=a("strong"),bso=o("dpr"),vso=o(" \u2014 "),oB=a("a"),Fso=o("DPRQuestionEncoderTokenizer"),Tso=o(" or "),rB=a("a"),Mso=o("DPRQuestionEncoderTokenizerFast"),Eso=o(" (DPR model)"),Cso=l(),es=a("li"),lse=a("strong"),wso=o("electra"),Aso=o(" \u2014 "),tB=a("a"),Lso=o("ElectraTokenizer"),yso=o(" or "),aB=a("a"),xso=o("ElectraTokenizerFast"),$so=o(" (ELECTRA model)"),kso=l(),Zg=a("li"),ise=a("strong"),Sso=o("flaubert"),Rso=o(" \u2014 "),nB=a("a"),Pso=o("FlaubertTokenizer"),Bso=o(" (FlauBERT model)"),Iso=l(),os=a("li"),dse=a("strong"),Nso=o("fnet"),qso=o(" \u2014 "),sB=a("a"),jso=o("FNetTokenizer"),Dso=o(" or "),lB=a("a"),Gso=o("FNetTokenizerFast"),Oso=o(" (FNet model)"),Vso=l(),eh=a("li"),cse=a("strong"),Xso=o("fsmt"),zso=o(" \u2014 "),iB=a("a"),Qso=o("FSMTTokenizer"),Wso=o(" (FairSeq Machine-Translation model)"),Hso=l(),rs=a("li"),fse=a("strong"),Uso=o("funnel"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("FunnelTokenizer"),Kso=o(" or "),cB=a("a"),Zso=o("FunnelTokenizerFast"),elo=o(" (Funnel Transformer model)"),olo=l(),ts=a("li"),mse=a("strong"),rlo=o("gpt2"),tlo=o(" \u2014 "),fB=a("a"),alo=o("GPT2Tokenizer"),nlo=o(" or "),mB=a("a"),slo=o("GPT2TokenizerFast"),llo=o(" (OpenAI GPT-2 model)"),ilo=l(),as=a("li"),gse=a("strong"),dlo=o("gpt_neo"),clo=o(" \u2014 "),gB=a("a"),flo=o("GPT2Tokenizer"),mlo=o(" or "),hB=a("a"),glo=o("GPT2TokenizerFast"),hlo=o(" (GPT Neo model)"),plo=l(),oh=a("li"),hse=a("strong"),_lo=o("gpt_neox"),ulo=o(" \u2014 "),pB=a("a"),blo=o("GPTNeoXTokenizerFast"),vlo=o(" (GPT NeoX model)"),Flo=l(),ns=a("li"),pse=a("strong"),Tlo=o("gptj"),Mlo=o(" \u2014 "),_B=a("a"),Elo=o("GPT2Tokenizer"),Clo=o(" or "),uB=a("a"),wlo=o("GPT2TokenizerFast"),Alo=o(" (GPT-J model)"),Llo=l(),ss=a("li"),_se=a("strong"),ylo=o("herbert"),xlo=o(" \u2014 "),bB=a("a"),$lo=o("HerbertTokenizer"),klo=o(" or "),vB=a("a"),Slo=o("HerbertTokenizerFast"),Rlo=o(" (HerBERT model)"),Plo=l(),rh=a("li"),use=a("strong"),Blo=o("hubert"),Ilo=o(" \u2014 "),FB=a("a"),Nlo=o("Wav2Vec2CTCTokenizer"),qlo=o(" (Hubert model)"),jlo=l(),ls=a("li"),bse=a("strong"),Dlo=o("ibert"),Glo=o(" \u2014 "),TB=a("a"),Olo=o("RobertaTokenizer"),Vlo=o(" or "),MB=a("a"),Xlo=o("RobertaTokenizerFast"),zlo=o(" (I-BERT model)"),Qlo=l(),is=a("li"),vse=a("strong"),Wlo=o("layoutlm"),Hlo=o(" \u2014 "),EB=a("a"),Ulo=o("LayoutLMTokenizer"),Jlo=o(" or "),CB=a("a"),Ylo=o("LayoutLMTokenizerFast"),Klo=o(" (LayoutLM model)"),Zlo=l(),ds=a("li"),Fse=a("strong"),eio=o("layoutlmv2"),oio=o(" \u2014 "),wB=a("a"),rio=o("LayoutLMv2Tokenizer"),tio=o(" or "),AB=a("a"),aio=o("LayoutLMv2TokenizerFast"),nio=o(" (LayoutLMv2 model)"),sio=l(),cs=a("li"),Tse=a("strong"),lio=o("layoutlmv3"),iio=o(" \u2014 "),LB=a("a"),dio=o("LayoutLMv3Tokenizer"),cio=o(" or "),yB=a("a"),fio=o("LayoutLMv3TokenizerFast"),mio=o(" (LayoutLMv3 model)"),gio=l(),fs=a("li"),Mse=a("strong"),hio=o("layoutxlm"),pio=o(" \u2014 "),xB=a("a"),_io=o("LayoutXLMTokenizer"),uio=o(" or "),$B=a("a"),bio=o("LayoutXLMTokenizerFast"),vio=o(" (LayoutXLM model)"),Fio=l(),ms=a("li"),Ese=a("strong"),Tio=o("led"),Mio=o(" \u2014 "),kB=a("a"),Eio=o("LEDTokenizer"),Cio=o(" or "),SB=a("a"),wio=o("LEDTokenizerFast"),Aio=o(" (LED model)"),Lio=l(),gs=a("li"),Cse=a("strong"),yio=o("longformer"),xio=o(" \u2014 "),RB=a("a"),$io=o("LongformerTokenizer"),kio=o(" or "),PB=a("a"),Sio=o("LongformerTokenizerFast"),Rio=o(" (Longformer model)"),Pio=l(),hs=a("li"),wse=a("strong"),Bio=o("longt5"),Iio=o(" \u2014 "),BB=a("a"),Nio=o("T5Tokenizer"),qio=o(" or "),IB=a("a"),jio=o("T5TokenizerFast"),Dio=o(" (LongT5 model)"),Gio=l(),th=a("li"),Ase=a("strong"),Oio=o("luke"),Vio=o(" \u2014 "),NB=a("a"),Xio=o("LukeTokenizer"),zio=o(" (LUKE model)"),Qio=l(),ps=a("li"),Lse=a("strong"),Wio=o("lxmert"),Hio=o(" \u2014 "),qB=a("a"),Uio=o("LxmertTokenizer"),Jio=o(" or "),jB=a("a"),Yio=o("LxmertTokenizerFast"),Kio=o(" (LXMERT model)"),Zio=l(),ah=a("li"),yse=a("strong"),edo=o("m2m_100"),odo=o(" \u2014 "),DB=a("a"),rdo=o("M2M100Tokenizer"),tdo=o(" (M2M100 model)"),ado=l(),nh=a("li"),xse=a("strong"),ndo=o("marian"),sdo=o(" \u2014 "),GB=a("a"),ldo=o("MarianTokenizer"),ido=o(" (Marian model)"),ddo=l(),_s=a("li"),$se=a("strong"),cdo=o("mbart"),fdo=o(" \u2014 "),OB=a("a"),mdo=o("MBartTokenizer"),gdo=o(" or "),VB=a("a"),hdo=o("MBartTokenizerFast"),pdo=o(" (mBART model)"),_do=l(),us=a("li"),kse=a("strong"),udo=o("mbart50"),bdo=o(" \u2014 "),XB=a("a"),vdo=o("MBart50Tokenizer"),Fdo=o(" or "),zB=a("a"),Tdo=o("MBart50TokenizerFast"),Mdo=o(" (mBART-50 model)"),Edo=l(),bs=a("li"),Sse=a("strong"),Cdo=o("megatron-bert"),wdo=o(" \u2014 "),QB=a("a"),Ado=o("BertTokenizer"),Ldo=o(" or "),WB=a("a"),ydo=o("BertTokenizerFast"),xdo=o(" (Megatron-BERT model)"),$do=l(),sh=a("li"),Rse=a("strong"),kdo=o("mluke"),Sdo=o(" \u2014 "),HB=a("a"),Rdo=o("MLukeTokenizer"),Pdo=o(" (mLUKE model)"),Bdo=l(),vs=a("li"),Pse=a("strong"),Ido=o("mobilebert"),Ndo=o(" \u2014 "),UB=a("a"),qdo=o("MobileBertTokenizer"),jdo=o(" or "),JB=a("a"),Ddo=o("MobileBertTokenizerFast"),Gdo=o(" (MobileBERT model)"),Odo=l(),Fs=a("li"),Bse=a("strong"),Vdo=o("mpnet"),Xdo=o(" \u2014 "),YB=a("a"),zdo=o("MPNetTokenizer"),Qdo=o(" or "),KB=a("a"),Wdo=o("MPNetTokenizerFast"),Hdo=o(" (MPNet model)"),Udo=l(),Ts=a("li"),Ise=a("strong"),Jdo=o("mt5"),Ydo=o(" \u2014 "),ZB=a("a"),Kdo=o("MT5Tokenizer"),Zdo=o(" or "),eI=a("a"),eco=o("MT5TokenizerFast"),oco=o(" (MT5 model)"),rco=l(),Ms=a("li"),Nse=a("strong"),tco=o("nezha"),aco=o(" \u2014 "),oI=a("a"),nco=o("BertTokenizer"),sco=o(" or "),rI=a("a"),lco=o("BertTokenizerFast"),ico=o(" (Nezha model)"),dco=l(),Es=a("li"),qse=a("strong"),cco=o("nystromformer"),fco=o(" \u2014 "),tI=a("a"),mco=o("AlbertTokenizer"),gco=o(" or "),aI=a("a"),hco=o("AlbertTokenizerFast"),pco=o(" (Nystr\xF6mformer model)"),_co=l(),Cs=a("li"),jse=a("strong"),uco=o("openai-gpt"),bco=o(" \u2014 "),nI=a("a"),vco=o("OpenAIGPTTokenizer"),Fco=o(" or "),sI=a("a"),Tco=o("OpenAIGPTTokenizerFast"),Mco=o(" (OpenAI GPT model)"),Eco=l(),lh=a("li"),Dse=a("strong"),Cco=o("opt"),wco=o(" \u2014 "),lI=a("a"),Aco=o("GPT2Tokenizer"),Lco=o(" (OPT model)"),yco=l(),ws=a("li"),Gse=a("strong"),xco=o("pegasus"),$co=o(" \u2014 "),iI=a("a"),kco=o("PegasusTokenizer"),Sco=o(" or "),dI=a("a"),Rco=o("PegasusTokenizerFast"),Pco=o(" (Pegasus model)"),Bco=l(),ih=a("li"),Ose=a("strong"),Ico=o("perceiver"),Nco=o(" \u2014 "),cI=a("a"),qco=o("PerceiverTokenizer"),jco=o(" (Perceiver model)"),Dco=l(),dh=a("li"),Vse=a("strong"),Gco=o("phobert"),Oco=o(" \u2014 "),fI=a("a"),Vco=o("PhobertTokenizer"),Xco=o(" (PhoBERT model)"),zco=l(),ch=a("li"),Xse=a("strong"),Qco=o("plbart"),Wco=o(" \u2014 "),mI=a("a"),Hco=o("PLBartTokenizer"),Uco=o(" (PLBart model)"),Jco=l(),fh=a("li"),zse=a("strong"),Yco=o("prophetnet"),Kco=o(" \u2014 "),gI=a("a"),Zco=o("ProphetNetTokenizer"),efo=o(" (ProphetNet model)"),ofo=l(),As=a("li"),Qse=a("strong"),rfo=o("qdqbert"),tfo=o(" \u2014 "),hI=a("a"),afo=o("BertTokenizer"),nfo=o(" or "),pI=a("a"),sfo=o("BertTokenizerFast"),lfo=o(" (QDQBert model)"),ifo=l(),mh=a("li"),Wse=a("strong"),dfo=o("rag"),cfo=o(" \u2014 "),_I=a("a"),ffo=o("RagTokenizer"),mfo=o(" (RAG model)"),gfo=l(),Ls=a("li"),Hse=a("strong"),hfo=o("realm"),pfo=o(" \u2014 "),uI=a("a"),_fo=o("RealmTokenizer"),ufo=o(" or "),bI=a("a"),bfo=o("RealmTokenizerFast"),vfo=o(" (REALM model)"),Ffo=l(),ys=a("li"),Use=a("strong"),Tfo=o("reformer"),Mfo=o(" \u2014 "),vI=a("a"),Efo=o("ReformerTokenizer"),Cfo=o(" or "),FI=a("a"),wfo=o("ReformerTokenizerFast"),Afo=o(" (Reformer model)"),Lfo=l(),xs=a("li"),Jse=a("strong"),yfo=o("rembert"),xfo=o(" \u2014 "),TI=a("a"),$fo=o("RemBertTokenizer"),kfo=o(" or "),MI=a("a"),Sfo=o("RemBertTokenizerFast"),Rfo=o(" (RemBERT model)"),Pfo=l(),$s=a("li"),Yse=a("strong"),Bfo=o("retribert"),Ifo=o(" \u2014 "),EI=a("a"),Nfo=o("RetriBertTokenizer"),qfo=o(" or "),CI=a("a"),jfo=o("RetriBertTokenizerFast"),Dfo=o(" (RetriBERT model)"),Gfo=l(),ks=a("li"),Kse=a("strong"),Ofo=o("roberta"),Vfo=o(" \u2014 "),wI=a("a"),Xfo=o("RobertaTokenizer"),zfo=o(" or "),AI=a("a"),Qfo=o("RobertaTokenizerFast"),Wfo=o(" (RoBERTa model)"),Hfo=l(),Ss=a("li"),Zse=a("strong"),Ufo=o("roformer"),Jfo=o(" \u2014 "),LI=a("a"),Yfo=o("RoFormerTokenizer"),Kfo=o(" or "),yI=a("a"),Zfo=o("RoFormerTokenizerFast"),emo=o(" (RoFormer model)"),omo=l(),gh=a("li"),ele=a("strong"),rmo=o("speech_to_text"),tmo=o(" \u2014 "),xI=a("a"),amo=o("Speech2TextTokenizer"),nmo=o(" (Speech2Text model)"),smo=l(),hh=a("li"),ole=a("strong"),lmo=o("speech_to_text_2"),imo=o(" \u2014 "),$I=a("a"),dmo=o("Speech2Text2Tokenizer"),cmo=o(" (Speech2Text2 model)"),fmo=l(),Rs=a("li"),rle=a("strong"),mmo=o("splinter"),gmo=o(" \u2014 "),kI=a("a"),hmo=o("SplinterTokenizer"),pmo=o(" or "),SI=a("a"),_mo=o("SplinterTokenizerFast"),umo=o(" (Splinter model)"),bmo=l(),Ps=a("li"),tle=a("strong"),vmo=o("squeezebert"),Fmo=o(" \u2014 "),RI=a("a"),Tmo=o("SqueezeBertTokenizer"),Mmo=o(" or "),PI=a("a"),Emo=o("SqueezeBertTokenizerFast"),Cmo=o(" (SqueezeBERT model)"),wmo=l(),Bs=a("li"),ale=a("strong"),Amo=o("t5"),Lmo=o(" \u2014 "),BI=a("a"),ymo=o("T5Tokenizer"),xmo=o(" or "),II=a("a"),$mo=o("T5TokenizerFast"),kmo=o(" (T5 model)"),Smo=l(),ph=a("li"),nle=a("strong"),Rmo=o("tapas"),Pmo=o(" \u2014 "),NI=a("a"),Bmo=o("TapasTokenizer"),Imo=o(" (TAPAS model)"),Nmo=l(),_h=a("li"),sle=a("strong"),qmo=o("tapex"),jmo=o(" \u2014 "),qI=a("a"),Dmo=o("TapexTokenizer"),Gmo=o(" (TAPEX model)"),Omo=l(),uh=a("li"),lle=a("strong"),Vmo=o("transfo-xl"),Xmo=o(" \u2014 "),jI=a("a"),zmo=o("TransfoXLTokenizer"),Qmo=o(" (Transformer-XL model)"),Wmo=l(),Is=a("li"),ile=a("strong"),Hmo=o("vilt"),Umo=o(" \u2014 "),DI=a("a"),Jmo=o("BertTokenizer"),Ymo=o(" or "),GI=a("a"),Kmo=o("BertTokenizerFast"),Zmo=o(" (ViLT model)"),ego=l(),Ns=a("li"),dle=a("strong"),ogo=o("visual_bert"),rgo=o(" \u2014 "),OI=a("a"),tgo=o("BertTokenizer"),ago=o(" or "),VI=a("a"),ngo=o("BertTokenizerFast"),sgo=o(" (VisualBERT model)"),lgo=l(),bh=a("li"),cle=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),XI=a("a"),cgo=o("Wav2Vec2CTCTokenizer"),fgo=o(" (Wav2Vec2 model)"),mgo=l(),vh=a("li"),fle=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),zI=a("a"),pgo=o("Wav2Vec2CTCTokenizer"),_go=o(" (Wav2Vec2-Conformer model)"),ugo=l(),Fh=a("li"),mle=a("strong"),bgo=o("wav2vec2_phoneme"),vgo=o(" \u2014 "),QI=a("a"),Fgo=o("Wav2Vec2PhonemeCTCTokenizer"),Tgo=o(" (Wav2Vec2Phoneme model)"),Mgo=l(),qs=a("li"),gle=a("strong"),Ego=o("xglm"),Cgo=o(" \u2014 "),WI=a("a"),wgo=o("XGLMTokenizer"),Ago=o(" or "),HI=a("a"),Lgo=o("XGLMTokenizerFast"),ygo=o(" (XGLM model)"),xgo=l(),Th=a("li"),hle=a("strong"),$go=o("xlm"),kgo=o(" \u2014 "),UI=a("a"),Sgo=o("XLMTokenizer"),Rgo=o(" (XLM model)"),Pgo=l(),Mh=a("li"),ple=a("strong"),Bgo=o("xlm-prophetnet"),Igo=o(" \u2014 "),JI=a("a"),Ngo=o("XLMProphetNetTokenizer"),qgo=o(" (XLM-ProphetNet model)"),jgo=l(),js=a("li"),_le=a("strong"),Dgo=o("xlm-roberta"),Ggo=o(" \u2014 "),YI=a("a"),Ogo=o("XLMRobertaTokenizer"),Vgo=o(" or "),KI=a("a"),Xgo=o("XLMRobertaTokenizerFast"),zgo=o(" (XLM-RoBERTa model)"),Qgo=l(),Ds=a("li"),ule=a("strong"),Wgo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),ZI=a("a"),Ugo=o("RobertaTokenizer"),Jgo=o(" or "),eN=a("a"),Ygo=o("RobertaTokenizerFast"),Kgo=o(" (XLM-RoBERTa-XL model)"),Zgo=l(),Gs=a("li"),ble=a("strong"),eho=o("xlnet"),oho=o(" \u2014 "),oN=a("a"),rho=o("XLNetTokenizer"),tho=o(" or "),rN=a("a"),aho=o("XLNetTokenizerFast"),nho=o(" (XLNet model)"),sho=l(),Os=a("li"),vle=a("strong"),lho=o("yoso"),iho=o(" \u2014 "),tN=a("a"),dho=o("AlbertTokenizer"),cho=o(" or "),aN=a("a"),fho=o("AlbertTokenizerFast"),mho=o(" (YOSO model)"),gho=l(),F(Eh.$$.fragment),hho=l(),Ch=a("div"),F(OL.$$.fragment),pho=l(),Fle=a("p"),_ho=o("Register a new tokenizer in this mapping."),HGe=l(),Si=a("h2"),wh=a("a"),Tle=a("span"),F(VL.$$.fragment),uho=l(),Mle=a("span"),bho=o("AutoFeatureExtractor"),UGe=l(),Lo=a("div"),F(XL.$$.fragment),vho=l(),zL=a("p"),Fho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=a("a"),Tho=o("AutoFeatureExtractor.from_pretrained()"),Mho=o(" class method."),Eho=l(),QL=a("p"),Cho=o("This class cannot be instantiated directly using "),Ele=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),He=a("div"),F(WL.$$.fragment),yho=l(),Cle=a("p"),xho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),$ho=l(),Sa=a("p"),kho=o("The feature extractor class to instantiate is selected based on the "),wle=a("code"),Sho=o("model_type"),Rho=o(` property of the config object
(either passed as an argument or loaded from `),Ale=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),Y=a("ul"),Ah=a("li"),yle=a("strong"),jho=o("beit"),Dho=o(" \u2014 "),sN=a("a"),Gho=o("BeitFeatureExtractor"),Oho=o(" (BEiT model)"),Vho=l(),Lh=a("li"),xle=a("strong"),Xho=o("clip"),zho=o(" \u2014 "),lN=a("a"),Qho=o("CLIPFeatureExtractor"),Who=o(" (CLIP model)"),Hho=l(),yh=a("li"),$le=a("strong"),Uho=o("convnext"),Jho=o(" \u2014 "),iN=a("a"),Yho=o("ConvNextFeatureExtractor"),Kho=o(" (ConvNeXT model)"),Zho=l(),xh=a("li"),kle=a("strong"),epo=o("cvt"),opo=o(" \u2014 "),dN=a("a"),rpo=o("ConvNextFeatureExtractor"),tpo=o(" (CvT model)"),apo=l(),$h=a("li"),Sle=a("strong"),npo=o("data2vec-audio"),spo=o(" \u2014 "),cN=a("a"),lpo=o("Wav2Vec2FeatureExtractor"),ipo=o(" (Data2VecAudio model)"),dpo=l(),kh=a("li"),Rle=a("strong"),cpo=o("data2vec-vision"),fpo=o(" \u2014 "),fN=a("a"),mpo=o("BeitFeatureExtractor"),gpo=o(" (Data2VecVision model)"),hpo=l(),Sh=a("li"),Ple=a("strong"),ppo=o("deit"),_po=o(" \u2014 "),mN=a("a"),upo=o("DeiTFeatureExtractor"),bpo=o(" (DeiT model)"),vpo=l(),Rh=a("li"),Ble=a("strong"),Fpo=o("detr"),Tpo=o(" \u2014 "),gN=a("a"),Mpo=o("DetrFeatureExtractor"),Epo=o(" (DETR model)"),Cpo=l(),Ph=a("li"),Ile=a("strong"),wpo=o("dpt"),Apo=o(" \u2014 "),hN=a("a"),Lpo=o("DPTFeatureExtractor"),ypo=o(" (DPT model)"),xpo=l(),Bh=a("li"),Nle=a("strong"),$po=o("flava"),kpo=o(" \u2014 "),pN=a("a"),Spo=o("FlavaFeatureExtractor"),Rpo=o(" (FLAVA model)"),Ppo=l(),Ih=a("li"),qle=a("strong"),Bpo=o("glpn"),Ipo=o(" \u2014 "),_N=a("a"),Npo=o("GLPNFeatureExtractor"),qpo=o(" (GLPN model)"),jpo=l(),Nh=a("li"),jle=a("strong"),Dpo=o("hubert"),Gpo=o(" \u2014 "),uN=a("a"),Opo=o("Wav2Vec2FeatureExtractor"),Vpo=o(" (Hubert model)"),Xpo=l(),qh=a("li"),Dle=a("strong"),zpo=o("imagegpt"),Qpo=o(" \u2014 "),bN=a("a"),Wpo=o("ImageGPTFeatureExtractor"),Hpo=o(" (ImageGPT model)"),Upo=l(),jh=a("li"),Gle=a("strong"),Jpo=o("layoutlmv2"),Ypo=o(" \u2014 "),vN=a("a"),Kpo=o("LayoutLMv2FeatureExtractor"),Zpo=o(" (LayoutLMv2 model)"),e_o=l(),Dh=a("li"),Ole=a("strong"),o_o=o("layoutlmv3"),r_o=o(" \u2014 "),FN=a("a"),t_o=o("LayoutLMv3FeatureExtractor"),a_o=o(" (LayoutLMv3 model)"),n_o=l(),Gh=a("li"),Vle=a("strong"),s_o=o("levit"),l_o=o(" \u2014 "),TN=a("a"),i_o=o("LevitFeatureExtractor"),d_o=o(" (LeViT model)"),c_o=l(),Oh=a("li"),Xle=a("strong"),f_o=o("maskformer"),m_o=o(" \u2014 "),MN=a("a"),g_o=o("MaskFormerFeatureExtractor"),h_o=o(" (MaskFormer model)"),p_o=l(),Vh=a("li"),zle=a("strong"),__o=o("mctct"),u_o=o(" \u2014 "),EN=a("a"),b_o=o("MCTCTFeatureExtractor"),v_o=o(" (M-CTC-T model)"),F_o=l(),Xh=a("li"),Qle=a("strong"),T_o=o("perceiver"),M_o=o(" \u2014 "),CN=a("a"),E_o=o("PerceiverFeatureExtractor"),C_o=o(" (Perceiver model)"),w_o=l(),zh=a("li"),Wle=a("strong"),A_o=o("poolformer"),L_o=o(" \u2014 "),wN=a("a"),y_o=o("PoolFormerFeatureExtractor"),x_o=o(" (PoolFormer model)"),$_o=l(),Qh=a("li"),Hle=a("strong"),k_o=o("regnet"),S_o=o(" \u2014 "),AN=a("a"),R_o=o("ConvNextFeatureExtractor"),P_o=o(" (RegNet model)"),B_o=l(),Wh=a("li"),Ule=a("strong"),I_o=o("resnet"),N_o=o(" \u2014 "),LN=a("a"),q_o=o("ConvNextFeatureExtractor"),j_o=o(" (ResNet model)"),D_o=l(),Hh=a("li"),Jle=a("strong"),G_o=o("segformer"),O_o=o(" \u2014 "),yN=a("a"),V_o=o("SegformerFeatureExtractor"),X_o=o(" (SegFormer model)"),z_o=l(),Uh=a("li"),Yle=a("strong"),Q_o=o("speech_to_text"),W_o=o(" \u2014 "),xN=a("a"),H_o=o("Speech2TextFeatureExtractor"),U_o=o(" (Speech2Text model)"),J_o=l(),Jh=a("li"),Kle=a("strong"),Y_o=o("swin"),K_o=o(" \u2014 "),$N=a("a"),Z_o=o("ViTFeatureExtractor"),euo=o(" (Swin Transformer model)"),ouo=l(),Yh=a("li"),Zle=a("strong"),ruo=o("van"),tuo=o(" \u2014 "),kN=a("a"),auo=o("ConvNextFeatureExtractor"),nuo=o(" (VAN model)"),suo=l(),Kh=a("li"),eie=a("strong"),luo=o("vilt"),iuo=o(" \u2014 "),SN=a("a"),duo=o("ViltFeatureExtractor"),cuo=o(" (ViLT model)"),fuo=l(),Zh=a("li"),oie=a("strong"),muo=o("vit"),guo=o(" \u2014 "),RN=a("a"),huo=o("ViTFeatureExtractor"),puo=o(" (ViT model)"),_uo=l(),ep=a("li"),rie=a("strong"),uuo=o("vit_mae"),buo=o(" \u2014 "),PN=a("a"),vuo=o("ViTFeatureExtractor"),Fuo=o(" (ViTMAE model)"),Tuo=l(),op=a("li"),tie=a("strong"),Muo=o("wav2vec2"),Euo=o(" \u2014 "),BN=a("a"),Cuo=o("Wav2Vec2FeatureExtractor"),wuo=o(" (Wav2Vec2 model)"),Auo=l(),rp=a("li"),aie=a("strong"),Luo=o("wav2vec2-conformer"),yuo=o(" \u2014 "),IN=a("a"),xuo=o("Wav2Vec2FeatureExtractor"),$uo=o(" (Wav2Vec2-Conformer model)"),kuo=l(),tp=a("li"),nie=a("strong"),Suo=o("yolos"),Ruo=o(" \u2014 "),NN=a("a"),Puo=o("YolosFeatureExtractor"),Buo=o(" (YOLOS model)"),Iuo=l(),F(ap.$$.fragment),Nuo=l(),F(np.$$.fragment),quo=l(),sp=a("div"),F(HL.$$.fragment),juo=l(),sie=a("p"),Duo=o("Register a new feature extractor for this class."),JGe=l(),Ri=a("h2"),lp=a("a"),lie=a("span"),F(UL.$$.fragment),Guo=l(),iie=a("span"),Ouo=o("AutoProcessor"),YGe=l(),yo=a("div"),F(JL.$$.fragment),Vuo=l(),YL=a("p"),Xuo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=a("a"),zuo=o("AutoProcessor.from_pretrained()"),Quo=o(" class method."),Wuo=l(),KL=a("p"),Huo=o("This class cannot be instantiated directly using "),die=a("code"),Uuo=o("__init__()"),Juo=o(" (throws an error)."),Yuo=l(),Ue=a("div"),F(ZL.$$.fragment),Kuo=l(),cie=a("p"),Zuo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),e7o=l(),Pi=a("p"),o7o=o("The processor class to instantiate is selected based on the "),fie=a("code"),r7o=o("model_type"),t7o=o(` property of the config object (either
passed as an argument or loaded from `),mie=a("code"),a7o=o("pretrained_model_name_or_path"),n7o=o(" if possible):"),s7o=l(),he=a("ul"),ip=a("li"),gie=a("strong"),l7o=o("clip"),i7o=o(" \u2014 "),jN=a("a"),d7o=o("CLIPProcessor"),c7o=o(" (CLIP model)"),f7o=l(),dp=a("li"),hie=a("strong"),m7o=o("flava"),g7o=o(" \u2014 "),pie=a("code"),h7o=o("FLAVAProcessor"),p7o=o(" (FLAVA model)"),_7o=l(),cp=a("li"),_ie=a("strong"),u7o=o("layoutlmv2"),b7o=o(" \u2014 "),DN=a("a"),v7o=o("LayoutLMv2Processor"),F7o=o(" (LayoutLMv2 model)"),T7o=l(),fp=a("li"),uie=a("strong"),M7o=o("layoutlmv3"),E7o=o(" \u2014 "),GN=a("a"),C7o=o("LayoutLMv3Processor"),w7o=o(" (LayoutLMv3 model)"),A7o=l(),mp=a("li"),bie=a("strong"),L7o=o("layoutxlm"),y7o=o(" \u2014 "),ON=a("a"),x7o=o("LayoutXLMProcessor"),$7o=o(" (LayoutXLM model)"),k7o=l(),gp=a("li"),vie=a("strong"),S7o=o("sew"),R7o=o(" \u2014 "),VN=a("a"),P7o=o("Wav2Vec2Processor"),B7o=o(" (SEW model)"),I7o=l(),hp=a("li"),Fie=a("strong"),N7o=o("sew-d"),q7o=o(" \u2014 "),XN=a("a"),j7o=o("Wav2Vec2Processor"),D7o=o(" (SEW-D model)"),G7o=l(),pp=a("li"),Tie=a("strong"),O7o=o("speech_to_text"),V7o=o(" \u2014 "),zN=a("a"),X7o=o("Speech2TextProcessor"),z7o=o(" (Speech2Text model)"),Q7o=l(),_p=a("li"),Mie=a("strong"),W7o=o("speech_to_text_2"),H7o=o(" \u2014 "),QN=a("a"),U7o=o("Speech2Text2Processor"),J7o=o(" (Speech2Text2 model)"),Y7o=l(),up=a("li"),Eie=a("strong"),K7o=o("trocr"),Z7o=o(" \u2014 "),WN=a("a"),e1o=o("TrOCRProcessor"),o1o=o(" (TrOCR model)"),r1o=l(),bp=a("li"),Cie=a("strong"),t1o=o("unispeech"),a1o=o(" \u2014 "),HN=a("a"),n1o=o("Wav2Vec2Processor"),s1o=o(" (UniSpeech model)"),l1o=l(),vp=a("li"),wie=a("strong"),i1o=o("unispeech-sat"),d1o=o(" \u2014 "),UN=a("a"),c1o=o("Wav2Vec2Processor"),f1o=o(" (UniSpeechSat model)"),m1o=l(),Fp=a("li"),Aie=a("strong"),g1o=o("vilt"),h1o=o(" \u2014 "),JN=a("a"),p1o=o("ViltProcessor"),_1o=o(" (ViLT model)"),u1o=l(),Tp=a("li"),Lie=a("strong"),b1o=o("vision-text-dual-encoder"),v1o=o(" \u2014 "),YN=a("a"),F1o=o("VisionTextDualEncoderProcessor"),T1o=o(" (VisionTextDualEncoder model)"),M1o=l(),Mp=a("li"),yie=a("strong"),E1o=o("wav2vec2"),C1o=o(" \u2014 "),KN=a("a"),w1o=o("Wav2Vec2Processor"),A1o=o(" (Wav2Vec2 model)"),L1o=l(),Ep=a("li"),xie=a("strong"),y1o=o("wav2vec2-conformer"),x1o=o(" \u2014 "),ZN=a("a"),$1o=o("Wav2Vec2Processor"),k1o=o(" (Wav2Vec2-Conformer model)"),S1o=l(),Cp=a("li"),$ie=a("strong"),R1o=o("wavlm"),P1o=o(" \u2014 "),eq=a("a"),B1o=o("Wav2Vec2Processor"),I1o=o(" (WavLM model)"),N1o=l(),F(wp.$$.fragment),q1o=l(),F(Ap.$$.fragment),j1o=l(),Lp=a("div"),F(ey.$$.fragment),D1o=l(),kie=a("p"),G1o=o("Register a new processor for this class."),KGe=l(),Bi=a("h2"),yp=a("a"),Sie=a("span"),F(oy.$$.fragment),O1o=l(),Rie=a("span"),V1o=o("AutoModel"),ZGe=l(),xo=a("div"),F(ry.$$.fragment),X1o=l(),Ii=a("p"),z1o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=a("a"),Q1o=o("from_pretrained()"),W1o=o(" class method or the "),rq=a("a"),H1o=o("from_config()"),U1o=o(` class
method.`),J1o=l(),ty=a("p"),Y1o=o("This class cannot be instantiated directly using "),Pie=a("code"),K1o=o("__init__()"),Z1o=o(" (throws an error)."),e2o=l(),nt=a("div"),F(ay.$$.fragment),o2o=l(),Bie=a("p"),r2o=o("Instantiates one of the base model classes of the library from a configuration."),t2o=l(),Ni=a("p"),a2o=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),n2o=o("not"),s2o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=a("a"),l2o=o("from_pretrained()"),i2o=o(" to load the model weights."),d2o=l(),F(xp.$$.fragment),c2o=l(),Je=a("div"),F(ny.$$.fragment),f2o=l(),Nie=a("p"),m2o=o("Instantiate one of the base model classes of the library from a pretrained model."),g2o=l(),Ra=a("p"),h2o=o("The model class to instantiate is selected based on the "),qie=a("code"),p2o=o("model_type"),_2o=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),u2o=o("pretrained_model_name_or_path"),b2o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),v2o=o("pretrained_model_name_or_path"),F2o=o(":"),T2o=l(),y=a("ul"),$p=a("li"),Gie=a("strong"),M2o=o("albert"),E2o=o(" \u2014 "),aq=a("a"),C2o=o("AlbertModel"),w2o=o(" (ALBERT model)"),A2o=l(),kp=a("li"),Oie=a("strong"),L2o=o("bart"),y2o=o(" \u2014 "),nq=a("a"),x2o=o("BartModel"),$2o=o(" (BART model)"),k2o=l(),Sp=a("li"),Vie=a("strong"),S2o=o("beit"),R2o=o(" \u2014 "),sq=a("a"),P2o=o("BeitModel"),B2o=o(" (BEiT model)"),I2o=l(),Rp=a("li"),Xie=a("strong"),N2o=o("bert"),q2o=o(" \u2014 "),lq=a("a"),j2o=o("BertModel"),D2o=o(" (BERT model)"),G2o=l(),Pp=a("li"),zie=a("strong"),O2o=o("bert-generation"),V2o=o(" \u2014 "),iq=a("a"),X2o=o("BertGenerationEncoder"),z2o=o(" (Bert Generation model)"),Q2o=l(),Bp=a("li"),Qie=a("strong"),W2o=o("big_bird"),H2o=o(" \u2014 "),dq=a("a"),U2o=o("BigBirdModel"),J2o=o(" (BigBird model)"),Y2o=l(),Ip=a("li"),Wie=a("strong"),K2o=o("bigbird_pegasus"),Z2o=o(" \u2014 "),cq=a("a"),ebo=o("BigBirdPegasusModel"),obo=o(" (BigBird-Pegasus model)"),rbo=l(),Np=a("li"),Hie=a("strong"),tbo=o("blenderbot"),abo=o(" \u2014 "),fq=a("a"),nbo=o("BlenderbotModel"),sbo=o(" (Blenderbot model)"),lbo=l(),qp=a("li"),Uie=a("strong"),ibo=o("blenderbot-small"),dbo=o(" \u2014 "),mq=a("a"),cbo=o("BlenderbotSmallModel"),fbo=o(" (BlenderbotSmall model)"),mbo=l(),jp=a("li"),Jie=a("strong"),gbo=o("bloom"),hbo=o(" \u2014 "),gq=a("a"),pbo=o("BloomModel"),_bo=o(" (BLOOM model)"),ubo=l(),Dp=a("li"),Yie=a("strong"),bbo=o("camembert"),vbo=o(" \u2014 "),hq=a("a"),Fbo=o("CamembertModel"),Tbo=o(" (CamemBERT model)"),Mbo=l(),Gp=a("li"),Kie=a("strong"),Ebo=o("canine"),Cbo=o(" \u2014 "),pq=a("a"),wbo=o("CanineModel"),Abo=o(" (CANINE model)"),Lbo=l(),Op=a("li"),Zie=a("strong"),ybo=o("clip"),xbo=o(" \u2014 "),_q=a("a"),$bo=o("CLIPModel"),kbo=o(" (CLIP model)"),Sbo=l(),Vp=a("li"),ede=a("strong"),Rbo=o("convbert"),Pbo=o(" \u2014 "),uq=a("a"),Bbo=o("ConvBertModel"),Ibo=o(" (ConvBERT model)"),Nbo=l(),Xp=a("li"),ode=a("strong"),qbo=o("convnext"),jbo=o(" \u2014 "),bq=a("a"),Dbo=o("ConvNextModel"),Gbo=o(" (ConvNeXT model)"),Obo=l(),zp=a("li"),rde=a("strong"),Vbo=o("ctrl"),Xbo=o(" \u2014 "),vq=a("a"),zbo=o("CTRLModel"),Qbo=o(" (CTRL model)"),Wbo=l(),Qp=a("li"),tde=a("strong"),Hbo=o("cvt"),Ubo=o(" \u2014 "),Fq=a("a"),Jbo=o("CvtModel"),Ybo=o(" (CvT model)"),Kbo=l(),Wp=a("li"),ade=a("strong"),Zbo=o("data2vec-audio"),evo=o(" \u2014 "),Tq=a("a"),ovo=o("Data2VecAudioModel"),rvo=o(" (Data2VecAudio model)"),tvo=l(),Hp=a("li"),nde=a("strong"),avo=o("data2vec-text"),nvo=o(" \u2014 "),Mq=a("a"),svo=o("Data2VecTextModel"),lvo=o(" (Data2VecText model)"),ivo=l(),Up=a("li"),sde=a("strong"),dvo=o("data2vec-vision"),cvo=o(" \u2014 "),Eq=a("a"),fvo=o("Data2VecVisionModel"),mvo=o(" (Data2VecVision model)"),gvo=l(),Jp=a("li"),lde=a("strong"),hvo=o("deberta"),pvo=o(" \u2014 "),Cq=a("a"),_vo=o("DebertaModel"),uvo=o(" (DeBERTa model)"),bvo=l(),Yp=a("li"),ide=a("strong"),vvo=o("deberta-v2"),Fvo=o(" \u2014 "),wq=a("a"),Tvo=o("DebertaV2Model"),Mvo=o(" (DeBERTa-v2 model)"),Evo=l(),Kp=a("li"),dde=a("strong"),Cvo=o("decision_transformer"),wvo=o(" \u2014 "),Aq=a("a"),Avo=o("DecisionTransformerModel"),Lvo=o(" (Decision Transformer model)"),yvo=l(),Zp=a("li"),cde=a("strong"),xvo=o("deit"),$vo=o(" \u2014 "),Lq=a("a"),kvo=o("DeiTModel"),Svo=o(" (DeiT model)"),Rvo=l(),e_=a("li"),fde=a("strong"),Pvo=o("detr"),Bvo=o(" \u2014 "),yq=a("a"),Ivo=o("DetrModel"),Nvo=o(" (DETR model)"),qvo=l(),o_=a("li"),mde=a("strong"),jvo=o("distilbert"),Dvo=o(" \u2014 "),xq=a("a"),Gvo=o("DistilBertModel"),Ovo=o(" (DistilBERT model)"),Vvo=l(),r_=a("li"),gde=a("strong"),Xvo=o("dpr"),zvo=o(" \u2014 "),$q=a("a"),Qvo=o("DPRQuestionEncoder"),Wvo=o(" (DPR model)"),Hvo=l(),t_=a("li"),hde=a("strong"),Uvo=o("dpt"),Jvo=o(" \u2014 "),kq=a("a"),Yvo=o("DPTModel"),Kvo=o(" (DPT model)"),Zvo=l(),a_=a("li"),pde=a("strong"),eFo=o("electra"),oFo=o(" \u2014 "),Sq=a("a"),rFo=o("ElectraModel"),tFo=o(" (ELECTRA model)"),aFo=l(),n_=a("li"),_de=a("strong"),nFo=o("flaubert"),sFo=o(" \u2014 "),Rq=a("a"),lFo=o("FlaubertModel"),iFo=o(" (FlauBERT model)"),dFo=l(),s_=a("li"),ude=a("strong"),cFo=o("flava"),fFo=o(" \u2014 "),Pq=a("a"),mFo=o("FlavaModel"),gFo=o(" (FLAVA model)"),hFo=l(),l_=a("li"),bde=a("strong"),pFo=o("fnet"),_Fo=o(" \u2014 "),Bq=a("a"),uFo=o("FNetModel"),bFo=o(" (FNet model)"),vFo=l(),i_=a("li"),vde=a("strong"),FFo=o("fsmt"),TFo=o(" \u2014 "),Iq=a("a"),MFo=o("FSMTModel"),EFo=o(" (FairSeq Machine-Translation model)"),CFo=l(),Vs=a("li"),Fde=a("strong"),wFo=o("funnel"),AFo=o(" \u2014 "),Nq=a("a"),LFo=o("FunnelModel"),yFo=o(" or "),qq=a("a"),xFo=o("FunnelBaseModel"),$Fo=o(" (Funnel Transformer model)"),kFo=l(),d_=a("li"),Tde=a("strong"),SFo=o("glpn"),RFo=o(" \u2014 "),jq=a("a"),PFo=o("GLPNModel"),BFo=o(" (GLPN model)"),IFo=l(),c_=a("li"),Mde=a("strong"),NFo=o("gpt2"),qFo=o(" \u2014 "),Dq=a("a"),jFo=o("GPT2Model"),DFo=o(" (OpenAI GPT-2 model)"),GFo=l(),f_=a("li"),Ede=a("strong"),OFo=o("gpt_neo"),VFo=o(" \u2014 "),Gq=a("a"),XFo=o("GPTNeoModel"),zFo=o(" (GPT Neo model)"),QFo=l(),m_=a("li"),Cde=a("strong"),WFo=o("gpt_neox"),HFo=o(" \u2014 "),Oq=a("a"),UFo=o("GPTNeoXModel"),JFo=o(" (GPT NeoX model)"),YFo=l(),g_=a("li"),wde=a("strong"),KFo=o("gptj"),ZFo=o(" \u2014 "),Vq=a("a"),e6o=o("GPTJModel"),o6o=o(" (GPT-J model)"),r6o=l(),h_=a("li"),Ade=a("strong"),t6o=o("hubert"),a6o=o(" \u2014 "),Xq=a("a"),n6o=o("HubertModel"),s6o=o(" (Hubert model)"),l6o=l(),p_=a("li"),Lde=a("strong"),i6o=o("ibert"),d6o=o(" \u2014 "),zq=a("a"),c6o=o("IBertModel"),f6o=o(" (I-BERT model)"),m6o=l(),__=a("li"),yde=a("strong"),g6o=o("imagegpt"),h6o=o(" \u2014 "),Qq=a("a"),p6o=o("ImageGPTModel"),_6o=o(" (ImageGPT model)"),u6o=l(),u_=a("li"),xde=a("strong"),b6o=o("layoutlm"),v6o=o(" \u2014 "),Wq=a("a"),F6o=o("LayoutLMModel"),T6o=o(" (LayoutLM model)"),M6o=l(),b_=a("li"),$de=a("strong"),E6o=o("layoutlmv2"),C6o=o(" \u2014 "),Hq=a("a"),w6o=o("LayoutLMv2Model"),A6o=o(" (LayoutLMv2 model)"),L6o=l(),v_=a("li"),kde=a("strong"),y6o=o("layoutlmv3"),x6o=o(" \u2014 "),Uq=a("a"),$6o=o("LayoutLMv3Model"),k6o=o(" (LayoutLMv3 model)"),S6o=l(),F_=a("li"),Sde=a("strong"),R6o=o("led"),P6o=o(" \u2014 "),Jq=a("a"),B6o=o("LEDModel"),I6o=o(" (LED model)"),N6o=l(),T_=a("li"),Rde=a("strong"),q6o=o("levit"),j6o=o(" \u2014 "),Yq=a("a"),D6o=o("LevitModel"),G6o=o(" (LeViT model)"),O6o=l(),M_=a("li"),Pde=a("strong"),V6o=o("longformer"),X6o=o(" \u2014 "),Kq=a("a"),z6o=o("LongformerModel"),Q6o=o(" (Longformer model)"),W6o=l(),E_=a("li"),Bde=a("strong"),H6o=o("longt5"),U6o=o(" \u2014 "),Zq=a("a"),J6o=o("LongT5Model"),Y6o=o(" (LongT5 model)"),K6o=l(),C_=a("li"),Ide=a("strong"),Z6o=o("luke"),eTo=o(" \u2014 "),ej=a("a"),oTo=o("LukeModel"),rTo=o(" (LUKE model)"),tTo=l(),w_=a("li"),Nde=a("strong"),aTo=o("lxmert"),nTo=o(" \u2014 "),oj=a("a"),sTo=o("LxmertModel"),lTo=o(" (LXMERT model)"),iTo=l(),A_=a("li"),qde=a("strong"),dTo=o("m2m_100"),cTo=o(" \u2014 "),rj=a("a"),fTo=o("M2M100Model"),mTo=o(" (M2M100 model)"),gTo=l(),L_=a("li"),jde=a("strong"),hTo=o("marian"),pTo=o(" \u2014 "),tj=a("a"),_To=o("MarianModel"),uTo=o(" (Marian model)"),bTo=l(),y_=a("li"),Dde=a("strong"),vTo=o("maskformer"),FTo=o(" \u2014 "),aj=a("a"),TTo=o("MaskFormerModel"),MTo=o(" (MaskFormer model)"),ETo=l(),x_=a("li"),Gde=a("strong"),CTo=o("mbart"),wTo=o(" \u2014 "),nj=a("a"),ATo=o("MBartModel"),LTo=o(" (mBART model)"),yTo=l(),$_=a("li"),Ode=a("strong"),xTo=o("mctct"),$To=o(" \u2014 "),sj=a("a"),kTo=o("MCTCTModel"),STo=o(" (M-CTC-T model)"),RTo=l(),k_=a("li"),Vde=a("strong"),PTo=o("megatron-bert"),BTo=o(" \u2014 "),lj=a("a"),ITo=o("MegatronBertModel"),NTo=o(" (Megatron-BERT model)"),qTo=l(),S_=a("li"),Xde=a("strong"),jTo=o("mobilebert"),DTo=o(" \u2014 "),ij=a("a"),GTo=o("MobileBertModel"),OTo=o(" (MobileBERT model)"),VTo=l(),R_=a("li"),zde=a("strong"),XTo=o("mpnet"),zTo=o(" \u2014 "),dj=a("a"),QTo=o("MPNetModel"),WTo=o(" (MPNet model)"),HTo=l(),P_=a("li"),Qde=a("strong"),UTo=o("mt5"),JTo=o(" \u2014 "),cj=a("a"),YTo=o("MT5Model"),KTo=o(" (MT5 model)"),ZTo=l(),B_=a("li"),Wde=a("strong"),eMo=o("nezha"),oMo=o(" \u2014 "),fj=a("a"),rMo=o("NezhaModel"),tMo=o(" (Nezha model)"),aMo=l(),I_=a("li"),Hde=a("strong"),nMo=o("nystromformer"),sMo=o(" \u2014 "),mj=a("a"),lMo=o("NystromformerModel"),iMo=o(" (Nystr\xF6mformer model)"),dMo=l(),N_=a("li"),Ude=a("strong"),cMo=o("openai-gpt"),fMo=o(" \u2014 "),gj=a("a"),mMo=o("OpenAIGPTModel"),gMo=o(" (OpenAI GPT model)"),hMo=l(),q_=a("li"),Jde=a("strong"),pMo=o("opt"),_Mo=o(" \u2014 "),hj=a("a"),uMo=o("OPTModel"),bMo=o(" (OPT model)"),vMo=l(),j_=a("li"),Yde=a("strong"),FMo=o("pegasus"),TMo=o(" \u2014 "),pj=a("a"),MMo=o("PegasusModel"),EMo=o(" (Pegasus model)"),CMo=l(),D_=a("li"),Kde=a("strong"),wMo=o("perceiver"),AMo=o(" \u2014 "),_j=a("a"),LMo=o("PerceiverModel"),yMo=o(" (Perceiver model)"),xMo=l(),G_=a("li"),Zde=a("strong"),$Mo=o("plbart"),kMo=o(" \u2014 "),uj=a("a"),SMo=o("PLBartModel"),RMo=o(" (PLBart model)"),PMo=l(),O_=a("li"),ece=a("strong"),BMo=o("poolformer"),IMo=o(" \u2014 "),bj=a("a"),NMo=o("PoolFormerModel"),qMo=o(" (PoolFormer model)"),jMo=l(),V_=a("li"),oce=a("strong"),DMo=o("prophetnet"),GMo=o(" \u2014 "),vj=a("a"),OMo=o("ProphetNetModel"),VMo=o(" (ProphetNet model)"),XMo=l(),X_=a("li"),rce=a("strong"),zMo=o("qdqbert"),QMo=o(" \u2014 "),Fj=a("a"),WMo=o("QDQBertModel"),HMo=o(" (QDQBert model)"),UMo=l(),z_=a("li"),tce=a("strong"),JMo=o("reformer"),YMo=o(" \u2014 "),Tj=a("a"),KMo=o("ReformerModel"),ZMo=o(" (Reformer model)"),eEo=l(),Q_=a("li"),ace=a("strong"),oEo=o("regnet"),rEo=o(" \u2014 "),Mj=a("a"),tEo=o("RegNetModel"),aEo=o(" (RegNet model)"),nEo=l(),W_=a("li"),nce=a("strong"),sEo=o("rembert"),lEo=o(" \u2014 "),Ej=a("a"),iEo=o("RemBertModel"),dEo=o(" (RemBERT model)"),cEo=l(),H_=a("li"),sce=a("strong"),fEo=o("resnet"),mEo=o(" \u2014 "),Cj=a("a"),gEo=o("ResNetModel"),hEo=o(" (ResNet model)"),pEo=l(),U_=a("li"),lce=a("strong"),_Eo=o("retribert"),uEo=o(" \u2014 "),wj=a("a"),bEo=o("RetriBertModel"),vEo=o(" (RetriBERT model)"),FEo=l(),J_=a("li"),ice=a("strong"),TEo=o("roberta"),MEo=o(" \u2014 "),Aj=a("a"),EEo=o("RobertaModel"),CEo=o(" (RoBERTa model)"),wEo=l(),Y_=a("li"),dce=a("strong"),AEo=o("roformer"),LEo=o(" \u2014 "),Lj=a("a"),yEo=o("RoFormerModel"),xEo=o(" (RoFormer model)"),$Eo=l(),K_=a("li"),cce=a("strong"),kEo=o("segformer"),SEo=o(" \u2014 "),yj=a("a"),REo=o("SegformerModel"),PEo=o(" (SegFormer model)"),BEo=l(),Z_=a("li"),fce=a("strong"),IEo=o("sew"),NEo=o(" \u2014 "),xj=a("a"),qEo=o("SEWModel"),jEo=o(" (SEW model)"),DEo=l(),eu=a("li"),mce=a("strong"),GEo=o("sew-d"),OEo=o(" \u2014 "),$j=a("a"),VEo=o("SEWDModel"),XEo=o(" (SEW-D model)"),zEo=l(),ou=a("li"),gce=a("strong"),QEo=o("speech_to_text"),WEo=o(" \u2014 "),kj=a("a"),HEo=o("Speech2TextModel"),UEo=o(" (Speech2Text model)"),JEo=l(),ru=a("li"),hce=a("strong"),YEo=o("splinter"),KEo=o(" \u2014 "),Sj=a("a"),ZEo=o("SplinterModel"),e4o=o(" (Splinter model)"),o4o=l(),tu=a("li"),pce=a("strong"),r4o=o("squeezebert"),t4o=o(" \u2014 "),Rj=a("a"),a4o=o("SqueezeBertModel"),n4o=o(" (SqueezeBERT model)"),s4o=l(),au=a("li"),_ce=a("strong"),l4o=o("swin"),i4o=o(" \u2014 "),Pj=a("a"),d4o=o("SwinModel"),c4o=o(" (Swin Transformer model)"),f4o=l(),nu=a("li"),uce=a("strong"),m4o=o("t5"),g4o=o(" \u2014 "),Bj=a("a"),h4o=o("T5Model"),p4o=o(" (T5 model)"),_4o=l(),su=a("li"),bce=a("strong"),u4o=o("tapas"),b4o=o(" \u2014 "),Ij=a("a"),v4o=o("TapasModel"),F4o=o(" (TAPAS model)"),T4o=l(),lu=a("li"),vce=a("strong"),M4o=o("trajectory_transformer"),E4o=o(" \u2014 "),Nj=a("a"),C4o=o("TrajectoryTransformerModel"),w4o=o(" (Trajectory Transformer model)"),A4o=l(),iu=a("li"),Fce=a("strong"),L4o=o("transfo-xl"),y4o=o(" \u2014 "),qj=a("a"),x4o=o("TransfoXLModel"),$4o=o(" (Transformer-XL model)"),k4o=l(),du=a("li"),Tce=a("strong"),S4o=o("unispeech"),R4o=o(" \u2014 "),jj=a("a"),P4o=o("UniSpeechModel"),B4o=o(" (UniSpeech model)"),I4o=l(),cu=a("li"),Mce=a("strong"),N4o=o("unispeech-sat"),q4o=o(" \u2014 "),Dj=a("a"),j4o=o("UniSpeechSatModel"),D4o=o(" (UniSpeechSat model)"),G4o=l(),fu=a("li"),Ece=a("strong"),O4o=o("van"),V4o=o(" \u2014 "),Gj=a("a"),X4o=o("VanModel"),z4o=o(" (VAN model)"),Q4o=l(),mu=a("li"),Cce=a("strong"),W4o=o("vilt"),H4o=o(" \u2014 "),Oj=a("a"),U4o=o("ViltModel"),J4o=o(" (ViLT model)"),Y4o=l(),gu=a("li"),wce=a("strong"),K4o=o("vision-text-dual-encoder"),Z4o=o(" \u2014 "),Vj=a("a"),eCo=o("VisionTextDualEncoderModel"),oCo=o(" (VisionTextDualEncoder model)"),rCo=l(),hu=a("li"),Ace=a("strong"),tCo=o("visual_bert"),aCo=o(" \u2014 "),Xj=a("a"),nCo=o("VisualBertModel"),sCo=o(" (VisualBERT model)"),lCo=l(),pu=a("li"),Lce=a("strong"),iCo=o("vit"),dCo=o(" \u2014 "),zj=a("a"),cCo=o("ViTModel"),fCo=o(" (ViT model)"),mCo=l(),_u=a("li"),yce=a("strong"),gCo=o("vit_mae"),hCo=o(" \u2014 "),Qj=a("a"),pCo=o("ViTMAEModel"),_Co=o(" (ViTMAE model)"),uCo=l(),uu=a("li"),xce=a("strong"),bCo=o("wav2vec2"),vCo=o(" \u2014 "),Wj=a("a"),FCo=o("Wav2Vec2Model"),TCo=o(" (Wav2Vec2 model)"),MCo=l(),bu=a("li"),$ce=a("strong"),ECo=o("wav2vec2-conformer"),CCo=o(" \u2014 "),Hj=a("a"),wCo=o("Wav2Vec2ConformerModel"),ACo=o(" (Wav2Vec2-Conformer model)"),LCo=l(),vu=a("li"),kce=a("strong"),yCo=o("wavlm"),xCo=o(" \u2014 "),Uj=a("a"),$Co=o("WavLMModel"),kCo=o(" (WavLM model)"),SCo=l(),Fu=a("li"),Sce=a("strong"),RCo=o("xglm"),PCo=o(" \u2014 "),Jj=a("a"),BCo=o("XGLMModel"),ICo=o(" (XGLM model)"),NCo=l(),Tu=a("li"),Rce=a("strong"),qCo=o("xlm"),jCo=o(" \u2014 "),Yj=a("a"),DCo=o("XLMModel"),GCo=o(" (XLM model)"),OCo=l(),Mu=a("li"),Pce=a("strong"),VCo=o("xlm-prophetnet"),XCo=o(" \u2014 "),Kj=a("a"),zCo=o("XLMProphetNetModel"),QCo=o(" (XLM-ProphetNet model)"),WCo=l(),Eu=a("li"),Bce=a("strong"),HCo=o("xlm-roberta"),UCo=o(" \u2014 "),Zj=a("a"),JCo=o("XLMRobertaModel"),YCo=o(" (XLM-RoBERTa model)"),KCo=l(),Cu=a("li"),Ice=a("strong"),ZCo=o("xlm-roberta-xl"),e5o=o(" \u2014 "),eD=a("a"),o5o=o("XLMRobertaXLModel"),r5o=o(" (XLM-RoBERTa-XL model)"),t5o=l(),wu=a("li"),Nce=a("strong"),a5o=o("xlnet"),n5o=o(" \u2014 "),oD=a("a"),s5o=o("XLNetModel"),l5o=o(" (XLNet model)"),i5o=l(),Au=a("li"),qce=a("strong"),d5o=o("yolos"),c5o=o(" \u2014 "),rD=a("a"),f5o=o("YolosModel"),m5o=o(" (YOLOS model)"),g5o=l(),Lu=a("li"),jce=a("strong"),h5o=o("yoso"),p5o=o(" \u2014 "),tD=a("a"),_5o=o("YosoModel"),u5o=o(" (YOSO model)"),b5o=l(),yu=a("p"),v5o=o("The model is set in evaluation mode by default using "),Dce=a("code"),F5o=o("model.eval()"),T5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=a("code"),M5o=o("model.train()"),E5o=l(),F(xu.$$.fragment),eOe=l(),qi=a("h2"),$u=a("a"),Oce=a("span"),F(sy.$$.fragment),C5o=l(),Vce=a("span"),w5o=o("AutoModelForPreTraining"),oOe=l(),$o=a("div"),F(ly.$$.fragment),A5o=l(),ji=a("p"),L5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=a("a"),y5o=o("from_pretrained()"),x5o=o(" class method or the "),nD=a("a"),$5o=o("from_config()"),k5o=o(` class
method.`),S5o=l(),iy=a("p"),R5o=o("This class cannot be instantiated directly using "),Xce=a("code"),P5o=o("__init__()"),B5o=o(" (throws an error)."),I5o=l(),st=a("div"),F(dy.$$.fragment),N5o=l(),zce=a("p"),q5o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),j5o=l(),Di=a("p"),D5o=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),G5o=o("not"),O5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=a("a"),V5o=o("from_pretrained()"),X5o=o(" to load the model weights."),z5o=l(),F(ku.$$.fragment),Q5o=l(),Ye=a("div"),F(cy.$$.fragment),W5o=l(),Wce=a("p"),H5o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),U5o=l(),Pa=a("p"),J5o=o("The model class to instantiate is selected based on the "),Hce=a("code"),Y5o=o("model_type"),K5o=o(` property of the config object (either
passed as an argument or loaded from `),Uce=a("code"),Z5o=o("pretrained_model_name_or_path"),e3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=a("code"),o3o=o("pretrained_model_name_or_path"),r3o=o(":"),t3o=l(),G=a("ul"),Su=a("li"),Yce=a("strong"),a3o=o("albert"),n3o=o(" \u2014 "),lD=a("a"),s3o=o("AlbertForPreTraining"),l3o=o(" (ALBERT model)"),i3o=l(),Ru=a("li"),Kce=a("strong"),d3o=o("bart"),c3o=o(" \u2014 "),iD=a("a"),f3o=o("BartForConditionalGeneration"),m3o=o(" (BART model)"),g3o=l(),Pu=a("li"),Zce=a("strong"),h3o=o("bert"),p3o=o(" \u2014 "),dD=a("a"),_3o=o("BertForPreTraining"),u3o=o(" (BERT model)"),b3o=l(),Bu=a("li"),efe=a("strong"),v3o=o("big_bird"),F3o=o(" \u2014 "),cD=a("a"),T3o=o("BigBirdForPreTraining"),M3o=o(" (BigBird model)"),E3o=l(),Iu=a("li"),ofe=a("strong"),C3o=o("bloom"),w3o=o(" \u2014 "),fD=a("a"),A3o=o("BloomForCausalLM"),L3o=o(" (BLOOM model)"),y3o=l(),Nu=a("li"),rfe=a("strong"),x3o=o("camembert"),$3o=o(" \u2014 "),mD=a("a"),k3o=o("CamembertForMaskedLM"),S3o=o(" (CamemBERT model)"),R3o=l(),qu=a("li"),tfe=a("strong"),P3o=o("ctrl"),B3o=o(" \u2014 "),gD=a("a"),I3o=o("CTRLLMHeadModel"),N3o=o(" (CTRL model)"),q3o=l(),ju=a("li"),afe=a("strong"),j3o=o("data2vec-text"),D3o=o(" \u2014 "),hD=a("a"),G3o=o("Data2VecTextForMaskedLM"),O3o=o(" (Data2VecText model)"),V3o=l(),Du=a("li"),nfe=a("strong"),X3o=o("deberta"),z3o=o(" \u2014 "),pD=a("a"),Q3o=o("DebertaForMaskedLM"),W3o=o(" (DeBERTa model)"),H3o=l(),Gu=a("li"),sfe=a("strong"),U3o=o("deberta-v2"),J3o=o(" \u2014 "),_D=a("a"),Y3o=o("DebertaV2ForMaskedLM"),K3o=o(" (DeBERTa-v2 model)"),Z3o=l(),Ou=a("li"),lfe=a("strong"),e0o=o("distilbert"),o0o=o(" \u2014 "),uD=a("a"),r0o=o("DistilBertForMaskedLM"),t0o=o(" (DistilBERT model)"),a0o=l(),Vu=a("li"),ife=a("strong"),n0o=o("electra"),s0o=o(" \u2014 "),bD=a("a"),l0o=o("ElectraForPreTraining"),i0o=o(" (ELECTRA model)"),d0o=l(),Xu=a("li"),dfe=a("strong"),c0o=o("flaubert"),f0o=o(" \u2014 "),vD=a("a"),m0o=o("FlaubertWithLMHeadModel"),g0o=o(" (FlauBERT model)"),h0o=l(),zu=a("li"),cfe=a("strong"),p0o=o("flava"),_0o=o(" \u2014 "),FD=a("a"),u0o=o("FlavaForPreTraining"),b0o=o(" (FLAVA model)"),v0o=l(),Qu=a("li"),ffe=a("strong"),F0o=o("fnet"),T0o=o(" \u2014 "),TD=a("a"),M0o=o("FNetForPreTraining"),E0o=o(" (FNet model)"),C0o=l(),Wu=a("li"),mfe=a("strong"),w0o=o("fsmt"),A0o=o(" \u2014 "),MD=a("a"),L0o=o("FSMTForConditionalGeneration"),y0o=o(" (FairSeq Machine-Translation model)"),x0o=l(),Hu=a("li"),gfe=a("strong"),$0o=o("funnel"),k0o=o(" \u2014 "),ED=a("a"),S0o=o("FunnelForPreTraining"),R0o=o(" (Funnel Transformer model)"),P0o=l(),Uu=a("li"),hfe=a("strong"),B0o=o("gpt2"),I0o=o(" \u2014 "),CD=a("a"),N0o=o("GPT2LMHeadModel"),q0o=o(" (OpenAI GPT-2 model)"),j0o=l(),Ju=a("li"),pfe=a("strong"),D0o=o("ibert"),G0o=o(" \u2014 "),wD=a("a"),O0o=o("IBertForMaskedLM"),V0o=o(" (I-BERT model)"),X0o=l(),Yu=a("li"),_fe=a("strong"),z0o=o("layoutlm"),Q0o=o(" \u2014 "),AD=a("a"),W0o=o("LayoutLMForMaskedLM"),H0o=o(" (LayoutLM model)"),U0o=l(),Ku=a("li"),ufe=a("strong"),J0o=o("longformer"),Y0o=o(" \u2014 "),LD=a("a"),K0o=o("LongformerForMaskedLM"),Z0o=o(" (Longformer model)"),ewo=l(),Zu=a("li"),bfe=a("strong"),owo=o("lxmert"),rwo=o(" \u2014 "),yD=a("a"),two=o("LxmertForPreTraining"),awo=o(" (LXMERT model)"),nwo=l(),e7=a("li"),vfe=a("strong"),swo=o("megatron-bert"),lwo=o(" \u2014 "),xD=a("a"),iwo=o("MegatronBertForPreTraining"),dwo=o(" (Megatron-BERT model)"),cwo=l(),o7=a("li"),Ffe=a("strong"),fwo=o("mobilebert"),mwo=o(" \u2014 "),$D=a("a"),gwo=o("MobileBertForPreTraining"),hwo=o(" (MobileBERT model)"),pwo=l(),r7=a("li"),Tfe=a("strong"),_wo=o("mpnet"),uwo=o(" \u2014 "),kD=a("a"),bwo=o("MPNetForMaskedLM"),vwo=o(" (MPNet model)"),Fwo=l(),t7=a("li"),Mfe=a("strong"),Two=o("nezha"),Mwo=o(" \u2014 "),SD=a("a"),Ewo=o("NezhaForPreTraining"),Cwo=o(" (Nezha model)"),wwo=l(),a7=a("li"),Efe=a("strong"),Awo=o("openai-gpt"),Lwo=o(" \u2014 "),RD=a("a"),ywo=o("OpenAIGPTLMHeadModel"),xwo=o(" (OpenAI GPT model)"),$wo=l(),n7=a("li"),Cfe=a("strong"),kwo=o("retribert"),Swo=o(" \u2014 "),PD=a("a"),Rwo=o("RetriBertModel"),Pwo=o(" (RetriBERT model)"),Bwo=l(),s7=a("li"),wfe=a("strong"),Iwo=o("roberta"),Nwo=o(" \u2014 "),BD=a("a"),qwo=o("RobertaForMaskedLM"),jwo=o(" (RoBERTa model)"),Dwo=l(),l7=a("li"),Afe=a("strong"),Gwo=o("splinter"),Owo=o(" \u2014 "),ID=a("a"),Vwo=o("SplinterForPreTraining"),Xwo=o(" (Splinter model)"),zwo=l(),i7=a("li"),Lfe=a("strong"),Qwo=o("squeezebert"),Wwo=o(" \u2014 "),ND=a("a"),Hwo=o("SqueezeBertForMaskedLM"),Uwo=o(" (SqueezeBERT model)"),Jwo=l(),d7=a("li"),yfe=a("strong"),Ywo=o("t5"),Kwo=o(" \u2014 "),qD=a("a"),Zwo=o("T5ForConditionalGeneration"),eAo=o(" (T5 model)"),oAo=l(),c7=a("li"),xfe=a("strong"),rAo=o("tapas"),tAo=o(" \u2014 "),jD=a("a"),aAo=o("TapasForMaskedLM"),nAo=o(" (TAPAS model)"),sAo=l(),f7=a("li"),$fe=a("strong"),lAo=o("transfo-xl"),iAo=o(" \u2014 "),DD=a("a"),dAo=o("TransfoXLLMHeadModel"),cAo=o(" (Transformer-XL model)"),fAo=l(),m7=a("li"),kfe=a("strong"),mAo=o("unispeech"),gAo=o(" \u2014 "),GD=a("a"),hAo=o("UniSpeechForPreTraining"),pAo=o(" (UniSpeech model)"),_Ao=l(),g7=a("li"),Sfe=a("strong"),uAo=o("unispeech-sat"),bAo=o(" \u2014 "),OD=a("a"),vAo=o("UniSpeechSatForPreTraining"),FAo=o(" (UniSpeechSat model)"),TAo=l(),h7=a("li"),Rfe=a("strong"),MAo=o("visual_bert"),EAo=o(" \u2014 "),VD=a("a"),CAo=o("VisualBertForPreTraining"),wAo=o(" (VisualBERT model)"),AAo=l(),p7=a("li"),Pfe=a("strong"),LAo=o("vit_mae"),yAo=o(" \u2014 "),XD=a("a"),xAo=o("ViTMAEForPreTraining"),$Ao=o(" (ViTMAE model)"),kAo=l(),_7=a("li"),Bfe=a("strong"),SAo=o("wav2vec2"),RAo=o(" \u2014 "),zD=a("a"),PAo=o("Wav2Vec2ForPreTraining"),BAo=o(" (Wav2Vec2 model)"),IAo=l(),u7=a("li"),Ife=a("strong"),NAo=o("wav2vec2-conformer"),qAo=o(" \u2014 "),QD=a("a"),jAo=o("Wav2Vec2ConformerForPreTraining"),DAo=o(" (Wav2Vec2-Conformer model)"),GAo=l(),b7=a("li"),Nfe=a("strong"),OAo=o("xlm"),VAo=o(" \u2014 "),WD=a("a"),XAo=o("XLMWithLMHeadModel"),zAo=o(" (XLM model)"),QAo=l(),v7=a("li"),qfe=a("strong"),WAo=o("xlm-roberta"),HAo=o(" \u2014 "),HD=a("a"),UAo=o("XLMRobertaForMaskedLM"),JAo=o(" (XLM-RoBERTa model)"),YAo=l(),F7=a("li"),jfe=a("strong"),KAo=o("xlm-roberta-xl"),ZAo=o(" \u2014 "),UD=a("a"),eLo=o("XLMRobertaXLForMaskedLM"),oLo=o(" (XLM-RoBERTa-XL model)"),rLo=l(),T7=a("li"),Dfe=a("strong"),tLo=o("xlnet"),aLo=o(" \u2014 "),JD=a("a"),nLo=o("XLNetLMHeadModel"),sLo=o(" (XLNet model)"),lLo=l(),M7=a("p"),iLo=o("The model is set in evaluation mode by default using "),Gfe=a("code"),dLo=o("model.eval()"),cLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=a("code"),fLo=o("model.train()"),mLo=l(),F(E7.$$.fragment),rOe=l(),Gi=a("h2"),C7=a("a"),Vfe=a("span"),F(fy.$$.fragment),gLo=l(),Xfe=a("span"),hLo=o("AutoModelForCausalLM"),tOe=l(),ko=a("div"),F(my.$$.fragment),pLo=l(),Oi=a("p"),_Lo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=a("a"),uLo=o("from_pretrained()"),bLo=o(" class method or the "),KD=a("a"),vLo=o("from_config()"),FLo=o(` class
method.`),TLo=l(),gy=a("p"),MLo=o("This class cannot be instantiated directly using "),zfe=a("code"),ELo=o("__init__()"),CLo=o(" (throws an error)."),wLo=l(),lt=a("div"),F(hy.$$.fragment),ALo=l(),Qfe=a("p"),LLo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yLo=l(),Vi=a("p"),xLo=o(`Note:
Loading a model from its configuration file does `),Wfe=a("strong"),$Lo=o("not"),kLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),SLo=o("from_pretrained()"),RLo=o(" to load the model weights."),PLo=l(),F(w7.$$.fragment),BLo=l(),Ke=a("div"),F(py.$$.fragment),ILo=l(),Hfe=a("p"),NLo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),qLo=l(),Ba=a("p"),jLo=o("The model class to instantiate is selected based on the "),Ufe=a("code"),DLo=o("model_type"),GLo=o(` property of the config object (either
passed as an argument or loaded from `),Jfe=a("code"),OLo=o("pretrained_model_name_or_path"),VLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=a("code"),XLo=o("pretrained_model_name_or_path"),zLo=o(":"),QLo=l(),z=a("ul"),A7=a("li"),Kfe=a("strong"),WLo=o("bart"),HLo=o(" \u2014 "),eG=a("a"),ULo=o("BartForCausalLM"),JLo=o(" (BART model)"),YLo=l(),L7=a("li"),Zfe=a("strong"),KLo=o("bert"),ZLo=o(" \u2014 "),oG=a("a"),eyo=o("BertLMHeadModel"),oyo=o(" (BERT model)"),ryo=l(),y7=a("li"),eme=a("strong"),tyo=o("bert-generation"),ayo=o(" \u2014 "),rG=a("a"),nyo=o("BertGenerationDecoder"),syo=o(" (Bert Generation model)"),lyo=l(),x7=a("li"),ome=a("strong"),iyo=o("big_bird"),dyo=o(" \u2014 "),tG=a("a"),cyo=o("BigBirdForCausalLM"),fyo=o(" (BigBird model)"),myo=l(),$7=a("li"),rme=a("strong"),gyo=o("bigbird_pegasus"),hyo=o(" \u2014 "),aG=a("a"),pyo=o("BigBirdPegasusForCausalLM"),_yo=o(" (BigBird-Pegasus model)"),uyo=l(),k7=a("li"),tme=a("strong"),byo=o("blenderbot"),vyo=o(" \u2014 "),nG=a("a"),Fyo=o("BlenderbotForCausalLM"),Tyo=o(" (Blenderbot model)"),Myo=l(),S7=a("li"),ame=a("strong"),Eyo=o("blenderbot-small"),Cyo=o(" \u2014 "),sG=a("a"),wyo=o("BlenderbotSmallForCausalLM"),Ayo=o(" (BlenderbotSmall model)"),Lyo=l(),R7=a("li"),nme=a("strong"),yyo=o("bloom"),xyo=o(" \u2014 "),lG=a("a"),$yo=o("BloomForCausalLM"),kyo=o(" (BLOOM model)"),Syo=l(),P7=a("li"),sme=a("strong"),Ryo=o("camembert"),Pyo=o(" \u2014 "),iG=a("a"),Byo=o("CamembertForCausalLM"),Iyo=o(" (CamemBERT model)"),Nyo=l(),B7=a("li"),lme=a("strong"),qyo=o("ctrl"),jyo=o(" \u2014 "),dG=a("a"),Dyo=o("CTRLLMHeadModel"),Gyo=o(" (CTRL model)"),Oyo=l(),I7=a("li"),ime=a("strong"),Vyo=o("data2vec-text"),Xyo=o(" \u2014 "),cG=a("a"),zyo=o("Data2VecTextForCausalLM"),Qyo=o(" (Data2VecText model)"),Wyo=l(),N7=a("li"),dme=a("strong"),Hyo=o("electra"),Uyo=o(" \u2014 "),fG=a("a"),Jyo=o("ElectraForCausalLM"),Yyo=o(" (ELECTRA model)"),Kyo=l(),q7=a("li"),cme=a("strong"),Zyo=o("gpt2"),e8o=o(" \u2014 "),mG=a("a"),o8o=o("GPT2LMHeadModel"),r8o=o(" (OpenAI GPT-2 model)"),t8o=l(),j7=a("li"),fme=a("strong"),a8o=o("gpt_neo"),n8o=o(" \u2014 "),gG=a("a"),s8o=o("GPTNeoForCausalLM"),l8o=o(" (GPT Neo model)"),i8o=l(),D7=a("li"),mme=a("strong"),d8o=o("gpt_neox"),c8o=o(" \u2014 "),hG=a("a"),f8o=o("GPTNeoXForCausalLM"),m8o=o(" (GPT NeoX model)"),g8o=l(),G7=a("li"),gme=a("strong"),h8o=o("gptj"),p8o=o(" \u2014 "),pG=a("a"),_8o=o("GPTJForCausalLM"),u8o=o(" (GPT-J model)"),b8o=l(),O7=a("li"),hme=a("strong"),v8o=o("marian"),F8o=o(" \u2014 "),_G=a("a"),T8o=o("MarianForCausalLM"),M8o=o(" (Marian model)"),E8o=l(),V7=a("li"),pme=a("strong"),C8o=o("mbart"),w8o=o(" \u2014 "),uG=a("a"),A8o=o("MBartForCausalLM"),L8o=o(" (mBART model)"),y8o=l(),X7=a("li"),_me=a("strong"),x8o=o("megatron-bert"),$8o=o(" \u2014 "),bG=a("a"),k8o=o("MegatronBertForCausalLM"),S8o=o(" (Megatron-BERT model)"),R8o=l(),z7=a("li"),ume=a("strong"),P8o=o("openai-gpt"),B8o=o(" \u2014 "),vG=a("a"),I8o=o("OpenAIGPTLMHeadModel"),N8o=o(" (OpenAI GPT model)"),q8o=l(),Q7=a("li"),bme=a("strong"),j8o=o("opt"),D8o=o(" \u2014 "),FG=a("a"),G8o=o("OPTForCausalLM"),O8o=o(" (OPT model)"),V8o=l(),W7=a("li"),vme=a("strong"),X8o=o("pegasus"),z8o=o(" \u2014 "),TG=a("a"),Q8o=o("PegasusForCausalLM"),W8o=o(" (Pegasus model)"),H8o=l(),H7=a("li"),Fme=a("strong"),U8o=o("plbart"),J8o=o(" \u2014 "),MG=a("a"),Y8o=o("PLBartForCausalLM"),K8o=o(" (PLBart model)"),Z8o=l(),U7=a("li"),Tme=a("strong"),e9o=o("prophetnet"),o9o=o(" \u2014 "),EG=a("a"),r9o=o("ProphetNetForCausalLM"),t9o=o(" (ProphetNet model)"),a9o=l(),J7=a("li"),Mme=a("strong"),n9o=o("qdqbert"),s9o=o(" \u2014 "),CG=a("a"),l9o=o("QDQBertLMHeadModel"),i9o=o(" (QDQBert model)"),d9o=l(),Y7=a("li"),Eme=a("strong"),c9o=o("reformer"),f9o=o(" \u2014 "),wG=a("a"),m9o=o("ReformerModelWithLMHead"),g9o=o(" (Reformer model)"),h9o=l(),K7=a("li"),Cme=a("strong"),p9o=o("rembert"),_9o=o(" \u2014 "),AG=a("a"),u9o=o("RemBertForCausalLM"),b9o=o(" (RemBERT model)"),v9o=l(),Z7=a("li"),wme=a("strong"),F9o=o("roberta"),T9o=o(" \u2014 "),LG=a("a"),M9o=o("RobertaForCausalLM"),E9o=o(" (RoBERTa model)"),C9o=l(),e1=a("li"),Ame=a("strong"),w9o=o("roformer"),A9o=o(" \u2014 "),yG=a("a"),L9o=o("RoFormerForCausalLM"),y9o=o(" (RoFormer model)"),x9o=l(),o1=a("li"),Lme=a("strong"),$9o=o("speech_to_text_2"),k9o=o(" \u2014 "),xG=a("a"),S9o=o("Speech2Text2ForCausalLM"),R9o=o(" (Speech2Text2 model)"),P9o=l(),r1=a("li"),yme=a("strong"),B9o=o("transfo-xl"),I9o=o(" \u2014 "),$G=a("a"),N9o=o("TransfoXLLMHeadModel"),q9o=o(" (Transformer-XL model)"),j9o=l(),t1=a("li"),xme=a("strong"),D9o=o("trocr"),G9o=o(" \u2014 "),kG=a("a"),O9o=o("TrOCRForCausalLM"),V9o=o(" (TrOCR model)"),X9o=l(),a1=a("li"),$me=a("strong"),z9o=o("xglm"),Q9o=o(" \u2014 "),SG=a("a"),W9o=o("XGLMForCausalLM"),H9o=o(" (XGLM model)"),U9o=l(),n1=a("li"),kme=a("strong"),J9o=o("xlm"),Y9o=o(" \u2014 "),RG=a("a"),K9o=o("XLMWithLMHeadModel"),Z9o=o(" (XLM model)"),exo=l(),s1=a("li"),Sme=a("strong"),oxo=o("xlm-prophetnet"),rxo=o(" \u2014 "),PG=a("a"),txo=o("XLMProphetNetForCausalLM"),axo=o(" (XLM-ProphetNet model)"),nxo=l(),l1=a("li"),Rme=a("strong"),sxo=o("xlm-roberta"),lxo=o(" \u2014 "),BG=a("a"),ixo=o("XLMRobertaForCausalLM"),dxo=o(" (XLM-RoBERTa model)"),cxo=l(),i1=a("li"),Pme=a("strong"),fxo=o("xlm-roberta-xl"),mxo=o(" \u2014 "),IG=a("a"),gxo=o("XLMRobertaXLForCausalLM"),hxo=o(" (XLM-RoBERTa-XL model)"),pxo=l(),d1=a("li"),Bme=a("strong"),_xo=o("xlnet"),uxo=o(" \u2014 "),NG=a("a"),bxo=o("XLNetLMHeadModel"),vxo=o(" (XLNet model)"),Fxo=l(),c1=a("p"),Txo=o("The model is set in evaluation mode by default using "),Ime=a("code"),Mxo=o("model.eval()"),Exo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=a("code"),Cxo=o("model.train()"),wxo=l(),F(f1.$$.fragment),aOe=l(),Xi=a("h2"),m1=a("a"),qme=a("span"),F(_y.$$.fragment),Axo=l(),jme=a("span"),Lxo=o("AutoModelForMaskedLM"),nOe=l(),So=a("div"),F(uy.$$.fragment),yxo=l(),zi=a("p"),xxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=a("a"),$xo=o("from_pretrained()"),kxo=o(" class method or the "),jG=a("a"),Sxo=o("from_config()"),Rxo=o(` class
method.`),Pxo=l(),by=a("p"),Bxo=o("This class cannot be instantiated directly using "),Dme=a("code"),Ixo=o("__init__()"),Nxo=o(" (throws an error)."),qxo=l(),it=a("div"),F(vy.$$.fragment),jxo=l(),Gme=a("p"),Dxo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxo=l(),Qi=a("p"),Oxo=o(`Note:
Loading a model from its configuration file does `),Ome=a("strong"),Vxo=o("not"),Xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=a("a"),zxo=o("from_pretrained()"),Qxo=o(" to load the model weights."),Wxo=l(),F(g1.$$.fragment),Hxo=l(),Ze=a("div"),F(Fy.$$.fragment),Uxo=l(),Vme=a("p"),Jxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yxo=l(),Ia=a("p"),Kxo=o("The model class to instantiate is selected based on the "),Xme=a("code"),Zxo=o("model_type"),e$o=o(` property of the config object (either
passed as an argument or loaded from `),zme=a("code"),o$o=o("pretrained_model_name_or_path"),r$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=a("code"),t$o=o("pretrained_model_name_or_path"),a$o=o(":"),n$o=l(),Q=a("ul"),h1=a("li"),Wme=a("strong"),s$o=o("albert"),l$o=o(" \u2014 "),GG=a("a"),i$o=o("AlbertForMaskedLM"),d$o=o(" (ALBERT model)"),c$o=l(),p1=a("li"),Hme=a("strong"),f$o=o("bart"),m$o=o(" \u2014 "),OG=a("a"),g$o=o("BartForConditionalGeneration"),h$o=o(" (BART model)"),p$o=l(),_1=a("li"),Ume=a("strong"),_$o=o("bert"),u$o=o(" \u2014 "),VG=a("a"),b$o=o("BertForMaskedLM"),v$o=o(" (BERT model)"),F$o=l(),u1=a("li"),Jme=a("strong"),T$o=o("big_bird"),M$o=o(" \u2014 "),XG=a("a"),E$o=o("BigBirdForMaskedLM"),C$o=o(" (BigBird model)"),w$o=l(),b1=a("li"),Yme=a("strong"),A$o=o("camembert"),L$o=o(" \u2014 "),zG=a("a"),y$o=o("CamembertForMaskedLM"),x$o=o(" (CamemBERT model)"),$$o=l(),v1=a("li"),Kme=a("strong"),k$o=o("convbert"),S$o=o(" \u2014 "),QG=a("a"),R$o=o("ConvBertForMaskedLM"),P$o=o(" (ConvBERT model)"),B$o=l(),F1=a("li"),Zme=a("strong"),I$o=o("data2vec-text"),N$o=o(" \u2014 "),WG=a("a"),q$o=o("Data2VecTextForMaskedLM"),j$o=o(" (Data2VecText model)"),D$o=l(),T1=a("li"),ege=a("strong"),G$o=o("deberta"),O$o=o(" \u2014 "),HG=a("a"),V$o=o("DebertaForMaskedLM"),X$o=o(" (DeBERTa model)"),z$o=l(),M1=a("li"),oge=a("strong"),Q$o=o("deberta-v2"),W$o=o(" \u2014 "),UG=a("a"),H$o=o("DebertaV2ForMaskedLM"),U$o=o(" (DeBERTa-v2 model)"),J$o=l(),E1=a("li"),rge=a("strong"),Y$o=o("distilbert"),K$o=o(" \u2014 "),JG=a("a"),Z$o=o("DistilBertForMaskedLM"),eko=o(" (DistilBERT model)"),oko=l(),C1=a("li"),tge=a("strong"),rko=o("electra"),tko=o(" \u2014 "),YG=a("a"),ako=o("ElectraForMaskedLM"),nko=o(" (ELECTRA model)"),sko=l(),w1=a("li"),age=a("strong"),lko=o("flaubert"),iko=o(" \u2014 "),KG=a("a"),dko=o("FlaubertWithLMHeadModel"),cko=o(" (FlauBERT model)"),fko=l(),A1=a("li"),nge=a("strong"),mko=o("fnet"),gko=o(" \u2014 "),ZG=a("a"),hko=o("FNetForMaskedLM"),pko=o(" (FNet model)"),_ko=l(),L1=a("li"),sge=a("strong"),uko=o("funnel"),bko=o(" \u2014 "),eO=a("a"),vko=o("FunnelForMaskedLM"),Fko=o(" (Funnel Transformer model)"),Tko=l(),y1=a("li"),lge=a("strong"),Mko=o("ibert"),Eko=o(" \u2014 "),oO=a("a"),Cko=o("IBertForMaskedLM"),wko=o(" (I-BERT model)"),Ako=l(),x1=a("li"),ige=a("strong"),Lko=o("layoutlm"),yko=o(" \u2014 "),rO=a("a"),xko=o("LayoutLMForMaskedLM"),$ko=o(" (LayoutLM model)"),kko=l(),$1=a("li"),dge=a("strong"),Sko=o("longformer"),Rko=o(" \u2014 "),tO=a("a"),Pko=o("LongformerForMaskedLM"),Bko=o(" (Longformer model)"),Iko=l(),k1=a("li"),cge=a("strong"),Nko=o("luke"),qko=o(" \u2014 "),aO=a("a"),jko=o("LukeForMaskedLM"),Dko=o(" (LUKE model)"),Gko=l(),S1=a("li"),fge=a("strong"),Oko=o("mbart"),Vko=o(" \u2014 "),nO=a("a"),Xko=o("MBartForConditionalGeneration"),zko=o(" (mBART model)"),Qko=l(),R1=a("li"),mge=a("strong"),Wko=o("megatron-bert"),Hko=o(" \u2014 "),sO=a("a"),Uko=o("MegatronBertForMaskedLM"),Jko=o(" (Megatron-BERT model)"),Yko=l(),P1=a("li"),gge=a("strong"),Kko=o("mobilebert"),Zko=o(" \u2014 "),lO=a("a"),eSo=o("MobileBertForMaskedLM"),oSo=o(" (MobileBERT model)"),rSo=l(),B1=a("li"),hge=a("strong"),tSo=o("mpnet"),aSo=o(" \u2014 "),iO=a("a"),nSo=o("MPNetForMaskedLM"),sSo=o(" (MPNet model)"),lSo=l(),I1=a("li"),pge=a("strong"),iSo=o("nezha"),dSo=o(" \u2014 "),dO=a("a"),cSo=o("NezhaForMaskedLM"),fSo=o(" (Nezha model)"),mSo=l(),N1=a("li"),_ge=a("strong"),gSo=o("nystromformer"),hSo=o(" \u2014 "),cO=a("a"),pSo=o("NystromformerForMaskedLM"),_So=o(" (Nystr\xF6mformer model)"),uSo=l(),q1=a("li"),uge=a("strong"),bSo=o("perceiver"),vSo=o(" \u2014 "),fO=a("a"),FSo=o("PerceiverForMaskedLM"),TSo=o(" (Perceiver model)"),MSo=l(),j1=a("li"),bge=a("strong"),ESo=o("qdqbert"),CSo=o(" \u2014 "),mO=a("a"),wSo=o("QDQBertForMaskedLM"),ASo=o(" (QDQBert model)"),LSo=l(),D1=a("li"),vge=a("strong"),ySo=o("reformer"),xSo=o(" \u2014 "),gO=a("a"),$So=o("ReformerForMaskedLM"),kSo=o(" (Reformer model)"),SSo=l(),G1=a("li"),Fge=a("strong"),RSo=o("rembert"),PSo=o(" \u2014 "),hO=a("a"),BSo=o("RemBertForMaskedLM"),ISo=o(" (RemBERT model)"),NSo=l(),O1=a("li"),Tge=a("strong"),qSo=o("roberta"),jSo=o(" \u2014 "),pO=a("a"),DSo=o("RobertaForMaskedLM"),GSo=o(" (RoBERTa model)"),OSo=l(),V1=a("li"),Mge=a("strong"),VSo=o("roformer"),XSo=o(" \u2014 "),_O=a("a"),zSo=o("RoFormerForMaskedLM"),QSo=o(" (RoFormer model)"),WSo=l(),X1=a("li"),Ege=a("strong"),HSo=o("squeezebert"),USo=o(" \u2014 "),uO=a("a"),JSo=o("SqueezeBertForMaskedLM"),YSo=o(" (SqueezeBERT model)"),KSo=l(),z1=a("li"),Cge=a("strong"),ZSo=o("tapas"),eRo=o(" \u2014 "),bO=a("a"),oRo=o("TapasForMaskedLM"),rRo=o(" (TAPAS model)"),tRo=l(),Q1=a("li"),wge=a("strong"),aRo=o("wav2vec2"),nRo=o(" \u2014 "),Age=a("code"),sRo=o("Wav2Vec2ForMaskedLM"),lRo=o(" (Wav2Vec2 model)"),iRo=l(),W1=a("li"),Lge=a("strong"),dRo=o("xlm"),cRo=o(" \u2014 "),vO=a("a"),fRo=o("XLMWithLMHeadModel"),mRo=o(" (XLM model)"),gRo=l(),H1=a("li"),yge=a("strong"),hRo=o("xlm-roberta"),pRo=o(" \u2014 "),FO=a("a"),_Ro=o("XLMRobertaForMaskedLM"),uRo=o(" (XLM-RoBERTa model)"),bRo=l(),U1=a("li"),xge=a("strong"),vRo=o("xlm-roberta-xl"),FRo=o(" \u2014 "),TO=a("a"),TRo=o("XLMRobertaXLForMaskedLM"),MRo=o(" (XLM-RoBERTa-XL model)"),ERo=l(),J1=a("li"),$ge=a("strong"),CRo=o("yoso"),wRo=o(" \u2014 "),MO=a("a"),ARo=o("YosoForMaskedLM"),LRo=o(" (YOSO model)"),yRo=l(),Y1=a("p"),xRo=o("The model is set in evaluation mode by default using "),kge=a("code"),$Ro=o("model.eval()"),kRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=a("code"),SRo=o("model.train()"),RRo=l(),F(K1.$$.fragment),sOe=l(),Wi=a("h2"),Z1=a("a"),Rge=a("span"),F(Ty.$$.fragment),PRo=l(),Pge=a("span"),BRo=o("AutoModelForSeq2SeqLM"),lOe=l(),Ro=a("div"),F(My.$$.fragment),IRo=l(),Hi=a("p"),NRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=a("a"),qRo=o("from_pretrained()"),jRo=o(" class method or the "),CO=a("a"),DRo=o("from_config()"),GRo=o(` class
method.`),ORo=l(),Ey=a("p"),VRo=o("This class cannot be instantiated directly using "),Bge=a("code"),XRo=o("__init__()"),zRo=o(" (throws an error)."),QRo=l(),dt=a("div"),F(Cy.$$.fragment),WRo=l(),Ige=a("p"),HRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),URo=l(),Ui=a("p"),JRo=o(`Note:
Loading a model from its configuration file does `),Nge=a("strong"),YRo=o("not"),KRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=a("a"),ZRo=o("from_pretrained()"),ePo=o(" to load the model weights."),oPo=l(),F(e2.$$.fragment),rPo=l(),eo=a("div"),F(wy.$$.fragment),tPo=l(),qge=a("p"),aPo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nPo=l(),Na=a("p"),sPo=o("The model class to instantiate is selected based on the "),jge=a("code"),lPo=o("model_type"),iPo=o(` property of the config object (either
passed as an argument or loaded from `),Dge=a("code"),dPo=o("pretrained_model_name_or_path"),cPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=a("code"),fPo=o("pretrained_model_name_or_path"),mPo=o(":"),gPo=l(),pe=a("ul"),o2=a("li"),Oge=a("strong"),hPo=o("bart"),pPo=o(" \u2014 "),AO=a("a"),_Po=o("BartForConditionalGeneration"),uPo=o(" (BART model)"),bPo=l(),r2=a("li"),Vge=a("strong"),vPo=o("bigbird_pegasus"),FPo=o(" \u2014 "),LO=a("a"),TPo=o("BigBirdPegasusForConditionalGeneration"),MPo=o(" (BigBird-Pegasus model)"),EPo=l(),t2=a("li"),Xge=a("strong"),CPo=o("blenderbot"),wPo=o(" \u2014 "),yO=a("a"),APo=o("BlenderbotForConditionalGeneration"),LPo=o(" (Blenderbot model)"),yPo=l(),a2=a("li"),zge=a("strong"),xPo=o("blenderbot-small"),$Po=o(" \u2014 "),xO=a("a"),kPo=o("BlenderbotSmallForConditionalGeneration"),SPo=o(" (BlenderbotSmall model)"),RPo=l(),n2=a("li"),Qge=a("strong"),PPo=o("encoder-decoder"),BPo=o(" \u2014 "),$O=a("a"),IPo=o("EncoderDecoderModel"),NPo=o(" (Encoder decoder model)"),qPo=l(),s2=a("li"),Wge=a("strong"),jPo=o("fsmt"),DPo=o(" \u2014 "),kO=a("a"),GPo=o("FSMTForConditionalGeneration"),OPo=o(" (FairSeq Machine-Translation model)"),VPo=l(),l2=a("li"),Hge=a("strong"),XPo=o("led"),zPo=o(" \u2014 "),SO=a("a"),QPo=o("LEDForConditionalGeneration"),WPo=o(" (LED model)"),HPo=l(),i2=a("li"),Uge=a("strong"),UPo=o("longt5"),JPo=o(" \u2014 "),RO=a("a"),YPo=o("LongT5ForConditionalGeneration"),KPo=o(" (LongT5 model)"),ZPo=l(),d2=a("li"),Jge=a("strong"),eBo=o("m2m_100"),oBo=o(" \u2014 "),PO=a("a"),rBo=o("M2M100ForConditionalGeneration"),tBo=o(" (M2M100 model)"),aBo=l(),c2=a("li"),Yge=a("strong"),nBo=o("marian"),sBo=o(" \u2014 "),BO=a("a"),lBo=o("MarianMTModel"),iBo=o(" (Marian model)"),dBo=l(),f2=a("li"),Kge=a("strong"),cBo=o("mbart"),fBo=o(" \u2014 "),IO=a("a"),mBo=o("MBartForConditionalGeneration"),gBo=o(" (mBART model)"),hBo=l(),m2=a("li"),Zge=a("strong"),pBo=o("mt5"),_Bo=o(" \u2014 "),NO=a("a"),uBo=o("MT5ForConditionalGeneration"),bBo=o(" (MT5 model)"),vBo=l(),g2=a("li"),ehe=a("strong"),FBo=o("pegasus"),TBo=o(" \u2014 "),qO=a("a"),MBo=o("PegasusForConditionalGeneration"),EBo=o(" (Pegasus model)"),CBo=l(),h2=a("li"),ohe=a("strong"),wBo=o("plbart"),ABo=o(" \u2014 "),jO=a("a"),LBo=o("PLBartForConditionalGeneration"),yBo=o(" (PLBart model)"),xBo=l(),p2=a("li"),rhe=a("strong"),$Bo=o("prophetnet"),kBo=o(" \u2014 "),DO=a("a"),SBo=o("ProphetNetForConditionalGeneration"),RBo=o(" (ProphetNet model)"),PBo=l(),_2=a("li"),the=a("strong"),BBo=o("t5"),IBo=o(" \u2014 "),GO=a("a"),NBo=o("T5ForConditionalGeneration"),qBo=o(" (T5 model)"),jBo=l(),u2=a("li"),ahe=a("strong"),DBo=o("xlm-prophetnet"),GBo=o(" \u2014 "),OO=a("a"),OBo=o("XLMProphetNetForConditionalGeneration"),VBo=o(" (XLM-ProphetNet model)"),XBo=l(),b2=a("p"),zBo=o("The model is set in evaluation mode by default using "),nhe=a("code"),QBo=o("model.eval()"),WBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=a("code"),HBo=o("model.train()"),UBo=l(),F(v2.$$.fragment),iOe=l(),Ji=a("h2"),F2=a("a"),lhe=a("span"),F(Ay.$$.fragment),JBo=l(),ihe=a("span"),YBo=o("AutoModelForSequenceClassification"),dOe=l(),Po=a("div"),F(Ly.$$.fragment),KBo=l(),Yi=a("p"),ZBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=a("a"),eIo=o("from_pretrained()"),oIo=o(" class method or the "),XO=a("a"),rIo=o("from_config()"),tIo=o(` class
method.`),aIo=l(),yy=a("p"),nIo=o("This class cannot be instantiated directly using "),dhe=a("code"),sIo=o("__init__()"),lIo=o(" (throws an error)."),iIo=l(),ct=a("div"),F(xy.$$.fragment),dIo=l(),che=a("p"),cIo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),fIo=l(),Ki=a("p"),mIo=o(`Note:
Loading a model from its configuration file does `),fhe=a("strong"),gIo=o("not"),hIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=a("a"),pIo=o("from_pretrained()"),_Io=o(" to load the model weights."),uIo=l(),F(T2.$$.fragment),bIo=l(),oo=a("div"),F($y.$$.fragment),vIo=l(),mhe=a("p"),FIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TIo=l(),qa=a("p"),MIo=o("The model class to instantiate is selected based on the "),ghe=a("code"),EIo=o("model_type"),CIo=o(` property of the config object (either
passed as an argument or loaded from `),hhe=a("code"),wIo=o("pretrained_model_name_or_path"),AIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=a("code"),LIo=o("pretrained_model_name_or_path"),yIo=o(":"),xIo=l(),N=a("ul"),M2=a("li"),_he=a("strong"),$Io=o("albert"),kIo=o(" \u2014 "),QO=a("a"),SIo=o("AlbertForSequenceClassification"),RIo=o(" (ALBERT model)"),PIo=l(),E2=a("li"),uhe=a("strong"),BIo=o("bart"),IIo=o(" \u2014 "),WO=a("a"),NIo=o("BartForSequenceClassification"),qIo=o(" (BART model)"),jIo=l(),C2=a("li"),bhe=a("strong"),DIo=o("bert"),GIo=o(" \u2014 "),HO=a("a"),OIo=o("BertForSequenceClassification"),VIo=o(" (BERT model)"),XIo=l(),w2=a("li"),vhe=a("strong"),zIo=o("big_bird"),QIo=o(" \u2014 "),UO=a("a"),WIo=o("BigBirdForSequenceClassification"),HIo=o(" (BigBird model)"),UIo=l(),A2=a("li"),Fhe=a("strong"),JIo=o("bigbird_pegasus"),YIo=o(" \u2014 "),JO=a("a"),KIo=o("BigBirdPegasusForSequenceClassification"),ZIo=o(" (BigBird-Pegasus model)"),eNo=l(),L2=a("li"),The=a("strong"),oNo=o("bloom"),rNo=o(" \u2014 "),YO=a("a"),tNo=o("BloomForSequenceClassification"),aNo=o(" (BLOOM model)"),nNo=l(),y2=a("li"),Mhe=a("strong"),sNo=o("camembert"),lNo=o(" \u2014 "),KO=a("a"),iNo=o("CamembertForSequenceClassification"),dNo=o(" (CamemBERT model)"),cNo=l(),x2=a("li"),Ehe=a("strong"),fNo=o("canine"),mNo=o(" \u2014 "),ZO=a("a"),gNo=o("CanineForSequenceClassification"),hNo=o(" (CANINE model)"),pNo=l(),$2=a("li"),Che=a("strong"),_No=o("convbert"),uNo=o(" \u2014 "),eV=a("a"),bNo=o("ConvBertForSequenceClassification"),vNo=o(" (ConvBERT model)"),FNo=l(),k2=a("li"),whe=a("strong"),TNo=o("ctrl"),MNo=o(" \u2014 "),oV=a("a"),ENo=o("CTRLForSequenceClassification"),CNo=o(" (CTRL model)"),wNo=l(),S2=a("li"),Ahe=a("strong"),ANo=o("data2vec-text"),LNo=o(" \u2014 "),rV=a("a"),yNo=o("Data2VecTextForSequenceClassification"),xNo=o(" (Data2VecText model)"),$No=l(),R2=a("li"),Lhe=a("strong"),kNo=o("deberta"),SNo=o(" \u2014 "),tV=a("a"),RNo=o("DebertaForSequenceClassification"),PNo=o(" (DeBERTa model)"),BNo=l(),P2=a("li"),yhe=a("strong"),INo=o("deberta-v2"),NNo=o(" \u2014 "),aV=a("a"),qNo=o("DebertaV2ForSequenceClassification"),jNo=o(" (DeBERTa-v2 model)"),DNo=l(),B2=a("li"),xhe=a("strong"),GNo=o("distilbert"),ONo=o(" \u2014 "),nV=a("a"),VNo=o("DistilBertForSequenceClassification"),XNo=o(" (DistilBERT model)"),zNo=l(),I2=a("li"),$he=a("strong"),QNo=o("electra"),WNo=o(" \u2014 "),sV=a("a"),HNo=o("ElectraForSequenceClassification"),UNo=o(" (ELECTRA model)"),JNo=l(),N2=a("li"),khe=a("strong"),YNo=o("flaubert"),KNo=o(" \u2014 "),lV=a("a"),ZNo=o("FlaubertForSequenceClassification"),eqo=o(" (FlauBERT model)"),oqo=l(),q2=a("li"),She=a("strong"),rqo=o("fnet"),tqo=o(" \u2014 "),iV=a("a"),aqo=o("FNetForSequenceClassification"),nqo=o(" (FNet model)"),sqo=l(),j2=a("li"),Rhe=a("strong"),lqo=o("funnel"),iqo=o(" \u2014 "),dV=a("a"),dqo=o("FunnelForSequenceClassification"),cqo=o(" (Funnel Transformer model)"),fqo=l(),D2=a("li"),Phe=a("strong"),mqo=o("gpt2"),gqo=o(" \u2014 "),cV=a("a"),hqo=o("GPT2ForSequenceClassification"),pqo=o(" (OpenAI GPT-2 model)"),_qo=l(),G2=a("li"),Bhe=a("strong"),uqo=o("gpt_neo"),bqo=o(" \u2014 "),fV=a("a"),vqo=o("GPTNeoForSequenceClassification"),Fqo=o(" (GPT Neo model)"),Tqo=l(),O2=a("li"),Ihe=a("strong"),Mqo=o("gptj"),Eqo=o(" \u2014 "),mV=a("a"),Cqo=o("GPTJForSequenceClassification"),wqo=o(" (GPT-J model)"),Aqo=l(),V2=a("li"),Nhe=a("strong"),Lqo=o("ibert"),yqo=o(" \u2014 "),gV=a("a"),xqo=o("IBertForSequenceClassification"),$qo=o(" (I-BERT model)"),kqo=l(),X2=a("li"),qhe=a("strong"),Sqo=o("layoutlm"),Rqo=o(" \u2014 "),hV=a("a"),Pqo=o("LayoutLMForSequenceClassification"),Bqo=o(" (LayoutLM model)"),Iqo=l(),z2=a("li"),jhe=a("strong"),Nqo=o("layoutlmv2"),qqo=o(" \u2014 "),pV=a("a"),jqo=o("LayoutLMv2ForSequenceClassification"),Dqo=o(" (LayoutLMv2 model)"),Gqo=l(),Q2=a("li"),Dhe=a("strong"),Oqo=o("layoutlmv3"),Vqo=o(" \u2014 "),_V=a("a"),Xqo=o("LayoutLMv3ForSequenceClassification"),zqo=o(" (LayoutLMv3 model)"),Qqo=l(),W2=a("li"),Ghe=a("strong"),Wqo=o("led"),Hqo=o(" \u2014 "),uV=a("a"),Uqo=o("LEDForSequenceClassification"),Jqo=o(" (LED model)"),Yqo=l(),H2=a("li"),Ohe=a("strong"),Kqo=o("longformer"),Zqo=o(" \u2014 "),bV=a("a"),ejo=o("LongformerForSequenceClassification"),ojo=o(" (Longformer model)"),rjo=l(),U2=a("li"),Vhe=a("strong"),tjo=o("mbart"),ajo=o(" \u2014 "),vV=a("a"),njo=o("MBartForSequenceClassification"),sjo=o(" (mBART model)"),ljo=l(),J2=a("li"),Xhe=a("strong"),ijo=o("megatron-bert"),djo=o(" \u2014 "),FV=a("a"),cjo=o("MegatronBertForSequenceClassification"),fjo=o(" (Megatron-BERT model)"),mjo=l(),Y2=a("li"),zhe=a("strong"),gjo=o("mobilebert"),hjo=o(" \u2014 "),TV=a("a"),pjo=o("MobileBertForSequenceClassification"),_jo=o(" (MobileBERT model)"),ujo=l(),K2=a("li"),Qhe=a("strong"),bjo=o("mpnet"),vjo=o(" \u2014 "),MV=a("a"),Fjo=o("MPNetForSequenceClassification"),Tjo=o(" (MPNet model)"),Mjo=l(),Z2=a("li"),Whe=a("strong"),Ejo=o("nezha"),Cjo=o(" \u2014 "),EV=a("a"),wjo=o("NezhaForSequenceClassification"),Ajo=o(" (Nezha model)"),Ljo=l(),eb=a("li"),Hhe=a("strong"),yjo=o("nystromformer"),xjo=o(" \u2014 "),CV=a("a"),$jo=o("NystromformerForSequenceClassification"),kjo=o(" (Nystr\xF6mformer model)"),Sjo=l(),ob=a("li"),Uhe=a("strong"),Rjo=o("openai-gpt"),Pjo=o(" \u2014 "),wV=a("a"),Bjo=o("OpenAIGPTForSequenceClassification"),Ijo=o(" (OpenAI GPT model)"),Njo=l(),rb=a("li"),Jhe=a("strong"),qjo=o("perceiver"),jjo=o(" \u2014 "),AV=a("a"),Djo=o("PerceiverForSequenceClassification"),Gjo=o(" (Perceiver model)"),Ojo=l(),tb=a("li"),Yhe=a("strong"),Vjo=o("plbart"),Xjo=o(" \u2014 "),LV=a("a"),zjo=o("PLBartForSequenceClassification"),Qjo=o(" (PLBart model)"),Wjo=l(),ab=a("li"),Khe=a("strong"),Hjo=o("qdqbert"),Ujo=o(" \u2014 "),yV=a("a"),Jjo=o("QDQBertForSequenceClassification"),Yjo=o(" (QDQBert model)"),Kjo=l(),nb=a("li"),Zhe=a("strong"),Zjo=o("reformer"),eDo=o(" \u2014 "),xV=a("a"),oDo=o("ReformerForSequenceClassification"),rDo=o(" (Reformer model)"),tDo=l(),sb=a("li"),epe=a("strong"),aDo=o("rembert"),nDo=o(" \u2014 "),$V=a("a"),sDo=o("RemBertForSequenceClassification"),lDo=o(" (RemBERT model)"),iDo=l(),lb=a("li"),ope=a("strong"),dDo=o("roberta"),cDo=o(" \u2014 "),kV=a("a"),fDo=o("RobertaForSequenceClassification"),mDo=o(" (RoBERTa model)"),gDo=l(),ib=a("li"),rpe=a("strong"),hDo=o("roformer"),pDo=o(" \u2014 "),SV=a("a"),_Do=o("RoFormerForSequenceClassification"),uDo=o(" (RoFormer model)"),bDo=l(),db=a("li"),tpe=a("strong"),vDo=o("squeezebert"),FDo=o(" \u2014 "),RV=a("a"),TDo=o("SqueezeBertForSequenceClassification"),MDo=o(" (SqueezeBERT model)"),EDo=l(),cb=a("li"),ape=a("strong"),CDo=o("tapas"),wDo=o(" \u2014 "),PV=a("a"),ADo=o("TapasForSequenceClassification"),LDo=o(" (TAPAS model)"),yDo=l(),fb=a("li"),npe=a("strong"),xDo=o("transfo-xl"),$Do=o(" \u2014 "),BV=a("a"),kDo=o("TransfoXLForSequenceClassification"),SDo=o(" (Transformer-XL model)"),RDo=l(),mb=a("li"),spe=a("strong"),PDo=o("xlm"),BDo=o(" \u2014 "),IV=a("a"),IDo=o("XLMForSequenceClassification"),NDo=o(" (XLM model)"),qDo=l(),gb=a("li"),lpe=a("strong"),jDo=o("xlm-roberta"),DDo=o(" \u2014 "),NV=a("a"),GDo=o("XLMRobertaForSequenceClassification"),ODo=o(" (XLM-RoBERTa model)"),VDo=l(),hb=a("li"),ipe=a("strong"),XDo=o("xlm-roberta-xl"),zDo=o(" \u2014 "),qV=a("a"),QDo=o("XLMRobertaXLForSequenceClassification"),WDo=o(" (XLM-RoBERTa-XL model)"),HDo=l(),pb=a("li"),dpe=a("strong"),UDo=o("xlnet"),JDo=o(" \u2014 "),jV=a("a"),YDo=o("XLNetForSequenceClassification"),KDo=o(" (XLNet model)"),ZDo=l(),_b=a("li"),cpe=a("strong"),eGo=o("yoso"),oGo=o(" \u2014 "),DV=a("a"),rGo=o("YosoForSequenceClassification"),tGo=o(" (YOSO model)"),aGo=l(),ub=a("p"),nGo=o("The model is set in evaluation mode by default using "),fpe=a("code"),sGo=o("model.eval()"),lGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=a("code"),iGo=o("model.train()"),dGo=l(),F(bb.$$.fragment),cOe=l(),Zi=a("h2"),vb=a("a"),gpe=a("span"),F(ky.$$.fragment),cGo=l(),hpe=a("span"),fGo=o("AutoModelForMultipleChoice"),fOe=l(),Bo=a("div"),F(Sy.$$.fragment),mGo=l(),ed=a("p"),gGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=a("a"),hGo=o("from_pretrained()"),pGo=o(" class method or the "),OV=a("a"),_Go=o("from_config()"),uGo=o(` class
method.`),bGo=l(),Ry=a("p"),vGo=o("This class cannot be instantiated directly using "),ppe=a("code"),FGo=o("__init__()"),TGo=o(" (throws an error)."),MGo=l(),ft=a("div"),F(Py.$$.fragment),EGo=l(),_pe=a("p"),CGo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wGo=l(),od=a("p"),AGo=o(`Note:
Loading a model from its configuration file does `),upe=a("strong"),LGo=o("not"),yGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),xGo=o("from_pretrained()"),$Go=o(" to load the model weights."),kGo=l(),F(Fb.$$.fragment),SGo=l(),ro=a("div"),F(By.$$.fragment),RGo=l(),bpe=a("p"),PGo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BGo=l(),ja=a("p"),IGo=o("The model class to instantiate is selected based on the "),vpe=a("code"),NGo=o("model_type"),qGo=o(` property of the config object (either
passed as an argument or loaded from `),Fpe=a("code"),jGo=o("pretrained_model_name_or_path"),DGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=a("code"),GGo=o("pretrained_model_name_or_path"),OGo=o(":"),VGo=l(),Z=a("ul"),Tb=a("li"),Mpe=a("strong"),XGo=o("albert"),zGo=o(" \u2014 "),XV=a("a"),QGo=o("AlbertForMultipleChoice"),WGo=o(" (ALBERT model)"),HGo=l(),Mb=a("li"),Epe=a("strong"),UGo=o("bert"),JGo=o(" \u2014 "),zV=a("a"),YGo=o("BertForMultipleChoice"),KGo=o(" (BERT model)"),ZGo=l(),Eb=a("li"),Cpe=a("strong"),eOo=o("big_bird"),oOo=o(" \u2014 "),QV=a("a"),rOo=o("BigBirdForMultipleChoice"),tOo=o(" (BigBird model)"),aOo=l(),Cb=a("li"),wpe=a("strong"),nOo=o("camembert"),sOo=o(" \u2014 "),WV=a("a"),lOo=o("CamembertForMultipleChoice"),iOo=o(" (CamemBERT model)"),dOo=l(),wb=a("li"),Ape=a("strong"),cOo=o("canine"),fOo=o(" \u2014 "),HV=a("a"),mOo=o("CanineForMultipleChoice"),gOo=o(" (CANINE model)"),hOo=l(),Ab=a("li"),Lpe=a("strong"),pOo=o("convbert"),_Oo=o(" \u2014 "),UV=a("a"),uOo=o("ConvBertForMultipleChoice"),bOo=o(" (ConvBERT model)"),vOo=l(),Lb=a("li"),ype=a("strong"),FOo=o("data2vec-text"),TOo=o(" \u2014 "),JV=a("a"),MOo=o("Data2VecTextForMultipleChoice"),EOo=o(" (Data2VecText model)"),COo=l(),yb=a("li"),xpe=a("strong"),wOo=o("deberta-v2"),AOo=o(" \u2014 "),YV=a("a"),LOo=o("DebertaV2ForMultipleChoice"),yOo=o(" (DeBERTa-v2 model)"),xOo=l(),xb=a("li"),$pe=a("strong"),$Oo=o("distilbert"),kOo=o(" \u2014 "),KV=a("a"),SOo=o("DistilBertForMultipleChoice"),ROo=o(" (DistilBERT model)"),POo=l(),$b=a("li"),kpe=a("strong"),BOo=o("electra"),IOo=o(" \u2014 "),ZV=a("a"),NOo=o("ElectraForMultipleChoice"),qOo=o(" (ELECTRA model)"),jOo=l(),kb=a("li"),Spe=a("strong"),DOo=o("flaubert"),GOo=o(" \u2014 "),eX=a("a"),OOo=o("FlaubertForMultipleChoice"),VOo=o(" (FlauBERT model)"),XOo=l(),Sb=a("li"),Rpe=a("strong"),zOo=o("fnet"),QOo=o(" \u2014 "),oX=a("a"),WOo=o("FNetForMultipleChoice"),HOo=o(" (FNet model)"),UOo=l(),Rb=a("li"),Ppe=a("strong"),JOo=o("funnel"),YOo=o(" \u2014 "),rX=a("a"),KOo=o("FunnelForMultipleChoice"),ZOo=o(" (Funnel Transformer model)"),eVo=l(),Pb=a("li"),Bpe=a("strong"),oVo=o("ibert"),rVo=o(" \u2014 "),tX=a("a"),tVo=o("IBertForMultipleChoice"),aVo=o(" (I-BERT model)"),nVo=l(),Bb=a("li"),Ipe=a("strong"),sVo=o("longformer"),lVo=o(" \u2014 "),aX=a("a"),iVo=o("LongformerForMultipleChoice"),dVo=o(" (Longformer model)"),cVo=l(),Ib=a("li"),Npe=a("strong"),fVo=o("megatron-bert"),mVo=o(" \u2014 "),nX=a("a"),gVo=o("MegatronBertForMultipleChoice"),hVo=o(" (Megatron-BERT model)"),pVo=l(),Nb=a("li"),qpe=a("strong"),_Vo=o("mobilebert"),uVo=o(" \u2014 "),sX=a("a"),bVo=o("MobileBertForMultipleChoice"),vVo=o(" (MobileBERT model)"),FVo=l(),qb=a("li"),jpe=a("strong"),TVo=o("mpnet"),MVo=o(" \u2014 "),lX=a("a"),EVo=o("MPNetForMultipleChoice"),CVo=o(" (MPNet model)"),wVo=l(),jb=a("li"),Dpe=a("strong"),AVo=o("nezha"),LVo=o(" \u2014 "),iX=a("a"),yVo=o("NezhaForMultipleChoice"),xVo=o(" (Nezha model)"),$Vo=l(),Db=a("li"),Gpe=a("strong"),kVo=o("nystromformer"),SVo=o(" \u2014 "),dX=a("a"),RVo=o("NystromformerForMultipleChoice"),PVo=o(" (Nystr\xF6mformer model)"),BVo=l(),Gb=a("li"),Ope=a("strong"),IVo=o("qdqbert"),NVo=o(" \u2014 "),cX=a("a"),qVo=o("QDQBertForMultipleChoice"),jVo=o(" (QDQBert model)"),DVo=l(),Ob=a("li"),Vpe=a("strong"),GVo=o("rembert"),OVo=o(" \u2014 "),fX=a("a"),VVo=o("RemBertForMultipleChoice"),XVo=o(" (RemBERT model)"),zVo=l(),Vb=a("li"),Xpe=a("strong"),QVo=o("roberta"),WVo=o(" \u2014 "),mX=a("a"),HVo=o("RobertaForMultipleChoice"),UVo=o(" (RoBERTa model)"),JVo=l(),Xb=a("li"),zpe=a("strong"),YVo=o("roformer"),KVo=o(" \u2014 "),gX=a("a"),ZVo=o("RoFormerForMultipleChoice"),eXo=o(" (RoFormer model)"),oXo=l(),zb=a("li"),Qpe=a("strong"),rXo=o("squeezebert"),tXo=o(" \u2014 "),hX=a("a"),aXo=o("SqueezeBertForMultipleChoice"),nXo=o(" (SqueezeBERT model)"),sXo=l(),Qb=a("li"),Wpe=a("strong"),lXo=o("xlm"),iXo=o(" \u2014 "),pX=a("a"),dXo=o("XLMForMultipleChoice"),cXo=o(" (XLM model)"),fXo=l(),Wb=a("li"),Hpe=a("strong"),mXo=o("xlm-roberta"),gXo=o(" \u2014 "),_X=a("a"),hXo=o("XLMRobertaForMultipleChoice"),pXo=o(" (XLM-RoBERTa model)"),_Xo=l(),Hb=a("li"),Upe=a("strong"),uXo=o("xlm-roberta-xl"),bXo=o(" \u2014 "),uX=a("a"),vXo=o("XLMRobertaXLForMultipleChoice"),FXo=o(" (XLM-RoBERTa-XL model)"),TXo=l(),Ub=a("li"),Jpe=a("strong"),MXo=o("xlnet"),EXo=o(" \u2014 "),bX=a("a"),CXo=o("XLNetForMultipleChoice"),wXo=o(" (XLNet model)"),AXo=l(),Jb=a("li"),Ype=a("strong"),LXo=o("yoso"),yXo=o(" \u2014 "),vX=a("a"),xXo=o("YosoForMultipleChoice"),$Xo=o(" (YOSO model)"),kXo=l(),Yb=a("p"),SXo=o("The model is set in evaluation mode by default using "),Kpe=a("code"),RXo=o("model.eval()"),PXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=a("code"),BXo=o("model.train()"),IXo=l(),F(Kb.$$.fragment),mOe=l(),rd=a("h2"),Zb=a("a"),e_e=a("span"),F(Iy.$$.fragment),NXo=l(),o_e=a("span"),qXo=o("AutoModelForNextSentencePrediction"),gOe=l(),Io=a("div"),F(Ny.$$.fragment),jXo=l(),td=a("p"),DXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=a("a"),GXo=o("from_pretrained()"),OXo=o(" class method or the "),TX=a("a"),VXo=o("from_config()"),XXo=o(` class
method.`),zXo=l(),qy=a("p"),QXo=o("This class cannot be instantiated directly using "),r_e=a("code"),WXo=o("__init__()"),HXo=o(" (throws an error)."),UXo=l(),mt=a("div"),F(jy.$$.fragment),JXo=l(),t_e=a("p"),YXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),KXo=l(),ad=a("p"),ZXo=o(`Note:
Loading a model from its configuration file does `),a_e=a("strong"),ezo=o("not"),ozo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),rzo=o("from_pretrained()"),tzo=o(" to load the model weights."),azo=l(),F(ev.$$.fragment),nzo=l(),to=a("div"),F(Dy.$$.fragment),szo=l(),n_e=a("p"),lzo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),izo=l(),Da=a("p"),dzo=o("The model class to instantiate is selected based on the "),s_e=a("code"),czo=o("model_type"),fzo=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),mzo=o("pretrained_model_name_or_path"),gzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),hzo=o("pretrained_model_name_or_path"),pzo=o(":"),_zo=l(),No=a("ul"),ov=a("li"),d_e=a("strong"),uzo=o("bert"),bzo=o(" \u2014 "),EX=a("a"),vzo=o("BertForNextSentencePrediction"),Fzo=o(" (BERT model)"),Tzo=l(),rv=a("li"),c_e=a("strong"),Mzo=o("fnet"),Ezo=o(" \u2014 "),CX=a("a"),Czo=o("FNetForNextSentencePrediction"),wzo=o(" (FNet model)"),Azo=l(),tv=a("li"),f_e=a("strong"),Lzo=o("megatron-bert"),yzo=o(" \u2014 "),wX=a("a"),xzo=o("MegatronBertForNextSentencePrediction"),$zo=o(" (Megatron-BERT model)"),kzo=l(),av=a("li"),m_e=a("strong"),Szo=o("mobilebert"),Rzo=o(" \u2014 "),AX=a("a"),Pzo=o("MobileBertForNextSentencePrediction"),Bzo=o(" (MobileBERT model)"),Izo=l(),nv=a("li"),g_e=a("strong"),Nzo=o("nezha"),qzo=o(" \u2014 "),LX=a("a"),jzo=o("NezhaForNextSentencePrediction"),Dzo=o(" (Nezha model)"),Gzo=l(),sv=a("li"),h_e=a("strong"),Ozo=o("qdqbert"),Vzo=o(" \u2014 "),yX=a("a"),Xzo=o("QDQBertForNextSentencePrediction"),zzo=o(" (QDQBert model)"),Qzo=l(),lv=a("p"),Wzo=o("The model is set in evaluation mode by default using "),p_e=a("code"),Hzo=o("model.eval()"),Uzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=a("code"),Jzo=o("model.train()"),Yzo=l(),F(iv.$$.fragment),hOe=l(),nd=a("h2"),dv=a("a"),u_e=a("span"),F(Gy.$$.fragment),Kzo=l(),b_e=a("span"),Zzo=o("AutoModelForTokenClassification"),pOe=l(),qo=a("div"),F(Oy.$$.fragment),eQo=l(),sd=a("p"),oQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=a("a"),rQo=o("from_pretrained()"),tQo=o(" class method or the "),$X=a("a"),aQo=o("from_config()"),nQo=o(` class
method.`),sQo=l(),Vy=a("p"),lQo=o("This class cannot be instantiated directly using "),v_e=a("code"),iQo=o("__init__()"),dQo=o(" (throws an error)."),cQo=l(),gt=a("div"),F(Xy.$$.fragment),fQo=l(),F_e=a("p"),mQo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gQo=l(),ld=a("p"),hQo=o(`Note:
Loading a model from its configuration file does `),T_e=a("strong"),pQo=o("not"),_Qo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),uQo=o("from_pretrained()"),bQo=o(" to load the model weights."),vQo=l(),F(cv.$$.fragment),FQo=l(),ao=a("div"),F(zy.$$.fragment),TQo=l(),M_e=a("p"),MQo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EQo=l(),Ga=a("p"),CQo=o("The model class to instantiate is selected based on the "),E_e=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),C_e=a("code"),LQo=o("pretrained_model_name_or_path"),yQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=a("code"),xQo=o("pretrained_model_name_or_path"),$Qo=o(":"),kQo=l(),H=a("ul"),fv=a("li"),A_e=a("strong"),SQo=o("albert"),RQo=o(" \u2014 "),SX=a("a"),PQo=o("AlbertForTokenClassification"),BQo=o(" (ALBERT model)"),IQo=l(),mv=a("li"),L_e=a("strong"),NQo=o("bert"),qQo=o(" \u2014 "),RX=a("a"),jQo=o("BertForTokenClassification"),DQo=o(" (BERT model)"),GQo=l(),gv=a("li"),y_e=a("strong"),OQo=o("big_bird"),VQo=o(" \u2014 "),PX=a("a"),XQo=o("BigBirdForTokenClassification"),zQo=o(" (BigBird model)"),QQo=l(),hv=a("li"),x_e=a("strong"),WQo=o("bloom"),HQo=o(" \u2014 "),BX=a("a"),UQo=o("BloomForTokenClassification"),JQo=o(" (BLOOM model)"),YQo=l(),pv=a("li"),$_e=a("strong"),KQo=o("camembert"),ZQo=o(" \u2014 "),IX=a("a"),eWo=o("CamembertForTokenClassification"),oWo=o(" (CamemBERT model)"),rWo=l(),_v=a("li"),k_e=a("strong"),tWo=o("canine"),aWo=o(" \u2014 "),NX=a("a"),nWo=o("CanineForTokenClassification"),sWo=o(" (CANINE model)"),lWo=l(),uv=a("li"),S_e=a("strong"),iWo=o("convbert"),dWo=o(" \u2014 "),qX=a("a"),cWo=o("ConvBertForTokenClassification"),fWo=o(" (ConvBERT model)"),mWo=l(),bv=a("li"),R_e=a("strong"),gWo=o("data2vec-text"),hWo=o(" \u2014 "),jX=a("a"),pWo=o("Data2VecTextForTokenClassification"),_Wo=o(" (Data2VecText model)"),uWo=l(),vv=a("li"),P_e=a("strong"),bWo=o("deberta"),vWo=o(" \u2014 "),DX=a("a"),FWo=o("DebertaForTokenClassification"),TWo=o(" (DeBERTa model)"),MWo=l(),Fv=a("li"),B_e=a("strong"),EWo=o("deberta-v2"),CWo=o(" \u2014 "),GX=a("a"),wWo=o("DebertaV2ForTokenClassification"),AWo=o(" (DeBERTa-v2 model)"),LWo=l(),Tv=a("li"),I_e=a("strong"),yWo=o("distilbert"),xWo=o(" \u2014 "),OX=a("a"),$Wo=o("DistilBertForTokenClassification"),kWo=o(" (DistilBERT model)"),SWo=l(),Mv=a("li"),N_e=a("strong"),RWo=o("electra"),PWo=o(" \u2014 "),VX=a("a"),BWo=o("ElectraForTokenClassification"),IWo=o(" (ELECTRA model)"),NWo=l(),Ev=a("li"),q_e=a("strong"),qWo=o("flaubert"),jWo=o(" \u2014 "),XX=a("a"),DWo=o("FlaubertForTokenClassification"),GWo=o(" (FlauBERT model)"),OWo=l(),Cv=a("li"),j_e=a("strong"),VWo=o("fnet"),XWo=o(" \u2014 "),zX=a("a"),zWo=o("FNetForTokenClassification"),QWo=o(" (FNet model)"),WWo=l(),wv=a("li"),D_e=a("strong"),HWo=o("funnel"),UWo=o(" \u2014 "),QX=a("a"),JWo=o("FunnelForTokenClassification"),YWo=o(" (Funnel Transformer model)"),KWo=l(),Av=a("li"),G_e=a("strong"),ZWo=o("gpt2"),eHo=o(" \u2014 "),WX=a("a"),oHo=o("GPT2ForTokenClassification"),rHo=o(" (OpenAI GPT-2 model)"),tHo=l(),Lv=a("li"),O_e=a("strong"),aHo=o("ibert"),nHo=o(" \u2014 "),HX=a("a"),sHo=o("IBertForTokenClassification"),lHo=o(" (I-BERT model)"),iHo=l(),yv=a("li"),V_e=a("strong"),dHo=o("layoutlm"),cHo=o(" \u2014 "),UX=a("a"),fHo=o("LayoutLMForTokenClassification"),mHo=o(" (LayoutLM model)"),gHo=l(),xv=a("li"),X_e=a("strong"),hHo=o("layoutlmv2"),pHo=o(" \u2014 "),JX=a("a"),_Ho=o("LayoutLMv2ForTokenClassification"),uHo=o(" (LayoutLMv2 model)"),bHo=l(),$v=a("li"),z_e=a("strong"),vHo=o("layoutlmv3"),FHo=o(" \u2014 "),YX=a("a"),THo=o("LayoutLMv3ForTokenClassification"),MHo=o(" (LayoutLMv3 model)"),EHo=l(),kv=a("li"),Q_e=a("strong"),CHo=o("longformer"),wHo=o(" \u2014 "),KX=a("a"),AHo=o("LongformerForTokenClassification"),LHo=o(" (Longformer model)"),yHo=l(),Sv=a("li"),W_e=a("strong"),xHo=o("megatron-bert"),$Ho=o(" \u2014 "),ZX=a("a"),kHo=o("MegatronBertForTokenClassification"),SHo=o(" (Megatron-BERT model)"),RHo=l(),Rv=a("li"),H_e=a("strong"),PHo=o("mobilebert"),BHo=o(" \u2014 "),ez=a("a"),IHo=o("MobileBertForTokenClassification"),NHo=o(" (MobileBERT model)"),qHo=l(),Pv=a("li"),U_e=a("strong"),jHo=o("mpnet"),DHo=o(" \u2014 "),oz=a("a"),GHo=o("MPNetForTokenClassification"),OHo=o(" (MPNet model)"),VHo=l(),Bv=a("li"),J_e=a("strong"),XHo=o("nezha"),zHo=o(" \u2014 "),rz=a("a"),QHo=o("NezhaForTokenClassification"),WHo=o(" (Nezha model)"),HHo=l(),Iv=a("li"),Y_e=a("strong"),UHo=o("nystromformer"),JHo=o(" \u2014 "),tz=a("a"),YHo=o("NystromformerForTokenClassification"),KHo=o(" (Nystr\xF6mformer model)"),ZHo=l(),Nv=a("li"),K_e=a("strong"),eUo=o("qdqbert"),oUo=o(" \u2014 "),az=a("a"),rUo=o("QDQBertForTokenClassification"),tUo=o(" (QDQBert model)"),aUo=l(),qv=a("li"),Z_e=a("strong"),nUo=o("rembert"),sUo=o(" \u2014 "),nz=a("a"),lUo=o("RemBertForTokenClassification"),iUo=o(" (RemBERT model)"),dUo=l(),jv=a("li"),eue=a("strong"),cUo=o("roberta"),fUo=o(" \u2014 "),sz=a("a"),mUo=o("RobertaForTokenClassification"),gUo=o(" (RoBERTa model)"),hUo=l(),Dv=a("li"),oue=a("strong"),pUo=o("roformer"),_Uo=o(" \u2014 "),lz=a("a"),uUo=o("RoFormerForTokenClassification"),bUo=o(" (RoFormer model)"),vUo=l(),Gv=a("li"),rue=a("strong"),FUo=o("squeezebert"),TUo=o(" \u2014 "),iz=a("a"),MUo=o("SqueezeBertForTokenClassification"),EUo=o(" (SqueezeBERT model)"),CUo=l(),Ov=a("li"),tue=a("strong"),wUo=o("xlm"),AUo=o(" \u2014 "),dz=a("a"),LUo=o("XLMForTokenClassification"),yUo=o(" (XLM model)"),xUo=l(),Vv=a("li"),aue=a("strong"),$Uo=o("xlm-roberta"),kUo=o(" \u2014 "),cz=a("a"),SUo=o("XLMRobertaForTokenClassification"),RUo=o(" (XLM-RoBERTa model)"),PUo=l(),Xv=a("li"),nue=a("strong"),BUo=o("xlm-roberta-xl"),IUo=o(" \u2014 "),fz=a("a"),NUo=o("XLMRobertaXLForTokenClassification"),qUo=o(" (XLM-RoBERTa-XL model)"),jUo=l(),zv=a("li"),sue=a("strong"),DUo=o("xlnet"),GUo=o(" \u2014 "),mz=a("a"),OUo=o("XLNetForTokenClassification"),VUo=o(" (XLNet model)"),XUo=l(),Qv=a("li"),lue=a("strong"),zUo=o("yoso"),QUo=o(" \u2014 "),gz=a("a"),WUo=o("YosoForTokenClassification"),HUo=o(" (YOSO model)"),UUo=l(),Wv=a("p"),JUo=o("The model is set in evaluation mode by default using "),iue=a("code"),YUo=o("model.eval()"),KUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=a("code"),ZUo=o("model.train()"),eJo=l(),F(Hv.$$.fragment),_Oe=l(),id=a("h2"),Uv=a("a"),cue=a("span"),F(Qy.$$.fragment),oJo=l(),fue=a("span"),rJo=o("AutoModelForQuestionAnswering"),uOe=l(),jo=a("div"),F(Wy.$$.fragment),tJo=l(),dd=a("p"),aJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=a("a"),nJo=o("from_pretrained()"),sJo=o(" class method or the "),pz=a("a"),lJo=o("from_config()"),iJo=o(` class
method.`),dJo=l(),Hy=a("p"),cJo=o("This class cannot be instantiated directly using "),mue=a("code"),fJo=o("__init__()"),mJo=o(" (throws an error)."),gJo=l(),ht=a("div"),F(Uy.$$.fragment),hJo=l(),gue=a("p"),pJo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_Jo=l(),cd=a("p"),uJo=o(`Note:
Loading a model from its configuration file does `),hue=a("strong"),bJo=o("not"),vJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=a("a"),FJo=o("from_pretrained()"),TJo=o(" to load the model weights."),MJo=l(),F(Jv.$$.fragment),EJo=l(),no=a("div"),F(Jy.$$.fragment),CJo=l(),pue=a("p"),wJo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),AJo=l(),Oa=a("p"),LJo=o("The model class to instantiate is selected based on the "),_ue=a("code"),yJo=o("model_type"),xJo=o(` property of the config object (either
passed as an argument or loaded from `),uue=a("code"),$Jo=o("pretrained_model_name_or_path"),kJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=a("code"),SJo=o("pretrained_model_name_or_path"),RJo=o(":"),PJo=l(),V=a("ul"),Yv=a("li"),vue=a("strong"),BJo=o("albert"),IJo=o(" \u2014 "),uz=a("a"),NJo=o("AlbertForQuestionAnswering"),qJo=o(" (ALBERT model)"),jJo=l(),Kv=a("li"),Fue=a("strong"),DJo=o("bart"),GJo=o(" \u2014 "),bz=a("a"),OJo=o("BartForQuestionAnswering"),VJo=o(" (BART model)"),XJo=l(),Zv=a("li"),Tue=a("strong"),zJo=o("bert"),QJo=o(" \u2014 "),vz=a("a"),WJo=o("BertForQuestionAnswering"),HJo=o(" (BERT model)"),UJo=l(),eF=a("li"),Mue=a("strong"),JJo=o("big_bird"),YJo=o(" \u2014 "),Fz=a("a"),KJo=o("BigBirdForQuestionAnswering"),ZJo=o(" (BigBird model)"),eYo=l(),oF=a("li"),Eue=a("strong"),oYo=o("bigbird_pegasus"),rYo=o(" \u2014 "),Tz=a("a"),tYo=o("BigBirdPegasusForQuestionAnswering"),aYo=o(" (BigBird-Pegasus model)"),nYo=l(),rF=a("li"),Cue=a("strong"),sYo=o("camembert"),lYo=o(" \u2014 "),Mz=a("a"),iYo=o("CamembertForQuestionAnswering"),dYo=o(" (CamemBERT model)"),cYo=l(),tF=a("li"),wue=a("strong"),fYo=o("canine"),mYo=o(" \u2014 "),Ez=a("a"),gYo=o("CanineForQuestionAnswering"),hYo=o(" (CANINE model)"),pYo=l(),aF=a("li"),Aue=a("strong"),_Yo=o("convbert"),uYo=o(" \u2014 "),Cz=a("a"),bYo=o("ConvBertForQuestionAnswering"),vYo=o(" (ConvBERT model)"),FYo=l(),nF=a("li"),Lue=a("strong"),TYo=o("data2vec-text"),MYo=o(" \u2014 "),wz=a("a"),EYo=o("Data2VecTextForQuestionAnswering"),CYo=o(" (Data2VecText model)"),wYo=l(),sF=a("li"),yue=a("strong"),AYo=o("deberta"),LYo=o(" \u2014 "),Az=a("a"),yYo=o("DebertaForQuestionAnswering"),xYo=o(" (DeBERTa model)"),$Yo=l(),lF=a("li"),xue=a("strong"),kYo=o("deberta-v2"),SYo=o(" \u2014 "),Lz=a("a"),RYo=o("DebertaV2ForQuestionAnswering"),PYo=o(" (DeBERTa-v2 model)"),BYo=l(),iF=a("li"),$ue=a("strong"),IYo=o("distilbert"),NYo=o(" \u2014 "),yz=a("a"),qYo=o("DistilBertForQuestionAnswering"),jYo=o(" (DistilBERT model)"),DYo=l(),dF=a("li"),kue=a("strong"),GYo=o("electra"),OYo=o(" \u2014 "),xz=a("a"),VYo=o("ElectraForQuestionAnswering"),XYo=o(" (ELECTRA model)"),zYo=l(),cF=a("li"),Sue=a("strong"),QYo=o("flaubert"),WYo=o(" \u2014 "),$z=a("a"),HYo=o("FlaubertForQuestionAnsweringSimple"),UYo=o(" (FlauBERT model)"),JYo=l(),fF=a("li"),Rue=a("strong"),YYo=o("fnet"),KYo=o(" \u2014 "),kz=a("a"),ZYo=o("FNetForQuestionAnswering"),eKo=o(" (FNet model)"),oKo=l(),mF=a("li"),Pue=a("strong"),rKo=o("funnel"),tKo=o(" \u2014 "),Sz=a("a"),aKo=o("FunnelForQuestionAnswering"),nKo=o(" (Funnel Transformer model)"),sKo=l(),gF=a("li"),Bue=a("strong"),lKo=o("gptj"),iKo=o(" \u2014 "),Rz=a("a"),dKo=o("GPTJForQuestionAnswering"),cKo=o(" (GPT-J model)"),fKo=l(),hF=a("li"),Iue=a("strong"),mKo=o("ibert"),gKo=o(" \u2014 "),Pz=a("a"),hKo=o("IBertForQuestionAnswering"),pKo=o(" (I-BERT model)"),_Ko=l(),pF=a("li"),Nue=a("strong"),uKo=o("layoutlmv2"),bKo=o(" \u2014 "),Bz=a("a"),vKo=o("LayoutLMv2ForQuestionAnswering"),FKo=o(" (LayoutLMv2 model)"),TKo=l(),_F=a("li"),que=a("strong"),MKo=o("layoutlmv3"),EKo=o(" \u2014 "),Iz=a("a"),CKo=o("LayoutLMv3ForQuestionAnswering"),wKo=o(" (LayoutLMv3 model)"),AKo=l(),uF=a("li"),jue=a("strong"),LKo=o("led"),yKo=o(" \u2014 "),Nz=a("a"),xKo=o("LEDForQuestionAnswering"),$Ko=o(" (LED model)"),kKo=l(),bF=a("li"),Due=a("strong"),SKo=o("longformer"),RKo=o(" \u2014 "),qz=a("a"),PKo=o("LongformerForQuestionAnswering"),BKo=o(" (Longformer model)"),IKo=l(),vF=a("li"),Gue=a("strong"),NKo=o("lxmert"),qKo=o(" \u2014 "),jz=a("a"),jKo=o("LxmertForQuestionAnswering"),DKo=o(" (LXMERT model)"),GKo=l(),FF=a("li"),Oue=a("strong"),OKo=o("mbart"),VKo=o(" \u2014 "),Dz=a("a"),XKo=o("MBartForQuestionAnswering"),zKo=o(" (mBART model)"),QKo=l(),TF=a("li"),Vue=a("strong"),WKo=o("megatron-bert"),HKo=o(" \u2014 "),Gz=a("a"),UKo=o("MegatronBertForQuestionAnswering"),JKo=o(" (Megatron-BERT model)"),YKo=l(),MF=a("li"),Xue=a("strong"),KKo=o("mobilebert"),ZKo=o(" \u2014 "),Oz=a("a"),eZo=o("MobileBertForQuestionAnswering"),oZo=o(" (MobileBERT model)"),rZo=l(),EF=a("li"),zue=a("strong"),tZo=o("mpnet"),aZo=o(" \u2014 "),Vz=a("a"),nZo=o("MPNetForQuestionAnswering"),sZo=o(" (MPNet model)"),lZo=l(),CF=a("li"),Que=a("strong"),iZo=o("nezha"),dZo=o(" \u2014 "),Xz=a("a"),cZo=o("NezhaForQuestionAnswering"),fZo=o(" (Nezha model)"),mZo=l(),wF=a("li"),Wue=a("strong"),gZo=o("nystromformer"),hZo=o(" \u2014 "),zz=a("a"),pZo=o("NystromformerForQuestionAnswering"),_Zo=o(" (Nystr\xF6mformer model)"),uZo=l(),AF=a("li"),Hue=a("strong"),bZo=o("qdqbert"),vZo=o(" \u2014 "),Qz=a("a"),FZo=o("QDQBertForQuestionAnswering"),TZo=o(" (QDQBert model)"),MZo=l(),LF=a("li"),Uue=a("strong"),EZo=o("reformer"),CZo=o(" \u2014 "),Wz=a("a"),wZo=o("ReformerForQuestionAnswering"),AZo=o(" (Reformer model)"),LZo=l(),yF=a("li"),Jue=a("strong"),yZo=o("rembert"),xZo=o(" \u2014 "),Hz=a("a"),$Zo=o("RemBertForQuestionAnswering"),kZo=o(" (RemBERT model)"),SZo=l(),xF=a("li"),Yue=a("strong"),RZo=o("roberta"),PZo=o(" \u2014 "),Uz=a("a"),BZo=o("RobertaForQuestionAnswering"),IZo=o(" (RoBERTa model)"),NZo=l(),$F=a("li"),Kue=a("strong"),qZo=o("roformer"),jZo=o(" \u2014 "),Jz=a("a"),DZo=o("RoFormerForQuestionAnswering"),GZo=o(" (RoFormer model)"),OZo=l(),kF=a("li"),Zue=a("strong"),VZo=o("splinter"),XZo=o(" \u2014 "),Yz=a("a"),zZo=o("SplinterForQuestionAnswering"),QZo=o(" (Splinter model)"),WZo=l(),SF=a("li"),e7e=a("strong"),HZo=o("squeezebert"),UZo=o(" \u2014 "),Kz=a("a"),JZo=o("SqueezeBertForQuestionAnswering"),YZo=o(" (SqueezeBERT model)"),KZo=l(),RF=a("li"),o7e=a("strong"),ZZo=o("xlm"),eer=o(" \u2014 "),Zz=a("a"),oer=o("XLMForQuestionAnsweringSimple"),rer=o(" (XLM model)"),ter=l(),PF=a("li"),r7e=a("strong"),aer=o("xlm-roberta"),ner=o(" \u2014 "),eQ=a("a"),ser=o("XLMRobertaForQuestionAnswering"),ler=o(" (XLM-RoBERTa model)"),ier=l(),BF=a("li"),t7e=a("strong"),der=o("xlm-roberta-xl"),cer=o(" \u2014 "),oQ=a("a"),fer=o("XLMRobertaXLForQuestionAnswering"),mer=o(" (XLM-RoBERTa-XL model)"),ger=l(),IF=a("li"),a7e=a("strong"),her=o("xlnet"),per=o(" \u2014 "),rQ=a("a"),_er=o("XLNetForQuestionAnsweringSimple"),uer=o(" (XLNet model)"),ber=l(),NF=a("li"),n7e=a("strong"),ver=o("yoso"),Fer=o(" \u2014 "),tQ=a("a"),Ter=o("YosoForQuestionAnswering"),Mer=o(" (YOSO model)"),Eer=l(),qF=a("p"),Cer=o("The model is set in evaluation mode by default using "),s7e=a("code"),wer=o("model.eval()"),Aer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l7e=a("code"),Ler=o("model.train()"),yer=l(),F(jF.$$.fragment),bOe=l(),fd=a("h2"),DF=a("a"),i7e=a("span"),F(Yy.$$.fragment),xer=l(),d7e=a("span"),$er=o("AutoModelForTableQuestionAnswering"),vOe=l(),Do=a("div"),F(Ky.$$.fragment),ker=l(),md=a("p"),Ser=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=a("a"),Rer=o("from_pretrained()"),Per=o(" class method or the "),nQ=a("a"),Ber=o("from_config()"),Ier=o(` class
method.`),Ner=l(),Zy=a("p"),qer=o("This class cannot be instantiated directly using "),c7e=a("code"),jer=o("__init__()"),Der=o(" (throws an error)."),Ger=l(),pt=a("div"),F(e8.$$.fragment),Oer=l(),f7e=a("p"),Ver=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Xer=l(),gd=a("p"),zer=o(`Note:
Loading a model from its configuration file does `),m7e=a("strong"),Qer=o("not"),Wer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=a("a"),Her=o("from_pretrained()"),Uer=o(" to load the model weights."),Jer=l(),F(GF.$$.fragment),Yer=l(),so=a("div"),F(o8.$$.fragment),Ker=l(),g7e=a("p"),Zer=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eor=l(),Va=a("p"),oor=o("The model class to instantiate is selected based on the "),h7e=a("code"),ror=o("model_type"),tor=o(` property of the config object (either
passed as an argument or loaded from `),p7e=a("code"),aor=o("pretrained_model_name_or_path"),nor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_7e=a("code"),sor=o("pretrained_model_name_or_path"),lor=o(":"),ior=l(),u7e=a("ul"),OF=a("li"),b7e=a("strong"),dor=o("tapas"),cor=o(" \u2014 "),lQ=a("a"),mor=o("TapasForQuestionAnswering"),gor=o(" (TAPAS model)"),hor=l(),VF=a("p"),por=o("The model is set in evaluation mode by default using "),v7e=a("code"),_or=o("model.eval()"),uor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F7e=a("code"),bor=o("model.train()"),vor=l(),F(XF.$$.fragment),FOe=l(),hd=a("h2"),zF=a("a"),T7e=a("span"),F(r8.$$.fragment),For=l(),M7e=a("span"),Tor=o("AutoModelForImageClassification"),TOe=l(),Go=a("div"),F(t8.$$.fragment),Mor=l(),pd=a("p"),Eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=a("a"),Cor=o("from_pretrained()"),wor=o(" class method or the "),dQ=a("a"),Aor=o("from_config()"),Lor=o(` class
method.`),yor=l(),a8=a("p"),xor=o("This class cannot be instantiated directly using "),E7e=a("code"),$or=o("__init__()"),kor=o(" (throws an error)."),Sor=l(),_t=a("div"),F(n8.$$.fragment),Ror=l(),C7e=a("p"),Por=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Bor=l(),_d=a("p"),Ior=o(`Note:
Loading a model from its configuration file does `),w7e=a("strong"),Nor=o("not"),qor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),jor=o("from_pretrained()"),Dor=o(" to load the model weights."),Gor=l(),F(QF.$$.fragment),Oor=l(),lo=a("div"),F(s8.$$.fragment),Vor=l(),A7e=a("p"),Xor=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),zor=l(),Xa=a("p"),Qor=o("The model class to instantiate is selected based on the "),L7e=a("code"),Wor=o("model_type"),Hor=o(` property of the config object (either
passed as an argument or loaded from `),y7e=a("code"),Uor=o("pretrained_model_name_or_path"),Jor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x7e=a("code"),Yor=o("pretrained_model_name_or_path"),Kor=o(":"),Zor=l(),Fe=a("ul"),WF=a("li"),$7e=a("strong"),err=o("beit"),orr=o(" \u2014 "),fQ=a("a"),rrr=o("BeitForImageClassification"),trr=o(" (BEiT model)"),arr=l(),HF=a("li"),k7e=a("strong"),nrr=o("convnext"),srr=o(" \u2014 "),mQ=a("a"),lrr=o("ConvNextForImageClassification"),irr=o(" (ConvNeXT model)"),drr=l(),UF=a("li"),S7e=a("strong"),crr=o("cvt"),frr=o(" \u2014 "),gQ=a("a"),mrr=o("CvtForImageClassification"),grr=o(" (CvT model)"),hrr=l(),JF=a("li"),R7e=a("strong"),prr=o("data2vec-vision"),_rr=o(" \u2014 "),hQ=a("a"),urr=o("Data2VecVisionForImageClassification"),brr=o(" (Data2VecVision model)"),vrr=l(),Xs=a("li"),P7e=a("strong"),Frr=o("deit"),Trr=o(" \u2014 "),pQ=a("a"),Mrr=o("DeiTForImageClassification"),Err=o(" or "),_Q=a("a"),Crr=o("DeiTForImageClassificationWithTeacher"),wrr=o(" (DeiT model)"),Arr=l(),YF=a("li"),B7e=a("strong"),Lrr=o("imagegpt"),yrr=o(" \u2014 "),uQ=a("a"),xrr=o("ImageGPTForImageClassification"),$rr=o(" (ImageGPT model)"),krr=l(),zs=a("li"),I7e=a("strong"),Srr=o("levit"),Rrr=o(" \u2014 "),bQ=a("a"),Prr=o("LevitForImageClassification"),Brr=o(" or "),vQ=a("a"),Irr=o("LevitForImageClassificationWithTeacher"),Nrr=o(" (LeViT model)"),qrr=l(),ut=a("li"),N7e=a("strong"),jrr=o("perceiver"),Drr=o(" \u2014 "),FQ=a("a"),Grr=o("PerceiverForImageClassificationLearned"),Orr=o(" or "),TQ=a("a"),Vrr=o("PerceiverForImageClassificationFourier"),Xrr=o(" or "),MQ=a("a"),zrr=o("PerceiverForImageClassificationConvProcessing"),Qrr=o(" (Perceiver model)"),Wrr=l(),KF=a("li"),q7e=a("strong"),Hrr=o("poolformer"),Urr=o(" \u2014 "),EQ=a("a"),Jrr=o("PoolFormerForImageClassification"),Yrr=o(" (PoolFormer model)"),Krr=l(),ZF=a("li"),j7e=a("strong"),Zrr=o("regnet"),etr=o(" \u2014 "),CQ=a("a"),otr=o("RegNetForImageClassification"),rtr=o(" (RegNet model)"),ttr=l(),e6=a("li"),D7e=a("strong"),atr=o("resnet"),ntr=o(" \u2014 "),wQ=a("a"),str=o("ResNetForImageClassification"),ltr=o(" (ResNet model)"),itr=l(),o6=a("li"),G7e=a("strong"),dtr=o("segformer"),ctr=o(" \u2014 "),AQ=a("a"),ftr=o("SegformerForImageClassification"),mtr=o(" (SegFormer model)"),gtr=l(),r6=a("li"),O7e=a("strong"),htr=o("swin"),ptr=o(" \u2014 "),LQ=a("a"),_tr=o("SwinForImageClassification"),utr=o(" (Swin Transformer model)"),btr=l(),t6=a("li"),V7e=a("strong"),vtr=o("van"),Ftr=o(" \u2014 "),yQ=a("a"),Ttr=o("VanForImageClassification"),Mtr=o(" (VAN model)"),Etr=l(),a6=a("li"),X7e=a("strong"),Ctr=o("vit"),wtr=o(" \u2014 "),xQ=a("a"),Atr=o("ViTForImageClassification"),Ltr=o(" (ViT model)"),ytr=l(),n6=a("p"),xtr=o("The model is set in evaluation mode by default using "),z7e=a("code"),$tr=o("model.eval()"),ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q7e=a("code"),Str=o("model.train()"),Rtr=l(),F(s6.$$.fragment),MOe=l(),ud=a("h2"),l6=a("a"),W7e=a("span"),F(l8.$$.fragment),Ptr=l(),H7e=a("span"),Btr=o("AutoModelForVision2Seq"),EOe=l(),Oo=a("div"),F(i8.$$.fragment),Itr=l(),bd=a("p"),Ntr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=a("a"),qtr=o("from_pretrained()"),jtr=o(" class method or the "),kQ=a("a"),Dtr=o("from_config()"),Gtr=o(` class
method.`),Otr=l(),d8=a("p"),Vtr=o("This class cannot be instantiated directly using "),U7e=a("code"),Xtr=o("__init__()"),ztr=o(" (throws an error)."),Qtr=l(),bt=a("div"),F(c8.$$.fragment),Wtr=l(),J7e=a("p"),Htr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Utr=l(),vd=a("p"),Jtr=o(`Note:
Loading a model from its configuration file does `),Y7e=a("strong"),Ytr=o("not"),Ktr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),Ztr=o("from_pretrained()"),ear=o(" to load the model weights."),oar=l(),F(i6.$$.fragment),rar=l(),io=a("div"),F(f8.$$.fragment),tar=l(),K7e=a("p"),aar=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nar=l(),za=a("p"),sar=o("The model class to instantiate is selected based on the "),Z7e=a("code"),lar=o("model_type"),iar=o(` property of the config object (either
passed as an argument or loaded from `),e1e=a("code"),dar=o("pretrained_model_name_or_path"),car=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=a("code"),far=o("pretrained_model_name_or_path"),mar=o(":"),gar=l(),r1e=a("ul"),d6=a("li"),t1e=a("strong"),har=o("vision-encoder-decoder"),par=o(" \u2014 "),RQ=a("a"),_ar=o("VisionEncoderDecoderModel"),uar=o(" (Vision Encoder decoder model)"),bar=l(),c6=a("p"),Far=o("The model is set in evaluation mode by default using "),a1e=a("code"),Tar=o("model.eval()"),Mar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n1e=a("code"),Ear=o("model.train()"),Car=l(),F(f6.$$.fragment),COe=l(),Fd=a("h2"),m6=a("a"),s1e=a("span"),F(m8.$$.fragment),war=l(),l1e=a("span"),Aar=o("AutoModelForVisualQuestionAnswering"),wOe=l(),Vo=a("div"),F(g8.$$.fragment),Lar=l(),Td=a("p"),yar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=a("a"),xar=o("from_pretrained()"),$ar=o(" class method or the "),BQ=a("a"),kar=o("from_config()"),Sar=o(` class
method.`),Rar=l(),h8=a("p"),Par=o("This class cannot be instantiated directly using "),i1e=a("code"),Bar=o("__init__()"),Iar=o(" (throws an error)."),Nar=l(),vt=a("div"),F(p8.$$.fragment),qar=l(),d1e=a("p"),jar=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Dar=l(),Md=a("p"),Gar=o(`Note:
Loading a model from its configuration file does `),c1e=a("strong"),Oar=o("not"),Var=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),Xar=o("from_pretrained()"),zar=o(" to load the model weights."),Qar=l(),F(g6.$$.fragment),War=l(),co=a("div"),F(_8.$$.fragment),Har=l(),f1e=a("p"),Uar=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Jar=l(),Qa=a("p"),Yar=o("The model class to instantiate is selected based on the "),m1e=a("code"),Kar=o("model_type"),Zar=o(` property of the config object (either
passed as an argument or loaded from `),g1e=a("code"),enr=o("pretrained_model_name_or_path"),onr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h1e=a("code"),rnr=o("pretrained_model_name_or_path"),tnr=o(":"),anr=l(),p1e=a("ul"),h6=a("li"),_1e=a("strong"),nnr=o("vilt"),snr=o(" \u2014 "),NQ=a("a"),lnr=o("ViltForQuestionAnswering"),inr=o(" (ViLT model)"),dnr=l(),p6=a("p"),cnr=o("The model is set in evaluation mode by default using "),u1e=a("code"),fnr=o("model.eval()"),mnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b1e=a("code"),gnr=o("model.train()"),hnr=l(),F(_6.$$.fragment),AOe=l(),Ed=a("h2"),u6=a("a"),v1e=a("span"),F(u8.$$.fragment),pnr=l(),F1e=a("span"),_nr=o("AutoModelForAudioClassification"),LOe=l(),Xo=a("div"),F(b8.$$.fragment),unr=l(),Cd=a("p"),bnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=a("a"),vnr=o("from_pretrained()"),Fnr=o(" class method or the "),jQ=a("a"),Tnr=o("from_config()"),Mnr=o(` class
method.`),Enr=l(),v8=a("p"),Cnr=o("This class cannot be instantiated directly using "),T1e=a("code"),wnr=o("__init__()"),Anr=o(" (throws an error)."),Lnr=l(),Ft=a("div"),F(F8.$$.fragment),ynr=l(),M1e=a("p"),xnr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$nr=l(),wd=a("p"),knr=o(`Note:
Loading a model from its configuration file does `),E1e=a("strong"),Snr=o("not"),Rnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),Pnr=o("from_pretrained()"),Bnr=o(" to load the model weights."),Inr=l(),F(b6.$$.fragment),Nnr=l(),fo=a("div"),F(T8.$$.fragment),qnr=l(),C1e=a("p"),jnr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Dnr=l(),Wa=a("p"),Gnr=o("The model class to instantiate is selected based on the "),w1e=a("code"),Onr=o("model_type"),Vnr=o(` property of the config object (either
passed as an argument or loaded from `),A1e=a("code"),Xnr=o("pretrained_model_name_or_path"),znr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L1e=a("code"),Qnr=o("pretrained_model_name_or_path"),Wnr=o(":"),Hnr=l(),Pe=a("ul"),v6=a("li"),y1e=a("strong"),Unr=o("data2vec-audio"),Jnr=o(" \u2014 "),GQ=a("a"),Ynr=o("Data2VecAudioForSequenceClassification"),Knr=o(" (Data2VecAudio model)"),Znr=l(),F6=a("li"),x1e=a("strong"),esr=o("hubert"),osr=o(" \u2014 "),OQ=a("a"),rsr=o("HubertForSequenceClassification"),tsr=o(" (Hubert model)"),asr=l(),T6=a("li"),$1e=a("strong"),nsr=o("sew"),ssr=o(" \u2014 "),VQ=a("a"),lsr=o("SEWForSequenceClassification"),isr=o(" (SEW model)"),dsr=l(),M6=a("li"),k1e=a("strong"),csr=o("sew-d"),fsr=o(" \u2014 "),XQ=a("a"),msr=o("SEWDForSequenceClassification"),gsr=o(" (SEW-D model)"),hsr=l(),E6=a("li"),S1e=a("strong"),psr=o("unispeech"),_sr=o(" \u2014 "),zQ=a("a"),usr=o("UniSpeechForSequenceClassification"),bsr=o(" (UniSpeech model)"),vsr=l(),C6=a("li"),R1e=a("strong"),Fsr=o("unispeech-sat"),Tsr=o(" \u2014 "),QQ=a("a"),Msr=o("UniSpeechSatForSequenceClassification"),Esr=o(" (UniSpeechSat model)"),Csr=l(),w6=a("li"),P1e=a("strong"),wsr=o("wav2vec2"),Asr=o(" \u2014 "),WQ=a("a"),Lsr=o("Wav2Vec2ForSequenceClassification"),ysr=o(" (Wav2Vec2 model)"),xsr=l(),A6=a("li"),B1e=a("strong"),$sr=o("wav2vec2-conformer"),ksr=o(" \u2014 "),HQ=a("a"),Ssr=o("Wav2Vec2ConformerForSequenceClassification"),Rsr=o(" (Wav2Vec2-Conformer model)"),Psr=l(),L6=a("li"),I1e=a("strong"),Bsr=o("wavlm"),Isr=o(" \u2014 "),UQ=a("a"),Nsr=o("WavLMForSequenceClassification"),qsr=o(" (WavLM model)"),jsr=l(),y6=a("p"),Dsr=o("The model is set in evaluation mode by default using "),N1e=a("code"),Gsr=o("model.eval()"),Osr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q1e=a("code"),Vsr=o("model.train()"),Xsr=l(),F(x6.$$.fragment),yOe=l(),Ad=a("h2"),$6=a("a"),j1e=a("span"),F(M8.$$.fragment),zsr=l(),D1e=a("span"),Qsr=o("AutoModelForAudioFrameClassification"),xOe=l(),zo=a("div"),F(E8.$$.fragment),Wsr=l(),Ld=a("p"),Hsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=a("a"),Usr=o("from_pretrained()"),Jsr=o(" class method or the "),YQ=a("a"),Ysr=o("from_config()"),Ksr=o(` class
method.`),Zsr=l(),C8=a("p"),elr=o("This class cannot be instantiated directly using "),G1e=a("code"),olr=o("__init__()"),rlr=o(" (throws an error)."),tlr=l(),Tt=a("div"),F(w8.$$.fragment),alr=l(),O1e=a("p"),nlr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),slr=l(),yd=a("p"),llr=o(`Note:
Loading a model from its configuration file does `),V1e=a("strong"),ilr=o("not"),dlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=a("a"),clr=o("from_pretrained()"),flr=o(" to load the model weights."),mlr=l(),F(k6.$$.fragment),glr=l(),mo=a("div"),F(A8.$$.fragment),hlr=l(),X1e=a("p"),plr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),_lr=l(),Ha=a("p"),ulr=o("The model class to instantiate is selected based on the "),z1e=a("code"),blr=o("model_type"),vlr=o(` property of the config object (either
passed as an argument or loaded from `),Q1e=a("code"),Flr=o("pretrained_model_name_or_path"),Tlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W1e=a("code"),Mlr=o("pretrained_model_name_or_path"),Elr=o(":"),Clr=l(),et=a("ul"),S6=a("li"),H1e=a("strong"),wlr=o("data2vec-audio"),Alr=o(" \u2014 "),ZQ=a("a"),Llr=o("Data2VecAudioForAudioFrameClassification"),ylr=o(" (Data2VecAudio model)"),xlr=l(),R6=a("li"),U1e=a("strong"),$lr=o("unispeech-sat"),klr=o(" \u2014 "),eW=a("a"),Slr=o("UniSpeechSatForAudioFrameClassification"),Rlr=o(" (UniSpeechSat model)"),Plr=l(),P6=a("li"),J1e=a("strong"),Blr=o("wav2vec2"),Ilr=o(" \u2014 "),oW=a("a"),Nlr=o("Wav2Vec2ForAudioFrameClassification"),qlr=o(" (Wav2Vec2 model)"),jlr=l(),B6=a("li"),Y1e=a("strong"),Dlr=o("wav2vec2-conformer"),Glr=o(" \u2014 "),rW=a("a"),Olr=o("Wav2Vec2ConformerForAudioFrameClassification"),Vlr=o(" (Wav2Vec2-Conformer model)"),Xlr=l(),I6=a("li"),K1e=a("strong"),zlr=o("wavlm"),Qlr=o(" \u2014 "),tW=a("a"),Wlr=o("WavLMForAudioFrameClassification"),Hlr=o(" (WavLM model)"),Ulr=l(),N6=a("p"),Jlr=o("The model is set in evaluation mode by default using "),Z1e=a("code"),Ylr=o("model.eval()"),Klr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e2e=a("code"),Zlr=o("model.train()"),eir=l(),F(q6.$$.fragment),$Oe=l(),xd=a("h2"),j6=a("a"),o2e=a("span"),F(L8.$$.fragment),oir=l(),r2e=a("span"),rir=o("AutoModelForCTC"),kOe=l(),Qo=a("div"),F(y8.$$.fragment),tir=l(),$d=a("p"),air=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=a("a"),nir=o("from_pretrained()"),sir=o(" class method or the "),nW=a("a"),lir=o("from_config()"),iir=o(` class
method.`),dir=l(),x8=a("p"),cir=o("This class cannot be instantiated directly using "),t2e=a("code"),fir=o("__init__()"),mir=o(" (throws an error)."),gir=l(),Mt=a("div"),F($8.$$.fragment),hir=l(),a2e=a("p"),pir=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),_ir=l(),kd=a("p"),uir=o(`Note:
Loading a model from its configuration file does `),n2e=a("strong"),bir=o("not"),vir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Fir=o("from_pretrained()"),Tir=o(" to load the model weights."),Mir=l(),F(D6.$$.fragment),Eir=l(),go=a("div"),F(k8.$$.fragment),Cir=l(),s2e=a("p"),wir=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Air=l(),Ua=a("p"),Lir=o("The model class to instantiate is selected based on the "),l2e=a("code"),yir=o("model_type"),xir=o(` property of the config object (either
passed as an argument or loaded from `),i2e=a("code"),$ir=o("pretrained_model_name_or_path"),kir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d2e=a("code"),Sir=o("pretrained_model_name_or_path"),Rir=o(":"),Pir=l(),Le=a("ul"),G6=a("li"),c2e=a("strong"),Bir=o("data2vec-audio"),Iir=o(" \u2014 "),lW=a("a"),Nir=o("Data2VecAudioForCTC"),qir=o(" (Data2VecAudio model)"),jir=l(),O6=a("li"),f2e=a("strong"),Dir=o("hubert"),Gir=o(" \u2014 "),iW=a("a"),Oir=o("HubertForCTC"),Vir=o(" (Hubert model)"),Xir=l(),V6=a("li"),m2e=a("strong"),zir=o("mctct"),Qir=o(" \u2014 "),dW=a("a"),Wir=o("MCTCTForCTC"),Hir=o(" (M-CTC-T model)"),Uir=l(),X6=a("li"),g2e=a("strong"),Jir=o("sew"),Yir=o(" \u2014 "),cW=a("a"),Kir=o("SEWForCTC"),Zir=o(" (SEW model)"),edr=l(),z6=a("li"),h2e=a("strong"),odr=o("sew-d"),rdr=o(" \u2014 "),fW=a("a"),tdr=o("SEWDForCTC"),adr=o(" (SEW-D model)"),ndr=l(),Q6=a("li"),p2e=a("strong"),sdr=o("unispeech"),ldr=o(" \u2014 "),mW=a("a"),idr=o("UniSpeechForCTC"),ddr=o(" (UniSpeech model)"),cdr=l(),W6=a("li"),_2e=a("strong"),fdr=o("unispeech-sat"),mdr=o(" \u2014 "),gW=a("a"),gdr=o("UniSpeechSatForCTC"),hdr=o(" (UniSpeechSat model)"),pdr=l(),H6=a("li"),u2e=a("strong"),_dr=o("wav2vec2"),udr=o(" \u2014 "),hW=a("a"),bdr=o("Wav2Vec2ForCTC"),vdr=o(" (Wav2Vec2 model)"),Fdr=l(),U6=a("li"),b2e=a("strong"),Tdr=o("wav2vec2-conformer"),Mdr=o(" \u2014 "),pW=a("a"),Edr=o("Wav2Vec2ConformerForCTC"),Cdr=o(" (Wav2Vec2-Conformer model)"),wdr=l(),J6=a("li"),v2e=a("strong"),Adr=o("wavlm"),Ldr=o(" \u2014 "),_W=a("a"),ydr=o("WavLMForCTC"),xdr=o(" (WavLM model)"),$dr=l(),Y6=a("p"),kdr=o("The model is set in evaluation mode by default using "),F2e=a("code"),Sdr=o("model.eval()"),Rdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T2e=a("code"),Pdr=o("model.train()"),Bdr=l(),F(K6.$$.fragment),SOe=l(),Sd=a("h2"),Z6=a("a"),M2e=a("span"),F(S8.$$.fragment),Idr=l(),E2e=a("span"),Ndr=o("AutoModelForSpeechSeq2Seq"),ROe=l(),Wo=a("div"),F(R8.$$.fragment),qdr=l(),Rd=a("p"),jdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=a("a"),Ddr=o("from_pretrained()"),Gdr=o(" class method or the "),bW=a("a"),Odr=o("from_config()"),Vdr=o(` class
method.`),Xdr=l(),P8=a("p"),zdr=o("This class cannot be instantiated directly using "),C2e=a("code"),Qdr=o("__init__()"),Wdr=o(" (throws an error)."),Hdr=l(),Et=a("div"),F(B8.$$.fragment),Udr=l(),w2e=a("p"),Jdr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ydr=l(),Pd=a("p"),Kdr=o(`Note:
Loading a model from its configuration file does `),A2e=a("strong"),Zdr=o("not"),ecr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=a("a"),ocr=o("from_pretrained()"),rcr=o(" to load the model weights."),tcr=l(),F(eT.$$.fragment),acr=l(),ho=a("div"),F(I8.$$.fragment),ncr=l(),L2e=a("p"),scr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),lcr=l(),Ja=a("p"),icr=o("The model class to instantiate is selected based on the "),y2e=a("code"),dcr=o("model_type"),ccr=o(` property of the config object (either
passed as an argument or loaded from `),x2e=a("code"),fcr=o("pretrained_model_name_or_path"),mcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$2e=a("code"),gcr=o("pretrained_model_name_or_path"),hcr=o(":"),pcr=l(),N8=a("ul"),oT=a("li"),k2e=a("strong"),_cr=o("speech-encoder-decoder"),ucr=o(" \u2014 "),FW=a("a"),bcr=o("SpeechEncoderDecoderModel"),vcr=o(" (Speech Encoder decoder model)"),Fcr=l(),rT=a("li"),S2e=a("strong"),Tcr=o("speech_to_text"),Mcr=o(" \u2014 "),TW=a("a"),Ecr=o("Speech2TextForConditionalGeneration"),Ccr=o(" (Speech2Text model)"),wcr=l(),tT=a("p"),Acr=o("The model is set in evaluation mode by default using "),R2e=a("code"),Lcr=o("model.eval()"),ycr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=a("code"),xcr=o("model.train()"),$cr=l(),F(aT.$$.fragment),POe=l(),Bd=a("h2"),nT=a("a"),B2e=a("span"),F(q8.$$.fragment),kcr=l(),I2e=a("span"),Scr=o("AutoModelForAudioXVector"),BOe=l(),Ho=a("div"),F(j8.$$.fragment),Rcr=l(),Id=a("p"),Pcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=a("a"),Bcr=o("from_pretrained()"),Icr=o(" class method or the "),EW=a("a"),Ncr=o("from_config()"),qcr=o(` class
method.`),jcr=l(),D8=a("p"),Dcr=o("This class cannot be instantiated directly using "),N2e=a("code"),Gcr=o("__init__()"),Ocr=o(" (throws an error)."),Vcr=l(),Ct=a("div"),F(G8.$$.fragment),Xcr=l(),q2e=a("p"),zcr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Qcr=l(),Nd=a("p"),Wcr=o(`Note:
Loading a model from its configuration file does `),j2e=a("strong"),Hcr=o("not"),Ucr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),Jcr=o("from_pretrained()"),Ycr=o(" to load the model weights."),Kcr=l(),F(sT.$$.fragment),Zcr=l(),po=a("div"),F(O8.$$.fragment),efr=l(),D2e=a("p"),ofr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rfr=l(),Ya=a("p"),tfr=o("The model class to instantiate is selected based on the "),G2e=a("code"),afr=o("model_type"),nfr=o(` property of the config object (either
passed as an argument or loaded from `),O2e=a("code"),sfr=o("pretrained_model_name_or_path"),lfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=a("code"),ifr=o("pretrained_model_name_or_path"),dfr=o(":"),cfr=l(),ot=a("ul"),lT=a("li"),X2e=a("strong"),ffr=o("data2vec-audio"),mfr=o(" \u2014 "),wW=a("a"),gfr=o("Data2VecAudioForXVector"),hfr=o(" (Data2VecAudio model)"),pfr=l(),iT=a("li"),z2e=a("strong"),_fr=o("unispeech-sat"),ufr=o(" \u2014 "),AW=a("a"),bfr=o("UniSpeechSatForXVector"),vfr=o(" (UniSpeechSat model)"),Ffr=l(),dT=a("li"),Q2e=a("strong"),Tfr=o("wav2vec2"),Mfr=o(" \u2014 "),LW=a("a"),Efr=o("Wav2Vec2ForXVector"),Cfr=o(" (Wav2Vec2 model)"),wfr=l(),cT=a("li"),W2e=a("strong"),Afr=o("wav2vec2-conformer"),Lfr=o(" \u2014 "),yW=a("a"),yfr=o("Wav2Vec2ConformerForXVector"),xfr=o(" (Wav2Vec2-Conformer model)"),$fr=l(),fT=a("li"),H2e=a("strong"),kfr=o("wavlm"),Sfr=o(" \u2014 "),xW=a("a"),Rfr=o("WavLMForXVector"),Pfr=o(" (WavLM model)"),Bfr=l(),mT=a("p"),Ifr=o("The model is set in evaluation mode by default using "),U2e=a("code"),Nfr=o("model.eval()"),qfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J2e=a("code"),jfr=o("model.train()"),Dfr=l(),F(gT.$$.fragment),IOe=l(),qd=a("h2"),hT=a("a"),Y2e=a("span"),F(V8.$$.fragment),Gfr=l(),K2e=a("span"),Ofr=o("AutoModelForMaskedImageModeling"),NOe=l(),Uo=a("div"),F(X8.$$.fragment),Vfr=l(),jd=a("p"),Xfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=a("a"),zfr=o("from_pretrained()"),Qfr=o(" class method or the "),kW=a("a"),Wfr=o("from_config()"),Hfr=o(` class
method.`),Ufr=l(),z8=a("p"),Jfr=o("This class cannot be instantiated directly using "),Z2e=a("code"),Yfr=o("__init__()"),Kfr=o(" (throws an error)."),Zfr=l(),wt=a("div"),F(Q8.$$.fragment),emr=l(),ebe=a("p"),omr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rmr=l(),Dd=a("p"),tmr=o(`Note:
Loading a model from its configuration file does `),obe=a("strong"),amr=o("not"),nmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),smr=o("from_pretrained()"),lmr=o(" to load the model weights."),imr=l(),F(pT.$$.fragment),dmr=l(),_o=a("div"),F(W8.$$.fragment),cmr=l(),rbe=a("p"),fmr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),mmr=l(),Ka=a("p"),gmr=o("The model class to instantiate is selected based on the "),tbe=a("code"),hmr=o("model_type"),pmr=o(` property of the config object (either
passed as an argument or loaded from `),abe=a("code"),_mr=o("pretrained_model_name_or_path"),umr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=a("code"),bmr=o("pretrained_model_name_or_path"),vmr=o(":"),Fmr=l(),Gd=a("ul"),_T=a("li"),sbe=a("strong"),Tmr=o("deit"),Mmr=o(" \u2014 "),RW=a("a"),Emr=o("DeiTForMaskedImageModeling"),Cmr=o(" (DeiT model)"),wmr=l(),uT=a("li"),lbe=a("strong"),Amr=o("swin"),Lmr=o(" \u2014 "),PW=a("a"),ymr=o("SwinForMaskedImageModeling"),xmr=o(" (Swin Transformer model)"),$mr=l(),bT=a("li"),ibe=a("strong"),kmr=o("vit"),Smr=o(" \u2014 "),BW=a("a"),Rmr=o("ViTForMaskedImageModeling"),Pmr=o(" (ViT model)"),Bmr=l(),vT=a("p"),Imr=o("The model is set in evaluation mode by default using "),dbe=a("code"),Nmr=o("model.eval()"),qmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cbe=a("code"),jmr=o("model.train()"),Dmr=l(),F(FT.$$.fragment),qOe=l(),Od=a("h2"),TT=a("a"),fbe=a("span"),F(H8.$$.fragment),Gmr=l(),mbe=a("span"),Omr=o("AutoModelForObjectDetection"),jOe=l(),Jo=a("div"),F(U8.$$.fragment),Vmr=l(),Vd=a("p"),Xmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=a("a"),zmr=o("from_pretrained()"),Qmr=o(" class method or the "),NW=a("a"),Wmr=o("from_config()"),Hmr=o(` class
method.`),Umr=l(),J8=a("p"),Jmr=o("This class cannot be instantiated directly using "),gbe=a("code"),Ymr=o("__init__()"),Kmr=o(" (throws an error)."),Zmr=l(),At=a("div"),F(Y8.$$.fragment),egr=l(),hbe=a("p"),ogr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rgr=l(),Xd=a("p"),tgr=o(`Note:
Loading a model from its configuration file does `),pbe=a("strong"),agr=o("not"),ngr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),sgr=o("from_pretrained()"),lgr=o(" to load the model weights."),igr=l(),F(MT.$$.fragment),dgr=l(),uo=a("div"),F(K8.$$.fragment),cgr=l(),_be=a("p"),fgr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),mgr=l(),Za=a("p"),ggr=o("The model class to instantiate is selected based on the "),ube=a("code"),hgr=o("model_type"),pgr=o(` property of the config object (either
passed as an argument or loaded from `),bbe=a("code"),_gr=o("pretrained_model_name_or_path"),ugr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vbe=a("code"),bgr=o("pretrained_model_name_or_path"),vgr=o(":"),Fgr=l(),Z8=a("ul"),ET=a("li"),Fbe=a("strong"),Tgr=o("detr"),Mgr=o(" \u2014 "),jW=a("a"),Egr=o("DetrForObjectDetection"),Cgr=o(" (DETR model)"),wgr=l(),CT=a("li"),Tbe=a("strong"),Agr=o("yolos"),Lgr=o(" \u2014 "),DW=a("a"),ygr=o("YolosForObjectDetection"),xgr=o(" (YOLOS model)"),$gr=l(),wT=a("p"),kgr=o("The model is set in evaluation mode by default using "),Mbe=a("code"),Sgr=o("model.eval()"),Rgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=a("code"),Pgr=o("model.train()"),Bgr=l(),F(AT.$$.fragment),DOe=l(),zd=a("h2"),LT=a("a"),Cbe=a("span"),F(e9.$$.fragment),Igr=l(),wbe=a("span"),Ngr=o("AutoModelForImageSegmentation"),GOe=l(),Yo=a("div"),F(o9.$$.fragment),qgr=l(),Qd=a("p"),jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=a("a"),Dgr=o("from_pretrained()"),Ggr=o(" class method or the "),OW=a("a"),Ogr=o("from_config()"),Vgr=o(` class
method.`),Xgr=l(),r9=a("p"),zgr=o("This class cannot be instantiated directly using "),Abe=a("code"),Qgr=o("__init__()"),Wgr=o(" (throws an error)."),Hgr=l(),Lt=a("div"),F(t9.$$.fragment),Ugr=l(),Lbe=a("p"),Jgr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ygr=l(),Wd=a("p"),Kgr=o(`Note:
Loading a model from its configuration file does `),ybe=a("strong"),Zgr=o("not"),ehr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),ohr=o("from_pretrained()"),rhr=o(" to load the model weights."),thr=l(),F(yT.$$.fragment),ahr=l(),bo=a("div"),F(a9.$$.fragment),nhr=l(),xbe=a("p"),shr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),lhr=l(),en=a("p"),ihr=o("The model class to instantiate is selected based on the "),$be=a("code"),dhr=o("model_type"),chr=o(` property of the config object (either
passed as an argument or loaded from `),kbe=a("code"),fhr=o("pretrained_model_name_or_path"),mhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=a("code"),ghr=o("pretrained_model_name_or_path"),hhr=o(":"),phr=l(),Rbe=a("ul"),xT=a("li"),Pbe=a("strong"),_hr=o("detr"),uhr=o(" \u2014 "),XW=a("a"),bhr=o("DetrForSegmentation"),vhr=o(" (DETR model)"),Fhr=l(),$T=a("p"),Thr=o("The model is set in evaluation mode by default using "),Bbe=a("code"),Mhr=o("model.eval()"),Ehr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=a("code"),Chr=o("model.train()"),whr=l(),F(kT.$$.fragment),OOe=l(),Hd=a("h2"),ST=a("a"),Nbe=a("span"),F(n9.$$.fragment),Ahr=l(),qbe=a("span"),Lhr=o("AutoModelForSemanticSegmentation"),VOe=l(),Ko=a("div"),F(s9.$$.fragment),yhr=l(),Ud=a("p"),xhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=a("a"),$hr=o("from_pretrained()"),khr=o(" class method or the "),QW=a("a"),Shr=o("from_config()"),Rhr=o(` class
method.`),Phr=l(),l9=a("p"),Bhr=o("This class cannot be instantiated directly using "),jbe=a("code"),Ihr=o("__init__()"),Nhr=o(" (throws an error)."),qhr=l(),yt=a("div"),F(i9.$$.fragment),jhr=l(),Dbe=a("p"),Dhr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Ghr=l(),Jd=a("p"),Ohr=o(`Note:
Loading a model from its configuration file does `),Gbe=a("strong"),Vhr=o("not"),Xhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),zhr=o("from_pretrained()"),Qhr=o(" to load the model weights."),Whr=l(),F(RT.$$.fragment),Hhr=l(),vo=a("div"),F(d9.$$.fragment),Uhr=l(),Obe=a("p"),Jhr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Yhr=l(),on=a("p"),Khr=o("The model class to instantiate is selected based on the "),Vbe=a("code"),Zhr=o("model_type"),epr=o(` property of the config object (either
passed as an argument or loaded from `),Xbe=a("code"),opr=o("pretrained_model_name_or_path"),rpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=a("code"),tpr=o("pretrained_model_name_or_path"),apr=o(":"),npr=l(),rn=a("ul"),PT=a("li"),Qbe=a("strong"),spr=o("beit"),lpr=o(" \u2014 "),HW=a("a"),ipr=o("BeitForSemanticSegmentation"),dpr=o(" (BEiT model)"),cpr=l(),BT=a("li"),Wbe=a("strong"),fpr=o("data2vec-vision"),mpr=o(" \u2014 "),UW=a("a"),gpr=o("Data2VecVisionForSemanticSegmentation"),hpr=o(" (Data2VecVision model)"),ppr=l(),IT=a("li"),Hbe=a("strong"),_pr=o("dpt"),upr=o(" \u2014 "),JW=a("a"),bpr=o("DPTForSemanticSegmentation"),vpr=o(" (DPT model)"),Fpr=l(),NT=a("li"),Ube=a("strong"),Tpr=o("segformer"),Mpr=o(" \u2014 "),YW=a("a"),Epr=o("SegformerForSemanticSegmentation"),Cpr=o(" (SegFormer model)"),wpr=l(),qT=a("p"),Apr=o("The model is set in evaluation mode by default using "),Jbe=a("code"),Lpr=o("model.eval()"),ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ybe=a("code"),xpr=o("model.train()"),$pr=l(),F(jT.$$.fragment),XOe=l(),Yd=a("h2"),DT=a("a"),Kbe=a("span"),F(c9.$$.fragment),kpr=l(),Zbe=a("span"),Spr=o("AutoModelForInstanceSegmentation"),zOe=l(),Zo=a("div"),F(f9.$$.fragment),Rpr=l(),Kd=a("p"),Ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=a("a"),Bpr=o("from_pretrained()"),Ipr=o(" class method or the "),ZW=a("a"),Npr=o("from_config()"),qpr=o(` class
method.`),jpr=l(),m9=a("p"),Dpr=o("This class cannot be instantiated directly using "),eve=a("code"),Gpr=o("__init__()"),Opr=o(" (throws an error)."),Vpr=l(),xt=a("div"),F(g9.$$.fragment),Xpr=l(),ove=a("p"),zpr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Qpr=l(),Zd=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),rve=a("strong"),Hpr=o("not"),Upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" to load the model weights."),Kpr=l(),F(GT.$$.fragment),Zpr=l(),Fo=a("div"),F(h9.$$.fragment),e_r=l(),tve=a("p"),o_r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),r_r=l(),tn=a("p"),t_r=o("The model class to instantiate is selected based on the "),ave=a("code"),a_r=o("model_type"),n_r=o(` property of the config object (either
passed as an argument or loaded from `),nve=a("code"),s_r=o("pretrained_model_name_or_path"),l_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sve=a("code"),i_r=o("pretrained_model_name_or_path"),d_r=o(":"),c_r=l(),lve=a("ul"),OT=a("li"),ive=a("strong"),f_r=o("maskformer"),m_r=o(" \u2014 "),oH=a("a"),g_r=o("MaskFormerForInstanceSegmentation"),h_r=o(" (MaskFormer model)"),p_r=l(),VT=a("p"),__r=o("The model is set in evaluation mode by default using "),dve=a("code"),u_r=o("model.eval()"),b_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cve=a("code"),v_r=o("model.train()"),F_r=l(),F(XT.$$.fragment),QOe=l(),ec=a("h2"),zT=a("a"),fve=a("span"),F(p9.$$.fragment),T_r=l(),mve=a("span"),M_r=o("TFAutoModel"),WOe=l(),er=a("div"),F(_9.$$.fragment),E_r=l(),oc=a("p"),C_r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=a("a"),w_r=o("from_pretrained()"),A_r=o(" class method or the "),tH=a("a"),L_r=o("from_config()"),y_r=o(` class
method.`),x_r=l(),u9=a("p"),$_r=o("This class cannot be instantiated directly using "),gve=a("code"),k_r=o("__init__()"),S_r=o(" (throws an error)."),R_r=l(),$t=a("div"),F(b9.$$.fragment),P_r=l(),hve=a("p"),B_r=o("Instantiates one of the base model classes of the library from a configuration."),I_r=l(),rc=a("p"),N_r=o(`Note:
Loading a model from its configuration file does `),pve=a("strong"),q_r=o("not"),j_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),D_r=o("from_pretrained()"),G_r=o(" to load the model weights."),O_r=l(),F(QT.$$.fragment),V_r=l(),yr=a("div"),F(v9.$$.fragment),X_r=l(),_ve=a("p"),z_r=o("Instantiate one of the base model classes of the library from a pretrained model."),Q_r=l(),an=a("p"),W_r=o("The model class to instantiate is selected based on the "),uve=a("code"),H_r=o("model_type"),U_r=o(` property of the config object (either
passed as an argument or loaded from `),bve=a("code"),J_r=o("pretrained_model_name_or_path"),Y_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vve=a("code"),K_r=o("pretrained_model_name_or_path"),Z_r=o(":"),eur=l(),j=a("ul"),WT=a("li"),Fve=a("strong"),our=o("albert"),rur=o(" \u2014 "),nH=a("a"),tur=o("TFAlbertModel"),aur=o(" (ALBERT model)"),nur=l(),HT=a("li"),Tve=a("strong"),sur=o("bart"),lur=o(" \u2014 "),sH=a("a"),iur=o("TFBartModel"),dur=o(" (BART model)"),cur=l(),UT=a("li"),Mve=a("strong"),fur=o("bert"),mur=o(" \u2014 "),lH=a("a"),gur=o("TFBertModel"),hur=o(" (BERT model)"),pur=l(),JT=a("li"),Eve=a("strong"),_ur=o("blenderbot"),uur=o(" \u2014 "),iH=a("a"),bur=o("TFBlenderbotModel"),vur=o(" (Blenderbot model)"),Fur=l(),YT=a("li"),Cve=a("strong"),Tur=o("blenderbot-small"),Mur=o(" \u2014 "),dH=a("a"),Eur=o("TFBlenderbotSmallModel"),Cur=o(" (BlenderbotSmall model)"),wur=l(),KT=a("li"),wve=a("strong"),Aur=o("camembert"),Lur=o(" \u2014 "),cH=a("a"),yur=o("TFCamembertModel"),xur=o(" (CamemBERT model)"),$ur=l(),ZT=a("li"),Ave=a("strong"),kur=o("clip"),Sur=o(" \u2014 "),fH=a("a"),Rur=o("TFCLIPModel"),Pur=o(" (CLIP model)"),Bur=l(),eM=a("li"),Lve=a("strong"),Iur=o("convbert"),Nur=o(" \u2014 "),mH=a("a"),qur=o("TFConvBertModel"),jur=o(" (ConvBERT model)"),Dur=l(),oM=a("li"),yve=a("strong"),Gur=o("convnext"),Our=o(" \u2014 "),gH=a("a"),Vur=o("TFConvNextModel"),Xur=o(" (ConvNeXT model)"),zur=l(),rM=a("li"),xve=a("strong"),Qur=o("ctrl"),Wur=o(" \u2014 "),hH=a("a"),Hur=o("TFCTRLModel"),Uur=o(" (CTRL model)"),Jur=l(),tM=a("li"),$ve=a("strong"),Yur=o("data2vec-vision"),Kur=o(" \u2014 "),pH=a("a"),Zur=o("TFData2VecVisionModel"),e7r=o(" (Data2VecVision model)"),o7r=l(),aM=a("li"),kve=a("strong"),r7r=o("deberta"),t7r=o(" \u2014 "),_H=a("a"),a7r=o("TFDebertaModel"),n7r=o(" (DeBERTa model)"),s7r=l(),nM=a("li"),Sve=a("strong"),l7r=o("deberta-v2"),i7r=o(" \u2014 "),uH=a("a"),d7r=o("TFDebertaV2Model"),c7r=o(" (DeBERTa-v2 model)"),f7r=l(),sM=a("li"),Rve=a("strong"),m7r=o("distilbert"),g7r=o(" \u2014 "),bH=a("a"),h7r=o("TFDistilBertModel"),p7r=o(" (DistilBERT model)"),_7r=l(),lM=a("li"),Pve=a("strong"),u7r=o("dpr"),b7r=o(" \u2014 "),vH=a("a"),v7r=o("TFDPRQuestionEncoder"),F7r=o(" (DPR model)"),T7r=l(),iM=a("li"),Bve=a("strong"),M7r=o("electra"),E7r=o(" \u2014 "),FH=a("a"),C7r=o("TFElectraModel"),w7r=o(" (ELECTRA model)"),A7r=l(),dM=a("li"),Ive=a("strong"),L7r=o("flaubert"),y7r=o(" \u2014 "),TH=a("a"),x7r=o("TFFlaubertModel"),$7r=o(" (FlauBERT model)"),k7r=l(),Qs=a("li"),Nve=a("strong"),S7r=o("funnel"),R7r=o(" \u2014 "),MH=a("a"),P7r=o("TFFunnelModel"),B7r=o(" or "),EH=a("a"),I7r=o("TFFunnelBaseModel"),N7r=o(" (Funnel Transformer model)"),q7r=l(),cM=a("li"),qve=a("strong"),j7r=o("gpt2"),D7r=o(" \u2014 "),CH=a("a"),G7r=o("TFGPT2Model"),O7r=o(" (OpenAI GPT-2 model)"),V7r=l(),fM=a("li"),jve=a("strong"),X7r=o("gptj"),z7r=o(" \u2014 "),wH=a("a"),Q7r=o("TFGPTJModel"),W7r=o(" (GPT-J model)"),H7r=l(),mM=a("li"),Dve=a("strong"),U7r=o("hubert"),J7r=o(" \u2014 "),AH=a("a"),Y7r=o("TFHubertModel"),K7r=o(" (Hubert model)"),Z7r=l(),gM=a("li"),Gve=a("strong"),e1r=o("layoutlm"),o1r=o(" \u2014 "),LH=a("a"),r1r=o("TFLayoutLMModel"),t1r=o(" (LayoutLM model)"),a1r=l(),hM=a("li"),Ove=a("strong"),n1r=o("led"),s1r=o(" \u2014 "),yH=a("a"),l1r=o("TFLEDModel"),i1r=o(" (LED model)"),d1r=l(),pM=a("li"),Vve=a("strong"),c1r=o("longformer"),f1r=o(" \u2014 "),xH=a("a"),m1r=o("TFLongformerModel"),g1r=o(" (Longformer model)"),h1r=l(),_M=a("li"),Xve=a("strong"),p1r=o("lxmert"),_1r=o(" \u2014 "),$H=a("a"),u1r=o("TFLxmertModel"),b1r=o(" (LXMERT model)"),v1r=l(),uM=a("li"),zve=a("strong"),F1r=o("marian"),T1r=o(" \u2014 "),kH=a("a"),M1r=o("TFMarianModel"),E1r=o(" (Marian model)"),C1r=l(),bM=a("li"),Qve=a("strong"),w1r=o("mbart"),A1r=o(" \u2014 "),SH=a("a"),L1r=o("TFMBartModel"),y1r=o(" (mBART model)"),x1r=l(),vM=a("li"),Wve=a("strong"),$1r=o("mobilebert"),k1r=o(" \u2014 "),RH=a("a"),S1r=o("TFMobileBertModel"),R1r=o(" (MobileBERT model)"),P1r=l(),FM=a("li"),Hve=a("strong"),B1r=o("mpnet"),I1r=o(" \u2014 "),PH=a("a"),N1r=o("TFMPNetModel"),q1r=o(" (MPNet model)"),j1r=l(),TM=a("li"),Uve=a("strong"),D1r=o("mt5"),G1r=o(" \u2014 "),BH=a("a"),O1r=o("TFMT5Model"),V1r=o(" (MT5 model)"),X1r=l(),MM=a("li"),Jve=a("strong"),z1r=o("openai-gpt"),Q1r=o(" \u2014 "),IH=a("a"),W1r=o("TFOpenAIGPTModel"),H1r=o(" (OpenAI GPT model)"),U1r=l(),EM=a("li"),Yve=a("strong"),J1r=o("opt"),Y1r=o(" \u2014 "),NH=a("a"),K1r=o("TFOPTModel"),Z1r=o(" (OPT model)"),e2r=l(),CM=a("li"),Kve=a("strong"),o2r=o("pegasus"),r2r=o(" \u2014 "),qH=a("a"),t2r=o("TFPegasusModel"),a2r=o(" (Pegasus model)"),n2r=l(),wM=a("li"),Zve=a("strong"),s2r=o("rembert"),l2r=o(" \u2014 "),jH=a("a"),i2r=o("TFRemBertModel"),d2r=o(" (RemBERT model)"),c2r=l(),AM=a("li"),eFe=a("strong"),f2r=o("roberta"),m2r=o(" \u2014 "),DH=a("a"),g2r=o("TFRobertaModel"),h2r=o(" (RoBERTa model)"),p2r=l(),LM=a("li"),oFe=a("strong"),_2r=o("roformer"),u2r=o(" \u2014 "),GH=a("a"),b2r=o("TFRoFormerModel"),v2r=o(" (RoFormer model)"),F2r=l(),yM=a("li"),rFe=a("strong"),T2r=o("speech_to_text"),M2r=o(" \u2014 "),OH=a("a"),E2r=o("TFSpeech2TextModel"),C2r=o(" (Speech2Text model)"),w2r=l(),xM=a("li"),tFe=a("strong"),A2r=o("swin"),L2r=o(" \u2014 "),VH=a("a"),y2r=o("TFSwinModel"),x2r=o(" (Swin Transformer model)"),$2r=l(),$M=a("li"),aFe=a("strong"),k2r=o("t5"),S2r=o(" \u2014 "),XH=a("a"),R2r=o("TFT5Model"),P2r=o(" (T5 model)"),B2r=l(),kM=a("li"),nFe=a("strong"),I2r=o("tapas"),N2r=o(" \u2014 "),zH=a("a"),q2r=o("TFTapasModel"),j2r=o(" (TAPAS model)"),D2r=l(),SM=a("li"),sFe=a("strong"),G2r=o("transfo-xl"),O2r=o(" \u2014 "),QH=a("a"),V2r=o("TFTransfoXLModel"),X2r=o(" (Transformer-XL model)"),z2r=l(),RM=a("li"),lFe=a("strong"),Q2r=o("vit"),W2r=o(" \u2014 "),WH=a("a"),H2r=o("TFViTModel"),U2r=o(" (ViT model)"),J2r=l(),PM=a("li"),iFe=a("strong"),Y2r=o("vit_mae"),K2r=o(" \u2014 "),HH=a("a"),Z2r=o("TFViTMAEModel"),ebr=o(" (ViTMAE model)"),obr=l(),BM=a("li"),dFe=a("strong"),rbr=o("wav2vec2"),tbr=o(" \u2014 "),UH=a("a"),abr=o("TFWav2Vec2Model"),nbr=o(" (Wav2Vec2 model)"),sbr=l(),IM=a("li"),cFe=a("strong"),lbr=o("xlm"),ibr=o(" \u2014 "),JH=a("a"),dbr=o("TFXLMModel"),cbr=o(" (XLM model)"),fbr=l(),NM=a("li"),fFe=a("strong"),mbr=o("xlm-roberta"),gbr=o(" \u2014 "),YH=a("a"),hbr=o("TFXLMRobertaModel"),pbr=o(" (XLM-RoBERTa model)"),_br=l(),qM=a("li"),mFe=a("strong"),ubr=o("xlnet"),bbr=o(" \u2014 "),KH=a("a"),vbr=o("TFXLNetModel"),Fbr=o(" (XLNet model)"),Tbr=l(),F(jM.$$.fragment),HOe=l(),tc=a("h2"),DM=a("a"),gFe=a("span"),F(F9.$$.fragment),Mbr=l(),hFe=a("span"),Ebr=o("TFAutoModelForPreTraining"),UOe=l(),or=a("div"),F(T9.$$.fragment),Cbr=l(),ac=a("p"),wbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=a("a"),Abr=o("from_pretrained()"),Lbr=o(" class method or the "),eU=a("a"),ybr=o("from_config()"),xbr=o(` class
method.`),$br=l(),M9=a("p"),kbr=o("This class cannot be instantiated directly using "),pFe=a("code"),Sbr=o("__init__()"),Rbr=o(" (throws an error)."),Pbr=l(),kt=a("div"),F(E9.$$.fragment),Bbr=l(),_Fe=a("p"),Ibr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Nbr=l(),nc=a("p"),qbr=o(`Note:
Loading a model from its configuration file does `),uFe=a("strong"),jbr=o("not"),Dbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=a("a"),Gbr=o("from_pretrained()"),Obr=o(" to load the model weights."),Vbr=l(),F(GM.$$.fragment),Xbr=l(),xr=a("div"),F(C9.$$.fragment),zbr=l(),bFe=a("p"),Qbr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Wbr=l(),nn=a("p"),Hbr=o("The model class to instantiate is selected based on the "),vFe=a("code"),Ubr=o("model_type"),Jbr=o(` property of the config object (either
passed as an argument or loaded from `),FFe=a("code"),Ybr=o("pretrained_model_name_or_path"),Kbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=a("code"),Zbr=o("pretrained_model_name_or_path"),evr=o(":"),ovr=l(),se=a("ul"),OM=a("li"),MFe=a("strong"),rvr=o("albert"),tvr=o(" \u2014 "),rU=a("a"),avr=o("TFAlbertForPreTraining"),nvr=o(" (ALBERT model)"),svr=l(),VM=a("li"),EFe=a("strong"),lvr=o("bart"),ivr=o(" \u2014 "),tU=a("a"),dvr=o("TFBartForConditionalGeneration"),cvr=o(" (BART model)"),fvr=l(),XM=a("li"),CFe=a("strong"),mvr=o("bert"),gvr=o(" \u2014 "),aU=a("a"),hvr=o("TFBertForPreTraining"),pvr=o(" (BERT model)"),_vr=l(),zM=a("li"),wFe=a("strong"),uvr=o("camembert"),bvr=o(" \u2014 "),nU=a("a"),vvr=o("TFCamembertForMaskedLM"),Fvr=o(" (CamemBERT model)"),Tvr=l(),QM=a("li"),AFe=a("strong"),Mvr=o("ctrl"),Evr=o(" \u2014 "),sU=a("a"),Cvr=o("TFCTRLLMHeadModel"),wvr=o(" (CTRL model)"),Avr=l(),WM=a("li"),LFe=a("strong"),Lvr=o("distilbert"),yvr=o(" \u2014 "),lU=a("a"),xvr=o("TFDistilBertForMaskedLM"),$vr=o(" (DistilBERT model)"),kvr=l(),HM=a("li"),yFe=a("strong"),Svr=o("electra"),Rvr=o(" \u2014 "),iU=a("a"),Pvr=o("TFElectraForPreTraining"),Bvr=o(" (ELECTRA model)"),Ivr=l(),UM=a("li"),xFe=a("strong"),Nvr=o("flaubert"),qvr=o(" \u2014 "),dU=a("a"),jvr=o("TFFlaubertWithLMHeadModel"),Dvr=o(" (FlauBERT model)"),Gvr=l(),JM=a("li"),$Fe=a("strong"),Ovr=o("funnel"),Vvr=o(" \u2014 "),cU=a("a"),Xvr=o("TFFunnelForPreTraining"),zvr=o(" (Funnel Transformer model)"),Qvr=l(),YM=a("li"),kFe=a("strong"),Wvr=o("gpt2"),Hvr=o(" \u2014 "),fU=a("a"),Uvr=o("TFGPT2LMHeadModel"),Jvr=o(" (OpenAI GPT-2 model)"),Yvr=l(),KM=a("li"),SFe=a("strong"),Kvr=o("layoutlm"),Zvr=o(" \u2014 "),mU=a("a"),eFr=o("TFLayoutLMForMaskedLM"),oFr=o(" (LayoutLM model)"),rFr=l(),ZM=a("li"),RFe=a("strong"),tFr=o("lxmert"),aFr=o(" \u2014 "),gU=a("a"),nFr=o("TFLxmertForPreTraining"),sFr=o(" (LXMERT model)"),lFr=l(),eE=a("li"),PFe=a("strong"),iFr=o("mobilebert"),dFr=o(" \u2014 "),hU=a("a"),cFr=o("TFMobileBertForPreTraining"),fFr=o(" (MobileBERT model)"),mFr=l(),oE=a("li"),BFe=a("strong"),gFr=o("mpnet"),hFr=o(" \u2014 "),pU=a("a"),pFr=o("TFMPNetForMaskedLM"),_Fr=o(" (MPNet model)"),uFr=l(),rE=a("li"),IFe=a("strong"),bFr=o("openai-gpt"),vFr=o(" \u2014 "),_U=a("a"),FFr=o("TFOpenAIGPTLMHeadModel"),TFr=o(" (OpenAI GPT model)"),MFr=l(),tE=a("li"),NFe=a("strong"),EFr=o("roberta"),CFr=o(" \u2014 "),uU=a("a"),wFr=o("TFRobertaForMaskedLM"),AFr=o(" (RoBERTa model)"),LFr=l(),aE=a("li"),qFe=a("strong"),yFr=o("t5"),xFr=o(" \u2014 "),bU=a("a"),$Fr=o("TFT5ForConditionalGeneration"),kFr=o(" (T5 model)"),SFr=l(),nE=a("li"),jFe=a("strong"),RFr=o("tapas"),PFr=o(" \u2014 "),vU=a("a"),BFr=o("TFTapasForMaskedLM"),IFr=o(" (TAPAS model)"),NFr=l(),sE=a("li"),DFe=a("strong"),qFr=o("transfo-xl"),jFr=o(" \u2014 "),FU=a("a"),DFr=o("TFTransfoXLLMHeadModel"),GFr=o(" (Transformer-XL model)"),OFr=l(),lE=a("li"),GFe=a("strong"),VFr=o("vit_mae"),XFr=o(" \u2014 "),TU=a("a"),zFr=o("TFViTMAEForPreTraining"),QFr=o(" (ViTMAE model)"),WFr=l(),iE=a("li"),OFe=a("strong"),HFr=o("xlm"),UFr=o(" \u2014 "),MU=a("a"),JFr=o("TFXLMWithLMHeadModel"),YFr=o(" (XLM model)"),KFr=l(),dE=a("li"),VFe=a("strong"),ZFr=o("xlm-roberta"),e6r=o(" \u2014 "),EU=a("a"),o6r=o("TFXLMRobertaForMaskedLM"),r6r=o(" (XLM-RoBERTa model)"),t6r=l(),cE=a("li"),XFe=a("strong"),a6r=o("xlnet"),n6r=o(" \u2014 "),CU=a("a"),s6r=o("TFXLNetLMHeadModel"),l6r=o(" (XLNet model)"),i6r=l(),F(fE.$$.fragment),JOe=l(),sc=a("h2"),mE=a("a"),zFe=a("span"),F(w9.$$.fragment),d6r=l(),QFe=a("span"),c6r=o("TFAutoModelForCausalLM"),YOe=l(),rr=a("div"),F(A9.$$.fragment),f6r=l(),lc=a("p"),m6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=a("a"),g6r=o("from_pretrained()"),h6r=o(" class method or the "),AU=a("a"),p6r=o("from_config()"),_6r=o(` class
method.`),u6r=l(),L9=a("p"),b6r=o("This class cannot be instantiated directly using "),WFe=a("code"),v6r=o("__init__()"),F6r=o(" (throws an error)."),T6r=l(),St=a("div"),F(y9.$$.fragment),M6r=l(),HFe=a("p"),E6r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),C6r=l(),ic=a("p"),w6r=o(`Note:
Loading a model from its configuration file does `),UFe=a("strong"),A6r=o("not"),L6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),y6r=o("from_pretrained()"),x6r=o(" to load the model weights."),$6r=l(),F(gE.$$.fragment),k6r=l(),$r=a("div"),F(x9.$$.fragment),S6r=l(),JFe=a("p"),R6r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),P6r=l(),sn=a("p"),B6r=o("The model class to instantiate is selected based on the "),YFe=a("code"),I6r=o("model_type"),N6r=o(` property of the config object (either
passed as an argument or loaded from `),KFe=a("code"),q6r=o("pretrained_model_name_or_path"),j6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=a("code"),D6r=o("pretrained_model_name_or_path"),G6r=o(":"),O6r=l(),Me=a("ul"),hE=a("li"),e6e=a("strong"),V6r=o("bert"),X6r=o(" \u2014 "),yU=a("a"),z6r=o("TFBertLMHeadModel"),Q6r=o(" (BERT model)"),W6r=l(),pE=a("li"),o6e=a("strong"),H6r=o("camembert"),U6r=o(" \u2014 "),xU=a("a"),J6r=o("TFCamembertForCausalLM"),Y6r=o(" (CamemBERT model)"),K6r=l(),_E=a("li"),r6e=a("strong"),Z6r=o("ctrl"),eTr=o(" \u2014 "),$U=a("a"),oTr=o("TFCTRLLMHeadModel"),rTr=o(" (CTRL model)"),tTr=l(),uE=a("li"),t6e=a("strong"),aTr=o("gpt2"),nTr=o(" \u2014 "),kU=a("a"),sTr=o("TFGPT2LMHeadModel"),lTr=o(" (OpenAI GPT-2 model)"),iTr=l(),bE=a("li"),a6e=a("strong"),dTr=o("gptj"),cTr=o(" \u2014 "),SU=a("a"),fTr=o("TFGPTJForCausalLM"),mTr=o(" (GPT-J model)"),gTr=l(),vE=a("li"),n6e=a("strong"),hTr=o("openai-gpt"),pTr=o(" \u2014 "),RU=a("a"),_Tr=o("TFOpenAIGPTLMHeadModel"),uTr=o(" (OpenAI GPT model)"),bTr=l(),FE=a("li"),s6e=a("strong"),vTr=o("opt"),FTr=o(" \u2014 "),PU=a("a"),TTr=o("TFOPTForCausalLM"),MTr=o(" (OPT model)"),ETr=l(),TE=a("li"),l6e=a("strong"),CTr=o("rembert"),wTr=o(" \u2014 "),BU=a("a"),ATr=o("TFRemBertForCausalLM"),LTr=o(" (RemBERT model)"),yTr=l(),ME=a("li"),i6e=a("strong"),xTr=o("roberta"),$Tr=o(" \u2014 "),IU=a("a"),kTr=o("TFRobertaForCausalLM"),STr=o(" (RoBERTa model)"),RTr=l(),EE=a("li"),d6e=a("strong"),PTr=o("roformer"),BTr=o(" \u2014 "),NU=a("a"),ITr=o("TFRoFormerForCausalLM"),NTr=o(" (RoFormer model)"),qTr=l(),CE=a("li"),c6e=a("strong"),jTr=o("transfo-xl"),DTr=o(" \u2014 "),qU=a("a"),GTr=o("TFTransfoXLLMHeadModel"),OTr=o(" (Transformer-XL model)"),VTr=l(),wE=a("li"),f6e=a("strong"),XTr=o("xlm"),zTr=o(" \u2014 "),jU=a("a"),QTr=o("TFXLMWithLMHeadModel"),WTr=o(" (XLM model)"),HTr=l(),AE=a("li"),m6e=a("strong"),UTr=o("xlnet"),JTr=o(" \u2014 "),DU=a("a"),YTr=o("TFXLNetLMHeadModel"),KTr=o(" (XLNet model)"),ZTr=l(),F(LE.$$.fragment),KOe=l(),dc=a("h2"),yE=a("a"),g6e=a("span"),F($9.$$.fragment),eMr=l(),h6e=a("span"),oMr=o("TFAutoModelForImageClassification"),ZOe=l(),tr=a("div"),F(k9.$$.fragment),rMr=l(),cc=a("p"),tMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=a("a"),aMr=o("from_pretrained()"),nMr=o(" class method or the "),OU=a("a"),sMr=o("from_config()"),lMr=o(` class
method.`),iMr=l(),S9=a("p"),dMr=o("This class cannot be instantiated directly using "),p6e=a("code"),cMr=o("__init__()"),fMr=o(" (throws an error)."),mMr=l(),Rt=a("div"),F(R9.$$.fragment),gMr=l(),_6e=a("p"),hMr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),pMr=l(),fc=a("p"),_Mr=o(`Note:
Loading a model from its configuration file does `),u6e=a("strong"),uMr=o("not"),bMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),vMr=o("from_pretrained()"),FMr=o(" to load the model weights."),TMr=l(),F(xE.$$.fragment),MMr=l(),kr=a("div"),F(P9.$$.fragment),EMr=l(),b6e=a("p"),CMr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),wMr=l(),ln=a("p"),AMr=o("The model class to instantiate is selected based on the "),v6e=a("code"),LMr=o("model_type"),yMr=o(` property of the config object (either
passed as an argument or loaded from `),F6e=a("code"),xMr=o("pretrained_model_name_or_path"),$Mr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=a("code"),kMr=o("pretrained_model_name_or_path"),SMr=o(":"),RMr=l(),dn=a("ul"),$E=a("li"),M6e=a("strong"),PMr=o("convnext"),BMr=o(" \u2014 "),XU=a("a"),IMr=o("TFConvNextForImageClassification"),NMr=o(" (ConvNeXT model)"),qMr=l(),kE=a("li"),E6e=a("strong"),jMr=o("data2vec-vision"),DMr=o(" \u2014 "),zU=a("a"),GMr=o("TFData2VecVisionForImageClassification"),OMr=o(" (Data2VecVision model)"),VMr=l(),SE=a("li"),C6e=a("strong"),XMr=o("swin"),zMr=o(" \u2014 "),QU=a("a"),QMr=o("TFSwinForImageClassification"),WMr=o(" (Swin Transformer model)"),HMr=l(),RE=a("li"),w6e=a("strong"),UMr=o("vit"),JMr=o(" \u2014 "),WU=a("a"),YMr=o("TFViTForImageClassification"),KMr=o(" (ViT model)"),ZMr=l(),F(PE.$$.fragment),eVe=l(),mc=a("h2"),BE=a("a"),A6e=a("span"),F(B9.$$.fragment),eEr=l(),L6e=a("span"),oEr=o("TFAutoModelForMaskedLM"),oVe=l(),ar=a("div"),F(I9.$$.fragment),rEr=l(),gc=a("p"),tEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=a("a"),aEr=o("from_pretrained()"),nEr=o(" class method or the "),UU=a("a"),sEr=o("from_config()"),lEr=o(` class
method.`),iEr=l(),N9=a("p"),dEr=o("This class cannot be instantiated directly using "),y6e=a("code"),cEr=o("__init__()"),fEr=o(" (throws an error)."),mEr=l(),Pt=a("div"),F(q9.$$.fragment),gEr=l(),x6e=a("p"),hEr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),pEr=l(),hc=a("p"),_Er=o(`Note:
Loading a model from its configuration file does `),$6e=a("strong"),uEr=o("not"),bEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=a("a"),vEr=o("from_pretrained()"),FEr=o(" to load the model weights."),TEr=l(),F(IE.$$.fragment),MEr=l(),Sr=a("div"),F(j9.$$.fragment),EEr=l(),k6e=a("p"),CEr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wEr=l(),cn=a("p"),AEr=o("The model class to instantiate is selected based on the "),S6e=a("code"),LEr=o("model_type"),yEr=o(` property of the config object (either
passed as an argument or loaded from `),R6e=a("code"),xEr=o("pretrained_model_name_or_path"),$Er=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=a("code"),kEr=o("pretrained_model_name_or_path"),SEr=o(":"),REr=l(),ie=a("ul"),NE=a("li"),B6e=a("strong"),PEr=o("albert"),BEr=o(" \u2014 "),YU=a("a"),IEr=o("TFAlbertForMaskedLM"),NEr=o(" (ALBERT model)"),qEr=l(),qE=a("li"),I6e=a("strong"),jEr=o("bert"),DEr=o(" \u2014 "),KU=a("a"),GEr=o("TFBertForMaskedLM"),OEr=o(" (BERT model)"),VEr=l(),jE=a("li"),N6e=a("strong"),XEr=o("camembert"),zEr=o(" \u2014 "),ZU=a("a"),QEr=o("TFCamembertForMaskedLM"),WEr=o(" (CamemBERT model)"),HEr=l(),DE=a("li"),q6e=a("strong"),UEr=o("convbert"),JEr=o(" \u2014 "),eJ=a("a"),YEr=o("TFConvBertForMaskedLM"),KEr=o(" (ConvBERT model)"),ZEr=l(),GE=a("li"),j6e=a("strong"),e4r=o("deberta"),o4r=o(" \u2014 "),oJ=a("a"),r4r=o("TFDebertaForMaskedLM"),t4r=o(" (DeBERTa model)"),a4r=l(),OE=a("li"),D6e=a("strong"),n4r=o("deberta-v2"),s4r=o(" \u2014 "),rJ=a("a"),l4r=o("TFDebertaV2ForMaskedLM"),i4r=o(" (DeBERTa-v2 model)"),d4r=l(),VE=a("li"),G6e=a("strong"),c4r=o("distilbert"),f4r=o(" \u2014 "),tJ=a("a"),m4r=o("TFDistilBertForMaskedLM"),g4r=o(" (DistilBERT model)"),h4r=l(),XE=a("li"),O6e=a("strong"),p4r=o("electra"),_4r=o(" \u2014 "),aJ=a("a"),u4r=o("TFElectraForMaskedLM"),b4r=o(" (ELECTRA model)"),v4r=l(),zE=a("li"),V6e=a("strong"),F4r=o("flaubert"),T4r=o(" \u2014 "),nJ=a("a"),M4r=o("TFFlaubertWithLMHeadModel"),E4r=o(" (FlauBERT model)"),C4r=l(),QE=a("li"),X6e=a("strong"),w4r=o("funnel"),A4r=o(" \u2014 "),sJ=a("a"),L4r=o("TFFunnelForMaskedLM"),y4r=o(" (Funnel Transformer model)"),x4r=l(),WE=a("li"),z6e=a("strong"),$4r=o("layoutlm"),k4r=o(" \u2014 "),lJ=a("a"),S4r=o("TFLayoutLMForMaskedLM"),R4r=o(" (LayoutLM model)"),P4r=l(),HE=a("li"),Q6e=a("strong"),B4r=o("longformer"),I4r=o(" \u2014 "),iJ=a("a"),N4r=o("TFLongformerForMaskedLM"),q4r=o(" (Longformer model)"),j4r=l(),UE=a("li"),W6e=a("strong"),D4r=o("mobilebert"),G4r=o(" \u2014 "),dJ=a("a"),O4r=o("TFMobileBertForMaskedLM"),V4r=o(" (MobileBERT model)"),X4r=l(),JE=a("li"),H6e=a("strong"),z4r=o("mpnet"),Q4r=o(" \u2014 "),cJ=a("a"),W4r=o("TFMPNetForMaskedLM"),H4r=o(" (MPNet model)"),U4r=l(),YE=a("li"),U6e=a("strong"),J4r=o("rembert"),Y4r=o(" \u2014 "),fJ=a("a"),K4r=o("TFRemBertForMaskedLM"),Z4r=o(" (RemBERT model)"),eCr=l(),KE=a("li"),J6e=a("strong"),oCr=o("roberta"),rCr=o(" \u2014 "),mJ=a("a"),tCr=o("TFRobertaForMaskedLM"),aCr=o(" (RoBERTa model)"),nCr=l(),ZE=a("li"),Y6e=a("strong"),sCr=o("roformer"),lCr=o(" \u2014 "),gJ=a("a"),iCr=o("TFRoFormerForMaskedLM"),dCr=o(" (RoFormer model)"),cCr=l(),e4=a("li"),K6e=a("strong"),fCr=o("tapas"),mCr=o(" \u2014 "),hJ=a("a"),gCr=o("TFTapasForMaskedLM"),hCr=o(" (TAPAS model)"),pCr=l(),o4=a("li"),Z6e=a("strong"),_Cr=o("xlm"),uCr=o(" \u2014 "),pJ=a("a"),bCr=o("TFXLMWithLMHeadModel"),vCr=o(" (XLM model)"),FCr=l(),r4=a("li"),eTe=a("strong"),TCr=o("xlm-roberta"),MCr=o(" \u2014 "),_J=a("a"),ECr=o("TFXLMRobertaForMaskedLM"),CCr=o(" (XLM-RoBERTa model)"),wCr=l(),F(t4.$$.fragment),rVe=l(),pc=a("h2"),a4=a("a"),oTe=a("span"),F(D9.$$.fragment),ACr=l(),rTe=a("span"),LCr=o("TFAutoModelForSeq2SeqLM"),tVe=l(),nr=a("div"),F(G9.$$.fragment),yCr=l(),_c=a("p"),xCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=a("a"),$Cr=o("from_pretrained()"),kCr=o(" class method or the "),bJ=a("a"),SCr=o("from_config()"),RCr=o(` class
method.`),PCr=l(),O9=a("p"),BCr=o("This class cannot be instantiated directly using "),tTe=a("code"),ICr=o("__init__()"),NCr=o(" (throws an error)."),qCr=l(),Bt=a("div"),F(V9.$$.fragment),jCr=l(),aTe=a("p"),DCr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),GCr=l(),uc=a("p"),OCr=o(`Note:
Loading a model from its configuration file does `),nTe=a("strong"),VCr=o("not"),XCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),zCr=o("from_pretrained()"),QCr=o(" to load the model weights."),WCr=l(),F(n4.$$.fragment),HCr=l(),Rr=a("div"),F(X9.$$.fragment),UCr=l(),sTe=a("p"),JCr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),YCr=l(),fn=a("p"),KCr=o("The model class to instantiate is selected based on the "),lTe=a("code"),ZCr=o("model_type"),e5r=o(` property of the config object (either
passed as an argument or loaded from `),iTe=a("code"),o5r=o("pretrained_model_name_or_path"),r5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=a("code"),t5r=o("pretrained_model_name_or_path"),a5r=o(":"),n5r=l(),ye=a("ul"),s4=a("li"),cTe=a("strong"),s5r=o("bart"),l5r=o(" \u2014 "),FJ=a("a"),i5r=o("TFBartForConditionalGeneration"),d5r=o(" (BART model)"),c5r=l(),l4=a("li"),fTe=a("strong"),f5r=o("blenderbot"),m5r=o(" \u2014 "),TJ=a("a"),g5r=o("TFBlenderbotForConditionalGeneration"),h5r=o(" (Blenderbot model)"),p5r=l(),i4=a("li"),mTe=a("strong"),_5r=o("blenderbot-small"),u5r=o(" \u2014 "),MJ=a("a"),b5r=o("TFBlenderbotSmallForConditionalGeneration"),v5r=o(" (BlenderbotSmall model)"),F5r=l(),d4=a("li"),gTe=a("strong"),T5r=o("encoder-decoder"),M5r=o(" \u2014 "),EJ=a("a"),E5r=o("TFEncoderDecoderModel"),C5r=o(" (Encoder decoder model)"),w5r=l(),c4=a("li"),hTe=a("strong"),A5r=o("led"),L5r=o(" \u2014 "),CJ=a("a"),y5r=o("TFLEDForConditionalGeneration"),x5r=o(" (LED model)"),$5r=l(),f4=a("li"),pTe=a("strong"),k5r=o("marian"),S5r=o(" \u2014 "),wJ=a("a"),R5r=o("TFMarianMTModel"),P5r=o(" (Marian model)"),B5r=l(),m4=a("li"),_Te=a("strong"),I5r=o("mbart"),N5r=o(" \u2014 "),AJ=a("a"),q5r=o("TFMBartForConditionalGeneration"),j5r=o(" (mBART model)"),D5r=l(),g4=a("li"),uTe=a("strong"),G5r=o("mt5"),O5r=o(" \u2014 "),LJ=a("a"),V5r=o("TFMT5ForConditionalGeneration"),X5r=o(" (MT5 model)"),z5r=l(),h4=a("li"),bTe=a("strong"),Q5r=o("pegasus"),W5r=o(" \u2014 "),yJ=a("a"),H5r=o("TFPegasusForConditionalGeneration"),U5r=o(" (Pegasus model)"),J5r=l(),p4=a("li"),vTe=a("strong"),Y5r=o("t5"),K5r=o(" \u2014 "),xJ=a("a"),Z5r=o("TFT5ForConditionalGeneration"),e3r=o(" (T5 model)"),o3r=l(),F(_4.$$.fragment),aVe=l(),bc=a("h2"),u4=a("a"),FTe=a("span"),F(z9.$$.fragment),r3r=l(),TTe=a("span"),t3r=o("TFAutoModelForSequenceClassification"),nVe=l(),sr=a("div"),F(Q9.$$.fragment),a3r=l(),vc=a("p"),n3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=a("a"),s3r=o("from_pretrained()"),l3r=o(" class method or the "),kJ=a("a"),i3r=o("from_config()"),d3r=o(` class
method.`),c3r=l(),W9=a("p"),f3r=o("This class cannot be instantiated directly using "),MTe=a("code"),m3r=o("__init__()"),g3r=o(" (throws an error)."),h3r=l(),It=a("div"),F(H9.$$.fragment),p3r=l(),ETe=a("p"),_3r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),u3r=l(),Fc=a("p"),b3r=o(`Note:
Loading a model from its configuration file does `),CTe=a("strong"),v3r=o("not"),F3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),T3r=o("from_pretrained()"),M3r=o(" to load the model weights."),E3r=l(),F(b4.$$.fragment),C3r=l(),Pr=a("div"),F(U9.$$.fragment),w3r=l(),wTe=a("p"),A3r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),L3r=l(),mn=a("p"),y3r=o("The model class to instantiate is selected based on the "),ATe=a("code"),x3r=o("model_type"),$3r=o(` property of the config object (either
passed as an argument or loaded from `),LTe=a("code"),k3r=o("pretrained_model_name_or_path"),S3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yTe=a("code"),R3r=o("pretrained_model_name_or_path"),P3r=o(":"),B3r=l(),te=a("ul"),v4=a("li"),xTe=a("strong"),I3r=o("albert"),N3r=o(" \u2014 "),RJ=a("a"),q3r=o("TFAlbertForSequenceClassification"),j3r=o(" (ALBERT model)"),D3r=l(),F4=a("li"),$Te=a("strong"),G3r=o("bert"),O3r=o(" \u2014 "),PJ=a("a"),V3r=o("TFBertForSequenceClassification"),X3r=o(" (BERT model)"),z3r=l(),T4=a("li"),kTe=a("strong"),Q3r=o("camembert"),W3r=o(" \u2014 "),BJ=a("a"),H3r=o("TFCamembertForSequenceClassification"),U3r=o(" (CamemBERT model)"),J3r=l(),M4=a("li"),STe=a("strong"),Y3r=o("convbert"),K3r=o(" \u2014 "),IJ=a("a"),Z3r=o("TFConvBertForSequenceClassification"),e0r=o(" (ConvBERT model)"),o0r=l(),E4=a("li"),RTe=a("strong"),r0r=o("ctrl"),t0r=o(" \u2014 "),NJ=a("a"),a0r=o("TFCTRLForSequenceClassification"),n0r=o(" (CTRL model)"),s0r=l(),C4=a("li"),PTe=a("strong"),l0r=o("deberta"),i0r=o(" \u2014 "),qJ=a("a"),d0r=o("TFDebertaForSequenceClassification"),c0r=o(" (DeBERTa model)"),f0r=l(),w4=a("li"),BTe=a("strong"),m0r=o("deberta-v2"),g0r=o(" \u2014 "),jJ=a("a"),h0r=o("TFDebertaV2ForSequenceClassification"),p0r=o(" (DeBERTa-v2 model)"),_0r=l(),A4=a("li"),ITe=a("strong"),u0r=o("distilbert"),b0r=o(" \u2014 "),DJ=a("a"),v0r=o("TFDistilBertForSequenceClassification"),F0r=o(" (DistilBERT model)"),T0r=l(),L4=a("li"),NTe=a("strong"),M0r=o("electra"),E0r=o(" \u2014 "),GJ=a("a"),C0r=o("TFElectraForSequenceClassification"),w0r=o(" (ELECTRA model)"),A0r=l(),y4=a("li"),qTe=a("strong"),L0r=o("flaubert"),y0r=o(" \u2014 "),OJ=a("a"),x0r=o("TFFlaubertForSequenceClassification"),$0r=o(" (FlauBERT model)"),k0r=l(),x4=a("li"),jTe=a("strong"),S0r=o("funnel"),R0r=o(" \u2014 "),VJ=a("a"),P0r=o("TFFunnelForSequenceClassification"),B0r=o(" (Funnel Transformer model)"),I0r=l(),$4=a("li"),DTe=a("strong"),N0r=o("gpt2"),q0r=o(" \u2014 "),XJ=a("a"),j0r=o("TFGPT2ForSequenceClassification"),D0r=o(" (OpenAI GPT-2 model)"),G0r=l(),k4=a("li"),GTe=a("strong"),O0r=o("gptj"),V0r=o(" \u2014 "),zJ=a("a"),X0r=o("TFGPTJForSequenceClassification"),z0r=o(" (GPT-J model)"),Q0r=l(),S4=a("li"),OTe=a("strong"),W0r=o("layoutlm"),H0r=o(" \u2014 "),QJ=a("a"),U0r=o("TFLayoutLMForSequenceClassification"),J0r=o(" (LayoutLM model)"),Y0r=l(),R4=a("li"),VTe=a("strong"),K0r=o("longformer"),Z0r=o(" \u2014 "),WJ=a("a"),ewr=o("TFLongformerForSequenceClassification"),owr=o(" (Longformer model)"),rwr=l(),P4=a("li"),XTe=a("strong"),twr=o("mobilebert"),awr=o(" \u2014 "),HJ=a("a"),nwr=o("TFMobileBertForSequenceClassification"),swr=o(" (MobileBERT model)"),lwr=l(),B4=a("li"),zTe=a("strong"),iwr=o("mpnet"),dwr=o(" \u2014 "),UJ=a("a"),cwr=o("TFMPNetForSequenceClassification"),fwr=o(" (MPNet model)"),mwr=l(),I4=a("li"),QTe=a("strong"),gwr=o("openai-gpt"),hwr=o(" \u2014 "),JJ=a("a"),pwr=o("TFOpenAIGPTForSequenceClassification"),_wr=o(" (OpenAI GPT model)"),uwr=l(),N4=a("li"),WTe=a("strong"),bwr=o("rembert"),vwr=o(" \u2014 "),YJ=a("a"),Fwr=o("TFRemBertForSequenceClassification"),Twr=o(" (RemBERT model)"),Mwr=l(),q4=a("li"),HTe=a("strong"),Ewr=o("roberta"),Cwr=o(" \u2014 "),KJ=a("a"),wwr=o("TFRobertaForSequenceClassification"),Awr=o(" (RoBERTa model)"),Lwr=l(),j4=a("li"),UTe=a("strong"),ywr=o("roformer"),xwr=o(" \u2014 "),ZJ=a("a"),$wr=o("TFRoFormerForSequenceClassification"),kwr=o(" (RoFormer model)"),Swr=l(),D4=a("li"),JTe=a("strong"),Rwr=o("tapas"),Pwr=o(" \u2014 "),eY=a("a"),Bwr=o("TFTapasForSequenceClassification"),Iwr=o(" (TAPAS model)"),Nwr=l(),G4=a("li"),YTe=a("strong"),qwr=o("transfo-xl"),jwr=o(" \u2014 "),oY=a("a"),Dwr=o("TFTransfoXLForSequenceClassification"),Gwr=o(" (Transformer-XL model)"),Owr=l(),O4=a("li"),KTe=a("strong"),Vwr=o("xlm"),Xwr=o(" \u2014 "),rY=a("a"),zwr=o("TFXLMForSequenceClassification"),Qwr=o(" (XLM model)"),Wwr=l(),V4=a("li"),ZTe=a("strong"),Hwr=o("xlm-roberta"),Uwr=o(" \u2014 "),tY=a("a"),Jwr=o("TFXLMRobertaForSequenceClassification"),Ywr=o(" (XLM-RoBERTa model)"),Kwr=l(),X4=a("li"),eMe=a("strong"),Zwr=o("xlnet"),eAr=o(" \u2014 "),aY=a("a"),oAr=o("TFXLNetForSequenceClassification"),rAr=o(" (XLNet model)"),tAr=l(),F(z4.$$.fragment),sVe=l(),Tc=a("h2"),Q4=a("a"),oMe=a("span"),F(J9.$$.fragment),aAr=l(),rMe=a("span"),nAr=o("TFAutoModelForMultipleChoice"),lVe=l(),lr=a("div"),F(Y9.$$.fragment),sAr=l(),Mc=a("p"),lAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=a("a"),iAr=o("from_pretrained()"),dAr=o(" class method or the "),sY=a("a"),cAr=o("from_config()"),fAr=o(` class
method.`),mAr=l(),K9=a("p"),gAr=o("This class cannot be instantiated directly using "),tMe=a("code"),hAr=o("__init__()"),pAr=o(" (throws an error)."),_Ar=l(),Nt=a("div"),F(Z9.$$.fragment),uAr=l(),aMe=a("p"),bAr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vAr=l(),Ec=a("p"),FAr=o(`Note:
Loading a model from its configuration file does `),nMe=a("strong"),TAr=o("not"),MAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=a("a"),EAr=o("from_pretrained()"),CAr=o(" to load the model weights."),wAr=l(),F(W4.$$.fragment),AAr=l(),Br=a("div"),F(ex.$$.fragment),LAr=l(),sMe=a("p"),yAr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),xAr=l(),gn=a("p"),$Ar=o("The model class to instantiate is selected based on the "),lMe=a("code"),kAr=o("model_type"),SAr=o(` property of the config object (either
passed as an argument or loaded from `),iMe=a("code"),RAr=o("pretrained_model_name_or_path"),PAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=a("code"),BAr=o("pretrained_model_name_or_path"),IAr=o(":"),NAr=l(),_e=a("ul"),H4=a("li"),cMe=a("strong"),qAr=o("albert"),jAr=o(" \u2014 "),iY=a("a"),DAr=o("TFAlbertForMultipleChoice"),GAr=o(" (ALBERT model)"),OAr=l(),U4=a("li"),fMe=a("strong"),VAr=o("bert"),XAr=o(" \u2014 "),dY=a("a"),zAr=o("TFBertForMultipleChoice"),QAr=o(" (BERT model)"),WAr=l(),J4=a("li"),mMe=a("strong"),HAr=o("camembert"),UAr=o(" \u2014 "),cY=a("a"),JAr=o("TFCamembertForMultipleChoice"),YAr=o(" (CamemBERT model)"),KAr=l(),Y4=a("li"),gMe=a("strong"),ZAr=o("convbert"),eLr=o(" \u2014 "),fY=a("a"),oLr=o("TFConvBertForMultipleChoice"),rLr=o(" (ConvBERT model)"),tLr=l(),K4=a("li"),hMe=a("strong"),aLr=o("distilbert"),nLr=o(" \u2014 "),mY=a("a"),sLr=o("TFDistilBertForMultipleChoice"),lLr=o(" (DistilBERT model)"),iLr=l(),Z4=a("li"),pMe=a("strong"),dLr=o("electra"),cLr=o(" \u2014 "),gY=a("a"),fLr=o("TFElectraForMultipleChoice"),mLr=o(" (ELECTRA model)"),gLr=l(),eC=a("li"),_Me=a("strong"),hLr=o("flaubert"),pLr=o(" \u2014 "),hY=a("a"),_Lr=o("TFFlaubertForMultipleChoice"),uLr=o(" (FlauBERT model)"),bLr=l(),oC=a("li"),uMe=a("strong"),vLr=o("funnel"),FLr=o(" \u2014 "),pY=a("a"),TLr=o("TFFunnelForMultipleChoice"),MLr=o(" (Funnel Transformer model)"),ELr=l(),rC=a("li"),bMe=a("strong"),CLr=o("longformer"),wLr=o(" \u2014 "),_Y=a("a"),ALr=o("TFLongformerForMultipleChoice"),LLr=o(" (Longformer model)"),yLr=l(),tC=a("li"),vMe=a("strong"),xLr=o("mobilebert"),$Lr=o(" \u2014 "),uY=a("a"),kLr=o("TFMobileBertForMultipleChoice"),SLr=o(" (MobileBERT model)"),RLr=l(),aC=a("li"),FMe=a("strong"),PLr=o("mpnet"),BLr=o(" \u2014 "),bY=a("a"),ILr=o("TFMPNetForMultipleChoice"),NLr=o(" (MPNet model)"),qLr=l(),nC=a("li"),TMe=a("strong"),jLr=o("rembert"),DLr=o(" \u2014 "),vY=a("a"),GLr=o("TFRemBertForMultipleChoice"),OLr=o(" (RemBERT model)"),VLr=l(),sC=a("li"),MMe=a("strong"),XLr=o("roberta"),zLr=o(" \u2014 "),FY=a("a"),QLr=o("TFRobertaForMultipleChoice"),WLr=o(" (RoBERTa model)"),HLr=l(),lC=a("li"),EMe=a("strong"),ULr=o("roformer"),JLr=o(" \u2014 "),TY=a("a"),YLr=o("TFRoFormerForMultipleChoice"),KLr=o(" (RoFormer model)"),ZLr=l(),iC=a("li"),CMe=a("strong"),eyr=o("xlm"),oyr=o(" \u2014 "),MY=a("a"),ryr=o("TFXLMForMultipleChoice"),tyr=o(" (XLM model)"),ayr=l(),dC=a("li"),wMe=a("strong"),nyr=o("xlm-roberta"),syr=o(" \u2014 "),EY=a("a"),lyr=o("TFXLMRobertaForMultipleChoice"),iyr=o(" (XLM-RoBERTa model)"),dyr=l(),cC=a("li"),AMe=a("strong"),cyr=o("xlnet"),fyr=o(" \u2014 "),CY=a("a"),myr=o("TFXLNetForMultipleChoice"),gyr=o(" (XLNet model)"),hyr=l(),F(fC.$$.fragment),iVe=l(),Cc=a("h2"),mC=a("a"),LMe=a("span"),F(ox.$$.fragment),pyr=l(),yMe=a("span"),_yr=o("TFAutoModelForNextSentencePrediction"),dVe=l(),ir=a("div"),F(rx.$$.fragment),uyr=l(),wc=a("p"),byr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=a("a"),vyr=o("from_pretrained()"),Fyr=o(" class method or the "),AY=a("a"),Tyr=o("from_config()"),Myr=o(` class
method.`),Eyr=l(),tx=a("p"),Cyr=o("This class cannot be instantiated directly using "),xMe=a("code"),wyr=o("__init__()"),Ayr=o(" (throws an error)."),Lyr=l(),qt=a("div"),F(ax.$$.fragment),yyr=l(),$Me=a("p"),xyr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$yr=l(),Ac=a("p"),kyr=o(`Note:
Loading a model from its configuration file does `),kMe=a("strong"),Syr=o("not"),Ryr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),Pyr=o("from_pretrained()"),Byr=o(" to load the model weights."),Iyr=l(),F(gC.$$.fragment),Nyr=l(),Ir=a("div"),F(nx.$$.fragment),qyr=l(),SMe=a("p"),jyr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Dyr=l(),hn=a("p"),Gyr=o("The model class to instantiate is selected based on the "),RMe=a("code"),Oyr=o("model_type"),Vyr=o(` property of the config object (either
passed as an argument or loaded from `),PMe=a("code"),Xyr=o("pretrained_model_name_or_path"),zyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BMe=a("code"),Qyr=o("pretrained_model_name_or_path"),Wyr=o(":"),Hyr=l(),sx=a("ul"),hC=a("li"),IMe=a("strong"),Uyr=o("bert"),Jyr=o(" \u2014 "),yY=a("a"),Yyr=o("TFBertForNextSentencePrediction"),Kyr=o(" (BERT model)"),Zyr=l(),pC=a("li"),NMe=a("strong"),e8r=o("mobilebert"),o8r=o(" \u2014 "),xY=a("a"),r8r=o("TFMobileBertForNextSentencePrediction"),t8r=o(" (MobileBERT model)"),a8r=l(),F(_C.$$.fragment),cVe=l(),Lc=a("h2"),uC=a("a"),qMe=a("span"),F(lx.$$.fragment),n8r=l(),jMe=a("span"),s8r=o("TFAutoModelForTableQuestionAnswering"),fVe=l(),dr=a("div"),F(ix.$$.fragment),l8r=l(),yc=a("p"),i8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=a("a"),d8r=o("from_pretrained()"),c8r=o(" class method or the "),kY=a("a"),f8r=o("from_config()"),m8r=o(` class
method.`),g8r=l(),dx=a("p"),h8r=o("This class cannot be instantiated directly using "),DMe=a("code"),p8r=o("__init__()"),_8r=o(" (throws an error)."),u8r=l(),jt=a("div"),F(cx.$$.fragment),b8r=l(),GMe=a("p"),v8r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),F8r=l(),xc=a("p"),T8r=o(`Note:
Loading a model from its configuration file does `),OMe=a("strong"),M8r=o("not"),E8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),C8r=o("from_pretrained()"),w8r=o(" to load the model weights."),A8r=l(),F(bC.$$.fragment),L8r=l(),Nr=a("div"),F(fx.$$.fragment),y8r=l(),VMe=a("p"),x8r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),$8r=l(),pn=a("p"),k8r=o("The model class to instantiate is selected based on the "),XMe=a("code"),S8r=o("model_type"),R8r=o(` property of the config object (either
passed as an argument or loaded from `),zMe=a("code"),P8r=o("pretrained_model_name_or_path"),B8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QMe=a("code"),I8r=o("pretrained_model_name_or_path"),N8r=o(":"),q8r=l(),WMe=a("ul"),vC=a("li"),HMe=a("strong"),j8r=o("tapas"),D8r=o(" \u2014 "),RY=a("a"),G8r=o("TFTapasForQuestionAnswering"),O8r=o(" (TAPAS model)"),V8r=l(),F(FC.$$.fragment),mVe=l(),$c=a("h2"),TC=a("a"),UMe=a("span"),F(mx.$$.fragment),X8r=l(),JMe=a("span"),z8r=o("TFAutoModelForTokenClassification"),gVe=l(),cr=a("div"),F(gx.$$.fragment),Q8r=l(),kc=a("p"),W8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=a("a"),H8r=o("from_pretrained()"),U8r=o(" class method or the "),BY=a("a"),J8r=o("from_config()"),Y8r=o(` class
method.`),K8r=l(),hx=a("p"),Z8r=o("This class cannot be instantiated directly using "),YMe=a("code"),e9r=o("__init__()"),o9r=o(" (throws an error)."),r9r=l(),Dt=a("div"),F(px.$$.fragment),t9r=l(),KMe=a("p"),a9r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),n9r=l(),Sc=a("p"),s9r=o(`Note:
Loading a model from its configuration file does `),ZMe=a("strong"),l9r=o("not"),i9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),d9r=o("from_pretrained()"),c9r=o(" to load the model weights."),f9r=l(),F(MC.$$.fragment),m9r=l(),qr=a("div"),F(_x.$$.fragment),g9r=l(),eEe=a("p"),h9r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),p9r=l(),_n=a("p"),_9r=o("The model class to instantiate is selected based on the "),oEe=a("code"),u9r=o("model_type"),b9r=o(` property of the config object (either
passed as an argument or loaded from `),rEe=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=a("code"),T9r=o("pretrained_model_name_or_path"),M9r=o(":"),E9r=l(),de=a("ul"),EC=a("li"),aEe=a("strong"),C9r=o("albert"),w9r=o(" \u2014 "),NY=a("a"),A9r=o("TFAlbertForTokenClassification"),L9r=o(" (ALBERT model)"),y9r=l(),CC=a("li"),nEe=a("strong"),x9r=o("bert"),$9r=o(" \u2014 "),qY=a("a"),k9r=o("TFBertForTokenClassification"),S9r=o(" (BERT model)"),R9r=l(),wC=a("li"),sEe=a("strong"),P9r=o("camembert"),B9r=o(" \u2014 "),jY=a("a"),I9r=o("TFCamembertForTokenClassification"),N9r=o(" (CamemBERT model)"),q9r=l(),AC=a("li"),lEe=a("strong"),j9r=o("convbert"),D9r=o(" \u2014 "),DY=a("a"),G9r=o("TFConvBertForTokenClassification"),O9r=o(" (ConvBERT model)"),V9r=l(),LC=a("li"),iEe=a("strong"),X9r=o("deberta"),z9r=o(" \u2014 "),GY=a("a"),Q9r=o("TFDebertaForTokenClassification"),W9r=o(" (DeBERTa model)"),H9r=l(),yC=a("li"),dEe=a("strong"),U9r=o("deberta-v2"),J9r=o(" \u2014 "),OY=a("a"),Y9r=o("TFDebertaV2ForTokenClassification"),K9r=o(" (DeBERTa-v2 model)"),Z9r=l(),xC=a("li"),cEe=a("strong"),exr=o("distilbert"),oxr=o(" \u2014 "),VY=a("a"),rxr=o("TFDistilBertForTokenClassification"),txr=o(" (DistilBERT model)"),axr=l(),$C=a("li"),fEe=a("strong"),nxr=o("electra"),sxr=o(" \u2014 "),XY=a("a"),lxr=o("TFElectraForTokenClassification"),ixr=o(" (ELECTRA model)"),dxr=l(),kC=a("li"),mEe=a("strong"),cxr=o("flaubert"),fxr=o(" \u2014 "),zY=a("a"),mxr=o("TFFlaubertForTokenClassification"),gxr=o(" (FlauBERT model)"),hxr=l(),SC=a("li"),gEe=a("strong"),pxr=o("funnel"),_xr=o(" \u2014 "),QY=a("a"),uxr=o("TFFunnelForTokenClassification"),bxr=o(" (Funnel Transformer model)"),vxr=l(),RC=a("li"),hEe=a("strong"),Fxr=o("layoutlm"),Txr=o(" \u2014 "),WY=a("a"),Mxr=o("TFLayoutLMForTokenClassification"),Exr=o(" (LayoutLM model)"),Cxr=l(),PC=a("li"),pEe=a("strong"),wxr=o("longformer"),Axr=o(" \u2014 "),HY=a("a"),Lxr=o("TFLongformerForTokenClassification"),yxr=o(" (Longformer model)"),xxr=l(),BC=a("li"),_Ee=a("strong"),$xr=o("mobilebert"),kxr=o(" \u2014 "),UY=a("a"),Sxr=o("TFMobileBertForTokenClassification"),Rxr=o(" (MobileBERT model)"),Pxr=l(),IC=a("li"),uEe=a("strong"),Bxr=o("mpnet"),Ixr=o(" \u2014 "),JY=a("a"),Nxr=o("TFMPNetForTokenClassification"),qxr=o(" (MPNet model)"),jxr=l(),NC=a("li"),bEe=a("strong"),Dxr=o("rembert"),Gxr=o(" \u2014 "),YY=a("a"),Oxr=o("TFRemBertForTokenClassification"),Vxr=o(" (RemBERT model)"),Xxr=l(),qC=a("li"),vEe=a("strong"),zxr=o("roberta"),Qxr=o(" \u2014 "),KY=a("a"),Wxr=o("TFRobertaForTokenClassification"),Hxr=o(" (RoBERTa model)"),Uxr=l(),jC=a("li"),FEe=a("strong"),Jxr=o("roformer"),Yxr=o(" \u2014 "),ZY=a("a"),Kxr=o("TFRoFormerForTokenClassification"),Zxr=o(" (RoFormer model)"),e$r=l(),DC=a("li"),TEe=a("strong"),o$r=o("xlm"),r$r=o(" \u2014 "),eK=a("a"),t$r=o("TFXLMForTokenClassification"),a$r=o(" (XLM model)"),n$r=l(),GC=a("li"),MEe=a("strong"),s$r=o("xlm-roberta"),l$r=o(" \u2014 "),oK=a("a"),i$r=o("TFXLMRobertaForTokenClassification"),d$r=o(" (XLM-RoBERTa model)"),c$r=l(),OC=a("li"),EEe=a("strong"),f$r=o("xlnet"),m$r=o(" \u2014 "),rK=a("a"),g$r=o("TFXLNetForTokenClassification"),h$r=o(" (XLNet model)"),p$r=l(),F(VC.$$.fragment),hVe=l(),Rc=a("h2"),XC=a("a"),CEe=a("span"),F(ux.$$.fragment),_$r=l(),wEe=a("span"),u$r=o("TFAutoModelForQuestionAnswering"),pVe=l(),fr=a("div"),F(bx.$$.fragment),b$r=l(),Pc=a("p"),v$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=a("a"),F$r=o("from_pretrained()"),T$r=o(" class method or the "),aK=a("a"),M$r=o("from_config()"),E$r=o(` class
method.`),C$r=l(),vx=a("p"),w$r=o("This class cannot be instantiated directly using "),AEe=a("code"),A$r=o("__init__()"),L$r=o(" (throws an error)."),y$r=l(),Gt=a("div"),F(Fx.$$.fragment),x$r=l(),LEe=a("p"),$$r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k$r=l(),Bc=a("p"),S$r=o(`Note:
Loading a model from its configuration file does `),yEe=a("strong"),R$r=o("not"),P$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),B$r=o("from_pretrained()"),I$r=o(" to load the model weights."),N$r=l(),F(zC.$$.fragment),q$r=l(),jr=a("div"),F(Tx.$$.fragment),j$r=l(),xEe=a("p"),D$r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G$r=l(),un=a("p"),O$r=o("The model class to instantiate is selected based on the "),$Ee=a("code"),V$r=o("model_type"),X$r=o(` property of the config object (either
passed as an argument or loaded from `),kEe=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SEe=a("code"),W$r=o("pretrained_model_name_or_path"),H$r=o(":"),U$r=l(),ce=a("ul"),QC=a("li"),REe=a("strong"),J$r=o("albert"),Y$r=o(" \u2014 "),sK=a("a"),K$r=o("TFAlbertForQuestionAnswering"),Z$r=o(" (ALBERT model)"),ekr=l(),WC=a("li"),PEe=a("strong"),okr=o("bert"),rkr=o(" \u2014 "),lK=a("a"),tkr=o("TFBertForQuestionAnswering"),akr=o(" (BERT model)"),nkr=l(),HC=a("li"),BEe=a("strong"),skr=o("camembert"),lkr=o(" \u2014 "),iK=a("a"),ikr=o("TFCamembertForQuestionAnswering"),dkr=o(" (CamemBERT model)"),ckr=l(),UC=a("li"),IEe=a("strong"),fkr=o("convbert"),mkr=o(" \u2014 "),dK=a("a"),gkr=o("TFConvBertForQuestionAnswering"),hkr=o(" (ConvBERT model)"),pkr=l(),JC=a("li"),NEe=a("strong"),_kr=o("deberta"),ukr=o(" \u2014 "),cK=a("a"),bkr=o("TFDebertaForQuestionAnswering"),vkr=o(" (DeBERTa model)"),Fkr=l(),YC=a("li"),qEe=a("strong"),Tkr=o("deberta-v2"),Mkr=o(" \u2014 "),fK=a("a"),Ekr=o("TFDebertaV2ForQuestionAnswering"),Ckr=o(" (DeBERTa-v2 model)"),wkr=l(),KC=a("li"),jEe=a("strong"),Akr=o("distilbert"),Lkr=o(" \u2014 "),mK=a("a"),ykr=o("TFDistilBertForQuestionAnswering"),xkr=o(" (DistilBERT model)"),$kr=l(),ZC=a("li"),DEe=a("strong"),kkr=o("electra"),Skr=o(" \u2014 "),gK=a("a"),Rkr=o("TFElectraForQuestionAnswering"),Pkr=o(" (ELECTRA model)"),Bkr=l(),e5=a("li"),GEe=a("strong"),Ikr=o("flaubert"),Nkr=o(" \u2014 "),hK=a("a"),qkr=o("TFFlaubertForQuestionAnsweringSimple"),jkr=o(" (FlauBERT model)"),Dkr=l(),o5=a("li"),OEe=a("strong"),Gkr=o("funnel"),Okr=o(" \u2014 "),pK=a("a"),Vkr=o("TFFunnelForQuestionAnswering"),Xkr=o(" (Funnel Transformer model)"),zkr=l(),r5=a("li"),VEe=a("strong"),Qkr=o("gptj"),Wkr=o(" \u2014 "),_K=a("a"),Hkr=o("TFGPTJForQuestionAnswering"),Ukr=o(" (GPT-J model)"),Jkr=l(),t5=a("li"),XEe=a("strong"),Ykr=o("longformer"),Kkr=o(" \u2014 "),uK=a("a"),Zkr=o("TFLongformerForQuestionAnswering"),eSr=o(" (Longformer model)"),oSr=l(),a5=a("li"),zEe=a("strong"),rSr=o("mobilebert"),tSr=o(" \u2014 "),bK=a("a"),aSr=o("TFMobileBertForQuestionAnswering"),nSr=o(" (MobileBERT model)"),sSr=l(),n5=a("li"),QEe=a("strong"),lSr=o("mpnet"),iSr=o(" \u2014 "),vK=a("a"),dSr=o("TFMPNetForQuestionAnswering"),cSr=o(" (MPNet model)"),fSr=l(),s5=a("li"),WEe=a("strong"),mSr=o("rembert"),gSr=o(" \u2014 "),FK=a("a"),hSr=o("TFRemBertForQuestionAnswering"),pSr=o(" (RemBERT model)"),_Sr=l(),l5=a("li"),HEe=a("strong"),uSr=o("roberta"),bSr=o(" \u2014 "),TK=a("a"),vSr=o("TFRobertaForQuestionAnswering"),FSr=o(" (RoBERTa model)"),TSr=l(),i5=a("li"),UEe=a("strong"),MSr=o("roformer"),ESr=o(" \u2014 "),MK=a("a"),CSr=o("TFRoFormerForQuestionAnswering"),wSr=o(" (RoFormer model)"),ASr=l(),d5=a("li"),JEe=a("strong"),LSr=o("xlm"),ySr=o(" \u2014 "),EK=a("a"),xSr=o("TFXLMForQuestionAnsweringSimple"),$Sr=o(" (XLM model)"),kSr=l(),c5=a("li"),YEe=a("strong"),SSr=o("xlm-roberta"),RSr=o(" \u2014 "),CK=a("a"),PSr=o("TFXLMRobertaForQuestionAnswering"),BSr=o(" (XLM-RoBERTa model)"),ISr=l(),f5=a("li"),KEe=a("strong"),NSr=o("xlnet"),qSr=o(" \u2014 "),wK=a("a"),jSr=o("TFXLNetForQuestionAnsweringSimple"),DSr=o(" (XLNet model)"),GSr=l(),F(m5.$$.fragment),_Ve=l(),Ic=a("h2"),g5=a("a"),ZEe=a("span"),F(Mx.$$.fragment),OSr=l(),e4e=a("span"),VSr=o("TFAutoModelForVision2Seq"),uVe=l(),mr=a("div"),F(Ex.$$.fragment),XSr=l(),Nc=a("p"),zSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=a("a"),QSr=o("from_pretrained()"),WSr=o(" class method or the "),LK=a("a"),HSr=o("from_config()"),USr=o(` class
method.`),JSr=l(),Cx=a("p"),YSr=o("This class cannot be instantiated directly using "),o4e=a("code"),KSr=o("__init__()"),ZSr=o(" (throws an error)."),eRr=l(),Ot=a("div"),F(wx.$$.fragment),oRr=l(),r4e=a("p"),rRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tRr=l(),qc=a("p"),aRr=o(`Note:
Loading a model from its configuration file does `),t4e=a("strong"),nRr=o("not"),sRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),lRr=o("from_pretrained()"),iRr=o(" to load the model weights."),dRr=l(),F(h5.$$.fragment),cRr=l(),Dr=a("div"),F(Ax.$$.fragment),fRr=l(),a4e=a("p"),mRr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gRr=l(),bn=a("p"),hRr=o("The model class to instantiate is selected based on the "),n4e=a("code"),pRr=o("model_type"),_Rr=o(` property of the config object (either
passed as an argument or loaded from `),s4e=a("code"),uRr=o("pretrained_model_name_or_path"),bRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l4e=a("code"),vRr=o("pretrained_model_name_or_path"),FRr=o(":"),TRr=l(),i4e=a("ul"),p5=a("li"),d4e=a("strong"),MRr=o("vision-encoder-decoder"),ERr=o(" \u2014 "),xK=a("a"),CRr=o("TFVisionEncoderDecoderModel"),wRr=o(" (Vision Encoder decoder model)"),ARr=l(),F(_5.$$.fragment),bVe=l(),jc=a("h2"),u5=a("a"),c4e=a("span"),F(Lx.$$.fragment),LRr=l(),f4e=a("span"),yRr=o("TFAutoModelForSpeechSeq2Seq"),vVe=l(),gr=a("div"),F(yx.$$.fragment),xRr=l(),Dc=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),kK=a("a"),RRr=o("from_config()"),PRr=o(` class
method.`),BRr=l(),xx=a("p"),IRr=o("This class cannot be instantiated directly using "),m4e=a("code"),NRr=o("__init__()"),qRr=o(" (throws an error)."),jRr=l(),Vt=a("div"),F($x.$$.fragment),DRr=l(),g4e=a("p"),GRr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ORr=l(),Gc=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),h4e=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),HRr=l(),F(b5.$$.fragment),URr=l(),Gr=a("div"),F(kx.$$.fragment),JRr=l(),p4e=a("p"),YRr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),KRr=l(),vn=a("p"),ZRr=o("The model class to instantiate is selected based on the "),_4e=a("code"),ePr=o("model_type"),oPr=o(` property of the config object (either
passed as an argument or loaded from `),u4e=a("code"),rPr=o("pretrained_model_name_or_path"),tPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b4e=a("code"),aPr=o("pretrained_model_name_or_path"),nPr=o(":"),sPr=l(),v4e=a("ul"),v5=a("li"),F4e=a("strong"),lPr=o("speech_to_text"),iPr=o(" \u2014 "),RK=a("a"),dPr=o("TFSpeech2TextForConditionalGeneration"),cPr=o(" (Speech2Text model)"),fPr=l(),F(F5.$$.fragment),FVe=l(),Oc=a("h2"),T5=a("a"),T4e=a("span"),F(Sx.$$.fragment),mPr=l(),M4e=a("span"),gPr=o("FlaxAutoModel"),TVe=l(),hr=a("div"),F(Rx.$$.fragment),hPr=l(),Vc=a("p"),pPr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=a("a"),_Pr=o("from_pretrained()"),uPr=o(" class method or the "),BK=a("a"),bPr=o("from_config()"),vPr=o(` class
method.`),FPr=l(),Px=a("p"),TPr=o("This class cannot be instantiated directly using "),E4e=a("code"),MPr=o("__init__()"),EPr=o(" (throws an error)."),CPr=l(),Xt=a("div"),F(Bx.$$.fragment),wPr=l(),C4e=a("p"),APr=o("Instantiates one of the base model classes of the library from a configuration."),LPr=l(),Xc=a("p"),yPr=o(`Note:
Loading a model from its configuration file does `),w4e=a("strong"),xPr=o("not"),$Pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),kPr=o("from_pretrained()"),SPr=o(" to load the model weights."),RPr=l(),F(M5.$$.fragment),PPr=l(),Or=a("div"),F(Ix.$$.fragment),BPr=l(),A4e=a("p"),IPr=o("Instantiate one of the base model classes of the library from a pretrained model."),NPr=l(),Fn=a("p"),qPr=o("The model class to instantiate is selected based on the "),L4e=a("code"),jPr=o("model_type"),DPr=o(` property of the config object (either
passed as an argument or loaded from `),y4e=a("code"),GPr=o("pretrained_model_name_or_path"),OPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x4e=a("code"),VPr=o("pretrained_model_name_or_path"),XPr=o(":"),zPr=l(),oe=a("ul"),E5=a("li"),$4e=a("strong"),QPr=o("albert"),WPr=o(" \u2014 "),NK=a("a"),HPr=o("FlaxAlbertModel"),UPr=o(" (ALBERT model)"),JPr=l(),C5=a("li"),k4e=a("strong"),YPr=o("bart"),KPr=o(" \u2014 "),qK=a("a"),ZPr=o("FlaxBartModel"),eBr=o(" (BART model)"),oBr=l(),w5=a("li"),S4e=a("strong"),rBr=o("beit"),tBr=o(" \u2014 "),jK=a("a"),aBr=o("FlaxBeitModel"),nBr=o(" (BEiT model)"),sBr=l(),A5=a("li"),R4e=a("strong"),lBr=o("bert"),iBr=o(" \u2014 "),DK=a("a"),dBr=o("FlaxBertModel"),cBr=o(" (BERT model)"),fBr=l(),L5=a("li"),P4e=a("strong"),mBr=o("big_bird"),gBr=o(" \u2014 "),GK=a("a"),hBr=o("FlaxBigBirdModel"),pBr=o(" (BigBird model)"),_Br=l(),y5=a("li"),B4e=a("strong"),uBr=o("blenderbot"),bBr=o(" \u2014 "),OK=a("a"),vBr=o("FlaxBlenderbotModel"),FBr=o(" (Blenderbot model)"),TBr=l(),x5=a("li"),I4e=a("strong"),MBr=o("blenderbot-small"),EBr=o(" \u2014 "),VK=a("a"),CBr=o("FlaxBlenderbotSmallModel"),wBr=o(" (BlenderbotSmall model)"),ABr=l(),$5=a("li"),N4e=a("strong"),LBr=o("clip"),yBr=o(" \u2014 "),XK=a("a"),xBr=o("FlaxCLIPModel"),$Br=o(" (CLIP model)"),kBr=l(),k5=a("li"),q4e=a("strong"),SBr=o("distilbert"),RBr=o(" \u2014 "),zK=a("a"),PBr=o("FlaxDistilBertModel"),BBr=o(" (DistilBERT model)"),IBr=l(),S5=a("li"),j4e=a("strong"),NBr=o("electra"),qBr=o(" \u2014 "),QK=a("a"),jBr=o("FlaxElectraModel"),DBr=o(" (ELECTRA model)"),GBr=l(),R5=a("li"),D4e=a("strong"),OBr=o("gpt2"),VBr=o(" \u2014 "),WK=a("a"),XBr=o("FlaxGPT2Model"),zBr=o(" (OpenAI GPT-2 model)"),QBr=l(),P5=a("li"),G4e=a("strong"),WBr=o("gpt_neo"),HBr=o(" \u2014 "),HK=a("a"),UBr=o("FlaxGPTNeoModel"),JBr=o(" (GPT Neo model)"),YBr=l(),B5=a("li"),O4e=a("strong"),KBr=o("gptj"),ZBr=o(" \u2014 "),UK=a("a"),eIr=o("FlaxGPTJModel"),oIr=o(" (GPT-J model)"),rIr=l(),I5=a("li"),V4e=a("strong"),tIr=o("longt5"),aIr=o(" \u2014 "),JK=a("a"),nIr=o("FlaxLongT5Model"),sIr=o(" (LongT5 model)"),lIr=l(),N5=a("li"),X4e=a("strong"),iIr=o("marian"),dIr=o(" \u2014 "),YK=a("a"),cIr=o("FlaxMarianModel"),fIr=o(" (Marian model)"),mIr=l(),q5=a("li"),z4e=a("strong"),gIr=o("mbart"),hIr=o(" \u2014 "),KK=a("a"),pIr=o("FlaxMBartModel"),_Ir=o(" (mBART model)"),uIr=l(),j5=a("li"),Q4e=a("strong"),bIr=o("mt5"),vIr=o(" \u2014 "),ZK=a("a"),FIr=o("FlaxMT5Model"),TIr=o(" (MT5 model)"),MIr=l(),D5=a("li"),W4e=a("strong"),EIr=o("opt"),CIr=o(" \u2014 "),eZ=a("a"),wIr=o("FlaxOPTModel"),AIr=o(" (OPT model)"),LIr=l(),G5=a("li"),H4e=a("strong"),yIr=o("pegasus"),xIr=o(" \u2014 "),oZ=a("a"),$Ir=o("FlaxPegasusModel"),kIr=o(" (Pegasus model)"),SIr=l(),O5=a("li"),U4e=a("strong"),RIr=o("roberta"),PIr=o(" \u2014 "),rZ=a("a"),BIr=o("FlaxRobertaModel"),IIr=o(" (RoBERTa model)"),NIr=l(),V5=a("li"),J4e=a("strong"),qIr=o("roformer"),jIr=o(" \u2014 "),tZ=a("a"),DIr=o("FlaxRoFormerModel"),GIr=o(" (RoFormer model)"),OIr=l(),X5=a("li"),Y4e=a("strong"),VIr=o("t5"),XIr=o(" \u2014 "),aZ=a("a"),zIr=o("FlaxT5Model"),QIr=o(" (T5 model)"),WIr=l(),z5=a("li"),K4e=a("strong"),HIr=o("vision-text-dual-encoder"),UIr=o(" \u2014 "),nZ=a("a"),JIr=o("FlaxVisionTextDualEncoderModel"),YIr=o(" (VisionTextDualEncoder model)"),KIr=l(),Q5=a("li"),Z4e=a("strong"),ZIr=o("vit"),eNr=o(" \u2014 "),sZ=a("a"),oNr=o("FlaxViTModel"),rNr=o(" (ViT model)"),tNr=l(),W5=a("li"),eCe=a("strong"),aNr=o("wav2vec2"),nNr=o(" \u2014 "),lZ=a("a"),sNr=o("FlaxWav2Vec2Model"),lNr=o(" (Wav2Vec2 model)"),iNr=l(),H5=a("li"),oCe=a("strong"),dNr=o("xglm"),cNr=o(" \u2014 "),iZ=a("a"),fNr=o("FlaxXGLMModel"),mNr=o(" (XGLM model)"),gNr=l(),U5=a("li"),rCe=a("strong"),hNr=o("xlm-roberta"),pNr=o(" \u2014 "),dZ=a("a"),_Nr=o("FlaxXLMRobertaModel"),uNr=o(" (XLM-RoBERTa model)"),bNr=l(),F(J5.$$.fragment),MVe=l(),zc=a("h2"),Y5=a("a"),tCe=a("span"),F(Nx.$$.fragment),vNr=l(),aCe=a("span"),FNr=o("FlaxAutoModelForCausalLM"),EVe=l(),pr=a("div"),F(qx.$$.fragment),TNr=l(),Qc=a("p"),MNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=a("a"),ENr=o("from_pretrained()"),CNr=o(" class method or the "),fZ=a("a"),wNr=o("from_config()"),ANr=o(` class
method.`),LNr=l(),jx=a("p"),yNr=o("This class cannot be instantiated directly using "),nCe=a("code"),xNr=o("__init__()"),$Nr=o(" (throws an error)."),kNr=l(),zt=a("div"),F(Dx.$$.fragment),SNr=l(),sCe=a("p"),RNr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),PNr=l(),Wc=a("p"),BNr=o(`Note:
Loading a model from its configuration file does `),lCe=a("strong"),INr=o("not"),NNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=a("a"),qNr=o("from_pretrained()"),jNr=o(" to load the model weights."),DNr=l(),F(K5.$$.fragment),GNr=l(),Vr=a("div"),F(Gx.$$.fragment),ONr=l(),iCe=a("p"),VNr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XNr=l(),Tn=a("p"),zNr=o("The model class to instantiate is selected based on the "),dCe=a("code"),QNr=o("model_type"),WNr=o(` property of the config object (either
passed as an argument or loaded from `),cCe=a("code"),HNr=o("pretrained_model_name_or_path"),UNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(":"),KNr=l(),xe=a("ul"),Z5=a("li"),mCe=a("strong"),ZNr=o("bart"),eqr=o(" \u2014 "),gZ=a("a"),oqr=o("FlaxBartForCausalLM"),rqr=o(" (BART model)"),tqr=l(),e3=a("li"),gCe=a("strong"),aqr=o("bert"),nqr=o(" \u2014 "),hZ=a("a"),sqr=o("FlaxBertForCausalLM"),lqr=o(" (BERT model)"),iqr=l(),o3=a("li"),hCe=a("strong"),dqr=o("big_bird"),cqr=o(" \u2014 "),pZ=a("a"),fqr=o("FlaxBigBirdForCausalLM"),mqr=o(" (BigBird model)"),gqr=l(),r3=a("li"),pCe=a("strong"),hqr=o("electra"),pqr=o(" \u2014 "),_Z=a("a"),_qr=o("FlaxElectraForCausalLM"),uqr=o(" (ELECTRA model)"),bqr=l(),t3=a("li"),_Ce=a("strong"),vqr=o("gpt2"),Fqr=o(" \u2014 "),uZ=a("a"),Tqr=o("FlaxGPT2LMHeadModel"),Mqr=o(" (OpenAI GPT-2 model)"),Eqr=l(),a3=a("li"),uCe=a("strong"),Cqr=o("gpt_neo"),wqr=o(" \u2014 "),bZ=a("a"),Aqr=o("FlaxGPTNeoForCausalLM"),Lqr=o(" (GPT Neo model)"),yqr=l(),n3=a("li"),bCe=a("strong"),xqr=o("gptj"),$qr=o(" \u2014 "),vZ=a("a"),kqr=o("FlaxGPTJForCausalLM"),Sqr=o(" (GPT-J model)"),Rqr=l(),s3=a("li"),vCe=a("strong"),Pqr=o("opt"),Bqr=o(" \u2014 "),FZ=a("a"),Iqr=o("FlaxOPTForCausalLM"),Nqr=o(" (OPT model)"),qqr=l(),l3=a("li"),FCe=a("strong"),jqr=o("roberta"),Dqr=o(" \u2014 "),TZ=a("a"),Gqr=o("FlaxRobertaForCausalLM"),Oqr=o(" (RoBERTa model)"),Vqr=l(),i3=a("li"),TCe=a("strong"),Xqr=o("xglm"),zqr=o(" \u2014 "),MZ=a("a"),Qqr=o("FlaxXGLMForCausalLM"),Wqr=o(" (XGLM model)"),Hqr=l(),F(d3.$$.fragment),CVe=l(),Hc=a("h2"),c3=a("a"),MCe=a("span"),F(Ox.$$.fragment),Uqr=l(),ECe=a("span"),Jqr=o("FlaxAutoModelForPreTraining"),wVe=l(),_r=a("div"),F(Vx.$$.fragment),Yqr=l(),Uc=a("p"),Kqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=a("a"),Zqr=o("from_pretrained()"),ejr=o(" class method or the "),CZ=a("a"),ojr=o("from_config()"),rjr=o(` class
method.`),tjr=l(),Xx=a("p"),ajr=o("This class cannot be instantiated directly using "),CCe=a("code"),njr=o("__init__()"),sjr=o(" (throws an error)."),ljr=l(),Qt=a("div"),F(zx.$$.fragment),ijr=l(),wCe=a("p"),djr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cjr=l(),Jc=a("p"),fjr=o(`Note:
Loading a model from its configuration file does `),ACe=a("strong"),mjr=o("not"),gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),hjr=o("from_pretrained()"),pjr=o(" to load the model weights."),_jr=l(),F(f3.$$.fragment),ujr=l(),Xr=a("div"),F(Qx.$$.fragment),bjr=l(),LCe=a("p"),vjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Fjr=l(),Mn=a("p"),Tjr=o("The model class to instantiate is selected based on the "),yCe=a("code"),Mjr=o("model_type"),Ejr=o(` property of the config object (either
passed as an argument or loaded from `),xCe=a("code"),Cjr=o("pretrained_model_name_or_path"),wjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ce=a("code"),Ajr=o("pretrained_model_name_or_path"),Ljr=o(":"),yjr=l(),Ee=a("ul"),m3=a("li"),kCe=a("strong"),xjr=o("albert"),$jr=o(" \u2014 "),AZ=a("a"),kjr=o("FlaxAlbertForPreTraining"),Sjr=o(" (ALBERT model)"),Rjr=l(),g3=a("li"),SCe=a("strong"),Pjr=o("bart"),Bjr=o(" \u2014 "),LZ=a("a"),Ijr=o("FlaxBartForConditionalGeneration"),Njr=o(" (BART model)"),qjr=l(),h3=a("li"),RCe=a("strong"),jjr=o("bert"),Djr=o(" \u2014 "),yZ=a("a"),Gjr=o("FlaxBertForPreTraining"),Ojr=o(" (BERT model)"),Vjr=l(),p3=a("li"),PCe=a("strong"),Xjr=o("big_bird"),zjr=o(" \u2014 "),xZ=a("a"),Qjr=o("FlaxBigBirdForPreTraining"),Wjr=o(" (BigBird model)"),Hjr=l(),_3=a("li"),BCe=a("strong"),Ujr=o("electra"),Jjr=o(" \u2014 "),$Z=a("a"),Yjr=o("FlaxElectraForPreTraining"),Kjr=o(" (ELECTRA model)"),Zjr=l(),u3=a("li"),ICe=a("strong"),eDr=o("longt5"),oDr=o(" \u2014 "),kZ=a("a"),rDr=o("FlaxLongT5ForConditionalGeneration"),tDr=o(" (LongT5 model)"),aDr=l(),b3=a("li"),NCe=a("strong"),nDr=o("mbart"),sDr=o(" \u2014 "),SZ=a("a"),lDr=o("FlaxMBartForConditionalGeneration"),iDr=o(" (mBART model)"),dDr=l(),v3=a("li"),qCe=a("strong"),cDr=o("mt5"),fDr=o(" \u2014 "),RZ=a("a"),mDr=o("FlaxMT5ForConditionalGeneration"),gDr=o(" (MT5 model)"),hDr=l(),F3=a("li"),jCe=a("strong"),pDr=o("roberta"),_Dr=o(" \u2014 "),PZ=a("a"),uDr=o("FlaxRobertaForMaskedLM"),bDr=o(" (RoBERTa model)"),vDr=l(),T3=a("li"),DCe=a("strong"),FDr=o("roformer"),TDr=o(" \u2014 "),BZ=a("a"),MDr=o("FlaxRoFormerForMaskedLM"),EDr=o(" (RoFormer model)"),CDr=l(),M3=a("li"),GCe=a("strong"),wDr=o("t5"),ADr=o(" \u2014 "),IZ=a("a"),LDr=o("FlaxT5ForConditionalGeneration"),yDr=o(" (T5 model)"),xDr=l(),E3=a("li"),OCe=a("strong"),$Dr=o("wav2vec2"),kDr=o(" \u2014 "),NZ=a("a"),SDr=o("FlaxWav2Vec2ForPreTraining"),RDr=o(" (Wav2Vec2 model)"),PDr=l(),C3=a("li"),VCe=a("strong"),BDr=o("xlm-roberta"),IDr=o(" \u2014 "),qZ=a("a"),NDr=o("FlaxXLMRobertaForMaskedLM"),qDr=o(" (XLM-RoBERTa model)"),jDr=l(),F(w3.$$.fragment),AVe=l(),Yc=a("h2"),A3=a("a"),XCe=a("span"),F(Wx.$$.fragment),DDr=l(),zCe=a("span"),GDr=o("FlaxAutoModelForMaskedLM"),LVe=l(),ur=a("div"),F(Hx.$$.fragment),ODr=l(),Kc=a("p"),VDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=a("a"),XDr=o("from_pretrained()"),zDr=o(" class method or the "),DZ=a("a"),QDr=o("from_config()"),WDr=o(` class
method.`),HDr=l(),Ux=a("p"),UDr=o("This class cannot be instantiated directly using "),QCe=a("code"),JDr=o("__init__()"),YDr=o(" (throws an error)."),KDr=l(),Wt=a("div"),F(Jx.$$.fragment),ZDr=l(),WCe=a("p"),eGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),oGr=l(),Zc=a("p"),rGr=o(`Note:
Loading a model from its configuration file does `),HCe=a("strong"),tGr=o("not"),aGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),nGr=o("from_pretrained()"),sGr=o(" to load the model weights."),lGr=l(),F(L3.$$.fragment),iGr=l(),zr=a("div"),F(Yx.$$.fragment),dGr=l(),UCe=a("p"),cGr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fGr=l(),En=a("p"),mGr=o("The model class to instantiate is selected based on the "),JCe=a("code"),gGr=o("model_type"),hGr=o(` property of the config object (either
passed as an argument or loaded from `),YCe=a("code"),pGr=o("pretrained_model_name_or_path"),_Gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=a("code"),uGr=o("pretrained_model_name_or_path"),bGr=o(":"),vGr=l(),$e=a("ul"),y3=a("li"),ZCe=a("strong"),FGr=o("albert"),TGr=o(" \u2014 "),OZ=a("a"),MGr=o("FlaxAlbertForMaskedLM"),EGr=o(" (ALBERT model)"),CGr=l(),x3=a("li"),e5e=a("strong"),wGr=o("bart"),AGr=o(" \u2014 "),VZ=a("a"),LGr=o("FlaxBartForConditionalGeneration"),yGr=o(" (BART model)"),xGr=l(),$3=a("li"),o5e=a("strong"),$Gr=o("bert"),kGr=o(" \u2014 "),XZ=a("a"),SGr=o("FlaxBertForMaskedLM"),RGr=o(" (BERT model)"),PGr=l(),k3=a("li"),r5e=a("strong"),BGr=o("big_bird"),IGr=o(" \u2014 "),zZ=a("a"),NGr=o("FlaxBigBirdForMaskedLM"),qGr=o(" (BigBird model)"),jGr=l(),S3=a("li"),t5e=a("strong"),DGr=o("distilbert"),GGr=o(" \u2014 "),QZ=a("a"),OGr=o("FlaxDistilBertForMaskedLM"),VGr=o(" (DistilBERT model)"),XGr=l(),R3=a("li"),a5e=a("strong"),zGr=o("electra"),QGr=o(" \u2014 "),WZ=a("a"),WGr=o("FlaxElectraForMaskedLM"),HGr=o(" (ELECTRA model)"),UGr=l(),P3=a("li"),n5e=a("strong"),JGr=o("mbart"),YGr=o(" \u2014 "),HZ=a("a"),KGr=o("FlaxMBartForConditionalGeneration"),ZGr=o(" (mBART model)"),eOr=l(),B3=a("li"),s5e=a("strong"),oOr=o("roberta"),rOr=o(" \u2014 "),UZ=a("a"),tOr=o("FlaxRobertaForMaskedLM"),aOr=o(" (RoBERTa model)"),nOr=l(),I3=a("li"),l5e=a("strong"),sOr=o("roformer"),lOr=o(" \u2014 "),JZ=a("a"),iOr=o("FlaxRoFormerForMaskedLM"),dOr=o(" (RoFormer model)"),cOr=l(),N3=a("li"),i5e=a("strong"),fOr=o("xlm-roberta"),mOr=o(" \u2014 "),YZ=a("a"),gOr=o("FlaxXLMRobertaForMaskedLM"),hOr=o(" (XLM-RoBERTa model)"),pOr=l(),F(q3.$$.fragment),yVe=l(),ef=a("h2"),j3=a("a"),d5e=a("span"),F(Kx.$$.fragment),_Or=l(),c5e=a("span"),uOr=o("FlaxAutoModelForSeq2SeqLM"),xVe=l(),br=a("div"),F(Zx.$$.fragment),bOr=l(),of=a("p"),vOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" class method or the "),ZZ=a("a"),MOr=o("from_config()"),EOr=o(` class
method.`),COr=l(),e$=a("p"),wOr=o("This class cannot be instantiated directly using "),f5e=a("code"),AOr=o("__init__()"),LOr=o(" (throws an error)."),yOr=l(),Ht=a("div"),F(o$.$$.fragment),xOr=l(),m5e=a("p"),$Or=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),kOr=l(),rf=a("p"),SOr=o(`Note:
Loading a model from its configuration file does `),g5e=a("strong"),ROr=o("not"),POr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=a("a"),BOr=o("from_pretrained()"),IOr=o(" to load the model weights."),NOr=l(),F(D3.$$.fragment),qOr=l(),Qr=a("div"),F(r$.$$.fragment),jOr=l(),h5e=a("p"),DOr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),GOr=l(),Cn=a("p"),OOr=o("The model class to instantiate is selected based on the "),p5e=a("code"),VOr=o("model_type"),XOr=o(` property of the config object (either
passed as an argument or loaded from `),_5e=a("code"),zOr=o("pretrained_model_name_or_path"),QOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u5e=a("code"),WOr=o("pretrained_model_name_or_path"),HOr=o(":"),UOr=l(),ke=a("ul"),G3=a("li"),b5e=a("strong"),JOr=o("bart"),YOr=o(" \u2014 "),oee=a("a"),KOr=o("FlaxBartForConditionalGeneration"),ZOr=o(" (BART model)"),eVr=l(),O3=a("li"),v5e=a("strong"),oVr=o("blenderbot"),rVr=o(" \u2014 "),ree=a("a"),tVr=o("FlaxBlenderbotForConditionalGeneration"),aVr=o(" (Blenderbot model)"),nVr=l(),V3=a("li"),F5e=a("strong"),sVr=o("blenderbot-small"),lVr=o(" \u2014 "),tee=a("a"),iVr=o("FlaxBlenderbotSmallForConditionalGeneration"),dVr=o(" (BlenderbotSmall model)"),cVr=l(),X3=a("li"),T5e=a("strong"),fVr=o("encoder-decoder"),mVr=o(" \u2014 "),aee=a("a"),gVr=o("FlaxEncoderDecoderModel"),hVr=o(" (Encoder decoder model)"),pVr=l(),z3=a("li"),M5e=a("strong"),_Vr=o("longt5"),uVr=o(" \u2014 "),nee=a("a"),bVr=o("FlaxLongT5ForConditionalGeneration"),vVr=o(" (LongT5 model)"),FVr=l(),Q3=a("li"),E5e=a("strong"),TVr=o("marian"),MVr=o(" \u2014 "),see=a("a"),EVr=o("FlaxMarianMTModel"),CVr=o(" (Marian model)"),wVr=l(),W3=a("li"),C5e=a("strong"),AVr=o("mbart"),LVr=o(" \u2014 "),lee=a("a"),yVr=o("FlaxMBartForConditionalGeneration"),xVr=o(" (mBART model)"),$Vr=l(),H3=a("li"),w5e=a("strong"),kVr=o("mt5"),SVr=o(" \u2014 "),iee=a("a"),RVr=o("FlaxMT5ForConditionalGeneration"),PVr=o(" (MT5 model)"),BVr=l(),U3=a("li"),A5e=a("strong"),IVr=o("pegasus"),NVr=o(" \u2014 "),dee=a("a"),qVr=o("FlaxPegasusForConditionalGeneration"),jVr=o(" (Pegasus model)"),DVr=l(),J3=a("li"),L5e=a("strong"),GVr=o("t5"),OVr=o(" \u2014 "),cee=a("a"),VVr=o("FlaxT5ForConditionalGeneration"),XVr=o(" (T5 model)"),zVr=l(),F(Y3.$$.fragment),$Ve=l(),tf=a("h2"),K3=a("a"),y5e=a("span"),F(t$.$$.fragment),QVr=l(),x5e=a("span"),WVr=o("FlaxAutoModelForSequenceClassification"),kVe=l(),vr=a("div"),F(a$.$$.fragment),HVr=l(),af=a("p"),UVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=a("a"),JVr=o("from_pretrained()"),YVr=o(" class method or the "),mee=a("a"),KVr=o("from_config()"),ZVr=o(` class
method.`),eXr=l(),n$=a("p"),oXr=o("This class cannot be instantiated directly using "),$5e=a("code"),rXr=o("__init__()"),tXr=o(" (throws an error)."),aXr=l(),Ut=a("div"),F(s$.$$.fragment),nXr=l(),k5e=a("p"),sXr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lXr=l(),nf=a("p"),iXr=o(`Note:
Loading a model from its configuration file does `),S5e=a("strong"),dXr=o("not"),cXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),fXr=o("from_pretrained()"),mXr=o(" to load the model weights."),gXr=l(),F(Z3.$$.fragment),hXr=l(),Wr=a("div"),F(l$.$$.fragment),pXr=l(),R5e=a("p"),_Xr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uXr=l(),wn=a("p"),bXr=o("The model class to instantiate is selected based on the "),P5e=a("code"),vXr=o("model_type"),FXr=o(` property of the config object (either
passed as an argument or loaded from `),B5e=a("code"),TXr=o("pretrained_model_name_or_path"),MXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I5e=a("code"),EXr=o("pretrained_model_name_or_path"),CXr=o(":"),wXr=l(),Se=a("ul"),e0=a("li"),N5e=a("strong"),AXr=o("albert"),LXr=o(" \u2014 "),hee=a("a"),yXr=o("FlaxAlbertForSequenceClassification"),xXr=o(" (ALBERT model)"),$Xr=l(),o0=a("li"),q5e=a("strong"),kXr=o("bart"),SXr=o(" \u2014 "),pee=a("a"),RXr=o("FlaxBartForSequenceClassification"),PXr=o(" (BART model)"),BXr=l(),r0=a("li"),j5e=a("strong"),IXr=o("bert"),NXr=o(" \u2014 "),_ee=a("a"),qXr=o("FlaxBertForSequenceClassification"),jXr=o(" (BERT model)"),DXr=l(),t0=a("li"),D5e=a("strong"),GXr=o("big_bird"),OXr=o(" \u2014 "),uee=a("a"),VXr=o("FlaxBigBirdForSequenceClassification"),XXr=o(" (BigBird model)"),zXr=l(),a0=a("li"),G5e=a("strong"),QXr=o("distilbert"),WXr=o(" \u2014 "),bee=a("a"),HXr=o("FlaxDistilBertForSequenceClassification"),UXr=o(" (DistilBERT model)"),JXr=l(),n0=a("li"),O5e=a("strong"),YXr=o("electra"),KXr=o(" \u2014 "),vee=a("a"),ZXr=o("FlaxElectraForSequenceClassification"),ezr=o(" (ELECTRA model)"),ozr=l(),s0=a("li"),V5e=a("strong"),rzr=o("mbart"),tzr=o(" \u2014 "),Fee=a("a"),azr=o("FlaxMBartForSequenceClassification"),nzr=o(" (mBART model)"),szr=l(),l0=a("li"),X5e=a("strong"),lzr=o("roberta"),izr=o(" \u2014 "),Tee=a("a"),dzr=o("FlaxRobertaForSequenceClassification"),czr=o(" (RoBERTa model)"),fzr=l(),i0=a("li"),z5e=a("strong"),mzr=o("roformer"),gzr=o(" \u2014 "),Mee=a("a"),hzr=o("FlaxRoFormerForSequenceClassification"),pzr=o(" (RoFormer model)"),_zr=l(),d0=a("li"),Q5e=a("strong"),uzr=o("xlm-roberta"),bzr=o(" \u2014 "),Eee=a("a"),vzr=o("FlaxXLMRobertaForSequenceClassification"),Fzr=o(" (XLM-RoBERTa model)"),Tzr=l(),F(c0.$$.fragment),SVe=l(),sf=a("h2"),f0=a("a"),W5e=a("span"),F(i$.$$.fragment),Mzr=l(),H5e=a("span"),Ezr=o("FlaxAutoModelForQuestionAnswering"),RVe=l(),Fr=a("div"),F(d$.$$.fragment),Czr=l(),lf=a("p"),wzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=a("a"),Azr=o("from_pretrained()"),Lzr=o(" class method or the "),wee=a("a"),yzr=o("from_config()"),xzr=o(` class
method.`),$zr=l(),c$=a("p"),kzr=o("This class cannot be instantiated directly using "),U5e=a("code"),Szr=o("__init__()"),Rzr=o(" (throws an error)."),Pzr=l(),Jt=a("div"),F(f$.$$.fragment),Bzr=l(),J5e=a("p"),Izr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Nzr=l(),df=a("p"),qzr=o(`Note:
Loading a model from its configuration file does `),Y5e=a("strong"),jzr=o("not"),Dzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=a("a"),Gzr=o("from_pretrained()"),Ozr=o(" to load the model weights."),Vzr=l(),F(m0.$$.fragment),Xzr=l(),Hr=a("div"),F(m$.$$.fragment),zzr=l(),K5e=a("p"),Qzr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Wzr=l(),An=a("p"),Hzr=o("The model class to instantiate is selected based on the "),Z5e=a("code"),Uzr=o("model_type"),Jzr=o(` property of the config object (either
passed as an argument or loaded from `),e3e=a("code"),Yzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o3e=a("code"),Zzr=o("pretrained_model_name_or_path"),eQr=o(":"),oQr=l(),Re=a("ul"),g0=a("li"),r3e=a("strong"),rQr=o("albert"),tQr=o(" \u2014 "),Lee=a("a"),aQr=o("FlaxAlbertForQuestionAnswering"),nQr=o(" (ALBERT model)"),sQr=l(),h0=a("li"),t3e=a("strong"),lQr=o("bart"),iQr=o(" \u2014 "),yee=a("a"),dQr=o("FlaxBartForQuestionAnswering"),cQr=o(" (BART model)"),fQr=l(),p0=a("li"),a3e=a("strong"),mQr=o("bert"),gQr=o(" \u2014 "),xee=a("a"),hQr=o("FlaxBertForQuestionAnswering"),pQr=o(" (BERT model)"),_Qr=l(),_0=a("li"),n3e=a("strong"),uQr=o("big_bird"),bQr=o(" \u2014 "),$ee=a("a"),vQr=o("FlaxBigBirdForQuestionAnswering"),FQr=o(" (BigBird model)"),TQr=l(),u0=a("li"),s3e=a("strong"),MQr=o("distilbert"),EQr=o(" \u2014 "),kee=a("a"),CQr=o("FlaxDistilBertForQuestionAnswering"),wQr=o(" (DistilBERT model)"),AQr=l(),b0=a("li"),l3e=a("strong"),LQr=o("electra"),yQr=o(" \u2014 "),See=a("a"),xQr=o("FlaxElectraForQuestionAnswering"),$Qr=o(" (ELECTRA model)"),kQr=l(),v0=a("li"),i3e=a("strong"),SQr=o("mbart"),RQr=o(" \u2014 "),Ree=a("a"),PQr=o("FlaxMBartForQuestionAnswering"),BQr=o(" (mBART model)"),IQr=l(),F0=a("li"),d3e=a("strong"),NQr=o("roberta"),qQr=o(" \u2014 "),Pee=a("a"),jQr=o("FlaxRobertaForQuestionAnswering"),DQr=o(" (RoBERTa model)"),GQr=l(),T0=a("li"),c3e=a("strong"),OQr=o("roformer"),VQr=o(" \u2014 "),Bee=a("a"),XQr=o("FlaxRoFormerForQuestionAnswering"),zQr=o(" (RoFormer model)"),QQr=l(),M0=a("li"),f3e=a("strong"),WQr=o("xlm-roberta"),HQr=o(" \u2014 "),Iee=a("a"),UQr=o("FlaxXLMRobertaForQuestionAnswering"),JQr=o(" (XLM-RoBERTa model)"),YQr=l(),F(E0.$$.fragment),PVe=l(),cf=a("h2"),C0=a("a"),m3e=a("span"),F(g$.$$.fragment),KQr=l(),g3e=a("span"),ZQr=o("FlaxAutoModelForTokenClassification"),BVe=l(),Tr=a("div"),F(h$.$$.fragment),eWr=l(),ff=a("p"),oWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=a("a"),rWr=o("from_pretrained()"),tWr=o(" class method or the "),qee=a("a"),aWr=o("from_config()"),nWr=o(` class
method.`),sWr=l(),p$=a("p"),lWr=o("This class cannot be instantiated directly using "),h3e=a("code"),iWr=o("__init__()"),dWr=o(" (throws an error)."),cWr=l(),Yt=a("div"),F(_$.$$.fragment),fWr=l(),p3e=a("p"),mWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gWr=l(),mf=a("p"),hWr=o(`Note:
Loading a model from its configuration file does `),_3e=a("strong"),pWr=o("not"),_Wr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=a("a"),uWr=o("from_pretrained()"),bWr=o(" to load the model weights."),vWr=l(),F(w0.$$.fragment),FWr=l(),Ur=a("div"),F(u$.$$.fragment),TWr=l(),u3e=a("p"),MWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EWr=l(),Ln=a("p"),CWr=o("The model class to instantiate is selected based on the "),b3e=a("code"),wWr=o("model_type"),AWr=o(` property of the config object (either
passed as an argument or loaded from `),v3e=a("code"),LWr=o("pretrained_model_name_or_path"),yWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F3e=a("code"),xWr=o("pretrained_model_name_or_path"),$Wr=o(":"),kWr=l(),Ve=a("ul"),A0=a("li"),T3e=a("strong"),SWr=o("albert"),RWr=o(" \u2014 "),Dee=a("a"),PWr=o("FlaxAlbertForTokenClassification"),BWr=o(" (ALBERT model)"),IWr=l(),L0=a("li"),M3e=a("strong"),NWr=o("bert"),qWr=o(" \u2014 "),Gee=a("a"),jWr=o("FlaxBertForTokenClassification"),DWr=o(" (BERT model)"),GWr=l(),y0=a("li"),E3e=a("strong"),OWr=o("big_bird"),VWr=o(" \u2014 "),Oee=a("a"),XWr=o("FlaxBigBirdForTokenClassification"),zWr=o(" (BigBird model)"),QWr=l(),x0=a("li"),C3e=a("strong"),WWr=o("distilbert"),HWr=o(" \u2014 "),Vee=a("a"),UWr=o("FlaxDistilBertForTokenClassification"),JWr=o(" (DistilBERT model)"),YWr=l(),$0=a("li"),w3e=a("strong"),KWr=o("electra"),ZWr=o(" \u2014 "),Xee=a("a"),eHr=o("FlaxElectraForTokenClassification"),oHr=o(" (ELECTRA model)"),rHr=l(),k0=a("li"),A3e=a("strong"),tHr=o("roberta"),aHr=o(" \u2014 "),zee=a("a"),nHr=o("FlaxRobertaForTokenClassification"),sHr=o(" (RoBERTa model)"),lHr=l(),S0=a("li"),L3e=a("strong"),iHr=o("roformer"),dHr=o(" \u2014 "),Qee=a("a"),cHr=o("FlaxRoFormerForTokenClassification"),fHr=o(" (RoFormer model)"),mHr=l(),R0=a("li"),y3e=a("strong"),gHr=o("xlm-roberta"),hHr=o(" \u2014 "),Wee=a("a"),pHr=o("FlaxXLMRobertaForTokenClassification"),_Hr=o(" (XLM-RoBERTa model)"),uHr=l(),F(P0.$$.fragment),IVe=l(),gf=a("h2"),B0=a("a"),x3e=a("span"),F(b$.$$.fragment),bHr=l(),$3e=a("span"),vHr=o("FlaxAutoModelForMultipleChoice"),NVe=l(),Mr=a("div"),F(v$.$$.fragment),FHr=l(),hf=a("p"),THr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=a("a"),MHr=o("from_pretrained()"),EHr=o(" class method or the "),Uee=a("a"),CHr=o("from_config()"),wHr=o(` class
method.`),AHr=l(),F$=a("p"),LHr=o("This class cannot be instantiated directly using "),k3e=a("code"),yHr=o("__init__()"),xHr=o(" (throws an error)."),$Hr=l(),Kt=a("div"),F(T$.$$.fragment),kHr=l(),S3e=a("p"),SHr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RHr=l(),pf=a("p"),PHr=o(`Note:
Loading a model from its configuration file does `),R3e=a("strong"),BHr=o("not"),IHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),NHr=o("from_pretrained()"),qHr=o(" to load the model weights."),jHr=l(),F(I0.$$.fragment),DHr=l(),Jr=a("div"),F(M$.$$.fragment),GHr=l(),P3e=a("p"),OHr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VHr=l(),yn=a("p"),XHr=o("The model class to instantiate is selected based on the "),B3e=a("code"),zHr=o("model_type"),QHr=o(` property of the config object (either
passed as an argument or loaded from `),I3e=a("code"),WHr=o("pretrained_model_name_or_path"),HHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N3e=a("code"),UHr=o("pretrained_model_name_or_path"),JHr=o(":"),YHr=l(),Xe=a("ul"),N0=a("li"),q3e=a("strong"),KHr=o("albert"),ZHr=o(" \u2014 "),Yee=a("a"),eUr=o("FlaxAlbertForMultipleChoice"),oUr=o(" (ALBERT model)"),rUr=l(),q0=a("li"),j3e=a("strong"),tUr=o("bert"),aUr=o(" \u2014 "),Kee=a("a"),nUr=o("FlaxBertForMultipleChoice"),sUr=o(" (BERT model)"),lUr=l(),j0=a("li"),D3e=a("strong"),iUr=o("big_bird"),dUr=o(" \u2014 "),Zee=a("a"),cUr=o("FlaxBigBirdForMultipleChoice"),fUr=o(" (BigBird model)"),mUr=l(),D0=a("li"),G3e=a("strong"),gUr=o("distilbert"),hUr=o(" \u2014 "),eoe=a("a"),pUr=o("FlaxDistilBertForMultipleChoice"),_Ur=o(" (DistilBERT model)"),uUr=l(),G0=a("li"),O3e=a("strong"),bUr=o("electra"),vUr=o(" \u2014 "),ooe=a("a"),FUr=o("FlaxElectraForMultipleChoice"),TUr=o(" (ELECTRA model)"),MUr=l(),O0=a("li"),V3e=a("strong"),EUr=o("roberta"),CUr=o(" \u2014 "),roe=a("a"),wUr=o("FlaxRobertaForMultipleChoice"),AUr=o(" (RoBERTa model)"),LUr=l(),V0=a("li"),X3e=a("strong"),yUr=o("roformer"),xUr=o(" \u2014 "),toe=a("a"),$Ur=o("FlaxRoFormerForMultipleChoice"),kUr=o(" (RoFormer model)"),SUr=l(),X0=a("li"),z3e=a("strong"),RUr=o("xlm-roberta"),PUr=o(" \u2014 "),aoe=a("a"),BUr=o("FlaxXLMRobertaForMultipleChoice"),IUr=o(" (XLM-RoBERTa model)"),NUr=l(),F(z0.$$.fragment),qVe=l(),_f=a("h2"),Q0=a("a"),Q3e=a("span"),F(E$.$$.fragment),qUr=l(),W3e=a("span"),jUr=o("FlaxAutoModelForNextSentencePrediction"),jVe=l(),Er=a("div"),F(C$.$$.fragment),DUr=l(),uf=a("p"),GUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=a("a"),OUr=o("from_pretrained()"),VUr=o(" class method or the "),soe=a("a"),XUr=o("from_config()"),zUr=o(` class
method.`),QUr=l(),w$=a("p"),WUr=o("This class cannot be instantiated directly using "),H3e=a("code"),HUr=o("__init__()"),UUr=o(" (throws an error)."),JUr=l(),Zt=a("div"),F(A$.$$.fragment),YUr=l(),U3e=a("p"),KUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZUr=l(),bf=a("p"),eJr=o(`Note:
Loading a model from its configuration file does `),J3e=a("strong"),oJr=o("not"),rJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=a("a"),tJr=o("from_pretrained()"),aJr=o(" to load the model weights."),nJr=l(),F(W0.$$.fragment),sJr=l(),Yr=a("div"),F(L$.$$.fragment),lJr=l(),Y3e=a("p"),iJr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),dJr=l(),xn=a("p"),cJr=o("The model class to instantiate is selected based on the "),K3e=a("code"),fJr=o("model_type"),mJr=o(` property of the config object (either
passed as an argument or loaded from `),Z3e=a("code"),gJr=o("pretrained_model_name_or_path"),hJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e0e=a("code"),pJr=o("pretrained_model_name_or_path"),_Jr=o(":"),uJr=l(),o0e=a("ul"),H0=a("li"),r0e=a("strong"),bJr=o("bert"),vJr=o(" \u2014 "),ioe=a("a"),FJr=o("FlaxBertForNextSentencePrediction"),TJr=o(" (BERT model)"),MJr=l(),F(U0.$$.fragment),DVe=l(),vf=a("h2"),J0=a("a"),t0e=a("span"),F(y$.$$.fragment),EJr=l(),a0e=a("span"),CJr=o("FlaxAutoModelForImageClassification"),GVe=l(),Cr=a("div"),F(x$.$$.fragment),wJr=l(),Ff=a("p"),AJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=a("a"),LJr=o("from_pretrained()"),yJr=o(" class method or the "),coe=a("a"),xJr=o("from_config()"),$Jr=o(` class
method.`),kJr=l(),$$=a("p"),SJr=o("This class cannot be instantiated directly using "),n0e=a("code"),RJr=o("__init__()"),PJr=o(" (throws an error)."),BJr=l(),ea=a("div"),F(k$.$$.fragment),IJr=l(),s0e=a("p"),NJr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qJr=l(),Tf=a("p"),jJr=o(`Note:
Loading a model from its configuration file does `),l0e=a("strong"),DJr=o("not"),GJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),OJr=o("from_pretrained()"),VJr=o(" to load the model weights."),XJr=l(),F(Y0.$$.fragment),zJr=l(),Kr=a("div"),F(S$.$$.fragment),QJr=l(),i0e=a("p"),WJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),HJr=l(),$n=a("p"),UJr=o("The model class to instantiate is selected based on the "),d0e=a("code"),JJr=o("model_type"),YJr=o(` property of the config object (either
passed as an argument or loaded from `),c0e=a("code"),KJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f0e=a("code"),eYr=o("pretrained_model_name_or_path"),oYr=o(":"),rYr=l(),R$=a("ul"),K0=a("li"),m0e=a("strong"),tYr=o("beit"),aYr=o(" \u2014 "),moe=a("a"),nYr=o("FlaxBeitForImageClassification"),sYr=o(" (BEiT model)"),lYr=l(),Z0=a("li"),g0e=a("strong"),iYr=o("vit"),dYr=o(" \u2014 "),goe=a("a"),cYr=o("FlaxViTForImageClassification"),fYr=o(" (ViT model)"),mYr=l(),F(ew.$$.fragment),OVe=l(),Mf=a("h2"),ow=a("a"),h0e=a("span"),F(P$.$$.fragment),gYr=l(),p0e=a("span"),hYr=o("FlaxAutoModelForVision2Seq"),VVe=l(),wr=a("div"),F(B$.$$.fragment),pYr=l(),Ef=a("p"),_Yr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=a("a"),uYr=o("from_pretrained()"),bYr=o(" class method or the "),poe=a("a"),vYr=o("from_config()"),FYr=o(` class
method.`),TYr=l(),I$=a("p"),MYr=o("This class cannot be instantiated directly using "),_0e=a("code"),EYr=o("__init__()"),CYr=o(" (throws an error)."),wYr=l(),oa=a("div"),F(N$.$$.fragment),AYr=l(),u0e=a("p"),LYr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yYr=l(),Cf=a("p"),xYr=o(`Note:
Loading a model from its configuration file does `),b0e=a("strong"),$Yr=o("not"),kYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),SYr=o("from_pretrained()"),RYr=o(" to load the model weights."),PYr=l(),F(rw.$$.fragment),BYr=l(),Zr=a("div"),F(q$.$$.fragment),IYr=l(),v0e=a("p"),NYr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qYr=l(),kn=a("p"),jYr=o("The model class to instantiate is selected based on the "),F0e=a("code"),DYr=o("model_type"),GYr=o(` property of the config object (either
passed as an argument or loaded from `),T0e=a("code"),OYr=o("pretrained_model_name_or_path"),VYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M0e=a("code"),XYr=o("pretrained_model_name_or_path"),zYr=o(":"),QYr=l(),E0e=a("ul"),tw=a("li"),C0e=a("strong"),WYr=o("vision-encoder-decoder"),HYr=o(" \u2014 "),uoe=a("a"),UYr=o("FlaxVisionEncoderDecoderModel"),JYr=o(" (Vision Encoder decoder model)"),YYr=l(),F(aw.$$.fragment),this.h()},l(f){const u=MDt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var j$=s(p);m=n(j$,"A",{id:!0,class:!0,href:!0});var w0e=s(m);_=n(w0e,"SPAN",{});var A0e=s(_);T(d.$$.fragment,A0e),A0e.forEach(t),w0e.forEach(t),h=i(j$),Eo=n(j$,"SPAN",{});var L0e=s(Eo);Ti=r(L0e,"Auto Classes"),L0e.forEach(t),j$.forEach(t),yf=i(f),at=n(f,"P",{});var D$=s(at);Mi=r(D$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(D$,"CODE",{});var y0e=s(Ei);wL=r(y0e,"from_pretrained()"),y0e.forEach(t),xf=r(D$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),D$.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Sn=s(Qe);Ci=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var x0e=s(Rn);AL=r(x0e,"AutoConfig"),x0e.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var $0e=s(Bn);LL=r($0e,"AutoModel"),$0e.forEach(t),wi=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var k0e=s(In);yL=r(k0e,"AutoTokenizer"),k0e.forEach(t),Ai=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),$f=i(f),T(xa.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var G$=s(Ae);rS=r(G$,"will create a model that is an instance of "),Li=n(G$,"A",{href:!0});var S0e=s(Li);tS=r(S0e,"BertModel"),S0e.forEach(t),aS=r(G$,"."),G$.forEach(t),Co=i(f),$a=n(f,"P",{});var O$=s($a);nS=r(O$,"There is one class of "),kf=n(O$,"CODE",{});var R0e=s(kf);sS=r(R0e,"AutoModel"),R0e.forEach(t),eQe=r(O$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),O$.forEach(t),jGe=i(f),yi=n(f,"H2",{class:!0});var V$=s(yi);Sf=n(V$,"A",{id:!0,class:!0,href:!0});var P0e=s(Sf);mte=n(P0e,"SPAN",{});var B0e=s(mte);T(xL.$$.fragment,B0e),B0e.forEach(t),P0e.forEach(t),oQe=i(V$),gte=n(V$,"SPAN",{});var I0e=s(gte);rQe=r(I0e,"Extending the Auto Classes"),I0e.forEach(t),V$.forEach(t),DGe=i(f),Nn=n(f,"P",{});var wf=s(Nn);tQe=r(wf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=n(wf,"CODE",{});var N0e=s(hte);aQe=r(N0e,"NewModel"),N0e.forEach(t),nQe=r(wf,", make sure you have a "),pte=n(wf,"CODE",{});var q0e=s(pte);sQe=r(q0e,"NewModelConfig"),q0e.forEach(t),lQe=r(wf,` then you can add those to the auto
classes like this:`),wf.forEach(t),GGe=i(f),T($L.$$.fragment,f),OGe=i(f),lS=n(f,"P",{});var j0e=s(lS);iQe=r(j0e,"You will then be able to use the auto classes like you would usually do!"),j0e.forEach(t),VGe=i(f),T(Rf.$$.fragment,f),XGe=i(f),xi=n(f,"H2",{class:!0});var X$=s(xi);Pf=n(X$,"A",{id:!0,class:!0,href:!0});var D0e=s(Pf);_te=n(D0e,"SPAN",{});var G0e=s(_te);T(kL.$$.fragment,G0e),G0e.forEach(t),D0e.forEach(t),dQe=i(X$),ute=n(X$,"SPAN",{});var O0e=s(ute);cQe=r(O0e,"AutoConfig"),O0e.forEach(t),X$.forEach(t),zGe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(SL.$$.fragment,rt),fQe=i(rt),RL=n(rt,"P",{});var z$=s(RL);mQe=r(z$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=n(z$,"A",{href:!0});var V0e=s(iS);gQe=r(V0e,"from_pretrained()"),V0e.forEach(t),hQe=r(z$," class method."),z$.forEach(t),pQe=i(rt),PL=n(rt,"P",{});var Q$=s(PL);_Qe=r(Q$,"This class cannot be instantiated directly using "),bte=n(Q$,"CODE",{});var X0e=s(bte);uQe=r(X0e,"__init__()"),X0e.forEach(t),bQe=r(Q$," (throws an error)."),Q$.forEach(t),vQe=i(rt),Ar=n(rt,"DIV",{class:!0});var tt=s(Ar);T(BL.$$.fragment,tt),FQe=i(tt),vte=n(tt,"P",{});var z0e=s(vte);TQe=r(z0e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),z0e.forEach(t),MQe=i(tt),$i=n(tt,"P",{});var Af=s($i);EQe=r(Af,"The configuration class to instantiate is selected based on the "),Fte=n(Af,"CODE",{});var Q0e=s(Fte);CQe=r(Q0e,"model_type"),Q0e.forEach(t),wQe=r(Af,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=n(Af,"CODE",{});var W0e=s(Tte);AQe=r(W0e,"pretrained_model_name_or_path"),W0e.forEach(t),LQe=r(Af,":"),Af.forEach(t),yQe=i(tt),A=n(tt,"UL",{});var L=s(A);Bf=n(L,"LI",{});var nw=s(Bf);Mte=n(nw,"STRONG",{});var H0e=s(Mte);xQe=r(H0e,"albert"),H0e.forEach(t),$Qe=r(nw," \u2014 "),dS=n(nw,"A",{href:!0});var U0e=s(dS);kQe=r(U0e,"AlbertConfig"),U0e.forEach(t),SQe=r(nw," (ALBERT model)"),nw.forEach(t),RQe=i(L),If=n(L,"LI",{});var sw=s(If);Ete=n(sw,"STRONG",{});var J0e=s(Ete);PQe=r(J0e,"bart"),J0e.forEach(t),BQe=r(sw," \u2014 "),cS=n(sw,"A",{href:!0});var Y0e=s(cS);IQe=r(Y0e,"BartConfig"),Y0e.forEach(t),NQe=r(sw," (BART model)"),sw.forEach(t),qQe=i(L),Nf=n(L,"LI",{});var lw=s(Nf);Cte=n(lw,"STRONG",{});var K0e=s(Cte);jQe=r(K0e,"beit"),K0e.forEach(t),DQe=r(lw," \u2014 "),fS=n(lw,"A",{href:!0});var Z0e=s(fS);GQe=r(Z0e,"BeitConfig"),Z0e.forEach(t),OQe=r(lw," (BEiT model)"),lw.forEach(t),VQe=i(L),qf=n(L,"LI",{});var iw=s(qf);wte=n(iw,"STRONG",{});var ewe=s(wte);XQe=r(ewe,"bert"),ewe.forEach(t),zQe=r(iw," \u2014 "),mS=n(iw,"A",{href:!0});var owe=s(mS);QQe=r(owe,"BertConfig"),owe.forEach(t),WQe=r(iw," (BERT model)"),iw.forEach(t),HQe=i(L),jf=n(L,"LI",{});var dw=s(jf);Ate=n(dw,"STRONG",{});var rwe=s(Ate);UQe=r(rwe,"bert-generation"),rwe.forEach(t),JQe=r(dw," \u2014 "),gS=n(dw,"A",{href:!0});var twe=s(gS);YQe=r(twe,"BertGenerationConfig"),twe.forEach(t),KQe=r(dw," (Bert Generation model)"),dw.forEach(t),ZQe=i(L),Df=n(L,"LI",{});var cw=s(Df);Lte=n(cw,"STRONG",{});var awe=s(Lte);eWe=r(awe,"big_bird"),awe.forEach(t),oWe=r(cw," \u2014 "),hS=n(cw,"A",{href:!0});var nwe=s(hS);rWe=r(nwe,"BigBirdConfig"),nwe.forEach(t),tWe=r(cw," (BigBird model)"),cw.forEach(t),aWe=i(L),Gf=n(L,"LI",{});var fw=s(Gf);yte=n(fw,"STRONG",{});var swe=s(yte);nWe=r(swe,"bigbird_pegasus"),swe.forEach(t),sWe=r(fw," \u2014 "),pS=n(fw,"A",{href:!0});var lwe=s(pS);lWe=r(lwe,"BigBirdPegasusConfig"),lwe.forEach(t),iWe=r(fw," (BigBird-Pegasus model)"),fw.forEach(t),dWe=i(L),Of=n(L,"LI",{});var mw=s(Of);xte=n(mw,"STRONG",{});var iwe=s(xte);cWe=r(iwe,"blenderbot"),iwe.forEach(t),fWe=r(mw," \u2014 "),_S=n(mw,"A",{href:!0});var dwe=s(_S);mWe=r(dwe,"BlenderbotConfig"),dwe.forEach(t),gWe=r(mw," (Blenderbot model)"),mw.forEach(t),hWe=i(L),Vf=n(L,"LI",{});var gw=s(Vf);$te=n(gw,"STRONG",{});var cwe=s($te);pWe=r(cwe,"blenderbot-small"),cwe.forEach(t),_We=r(gw," \u2014 "),uS=n(gw,"A",{href:!0});var fwe=s(uS);uWe=r(fwe,"BlenderbotSmallConfig"),fwe.forEach(t),bWe=r(gw," (BlenderbotSmall model)"),gw.forEach(t),vWe=i(L),Xf=n(L,"LI",{});var hw=s(Xf);kte=n(hw,"STRONG",{});var mwe=s(kte);FWe=r(mwe,"bloom"),mwe.forEach(t),TWe=r(hw," \u2014 "),bS=n(hw,"A",{href:!0});var gwe=s(bS);MWe=r(gwe,"BloomConfig"),gwe.forEach(t),EWe=r(hw," (BLOOM model)"),hw.forEach(t),CWe=i(L),zf=n(L,"LI",{});var pw=s(zf);Ste=n(pw,"STRONG",{});var hwe=s(Ste);wWe=r(hwe,"camembert"),hwe.forEach(t),AWe=r(pw," \u2014 "),vS=n(pw,"A",{href:!0});var pwe=s(vS);LWe=r(pwe,"CamembertConfig"),pwe.forEach(t),yWe=r(pw," (CamemBERT model)"),pw.forEach(t),xWe=i(L),Qf=n(L,"LI",{});var _w=s(Qf);Rte=n(_w,"STRONG",{});var _we=s(Rte);$We=r(_we,"canine"),_we.forEach(t),kWe=r(_w," \u2014 "),FS=n(_w,"A",{href:!0});var uwe=s(FS);SWe=r(uwe,"CanineConfig"),uwe.forEach(t),RWe=r(_w," (CANINE model)"),_w.forEach(t),PWe=i(L),Wf=n(L,"LI",{});var uw=s(Wf);Pte=n(uw,"STRONG",{});var bwe=s(Pte);BWe=r(bwe,"clip"),bwe.forEach(t),IWe=r(uw," \u2014 "),TS=n(uw,"A",{href:!0});var vwe=s(TS);NWe=r(vwe,"CLIPConfig"),vwe.forEach(t),qWe=r(uw," (CLIP model)"),uw.forEach(t),jWe=i(L),Hf=n(L,"LI",{});var bw=s(Hf);Bte=n(bw,"STRONG",{});var Fwe=s(Bte);DWe=r(Fwe,"convbert"),Fwe.forEach(t),GWe=r(bw," \u2014 "),MS=n(bw,"A",{href:!0});var Twe=s(MS);OWe=r(Twe,"ConvBertConfig"),Twe.forEach(t),VWe=r(bw," (ConvBERT model)"),bw.forEach(t),XWe=i(L),Uf=n(L,"LI",{});var vw=s(Uf);Ite=n(vw,"STRONG",{});var Mwe=s(Ite);zWe=r(Mwe,"convnext"),Mwe.forEach(t),QWe=r(vw," \u2014 "),ES=n(vw,"A",{href:!0});var Ewe=s(ES);WWe=r(Ewe,"ConvNextConfig"),Ewe.forEach(t),HWe=r(vw," (ConvNeXT model)"),vw.forEach(t),UWe=i(L),Jf=n(L,"LI",{});var Fw=s(Jf);Nte=n(Fw,"STRONG",{});var Cwe=s(Nte);JWe=r(Cwe,"ctrl"),Cwe.forEach(t),YWe=r(Fw," \u2014 "),CS=n(Fw,"A",{href:!0});var wwe=s(CS);KWe=r(wwe,"CTRLConfig"),wwe.forEach(t),ZWe=r(Fw," (CTRL model)"),Fw.forEach(t),eHe=i(L),Yf=n(L,"LI",{});var Tw=s(Yf);qte=n(Tw,"STRONG",{});var Awe=s(qte);oHe=r(Awe,"cvt"),Awe.forEach(t),rHe=r(Tw," \u2014 "),wS=n(Tw,"A",{href:!0});var Lwe=s(wS);tHe=r(Lwe,"CvtConfig"),Lwe.forEach(t),aHe=r(Tw," (CvT model)"),Tw.forEach(t),nHe=i(L),Kf=n(L,"LI",{});var Mw=s(Kf);jte=n(Mw,"STRONG",{});var ywe=s(jte);sHe=r(ywe,"data2vec-audio"),ywe.forEach(t),lHe=r(Mw," \u2014 "),AS=n(Mw,"A",{href:!0});var xwe=s(AS);iHe=r(xwe,"Data2VecAudioConfig"),xwe.forEach(t),dHe=r(Mw," (Data2VecAudio model)"),Mw.forEach(t),cHe=i(L),Zf=n(L,"LI",{});var Ew=s(Zf);Dte=n(Ew,"STRONG",{});var $we=s(Dte);fHe=r($we,"data2vec-text"),$we.forEach(t),mHe=r(Ew," \u2014 "),LS=n(Ew,"A",{href:!0});var kwe=s(LS);gHe=r(kwe,"Data2VecTextConfig"),kwe.forEach(t),hHe=r(Ew," (Data2VecText model)"),Ew.forEach(t),pHe=i(L),em=n(L,"LI",{});var Cw=s(em);Gte=n(Cw,"STRONG",{});var Swe=s(Gte);_He=r(Swe,"data2vec-vision"),Swe.forEach(t),uHe=r(Cw," \u2014 "),yS=n(Cw,"A",{href:!0});var Rwe=s(yS);bHe=r(Rwe,"Data2VecVisionConfig"),Rwe.forEach(t),vHe=r(Cw," (Data2VecVision model)"),Cw.forEach(t),FHe=i(L),om=n(L,"LI",{});var ww=s(om);Ote=n(ww,"STRONG",{});var Pwe=s(Ote);THe=r(Pwe,"deberta"),Pwe.forEach(t),MHe=r(ww," \u2014 "),xS=n(ww,"A",{href:!0});var Bwe=s(xS);EHe=r(Bwe,"DebertaConfig"),Bwe.forEach(t),CHe=r(ww," (DeBERTa model)"),ww.forEach(t),wHe=i(L),rm=n(L,"LI",{});var Aw=s(rm);Vte=n(Aw,"STRONG",{});var Iwe=s(Vte);AHe=r(Iwe,"deberta-v2"),Iwe.forEach(t),LHe=r(Aw," \u2014 "),$S=n(Aw,"A",{href:!0});var Nwe=s($S);yHe=r(Nwe,"DebertaV2Config"),Nwe.forEach(t),xHe=r(Aw," (DeBERTa-v2 model)"),Aw.forEach(t),$He=i(L),tm=n(L,"LI",{});var Lw=s(tm);Xte=n(Lw,"STRONG",{});var qwe=s(Xte);kHe=r(qwe,"decision_transformer"),qwe.forEach(t),SHe=r(Lw," \u2014 "),kS=n(Lw,"A",{href:!0});var jwe=s(kS);RHe=r(jwe,"DecisionTransformerConfig"),jwe.forEach(t),PHe=r(Lw," (Decision Transformer model)"),Lw.forEach(t),BHe=i(L),am=n(L,"LI",{});var yw=s(am);zte=n(yw,"STRONG",{});var ZYr=s(zte);IHe=r(ZYr,"deit"),ZYr.forEach(t),NHe=r(yw," \u2014 "),SS=n(yw,"A",{href:!0});var eKr=s(SS);qHe=r(eKr,"DeiTConfig"),eKr.forEach(t),jHe=r(yw," (DeiT model)"),yw.forEach(t),DHe=i(L),nm=n(L,"LI",{});var Dwe=s(nm);Qte=n(Dwe,"STRONG",{});var oKr=s(Qte);GHe=r(oKr,"detr"),oKr.forEach(t),OHe=r(Dwe," \u2014 "),RS=n(Dwe,"A",{href:!0});var rKr=s(RS);VHe=r(rKr,"DetrConfig"),rKr.forEach(t),XHe=r(Dwe," (DETR model)"),Dwe.forEach(t),zHe=i(L),sm=n(L,"LI",{});var Gwe=s(sm);Wte=n(Gwe,"STRONG",{});var tKr=s(Wte);QHe=r(tKr,"distilbert"),tKr.forEach(t),WHe=r(Gwe," \u2014 "),PS=n(Gwe,"A",{href:!0});var aKr=s(PS);HHe=r(aKr,"DistilBertConfig"),aKr.forEach(t),UHe=r(Gwe," (DistilBERT model)"),Gwe.forEach(t),JHe=i(L),lm=n(L,"LI",{});var Owe=s(lm);Hte=n(Owe,"STRONG",{});var nKr=s(Hte);YHe=r(nKr,"dpr"),nKr.forEach(t),KHe=r(Owe," \u2014 "),BS=n(Owe,"A",{href:!0});var sKr=s(BS);ZHe=r(sKr,"DPRConfig"),sKr.forEach(t),eUe=r(Owe," (DPR model)"),Owe.forEach(t),oUe=i(L),im=n(L,"LI",{});var Vwe=s(im);Ute=n(Vwe,"STRONG",{});var lKr=s(Ute);rUe=r(lKr,"dpt"),lKr.forEach(t),tUe=r(Vwe," \u2014 "),IS=n(Vwe,"A",{href:!0});var iKr=s(IS);aUe=r(iKr,"DPTConfig"),iKr.forEach(t),nUe=r(Vwe," (DPT model)"),Vwe.forEach(t),sUe=i(L),dm=n(L,"LI",{});var Xwe=s(dm);Jte=n(Xwe,"STRONG",{});var dKr=s(Jte);lUe=r(dKr,"electra"),dKr.forEach(t),iUe=r(Xwe," \u2014 "),NS=n(Xwe,"A",{href:!0});var cKr=s(NS);dUe=r(cKr,"ElectraConfig"),cKr.forEach(t),cUe=r(Xwe," (ELECTRA model)"),Xwe.forEach(t),fUe=i(L),cm=n(L,"LI",{});var zwe=s(cm);Yte=n(zwe,"STRONG",{});var fKr=s(Yte);mUe=r(fKr,"encoder-decoder"),fKr.forEach(t),gUe=r(zwe," \u2014 "),qS=n(zwe,"A",{href:!0});var mKr=s(qS);hUe=r(mKr,"EncoderDecoderConfig"),mKr.forEach(t),pUe=r(zwe," (Encoder decoder model)"),zwe.forEach(t),_Ue=i(L),fm=n(L,"LI",{});var Qwe=s(fm);Kte=n(Qwe,"STRONG",{});var gKr=s(Kte);uUe=r(gKr,"flaubert"),gKr.forEach(t),bUe=r(Qwe," \u2014 "),jS=n(Qwe,"A",{href:!0});var hKr=s(jS);vUe=r(hKr,"FlaubertConfig"),hKr.forEach(t),FUe=r(Qwe," (FlauBERT model)"),Qwe.forEach(t),TUe=i(L),mm=n(L,"LI",{});var Wwe=s(mm);Zte=n(Wwe,"STRONG",{});var pKr=s(Zte);MUe=r(pKr,"flava"),pKr.forEach(t),EUe=r(Wwe," \u2014 "),DS=n(Wwe,"A",{href:!0});var _Kr=s(DS);CUe=r(_Kr,"FlavaConfig"),_Kr.forEach(t),wUe=r(Wwe," (FLAVA model)"),Wwe.forEach(t),AUe=i(L),gm=n(L,"LI",{});var Hwe=s(gm);eae=n(Hwe,"STRONG",{});var uKr=s(eae);LUe=r(uKr,"fnet"),uKr.forEach(t),yUe=r(Hwe," \u2014 "),GS=n(Hwe,"A",{href:!0});var bKr=s(GS);xUe=r(bKr,"FNetConfig"),bKr.forEach(t),$Ue=r(Hwe," (FNet model)"),Hwe.forEach(t),kUe=i(L),hm=n(L,"LI",{});var Uwe=s(hm);oae=n(Uwe,"STRONG",{});var vKr=s(oae);SUe=r(vKr,"fsmt"),vKr.forEach(t),RUe=r(Uwe," \u2014 "),OS=n(Uwe,"A",{href:!0});var FKr=s(OS);PUe=r(FKr,"FSMTConfig"),FKr.forEach(t),BUe=r(Uwe," (FairSeq Machine-Translation model)"),Uwe.forEach(t),IUe=i(L),pm=n(L,"LI",{});var Jwe=s(pm);rae=n(Jwe,"STRONG",{});var TKr=s(rae);NUe=r(TKr,"funnel"),TKr.forEach(t),qUe=r(Jwe," \u2014 "),VS=n(Jwe,"A",{href:!0});var MKr=s(VS);jUe=r(MKr,"FunnelConfig"),MKr.forEach(t),DUe=r(Jwe," (Funnel Transformer model)"),Jwe.forEach(t),GUe=i(L),_m=n(L,"LI",{});var Ywe=s(_m);tae=n(Ywe,"STRONG",{});var EKr=s(tae);OUe=r(EKr,"glpn"),EKr.forEach(t),VUe=r(Ywe," \u2014 "),XS=n(Ywe,"A",{href:!0});var CKr=s(XS);XUe=r(CKr,"GLPNConfig"),CKr.forEach(t),zUe=r(Ywe," (GLPN model)"),Ywe.forEach(t),QUe=i(L),um=n(L,"LI",{});var Kwe=s(um);aae=n(Kwe,"STRONG",{});var wKr=s(aae);WUe=r(wKr,"gpt2"),wKr.forEach(t),HUe=r(Kwe," \u2014 "),zS=n(Kwe,"A",{href:!0});var AKr=s(zS);UUe=r(AKr,"GPT2Config"),AKr.forEach(t),JUe=r(Kwe," (OpenAI GPT-2 model)"),Kwe.forEach(t),YUe=i(L),bm=n(L,"LI",{});var Zwe=s(bm);nae=n(Zwe,"STRONG",{});var LKr=s(nae);KUe=r(LKr,"gpt_neo"),LKr.forEach(t),ZUe=r(Zwe," \u2014 "),QS=n(Zwe,"A",{href:!0});var yKr=s(QS);eJe=r(yKr,"GPTNeoConfig"),yKr.forEach(t),oJe=r(Zwe," (GPT Neo model)"),Zwe.forEach(t),rJe=i(L),vm=n(L,"LI",{});var eAe=s(vm);sae=n(eAe,"STRONG",{});var xKr=s(sae);tJe=r(xKr,"gpt_neox"),xKr.forEach(t),aJe=r(eAe," \u2014 "),WS=n(eAe,"A",{href:!0});var $Kr=s(WS);nJe=r($Kr,"GPTNeoXConfig"),$Kr.forEach(t),sJe=r(eAe," (GPT NeoX model)"),eAe.forEach(t),lJe=i(L),Fm=n(L,"LI",{});var oAe=s(Fm);lae=n(oAe,"STRONG",{});var kKr=s(lae);iJe=r(kKr,"gptj"),kKr.forEach(t),dJe=r(oAe," \u2014 "),HS=n(oAe,"A",{href:!0});var SKr=s(HS);cJe=r(SKr,"GPTJConfig"),SKr.forEach(t),fJe=r(oAe," (GPT-J model)"),oAe.forEach(t),mJe=i(L),Tm=n(L,"LI",{});var rAe=s(Tm);iae=n(rAe,"STRONG",{});var RKr=s(iae);gJe=r(RKr,"hubert"),RKr.forEach(t),hJe=r(rAe," \u2014 "),US=n(rAe,"A",{href:!0});var PKr=s(US);pJe=r(PKr,"HubertConfig"),PKr.forEach(t),_Je=r(rAe," (Hubert model)"),rAe.forEach(t),uJe=i(L),Mm=n(L,"LI",{});var tAe=s(Mm);dae=n(tAe,"STRONG",{});var BKr=s(dae);bJe=r(BKr,"ibert"),BKr.forEach(t),vJe=r(tAe," \u2014 "),JS=n(tAe,"A",{href:!0});var IKr=s(JS);FJe=r(IKr,"IBertConfig"),IKr.forEach(t),TJe=r(tAe," (I-BERT model)"),tAe.forEach(t),MJe=i(L),Em=n(L,"LI",{});var aAe=s(Em);cae=n(aAe,"STRONG",{});var NKr=s(cae);EJe=r(NKr,"imagegpt"),NKr.forEach(t),CJe=r(aAe," \u2014 "),YS=n(aAe,"A",{href:!0});var qKr=s(YS);wJe=r(qKr,"ImageGPTConfig"),qKr.forEach(t),AJe=r(aAe," (ImageGPT model)"),aAe.forEach(t),LJe=i(L),Cm=n(L,"LI",{});var nAe=s(Cm);fae=n(nAe,"STRONG",{});var jKr=s(fae);yJe=r(jKr,"layoutlm"),jKr.forEach(t),xJe=r(nAe," \u2014 "),KS=n(nAe,"A",{href:!0});var DKr=s(KS);$Je=r(DKr,"LayoutLMConfig"),DKr.forEach(t),kJe=r(nAe," (LayoutLM model)"),nAe.forEach(t),SJe=i(L),wm=n(L,"LI",{});var sAe=s(wm);mae=n(sAe,"STRONG",{});var GKr=s(mae);RJe=r(GKr,"layoutlmv2"),GKr.forEach(t),PJe=r(sAe," \u2014 "),ZS=n(sAe,"A",{href:!0});var OKr=s(ZS);BJe=r(OKr,"LayoutLMv2Config"),OKr.forEach(t),IJe=r(sAe," (LayoutLMv2 model)"),sAe.forEach(t),NJe=i(L),Am=n(L,"LI",{});var lAe=s(Am);gae=n(lAe,"STRONG",{});var VKr=s(gae);qJe=r(VKr,"layoutlmv3"),VKr.forEach(t),jJe=r(lAe," \u2014 "),eR=n(lAe,"A",{href:!0});var XKr=s(eR);DJe=r(XKr,"LayoutLMv3Config"),XKr.forEach(t),GJe=r(lAe," (LayoutLMv3 model)"),lAe.forEach(t),OJe=i(L),Lm=n(L,"LI",{});var iAe=s(Lm);hae=n(iAe,"STRONG",{});var zKr=s(hae);VJe=r(zKr,"led"),zKr.forEach(t),XJe=r(iAe," \u2014 "),oR=n(iAe,"A",{href:!0});var QKr=s(oR);zJe=r(QKr,"LEDConfig"),QKr.forEach(t),QJe=r(iAe," (LED model)"),iAe.forEach(t),WJe=i(L),ym=n(L,"LI",{});var dAe=s(ym);pae=n(dAe,"STRONG",{});var WKr=s(pae);HJe=r(WKr,"levit"),WKr.forEach(t),UJe=r(dAe," \u2014 "),rR=n(dAe,"A",{href:!0});var HKr=s(rR);JJe=r(HKr,"LevitConfig"),HKr.forEach(t),YJe=r(dAe," (LeViT model)"),dAe.forEach(t),KJe=i(L),xm=n(L,"LI",{});var cAe=s(xm);_ae=n(cAe,"STRONG",{});var UKr=s(_ae);ZJe=r(UKr,"longformer"),UKr.forEach(t),eYe=r(cAe," \u2014 "),tR=n(cAe,"A",{href:!0});var JKr=s(tR);oYe=r(JKr,"LongformerConfig"),JKr.forEach(t),rYe=r(cAe," (Longformer model)"),cAe.forEach(t),tYe=i(L),$m=n(L,"LI",{});var fAe=s($m);uae=n(fAe,"STRONG",{});var YKr=s(uae);aYe=r(YKr,"longt5"),YKr.forEach(t),nYe=r(fAe," \u2014 "),aR=n(fAe,"A",{href:!0});var KKr=s(aR);sYe=r(KKr,"LongT5Config"),KKr.forEach(t),lYe=r(fAe," (LongT5 model)"),fAe.forEach(t),iYe=i(L),km=n(L,"LI",{});var mAe=s(km);bae=n(mAe,"STRONG",{});var ZKr=s(bae);dYe=r(ZKr,"luke"),ZKr.forEach(t),cYe=r(mAe," \u2014 "),nR=n(mAe,"A",{href:!0});var eZr=s(nR);fYe=r(eZr,"LukeConfig"),eZr.forEach(t),mYe=r(mAe," (LUKE model)"),mAe.forEach(t),gYe=i(L),Sm=n(L,"LI",{});var gAe=s(Sm);vae=n(gAe,"STRONG",{});var oZr=s(vae);hYe=r(oZr,"lxmert"),oZr.forEach(t),pYe=r(gAe," \u2014 "),sR=n(gAe,"A",{href:!0});var rZr=s(sR);_Ye=r(rZr,"LxmertConfig"),rZr.forEach(t),uYe=r(gAe," (LXMERT model)"),gAe.forEach(t),bYe=i(L),Rm=n(L,"LI",{});var hAe=s(Rm);Fae=n(hAe,"STRONG",{});var tZr=s(Fae);vYe=r(tZr,"m2m_100"),tZr.forEach(t),FYe=r(hAe," \u2014 "),lR=n(hAe,"A",{href:!0});var aZr=s(lR);TYe=r(aZr,"M2M100Config"),aZr.forEach(t),MYe=r(hAe," (M2M100 model)"),hAe.forEach(t),EYe=i(L),Pm=n(L,"LI",{});var pAe=s(Pm);Tae=n(pAe,"STRONG",{});var nZr=s(Tae);CYe=r(nZr,"marian"),nZr.forEach(t),wYe=r(pAe," \u2014 "),iR=n(pAe,"A",{href:!0});var sZr=s(iR);AYe=r(sZr,"MarianConfig"),sZr.forEach(t),LYe=r(pAe," (Marian model)"),pAe.forEach(t),yYe=i(L),Bm=n(L,"LI",{});var _Ae=s(Bm);Mae=n(_Ae,"STRONG",{});var lZr=s(Mae);xYe=r(lZr,"maskformer"),lZr.forEach(t),$Ye=r(_Ae," \u2014 "),dR=n(_Ae,"A",{href:!0});var iZr=s(dR);kYe=r(iZr,"MaskFormerConfig"),iZr.forEach(t),SYe=r(_Ae," (MaskFormer model)"),_Ae.forEach(t),RYe=i(L),Im=n(L,"LI",{});var uAe=s(Im);Eae=n(uAe,"STRONG",{});var dZr=s(Eae);PYe=r(dZr,"mbart"),dZr.forEach(t),BYe=r(uAe," \u2014 "),cR=n(uAe,"A",{href:!0});var cZr=s(cR);IYe=r(cZr,"MBartConfig"),cZr.forEach(t),NYe=r(uAe," (mBART model)"),uAe.forEach(t),qYe=i(L),Nm=n(L,"LI",{});var bAe=s(Nm);Cae=n(bAe,"STRONG",{});var fZr=s(Cae);jYe=r(fZr,"mctct"),fZr.forEach(t),DYe=r(bAe," \u2014 "),fR=n(bAe,"A",{href:!0});var mZr=s(fR);GYe=r(mZr,"MCTCTConfig"),mZr.forEach(t),OYe=r(bAe," (M-CTC-T model)"),bAe.forEach(t),VYe=i(L),qm=n(L,"LI",{});var vAe=s(qm);wae=n(vAe,"STRONG",{});var gZr=s(wae);XYe=r(gZr,"megatron-bert"),gZr.forEach(t),zYe=r(vAe," \u2014 "),mR=n(vAe,"A",{href:!0});var hZr=s(mR);QYe=r(hZr,"MegatronBertConfig"),hZr.forEach(t),WYe=r(vAe," (Megatron-BERT model)"),vAe.forEach(t),HYe=i(L),jm=n(L,"LI",{});var FAe=s(jm);Aae=n(FAe,"STRONG",{});var pZr=s(Aae);UYe=r(pZr,"mobilebert"),pZr.forEach(t),JYe=r(FAe," \u2014 "),gR=n(FAe,"A",{href:!0});var _Zr=s(gR);YYe=r(_Zr,"MobileBertConfig"),_Zr.forEach(t),KYe=r(FAe," (MobileBERT model)"),FAe.forEach(t),ZYe=i(L),Dm=n(L,"LI",{});var TAe=s(Dm);Lae=n(TAe,"STRONG",{});var uZr=s(Lae);eKe=r(uZr,"mpnet"),uZr.forEach(t),oKe=r(TAe," \u2014 "),hR=n(TAe,"A",{href:!0});var bZr=s(hR);rKe=r(bZr,"MPNetConfig"),bZr.forEach(t),tKe=r(TAe," (MPNet model)"),TAe.forEach(t),aKe=i(L),Gm=n(L,"LI",{});var MAe=s(Gm);yae=n(MAe,"STRONG",{});var vZr=s(yae);nKe=r(vZr,"mt5"),vZr.forEach(t),sKe=r(MAe," \u2014 "),pR=n(MAe,"A",{href:!0});var FZr=s(pR);lKe=r(FZr,"MT5Config"),FZr.forEach(t),iKe=r(MAe," (MT5 model)"),MAe.forEach(t),dKe=i(L),Om=n(L,"LI",{});var EAe=s(Om);xae=n(EAe,"STRONG",{});var TZr=s(xae);cKe=r(TZr,"nezha"),TZr.forEach(t),fKe=r(EAe," \u2014 "),_R=n(EAe,"A",{href:!0});var MZr=s(_R);mKe=r(MZr,"NezhaConfig"),MZr.forEach(t),gKe=r(EAe," (Nezha model)"),EAe.forEach(t),hKe=i(L),Vm=n(L,"LI",{});var CAe=s(Vm);$ae=n(CAe,"STRONG",{});var EZr=s($ae);pKe=r(EZr,"nystromformer"),EZr.forEach(t),_Ke=r(CAe," \u2014 "),uR=n(CAe,"A",{href:!0});var CZr=s(uR);uKe=r(CZr,"NystromformerConfig"),CZr.forEach(t),bKe=r(CAe," (Nystr\xF6mformer model)"),CAe.forEach(t),vKe=i(L),Xm=n(L,"LI",{});var wAe=s(Xm);kae=n(wAe,"STRONG",{});var wZr=s(kae);FKe=r(wZr,"openai-gpt"),wZr.forEach(t),TKe=r(wAe," \u2014 "),bR=n(wAe,"A",{href:!0});var AZr=s(bR);MKe=r(AZr,"OpenAIGPTConfig"),AZr.forEach(t),EKe=r(wAe," (OpenAI GPT model)"),wAe.forEach(t),CKe=i(L),zm=n(L,"LI",{});var AAe=s(zm);Sae=n(AAe,"STRONG",{});var LZr=s(Sae);wKe=r(LZr,"opt"),LZr.forEach(t),AKe=r(AAe," \u2014 "),vR=n(AAe,"A",{href:!0});var yZr=s(vR);LKe=r(yZr,"OPTConfig"),yZr.forEach(t),yKe=r(AAe," (OPT model)"),AAe.forEach(t),xKe=i(L),Qm=n(L,"LI",{});var LAe=s(Qm);Rae=n(LAe,"STRONG",{});var xZr=s(Rae);$Ke=r(xZr,"pegasus"),xZr.forEach(t),kKe=r(LAe," \u2014 "),FR=n(LAe,"A",{href:!0});var $Zr=s(FR);SKe=r($Zr,"PegasusConfig"),$Zr.forEach(t),RKe=r(LAe," (Pegasus model)"),LAe.forEach(t),PKe=i(L),Wm=n(L,"LI",{});var yAe=s(Wm);Pae=n(yAe,"STRONG",{});var kZr=s(Pae);BKe=r(kZr,"perceiver"),kZr.forEach(t),IKe=r(yAe," \u2014 "),TR=n(yAe,"A",{href:!0});var SZr=s(TR);NKe=r(SZr,"PerceiverConfig"),SZr.forEach(t),qKe=r(yAe," (Perceiver model)"),yAe.forEach(t),jKe=i(L),Hm=n(L,"LI",{});var xAe=s(Hm);Bae=n(xAe,"STRONG",{});var RZr=s(Bae);DKe=r(RZr,"plbart"),RZr.forEach(t),GKe=r(xAe," \u2014 "),MR=n(xAe,"A",{href:!0});var PZr=s(MR);OKe=r(PZr,"PLBartConfig"),PZr.forEach(t),VKe=r(xAe," (PLBart model)"),xAe.forEach(t),XKe=i(L),Um=n(L,"LI",{});var $Ae=s(Um);Iae=n($Ae,"STRONG",{});var BZr=s(Iae);zKe=r(BZr,"poolformer"),BZr.forEach(t),QKe=r($Ae," \u2014 "),ER=n($Ae,"A",{href:!0});var IZr=s(ER);WKe=r(IZr,"PoolFormerConfig"),IZr.forEach(t),HKe=r($Ae," (PoolFormer model)"),$Ae.forEach(t),UKe=i(L),Jm=n(L,"LI",{});var kAe=s(Jm);Nae=n(kAe,"STRONG",{});var NZr=s(Nae);JKe=r(NZr,"prophetnet"),NZr.forEach(t),YKe=r(kAe," \u2014 "),CR=n(kAe,"A",{href:!0});var qZr=s(CR);KKe=r(qZr,"ProphetNetConfig"),qZr.forEach(t),ZKe=r(kAe," (ProphetNet model)"),kAe.forEach(t),eZe=i(L),Ym=n(L,"LI",{});var SAe=s(Ym);qae=n(SAe,"STRONG",{});var jZr=s(qae);oZe=r(jZr,"qdqbert"),jZr.forEach(t),rZe=r(SAe," \u2014 "),wR=n(SAe,"A",{href:!0});var DZr=s(wR);tZe=r(DZr,"QDQBertConfig"),DZr.forEach(t),aZe=r(SAe," (QDQBert model)"),SAe.forEach(t),nZe=i(L),Km=n(L,"LI",{});var RAe=s(Km);jae=n(RAe,"STRONG",{});var GZr=s(jae);sZe=r(GZr,"rag"),GZr.forEach(t),lZe=r(RAe," \u2014 "),AR=n(RAe,"A",{href:!0});var OZr=s(AR);iZe=r(OZr,"RagConfig"),OZr.forEach(t),dZe=r(RAe," (RAG model)"),RAe.forEach(t),cZe=i(L),Zm=n(L,"LI",{});var PAe=s(Zm);Dae=n(PAe,"STRONG",{});var VZr=s(Dae);fZe=r(VZr,"realm"),VZr.forEach(t),mZe=r(PAe," \u2014 "),LR=n(PAe,"A",{href:!0});var XZr=s(LR);gZe=r(XZr,"RealmConfig"),XZr.forEach(t),hZe=r(PAe," (REALM model)"),PAe.forEach(t),pZe=i(L),eg=n(L,"LI",{});var BAe=s(eg);Gae=n(BAe,"STRONG",{});var zZr=s(Gae);_Ze=r(zZr,"reformer"),zZr.forEach(t),uZe=r(BAe," \u2014 "),yR=n(BAe,"A",{href:!0});var QZr=s(yR);bZe=r(QZr,"ReformerConfig"),QZr.forEach(t),vZe=r(BAe," (Reformer model)"),BAe.forEach(t),FZe=i(L),og=n(L,"LI",{});var IAe=s(og);Oae=n(IAe,"STRONG",{});var WZr=s(Oae);TZe=r(WZr,"regnet"),WZr.forEach(t),MZe=r(IAe," \u2014 "),xR=n(IAe,"A",{href:!0});var HZr=s(xR);EZe=r(HZr,"RegNetConfig"),HZr.forEach(t),CZe=r(IAe," (RegNet model)"),IAe.forEach(t),wZe=i(L),rg=n(L,"LI",{});var NAe=s(rg);Vae=n(NAe,"STRONG",{});var UZr=s(Vae);AZe=r(UZr,"rembert"),UZr.forEach(t),LZe=r(NAe," \u2014 "),$R=n(NAe,"A",{href:!0});var JZr=s($R);yZe=r(JZr,"RemBertConfig"),JZr.forEach(t),xZe=r(NAe," (RemBERT model)"),NAe.forEach(t),$Ze=i(L),tg=n(L,"LI",{});var qAe=s(tg);Xae=n(qAe,"STRONG",{});var YZr=s(Xae);kZe=r(YZr,"resnet"),YZr.forEach(t),SZe=r(qAe," \u2014 "),kR=n(qAe,"A",{href:!0});var KZr=s(kR);RZe=r(KZr,"ResNetConfig"),KZr.forEach(t),PZe=r(qAe," (ResNet model)"),qAe.forEach(t),BZe=i(L),ag=n(L,"LI",{});var jAe=s(ag);zae=n(jAe,"STRONG",{});var ZZr=s(zae);IZe=r(ZZr,"retribert"),ZZr.forEach(t),NZe=r(jAe," \u2014 "),SR=n(jAe,"A",{href:!0});var eet=s(SR);qZe=r(eet,"RetriBertConfig"),eet.forEach(t),jZe=r(jAe," (RetriBERT model)"),jAe.forEach(t),DZe=i(L),ng=n(L,"LI",{});var DAe=s(ng);Qae=n(DAe,"STRONG",{});var oet=s(Qae);GZe=r(oet,"roberta"),oet.forEach(t),OZe=r(DAe," \u2014 "),RR=n(DAe,"A",{href:!0});var ret=s(RR);VZe=r(ret,"RobertaConfig"),ret.forEach(t),XZe=r(DAe," (RoBERTa model)"),DAe.forEach(t),zZe=i(L),sg=n(L,"LI",{});var GAe=s(sg);Wae=n(GAe,"STRONG",{});var tet=s(Wae);QZe=r(tet,"roformer"),tet.forEach(t),WZe=r(GAe," \u2014 "),PR=n(GAe,"A",{href:!0});var aet=s(PR);HZe=r(aet,"RoFormerConfig"),aet.forEach(t),UZe=r(GAe," (RoFormer model)"),GAe.forEach(t),JZe=i(L),lg=n(L,"LI",{});var OAe=s(lg);Hae=n(OAe,"STRONG",{});var net=s(Hae);YZe=r(net,"segformer"),net.forEach(t),KZe=r(OAe," \u2014 "),BR=n(OAe,"A",{href:!0});var set=s(BR);ZZe=r(set,"SegformerConfig"),set.forEach(t),eeo=r(OAe," (SegFormer model)"),OAe.forEach(t),oeo=i(L),ig=n(L,"LI",{});var VAe=s(ig);Uae=n(VAe,"STRONG",{});var iet=s(Uae);reo=r(iet,"sew"),iet.forEach(t),teo=r(VAe," \u2014 "),IR=n(VAe,"A",{href:!0});var det=s(IR);aeo=r(det,"SEWConfig"),det.forEach(t),neo=r(VAe," (SEW model)"),VAe.forEach(t),seo=i(L),dg=n(L,"LI",{});var XAe=s(dg);Jae=n(XAe,"STRONG",{});var cet=s(Jae);leo=r(cet,"sew-d"),cet.forEach(t),ieo=r(XAe," \u2014 "),NR=n(XAe,"A",{href:!0});var fet=s(NR);deo=r(fet,"SEWDConfig"),fet.forEach(t),ceo=r(XAe," (SEW-D model)"),XAe.forEach(t),feo=i(L),cg=n(L,"LI",{});var zAe=s(cg);Yae=n(zAe,"STRONG",{});var met=s(Yae);meo=r(met,"speech-encoder-decoder"),met.forEach(t),geo=r(zAe," \u2014 "),qR=n(zAe,"A",{href:!0});var get=s(qR);heo=r(get,"SpeechEncoderDecoderConfig"),get.forEach(t),peo=r(zAe," (Speech Encoder decoder model)"),zAe.forEach(t),_eo=i(L),fg=n(L,"LI",{});var QAe=s(fg);Kae=n(QAe,"STRONG",{});var het=s(Kae);ueo=r(het,"speech_to_text"),het.forEach(t),beo=r(QAe," \u2014 "),jR=n(QAe,"A",{href:!0});var pet=s(jR);veo=r(pet,"Speech2TextConfig"),pet.forEach(t),Feo=r(QAe," (Speech2Text model)"),QAe.forEach(t),Teo=i(L),mg=n(L,"LI",{});var WAe=s(mg);Zae=n(WAe,"STRONG",{});var _et=s(Zae);Meo=r(_et,"speech_to_text_2"),_et.forEach(t),Eeo=r(WAe," \u2014 "),DR=n(WAe,"A",{href:!0});var uet=s(DR);Ceo=r(uet,"Speech2Text2Config"),uet.forEach(t),weo=r(WAe," (Speech2Text2 model)"),WAe.forEach(t),Aeo=i(L),gg=n(L,"LI",{});var HAe=s(gg);ene=n(HAe,"STRONG",{});var bet=s(ene);Leo=r(bet,"splinter"),bet.forEach(t),yeo=r(HAe," \u2014 "),GR=n(HAe,"A",{href:!0});var vet=s(GR);xeo=r(vet,"SplinterConfig"),vet.forEach(t),$eo=r(HAe," (Splinter model)"),HAe.forEach(t),keo=i(L),hg=n(L,"LI",{});var UAe=s(hg);one=n(UAe,"STRONG",{});var Fet=s(one);Seo=r(Fet,"squeezebert"),Fet.forEach(t),Reo=r(UAe," \u2014 "),OR=n(UAe,"A",{href:!0});var Tet=s(OR);Peo=r(Tet,"SqueezeBertConfig"),Tet.forEach(t),Beo=r(UAe," (SqueezeBERT model)"),UAe.forEach(t),Ieo=i(L),pg=n(L,"LI",{});var JAe=s(pg);rne=n(JAe,"STRONG",{});var Met=s(rne);Neo=r(Met,"swin"),Met.forEach(t),qeo=r(JAe," \u2014 "),VR=n(JAe,"A",{href:!0});var Eet=s(VR);jeo=r(Eet,"SwinConfig"),Eet.forEach(t),Deo=r(JAe," (Swin Transformer model)"),JAe.forEach(t),Geo=i(L),_g=n(L,"LI",{});var YAe=s(_g);tne=n(YAe,"STRONG",{});var Cet=s(tne);Oeo=r(Cet,"t5"),Cet.forEach(t),Veo=r(YAe," \u2014 "),XR=n(YAe,"A",{href:!0});var wet=s(XR);Xeo=r(wet,"T5Config"),wet.forEach(t),zeo=r(YAe," (T5 model)"),YAe.forEach(t),Qeo=i(L),ug=n(L,"LI",{});var KAe=s(ug);ane=n(KAe,"STRONG",{});var Aet=s(ane);Weo=r(Aet,"tapas"),Aet.forEach(t),Heo=r(KAe," \u2014 "),zR=n(KAe,"A",{href:!0});var Let=s(zR);Ueo=r(Let,"TapasConfig"),Let.forEach(t),Jeo=r(KAe," (TAPAS model)"),KAe.forEach(t),Yeo=i(L),bg=n(L,"LI",{});var ZAe=s(bg);nne=n(ZAe,"STRONG",{});var yet=s(nne);Keo=r(yet,"trajectory_transformer"),yet.forEach(t),Zeo=r(ZAe," \u2014 "),QR=n(ZAe,"A",{href:!0});var xet=s(QR);eoo=r(xet,"TrajectoryTransformerConfig"),xet.forEach(t),ooo=r(ZAe," (Trajectory Transformer model)"),ZAe.forEach(t),roo=i(L),vg=n(L,"LI",{});var eLe=s(vg);sne=n(eLe,"STRONG",{});var $et=s(sne);too=r($et,"transfo-xl"),$et.forEach(t),aoo=r(eLe," \u2014 "),WR=n(eLe,"A",{href:!0});var ket=s(WR);noo=r(ket,"TransfoXLConfig"),ket.forEach(t),soo=r(eLe," (Transformer-XL model)"),eLe.forEach(t),loo=i(L),Fg=n(L,"LI",{});var oLe=s(Fg);lne=n(oLe,"STRONG",{});var Set=s(lne);ioo=r(Set,"trocr"),Set.forEach(t),doo=r(oLe," \u2014 "),HR=n(oLe,"A",{href:!0});var Ret=s(HR);coo=r(Ret,"TrOCRConfig"),Ret.forEach(t),foo=r(oLe," (TrOCR model)"),oLe.forEach(t),moo=i(L),Tg=n(L,"LI",{});var rLe=s(Tg);ine=n(rLe,"STRONG",{});var Pet=s(ine);goo=r(Pet,"unispeech"),Pet.forEach(t),hoo=r(rLe," \u2014 "),UR=n(rLe,"A",{href:!0});var Bet=s(UR);poo=r(Bet,"UniSpeechConfig"),Bet.forEach(t),_oo=r(rLe," (UniSpeech model)"),rLe.forEach(t),uoo=i(L),Mg=n(L,"LI",{});var tLe=s(Mg);dne=n(tLe,"STRONG",{});var Iet=s(dne);boo=r(Iet,"unispeech-sat"),Iet.forEach(t),voo=r(tLe," \u2014 "),JR=n(tLe,"A",{href:!0});var Net=s(JR);Foo=r(Net,"UniSpeechSatConfig"),Net.forEach(t),Too=r(tLe," (UniSpeechSat model)"),tLe.forEach(t),Moo=i(L),Eg=n(L,"LI",{});var aLe=s(Eg);cne=n(aLe,"STRONG",{});var qet=s(cne);Eoo=r(qet,"van"),qet.forEach(t),Coo=r(aLe," \u2014 "),YR=n(aLe,"A",{href:!0});var jet=s(YR);woo=r(jet,"VanConfig"),jet.forEach(t),Aoo=r(aLe," (VAN model)"),aLe.forEach(t),Loo=i(L),Cg=n(L,"LI",{});var nLe=s(Cg);fne=n(nLe,"STRONG",{});var Det=s(fne);yoo=r(Det,"vilt"),Det.forEach(t),xoo=r(nLe," \u2014 "),KR=n(nLe,"A",{href:!0});var Get=s(KR);$oo=r(Get,"ViltConfig"),Get.forEach(t),koo=r(nLe," (ViLT model)"),nLe.forEach(t),Soo=i(L),wg=n(L,"LI",{});var sLe=s(wg);mne=n(sLe,"STRONG",{});var Oet=s(mne);Roo=r(Oet,"vision-encoder-decoder"),Oet.forEach(t),Poo=r(sLe," \u2014 "),ZR=n(sLe,"A",{href:!0});var Vet=s(ZR);Boo=r(Vet,"VisionEncoderDecoderConfig"),Vet.forEach(t),Ioo=r(sLe," (Vision Encoder decoder model)"),sLe.forEach(t),Noo=i(L),Ag=n(L,"LI",{});var lLe=s(Ag);gne=n(lLe,"STRONG",{});var Xet=s(gne);qoo=r(Xet,"vision-text-dual-encoder"),Xet.forEach(t),joo=r(lLe," \u2014 "),eP=n(lLe,"A",{href:!0});var zet=s(eP);Doo=r(zet,"VisionTextDualEncoderConfig"),zet.forEach(t),Goo=r(lLe," (VisionTextDualEncoder model)"),lLe.forEach(t),Ooo=i(L),Lg=n(L,"LI",{});var iLe=s(Lg);hne=n(iLe,"STRONG",{});var Qet=s(hne);Voo=r(Qet,"visual_bert"),Qet.forEach(t),Xoo=r(iLe," \u2014 "),oP=n(iLe,"A",{href:!0});var Wet=s(oP);zoo=r(Wet,"VisualBertConfig"),Wet.forEach(t),Qoo=r(iLe," (VisualBERT model)"),iLe.forEach(t),Woo=i(L),yg=n(L,"LI",{});var dLe=s(yg);pne=n(dLe,"STRONG",{});var Het=s(pne);Hoo=r(Het,"vit"),Het.forEach(t),Uoo=r(dLe," \u2014 "),rP=n(dLe,"A",{href:!0});var Uet=s(rP);Joo=r(Uet,"ViTConfig"),Uet.forEach(t),Yoo=r(dLe," (ViT model)"),dLe.forEach(t),Koo=i(L),xg=n(L,"LI",{});var cLe=s(xg);_ne=n(cLe,"STRONG",{});var Jet=s(_ne);Zoo=r(Jet,"vit_mae"),Jet.forEach(t),ero=r(cLe," \u2014 "),tP=n(cLe,"A",{href:!0});var Yet=s(tP);oro=r(Yet,"ViTMAEConfig"),Yet.forEach(t),rro=r(cLe," (ViTMAE model)"),cLe.forEach(t),tro=i(L),$g=n(L,"LI",{});var fLe=s($g);une=n(fLe,"STRONG",{});var Ket=s(une);aro=r(Ket,"wav2vec2"),Ket.forEach(t),nro=r(fLe," \u2014 "),aP=n(fLe,"A",{href:!0});var Zet=s(aP);sro=r(Zet,"Wav2Vec2Config"),Zet.forEach(t),lro=r(fLe," (Wav2Vec2 model)"),fLe.forEach(t),iro=i(L),kg=n(L,"LI",{});var mLe=s(kg);bne=n(mLe,"STRONG",{});var eot=s(bne);dro=r(eot,"wav2vec2-conformer"),eot.forEach(t),cro=r(mLe," \u2014 "),nP=n(mLe,"A",{href:!0});var oot=s(nP);fro=r(oot,"Wav2Vec2ConformerConfig"),oot.forEach(t),mro=r(mLe," (Wav2Vec2-Conformer model)"),mLe.forEach(t),gro=i(L),Sg=n(L,"LI",{});var gLe=s(Sg);vne=n(gLe,"STRONG",{});var rot=s(vne);hro=r(rot,"wavlm"),rot.forEach(t),pro=r(gLe," \u2014 "),sP=n(gLe,"A",{href:!0});var tot=s(sP);_ro=r(tot,"WavLMConfig"),tot.forEach(t),uro=r(gLe," (WavLM model)"),gLe.forEach(t),bro=i(L),Rg=n(L,"LI",{});var hLe=s(Rg);Fne=n(hLe,"STRONG",{});var aot=s(Fne);vro=r(aot,"xglm"),aot.forEach(t),Fro=r(hLe," \u2014 "),lP=n(hLe,"A",{href:!0});var not=s(lP);Tro=r(not,"XGLMConfig"),not.forEach(t),Mro=r(hLe," (XGLM model)"),hLe.forEach(t),Ero=i(L),Pg=n(L,"LI",{});var pLe=s(Pg);Tne=n(pLe,"STRONG",{});var sot=s(Tne);Cro=r(sot,"xlm"),sot.forEach(t),wro=r(pLe," \u2014 "),iP=n(pLe,"A",{href:!0});var lot=s(iP);Aro=r(lot,"XLMConfig"),lot.forEach(t),Lro=r(pLe," (XLM model)"),pLe.forEach(t),yro=i(L),Bg=n(L,"LI",{});var _Le=s(Bg);Mne=n(_Le,"STRONG",{});var iot=s(Mne);xro=r(iot,"xlm-prophetnet"),iot.forEach(t),$ro=r(_Le," \u2014 "),dP=n(_Le,"A",{href:!0});var dot=s(dP);kro=r(dot,"XLMProphetNetConfig"),dot.forEach(t),Sro=r(_Le," (XLM-ProphetNet model)"),_Le.forEach(t),Rro=i(L),Ig=n(L,"LI",{});var uLe=s(Ig);Ene=n(uLe,"STRONG",{});var cot=s(Ene);Pro=r(cot,"xlm-roberta"),cot.forEach(t),Bro=r(uLe," \u2014 "),cP=n(uLe,"A",{href:!0});var fot=s(cP);Iro=r(fot,"XLMRobertaConfig"),fot.forEach(t),Nro=r(uLe," (XLM-RoBERTa model)"),uLe.forEach(t),qro=i(L),Ng=n(L,"LI",{});var bLe=s(Ng);Cne=n(bLe,"STRONG",{});var mot=s(Cne);jro=r(mot,"xlm-roberta-xl"),mot.forEach(t),Dro=r(bLe," \u2014 "),fP=n(bLe,"A",{href:!0});var got=s(fP);Gro=r(got,"XLMRobertaXLConfig"),got.forEach(t),Oro=r(bLe," (XLM-RoBERTa-XL model)"),bLe.forEach(t),Vro=i(L),qg=n(L,"LI",{});var vLe=s(qg);wne=n(vLe,"STRONG",{});var hot=s(wne);Xro=r(hot,"xlnet"),hot.forEach(t),zro=r(vLe," \u2014 "),mP=n(vLe,"A",{href:!0});var pot=s(mP);Qro=r(pot,"XLNetConfig"),pot.forEach(t),Wro=r(vLe," (XLNet model)"),vLe.forEach(t),Hro=i(L),jg=n(L,"LI",{});var FLe=s(jg);Ane=n(FLe,"STRONG",{});var _ot=s(Ane);Uro=r(_ot,"yolos"),_ot.forEach(t),Jro=r(FLe," \u2014 "),gP=n(FLe,"A",{href:!0});var uot=s(gP);Yro=r(uot,"YolosConfig"),uot.forEach(t),Kro=r(FLe," (YOLOS model)"),FLe.forEach(t),Zro=i(L),Dg=n(L,"LI",{});var TLe=s(Dg);Lne=n(TLe,"STRONG",{});var bot=s(Lne);eto=r(bot,"yoso"),bot.forEach(t),oto=r(TLe," \u2014 "),hP=n(TLe,"A",{href:!0});var vot=s(hP);rto=r(vot,"YosoConfig"),vot.forEach(t),tto=r(TLe," (YOSO model)"),TLe.forEach(t),L.forEach(t),ato=i(tt),T(Gg.$$.fragment,tt),tt.forEach(t),nto=i(rt),Og=n(rt,"DIV",{class:!0});var zVe=s(Og);T(IL.$$.fragment,zVe),sto=i(zVe),yne=n(zVe,"P",{});var Fot=s(yne);lto=r(Fot,"Register a new configuration for this class."),Fot.forEach(t),zVe.forEach(t),rt.forEach(t),QGe=i(f),ki=n(f,"H2",{class:!0});var QVe=s(ki);Vg=n(QVe,"A",{id:!0,class:!0,href:!0});var Tot=s(Vg);xne=n(Tot,"SPAN",{});var Mot=s(xne);T(NL.$$.fragment,Mot),Mot.forEach(t),Tot.forEach(t),ito=i(QVe),$ne=n(QVe,"SPAN",{});var Eot=s($ne);dto=r(Eot,"AutoTokenizer"),Eot.forEach(t),QVe.forEach(t),WGe=i(f),Ao=n(f,"DIV",{class:!0});var Ws=s(Ao);T(qL.$$.fragment,Ws),cto=i(Ws),jL=n(Ws,"P",{});var WVe=s(jL);fto=r(WVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=n(WVe,"A",{href:!0});var Cot=s(pP);mto=r(Cot,"AutoTokenizer.from_pretrained()"),Cot.forEach(t),gto=r(WVe," class method."),WVe.forEach(t),hto=i(Ws),DL=n(Ws,"P",{});var HVe=s(DL);pto=r(HVe,"This class cannot be instantiated directly using "),kne=n(HVe,"CODE",{});var wot=s(kne);_to=r(wot,"__init__()"),wot.forEach(t),uto=r(HVe," (throws an error)."),HVe.forEach(t),bto=i(Ws),Lr=n(Ws,"DIV",{class:!0});var Hs=s(Lr);T(GL.$$.fragment,Hs),vto=i(Hs),Sne=n(Hs,"P",{});var Aot=s(Sne);Fto=r(Aot,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Aot.forEach(t),Tto=i(Hs),ka=n(Hs,"P",{});var xw=s(ka);Mto=r(xw,"The tokenizer class to instantiate is selected based on the "),Rne=n(xw,"CODE",{});var Lot=s(Rne);Eto=r(Lot,"model_type"),Lot.forEach(t),Cto=r(xw,` property of the config object (either
passed as an argument or loaded from `),Pne=n(xw,"CODE",{});var yot=s(Pne);wto=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),Ato=r(xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=n(xw,"CODE",{});var xot=s(Bne);Lto=r(xot,"pretrained_model_name_or_path"),xot.forEach(t),yto=r(xw,":"),xw.forEach(t),xto=i(Hs),k=n(Hs,"UL",{});var S=s(k);qn=n(S,"LI",{});var W$=s(qn);Ine=n(W$,"STRONG",{});var $ot=s(Ine);$to=r($ot,"albert"),$ot.forEach(t),kto=r(W$," \u2014 "),_P=n(W$,"A",{href:!0});var kot=s(_P);Sto=r(kot,"AlbertTokenizer"),kot.forEach(t),Rto=r(W$," or "),uP=n(W$,"A",{href:!0});var Sot=s(uP);Pto=r(Sot,"AlbertTokenizerFast"),Sot.forEach(t),Bto=r(W$," (ALBERT model)"),W$.forEach(t),Ito=i(S),jn=n(S,"LI",{});var H$=s(jn);Nne=n(H$,"STRONG",{});var Rot=s(Nne);Nto=r(Rot,"bart"),Rot.forEach(t),qto=r(H$," \u2014 "),bP=n(H$,"A",{href:!0});var Pot=s(bP);jto=r(Pot,"BartTokenizer"),Pot.forEach(t),Dto=r(H$," or "),vP=n(H$,"A",{href:!0});var Bot=s(vP);Gto=r(Bot,"BartTokenizerFast"),Bot.forEach(t),Oto=r(H$," (BART model)"),H$.forEach(t),Vto=i(S),Dn=n(S,"LI",{});var U$=s(Dn);qne=n(U$,"STRONG",{});var Iot=s(qne);Xto=r(Iot,"barthez"),Iot.forEach(t),zto=r(U$," \u2014 "),FP=n(U$,"A",{href:!0});var Not=s(FP);Qto=r(Not,"BarthezTokenizer"),Not.forEach(t),Wto=r(U$," or "),TP=n(U$,"A",{href:!0});var qot=s(TP);Hto=r(qot,"BarthezTokenizerFast"),qot.forEach(t),Uto=r(U$," (BARThez model)"),U$.forEach(t),Jto=i(S),Xg=n(S,"LI",{});var MLe=s(Xg);jne=n(MLe,"STRONG",{});var jot=s(jne);Yto=r(jot,"bartpho"),jot.forEach(t),Kto=r(MLe," \u2014 "),MP=n(MLe,"A",{href:!0});var Dot=s(MP);Zto=r(Dot,"BartphoTokenizer"),Dot.forEach(t),eao=r(MLe," (BARTpho model)"),MLe.forEach(t),oao=i(S),Gn=n(S,"LI",{});var J$=s(Gn);Dne=n(J$,"STRONG",{});var Got=s(Dne);rao=r(Got,"bert"),Got.forEach(t),tao=r(J$," \u2014 "),EP=n(J$,"A",{href:!0});var Oot=s(EP);aao=r(Oot,"BertTokenizer"),Oot.forEach(t),nao=r(J$," or "),CP=n(J$,"A",{href:!0});var Vot=s(CP);sao=r(Vot,"BertTokenizerFast"),Vot.forEach(t),lao=r(J$," (BERT model)"),J$.forEach(t),iao=i(S),zg=n(S,"LI",{});var ELe=s(zg);Gne=n(ELe,"STRONG",{});var Xot=s(Gne);dao=r(Xot,"bert-generation"),Xot.forEach(t),cao=r(ELe," \u2014 "),wP=n(ELe,"A",{href:!0});var zot=s(wP);fao=r(zot,"BertGenerationTokenizer"),zot.forEach(t),mao=r(ELe," (Bert Generation model)"),ELe.forEach(t),gao=i(S),Qg=n(S,"LI",{});var CLe=s(Qg);One=n(CLe,"STRONG",{});var Qot=s(One);hao=r(Qot,"bert-japanese"),Qot.forEach(t),pao=r(CLe," \u2014 "),AP=n(CLe,"A",{href:!0});var Wot=s(AP);_ao=r(Wot,"BertJapaneseTokenizer"),Wot.forEach(t),uao=r(CLe," (BertJapanese model)"),CLe.forEach(t),bao=i(S),Wg=n(S,"LI",{});var wLe=s(Wg);Vne=n(wLe,"STRONG",{});var Hot=s(Vne);vao=r(Hot,"bertweet"),Hot.forEach(t),Fao=r(wLe," \u2014 "),LP=n(wLe,"A",{href:!0});var Uot=s(LP);Tao=r(Uot,"BertweetTokenizer"),Uot.forEach(t),Mao=r(wLe," (BERTweet model)"),wLe.forEach(t),Eao=i(S),On=n(S,"LI",{});var Y$=s(On);Xne=n(Y$,"STRONG",{});var Jot=s(Xne);Cao=r(Jot,"big_bird"),Jot.forEach(t),wao=r(Y$," \u2014 "),yP=n(Y$,"A",{href:!0});var Yot=s(yP);Aao=r(Yot,"BigBirdTokenizer"),Yot.forEach(t),Lao=r(Y$," or "),xP=n(Y$,"A",{href:!0});var Kot=s(xP);yao=r(Kot,"BigBirdTokenizerFast"),Kot.forEach(t),xao=r(Y$," (BigBird model)"),Y$.forEach(t),$ao=i(S),Vn=n(S,"LI",{});var K$=s(Vn);zne=n(K$,"STRONG",{});var Zot=s(zne);kao=r(Zot,"bigbird_pegasus"),Zot.forEach(t),Sao=r(K$," \u2014 "),$P=n(K$,"A",{href:!0});var ert=s($P);Rao=r(ert,"PegasusTokenizer"),ert.forEach(t),Pao=r(K$," or "),kP=n(K$,"A",{href:!0});var ort=s(kP);Bao=r(ort,"PegasusTokenizerFast"),ort.forEach(t),Iao=r(K$," (BigBird-Pegasus model)"),K$.forEach(t),Nao=i(S),Xn=n(S,"LI",{});var Z$=s(Xn);Qne=n(Z$,"STRONG",{});var rrt=s(Qne);qao=r(rrt,"blenderbot"),rrt.forEach(t),jao=r(Z$," \u2014 "),SP=n(Z$,"A",{href:!0});var trt=s(SP);Dao=r(trt,"BlenderbotTokenizer"),trt.forEach(t),Gao=r(Z$," or "),RP=n(Z$,"A",{href:!0});var art=s(RP);Oao=r(art,"BlenderbotTokenizerFast"),art.forEach(t),Vao=r(Z$," (Blenderbot model)"),Z$.forEach(t),Xao=i(S),Hg=n(S,"LI",{});var ALe=s(Hg);Wne=n(ALe,"STRONG",{});var nrt=s(Wne);zao=r(nrt,"blenderbot-small"),nrt.forEach(t),Qao=r(ALe," \u2014 "),PP=n(ALe,"A",{href:!0});var srt=s(PP);Wao=r(srt,"BlenderbotSmallTokenizer"),srt.forEach(t),Hao=r(ALe," (BlenderbotSmall model)"),ALe.forEach(t),Uao=i(S),Ug=n(S,"LI",{});var LLe=s(Ug);Hne=n(LLe,"STRONG",{});var lrt=s(Hne);Jao=r(lrt,"bloom"),lrt.forEach(t),Yao=r(LLe," \u2014 "),BP=n(LLe,"A",{href:!0});var irt=s(BP);Kao=r(irt,"BloomTokenizerFast"),irt.forEach(t),Zao=r(LLe," (BLOOM model)"),LLe.forEach(t),eno=i(S),Jg=n(S,"LI",{});var yLe=s(Jg);Une=n(yLe,"STRONG",{});var drt=s(Une);ono=r(drt,"byt5"),drt.forEach(t),rno=r(yLe," \u2014 "),IP=n(yLe,"A",{href:!0});var crt=s(IP);tno=r(crt,"ByT5Tokenizer"),crt.forEach(t),ano=r(yLe," (ByT5 model)"),yLe.forEach(t),nno=i(S),zn=n(S,"LI",{});var ek=s(zn);Jne=n(ek,"STRONG",{});var frt=s(Jne);sno=r(frt,"camembert"),frt.forEach(t),lno=r(ek," \u2014 "),NP=n(ek,"A",{href:!0});var mrt=s(NP);ino=r(mrt,"CamembertTokenizer"),mrt.forEach(t),dno=r(ek," or "),qP=n(ek,"A",{href:!0});var grt=s(qP);cno=r(grt,"CamembertTokenizerFast"),grt.forEach(t),fno=r(ek," (CamemBERT model)"),ek.forEach(t),mno=i(S),Yg=n(S,"LI",{});var xLe=s(Yg);Yne=n(xLe,"STRONG",{});var hrt=s(Yne);gno=r(hrt,"canine"),hrt.forEach(t),hno=r(xLe," \u2014 "),jP=n(xLe,"A",{href:!0});var prt=s(jP);pno=r(prt,"CanineTokenizer"),prt.forEach(t),_no=r(xLe," (CANINE model)"),xLe.forEach(t),uno=i(S),Qn=n(S,"LI",{});var ok=s(Qn);Kne=n(ok,"STRONG",{});var _rt=s(Kne);bno=r(_rt,"clip"),_rt.forEach(t),vno=r(ok," \u2014 "),DP=n(ok,"A",{href:!0});var urt=s(DP);Fno=r(urt,"CLIPTokenizer"),urt.forEach(t),Tno=r(ok," or "),GP=n(ok,"A",{href:!0});var brt=s(GP);Mno=r(brt,"CLIPTokenizerFast"),brt.forEach(t),Eno=r(ok," (CLIP model)"),ok.forEach(t),Cno=i(S),Wn=n(S,"LI",{});var rk=s(Wn);Zne=n(rk,"STRONG",{});var vrt=s(Zne);wno=r(vrt,"convbert"),vrt.forEach(t),Ano=r(rk," \u2014 "),OP=n(rk,"A",{href:!0});var Frt=s(OP);Lno=r(Frt,"ConvBertTokenizer"),Frt.forEach(t),yno=r(rk," or "),VP=n(rk,"A",{href:!0});var Trt=s(VP);xno=r(Trt,"ConvBertTokenizerFast"),Trt.forEach(t),$no=r(rk," (ConvBERT model)"),rk.forEach(t),kno=i(S),Hn=n(S,"LI",{});var tk=s(Hn);ese=n(tk,"STRONG",{});var Mrt=s(ese);Sno=r(Mrt,"cpm"),Mrt.forEach(t),Rno=r(tk," \u2014 "),XP=n(tk,"A",{href:!0});var Ert=s(XP);Pno=r(Ert,"CpmTokenizer"),Ert.forEach(t),Bno=r(tk," or "),zP=n(tk,"A",{href:!0});var Crt=s(zP);Ino=r(Crt,"CpmTokenizerFast"),Crt.forEach(t),Nno=r(tk," (CPM model)"),tk.forEach(t),qno=i(S),Kg=n(S,"LI",{});var $Le=s(Kg);ose=n($Le,"STRONG",{});var wrt=s(ose);jno=r(wrt,"ctrl"),wrt.forEach(t),Dno=r($Le," \u2014 "),QP=n($Le,"A",{href:!0});var Art=s(QP);Gno=r(Art,"CTRLTokenizer"),Art.forEach(t),Ono=r($Le," (CTRL model)"),$Le.forEach(t),Vno=i(S),Un=n(S,"LI",{});var ak=s(Un);rse=n(ak,"STRONG",{});var Lrt=s(rse);Xno=r(Lrt,"data2vec-text"),Lrt.forEach(t),zno=r(ak," \u2014 "),WP=n(ak,"A",{href:!0});var yrt=s(WP);Qno=r(yrt,"RobertaTokenizer"),yrt.forEach(t),Wno=r(ak," or "),HP=n(ak,"A",{href:!0});var xrt=s(HP);Hno=r(xrt,"RobertaTokenizerFast"),xrt.forEach(t),Uno=r(ak," (Data2VecText model)"),ak.forEach(t),Jno=i(S),Jn=n(S,"LI",{});var nk=s(Jn);tse=n(nk,"STRONG",{});var $rt=s(tse);Yno=r($rt,"deberta"),$rt.forEach(t),Kno=r(nk," \u2014 "),UP=n(nk,"A",{href:!0});var krt=s(UP);Zno=r(krt,"DebertaTokenizer"),krt.forEach(t),eso=r(nk," or "),JP=n(nk,"A",{href:!0});var Srt=s(JP);oso=r(Srt,"DebertaTokenizerFast"),Srt.forEach(t),rso=r(nk," (DeBERTa model)"),nk.forEach(t),tso=i(S),Yn=n(S,"LI",{});var sk=s(Yn);ase=n(sk,"STRONG",{});var Rrt=s(ase);aso=r(Rrt,"deberta-v2"),Rrt.forEach(t),nso=r(sk," \u2014 "),YP=n(sk,"A",{href:!0});var Prt=s(YP);sso=r(Prt,"DebertaV2Tokenizer"),Prt.forEach(t),lso=r(sk," or "),KP=n(sk,"A",{href:!0});var Brt=s(KP);iso=r(Brt,"DebertaV2TokenizerFast"),Brt.forEach(t),dso=r(sk," (DeBERTa-v2 model)"),sk.forEach(t),cso=i(S),Kn=n(S,"LI",{});var lk=s(Kn);nse=n(lk,"STRONG",{});var Irt=s(nse);fso=r(Irt,"distilbert"),Irt.forEach(t),mso=r(lk," \u2014 "),ZP=n(lk,"A",{href:!0});var Nrt=s(ZP);gso=r(Nrt,"DistilBertTokenizer"),Nrt.forEach(t),hso=r(lk," or "),eB=n(lk,"A",{href:!0});var qrt=s(eB);pso=r(qrt,"DistilBertTokenizerFast"),qrt.forEach(t),_so=r(lk," (DistilBERT model)"),lk.forEach(t),uso=i(S),Zn=n(S,"LI",{});var ik=s(Zn);sse=n(ik,"STRONG",{});var jrt=s(sse);bso=r(jrt,"dpr"),jrt.forEach(t),vso=r(ik," \u2014 "),oB=n(ik,"A",{href:!0});var Drt=s(oB);Fso=r(Drt,"DPRQuestionEncoderTokenizer"),Drt.forEach(t),Tso=r(ik," or "),rB=n(ik,"A",{href:!0});var Grt=s(rB);Mso=r(Grt,"DPRQuestionEncoderTokenizerFast"),Grt.forEach(t),Eso=r(ik," (DPR model)"),ik.forEach(t),Cso=i(S),es=n(S,"LI",{});var dk=s(es);lse=n(dk,"STRONG",{});var Ort=s(lse);wso=r(Ort,"electra"),Ort.forEach(t),Aso=r(dk," \u2014 "),tB=n(dk,"A",{href:!0});var Vrt=s(tB);Lso=r(Vrt,"ElectraTokenizer"),Vrt.forEach(t),yso=r(dk," or "),aB=n(dk,"A",{href:!0});var Xrt=s(aB);xso=r(Xrt,"ElectraTokenizerFast"),Xrt.forEach(t),$so=r(dk," (ELECTRA model)"),dk.forEach(t),kso=i(S),Zg=n(S,"LI",{});var kLe=s(Zg);ise=n(kLe,"STRONG",{});var zrt=s(ise);Sso=r(zrt,"flaubert"),zrt.forEach(t),Rso=r(kLe," \u2014 "),nB=n(kLe,"A",{href:!0});var Qrt=s(nB);Pso=r(Qrt,"FlaubertTokenizer"),Qrt.forEach(t),Bso=r(kLe," (FlauBERT model)"),kLe.forEach(t),Iso=i(S),os=n(S,"LI",{});var ck=s(os);dse=n(ck,"STRONG",{});var Wrt=s(dse);Nso=r(Wrt,"fnet"),Wrt.forEach(t),qso=r(ck," \u2014 "),sB=n(ck,"A",{href:!0});var Hrt=s(sB);jso=r(Hrt,"FNetTokenizer"),Hrt.forEach(t),Dso=r(ck," or "),lB=n(ck,"A",{href:!0});var Urt=s(lB);Gso=r(Urt,"FNetTokenizerFast"),Urt.forEach(t),Oso=r(ck," (FNet model)"),ck.forEach(t),Vso=i(S),eh=n(S,"LI",{});var SLe=s(eh);cse=n(SLe,"STRONG",{});var Jrt=s(cse);Xso=r(Jrt,"fsmt"),Jrt.forEach(t),zso=r(SLe," \u2014 "),iB=n(SLe,"A",{href:!0});var Yrt=s(iB);Qso=r(Yrt,"FSMTTokenizer"),Yrt.forEach(t),Wso=r(SLe," (FairSeq Machine-Translation model)"),SLe.forEach(t),Hso=i(S),rs=n(S,"LI",{});var fk=s(rs);fse=n(fk,"STRONG",{});var Krt=s(fse);Uso=r(Krt,"funnel"),Krt.forEach(t),Jso=r(fk," \u2014 "),dB=n(fk,"A",{href:!0});var Zrt=s(dB);Yso=r(Zrt,"FunnelTokenizer"),Zrt.forEach(t),Kso=r(fk," or "),cB=n(fk,"A",{href:!0});var ett=s(cB);Zso=r(ett,"FunnelTokenizerFast"),ett.forEach(t),elo=r(fk," (Funnel Transformer model)"),fk.forEach(t),olo=i(S),ts=n(S,"LI",{});var mk=s(ts);mse=n(mk,"STRONG",{});var ott=s(mse);rlo=r(ott,"gpt2"),ott.forEach(t),tlo=r(mk," \u2014 "),fB=n(mk,"A",{href:!0});var rtt=s(fB);alo=r(rtt,"GPT2Tokenizer"),rtt.forEach(t),nlo=r(mk," or "),mB=n(mk,"A",{href:!0});var ttt=s(mB);slo=r(ttt,"GPT2TokenizerFast"),ttt.forEach(t),llo=r(mk," (OpenAI GPT-2 model)"),mk.forEach(t),ilo=i(S),as=n(S,"LI",{});var gk=s(as);gse=n(gk,"STRONG",{});var att=s(gse);dlo=r(att,"gpt_neo"),att.forEach(t),clo=r(gk," \u2014 "),gB=n(gk,"A",{href:!0});var ntt=s(gB);flo=r(ntt,"GPT2Tokenizer"),ntt.forEach(t),mlo=r(gk," or "),hB=n(gk,"A",{href:!0});var stt=s(hB);glo=r(stt,"GPT2TokenizerFast"),stt.forEach(t),hlo=r(gk," (GPT Neo model)"),gk.forEach(t),plo=i(S),oh=n(S,"LI",{});var RLe=s(oh);hse=n(RLe,"STRONG",{});var ltt=s(hse);_lo=r(ltt,"gpt_neox"),ltt.forEach(t),ulo=r(RLe," \u2014 "),pB=n(RLe,"A",{href:!0});var itt=s(pB);blo=r(itt,"GPTNeoXTokenizerFast"),itt.forEach(t),vlo=r(RLe," (GPT NeoX model)"),RLe.forEach(t),Flo=i(S),ns=n(S,"LI",{});var hk=s(ns);pse=n(hk,"STRONG",{});var dtt=s(pse);Tlo=r(dtt,"gptj"),dtt.forEach(t),Mlo=r(hk," \u2014 "),_B=n(hk,"A",{href:!0});var ctt=s(_B);Elo=r(ctt,"GPT2Tokenizer"),ctt.forEach(t),Clo=r(hk," or "),uB=n(hk,"A",{href:!0});var ftt=s(uB);wlo=r(ftt,"GPT2TokenizerFast"),ftt.forEach(t),Alo=r(hk," (GPT-J model)"),hk.forEach(t),Llo=i(S),ss=n(S,"LI",{});var pk=s(ss);_se=n(pk,"STRONG",{});var mtt=s(_se);ylo=r(mtt,"herbert"),mtt.forEach(t),xlo=r(pk," \u2014 "),bB=n(pk,"A",{href:!0});var gtt=s(bB);$lo=r(gtt,"HerbertTokenizer"),gtt.forEach(t),klo=r(pk," or "),vB=n(pk,"A",{href:!0});var htt=s(vB);Slo=r(htt,"HerbertTokenizerFast"),htt.forEach(t),Rlo=r(pk," (HerBERT model)"),pk.forEach(t),Plo=i(S),rh=n(S,"LI",{});var PLe=s(rh);use=n(PLe,"STRONG",{});var ptt=s(use);Blo=r(ptt,"hubert"),ptt.forEach(t),Ilo=r(PLe," \u2014 "),FB=n(PLe,"A",{href:!0});var _tt=s(FB);Nlo=r(_tt,"Wav2Vec2CTCTokenizer"),_tt.forEach(t),qlo=r(PLe," (Hubert model)"),PLe.forEach(t),jlo=i(S),ls=n(S,"LI",{});var _k=s(ls);bse=n(_k,"STRONG",{});var utt=s(bse);Dlo=r(utt,"ibert"),utt.forEach(t),Glo=r(_k," \u2014 "),TB=n(_k,"A",{href:!0});var btt=s(TB);Olo=r(btt,"RobertaTokenizer"),btt.forEach(t),Vlo=r(_k," or "),MB=n(_k,"A",{href:!0});var vtt=s(MB);Xlo=r(vtt,"RobertaTokenizerFast"),vtt.forEach(t),zlo=r(_k," (I-BERT model)"),_k.forEach(t),Qlo=i(S),is=n(S,"LI",{});var uk=s(is);vse=n(uk,"STRONG",{});var Ftt=s(vse);Wlo=r(Ftt,"layoutlm"),Ftt.forEach(t),Hlo=r(uk," \u2014 "),EB=n(uk,"A",{href:!0});var Ttt=s(EB);Ulo=r(Ttt,"LayoutLMTokenizer"),Ttt.forEach(t),Jlo=r(uk," or "),CB=n(uk,"A",{href:!0});var Mtt=s(CB);Ylo=r(Mtt,"LayoutLMTokenizerFast"),Mtt.forEach(t),Klo=r(uk," (LayoutLM model)"),uk.forEach(t),Zlo=i(S),ds=n(S,"LI",{});var bk=s(ds);Fse=n(bk,"STRONG",{});var Ett=s(Fse);eio=r(Ett,"layoutlmv2"),Ett.forEach(t),oio=r(bk," \u2014 "),wB=n(bk,"A",{href:!0});var Ctt=s(wB);rio=r(Ctt,"LayoutLMv2Tokenizer"),Ctt.forEach(t),tio=r(bk," or "),AB=n(bk,"A",{href:!0});var wtt=s(AB);aio=r(wtt,"LayoutLMv2TokenizerFast"),wtt.forEach(t),nio=r(bk," (LayoutLMv2 model)"),bk.forEach(t),sio=i(S),cs=n(S,"LI",{});var vk=s(cs);Tse=n(vk,"STRONG",{});var Att=s(Tse);lio=r(Att,"layoutlmv3"),Att.forEach(t),iio=r(vk," \u2014 "),LB=n(vk,"A",{href:!0});var Ltt=s(LB);dio=r(Ltt,"LayoutLMv3Tokenizer"),Ltt.forEach(t),cio=r(vk," or "),yB=n(vk,"A",{href:!0});var ytt=s(yB);fio=r(ytt,"LayoutLMv3TokenizerFast"),ytt.forEach(t),mio=r(vk," (LayoutLMv3 model)"),vk.forEach(t),gio=i(S),fs=n(S,"LI",{});var Fk=s(fs);Mse=n(Fk,"STRONG",{});var xtt=s(Mse);hio=r(xtt,"layoutxlm"),xtt.forEach(t),pio=r(Fk," \u2014 "),xB=n(Fk,"A",{href:!0});var $tt=s(xB);_io=r($tt,"LayoutXLMTokenizer"),$tt.forEach(t),uio=r(Fk," or "),$B=n(Fk,"A",{href:!0});var ktt=s($B);bio=r(ktt,"LayoutXLMTokenizerFast"),ktt.forEach(t),vio=r(Fk," (LayoutXLM model)"),Fk.forEach(t),Fio=i(S),ms=n(S,"LI",{});var Tk=s(ms);Ese=n(Tk,"STRONG",{});var Stt=s(Ese);Tio=r(Stt,"led"),Stt.forEach(t),Mio=r(Tk," \u2014 "),kB=n(Tk,"A",{href:!0});var Rtt=s(kB);Eio=r(Rtt,"LEDTokenizer"),Rtt.forEach(t),Cio=r(Tk," or "),SB=n(Tk,"A",{href:!0});var Ptt=s(SB);wio=r(Ptt,"LEDTokenizerFast"),Ptt.forEach(t),Aio=r(Tk," (LED model)"),Tk.forEach(t),Lio=i(S),gs=n(S,"LI",{});var Mk=s(gs);Cse=n(Mk,"STRONG",{});var Btt=s(Cse);yio=r(Btt,"longformer"),Btt.forEach(t),xio=r(Mk," \u2014 "),RB=n(Mk,"A",{href:!0});var Itt=s(RB);$io=r(Itt,"LongformerTokenizer"),Itt.forEach(t),kio=r(Mk," or "),PB=n(Mk,"A",{href:!0});var Ntt=s(PB);Sio=r(Ntt,"LongformerTokenizerFast"),Ntt.forEach(t),Rio=r(Mk," (Longformer model)"),Mk.forEach(t),Pio=i(S),hs=n(S,"LI",{});var Ek=s(hs);wse=n(Ek,"STRONG",{});var qtt=s(wse);Bio=r(qtt,"longt5"),qtt.forEach(t),Iio=r(Ek," \u2014 "),BB=n(Ek,"A",{href:!0});var jtt=s(BB);Nio=r(jtt,"T5Tokenizer"),jtt.forEach(t),qio=r(Ek," or "),IB=n(Ek,"A",{href:!0});var Dtt=s(IB);jio=r(Dtt,"T5TokenizerFast"),Dtt.forEach(t),Dio=r(Ek," (LongT5 model)"),Ek.forEach(t),Gio=i(S),th=n(S,"LI",{});var BLe=s(th);Ase=n(BLe,"STRONG",{});var Gtt=s(Ase);Oio=r(Gtt,"luke"),Gtt.forEach(t),Vio=r(BLe," \u2014 "),NB=n(BLe,"A",{href:!0});var Ott=s(NB);Xio=r(Ott,"LukeTokenizer"),Ott.forEach(t),zio=r(BLe," (LUKE model)"),BLe.forEach(t),Qio=i(S),ps=n(S,"LI",{});var Ck=s(ps);Lse=n(Ck,"STRONG",{});var Vtt=s(Lse);Wio=r(Vtt,"lxmert"),Vtt.forEach(t),Hio=r(Ck," \u2014 "),qB=n(Ck,"A",{href:!0});var Xtt=s(qB);Uio=r(Xtt,"LxmertTokenizer"),Xtt.forEach(t),Jio=r(Ck," or "),jB=n(Ck,"A",{href:!0});var ztt=s(jB);Yio=r(ztt,"LxmertTokenizerFast"),ztt.forEach(t),Kio=r(Ck," (LXMERT model)"),Ck.forEach(t),Zio=i(S),ah=n(S,"LI",{});var ILe=s(ah);yse=n(ILe,"STRONG",{});var Qtt=s(yse);edo=r(Qtt,"m2m_100"),Qtt.forEach(t),odo=r(ILe," \u2014 "),DB=n(ILe,"A",{href:!0});var Wtt=s(DB);rdo=r(Wtt,"M2M100Tokenizer"),Wtt.forEach(t),tdo=r(ILe," (M2M100 model)"),ILe.forEach(t),ado=i(S),nh=n(S,"LI",{});var NLe=s(nh);xse=n(NLe,"STRONG",{});var Htt=s(xse);ndo=r(Htt,"marian"),Htt.forEach(t),sdo=r(NLe," \u2014 "),GB=n(NLe,"A",{href:!0});var Utt=s(GB);ldo=r(Utt,"MarianTokenizer"),Utt.forEach(t),ido=r(NLe," (Marian model)"),NLe.forEach(t),ddo=i(S),_s=n(S,"LI",{});var wk=s(_s);$se=n(wk,"STRONG",{});var Jtt=s($se);cdo=r(Jtt,"mbart"),Jtt.forEach(t),fdo=r(wk," \u2014 "),OB=n(wk,"A",{href:!0});var Ytt=s(OB);mdo=r(Ytt,"MBartTokenizer"),Ytt.forEach(t),gdo=r(wk," or "),VB=n(wk,"A",{href:!0});var Ktt=s(VB);hdo=r(Ktt,"MBartTokenizerFast"),Ktt.forEach(t),pdo=r(wk," (mBART model)"),wk.forEach(t),_do=i(S),us=n(S,"LI",{});var Ak=s(us);kse=n(Ak,"STRONG",{});var Ztt=s(kse);udo=r(Ztt,"mbart50"),Ztt.forEach(t),bdo=r(Ak," \u2014 "),XB=n(Ak,"A",{href:!0});var eat=s(XB);vdo=r(eat,"MBart50Tokenizer"),eat.forEach(t),Fdo=r(Ak," or "),zB=n(Ak,"A",{href:!0});var oat=s(zB);Tdo=r(oat,"MBart50TokenizerFast"),oat.forEach(t),Mdo=r(Ak," (mBART-50 model)"),Ak.forEach(t),Edo=i(S),bs=n(S,"LI",{});var Lk=s(bs);Sse=n(Lk,"STRONG",{});var rat=s(Sse);Cdo=r(rat,"megatron-bert"),rat.forEach(t),wdo=r(Lk," \u2014 "),QB=n(Lk,"A",{href:!0});var tat=s(QB);Ado=r(tat,"BertTokenizer"),tat.forEach(t),Ldo=r(Lk," or "),WB=n(Lk,"A",{href:!0});var aat=s(WB);ydo=r(aat,"BertTokenizerFast"),aat.forEach(t),xdo=r(Lk," (Megatron-BERT model)"),Lk.forEach(t),$do=i(S),sh=n(S,"LI",{});var qLe=s(sh);Rse=n(qLe,"STRONG",{});var nat=s(Rse);kdo=r(nat,"mluke"),nat.forEach(t),Sdo=r(qLe," \u2014 "),HB=n(qLe,"A",{href:!0});var sat=s(HB);Rdo=r(sat,"MLukeTokenizer"),sat.forEach(t),Pdo=r(qLe," (mLUKE model)"),qLe.forEach(t),Bdo=i(S),vs=n(S,"LI",{});var yk=s(vs);Pse=n(yk,"STRONG",{});var lat=s(Pse);Ido=r(lat,"mobilebert"),lat.forEach(t),Ndo=r(yk," \u2014 "),UB=n(yk,"A",{href:!0});var iat=s(UB);qdo=r(iat,"MobileBertTokenizer"),iat.forEach(t),jdo=r(yk," or "),JB=n(yk,"A",{href:!0});var dat=s(JB);Ddo=r(dat,"MobileBertTokenizerFast"),dat.forEach(t),Gdo=r(yk," (MobileBERT model)"),yk.forEach(t),Odo=i(S),Fs=n(S,"LI",{});var xk=s(Fs);Bse=n(xk,"STRONG",{});var cat=s(Bse);Vdo=r(cat,"mpnet"),cat.forEach(t),Xdo=r(xk," \u2014 "),YB=n(xk,"A",{href:!0});var fat=s(YB);zdo=r(fat,"MPNetTokenizer"),fat.forEach(t),Qdo=r(xk," or "),KB=n(xk,"A",{href:!0});var mat=s(KB);Wdo=r(mat,"MPNetTokenizerFast"),mat.forEach(t),Hdo=r(xk," (MPNet model)"),xk.forEach(t),Udo=i(S),Ts=n(S,"LI",{});var $k=s(Ts);Ise=n($k,"STRONG",{});var gat=s(Ise);Jdo=r(gat,"mt5"),gat.forEach(t),Ydo=r($k," \u2014 "),ZB=n($k,"A",{href:!0});var hat=s(ZB);Kdo=r(hat,"MT5Tokenizer"),hat.forEach(t),Zdo=r($k," or "),eI=n($k,"A",{href:!0});var pat=s(eI);eco=r(pat,"MT5TokenizerFast"),pat.forEach(t),oco=r($k," (MT5 model)"),$k.forEach(t),rco=i(S),Ms=n(S,"LI",{});var kk=s(Ms);Nse=n(kk,"STRONG",{});var _at=s(Nse);tco=r(_at,"nezha"),_at.forEach(t),aco=r(kk," \u2014 "),oI=n(kk,"A",{href:!0});var uat=s(oI);nco=r(uat,"BertTokenizer"),uat.forEach(t),sco=r(kk," or "),rI=n(kk,"A",{href:!0});var bat=s(rI);lco=r(bat,"BertTokenizerFast"),bat.forEach(t),ico=r(kk," (Nezha model)"),kk.forEach(t),dco=i(S),Es=n(S,"LI",{});var Sk=s(Es);qse=n(Sk,"STRONG",{});var vat=s(qse);cco=r(vat,"nystromformer"),vat.forEach(t),fco=r(Sk," \u2014 "),tI=n(Sk,"A",{href:!0});var Fat=s(tI);mco=r(Fat,"AlbertTokenizer"),Fat.forEach(t),gco=r(Sk," or "),aI=n(Sk,"A",{href:!0});var Tat=s(aI);hco=r(Tat,"AlbertTokenizerFast"),Tat.forEach(t),pco=r(Sk," (Nystr\xF6mformer model)"),Sk.forEach(t),_co=i(S),Cs=n(S,"LI",{});var Rk=s(Cs);jse=n(Rk,"STRONG",{});var Mat=s(jse);uco=r(Mat,"openai-gpt"),Mat.forEach(t),bco=r(Rk," \u2014 "),nI=n(Rk,"A",{href:!0});var Eat=s(nI);vco=r(Eat,"OpenAIGPTTokenizer"),Eat.forEach(t),Fco=r(Rk," or "),sI=n(Rk,"A",{href:!0});var Cat=s(sI);Tco=r(Cat,"OpenAIGPTTokenizerFast"),Cat.forEach(t),Mco=r(Rk," (OpenAI GPT model)"),Rk.forEach(t),Eco=i(S),lh=n(S,"LI",{});var jLe=s(lh);Dse=n(jLe,"STRONG",{});var wat=s(Dse);Cco=r(wat,"opt"),wat.forEach(t),wco=r(jLe," \u2014 "),lI=n(jLe,"A",{href:!0});var Aat=s(lI);Aco=r(Aat,"GPT2Tokenizer"),Aat.forEach(t),Lco=r(jLe," (OPT model)"),jLe.forEach(t),yco=i(S),ws=n(S,"LI",{});var Pk=s(ws);Gse=n(Pk,"STRONG",{});var Lat=s(Gse);xco=r(Lat,"pegasus"),Lat.forEach(t),$co=r(Pk," \u2014 "),iI=n(Pk,"A",{href:!0});var yat=s(iI);kco=r(yat,"PegasusTokenizer"),yat.forEach(t),Sco=r(Pk," or "),dI=n(Pk,"A",{href:!0});var xat=s(dI);Rco=r(xat,"PegasusTokenizerFast"),xat.forEach(t),Pco=r(Pk," (Pegasus model)"),Pk.forEach(t),Bco=i(S),ih=n(S,"LI",{});var DLe=s(ih);Ose=n(DLe,"STRONG",{});var $at=s(Ose);Ico=r($at,"perceiver"),$at.forEach(t),Nco=r(DLe," \u2014 "),cI=n(DLe,"A",{href:!0});var kat=s(cI);qco=r(kat,"PerceiverTokenizer"),kat.forEach(t),jco=r(DLe," (Perceiver model)"),DLe.forEach(t),Dco=i(S),dh=n(S,"LI",{});var GLe=s(dh);Vse=n(GLe,"STRONG",{});var Sat=s(Vse);Gco=r(Sat,"phobert"),Sat.forEach(t),Oco=r(GLe," \u2014 "),fI=n(GLe,"A",{href:!0});var Rat=s(fI);Vco=r(Rat,"PhobertTokenizer"),Rat.forEach(t),Xco=r(GLe," (PhoBERT model)"),GLe.forEach(t),zco=i(S),ch=n(S,"LI",{});var OLe=s(ch);Xse=n(OLe,"STRONG",{});var Pat=s(Xse);Qco=r(Pat,"plbart"),Pat.forEach(t),Wco=r(OLe," \u2014 "),mI=n(OLe,"A",{href:!0});var Bat=s(mI);Hco=r(Bat,"PLBartTokenizer"),Bat.forEach(t),Uco=r(OLe," (PLBart model)"),OLe.forEach(t),Jco=i(S),fh=n(S,"LI",{});var VLe=s(fh);zse=n(VLe,"STRONG",{});var Iat=s(zse);Yco=r(Iat,"prophetnet"),Iat.forEach(t),Kco=r(VLe," \u2014 "),gI=n(VLe,"A",{href:!0});var Nat=s(gI);Zco=r(Nat,"ProphetNetTokenizer"),Nat.forEach(t),efo=r(VLe," (ProphetNet model)"),VLe.forEach(t),ofo=i(S),As=n(S,"LI",{});var Bk=s(As);Qse=n(Bk,"STRONG",{});var qat=s(Qse);rfo=r(qat,"qdqbert"),qat.forEach(t),tfo=r(Bk," \u2014 "),hI=n(Bk,"A",{href:!0});var jat=s(hI);afo=r(jat,"BertTokenizer"),jat.forEach(t),nfo=r(Bk," or "),pI=n(Bk,"A",{href:!0});var Dat=s(pI);sfo=r(Dat,"BertTokenizerFast"),Dat.forEach(t),lfo=r(Bk," (QDQBert model)"),Bk.forEach(t),ifo=i(S),mh=n(S,"LI",{});var XLe=s(mh);Wse=n(XLe,"STRONG",{});var Gat=s(Wse);dfo=r(Gat,"rag"),Gat.forEach(t),cfo=r(XLe," \u2014 "),_I=n(XLe,"A",{href:!0});var Oat=s(_I);ffo=r(Oat,"RagTokenizer"),Oat.forEach(t),mfo=r(XLe," (RAG model)"),XLe.forEach(t),gfo=i(S),Ls=n(S,"LI",{});var Ik=s(Ls);Hse=n(Ik,"STRONG",{});var Vat=s(Hse);hfo=r(Vat,"realm"),Vat.forEach(t),pfo=r(Ik," \u2014 "),uI=n(Ik,"A",{href:!0});var Xat=s(uI);_fo=r(Xat,"RealmTokenizer"),Xat.forEach(t),ufo=r(Ik," or "),bI=n(Ik,"A",{href:!0});var zat=s(bI);bfo=r(zat,"RealmTokenizerFast"),zat.forEach(t),vfo=r(Ik," (REALM model)"),Ik.forEach(t),Ffo=i(S),ys=n(S,"LI",{});var Nk=s(ys);Use=n(Nk,"STRONG",{});var Qat=s(Use);Tfo=r(Qat,"reformer"),Qat.forEach(t),Mfo=r(Nk," \u2014 "),vI=n(Nk,"A",{href:!0});var Wat=s(vI);Efo=r(Wat,"ReformerTokenizer"),Wat.forEach(t),Cfo=r(Nk," or "),FI=n(Nk,"A",{href:!0});var Hat=s(FI);wfo=r(Hat,"ReformerTokenizerFast"),Hat.forEach(t),Afo=r(Nk," (Reformer model)"),Nk.forEach(t),Lfo=i(S),xs=n(S,"LI",{});var qk=s(xs);Jse=n(qk,"STRONG",{});var Uat=s(Jse);yfo=r(Uat,"rembert"),Uat.forEach(t),xfo=r(qk," \u2014 "),TI=n(qk,"A",{href:!0});var Jat=s(TI);$fo=r(Jat,"RemBertTokenizer"),Jat.forEach(t),kfo=r(qk," or "),MI=n(qk,"A",{href:!0});var Yat=s(MI);Sfo=r(Yat,"RemBertTokenizerFast"),Yat.forEach(t),Rfo=r(qk," (RemBERT model)"),qk.forEach(t),Pfo=i(S),$s=n(S,"LI",{});var jk=s($s);Yse=n(jk,"STRONG",{});var Kat=s(Yse);Bfo=r(Kat,"retribert"),Kat.forEach(t),Ifo=r(jk," \u2014 "),EI=n(jk,"A",{href:!0});var Zat=s(EI);Nfo=r(Zat,"RetriBertTokenizer"),Zat.forEach(t),qfo=r(jk," or "),CI=n(jk,"A",{href:!0});var ent=s(CI);jfo=r(ent,"RetriBertTokenizerFast"),ent.forEach(t),Dfo=r(jk," (RetriBERT model)"),jk.forEach(t),Gfo=i(S),ks=n(S,"LI",{});var Dk=s(ks);Kse=n(Dk,"STRONG",{});var ont=s(Kse);Ofo=r(ont,"roberta"),ont.forEach(t),Vfo=r(Dk," \u2014 "),wI=n(Dk,"A",{href:!0});var rnt=s(wI);Xfo=r(rnt,"RobertaTokenizer"),rnt.forEach(t),zfo=r(Dk," or "),AI=n(Dk,"A",{href:!0});var tnt=s(AI);Qfo=r(tnt,"RobertaTokenizerFast"),tnt.forEach(t),Wfo=r(Dk," (RoBERTa model)"),Dk.forEach(t),Hfo=i(S),Ss=n(S,"LI",{});var Gk=s(Ss);Zse=n(Gk,"STRONG",{});var ant=s(Zse);Ufo=r(ant,"roformer"),ant.forEach(t),Jfo=r(Gk," \u2014 "),LI=n(Gk,"A",{href:!0});var nnt=s(LI);Yfo=r(nnt,"RoFormerTokenizer"),nnt.forEach(t),Kfo=r(Gk," or "),yI=n(Gk,"A",{href:!0});var snt=s(yI);Zfo=r(snt,"RoFormerTokenizerFast"),snt.forEach(t),emo=r(Gk," (RoFormer model)"),Gk.forEach(t),omo=i(S),gh=n(S,"LI",{});var zLe=s(gh);ele=n(zLe,"STRONG",{});var lnt=s(ele);rmo=r(lnt,"speech_to_text"),lnt.forEach(t),tmo=r(zLe," \u2014 "),xI=n(zLe,"A",{href:!0});var int=s(xI);amo=r(int,"Speech2TextTokenizer"),int.forEach(t),nmo=r(zLe," (Speech2Text model)"),zLe.forEach(t),smo=i(S),hh=n(S,"LI",{});var QLe=s(hh);ole=n(QLe,"STRONG",{});var dnt=s(ole);lmo=r(dnt,"speech_to_text_2"),dnt.forEach(t),imo=r(QLe," \u2014 "),$I=n(QLe,"A",{href:!0});var cnt=s($I);dmo=r(cnt,"Speech2Text2Tokenizer"),cnt.forEach(t),cmo=r(QLe," (Speech2Text2 model)"),QLe.forEach(t),fmo=i(S),Rs=n(S,"LI",{});var Ok=s(Rs);rle=n(Ok,"STRONG",{});var fnt=s(rle);mmo=r(fnt,"splinter"),fnt.forEach(t),gmo=r(Ok," \u2014 "),kI=n(Ok,"A",{href:!0});var mnt=s(kI);hmo=r(mnt,"SplinterTokenizer"),mnt.forEach(t),pmo=r(Ok," or "),SI=n(Ok,"A",{href:!0});var gnt=s(SI);_mo=r(gnt,"SplinterTokenizerFast"),gnt.forEach(t),umo=r(Ok," (Splinter model)"),Ok.forEach(t),bmo=i(S),Ps=n(S,"LI",{});var Vk=s(Ps);tle=n(Vk,"STRONG",{});var hnt=s(tle);vmo=r(hnt,"squeezebert"),hnt.forEach(t),Fmo=r(Vk," \u2014 "),RI=n(Vk,"A",{href:!0});var pnt=s(RI);Tmo=r(pnt,"SqueezeBertTokenizer"),pnt.forEach(t),Mmo=r(Vk," or "),PI=n(Vk,"A",{href:!0});var _nt=s(PI);Emo=r(_nt,"SqueezeBertTokenizerFast"),_nt.forEach(t),Cmo=r(Vk," (SqueezeBERT model)"),Vk.forEach(t),wmo=i(S),Bs=n(S,"LI",{});var Xk=s(Bs);ale=n(Xk,"STRONG",{});var unt=s(ale);Amo=r(unt,"t5"),unt.forEach(t),Lmo=r(Xk," \u2014 "),BI=n(Xk,"A",{href:!0});var bnt=s(BI);ymo=r(bnt,"T5Tokenizer"),bnt.forEach(t),xmo=r(Xk," or "),II=n(Xk,"A",{href:!0});var vnt=s(II);$mo=r(vnt,"T5TokenizerFast"),vnt.forEach(t),kmo=r(Xk," (T5 model)"),Xk.forEach(t),Smo=i(S),ph=n(S,"LI",{});var WLe=s(ph);nle=n(WLe,"STRONG",{});var Fnt=s(nle);Rmo=r(Fnt,"tapas"),Fnt.forEach(t),Pmo=r(WLe," \u2014 "),NI=n(WLe,"A",{href:!0});var Tnt=s(NI);Bmo=r(Tnt,"TapasTokenizer"),Tnt.forEach(t),Imo=r(WLe," (TAPAS model)"),WLe.forEach(t),Nmo=i(S),_h=n(S,"LI",{});var HLe=s(_h);sle=n(HLe,"STRONG",{});var Mnt=s(sle);qmo=r(Mnt,"tapex"),Mnt.forEach(t),jmo=r(HLe," \u2014 "),qI=n(HLe,"A",{href:!0});var Ent=s(qI);Dmo=r(Ent,"TapexTokenizer"),Ent.forEach(t),Gmo=r(HLe," (TAPEX model)"),HLe.forEach(t),Omo=i(S),uh=n(S,"LI",{});var ULe=s(uh);lle=n(ULe,"STRONG",{});var Cnt=s(lle);Vmo=r(Cnt,"transfo-xl"),Cnt.forEach(t),Xmo=r(ULe," \u2014 "),jI=n(ULe,"A",{href:!0});var wnt=s(jI);zmo=r(wnt,"TransfoXLTokenizer"),wnt.forEach(t),Qmo=r(ULe," (Transformer-XL model)"),ULe.forEach(t),Wmo=i(S),Is=n(S,"LI",{});var zk=s(Is);ile=n(zk,"STRONG",{});var Ant=s(ile);Hmo=r(Ant,"vilt"),Ant.forEach(t),Umo=r(zk," \u2014 "),DI=n(zk,"A",{href:!0});var Lnt=s(DI);Jmo=r(Lnt,"BertTokenizer"),Lnt.forEach(t),Ymo=r(zk," or "),GI=n(zk,"A",{href:!0});var ynt=s(GI);Kmo=r(ynt,"BertTokenizerFast"),ynt.forEach(t),Zmo=r(zk," (ViLT model)"),zk.forEach(t),ego=i(S),Ns=n(S,"LI",{});var Qk=s(Ns);dle=n(Qk,"STRONG",{});var xnt=s(dle);ogo=r(xnt,"visual_bert"),xnt.forEach(t),rgo=r(Qk," \u2014 "),OI=n(Qk,"A",{href:!0});var $nt=s(OI);tgo=r($nt,"BertTokenizer"),$nt.forEach(t),ago=r(Qk," or "),VI=n(Qk,"A",{href:!0});var knt=s(VI);ngo=r(knt,"BertTokenizerFast"),knt.forEach(t),sgo=r(Qk," (VisualBERT model)"),Qk.forEach(t),lgo=i(S),bh=n(S,"LI",{});var JLe=s(bh);cle=n(JLe,"STRONG",{});var Snt=s(cle);igo=r(Snt,"wav2vec2"),Snt.forEach(t),dgo=r(JLe," \u2014 "),XI=n(JLe,"A",{href:!0});var Rnt=s(XI);cgo=r(Rnt,"Wav2Vec2CTCTokenizer"),Rnt.forEach(t),fgo=r(JLe," (Wav2Vec2 model)"),JLe.forEach(t),mgo=i(S),vh=n(S,"LI",{});var YLe=s(vh);fle=n(YLe,"STRONG",{});var Pnt=s(fle);ggo=r(Pnt,"wav2vec2-conformer"),Pnt.forEach(t),hgo=r(YLe," \u2014 "),zI=n(YLe,"A",{href:!0});var Bnt=s(zI);pgo=r(Bnt,"Wav2Vec2CTCTokenizer"),Bnt.forEach(t),_go=r(YLe," (Wav2Vec2-Conformer model)"),YLe.forEach(t),ugo=i(S),Fh=n(S,"LI",{});var KLe=s(Fh);mle=n(KLe,"STRONG",{});var Int=s(mle);bgo=r(Int,"wav2vec2_phoneme"),Int.forEach(t),vgo=r(KLe," \u2014 "),QI=n(KLe,"A",{href:!0});var Nnt=s(QI);Fgo=r(Nnt,"Wav2Vec2PhonemeCTCTokenizer"),Nnt.forEach(t),Tgo=r(KLe," (Wav2Vec2Phoneme model)"),KLe.forEach(t),Mgo=i(S),qs=n(S,"LI",{});var Wk=s(qs);gle=n(Wk,"STRONG",{});var qnt=s(gle);Ego=r(qnt,"xglm"),qnt.forEach(t),Cgo=r(Wk," \u2014 "),WI=n(Wk,"A",{href:!0});var jnt=s(WI);wgo=r(jnt,"XGLMTokenizer"),jnt.forEach(t),Ago=r(Wk," or "),HI=n(Wk,"A",{href:!0});var Dnt=s(HI);Lgo=r(Dnt,"XGLMTokenizerFast"),Dnt.forEach(t),ygo=r(Wk," (XGLM model)"),Wk.forEach(t),xgo=i(S),Th=n(S,"LI",{});var ZLe=s(Th);hle=n(ZLe,"STRONG",{});var Gnt=s(hle);$go=r(Gnt,"xlm"),Gnt.forEach(t),kgo=r(ZLe," \u2014 "),UI=n(ZLe,"A",{href:!0});var Ont=s(UI);Sgo=r(Ont,"XLMTokenizer"),Ont.forEach(t),Rgo=r(ZLe," (XLM model)"),ZLe.forEach(t),Pgo=i(S),Mh=n(S,"LI",{});var eye=s(Mh);ple=n(eye,"STRONG",{});var Vnt=s(ple);Bgo=r(Vnt,"xlm-prophetnet"),Vnt.forEach(t),Igo=r(eye," \u2014 "),JI=n(eye,"A",{href:!0});var Xnt=s(JI);Ngo=r(Xnt,"XLMProphetNetTokenizer"),Xnt.forEach(t),qgo=r(eye," (XLM-ProphetNet model)"),eye.forEach(t),jgo=i(S),js=n(S,"LI",{});var Hk=s(js);_le=n(Hk,"STRONG",{});var znt=s(_le);Dgo=r(znt,"xlm-roberta"),znt.forEach(t),Ggo=r(Hk," \u2014 "),YI=n(Hk,"A",{href:!0});var Qnt=s(YI);Ogo=r(Qnt,"XLMRobertaTokenizer"),Qnt.forEach(t),Vgo=r(Hk," or "),KI=n(Hk,"A",{href:!0});var Wnt=s(KI);Xgo=r(Wnt,"XLMRobertaTokenizerFast"),Wnt.forEach(t),zgo=r(Hk," (XLM-RoBERTa model)"),Hk.forEach(t),Qgo=i(S),Ds=n(S,"LI",{});var Uk=s(Ds);ule=n(Uk,"STRONG",{});var Hnt=s(ule);Wgo=r(Hnt,"xlm-roberta-xl"),Hnt.forEach(t),Hgo=r(Uk," \u2014 "),ZI=n(Uk,"A",{href:!0});var Unt=s(ZI);Ugo=r(Unt,"RobertaTokenizer"),Unt.forEach(t),Jgo=r(Uk," or "),eN=n(Uk,"A",{href:!0});var Jnt=s(eN);Ygo=r(Jnt,"RobertaTokenizerFast"),Jnt.forEach(t),Kgo=r(Uk," (XLM-RoBERTa-XL model)"),Uk.forEach(t),Zgo=i(S),Gs=n(S,"LI",{});var Jk=s(Gs);ble=n(Jk,"STRONG",{});var Ynt=s(ble);eho=r(Ynt,"xlnet"),Ynt.forEach(t),oho=r(Jk," \u2014 "),oN=n(Jk,"A",{href:!0});var Knt=s(oN);rho=r(Knt,"XLNetTokenizer"),Knt.forEach(t),tho=r(Jk," or "),rN=n(Jk,"A",{href:!0});var Znt=s(rN);aho=r(Znt,"XLNetTokenizerFast"),Znt.forEach(t),nho=r(Jk," (XLNet model)"),Jk.forEach(t),sho=i(S),Os=n(S,"LI",{});var Yk=s(Os);vle=n(Yk,"STRONG",{});var est=s(vle);lho=r(est,"yoso"),est.forEach(t),iho=r(Yk," \u2014 "),tN=n(Yk,"A",{href:!0});var ost=s(tN);dho=r(ost,"AlbertTokenizer"),ost.forEach(t),cho=r(Yk," or "),aN=n(Yk,"A",{href:!0});var rst=s(aN);fho=r(rst,"AlbertTokenizerFast"),rst.forEach(t),mho=r(Yk," (YOSO model)"),Yk.forEach(t),S.forEach(t),gho=i(Hs),T(Eh.$$.fragment,Hs),Hs.forEach(t),hho=i(Ws),Ch=n(Ws,"DIV",{class:!0});var UVe=s(Ch);T(OL.$$.fragment,UVe),pho=i(UVe),Fle=n(UVe,"P",{});var tst=s(Fle);_ho=r(tst,"Register a new tokenizer in this mapping."),tst.forEach(t),UVe.forEach(t),Ws.forEach(t),HGe=i(f),Si=n(f,"H2",{class:!0});var JVe=s(Si);wh=n(JVe,"A",{id:!0,class:!0,href:!0});var ast=s(wh);Tle=n(ast,"SPAN",{});var nst=s(Tle);T(VL.$$.fragment,nst),nst.forEach(t),ast.forEach(t),uho=i(JVe),Mle=n(JVe,"SPAN",{});var sst=s(Mle);bho=r(sst,"AutoFeatureExtractor"),sst.forEach(t),JVe.forEach(t),UGe=i(f),Lo=n(f,"DIV",{class:!0});var Us=s(Lo);T(XL.$$.fragment,Us),vho=i(Us),zL=n(Us,"P",{});var YVe=s(zL);Fho=r(YVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=n(YVe,"A",{href:!0});var lst=s(nN);Tho=r(lst,"AutoFeatureExtractor.from_pretrained()"),lst.forEach(t),Mho=r(YVe," class method."),YVe.forEach(t),Eho=i(Us),QL=n(Us,"P",{});var KVe=s(QL);Cho=r(KVe,"This class cannot be instantiated directly using "),Ele=n(KVe,"CODE",{});var ist=s(Ele);who=r(ist,"__init__()"),ist.forEach(t),Aho=r(KVe," (throws an error)."),KVe.forEach(t),Lho=i(Us),He=n(Us,"DIV",{class:!0});var ra=s(He);T(WL.$$.fragment,ra),yho=i(ra),Cle=n(ra,"P",{});var dst=s(Cle);xho=r(dst,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dst.forEach(t),$ho=i(ra),Sa=n(ra,"P",{});var $w=s(Sa);kho=r($w,"The feature extractor class to instantiate is selected based on the "),wle=n($w,"CODE",{});var cst=s(wle);Sho=r(cst,"model_type"),cst.forEach(t),Rho=r($w,` property of the config object
(either passed as an argument or loaded from `),Ale=n($w,"CODE",{});var fst=s(Ale);Pho=r(fst,"pretrained_model_name_or_path"),fst.forEach(t),Bho=r($w,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=n($w,"CODE",{});var mst=s(Lle);Iho=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),Nho=r($w,":"),$w.forEach(t),qho=i(ra),Y=n(ra,"UL",{});var K=s(Y);Ah=n(K,"LI",{});var oye=s(Ah);yle=n(oye,"STRONG",{});var gst=s(yle);jho=r(gst,"beit"),gst.forEach(t),Dho=r(oye," \u2014 "),sN=n(oye,"A",{href:!0});var hst=s(sN);Gho=r(hst,"BeitFeatureExtractor"),hst.forEach(t),Oho=r(oye," (BEiT model)"),oye.forEach(t),Vho=i(K),Lh=n(K,"LI",{});var rye=s(Lh);xle=n(rye,"STRONG",{});var pst=s(xle);Xho=r(pst,"clip"),pst.forEach(t),zho=r(rye," \u2014 "),lN=n(rye,"A",{href:!0});var _st=s(lN);Qho=r(_st,"CLIPFeatureExtractor"),_st.forEach(t),Who=r(rye," (CLIP model)"),rye.forEach(t),Hho=i(K),yh=n(K,"LI",{});var tye=s(yh);$le=n(tye,"STRONG",{});var ust=s($le);Uho=r(ust,"convnext"),ust.forEach(t),Jho=r(tye," \u2014 "),iN=n(tye,"A",{href:!0});var bst=s(iN);Yho=r(bst,"ConvNextFeatureExtractor"),bst.forEach(t),Kho=r(tye," (ConvNeXT model)"),tye.forEach(t),Zho=i(K),xh=n(K,"LI",{});var aye=s(xh);kle=n(aye,"STRONG",{});var vst=s(kle);epo=r(vst,"cvt"),vst.forEach(t),opo=r(aye," \u2014 "),dN=n(aye,"A",{href:!0});var Fst=s(dN);rpo=r(Fst,"ConvNextFeatureExtractor"),Fst.forEach(t),tpo=r(aye," (CvT model)"),aye.forEach(t),apo=i(K),$h=n(K,"LI",{});var nye=s($h);Sle=n(nye,"STRONG",{});var Tst=s(Sle);npo=r(Tst,"data2vec-audio"),Tst.forEach(t),spo=r(nye," \u2014 "),cN=n(nye,"A",{href:!0});var Mst=s(cN);lpo=r(Mst,"Wav2Vec2FeatureExtractor"),Mst.forEach(t),ipo=r(nye," (Data2VecAudio model)"),nye.forEach(t),dpo=i(K),kh=n(K,"LI",{});var sye=s(kh);Rle=n(sye,"STRONG",{});var Est=s(Rle);cpo=r(Est,"data2vec-vision"),Est.forEach(t),fpo=r(sye," \u2014 "),fN=n(sye,"A",{href:!0});var Cst=s(fN);mpo=r(Cst,"BeitFeatureExtractor"),Cst.forEach(t),gpo=r(sye," (Data2VecVision model)"),sye.forEach(t),hpo=i(K),Sh=n(K,"LI",{});var lye=s(Sh);Ple=n(lye,"STRONG",{});var wst=s(Ple);ppo=r(wst,"deit"),wst.forEach(t),_po=r(lye," \u2014 "),mN=n(lye,"A",{href:!0});var Ast=s(mN);upo=r(Ast,"DeiTFeatureExtractor"),Ast.forEach(t),bpo=r(lye," (DeiT model)"),lye.forEach(t),vpo=i(K),Rh=n(K,"LI",{});var iye=s(Rh);Ble=n(iye,"STRONG",{});var Lst=s(Ble);Fpo=r(Lst,"detr"),Lst.forEach(t),Tpo=r(iye," \u2014 "),gN=n(iye,"A",{href:!0});var yst=s(gN);Mpo=r(yst,"DetrFeatureExtractor"),yst.forEach(t),Epo=r(iye," (DETR model)"),iye.forEach(t),Cpo=i(K),Ph=n(K,"LI",{});var dye=s(Ph);Ile=n(dye,"STRONG",{});var xst=s(Ile);wpo=r(xst,"dpt"),xst.forEach(t),Apo=r(dye," \u2014 "),hN=n(dye,"A",{href:!0});var $st=s(hN);Lpo=r($st,"DPTFeatureExtractor"),$st.forEach(t),ypo=r(dye," (DPT model)"),dye.forEach(t),xpo=i(K),Bh=n(K,"LI",{});var cye=s(Bh);Nle=n(cye,"STRONG",{});var kst=s(Nle);$po=r(kst,"flava"),kst.forEach(t),kpo=r(cye," \u2014 "),pN=n(cye,"A",{href:!0});var Sst=s(pN);Spo=r(Sst,"FlavaFeatureExtractor"),Sst.forEach(t),Rpo=r(cye," (FLAVA model)"),cye.forEach(t),Ppo=i(K),Ih=n(K,"LI",{});var fye=s(Ih);qle=n(fye,"STRONG",{});var Rst=s(qle);Bpo=r(Rst,"glpn"),Rst.forEach(t),Ipo=r(fye," \u2014 "),_N=n(fye,"A",{href:!0});var Pst=s(_N);Npo=r(Pst,"GLPNFeatureExtractor"),Pst.forEach(t),qpo=r(fye," (GLPN model)"),fye.forEach(t),jpo=i(K),Nh=n(K,"LI",{});var mye=s(Nh);jle=n(mye,"STRONG",{});var Bst=s(jle);Dpo=r(Bst,"hubert"),Bst.forEach(t),Gpo=r(mye," \u2014 "),uN=n(mye,"A",{href:!0});var Ist=s(uN);Opo=r(Ist,"Wav2Vec2FeatureExtractor"),Ist.forEach(t),Vpo=r(mye," (Hubert model)"),mye.forEach(t),Xpo=i(K),qh=n(K,"LI",{});var gye=s(qh);Dle=n(gye,"STRONG",{});var Nst=s(Dle);zpo=r(Nst,"imagegpt"),Nst.forEach(t),Qpo=r(gye," \u2014 "),bN=n(gye,"A",{href:!0});var qst=s(bN);Wpo=r(qst,"ImageGPTFeatureExtractor"),qst.forEach(t),Hpo=r(gye," (ImageGPT model)"),gye.forEach(t),Upo=i(K),jh=n(K,"LI",{});var hye=s(jh);Gle=n(hye,"STRONG",{});var jst=s(Gle);Jpo=r(jst,"layoutlmv2"),jst.forEach(t),Ypo=r(hye," \u2014 "),vN=n(hye,"A",{href:!0});var Dst=s(vN);Kpo=r(Dst,"LayoutLMv2FeatureExtractor"),Dst.forEach(t),Zpo=r(hye," (LayoutLMv2 model)"),hye.forEach(t),e_o=i(K),Dh=n(K,"LI",{});var pye=s(Dh);Ole=n(pye,"STRONG",{});var Gst=s(Ole);o_o=r(Gst,"layoutlmv3"),Gst.forEach(t),r_o=r(pye," \u2014 "),FN=n(pye,"A",{href:!0});var Ost=s(FN);t_o=r(Ost,"LayoutLMv3FeatureExtractor"),Ost.forEach(t),a_o=r(pye," (LayoutLMv3 model)"),pye.forEach(t),n_o=i(K),Gh=n(K,"LI",{});var _ye=s(Gh);Vle=n(_ye,"STRONG",{});var Vst=s(Vle);s_o=r(Vst,"levit"),Vst.forEach(t),l_o=r(_ye," \u2014 "),TN=n(_ye,"A",{href:!0});var Xst=s(TN);i_o=r(Xst,"LevitFeatureExtractor"),Xst.forEach(t),d_o=r(_ye," (LeViT model)"),_ye.forEach(t),c_o=i(K),Oh=n(K,"LI",{});var uye=s(Oh);Xle=n(uye,"STRONG",{});var zst=s(Xle);f_o=r(zst,"maskformer"),zst.forEach(t),m_o=r(uye," \u2014 "),MN=n(uye,"A",{href:!0});var Qst=s(MN);g_o=r(Qst,"MaskFormerFeatureExtractor"),Qst.forEach(t),h_o=r(uye," (MaskFormer model)"),uye.forEach(t),p_o=i(K),Vh=n(K,"LI",{});var bye=s(Vh);zle=n(bye,"STRONG",{});var Wst=s(zle);__o=r(Wst,"mctct"),Wst.forEach(t),u_o=r(bye," \u2014 "),EN=n(bye,"A",{href:!0});var Hst=s(EN);b_o=r(Hst,"MCTCTFeatureExtractor"),Hst.forEach(t),v_o=r(bye," (M-CTC-T model)"),bye.forEach(t),F_o=i(K),Xh=n(K,"LI",{});var vye=s(Xh);Qle=n(vye,"STRONG",{});var Ust=s(Qle);T_o=r(Ust,"perceiver"),Ust.forEach(t),M_o=r(vye," \u2014 "),CN=n(vye,"A",{href:!0});var Jst=s(CN);E_o=r(Jst,"PerceiverFeatureExtractor"),Jst.forEach(t),C_o=r(vye," (Perceiver model)"),vye.forEach(t),w_o=i(K),zh=n(K,"LI",{});var Fye=s(zh);Wle=n(Fye,"STRONG",{});var Yst=s(Wle);A_o=r(Yst,"poolformer"),Yst.forEach(t),L_o=r(Fye," \u2014 "),wN=n(Fye,"A",{href:!0});var Kst=s(wN);y_o=r(Kst,"PoolFormerFeatureExtractor"),Kst.forEach(t),x_o=r(Fye," (PoolFormer model)"),Fye.forEach(t),$_o=i(K),Qh=n(K,"LI",{});var Tye=s(Qh);Hle=n(Tye,"STRONG",{});var Zst=s(Hle);k_o=r(Zst,"regnet"),Zst.forEach(t),S_o=r(Tye," \u2014 "),AN=n(Tye,"A",{href:!0});var elt=s(AN);R_o=r(elt,"ConvNextFeatureExtractor"),elt.forEach(t),P_o=r(Tye," (RegNet model)"),Tye.forEach(t),B_o=i(K),Wh=n(K,"LI",{});var Mye=s(Wh);Ule=n(Mye,"STRONG",{});var olt=s(Ule);I_o=r(olt,"resnet"),olt.forEach(t),N_o=r(Mye," \u2014 "),LN=n(Mye,"A",{href:!0});var rlt=s(LN);q_o=r(rlt,"ConvNextFeatureExtractor"),rlt.forEach(t),j_o=r(Mye," (ResNet model)"),Mye.forEach(t),D_o=i(K),Hh=n(K,"LI",{});var Eye=s(Hh);Jle=n(Eye,"STRONG",{});var tlt=s(Jle);G_o=r(tlt,"segformer"),tlt.forEach(t),O_o=r(Eye," \u2014 "),yN=n(Eye,"A",{href:!0});var alt=s(yN);V_o=r(alt,"SegformerFeatureExtractor"),alt.forEach(t),X_o=r(Eye," (SegFormer model)"),Eye.forEach(t),z_o=i(K),Uh=n(K,"LI",{});var Cye=s(Uh);Yle=n(Cye,"STRONG",{});var nlt=s(Yle);Q_o=r(nlt,"speech_to_text"),nlt.forEach(t),W_o=r(Cye," \u2014 "),xN=n(Cye,"A",{href:!0});var slt=s(xN);H_o=r(slt,"Speech2TextFeatureExtractor"),slt.forEach(t),U_o=r(Cye," (Speech2Text model)"),Cye.forEach(t),J_o=i(K),Jh=n(K,"LI",{});var wye=s(Jh);Kle=n(wye,"STRONG",{});var llt=s(Kle);Y_o=r(llt,"swin"),llt.forEach(t),K_o=r(wye," \u2014 "),$N=n(wye,"A",{href:!0});var ilt=s($N);Z_o=r(ilt,"ViTFeatureExtractor"),ilt.forEach(t),euo=r(wye," (Swin Transformer model)"),wye.forEach(t),ouo=i(K),Yh=n(K,"LI",{});var Aye=s(Yh);Zle=n(Aye,"STRONG",{});var dlt=s(Zle);ruo=r(dlt,"van"),dlt.forEach(t),tuo=r(Aye," \u2014 "),kN=n(Aye,"A",{href:!0});var clt=s(kN);auo=r(clt,"ConvNextFeatureExtractor"),clt.forEach(t),nuo=r(Aye," (VAN model)"),Aye.forEach(t),suo=i(K),Kh=n(K,"LI",{});var Lye=s(Kh);eie=n(Lye,"STRONG",{});var flt=s(eie);luo=r(flt,"vilt"),flt.forEach(t),iuo=r(Lye," \u2014 "),SN=n(Lye,"A",{href:!0});var mlt=s(SN);duo=r(mlt,"ViltFeatureExtractor"),mlt.forEach(t),cuo=r(Lye," (ViLT model)"),Lye.forEach(t),fuo=i(K),Zh=n(K,"LI",{});var yye=s(Zh);oie=n(yye,"STRONG",{});var glt=s(oie);muo=r(glt,"vit"),glt.forEach(t),guo=r(yye," \u2014 "),RN=n(yye,"A",{href:!0});var hlt=s(RN);huo=r(hlt,"ViTFeatureExtractor"),hlt.forEach(t),puo=r(yye," (ViT model)"),yye.forEach(t),_uo=i(K),ep=n(K,"LI",{});var xye=s(ep);rie=n(xye,"STRONG",{});var plt=s(rie);uuo=r(plt,"vit_mae"),plt.forEach(t),buo=r(xye," \u2014 "),PN=n(xye,"A",{href:!0});var _lt=s(PN);vuo=r(_lt,"ViTFeatureExtractor"),_lt.forEach(t),Fuo=r(xye," (ViTMAE model)"),xye.forEach(t),Tuo=i(K),op=n(K,"LI",{});var $ye=s(op);tie=n($ye,"STRONG",{});var ult=s(tie);Muo=r(ult,"wav2vec2"),ult.forEach(t),Euo=r($ye," \u2014 "),BN=n($ye,"A",{href:!0});var blt=s(BN);Cuo=r(blt,"Wav2Vec2FeatureExtractor"),blt.forEach(t),wuo=r($ye," (Wav2Vec2 model)"),$ye.forEach(t),Auo=i(K),rp=n(K,"LI",{});var kye=s(rp);aie=n(kye,"STRONG",{});var vlt=s(aie);Luo=r(vlt,"wav2vec2-conformer"),vlt.forEach(t),yuo=r(kye," \u2014 "),IN=n(kye,"A",{href:!0});var Flt=s(IN);xuo=r(Flt,"Wav2Vec2FeatureExtractor"),Flt.forEach(t),$uo=r(kye," (Wav2Vec2-Conformer model)"),kye.forEach(t),kuo=i(K),tp=n(K,"LI",{});var Sye=s(tp);nie=n(Sye,"STRONG",{});var Tlt=s(nie);Suo=r(Tlt,"yolos"),Tlt.forEach(t),Ruo=r(Sye," \u2014 "),NN=n(Sye,"A",{href:!0});var Mlt=s(NN);Puo=r(Mlt,"YolosFeatureExtractor"),Mlt.forEach(t),Buo=r(Sye," (YOLOS model)"),Sye.forEach(t),K.forEach(t),Iuo=i(ra),T(ap.$$.fragment,ra),Nuo=i(ra),T(np.$$.fragment,ra),ra.forEach(t),quo=i(Us),sp=n(Us,"DIV",{class:!0});var ZVe=s(sp);T(HL.$$.fragment,ZVe),juo=i(ZVe),sie=n(ZVe,"P",{});var Elt=s(sie);Duo=r(Elt,"Register a new feature extractor for this class."),Elt.forEach(t),ZVe.forEach(t),Us.forEach(t),JGe=i(f),Ri=n(f,"H2",{class:!0});var eXe=s(Ri);lp=n(eXe,"A",{id:!0,class:!0,href:!0});var Clt=s(lp);lie=n(Clt,"SPAN",{});var wlt=s(lie);T(UL.$$.fragment,wlt),wlt.forEach(t),Clt.forEach(t),Guo=i(eXe),iie=n(eXe,"SPAN",{});var Alt=s(iie);Ouo=r(Alt,"AutoProcessor"),Alt.forEach(t),eXe.forEach(t),YGe=i(f),yo=n(f,"DIV",{class:!0});var Js=s(yo);T(JL.$$.fragment,Js),Vuo=i(Js),YL=n(Js,"P",{});var oXe=s(YL);Xuo=r(oXe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=n(oXe,"A",{href:!0});var Llt=s(qN);zuo=r(Llt,"AutoProcessor.from_pretrained()"),Llt.forEach(t),Quo=r(oXe," class method."),oXe.forEach(t),Wuo=i(Js),KL=n(Js,"P",{});var rXe=s(KL);Huo=r(rXe,"This class cannot be instantiated directly using "),die=n(rXe,"CODE",{});var ylt=s(die);Uuo=r(ylt,"__init__()"),ylt.forEach(t),Juo=r(rXe," (throws an error)."),rXe.forEach(t),Yuo=i(Js),Ue=n(Js,"DIV",{class:!0});var ta=s(Ue);T(ZL.$$.fragment,ta),Kuo=i(ta),cie=n(ta,"P",{});var xlt=s(cie);Zuo=r(xlt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xlt.forEach(t),e7o=i(ta),Pi=n(ta,"P",{});var boe=s(Pi);o7o=r(boe,"The processor class to instantiate is selected based on the "),fie=n(boe,"CODE",{});var $lt=s(fie);r7o=r($lt,"model_type"),$lt.forEach(t),t7o=r(boe,` property of the config object (either
passed as an argument or loaded from `),mie=n(boe,"CODE",{});var klt=s(mie);a7o=r(klt,"pretrained_model_name_or_path"),klt.forEach(t),n7o=r(boe," if possible):"),boe.forEach(t),s7o=i(ta),he=n(ta,"UL",{});var ue=s(he);ip=n(ue,"LI",{});var Rye=s(ip);gie=n(Rye,"STRONG",{});var Slt=s(gie);l7o=r(Slt,"clip"),Slt.forEach(t),i7o=r(Rye," \u2014 "),jN=n(Rye,"A",{href:!0});var Rlt=s(jN);d7o=r(Rlt,"CLIPProcessor"),Rlt.forEach(t),c7o=r(Rye," (CLIP model)"),Rye.forEach(t),f7o=i(ue),dp=n(ue,"LI",{});var Pye=s(dp);hie=n(Pye,"STRONG",{});var Plt=s(hie);m7o=r(Plt,"flava"),Plt.forEach(t),g7o=r(Pye," \u2014 "),pie=n(Pye,"CODE",{});var Blt=s(pie);h7o=r(Blt,"FLAVAProcessor"),Blt.forEach(t),p7o=r(Pye," (FLAVA model)"),Pye.forEach(t),_7o=i(ue),cp=n(ue,"LI",{});var Bye=s(cp);_ie=n(Bye,"STRONG",{});var Ilt=s(_ie);u7o=r(Ilt,"layoutlmv2"),Ilt.forEach(t),b7o=r(Bye," \u2014 "),DN=n(Bye,"A",{href:!0});var Nlt=s(DN);v7o=r(Nlt,"LayoutLMv2Processor"),Nlt.forEach(t),F7o=r(Bye," (LayoutLMv2 model)"),Bye.forEach(t),T7o=i(ue),fp=n(ue,"LI",{});var Iye=s(fp);uie=n(Iye,"STRONG",{});var qlt=s(uie);M7o=r(qlt,"layoutlmv3"),qlt.forEach(t),E7o=r(Iye," \u2014 "),GN=n(Iye,"A",{href:!0});var jlt=s(GN);C7o=r(jlt,"LayoutLMv3Processor"),jlt.forEach(t),w7o=r(Iye," (LayoutLMv3 model)"),Iye.forEach(t),A7o=i(ue),mp=n(ue,"LI",{});var Nye=s(mp);bie=n(Nye,"STRONG",{});var Dlt=s(bie);L7o=r(Dlt,"layoutxlm"),Dlt.forEach(t),y7o=r(Nye," \u2014 "),ON=n(Nye,"A",{href:!0});var Glt=s(ON);x7o=r(Glt,"LayoutXLMProcessor"),Glt.forEach(t),$7o=r(Nye," (LayoutXLM model)"),Nye.forEach(t),k7o=i(ue),gp=n(ue,"LI",{});var qye=s(gp);vie=n(qye,"STRONG",{});var Olt=s(vie);S7o=r(Olt,"sew"),Olt.forEach(t),R7o=r(qye," \u2014 "),VN=n(qye,"A",{href:!0});var Vlt=s(VN);P7o=r(Vlt,"Wav2Vec2Processor"),Vlt.forEach(t),B7o=r(qye," (SEW model)"),qye.forEach(t),I7o=i(ue),hp=n(ue,"LI",{});var jye=s(hp);Fie=n(jye,"STRONG",{});var Xlt=s(Fie);N7o=r(Xlt,"sew-d"),Xlt.forEach(t),q7o=r(jye," \u2014 "),XN=n(jye,"A",{href:!0});var zlt=s(XN);j7o=r(zlt,"Wav2Vec2Processor"),zlt.forEach(t),D7o=r(jye," (SEW-D model)"),jye.forEach(t),G7o=i(ue),pp=n(ue,"LI",{});var Dye=s(pp);Tie=n(Dye,"STRONG",{});var Qlt=s(Tie);O7o=r(Qlt,"speech_to_text"),Qlt.forEach(t),V7o=r(Dye," \u2014 "),zN=n(Dye,"A",{href:!0});var Wlt=s(zN);X7o=r(Wlt,"Speech2TextProcessor"),Wlt.forEach(t),z7o=r(Dye," (Speech2Text model)"),Dye.forEach(t),Q7o=i(ue),_p=n(ue,"LI",{});var Gye=s(_p);Mie=n(Gye,"STRONG",{});var Hlt=s(Mie);W7o=r(Hlt,"speech_to_text_2"),Hlt.forEach(t),H7o=r(Gye," \u2014 "),QN=n(Gye,"A",{href:!0});var Ult=s(QN);U7o=r(Ult,"Speech2Text2Processor"),Ult.forEach(t),J7o=r(Gye," (Speech2Text2 model)"),Gye.forEach(t),Y7o=i(ue),up=n(ue,"LI",{});var Oye=s(up);Eie=n(Oye,"STRONG",{});var Jlt=s(Eie);K7o=r(Jlt,"trocr"),Jlt.forEach(t),Z7o=r(Oye," \u2014 "),WN=n(Oye,"A",{href:!0});var Ylt=s(WN);e1o=r(Ylt,"TrOCRProcessor"),Ylt.forEach(t),o1o=r(Oye," (TrOCR model)"),Oye.forEach(t),r1o=i(ue),bp=n(ue,"LI",{});var Vye=s(bp);Cie=n(Vye,"STRONG",{});var Klt=s(Cie);t1o=r(Klt,"unispeech"),Klt.forEach(t),a1o=r(Vye," \u2014 "),HN=n(Vye,"A",{href:!0});var Zlt=s(HN);n1o=r(Zlt,"Wav2Vec2Processor"),Zlt.forEach(t),s1o=r(Vye," (UniSpeech model)"),Vye.forEach(t),l1o=i(ue),vp=n(ue,"LI",{});var Xye=s(vp);wie=n(Xye,"STRONG",{});var eit=s(wie);i1o=r(eit,"unispeech-sat"),eit.forEach(t),d1o=r(Xye," \u2014 "),UN=n(Xye,"A",{href:!0});var oit=s(UN);c1o=r(oit,"Wav2Vec2Processor"),oit.forEach(t),f1o=r(Xye," (UniSpeechSat model)"),Xye.forEach(t),m1o=i(ue),Fp=n(ue,"LI",{});var zye=s(Fp);Aie=n(zye,"STRONG",{});var rit=s(Aie);g1o=r(rit,"vilt"),rit.forEach(t),h1o=r(zye," \u2014 "),JN=n(zye,"A",{href:!0});var tit=s(JN);p1o=r(tit,"ViltProcessor"),tit.forEach(t),_1o=r(zye," (ViLT model)"),zye.forEach(t),u1o=i(ue),Tp=n(ue,"LI",{});var Qye=s(Tp);Lie=n(Qye,"STRONG",{});var ait=s(Lie);b1o=r(ait,"vision-text-dual-encoder"),ait.forEach(t),v1o=r(Qye," \u2014 "),YN=n(Qye,"A",{href:!0});var nit=s(YN);F1o=r(nit,"VisionTextDualEncoderProcessor"),nit.forEach(t),T1o=r(Qye," (VisionTextDualEncoder model)"),Qye.forEach(t),M1o=i(ue),Mp=n(ue,"LI",{});var Wye=s(Mp);yie=n(Wye,"STRONG",{});var sit=s(yie);E1o=r(sit,"wav2vec2"),sit.forEach(t),C1o=r(Wye," \u2014 "),KN=n(Wye,"A",{href:!0});var lit=s(KN);w1o=r(lit,"Wav2Vec2Processor"),lit.forEach(t),A1o=r(Wye," (Wav2Vec2 model)"),Wye.forEach(t),L1o=i(ue),Ep=n(ue,"LI",{});var Hye=s(Ep);xie=n(Hye,"STRONG",{});var iit=s(xie);y1o=r(iit,"wav2vec2-conformer"),iit.forEach(t),x1o=r(Hye," \u2014 "),ZN=n(Hye,"A",{href:!0});var dit=s(ZN);$1o=r(dit,"Wav2Vec2Processor"),dit.forEach(t),k1o=r(Hye," (Wav2Vec2-Conformer model)"),Hye.forEach(t),S1o=i(ue),Cp=n(ue,"LI",{});var Uye=s(Cp);$ie=n(Uye,"STRONG",{});var cit=s($ie);R1o=r(cit,"wavlm"),cit.forEach(t),P1o=r(Uye," \u2014 "),eq=n(Uye,"A",{href:!0});var fit=s(eq);B1o=r(fit,"Wav2Vec2Processor"),fit.forEach(t),I1o=r(Uye," (WavLM model)"),Uye.forEach(t),ue.forEach(t),N1o=i(ta),T(wp.$$.fragment,ta),q1o=i(ta),T(Ap.$$.fragment,ta),ta.forEach(t),j1o=i(Js),Lp=n(Js,"DIV",{class:!0});var tXe=s(Lp);T(ey.$$.fragment,tXe),D1o=i(tXe),kie=n(tXe,"P",{});var mit=s(kie);G1o=r(mit,"Register a new processor for this class."),mit.forEach(t),tXe.forEach(t),Js.forEach(t),KGe=i(f),Bi=n(f,"H2",{class:!0});var aXe=s(Bi);yp=n(aXe,"A",{id:!0,class:!0,href:!0});var git=s(yp);Sie=n(git,"SPAN",{});var hit=s(Sie);T(oy.$$.fragment,hit),hit.forEach(t),git.forEach(t),O1o=i(aXe),Rie=n(aXe,"SPAN",{});var pit=s(Rie);V1o=r(pit,"AutoModel"),pit.forEach(t),aXe.forEach(t),ZGe=i(f),xo=n(f,"DIV",{class:!0});var Ys=s(xo);T(ry.$$.fragment,Ys),X1o=i(Ys),Ii=n(Ys,"P",{});var voe=s(Ii);z1o=r(voe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=n(voe,"A",{href:!0});var _it=s(oq);Q1o=r(_it,"from_pretrained()"),_it.forEach(t),W1o=r(voe," class method or the "),rq=n(voe,"A",{href:!0});var uit=s(rq);H1o=r(uit,"from_config()"),uit.forEach(t),U1o=r(voe,` class
method.`),voe.forEach(t),J1o=i(Ys),ty=n(Ys,"P",{});var nXe=s(ty);Y1o=r(nXe,"This class cannot be instantiated directly using "),Pie=n(nXe,"CODE",{});var bit=s(Pie);K1o=r(bit,"__init__()"),bit.forEach(t),Z1o=r(nXe," (throws an error)."),nXe.forEach(t),e2o=i(Ys),nt=n(Ys,"DIV",{class:!0});var kw=s(nt);T(ay.$$.fragment,kw),o2o=i(kw),Bie=n(kw,"P",{});var vit=s(Bie);r2o=r(vit,"Instantiates one of the base model classes of the library from a configuration."),vit.forEach(t),t2o=i(kw),Ni=n(kw,"P",{});var Foe=s(Ni);a2o=r(Foe,`Note:
Loading a model from its configuration file does `),Iie=n(Foe,"STRONG",{});var Fit=s(Iie);n2o=r(Fit,"not"),Fit.forEach(t),s2o=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=n(Foe,"A",{href:!0});var Tit=s(tq);l2o=r(Tit,"from_pretrained()"),Tit.forEach(t),i2o=r(Foe," to load the model weights."),Foe.forEach(t),d2o=i(kw),T(xp.$$.fragment,kw),kw.forEach(t),c2o=i(Ys),Je=n(Ys,"DIV",{class:!0});var aa=s(Je);T(ny.$$.fragment,aa),f2o=i(aa),Nie=n(aa,"P",{});var Mit=s(Nie);m2o=r(Mit,"Instantiate one of the base model classes of the library from a pretrained model."),Mit.forEach(t),g2o=i(aa),Ra=n(aa,"P",{});var Sw=s(Ra);h2o=r(Sw,"The model class to instantiate is selected based on the "),qie=n(Sw,"CODE",{});var Eit=s(qie);p2o=r(Eit,"model_type"),Eit.forEach(t),_2o=r(Sw,` property of the config object (either
passed as an argument or loaded from `),jie=n(Sw,"CODE",{});var Cit=s(jie);u2o=r(Cit,"pretrained_model_name_or_path"),Cit.forEach(t),b2o=r(Sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(Sw,"CODE",{});var wit=s(Die);v2o=r(wit,"pretrained_model_name_or_path"),wit.forEach(t),F2o=r(Sw,":"),Sw.forEach(t),T2o=i(aa),y=n(aa,"UL",{});var $=s(y);$p=n($,"LI",{});var Jye=s($p);Gie=n(Jye,"STRONG",{});var Ait=s(Gie);M2o=r(Ait,"albert"),Ait.forEach(t),E2o=r(Jye," \u2014 "),aq=n(Jye,"A",{href:!0});var Lit=s(aq);C2o=r(Lit,"AlbertModel"),Lit.forEach(t),w2o=r(Jye," (ALBERT model)"),Jye.forEach(t),A2o=i($),kp=n($,"LI",{});var Yye=s(kp);Oie=n(Yye,"STRONG",{});var yit=s(Oie);L2o=r(yit,"bart"),yit.forEach(t),y2o=r(Yye," \u2014 "),nq=n(Yye,"A",{href:!0});var xit=s(nq);x2o=r(xit,"BartModel"),xit.forEach(t),$2o=r(Yye," (BART model)"),Yye.forEach(t),k2o=i($),Sp=n($,"LI",{});var Kye=s(Sp);Vie=n(Kye,"STRONG",{});var $it=s(Vie);S2o=r($it,"beit"),$it.forEach(t),R2o=r(Kye," \u2014 "),sq=n(Kye,"A",{href:!0});var kit=s(sq);P2o=r(kit,"BeitModel"),kit.forEach(t),B2o=r(Kye," (BEiT model)"),Kye.forEach(t),I2o=i($),Rp=n($,"LI",{});var Zye=s(Rp);Xie=n(Zye,"STRONG",{});var Sit=s(Xie);N2o=r(Sit,"bert"),Sit.forEach(t),q2o=r(Zye," \u2014 "),lq=n(Zye,"A",{href:!0});var Rit=s(lq);j2o=r(Rit,"BertModel"),Rit.forEach(t),D2o=r(Zye," (BERT model)"),Zye.forEach(t),G2o=i($),Pp=n($,"LI",{});var e8e=s(Pp);zie=n(e8e,"STRONG",{});var Pit=s(zie);O2o=r(Pit,"bert-generation"),Pit.forEach(t),V2o=r(e8e," \u2014 "),iq=n(e8e,"A",{href:!0});var Bit=s(iq);X2o=r(Bit,"BertGenerationEncoder"),Bit.forEach(t),z2o=r(e8e," (Bert Generation model)"),e8e.forEach(t),Q2o=i($),Bp=n($,"LI",{});var o8e=s(Bp);Qie=n(o8e,"STRONG",{});var Iit=s(Qie);W2o=r(Iit,"big_bird"),Iit.forEach(t),H2o=r(o8e," \u2014 "),dq=n(o8e,"A",{href:!0});var Nit=s(dq);U2o=r(Nit,"BigBirdModel"),Nit.forEach(t),J2o=r(o8e," (BigBird model)"),o8e.forEach(t),Y2o=i($),Ip=n($,"LI",{});var r8e=s(Ip);Wie=n(r8e,"STRONG",{});var qit=s(Wie);K2o=r(qit,"bigbird_pegasus"),qit.forEach(t),Z2o=r(r8e," \u2014 "),cq=n(r8e,"A",{href:!0});var jit=s(cq);ebo=r(jit,"BigBirdPegasusModel"),jit.forEach(t),obo=r(r8e," (BigBird-Pegasus model)"),r8e.forEach(t),rbo=i($),Np=n($,"LI",{});var t8e=s(Np);Hie=n(t8e,"STRONG",{});var Dit=s(Hie);tbo=r(Dit,"blenderbot"),Dit.forEach(t),abo=r(t8e," \u2014 "),fq=n(t8e,"A",{href:!0});var Git=s(fq);nbo=r(Git,"BlenderbotModel"),Git.forEach(t),sbo=r(t8e," (Blenderbot model)"),t8e.forEach(t),lbo=i($),qp=n($,"LI",{});var a8e=s(qp);Uie=n(a8e,"STRONG",{});var Oit=s(Uie);ibo=r(Oit,"blenderbot-small"),Oit.forEach(t),dbo=r(a8e," \u2014 "),mq=n(a8e,"A",{href:!0});var Vit=s(mq);cbo=r(Vit,"BlenderbotSmallModel"),Vit.forEach(t),fbo=r(a8e," (BlenderbotSmall model)"),a8e.forEach(t),mbo=i($),jp=n($,"LI",{});var n8e=s(jp);Jie=n(n8e,"STRONG",{});var Xit=s(Jie);gbo=r(Xit,"bloom"),Xit.forEach(t),hbo=r(n8e," \u2014 "),gq=n(n8e,"A",{href:!0});var zit=s(gq);pbo=r(zit,"BloomModel"),zit.forEach(t),_bo=r(n8e," (BLOOM model)"),n8e.forEach(t),ubo=i($),Dp=n($,"LI",{});var s8e=s(Dp);Yie=n(s8e,"STRONG",{});var Qit=s(Yie);bbo=r(Qit,"camembert"),Qit.forEach(t),vbo=r(s8e," \u2014 "),hq=n(s8e,"A",{href:!0});var Wit=s(hq);Fbo=r(Wit,"CamembertModel"),Wit.forEach(t),Tbo=r(s8e," (CamemBERT model)"),s8e.forEach(t),Mbo=i($),Gp=n($,"LI",{});var l8e=s(Gp);Kie=n(l8e,"STRONG",{});var Hit=s(Kie);Ebo=r(Hit,"canine"),Hit.forEach(t),Cbo=r(l8e," \u2014 "),pq=n(l8e,"A",{href:!0});var Uit=s(pq);wbo=r(Uit,"CanineModel"),Uit.forEach(t),Abo=r(l8e," (CANINE model)"),l8e.forEach(t),Lbo=i($),Op=n($,"LI",{});var i8e=s(Op);Zie=n(i8e,"STRONG",{});var Jit=s(Zie);ybo=r(Jit,"clip"),Jit.forEach(t),xbo=r(i8e," \u2014 "),_q=n(i8e,"A",{href:!0});var Yit=s(_q);$bo=r(Yit,"CLIPModel"),Yit.forEach(t),kbo=r(i8e," (CLIP model)"),i8e.forEach(t),Sbo=i($),Vp=n($,"LI",{});var d8e=s(Vp);ede=n(d8e,"STRONG",{});var Kit=s(ede);Rbo=r(Kit,"convbert"),Kit.forEach(t),Pbo=r(d8e," \u2014 "),uq=n(d8e,"A",{href:!0});var Zit=s(uq);Bbo=r(Zit,"ConvBertModel"),Zit.forEach(t),Ibo=r(d8e," (ConvBERT model)"),d8e.forEach(t),Nbo=i($),Xp=n($,"LI",{});var c8e=s(Xp);ode=n(c8e,"STRONG",{});var edt=s(ode);qbo=r(edt,"convnext"),edt.forEach(t),jbo=r(c8e," \u2014 "),bq=n(c8e,"A",{href:!0});var odt=s(bq);Dbo=r(odt,"ConvNextModel"),odt.forEach(t),Gbo=r(c8e," (ConvNeXT model)"),c8e.forEach(t),Obo=i($),zp=n($,"LI",{});var f8e=s(zp);rde=n(f8e,"STRONG",{});var rdt=s(rde);Vbo=r(rdt,"ctrl"),rdt.forEach(t),Xbo=r(f8e," \u2014 "),vq=n(f8e,"A",{href:!0});var tdt=s(vq);zbo=r(tdt,"CTRLModel"),tdt.forEach(t),Qbo=r(f8e," (CTRL model)"),f8e.forEach(t),Wbo=i($),Qp=n($,"LI",{});var m8e=s(Qp);tde=n(m8e,"STRONG",{});var adt=s(tde);Hbo=r(adt,"cvt"),adt.forEach(t),Ubo=r(m8e," \u2014 "),Fq=n(m8e,"A",{href:!0});var ndt=s(Fq);Jbo=r(ndt,"CvtModel"),ndt.forEach(t),Ybo=r(m8e," (CvT model)"),m8e.forEach(t),Kbo=i($),Wp=n($,"LI",{});var g8e=s(Wp);ade=n(g8e,"STRONG",{});var sdt=s(ade);Zbo=r(sdt,"data2vec-audio"),sdt.forEach(t),evo=r(g8e," \u2014 "),Tq=n(g8e,"A",{href:!0});var ldt=s(Tq);ovo=r(ldt,"Data2VecAudioModel"),ldt.forEach(t),rvo=r(g8e," (Data2VecAudio model)"),g8e.forEach(t),tvo=i($),Hp=n($,"LI",{});var h8e=s(Hp);nde=n(h8e,"STRONG",{});var idt=s(nde);avo=r(idt,"data2vec-text"),idt.forEach(t),nvo=r(h8e," \u2014 "),Mq=n(h8e,"A",{href:!0});var ddt=s(Mq);svo=r(ddt,"Data2VecTextModel"),ddt.forEach(t),lvo=r(h8e," (Data2VecText model)"),h8e.forEach(t),ivo=i($),Up=n($,"LI",{});var p8e=s(Up);sde=n(p8e,"STRONG",{});var cdt=s(sde);dvo=r(cdt,"data2vec-vision"),cdt.forEach(t),cvo=r(p8e," \u2014 "),Eq=n(p8e,"A",{href:!0});var fdt=s(Eq);fvo=r(fdt,"Data2VecVisionModel"),fdt.forEach(t),mvo=r(p8e," (Data2VecVision model)"),p8e.forEach(t),gvo=i($),Jp=n($,"LI",{});var _8e=s(Jp);lde=n(_8e,"STRONG",{});var mdt=s(lde);hvo=r(mdt,"deberta"),mdt.forEach(t),pvo=r(_8e," \u2014 "),Cq=n(_8e,"A",{href:!0});var gdt=s(Cq);_vo=r(gdt,"DebertaModel"),gdt.forEach(t),uvo=r(_8e," (DeBERTa model)"),_8e.forEach(t),bvo=i($),Yp=n($,"LI",{});var u8e=s(Yp);ide=n(u8e,"STRONG",{});var hdt=s(ide);vvo=r(hdt,"deberta-v2"),hdt.forEach(t),Fvo=r(u8e," \u2014 "),wq=n(u8e,"A",{href:!0});var pdt=s(wq);Tvo=r(pdt,"DebertaV2Model"),pdt.forEach(t),Mvo=r(u8e," (DeBERTa-v2 model)"),u8e.forEach(t),Evo=i($),Kp=n($,"LI",{});var b8e=s(Kp);dde=n(b8e,"STRONG",{});var _dt=s(dde);Cvo=r(_dt,"decision_transformer"),_dt.forEach(t),wvo=r(b8e," \u2014 "),Aq=n(b8e,"A",{href:!0});var udt=s(Aq);Avo=r(udt,"DecisionTransformerModel"),udt.forEach(t),Lvo=r(b8e," (Decision Transformer model)"),b8e.forEach(t),yvo=i($),Zp=n($,"LI",{});var v8e=s(Zp);cde=n(v8e,"STRONG",{});var bdt=s(cde);xvo=r(bdt,"deit"),bdt.forEach(t),$vo=r(v8e," \u2014 "),Lq=n(v8e,"A",{href:!0});var vdt=s(Lq);kvo=r(vdt,"DeiTModel"),vdt.forEach(t),Svo=r(v8e," (DeiT model)"),v8e.forEach(t),Rvo=i($),e_=n($,"LI",{});var F8e=s(e_);fde=n(F8e,"STRONG",{});var Fdt=s(fde);Pvo=r(Fdt,"detr"),Fdt.forEach(t),Bvo=r(F8e," \u2014 "),yq=n(F8e,"A",{href:!0});var Tdt=s(yq);Ivo=r(Tdt,"DetrModel"),Tdt.forEach(t),Nvo=r(F8e," (DETR model)"),F8e.forEach(t),qvo=i($),o_=n($,"LI",{});var T8e=s(o_);mde=n(T8e,"STRONG",{});var Mdt=s(mde);jvo=r(Mdt,"distilbert"),Mdt.forEach(t),Dvo=r(T8e," \u2014 "),xq=n(T8e,"A",{href:!0});var Edt=s(xq);Gvo=r(Edt,"DistilBertModel"),Edt.forEach(t),Ovo=r(T8e," (DistilBERT model)"),T8e.forEach(t),Vvo=i($),r_=n($,"LI",{});var M8e=s(r_);gde=n(M8e,"STRONG",{});var Cdt=s(gde);Xvo=r(Cdt,"dpr"),Cdt.forEach(t),zvo=r(M8e," \u2014 "),$q=n(M8e,"A",{href:!0});var wdt=s($q);Qvo=r(wdt,"DPRQuestionEncoder"),wdt.forEach(t),Wvo=r(M8e," (DPR model)"),M8e.forEach(t),Hvo=i($),t_=n($,"LI",{});var E8e=s(t_);hde=n(E8e,"STRONG",{});var Adt=s(hde);Uvo=r(Adt,"dpt"),Adt.forEach(t),Jvo=r(E8e," \u2014 "),kq=n(E8e,"A",{href:!0});var Ldt=s(kq);Yvo=r(Ldt,"DPTModel"),Ldt.forEach(t),Kvo=r(E8e," (DPT model)"),E8e.forEach(t),Zvo=i($),a_=n($,"LI",{});var C8e=s(a_);pde=n(C8e,"STRONG",{});var ydt=s(pde);eFo=r(ydt,"electra"),ydt.forEach(t),oFo=r(C8e," \u2014 "),Sq=n(C8e,"A",{href:!0});var xdt=s(Sq);rFo=r(xdt,"ElectraModel"),xdt.forEach(t),tFo=r(C8e," (ELECTRA model)"),C8e.forEach(t),aFo=i($),n_=n($,"LI",{});var w8e=s(n_);_de=n(w8e,"STRONG",{});var $dt=s(_de);nFo=r($dt,"flaubert"),$dt.forEach(t),sFo=r(w8e," \u2014 "),Rq=n(w8e,"A",{href:!0});var kdt=s(Rq);lFo=r(kdt,"FlaubertModel"),kdt.forEach(t),iFo=r(w8e," (FlauBERT model)"),w8e.forEach(t),dFo=i($),s_=n($,"LI",{});var A8e=s(s_);ude=n(A8e,"STRONG",{});var Sdt=s(ude);cFo=r(Sdt,"flava"),Sdt.forEach(t),fFo=r(A8e," \u2014 "),Pq=n(A8e,"A",{href:!0});var Rdt=s(Pq);mFo=r(Rdt,"FlavaModel"),Rdt.forEach(t),gFo=r(A8e," (FLAVA model)"),A8e.forEach(t),hFo=i($),l_=n($,"LI",{});var L8e=s(l_);bde=n(L8e,"STRONG",{});var Pdt=s(bde);pFo=r(Pdt,"fnet"),Pdt.forEach(t),_Fo=r(L8e," \u2014 "),Bq=n(L8e,"A",{href:!0});var Bdt=s(Bq);uFo=r(Bdt,"FNetModel"),Bdt.forEach(t),bFo=r(L8e," (FNet model)"),L8e.forEach(t),vFo=i($),i_=n($,"LI",{});var y8e=s(i_);vde=n(y8e,"STRONG",{});var Idt=s(vde);FFo=r(Idt,"fsmt"),Idt.forEach(t),TFo=r(y8e," \u2014 "),Iq=n(y8e,"A",{href:!0});var Ndt=s(Iq);MFo=r(Ndt,"FSMTModel"),Ndt.forEach(t),EFo=r(y8e," (FairSeq Machine-Translation model)"),y8e.forEach(t),CFo=i($),Vs=n($,"LI",{});var Kk=s(Vs);Fde=n(Kk,"STRONG",{});var qdt=s(Fde);wFo=r(qdt,"funnel"),qdt.forEach(t),AFo=r(Kk," \u2014 "),Nq=n(Kk,"A",{href:!0});var jdt=s(Nq);LFo=r(jdt,"FunnelModel"),jdt.forEach(t),yFo=r(Kk," or "),qq=n(Kk,"A",{href:!0});var Ddt=s(qq);xFo=r(Ddt,"FunnelBaseModel"),Ddt.forEach(t),$Fo=r(Kk," (Funnel Transformer model)"),Kk.forEach(t),kFo=i($),d_=n($,"LI",{});var x8e=s(d_);Tde=n(x8e,"STRONG",{});var Gdt=s(Tde);SFo=r(Gdt,"glpn"),Gdt.forEach(t),RFo=r(x8e," \u2014 "),jq=n(x8e,"A",{href:!0});var Odt=s(jq);PFo=r(Odt,"GLPNModel"),Odt.forEach(t),BFo=r(x8e," (GLPN model)"),x8e.forEach(t),IFo=i($),c_=n($,"LI",{});var $8e=s(c_);Mde=n($8e,"STRONG",{});var Vdt=s(Mde);NFo=r(Vdt,"gpt2"),Vdt.forEach(t),qFo=r($8e," \u2014 "),Dq=n($8e,"A",{href:!0});var Xdt=s(Dq);jFo=r(Xdt,"GPT2Model"),Xdt.forEach(t),DFo=r($8e," (OpenAI GPT-2 model)"),$8e.forEach(t),GFo=i($),f_=n($,"LI",{});var k8e=s(f_);Ede=n(k8e,"STRONG",{});var zdt=s(Ede);OFo=r(zdt,"gpt_neo"),zdt.forEach(t),VFo=r(k8e," \u2014 "),Gq=n(k8e,"A",{href:!0});var Qdt=s(Gq);XFo=r(Qdt,"GPTNeoModel"),Qdt.forEach(t),zFo=r(k8e," (GPT Neo model)"),k8e.forEach(t),QFo=i($),m_=n($,"LI",{});var S8e=s(m_);Cde=n(S8e,"STRONG",{});var Wdt=s(Cde);WFo=r(Wdt,"gpt_neox"),Wdt.forEach(t),HFo=r(S8e," \u2014 "),Oq=n(S8e,"A",{href:!0});var Hdt=s(Oq);UFo=r(Hdt,"GPTNeoXModel"),Hdt.forEach(t),JFo=r(S8e," (GPT NeoX model)"),S8e.forEach(t),YFo=i($),g_=n($,"LI",{});var R8e=s(g_);wde=n(R8e,"STRONG",{});var Udt=s(wde);KFo=r(Udt,"gptj"),Udt.forEach(t),ZFo=r(R8e," \u2014 "),Vq=n(R8e,"A",{href:!0});var Jdt=s(Vq);e6o=r(Jdt,"GPTJModel"),Jdt.forEach(t),o6o=r(R8e," (GPT-J model)"),R8e.forEach(t),r6o=i($),h_=n($,"LI",{});var P8e=s(h_);Ade=n(P8e,"STRONG",{});var Ydt=s(Ade);t6o=r(Ydt,"hubert"),Ydt.forEach(t),a6o=r(P8e," \u2014 "),Xq=n(P8e,"A",{href:!0});var Kdt=s(Xq);n6o=r(Kdt,"HubertModel"),Kdt.forEach(t),s6o=r(P8e," (Hubert model)"),P8e.forEach(t),l6o=i($),p_=n($,"LI",{});var B8e=s(p_);Lde=n(B8e,"STRONG",{});var Zdt=s(Lde);i6o=r(Zdt,"ibert"),Zdt.forEach(t),d6o=r(B8e," \u2014 "),zq=n(B8e,"A",{href:!0});var ect=s(zq);c6o=r(ect,"IBertModel"),ect.forEach(t),f6o=r(B8e," (I-BERT model)"),B8e.forEach(t),m6o=i($),__=n($,"LI",{});var I8e=s(__);yde=n(I8e,"STRONG",{});var oct=s(yde);g6o=r(oct,"imagegpt"),oct.forEach(t),h6o=r(I8e," \u2014 "),Qq=n(I8e,"A",{href:!0});var rct=s(Qq);p6o=r(rct,"ImageGPTModel"),rct.forEach(t),_6o=r(I8e," (ImageGPT model)"),I8e.forEach(t),u6o=i($),u_=n($,"LI",{});var N8e=s(u_);xde=n(N8e,"STRONG",{});var tct=s(xde);b6o=r(tct,"layoutlm"),tct.forEach(t),v6o=r(N8e," \u2014 "),Wq=n(N8e,"A",{href:!0});var act=s(Wq);F6o=r(act,"LayoutLMModel"),act.forEach(t),T6o=r(N8e," (LayoutLM model)"),N8e.forEach(t),M6o=i($),b_=n($,"LI",{});var q8e=s(b_);$de=n(q8e,"STRONG",{});var nct=s($de);E6o=r(nct,"layoutlmv2"),nct.forEach(t),C6o=r(q8e," \u2014 "),Hq=n(q8e,"A",{href:!0});var sct=s(Hq);w6o=r(sct,"LayoutLMv2Model"),sct.forEach(t),A6o=r(q8e," (LayoutLMv2 model)"),q8e.forEach(t),L6o=i($),v_=n($,"LI",{});var j8e=s(v_);kde=n(j8e,"STRONG",{});var lct=s(kde);y6o=r(lct,"layoutlmv3"),lct.forEach(t),x6o=r(j8e," \u2014 "),Uq=n(j8e,"A",{href:!0});var ict=s(Uq);$6o=r(ict,"LayoutLMv3Model"),ict.forEach(t),k6o=r(j8e," (LayoutLMv3 model)"),j8e.forEach(t),S6o=i($),F_=n($,"LI",{});var D8e=s(F_);Sde=n(D8e,"STRONG",{});var dct=s(Sde);R6o=r(dct,"led"),dct.forEach(t),P6o=r(D8e," \u2014 "),Jq=n(D8e,"A",{href:!0});var cct=s(Jq);B6o=r(cct,"LEDModel"),cct.forEach(t),I6o=r(D8e," (LED model)"),D8e.forEach(t),N6o=i($),T_=n($,"LI",{});var G8e=s(T_);Rde=n(G8e,"STRONG",{});var fct=s(Rde);q6o=r(fct,"levit"),fct.forEach(t),j6o=r(G8e," \u2014 "),Yq=n(G8e,"A",{href:!0});var mct=s(Yq);D6o=r(mct,"LevitModel"),mct.forEach(t),G6o=r(G8e," (LeViT model)"),G8e.forEach(t),O6o=i($),M_=n($,"LI",{});var O8e=s(M_);Pde=n(O8e,"STRONG",{});var gct=s(Pde);V6o=r(gct,"longformer"),gct.forEach(t),X6o=r(O8e," \u2014 "),Kq=n(O8e,"A",{href:!0});var hct=s(Kq);z6o=r(hct,"LongformerModel"),hct.forEach(t),Q6o=r(O8e," (Longformer model)"),O8e.forEach(t),W6o=i($),E_=n($,"LI",{});var V8e=s(E_);Bde=n(V8e,"STRONG",{});var pct=s(Bde);H6o=r(pct,"longt5"),pct.forEach(t),U6o=r(V8e," \u2014 "),Zq=n(V8e,"A",{href:!0});var _ct=s(Zq);J6o=r(_ct,"LongT5Model"),_ct.forEach(t),Y6o=r(V8e," (LongT5 model)"),V8e.forEach(t),K6o=i($),C_=n($,"LI",{});var X8e=s(C_);Ide=n(X8e,"STRONG",{});var uct=s(Ide);Z6o=r(uct,"luke"),uct.forEach(t),eTo=r(X8e," \u2014 "),ej=n(X8e,"A",{href:!0});var bct=s(ej);oTo=r(bct,"LukeModel"),bct.forEach(t),rTo=r(X8e," (LUKE model)"),X8e.forEach(t),tTo=i($),w_=n($,"LI",{});var z8e=s(w_);Nde=n(z8e,"STRONG",{});var vct=s(Nde);aTo=r(vct,"lxmert"),vct.forEach(t),nTo=r(z8e," \u2014 "),oj=n(z8e,"A",{href:!0});var Fct=s(oj);sTo=r(Fct,"LxmertModel"),Fct.forEach(t),lTo=r(z8e," (LXMERT model)"),z8e.forEach(t),iTo=i($),A_=n($,"LI",{});var Q8e=s(A_);qde=n(Q8e,"STRONG",{});var Tct=s(qde);dTo=r(Tct,"m2m_100"),Tct.forEach(t),cTo=r(Q8e," \u2014 "),rj=n(Q8e,"A",{href:!0});var Mct=s(rj);fTo=r(Mct,"M2M100Model"),Mct.forEach(t),mTo=r(Q8e," (M2M100 model)"),Q8e.forEach(t),gTo=i($),L_=n($,"LI",{});var W8e=s(L_);jde=n(W8e,"STRONG",{});var Ect=s(jde);hTo=r(Ect,"marian"),Ect.forEach(t),pTo=r(W8e," \u2014 "),tj=n(W8e,"A",{href:!0});var Cct=s(tj);_To=r(Cct,"MarianModel"),Cct.forEach(t),uTo=r(W8e," (Marian model)"),W8e.forEach(t),bTo=i($),y_=n($,"LI",{});var H8e=s(y_);Dde=n(H8e,"STRONG",{});var wct=s(Dde);vTo=r(wct,"maskformer"),wct.forEach(t),FTo=r(H8e," \u2014 "),aj=n(H8e,"A",{href:!0});var Act=s(aj);TTo=r(Act,"MaskFormerModel"),Act.forEach(t),MTo=r(H8e," (MaskFormer model)"),H8e.forEach(t),ETo=i($),x_=n($,"LI",{});var U8e=s(x_);Gde=n(U8e,"STRONG",{});var Lct=s(Gde);CTo=r(Lct,"mbart"),Lct.forEach(t),wTo=r(U8e," \u2014 "),nj=n(U8e,"A",{href:!0});var yct=s(nj);ATo=r(yct,"MBartModel"),yct.forEach(t),LTo=r(U8e," (mBART model)"),U8e.forEach(t),yTo=i($),$_=n($,"LI",{});var J8e=s($_);Ode=n(J8e,"STRONG",{});var xct=s(Ode);xTo=r(xct,"mctct"),xct.forEach(t),$To=r(J8e," \u2014 "),sj=n(J8e,"A",{href:!0});var $ct=s(sj);kTo=r($ct,"MCTCTModel"),$ct.forEach(t),STo=r(J8e," (M-CTC-T model)"),J8e.forEach(t),RTo=i($),k_=n($,"LI",{});var Y8e=s(k_);Vde=n(Y8e,"STRONG",{});var kct=s(Vde);PTo=r(kct,"megatron-bert"),kct.forEach(t),BTo=r(Y8e," \u2014 "),lj=n(Y8e,"A",{href:!0});var Sct=s(lj);ITo=r(Sct,"MegatronBertModel"),Sct.forEach(t),NTo=r(Y8e," (Megatron-BERT model)"),Y8e.forEach(t),qTo=i($),S_=n($,"LI",{});var K8e=s(S_);Xde=n(K8e,"STRONG",{});var Rct=s(Xde);jTo=r(Rct,"mobilebert"),Rct.forEach(t),DTo=r(K8e," \u2014 "),ij=n(K8e,"A",{href:!0});var Pct=s(ij);GTo=r(Pct,"MobileBertModel"),Pct.forEach(t),OTo=r(K8e," (MobileBERT model)"),K8e.forEach(t),VTo=i($),R_=n($,"LI",{});var Z8e=s(R_);zde=n(Z8e,"STRONG",{});var Bct=s(zde);XTo=r(Bct,"mpnet"),Bct.forEach(t),zTo=r(Z8e," \u2014 "),dj=n(Z8e,"A",{href:!0});var Ict=s(dj);QTo=r(Ict,"MPNetModel"),Ict.forEach(t),WTo=r(Z8e," (MPNet model)"),Z8e.forEach(t),HTo=i($),P_=n($,"LI",{});var e9e=s(P_);Qde=n(e9e,"STRONG",{});var Nct=s(Qde);UTo=r(Nct,"mt5"),Nct.forEach(t),JTo=r(e9e," \u2014 "),cj=n(e9e,"A",{href:!0});var qct=s(cj);YTo=r(qct,"MT5Model"),qct.forEach(t),KTo=r(e9e," (MT5 model)"),e9e.forEach(t),ZTo=i($),B_=n($,"LI",{});var o9e=s(B_);Wde=n(o9e,"STRONG",{});var jct=s(Wde);eMo=r(jct,"nezha"),jct.forEach(t),oMo=r(o9e," \u2014 "),fj=n(o9e,"A",{href:!0});var Dct=s(fj);rMo=r(Dct,"NezhaModel"),Dct.forEach(t),tMo=r(o9e," (Nezha model)"),o9e.forEach(t),aMo=i($),I_=n($,"LI",{});var r9e=s(I_);Hde=n(r9e,"STRONG",{});var Gct=s(Hde);nMo=r(Gct,"nystromformer"),Gct.forEach(t),sMo=r(r9e," \u2014 "),mj=n(r9e,"A",{href:!0});var Oct=s(mj);lMo=r(Oct,"NystromformerModel"),Oct.forEach(t),iMo=r(r9e," (Nystr\xF6mformer model)"),r9e.forEach(t),dMo=i($),N_=n($,"LI",{});var t9e=s(N_);Ude=n(t9e,"STRONG",{});var Vct=s(Ude);cMo=r(Vct,"openai-gpt"),Vct.forEach(t),fMo=r(t9e," \u2014 "),gj=n(t9e,"A",{href:!0});var Xct=s(gj);mMo=r(Xct,"OpenAIGPTModel"),Xct.forEach(t),gMo=r(t9e," (OpenAI GPT model)"),t9e.forEach(t),hMo=i($),q_=n($,"LI",{});var a9e=s(q_);Jde=n(a9e,"STRONG",{});var zct=s(Jde);pMo=r(zct,"opt"),zct.forEach(t),_Mo=r(a9e," \u2014 "),hj=n(a9e,"A",{href:!0});var Qct=s(hj);uMo=r(Qct,"OPTModel"),Qct.forEach(t),bMo=r(a9e," (OPT model)"),a9e.forEach(t),vMo=i($),j_=n($,"LI",{});var n9e=s(j_);Yde=n(n9e,"STRONG",{});var Wct=s(Yde);FMo=r(Wct,"pegasus"),Wct.forEach(t),TMo=r(n9e," \u2014 "),pj=n(n9e,"A",{href:!0});var Hct=s(pj);MMo=r(Hct,"PegasusModel"),Hct.forEach(t),EMo=r(n9e," (Pegasus model)"),n9e.forEach(t),CMo=i($),D_=n($,"LI",{});var s9e=s(D_);Kde=n(s9e,"STRONG",{});var Uct=s(Kde);wMo=r(Uct,"perceiver"),Uct.forEach(t),AMo=r(s9e," \u2014 "),_j=n(s9e,"A",{href:!0});var Jct=s(_j);LMo=r(Jct,"PerceiverModel"),Jct.forEach(t),yMo=r(s9e," (Perceiver model)"),s9e.forEach(t),xMo=i($),G_=n($,"LI",{});var l9e=s(G_);Zde=n(l9e,"STRONG",{});var Yct=s(Zde);$Mo=r(Yct,"plbart"),Yct.forEach(t),kMo=r(l9e," \u2014 "),uj=n(l9e,"A",{href:!0});var Kct=s(uj);SMo=r(Kct,"PLBartModel"),Kct.forEach(t),RMo=r(l9e," (PLBart model)"),l9e.forEach(t),PMo=i($),O_=n($,"LI",{});var i9e=s(O_);ece=n(i9e,"STRONG",{});var Zct=s(ece);BMo=r(Zct,"poolformer"),Zct.forEach(t),IMo=r(i9e," \u2014 "),bj=n(i9e,"A",{href:!0});var eft=s(bj);NMo=r(eft,"PoolFormerModel"),eft.forEach(t),qMo=r(i9e," (PoolFormer model)"),i9e.forEach(t),jMo=i($),V_=n($,"LI",{});var d9e=s(V_);oce=n(d9e,"STRONG",{});var oft=s(oce);DMo=r(oft,"prophetnet"),oft.forEach(t),GMo=r(d9e," \u2014 "),vj=n(d9e,"A",{href:!0});var rft=s(vj);OMo=r(rft,"ProphetNetModel"),rft.forEach(t),VMo=r(d9e," (ProphetNet model)"),d9e.forEach(t),XMo=i($),X_=n($,"LI",{});var c9e=s(X_);rce=n(c9e,"STRONG",{});var tft=s(rce);zMo=r(tft,"qdqbert"),tft.forEach(t),QMo=r(c9e," \u2014 "),Fj=n(c9e,"A",{href:!0});var aft=s(Fj);WMo=r(aft,"QDQBertModel"),aft.forEach(t),HMo=r(c9e," (QDQBert model)"),c9e.forEach(t),UMo=i($),z_=n($,"LI",{});var f9e=s(z_);tce=n(f9e,"STRONG",{});var nft=s(tce);JMo=r(nft,"reformer"),nft.forEach(t),YMo=r(f9e," \u2014 "),Tj=n(f9e,"A",{href:!0});var sft=s(Tj);KMo=r(sft,"ReformerModel"),sft.forEach(t),ZMo=r(f9e," (Reformer model)"),f9e.forEach(t),eEo=i($),Q_=n($,"LI",{});var m9e=s(Q_);ace=n(m9e,"STRONG",{});var lft=s(ace);oEo=r(lft,"regnet"),lft.forEach(t),rEo=r(m9e," \u2014 "),Mj=n(m9e,"A",{href:!0});var ift=s(Mj);tEo=r(ift,"RegNetModel"),ift.forEach(t),aEo=r(m9e," (RegNet model)"),m9e.forEach(t),nEo=i($),W_=n($,"LI",{});var g9e=s(W_);nce=n(g9e,"STRONG",{});var dft=s(nce);sEo=r(dft,"rembert"),dft.forEach(t),lEo=r(g9e," \u2014 "),Ej=n(g9e,"A",{href:!0});var cft=s(Ej);iEo=r(cft,"RemBertModel"),cft.forEach(t),dEo=r(g9e," (RemBERT model)"),g9e.forEach(t),cEo=i($),H_=n($,"LI",{});var h9e=s(H_);sce=n(h9e,"STRONG",{});var fft=s(sce);fEo=r(fft,"resnet"),fft.forEach(t),mEo=r(h9e," \u2014 "),Cj=n(h9e,"A",{href:!0});var mft=s(Cj);gEo=r(mft,"ResNetModel"),mft.forEach(t),hEo=r(h9e," (ResNet model)"),h9e.forEach(t),pEo=i($),U_=n($,"LI",{});var p9e=s(U_);lce=n(p9e,"STRONG",{});var gft=s(lce);_Eo=r(gft,"retribert"),gft.forEach(t),uEo=r(p9e," \u2014 "),wj=n(p9e,"A",{href:!0});var hft=s(wj);bEo=r(hft,"RetriBertModel"),hft.forEach(t),vEo=r(p9e," (RetriBERT model)"),p9e.forEach(t),FEo=i($),J_=n($,"LI",{});var _9e=s(J_);ice=n(_9e,"STRONG",{});var pft=s(ice);TEo=r(pft,"roberta"),pft.forEach(t),MEo=r(_9e," \u2014 "),Aj=n(_9e,"A",{href:!0});var _ft=s(Aj);EEo=r(_ft,"RobertaModel"),_ft.forEach(t),CEo=r(_9e," (RoBERTa model)"),_9e.forEach(t),wEo=i($),Y_=n($,"LI",{});var u9e=s(Y_);dce=n(u9e,"STRONG",{});var uft=s(dce);AEo=r(uft,"roformer"),uft.forEach(t),LEo=r(u9e," \u2014 "),Lj=n(u9e,"A",{href:!0});var bft=s(Lj);yEo=r(bft,"RoFormerModel"),bft.forEach(t),xEo=r(u9e," (RoFormer model)"),u9e.forEach(t),$Eo=i($),K_=n($,"LI",{});var b9e=s(K_);cce=n(b9e,"STRONG",{});var vft=s(cce);kEo=r(vft,"segformer"),vft.forEach(t),SEo=r(b9e," \u2014 "),yj=n(b9e,"A",{href:!0});var Fft=s(yj);REo=r(Fft,"SegformerModel"),Fft.forEach(t),PEo=r(b9e," (SegFormer model)"),b9e.forEach(t),BEo=i($),Z_=n($,"LI",{});var v9e=s(Z_);fce=n(v9e,"STRONG",{});var Tft=s(fce);IEo=r(Tft,"sew"),Tft.forEach(t),NEo=r(v9e," \u2014 "),xj=n(v9e,"A",{href:!0});var Mft=s(xj);qEo=r(Mft,"SEWModel"),Mft.forEach(t),jEo=r(v9e," (SEW model)"),v9e.forEach(t),DEo=i($),eu=n($,"LI",{});var F9e=s(eu);mce=n(F9e,"STRONG",{});var Eft=s(mce);GEo=r(Eft,"sew-d"),Eft.forEach(t),OEo=r(F9e," \u2014 "),$j=n(F9e,"A",{href:!0});var Cft=s($j);VEo=r(Cft,"SEWDModel"),Cft.forEach(t),XEo=r(F9e," (SEW-D model)"),F9e.forEach(t),zEo=i($),ou=n($,"LI",{});var T9e=s(ou);gce=n(T9e,"STRONG",{});var wft=s(gce);QEo=r(wft,"speech_to_text"),wft.forEach(t),WEo=r(T9e," \u2014 "),kj=n(T9e,"A",{href:!0});var Aft=s(kj);HEo=r(Aft,"Speech2TextModel"),Aft.forEach(t),UEo=r(T9e," (Speech2Text model)"),T9e.forEach(t),JEo=i($),ru=n($,"LI",{});var M9e=s(ru);hce=n(M9e,"STRONG",{});var Lft=s(hce);YEo=r(Lft,"splinter"),Lft.forEach(t),KEo=r(M9e," \u2014 "),Sj=n(M9e,"A",{href:!0});var yft=s(Sj);ZEo=r(yft,"SplinterModel"),yft.forEach(t),e4o=r(M9e," (Splinter model)"),M9e.forEach(t),o4o=i($),tu=n($,"LI",{});var E9e=s(tu);pce=n(E9e,"STRONG",{});var xft=s(pce);r4o=r(xft,"squeezebert"),xft.forEach(t),t4o=r(E9e," \u2014 "),Rj=n(E9e,"A",{href:!0});var $ft=s(Rj);a4o=r($ft,"SqueezeBertModel"),$ft.forEach(t),n4o=r(E9e," (SqueezeBERT model)"),E9e.forEach(t),s4o=i($),au=n($,"LI",{});var C9e=s(au);_ce=n(C9e,"STRONG",{});var kft=s(_ce);l4o=r(kft,"swin"),kft.forEach(t),i4o=r(C9e," \u2014 "),Pj=n(C9e,"A",{href:!0});var Sft=s(Pj);d4o=r(Sft,"SwinModel"),Sft.forEach(t),c4o=r(C9e," (Swin Transformer model)"),C9e.forEach(t),f4o=i($),nu=n($,"LI",{});var w9e=s(nu);uce=n(w9e,"STRONG",{});var Rft=s(uce);m4o=r(Rft,"t5"),Rft.forEach(t),g4o=r(w9e," \u2014 "),Bj=n(w9e,"A",{href:!0});var Pft=s(Bj);h4o=r(Pft,"T5Model"),Pft.forEach(t),p4o=r(w9e," (T5 model)"),w9e.forEach(t),_4o=i($),su=n($,"LI",{});var A9e=s(su);bce=n(A9e,"STRONG",{});var Bft=s(bce);u4o=r(Bft,"tapas"),Bft.forEach(t),b4o=r(A9e," \u2014 "),Ij=n(A9e,"A",{href:!0});var Ift=s(Ij);v4o=r(Ift,"TapasModel"),Ift.forEach(t),F4o=r(A9e," (TAPAS model)"),A9e.forEach(t),T4o=i($),lu=n($,"LI",{});var L9e=s(lu);vce=n(L9e,"STRONG",{});var Nft=s(vce);M4o=r(Nft,"trajectory_transformer"),Nft.forEach(t),E4o=r(L9e," \u2014 "),Nj=n(L9e,"A",{href:!0});var qft=s(Nj);C4o=r(qft,"TrajectoryTransformerModel"),qft.forEach(t),w4o=r(L9e," (Trajectory Transformer model)"),L9e.forEach(t),A4o=i($),iu=n($,"LI",{});var y9e=s(iu);Fce=n(y9e,"STRONG",{});var jft=s(Fce);L4o=r(jft,"transfo-xl"),jft.forEach(t),y4o=r(y9e," \u2014 "),qj=n(y9e,"A",{href:!0});var Dft=s(qj);x4o=r(Dft,"TransfoXLModel"),Dft.forEach(t),$4o=r(y9e," (Transformer-XL model)"),y9e.forEach(t),k4o=i($),du=n($,"LI",{});var x9e=s(du);Tce=n(x9e,"STRONG",{});var Gft=s(Tce);S4o=r(Gft,"unispeech"),Gft.forEach(t),R4o=r(x9e," \u2014 "),jj=n(x9e,"A",{href:!0});var Oft=s(jj);P4o=r(Oft,"UniSpeechModel"),Oft.forEach(t),B4o=r(x9e," (UniSpeech model)"),x9e.forEach(t),I4o=i($),cu=n($,"LI",{});var $9e=s(cu);Mce=n($9e,"STRONG",{});var Vft=s(Mce);N4o=r(Vft,"unispeech-sat"),Vft.forEach(t),q4o=r($9e," \u2014 "),Dj=n($9e,"A",{href:!0});var Xft=s(Dj);j4o=r(Xft,"UniSpeechSatModel"),Xft.forEach(t),D4o=r($9e," (UniSpeechSat model)"),$9e.forEach(t),G4o=i($),fu=n($,"LI",{});var k9e=s(fu);Ece=n(k9e,"STRONG",{});var zft=s(Ece);O4o=r(zft,"van"),zft.forEach(t),V4o=r(k9e," \u2014 "),Gj=n(k9e,"A",{href:!0});var Qft=s(Gj);X4o=r(Qft,"VanModel"),Qft.forEach(t),z4o=r(k9e," (VAN model)"),k9e.forEach(t),Q4o=i($),mu=n($,"LI",{});var S9e=s(mu);Cce=n(S9e,"STRONG",{});var Wft=s(Cce);W4o=r(Wft,"vilt"),Wft.forEach(t),H4o=r(S9e," \u2014 "),Oj=n(S9e,"A",{href:!0});var Hft=s(Oj);U4o=r(Hft,"ViltModel"),Hft.forEach(t),J4o=r(S9e," (ViLT model)"),S9e.forEach(t),Y4o=i($),gu=n($,"LI",{});var R9e=s(gu);wce=n(R9e,"STRONG",{});var Uft=s(wce);K4o=r(Uft,"vision-text-dual-encoder"),Uft.forEach(t),Z4o=r(R9e," \u2014 "),Vj=n(R9e,"A",{href:!0});var Jft=s(Vj);eCo=r(Jft,"VisionTextDualEncoderModel"),Jft.forEach(t),oCo=r(R9e," (VisionTextDualEncoder model)"),R9e.forEach(t),rCo=i($),hu=n($,"LI",{});var P9e=s(hu);Ace=n(P9e,"STRONG",{});var Yft=s(Ace);tCo=r(Yft,"visual_bert"),Yft.forEach(t),aCo=r(P9e," \u2014 "),Xj=n(P9e,"A",{href:!0});var Kft=s(Xj);nCo=r(Kft,"VisualBertModel"),Kft.forEach(t),sCo=r(P9e," (VisualBERT model)"),P9e.forEach(t),lCo=i($),pu=n($,"LI",{});var B9e=s(pu);Lce=n(B9e,"STRONG",{});var Zft=s(Lce);iCo=r(Zft,"vit"),Zft.forEach(t),dCo=r(B9e," \u2014 "),zj=n(B9e,"A",{href:!0});var emt=s(zj);cCo=r(emt,"ViTModel"),emt.forEach(t),fCo=r(B9e," (ViT model)"),B9e.forEach(t),mCo=i($),_u=n($,"LI",{});var I9e=s(_u);yce=n(I9e,"STRONG",{});var omt=s(yce);gCo=r(omt,"vit_mae"),omt.forEach(t),hCo=r(I9e," \u2014 "),Qj=n(I9e,"A",{href:!0});var rmt=s(Qj);pCo=r(rmt,"ViTMAEModel"),rmt.forEach(t),_Co=r(I9e," (ViTMAE model)"),I9e.forEach(t),uCo=i($),uu=n($,"LI",{});var N9e=s(uu);xce=n(N9e,"STRONG",{});var tmt=s(xce);bCo=r(tmt,"wav2vec2"),tmt.forEach(t),vCo=r(N9e," \u2014 "),Wj=n(N9e,"A",{href:!0});var amt=s(Wj);FCo=r(amt,"Wav2Vec2Model"),amt.forEach(t),TCo=r(N9e," (Wav2Vec2 model)"),N9e.forEach(t),MCo=i($),bu=n($,"LI",{});var q9e=s(bu);$ce=n(q9e,"STRONG",{});var nmt=s($ce);ECo=r(nmt,"wav2vec2-conformer"),nmt.forEach(t),CCo=r(q9e," \u2014 "),Hj=n(q9e,"A",{href:!0});var smt=s(Hj);wCo=r(smt,"Wav2Vec2ConformerModel"),smt.forEach(t),ACo=r(q9e," (Wav2Vec2-Conformer model)"),q9e.forEach(t),LCo=i($),vu=n($,"LI",{});var j9e=s(vu);kce=n(j9e,"STRONG",{});var lmt=s(kce);yCo=r(lmt,"wavlm"),lmt.forEach(t),xCo=r(j9e," \u2014 "),Uj=n(j9e,"A",{href:!0});var imt=s(Uj);$Co=r(imt,"WavLMModel"),imt.forEach(t),kCo=r(j9e," (WavLM model)"),j9e.forEach(t),SCo=i($),Fu=n($,"LI",{});var D9e=s(Fu);Sce=n(D9e,"STRONG",{});var dmt=s(Sce);RCo=r(dmt,"xglm"),dmt.forEach(t),PCo=r(D9e," \u2014 "),Jj=n(D9e,"A",{href:!0});var cmt=s(Jj);BCo=r(cmt,"XGLMModel"),cmt.forEach(t),ICo=r(D9e," (XGLM model)"),D9e.forEach(t),NCo=i($),Tu=n($,"LI",{});var G9e=s(Tu);Rce=n(G9e,"STRONG",{});var fmt=s(Rce);qCo=r(fmt,"xlm"),fmt.forEach(t),jCo=r(G9e," \u2014 "),Yj=n(G9e,"A",{href:!0});var mmt=s(Yj);DCo=r(mmt,"XLMModel"),mmt.forEach(t),GCo=r(G9e," (XLM model)"),G9e.forEach(t),OCo=i($),Mu=n($,"LI",{});var O9e=s(Mu);Pce=n(O9e,"STRONG",{});var gmt=s(Pce);VCo=r(gmt,"xlm-prophetnet"),gmt.forEach(t),XCo=r(O9e," \u2014 "),Kj=n(O9e,"A",{href:!0});var hmt=s(Kj);zCo=r(hmt,"XLMProphetNetModel"),hmt.forEach(t),QCo=r(O9e," (XLM-ProphetNet model)"),O9e.forEach(t),WCo=i($),Eu=n($,"LI",{});var V9e=s(Eu);Bce=n(V9e,"STRONG",{});var pmt=s(Bce);HCo=r(pmt,"xlm-roberta"),pmt.forEach(t),UCo=r(V9e," \u2014 "),Zj=n(V9e,"A",{href:!0});var _mt=s(Zj);JCo=r(_mt,"XLMRobertaModel"),_mt.forEach(t),YCo=r(V9e," (XLM-RoBERTa model)"),V9e.forEach(t),KCo=i($),Cu=n($,"LI",{});var X9e=s(Cu);Ice=n(X9e,"STRONG",{});var umt=s(Ice);ZCo=r(umt,"xlm-roberta-xl"),umt.forEach(t),e5o=r(X9e," \u2014 "),eD=n(X9e,"A",{href:!0});var bmt=s(eD);o5o=r(bmt,"XLMRobertaXLModel"),bmt.forEach(t),r5o=r(X9e," (XLM-RoBERTa-XL model)"),X9e.forEach(t),t5o=i($),wu=n($,"LI",{});var z9e=s(wu);Nce=n(z9e,"STRONG",{});var vmt=s(Nce);a5o=r(vmt,"xlnet"),vmt.forEach(t),n5o=r(z9e," \u2014 "),oD=n(z9e,"A",{href:!0});var Fmt=s(oD);s5o=r(Fmt,"XLNetModel"),Fmt.forEach(t),l5o=r(z9e," (XLNet model)"),z9e.forEach(t),i5o=i($),Au=n($,"LI",{});var Q9e=s(Au);qce=n(Q9e,"STRONG",{});var Tmt=s(qce);d5o=r(Tmt,"yolos"),Tmt.forEach(t),c5o=r(Q9e," \u2014 "),rD=n(Q9e,"A",{href:!0});var Mmt=s(rD);f5o=r(Mmt,"YolosModel"),Mmt.forEach(t),m5o=r(Q9e," (YOLOS model)"),Q9e.forEach(t),g5o=i($),Lu=n($,"LI",{});var W9e=s(Lu);jce=n(W9e,"STRONG",{});var Emt=s(jce);h5o=r(Emt,"yoso"),Emt.forEach(t),p5o=r(W9e," \u2014 "),tD=n(W9e,"A",{href:!0});var Cmt=s(tD);_5o=r(Cmt,"YosoModel"),Cmt.forEach(t),u5o=r(W9e," (YOSO model)"),W9e.forEach(t),$.forEach(t),b5o=i(aa),yu=n(aa,"P",{});var H9e=s(yu);v5o=r(H9e,"The model is set in evaluation mode by default using "),Dce=n(H9e,"CODE",{});var wmt=s(Dce);F5o=r(wmt,"model.eval()"),wmt.forEach(t),T5o=r(H9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=n(H9e,"CODE",{});var Amt=s(Gce);M5o=r(Amt,"model.train()"),Amt.forEach(t),H9e.forEach(t),E5o=i(aa),T(xu.$$.fragment,aa),aa.forEach(t),Ys.forEach(t),eOe=i(f),qi=n(f,"H2",{class:!0});var sXe=s(qi);$u=n(sXe,"A",{id:!0,class:!0,href:!0});var Lmt=s($u);Oce=n(Lmt,"SPAN",{});var ymt=s(Oce);T(sy.$$.fragment,ymt),ymt.forEach(t),Lmt.forEach(t),C5o=i(sXe),Vce=n(sXe,"SPAN",{});var xmt=s(Vce);w5o=r(xmt,"AutoModelForPreTraining"),xmt.forEach(t),sXe.forEach(t),oOe=i(f),$o=n(f,"DIV",{class:!0});var Ks=s($o);T(ly.$$.fragment,Ks),A5o=i(Ks),ji=n(Ks,"P",{});var Toe=s(ji);L5o=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=n(Toe,"A",{href:!0});var $mt=s(aD);y5o=r($mt,"from_pretrained()"),$mt.forEach(t),x5o=r(Toe," class method or the "),nD=n(Toe,"A",{href:!0});var kmt=s(nD);$5o=r(kmt,"from_config()"),kmt.forEach(t),k5o=r(Toe,` class
method.`),Toe.forEach(t),S5o=i(Ks),iy=n(Ks,"P",{});var lXe=s(iy);R5o=r(lXe,"This class cannot be instantiated directly using "),Xce=n(lXe,"CODE",{});var Smt=s(Xce);P5o=r(Smt,"__init__()"),Smt.forEach(t),B5o=r(lXe," (throws an error)."),lXe.forEach(t),I5o=i(Ks),st=n(Ks,"DIV",{class:!0});var Rw=s(st);T(dy.$$.fragment,Rw),N5o=i(Rw),zce=n(Rw,"P",{});var Rmt=s(zce);q5o=r(Rmt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rmt.forEach(t),j5o=i(Rw),Di=n(Rw,"P",{});var Moe=s(Di);D5o=r(Moe,`Note:
Loading a model from its configuration file does `),Qce=n(Moe,"STRONG",{});var Pmt=s(Qce);G5o=r(Pmt,"not"),Pmt.forEach(t),O5o=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=n(Moe,"A",{href:!0});var Bmt=s(sD);V5o=r(Bmt,"from_pretrained()"),Bmt.forEach(t),X5o=r(Moe," to load the model weights."),Moe.forEach(t),z5o=i(Rw),T(ku.$$.fragment,Rw),Rw.forEach(t),Q5o=i(Ks),Ye=n(Ks,"DIV",{class:!0});var na=s(Ye);T(cy.$$.fragment,na),W5o=i(na),Wce=n(na,"P",{});var Imt=s(Wce);H5o=r(Imt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Imt.forEach(t),U5o=i(na),Pa=n(na,"P",{});var Pw=s(Pa);J5o=r(Pw,"The model class to instantiate is selected based on the "),Hce=n(Pw,"CODE",{});var Nmt=s(Hce);Y5o=r(Nmt,"model_type"),Nmt.forEach(t),K5o=r(Pw,` property of the config object (either
passed as an argument or loaded from `),Uce=n(Pw,"CODE",{});var qmt=s(Uce);Z5o=r(qmt,"pretrained_model_name_or_path"),qmt.forEach(t),e3o=r(Pw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=n(Pw,"CODE",{});var jmt=s(Jce);o3o=r(jmt,"pretrained_model_name_or_path"),jmt.forEach(t),r3o=r(Pw,":"),Pw.forEach(t),t3o=i(na),G=n(na,"UL",{});var O=s(G);Su=n(O,"LI",{});var U9e=s(Su);Yce=n(U9e,"STRONG",{});var Dmt=s(Yce);a3o=r(Dmt,"albert"),Dmt.forEach(t),n3o=r(U9e," \u2014 "),lD=n(U9e,"A",{href:!0});var Gmt=s(lD);s3o=r(Gmt,"AlbertForPreTraining"),Gmt.forEach(t),l3o=r(U9e," (ALBERT model)"),U9e.forEach(t),i3o=i(O),Ru=n(O,"LI",{});var J9e=s(Ru);Kce=n(J9e,"STRONG",{});var Omt=s(Kce);d3o=r(Omt,"bart"),Omt.forEach(t),c3o=r(J9e," \u2014 "),iD=n(J9e,"A",{href:!0});var Vmt=s(iD);f3o=r(Vmt,"BartForConditionalGeneration"),Vmt.forEach(t),m3o=r(J9e," (BART model)"),J9e.forEach(t),g3o=i(O),Pu=n(O,"LI",{});var Y9e=s(Pu);Zce=n(Y9e,"STRONG",{});var Xmt=s(Zce);h3o=r(Xmt,"bert"),Xmt.forEach(t),p3o=r(Y9e," \u2014 "),dD=n(Y9e,"A",{href:!0});var zmt=s(dD);_3o=r(zmt,"BertForPreTraining"),zmt.forEach(t),u3o=r(Y9e," (BERT model)"),Y9e.forEach(t),b3o=i(O),Bu=n(O,"LI",{});var K9e=s(Bu);efe=n(K9e,"STRONG",{});var Qmt=s(efe);v3o=r(Qmt,"big_bird"),Qmt.forEach(t),F3o=r(K9e," \u2014 "),cD=n(K9e,"A",{href:!0});var Wmt=s(cD);T3o=r(Wmt,"BigBirdForPreTraining"),Wmt.forEach(t),M3o=r(K9e," (BigBird model)"),K9e.forEach(t),E3o=i(O),Iu=n(O,"LI",{});var Z9e=s(Iu);ofe=n(Z9e,"STRONG",{});var Hmt=s(ofe);C3o=r(Hmt,"bloom"),Hmt.forEach(t),w3o=r(Z9e," \u2014 "),fD=n(Z9e,"A",{href:!0});var Umt=s(fD);A3o=r(Umt,"BloomForCausalLM"),Umt.forEach(t),L3o=r(Z9e," (BLOOM model)"),Z9e.forEach(t),y3o=i(O),Nu=n(O,"LI",{});var exe=s(Nu);rfe=n(exe,"STRONG",{});var Jmt=s(rfe);x3o=r(Jmt,"camembert"),Jmt.forEach(t),$3o=r(exe," \u2014 "),mD=n(exe,"A",{href:!0});var Ymt=s(mD);k3o=r(Ymt,"CamembertForMaskedLM"),Ymt.forEach(t),S3o=r(exe," (CamemBERT model)"),exe.forEach(t),R3o=i(O),qu=n(O,"LI",{});var oxe=s(qu);tfe=n(oxe,"STRONG",{});var Kmt=s(tfe);P3o=r(Kmt,"ctrl"),Kmt.forEach(t),B3o=r(oxe," \u2014 "),gD=n(oxe,"A",{href:!0});var Zmt=s(gD);I3o=r(Zmt,"CTRLLMHeadModel"),Zmt.forEach(t),N3o=r(oxe," (CTRL model)"),oxe.forEach(t),q3o=i(O),ju=n(O,"LI",{});var rxe=s(ju);afe=n(rxe,"STRONG",{});var egt=s(afe);j3o=r(egt,"data2vec-text"),egt.forEach(t),D3o=r(rxe," \u2014 "),hD=n(rxe,"A",{href:!0});var ogt=s(hD);G3o=r(ogt,"Data2VecTextForMaskedLM"),ogt.forEach(t),O3o=r(rxe," (Data2VecText model)"),rxe.forEach(t),V3o=i(O),Du=n(O,"LI",{});var txe=s(Du);nfe=n(txe,"STRONG",{});var rgt=s(nfe);X3o=r(rgt,"deberta"),rgt.forEach(t),z3o=r(txe," \u2014 "),pD=n(txe,"A",{href:!0});var tgt=s(pD);Q3o=r(tgt,"DebertaForMaskedLM"),tgt.forEach(t),W3o=r(txe," (DeBERTa model)"),txe.forEach(t),H3o=i(O),Gu=n(O,"LI",{});var axe=s(Gu);sfe=n(axe,"STRONG",{});var agt=s(sfe);U3o=r(agt,"deberta-v2"),agt.forEach(t),J3o=r(axe," \u2014 "),_D=n(axe,"A",{href:!0});var ngt=s(_D);Y3o=r(ngt,"DebertaV2ForMaskedLM"),ngt.forEach(t),K3o=r(axe," (DeBERTa-v2 model)"),axe.forEach(t),Z3o=i(O),Ou=n(O,"LI",{});var nxe=s(Ou);lfe=n(nxe,"STRONG",{});var sgt=s(lfe);e0o=r(sgt,"distilbert"),sgt.forEach(t),o0o=r(nxe," \u2014 "),uD=n(nxe,"A",{href:!0});var lgt=s(uD);r0o=r(lgt,"DistilBertForMaskedLM"),lgt.forEach(t),t0o=r(nxe," (DistilBERT model)"),nxe.forEach(t),a0o=i(O),Vu=n(O,"LI",{});var sxe=s(Vu);ife=n(sxe,"STRONG",{});var igt=s(ife);n0o=r(igt,"electra"),igt.forEach(t),s0o=r(sxe," \u2014 "),bD=n(sxe,"A",{href:!0});var dgt=s(bD);l0o=r(dgt,"ElectraForPreTraining"),dgt.forEach(t),i0o=r(sxe," (ELECTRA model)"),sxe.forEach(t),d0o=i(O),Xu=n(O,"LI",{});var lxe=s(Xu);dfe=n(lxe,"STRONG",{});var cgt=s(dfe);c0o=r(cgt,"flaubert"),cgt.forEach(t),f0o=r(lxe," \u2014 "),vD=n(lxe,"A",{href:!0});var fgt=s(vD);m0o=r(fgt,"FlaubertWithLMHeadModel"),fgt.forEach(t),g0o=r(lxe," (FlauBERT model)"),lxe.forEach(t),h0o=i(O),zu=n(O,"LI",{});var ixe=s(zu);cfe=n(ixe,"STRONG",{});var mgt=s(cfe);p0o=r(mgt,"flava"),mgt.forEach(t),_0o=r(ixe," \u2014 "),FD=n(ixe,"A",{href:!0});var ggt=s(FD);u0o=r(ggt,"FlavaForPreTraining"),ggt.forEach(t),b0o=r(ixe," (FLAVA model)"),ixe.forEach(t),v0o=i(O),Qu=n(O,"LI",{});var dxe=s(Qu);ffe=n(dxe,"STRONG",{});var hgt=s(ffe);F0o=r(hgt,"fnet"),hgt.forEach(t),T0o=r(dxe," \u2014 "),TD=n(dxe,"A",{href:!0});var pgt=s(TD);M0o=r(pgt,"FNetForPreTraining"),pgt.forEach(t),E0o=r(dxe," (FNet model)"),dxe.forEach(t),C0o=i(O),Wu=n(O,"LI",{});var cxe=s(Wu);mfe=n(cxe,"STRONG",{});var _gt=s(mfe);w0o=r(_gt,"fsmt"),_gt.forEach(t),A0o=r(cxe," \u2014 "),MD=n(cxe,"A",{href:!0});var ugt=s(MD);L0o=r(ugt,"FSMTForConditionalGeneration"),ugt.forEach(t),y0o=r(cxe," (FairSeq Machine-Translation model)"),cxe.forEach(t),x0o=i(O),Hu=n(O,"LI",{});var fxe=s(Hu);gfe=n(fxe,"STRONG",{});var bgt=s(gfe);$0o=r(bgt,"funnel"),bgt.forEach(t),k0o=r(fxe," \u2014 "),ED=n(fxe,"A",{href:!0});var vgt=s(ED);S0o=r(vgt,"FunnelForPreTraining"),vgt.forEach(t),R0o=r(fxe," (Funnel Transformer model)"),fxe.forEach(t),P0o=i(O),Uu=n(O,"LI",{});var mxe=s(Uu);hfe=n(mxe,"STRONG",{});var Fgt=s(hfe);B0o=r(Fgt,"gpt2"),Fgt.forEach(t),I0o=r(mxe," \u2014 "),CD=n(mxe,"A",{href:!0});var Tgt=s(CD);N0o=r(Tgt,"GPT2LMHeadModel"),Tgt.forEach(t),q0o=r(mxe," (OpenAI GPT-2 model)"),mxe.forEach(t),j0o=i(O),Ju=n(O,"LI",{});var gxe=s(Ju);pfe=n(gxe,"STRONG",{});var Mgt=s(pfe);D0o=r(Mgt,"ibert"),Mgt.forEach(t),G0o=r(gxe," \u2014 "),wD=n(gxe,"A",{href:!0});var Egt=s(wD);O0o=r(Egt,"IBertForMaskedLM"),Egt.forEach(t),V0o=r(gxe," (I-BERT model)"),gxe.forEach(t),X0o=i(O),Yu=n(O,"LI",{});var hxe=s(Yu);_fe=n(hxe,"STRONG",{});var Cgt=s(_fe);z0o=r(Cgt,"layoutlm"),Cgt.forEach(t),Q0o=r(hxe," \u2014 "),AD=n(hxe,"A",{href:!0});var wgt=s(AD);W0o=r(wgt,"LayoutLMForMaskedLM"),wgt.forEach(t),H0o=r(hxe," (LayoutLM model)"),hxe.forEach(t),U0o=i(O),Ku=n(O,"LI",{});var pxe=s(Ku);ufe=n(pxe,"STRONG",{});var Agt=s(ufe);J0o=r(Agt,"longformer"),Agt.forEach(t),Y0o=r(pxe," \u2014 "),LD=n(pxe,"A",{href:!0});var Lgt=s(LD);K0o=r(Lgt,"LongformerForMaskedLM"),Lgt.forEach(t),Z0o=r(pxe," (Longformer model)"),pxe.forEach(t),ewo=i(O),Zu=n(O,"LI",{});var _xe=s(Zu);bfe=n(_xe,"STRONG",{});var ygt=s(bfe);owo=r(ygt,"lxmert"),ygt.forEach(t),rwo=r(_xe," \u2014 "),yD=n(_xe,"A",{href:!0});var xgt=s(yD);two=r(xgt,"LxmertForPreTraining"),xgt.forEach(t),awo=r(_xe," (LXMERT model)"),_xe.forEach(t),nwo=i(O),e7=n(O,"LI",{});var uxe=s(e7);vfe=n(uxe,"STRONG",{});var $gt=s(vfe);swo=r($gt,"megatron-bert"),$gt.forEach(t),lwo=r(uxe," \u2014 "),xD=n(uxe,"A",{href:!0});var kgt=s(xD);iwo=r(kgt,"MegatronBertForPreTraining"),kgt.forEach(t),dwo=r(uxe," (Megatron-BERT model)"),uxe.forEach(t),cwo=i(O),o7=n(O,"LI",{});var bxe=s(o7);Ffe=n(bxe,"STRONG",{});var Sgt=s(Ffe);fwo=r(Sgt,"mobilebert"),Sgt.forEach(t),mwo=r(bxe," \u2014 "),$D=n(bxe,"A",{href:!0});var Rgt=s($D);gwo=r(Rgt,"MobileBertForPreTraining"),Rgt.forEach(t),hwo=r(bxe," (MobileBERT model)"),bxe.forEach(t),pwo=i(O),r7=n(O,"LI",{});var vxe=s(r7);Tfe=n(vxe,"STRONG",{});var Pgt=s(Tfe);_wo=r(Pgt,"mpnet"),Pgt.forEach(t),uwo=r(vxe," \u2014 "),kD=n(vxe,"A",{href:!0});var Bgt=s(kD);bwo=r(Bgt,"MPNetForMaskedLM"),Bgt.forEach(t),vwo=r(vxe," (MPNet model)"),vxe.forEach(t),Fwo=i(O),t7=n(O,"LI",{});var Fxe=s(t7);Mfe=n(Fxe,"STRONG",{});var Igt=s(Mfe);Two=r(Igt,"nezha"),Igt.forEach(t),Mwo=r(Fxe," \u2014 "),SD=n(Fxe,"A",{href:!0});var Ngt=s(SD);Ewo=r(Ngt,"NezhaForPreTraining"),Ngt.forEach(t),Cwo=r(Fxe," (Nezha model)"),Fxe.forEach(t),wwo=i(O),a7=n(O,"LI",{});var Txe=s(a7);Efe=n(Txe,"STRONG",{});var qgt=s(Efe);Awo=r(qgt,"openai-gpt"),qgt.forEach(t),Lwo=r(Txe," \u2014 "),RD=n(Txe,"A",{href:!0});var jgt=s(RD);ywo=r(jgt,"OpenAIGPTLMHeadModel"),jgt.forEach(t),xwo=r(Txe," (OpenAI GPT model)"),Txe.forEach(t),$wo=i(O),n7=n(O,"LI",{});var Mxe=s(n7);Cfe=n(Mxe,"STRONG",{});var Dgt=s(Cfe);kwo=r(Dgt,"retribert"),Dgt.forEach(t),Swo=r(Mxe," \u2014 "),PD=n(Mxe,"A",{href:!0});var Ggt=s(PD);Rwo=r(Ggt,"RetriBertModel"),Ggt.forEach(t),Pwo=r(Mxe," (RetriBERT model)"),Mxe.forEach(t),Bwo=i(O),s7=n(O,"LI",{});var Exe=s(s7);wfe=n(Exe,"STRONG",{});var Ogt=s(wfe);Iwo=r(Ogt,"roberta"),Ogt.forEach(t),Nwo=r(Exe," \u2014 "),BD=n(Exe,"A",{href:!0});var Vgt=s(BD);qwo=r(Vgt,"RobertaForMaskedLM"),Vgt.forEach(t),jwo=r(Exe," (RoBERTa model)"),Exe.forEach(t),Dwo=i(O),l7=n(O,"LI",{});var Cxe=s(l7);Afe=n(Cxe,"STRONG",{});var Xgt=s(Afe);Gwo=r(Xgt,"splinter"),Xgt.forEach(t),Owo=r(Cxe," \u2014 "),ID=n(Cxe,"A",{href:!0});var zgt=s(ID);Vwo=r(zgt,"SplinterForPreTraining"),zgt.forEach(t),Xwo=r(Cxe," (Splinter model)"),Cxe.forEach(t),zwo=i(O),i7=n(O,"LI",{});var wxe=s(i7);Lfe=n(wxe,"STRONG",{});var Qgt=s(Lfe);Qwo=r(Qgt,"squeezebert"),Qgt.forEach(t),Wwo=r(wxe," \u2014 "),ND=n(wxe,"A",{href:!0});var Wgt=s(ND);Hwo=r(Wgt,"SqueezeBertForMaskedLM"),Wgt.forEach(t),Uwo=r(wxe," (SqueezeBERT model)"),wxe.forEach(t),Jwo=i(O),d7=n(O,"LI",{});var Axe=s(d7);yfe=n(Axe,"STRONG",{});var Hgt=s(yfe);Ywo=r(Hgt,"t5"),Hgt.forEach(t),Kwo=r(Axe," \u2014 "),qD=n(Axe,"A",{href:!0});var Ugt=s(qD);Zwo=r(Ugt,"T5ForConditionalGeneration"),Ugt.forEach(t),eAo=r(Axe," (T5 model)"),Axe.forEach(t),oAo=i(O),c7=n(O,"LI",{});var Lxe=s(c7);xfe=n(Lxe,"STRONG",{});var Jgt=s(xfe);rAo=r(Jgt,"tapas"),Jgt.forEach(t),tAo=r(Lxe," \u2014 "),jD=n(Lxe,"A",{href:!0});var Ygt=s(jD);aAo=r(Ygt,"TapasForMaskedLM"),Ygt.forEach(t),nAo=r(Lxe," (TAPAS model)"),Lxe.forEach(t),sAo=i(O),f7=n(O,"LI",{});var yxe=s(f7);$fe=n(yxe,"STRONG",{});var Kgt=s($fe);lAo=r(Kgt,"transfo-xl"),Kgt.forEach(t),iAo=r(yxe," \u2014 "),DD=n(yxe,"A",{href:!0});var Zgt=s(DD);dAo=r(Zgt,"TransfoXLLMHeadModel"),Zgt.forEach(t),cAo=r(yxe," (Transformer-XL model)"),yxe.forEach(t),fAo=i(O),m7=n(O,"LI",{});var xxe=s(m7);kfe=n(xxe,"STRONG",{});var eht=s(kfe);mAo=r(eht,"unispeech"),eht.forEach(t),gAo=r(xxe," \u2014 "),GD=n(xxe,"A",{href:!0});var oht=s(GD);hAo=r(oht,"UniSpeechForPreTraining"),oht.forEach(t),pAo=r(xxe," (UniSpeech model)"),xxe.forEach(t),_Ao=i(O),g7=n(O,"LI",{});var $xe=s(g7);Sfe=n($xe,"STRONG",{});var rht=s(Sfe);uAo=r(rht,"unispeech-sat"),rht.forEach(t),bAo=r($xe," \u2014 "),OD=n($xe,"A",{href:!0});var tht=s(OD);vAo=r(tht,"UniSpeechSatForPreTraining"),tht.forEach(t),FAo=r($xe," (UniSpeechSat model)"),$xe.forEach(t),TAo=i(O),h7=n(O,"LI",{});var kxe=s(h7);Rfe=n(kxe,"STRONG",{});var aht=s(Rfe);MAo=r(aht,"visual_bert"),aht.forEach(t),EAo=r(kxe," \u2014 "),VD=n(kxe,"A",{href:!0});var nht=s(VD);CAo=r(nht,"VisualBertForPreTraining"),nht.forEach(t),wAo=r(kxe," (VisualBERT model)"),kxe.forEach(t),AAo=i(O),p7=n(O,"LI",{});var Sxe=s(p7);Pfe=n(Sxe,"STRONG",{});var sht=s(Pfe);LAo=r(sht,"vit_mae"),sht.forEach(t),yAo=r(Sxe," \u2014 "),XD=n(Sxe,"A",{href:!0});var lht=s(XD);xAo=r(lht,"ViTMAEForPreTraining"),lht.forEach(t),$Ao=r(Sxe," (ViTMAE model)"),Sxe.forEach(t),kAo=i(O),_7=n(O,"LI",{});var Rxe=s(_7);Bfe=n(Rxe,"STRONG",{});var iht=s(Bfe);SAo=r(iht,"wav2vec2"),iht.forEach(t),RAo=r(Rxe," \u2014 "),zD=n(Rxe,"A",{href:!0});var dht=s(zD);PAo=r(dht,"Wav2Vec2ForPreTraining"),dht.forEach(t),BAo=r(Rxe," (Wav2Vec2 model)"),Rxe.forEach(t),IAo=i(O),u7=n(O,"LI",{});var Pxe=s(u7);Ife=n(Pxe,"STRONG",{});var cht=s(Ife);NAo=r(cht,"wav2vec2-conformer"),cht.forEach(t),qAo=r(Pxe," \u2014 "),QD=n(Pxe,"A",{href:!0});var fht=s(QD);jAo=r(fht,"Wav2Vec2ConformerForPreTraining"),fht.forEach(t),DAo=r(Pxe," (Wav2Vec2-Conformer model)"),Pxe.forEach(t),GAo=i(O),b7=n(O,"LI",{});var Bxe=s(b7);Nfe=n(Bxe,"STRONG",{});var mht=s(Nfe);OAo=r(mht,"xlm"),mht.forEach(t),VAo=r(Bxe," \u2014 "),WD=n(Bxe,"A",{href:!0});var ght=s(WD);XAo=r(ght,"XLMWithLMHeadModel"),ght.forEach(t),zAo=r(Bxe," (XLM model)"),Bxe.forEach(t),QAo=i(O),v7=n(O,"LI",{});var Ixe=s(v7);qfe=n(Ixe,"STRONG",{});var hht=s(qfe);WAo=r(hht,"xlm-roberta"),hht.forEach(t),HAo=r(Ixe," \u2014 "),HD=n(Ixe,"A",{href:!0});var pht=s(HD);UAo=r(pht,"XLMRobertaForMaskedLM"),pht.forEach(t),JAo=r(Ixe," (XLM-RoBERTa model)"),Ixe.forEach(t),YAo=i(O),F7=n(O,"LI",{});var Nxe=s(F7);jfe=n(Nxe,"STRONG",{});var _ht=s(jfe);KAo=r(_ht,"xlm-roberta-xl"),_ht.forEach(t),ZAo=r(Nxe," \u2014 "),UD=n(Nxe,"A",{href:!0});var uht=s(UD);eLo=r(uht,"XLMRobertaXLForMaskedLM"),uht.forEach(t),oLo=r(Nxe," (XLM-RoBERTa-XL model)"),Nxe.forEach(t),rLo=i(O),T7=n(O,"LI",{});var qxe=s(T7);Dfe=n(qxe,"STRONG",{});var bht=s(Dfe);tLo=r(bht,"xlnet"),bht.forEach(t),aLo=r(qxe," \u2014 "),JD=n(qxe,"A",{href:!0});var vht=s(JD);nLo=r(vht,"XLNetLMHeadModel"),vht.forEach(t),sLo=r(qxe," (XLNet model)"),qxe.forEach(t),O.forEach(t),lLo=i(na),M7=n(na,"P",{});var jxe=s(M7);iLo=r(jxe,"The model is set in evaluation mode by default using "),Gfe=n(jxe,"CODE",{});var Fht=s(Gfe);dLo=r(Fht,"model.eval()"),Fht.forEach(t),cLo=r(jxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=n(jxe,"CODE",{});var Tht=s(Ofe);fLo=r(Tht,"model.train()"),Tht.forEach(t),jxe.forEach(t),mLo=i(na),T(E7.$$.fragment,na),na.forEach(t),Ks.forEach(t),rOe=i(f),Gi=n(f,"H2",{class:!0});var iXe=s(Gi);C7=n(iXe,"A",{id:!0,class:!0,href:!0});var Mht=s(C7);Vfe=n(Mht,"SPAN",{});var Eht=s(Vfe);T(fy.$$.fragment,Eht),Eht.forEach(t),Mht.forEach(t),gLo=i(iXe),Xfe=n(iXe,"SPAN",{});var Cht=s(Xfe);hLo=r(Cht,"AutoModelForCausalLM"),Cht.forEach(t),iXe.forEach(t),tOe=i(f),ko=n(f,"DIV",{class:!0});var Zs=s(ko);T(my.$$.fragment,Zs),pLo=i(Zs),Oi=n(Zs,"P",{});var Eoe=s(Oi);_Lo=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=n(Eoe,"A",{href:!0});var wht=s(YD);uLo=r(wht,"from_pretrained()"),wht.forEach(t),bLo=r(Eoe," class method or the "),KD=n(Eoe,"A",{href:!0});var Aht=s(KD);vLo=r(Aht,"from_config()"),Aht.forEach(t),FLo=r(Eoe,` class
method.`),Eoe.forEach(t),TLo=i(Zs),gy=n(Zs,"P",{});var dXe=s(gy);MLo=r(dXe,"This class cannot be instantiated directly using "),zfe=n(dXe,"CODE",{});var Lht=s(zfe);ELo=r(Lht,"__init__()"),Lht.forEach(t),CLo=r(dXe," (throws an error)."),dXe.forEach(t),wLo=i(Zs),lt=n(Zs,"DIV",{class:!0});var Bw=s(lt);T(hy.$$.fragment,Bw),ALo=i(Bw),Qfe=n(Bw,"P",{});var yht=s(Qfe);LLo=r(yht,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yht.forEach(t),yLo=i(Bw),Vi=n(Bw,"P",{});var Coe=s(Vi);xLo=r(Coe,`Note:
Loading a model from its configuration file does `),Wfe=n(Coe,"STRONG",{});var xht=s(Wfe);$Lo=r(xht,"not"),xht.forEach(t),kLo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(Coe,"A",{href:!0});var $ht=s(ZD);SLo=r($ht,"from_pretrained()"),$ht.forEach(t),RLo=r(Coe," to load the model weights."),Coe.forEach(t),PLo=i(Bw),T(w7.$$.fragment,Bw),Bw.forEach(t),BLo=i(Zs),Ke=n(Zs,"DIV",{class:!0});var sa=s(Ke);T(py.$$.fragment,sa),ILo=i(sa),Hfe=n(sa,"P",{});var kht=s(Hfe);NLo=r(kht,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kht.forEach(t),qLo=i(sa),Ba=n(sa,"P",{});var Iw=s(Ba);jLo=r(Iw,"The model class to instantiate is selected based on the "),Ufe=n(Iw,"CODE",{});var Sht=s(Ufe);DLo=r(Sht,"model_type"),Sht.forEach(t),GLo=r(Iw,` property of the config object (either
passed as an argument or loaded from `),Jfe=n(Iw,"CODE",{});var Rht=s(Jfe);OLo=r(Rht,"pretrained_model_name_or_path"),Rht.forEach(t),VLo=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=n(Iw,"CODE",{});var Pht=s(Yfe);XLo=r(Pht,"pretrained_model_name_or_path"),Pht.forEach(t),zLo=r(Iw,":"),Iw.forEach(t),QLo=i(sa),z=n(sa,"UL",{});var W=s(z);A7=n(W,"LI",{});var Dxe=s(A7);Kfe=n(Dxe,"STRONG",{});var Bht=s(Kfe);WLo=r(Bht,"bart"),Bht.forEach(t),HLo=r(Dxe," \u2014 "),eG=n(Dxe,"A",{href:!0});var Iht=s(eG);ULo=r(Iht,"BartForCausalLM"),Iht.forEach(t),JLo=r(Dxe," (BART model)"),Dxe.forEach(t),YLo=i(W),L7=n(W,"LI",{});var Gxe=s(L7);Zfe=n(Gxe,"STRONG",{});var Nht=s(Zfe);KLo=r(Nht,"bert"),Nht.forEach(t),ZLo=r(Gxe," \u2014 "),oG=n(Gxe,"A",{href:!0});var qht=s(oG);eyo=r(qht,"BertLMHeadModel"),qht.forEach(t),oyo=r(Gxe," (BERT model)"),Gxe.forEach(t),ryo=i(W),y7=n(W,"LI",{});var Oxe=s(y7);eme=n(Oxe,"STRONG",{});var jht=s(eme);tyo=r(jht,"bert-generation"),jht.forEach(t),ayo=r(Oxe," \u2014 "),rG=n(Oxe,"A",{href:!0});var Dht=s(rG);nyo=r(Dht,"BertGenerationDecoder"),Dht.forEach(t),syo=r(Oxe," (Bert Generation model)"),Oxe.forEach(t),lyo=i(W),x7=n(W,"LI",{});var Vxe=s(x7);ome=n(Vxe,"STRONG",{});var Ght=s(ome);iyo=r(Ght,"big_bird"),Ght.forEach(t),dyo=r(Vxe," \u2014 "),tG=n(Vxe,"A",{href:!0});var Oht=s(tG);cyo=r(Oht,"BigBirdForCausalLM"),Oht.forEach(t),fyo=r(Vxe," (BigBird model)"),Vxe.forEach(t),myo=i(W),$7=n(W,"LI",{});var Xxe=s($7);rme=n(Xxe,"STRONG",{});var Vht=s(rme);gyo=r(Vht,"bigbird_pegasus"),Vht.forEach(t),hyo=r(Xxe," \u2014 "),aG=n(Xxe,"A",{href:!0});var Xht=s(aG);pyo=r(Xht,"BigBirdPegasusForCausalLM"),Xht.forEach(t),_yo=r(Xxe," (BigBird-Pegasus model)"),Xxe.forEach(t),uyo=i(W),k7=n(W,"LI",{});var zxe=s(k7);tme=n(zxe,"STRONG",{});var zht=s(tme);byo=r(zht,"blenderbot"),zht.forEach(t),vyo=r(zxe," \u2014 "),nG=n(zxe,"A",{href:!0});var Qht=s(nG);Fyo=r(Qht,"BlenderbotForCausalLM"),Qht.forEach(t),Tyo=r(zxe," (Blenderbot model)"),zxe.forEach(t),Myo=i(W),S7=n(W,"LI",{});var Qxe=s(S7);ame=n(Qxe,"STRONG",{});var Wht=s(ame);Eyo=r(Wht,"blenderbot-small"),Wht.forEach(t),Cyo=r(Qxe," \u2014 "),sG=n(Qxe,"A",{href:!0});var Hht=s(sG);wyo=r(Hht,"BlenderbotSmallForCausalLM"),Hht.forEach(t),Ayo=r(Qxe," (BlenderbotSmall model)"),Qxe.forEach(t),Lyo=i(W),R7=n(W,"LI",{});var Wxe=s(R7);nme=n(Wxe,"STRONG",{});var Uht=s(nme);yyo=r(Uht,"bloom"),Uht.forEach(t),xyo=r(Wxe," \u2014 "),lG=n(Wxe,"A",{href:!0});var Jht=s(lG);$yo=r(Jht,"BloomForCausalLM"),Jht.forEach(t),kyo=r(Wxe," (BLOOM model)"),Wxe.forEach(t),Syo=i(W),P7=n(W,"LI",{});var Hxe=s(P7);sme=n(Hxe,"STRONG",{});var Yht=s(sme);Ryo=r(Yht,"camembert"),Yht.forEach(t),Pyo=r(Hxe," \u2014 "),iG=n(Hxe,"A",{href:!0});var Kht=s(iG);Byo=r(Kht,"CamembertForCausalLM"),Kht.forEach(t),Iyo=r(Hxe," (CamemBERT model)"),Hxe.forEach(t),Nyo=i(W),B7=n(W,"LI",{});var Uxe=s(B7);lme=n(Uxe,"STRONG",{});var Zht=s(lme);qyo=r(Zht,"ctrl"),Zht.forEach(t),jyo=r(Uxe," \u2014 "),dG=n(Uxe,"A",{href:!0});var ept=s(dG);Dyo=r(ept,"CTRLLMHeadModel"),ept.forEach(t),Gyo=r(Uxe," (CTRL model)"),Uxe.forEach(t),Oyo=i(W),I7=n(W,"LI",{});var Jxe=s(I7);ime=n(Jxe,"STRONG",{});var opt=s(ime);Vyo=r(opt,"data2vec-text"),opt.forEach(t),Xyo=r(Jxe," \u2014 "),cG=n(Jxe,"A",{href:!0});var rpt=s(cG);zyo=r(rpt,"Data2VecTextForCausalLM"),rpt.forEach(t),Qyo=r(Jxe," (Data2VecText model)"),Jxe.forEach(t),Wyo=i(W),N7=n(W,"LI",{});var Yxe=s(N7);dme=n(Yxe,"STRONG",{});var tpt=s(dme);Hyo=r(tpt,"electra"),tpt.forEach(t),Uyo=r(Yxe," \u2014 "),fG=n(Yxe,"A",{href:!0});var apt=s(fG);Jyo=r(apt,"ElectraForCausalLM"),apt.forEach(t),Yyo=r(Yxe," (ELECTRA model)"),Yxe.forEach(t),Kyo=i(W),q7=n(W,"LI",{});var Kxe=s(q7);cme=n(Kxe,"STRONG",{});var npt=s(cme);Zyo=r(npt,"gpt2"),npt.forEach(t),e8o=r(Kxe," \u2014 "),mG=n(Kxe,"A",{href:!0});var spt=s(mG);o8o=r(spt,"GPT2LMHeadModel"),spt.forEach(t),r8o=r(Kxe," (OpenAI GPT-2 model)"),Kxe.forEach(t),t8o=i(W),j7=n(W,"LI",{});var Zxe=s(j7);fme=n(Zxe,"STRONG",{});var lpt=s(fme);a8o=r(lpt,"gpt_neo"),lpt.forEach(t),n8o=r(Zxe," \u2014 "),gG=n(Zxe,"A",{href:!0});var ipt=s(gG);s8o=r(ipt,"GPTNeoForCausalLM"),ipt.forEach(t),l8o=r(Zxe," (GPT Neo model)"),Zxe.forEach(t),i8o=i(W),D7=n(W,"LI",{});var e$e=s(D7);mme=n(e$e,"STRONG",{});var dpt=s(mme);d8o=r(dpt,"gpt_neox"),dpt.forEach(t),c8o=r(e$e," \u2014 "),hG=n(e$e,"A",{href:!0});var cpt=s(hG);f8o=r(cpt,"GPTNeoXForCausalLM"),cpt.forEach(t),m8o=r(e$e," (GPT NeoX model)"),e$e.forEach(t),g8o=i(W),G7=n(W,"LI",{});var o$e=s(G7);gme=n(o$e,"STRONG",{});var fpt=s(gme);h8o=r(fpt,"gptj"),fpt.forEach(t),p8o=r(o$e," \u2014 "),pG=n(o$e,"A",{href:!0});var mpt=s(pG);_8o=r(mpt,"GPTJForCausalLM"),mpt.forEach(t),u8o=r(o$e," (GPT-J model)"),o$e.forEach(t),b8o=i(W),O7=n(W,"LI",{});var r$e=s(O7);hme=n(r$e,"STRONG",{});var gpt=s(hme);v8o=r(gpt,"marian"),gpt.forEach(t),F8o=r(r$e," \u2014 "),_G=n(r$e,"A",{href:!0});var hpt=s(_G);T8o=r(hpt,"MarianForCausalLM"),hpt.forEach(t),M8o=r(r$e," (Marian model)"),r$e.forEach(t),E8o=i(W),V7=n(W,"LI",{});var t$e=s(V7);pme=n(t$e,"STRONG",{});var ppt=s(pme);C8o=r(ppt,"mbart"),ppt.forEach(t),w8o=r(t$e," \u2014 "),uG=n(t$e,"A",{href:!0});var _pt=s(uG);A8o=r(_pt,"MBartForCausalLM"),_pt.forEach(t),L8o=r(t$e," (mBART model)"),t$e.forEach(t),y8o=i(W),X7=n(W,"LI",{});var a$e=s(X7);_me=n(a$e,"STRONG",{});var upt=s(_me);x8o=r(upt,"megatron-bert"),upt.forEach(t),$8o=r(a$e," \u2014 "),bG=n(a$e,"A",{href:!0});var bpt=s(bG);k8o=r(bpt,"MegatronBertForCausalLM"),bpt.forEach(t),S8o=r(a$e," (Megatron-BERT model)"),a$e.forEach(t),R8o=i(W),z7=n(W,"LI",{});var n$e=s(z7);ume=n(n$e,"STRONG",{});var vpt=s(ume);P8o=r(vpt,"openai-gpt"),vpt.forEach(t),B8o=r(n$e," \u2014 "),vG=n(n$e,"A",{href:!0});var Fpt=s(vG);I8o=r(Fpt,"OpenAIGPTLMHeadModel"),Fpt.forEach(t),N8o=r(n$e," (OpenAI GPT model)"),n$e.forEach(t),q8o=i(W),Q7=n(W,"LI",{});var s$e=s(Q7);bme=n(s$e,"STRONG",{});var Tpt=s(bme);j8o=r(Tpt,"opt"),Tpt.forEach(t),D8o=r(s$e," \u2014 "),FG=n(s$e,"A",{href:!0});var Mpt=s(FG);G8o=r(Mpt,"OPTForCausalLM"),Mpt.forEach(t),O8o=r(s$e," (OPT model)"),s$e.forEach(t),V8o=i(W),W7=n(W,"LI",{});var l$e=s(W7);vme=n(l$e,"STRONG",{});var Ept=s(vme);X8o=r(Ept,"pegasus"),Ept.forEach(t),z8o=r(l$e," \u2014 "),TG=n(l$e,"A",{href:!0});var Cpt=s(TG);Q8o=r(Cpt,"PegasusForCausalLM"),Cpt.forEach(t),W8o=r(l$e," (Pegasus model)"),l$e.forEach(t),H8o=i(W),H7=n(W,"LI",{});var i$e=s(H7);Fme=n(i$e,"STRONG",{});var wpt=s(Fme);U8o=r(wpt,"plbart"),wpt.forEach(t),J8o=r(i$e," \u2014 "),MG=n(i$e,"A",{href:!0});var Apt=s(MG);Y8o=r(Apt,"PLBartForCausalLM"),Apt.forEach(t),K8o=r(i$e," (PLBart model)"),i$e.forEach(t),Z8o=i(W),U7=n(W,"LI",{});var d$e=s(U7);Tme=n(d$e,"STRONG",{});var Lpt=s(Tme);e9o=r(Lpt,"prophetnet"),Lpt.forEach(t),o9o=r(d$e," \u2014 "),EG=n(d$e,"A",{href:!0});var ypt=s(EG);r9o=r(ypt,"ProphetNetForCausalLM"),ypt.forEach(t),t9o=r(d$e," (ProphetNet model)"),d$e.forEach(t),a9o=i(W),J7=n(W,"LI",{});var c$e=s(J7);Mme=n(c$e,"STRONG",{});var xpt=s(Mme);n9o=r(xpt,"qdqbert"),xpt.forEach(t),s9o=r(c$e," \u2014 "),CG=n(c$e,"A",{href:!0});var $pt=s(CG);l9o=r($pt,"QDQBertLMHeadModel"),$pt.forEach(t),i9o=r(c$e," (QDQBert model)"),c$e.forEach(t),d9o=i(W),Y7=n(W,"LI",{});var f$e=s(Y7);Eme=n(f$e,"STRONG",{});var kpt=s(Eme);c9o=r(kpt,"reformer"),kpt.forEach(t),f9o=r(f$e," \u2014 "),wG=n(f$e,"A",{href:!0});var Spt=s(wG);m9o=r(Spt,"ReformerModelWithLMHead"),Spt.forEach(t),g9o=r(f$e," (Reformer model)"),f$e.forEach(t),h9o=i(W),K7=n(W,"LI",{});var m$e=s(K7);Cme=n(m$e,"STRONG",{});var Rpt=s(Cme);p9o=r(Rpt,"rembert"),Rpt.forEach(t),_9o=r(m$e," \u2014 "),AG=n(m$e,"A",{href:!0});var Ppt=s(AG);u9o=r(Ppt,"RemBertForCausalLM"),Ppt.forEach(t),b9o=r(m$e," (RemBERT model)"),m$e.forEach(t),v9o=i(W),Z7=n(W,"LI",{});var g$e=s(Z7);wme=n(g$e,"STRONG",{});var Bpt=s(wme);F9o=r(Bpt,"roberta"),Bpt.forEach(t),T9o=r(g$e," \u2014 "),LG=n(g$e,"A",{href:!0});var Ipt=s(LG);M9o=r(Ipt,"RobertaForCausalLM"),Ipt.forEach(t),E9o=r(g$e," (RoBERTa model)"),g$e.forEach(t),C9o=i(W),e1=n(W,"LI",{});var h$e=s(e1);Ame=n(h$e,"STRONG",{});var Npt=s(Ame);w9o=r(Npt,"roformer"),Npt.forEach(t),A9o=r(h$e," \u2014 "),yG=n(h$e,"A",{href:!0});var qpt=s(yG);L9o=r(qpt,"RoFormerForCausalLM"),qpt.forEach(t),y9o=r(h$e," (RoFormer model)"),h$e.forEach(t),x9o=i(W),o1=n(W,"LI",{});var p$e=s(o1);Lme=n(p$e,"STRONG",{});var jpt=s(Lme);$9o=r(jpt,"speech_to_text_2"),jpt.forEach(t),k9o=r(p$e," \u2014 "),xG=n(p$e,"A",{href:!0});var Dpt=s(xG);S9o=r(Dpt,"Speech2Text2ForCausalLM"),Dpt.forEach(t),R9o=r(p$e," (Speech2Text2 model)"),p$e.forEach(t),P9o=i(W),r1=n(W,"LI",{});var _$e=s(r1);yme=n(_$e,"STRONG",{});var Gpt=s(yme);B9o=r(Gpt,"transfo-xl"),Gpt.forEach(t),I9o=r(_$e," \u2014 "),$G=n(_$e,"A",{href:!0});var Opt=s($G);N9o=r(Opt,"TransfoXLLMHeadModel"),Opt.forEach(t),q9o=r(_$e," (Transformer-XL model)"),_$e.forEach(t),j9o=i(W),t1=n(W,"LI",{});var u$e=s(t1);xme=n(u$e,"STRONG",{});var Vpt=s(xme);D9o=r(Vpt,"trocr"),Vpt.forEach(t),G9o=r(u$e," \u2014 "),kG=n(u$e,"A",{href:!0});var Xpt=s(kG);O9o=r(Xpt,"TrOCRForCausalLM"),Xpt.forEach(t),V9o=r(u$e," (TrOCR model)"),u$e.forEach(t),X9o=i(W),a1=n(W,"LI",{});var b$e=s(a1);$me=n(b$e,"STRONG",{});var zpt=s($me);z9o=r(zpt,"xglm"),zpt.forEach(t),Q9o=r(b$e," \u2014 "),SG=n(b$e,"A",{href:!0});var Qpt=s(SG);W9o=r(Qpt,"XGLMForCausalLM"),Qpt.forEach(t),H9o=r(b$e," (XGLM model)"),b$e.forEach(t),U9o=i(W),n1=n(W,"LI",{});var v$e=s(n1);kme=n(v$e,"STRONG",{});var Wpt=s(kme);J9o=r(Wpt,"xlm"),Wpt.forEach(t),Y9o=r(v$e," \u2014 "),RG=n(v$e,"A",{href:!0});var Hpt=s(RG);K9o=r(Hpt,"XLMWithLMHeadModel"),Hpt.forEach(t),Z9o=r(v$e," (XLM model)"),v$e.forEach(t),exo=i(W),s1=n(W,"LI",{});var F$e=s(s1);Sme=n(F$e,"STRONG",{});var Upt=s(Sme);oxo=r(Upt,"xlm-prophetnet"),Upt.forEach(t),rxo=r(F$e," \u2014 "),PG=n(F$e,"A",{href:!0});var Jpt=s(PG);txo=r(Jpt,"XLMProphetNetForCausalLM"),Jpt.forEach(t),axo=r(F$e," (XLM-ProphetNet model)"),F$e.forEach(t),nxo=i(W),l1=n(W,"LI",{});var T$e=s(l1);Rme=n(T$e,"STRONG",{});var Ypt=s(Rme);sxo=r(Ypt,"xlm-roberta"),Ypt.forEach(t),lxo=r(T$e," \u2014 "),BG=n(T$e,"A",{href:!0});var Kpt=s(BG);ixo=r(Kpt,"XLMRobertaForCausalLM"),Kpt.forEach(t),dxo=r(T$e," (XLM-RoBERTa model)"),T$e.forEach(t),cxo=i(W),i1=n(W,"LI",{});var M$e=s(i1);Pme=n(M$e,"STRONG",{});var Zpt=s(Pme);fxo=r(Zpt,"xlm-roberta-xl"),Zpt.forEach(t),mxo=r(M$e," \u2014 "),IG=n(M$e,"A",{href:!0});var e_t=s(IG);gxo=r(e_t,"XLMRobertaXLForCausalLM"),e_t.forEach(t),hxo=r(M$e," (XLM-RoBERTa-XL model)"),M$e.forEach(t),pxo=i(W),d1=n(W,"LI",{});var E$e=s(d1);Bme=n(E$e,"STRONG",{});var o_t=s(Bme);_xo=r(o_t,"xlnet"),o_t.forEach(t),uxo=r(E$e," \u2014 "),NG=n(E$e,"A",{href:!0});var r_t=s(NG);bxo=r(r_t,"XLNetLMHeadModel"),r_t.forEach(t),vxo=r(E$e," (XLNet model)"),E$e.forEach(t),W.forEach(t),Fxo=i(sa),c1=n(sa,"P",{});var C$e=s(c1);Txo=r(C$e,"The model is set in evaluation mode by default using "),Ime=n(C$e,"CODE",{});var t_t=s(Ime);Mxo=r(t_t,"model.eval()"),t_t.forEach(t),Exo=r(C$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=n(C$e,"CODE",{});var a_t=s(Nme);Cxo=r(a_t,"model.train()"),a_t.forEach(t),C$e.forEach(t),wxo=i(sa),T(f1.$$.fragment,sa),sa.forEach(t),Zs.forEach(t),aOe=i(f),Xi=n(f,"H2",{class:!0});var cXe=s(Xi);m1=n(cXe,"A",{id:!0,class:!0,href:!0});var n_t=s(m1);qme=n(n_t,"SPAN",{});var s_t=s(qme);T(_y.$$.fragment,s_t),s_t.forEach(t),n_t.forEach(t),Axo=i(cXe),jme=n(cXe,"SPAN",{});var l_t=s(jme);Lxo=r(l_t,"AutoModelForMaskedLM"),l_t.forEach(t),cXe.forEach(t),nOe=i(f),So=n(f,"DIV",{class:!0});var el=s(So);T(uy.$$.fragment,el),yxo=i(el),zi=n(el,"P",{});var woe=s(zi);xxo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=n(woe,"A",{href:!0});var i_t=s(qG);$xo=r(i_t,"from_pretrained()"),i_t.forEach(t),kxo=r(woe," class method or the "),jG=n(woe,"A",{href:!0});var d_t=s(jG);Sxo=r(d_t,"from_config()"),d_t.forEach(t),Rxo=r(woe,` class
method.`),woe.forEach(t),Pxo=i(el),by=n(el,"P",{});var fXe=s(by);Bxo=r(fXe,"This class cannot be instantiated directly using "),Dme=n(fXe,"CODE",{});var c_t=s(Dme);Ixo=r(c_t,"__init__()"),c_t.forEach(t),Nxo=r(fXe," (throws an error)."),fXe.forEach(t),qxo=i(el),it=n(el,"DIV",{class:!0});var Nw=s(it);T(vy.$$.fragment,Nw),jxo=i(Nw),Gme=n(Nw,"P",{});var f_t=s(Gme);Dxo=r(f_t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),f_t.forEach(t),Gxo=i(Nw),Qi=n(Nw,"P",{});var Aoe=s(Qi);Oxo=r(Aoe,`Note:
Loading a model from its configuration file does `),Ome=n(Aoe,"STRONG",{});var m_t=s(Ome);Vxo=r(m_t,"not"),m_t.forEach(t),Xxo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=n(Aoe,"A",{href:!0});var g_t=s(DG);zxo=r(g_t,"from_pretrained()"),g_t.forEach(t),Qxo=r(Aoe," to load the model weights."),Aoe.forEach(t),Wxo=i(Nw),T(g1.$$.fragment,Nw),Nw.forEach(t),Hxo=i(el),Ze=n(el,"DIV",{class:!0});var la=s(Ze);T(Fy.$$.fragment,la),Uxo=i(la),Vme=n(la,"P",{});var h_t=s(Vme);Jxo=r(h_t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),h_t.forEach(t),Yxo=i(la),Ia=n(la,"P",{});var qw=s(Ia);Kxo=r(qw,"The model class to instantiate is selected based on the "),Xme=n(qw,"CODE",{});var p_t=s(Xme);Zxo=r(p_t,"model_type"),p_t.forEach(t),e$o=r(qw,` property of the config object (either
passed as an argument or loaded from `),zme=n(qw,"CODE",{});var __t=s(zme);o$o=r(__t,"pretrained_model_name_or_path"),__t.forEach(t),r$o=r(qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=n(qw,"CODE",{});var u_t=s(Qme);t$o=r(u_t,"pretrained_model_name_or_path"),u_t.forEach(t),a$o=r(qw,":"),qw.forEach(t),n$o=i(la),Q=n(la,"UL",{});var U=s(Q);h1=n(U,"LI",{});var w$e=s(h1);Wme=n(w$e,"STRONG",{});var b_t=s(Wme);s$o=r(b_t,"albert"),b_t.forEach(t),l$o=r(w$e," \u2014 "),GG=n(w$e,"A",{href:!0});var v_t=s(GG);i$o=r(v_t,"AlbertForMaskedLM"),v_t.forEach(t),d$o=r(w$e," (ALBERT model)"),w$e.forEach(t),c$o=i(U),p1=n(U,"LI",{});var A$e=s(p1);Hme=n(A$e,"STRONG",{});var F_t=s(Hme);f$o=r(F_t,"bart"),F_t.forEach(t),m$o=r(A$e," \u2014 "),OG=n(A$e,"A",{href:!0});var T_t=s(OG);g$o=r(T_t,"BartForConditionalGeneration"),T_t.forEach(t),h$o=r(A$e," (BART model)"),A$e.forEach(t),p$o=i(U),_1=n(U,"LI",{});var L$e=s(_1);Ume=n(L$e,"STRONG",{});var M_t=s(Ume);_$o=r(M_t,"bert"),M_t.forEach(t),u$o=r(L$e," \u2014 "),VG=n(L$e,"A",{href:!0});var E_t=s(VG);b$o=r(E_t,"BertForMaskedLM"),E_t.forEach(t),v$o=r(L$e," (BERT model)"),L$e.forEach(t),F$o=i(U),u1=n(U,"LI",{});var y$e=s(u1);Jme=n(y$e,"STRONG",{});var C_t=s(Jme);T$o=r(C_t,"big_bird"),C_t.forEach(t),M$o=r(y$e," \u2014 "),XG=n(y$e,"A",{href:!0});var w_t=s(XG);E$o=r(w_t,"BigBirdForMaskedLM"),w_t.forEach(t),C$o=r(y$e," (BigBird model)"),y$e.forEach(t),w$o=i(U),b1=n(U,"LI",{});var x$e=s(b1);Yme=n(x$e,"STRONG",{});var A_t=s(Yme);A$o=r(A_t,"camembert"),A_t.forEach(t),L$o=r(x$e," \u2014 "),zG=n(x$e,"A",{href:!0});var L_t=s(zG);y$o=r(L_t,"CamembertForMaskedLM"),L_t.forEach(t),x$o=r(x$e," (CamemBERT model)"),x$e.forEach(t),$$o=i(U),v1=n(U,"LI",{});var $$e=s(v1);Kme=n($$e,"STRONG",{});var y_t=s(Kme);k$o=r(y_t,"convbert"),y_t.forEach(t),S$o=r($$e," \u2014 "),QG=n($$e,"A",{href:!0});var x_t=s(QG);R$o=r(x_t,"ConvBertForMaskedLM"),x_t.forEach(t),P$o=r($$e," (ConvBERT model)"),$$e.forEach(t),B$o=i(U),F1=n(U,"LI",{});var k$e=s(F1);Zme=n(k$e,"STRONG",{});var $_t=s(Zme);I$o=r($_t,"data2vec-text"),$_t.forEach(t),N$o=r(k$e," \u2014 "),WG=n(k$e,"A",{href:!0});var k_t=s(WG);q$o=r(k_t,"Data2VecTextForMaskedLM"),k_t.forEach(t),j$o=r(k$e," (Data2VecText model)"),k$e.forEach(t),D$o=i(U),T1=n(U,"LI",{});var S$e=s(T1);ege=n(S$e,"STRONG",{});var S_t=s(ege);G$o=r(S_t,"deberta"),S_t.forEach(t),O$o=r(S$e," \u2014 "),HG=n(S$e,"A",{href:!0});var R_t=s(HG);V$o=r(R_t,"DebertaForMaskedLM"),R_t.forEach(t),X$o=r(S$e," (DeBERTa model)"),S$e.forEach(t),z$o=i(U),M1=n(U,"LI",{});var R$e=s(M1);oge=n(R$e,"STRONG",{});var P_t=s(oge);Q$o=r(P_t,"deberta-v2"),P_t.forEach(t),W$o=r(R$e," \u2014 "),UG=n(R$e,"A",{href:!0});var B_t=s(UG);H$o=r(B_t,"DebertaV2ForMaskedLM"),B_t.forEach(t),U$o=r(R$e," (DeBERTa-v2 model)"),R$e.forEach(t),J$o=i(U),E1=n(U,"LI",{});var P$e=s(E1);rge=n(P$e,"STRONG",{});var I_t=s(rge);Y$o=r(I_t,"distilbert"),I_t.forEach(t),K$o=r(P$e," \u2014 "),JG=n(P$e,"A",{href:!0});var N_t=s(JG);Z$o=r(N_t,"DistilBertForMaskedLM"),N_t.forEach(t),eko=r(P$e," (DistilBERT model)"),P$e.forEach(t),oko=i(U),C1=n(U,"LI",{});var B$e=s(C1);tge=n(B$e,"STRONG",{});var q_t=s(tge);rko=r(q_t,"electra"),q_t.forEach(t),tko=r(B$e," \u2014 "),YG=n(B$e,"A",{href:!0});var j_t=s(YG);ako=r(j_t,"ElectraForMaskedLM"),j_t.forEach(t),nko=r(B$e," (ELECTRA model)"),B$e.forEach(t),sko=i(U),w1=n(U,"LI",{});var I$e=s(w1);age=n(I$e,"STRONG",{});var D_t=s(age);lko=r(D_t,"flaubert"),D_t.forEach(t),iko=r(I$e," \u2014 "),KG=n(I$e,"A",{href:!0});var G_t=s(KG);dko=r(G_t,"FlaubertWithLMHeadModel"),G_t.forEach(t),cko=r(I$e," (FlauBERT model)"),I$e.forEach(t),fko=i(U),A1=n(U,"LI",{});var N$e=s(A1);nge=n(N$e,"STRONG",{});var O_t=s(nge);mko=r(O_t,"fnet"),O_t.forEach(t),gko=r(N$e," \u2014 "),ZG=n(N$e,"A",{href:!0});var V_t=s(ZG);hko=r(V_t,"FNetForMaskedLM"),V_t.forEach(t),pko=r(N$e," (FNet model)"),N$e.forEach(t),_ko=i(U),L1=n(U,"LI",{});var q$e=s(L1);sge=n(q$e,"STRONG",{});var X_t=s(sge);uko=r(X_t,"funnel"),X_t.forEach(t),bko=r(q$e," \u2014 "),eO=n(q$e,"A",{href:!0});var z_t=s(eO);vko=r(z_t,"FunnelForMaskedLM"),z_t.forEach(t),Fko=r(q$e," (Funnel Transformer model)"),q$e.forEach(t),Tko=i(U),y1=n(U,"LI",{});var j$e=s(y1);lge=n(j$e,"STRONG",{});var Q_t=s(lge);Mko=r(Q_t,"ibert"),Q_t.forEach(t),Eko=r(j$e," \u2014 "),oO=n(j$e,"A",{href:!0});var W_t=s(oO);Cko=r(W_t,"IBertForMaskedLM"),W_t.forEach(t),wko=r(j$e," (I-BERT model)"),j$e.forEach(t),Ako=i(U),x1=n(U,"LI",{});var D$e=s(x1);ige=n(D$e,"STRONG",{});var H_t=s(ige);Lko=r(H_t,"layoutlm"),H_t.forEach(t),yko=r(D$e," \u2014 "),rO=n(D$e,"A",{href:!0});var U_t=s(rO);xko=r(U_t,"LayoutLMForMaskedLM"),U_t.forEach(t),$ko=r(D$e," (LayoutLM model)"),D$e.forEach(t),kko=i(U),$1=n(U,"LI",{});var G$e=s($1);dge=n(G$e,"STRONG",{});var J_t=s(dge);Sko=r(J_t,"longformer"),J_t.forEach(t),Rko=r(G$e," \u2014 "),tO=n(G$e,"A",{href:!0});var Y_t=s(tO);Pko=r(Y_t,"LongformerForMaskedLM"),Y_t.forEach(t),Bko=r(G$e," (Longformer model)"),G$e.forEach(t),Iko=i(U),k1=n(U,"LI",{});var O$e=s(k1);cge=n(O$e,"STRONG",{});var K_t=s(cge);Nko=r(K_t,"luke"),K_t.forEach(t),qko=r(O$e," \u2014 "),aO=n(O$e,"A",{href:!0});var Z_t=s(aO);jko=r(Z_t,"LukeForMaskedLM"),Z_t.forEach(t),Dko=r(O$e," (LUKE model)"),O$e.forEach(t),Gko=i(U),S1=n(U,"LI",{});var V$e=s(S1);fge=n(V$e,"STRONG",{});var eut=s(fge);Oko=r(eut,"mbart"),eut.forEach(t),Vko=r(V$e," \u2014 "),nO=n(V$e,"A",{href:!0});var out=s(nO);Xko=r(out,"MBartForConditionalGeneration"),out.forEach(t),zko=r(V$e," (mBART model)"),V$e.forEach(t),Qko=i(U),R1=n(U,"LI",{});var X$e=s(R1);mge=n(X$e,"STRONG",{});var rut=s(mge);Wko=r(rut,"megatron-bert"),rut.forEach(t),Hko=r(X$e," \u2014 "),sO=n(X$e,"A",{href:!0});var tut=s(sO);Uko=r(tut,"MegatronBertForMaskedLM"),tut.forEach(t),Jko=r(X$e," (Megatron-BERT model)"),X$e.forEach(t),Yko=i(U),P1=n(U,"LI",{});var z$e=s(P1);gge=n(z$e,"STRONG",{});var aut=s(gge);Kko=r(aut,"mobilebert"),aut.forEach(t),Zko=r(z$e," \u2014 "),lO=n(z$e,"A",{href:!0});var nut=s(lO);eSo=r(nut,"MobileBertForMaskedLM"),nut.forEach(t),oSo=r(z$e," (MobileBERT model)"),z$e.forEach(t),rSo=i(U),B1=n(U,"LI",{});var Q$e=s(B1);hge=n(Q$e,"STRONG",{});var sut=s(hge);tSo=r(sut,"mpnet"),sut.forEach(t),aSo=r(Q$e," \u2014 "),iO=n(Q$e,"A",{href:!0});var lut=s(iO);nSo=r(lut,"MPNetForMaskedLM"),lut.forEach(t),sSo=r(Q$e," (MPNet model)"),Q$e.forEach(t),lSo=i(U),I1=n(U,"LI",{});var W$e=s(I1);pge=n(W$e,"STRONG",{});var iut=s(pge);iSo=r(iut,"nezha"),iut.forEach(t),dSo=r(W$e," \u2014 "),dO=n(W$e,"A",{href:!0});var dut=s(dO);cSo=r(dut,"NezhaForMaskedLM"),dut.forEach(t),fSo=r(W$e," (Nezha model)"),W$e.forEach(t),mSo=i(U),N1=n(U,"LI",{});var H$e=s(N1);_ge=n(H$e,"STRONG",{});var cut=s(_ge);gSo=r(cut,"nystromformer"),cut.forEach(t),hSo=r(H$e," \u2014 "),cO=n(H$e,"A",{href:!0});var fut=s(cO);pSo=r(fut,"NystromformerForMaskedLM"),fut.forEach(t),_So=r(H$e," (Nystr\xF6mformer model)"),H$e.forEach(t),uSo=i(U),q1=n(U,"LI",{});var U$e=s(q1);uge=n(U$e,"STRONG",{});var mut=s(uge);bSo=r(mut,"perceiver"),mut.forEach(t),vSo=r(U$e," \u2014 "),fO=n(U$e,"A",{href:!0});var gut=s(fO);FSo=r(gut,"PerceiverForMaskedLM"),gut.forEach(t),TSo=r(U$e," (Perceiver model)"),U$e.forEach(t),MSo=i(U),j1=n(U,"LI",{});var J$e=s(j1);bge=n(J$e,"STRONG",{});var hut=s(bge);ESo=r(hut,"qdqbert"),hut.forEach(t),CSo=r(J$e," \u2014 "),mO=n(J$e,"A",{href:!0});var put=s(mO);wSo=r(put,"QDQBertForMaskedLM"),put.forEach(t),ASo=r(J$e," (QDQBert model)"),J$e.forEach(t),LSo=i(U),D1=n(U,"LI",{});var Y$e=s(D1);vge=n(Y$e,"STRONG",{});var _ut=s(vge);ySo=r(_ut,"reformer"),_ut.forEach(t),xSo=r(Y$e," \u2014 "),gO=n(Y$e,"A",{href:!0});var uut=s(gO);$So=r(uut,"ReformerForMaskedLM"),uut.forEach(t),kSo=r(Y$e," (Reformer model)"),Y$e.forEach(t),SSo=i(U),G1=n(U,"LI",{});var K$e=s(G1);Fge=n(K$e,"STRONG",{});var but=s(Fge);RSo=r(but,"rembert"),but.forEach(t),PSo=r(K$e," \u2014 "),hO=n(K$e,"A",{href:!0});var vut=s(hO);BSo=r(vut,"RemBertForMaskedLM"),vut.forEach(t),ISo=r(K$e," (RemBERT model)"),K$e.forEach(t),NSo=i(U),O1=n(U,"LI",{});var Z$e=s(O1);Tge=n(Z$e,"STRONG",{});var Fut=s(Tge);qSo=r(Fut,"roberta"),Fut.forEach(t),jSo=r(Z$e," \u2014 "),pO=n(Z$e,"A",{href:!0});var Tut=s(pO);DSo=r(Tut,"RobertaForMaskedLM"),Tut.forEach(t),GSo=r(Z$e," (RoBERTa model)"),Z$e.forEach(t),OSo=i(U),V1=n(U,"LI",{});var eke=s(V1);Mge=n(eke,"STRONG",{});var Mut=s(Mge);VSo=r(Mut,"roformer"),Mut.forEach(t),XSo=r(eke," \u2014 "),_O=n(eke,"A",{href:!0});var Eut=s(_O);zSo=r(Eut,"RoFormerForMaskedLM"),Eut.forEach(t),QSo=r(eke," (RoFormer model)"),eke.forEach(t),WSo=i(U),X1=n(U,"LI",{});var oke=s(X1);Ege=n(oke,"STRONG",{});var Cut=s(Ege);HSo=r(Cut,"squeezebert"),Cut.forEach(t),USo=r(oke," \u2014 "),uO=n(oke,"A",{href:!0});var wut=s(uO);JSo=r(wut,"SqueezeBertForMaskedLM"),wut.forEach(t),YSo=r(oke," (SqueezeBERT model)"),oke.forEach(t),KSo=i(U),z1=n(U,"LI",{});var rke=s(z1);Cge=n(rke,"STRONG",{});var Aut=s(Cge);ZSo=r(Aut,"tapas"),Aut.forEach(t),eRo=r(rke," \u2014 "),bO=n(rke,"A",{href:!0});var Lut=s(bO);oRo=r(Lut,"TapasForMaskedLM"),Lut.forEach(t),rRo=r(rke," (TAPAS model)"),rke.forEach(t),tRo=i(U),Q1=n(U,"LI",{});var tke=s(Q1);wge=n(tke,"STRONG",{});var yut=s(wge);aRo=r(yut,"wav2vec2"),yut.forEach(t),nRo=r(tke," \u2014 "),Age=n(tke,"CODE",{});var xut=s(Age);sRo=r(xut,"Wav2Vec2ForMaskedLM"),xut.forEach(t),lRo=r(tke," (Wav2Vec2 model)"),tke.forEach(t),iRo=i(U),W1=n(U,"LI",{});var ake=s(W1);Lge=n(ake,"STRONG",{});var $ut=s(Lge);dRo=r($ut,"xlm"),$ut.forEach(t),cRo=r(ake," \u2014 "),vO=n(ake,"A",{href:!0});var kut=s(vO);fRo=r(kut,"XLMWithLMHeadModel"),kut.forEach(t),mRo=r(ake," (XLM model)"),ake.forEach(t),gRo=i(U),H1=n(U,"LI",{});var nke=s(H1);yge=n(nke,"STRONG",{});var Sut=s(yge);hRo=r(Sut,"xlm-roberta"),Sut.forEach(t),pRo=r(nke," \u2014 "),FO=n(nke,"A",{href:!0});var Rut=s(FO);_Ro=r(Rut,"XLMRobertaForMaskedLM"),Rut.forEach(t),uRo=r(nke," (XLM-RoBERTa model)"),nke.forEach(t),bRo=i(U),U1=n(U,"LI",{});var ske=s(U1);xge=n(ske,"STRONG",{});var Put=s(xge);vRo=r(Put,"xlm-roberta-xl"),Put.forEach(t),FRo=r(ske," \u2014 "),TO=n(ske,"A",{href:!0});var But=s(TO);TRo=r(But,"XLMRobertaXLForMaskedLM"),But.forEach(t),MRo=r(ske," (XLM-RoBERTa-XL model)"),ske.forEach(t),ERo=i(U),J1=n(U,"LI",{});var lke=s(J1);$ge=n(lke,"STRONG",{});var Iut=s($ge);CRo=r(Iut,"yoso"),Iut.forEach(t),wRo=r(lke," \u2014 "),MO=n(lke,"A",{href:!0});var Nut=s(MO);ARo=r(Nut,"YosoForMaskedLM"),Nut.forEach(t),LRo=r(lke," (YOSO model)"),lke.forEach(t),U.forEach(t),yRo=i(la),Y1=n(la,"P",{});var ike=s(Y1);xRo=r(ike,"The model is set in evaluation mode by default using "),kge=n(ike,"CODE",{});var qut=s(kge);$Ro=r(qut,"model.eval()"),qut.forEach(t),kRo=r(ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=n(ike,"CODE",{});var jut=s(Sge);SRo=r(jut,"model.train()"),jut.forEach(t),ike.forEach(t),RRo=i(la),T(K1.$$.fragment,la),la.forEach(t),el.forEach(t),sOe=i(f),Wi=n(f,"H2",{class:!0});var mXe=s(Wi);Z1=n(mXe,"A",{id:!0,class:!0,href:!0});var Dut=s(Z1);Rge=n(Dut,"SPAN",{});var Gut=s(Rge);T(Ty.$$.fragment,Gut),Gut.forEach(t),Dut.forEach(t),PRo=i(mXe),Pge=n(mXe,"SPAN",{});var Out=s(Pge);BRo=r(Out,"AutoModelForSeq2SeqLM"),Out.forEach(t),mXe.forEach(t),lOe=i(f),Ro=n(f,"DIV",{class:!0});var ol=s(Ro);T(My.$$.fragment,ol),IRo=i(ol),Hi=n(ol,"P",{});var Loe=s(Hi);NRo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=n(Loe,"A",{href:!0});var Vut=s(EO);qRo=r(Vut,"from_pretrained()"),Vut.forEach(t),jRo=r(Loe," class method or the "),CO=n(Loe,"A",{href:!0});var Xut=s(CO);DRo=r(Xut,"from_config()"),Xut.forEach(t),GRo=r(Loe,` class
method.`),Loe.forEach(t),ORo=i(ol),Ey=n(ol,"P",{});var gXe=s(Ey);VRo=r(gXe,"This class cannot be instantiated directly using "),Bge=n(gXe,"CODE",{});var zut=s(Bge);XRo=r(zut,"__init__()"),zut.forEach(t),zRo=r(gXe," (throws an error)."),gXe.forEach(t),QRo=i(ol),dt=n(ol,"DIV",{class:!0});var jw=s(dt);T(Cy.$$.fragment,jw),WRo=i(jw),Ige=n(jw,"P",{});var Qut=s(Ige);HRo=r(Qut,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qut.forEach(t),URo=i(jw),Ui=n(jw,"P",{});var yoe=s(Ui);JRo=r(yoe,`Note:
Loading a model from its configuration file does `),Nge=n(yoe,"STRONG",{});var Wut=s(Nge);YRo=r(Wut,"not"),Wut.forEach(t),KRo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=n(yoe,"A",{href:!0});var Hut=s(wO);ZRo=r(Hut,"from_pretrained()"),Hut.forEach(t),ePo=r(yoe," to load the model weights."),yoe.forEach(t),oPo=i(jw),T(e2.$$.fragment,jw),jw.forEach(t),rPo=i(ol),eo=n(ol,"DIV",{class:!0});var ia=s(eo);T(wy.$$.fragment,ia),tPo=i(ia),qge=n(ia,"P",{});var Uut=s(qge);aPo=r(Uut,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Uut.forEach(t),nPo=i(ia),Na=n(ia,"P",{});var Dw=s(Na);sPo=r(Dw,"The model class to instantiate is selected based on the "),jge=n(Dw,"CODE",{});var Jut=s(jge);lPo=r(Jut,"model_type"),Jut.forEach(t),iPo=r(Dw,` property of the config object (either
passed as an argument or loaded from `),Dge=n(Dw,"CODE",{});var Yut=s(Dge);dPo=r(Yut,"pretrained_model_name_or_path"),Yut.forEach(t),cPo=r(Dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=n(Dw,"CODE",{});var Kut=s(Gge);fPo=r(Kut,"pretrained_model_name_or_path"),Kut.forEach(t),mPo=r(Dw,":"),Dw.forEach(t),gPo=i(ia),pe=n(ia,"UL",{});var be=s(pe);o2=n(be,"LI",{});var dke=s(o2);Oge=n(dke,"STRONG",{});var Zut=s(Oge);hPo=r(Zut,"bart"),Zut.forEach(t),pPo=r(dke," \u2014 "),AO=n(dke,"A",{href:!0});var e7t=s(AO);_Po=r(e7t,"BartForConditionalGeneration"),e7t.forEach(t),uPo=r(dke," (BART model)"),dke.forEach(t),bPo=i(be),r2=n(be,"LI",{});var cke=s(r2);Vge=n(cke,"STRONG",{});var o7t=s(Vge);vPo=r(o7t,"bigbird_pegasus"),o7t.forEach(t),FPo=r(cke," \u2014 "),LO=n(cke,"A",{href:!0});var r7t=s(LO);TPo=r(r7t,"BigBirdPegasusForConditionalGeneration"),r7t.forEach(t),MPo=r(cke," (BigBird-Pegasus model)"),cke.forEach(t),EPo=i(be),t2=n(be,"LI",{});var fke=s(t2);Xge=n(fke,"STRONG",{});var t7t=s(Xge);CPo=r(t7t,"blenderbot"),t7t.forEach(t),wPo=r(fke," \u2014 "),yO=n(fke,"A",{href:!0});var a7t=s(yO);APo=r(a7t,"BlenderbotForConditionalGeneration"),a7t.forEach(t),LPo=r(fke," (Blenderbot model)"),fke.forEach(t),yPo=i(be),a2=n(be,"LI",{});var mke=s(a2);zge=n(mke,"STRONG",{});var n7t=s(zge);xPo=r(n7t,"blenderbot-small"),n7t.forEach(t),$Po=r(mke," \u2014 "),xO=n(mke,"A",{href:!0});var s7t=s(xO);kPo=r(s7t,"BlenderbotSmallForConditionalGeneration"),s7t.forEach(t),SPo=r(mke," (BlenderbotSmall model)"),mke.forEach(t),RPo=i(be),n2=n(be,"LI",{});var gke=s(n2);Qge=n(gke,"STRONG",{});var l7t=s(Qge);PPo=r(l7t,"encoder-decoder"),l7t.forEach(t),BPo=r(gke," \u2014 "),$O=n(gke,"A",{href:!0});var i7t=s($O);IPo=r(i7t,"EncoderDecoderModel"),i7t.forEach(t),NPo=r(gke," (Encoder decoder model)"),gke.forEach(t),qPo=i(be),s2=n(be,"LI",{});var hke=s(s2);Wge=n(hke,"STRONG",{});var d7t=s(Wge);jPo=r(d7t,"fsmt"),d7t.forEach(t),DPo=r(hke," \u2014 "),kO=n(hke,"A",{href:!0});var c7t=s(kO);GPo=r(c7t,"FSMTForConditionalGeneration"),c7t.forEach(t),OPo=r(hke," (FairSeq Machine-Translation model)"),hke.forEach(t),VPo=i(be),l2=n(be,"LI",{});var pke=s(l2);Hge=n(pke,"STRONG",{});var f7t=s(Hge);XPo=r(f7t,"led"),f7t.forEach(t),zPo=r(pke," \u2014 "),SO=n(pke,"A",{href:!0});var m7t=s(SO);QPo=r(m7t,"LEDForConditionalGeneration"),m7t.forEach(t),WPo=r(pke," (LED model)"),pke.forEach(t),HPo=i(be),i2=n(be,"LI",{});var _ke=s(i2);Uge=n(_ke,"STRONG",{});var g7t=s(Uge);UPo=r(g7t,"longt5"),g7t.forEach(t),JPo=r(_ke," \u2014 "),RO=n(_ke,"A",{href:!0});var h7t=s(RO);YPo=r(h7t,"LongT5ForConditionalGeneration"),h7t.forEach(t),KPo=r(_ke," (LongT5 model)"),_ke.forEach(t),ZPo=i(be),d2=n(be,"LI",{});var uke=s(d2);Jge=n(uke,"STRONG",{});var p7t=s(Jge);eBo=r(p7t,"m2m_100"),p7t.forEach(t),oBo=r(uke," \u2014 "),PO=n(uke,"A",{href:!0});var _7t=s(PO);rBo=r(_7t,"M2M100ForConditionalGeneration"),_7t.forEach(t),tBo=r(uke," (M2M100 model)"),uke.forEach(t),aBo=i(be),c2=n(be,"LI",{});var bke=s(c2);Yge=n(bke,"STRONG",{});var u7t=s(Yge);nBo=r(u7t,"marian"),u7t.forEach(t),sBo=r(bke," \u2014 "),BO=n(bke,"A",{href:!0});var b7t=s(BO);lBo=r(b7t,"MarianMTModel"),b7t.forEach(t),iBo=r(bke," (Marian model)"),bke.forEach(t),dBo=i(be),f2=n(be,"LI",{});var vke=s(f2);Kge=n(vke,"STRONG",{});var v7t=s(Kge);cBo=r(v7t,"mbart"),v7t.forEach(t),fBo=r(vke," \u2014 "),IO=n(vke,"A",{href:!0});var F7t=s(IO);mBo=r(F7t,"MBartForConditionalGeneration"),F7t.forEach(t),gBo=r(vke," (mBART model)"),vke.forEach(t),hBo=i(be),m2=n(be,"LI",{});var Fke=s(m2);Zge=n(Fke,"STRONG",{});var T7t=s(Zge);pBo=r(T7t,"mt5"),T7t.forEach(t),_Bo=r(Fke," \u2014 "),NO=n(Fke,"A",{href:!0});var M7t=s(NO);uBo=r(M7t,"MT5ForConditionalGeneration"),M7t.forEach(t),bBo=r(Fke," (MT5 model)"),Fke.forEach(t),vBo=i(be),g2=n(be,"LI",{});var Tke=s(g2);ehe=n(Tke,"STRONG",{});var E7t=s(ehe);FBo=r(E7t,"pegasus"),E7t.forEach(t),TBo=r(Tke," \u2014 "),qO=n(Tke,"A",{href:!0});var C7t=s(qO);MBo=r(C7t,"PegasusForConditionalGeneration"),C7t.forEach(t),EBo=r(Tke," (Pegasus model)"),Tke.forEach(t),CBo=i(be),h2=n(be,"LI",{});var Mke=s(h2);ohe=n(Mke,"STRONG",{});var w7t=s(ohe);wBo=r(w7t,"plbart"),w7t.forEach(t),ABo=r(Mke," \u2014 "),jO=n(Mke,"A",{href:!0});var A7t=s(jO);LBo=r(A7t,"PLBartForConditionalGeneration"),A7t.forEach(t),yBo=r(Mke," (PLBart model)"),Mke.forEach(t),xBo=i(be),p2=n(be,"LI",{});var Eke=s(p2);rhe=n(Eke,"STRONG",{});var L7t=s(rhe);$Bo=r(L7t,"prophetnet"),L7t.forEach(t),kBo=r(Eke," \u2014 "),DO=n(Eke,"A",{href:!0});var y7t=s(DO);SBo=r(y7t,"ProphetNetForConditionalGeneration"),y7t.forEach(t),RBo=r(Eke," (ProphetNet model)"),Eke.forEach(t),PBo=i(be),_2=n(be,"LI",{});var Cke=s(_2);the=n(Cke,"STRONG",{});var x7t=s(the);BBo=r(x7t,"t5"),x7t.forEach(t),IBo=r(Cke," \u2014 "),GO=n(Cke,"A",{href:!0});var $7t=s(GO);NBo=r($7t,"T5ForConditionalGeneration"),$7t.forEach(t),qBo=r(Cke," (T5 model)"),Cke.forEach(t),jBo=i(be),u2=n(be,"LI",{});var wke=s(u2);ahe=n(wke,"STRONG",{});var k7t=s(ahe);DBo=r(k7t,"xlm-prophetnet"),k7t.forEach(t),GBo=r(wke," \u2014 "),OO=n(wke,"A",{href:!0});var S7t=s(OO);OBo=r(S7t,"XLMProphetNetForConditionalGeneration"),S7t.forEach(t),VBo=r(wke," (XLM-ProphetNet model)"),wke.forEach(t),be.forEach(t),XBo=i(ia),b2=n(ia,"P",{});var Ake=s(b2);zBo=r(Ake,"The model is set in evaluation mode by default using "),nhe=n(Ake,"CODE",{});var R7t=s(nhe);QBo=r(R7t,"model.eval()"),R7t.forEach(t),WBo=r(Ake,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=n(Ake,"CODE",{});var P7t=s(she);HBo=r(P7t,"model.train()"),P7t.forEach(t),Ake.forEach(t),UBo=i(ia),T(v2.$$.fragment,ia),ia.forEach(t),ol.forEach(t),iOe=i(f),Ji=n(f,"H2",{class:!0});var hXe=s(Ji);F2=n(hXe,"A",{id:!0,class:!0,href:!0});var B7t=s(F2);lhe=n(B7t,"SPAN",{});var I7t=s(lhe);T(Ay.$$.fragment,I7t),I7t.forEach(t),B7t.forEach(t),JBo=i(hXe),ihe=n(hXe,"SPAN",{});var N7t=s(ihe);YBo=r(N7t,"AutoModelForSequenceClassification"),N7t.forEach(t),hXe.forEach(t),dOe=i(f),Po=n(f,"DIV",{class:!0});var rl=s(Po);T(Ly.$$.fragment,rl),KBo=i(rl),Yi=n(rl,"P",{});var xoe=s(Yi);ZBo=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=n(xoe,"A",{href:!0});var q7t=s(VO);eIo=r(q7t,"from_pretrained()"),q7t.forEach(t),oIo=r(xoe," class method or the "),XO=n(xoe,"A",{href:!0});var j7t=s(XO);rIo=r(j7t,"from_config()"),j7t.forEach(t),tIo=r(xoe,` class
method.`),xoe.forEach(t),aIo=i(rl),yy=n(rl,"P",{});var pXe=s(yy);nIo=r(pXe,"This class cannot be instantiated directly using "),dhe=n(pXe,"CODE",{});var D7t=s(dhe);sIo=r(D7t,"__init__()"),D7t.forEach(t),lIo=r(pXe," (throws an error)."),pXe.forEach(t),iIo=i(rl),ct=n(rl,"DIV",{class:!0});var Gw=s(ct);T(xy.$$.fragment,Gw),dIo=i(Gw),che=n(Gw,"P",{});var G7t=s(che);cIo=r(G7t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),G7t.forEach(t),fIo=i(Gw),Ki=n(Gw,"P",{});var $oe=s(Ki);mIo=r($oe,`Note:
Loading a model from its configuration file does `),fhe=n($oe,"STRONG",{});var O7t=s(fhe);gIo=r(O7t,"not"),O7t.forEach(t),hIo=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=n($oe,"A",{href:!0});var V7t=s(zO);pIo=r(V7t,"from_pretrained()"),V7t.forEach(t),_Io=r($oe," to load the model weights."),$oe.forEach(t),uIo=i(Gw),T(T2.$$.fragment,Gw),Gw.forEach(t),bIo=i(rl),oo=n(rl,"DIV",{class:!0});var da=s(oo);T($y.$$.fragment,da),vIo=i(da),mhe=n(da,"P",{});var X7t=s(mhe);FIo=r(X7t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),X7t.forEach(t),TIo=i(da),qa=n(da,"P",{});var Ow=s(qa);MIo=r(Ow,"The model class to instantiate is selected based on the "),ghe=n(Ow,"CODE",{});var z7t=s(ghe);EIo=r(z7t,"model_type"),z7t.forEach(t),CIo=r(Ow,` property of the config object (either
passed as an argument or loaded from `),hhe=n(Ow,"CODE",{});var Q7t=s(hhe);wIo=r(Q7t,"pretrained_model_name_or_path"),Q7t.forEach(t),AIo=r(Ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=n(Ow,"CODE",{});var W7t=s(phe);LIo=r(W7t,"pretrained_model_name_or_path"),W7t.forEach(t),yIo=r(Ow,":"),Ow.forEach(t),xIo=i(da),N=n(da,"UL",{});var q=s(N);M2=n(q,"LI",{});var Lke=s(M2);_he=n(Lke,"STRONG",{});var H7t=s(_he);$Io=r(H7t,"albert"),H7t.forEach(t),kIo=r(Lke," \u2014 "),QO=n(Lke,"A",{href:!0});var U7t=s(QO);SIo=r(U7t,"AlbertForSequenceClassification"),U7t.forEach(t),RIo=r(Lke," (ALBERT model)"),Lke.forEach(t),PIo=i(q),E2=n(q,"LI",{});var yke=s(E2);uhe=n(yke,"STRONG",{});var J7t=s(uhe);BIo=r(J7t,"bart"),J7t.forEach(t),IIo=r(yke," \u2014 "),WO=n(yke,"A",{href:!0});var Y7t=s(WO);NIo=r(Y7t,"BartForSequenceClassification"),Y7t.forEach(t),qIo=r(yke," (BART model)"),yke.forEach(t),jIo=i(q),C2=n(q,"LI",{});var xke=s(C2);bhe=n(xke,"STRONG",{});var K7t=s(bhe);DIo=r(K7t,"bert"),K7t.forEach(t),GIo=r(xke," \u2014 "),HO=n(xke,"A",{href:!0});var Z7t=s(HO);OIo=r(Z7t,"BertForSequenceClassification"),Z7t.forEach(t),VIo=r(xke," (BERT model)"),xke.forEach(t),XIo=i(q),w2=n(q,"LI",{});var $ke=s(w2);vhe=n($ke,"STRONG",{});var e1t=s(vhe);zIo=r(e1t,"big_bird"),e1t.forEach(t),QIo=r($ke," \u2014 "),UO=n($ke,"A",{href:!0});var o1t=s(UO);WIo=r(o1t,"BigBirdForSequenceClassification"),o1t.forEach(t),HIo=r($ke," (BigBird model)"),$ke.forEach(t),UIo=i(q),A2=n(q,"LI",{});var kke=s(A2);Fhe=n(kke,"STRONG",{});var r1t=s(Fhe);JIo=r(r1t,"bigbird_pegasus"),r1t.forEach(t),YIo=r(kke," \u2014 "),JO=n(kke,"A",{href:!0});var t1t=s(JO);KIo=r(t1t,"BigBirdPegasusForSequenceClassification"),t1t.forEach(t),ZIo=r(kke," (BigBird-Pegasus model)"),kke.forEach(t),eNo=i(q),L2=n(q,"LI",{});var Ske=s(L2);The=n(Ske,"STRONG",{});var a1t=s(The);oNo=r(a1t,"bloom"),a1t.forEach(t),rNo=r(Ske," \u2014 "),YO=n(Ske,"A",{href:!0});var n1t=s(YO);tNo=r(n1t,"BloomForSequenceClassification"),n1t.forEach(t),aNo=r(Ske," (BLOOM model)"),Ske.forEach(t),nNo=i(q),y2=n(q,"LI",{});var Rke=s(y2);Mhe=n(Rke,"STRONG",{});var s1t=s(Mhe);sNo=r(s1t,"camembert"),s1t.forEach(t),lNo=r(Rke," \u2014 "),KO=n(Rke,"A",{href:!0});var l1t=s(KO);iNo=r(l1t,"CamembertForSequenceClassification"),l1t.forEach(t),dNo=r(Rke," (CamemBERT model)"),Rke.forEach(t),cNo=i(q),x2=n(q,"LI",{});var Pke=s(x2);Ehe=n(Pke,"STRONG",{});var i1t=s(Ehe);fNo=r(i1t,"canine"),i1t.forEach(t),mNo=r(Pke," \u2014 "),ZO=n(Pke,"A",{href:!0});var d1t=s(ZO);gNo=r(d1t,"CanineForSequenceClassification"),d1t.forEach(t),hNo=r(Pke," (CANINE model)"),Pke.forEach(t),pNo=i(q),$2=n(q,"LI",{});var Bke=s($2);Che=n(Bke,"STRONG",{});var c1t=s(Che);_No=r(c1t,"convbert"),c1t.forEach(t),uNo=r(Bke," \u2014 "),eV=n(Bke,"A",{href:!0});var f1t=s(eV);bNo=r(f1t,"ConvBertForSequenceClassification"),f1t.forEach(t),vNo=r(Bke," (ConvBERT model)"),Bke.forEach(t),FNo=i(q),k2=n(q,"LI",{});var Ike=s(k2);whe=n(Ike,"STRONG",{});var m1t=s(whe);TNo=r(m1t,"ctrl"),m1t.forEach(t),MNo=r(Ike," \u2014 "),oV=n(Ike,"A",{href:!0});var g1t=s(oV);ENo=r(g1t,"CTRLForSequenceClassification"),g1t.forEach(t),CNo=r(Ike," (CTRL model)"),Ike.forEach(t),wNo=i(q),S2=n(q,"LI",{});var Nke=s(S2);Ahe=n(Nke,"STRONG",{});var h1t=s(Ahe);ANo=r(h1t,"data2vec-text"),h1t.forEach(t),LNo=r(Nke," \u2014 "),rV=n(Nke,"A",{href:!0});var p1t=s(rV);yNo=r(p1t,"Data2VecTextForSequenceClassification"),p1t.forEach(t),xNo=r(Nke," (Data2VecText model)"),Nke.forEach(t),$No=i(q),R2=n(q,"LI",{});var qke=s(R2);Lhe=n(qke,"STRONG",{});var _1t=s(Lhe);kNo=r(_1t,"deberta"),_1t.forEach(t),SNo=r(qke," \u2014 "),tV=n(qke,"A",{href:!0});var u1t=s(tV);RNo=r(u1t,"DebertaForSequenceClassification"),u1t.forEach(t),PNo=r(qke," (DeBERTa model)"),qke.forEach(t),BNo=i(q),P2=n(q,"LI",{});var jke=s(P2);yhe=n(jke,"STRONG",{});var b1t=s(yhe);INo=r(b1t,"deberta-v2"),b1t.forEach(t),NNo=r(jke," \u2014 "),aV=n(jke,"A",{href:!0});var v1t=s(aV);qNo=r(v1t,"DebertaV2ForSequenceClassification"),v1t.forEach(t),jNo=r(jke," (DeBERTa-v2 model)"),jke.forEach(t),DNo=i(q),B2=n(q,"LI",{});var Dke=s(B2);xhe=n(Dke,"STRONG",{});var F1t=s(xhe);GNo=r(F1t,"distilbert"),F1t.forEach(t),ONo=r(Dke," \u2014 "),nV=n(Dke,"A",{href:!0});var T1t=s(nV);VNo=r(T1t,"DistilBertForSequenceClassification"),T1t.forEach(t),XNo=r(Dke," (DistilBERT model)"),Dke.forEach(t),zNo=i(q),I2=n(q,"LI",{});var Gke=s(I2);$he=n(Gke,"STRONG",{});var M1t=s($he);QNo=r(M1t,"electra"),M1t.forEach(t),WNo=r(Gke," \u2014 "),sV=n(Gke,"A",{href:!0});var E1t=s(sV);HNo=r(E1t,"ElectraForSequenceClassification"),E1t.forEach(t),UNo=r(Gke," (ELECTRA model)"),Gke.forEach(t),JNo=i(q),N2=n(q,"LI",{});var Oke=s(N2);khe=n(Oke,"STRONG",{});var C1t=s(khe);YNo=r(C1t,"flaubert"),C1t.forEach(t),KNo=r(Oke," \u2014 "),lV=n(Oke,"A",{href:!0});var w1t=s(lV);ZNo=r(w1t,"FlaubertForSequenceClassification"),w1t.forEach(t),eqo=r(Oke," (FlauBERT model)"),Oke.forEach(t),oqo=i(q),q2=n(q,"LI",{});var Vke=s(q2);She=n(Vke,"STRONG",{});var A1t=s(She);rqo=r(A1t,"fnet"),A1t.forEach(t),tqo=r(Vke," \u2014 "),iV=n(Vke,"A",{href:!0});var L1t=s(iV);aqo=r(L1t,"FNetForSequenceClassification"),L1t.forEach(t),nqo=r(Vke," (FNet model)"),Vke.forEach(t),sqo=i(q),j2=n(q,"LI",{});var Xke=s(j2);Rhe=n(Xke,"STRONG",{});var y1t=s(Rhe);lqo=r(y1t,"funnel"),y1t.forEach(t),iqo=r(Xke," \u2014 "),dV=n(Xke,"A",{href:!0});var x1t=s(dV);dqo=r(x1t,"FunnelForSequenceClassification"),x1t.forEach(t),cqo=r(Xke," (Funnel Transformer model)"),Xke.forEach(t),fqo=i(q),D2=n(q,"LI",{});var zke=s(D2);Phe=n(zke,"STRONG",{});var $1t=s(Phe);mqo=r($1t,"gpt2"),$1t.forEach(t),gqo=r(zke," \u2014 "),cV=n(zke,"A",{href:!0});var k1t=s(cV);hqo=r(k1t,"GPT2ForSequenceClassification"),k1t.forEach(t),pqo=r(zke," (OpenAI GPT-2 model)"),zke.forEach(t),_qo=i(q),G2=n(q,"LI",{});var Qke=s(G2);Bhe=n(Qke,"STRONG",{});var S1t=s(Bhe);uqo=r(S1t,"gpt_neo"),S1t.forEach(t),bqo=r(Qke," \u2014 "),fV=n(Qke,"A",{href:!0});var R1t=s(fV);vqo=r(R1t,"GPTNeoForSequenceClassification"),R1t.forEach(t),Fqo=r(Qke," (GPT Neo model)"),Qke.forEach(t),Tqo=i(q),O2=n(q,"LI",{});var Wke=s(O2);Ihe=n(Wke,"STRONG",{});var P1t=s(Ihe);Mqo=r(P1t,"gptj"),P1t.forEach(t),Eqo=r(Wke," \u2014 "),mV=n(Wke,"A",{href:!0});var B1t=s(mV);Cqo=r(B1t,"GPTJForSequenceClassification"),B1t.forEach(t),wqo=r(Wke," (GPT-J model)"),Wke.forEach(t),Aqo=i(q),V2=n(q,"LI",{});var Hke=s(V2);Nhe=n(Hke,"STRONG",{});var I1t=s(Nhe);Lqo=r(I1t,"ibert"),I1t.forEach(t),yqo=r(Hke," \u2014 "),gV=n(Hke,"A",{href:!0});var N1t=s(gV);xqo=r(N1t,"IBertForSequenceClassification"),N1t.forEach(t),$qo=r(Hke," (I-BERT model)"),Hke.forEach(t),kqo=i(q),X2=n(q,"LI",{});var Uke=s(X2);qhe=n(Uke,"STRONG",{});var q1t=s(qhe);Sqo=r(q1t,"layoutlm"),q1t.forEach(t),Rqo=r(Uke," \u2014 "),hV=n(Uke,"A",{href:!0});var j1t=s(hV);Pqo=r(j1t,"LayoutLMForSequenceClassification"),j1t.forEach(t),Bqo=r(Uke," (LayoutLM model)"),Uke.forEach(t),Iqo=i(q),z2=n(q,"LI",{});var Jke=s(z2);jhe=n(Jke,"STRONG",{});var D1t=s(jhe);Nqo=r(D1t,"layoutlmv2"),D1t.forEach(t),qqo=r(Jke," \u2014 "),pV=n(Jke,"A",{href:!0});var G1t=s(pV);jqo=r(G1t,"LayoutLMv2ForSequenceClassification"),G1t.forEach(t),Dqo=r(Jke," (LayoutLMv2 model)"),Jke.forEach(t),Gqo=i(q),Q2=n(q,"LI",{});var Yke=s(Q2);Dhe=n(Yke,"STRONG",{});var O1t=s(Dhe);Oqo=r(O1t,"layoutlmv3"),O1t.forEach(t),Vqo=r(Yke," \u2014 "),_V=n(Yke,"A",{href:!0});var V1t=s(_V);Xqo=r(V1t,"LayoutLMv3ForSequenceClassification"),V1t.forEach(t),zqo=r(Yke," (LayoutLMv3 model)"),Yke.forEach(t),Qqo=i(q),W2=n(q,"LI",{});var Kke=s(W2);Ghe=n(Kke,"STRONG",{});var X1t=s(Ghe);Wqo=r(X1t,"led"),X1t.forEach(t),Hqo=r(Kke," \u2014 "),uV=n(Kke,"A",{href:!0});var z1t=s(uV);Uqo=r(z1t,"LEDForSequenceClassification"),z1t.forEach(t),Jqo=r(Kke," (LED model)"),Kke.forEach(t),Yqo=i(q),H2=n(q,"LI",{});var Zke=s(H2);Ohe=n(Zke,"STRONG",{});var Q1t=s(Ohe);Kqo=r(Q1t,"longformer"),Q1t.forEach(t),Zqo=r(Zke," \u2014 "),bV=n(Zke,"A",{href:!0});var W1t=s(bV);ejo=r(W1t,"LongformerForSequenceClassification"),W1t.forEach(t),ojo=r(Zke," (Longformer model)"),Zke.forEach(t),rjo=i(q),U2=n(q,"LI",{});var eSe=s(U2);Vhe=n(eSe,"STRONG",{});var H1t=s(Vhe);tjo=r(H1t,"mbart"),H1t.forEach(t),ajo=r(eSe," \u2014 "),vV=n(eSe,"A",{href:!0});var U1t=s(vV);njo=r(U1t,"MBartForSequenceClassification"),U1t.forEach(t),sjo=r(eSe," (mBART model)"),eSe.forEach(t),ljo=i(q),J2=n(q,"LI",{});var oSe=s(J2);Xhe=n(oSe,"STRONG",{});var J1t=s(Xhe);ijo=r(J1t,"megatron-bert"),J1t.forEach(t),djo=r(oSe," \u2014 "),FV=n(oSe,"A",{href:!0});var Y1t=s(FV);cjo=r(Y1t,"MegatronBertForSequenceClassification"),Y1t.forEach(t),fjo=r(oSe," (Megatron-BERT model)"),oSe.forEach(t),mjo=i(q),Y2=n(q,"LI",{});var rSe=s(Y2);zhe=n(rSe,"STRONG",{});var K1t=s(zhe);gjo=r(K1t,"mobilebert"),K1t.forEach(t),hjo=r(rSe," \u2014 "),TV=n(rSe,"A",{href:!0});var Z1t=s(TV);pjo=r(Z1t,"MobileBertForSequenceClassification"),Z1t.forEach(t),_jo=r(rSe," (MobileBERT model)"),rSe.forEach(t),ujo=i(q),K2=n(q,"LI",{});var tSe=s(K2);Qhe=n(tSe,"STRONG",{});var e2t=s(Qhe);bjo=r(e2t,"mpnet"),e2t.forEach(t),vjo=r(tSe," \u2014 "),MV=n(tSe,"A",{href:!0});var o2t=s(MV);Fjo=r(o2t,"MPNetForSequenceClassification"),o2t.forEach(t),Tjo=r(tSe," (MPNet model)"),tSe.forEach(t),Mjo=i(q),Z2=n(q,"LI",{});var aSe=s(Z2);Whe=n(aSe,"STRONG",{});var r2t=s(Whe);Ejo=r(r2t,"nezha"),r2t.forEach(t),Cjo=r(aSe," \u2014 "),EV=n(aSe,"A",{href:!0});var t2t=s(EV);wjo=r(t2t,"NezhaForSequenceClassification"),t2t.forEach(t),Ajo=r(aSe," (Nezha model)"),aSe.forEach(t),Ljo=i(q),eb=n(q,"LI",{});var nSe=s(eb);Hhe=n(nSe,"STRONG",{});var a2t=s(Hhe);yjo=r(a2t,"nystromformer"),a2t.forEach(t),xjo=r(nSe," \u2014 "),CV=n(nSe,"A",{href:!0});var n2t=s(CV);$jo=r(n2t,"NystromformerForSequenceClassification"),n2t.forEach(t),kjo=r(nSe," (Nystr\xF6mformer model)"),nSe.forEach(t),Sjo=i(q),ob=n(q,"LI",{});var sSe=s(ob);Uhe=n(sSe,"STRONG",{});var s2t=s(Uhe);Rjo=r(s2t,"openai-gpt"),s2t.forEach(t),Pjo=r(sSe," \u2014 "),wV=n(sSe,"A",{href:!0});var l2t=s(wV);Bjo=r(l2t,"OpenAIGPTForSequenceClassification"),l2t.forEach(t),Ijo=r(sSe," (OpenAI GPT model)"),sSe.forEach(t),Njo=i(q),rb=n(q,"LI",{});var lSe=s(rb);Jhe=n(lSe,"STRONG",{});var i2t=s(Jhe);qjo=r(i2t,"perceiver"),i2t.forEach(t),jjo=r(lSe," \u2014 "),AV=n(lSe,"A",{href:!0});var d2t=s(AV);Djo=r(d2t,"PerceiverForSequenceClassification"),d2t.forEach(t),Gjo=r(lSe," (Perceiver model)"),lSe.forEach(t),Ojo=i(q),tb=n(q,"LI",{});var iSe=s(tb);Yhe=n(iSe,"STRONG",{});var c2t=s(Yhe);Vjo=r(c2t,"plbart"),c2t.forEach(t),Xjo=r(iSe," \u2014 "),LV=n(iSe,"A",{href:!0});var f2t=s(LV);zjo=r(f2t,"PLBartForSequenceClassification"),f2t.forEach(t),Qjo=r(iSe," (PLBart model)"),iSe.forEach(t),Wjo=i(q),ab=n(q,"LI",{});var dSe=s(ab);Khe=n(dSe,"STRONG",{});var m2t=s(Khe);Hjo=r(m2t,"qdqbert"),m2t.forEach(t),Ujo=r(dSe," \u2014 "),yV=n(dSe,"A",{href:!0});var g2t=s(yV);Jjo=r(g2t,"QDQBertForSequenceClassification"),g2t.forEach(t),Yjo=r(dSe," (QDQBert model)"),dSe.forEach(t),Kjo=i(q),nb=n(q,"LI",{});var cSe=s(nb);Zhe=n(cSe,"STRONG",{});var h2t=s(Zhe);Zjo=r(h2t,"reformer"),h2t.forEach(t),eDo=r(cSe," \u2014 "),xV=n(cSe,"A",{href:!0});var p2t=s(xV);oDo=r(p2t,"ReformerForSequenceClassification"),p2t.forEach(t),rDo=r(cSe," (Reformer model)"),cSe.forEach(t),tDo=i(q),sb=n(q,"LI",{});var fSe=s(sb);epe=n(fSe,"STRONG",{});var _2t=s(epe);aDo=r(_2t,"rembert"),_2t.forEach(t),nDo=r(fSe," \u2014 "),$V=n(fSe,"A",{href:!0});var u2t=s($V);sDo=r(u2t,"RemBertForSequenceClassification"),u2t.forEach(t),lDo=r(fSe," (RemBERT model)"),fSe.forEach(t),iDo=i(q),lb=n(q,"LI",{});var mSe=s(lb);ope=n(mSe,"STRONG",{});var b2t=s(ope);dDo=r(b2t,"roberta"),b2t.forEach(t),cDo=r(mSe," \u2014 "),kV=n(mSe,"A",{href:!0});var v2t=s(kV);fDo=r(v2t,"RobertaForSequenceClassification"),v2t.forEach(t),mDo=r(mSe," (RoBERTa model)"),mSe.forEach(t),gDo=i(q),ib=n(q,"LI",{});var gSe=s(ib);rpe=n(gSe,"STRONG",{});var F2t=s(rpe);hDo=r(F2t,"roformer"),F2t.forEach(t),pDo=r(gSe," \u2014 "),SV=n(gSe,"A",{href:!0});var T2t=s(SV);_Do=r(T2t,"RoFormerForSequenceClassification"),T2t.forEach(t),uDo=r(gSe," (RoFormer model)"),gSe.forEach(t),bDo=i(q),db=n(q,"LI",{});var hSe=s(db);tpe=n(hSe,"STRONG",{});var M2t=s(tpe);vDo=r(M2t,"squeezebert"),M2t.forEach(t),FDo=r(hSe," \u2014 "),RV=n(hSe,"A",{href:!0});var E2t=s(RV);TDo=r(E2t,"SqueezeBertForSequenceClassification"),E2t.forEach(t),MDo=r(hSe," (SqueezeBERT model)"),hSe.forEach(t),EDo=i(q),cb=n(q,"LI",{});var pSe=s(cb);ape=n(pSe,"STRONG",{});var C2t=s(ape);CDo=r(C2t,"tapas"),C2t.forEach(t),wDo=r(pSe," \u2014 "),PV=n(pSe,"A",{href:!0});var w2t=s(PV);ADo=r(w2t,"TapasForSequenceClassification"),w2t.forEach(t),LDo=r(pSe," (TAPAS model)"),pSe.forEach(t),yDo=i(q),fb=n(q,"LI",{});var _Se=s(fb);npe=n(_Se,"STRONG",{});var A2t=s(npe);xDo=r(A2t,"transfo-xl"),A2t.forEach(t),$Do=r(_Se," \u2014 "),BV=n(_Se,"A",{href:!0});var L2t=s(BV);kDo=r(L2t,"TransfoXLForSequenceClassification"),L2t.forEach(t),SDo=r(_Se," (Transformer-XL model)"),_Se.forEach(t),RDo=i(q),mb=n(q,"LI",{});var uSe=s(mb);spe=n(uSe,"STRONG",{});var y2t=s(spe);PDo=r(y2t,"xlm"),y2t.forEach(t),BDo=r(uSe," \u2014 "),IV=n(uSe,"A",{href:!0});var x2t=s(IV);IDo=r(x2t,"XLMForSequenceClassification"),x2t.forEach(t),NDo=r(uSe," (XLM model)"),uSe.forEach(t),qDo=i(q),gb=n(q,"LI",{});var bSe=s(gb);lpe=n(bSe,"STRONG",{});var $2t=s(lpe);jDo=r($2t,"xlm-roberta"),$2t.forEach(t),DDo=r(bSe," \u2014 "),NV=n(bSe,"A",{href:!0});var k2t=s(NV);GDo=r(k2t,"XLMRobertaForSequenceClassification"),k2t.forEach(t),ODo=r(bSe," (XLM-RoBERTa model)"),bSe.forEach(t),VDo=i(q),hb=n(q,"LI",{});var vSe=s(hb);ipe=n(vSe,"STRONG",{});var S2t=s(ipe);XDo=r(S2t,"xlm-roberta-xl"),S2t.forEach(t),zDo=r(vSe," \u2014 "),qV=n(vSe,"A",{href:!0});var R2t=s(qV);QDo=r(R2t,"XLMRobertaXLForSequenceClassification"),R2t.forEach(t),WDo=r(vSe," (XLM-RoBERTa-XL model)"),vSe.forEach(t),HDo=i(q),pb=n(q,"LI",{});var FSe=s(pb);dpe=n(FSe,"STRONG",{});var P2t=s(dpe);UDo=r(P2t,"xlnet"),P2t.forEach(t),JDo=r(FSe," \u2014 "),jV=n(FSe,"A",{href:!0});var B2t=s(jV);YDo=r(B2t,"XLNetForSequenceClassification"),B2t.forEach(t),KDo=r(FSe," (XLNet model)"),FSe.forEach(t),ZDo=i(q),_b=n(q,"LI",{});var TSe=s(_b);cpe=n(TSe,"STRONG",{});var I2t=s(cpe);eGo=r(I2t,"yoso"),I2t.forEach(t),oGo=r(TSe," \u2014 "),DV=n(TSe,"A",{href:!0});var N2t=s(DV);rGo=r(N2t,"YosoForSequenceClassification"),N2t.forEach(t),tGo=r(TSe," (YOSO model)"),TSe.forEach(t),q.forEach(t),aGo=i(da),ub=n(da,"P",{});var MSe=s(ub);nGo=r(MSe,"The model is set in evaluation mode by default using "),fpe=n(MSe,"CODE",{});var q2t=s(fpe);sGo=r(q2t,"model.eval()"),q2t.forEach(t),lGo=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=n(MSe,"CODE",{});var j2t=s(mpe);iGo=r(j2t,"model.train()"),j2t.forEach(t),MSe.forEach(t),dGo=i(da),T(bb.$$.fragment,da),da.forEach(t),rl.forEach(t),cOe=i(f),Zi=n(f,"H2",{class:!0});var _Xe=s(Zi);vb=n(_Xe,"A",{id:!0,class:!0,href:!0});var D2t=s(vb);gpe=n(D2t,"SPAN",{});var G2t=s(gpe);T(ky.$$.fragment,G2t),G2t.forEach(t),D2t.forEach(t),cGo=i(_Xe),hpe=n(_Xe,"SPAN",{});var O2t=s(hpe);fGo=r(O2t,"AutoModelForMultipleChoice"),O2t.forEach(t),_Xe.forEach(t),fOe=i(f),Bo=n(f,"DIV",{class:!0});var tl=s(Bo);T(Sy.$$.fragment,tl),mGo=i(tl),ed=n(tl,"P",{});var koe=s(ed);gGo=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=n(koe,"A",{href:!0});var V2t=s(GV);hGo=r(V2t,"from_pretrained()"),V2t.forEach(t),pGo=r(koe," class method or the "),OV=n(koe,"A",{href:!0});var X2t=s(OV);_Go=r(X2t,"from_config()"),X2t.forEach(t),uGo=r(koe,` class
method.`),koe.forEach(t),bGo=i(tl),Ry=n(tl,"P",{});var uXe=s(Ry);vGo=r(uXe,"This class cannot be instantiated directly using "),ppe=n(uXe,"CODE",{});var z2t=s(ppe);FGo=r(z2t,"__init__()"),z2t.forEach(t),TGo=r(uXe," (throws an error)."),uXe.forEach(t),MGo=i(tl),ft=n(tl,"DIV",{class:!0});var Vw=s(ft);T(Py.$$.fragment,Vw),EGo=i(Vw),_pe=n(Vw,"P",{});var Q2t=s(_pe);CGo=r(Q2t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Q2t.forEach(t),wGo=i(Vw),od=n(Vw,"P",{});var Soe=s(od);AGo=r(Soe,`Note:
Loading a model from its configuration file does `),upe=n(Soe,"STRONG",{});var W2t=s(upe);LGo=r(W2t,"not"),W2t.forEach(t),yGo=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(Soe,"A",{href:!0});var H2t=s(VV);xGo=r(H2t,"from_pretrained()"),H2t.forEach(t),$Go=r(Soe," to load the model weights."),Soe.forEach(t),kGo=i(Vw),T(Fb.$$.fragment,Vw),Vw.forEach(t),SGo=i(tl),ro=n(tl,"DIV",{class:!0});var ca=s(ro);T(By.$$.fragment,ca),RGo=i(ca),bpe=n(ca,"P",{});var U2t=s(bpe);PGo=r(U2t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),U2t.forEach(t),BGo=i(ca),ja=n(ca,"P",{});var Xw=s(ja);IGo=r(Xw,"The model class to instantiate is selected based on the "),vpe=n(Xw,"CODE",{});var J2t=s(vpe);NGo=r(J2t,"model_type"),J2t.forEach(t),qGo=r(Xw,` property of the config object (either
passed as an argument or loaded from `),Fpe=n(Xw,"CODE",{});var Y2t=s(Fpe);jGo=r(Y2t,"pretrained_model_name_or_path"),Y2t.forEach(t),DGo=r(Xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=n(Xw,"CODE",{});var K2t=s(Tpe);GGo=r(K2t,"pretrained_model_name_or_path"),K2t.forEach(t),OGo=r(Xw,":"),Xw.forEach(t),VGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);Tb=n(ee,"LI",{});var ESe=s(Tb);Mpe=n(ESe,"STRONG",{});var Z2t=s(Mpe);XGo=r(Z2t,"albert"),Z2t.forEach(t),zGo=r(ESe," \u2014 "),XV=n(ESe,"A",{href:!0});var ebt=s(XV);QGo=r(ebt,"AlbertForMultipleChoice"),ebt.forEach(t),WGo=r(ESe," (ALBERT model)"),ESe.forEach(t),HGo=i(ee),Mb=n(ee,"LI",{});var CSe=s(Mb);Epe=n(CSe,"STRONG",{});var obt=s(Epe);UGo=r(obt,"bert"),obt.forEach(t),JGo=r(CSe," \u2014 "),zV=n(CSe,"A",{href:!0});var rbt=s(zV);YGo=r(rbt,"BertForMultipleChoice"),rbt.forEach(t),KGo=r(CSe," (BERT model)"),CSe.forEach(t),ZGo=i(ee),Eb=n(ee,"LI",{});var wSe=s(Eb);Cpe=n(wSe,"STRONG",{});var tbt=s(Cpe);eOo=r(tbt,"big_bird"),tbt.forEach(t),oOo=r(wSe," \u2014 "),QV=n(wSe,"A",{href:!0});var abt=s(QV);rOo=r(abt,"BigBirdForMultipleChoice"),abt.forEach(t),tOo=r(wSe," (BigBird model)"),wSe.forEach(t),aOo=i(ee),Cb=n(ee,"LI",{});var ASe=s(Cb);wpe=n(ASe,"STRONG",{});var nbt=s(wpe);nOo=r(nbt,"camembert"),nbt.forEach(t),sOo=r(ASe," \u2014 "),WV=n(ASe,"A",{href:!0});var sbt=s(WV);lOo=r(sbt,"CamembertForMultipleChoice"),sbt.forEach(t),iOo=r(ASe," (CamemBERT model)"),ASe.forEach(t),dOo=i(ee),wb=n(ee,"LI",{});var LSe=s(wb);Ape=n(LSe,"STRONG",{});var lbt=s(Ape);cOo=r(lbt,"canine"),lbt.forEach(t),fOo=r(LSe," \u2014 "),HV=n(LSe,"A",{href:!0});var ibt=s(HV);mOo=r(ibt,"CanineForMultipleChoice"),ibt.forEach(t),gOo=r(LSe," (CANINE model)"),LSe.forEach(t),hOo=i(ee),Ab=n(ee,"LI",{});var ySe=s(Ab);Lpe=n(ySe,"STRONG",{});var dbt=s(Lpe);pOo=r(dbt,"convbert"),dbt.forEach(t),_Oo=r(ySe," \u2014 "),UV=n(ySe,"A",{href:!0});var cbt=s(UV);uOo=r(cbt,"ConvBertForMultipleChoice"),cbt.forEach(t),bOo=r(ySe," (ConvBERT model)"),ySe.forEach(t),vOo=i(ee),Lb=n(ee,"LI",{});var xSe=s(Lb);ype=n(xSe,"STRONG",{});var fbt=s(ype);FOo=r(fbt,"data2vec-text"),fbt.forEach(t),TOo=r(xSe," \u2014 "),JV=n(xSe,"A",{href:!0});var mbt=s(JV);MOo=r(mbt,"Data2VecTextForMultipleChoice"),mbt.forEach(t),EOo=r(xSe," (Data2VecText model)"),xSe.forEach(t),COo=i(ee),yb=n(ee,"LI",{});var $Se=s(yb);xpe=n($Se,"STRONG",{});var gbt=s(xpe);wOo=r(gbt,"deberta-v2"),gbt.forEach(t),AOo=r($Se," \u2014 "),YV=n($Se,"A",{href:!0});var hbt=s(YV);LOo=r(hbt,"DebertaV2ForMultipleChoice"),hbt.forEach(t),yOo=r($Se," (DeBERTa-v2 model)"),$Se.forEach(t),xOo=i(ee),xb=n(ee,"LI",{});var kSe=s(xb);$pe=n(kSe,"STRONG",{});var pbt=s($pe);$Oo=r(pbt,"distilbert"),pbt.forEach(t),kOo=r(kSe," \u2014 "),KV=n(kSe,"A",{href:!0});var _bt=s(KV);SOo=r(_bt,"DistilBertForMultipleChoice"),_bt.forEach(t),ROo=r(kSe," (DistilBERT model)"),kSe.forEach(t),POo=i(ee),$b=n(ee,"LI",{});var SSe=s($b);kpe=n(SSe,"STRONG",{});var ubt=s(kpe);BOo=r(ubt,"electra"),ubt.forEach(t),IOo=r(SSe," \u2014 "),ZV=n(SSe,"A",{href:!0});var bbt=s(ZV);NOo=r(bbt,"ElectraForMultipleChoice"),bbt.forEach(t),qOo=r(SSe," (ELECTRA model)"),SSe.forEach(t),jOo=i(ee),kb=n(ee,"LI",{});var RSe=s(kb);Spe=n(RSe,"STRONG",{});var vbt=s(Spe);DOo=r(vbt,"flaubert"),vbt.forEach(t),GOo=r(RSe," \u2014 "),eX=n(RSe,"A",{href:!0});var Fbt=s(eX);OOo=r(Fbt,"FlaubertForMultipleChoice"),Fbt.forEach(t),VOo=r(RSe," (FlauBERT model)"),RSe.forEach(t),XOo=i(ee),Sb=n(ee,"LI",{});var PSe=s(Sb);Rpe=n(PSe,"STRONG",{});var Tbt=s(Rpe);zOo=r(Tbt,"fnet"),Tbt.forEach(t),QOo=r(PSe," \u2014 "),oX=n(PSe,"A",{href:!0});var Mbt=s(oX);WOo=r(Mbt,"FNetForMultipleChoice"),Mbt.forEach(t),HOo=r(PSe," (FNet model)"),PSe.forEach(t),UOo=i(ee),Rb=n(ee,"LI",{});var BSe=s(Rb);Ppe=n(BSe,"STRONG",{});var Ebt=s(Ppe);JOo=r(Ebt,"funnel"),Ebt.forEach(t),YOo=r(BSe," \u2014 "),rX=n(BSe,"A",{href:!0});var Cbt=s(rX);KOo=r(Cbt,"FunnelForMultipleChoice"),Cbt.forEach(t),ZOo=r(BSe," (Funnel Transformer model)"),BSe.forEach(t),eVo=i(ee),Pb=n(ee,"LI",{});var ISe=s(Pb);Bpe=n(ISe,"STRONG",{});var wbt=s(Bpe);oVo=r(wbt,"ibert"),wbt.forEach(t),rVo=r(ISe," \u2014 "),tX=n(ISe,"A",{href:!0});var Abt=s(tX);tVo=r(Abt,"IBertForMultipleChoice"),Abt.forEach(t),aVo=r(ISe," (I-BERT model)"),ISe.forEach(t),nVo=i(ee),Bb=n(ee,"LI",{});var NSe=s(Bb);Ipe=n(NSe,"STRONG",{});var Lbt=s(Ipe);sVo=r(Lbt,"longformer"),Lbt.forEach(t),lVo=r(NSe," \u2014 "),aX=n(NSe,"A",{href:!0});var ybt=s(aX);iVo=r(ybt,"LongformerForMultipleChoice"),ybt.forEach(t),dVo=r(NSe," (Longformer model)"),NSe.forEach(t),cVo=i(ee),Ib=n(ee,"LI",{});var qSe=s(Ib);Npe=n(qSe,"STRONG",{});var xbt=s(Npe);fVo=r(xbt,"megatron-bert"),xbt.forEach(t),mVo=r(qSe," \u2014 "),nX=n(qSe,"A",{href:!0});var $bt=s(nX);gVo=r($bt,"MegatronBertForMultipleChoice"),$bt.forEach(t),hVo=r(qSe," (Megatron-BERT model)"),qSe.forEach(t),pVo=i(ee),Nb=n(ee,"LI",{});var jSe=s(Nb);qpe=n(jSe,"STRONG",{});var kbt=s(qpe);_Vo=r(kbt,"mobilebert"),kbt.forEach(t),uVo=r(jSe," \u2014 "),sX=n(jSe,"A",{href:!0});var Sbt=s(sX);bVo=r(Sbt,"MobileBertForMultipleChoice"),Sbt.forEach(t),vVo=r(jSe," (MobileBERT model)"),jSe.forEach(t),FVo=i(ee),qb=n(ee,"LI",{});var DSe=s(qb);jpe=n(DSe,"STRONG",{});var Rbt=s(jpe);TVo=r(Rbt,"mpnet"),Rbt.forEach(t),MVo=r(DSe," \u2014 "),lX=n(DSe,"A",{href:!0});var Pbt=s(lX);EVo=r(Pbt,"MPNetForMultipleChoice"),Pbt.forEach(t),CVo=r(DSe," (MPNet model)"),DSe.forEach(t),wVo=i(ee),jb=n(ee,"LI",{});var GSe=s(jb);Dpe=n(GSe,"STRONG",{});var Bbt=s(Dpe);AVo=r(Bbt,"nezha"),Bbt.forEach(t),LVo=r(GSe," \u2014 "),iX=n(GSe,"A",{href:!0});var Ibt=s(iX);yVo=r(Ibt,"NezhaForMultipleChoice"),Ibt.forEach(t),xVo=r(GSe," (Nezha model)"),GSe.forEach(t),$Vo=i(ee),Db=n(ee,"LI",{});var OSe=s(Db);Gpe=n(OSe,"STRONG",{});var Nbt=s(Gpe);kVo=r(Nbt,"nystromformer"),Nbt.forEach(t),SVo=r(OSe," \u2014 "),dX=n(OSe,"A",{href:!0});var qbt=s(dX);RVo=r(qbt,"NystromformerForMultipleChoice"),qbt.forEach(t),PVo=r(OSe," (Nystr\xF6mformer model)"),OSe.forEach(t),BVo=i(ee),Gb=n(ee,"LI",{});var VSe=s(Gb);Ope=n(VSe,"STRONG",{});var jbt=s(Ope);IVo=r(jbt,"qdqbert"),jbt.forEach(t),NVo=r(VSe," \u2014 "),cX=n(VSe,"A",{href:!0});var Dbt=s(cX);qVo=r(Dbt,"QDQBertForMultipleChoice"),Dbt.forEach(t),jVo=r(VSe," (QDQBert model)"),VSe.forEach(t),DVo=i(ee),Ob=n(ee,"LI",{});var XSe=s(Ob);Vpe=n(XSe,"STRONG",{});var Gbt=s(Vpe);GVo=r(Gbt,"rembert"),Gbt.forEach(t),OVo=r(XSe," \u2014 "),fX=n(XSe,"A",{href:!0});var Obt=s(fX);VVo=r(Obt,"RemBertForMultipleChoice"),Obt.forEach(t),XVo=r(XSe," (RemBERT model)"),XSe.forEach(t),zVo=i(ee),Vb=n(ee,"LI",{});var zSe=s(Vb);Xpe=n(zSe,"STRONG",{});var Vbt=s(Xpe);QVo=r(Vbt,"roberta"),Vbt.forEach(t),WVo=r(zSe," \u2014 "),mX=n(zSe,"A",{href:!0});var Xbt=s(mX);HVo=r(Xbt,"RobertaForMultipleChoice"),Xbt.forEach(t),UVo=r(zSe," (RoBERTa model)"),zSe.forEach(t),JVo=i(ee),Xb=n(ee,"LI",{});var QSe=s(Xb);zpe=n(QSe,"STRONG",{});var zbt=s(zpe);YVo=r(zbt,"roformer"),zbt.forEach(t),KVo=r(QSe," \u2014 "),gX=n(QSe,"A",{href:!0});var Qbt=s(gX);ZVo=r(Qbt,"RoFormerForMultipleChoice"),Qbt.forEach(t),eXo=r(QSe," (RoFormer model)"),QSe.forEach(t),oXo=i(ee),zb=n(ee,"LI",{});var WSe=s(zb);Qpe=n(WSe,"STRONG",{});var Wbt=s(Qpe);rXo=r(Wbt,"squeezebert"),Wbt.forEach(t),tXo=r(WSe," \u2014 "),hX=n(WSe,"A",{href:!0});var Hbt=s(hX);aXo=r(Hbt,"SqueezeBertForMultipleChoice"),Hbt.forEach(t),nXo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),sXo=i(ee),Qb=n(ee,"LI",{});var HSe=s(Qb);Wpe=n(HSe,"STRONG",{});var Ubt=s(Wpe);lXo=r(Ubt,"xlm"),Ubt.forEach(t),iXo=r(HSe," \u2014 "),pX=n(HSe,"A",{href:!0});var Jbt=s(pX);dXo=r(Jbt,"XLMForMultipleChoice"),Jbt.forEach(t),cXo=r(HSe," (XLM model)"),HSe.forEach(t),fXo=i(ee),Wb=n(ee,"LI",{});var USe=s(Wb);Hpe=n(USe,"STRONG",{});var Ybt=s(Hpe);mXo=r(Ybt,"xlm-roberta"),Ybt.forEach(t),gXo=r(USe," \u2014 "),_X=n(USe,"A",{href:!0});var Kbt=s(_X);hXo=r(Kbt,"XLMRobertaForMultipleChoice"),Kbt.forEach(t),pXo=r(USe," (XLM-RoBERTa model)"),USe.forEach(t),_Xo=i(ee),Hb=n(ee,"LI",{});var JSe=s(Hb);Upe=n(JSe,"STRONG",{});var Zbt=s(Upe);uXo=r(Zbt,"xlm-roberta-xl"),Zbt.forEach(t),bXo=r(JSe," \u2014 "),uX=n(JSe,"A",{href:!0});var evt=s(uX);vXo=r(evt,"XLMRobertaXLForMultipleChoice"),evt.forEach(t),FXo=r(JSe," (XLM-RoBERTa-XL model)"),JSe.forEach(t),TXo=i(ee),Ub=n(ee,"LI",{});var YSe=s(Ub);Jpe=n(YSe,"STRONG",{});var ovt=s(Jpe);MXo=r(ovt,"xlnet"),ovt.forEach(t),EXo=r(YSe," \u2014 "),bX=n(YSe,"A",{href:!0});var rvt=s(bX);CXo=r(rvt,"XLNetForMultipleChoice"),rvt.forEach(t),wXo=r(YSe," (XLNet model)"),YSe.forEach(t),AXo=i(ee),Jb=n(ee,"LI",{});var KSe=s(Jb);Ype=n(KSe,"STRONG",{});var tvt=s(Ype);LXo=r(tvt,"yoso"),tvt.forEach(t),yXo=r(KSe," \u2014 "),vX=n(KSe,"A",{href:!0});var avt=s(vX);xXo=r(avt,"YosoForMultipleChoice"),avt.forEach(t),$Xo=r(KSe," (YOSO model)"),KSe.forEach(t),ee.forEach(t),kXo=i(ca),Yb=n(ca,"P",{});var ZSe=s(Yb);SXo=r(ZSe,"The model is set in evaluation mode by default using "),Kpe=n(ZSe,"CODE",{});var nvt=s(Kpe);RXo=r(nvt,"model.eval()"),nvt.forEach(t),PXo=r(ZSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=n(ZSe,"CODE",{});var svt=s(Zpe);BXo=r(svt,"model.train()"),svt.forEach(t),ZSe.forEach(t),IXo=i(ca),T(Kb.$$.fragment,ca),ca.forEach(t),tl.forEach(t),mOe=i(f),rd=n(f,"H2",{class:!0});var bXe=s(rd);Zb=n(bXe,"A",{id:!0,class:!0,href:!0});var lvt=s(Zb);e_e=n(lvt,"SPAN",{});var ivt=s(e_e);T(Iy.$$.fragment,ivt),ivt.forEach(t),lvt.forEach(t),NXo=i(bXe),o_e=n(bXe,"SPAN",{});var dvt=s(o_e);qXo=r(dvt,"AutoModelForNextSentencePrediction"),dvt.forEach(t),bXe.forEach(t),gOe=i(f),Io=n(f,"DIV",{class:!0});var al=s(Io);T(Ny.$$.fragment,al),jXo=i(al),td=n(al,"P",{});var Roe=s(td);DXo=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=n(Roe,"A",{href:!0});var cvt=s(FX);GXo=r(cvt,"from_pretrained()"),cvt.forEach(t),OXo=r(Roe," class method or the "),TX=n(Roe,"A",{href:!0});var fvt=s(TX);VXo=r(fvt,"from_config()"),fvt.forEach(t),XXo=r(Roe,` class
method.`),Roe.forEach(t),zXo=i(al),qy=n(al,"P",{});var vXe=s(qy);QXo=r(vXe,"This class cannot be instantiated directly using "),r_e=n(vXe,"CODE",{});var mvt=s(r_e);WXo=r(mvt,"__init__()"),mvt.forEach(t),HXo=r(vXe," (throws an error)."),vXe.forEach(t),UXo=i(al),mt=n(al,"DIV",{class:!0});var zw=s(mt);T(jy.$$.fragment,zw),JXo=i(zw),t_e=n(zw,"P",{});var gvt=s(t_e);YXo=r(gvt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gvt.forEach(t),KXo=i(zw),ad=n(zw,"P",{});var Poe=s(ad);ZXo=r(Poe,`Note:
Loading a model from its configuration file does `),a_e=n(Poe,"STRONG",{});var hvt=s(a_e);ezo=r(hvt,"not"),hvt.forEach(t),ozo=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(Poe,"A",{href:!0});var pvt=s(MX);rzo=r(pvt,"from_pretrained()"),pvt.forEach(t),tzo=r(Poe," to load the model weights."),Poe.forEach(t),azo=i(zw),T(ev.$$.fragment,zw),zw.forEach(t),nzo=i(al),to=n(al,"DIV",{class:!0});var fa=s(to);T(Dy.$$.fragment,fa),szo=i(fa),n_e=n(fa,"P",{});var _vt=s(n_e);lzo=r(_vt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_vt.forEach(t),izo=i(fa),Da=n(fa,"P",{});var Qw=s(Da);dzo=r(Qw,"The model class to instantiate is selected based on the "),s_e=n(Qw,"CODE",{});var uvt=s(s_e);czo=r(uvt,"model_type"),uvt.forEach(t),fzo=r(Qw,` property of the config object (either
passed as an argument or loaded from `),l_e=n(Qw,"CODE",{});var bvt=s(l_e);mzo=r(bvt,"pretrained_model_name_or_path"),bvt.forEach(t),gzo=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(Qw,"CODE",{});var vvt=s(i_e);hzo=r(vvt,"pretrained_model_name_or_path"),vvt.forEach(t),pzo=r(Qw,":"),Qw.forEach(t),_zo=i(fa),No=n(fa,"UL",{});var ma=s(No);ov=n(ma,"LI",{});var eRe=s(ov);d_e=n(eRe,"STRONG",{});var Fvt=s(d_e);uzo=r(Fvt,"bert"),Fvt.forEach(t),bzo=r(eRe," \u2014 "),EX=n(eRe,"A",{href:!0});var Tvt=s(EX);vzo=r(Tvt,"BertForNextSentencePrediction"),Tvt.forEach(t),Fzo=r(eRe," (BERT model)"),eRe.forEach(t),Tzo=i(ma),rv=n(ma,"LI",{});var oRe=s(rv);c_e=n(oRe,"STRONG",{});var Mvt=s(c_e);Mzo=r(Mvt,"fnet"),Mvt.forEach(t),Ezo=r(oRe," \u2014 "),CX=n(oRe,"A",{href:!0});var Evt=s(CX);Czo=r(Evt,"FNetForNextSentencePrediction"),Evt.forEach(t),wzo=r(oRe," (FNet model)"),oRe.forEach(t),Azo=i(ma),tv=n(ma,"LI",{});var rRe=s(tv);f_e=n(rRe,"STRONG",{});var Cvt=s(f_e);Lzo=r(Cvt,"megatron-bert"),Cvt.forEach(t),yzo=r(rRe," \u2014 "),wX=n(rRe,"A",{href:!0});var wvt=s(wX);xzo=r(wvt,"MegatronBertForNextSentencePrediction"),wvt.forEach(t),$zo=r(rRe," (Megatron-BERT model)"),rRe.forEach(t),kzo=i(ma),av=n(ma,"LI",{});var tRe=s(av);m_e=n(tRe,"STRONG",{});var Avt=s(m_e);Szo=r(Avt,"mobilebert"),Avt.forEach(t),Rzo=r(tRe," \u2014 "),AX=n(tRe,"A",{href:!0});var Lvt=s(AX);Pzo=r(Lvt,"MobileBertForNextSentencePrediction"),Lvt.forEach(t),Bzo=r(tRe," (MobileBERT model)"),tRe.forEach(t),Izo=i(ma),nv=n(ma,"LI",{});var aRe=s(nv);g_e=n(aRe,"STRONG",{});var yvt=s(g_e);Nzo=r(yvt,"nezha"),yvt.forEach(t),qzo=r(aRe," \u2014 "),LX=n(aRe,"A",{href:!0});var xvt=s(LX);jzo=r(xvt,"NezhaForNextSentencePrediction"),xvt.forEach(t),Dzo=r(aRe," (Nezha model)"),aRe.forEach(t),Gzo=i(ma),sv=n(ma,"LI",{});var nRe=s(sv);h_e=n(nRe,"STRONG",{});var $vt=s(h_e);Ozo=r($vt,"qdqbert"),$vt.forEach(t),Vzo=r(nRe," \u2014 "),yX=n(nRe,"A",{href:!0});var kvt=s(yX);Xzo=r(kvt,"QDQBertForNextSentencePrediction"),kvt.forEach(t),zzo=r(nRe," (QDQBert model)"),nRe.forEach(t),ma.forEach(t),Qzo=i(fa),lv=n(fa,"P",{});var sRe=s(lv);Wzo=r(sRe,"The model is set in evaluation mode by default using "),p_e=n(sRe,"CODE",{});var Svt=s(p_e);Hzo=r(Svt,"model.eval()"),Svt.forEach(t),Uzo=r(sRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=n(sRe,"CODE",{});var Rvt=s(__e);Jzo=r(Rvt,"model.train()"),Rvt.forEach(t),sRe.forEach(t),Yzo=i(fa),T(iv.$$.fragment,fa),fa.forEach(t),al.forEach(t),hOe=i(f),nd=n(f,"H2",{class:!0});var FXe=s(nd);dv=n(FXe,"A",{id:!0,class:!0,href:!0});var Pvt=s(dv);u_e=n(Pvt,"SPAN",{});var Bvt=s(u_e);T(Gy.$$.fragment,Bvt),Bvt.forEach(t),Pvt.forEach(t),Kzo=i(FXe),b_e=n(FXe,"SPAN",{});var Ivt=s(b_e);Zzo=r(Ivt,"AutoModelForTokenClassification"),Ivt.forEach(t),FXe.forEach(t),pOe=i(f),qo=n(f,"DIV",{class:!0});var nl=s(qo);T(Oy.$$.fragment,nl),eQo=i(nl),sd=n(nl,"P",{});var Boe=s(sd);oQo=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=n(Boe,"A",{href:!0});var Nvt=s(xX);rQo=r(Nvt,"from_pretrained()"),Nvt.forEach(t),tQo=r(Boe," class method or the "),$X=n(Boe,"A",{href:!0});var qvt=s($X);aQo=r(qvt,"from_config()"),qvt.forEach(t),nQo=r(Boe,` class
method.`),Boe.forEach(t),sQo=i(nl),Vy=n(nl,"P",{});var TXe=s(Vy);lQo=r(TXe,"This class cannot be instantiated directly using "),v_e=n(TXe,"CODE",{});var jvt=s(v_e);iQo=r(jvt,"__init__()"),jvt.forEach(t),dQo=r(TXe," (throws an error)."),TXe.forEach(t),cQo=i(nl),gt=n(nl,"DIV",{class:!0});var Ww=s(gt);T(Xy.$$.fragment,Ww),fQo=i(Ww),F_e=n(Ww,"P",{});var Dvt=s(F_e);mQo=r(Dvt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Dvt.forEach(t),gQo=i(Ww),ld=n(Ww,"P",{});var Ioe=s(ld);hQo=r(Ioe,`Note:
Loading a model from its configuration file does `),T_e=n(Ioe,"STRONG",{});var Gvt=s(T_e);pQo=r(Gvt,"not"),Gvt.forEach(t),_Qo=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(Ioe,"A",{href:!0});var Ovt=s(kX);uQo=r(Ovt,"from_pretrained()"),Ovt.forEach(t),bQo=r(Ioe," to load the model weights."),Ioe.forEach(t),vQo=i(Ww),T(cv.$$.fragment,Ww),Ww.forEach(t),FQo=i(nl),ao=n(nl,"DIV",{class:!0});var ga=s(ao);T(zy.$$.fragment,ga),TQo=i(ga),M_e=n(ga,"P",{});var Vvt=s(M_e);MQo=r(Vvt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Vvt.forEach(t),EQo=i(ga),Ga=n(ga,"P",{});var Hw=s(Ga);CQo=r(Hw,"The model class to instantiate is selected based on the "),E_e=n(Hw,"CODE",{});var Xvt=s(E_e);wQo=r(Xvt,"model_type"),Xvt.forEach(t),AQo=r(Hw,` property of the config object (either
passed as an argument or loaded from `),C_e=n(Hw,"CODE",{});var zvt=s(C_e);LQo=r(zvt,"pretrained_model_name_or_path"),zvt.forEach(t),yQo=r(Hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=n(Hw,"CODE",{});var Qvt=s(w_e);xQo=r(Qvt,"pretrained_model_name_or_path"),Qvt.forEach(t),$Qo=r(Hw,":"),Hw.forEach(t),kQo=i(ga),H=n(ga,"UL",{});var J=s(H);fv=n(J,"LI",{});var lRe=s(fv);A_e=n(lRe,"STRONG",{});var Wvt=s(A_e);SQo=r(Wvt,"albert"),Wvt.forEach(t),RQo=r(lRe," \u2014 "),SX=n(lRe,"A",{href:!0});var Hvt=s(SX);PQo=r(Hvt,"AlbertForTokenClassification"),Hvt.forEach(t),BQo=r(lRe," (ALBERT model)"),lRe.forEach(t),IQo=i(J),mv=n(J,"LI",{});var iRe=s(mv);L_e=n(iRe,"STRONG",{});var Uvt=s(L_e);NQo=r(Uvt,"bert"),Uvt.forEach(t),qQo=r(iRe," \u2014 "),RX=n(iRe,"A",{href:!0});var Jvt=s(RX);jQo=r(Jvt,"BertForTokenClassification"),Jvt.forEach(t),DQo=r(iRe," (BERT model)"),iRe.forEach(t),GQo=i(J),gv=n(J,"LI",{});var dRe=s(gv);y_e=n(dRe,"STRONG",{});var Yvt=s(y_e);OQo=r(Yvt,"big_bird"),Yvt.forEach(t),VQo=r(dRe," \u2014 "),PX=n(dRe,"A",{href:!0});var Kvt=s(PX);XQo=r(Kvt,"BigBirdForTokenClassification"),Kvt.forEach(t),zQo=r(dRe," (BigBird model)"),dRe.forEach(t),QQo=i(J),hv=n(J,"LI",{});var cRe=s(hv);x_e=n(cRe,"STRONG",{});var Zvt=s(x_e);WQo=r(Zvt,"bloom"),Zvt.forEach(t),HQo=r(cRe," \u2014 "),BX=n(cRe,"A",{href:!0});var eFt=s(BX);UQo=r(eFt,"BloomForTokenClassification"),eFt.forEach(t),JQo=r(cRe," (BLOOM model)"),cRe.forEach(t),YQo=i(J),pv=n(J,"LI",{});var fRe=s(pv);$_e=n(fRe,"STRONG",{});var oFt=s($_e);KQo=r(oFt,"camembert"),oFt.forEach(t),ZQo=r(fRe," \u2014 "),IX=n(fRe,"A",{href:!0});var rFt=s(IX);eWo=r(rFt,"CamembertForTokenClassification"),rFt.forEach(t),oWo=r(fRe," (CamemBERT model)"),fRe.forEach(t),rWo=i(J),_v=n(J,"LI",{});var mRe=s(_v);k_e=n(mRe,"STRONG",{});var tFt=s(k_e);tWo=r(tFt,"canine"),tFt.forEach(t),aWo=r(mRe," \u2014 "),NX=n(mRe,"A",{href:!0});var aFt=s(NX);nWo=r(aFt,"CanineForTokenClassification"),aFt.forEach(t),sWo=r(mRe," (CANINE model)"),mRe.forEach(t),lWo=i(J),uv=n(J,"LI",{});var gRe=s(uv);S_e=n(gRe,"STRONG",{});var nFt=s(S_e);iWo=r(nFt,"convbert"),nFt.forEach(t),dWo=r(gRe," \u2014 "),qX=n(gRe,"A",{href:!0});var sFt=s(qX);cWo=r(sFt,"ConvBertForTokenClassification"),sFt.forEach(t),fWo=r(gRe," (ConvBERT model)"),gRe.forEach(t),mWo=i(J),bv=n(J,"LI",{});var hRe=s(bv);R_e=n(hRe,"STRONG",{});var lFt=s(R_e);gWo=r(lFt,"data2vec-text"),lFt.forEach(t),hWo=r(hRe," \u2014 "),jX=n(hRe,"A",{href:!0});var iFt=s(jX);pWo=r(iFt,"Data2VecTextForTokenClassification"),iFt.forEach(t),_Wo=r(hRe," (Data2VecText model)"),hRe.forEach(t),uWo=i(J),vv=n(J,"LI",{});var pRe=s(vv);P_e=n(pRe,"STRONG",{});var dFt=s(P_e);bWo=r(dFt,"deberta"),dFt.forEach(t),vWo=r(pRe," \u2014 "),DX=n(pRe,"A",{href:!0});var cFt=s(DX);FWo=r(cFt,"DebertaForTokenClassification"),cFt.forEach(t),TWo=r(pRe," (DeBERTa model)"),pRe.forEach(t),MWo=i(J),Fv=n(J,"LI",{});var _Re=s(Fv);B_e=n(_Re,"STRONG",{});var fFt=s(B_e);EWo=r(fFt,"deberta-v2"),fFt.forEach(t),CWo=r(_Re," \u2014 "),GX=n(_Re,"A",{href:!0});var mFt=s(GX);wWo=r(mFt,"DebertaV2ForTokenClassification"),mFt.forEach(t),AWo=r(_Re," (DeBERTa-v2 model)"),_Re.forEach(t),LWo=i(J),Tv=n(J,"LI",{});var uRe=s(Tv);I_e=n(uRe,"STRONG",{});var gFt=s(I_e);yWo=r(gFt,"distilbert"),gFt.forEach(t),xWo=r(uRe," \u2014 "),OX=n(uRe,"A",{href:!0});var hFt=s(OX);$Wo=r(hFt,"DistilBertForTokenClassification"),hFt.forEach(t),kWo=r(uRe," (DistilBERT model)"),uRe.forEach(t),SWo=i(J),Mv=n(J,"LI",{});var bRe=s(Mv);N_e=n(bRe,"STRONG",{});var pFt=s(N_e);RWo=r(pFt,"electra"),pFt.forEach(t),PWo=r(bRe," \u2014 "),VX=n(bRe,"A",{href:!0});var _Ft=s(VX);BWo=r(_Ft,"ElectraForTokenClassification"),_Ft.forEach(t),IWo=r(bRe," (ELECTRA model)"),bRe.forEach(t),NWo=i(J),Ev=n(J,"LI",{});var vRe=s(Ev);q_e=n(vRe,"STRONG",{});var uFt=s(q_e);qWo=r(uFt,"flaubert"),uFt.forEach(t),jWo=r(vRe," \u2014 "),XX=n(vRe,"A",{href:!0});var bFt=s(XX);DWo=r(bFt,"FlaubertForTokenClassification"),bFt.forEach(t),GWo=r(vRe," (FlauBERT model)"),vRe.forEach(t),OWo=i(J),Cv=n(J,"LI",{});var FRe=s(Cv);j_e=n(FRe,"STRONG",{});var vFt=s(j_e);VWo=r(vFt,"fnet"),vFt.forEach(t),XWo=r(FRe," \u2014 "),zX=n(FRe,"A",{href:!0});var FFt=s(zX);zWo=r(FFt,"FNetForTokenClassification"),FFt.forEach(t),QWo=r(FRe," (FNet model)"),FRe.forEach(t),WWo=i(J),wv=n(J,"LI",{});var TRe=s(wv);D_e=n(TRe,"STRONG",{});var TFt=s(D_e);HWo=r(TFt,"funnel"),TFt.forEach(t),UWo=r(TRe," \u2014 "),QX=n(TRe,"A",{href:!0});var MFt=s(QX);JWo=r(MFt,"FunnelForTokenClassification"),MFt.forEach(t),YWo=r(TRe," (Funnel Transformer model)"),TRe.forEach(t),KWo=i(J),Av=n(J,"LI",{});var MRe=s(Av);G_e=n(MRe,"STRONG",{});var EFt=s(G_e);ZWo=r(EFt,"gpt2"),EFt.forEach(t),eHo=r(MRe," \u2014 "),WX=n(MRe,"A",{href:!0});var CFt=s(WX);oHo=r(CFt,"GPT2ForTokenClassification"),CFt.forEach(t),rHo=r(MRe," (OpenAI GPT-2 model)"),MRe.forEach(t),tHo=i(J),Lv=n(J,"LI",{});var ERe=s(Lv);O_e=n(ERe,"STRONG",{});var wFt=s(O_e);aHo=r(wFt,"ibert"),wFt.forEach(t),nHo=r(ERe," \u2014 "),HX=n(ERe,"A",{href:!0});var AFt=s(HX);sHo=r(AFt,"IBertForTokenClassification"),AFt.forEach(t),lHo=r(ERe," (I-BERT model)"),ERe.forEach(t),iHo=i(J),yv=n(J,"LI",{});var CRe=s(yv);V_e=n(CRe,"STRONG",{});var LFt=s(V_e);dHo=r(LFt,"layoutlm"),LFt.forEach(t),cHo=r(CRe," \u2014 "),UX=n(CRe,"A",{href:!0});var yFt=s(UX);fHo=r(yFt,"LayoutLMForTokenClassification"),yFt.forEach(t),mHo=r(CRe," (LayoutLM model)"),CRe.forEach(t),gHo=i(J),xv=n(J,"LI",{});var wRe=s(xv);X_e=n(wRe,"STRONG",{});var xFt=s(X_e);hHo=r(xFt,"layoutlmv2"),xFt.forEach(t),pHo=r(wRe," \u2014 "),JX=n(wRe,"A",{href:!0});var $Ft=s(JX);_Ho=r($Ft,"LayoutLMv2ForTokenClassification"),$Ft.forEach(t),uHo=r(wRe," (LayoutLMv2 model)"),wRe.forEach(t),bHo=i(J),$v=n(J,"LI",{});var ARe=s($v);z_e=n(ARe,"STRONG",{});var kFt=s(z_e);vHo=r(kFt,"layoutlmv3"),kFt.forEach(t),FHo=r(ARe," \u2014 "),YX=n(ARe,"A",{href:!0});var SFt=s(YX);THo=r(SFt,"LayoutLMv3ForTokenClassification"),SFt.forEach(t),MHo=r(ARe," (LayoutLMv3 model)"),ARe.forEach(t),EHo=i(J),kv=n(J,"LI",{});var LRe=s(kv);Q_e=n(LRe,"STRONG",{});var RFt=s(Q_e);CHo=r(RFt,"longformer"),RFt.forEach(t),wHo=r(LRe," \u2014 "),KX=n(LRe,"A",{href:!0});var PFt=s(KX);AHo=r(PFt,"LongformerForTokenClassification"),PFt.forEach(t),LHo=r(LRe," (Longformer model)"),LRe.forEach(t),yHo=i(J),Sv=n(J,"LI",{});var yRe=s(Sv);W_e=n(yRe,"STRONG",{});var BFt=s(W_e);xHo=r(BFt,"megatron-bert"),BFt.forEach(t),$Ho=r(yRe," \u2014 "),ZX=n(yRe,"A",{href:!0});var IFt=s(ZX);kHo=r(IFt,"MegatronBertForTokenClassification"),IFt.forEach(t),SHo=r(yRe," (Megatron-BERT model)"),yRe.forEach(t),RHo=i(J),Rv=n(J,"LI",{});var xRe=s(Rv);H_e=n(xRe,"STRONG",{});var NFt=s(H_e);PHo=r(NFt,"mobilebert"),NFt.forEach(t),BHo=r(xRe," \u2014 "),ez=n(xRe,"A",{href:!0});var qFt=s(ez);IHo=r(qFt,"MobileBertForTokenClassification"),qFt.forEach(t),NHo=r(xRe," (MobileBERT model)"),xRe.forEach(t),qHo=i(J),Pv=n(J,"LI",{});var $Re=s(Pv);U_e=n($Re,"STRONG",{});var jFt=s(U_e);jHo=r(jFt,"mpnet"),jFt.forEach(t),DHo=r($Re," \u2014 "),oz=n($Re,"A",{href:!0});var DFt=s(oz);GHo=r(DFt,"MPNetForTokenClassification"),DFt.forEach(t),OHo=r($Re," (MPNet model)"),$Re.forEach(t),VHo=i(J),Bv=n(J,"LI",{});var kRe=s(Bv);J_e=n(kRe,"STRONG",{});var GFt=s(J_e);XHo=r(GFt,"nezha"),GFt.forEach(t),zHo=r(kRe," \u2014 "),rz=n(kRe,"A",{href:!0});var OFt=s(rz);QHo=r(OFt,"NezhaForTokenClassification"),OFt.forEach(t),WHo=r(kRe," (Nezha model)"),kRe.forEach(t),HHo=i(J),Iv=n(J,"LI",{});var SRe=s(Iv);Y_e=n(SRe,"STRONG",{});var VFt=s(Y_e);UHo=r(VFt,"nystromformer"),VFt.forEach(t),JHo=r(SRe," \u2014 "),tz=n(SRe,"A",{href:!0});var XFt=s(tz);YHo=r(XFt,"NystromformerForTokenClassification"),XFt.forEach(t),KHo=r(SRe," (Nystr\xF6mformer model)"),SRe.forEach(t),ZHo=i(J),Nv=n(J,"LI",{});var RRe=s(Nv);K_e=n(RRe,"STRONG",{});var zFt=s(K_e);eUo=r(zFt,"qdqbert"),zFt.forEach(t),oUo=r(RRe," \u2014 "),az=n(RRe,"A",{href:!0});var QFt=s(az);rUo=r(QFt,"QDQBertForTokenClassification"),QFt.forEach(t),tUo=r(RRe," (QDQBert model)"),RRe.forEach(t),aUo=i(J),qv=n(J,"LI",{});var PRe=s(qv);Z_e=n(PRe,"STRONG",{});var WFt=s(Z_e);nUo=r(WFt,"rembert"),WFt.forEach(t),sUo=r(PRe," \u2014 "),nz=n(PRe,"A",{href:!0});var HFt=s(nz);lUo=r(HFt,"RemBertForTokenClassification"),HFt.forEach(t),iUo=r(PRe," (RemBERT model)"),PRe.forEach(t),dUo=i(J),jv=n(J,"LI",{});var BRe=s(jv);eue=n(BRe,"STRONG",{});var UFt=s(eue);cUo=r(UFt,"roberta"),UFt.forEach(t),fUo=r(BRe," \u2014 "),sz=n(BRe,"A",{href:!0});var JFt=s(sz);mUo=r(JFt,"RobertaForTokenClassification"),JFt.forEach(t),gUo=r(BRe," (RoBERTa model)"),BRe.forEach(t),hUo=i(J),Dv=n(J,"LI",{});var IRe=s(Dv);oue=n(IRe,"STRONG",{});var YFt=s(oue);pUo=r(YFt,"roformer"),YFt.forEach(t),_Uo=r(IRe," \u2014 "),lz=n(IRe,"A",{href:!0});var KFt=s(lz);uUo=r(KFt,"RoFormerForTokenClassification"),KFt.forEach(t),bUo=r(IRe," (RoFormer model)"),IRe.forEach(t),vUo=i(J),Gv=n(J,"LI",{});var NRe=s(Gv);rue=n(NRe,"STRONG",{});var ZFt=s(rue);FUo=r(ZFt,"squeezebert"),ZFt.forEach(t),TUo=r(NRe," \u2014 "),iz=n(NRe,"A",{href:!0});var e6t=s(iz);MUo=r(e6t,"SqueezeBertForTokenClassification"),e6t.forEach(t),EUo=r(NRe," (SqueezeBERT model)"),NRe.forEach(t),CUo=i(J),Ov=n(J,"LI",{});var qRe=s(Ov);tue=n(qRe,"STRONG",{});var o6t=s(tue);wUo=r(o6t,"xlm"),o6t.forEach(t),AUo=r(qRe," \u2014 "),dz=n(qRe,"A",{href:!0});var r6t=s(dz);LUo=r(r6t,"XLMForTokenClassification"),r6t.forEach(t),yUo=r(qRe," (XLM model)"),qRe.forEach(t),xUo=i(J),Vv=n(J,"LI",{});var jRe=s(Vv);aue=n(jRe,"STRONG",{});var t6t=s(aue);$Uo=r(t6t,"xlm-roberta"),t6t.forEach(t),kUo=r(jRe," \u2014 "),cz=n(jRe,"A",{href:!0});var a6t=s(cz);SUo=r(a6t,"XLMRobertaForTokenClassification"),a6t.forEach(t),RUo=r(jRe," (XLM-RoBERTa model)"),jRe.forEach(t),PUo=i(J),Xv=n(J,"LI",{});var DRe=s(Xv);nue=n(DRe,"STRONG",{});var n6t=s(nue);BUo=r(n6t,"xlm-roberta-xl"),n6t.forEach(t),IUo=r(DRe," \u2014 "),fz=n(DRe,"A",{href:!0});var s6t=s(fz);NUo=r(s6t,"XLMRobertaXLForTokenClassification"),s6t.forEach(t),qUo=r(DRe," (XLM-RoBERTa-XL model)"),DRe.forEach(t),jUo=i(J),zv=n(J,"LI",{});var GRe=s(zv);sue=n(GRe,"STRONG",{});var l6t=s(sue);DUo=r(l6t,"xlnet"),l6t.forEach(t),GUo=r(GRe," \u2014 "),mz=n(GRe,"A",{href:!0});var i6t=s(mz);OUo=r(i6t,"XLNetForTokenClassification"),i6t.forEach(t),VUo=r(GRe," (XLNet model)"),GRe.forEach(t),XUo=i(J),Qv=n(J,"LI",{});var ORe=s(Qv);lue=n(ORe,"STRONG",{});var d6t=s(lue);zUo=r(d6t,"yoso"),d6t.forEach(t),QUo=r(ORe," \u2014 "),gz=n(ORe,"A",{href:!0});var c6t=s(gz);WUo=r(c6t,"YosoForTokenClassification"),c6t.forEach(t),HUo=r(ORe," (YOSO model)"),ORe.forEach(t),J.forEach(t),UUo=i(ga),Wv=n(ga,"P",{});var VRe=s(Wv);JUo=r(VRe,"The model is set in evaluation mode by default using "),iue=n(VRe,"CODE",{});var f6t=s(iue);YUo=r(f6t,"model.eval()"),f6t.forEach(t),KUo=r(VRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=n(VRe,"CODE",{});var m6t=s(due);ZUo=r(m6t,"model.train()"),m6t.forEach(t),VRe.forEach(t),eJo=i(ga),T(Hv.$$.fragment,ga),ga.forEach(t),nl.forEach(t),_Oe=i(f),id=n(f,"H2",{class:!0});var MXe=s(id);Uv=n(MXe,"A",{id:!0,class:!0,href:!0});var g6t=s(Uv);cue=n(g6t,"SPAN",{});var h6t=s(cue);T(Qy.$$.fragment,h6t),h6t.forEach(t),g6t.forEach(t),oJo=i(MXe),fue=n(MXe,"SPAN",{});var p6t=s(fue);rJo=r(p6t,"AutoModelForQuestionAnswering"),p6t.forEach(t),MXe.forEach(t),uOe=i(f),jo=n(f,"DIV",{class:!0});var sl=s(jo);T(Wy.$$.fragment,sl),tJo=i(sl),dd=n(sl,"P",{});var Noe=s(dd);aJo=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=n(Noe,"A",{href:!0});var _6t=s(hz);nJo=r(_6t,"from_pretrained()"),_6t.forEach(t),sJo=r(Noe," class method or the "),pz=n(Noe,"A",{href:!0});var u6t=s(pz);lJo=r(u6t,"from_config()"),u6t.forEach(t),iJo=r(Noe,` class
method.`),Noe.forEach(t),dJo=i(sl),Hy=n(sl,"P",{});var EXe=s(Hy);cJo=r(EXe,"This class cannot be instantiated directly using "),mue=n(EXe,"CODE",{});var b6t=s(mue);fJo=r(b6t,"__init__()"),b6t.forEach(t),mJo=r(EXe," (throws an error)."),EXe.forEach(t),gJo=i(sl),ht=n(sl,"DIV",{class:!0});var Uw=s(ht);T(Uy.$$.fragment,Uw),hJo=i(Uw),gue=n(Uw,"P",{});var v6t=s(gue);pJo=r(v6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v6t.forEach(t),_Jo=i(Uw),cd=n(Uw,"P",{});var qoe=s(cd);uJo=r(qoe,`Note:
Loading a model from its configuration file does `),hue=n(qoe,"STRONG",{});var F6t=s(hue);bJo=r(F6t,"not"),F6t.forEach(t),vJo=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=n(qoe,"A",{href:!0});var T6t=s(_z);FJo=r(T6t,"from_pretrained()"),T6t.forEach(t),TJo=r(qoe," to load the model weights."),qoe.forEach(t),MJo=i(Uw),T(Jv.$$.fragment,Uw),Uw.forEach(t),EJo=i(sl),no=n(sl,"DIV",{class:!0});var ha=s(no);T(Jy.$$.fragment,ha),CJo=i(ha),pue=n(ha,"P",{});var M6t=s(pue);wJo=r(M6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),M6t.forEach(t),AJo=i(ha),Oa=n(ha,"P",{});var Jw=s(Oa);LJo=r(Jw,"The model class to instantiate is selected based on the "),_ue=n(Jw,"CODE",{});var E6t=s(_ue);yJo=r(E6t,"model_type"),E6t.forEach(t),xJo=r(Jw,` property of the config object (either
passed as an argument or loaded from `),uue=n(Jw,"CODE",{});var C6t=s(uue);$Jo=r(C6t,"pretrained_model_name_or_path"),C6t.forEach(t),kJo=r(Jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=n(Jw,"CODE",{});var w6t=s(bue);SJo=r(w6t,"pretrained_model_name_or_path"),w6t.forEach(t),RJo=r(Jw,":"),Jw.forEach(t),PJo=i(ha),V=n(ha,"UL",{});var X=s(V);Yv=n(X,"LI",{});var XRe=s(Yv);vue=n(XRe,"STRONG",{});var A6t=s(vue);BJo=r(A6t,"albert"),A6t.forEach(t),IJo=r(XRe," \u2014 "),uz=n(XRe,"A",{href:!0});var L6t=s(uz);NJo=r(L6t,"AlbertForQuestionAnswering"),L6t.forEach(t),qJo=r(XRe," (ALBERT model)"),XRe.forEach(t),jJo=i(X),Kv=n(X,"LI",{});var zRe=s(Kv);Fue=n(zRe,"STRONG",{});var y6t=s(Fue);DJo=r(y6t,"bart"),y6t.forEach(t),GJo=r(zRe," \u2014 "),bz=n(zRe,"A",{href:!0});var x6t=s(bz);OJo=r(x6t,"BartForQuestionAnswering"),x6t.forEach(t),VJo=r(zRe," (BART model)"),zRe.forEach(t),XJo=i(X),Zv=n(X,"LI",{});var QRe=s(Zv);Tue=n(QRe,"STRONG",{});var $6t=s(Tue);zJo=r($6t,"bert"),$6t.forEach(t),QJo=r(QRe," \u2014 "),vz=n(QRe,"A",{href:!0});var k6t=s(vz);WJo=r(k6t,"BertForQuestionAnswering"),k6t.forEach(t),HJo=r(QRe," (BERT model)"),QRe.forEach(t),UJo=i(X),eF=n(X,"LI",{});var WRe=s(eF);Mue=n(WRe,"STRONG",{});var S6t=s(Mue);JJo=r(S6t,"big_bird"),S6t.forEach(t),YJo=r(WRe," \u2014 "),Fz=n(WRe,"A",{href:!0});var R6t=s(Fz);KJo=r(R6t,"BigBirdForQuestionAnswering"),R6t.forEach(t),ZJo=r(WRe," (BigBird model)"),WRe.forEach(t),eYo=i(X),oF=n(X,"LI",{});var HRe=s(oF);Eue=n(HRe,"STRONG",{});var P6t=s(Eue);oYo=r(P6t,"bigbird_pegasus"),P6t.forEach(t),rYo=r(HRe," \u2014 "),Tz=n(HRe,"A",{href:!0});var B6t=s(Tz);tYo=r(B6t,"BigBirdPegasusForQuestionAnswering"),B6t.forEach(t),aYo=r(HRe," (BigBird-Pegasus model)"),HRe.forEach(t),nYo=i(X),rF=n(X,"LI",{});var URe=s(rF);Cue=n(URe,"STRONG",{});var I6t=s(Cue);sYo=r(I6t,"camembert"),I6t.forEach(t),lYo=r(URe," \u2014 "),Mz=n(URe,"A",{href:!0});var N6t=s(Mz);iYo=r(N6t,"CamembertForQuestionAnswering"),N6t.forEach(t),dYo=r(URe," (CamemBERT model)"),URe.forEach(t),cYo=i(X),tF=n(X,"LI",{});var JRe=s(tF);wue=n(JRe,"STRONG",{});var q6t=s(wue);fYo=r(q6t,"canine"),q6t.forEach(t),mYo=r(JRe," \u2014 "),Ez=n(JRe,"A",{href:!0});var j6t=s(Ez);gYo=r(j6t,"CanineForQuestionAnswering"),j6t.forEach(t),hYo=r(JRe," (CANINE model)"),JRe.forEach(t),pYo=i(X),aF=n(X,"LI",{});var YRe=s(aF);Aue=n(YRe,"STRONG",{});var D6t=s(Aue);_Yo=r(D6t,"convbert"),D6t.forEach(t),uYo=r(YRe," \u2014 "),Cz=n(YRe,"A",{href:!0});var G6t=s(Cz);bYo=r(G6t,"ConvBertForQuestionAnswering"),G6t.forEach(t),vYo=r(YRe," (ConvBERT model)"),YRe.forEach(t),FYo=i(X),nF=n(X,"LI",{});var KRe=s(nF);Lue=n(KRe,"STRONG",{});var O6t=s(Lue);TYo=r(O6t,"data2vec-text"),O6t.forEach(t),MYo=r(KRe," \u2014 "),wz=n(KRe,"A",{href:!0});var V6t=s(wz);EYo=r(V6t,"Data2VecTextForQuestionAnswering"),V6t.forEach(t),CYo=r(KRe," (Data2VecText model)"),KRe.forEach(t),wYo=i(X),sF=n(X,"LI",{});var ZRe=s(sF);yue=n(ZRe,"STRONG",{});var X6t=s(yue);AYo=r(X6t,"deberta"),X6t.forEach(t),LYo=r(ZRe," \u2014 "),Az=n(ZRe,"A",{href:!0});var z6t=s(Az);yYo=r(z6t,"DebertaForQuestionAnswering"),z6t.forEach(t),xYo=r(ZRe," (DeBERTa model)"),ZRe.forEach(t),$Yo=i(X),lF=n(X,"LI",{});var ePe=s(lF);xue=n(ePe,"STRONG",{});var Q6t=s(xue);kYo=r(Q6t,"deberta-v2"),Q6t.forEach(t),SYo=r(ePe," \u2014 "),Lz=n(ePe,"A",{href:!0});var W6t=s(Lz);RYo=r(W6t,"DebertaV2ForQuestionAnswering"),W6t.forEach(t),PYo=r(ePe," (DeBERTa-v2 model)"),ePe.forEach(t),BYo=i(X),iF=n(X,"LI",{});var oPe=s(iF);$ue=n(oPe,"STRONG",{});var H6t=s($ue);IYo=r(H6t,"distilbert"),H6t.forEach(t),NYo=r(oPe," \u2014 "),yz=n(oPe,"A",{href:!0});var U6t=s(yz);qYo=r(U6t,"DistilBertForQuestionAnswering"),U6t.forEach(t),jYo=r(oPe," (DistilBERT model)"),oPe.forEach(t),DYo=i(X),dF=n(X,"LI",{});var rPe=s(dF);kue=n(rPe,"STRONG",{});var J6t=s(kue);GYo=r(J6t,"electra"),J6t.forEach(t),OYo=r(rPe," \u2014 "),xz=n(rPe,"A",{href:!0});var Y6t=s(xz);VYo=r(Y6t,"ElectraForQuestionAnswering"),Y6t.forEach(t),XYo=r(rPe," (ELECTRA model)"),rPe.forEach(t),zYo=i(X),cF=n(X,"LI",{});var tPe=s(cF);Sue=n(tPe,"STRONG",{});var K6t=s(Sue);QYo=r(K6t,"flaubert"),K6t.forEach(t),WYo=r(tPe," \u2014 "),$z=n(tPe,"A",{href:!0});var Z6t=s($z);HYo=r(Z6t,"FlaubertForQuestionAnsweringSimple"),Z6t.forEach(t),UYo=r(tPe," (FlauBERT model)"),tPe.forEach(t),JYo=i(X),fF=n(X,"LI",{});var aPe=s(fF);Rue=n(aPe,"STRONG",{});var eTt=s(Rue);YYo=r(eTt,"fnet"),eTt.forEach(t),KYo=r(aPe," \u2014 "),kz=n(aPe,"A",{href:!0});var oTt=s(kz);ZYo=r(oTt,"FNetForQuestionAnswering"),oTt.forEach(t),eKo=r(aPe," (FNet model)"),aPe.forEach(t),oKo=i(X),mF=n(X,"LI",{});var nPe=s(mF);Pue=n(nPe,"STRONG",{});var rTt=s(Pue);rKo=r(rTt,"funnel"),rTt.forEach(t),tKo=r(nPe," \u2014 "),Sz=n(nPe,"A",{href:!0});var tTt=s(Sz);aKo=r(tTt,"FunnelForQuestionAnswering"),tTt.forEach(t),nKo=r(nPe," (Funnel Transformer model)"),nPe.forEach(t),sKo=i(X),gF=n(X,"LI",{});var sPe=s(gF);Bue=n(sPe,"STRONG",{});var aTt=s(Bue);lKo=r(aTt,"gptj"),aTt.forEach(t),iKo=r(sPe," \u2014 "),Rz=n(sPe,"A",{href:!0});var nTt=s(Rz);dKo=r(nTt,"GPTJForQuestionAnswering"),nTt.forEach(t),cKo=r(sPe," (GPT-J model)"),sPe.forEach(t),fKo=i(X),hF=n(X,"LI",{});var lPe=s(hF);Iue=n(lPe,"STRONG",{});var sTt=s(Iue);mKo=r(sTt,"ibert"),sTt.forEach(t),gKo=r(lPe," \u2014 "),Pz=n(lPe,"A",{href:!0});var lTt=s(Pz);hKo=r(lTt,"IBertForQuestionAnswering"),lTt.forEach(t),pKo=r(lPe," (I-BERT model)"),lPe.forEach(t),_Ko=i(X),pF=n(X,"LI",{});var iPe=s(pF);Nue=n(iPe,"STRONG",{});var iTt=s(Nue);uKo=r(iTt,"layoutlmv2"),iTt.forEach(t),bKo=r(iPe," \u2014 "),Bz=n(iPe,"A",{href:!0});var dTt=s(Bz);vKo=r(dTt,"LayoutLMv2ForQuestionAnswering"),dTt.forEach(t),FKo=r(iPe," (LayoutLMv2 model)"),iPe.forEach(t),TKo=i(X),_F=n(X,"LI",{});var dPe=s(_F);que=n(dPe,"STRONG",{});var cTt=s(que);MKo=r(cTt,"layoutlmv3"),cTt.forEach(t),EKo=r(dPe," \u2014 "),Iz=n(dPe,"A",{href:!0});var fTt=s(Iz);CKo=r(fTt,"LayoutLMv3ForQuestionAnswering"),fTt.forEach(t),wKo=r(dPe," (LayoutLMv3 model)"),dPe.forEach(t),AKo=i(X),uF=n(X,"LI",{});var cPe=s(uF);jue=n(cPe,"STRONG",{});var mTt=s(jue);LKo=r(mTt,"led"),mTt.forEach(t),yKo=r(cPe," \u2014 "),Nz=n(cPe,"A",{href:!0});var gTt=s(Nz);xKo=r(gTt,"LEDForQuestionAnswering"),gTt.forEach(t),$Ko=r(cPe," (LED model)"),cPe.forEach(t),kKo=i(X),bF=n(X,"LI",{});var fPe=s(bF);Due=n(fPe,"STRONG",{});var hTt=s(Due);SKo=r(hTt,"longformer"),hTt.forEach(t),RKo=r(fPe," \u2014 "),qz=n(fPe,"A",{href:!0});var pTt=s(qz);PKo=r(pTt,"LongformerForQuestionAnswering"),pTt.forEach(t),BKo=r(fPe," (Longformer model)"),fPe.forEach(t),IKo=i(X),vF=n(X,"LI",{});var mPe=s(vF);Gue=n(mPe,"STRONG",{});var _Tt=s(Gue);NKo=r(_Tt,"lxmert"),_Tt.forEach(t),qKo=r(mPe," \u2014 "),jz=n(mPe,"A",{href:!0});var uTt=s(jz);jKo=r(uTt,"LxmertForQuestionAnswering"),uTt.forEach(t),DKo=r(mPe," (LXMERT model)"),mPe.forEach(t),GKo=i(X),FF=n(X,"LI",{});var gPe=s(FF);Oue=n(gPe,"STRONG",{});var bTt=s(Oue);OKo=r(bTt,"mbart"),bTt.forEach(t),VKo=r(gPe," \u2014 "),Dz=n(gPe,"A",{href:!0});var vTt=s(Dz);XKo=r(vTt,"MBartForQuestionAnswering"),vTt.forEach(t),zKo=r(gPe," (mBART model)"),gPe.forEach(t),QKo=i(X),TF=n(X,"LI",{});var hPe=s(TF);Vue=n(hPe,"STRONG",{});var FTt=s(Vue);WKo=r(FTt,"megatron-bert"),FTt.forEach(t),HKo=r(hPe," \u2014 "),Gz=n(hPe,"A",{href:!0});var TTt=s(Gz);UKo=r(TTt,"MegatronBertForQuestionAnswering"),TTt.forEach(t),JKo=r(hPe," (Megatron-BERT model)"),hPe.forEach(t),YKo=i(X),MF=n(X,"LI",{});var pPe=s(MF);Xue=n(pPe,"STRONG",{});var MTt=s(Xue);KKo=r(MTt,"mobilebert"),MTt.forEach(t),ZKo=r(pPe," \u2014 "),Oz=n(pPe,"A",{href:!0});var ETt=s(Oz);eZo=r(ETt,"MobileBertForQuestionAnswering"),ETt.forEach(t),oZo=r(pPe," (MobileBERT model)"),pPe.forEach(t),rZo=i(X),EF=n(X,"LI",{});var _Pe=s(EF);zue=n(_Pe,"STRONG",{});var CTt=s(zue);tZo=r(CTt,"mpnet"),CTt.forEach(t),aZo=r(_Pe," \u2014 "),Vz=n(_Pe,"A",{href:!0});var wTt=s(Vz);nZo=r(wTt,"MPNetForQuestionAnswering"),wTt.forEach(t),sZo=r(_Pe," (MPNet model)"),_Pe.forEach(t),lZo=i(X),CF=n(X,"LI",{});var uPe=s(CF);Que=n(uPe,"STRONG",{});var ATt=s(Que);iZo=r(ATt,"nezha"),ATt.forEach(t),dZo=r(uPe," \u2014 "),Xz=n(uPe,"A",{href:!0});var LTt=s(Xz);cZo=r(LTt,"NezhaForQuestionAnswering"),LTt.forEach(t),fZo=r(uPe," (Nezha model)"),uPe.forEach(t),mZo=i(X),wF=n(X,"LI",{});var bPe=s(wF);Wue=n(bPe,"STRONG",{});var yTt=s(Wue);gZo=r(yTt,"nystromformer"),yTt.forEach(t),hZo=r(bPe," \u2014 "),zz=n(bPe,"A",{href:!0});var xTt=s(zz);pZo=r(xTt,"NystromformerForQuestionAnswering"),xTt.forEach(t),_Zo=r(bPe," (Nystr\xF6mformer model)"),bPe.forEach(t),uZo=i(X),AF=n(X,"LI",{});var vPe=s(AF);Hue=n(vPe,"STRONG",{});var $Tt=s(Hue);bZo=r($Tt,"qdqbert"),$Tt.forEach(t),vZo=r(vPe," \u2014 "),Qz=n(vPe,"A",{href:!0});var kTt=s(Qz);FZo=r(kTt,"QDQBertForQuestionAnswering"),kTt.forEach(t),TZo=r(vPe," (QDQBert model)"),vPe.forEach(t),MZo=i(X),LF=n(X,"LI",{});var FPe=s(LF);Uue=n(FPe,"STRONG",{});var STt=s(Uue);EZo=r(STt,"reformer"),STt.forEach(t),CZo=r(FPe," \u2014 "),Wz=n(FPe,"A",{href:!0});var RTt=s(Wz);wZo=r(RTt,"ReformerForQuestionAnswering"),RTt.forEach(t),AZo=r(FPe," (Reformer model)"),FPe.forEach(t),LZo=i(X),yF=n(X,"LI",{});var TPe=s(yF);Jue=n(TPe,"STRONG",{});var PTt=s(Jue);yZo=r(PTt,"rembert"),PTt.forEach(t),xZo=r(TPe," \u2014 "),Hz=n(TPe,"A",{href:!0});var BTt=s(Hz);$Zo=r(BTt,"RemBertForQuestionAnswering"),BTt.forEach(t),kZo=r(TPe," (RemBERT model)"),TPe.forEach(t),SZo=i(X),xF=n(X,"LI",{});var MPe=s(xF);Yue=n(MPe,"STRONG",{});var ITt=s(Yue);RZo=r(ITt,"roberta"),ITt.forEach(t),PZo=r(MPe," \u2014 "),Uz=n(MPe,"A",{href:!0});var NTt=s(Uz);BZo=r(NTt,"RobertaForQuestionAnswering"),NTt.forEach(t),IZo=r(MPe," (RoBERTa model)"),MPe.forEach(t),NZo=i(X),$F=n(X,"LI",{});var EPe=s($F);Kue=n(EPe,"STRONG",{});var qTt=s(Kue);qZo=r(qTt,"roformer"),qTt.forEach(t),jZo=r(EPe," \u2014 "),Jz=n(EPe,"A",{href:!0});var jTt=s(Jz);DZo=r(jTt,"RoFormerForQuestionAnswering"),jTt.forEach(t),GZo=r(EPe," (RoFormer model)"),EPe.forEach(t),OZo=i(X),kF=n(X,"LI",{});var CPe=s(kF);Zue=n(CPe,"STRONG",{});var DTt=s(Zue);VZo=r(DTt,"splinter"),DTt.forEach(t),XZo=r(CPe," \u2014 "),Yz=n(CPe,"A",{href:!0});var GTt=s(Yz);zZo=r(GTt,"SplinterForQuestionAnswering"),GTt.forEach(t),QZo=r(CPe," (Splinter model)"),CPe.forEach(t),WZo=i(X),SF=n(X,"LI",{});var wPe=s(SF);e7e=n(wPe,"STRONG",{});var OTt=s(e7e);HZo=r(OTt,"squeezebert"),OTt.forEach(t),UZo=r(wPe," \u2014 "),Kz=n(wPe,"A",{href:!0});var VTt=s(Kz);JZo=r(VTt,"SqueezeBertForQuestionAnswering"),VTt.forEach(t),YZo=r(wPe," (SqueezeBERT model)"),wPe.forEach(t),KZo=i(X),RF=n(X,"LI",{});var APe=s(RF);o7e=n(APe,"STRONG",{});var XTt=s(o7e);ZZo=r(XTt,"xlm"),XTt.forEach(t),eer=r(APe," \u2014 "),Zz=n(APe,"A",{href:!0});var zTt=s(Zz);oer=r(zTt,"XLMForQuestionAnsweringSimple"),zTt.forEach(t),rer=r(APe," (XLM model)"),APe.forEach(t),ter=i(X),PF=n(X,"LI",{});var LPe=s(PF);r7e=n(LPe,"STRONG",{});var QTt=s(r7e);aer=r(QTt,"xlm-roberta"),QTt.forEach(t),ner=r(LPe," \u2014 "),eQ=n(LPe,"A",{href:!0});var WTt=s(eQ);ser=r(WTt,"XLMRobertaForQuestionAnswering"),WTt.forEach(t),ler=r(LPe," (XLM-RoBERTa model)"),LPe.forEach(t),ier=i(X),BF=n(X,"LI",{});var yPe=s(BF);t7e=n(yPe,"STRONG",{});var HTt=s(t7e);der=r(HTt,"xlm-roberta-xl"),HTt.forEach(t),cer=r(yPe," \u2014 "),oQ=n(yPe,"A",{href:!0});var UTt=s(oQ);fer=r(UTt,"XLMRobertaXLForQuestionAnswering"),UTt.forEach(t),mer=r(yPe," (XLM-RoBERTa-XL model)"),yPe.forEach(t),ger=i(X),IF=n(X,"LI",{});var xPe=s(IF);a7e=n(xPe,"STRONG",{});var JTt=s(a7e);her=r(JTt,"xlnet"),JTt.forEach(t),per=r(xPe," \u2014 "),rQ=n(xPe,"A",{href:!0});var YTt=s(rQ);_er=r(YTt,"XLNetForQuestionAnsweringSimple"),YTt.forEach(t),uer=r(xPe," (XLNet model)"),xPe.forEach(t),ber=i(X),NF=n(X,"LI",{});var $Pe=s(NF);n7e=n($Pe,"STRONG",{});var KTt=s(n7e);ver=r(KTt,"yoso"),KTt.forEach(t),Fer=r($Pe," \u2014 "),tQ=n($Pe,"A",{href:!0});var ZTt=s(tQ);Ter=r(ZTt,"YosoForQuestionAnswering"),ZTt.forEach(t),Mer=r($Pe," (YOSO model)"),$Pe.forEach(t),X.forEach(t),Eer=i(ha),qF=n(ha,"P",{});var kPe=s(qF);Cer=r(kPe,"The model is set in evaluation mode by default using "),s7e=n(kPe,"CODE",{});var eMt=s(s7e);wer=r(eMt,"model.eval()"),eMt.forEach(t),Aer=r(kPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l7e=n(kPe,"CODE",{});var oMt=s(l7e);Ler=r(oMt,"model.train()"),oMt.forEach(t),kPe.forEach(t),yer=i(ha),T(jF.$$.fragment,ha),ha.forEach(t),sl.forEach(t),bOe=i(f),fd=n(f,"H2",{class:!0});var CXe=s(fd);DF=n(CXe,"A",{id:!0,class:!0,href:!0});var rMt=s(DF);i7e=n(rMt,"SPAN",{});var tMt=s(i7e);T(Yy.$$.fragment,tMt),tMt.forEach(t),rMt.forEach(t),xer=i(CXe),d7e=n(CXe,"SPAN",{});var aMt=s(d7e);$er=r(aMt,"AutoModelForTableQuestionAnswering"),aMt.forEach(t),CXe.forEach(t),vOe=i(f),Do=n(f,"DIV",{class:!0});var ll=s(Do);T(Ky.$$.fragment,ll),ker=i(ll),md=n(ll,"P",{});var joe=s(md);Ser=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=n(joe,"A",{href:!0});var nMt=s(aQ);Rer=r(nMt,"from_pretrained()"),nMt.forEach(t),Per=r(joe," class method or the "),nQ=n(joe,"A",{href:!0});var sMt=s(nQ);Ber=r(sMt,"from_config()"),sMt.forEach(t),Ier=r(joe,` class
method.`),joe.forEach(t),Ner=i(ll),Zy=n(ll,"P",{});var wXe=s(Zy);qer=r(wXe,"This class cannot be instantiated directly using "),c7e=n(wXe,"CODE",{});var lMt=s(c7e);jer=r(lMt,"__init__()"),lMt.forEach(t),Der=r(wXe," (throws an error)."),wXe.forEach(t),Ger=i(ll),pt=n(ll,"DIV",{class:!0});var Yw=s(pt);T(e8.$$.fragment,Yw),Oer=i(Yw),f7e=n(Yw,"P",{});var iMt=s(f7e);Ver=r(iMt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),iMt.forEach(t),Xer=i(Yw),gd=n(Yw,"P",{});var Doe=s(gd);zer=r(Doe,`Note:
Loading a model from its configuration file does `),m7e=n(Doe,"STRONG",{});var dMt=s(m7e);Qer=r(dMt,"not"),dMt.forEach(t),Wer=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=n(Doe,"A",{href:!0});var cMt=s(sQ);Her=r(cMt,"from_pretrained()"),cMt.forEach(t),Uer=r(Doe," to load the model weights."),Doe.forEach(t),Jer=i(Yw),T(GF.$$.fragment,Yw),Yw.forEach(t),Yer=i(ll),so=n(ll,"DIV",{class:!0});var pa=s(so);T(o8.$$.fragment,pa),Ker=i(pa),g7e=n(pa,"P",{});var fMt=s(g7e);Zer=r(fMt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),fMt.forEach(t),eor=i(pa),Va=n(pa,"P",{});var Kw=s(Va);oor=r(Kw,"The model class to instantiate is selected based on the "),h7e=n(Kw,"CODE",{});var mMt=s(h7e);ror=r(mMt,"model_type"),mMt.forEach(t),tor=r(Kw,` property of the config object (either
passed as an argument or loaded from `),p7e=n(Kw,"CODE",{});var gMt=s(p7e);aor=r(gMt,"pretrained_model_name_or_path"),gMt.forEach(t),nor=r(Kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_7e=n(Kw,"CODE",{});var hMt=s(_7e);sor=r(hMt,"pretrained_model_name_or_path"),hMt.forEach(t),lor=r(Kw,":"),Kw.forEach(t),ior=i(pa),u7e=n(pa,"UL",{});var pMt=s(u7e);OF=n(pMt,"LI",{});var SPe=s(OF);b7e=n(SPe,"STRONG",{});var _Mt=s(b7e);dor=r(_Mt,"tapas"),_Mt.forEach(t),cor=r(SPe," \u2014 "),lQ=n(SPe,"A",{href:!0});var uMt=s(lQ);mor=r(uMt,"TapasForQuestionAnswering"),uMt.forEach(t),gor=r(SPe," (TAPAS model)"),SPe.forEach(t),pMt.forEach(t),hor=i(pa),VF=n(pa,"P",{});var RPe=s(VF);por=r(RPe,"The model is set in evaluation mode by default using "),v7e=n(RPe,"CODE",{});var bMt=s(v7e);_or=r(bMt,"model.eval()"),bMt.forEach(t),uor=r(RPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F7e=n(RPe,"CODE",{});var vMt=s(F7e);bor=r(vMt,"model.train()"),vMt.forEach(t),RPe.forEach(t),vor=i(pa),T(XF.$$.fragment,pa),pa.forEach(t),ll.forEach(t),FOe=i(f),hd=n(f,"H2",{class:!0});var AXe=s(hd);zF=n(AXe,"A",{id:!0,class:!0,href:!0});var FMt=s(zF);T7e=n(FMt,"SPAN",{});var TMt=s(T7e);T(r8.$$.fragment,TMt),TMt.forEach(t),FMt.forEach(t),For=i(AXe),M7e=n(AXe,"SPAN",{});var MMt=s(M7e);Tor=r(MMt,"AutoModelForImageClassification"),MMt.forEach(t),AXe.forEach(t),TOe=i(f),Go=n(f,"DIV",{class:!0});var il=s(Go);T(t8.$$.fragment,il),Mor=i(il),pd=n(il,"P",{});var Goe=s(pd);Eor=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=n(Goe,"A",{href:!0});var EMt=s(iQ);Cor=r(EMt,"from_pretrained()"),EMt.forEach(t),wor=r(Goe," class method or the "),dQ=n(Goe,"A",{href:!0});var CMt=s(dQ);Aor=r(CMt,"from_config()"),CMt.forEach(t),Lor=r(Goe,` class
method.`),Goe.forEach(t),yor=i(il),a8=n(il,"P",{});var LXe=s(a8);xor=r(LXe,"This class cannot be instantiated directly using "),E7e=n(LXe,"CODE",{});var wMt=s(E7e);$or=r(wMt,"__init__()"),wMt.forEach(t),kor=r(LXe," (throws an error)."),LXe.forEach(t),Sor=i(il),_t=n(il,"DIV",{class:!0});var Zw=s(_t);T(n8.$$.fragment,Zw),Ror=i(Zw),C7e=n(Zw,"P",{});var AMt=s(C7e);Por=r(AMt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),AMt.forEach(t),Bor=i(Zw),_d=n(Zw,"P",{});var Ooe=s(_d);Ior=r(Ooe,`Note:
Loading a model from its configuration file does `),w7e=n(Ooe,"STRONG",{});var LMt=s(w7e);Nor=r(LMt,"not"),LMt.forEach(t),qor=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Ooe,"A",{href:!0});var yMt=s(cQ);jor=r(yMt,"from_pretrained()"),yMt.forEach(t),Dor=r(Ooe," to load the model weights."),Ooe.forEach(t),Gor=i(Zw),T(QF.$$.fragment,Zw),Zw.forEach(t),Oor=i(il),lo=n(il,"DIV",{class:!0});var _a=s(lo);T(s8.$$.fragment,_a),Vor=i(_a),A7e=n(_a,"P",{});var xMt=s(A7e);Xor=r(xMt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),xMt.forEach(t),zor=i(_a),Xa=n(_a,"P",{});var eA=s(Xa);Qor=r(eA,"The model class to instantiate is selected based on the "),L7e=n(eA,"CODE",{});var $Mt=s(L7e);Wor=r($Mt,"model_type"),$Mt.forEach(t),Hor=r(eA,` property of the config object (either
passed as an argument or loaded from `),y7e=n(eA,"CODE",{});var kMt=s(y7e);Uor=r(kMt,"pretrained_model_name_or_path"),kMt.forEach(t),Jor=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x7e=n(eA,"CODE",{});var SMt=s(x7e);Yor=r(SMt,"pretrained_model_name_or_path"),SMt.forEach(t),Kor=r(eA,":"),eA.forEach(t),Zor=i(_a),Fe=n(_a,"UL",{});var Te=s(Fe);WF=n(Te,"LI",{});var PPe=s(WF);$7e=n(PPe,"STRONG",{});var RMt=s($7e);err=r(RMt,"beit"),RMt.forEach(t),orr=r(PPe," \u2014 "),fQ=n(PPe,"A",{href:!0});var PMt=s(fQ);rrr=r(PMt,"BeitForImageClassification"),PMt.forEach(t),trr=r(PPe," (BEiT model)"),PPe.forEach(t),arr=i(Te),HF=n(Te,"LI",{});var BPe=s(HF);k7e=n(BPe,"STRONG",{});var BMt=s(k7e);nrr=r(BMt,"convnext"),BMt.forEach(t),srr=r(BPe," \u2014 "),mQ=n(BPe,"A",{href:!0});var IMt=s(mQ);lrr=r(IMt,"ConvNextForImageClassification"),IMt.forEach(t),irr=r(BPe," (ConvNeXT model)"),BPe.forEach(t),drr=i(Te),UF=n(Te,"LI",{});var IPe=s(UF);S7e=n(IPe,"STRONG",{});var NMt=s(S7e);crr=r(NMt,"cvt"),NMt.forEach(t),frr=r(IPe," \u2014 "),gQ=n(IPe,"A",{href:!0});var qMt=s(gQ);mrr=r(qMt,"CvtForImageClassification"),qMt.forEach(t),grr=r(IPe," (CvT model)"),IPe.forEach(t),hrr=i(Te),JF=n(Te,"LI",{});var NPe=s(JF);R7e=n(NPe,"STRONG",{});var jMt=s(R7e);prr=r(jMt,"data2vec-vision"),jMt.forEach(t),_rr=r(NPe," \u2014 "),hQ=n(NPe,"A",{href:!0});var DMt=s(hQ);urr=r(DMt,"Data2VecVisionForImageClassification"),DMt.forEach(t),brr=r(NPe," (Data2VecVision model)"),NPe.forEach(t),vrr=i(Te),Xs=n(Te,"LI",{});var Zk=s(Xs);P7e=n(Zk,"STRONG",{});var GMt=s(P7e);Frr=r(GMt,"deit"),GMt.forEach(t),Trr=r(Zk," \u2014 "),pQ=n(Zk,"A",{href:!0});var OMt=s(pQ);Mrr=r(OMt,"DeiTForImageClassification"),OMt.forEach(t),Err=r(Zk," or "),_Q=n(Zk,"A",{href:!0});var VMt=s(_Q);Crr=r(VMt,"DeiTForImageClassificationWithTeacher"),VMt.forEach(t),wrr=r(Zk," (DeiT model)"),Zk.forEach(t),Arr=i(Te),YF=n(Te,"LI",{});var qPe=s(YF);B7e=n(qPe,"STRONG",{});var XMt=s(B7e);Lrr=r(XMt,"imagegpt"),XMt.forEach(t),yrr=r(qPe," \u2014 "),uQ=n(qPe,"A",{href:!0});var zMt=s(uQ);xrr=r(zMt,"ImageGPTForImageClassification"),zMt.forEach(t),$rr=r(qPe," (ImageGPT model)"),qPe.forEach(t),krr=i(Te),zs=n(Te,"LI",{});var eS=s(zs);I7e=n(eS,"STRONG",{});var QMt=s(I7e);Srr=r(QMt,"levit"),QMt.forEach(t),Rrr=r(eS," \u2014 "),bQ=n(eS,"A",{href:!0});var WMt=s(bQ);Prr=r(WMt,"LevitForImageClassification"),WMt.forEach(t),Brr=r(eS," or "),vQ=n(eS,"A",{href:!0});var HMt=s(vQ);Irr=r(HMt,"LevitForImageClassificationWithTeacher"),HMt.forEach(t),Nrr=r(eS," (LeViT model)"),eS.forEach(t),qrr=i(Te),ut=n(Te,"LI",{});var Lf=s(ut);N7e=n(Lf,"STRONG",{});var UMt=s(N7e);jrr=r(UMt,"perceiver"),UMt.forEach(t),Drr=r(Lf," \u2014 "),FQ=n(Lf,"A",{href:!0});var JMt=s(FQ);Grr=r(JMt,"PerceiverForImageClassificationLearned"),JMt.forEach(t),Orr=r(Lf," or "),TQ=n(Lf,"A",{href:!0});var YMt=s(TQ);Vrr=r(YMt,"PerceiverForImageClassificationFourier"),YMt.forEach(t),Xrr=r(Lf," or "),MQ=n(Lf,"A",{href:!0});var KMt=s(MQ);zrr=r(KMt,"PerceiverForImageClassificationConvProcessing"),KMt.forEach(t),Qrr=r(Lf," (Perceiver model)"),Lf.forEach(t),Wrr=i(Te),KF=n(Te,"LI",{});var jPe=s(KF);q7e=n(jPe,"STRONG",{});var ZMt=s(q7e);Hrr=r(ZMt,"poolformer"),ZMt.forEach(t),Urr=r(jPe," \u2014 "),EQ=n(jPe,"A",{href:!0});var eEt=s(EQ);Jrr=r(eEt,"PoolFormerForImageClassification"),eEt.forEach(t),Yrr=r(jPe," (PoolFormer model)"),jPe.forEach(t),Krr=i(Te),ZF=n(Te,"LI",{});var DPe=s(ZF);j7e=n(DPe,"STRONG",{});var oEt=s(j7e);Zrr=r(oEt,"regnet"),oEt.forEach(t),etr=r(DPe," \u2014 "),CQ=n(DPe,"A",{href:!0});var rEt=s(CQ);otr=r(rEt,"RegNetForImageClassification"),rEt.forEach(t),rtr=r(DPe," (RegNet model)"),DPe.forEach(t),ttr=i(Te),e6=n(Te,"LI",{});var GPe=s(e6);D7e=n(GPe,"STRONG",{});var tEt=s(D7e);atr=r(tEt,"resnet"),tEt.forEach(t),ntr=r(GPe," \u2014 "),wQ=n(GPe,"A",{href:!0});var aEt=s(wQ);str=r(aEt,"ResNetForImageClassification"),aEt.forEach(t),ltr=r(GPe," (ResNet model)"),GPe.forEach(t),itr=i(Te),o6=n(Te,"LI",{});var OPe=s(o6);G7e=n(OPe,"STRONG",{});var nEt=s(G7e);dtr=r(nEt,"segformer"),nEt.forEach(t),ctr=r(OPe," \u2014 "),AQ=n(OPe,"A",{href:!0});var sEt=s(AQ);ftr=r(sEt,"SegformerForImageClassification"),sEt.forEach(t),mtr=r(OPe," (SegFormer model)"),OPe.forEach(t),gtr=i(Te),r6=n(Te,"LI",{});var VPe=s(r6);O7e=n(VPe,"STRONG",{});var lEt=s(O7e);htr=r(lEt,"swin"),lEt.forEach(t),ptr=r(VPe," \u2014 "),LQ=n(VPe,"A",{href:!0});var iEt=s(LQ);_tr=r(iEt,"SwinForImageClassification"),iEt.forEach(t),utr=r(VPe," (Swin Transformer model)"),VPe.forEach(t),btr=i(Te),t6=n(Te,"LI",{});var XPe=s(t6);V7e=n(XPe,"STRONG",{});var dEt=s(V7e);vtr=r(dEt,"van"),dEt.forEach(t),Ftr=r(XPe," \u2014 "),yQ=n(XPe,"A",{href:!0});var cEt=s(yQ);Ttr=r(cEt,"VanForImageClassification"),cEt.forEach(t),Mtr=r(XPe," (VAN model)"),XPe.forEach(t),Etr=i(Te),a6=n(Te,"LI",{});var zPe=s(a6);X7e=n(zPe,"STRONG",{});var fEt=s(X7e);Ctr=r(fEt,"vit"),fEt.forEach(t),wtr=r(zPe," \u2014 "),xQ=n(zPe,"A",{href:!0});var mEt=s(xQ);Atr=r(mEt,"ViTForImageClassification"),mEt.forEach(t),Ltr=r(zPe," (ViT model)"),zPe.forEach(t),Te.forEach(t),ytr=i(_a),n6=n(_a,"P",{});var QPe=s(n6);xtr=r(QPe,"The model is set in evaluation mode by default using "),z7e=n(QPe,"CODE",{});var gEt=s(z7e);$tr=r(gEt,"model.eval()"),gEt.forEach(t),ktr=r(QPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q7e=n(QPe,"CODE",{});var hEt=s(Q7e);Str=r(hEt,"model.train()"),hEt.forEach(t),QPe.forEach(t),Rtr=i(_a),T(s6.$$.fragment,_a),_a.forEach(t),il.forEach(t),MOe=i(f),ud=n(f,"H2",{class:!0});var yXe=s(ud);l6=n(yXe,"A",{id:!0,class:!0,href:!0});var pEt=s(l6);W7e=n(pEt,"SPAN",{});var _Et=s(W7e);T(l8.$$.fragment,_Et),_Et.forEach(t),pEt.forEach(t),Ptr=i(yXe),H7e=n(yXe,"SPAN",{});var uEt=s(H7e);Btr=r(uEt,"AutoModelForVision2Seq"),uEt.forEach(t),yXe.forEach(t),EOe=i(f),Oo=n(f,"DIV",{class:!0});var dl=s(Oo);T(i8.$$.fragment,dl),Itr=i(dl),bd=n(dl,"P",{});var Voe=s(bd);Ntr=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=n(Voe,"A",{href:!0});var bEt=s($Q);qtr=r(bEt,"from_pretrained()"),bEt.forEach(t),jtr=r(Voe," class method or the "),kQ=n(Voe,"A",{href:!0});var vEt=s(kQ);Dtr=r(vEt,"from_config()"),vEt.forEach(t),Gtr=r(Voe,` class
method.`),Voe.forEach(t),Otr=i(dl),d8=n(dl,"P",{});var xXe=s(d8);Vtr=r(xXe,"This class cannot be instantiated directly using "),U7e=n(xXe,"CODE",{});var FEt=s(U7e);Xtr=r(FEt,"__init__()"),FEt.forEach(t),ztr=r(xXe," (throws an error)."),xXe.forEach(t),Qtr=i(dl),bt=n(dl,"DIV",{class:!0});var oA=s(bt);T(c8.$$.fragment,oA),Wtr=i(oA),J7e=n(oA,"P",{});var TEt=s(J7e);Htr=r(TEt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),TEt.forEach(t),Utr=i(oA),vd=n(oA,"P",{});var Xoe=s(vd);Jtr=r(Xoe,`Note:
Loading a model from its configuration file does `),Y7e=n(Xoe,"STRONG",{});var MEt=s(Y7e);Ytr=r(MEt,"not"),MEt.forEach(t),Ktr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(Xoe,"A",{href:!0});var EEt=s(SQ);Ztr=r(EEt,"from_pretrained()"),EEt.forEach(t),ear=r(Xoe," to load the model weights."),Xoe.forEach(t),oar=i(oA),T(i6.$$.fragment,oA),oA.forEach(t),rar=i(dl),io=n(dl,"DIV",{class:!0});var ua=s(io);T(f8.$$.fragment,ua),tar=i(ua),K7e=n(ua,"P",{});var CEt=s(K7e);aar=r(CEt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CEt.forEach(t),nar=i(ua),za=n(ua,"P",{});var rA=s(za);sar=r(rA,"The model class to instantiate is selected based on the "),Z7e=n(rA,"CODE",{});var wEt=s(Z7e);lar=r(wEt,"model_type"),wEt.forEach(t),iar=r(rA,` property of the config object (either
passed as an argument or loaded from `),e1e=n(rA,"CODE",{});var AEt=s(e1e);dar=r(AEt,"pretrained_model_name_or_path"),AEt.forEach(t),car=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o1e=n(rA,"CODE",{});var LEt=s(o1e);far=r(LEt,"pretrained_model_name_or_path"),LEt.forEach(t),mar=r(rA,":"),rA.forEach(t),gar=i(ua),r1e=n(ua,"UL",{});var yEt=s(r1e);d6=n(yEt,"LI",{});var WPe=s(d6);t1e=n(WPe,"STRONG",{});var xEt=s(t1e);har=r(xEt,"vision-encoder-decoder"),xEt.forEach(t),par=r(WPe," \u2014 "),RQ=n(WPe,"A",{href:!0});var $Et=s(RQ);_ar=r($Et,"VisionEncoderDecoderModel"),$Et.forEach(t),uar=r(WPe," (Vision Encoder decoder model)"),WPe.forEach(t),yEt.forEach(t),bar=i(ua),c6=n(ua,"P",{});var HPe=s(c6);Far=r(HPe,"The model is set in evaluation mode by default using "),a1e=n(HPe,"CODE",{});var kEt=s(a1e);Tar=r(kEt,"model.eval()"),kEt.forEach(t),Mar=r(HPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n1e=n(HPe,"CODE",{});var SEt=s(n1e);Ear=r(SEt,"model.train()"),SEt.forEach(t),HPe.forEach(t),Car=i(ua),T(f6.$$.fragment,ua),ua.forEach(t),dl.forEach(t),COe=i(f),Fd=n(f,"H2",{class:!0});var $Xe=s(Fd);m6=n($Xe,"A",{id:!0,class:!0,href:!0});var REt=s(m6);s1e=n(REt,"SPAN",{});var PEt=s(s1e);T(m8.$$.fragment,PEt),PEt.forEach(t),REt.forEach(t),war=i($Xe),l1e=n($Xe,"SPAN",{});var BEt=s(l1e);Aar=r(BEt,"AutoModelForVisualQuestionAnswering"),BEt.forEach(t),$Xe.forEach(t),wOe=i(f),Vo=n(f,"DIV",{class:!0});var cl=s(Vo);T(g8.$$.fragment,cl),Lar=i(cl),Td=n(cl,"P",{});var zoe=s(Td);yar=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=n(zoe,"A",{href:!0});var IEt=s(PQ);xar=r(IEt,"from_pretrained()"),IEt.forEach(t),$ar=r(zoe," class method or the "),BQ=n(zoe,"A",{href:!0});var NEt=s(BQ);kar=r(NEt,"from_config()"),NEt.forEach(t),Sar=r(zoe,` class
method.`),zoe.forEach(t),Rar=i(cl),h8=n(cl,"P",{});var kXe=s(h8);Par=r(kXe,"This class cannot be instantiated directly using "),i1e=n(kXe,"CODE",{});var qEt=s(i1e);Bar=r(qEt,"__init__()"),qEt.forEach(t),Iar=r(kXe," (throws an error)."),kXe.forEach(t),Nar=i(cl),vt=n(cl,"DIV",{class:!0});var tA=s(vt);T(p8.$$.fragment,tA),qar=i(tA),d1e=n(tA,"P",{});var jEt=s(d1e);jar=r(jEt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),jEt.forEach(t),Dar=i(tA),Md=n(tA,"P",{});var Qoe=s(Md);Gar=r(Qoe,`Note:
Loading a model from its configuration file does `),c1e=n(Qoe,"STRONG",{});var DEt=s(c1e);Oar=r(DEt,"not"),DEt.forEach(t),Var=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(Qoe,"A",{href:!0});var GEt=s(IQ);Xar=r(GEt,"from_pretrained()"),GEt.forEach(t),zar=r(Qoe," to load the model weights."),Qoe.forEach(t),Qar=i(tA),T(g6.$$.fragment,tA),tA.forEach(t),War=i(cl),co=n(cl,"DIV",{class:!0});var ba=s(co);T(_8.$$.fragment,ba),Har=i(ba),f1e=n(ba,"P",{});var OEt=s(f1e);Uar=r(OEt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),OEt.forEach(t),Jar=i(ba),Qa=n(ba,"P",{});var aA=s(Qa);Yar=r(aA,"The model class to instantiate is selected based on the "),m1e=n(aA,"CODE",{});var VEt=s(m1e);Kar=r(VEt,"model_type"),VEt.forEach(t),Zar=r(aA,` property of the config object (either
passed as an argument or loaded from `),g1e=n(aA,"CODE",{});var XEt=s(g1e);enr=r(XEt,"pretrained_model_name_or_path"),XEt.forEach(t),onr=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h1e=n(aA,"CODE",{});var zEt=s(h1e);rnr=r(zEt,"pretrained_model_name_or_path"),zEt.forEach(t),tnr=r(aA,":"),aA.forEach(t),anr=i(ba),p1e=n(ba,"UL",{});var QEt=s(p1e);h6=n(QEt,"LI",{});var UPe=s(h6);_1e=n(UPe,"STRONG",{});var WEt=s(_1e);nnr=r(WEt,"vilt"),WEt.forEach(t),snr=r(UPe," \u2014 "),NQ=n(UPe,"A",{href:!0});var HEt=s(NQ);lnr=r(HEt,"ViltForQuestionAnswering"),HEt.forEach(t),inr=r(UPe," (ViLT model)"),UPe.forEach(t),QEt.forEach(t),dnr=i(ba),p6=n(ba,"P",{});var JPe=s(p6);cnr=r(JPe,"The model is set in evaluation mode by default using "),u1e=n(JPe,"CODE",{});var UEt=s(u1e);fnr=r(UEt,"model.eval()"),UEt.forEach(t),mnr=r(JPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b1e=n(JPe,"CODE",{});var JEt=s(b1e);gnr=r(JEt,"model.train()"),JEt.forEach(t),JPe.forEach(t),hnr=i(ba),T(_6.$$.fragment,ba),ba.forEach(t),cl.forEach(t),AOe=i(f),Ed=n(f,"H2",{class:!0});var SXe=s(Ed);u6=n(SXe,"A",{id:!0,class:!0,href:!0});var YEt=s(u6);v1e=n(YEt,"SPAN",{});var KEt=s(v1e);T(u8.$$.fragment,KEt),KEt.forEach(t),YEt.forEach(t),pnr=i(SXe),F1e=n(SXe,"SPAN",{});var ZEt=s(F1e);_nr=r(ZEt,"AutoModelForAudioClassification"),ZEt.forEach(t),SXe.forEach(t),LOe=i(f),Xo=n(f,"DIV",{class:!0});var fl=s(Xo);T(b8.$$.fragment,fl),unr=i(fl),Cd=n(fl,"P",{});var Woe=s(Cd);bnr=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=n(Woe,"A",{href:!0});var e4t=s(qQ);vnr=r(e4t,"from_pretrained()"),e4t.forEach(t),Fnr=r(Woe," class method or the "),jQ=n(Woe,"A",{href:!0});var o4t=s(jQ);Tnr=r(o4t,"from_config()"),o4t.forEach(t),Mnr=r(Woe,` class
method.`),Woe.forEach(t),Enr=i(fl),v8=n(fl,"P",{});var RXe=s(v8);Cnr=r(RXe,"This class cannot be instantiated directly using "),T1e=n(RXe,"CODE",{});var r4t=s(T1e);wnr=r(r4t,"__init__()"),r4t.forEach(t),Anr=r(RXe," (throws an error)."),RXe.forEach(t),Lnr=i(fl),Ft=n(fl,"DIV",{class:!0});var nA=s(Ft);T(F8.$$.fragment,nA),ynr=i(nA),M1e=n(nA,"P",{});var t4t=s(M1e);xnr=r(t4t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),t4t.forEach(t),$nr=i(nA),wd=n(nA,"P",{});var Hoe=s(wd);knr=r(Hoe,`Note:
Loading a model from its configuration file does `),E1e=n(Hoe,"STRONG",{});var a4t=s(E1e);Snr=r(a4t,"not"),a4t.forEach(t),Rnr=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Hoe,"A",{href:!0});var n4t=s(DQ);Pnr=r(n4t,"from_pretrained()"),n4t.forEach(t),Bnr=r(Hoe," to load the model weights."),Hoe.forEach(t),Inr=i(nA),T(b6.$$.fragment,nA),nA.forEach(t),Nnr=i(fl),fo=n(fl,"DIV",{class:!0});var va=s(fo);T(T8.$$.fragment,va),qnr=i(va),C1e=n(va,"P",{});var s4t=s(C1e);jnr=r(s4t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),s4t.forEach(t),Dnr=i(va),Wa=n(va,"P",{});var sA=s(Wa);Gnr=r(sA,"The model class to instantiate is selected based on the "),w1e=n(sA,"CODE",{});var l4t=s(w1e);Onr=r(l4t,"model_type"),l4t.forEach(t),Vnr=r(sA,` property of the config object (either
passed as an argument or loaded from `),A1e=n(sA,"CODE",{});var i4t=s(A1e);Xnr=r(i4t,"pretrained_model_name_or_path"),i4t.forEach(t),znr=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L1e=n(sA,"CODE",{});var d4t=s(L1e);Qnr=r(d4t,"pretrained_model_name_or_path"),d4t.forEach(t),Wnr=r(sA,":"),sA.forEach(t),Hnr=i(va),Pe=n(va,"UL",{});var ze=s(Pe);v6=n(ze,"LI",{});var YPe=s(v6);y1e=n(YPe,"STRONG",{});var c4t=s(y1e);Unr=r(c4t,"data2vec-audio"),c4t.forEach(t),Jnr=r(YPe," \u2014 "),GQ=n(YPe,"A",{href:!0});var f4t=s(GQ);Ynr=r(f4t,"Data2VecAudioForSequenceClassification"),f4t.forEach(t),Knr=r(YPe," (Data2VecAudio model)"),YPe.forEach(t),Znr=i(ze),F6=n(ze,"LI",{});var KPe=s(F6);x1e=n(KPe,"STRONG",{});var m4t=s(x1e);esr=r(m4t,"hubert"),m4t.forEach(t),osr=r(KPe," \u2014 "),OQ=n(KPe,"A",{href:!0});var g4t=s(OQ);rsr=r(g4t,"HubertForSequenceClassification"),g4t.forEach(t),tsr=r(KPe," (Hubert model)"),KPe.forEach(t),asr=i(ze),T6=n(ze,"LI",{});var ZPe=s(T6);$1e=n(ZPe,"STRONG",{});var h4t=s($1e);nsr=r(h4t,"sew"),h4t.forEach(t),ssr=r(ZPe," \u2014 "),VQ=n(ZPe,"A",{href:!0});var p4t=s(VQ);lsr=r(p4t,"SEWForSequenceClassification"),p4t.forEach(t),isr=r(ZPe," (SEW model)"),ZPe.forEach(t),dsr=i(ze),M6=n(ze,"LI",{});var eBe=s(M6);k1e=n(eBe,"STRONG",{});var _4t=s(k1e);csr=r(_4t,"sew-d"),_4t.forEach(t),fsr=r(eBe," \u2014 "),XQ=n(eBe,"A",{href:!0});var u4t=s(XQ);msr=r(u4t,"SEWDForSequenceClassification"),u4t.forEach(t),gsr=r(eBe," (SEW-D model)"),eBe.forEach(t),hsr=i(ze),E6=n(ze,"LI",{});var oBe=s(E6);S1e=n(oBe,"STRONG",{});var b4t=s(S1e);psr=r(b4t,"unispeech"),b4t.forEach(t),_sr=r(oBe," \u2014 "),zQ=n(oBe,"A",{href:!0});var v4t=s(zQ);usr=r(v4t,"UniSpeechForSequenceClassification"),v4t.forEach(t),bsr=r(oBe," (UniSpeech model)"),oBe.forEach(t),vsr=i(ze),C6=n(ze,"LI",{});var rBe=s(C6);R1e=n(rBe,"STRONG",{});var F4t=s(R1e);Fsr=r(F4t,"unispeech-sat"),F4t.forEach(t),Tsr=r(rBe," \u2014 "),QQ=n(rBe,"A",{href:!0});var T4t=s(QQ);Msr=r(T4t,"UniSpeechSatForSequenceClassification"),T4t.forEach(t),Esr=r(rBe," (UniSpeechSat model)"),rBe.forEach(t),Csr=i(ze),w6=n(ze,"LI",{});var tBe=s(w6);P1e=n(tBe,"STRONG",{});var M4t=s(P1e);wsr=r(M4t,"wav2vec2"),M4t.forEach(t),Asr=r(tBe," \u2014 "),WQ=n(tBe,"A",{href:!0});var E4t=s(WQ);Lsr=r(E4t,"Wav2Vec2ForSequenceClassification"),E4t.forEach(t),ysr=r(tBe," (Wav2Vec2 model)"),tBe.forEach(t),xsr=i(ze),A6=n(ze,"LI",{});var aBe=s(A6);B1e=n(aBe,"STRONG",{});var C4t=s(B1e);$sr=r(C4t,"wav2vec2-conformer"),C4t.forEach(t),ksr=r(aBe," \u2014 "),HQ=n(aBe,"A",{href:!0});var w4t=s(HQ);Ssr=r(w4t,"Wav2Vec2ConformerForSequenceClassification"),w4t.forEach(t),Rsr=r(aBe," (Wav2Vec2-Conformer model)"),aBe.forEach(t),Psr=i(ze),L6=n(ze,"LI",{});var nBe=s(L6);I1e=n(nBe,"STRONG",{});var A4t=s(I1e);Bsr=r(A4t,"wavlm"),A4t.forEach(t),Isr=r(nBe," \u2014 "),UQ=n(nBe,"A",{href:!0});var L4t=s(UQ);Nsr=r(L4t,"WavLMForSequenceClassification"),L4t.forEach(t),qsr=r(nBe," (WavLM model)"),nBe.forEach(t),ze.forEach(t),jsr=i(va),y6=n(va,"P",{});var sBe=s(y6);Dsr=r(sBe,"The model is set in evaluation mode by default using "),N1e=n(sBe,"CODE",{});var y4t=s(N1e);Gsr=r(y4t,"model.eval()"),y4t.forEach(t),Osr=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q1e=n(sBe,"CODE",{});var x4t=s(q1e);Vsr=r(x4t,"model.train()"),x4t.forEach(t),sBe.forEach(t),Xsr=i(va),T(x6.$$.fragment,va),va.forEach(t),fl.forEach(t),yOe=i(f),Ad=n(f,"H2",{class:!0});var PXe=s(Ad);$6=n(PXe,"A",{id:!0,class:!0,href:!0});var $4t=s($6);j1e=n($4t,"SPAN",{});var k4t=s(j1e);T(M8.$$.fragment,k4t),k4t.forEach(t),$4t.forEach(t),zsr=i(PXe),D1e=n(PXe,"SPAN",{});var S4t=s(D1e);Qsr=r(S4t,"AutoModelForAudioFrameClassification"),S4t.forEach(t),PXe.forEach(t),xOe=i(f),zo=n(f,"DIV",{class:!0});var ml=s(zo);T(E8.$$.fragment,ml),Wsr=i(ml),Ld=n(ml,"P",{});var Uoe=s(Ld);Hsr=r(Uoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=n(Uoe,"A",{href:!0});var R4t=s(JQ);Usr=r(R4t,"from_pretrained()"),R4t.forEach(t),Jsr=r(Uoe," class method or the "),YQ=n(Uoe,"A",{href:!0});var P4t=s(YQ);Ysr=r(P4t,"from_config()"),P4t.forEach(t),Ksr=r(Uoe,` class
method.`),Uoe.forEach(t),Zsr=i(ml),C8=n(ml,"P",{});var BXe=s(C8);elr=r(BXe,"This class cannot be instantiated directly using "),G1e=n(BXe,"CODE",{});var B4t=s(G1e);olr=r(B4t,"__init__()"),B4t.forEach(t),rlr=r(BXe," (throws an error)."),BXe.forEach(t),tlr=i(ml),Tt=n(ml,"DIV",{class:!0});var lA=s(Tt);T(w8.$$.fragment,lA),alr=i(lA),O1e=n(lA,"P",{});var I4t=s(O1e);nlr=r(I4t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),I4t.forEach(t),slr=i(lA),yd=n(lA,"P",{});var Joe=s(yd);llr=r(Joe,`Note:
Loading a model from its configuration file does `),V1e=n(Joe,"STRONG",{});var N4t=s(V1e);ilr=r(N4t,"not"),N4t.forEach(t),dlr=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=n(Joe,"A",{href:!0});var q4t=s(KQ);clr=r(q4t,"from_pretrained()"),q4t.forEach(t),flr=r(Joe," to load the model weights."),Joe.forEach(t),mlr=i(lA),T(k6.$$.fragment,lA),lA.forEach(t),glr=i(ml),mo=n(ml,"DIV",{class:!0});var Fa=s(mo);T(A8.$$.fragment,Fa),hlr=i(Fa),X1e=n(Fa,"P",{});var j4t=s(X1e);plr=r(j4t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),j4t.forEach(t),_lr=i(Fa),Ha=n(Fa,"P",{});var iA=s(Ha);ulr=r(iA,"The model class to instantiate is selected based on the "),z1e=n(iA,"CODE",{});var D4t=s(z1e);blr=r(D4t,"model_type"),D4t.forEach(t),vlr=r(iA,` property of the config object (either
passed as an argument or loaded from `),Q1e=n(iA,"CODE",{});var G4t=s(Q1e);Flr=r(G4t,"pretrained_model_name_or_path"),G4t.forEach(t),Tlr=r(iA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W1e=n(iA,"CODE",{});var O4t=s(W1e);Mlr=r(O4t,"pretrained_model_name_or_path"),O4t.forEach(t),Elr=r(iA,":"),iA.forEach(t),Clr=i(Fa),et=n(Fa,"UL",{});var gl=s(et);S6=n(gl,"LI",{});var lBe=s(S6);H1e=n(lBe,"STRONG",{});var V4t=s(H1e);wlr=r(V4t,"data2vec-audio"),V4t.forEach(t),Alr=r(lBe," \u2014 "),ZQ=n(lBe,"A",{href:!0});var X4t=s(ZQ);Llr=r(X4t,"Data2VecAudioForAudioFrameClassification"),X4t.forEach(t),ylr=r(lBe," (Data2VecAudio model)"),lBe.forEach(t),xlr=i(gl),R6=n(gl,"LI",{});var iBe=s(R6);U1e=n(iBe,"STRONG",{});var z4t=s(U1e);$lr=r(z4t,"unispeech-sat"),z4t.forEach(t),klr=r(iBe," \u2014 "),eW=n(iBe,"A",{href:!0});var Q4t=s(eW);Slr=r(Q4t,"UniSpeechSatForAudioFrameClassification"),Q4t.forEach(t),Rlr=r(iBe," (UniSpeechSat model)"),iBe.forEach(t),Plr=i(gl),P6=n(gl,"LI",{});var dBe=s(P6);J1e=n(dBe,"STRONG",{});var W4t=s(J1e);Blr=r(W4t,"wav2vec2"),W4t.forEach(t),Ilr=r(dBe," \u2014 "),oW=n(dBe,"A",{href:!0});var H4t=s(oW);Nlr=r(H4t,"Wav2Vec2ForAudioFrameClassification"),H4t.forEach(t),qlr=r(dBe," (Wav2Vec2 model)"),dBe.forEach(t),jlr=i(gl),B6=n(gl,"LI",{});var cBe=s(B6);Y1e=n(cBe,"STRONG",{});var U4t=s(Y1e);Dlr=r(U4t,"wav2vec2-conformer"),U4t.forEach(t),Glr=r(cBe," \u2014 "),rW=n(cBe,"A",{href:!0});var J4t=s(rW);Olr=r(J4t,"Wav2Vec2ConformerForAudioFrameClassification"),J4t.forEach(t),Vlr=r(cBe," (Wav2Vec2-Conformer model)"),cBe.forEach(t),Xlr=i(gl),I6=n(gl,"LI",{});var fBe=s(I6);K1e=n(fBe,"STRONG",{});var Y4t=s(K1e);zlr=r(Y4t,"wavlm"),Y4t.forEach(t),Qlr=r(fBe," \u2014 "),tW=n(fBe,"A",{href:!0});var K4t=s(tW);Wlr=r(K4t,"WavLMForAudioFrameClassification"),K4t.forEach(t),Hlr=r(fBe," (WavLM model)"),fBe.forEach(t),gl.forEach(t),Ulr=i(Fa),N6=n(Fa,"P",{});var mBe=s(N6);Jlr=r(mBe,"The model is set in evaluation mode by default using "),Z1e=n(mBe,"CODE",{});var Z4t=s(Z1e);Ylr=r(Z4t,"model.eval()"),Z4t.forEach(t),Klr=r(mBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e2e=n(mBe,"CODE",{});var eCt=s(e2e);Zlr=r(eCt,"model.train()"),eCt.forEach(t),mBe.forEach(t),eir=i(Fa),T(q6.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),$Oe=i(f),xd=n(f,"H2",{class:!0});var IXe=s(xd);j6=n(IXe,"A",{id:!0,class:!0,href:!0});var oCt=s(j6);o2e=n(oCt,"SPAN",{});var rCt=s(o2e);T(L8.$$.fragment,rCt),rCt.forEach(t),oCt.forEach(t),oir=i(IXe),r2e=n(IXe,"SPAN",{});var tCt=s(r2e);rir=r(tCt,"AutoModelForCTC"),tCt.forEach(t),IXe.forEach(t),kOe=i(f),Qo=n(f,"DIV",{class:!0});var hl=s(Qo);T(y8.$$.fragment,hl),tir=i(hl),$d=n(hl,"P",{});var Yoe=s($d);air=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=n(Yoe,"A",{href:!0});var aCt=s(aW);nir=r(aCt,"from_pretrained()"),aCt.forEach(t),sir=r(Yoe," class method or the "),nW=n(Yoe,"A",{href:!0});var nCt=s(nW);lir=r(nCt,"from_config()"),nCt.forEach(t),iir=r(Yoe,` class
method.`),Yoe.forEach(t),dir=i(hl),x8=n(hl,"P",{});var NXe=s(x8);cir=r(NXe,"This class cannot be instantiated directly using "),t2e=n(NXe,"CODE",{});var sCt=s(t2e);fir=r(sCt,"__init__()"),sCt.forEach(t),mir=r(NXe," (throws an error)."),NXe.forEach(t),gir=i(hl),Mt=n(hl,"DIV",{class:!0});var dA=s(Mt);T($8.$$.fragment,dA),hir=i(dA),a2e=n(dA,"P",{});var lCt=s(a2e);pir=r(lCt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),lCt.forEach(t),_ir=i(dA),kd=n(dA,"P",{});var Koe=s(kd);uir=r(Koe,`Note:
Loading a model from its configuration file does `),n2e=n(Koe,"STRONG",{});var iCt=s(n2e);bir=r(iCt,"not"),iCt.forEach(t),vir=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(Koe,"A",{href:!0});var dCt=s(sW);Fir=r(dCt,"from_pretrained()"),dCt.forEach(t),Tir=r(Koe," to load the model weights."),Koe.forEach(t),Mir=i(dA),T(D6.$$.fragment,dA),dA.forEach(t),Eir=i(hl),go=n(hl,"DIV",{class:!0});var Ta=s(go);T(k8.$$.fragment,Ta),Cir=i(Ta),s2e=n(Ta,"P",{});var cCt=s(s2e);wir=r(cCt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),cCt.forEach(t),Air=i(Ta),Ua=n(Ta,"P",{});var cA=s(Ua);Lir=r(cA,"The model class to instantiate is selected based on the "),l2e=n(cA,"CODE",{});var fCt=s(l2e);yir=r(fCt,"model_type"),fCt.forEach(t),xir=r(cA,` property of the config object (either
passed as an argument or loaded from `),i2e=n(cA,"CODE",{});var mCt=s(i2e);$ir=r(mCt,"pretrained_model_name_or_path"),mCt.forEach(t),kir=r(cA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d2e=n(cA,"CODE",{});var gCt=s(d2e);Sir=r(gCt,"pretrained_model_name_or_path"),gCt.forEach(t),Rir=r(cA,":"),cA.forEach(t),Pir=i(Ta),Le=n(Ta,"UL",{});var Be=s(Le);G6=n(Be,"LI",{});var gBe=s(G6);c2e=n(gBe,"STRONG",{});var hCt=s(c2e);Bir=r(hCt,"data2vec-audio"),hCt.forEach(t),Iir=r(gBe," \u2014 "),lW=n(gBe,"A",{href:!0});var pCt=s(lW);Nir=r(pCt,"Data2VecAudioForCTC"),pCt.forEach(t),qir=r(gBe," (Data2VecAudio model)"),gBe.forEach(t),jir=i(Be),O6=n(Be,"LI",{});var hBe=s(O6);f2e=n(hBe,"STRONG",{});var _Ct=s(f2e);Dir=r(_Ct,"hubert"),_Ct.forEach(t),Gir=r(hBe," \u2014 "),iW=n(hBe,"A",{href:!0});var uCt=s(iW);Oir=r(uCt,"HubertForCTC"),uCt.forEach(t),Vir=r(hBe," (Hubert model)"),hBe.forEach(t),Xir=i(Be),V6=n(Be,"LI",{});var pBe=s(V6);m2e=n(pBe,"STRONG",{});var bCt=s(m2e);zir=r(bCt,"mctct"),bCt.forEach(t),Qir=r(pBe," \u2014 "),dW=n(pBe,"A",{href:!0});var vCt=s(dW);Wir=r(vCt,"MCTCTForCTC"),vCt.forEach(t),Hir=r(pBe," (M-CTC-T model)"),pBe.forEach(t),Uir=i(Be),X6=n(Be,"LI",{});var _Be=s(X6);g2e=n(_Be,"STRONG",{});var FCt=s(g2e);Jir=r(FCt,"sew"),FCt.forEach(t),Yir=r(_Be," \u2014 "),cW=n(_Be,"A",{href:!0});var TCt=s(cW);Kir=r(TCt,"SEWForCTC"),TCt.forEach(t),Zir=r(_Be," (SEW model)"),_Be.forEach(t),edr=i(Be),z6=n(Be,"LI",{});var uBe=s(z6);h2e=n(uBe,"STRONG",{});var MCt=s(h2e);odr=r(MCt,"sew-d"),MCt.forEach(t),rdr=r(uBe," \u2014 "),fW=n(uBe,"A",{href:!0});var ECt=s(fW);tdr=r(ECt,"SEWDForCTC"),ECt.forEach(t),adr=r(uBe," (SEW-D model)"),uBe.forEach(t),ndr=i(Be),Q6=n(Be,"LI",{});var bBe=s(Q6);p2e=n(bBe,"STRONG",{});var CCt=s(p2e);sdr=r(CCt,"unispeech"),CCt.forEach(t),ldr=r(bBe," \u2014 "),mW=n(bBe,"A",{href:!0});var wCt=s(mW);idr=r(wCt,"UniSpeechForCTC"),wCt.forEach(t),ddr=r(bBe," (UniSpeech model)"),bBe.forEach(t),cdr=i(Be),W6=n(Be,"LI",{});var vBe=s(W6);_2e=n(vBe,"STRONG",{});var ACt=s(_2e);fdr=r(ACt,"unispeech-sat"),ACt.forEach(t),mdr=r(vBe," \u2014 "),gW=n(vBe,"A",{href:!0});var LCt=s(gW);gdr=r(LCt,"UniSpeechSatForCTC"),LCt.forEach(t),hdr=r(vBe," (UniSpeechSat model)"),vBe.forEach(t),pdr=i(Be),H6=n(Be,"LI",{});var FBe=s(H6);u2e=n(FBe,"STRONG",{});var yCt=s(u2e);_dr=r(yCt,"wav2vec2"),yCt.forEach(t),udr=r(FBe," \u2014 "),hW=n(FBe,"A",{href:!0});var xCt=s(hW);bdr=r(xCt,"Wav2Vec2ForCTC"),xCt.forEach(t),vdr=r(FBe," (Wav2Vec2 model)"),FBe.forEach(t),Fdr=i(Be),U6=n(Be,"LI",{});var TBe=s(U6);b2e=n(TBe,"STRONG",{});var $Ct=s(b2e);Tdr=r($Ct,"wav2vec2-conformer"),$Ct.forEach(t),Mdr=r(TBe," \u2014 "),pW=n(TBe,"A",{href:!0});var kCt=s(pW);Edr=r(kCt,"Wav2Vec2ConformerForCTC"),kCt.forEach(t),Cdr=r(TBe," (Wav2Vec2-Conformer model)"),TBe.forEach(t),wdr=i(Be),J6=n(Be,"LI",{});var MBe=s(J6);v2e=n(MBe,"STRONG",{});var SCt=s(v2e);Adr=r(SCt,"wavlm"),SCt.forEach(t),Ldr=r(MBe," \u2014 "),_W=n(MBe,"A",{href:!0});var RCt=s(_W);ydr=r(RCt,"WavLMForCTC"),RCt.forEach(t),xdr=r(MBe," (WavLM model)"),MBe.forEach(t),Be.forEach(t),$dr=i(Ta),Y6=n(Ta,"P",{});var EBe=s(Y6);kdr=r(EBe,"The model is set in evaluation mode by default using "),F2e=n(EBe,"CODE",{});var PCt=s(F2e);Sdr=r(PCt,"model.eval()"),PCt.forEach(t),Rdr=r(EBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T2e=n(EBe,"CODE",{});var BCt=s(T2e);Pdr=r(BCt,"model.train()"),BCt.forEach(t),EBe.forEach(t),Bdr=i(Ta),T(K6.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),SOe=i(f),Sd=n(f,"H2",{class:!0});var qXe=s(Sd);Z6=n(qXe,"A",{id:!0,class:!0,href:!0});var ICt=s(Z6);M2e=n(ICt,"SPAN",{});var NCt=s(M2e);T(S8.$$.fragment,NCt),NCt.forEach(t),ICt.forEach(t),Idr=i(qXe),E2e=n(qXe,"SPAN",{});var qCt=s(E2e);Ndr=r(qCt,"AutoModelForSpeechSeq2Seq"),qCt.forEach(t),qXe.forEach(t),ROe=i(f),Wo=n(f,"DIV",{class:!0});var pl=s(Wo);T(R8.$$.fragment,pl),qdr=i(pl),Rd=n(pl,"P",{});var Zoe=s(Rd);jdr=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=n(Zoe,"A",{href:!0});var jCt=s(uW);Ddr=r(jCt,"from_pretrained()"),jCt.forEach(t),Gdr=r(Zoe," class method or the "),bW=n(Zoe,"A",{href:!0});var DCt=s(bW);Odr=r(DCt,"from_config()"),DCt.forEach(t),Vdr=r(Zoe,` class
method.`),Zoe.forEach(t),Xdr=i(pl),P8=n(pl,"P",{});var jXe=s(P8);zdr=r(jXe,"This class cannot be instantiated directly using "),C2e=n(jXe,"CODE",{});var GCt=s(C2e);Qdr=r(GCt,"__init__()"),GCt.forEach(t),Wdr=r(jXe," (throws an error)."),jXe.forEach(t),Hdr=i(pl),Et=n(pl,"DIV",{class:!0});var fA=s(Et);T(B8.$$.fragment,fA),Udr=i(fA),w2e=n(fA,"P",{});var OCt=s(w2e);Jdr=r(OCt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),OCt.forEach(t),Ydr=i(fA),Pd=n(fA,"P",{});var ere=s(Pd);Kdr=r(ere,`Note:
Loading a model from its configuration file does `),A2e=n(ere,"STRONG",{});var VCt=s(A2e);Zdr=r(VCt,"not"),VCt.forEach(t),ecr=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=n(ere,"A",{href:!0});var XCt=s(vW);ocr=r(XCt,"from_pretrained()"),XCt.forEach(t),rcr=r(ere," to load the model weights."),ere.forEach(t),tcr=i(fA),T(eT.$$.fragment,fA),fA.forEach(t),acr=i(pl),ho=n(pl,"DIV",{class:!0});var Ma=s(ho);T(I8.$$.fragment,Ma),ncr=i(Ma),L2e=n(Ma,"P",{});var zCt=s(L2e);scr=r(zCt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zCt.forEach(t),lcr=i(Ma),Ja=n(Ma,"P",{});var mA=s(Ja);icr=r(mA,"The model class to instantiate is selected based on the "),y2e=n(mA,"CODE",{});var QCt=s(y2e);dcr=r(QCt,"model_type"),QCt.forEach(t),ccr=r(mA,` property of the config object (either
passed as an argument or loaded from `),x2e=n(mA,"CODE",{});var WCt=s(x2e);fcr=r(WCt,"pretrained_model_name_or_path"),WCt.forEach(t),mcr=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$2e=n(mA,"CODE",{});var HCt=s($2e);gcr=r(HCt,"pretrained_model_name_or_path"),HCt.forEach(t),hcr=r(mA,":"),mA.forEach(t),pcr=i(Ma),N8=n(Ma,"UL",{});var DXe=s(N8);oT=n(DXe,"LI",{});var CBe=s(oT);k2e=n(CBe,"STRONG",{});var UCt=s(k2e);_cr=r(UCt,"speech-encoder-decoder"),UCt.forEach(t),ucr=r(CBe," \u2014 "),FW=n(CBe,"A",{href:!0});var JCt=s(FW);bcr=r(JCt,"SpeechEncoderDecoderModel"),JCt.forEach(t),vcr=r(CBe," (Speech Encoder decoder model)"),CBe.forEach(t),Fcr=i(DXe),rT=n(DXe,"LI",{});var wBe=s(rT);S2e=n(wBe,"STRONG",{});var YCt=s(S2e);Tcr=r(YCt,"speech_to_text"),YCt.forEach(t),Mcr=r(wBe," \u2014 "),TW=n(wBe,"A",{href:!0});var KCt=s(TW);Ecr=r(KCt,"Speech2TextForConditionalGeneration"),KCt.forEach(t),Ccr=r(wBe," (Speech2Text model)"),wBe.forEach(t),DXe.forEach(t),wcr=i(Ma),tT=n(Ma,"P",{});var ABe=s(tT);Acr=r(ABe,"The model is set in evaluation mode by default using "),R2e=n(ABe,"CODE",{});var ZCt=s(R2e);Lcr=r(ZCt,"model.eval()"),ZCt.forEach(t),ycr=r(ABe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=n(ABe,"CODE",{});var e5t=s(P2e);xcr=r(e5t,"model.train()"),e5t.forEach(t),ABe.forEach(t),$cr=i(Ma),T(aT.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),POe=i(f),Bd=n(f,"H2",{class:!0});var GXe=s(Bd);nT=n(GXe,"A",{id:!0,class:!0,href:!0});var o5t=s(nT);B2e=n(o5t,"SPAN",{});var r5t=s(B2e);T(q8.$$.fragment,r5t),r5t.forEach(t),o5t.forEach(t),kcr=i(GXe),I2e=n(GXe,"SPAN",{});var t5t=s(I2e);Scr=r(t5t,"AutoModelForAudioXVector"),t5t.forEach(t),GXe.forEach(t),BOe=i(f),Ho=n(f,"DIV",{class:!0});var _l=s(Ho);T(j8.$$.fragment,_l),Rcr=i(_l),Id=n(_l,"P",{});var ore=s(Id);Pcr=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=n(ore,"A",{href:!0});var a5t=s(MW);Bcr=r(a5t,"from_pretrained()"),a5t.forEach(t),Icr=r(ore," class method or the "),EW=n(ore,"A",{href:!0});var n5t=s(EW);Ncr=r(n5t,"from_config()"),n5t.forEach(t),qcr=r(ore,` class
method.`),ore.forEach(t),jcr=i(_l),D8=n(_l,"P",{});var OXe=s(D8);Dcr=r(OXe,"This class cannot be instantiated directly using "),N2e=n(OXe,"CODE",{});var s5t=s(N2e);Gcr=r(s5t,"__init__()"),s5t.forEach(t),Ocr=r(OXe," (throws an error)."),OXe.forEach(t),Vcr=i(_l),Ct=n(_l,"DIV",{class:!0});var gA=s(Ct);T(G8.$$.fragment,gA),Xcr=i(gA),q2e=n(gA,"P",{});var l5t=s(q2e);zcr=r(l5t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),l5t.forEach(t),Qcr=i(gA),Nd=n(gA,"P",{});var rre=s(Nd);Wcr=r(rre,`Note:
Loading a model from its configuration file does `),j2e=n(rre,"STRONG",{});var i5t=s(j2e);Hcr=r(i5t,"not"),i5t.forEach(t),Ucr=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(rre,"A",{href:!0});var d5t=s(CW);Jcr=r(d5t,"from_pretrained()"),d5t.forEach(t),Ycr=r(rre," to load the model weights."),rre.forEach(t),Kcr=i(gA),T(sT.$$.fragment,gA),gA.forEach(t),Zcr=i(_l),po=n(_l,"DIV",{class:!0});var Ea=s(po);T(O8.$$.fragment,Ea),efr=i(Ea),D2e=n(Ea,"P",{});var c5t=s(D2e);ofr=r(c5t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),c5t.forEach(t),rfr=i(Ea),Ya=n(Ea,"P",{});var hA=s(Ya);tfr=r(hA,"The model class to instantiate is selected based on the "),G2e=n(hA,"CODE",{});var f5t=s(G2e);afr=r(f5t,"model_type"),f5t.forEach(t),nfr=r(hA,` property of the config object (either
passed as an argument or loaded from `),O2e=n(hA,"CODE",{});var m5t=s(O2e);sfr=r(m5t,"pretrained_model_name_or_path"),m5t.forEach(t),lfr=r(hA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=n(hA,"CODE",{});var g5t=s(V2e);ifr=r(g5t,"pretrained_model_name_or_path"),g5t.forEach(t),dfr=r(hA,":"),hA.forEach(t),cfr=i(Ea),ot=n(Ea,"UL",{});var ul=s(ot);lT=n(ul,"LI",{});var LBe=s(lT);X2e=n(LBe,"STRONG",{});var h5t=s(X2e);ffr=r(h5t,"data2vec-audio"),h5t.forEach(t),mfr=r(LBe," \u2014 "),wW=n(LBe,"A",{href:!0});var p5t=s(wW);gfr=r(p5t,"Data2VecAudioForXVector"),p5t.forEach(t),hfr=r(LBe," (Data2VecAudio model)"),LBe.forEach(t),pfr=i(ul),iT=n(ul,"LI",{});var yBe=s(iT);z2e=n(yBe,"STRONG",{});var _5t=s(z2e);_fr=r(_5t,"unispeech-sat"),_5t.forEach(t),ufr=r(yBe," \u2014 "),AW=n(yBe,"A",{href:!0});var u5t=s(AW);bfr=r(u5t,"UniSpeechSatForXVector"),u5t.forEach(t),vfr=r(yBe," (UniSpeechSat model)"),yBe.forEach(t),Ffr=i(ul),dT=n(ul,"LI",{});var xBe=s(dT);Q2e=n(xBe,"STRONG",{});var b5t=s(Q2e);Tfr=r(b5t,"wav2vec2"),b5t.forEach(t),Mfr=r(xBe," \u2014 "),LW=n(xBe,"A",{href:!0});var v5t=s(LW);Efr=r(v5t,"Wav2Vec2ForXVector"),v5t.forEach(t),Cfr=r(xBe," (Wav2Vec2 model)"),xBe.forEach(t),wfr=i(ul),cT=n(ul,"LI",{});var $Be=s(cT);W2e=n($Be,"STRONG",{});var F5t=s(W2e);Afr=r(F5t,"wav2vec2-conformer"),F5t.forEach(t),Lfr=r($Be," \u2014 "),yW=n($Be,"A",{href:!0});var T5t=s(yW);yfr=r(T5t,"Wav2Vec2ConformerForXVector"),T5t.forEach(t),xfr=r($Be," (Wav2Vec2-Conformer model)"),$Be.forEach(t),$fr=i(ul),fT=n(ul,"LI",{});var kBe=s(fT);H2e=n(kBe,"STRONG",{});var M5t=s(H2e);kfr=r(M5t,"wavlm"),M5t.forEach(t),Sfr=r(kBe," \u2014 "),xW=n(kBe,"A",{href:!0});var E5t=s(xW);Rfr=r(E5t,"WavLMForXVector"),E5t.forEach(t),Pfr=r(kBe," (WavLM model)"),kBe.forEach(t),ul.forEach(t),Bfr=i(Ea),mT=n(Ea,"P",{});var SBe=s(mT);Ifr=r(SBe,"The model is set in evaluation mode by default using "),U2e=n(SBe,"CODE",{});var C5t=s(U2e);Nfr=r(C5t,"model.eval()"),C5t.forEach(t),qfr=r(SBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J2e=n(SBe,"CODE",{});var w5t=s(J2e);jfr=r(w5t,"model.train()"),w5t.forEach(t),SBe.forEach(t),Dfr=i(Ea),T(gT.$$.fragment,Ea),Ea.forEach(t),_l.forEach(t),IOe=i(f),qd=n(f,"H2",{class:!0});var VXe=s(qd);hT=n(VXe,"A",{id:!0,class:!0,href:!0});var A5t=s(hT);Y2e=n(A5t,"SPAN",{});var L5t=s(Y2e);T(V8.$$.fragment,L5t),L5t.forEach(t),A5t.forEach(t),Gfr=i(VXe),K2e=n(VXe,"SPAN",{});var y5t=s(K2e);Ofr=r(y5t,"AutoModelForMaskedImageModeling"),y5t.forEach(t),VXe.forEach(t),NOe=i(f),Uo=n(f,"DIV",{class:!0});var bl=s(Uo);T(X8.$$.fragment,bl),Vfr=i(bl),jd=n(bl,"P",{});var tre=s(jd);Xfr=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=n(tre,"A",{href:!0});var x5t=s($W);zfr=r(x5t,"from_pretrained()"),x5t.forEach(t),Qfr=r(tre," class method or the "),kW=n(tre,"A",{href:!0});var $5t=s(kW);Wfr=r($5t,"from_config()"),$5t.forEach(t),Hfr=r(tre,` class
method.`),tre.forEach(t),Ufr=i(bl),z8=n(bl,"P",{});var XXe=s(z8);Jfr=r(XXe,"This class cannot be instantiated directly using "),Z2e=n(XXe,"CODE",{});var k5t=s(Z2e);Yfr=r(k5t,"__init__()"),k5t.forEach(t),Kfr=r(XXe," (throws an error)."),XXe.forEach(t),Zfr=i(bl),wt=n(bl,"DIV",{class:!0});var pA=s(wt);T(Q8.$$.fragment,pA),emr=i(pA),ebe=n(pA,"P",{});var S5t=s(ebe);omr=r(S5t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),S5t.forEach(t),rmr=i(pA),Dd=n(pA,"P",{});var are=s(Dd);tmr=r(are,`Note:
Loading a model from its configuration file does `),obe=n(are,"STRONG",{});var R5t=s(obe);amr=r(R5t,"not"),R5t.forEach(t),nmr=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(are,"A",{href:!0});var P5t=s(SW);smr=r(P5t,"from_pretrained()"),P5t.forEach(t),lmr=r(are," to load the model weights."),are.forEach(t),imr=i(pA),T(pT.$$.fragment,pA),pA.forEach(t),dmr=i(bl),_o=n(bl,"DIV",{class:!0});var Ca=s(_o);T(W8.$$.fragment,Ca),cmr=i(Ca),rbe=n(Ca,"P",{});var B5t=s(rbe);fmr=r(B5t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B5t.forEach(t),mmr=i(Ca),Ka=n(Ca,"P",{});var _A=s(Ka);gmr=r(_A,"The model class to instantiate is selected based on the "),tbe=n(_A,"CODE",{});var I5t=s(tbe);hmr=r(I5t,"model_type"),I5t.forEach(t),pmr=r(_A,` property of the config object (either
passed as an argument or loaded from `),abe=n(_A,"CODE",{});var N5t=s(abe);_mr=r(N5t,"pretrained_model_name_or_path"),N5t.forEach(t),umr=r(_A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=n(_A,"CODE",{});var q5t=s(nbe);bmr=r(q5t,"pretrained_model_name_or_path"),q5t.forEach(t),vmr=r(_A,":"),_A.forEach(t),Fmr=i(Ca),Gd=n(Ca,"UL",{});var nre=s(Gd);_T=n(nre,"LI",{});var RBe=s(_T);sbe=n(RBe,"STRONG",{});var j5t=s(sbe);Tmr=r(j5t,"deit"),j5t.forEach(t),Mmr=r(RBe," \u2014 "),RW=n(RBe,"A",{href:!0});var D5t=s(RW);Emr=r(D5t,"DeiTForMaskedImageModeling"),D5t.forEach(t),Cmr=r(RBe," (DeiT model)"),RBe.forEach(t),wmr=i(nre),uT=n(nre,"LI",{});var PBe=s(uT);lbe=n(PBe,"STRONG",{});var G5t=s(lbe);Amr=r(G5t,"swin"),G5t.forEach(t),Lmr=r(PBe," \u2014 "),PW=n(PBe,"A",{href:!0});var O5t=s(PW);ymr=r(O5t,"SwinForMaskedImageModeling"),O5t.forEach(t),xmr=r(PBe," (Swin Transformer model)"),PBe.forEach(t),$mr=i(nre),bT=n(nre,"LI",{});var BBe=s(bT);ibe=n(BBe,"STRONG",{});var V5t=s(ibe);kmr=r(V5t,"vit"),V5t.forEach(t),Smr=r(BBe," \u2014 "),BW=n(BBe,"A",{href:!0});var X5t=s(BW);Rmr=r(X5t,"ViTForMaskedImageModeling"),X5t.forEach(t),Pmr=r(BBe," (ViT model)"),BBe.forEach(t),nre.forEach(t),Bmr=i(Ca),vT=n(Ca,"P",{});var IBe=s(vT);Imr=r(IBe,"The model is set in evaluation mode by default using "),dbe=n(IBe,"CODE",{});var z5t=s(dbe);Nmr=r(z5t,"model.eval()"),z5t.forEach(t),qmr=r(IBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cbe=n(IBe,"CODE",{});var Q5t=s(cbe);jmr=r(Q5t,"model.train()"),Q5t.forEach(t),IBe.forEach(t),Dmr=i(Ca),T(FT.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),qOe=i(f),Od=n(f,"H2",{class:!0});var zXe=s(Od);TT=n(zXe,"A",{id:!0,class:!0,href:!0});var W5t=s(TT);fbe=n(W5t,"SPAN",{});var H5t=s(fbe);T(H8.$$.fragment,H5t),H5t.forEach(t),W5t.forEach(t),Gmr=i(zXe),mbe=n(zXe,"SPAN",{});var U5t=s(mbe);Omr=r(U5t,"AutoModelForObjectDetection"),U5t.forEach(t),zXe.forEach(t),jOe=i(f),Jo=n(f,"DIV",{class:!0});var vl=s(Jo);T(U8.$$.fragment,vl),Vmr=i(vl),Vd=n(vl,"P",{});var sre=s(Vd);Xmr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=n(sre,"A",{href:!0});var J5t=s(IW);zmr=r(J5t,"from_pretrained()"),J5t.forEach(t),Qmr=r(sre," class method or the "),NW=n(sre,"A",{href:!0});var Y5t=s(NW);Wmr=r(Y5t,"from_config()"),Y5t.forEach(t),Hmr=r(sre,` class
method.`),sre.forEach(t),Umr=i(vl),J8=n(vl,"P",{});var QXe=s(J8);Jmr=r(QXe,"This class cannot be instantiated directly using "),gbe=n(QXe,"CODE",{});var K5t=s(gbe);Ymr=r(K5t,"__init__()"),K5t.forEach(t),Kmr=r(QXe," (throws an error)."),QXe.forEach(t),Zmr=i(vl),At=n(vl,"DIV",{class:!0});var uA=s(At);T(Y8.$$.fragment,uA),egr=i(uA),hbe=n(uA,"P",{});var Z5t=s(hbe);ogr=r(Z5t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Z5t.forEach(t),rgr=i(uA),Xd=n(uA,"P",{});var lre=s(Xd);tgr=r(lre,`Note:
Loading a model from its configuration file does `),pbe=n(lre,"STRONG",{});var e3t=s(pbe);agr=r(e3t,"not"),e3t.forEach(t),ngr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(lre,"A",{href:!0});var o3t=s(qW);sgr=r(o3t,"from_pretrained()"),o3t.forEach(t),lgr=r(lre," to load the model weights."),lre.forEach(t),igr=i(uA),T(MT.$$.fragment,uA),uA.forEach(t),dgr=i(vl),uo=n(vl,"DIV",{class:!0});var wa=s(uo);T(K8.$$.fragment,wa),cgr=i(wa),_be=n(wa,"P",{});var r3t=s(_be);fgr=r(r3t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),r3t.forEach(t),mgr=i(wa),Za=n(wa,"P",{});var bA=s(Za);ggr=r(bA,"The model class to instantiate is selected based on the "),ube=n(bA,"CODE",{});var t3t=s(ube);hgr=r(t3t,"model_type"),t3t.forEach(t),pgr=r(bA,` property of the config object (either
passed as an argument or loaded from `),bbe=n(bA,"CODE",{});var a3t=s(bbe);_gr=r(a3t,"pretrained_model_name_or_path"),a3t.forEach(t),ugr=r(bA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vbe=n(bA,"CODE",{});var n3t=s(vbe);bgr=r(n3t,"pretrained_model_name_or_path"),n3t.forEach(t),vgr=r(bA,":"),bA.forEach(t),Fgr=i(wa),Z8=n(wa,"UL",{});var WXe=s(Z8);ET=n(WXe,"LI",{});var NBe=s(ET);Fbe=n(NBe,"STRONG",{});var s3t=s(Fbe);Tgr=r(s3t,"detr"),s3t.forEach(t),Mgr=r(NBe," \u2014 "),jW=n(NBe,"A",{href:!0});var l3t=s(jW);Egr=r(l3t,"DetrForObjectDetection"),l3t.forEach(t),Cgr=r(NBe," (DETR model)"),NBe.forEach(t),wgr=i(WXe),CT=n(WXe,"LI",{});var qBe=s(CT);Tbe=n(qBe,"STRONG",{});var i3t=s(Tbe);Agr=r(i3t,"yolos"),i3t.forEach(t),Lgr=r(qBe," \u2014 "),DW=n(qBe,"A",{href:!0});var d3t=s(DW);ygr=r(d3t,"YolosForObjectDetection"),d3t.forEach(t),xgr=r(qBe," (YOLOS model)"),qBe.forEach(t),WXe.forEach(t),$gr=i(wa),wT=n(wa,"P",{});var jBe=s(wT);kgr=r(jBe,"The model is set in evaluation mode by default using "),Mbe=n(jBe,"CODE",{});var c3t=s(Mbe);Sgr=r(c3t,"model.eval()"),c3t.forEach(t),Rgr=r(jBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=n(jBe,"CODE",{});var f3t=s(Ebe);Pgr=r(f3t,"model.train()"),f3t.forEach(t),jBe.forEach(t),Bgr=i(wa),T(AT.$$.fragment,wa),wa.forEach(t),vl.forEach(t),DOe=i(f),zd=n(f,"H2",{class:!0});var HXe=s(zd);LT=n(HXe,"A",{id:!0,class:!0,href:!0});var m3t=s(LT);Cbe=n(m3t,"SPAN",{});var g3t=s(Cbe);T(e9.$$.fragment,g3t),g3t.forEach(t),m3t.forEach(t),Igr=i(HXe),wbe=n(HXe,"SPAN",{});var h3t=s(wbe);Ngr=r(h3t,"AutoModelForImageSegmentation"),h3t.forEach(t),HXe.forEach(t),GOe=i(f),Yo=n(f,"DIV",{class:!0});var Fl=s(Yo);T(o9.$$.fragment,Fl),qgr=i(Fl),Qd=n(Fl,"P",{});var ire=s(Qd);jgr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=n(ire,"A",{href:!0});var p3t=s(GW);Dgr=r(p3t,"from_pretrained()"),p3t.forEach(t),Ggr=r(ire," class method or the "),OW=n(ire,"A",{href:!0});var _3t=s(OW);Ogr=r(_3t,"from_config()"),_3t.forEach(t),Vgr=r(ire,` class
method.`),ire.forEach(t),Xgr=i(Fl),r9=n(Fl,"P",{});var UXe=s(r9);zgr=r(UXe,"This class cannot be instantiated directly using "),Abe=n(UXe,"CODE",{});var u3t=s(Abe);Qgr=r(u3t,"__init__()"),u3t.forEach(t),Wgr=r(UXe," (throws an error)."),UXe.forEach(t),Hgr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var vA=s(Lt);T(t9.$$.fragment,vA),Ugr=i(vA),Lbe=n(vA,"P",{});var b3t=s(Lbe);Jgr=r(b3t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),b3t.forEach(t),Ygr=i(vA),Wd=n(vA,"P",{});var dre=s(Wd);Kgr=r(dre,`Note:
Loading a model from its configuration file does `),ybe=n(dre,"STRONG",{});var v3t=s(ybe);Zgr=r(v3t,"not"),v3t.forEach(t),ehr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(dre,"A",{href:!0});var F3t=s(VW);ohr=r(F3t,"from_pretrained()"),F3t.forEach(t),rhr=r(dre," to load the model weights."),dre.forEach(t),thr=i(vA),T(yT.$$.fragment,vA),vA.forEach(t),ahr=i(Fl),bo=n(Fl,"DIV",{class:!0});var Aa=s(bo);T(a9.$$.fragment,Aa),nhr=i(Aa),xbe=n(Aa,"P",{});var T3t=s(xbe);shr=r(T3t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),T3t.forEach(t),lhr=i(Aa),en=n(Aa,"P",{});var FA=s(en);ihr=r(FA,"The model class to instantiate is selected based on the "),$be=n(FA,"CODE",{});var M3t=s($be);dhr=r(M3t,"model_type"),M3t.forEach(t),chr=r(FA,` property of the config object (either
passed as an argument or loaded from `),kbe=n(FA,"CODE",{});var E3t=s(kbe);fhr=r(E3t,"pretrained_model_name_or_path"),E3t.forEach(t),mhr=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=n(FA,"CODE",{});var C3t=s(Sbe);ghr=r(C3t,"pretrained_model_name_or_path"),C3t.forEach(t),hhr=r(FA,":"),FA.forEach(t),phr=i(Aa),Rbe=n(Aa,"UL",{});var w3t=s(Rbe);xT=n(w3t,"LI",{});var DBe=s(xT);Pbe=n(DBe,"STRONG",{});var A3t=s(Pbe);_hr=r(A3t,"detr"),A3t.forEach(t),uhr=r(DBe," \u2014 "),XW=n(DBe,"A",{href:!0});var L3t=s(XW);bhr=r(L3t,"DetrForSegmentation"),L3t.forEach(t),vhr=r(DBe," (DETR model)"),DBe.forEach(t),w3t.forEach(t),Fhr=i(Aa),$T=n(Aa,"P",{});var GBe=s($T);Thr=r(GBe,"The model is set in evaluation mode by default using "),Bbe=n(GBe,"CODE",{});var y3t=s(Bbe);Mhr=r(y3t,"model.eval()"),y3t.forEach(t),Ehr=r(GBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=n(GBe,"CODE",{});var x3t=s(Ibe);Chr=r(x3t,"model.train()"),x3t.forEach(t),GBe.forEach(t),whr=i(Aa),T(kT.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),OOe=i(f),Hd=n(f,"H2",{class:!0});var JXe=s(Hd);ST=n(JXe,"A",{id:!0,class:!0,href:!0});var $3t=s(ST);Nbe=n($3t,"SPAN",{});var k3t=s(Nbe);T(n9.$$.fragment,k3t),k3t.forEach(t),$3t.forEach(t),Ahr=i(JXe),qbe=n(JXe,"SPAN",{});var S3t=s(qbe);Lhr=r(S3t,"AutoModelForSemanticSegmentation"),S3t.forEach(t),JXe.forEach(t),VOe=i(f),Ko=n(f,"DIV",{class:!0});var Tl=s(Ko);T(s9.$$.fragment,Tl),yhr=i(Tl),Ud=n(Tl,"P",{});var cre=s(Ud);xhr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=n(cre,"A",{href:!0});var R3t=s(zW);$hr=r(R3t,"from_pretrained()"),R3t.forEach(t),khr=r(cre," class method or the "),QW=n(cre,"A",{href:!0});var P3t=s(QW);Shr=r(P3t,"from_config()"),P3t.forEach(t),Rhr=r(cre,` class
method.`),cre.forEach(t),Phr=i(Tl),l9=n(Tl,"P",{});var YXe=s(l9);Bhr=r(YXe,"This class cannot be instantiated directly using "),jbe=n(YXe,"CODE",{});var B3t=s(jbe);Ihr=r(B3t,"__init__()"),B3t.forEach(t),Nhr=r(YXe," (throws an error)."),YXe.forEach(t),qhr=i(Tl),yt=n(Tl,"DIV",{class:!0});var TA=s(yt);T(i9.$$.fragment,TA),jhr=i(TA),Dbe=n(TA,"P",{});var I3t=s(Dbe);Dhr=r(I3t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),I3t.forEach(t),Ghr=i(TA),Jd=n(TA,"P",{});var fre=s(Jd);Ohr=r(fre,`Note:
Loading a model from its configuration file does `),Gbe=n(fre,"STRONG",{});var N3t=s(Gbe);Vhr=r(N3t,"not"),N3t.forEach(t),Xhr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(fre,"A",{href:!0});var q3t=s(WW);zhr=r(q3t,"from_pretrained()"),q3t.forEach(t),Qhr=r(fre," to load the model weights."),fre.forEach(t),Whr=i(TA),T(RT.$$.fragment,TA),TA.forEach(t),Hhr=i(Tl),vo=n(Tl,"DIV",{class:!0});var La=s(vo);T(d9.$$.fragment,La),Uhr=i(La),Obe=n(La,"P",{});var j3t=s(Obe);Jhr=r(j3t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),j3t.forEach(t),Yhr=i(La),on=n(La,"P",{});var MA=s(on);Khr=r(MA,"The model class to instantiate is selected based on the "),Vbe=n(MA,"CODE",{});var D3t=s(Vbe);Zhr=r(D3t,"model_type"),D3t.forEach(t),epr=r(MA,` property of the config object (either
passed as an argument or loaded from `),Xbe=n(MA,"CODE",{});var G3t=s(Xbe);opr=r(G3t,"pretrained_model_name_or_path"),G3t.forEach(t),rpr=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=n(MA,"CODE",{});var O3t=s(zbe);tpr=r(O3t,"pretrained_model_name_or_path"),O3t.forEach(t),apr=r(MA,":"),MA.forEach(t),npr=i(La),rn=n(La,"UL",{});var EA=s(rn);PT=n(EA,"LI",{});var OBe=s(PT);Qbe=n(OBe,"STRONG",{});var V3t=s(Qbe);spr=r(V3t,"beit"),V3t.forEach(t),lpr=r(OBe," \u2014 "),HW=n(OBe,"A",{href:!0});var X3t=s(HW);ipr=r(X3t,"BeitForSemanticSegmentation"),X3t.forEach(t),dpr=r(OBe," (BEiT model)"),OBe.forEach(t),cpr=i(EA),BT=n(EA,"LI",{});var VBe=s(BT);Wbe=n(VBe,"STRONG",{});var z3t=s(Wbe);fpr=r(z3t,"data2vec-vision"),z3t.forEach(t),mpr=r(VBe," \u2014 "),UW=n(VBe,"A",{href:!0});var Q3t=s(UW);gpr=r(Q3t,"Data2VecVisionForSemanticSegmentation"),Q3t.forEach(t),hpr=r(VBe," (Data2VecVision model)"),VBe.forEach(t),ppr=i(EA),IT=n(EA,"LI",{});var XBe=s(IT);Hbe=n(XBe,"STRONG",{});var W3t=s(Hbe);_pr=r(W3t,"dpt"),W3t.forEach(t),upr=r(XBe," \u2014 "),JW=n(XBe,"A",{href:!0});var H3t=s(JW);bpr=r(H3t,"DPTForSemanticSegmentation"),H3t.forEach(t),vpr=r(XBe," (DPT model)"),XBe.forEach(t),Fpr=i(EA),NT=n(EA,"LI",{});var zBe=s(NT);Ube=n(zBe,"STRONG",{});var U3t=s(Ube);Tpr=r(U3t,"segformer"),U3t.forEach(t),Mpr=r(zBe," \u2014 "),YW=n(zBe,"A",{href:!0});var J3t=s(YW);Epr=r(J3t,"SegformerForSemanticSegmentation"),J3t.forEach(t),Cpr=r(zBe," (SegFormer model)"),zBe.forEach(t),EA.forEach(t),wpr=i(La),qT=n(La,"P",{});var QBe=s(qT);Apr=r(QBe,"The model is set in evaluation mode by default using "),Jbe=n(QBe,"CODE",{});var Y3t=s(Jbe);Lpr=r(Y3t,"model.eval()"),Y3t.forEach(t),ypr=r(QBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ybe=n(QBe,"CODE",{});var K3t=s(Ybe);xpr=r(K3t,"model.train()"),K3t.forEach(t),QBe.forEach(t),$pr=i(La),T(jT.$$.fragment,La),La.forEach(t),Tl.forEach(t),XOe=i(f),Yd=n(f,"H2",{class:!0});var KXe=s(Yd);DT=n(KXe,"A",{id:!0,class:!0,href:!0});var Z3t=s(DT);Kbe=n(Z3t,"SPAN",{});var e0t=s(Kbe);T(c9.$$.fragment,e0t),e0t.forEach(t),Z3t.forEach(t),kpr=i(KXe),Zbe=n(KXe,"SPAN",{});var o0t=s(Zbe);Spr=r(o0t,"AutoModelForInstanceSegmentation"),o0t.forEach(t),KXe.forEach(t),zOe=i(f),Zo=n(f,"DIV",{class:!0});var Ml=s(Zo);T(f9.$$.fragment,Ml),Rpr=i(Ml),Kd=n(Ml,"P",{});var mre=s(Kd);Ppr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=n(mre,"A",{href:!0});var r0t=s(KW);Bpr=r(r0t,"from_pretrained()"),r0t.forEach(t),Ipr=r(mre," class method or the "),ZW=n(mre,"A",{href:!0});var t0t=s(ZW);Npr=r(t0t,"from_config()"),t0t.forEach(t),qpr=r(mre,` class
method.`),mre.forEach(t),jpr=i(Ml),m9=n(Ml,"P",{});var ZXe=s(m9);Dpr=r(ZXe,"This class cannot be instantiated directly using "),eve=n(ZXe,"CODE",{});var a0t=s(eve);Gpr=r(a0t,"__init__()"),a0t.forEach(t),Opr=r(ZXe," (throws an error)."),ZXe.forEach(t),Vpr=i(Ml),xt=n(Ml,"DIV",{class:!0});var CA=s(xt);T(g9.$$.fragment,CA),Xpr=i(CA),ove=n(CA,"P",{});var n0t=s(ove);zpr=r(n0t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),n0t.forEach(t),Qpr=i(CA),Zd=n(CA,"P",{});var gre=s(Zd);Wpr=r(gre,`Note:
Loading a model from its configuration file does `),rve=n(gre,"STRONG",{});var s0t=s(rve);Hpr=r(s0t,"not"),s0t.forEach(t),Upr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(gre,"A",{href:!0});var l0t=s(eH);Jpr=r(l0t,"from_pretrained()"),l0t.forEach(t),Ypr=r(gre," to load the model weights."),gre.forEach(t),Kpr=i(CA),T(GT.$$.fragment,CA),CA.forEach(t),Zpr=i(Ml),Fo=n(Ml,"DIV",{class:!0});var ya=s(Fo);T(h9.$$.fragment,ya),e_r=i(ya),tve=n(ya,"P",{});var i0t=s(tve);o_r=r(i0t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),i0t.forEach(t),r_r=i(ya),tn=n(ya,"P",{});var wA=s(tn);t_r=r(wA,"The model class to instantiate is selected based on the "),ave=n(wA,"CODE",{});var d0t=s(ave);a_r=r(d0t,"model_type"),d0t.forEach(t),n_r=r(wA,` property of the config object (either
passed as an argument or loaded from `),nve=n(wA,"CODE",{});var c0t=s(nve);s_r=r(c0t,"pretrained_model_name_or_path"),c0t.forEach(t),l_r=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sve=n(wA,"CODE",{});var f0t=s(sve);i_r=r(f0t,"pretrained_model_name_or_path"),f0t.forEach(t),d_r=r(wA,":"),wA.forEach(t),c_r=i(ya),lve=n(ya,"UL",{});var m0t=s(lve);OT=n(m0t,"LI",{});var WBe=s(OT);ive=n(WBe,"STRONG",{});var g0t=s(ive);f_r=r(g0t,"maskformer"),g0t.forEach(t),m_r=r(WBe," \u2014 "),oH=n(WBe,"A",{href:!0});var h0t=s(oH);g_r=r(h0t,"MaskFormerForInstanceSegmentation"),h0t.forEach(t),h_r=r(WBe," (MaskFormer model)"),WBe.forEach(t),m0t.forEach(t),p_r=i(ya),VT=n(ya,"P",{});var HBe=s(VT);__r=r(HBe,"The model is set in evaluation mode by default using "),dve=n(HBe,"CODE",{});var p0t=s(dve);u_r=r(p0t,"model.eval()"),p0t.forEach(t),b_r=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cve=n(HBe,"CODE",{});var _0t=s(cve);v_r=r(_0t,"model.train()"),_0t.forEach(t),HBe.forEach(t),F_r=i(ya),T(XT.$$.fragment,ya),ya.forEach(t),Ml.forEach(t),QOe=i(f),ec=n(f,"H2",{class:!0});var eze=s(ec);zT=n(eze,"A",{id:!0,class:!0,href:!0});var u0t=s(zT);fve=n(u0t,"SPAN",{});var b0t=s(fve);T(p9.$$.fragment,b0t),b0t.forEach(t),u0t.forEach(t),T_r=i(eze),mve=n(eze,"SPAN",{});var v0t=s(mve);M_r=r(v0t,"TFAutoModel"),v0t.forEach(t),eze.forEach(t),WOe=i(f),er=n(f,"DIV",{class:!0});var El=s(er);T(_9.$$.fragment,El),E_r=i(El),oc=n(El,"P",{});var hre=s(oc);C_r=r(hre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=n(hre,"A",{href:!0});var F0t=s(rH);w_r=r(F0t,"from_pretrained()"),F0t.forEach(t),A_r=r(hre," class method or the "),tH=n(hre,"A",{href:!0});var T0t=s(tH);L_r=r(T0t,"from_config()"),T0t.forEach(t),y_r=r(hre,` class
method.`),hre.forEach(t),x_r=i(El),u9=n(El,"P",{});var oze=s(u9);$_r=r(oze,"This class cannot be instantiated directly using "),gve=n(oze,"CODE",{});var M0t=s(gve);k_r=r(M0t,"__init__()"),M0t.forEach(t),S_r=r(oze," (throws an error)."),oze.forEach(t),R_r=i(El),$t=n(El,"DIV",{class:!0});var AA=s($t);T(b9.$$.fragment,AA),P_r=i(AA),hve=n(AA,"P",{});var E0t=s(hve);B_r=r(E0t,"Instantiates one of the base model classes of the library from a configuration."),E0t.forEach(t),I_r=i(AA),rc=n(AA,"P",{});var pre=s(rc);N_r=r(pre,`Note:
Loading a model from its configuration file does `),pve=n(pre,"STRONG",{});var C0t=s(pve);q_r=r(C0t,"not"),C0t.forEach(t),j_r=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(pre,"A",{href:!0});var w0t=s(aH);D_r=r(w0t,"from_pretrained()"),w0t.forEach(t),G_r=r(pre," to load the model weights."),pre.forEach(t),O_r=i(AA),T(QT.$$.fragment,AA),AA.forEach(t),V_r=i(El),yr=n(El,"DIV",{class:!0});var Cl=s(yr);T(v9.$$.fragment,Cl),X_r=i(Cl),_ve=n(Cl,"P",{});var A0t=s(_ve);z_r=r(A0t,"Instantiate one of the base model classes of the library from a pretrained model."),A0t.forEach(t),Q_r=i(Cl),an=n(Cl,"P",{});var LA=s(an);W_r=r(LA,"The model class to instantiate is selected based on the "),uve=n(LA,"CODE",{});var L0t=s(uve);H_r=r(L0t,"model_type"),L0t.forEach(t),U_r=r(LA,` property of the config object (either
passed as an argument or loaded from `),bve=n(LA,"CODE",{});var y0t=s(bve);J_r=r(y0t,"pretrained_model_name_or_path"),y0t.forEach(t),Y_r=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vve=n(LA,"CODE",{});var x0t=s(vve);K_r=r(x0t,"pretrained_model_name_or_path"),x0t.forEach(t),Z_r=r(LA,":"),LA.forEach(t),eur=i(Cl),j=n(Cl,"UL",{});var D=s(j);WT=n(D,"LI",{});var UBe=s(WT);Fve=n(UBe,"STRONG",{});var $0t=s(Fve);our=r($0t,"albert"),$0t.forEach(t),rur=r(UBe," \u2014 "),nH=n(UBe,"A",{href:!0});var k0t=s(nH);tur=r(k0t,"TFAlbertModel"),k0t.forEach(t),aur=r(UBe," (ALBERT model)"),UBe.forEach(t),nur=i(D),HT=n(D,"LI",{});var JBe=s(HT);Tve=n(JBe,"STRONG",{});var S0t=s(Tve);sur=r(S0t,"bart"),S0t.forEach(t),lur=r(JBe," \u2014 "),sH=n(JBe,"A",{href:!0});var R0t=s(sH);iur=r(R0t,"TFBartModel"),R0t.forEach(t),dur=r(JBe," (BART model)"),JBe.forEach(t),cur=i(D),UT=n(D,"LI",{});var YBe=s(UT);Mve=n(YBe,"STRONG",{});var P0t=s(Mve);fur=r(P0t,"bert"),P0t.forEach(t),mur=r(YBe," \u2014 "),lH=n(YBe,"A",{href:!0});var B0t=s(lH);gur=r(B0t,"TFBertModel"),B0t.forEach(t),hur=r(YBe," (BERT model)"),YBe.forEach(t),pur=i(D),JT=n(D,"LI",{});var KBe=s(JT);Eve=n(KBe,"STRONG",{});var I0t=s(Eve);_ur=r(I0t,"blenderbot"),I0t.forEach(t),uur=r(KBe," \u2014 "),iH=n(KBe,"A",{href:!0});var N0t=s(iH);bur=r(N0t,"TFBlenderbotModel"),N0t.forEach(t),vur=r(KBe," (Blenderbot model)"),KBe.forEach(t),Fur=i(D),YT=n(D,"LI",{});var ZBe=s(YT);Cve=n(ZBe,"STRONG",{});var q0t=s(Cve);Tur=r(q0t,"blenderbot-small"),q0t.forEach(t),Mur=r(ZBe," \u2014 "),dH=n(ZBe,"A",{href:!0});var j0t=s(dH);Eur=r(j0t,"TFBlenderbotSmallModel"),j0t.forEach(t),Cur=r(ZBe," (BlenderbotSmall model)"),ZBe.forEach(t),wur=i(D),KT=n(D,"LI",{});var eIe=s(KT);wve=n(eIe,"STRONG",{});var D0t=s(wve);Aur=r(D0t,"camembert"),D0t.forEach(t),Lur=r(eIe," \u2014 "),cH=n(eIe,"A",{href:!0});var G0t=s(cH);yur=r(G0t,"TFCamembertModel"),G0t.forEach(t),xur=r(eIe," (CamemBERT model)"),eIe.forEach(t),$ur=i(D),ZT=n(D,"LI",{});var oIe=s(ZT);Ave=n(oIe,"STRONG",{});var O0t=s(Ave);kur=r(O0t,"clip"),O0t.forEach(t),Sur=r(oIe," \u2014 "),fH=n(oIe,"A",{href:!0});var V0t=s(fH);Rur=r(V0t,"TFCLIPModel"),V0t.forEach(t),Pur=r(oIe," (CLIP model)"),oIe.forEach(t),Bur=i(D),eM=n(D,"LI",{});var rIe=s(eM);Lve=n(rIe,"STRONG",{});var X0t=s(Lve);Iur=r(X0t,"convbert"),X0t.forEach(t),Nur=r(rIe," \u2014 "),mH=n(rIe,"A",{href:!0});var z0t=s(mH);qur=r(z0t,"TFConvBertModel"),z0t.forEach(t),jur=r(rIe," (ConvBERT model)"),rIe.forEach(t),Dur=i(D),oM=n(D,"LI",{});var tIe=s(oM);yve=n(tIe,"STRONG",{});var Q0t=s(yve);Gur=r(Q0t,"convnext"),Q0t.forEach(t),Our=r(tIe," \u2014 "),gH=n(tIe,"A",{href:!0});var W0t=s(gH);Vur=r(W0t,"TFConvNextModel"),W0t.forEach(t),Xur=r(tIe," (ConvNeXT model)"),tIe.forEach(t),zur=i(D),rM=n(D,"LI",{});var aIe=s(rM);xve=n(aIe,"STRONG",{});var H0t=s(xve);Qur=r(H0t,"ctrl"),H0t.forEach(t),Wur=r(aIe," \u2014 "),hH=n(aIe,"A",{href:!0});var U0t=s(hH);Hur=r(U0t,"TFCTRLModel"),U0t.forEach(t),Uur=r(aIe," (CTRL model)"),aIe.forEach(t),Jur=i(D),tM=n(D,"LI",{});var nIe=s(tM);$ve=n(nIe,"STRONG",{});var J0t=s($ve);Yur=r(J0t,"data2vec-vision"),J0t.forEach(t),Kur=r(nIe," \u2014 "),pH=n(nIe,"A",{href:!0});var Y0t=s(pH);Zur=r(Y0t,"TFData2VecVisionModel"),Y0t.forEach(t),e7r=r(nIe," (Data2VecVision model)"),nIe.forEach(t),o7r=i(D),aM=n(D,"LI",{});var sIe=s(aM);kve=n(sIe,"STRONG",{});var K0t=s(kve);r7r=r(K0t,"deberta"),K0t.forEach(t),t7r=r(sIe," \u2014 "),_H=n(sIe,"A",{href:!0});var Z0t=s(_H);a7r=r(Z0t,"TFDebertaModel"),Z0t.forEach(t),n7r=r(sIe," (DeBERTa model)"),sIe.forEach(t),s7r=i(D),nM=n(D,"LI",{});var lIe=s(nM);Sve=n(lIe,"STRONG",{});var ewt=s(Sve);l7r=r(ewt,"deberta-v2"),ewt.forEach(t),i7r=r(lIe," \u2014 "),uH=n(lIe,"A",{href:!0});var owt=s(uH);d7r=r(owt,"TFDebertaV2Model"),owt.forEach(t),c7r=r(lIe," (DeBERTa-v2 model)"),lIe.forEach(t),f7r=i(D),sM=n(D,"LI",{});var iIe=s(sM);Rve=n(iIe,"STRONG",{});var rwt=s(Rve);m7r=r(rwt,"distilbert"),rwt.forEach(t),g7r=r(iIe," \u2014 "),bH=n(iIe,"A",{href:!0});var twt=s(bH);h7r=r(twt,"TFDistilBertModel"),twt.forEach(t),p7r=r(iIe," (DistilBERT model)"),iIe.forEach(t),_7r=i(D),lM=n(D,"LI",{});var dIe=s(lM);Pve=n(dIe,"STRONG",{});var awt=s(Pve);u7r=r(awt,"dpr"),awt.forEach(t),b7r=r(dIe," \u2014 "),vH=n(dIe,"A",{href:!0});var nwt=s(vH);v7r=r(nwt,"TFDPRQuestionEncoder"),nwt.forEach(t),F7r=r(dIe," (DPR model)"),dIe.forEach(t),T7r=i(D),iM=n(D,"LI",{});var cIe=s(iM);Bve=n(cIe,"STRONG",{});var swt=s(Bve);M7r=r(swt,"electra"),swt.forEach(t),E7r=r(cIe," \u2014 "),FH=n(cIe,"A",{href:!0});var lwt=s(FH);C7r=r(lwt,"TFElectraModel"),lwt.forEach(t),w7r=r(cIe," (ELECTRA model)"),cIe.forEach(t),A7r=i(D),dM=n(D,"LI",{});var fIe=s(dM);Ive=n(fIe,"STRONG",{});var iwt=s(Ive);L7r=r(iwt,"flaubert"),iwt.forEach(t),y7r=r(fIe," \u2014 "),TH=n(fIe,"A",{href:!0});var dwt=s(TH);x7r=r(dwt,"TFFlaubertModel"),dwt.forEach(t),$7r=r(fIe," (FlauBERT model)"),fIe.forEach(t),k7r=i(D),Qs=n(D,"LI",{});var oS=s(Qs);Nve=n(oS,"STRONG",{});var cwt=s(Nve);S7r=r(cwt,"funnel"),cwt.forEach(t),R7r=r(oS," \u2014 "),MH=n(oS,"A",{href:!0});var fwt=s(MH);P7r=r(fwt,"TFFunnelModel"),fwt.forEach(t),B7r=r(oS," or "),EH=n(oS,"A",{href:!0});var mwt=s(EH);I7r=r(mwt,"TFFunnelBaseModel"),mwt.forEach(t),N7r=r(oS," (Funnel Transformer model)"),oS.forEach(t),q7r=i(D),cM=n(D,"LI",{});var mIe=s(cM);qve=n(mIe,"STRONG",{});var gwt=s(qve);j7r=r(gwt,"gpt2"),gwt.forEach(t),D7r=r(mIe," \u2014 "),CH=n(mIe,"A",{href:!0});var hwt=s(CH);G7r=r(hwt,"TFGPT2Model"),hwt.forEach(t),O7r=r(mIe," (OpenAI GPT-2 model)"),mIe.forEach(t),V7r=i(D),fM=n(D,"LI",{});var gIe=s(fM);jve=n(gIe,"STRONG",{});var pwt=s(jve);X7r=r(pwt,"gptj"),pwt.forEach(t),z7r=r(gIe," \u2014 "),wH=n(gIe,"A",{href:!0});var _wt=s(wH);Q7r=r(_wt,"TFGPTJModel"),_wt.forEach(t),W7r=r(gIe," (GPT-J model)"),gIe.forEach(t),H7r=i(D),mM=n(D,"LI",{});var hIe=s(mM);Dve=n(hIe,"STRONG",{});var uwt=s(Dve);U7r=r(uwt,"hubert"),uwt.forEach(t),J7r=r(hIe," \u2014 "),AH=n(hIe,"A",{href:!0});var bwt=s(AH);Y7r=r(bwt,"TFHubertModel"),bwt.forEach(t),K7r=r(hIe," (Hubert model)"),hIe.forEach(t),Z7r=i(D),gM=n(D,"LI",{});var pIe=s(gM);Gve=n(pIe,"STRONG",{});var vwt=s(Gve);e1r=r(vwt,"layoutlm"),vwt.forEach(t),o1r=r(pIe," \u2014 "),LH=n(pIe,"A",{href:!0});var Fwt=s(LH);r1r=r(Fwt,"TFLayoutLMModel"),Fwt.forEach(t),t1r=r(pIe," (LayoutLM model)"),pIe.forEach(t),a1r=i(D),hM=n(D,"LI",{});var _Ie=s(hM);Ove=n(_Ie,"STRONG",{});var Twt=s(Ove);n1r=r(Twt,"led"),Twt.forEach(t),s1r=r(_Ie," \u2014 "),yH=n(_Ie,"A",{href:!0});var Mwt=s(yH);l1r=r(Mwt,"TFLEDModel"),Mwt.forEach(t),i1r=r(_Ie," (LED model)"),_Ie.forEach(t),d1r=i(D),pM=n(D,"LI",{});var uIe=s(pM);Vve=n(uIe,"STRONG",{});var Ewt=s(Vve);c1r=r(Ewt,"longformer"),Ewt.forEach(t),f1r=r(uIe," \u2014 "),xH=n(uIe,"A",{href:!0});var Cwt=s(xH);m1r=r(Cwt,"TFLongformerModel"),Cwt.forEach(t),g1r=r(uIe," (Longformer model)"),uIe.forEach(t),h1r=i(D),_M=n(D,"LI",{});var bIe=s(_M);Xve=n(bIe,"STRONG",{});var wwt=s(Xve);p1r=r(wwt,"lxmert"),wwt.forEach(t),_1r=r(bIe," \u2014 "),$H=n(bIe,"A",{href:!0});var Awt=s($H);u1r=r(Awt,"TFLxmertModel"),Awt.forEach(t),b1r=r(bIe," (LXMERT model)"),bIe.forEach(t),v1r=i(D),uM=n(D,"LI",{});var vIe=s(uM);zve=n(vIe,"STRONG",{});var Lwt=s(zve);F1r=r(Lwt,"marian"),Lwt.forEach(t),T1r=r(vIe," \u2014 "),kH=n(vIe,"A",{href:!0});var ywt=s(kH);M1r=r(ywt,"TFMarianModel"),ywt.forEach(t),E1r=r(vIe," (Marian model)"),vIe.forEach(t),C1r=i(D),bM=n(D,"LI",{});var FIe=s(bM);Qve=n(FIe,"STRONG",{});var xwt=s(Qve);w1r=r(xwt,"mbart"),xwt.forEach(t),A1r=r(FIe," \u2014 "),SH=n(FIe,"A",{href:!0});var $wt=s(SH);L1r=r($wt,"TFMBartModel"),$wt.forEach(t),y1r=r(FIe," (mBART model)"),FIe.forEach(t),x1r=i(D),vM=n(D,"LI",{});var TIe=s(vM);Wve=n(TIe,"STRONG",{});var kwt=s(Wve);$1r=r(kwt,"mobilebert"),kwt.forEach(t),k1r=r(TIe," \u2014 "),RH=n(TIe,"A",{href:!0});var Swt=s(RH);S1r=r(Swt,"TFMobileBertModel"),Swt.forEach(t),R1r=r(TIe," (MobileBERT model)"),TIe.forEach(t),P1r=i(D),FM=n(D,"LI",{});var MIe=s(FM);Hve=n(MIe,"STRONG",{});var Rwt=s(Hve);B1r=r(Rwt,"mpnet"),Rwt.forEach(t),I1r=r(MIe," \u2014 "),PH=n(MIe,"A",{href:!0});var Pwt=s(PH);N1r=r(Pwt,"TFMPNetModel"),Pwt.forEach(t),q1r=r(MIe," (MPNet model)"),MIe.forEach(t),j1r=i(D),TM=n(D,"LI",{});var EIe=s(TM);Uve=n(EIe,"STRONG",{});var Bwt=s(Uve);D1r=r(Bwt,"mt5"),Bwt.forEach(t),G1r=r(EIe," \u2014 "),BH=n(EIe,"A",{href:!0});var Iwt=s(BH);O1r=r(Iwt,"TFMT5Model"),Iwt.forEach(t),V1r=r(EIe," (MT5 model)"),EIe.forEach(t),X1r=i(D),MM=n(D,"LI",{});var CIe=s(MM);Jve=n(CIe,"STRONG",{});var Nwt=s(Jve);z1r=r(Nwt,"openai-gpt"),Nwt.forEach(t),Q1r=r(CIe," \u2014 "),IH=n(CIe,"A",{href:!0});var qwt=s(IH);W1r=r(qwt,"TFOpenAIGPTModel"),qwt.forEach(t),H1r=r(CIe," (OpenAI GPT model)"),CIe.forEach(t),U1r=i(D),EM=n(D,"LI",{});var wIe=s(EM);Yve=n(wIe,"STRONG",{});var jwt=s(Yve);J1r=r(jwt,"opt"),jwt.forEach(t),Y1r=r(wIe," \u2014 "),NH=n(wIe,"A",{href:!0});var Dwt=s(NH);K1r=r(Dwt,"TFOPTModel"),Dwt.forEach(t),Z1r=r(wIe," (OPT model)"),wIe.forEach(t),e2r=i(D),CM=n(D,"LI",{});var AIe=s(CM);Kve=n(AIe,"STRONG",{});var Gwt=s(Kve);o2r=r(Gwt,"pegasus"),Gwt.forEach(t),r2r=r(AIe," \u2014 "),qH=n(AIe,"A",{href:!0});var Owt=s(qH);t2r=r(Owt,"TFPegasusModel"),Owt.forEach(t),a2r=r(AIe," (Pegasus model)"),AIe.forEach(t),n2r=i(D),wM=n(D,"LI",{});var LIe=s(wM);Zve=n(LIe,"STRONG",{});var Vwt=s(Zve);s2r=r(Vwt,"rembert"),Vwt.forEach(t),l2r=r(LIe," \u2014 "),jH=n(LIe,"A",{href:!0});var Xwt=s(jH);i2r=r(Xwt,"TFRemBertModel"),Xwt.forEach(t),d2r=r(LIe," (RemBERT model)"),LIe.forEach(t),c2r=i(D),AM=n(D,"LI",{});var yIe=s(AM);eFe=n(yIe,"STRONG",{});var zwt=s(eFe);f2r=r(zwt,"roberta"),zwt.forEach(t),m2r=r(yIe," \u2014 "),DH=n(yIe,"A",{href:!0});var Qwt=s(DH);g2r=r(Qwt,"TFRobertaModel"),Qwt.forEach(t),h2r=r(yIe," (RoBERTa model)"),yIe.forEach(t),p2r=i(D),LM=n(D,"LI",{});var xIe=s(LM);oFe=n(xIe,"STRONG",{});var Wwt=s(oFe);_2r=r(Wwt,"roformer"),Wwt.forEach(t),u2r=r(xIe," \u2014 "),GH=n(xIe,"A",{href:!0});var Hwt=s(GH);b2r=r(Hwt,"TFRoFormerModel"),Hwt.forEach(t),v2r=r(xIe," (RoFormer model)"),xIe.forEach(t),F2r=i(D),yM=n(D,"LI",{});var $Ie=s(yM);rFe=n($Ie,"STRONG",{});var Uwt=s(rFe);T2r=r(Uwt,"speech_to_text"),Uwt.forEach(t),M2r=r($Ie," \u2014 "),OH=n($Ie,"A",{href:!0});var Jwt=s(OH);E2r=r(Jwt,"TFSpeech2TextModel"),Jwt.forEach(t),C2r=r($Ie," (Speech2Text model)"),$Ie.forEach(t),w2r=i(D),xM=n(D,"LI",{});var kIe=s(xM);tFe=n(kIe,"STRONG",{});var Ywt=s(tFe);A2r=r(Ywt,"swin"),Ywt.forEach(t),L2r=r(kIe," \u2014 "),VH=n(kIe,"A",{href:!0});var Kwt=s(VH);y2r=r(Kwt,"TFSwinModel"),Kwt.forEach(t),x2r=r(kIe," (Swin Transformer model)"),kIe.forEach(t),$2r=i(D),$M=n(D,"LI",{});var SIe=s($M);aFe=n(SIe,"STRONG",{});var Zwt=s(aFe);k2r=r(Zwt,"t5"),Zwt.forEach(t),S2r=r(SIe," \u2014 "),XH=n(SIe,"A",{href:!0});var eAt=s(XH);R2r=r(eAt,"TFT5Model"),eAt.forEach(t),P2r=r(SIe," (T5 model)"),SIe.forEach(t),B2r=i(D),kM=n(D,"LI",{});var RIe=s(kM);nFe=n(RIe,"STRONG",{});var oAt=s(nFe);I2r=r(oAt,"tapas"),oAt.forEach(t),N2r=r(RIe," \u2014 "),zH=n(RIe,"A",{href:!0});var rAt=s(zH);q2r=r(rAt,"TFTapasModel"),rAt.forEach(t),j2r=r(RIe," (TAPAS model)"),RIe.forEach(t),D2r=i(D),SM=n(D,"LI",{});var PIe=s(SM);sFe=n(PIe,"STRONG",{});var tAt=s(sFe);G2r=r(tAt,"transfo-xl"),tAt.forEach(t),O2r=r(PIe," \u2014 "),QH=n(PIe,"A",{href:!0});var aAt=s(QH);V2r=r(aAt,"TFTransfoXLModel"),aAt.forEach(t),X2r=r(PIe," (Transformer-XL model)"),PIe.forEach(t),z2r=i(D),RM=n(D,"LI",{});var BIe=s(RM);lFe=n(BIe,"STRONG",{});var nAt=s(lFe);Q2r=r(nAt,"vit"),nAt.forEach(t),W2r=r(BIe," \u2014 "),WH=n(BIe,"A",{href:!0});var sAt=s(WH);H2r=r(sAt,"TFViTModel"),sAt.forEach(t),U2r=r(BIe," (ViT model)"),BIe.forEach(t),J2r=i(D),PM=n(D,"LI",{});var IIe=s(PM);iFe=n(IIe,"STRONG",{});var lAt=s(iFe);Y2r=r(lAt,"vit_mae"),lAt.forEach(t),K2r=r(IIe," \u2014 "),HH=n(IIe,"A",{href:!0});var iAt=s(HH);Z2r=r(iAt,"TFViTMAEModel"),iAt.forEach(t),ebr=r(IIe," (ViTMAE model)"),IIe.forEach(t),obr=i(D),BM=n(D,"LI",{});var NIe=s(BM);dFe=n(NIe,"STRONG",{});var dAt=s(dFe);rbr=r(dAt,"wav2vec2"),dAt.forEach(t),tbr=r(NIe," \u2014 "),UH=n(NIe,"A",{href:!0});var cAt=s(UH);abr=r(cAt,"TFWav2Vec2Model"),cAt.forEach(t),nbr=r(NIe," (Wav2Vec2 model)"),NIe.forEach(t),sbr=i(D),IM=n(D,"LI",{});var qIe=s(IM);cFe=n(qIe,"STRONG",{});var fAt=s(cFe);lbr=r(fAt,"xlm"),fAt.forEach(t),ibr=r(qIe," \u2014 "),JH=n(qIe,"A",{href:!0});var mAt=s(JH);dbr=r(mAt,"TFXLMModel"),mAt.forEach(t),cbr=r(qIe," (XLM model)"),qIe.forEach(t),fbr=i(D),NM=n(D,"LI",{});var jIe=s(NM);fFe=n(jIe,"STRONG",{});var gAt=s(fFe);mbr=r(gAt,"xlm-roberta"),gAt.forEach(t),gbr=r(jIe," \u2014 "),YH=n(jIe,"A",{href:!0});var hAt=s(YH);hbr=r(hAt,"TFXLMRobertaModel"),hAt.forEach(t),pbr=r(jIe," (XLM-RoBERTa model)"),jIe.forEach(t),_br=i(D),qM=n(D,"LI",{});var DIe=s(qM);mFe=n(DIe,"STRONG",{});var pAt=s(mFe);ubr=r(pAt,"xlnet"),pAt.forEach(t),bbr=r(DIe," \u2014 "),KH=n(DIe,"A",{href:!0});var _At=s(KH);vbr=r(_At,"TFXLNetModel"),_At.forEach(t),Fbr=r(DIe," (XLNet model)"),DIe.forEach(t),D.forEach(t),Tbr=i(Cl),T(jM.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),HOe=i(f),tc=n(f,"H2",{class:!0});var rze=s(tc);DM=n(rze,"A",{id:!0,class:!0,href:!0});var uAt=s(DM);gFe=n(uAt,"SPAN",{});var bAt=s(gFe);T(F9.$$.fragment,bAt),bAt.forEach(t),uAt.forEach(t),Mbr=i(rze),hFe=n(rze,"SPAN",{});var vAt=s(hFe);Ebr=r(vAt,"TFAutoModelForPreTraining"),vAt.forEach(t),rze.forEach(t),UOe=i(f),or=n(f,"DIV",{class:!0});var wl=s(or);T(T9.$$.fragment,wl),Cbr=i(wl),ac=n(wl,"P",{});var _re=s(ac);wbr=r(_re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=n(_re,"A",{href:!0});var FAt=s(ZH);Abr=r(FAt,"from_pretrained()"),FAt.forEach(t),Lbr=r(_re," class method or the "),eU=n(_re,"A",{href:!0});var TAt=s(eU);ybr=r(TAt,"from_config()"),TAt.forEach(t),xbr=r(_re,` class
method.`),_re.forEach(t),$br=i(wl),M9=n(wl,"P",{});var tze=s(M9);kbr=r(tze,"This class cannot be instantiated directly using "),pFe=n(tze,"CODE",{});var MAt=s(pFe);Sbr=r(MAt,"__init__()"),MAt.forEach(t),Rbr=r(tze," (throws an error)."),tze.forEach(t),Pbr=i(wl),kt=n(wl,"DIV",{class:!0});var yA=s(kt);T(E9.$$.fragment,yA),Bbr=i(yA),_Fe=n(yA,"P",{});var EAt=s(_Fe);Ibr=r(EAt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),EAt.forEach(t),Nbr=i(yA),nc=n(yA,"P",{});var ure=s(nc);qbr=r(ure,`Note:
Loading a model from its configuration file does `),uFe=n(ure,"STRONG",{});var CAt=s(uFe);jbr=r(CAt,"not"),CAt.forEach(t),Dbr=r(ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=n(ure,"A",{href:!0});var wAt=s(oU);Gbr=r(wAt,"from_pretrained()"),wAt.forEach(t),Obr=r(ure," to load the model weights."),ure.forEach(t),Vbr=i(yA),T(GM.$$.fragment,yA),yA.forEach(t),Xbr=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(C9.$$.fragment,Al),zbr=i(Al),bFe=n(Al,"P",{});var AAt=s(bFe);Qbr=r(AAt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),AAt.forEach(t),Wbr=i(Al),nn=n(Al,"P",{});var xA=s(nn);Hbr=r(xA,"The model class to instantiate is selected based on the "),vFe=n(xA,"CODE",{});var LAt=s(vFe);Ubr=r(LAt,"model_type"),LAt.forEach(t),Jbr=r(xA,` property of the config object (either
passed as an argument or loaded from `),FFe=n(xA,"CODE",{});var yAt=s(FFe);Ybr=r(yAt,"pretrained_model_name_or_path"),yAt.forEach(t),Kbr=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=n(xA,"CODE",{});var xAt=s(TFe);Zbr=r(xAt,"pretrained_model_name_or_path"),xAt.forEach(t),evr=r(xA,":"),xA.forEach(t),ovr=i(Al),se=n(Al,"UL",{});var le=s(se);OM=n(le,"LI",{});var GIe=s(OM);MFe=n(GIe,"STRONG",{});var $At=s(MFe);rvr=r($At,"albert"),$At.forEach(t),tvr=r(GIe," \u2014 "),rU=n(GIe,"A",{href:!0});var kAt=s(rU);avr=r(kAt,"TFAlbertForPreTraining"),kAt.forEach(t),nvr=r(GIe," (ALBERT model)"),GIe.forEach(t),svr=i(le),VM=n(le,"LI",{});var OIe=s(VM);EFe=n(OIe,"STRONG",{});var SAt=s(EFe);lvr=r(SAt,"bart"),SAt.forEach(t),ivr=r(OIe," \u2014 "),tU=n(OIe,"A",{href:!0});var RAt=s(tU);dvr=r(RAt,"TFBartForConditionalGeneration"),RAt.forEach(t),cvr=r(OIe," (BART model)"),OIe.forEach(t),fvr=i(le),XM=n(le,"LI",{});var VIe=s(XM);CFe=n(VIe,"STRONG",{});var PAt=s(CFe);mvr=r(PAt,"bert"),PAt.forEach(t),gvr=r(VIe," \u2014 "),aU=n(VIe,"A",{href:!0});var BAt=s(aU);hvr=r(BAt,"TFBertForPreTraining"),BAt.forEach(t),pvr=r(VIe," (BERT model)"),VIe.forEach(t),_vr=i(le),zM=n(le,"LI",{});var XIe=s(zM);wFe=n(XIe,"STRONG",{});var IAt=s(wFe);uvr=r(IAt,"camembert"),IAt.forEach(t),bvr=r(XIe," \u2014 "),nU=n(XIe,"A",{href:!0});var NAt=s(nU);vvr=r(NAt,"TFCamembertForMaskedLM"),NAt.forEach(t),Fvr=r(XIe," (CamemBERT model)"),XIe.forEach(t),Tvr=i(le),QM=n(le,"LI",{});var zIe=s(QM);AFe=n(zIe,"STRONG",{});var qAt=s(AFe);Mvr=r(qAt,"ctrl"),qAt.forEach(t),Evr=r(zIe," \u2014 "),sU=n(zIe,"A",{href:!0});var jAt=s(sU);Cvr=r(jAt,"TFCTRLLMHeadModel"),jAt.forEach(t),wvr=r(zIe," (CTRL model)"),zIe.forEach(t),Avr=i(le),WM=n(le,"LI",{});var QIe=s(WM);LFe=n(QIe,"STRONG",{});var DAt=s(LFe);Lvr=r(DAt,"distilbert"),DAt.forEach(t),yvr=r(QIe," \u2014 "),lU=n(QIe,"A",{href:!0});var GAt=s(lU);xvr=r(GAt,"TFDistilBertForMaskedLM"),GAt.forEach(t),$vr=r(QIe," (DistilBERT model)"),QIe.forEach(t),kvr=i(le),HM=n(le,"LI",{});var WIe=s(HM);yFe=n(WIe,"STRONG",{});var OAt=s(yFe);Svr=r(OAt,"electra"),OAt.forEach(t),Rvr=r(WIe," \u2014 "),iU=n(WIe,"A",{href:!0});var VAt=s(iU);Pvr=r(VAt,"TFElectraForPreTraining"),VAt.forEach(t),Bvr=r(WIe," (ELECTRA model)"),WIe.forEach(t),Ivr=i(le),UM=n(le,"LI",{});var HIe=s(UM);xFe=n(HIe,"STRONG",{});var XAt=s(xFe);Nvr=r(XAt,"flaubert"),XAt.forEach(t),qvr=r(HIe," \u2014 "),dU=n(HIe,"A",{href:!0});var zAt=s(dU);jvr=r(zAt,"TFFlaubertWithLMHeadModel"),zAt.forEach(t),Dvr=r(HIe," (FlauBERT model)"),HIe.forEach(t),Gvr=i(le),JM=n(le,"LI",{});var UIe=s(JM);$Fe=n(UIe,"STRONG",{});var QAt=s($Fe);Ovr=r(QAt,"funnel"),QAt.forEach(t),Vvr=r(UIe," \u2014 "),cU=n(UIe,"A",{href:!0});var WAt=s(cU);Xvr=r(WAt,"TFFunnelForPreTraining"),WAt.forEach(t),zvr=r(UIe," (Funnel Transformer model)"),UIe.forEach(t),Qvr=i(le),YM=n(le,"LI",{});var JIe=s(YM);kFe=n(JIe,"STRONG",{});var HAt=s(kFe);Wvr=r(HAt,"gpt2"),HAt.forEach(t),Hvr=r(JIe," \u2014 "),fU=n(JIe,"A",{href:!0});var UAt=s(fU);Uvr=r(UAt,"TFGPT2LMHeadModel"),UAt.forEach(t),Jvr=r(JIe," (OpenAI GPT-2 model)"),JIe.forEach(t),Yvr=i(le),KM=n(le,"LI",{});var YIe=s(KM);SFe=n(YIe,"STRONG",{});var JAt=s(SFe);Kvr=r(JAt,"layoutlm"),JAt.forEach(t),Zvr=r(YIe," \u2014 "),mU=n(YIe,"A",{href:!0});var YAt=s(mU);eFr=r(YAt,"TFLayoutLMForMaskedLM"),YAt.forEach(t),oFr=r(YIe," (LayoutLM model)"),YIe.forEach(t),rFr=i(le),ZM=n(le,"LI",{});var KIe=s(ZM);RFe=n(KIe,"STRONG",{});var KAt=s(RFe);tFr=r(KAt,"lxmert"),KAt.forEach(t),aFr=r(KIe," \u2014 "),gU=n(KIe,"A",{href:!0});var ZAt=s(gU);nFr=r(ZAt,"TFLxmertForPreTraining"),ZAt.forEach(t),sFr=r(KIe," (LXMERT model)"),KIe.forEach(t),lFr=i(le),eE=n(le,"LI",{});var ZIe=s(eE);PFe=n(ZIe,"STRONG",{});var eLt=s(PFe);iFr=r(eLt,"mobilebert"),eLt.forEach(t),dFr=r(ZIe," \u2014 "),hU=n(ZIe,"A",{href:!0});var oLt=s(hU);cFr=r(oLt,"TFMobileBertForPreTraining"),oLt.forEach(t),fFr=r(ZIe," (MobileBERT model)"),ZIe.forEach(t),mFr=i(le),oE=n(le,"LI",{});var eNe=s(oE);BFe=n(eNe,"STRONG",{});var rLt=s(BFe);gFr=r(rLt,"mpnet"),rLt.forEach(t),hFr=r(eNe," \u2014 "),pU=n(eNe,"A",{href:!0});var tLt=s(pU);pFr=r(tLt,"TFMPNetForMaskedLM"),tLt.forEach(t),_Fr=r(eNe," (MPNet model)"),eNe.forEach(t),uFr=i(le),rE=n(le,"LI",{});var oNe=s(rE);IFe=n(oNe,"STRONG",{});var aLt=s(IFe);bFr=r(aLt,"openai-gpt"),aLt.forEach(t),vFr=r(oNe," \u2014 "),_U=n(oNe,"A",{href:!0});var nLt=s(_U);FFr=r(nLt,"TFOpenAIGPTLMHeadModel"),nLt.forEach(t),TFr=r(oNe," (OpenAI GPT model)"),oNe.forEach(t),MFr=i(le),tE=n(le,"LI",{});var rNe=s(tE);NFe=n(rNe,"STRONG",{});var sLt=s(NFe);EFr=r(sLt,"roberta"),sLt.forEach(t),CFr=r(rNe," \u2014 "),uU=n(rNe,"A",{href:!0});var lLt=s(uU);wFr=r(lLt,"TFRobertaForMaskedLM"),lLt.forEach(t),AFr=r(rNe," (RoBERTa model)"),rNe.forEach(t),LFr=i(le),aE=n(le,"LI",{});var tNe=s(aE);qFe=n(tNe,"STRONG",{});var iLt=s(qFe);yFr=r(iLt,"t5"),iLt.forEach(t),xFr=r(tNe," \u2014 "),bU=n(tNe,"A",{href:!0});var dLt=s(bU);$Fr=r(dLt,"TFT5ForConditionalGeneration"),dLt.forEach(t),kFr=r(tNe," (T5 model)"),tNe.forEach(t),SFr=i(le),nE=n(le,"LI",{});var aNe=s(nE);jFe=n(aNe,"STRONG",{});var cLt=s(jFe);RFr=r(cLt,"tapas"),cLt.forEach(t),PFr=r(aNe," \u2014 "),vU=n(aNe,"A",{href:!0});var fLt=s(vU);BFr=r(fLt,"TFTapasForMaskedLM"),fLt.forEach(t),IFr=r(aNe," (TAPAS model)"),aNe.forEach(t),NFr=i(le),sE=n(le,"LI",{});var nNe=s(sE);DFe=n(nNe,"STRONG",{});var mLt=s(DFe);qFr=r(mLt,"transfo-xl"),mLt.forEach(t),jFr=r(nNe," \u2014 "),FU=n(nNe,"A",{href:!0});var gLt=s(FU);DFr=r(gLt,"TFTransfoXLLMHeadModel"),gLt.forEach(t),GFr=r(nNe," (Transformer-XL model)"),nNe.forEach(t),OFr=i(le),lE=n(le,"LI",{});var sNe=s(lE);GFe=n(sNe,"STRONG",{});var hLt=s(GFe);VFr=r(hLt,"vit_mae"),hLt.forEach(t),XFr=r(sNe," \u2014 "),TU=n(sNe,"A",{href:!0});var pLt=s(TU);zFr=r(pLt,"TFViTMAEForPreTraining"),pLt.forEach(t),QFr=r(sNe," (ViTMAE model)"),sNe.forEach(t),WFr=i(le),iE=n(le,"LI",{});var lNe=s(iE);OFe=n(lNe,"STRONG",{});var _Lt=s(OFe);HFr=r(_Lt,"xlm"),_Lt.forEach(t),UFr=r(lNe," \u2014 "),MU=n(lNe,"A",{href:!0});var uLt=s(MU);JFr=r(uLt,"TFXLMWithLMHeadModel"),uLt.forEach(t),YFr=r(lNe," (XLM model)"),lNe.forEach(t),KFr=i(le),dE=n(le,"LI",{});var iNe=s(dE);VFe=n(iNe,"STRONG",{});var bLt=s(VFe);ZFr=r(bLt,"xlm-roberta"),bLt.forEach(t),e6r=r(iNe," \u2014 "),EU=n(iNe,"A",{href:!0});var vLt=s(EU);o6r=r(vLt,"TFXLMRobertaForMaskedLM"),vLt.forEach(t),r6r=r(iNe," (XLM-RoBERTa model)"),iNe.forEach(t),t6r=i(le),cE=n(le,"LI",{});var dNe=s(cE);XFe=n(dNe,"STRONG",{});var FLt=s(XFe);a6r=r(FLt,"xlnet"),FLt.forEach(t),n6r=r(dNe," \u2014 "),CU=n(dNe,"A",{href:!0});var TLt=s(CU);s6r=r(TLt,"TFXLNetLMHeadModel"),TLt.forEach(t),l6r=r(dNe," (XLNet model)"),dNe.forEach(t),le.forEach(t),i6r=i(Al),T(fE.$$.fragment,Al),Al.forEach(t),wl.forEach(t),JOe=i(f),sc=n(f,"H2",{class:!0});var aze=s(sc);mE=n(aze,"A",{id:!0,class:!0,href:!0});var MLt=s(mE);zFe=n(MLt,"SPAN",{});var ELt=s(zFe);T(w9.$$.fragment,ELt),ELt.forEach(t),MLt.forEach(t),d6r=i(aze),QFe=n(aze,"SPAN",{});var CLt=s(QFe);c6r=r(CLt,"TFAutoModelForCausalLM"),CLt.forEach(t),aze.forEach(t),YOe=i(f),rr=n(f,"DIV",{class:!0});var Ll=s(rr);T(A9.$$.fragment,Ll),f6r=i(Ll),lc=n(Ll,"P",{});var bre=s(lc);m6r=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=n(bre,"A",{href:!0});var wLt=s(wU);g6r=r(wLt,"from_pretrained()"),wLt.forEach(t),h6r=r(bre," class method or the "),AU=n(bre,"A",{href:!0});var ALt=s(AU);p6r=r(ALt,"from_config()"),ALt.forEach(t),_6r=r(bre,` class
method.`),bre.forEach(t),u6r=i(Ll),L9=n(Ll,"P",{});var nze=s(L9);b6r=r(nze,"This class cannot be instantiated directly using "),WFe=n(nze,"CODE",{});var LLt=s(WFe);v6r=r(LLt,"__init__()"),LLt.forEach(t),F6r=r(nze," (throws an error)."),nze.forEach(t),T6r=i(Ll),St=n(Ll,"DIV",{class:!0});var $A=s(St);T(y9.$$.fragment,$A),M6r=i($A),HFe=n($A,"P",{});var yLt=s(HFe);E6r=r(yLt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yLt.forEach(t),C6r=i($A),ic=n($A,"P",{});var vre=s(ic);w6r=r(vre,`Note:
Loading a model from its configuration file does `),UFe=n(vre,"STRONG",{});var xLt=s(UFe);A6r=r(xLt,"not"),xLt.forEach(t),L6r=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(vre,"A",{href:!0});var $Lt=s(LU);y6r=r($Lt,"from_pretrained()"),$Lt.forEach(t),x6r=r(vre," to load the model weights."),vre.forEach(t),$6r=i($A),T(gE.$$.fragment,$A),$A.forEach(t),k6r=i(Ll),$r=n(Ll,"DIV",{class:!0});var yl=s($r);T(x9.$$.fragment,yl),S6r=i(yl),JFe=n(yl,"P",{});var kLt=s(JFe);R6r=r(kLt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kLt.forEach(t),P6r=i(yl),sn=n(yl,"P",{});var kA=s(sn);B6r=r(kA,"The model class to instantiate is selected based on the "),YFe=n(kA,"CODE",{});var SLt=s(YFe);I6r=r(SLt,"model_type"),SLt.forEach(t),N6r=r(kA,` property of the config object (either
passed as an argument or loaded from `),KFe=n(kA,"CODE",{});var RLt=s(KFe);q6r=r(RLt,"pretrained_model_name_or_path"),RLt.forEach(t),j6r=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=n(kA,"CODE",{});var PLt=s(ZFe);D6r=r(PLt,"pretrained_model_name_or_path"),PLt.forEach(t),G6r=r(kA,":"),kA.forEach(t),O6r=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);hE=n(Ce,"LI",{});var cNe=s(hE);e6e=n(cNe,"STRONG",{});var BLt=s(e6e);V6r=r(BLt,"bert"),BLt.forEach(t),X6r=r(cNe," \u2014 "),yU=n(cNe,"A",{href:!0});var ILt=s(yU);z6r=r(ILt,"TFBertLMHeadModel"),ILt.forEach(t),Q6r=r(cNe," (BERT model)"),cNe.forEach(t),W6r=i(Ce),pE=n(Ce,"LI",{});var fNe=s(pE);o6e=n(fNe,"STRONG",{});var NLt=s(o6e);H6r=r(NLt,"camembert"),NLt.forEach(t),U6r=r(fNe," \u2014 "),xU=n(fNe,"A",{href:!0});var qLt=s(xU);J6r=r(qLt,"TFCamembertForCausalLM"),qLt.forEach(t),Y6r=r(fNe," (CamemBERT model)"),fNe.forEach(t),K6r=i(Ce),_E=n(Ce,"LI",{});var mNe=s(_E);r6e=n(mNe,"STRONG",{});var jLt=s(r6e);Z6r=r(jLt,"ctrl"),jLt.forEach(t),eTr=r(mNe," \u2014 "),$U=n(mNe,"A",{href:!0});var DLt=s($U);oTr=r(DLt,"TFCTRLLMHeadModel"),DLt.forEach(t),rTr=r(mNe," (CTRL model)"),mNe.forEach(t),tTr=i(Ce),uE=n(Ce,"LI",{});var gNe=s(uE);t6e=n(gNe,"STRONG",{});var GLt=s(t6e);aTr=r(GLt,"gpt2"),GLt.forEach(t),nTr=r(gNe," \u2014 "),kU=n(gNe,"A",{href:!0});var OLt=s(kU);sTr=r(OLt,"TFGPT2LMHeadModel"),OLt.forEach(t),lTr=r(gNe," (OpenAI GPT-2 model)"),gNe.forEach(t),iTr=i(Ce),bE=n(Ce,"LI",{});var hNe=s(bE);a6e=n(hNe,"STRONG",{});var VLt=s(a6e);dTr=r(VLt,"gptj"),VLt.forEach(t),cTr=r(hNe," \u2014 "),SU=n(hNe,"A",{href:!0});var XLt=s(SU);fTr=r(XLt,"TFGPTJForCausalLM"),XLt.forEach(t),mTr=r(hNe," (GPT-J model)"),hNe.forEach(t),gTr=i(Ce),vE=n(Ce,"LI",{});var pNe=s(vE);n6e=n(pNe,"STRONG",{});var zLt=s(n6e);hTr=r(zLt,"openai-gpt"),zLt.forEach(t),pTr=r(pNe," \u2014 "),RU=n(pNe,"A",{href:!0});var QLt=s(RU);_Tr=r(QLt,"TFOpenAIGPTLMHeadModel"),QLt.forEach(t),uTr=r(pNe," (OpenAI GPT model)"),pNe.forEach(t),bTr=i(Ce),FE=n(Ce,"LI",{});var _Ne=s(FE);s6e=n(_Ne,"STRONG",{});var WLt=s(s6e);vTr=r(WLt,"opt"),WLt.forEach(t),FTr=r(_Ne," \u2014 "),PU=n(_Ne,"A",{href:!0});var HLt=s(PU);TTr=r(HLt,"TFOPTForCausalLM"),HLt.forEach(t),MTr=r(_Ne," (OPT model)"),_Ne.forEach(t),ETr=i(Ce),TE=n(Ce,"LI",{});var uNe=s(TE);l6e=n(uNe,"STRONG",{});var ULt=s(l6e);CTr=r(ULt,"rembert"),ULt.forEach(t),wTr=r(uNe," \u2014 "),BU=n(uNe,"A",{href:!0});var JLt=s(BU);ATr=r(JLt,"TFRemBertForCausalLM"),JLt.forEach(t),LTr=r(uNe," (RemBERT model)"),uNe.forEach(t),yTr=i(Ce),ME=n(Ce,"LI",{});var bNe=s(ME);i6e=n(bNe,"STRONG",{});var YLt=s(i6e);xTr=r(YLt,"roberta"),YLt.forEach(t),$Tr=r(bNe," \u2014 "),IU=n(bNe,"A",{href:!0});var KLt=s(IU);kTr=r(KLt,"TFRobertaForCausalLM"),KLt.forEach(t),STr=r(bNe," (RoBERTa model)"),bNe.forEach(t),RTr=i(Ce),EE=n(Ce,"LI",{});var vNe=s(EE);d6e=n(vNe,"STRONG",{});var ZLt=s(d6e);PTr=r(ZLt,"roformer"),ZLt.forEach(t),BTr=r(vNe," \u2014 "),NU=n(vNe,"A",{href:!0});var eyt=s(NU);ITr=r(eyt,"TFRoFormerForCausalLM"),eyt.forEach(t),NTr=r(vNe," (RoFormer model)"),vNe.forEach(t),qTr=i(Ce),CE=n(Ce,"LI",{});var FNe=s(CE);c6e=n(FNe,"STRONG",{});var oyt=s(c6e);jTr=r(oyt,"transfo-xl"),oyt.forEach(t),DTr=r(FNe," \u2014 "),qU=n(FNe,"A",{href:!0});var ryt=s(qU);GTr=r(ryt,"TFTransfoXLLMHeadModel"),ryt.forEach(t),OTr=r(FNe," (Transformer-XL model)"),FNe.forEach(t),VTr=i(Ce),wE=n(Ce,"LI",{});var TNe=s(wE);f6e=n(TNe,"STRONG",{});var tyt=s(f6e);XTr=r(tyt,"xlm"),tyt.forEach(t),zTr=r(TNe," \u2014 "),jU=n(TNe,"A",{href:!0});var ayt=s(jU);QTr=r(ayt,"TFXLMWithLMHeadModel"),ayt.forEach(t),WTr=r(TNe," (XLM model)"),TNe.forEach(t),HTr=i(Ce),AE=n(Ce,"LI",{});var MNe=s(AE);m6e=n(MNe,"STRONG",{});var nyt=s(m6e);UTr=r(nyt,"xlnet"),nyt.forEach(t),JTr=r(MNe," \u2014 "),DU=n(MNe,"A",{href:!0});var syt=s(DU);YTr=r(syt,"TFXLNetLMHeadModel"),syt.forEach(t),KTr=r(MNe," (XLNet model)"),MNe.forEach(t),Ce.forEach(t),ZTr=i(yl),T(LE.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),KOe=i(f),dc=n(f,"H2",{class:!0});var sze=s(dc);yE=n(sze,"A",{id:!0,class:!0,href:!0});var lyt=s(yE);g6e=n(lyt,"SPAN",{});var iyt=s(g6e);T($9.$$.fragment,iyt),iyt.forEach(t),lyt.forEach(t),eMr=i(sze),h6e=n(sze,"SPAN",{});var dyt=s(h6e);oMr=r(dyt,"TFAutoModelForImageClassification"),dyt.forEach(t),sze.forEach(t),ZOe=i(f),tr=n(f,"DIV",{class:!0});var xl=s(tr);T(k9.$$.fragment,xl),rMr=i(xl),cc=n(xl,"P",{});var Fre=s(cc);tMr=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=n(Fre,"A",{href:!0});var cyt=s(GU);aMr=r(cyt,"from_pretrained()"),cyt.forEach(t),nMr=r(Fre," class method or the "),OU=n(Fre,"A",{href:!0});var fyt=s(OU);sMr=r(fyt,"from_config()"),fyt.forEach(t),lMr=r(Fre,` class
method.`),Fre.forEach(t),iMr=i(xl),S9=n(xl,"P",{});var lze=s(S9);dMr=r(lze,"This class cannot be instantiated directly using "),p6e=n(lze,"CODE",{});var myt=s(p6e);cMr=r(myt,"__init__()"),myt.forEach(t),fMr=r(lze," (throws an error)."),lze.forEach(t),mMr=i(xl),Rt=n(xl,"DIV",{class:!0});var SA=s(Rt);T(R9.$$.fragment,SA),gMr=i(SA),_6e=n(SA,"P",{});var gyt=s(_6e);hMr=r(gyt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),gyt.forEach(t),pMr=i(SA),fc=n(SA,"P",{});var Tre=s(fc);_Mr=r(Tre,`Note:
Loading a model from its configuration file does `),u6e=n(Tre,"STRONG",{});var hyt=s(u6e);uMr=r(hyt,"not"),hyt.forEach(t),bMr=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Tre,"A",{href:!0});var pyt=s(VU);vMr=r(pyt,"from_pretrained()"),pyt.forEach(t),FMr=r(Tre," to load the model weights."),Tre.forEach(t),TMr=i(SA),T(xE.$$.fragment,SA),SA.forEach(t),MMr=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(P9.$$.fragment,$l),EMr=i($l),b6e=n($l,"P",{});var _yt=s(b6e);CMr=r(_yt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_yt.forEach(t),wMr=i($l),ln=n($l,"P",{});var RA=s(ln);AMr=r(RA,"The model class to instantiate is selected based on the "),v6e=n(RA,"CODE",{});var uyt=s(v6e);LMr=r(uyt,"model_type"),uyt.forEach(t),yMr=r(RA,` property of the config object (either
passed as an argument or loaded from `),F6e=n(RA,"CODE",{});var byt=s(F6e);xMr=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),$Mr=r(RA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=n(RA,"CODE",{});var vyt=s(T6e);kMr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),SMr=r(RA,":"),RA.forEach(t),RMr=i($l),dn=n($l,"UL",{});var PA=s(dn);$E=n(PA,"LI",{});var ENe=s($E);M6e=n(ENe,"STRONG",{});var Fyt=s(M6e);PMr=r(Fyt,"convnext"),Fyt.forEach(t),BMr=r(ENe," \u2014 "),XU=n(ENe,"A",{href:!0});var Tyt=s(XU);IMr=r(Tyt,"TFConvNextForImageClassification"),Tyt.forEach(t),NMr=r(ENe," (ConvNeXT model)"),ENe.forEach(t),qMr=i(PA),kE=n(PA,"LI",{});var CNe=s(kE);E6e=n(CNe,"STRONG",{});var Myt=s(E6e);jMr=r(Myt,"data2vec-vision"),Myt.forEach(t),DMr=r(CNe," \u2014 "),zU=n(CNe,"A",{href:!0});var Eyt=s(zU);GMr=r(Eyt,"TFData2VecVisionForImageClassification"),Eyt.forEach(t),OMr=r(CNe," (Data2VecVision model)"),CNe.forEach(t),VMr=i(PA),SE=n(PA,"LI",{});var wNe=s(SE);C6e=n(wNe,"STRONG",{});var Cyt=s(C6e);XMr=r(Cyt,"swin"),Cyt.forEach(t),zMr=r(wNe," \u2014 "),QU=n(wNe,"A",{href:!0});var wyt=s(QU);QMr=r(wyt,"TFSwinForImageClassification"),wyt.forEach(t),WMr=r(wNe," (Swin Transformer model)"),wNe.forEach(t),HMr=i(PA),RE=n(PA,"LI",{});var ANe=s(RE);w6e=n(ANe,"STRONG",{});var Ayt=s(w6e);UMr=r(Ayt,"vit"),Ayt.forEach(t),JMr=r(ANe," \u2014 "),WU=n(ANe,"A",{href:!0});var Lyt=s(WU);YMr=r(Lyt,"TFViTForImageClassification"),Lyt.forEach(t),KMr=r(ANe," (ViT model)"),ANe.forEach(t),PA.forEach(t),ZMr=i($l),T(PE.$$.fragment,$l),$l.forEach(t),xl.forEach(t),eVe=i(f),mc=n(f,"H2",{class:!0});var ize=s(mc);BE=n(ize,"A",{id:!0,class:!0,href:!0});var yyt=s(BE);A6e=n(yyt,"SPAN",{});var xyt=s(A6e);T(B9.$$.fragment,xyt),xyt.forEach(t),yyt.forEach(t),eEr=i(ize),L6e=n(ize,"SPAN",{});var $yt=s(L6e);oEr=r($yt,"TFAutoModelForMaskedLM"),$yt.forEach(t),ize.forEach(t),oVe=i(f),ar=n(f,"DIV",{class:!0});var kl=s(ar);T(I9.$$.fragment,kl),rEr=i(kl),gc=n(kl,"P",{});var Mre=s(gc);tEr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=n(Mre,"A",{href:!0});var kyt=s(HU);aEr=r(kyt,"from_pretrained()"),kyt.forEach(t),nEr=r(Mre," class method or the "),UU=n(Mre,"A",{href:!0});var Syt=s(UU);sEr=r(Syt,"from_config()"),Syt.forEach(t),lEr=r(Mre,` class
method.`),Mre.forEach(t),iEr=i(kl),N9=n(kl,"P",{});var dze=s(N9);dEr=r(dze,"This class cannot be instantiated directly using "),y6e=n(dze,"CODE",{});var Ryt=s(y6e);cEr=r(Ryt,"__init__()"),Ryt.forEach(t),fEr=r(dze," (throws an error)."),dze.forEach(t),mEr=i(kl),Pt=n(kl,"DIV",{class:!0});var BA=s(Pt);T(q9.$$.fragment,BA),gEr=i(BA),x6e=n(BA,"P",{});var Pyt=s(x6e);hEr=r(Pyt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Pyt.forEach(t),pEr=i(BA),hc=n(BA,"P",{});var Ere=s(hc);_Er=r(Ere,`Note:
Loading a model from its configuration file does `),$6e=n(Ere,"STRONG",{});var Byt=s($6e);uEr=r(Byt,"not"),Byt.forEach(t),bEr=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=n(Ere,"A",{href:!0});var Iyt=s(JU);vEr=r(Iyt,"from_pretrained()"),Iyt.forEach(t),FEr=r(Ere," to load the model weights."),Ere.forEach(t),TEr=i(BA),T(IE.$$.fragment,BA),BA.forEach(t),MEr=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(j9.$$.fragment,Sl),EEr=i(Sl),k6e=n(Sl,"P",{});var Nyt=s(k6e);CEr=r(Nyt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Nyt.forEach(t),wEr=i(Sl),cn=n(Sl,"P",{});var IA=s(cn);AEr=r(IA,"The model class to instantiate is selected based on the "),S6e=n(IA,"CODE",{});var qyt=s(S6e);LEr=r(qyt,"model_type"),qyt.forEach(t),yEr=r(IA,` property of the config object (either
passed as an argument or loaded from `),R6e=n(IA,"CODE",{});var jyt=s(R6e);xEr=r(jyt,"pretrained_model_name_or_path"),jyt.forEach(t),$Er=r(IA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=n(IA,"CODE",{});var Dyt=s(P6e);kEr=r(Dyt,"pretrained_model_name_or_path"),Dyt.forEach(t),SEr=r(IA,":"),IA.forEach(t),REr=i(Sl),ie=n(Sl,"UL",{});var fe=s(ie);NE=n(fe,"LI",{});var LNe=s(NE);B6e=n(LNe,"STRONG",{});var Gyt=s(B6e);PEr=r(Gyt,"albert"),Gyt.forEach(t),BEr=r(LNe," \u2014 "),YU=n(LNe,"A",{href:!0});var Oyt=s(YU);IEr=r(Oyt,"TFAlbertForMaskedLM"),Oyt.forEach(t),NEr=r(LNe," (ALBERT model)"),LNe.forEach(t),qEr=i(fe),qE=n(fe,"LI",{});var yNe=s(qE);I6e=n(yNe,"STRONG",{});var Vyt=s(I6e);jEr=r(Vyt,"bert"),Vyt.forEach(t),DEr=r(yNe," \u2014 "),KU=n(yNe,"A",{href:!0});var Xyt=s(KU);GEr=r(Xyt,"TFBertForMaskedLM"),Xyt.forEach(t),OEr=r(yNe," (BERT model)"),yNe.forEach(t),VEr=i(fe),jE=n(fe,"LI",{});var xNe=s(jE);N6e=n(xNe,"STRONG",{});var zyt=s(N6e);XEr=r(zyt,"camembert"),zyt.forEach(t),zEr=r(xNe," \u2014 "),ZU=n(xNe,"A",{href:!0});var Qyt=s(ZU);QEr=r(Qyt,"TFCamembertForMaskedLM"),Qyt.forEach(t),WEr=r(xNe," (CamemBERT model)"),xNe.forEach(t),HEr=i(fe),DE=n(fe,"LI",{});var $Ne=s(DE);q6e=n($Ne,"STRONG",{});var Wyt=s(q6e);UEr=r(Wyt,"convbert"),Wyt.forEach(t),JEr=r($Ne," \u2014 "),eJ=n($Ne,"A",{href:!0});var Hyt=s(eJ);YEr=r(Hyt,"TFConvBertForMaskedLM"),Hyt.forEach(t),KEr=r($Ne," (ConvBERT model)"),$Ne.forEach(t),ZEr=i(fe),GE=n(fe,"LI",{});var kNe=s(GE);j6e=n(kNe,"STRONG",{});var Uyt=s(j6e);e4r=r(Uyt,"deberta"),Uyt.forEach(t),o4r=r(kNe," \u2014 "),oJ=n(kNe,"A",{href:!0});var Jyt=s(oJ);r4r=r(Jyt,"TFDebertaForMaskedLM"),Jyt.forEach(t),t4r=r(kNe," (DeBERTa model)"),kNe.forEach(t),a4r=i(fe),OE=n(fe,"LI",{});var SNe=s(OE);D6e=n(SNe,"STRONG",{});var Yyt=s(D6e);n4r=r(Yyt,"deberta-v2"),Yyt.forEach(t),s4r=r(SNe," \u2014 "),rJ=n(SNe,"A",{href:!0});var Kyt=s(rJ);l4r=r(Kyt,"TFDebertaV2ForMaskedLM"),Kyt.forEach(t),i4r=r(SNe," (DeBERTa-v2 model)"),SNe.forEach(t),d4r=i(fe),VE=n(fe,"LI",{});var RNe=s(VE);G6e=n(RNe,"STRONG",{});var Zyt=s(G6e);c4r=r(Zyt,"distilbert"),Zyt.forEach(t),f4r=r(RNe," \u2014 "),tJ=n(RNe,"A",{href:!0});var e8t=s(tJ);m4r=r(e8t,"TFDistilBertForMaskedLM"),e8t.forEach(t),g4r=r(RNe," (DistilBERT model)"),RNe.forEach(t),h4r=i(fe),XE=n(fe,"LI",{});var PNe=s(XE);O6e=n(PNe,"STRONG",{});var o8t=s(O6e);p4r=r(o8t,"electra"),o8t.forEach(t),_4r=r(PNe," \u2014 "),aJ=n(PNe,"A",{href:!0});var r8t=s(aJ);u4r=r(r8t,"TFElectraForMaskedLM"),r8t.forEach(t),b4r=r(PNe," (ELECTRA model)"),PNe.forEach(t),v4r=i(fe),zE=n(fe,"LI",{});var BNe=s(zE);V6e=n(BNe,"STRONG",{});var t8t=s(V6e);F4r=r(t8t,"flaubert"),t8t.forEach(t),T4r=r(BNe," \u2014 "),nJ=n(BNe,"A",{href:!0});var a8t=s(nJ);M4r=r(a8t,"TFFlaubertWithLMHeadModel"),a8t.forEach(t),E4r=r(BNe," (FlauBERT model)"),BNe.forEach(t),C4r=i(fe),QE=n(fe,"LI",{});var INe=s(QE);X6e=n(INe,"STRONG",{});var n8t=s(X6e);w4r=r(n8t,"funnel"),n8t.forEach(t),A4r=r(INe," \u2014 "),sJ=n(INe,"A",{href:!0});var s8t=s(sJ);L4r=r(s8t,"TFFunnelForMaskedLM"),s8t.forEach(t),y4r=r(INe," (Funnel Transformer model)"),INe.forEach(t),x4r=i(fe),WE=n(fe,"LI",{});var NNe=s(WE);z6e=n(NNe,"STRONG",{});var l8t=s(z6e);$4r=r(l8t,"layoutlm"),l8t.forEach(t),k4r=r(NNe," \u2014 "),lJ=n(NNe,"A",{href:!0});var i8t=s(lJ);S4r=r(i8t,"TFLayoutLMForMaskedLM"),i8t.forEach(t),R4r=r(NNe," (LayoutLM model)"),NNe.forEach(t),P4r=i(fe),HE=n(fe,"LI",{});var qNe=s(HE);Q6e=n(qNe,"STRONG",{});var d8t=s(Q6e);B4r=r(d8t,"longformer"),d8t.forEach(t),I4r=r(qNe," \u2014 "),iJ=n(qNe,"A",{href:!0});var c8t=s(iJ);N4r=r(c8t,"TFLongformerForMaskedLM"),c8t.forEach(t),q4r=r(qNe," (Longformer model)"),qNe.forEach(t),j4r=i(fe),UE=n(fe,"LI",{});var jNe=s(UE);W6e=n(jNe,"STRONG",{});var f8t=s(W6e);D4r=r(f8t,"mobilebert"),f8t.forEach(t),G4r=r(jNe," \u2014 "),dJ=n(jNe,"A",{href:!0});var m8t=s(dJ);O4r=r(m8t,"TFMobileBertForMaskedLM"),m8t.forEach(t),V4r=r(jNe," (MobileBERT model)"),jNe.forEach(t),X4r=i(fe),JE=n(fe,"LI",{});var DNe=s(JE);H6e=n(DNe,"STRONG",{});var g8t=s(H6e);z4r=r(g8t,"mpnet"),g8t.forEach(t),Q4r=r(DNe," \u2014 "),cJ=n(DNe,"A",{href:!0});var h8t=s(cJ);W4r=r(h8t,"TFMPNetForMaskedLM"),h8t.forEach(t),H4r=r(DNe," (MPNet model)"),DNe.forEach(t),U4r=i(fe),YE=n(fe,"LI",{});var GNe=s(YE);U6e=n(GNe,"STRONG",{});var p8t=s(U6e);J4r=r(p8t,"rembert"),p8t.forEach(t),Y4r=r(GNe," \u2014 "),fJ=n(GNe,"A",{href:!0});var _8t=s(fJ);K4r=r(_8t,"TFRemBertForMaskedLM"),_8t.forEach(t),Z4r=r(GNe," (RemBERT model)"),GNe.forEach(t),eCr=i(fe),KE=n(fe,"LI",{});var ONe=s(KE);J6e=n(ONe,"STRONG",{});var u8t=s(J6e);oCr=r(u8t,"roberta"),u8t.forEach(t),rCr=r(ONe," \u2014 "),mJ=n(ONe,"A",{href:!0});var b8t=s(mJ);tCr=r(b8t,"TFRobertaForMaskedLM"),b8t.forEach(t),aCr=r(ONe," (RoBERTa model)"),ONe.forEach(t),nCr=i(fe),ZE=n(fe,"LI",{});var VNe=s(ZE);Y6e=n(VNe,"STRONG",{});var v8t=s(Y6e);sCr=r(v8t,"roformer"),v8t.forEach(t),lCr=r(VNe," \u2014 "),gJ=n(VNe,"A",{href:!0});var F8t=s(gJ);iCr=r(F8t,"TFRoFormerForMaskedLM"),F8t.forEach(t),dCr=r(VNe," (RoFormer model)"),VNe.forEach(t),cCr=i(fe),e4=n(fe,"LI",{});var XNe=s(e4);K6e=n(XNe,"STRONG",{});var T8t=s(K6e);fCr=r(T8t,"tapas"),T8t.forEach(t),mCr=r(XNe," \u2014 "),hJ=n(XNe,"A",{href:!0});var M8t=s(hJ);gCr=r(M8t,"TFTapasForMaskedLM"),M8t.forEach(t),hCr=r(XNe," (TAPAS model)"),XNe.forEach(t),pCr=i(fe),o4=n(fe,"LI",{});var zNe=s(o4);Z6e=n(zNe,"STRONG",{});var E8t=s(Z6e);_Cr=r(E8t,"xlm"),E8t.forEach(t),uCr=r(zNe," \u2014 "),pJ=n(zNe,"A",{href:!0});var C8t=s(pJ);bCr=r(C8t,"TFXLMWithLMHeadModel"),C8t.forEach(t),vCr=r(zNe," (XLM model)"),zNe.forEach(t),FCr=i(fe),r4=n(fe,"LI",{});var QNe=s(r4);eTe=n(QNe,"STRONG",{});var w8t=s(eTe);TCr=r(w8t,"xlm-roberta"),w8t.forEach(t),MCr=r(QNe," \u2014 "),_J=n(QNe,"A",{href:!0});var A8t=s(_J);ECr=r(A8t,"TFXLMRobertaForMaskedLM"),A8t.forEach(t),CCr=r(QNe," (XLM-RoBERTa model)"),QNe.forEach(t),fe.forEach(t),wCr=i(Sl),T(t4.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),rVe=i(f),pc=n(f,"H2",{class:!0});var cze=s(pc);a4=n(cze,"A",{id:!0,class:!0,href:!0});var L8t=s(a4);oTe=n(L8t,"SPAN",{});var y8t=s(oTe);T(D9.$$.fragment,y8t),y8t.forEach(t),L8t.forEach(t),ACr=i(cze),rTe=n(cze,"SPAN",{});var x8t=s(rTe);LCr=r(x8t,"TFAutoModelForSeq2SeqLM"),x8t.forEach(t),cze.forEach(t),tVe=i(f),nr=n(f,"DIV",{class:!0});var Rl=s(nr);T(G9.$$.fragment,Rl),yCr=i(Rl),_c=n(Rl,"P",{});var Cre=s(_c);xCr=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=n(Cre,"A",{href:!0});var $8t=s(uJ);$Cr=r($8t,"from_pretrained()"),$8t.forEach(t),kCr=r(Cre," class method or the "),bJ=n(Cre,"A",{href:!0});var k8t=s(bJ);SCr=r(k8t,"from_config()"),k8t.forEach(t),RCr=r(Cre,` class
method.`),Cre.forEach(t),PCr=i(Rl),O9=n(Rl,"P",{});var fze=s(O9);BCr=r(fze,"This class cannot be instantiated directly using "),tTe=n(fze,"CODE",{});var S8t=s(tTe);ICr=r(S8t,"__init__()"),S8t.forEach(t),NCr=r(fze," (throws an error)."),fze.forEach(t),qCr=i(Rl),Bt=n(Rl,"DIV",{class:!0});var NA=s(Bt);T(V9.$$.fragment,NA),jCr=i(NA),aTe=n(NA,"P",{});var R8t=s(aTe);DCr=r(R8t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),R8t.forEach(t),GCr=i(NA),uc=n(NA,"P",{});var wre=s(uc);OCr=r(wre,`Note:
Loading a model from its configuration file does `),nTe=n(wre,"STRONG",{});var P8t=s(nTe);VCr=r(P8t,"not"),P8t.forEach(t),XCr=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(wre,"A",{href:!0});var B8t=s(vJ);zCr=r(B8t,"from_pretrained()"),B8t.forEach(t),QCr=r(wre," to load the model weights."),wre.forEach(t),WCr=i(NA),T(n4.$$.fragment,NA),NA.forEach(t),HCr=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(X9.$$.fragment,Pl),UCr=i(Pl),sTe=n(Pl,"P",{});var I8t=s(sTe);JCr=r(I8t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),I8t.forEach(t),YCr=i(Pl),fn=n(Pl,"P",{});var qA=s(fn);KCr=r(qA,"The model class to instantiate is selected based on the "),lTe=n(qA,"CODE",{});var N8t=s(lTe);ZCr=r(N8t,"model_type"),N8t.forEach(t),e5r=r(qA,` property of the config object (either
passed as an argument or loaded from `),iTe=n(qA,"CODE",{});var q8t=s(iTe);o5r=r(q8t,"pretrained_model_name_or_path"),q8t.forEach(t),r5r=r(qA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=n(qA,"CODE",{});var j8t=s(dTe);t5r=r(j8t,"pretrained_model_name_or_path"),j8t.forEach(t),a5r=r(qA,":"),qA.forEach(t),n5r=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);s4=n(Ie,"LI",{});var WNe=s(s4);cTe=n(WNe,"STRONG",{});var D8t=s(cTe);s5r=r(D8t,"bart"),D8t.forEach(t),l5r=r(WNe," \u2014 "),FJ=n(WNe,"A",{href:!0});var G8t=s(FJ);i5r=r(G8t,"TFBartForConditionalGeneration"),G8t.forEach(t),d5r=r(WNe," (BART model)"),WNe.forEach(t),c5r=i(Ie),l4=n(Ie,"LI",{});var HNe=s(l4);fTe=n(HNe,"STRONG",{});var O8t=s(fTe);f5r=r(O8t,"blenderbot"),O8t.forEach(t),m5r=r(HNe," \u2014 "),TJ=n(HNe,"A",{href:!0});var V8t=s(TJ);g5r=r(V8t,"TFBlenderbotForConditionalGeneration"),V8t.forEach(t),h5r=r(HNe," (Blenderbot model)"),HNe.forEach(t),p5r=i(Ie),i4=n(Ie,"LI",{});var UNe=s(i4);mTe=n(UNe,"STRONG",{});var X8t=s(mTe);_5r=r(X8t,"blenderbot-small"),X8t.forEach(t),u5r=r(UNe," \u2014 "),MJ=n(UNe,"A",{href:!0});var z8t=s(MJ);b5r=r(z8t,"TFBlenderbotSmallForConditionalGeneration"),z8t.forEach(t),v5r=r(UNe," (BlenderbotSmall model)"),UNe.forEach(t),F5r=i(Ie),d4=n(Ie,"LI",{});var JNe=s(d4);gTe=n(JNe,"STRONG",{});var Q8t=s(gTe);T5r=r(Q8t,"encoder-decoder"),Q8t.forEach(t),M5r=r(JNe," \u2014 "),EJ=n(JNe,"A",{href:!0});var W8t=s(EJ);E5r=r(W8t,"TFEncoderDecoderModel"),W8t.forEach(t),C5r=r(JNe," (Encoder decoder model)"),JNe.forEach(t),w5r=i(Ie),c4=n(Ie,"LI",{});var YNe=s(c4);hTe=n(YNe,"STRONG",{});var H8t=s(hTe);A5r=r(H8t,"led"),H8t.forEach(t),L5r=r(YNe," \u2014 "),CJ=n(YNe,"A",{href:!0});var U8t=s(CJ);y5r=r(U8t,"TFLEDForConditionalGeneration"),U8t.forEach(t),x5r=r(YNe," (LED model)"),YNe.forEach(t),$5r=i(Ie),f4=n(Ie,"LI",{});var KNe=s(f4);pTe=n(KNe,"STRONG",{});var J8t=s(pTe);k5r=r(J8t,"marian"),J8t.forEach(t),S5r=r(KNe," \u2014 "),wJ=n(KNe,"A",{href:!0});var Y8t=s(wJ);R5r=r(Y8t,"TFMarianMTModel"),Y8t.forEach(t),P5r=r(KNe," (Marian model)"),KNe.forEach(t),B5r=i(Ie),m4=n(Ie,"LI",{});var ZNe=s(m4);_Te=n(ZNe,"STRONG",{});var K8t=s(_Te);I5r=r(K8t,"mbart"),K8t.forEach(t),N5r=r(ZNe," \u2014 "),AJ=n(ZNe,"A",{href:!0});var Z8t=s(AJ);q5r=r(Z8t,"TFMBartForConditionalGeneration"),Z8t.forEach(t),j5r=r(ZNe," (mBART model)"),ZNe.forEach(t),D5r=i(Ie),g4=n(Ie,"LI",{});var eqe=s(g4);uTe=n(eqe,"STRONG",{});var e9t=s(uTe);G5r=r(e9t,"mt5"),e9t.forEach(t),O5r=r(eqe," \u2014 "),LJ=n(eqe,"A",{href:!0});var o9t=s(LJ);V5r=r(o9t,"TFMT5ForConditionalGeneration"),o9t.forEach(t),X5r=r(eqe," (MT5 model)"),eqe.forEach(t),z5r=i(Ie),h4=n(Ie,"LI",{});var oqe=s(h4);bTe=n(oqe,"STRONG",{});var r9t=s(bTe);Q5r=r(r9t,"pegasus"),r9t.forEach(t),W5r=r(oqe," \u2014 "),yJ=n(oqe,"A",{href:!0});var t9t=s(yJ);H5r=r(t9t,"TFPegasusForConditionalGeneration"),t9t.forEach(t),U5r=r(oqe," (Pegasus model)"),oqe.forEach(t),J5r=i(Ie),p4=n(Ie,"LI",{});var rqe=s(p4);vTe=n(rqe,"STRONG",{});var a9t=s(vTe);Y5r=r(a9t,"t5"),a9t.forEach(t),K5r=r(rqe," \u2014 "),xJ=n(rqe,"A",{href:!0});var n9t=s(xJ);Z5r=r(n9t,"TFT5ForConditionalGeneration"),n9t.forEach(t),e3r=r(rqe," (T5 model)"),rqe.forEach(t),Ie.forEach(t),o3r=i(Pl),T(_4.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),aVe=i(f),bc=n(f,"H2",{class:!0});var mze=s(bc);u4=n(mze,"A",{id:!0,class:!0,href:!0});var s9t=s(u4);FTe=n(s9t,"SPAN",{});var l9t=s(FTe);T(z9.$$.fragment,l9t),l9t.forEach(t),s9t.forEach(t),r3r=i(mze),TTe=n(mze,"SPAN",{});var i9t=s(TTe);t3r=r(i9t,"TFAutoModelForSequenceClassification"),i9t.forEach(t),mze.forEach(t),nVe=i(f),sr=n(f,"DIV",{class:!0});var Bl=s(sr);T(Q9.$$.fragment,Bl),a3r=i(Bl),vc=n(Bl,"P",{});var Are=s(vc);n3r=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=n(Are,"A",{href:!0});var d9t=s($J);s3r=r(d9t,"from_pretrained()"),d9t.forEach(t),l3r=r(Are," class method or the "),kJ=n(Are,"A",{href:!0});var c9t=s(kJ);i3r=r(c9t,"from_config()"),c9t.forEach(t),d3r=r(Are,` class
method.`),Are.forEach(t),c3r=i(Bl),W9=n(Bl,"P",{});var gze=s(W9);f3r=r(gze,"This class cannot be instantiated directly using "),MTe=n(gze,"CODE",{});var f9t=s(MTe);m3r=r(f9t,"__init__()"),f9t.forEach(t),g3r=r(gze," (throws an error)."),gze.forEach(t),h3r=i(Bl),It=n(Bl,"DIV",{class:!0});var jA=s(It);T(H9.$$.fragment,jA),p3r=i(jA),ETe=n(jA,"P",{});var m9t=s(ETe);_3r=r(m9t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),m9t.forEach(t),u3r=i(jA),Fc=n(jA,"P",{});var Lre=s(Fc);b3r=r(Lre,`Note:
Loading a model from its configuration file does `),CTe=n(Lre,"STRONG",{});var g9t=s(CTe);v3r=r(g9t,"not"),g9t.forEach(t),F3r=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(Lre,"A",{href:!0});var h9t=s(SJ);T3r=r(h9t,"from_pretrained()"),h9t.forEach(t),M3r=r(Lre," to load the model weights."),Lre.forEach(t),E3r=i(jA),T(b4.$$.fragment,jA),jA.forEach(t),C3r=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(U9.$$.fragment,Il),w3r=i(Il),wTe=n(Il,"P",{});var p9t=s(wTe);A3r=r(p9t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),p9t.forEach(t),L3r=i(Il),mn=n(Il,"P",{});var DA=s(mn);y3r=r(DA,"The model class to instantiate is selected based on the "),ATe=n(DA,"CODE",{});var _9t=s(ATe);x3r=r(_9t,"model_type"),_9t.forEach(t),$3r=r(DA,` property of the config object (either
passed as an argument or loaded from `),LTe=n(DA,"CODE",{});var u9t=s(LTe);k3r=r(u9t,"pretrained_model_name_or_path"),u9t.forEach(t),S3r=r(DA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yTe=n(DA,"CODE",{});var b9t=s(yTe);R3r=r(b9t,"pretrained_model_name_or_path"),b9t.forEach(t),P3r=r(DA,":"),DA.forEach(t),B3r=i(Il),te=n(Il,"UL",{});var ne=s(te);v4=n(ne,"LI",{});var tqe=s(v4);xTe=n(tqe,"STRONG",{});var v9t=s(xTe);I3r=r(v9t,"albert"),v9t.forEach(t),N3r=r(tqe," \u2014 "),RJ=n(tqe,"A",{href:!0});var F9t=s(RJ);q3r=r(F9t,"TFAlbertForSequenceClassification"),F9t.forEach(t),j3r=r(tqe," (ALBERT model)"),tqe.forEach(t),D3r=i(ne),F4=n(ne,"LI",{});var aqe=s(F4);$Te=n(aqe,"STRONG",{});var T9t=s($Te);G3r=r(T9t,"bert"),T9t.forEach(t),O3r=r(aqe," \u2014 "),PJ=n(aqe,"A",{href:!0});var M9t=s(PJ);V3r=r(M9t,"TFBertForSequenceClassification"),M9t.forEach(t),X3r=r(aqe," (BERT model)"),aqe.forEach(t),z3r=i(ne),T4=n(ne,"LI",{});var nqe=s(T4);kTe=n(nqe,"STRONG",{});var E9t=s(kTe);Q3r=r(E9t,"camembert"),E9t.forEach(t),W3r=r(nqe," \u2014 "),BJ=n(nqe,"A",{href:!0});var C9t=s(BJ);H3r=r(C9t,"TFCamembertForSequenceClassification"),C9t.forEach(t),U3r=r(nqe," (CamemBERT model)"),nqe.forEach(t),J3r=i(ne),M4=n(ne,"LI",{});var sqe=s(M4);STe=n(sqe,"STRONG",{});var w9t=s(STe);Y3r=r(w9t,"convbert"),w9t.forEach(t),K3r=r(sqe," \u2014 "),IJ=n(sqe,"A",{href:!0});var A9t=s(IJ);Z3r=r(A9t,"TFConvBertForSequenceClassification"),A9t.forEach(t),e0r=r(sqe," (ConvBERT model)"),sqe.forEach(t),o0r=i(ne),E4=n(ne,"LI",{});var lqe=s(E4);RTe=n(lqe,"STRONG",{});var L9t=s(RTe);r0r=r(L9t,"ctrl"),L9t.forEach(t),t0r=r(lqe," \u2014 "),NJ=n(lqe,"A",{href:!0});var y9t=s(NJ);a0r=r(y9t,"TFCTRLForSequenceClassification"),y9t.forEach(t),n0r=r(lqe," (CTRL model)"),lqe.forEach(t),s0r=i(ne),C4=n(ne,"LI",{});var iqe=s(C4);PTe=n(iqe,"STRONG",{});var x9t=s(PTe);l0r=r(x9t,"deberta"),x9t.forEach(t),i0r=r(iqe," \u2014 "),qJ=n(iqe,"A",{href:!0});var $9t=s(qJ);d0r=r($9t,"TFDebertaForSequenceClassification"),$9t.forEach(t),c0r=r(iqe," (DeBERTa model)"),iqe.forEach(t),f0r=i(ne),w4=n(ne,"LI",{});var dqe=s(w4);BTe=n(dqe,"STRONG",{});var k9t=s(BTe);m0r=r(k9t,"deberta-v2"),k9t.forEach(t),g0r=r(dqe," \u2014 "),jJ=n(dqe,"A",{href:!0});var S9t=s(jJ);h0r=r(S9t,"TFDebertaV2ForSequenceClassification"),S9t.forEach(t),p0r=r(dqe," (DeBERTa-v2 model)"),dqe.forEach(t),_0r=i(ne),A4=n(ne,"LI",{});var cqe=s(A4);ITe=n(cqe,"STRONG",{});var R9t=s(ITe);u0r=r(R9t,"distilbert"),R9t.forEach(t),b0r=r(cqe," \u2014 "),DJ=n(cqe,"A",{href:!0});var P9t=s(DJ);v0r=r(P9t,"TFDistilBertForSequenceClassification"),P9t.forEach(t),F0r=r(cqe," (DistilBERT model)"),cqe.forEach(t),T0r=i(ne),L4=n(ne,"LI",{});var fqe=s(L4);NTe=n(fqe,"STRONG",{});var B9t=s(NTe);M0r=r(B9t,"electra"),B9t.forEach(t),E0r=r(fqe," \u2014 "),GJ=n(fqe,"A",{href:!0});var I9t=s(GJ);C0r=r(I9t,"TFElectraForSequenceClassification"),I9t.forEach(t),w0r=r(fqe," (ELECTRA model)"),fqe.forEach(t),A0r=i(ne),y4=n(ne,"LI",{});var mqe=s(y4);qTe=n(mqe,"STRONG",{});var N9t=s(qTe);L0r=r(N9t,"flaubert"),N9t.forEach(t),y0r=r(mqe," \u2014 "),OJ=n(mqe,"A",{href:!0});var q9t=s(OJ);x0r=r(q9t,"TFFlaubertForSequenceClassification"),q9t.forEach(t),$0r=r(mqe," (FlauBERT model)"),mqe.forEach(t),k0r=i(ne),x4=n(ne,"LI",{});var gqe=s(x4);jTe=n(gqe,"STRONG",{});var j9t=s(jTe);S0r=r(j9t,"funnel"),j9t.forEach(t),R0r=r(gqe," \u2014 "),VJ=n(gqe,"A",{href:!0});var D9t=s(VJ);P0r=r(D9t,"TFFunnelForSequenceClassification"),D9t.forEach(t),B0r=r(gqe," (Funnel Transformer model)"),gqe.forEach(t),I0r=i(ne),$4=n(ne,"LI",{});var hqe=s($4);DTe=n(hqe,"STRONG",{});var G9t=s(DTe);N0r=r(G9t,"gpt2"),G9t.forEach(t),q0r=r(hqe," \u2014 "),XJ=n(hqe,"A",{href:!0});var O9t=s(XJ);j0r=r(O9t,"TFGPT2ForSequenceClassification"),O9t.forEach(t),D0r=r(hqe," (OpenAI GPT-2 model)"),hqe.forEach(t),G0r=i(ne),k4=n(ne,"LI",{});var pqe=s(k4);GTe=n(pqe,"STRONG",{});var V9t=s(GTe);O0r=r(V9t,"gptj"),V9t.forEach(t),V0r=r(pqe," \u2014 "),zJ=n(pqe,"A",{href:!0});var X9t=s(zJ);X0r=r(X9t,"TFGPTJForSequenceClassification"),X9t.forEach(t),z0r=r(pqe," (GPT-J model)"),pqe.forEach(t),Q0r=i(ne),S4=n(ne,"LI",{});var _qe=s(S4);OTe=n(_qe,"STRONG",{});var z9t=s(OTe);W0r=r(z9t,"layoutlm"),z9t.forEach(t),H0r=r(_qe," \u2014 "),QJ=n(_qe,"A",{href:!0});var Q9t=s(QJ);U0r=r(Q9t,"TFLayoutLMForSequenceClassification"),Q9t.forEach(t),J0r=r(_qe," (LayoutLM model)"),_qe.forEach(t),Y0r=i(ne),R4=n(ne,"LI",{});var uqe=s(R4);VTe=n(uqe,"STRONG",{});var W9t=s(VTe);K0r=r(W9t,"longformer"),W9t.forEach(t),Z0r=r(uqe," \u2014 "),WJ=n(uqe,"A",{href:!0});var H9t=s(WJ);ewr=r(H9t,"TFLongformerForSequenceClassification"),H9t.forEach(t),owr=r(uqe," (Longformer model)"),uqe.forEach(t),rwr=i(ne),P4=n(ne,"LI",{});var bqe=s(P4);XTe=n(bqe,"STRONG",{});var U9t=s(XTe);twr=r(U9t,"mobilebert"),U9t.forEach(t),awr=r(bqe," \u2014 "),HJ=n(bqe,"A",{href:!0});var J9t=s(HJ);nwr=r(J9t,"TFMobileBertForSequenceClassification"),J9t.forEach(t),swr=r(bqe," (MobileBERT model)"),bqe.forEach(t),lwr=i(ne),B4=n(ne,"LI",{});var vqe=s(B4);zTe=n(vqe,"STRONG",{});var Y9t=s(zTe);iwr=r(Y9t,"mpnet"),Y9t.forEach(t),dwr=r(vqe," \u2014 "),UJ=n(vqe,"A",{href:!0});var K9t=s(UJ);cwr=r(K9t,"TFMPNetForSequenceClassification"),K9t.forEach(t),fwr=r(vqe," (MPNet model)"),vqe.forEach(t),mwr=i(ne),I4=n(ne,"LI",{});var Fqe=s(I4);QTe=n(Fqe,"STRONG",{});var Z9t=s(QTe);gwr=r(Z9t,"openai-gpt"),Z9t.forEach(t),hwr=r(Fqe," \u2014 "),JJ=n(Fqe,"A",{href:!0});var ext=s(JJ);pwr=r(ext,"TFOpenAIGPTForSequenceClassification"),ext.forEach(t),_wr=r(Fqe," (OpenAI GPT model)"),Fqe.forEach(t),uwr=i(ne),N4=n(ne,"LI",{});var Tqe=s(N4);WTe=n(Tqe,"STRONG",{});var oxt=s(WTe);bwr=r(oxt,"rembert"),oxt.forEach(t),vwr=r(Tqe," \u2014 "),YJ=n(Tqe,"A",{href:!0});var rxt=s(YJ);Fwr=r(rxt,"TFRemBertForSequenceClassification"),rxt.forEach(t),Twr=r(Tqe," (RemBERT model)"),Tqe.forEach(t),Mwr=i(ne),q4=n(ne,"LI",{});var Mqe=s(q4);HTe=n(Mqe,"STRONG",{});var txt=s(HTe);Ewr=r(txt,"roberta"),txt.forEach(t),Cwr=r(Mqe," \u2014 "),KJ=n(Mqe,"A",{href:!0});var axt=s(KJ);wwr=r(axt,"TFRobertaForSequenceClassification"),axt.forEach(t),Awr=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),Lwr=i(ne),j4=n(ne,"LI",{});var Eqe=s(j4);UTe=n(Eqe,"STRONG",{});var nxt=s(UTe);ywr=r(nxt,"roformer"),nxt.forEach(t),xwr=r(Eqe," \u2014 "),ZJ=n(Eqe,"A",{href:!0});var sxt=s(ZJ);$wr=r(sxt,"TFRoFormerForSequenceClassification"),sxt.forEach(t),kwr=r(Eqe," (RoFormer model)"),Eqe.forEach(t),Swr=i(ne),D4=n(ne,"LI",{});var Cqe=s(D4);JTe=n(Cqe,"STRONG",{});var lxt=s(JTe);Rwr=r(lxt,"tapas"),lxt.forEach(t),Pwr=r(Cqe," \u2014 "),eY=n(Cqe,"A",{href:!0});var ixt=s(eY);Bwr=r(ixt,"TFTapasForSequenceClassification"),ixt.forEach(t),Iwr=r(Cqe," (TAPAS model)"),Cqe.forEach(t),Nwr=i(ne),G4=n(ne,"LI",{});var wqe=s(G4);YTe=n(wqe,"STRONG",{});var dxt=s(YTe);qwr=r(dxt,"transfo-xl"),dxt.forEach(t),jwr=r(wqe," \u2014 "),oY=n(wqe,"A",{href:!0});var cxt=s(oY);Dwr=r(cxt,"TFTransfoXLForSequenceClassification"),cxt.forEach(t),Gwr=r(wqe," (Transformer-XL model)"),wqe.forEach(t),Owr=i(ne),O4=n(ne,"LI",{});var Aqe=s(O4);KTe=n(Aqe,"STRONG",{});var fxt=s(KTe);Vwr=r(fxt,"xlm"),fxt.forEach(t),Xwr=r(Aqe," \u2014 "),rY=n(Aqe,"A",{href:!0});var mxt=s(rY);zwr=r(mxt,"TFXLMForSequenceClassification"),mxt.forEach(t),Qwr=r(Aqe," (XLM model)"),Aqe.forEach(t),Wwr=i(ne),V4=n(ne,"LI",{});var Lqe=s(V4);ZTe=n(Lqe,"STRONG",{});var gxt=s(ZTe);Hwr=r(gxt,"xlm-roberta"),gxt.forEach(t),Uwr=r(Lqe," \u2014 "),tY=n(Lqe,"A",{href:!0});var hxt=s(tY);Jwr=r(hxt,"TFXLMRobertaForSequenceClassification"),hxt.forEach(t),Ywr=r(Lqe," (XLM-RoBERTa model)"),Lqe.forEach(t),Kwr=i(ne),X4=n(ne,"LI",{});var yqe=s(X4);eMe=n(yqe,"STRONG",{});var pxt=s(eMe);Zwr=r(pxt,"xlnet"),pxt.forEach(t),eAr=r(yqe," \u2014 "),aY=n(yqe,"A",{href:!0});var _xt=s(aY);oAr=r(_xt,"TFXLNetForSequenceClassification"),_xt.forEach(t),rAr=r(yqe," (XLNet model)"),yqe.forEach(t),ne.forEach(t),tAr=i(Il),T(z4.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),sVe=i(f),Tc=n(f,"H2",{class:!0});var hze=s(Tc);Q4=n(hze,"A",{id:!0,class:!0,href:!0});var uxt=s(Q4);oMe=n(uxt,"SPAN",{});var bxt=s(oMe);T(J9.$$.fragment,bxt),bxt.forEach(t),uxt.forEach(t),aAr=i(hze),rMe=n(hze,"SPAN",{});var vxt=s(rMe);nAr=r(vxt,"TFAutoModelForMultipleChoice"),vxt.forEach(t),hze.forEach(t),lVe=i(f),lr=n(f,"DIV",{class:!0});var Nl=s(lr);T(Y9.$$.fragment,Nl),sAr=i(Nl),Mc=n(Nl,"P",{});var yre=s(Mc);lAr=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=n(yre,"A",{href:!0});var Fxt=s(nY);iAr=r(Fxt,"from_pretrained()"),Fxt.forEach(t),dAr=r(yre," class method or the "),sY=n(yre,"A",{href:!0});var Txt=s(sY);cAr=r(Txt,"from_config()"),Txt.forEach(t),fAr=r(yre,` class
method.`),yre.forEach(t),mAr=i(Nl),K9=n(Nl,"P",{});var pze=s(K9);gAr=r(pze,"This class cannot be instantiated directly using "),tMe=n(pze,"CODE",{});var Mxt=s(tMe);hAr=r(Mxt,"__init__()"),Mxt.forEach(t),pAr=r(pze," (throws an error)."),pze.forEach(t),_Ar=i(Nl),Nt=n(Nl,"DIV",{class:!0});var GA=s(Nt);T(Z9.$$.fragment,GA),uAr=i(GA),aMe=n(GA,"P",{});var Ext=s(aMe);bAr=r(Ext,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ext.forEach(t),vAr=i(GA),Ec=n(GA,"P",{});var xre=s(Ec);FAr=r(xre,`Note:
Loading a model from its configuration file does `),nMe=n(xre,"STRONG",{});var Cxt=s(nMe);TAr=r(Cxt,"not"),Cxt.forEach(t),MAr=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=n(xre,"A",{href:!0});var wxt=s(lY);EAr=r(wxt,"from_pretrained()"),wxt.forEach(t),CAr=r(xre," to load the model weights."),xre.forEach(t),wAr=i(GA),T(W4.$$.fragment,GA),GA.forEach(t),AAr=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(ex.$$.fragment,ql),LAr=i(ql),sMe=n(ql,"P",{});var Axt=s(sMe);yAr=r(Axt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Axt.forEach(t),xAr=i(ql),gn=n(ql,"P",{});var OA=s(gn);$Ar=r(OA,"The model class to instantiate is selected based on the "),lMe=n(OA,"CODE",{});var Lxt=s(lMe);kAr=r(Lxt,"model_type"),Lxt.forEach(t),SAr=r(OA,` property of the config object (either
passed as an argument or loaded from `),iMe=n(OA,"CODE",{});var yxt=s(iMe);RAr=r(yxt,"pretrained_model_name_or_path"),yxt.forEach(t),PAr=r(OA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=n(OA,"CODE",{});var xxt=s(dMe);BAr=r(xxt,"pretrained_model_name_or_path"),xxt.forEach(t),IAr=r(OA,":"),OA.forEach(t),NAr=i(ql),_e=n(ql,"UL",{});var ve=s(_e);H4=n(ve,"LI",{});var xqe=s(H4);cMe=n(xqe,"STRONG",{});var $xt=s(cMe);qAr=r($xt,"albert"),$xt.forEach(t),jAr=r(xqe," \u2014 "),iY=n(xqe,"A",{href:!0});var kxt=s(iY);DAr=r(kxt,"TFAlbertForMultipleChoice"),kxt.forEach(t),GAr=r(xqe," (ALBERT model)"),xqe.forEach(t),OAr=i(ve),U4=n(ve,"LI",{});var $qe=s(U4);fMe=n($qe,"STRONG",{});var Sxt=s(fMe);VAr=r(Sxt,"bert"),Sxt.forEach(t),XAr=r($qe," \u2014 "),dY=n($qe,"A",{href:!0});var Rxt=s(dY);zAr=r(Rxt,"TFBertForMultipleChoice"),Rxt.forEach(t),QAr=r($qe," (BERT model)"),$qe.forEach(t),WAr=i(ve),J4=n(ve,"LI",{});var kqe=s(J4);mMe=n(kqe,"STRONG",{});var Pxt=s(mMe);HAr=r(Pxt,"camembert"),Pxt.forEach(t),UAr=r(kqe," \u2014 "),cY=n(kqe,"A",{href:!0});var Bxt=s(cY);JAr=r(Bxt,"TFCamembertForMultipleChoice"),Bxt.forEach(t),YAr=r(kqe," (CamemBERT model)"),kqe.forEach(t),KAr=i(ve),Y4=n(ve,"LI",{});var Sqe=s(Y4);gMe=n(Sqe,"STRONG",{});var Ixt=s(gMe);ZAr=r(Ixt,"convbert"),Ixt.forEach(t),eLr=r(Sqe," \u2014 "),fY=n(Sqe,"A",{href:!0});var Nxt=s(fY);oLr=r(Nxt,"TFConvBertForMultipleChoice"),Nxt.forEach(t),rLr=r(Sqe," (ConvBERT model)"),Sqe.forEach(t),tLr=i(ve),K4=n(ve,"LI",{});var Rqe=s(K4);hMe=n(Rqe,"STRONG",{});var qxt=s(hMe);aLr=r(qxt,"distilbert"),qxt.forEach(t),nLr=r(Rqe," \u2014 "),mY=n(Rqe,"A",{href:!0});var jxt=s(mY);sLr=r(jxt,"TFDistilBertForMultipleChoice"),jxt.forEach(t),lLr=r(Rqe," (DistilBERT model)"),Rqe.forEach(t),iLr=i(ve),Z4=n(ve,"LI",{});var Pqe=s(Z4);pMe=n(Pqe,"STRONG",{});var Dxt=s(pMe);dLr=r(Dxt,"electra"),Dxt.forEach(t),cLr=r(Pqe," \u2014 "),gY=n(Pqe,"A",{href:!0});var Gxt=s(gY);fLr=r(Gxt,"TFElectraForMultipleChoice"),Gxt.forEach(t),mLr=r(Pqe," (ELECTRA model)"),Pqe.forEach(t),gLr=i(ve),eC=n(ve,"LI",{});var Bqe=s(eC);_Me=n(Bqe,"STRONG",{});var Oxt=s(_Me);hLr=r(Oxt,"flaubert"),Oxt.forEach(t),pLr=r(Bqe," \u2014 "),hY=n(Bqe,"A",{href:!0});var Vxt=s(hY);_Lr=r(Vxt,"TFFlaubertForMultipleChoice"),Vxt.forEach(t),uLr=r(Bqe," (FlauBERT model)"),Bqe.forEach(t),bLr=i(ve),oC=n(ve,"LI",{});var Iqe=s(oC);uMe=n(Iqe,"STRONG",{});var Xxt=s(uMe);vLr=r(Xxt,"funnel"),Xxt.forEach(t),FLr=r(Iqe," \u2014 "),pY=n(Iqe,"A",{href:!0});var zxt=s(pY);TLr=r(zxt,"TFFunnelForMultipleChoice"),zxt.forEach(t),MLr=r(Iqe," (Funnel Transformer model)"),Iqe.forEach(t),ELr=i(ve),rC=n(ve,"LI",{});var Nqe=s(rC);bMe=n(Nqe,"STRONG",{});var Qxt=s(bMe);CLr=r(Qxt,"longformer"),Qxt.forEach(t),wLr=r(Nqe," \u2014 "),_Y=n(Nqe,"A",{href:!0});var Wxt=s(_Y);ALr=r(Wxt,"TFLongformerForMultipleChoice"),Wxt.forEach(t),LLr=r(Nqe," (Longformer model)"),Nqe.forEach(t),yLr=i(ve),tC=n(ve,"LI",{});var qqe=s(tC);vMe=n(qqe,"STRONG",{});var Hxt=s(vMe);xLr=r(Hxt,"mobilebert"),Hxt.forEach(t),$Lr=r(qqe," \u2014 "),uY=n(qqe,"A",{href:!0});var Uxt=s(uY);kLr=r(Uxt,"TFMobileBertForMultipleChoice"),Uxt.forEach(t),SLr=r(qqe," (MobileBERT model)"),qqe.forEach(t),RLr=i(ve),aC=n(ve,"LI",{});var jqe=s(aC);FMe=n(jqe,"STRONG",{});var Jxt=s(FMe);PLr=r(Jxt,"mpnet"),Jxt.forEach(t),BLr=r(jqe," \u2014 "),bY=n(jqe,"A",{href:!0});var Yxt=s(bY);ILr=r(Yxt,"TFMPNetForMultipleChoice"),Yxt.forEach(t),NLr=r(jqe," (MPNet model)"),jqe.forEach(t),qLr=i(ve),nC=n(ve,"LI",{});var Dqe=s(nC);TMe=n(Dqe,"STRONG",{});var Kxt=s(TMe);jLr=r(Kxt,"rembert"),Kxt.forEach(t),DLr=r(Dqe," \u2014 "),vY=n(Dqe,"A",{href:!0});var Zxt=s(vY);GLr=r(Zxt,"TFRemBertForMultipleChoice"),Zxt.forEach(t),OLr=r(Dqe," (RemBERT model)"),Dqe.forEach(t),VLr=i(ve),sC=n(ve,"LI",{});var Gqe=s(sC);MMe=n(Gqe,"STRONG",{});var e$t=s(MMe);XLr=r(e$t,"roberta"),e$t.forEach(t),zLr=r(Gqe," \u2014 "),FY=n(Gqe,"A",{href:!0});var o$t=s(FY);QLr=r(o$t,"TFRobertaForMultipleChoice"),o$t.forEach(t),WLr=r(Gqe," (RoBERTa model)"),Gqe.forEach(t),HLr=i(ve),lC=n(ve,"LI",{});var Oqe=s(lC);EMe=n(Oqe,"STRONG",{});var r$t=s(EMe);ULr=r(r$t,"roformer"),r$t.forEach(t),JLr=r(Oqe," \u2014 "),TY=n(Oqe,"A",{href:!0});var t$t=s(TY);YLr=r(t$t,"TFRoFormerForMultipleChoice"),t$t.forEach(t),KLr=r(Oqe," (RoFormer model)"),Oqe.forEach(t),ZLr=i(ve),iC=n(ve,"LI",{});var Vqe=s(iC);CMe=n(Vqe,"STRONG",{});var a$t=s(CMe);eyr=r(a$t,"xlm"),a$t.forEach(t),oyr=r(Vqe," \u2014 "),MY=n(Vqe,"A",{href:!0});var n$t=s(MY);ryr=r(n$t,"TFXLMForMultipleChoice"),n$t.forEach(t),tyr=r(Vqe," (XLM model)"),Vqe.forEach(t),ayr=i(ve),dC=n(ve,"LI",{});var Xqe=s(dC);wMe=n(Xqe,"STRONG",{});var s$t=s(wMe);nyr=r(s$t,"xlm-roberta"),s$t.forEach(t),syr=r(Xqe," \u2014 "),EY=n(Xqe,"A",{href:!0});var l$t=s(EY);lyr=r(l$t,"TFXLMRobertaForMultipleChoice"),l$t.forEach(t),iyr=r(Xqe," (XLM-RoBERTa model)"),Xqe.forEach(t),dyr=i(ve),cC=n(ve,"LI",{});var zqe=s(cC);AMe=n(zqe,"STRONG",{});var i$t=s(AMe);cyr=r(i$t,"xlnet"),i$t.forEach(t),fyr=r(zqe," \u2014 "),CY=n(zqe,"A",{href:!0});var d$t=s(CY);myr=r(d$t,"TFXLNetForMultipleChoice"),d$t.forEach(t),gyr=r(zqe," (XLNet model)"),zqe.forEach(t),ve.forEach(t),hyr=i(ql),T(fC.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),iVe=i(f),Cc=n(f,"H2",{class:!0});var _ze=s(Cc);mC=n(_ze,"A",{id:!0,class:!0,href:!0});var c$t=s(mC);LMe=n(c$t,"SPAN",{});var f$t=s(LMe);T(ox.$$.fragment,f$t),f$t.forEach(t),c$t.forEach(t),pyr=i(_ze),yMe=n(_ze,"SPAN",{});var m$t=s(yMe);_yr=r(m$t,"TFAutoModelForNextSentencePrediction"),m$t.forEach(t),_ze.forEach(t),dVe=i(f),ir=n(f,"DIV",{class:!0});var jl=s(ir);T(rx.$$.fragment,jl),uyr=i(jl),wc=n(jl,"P",{});var $re=s(wc);byr=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=n($re,"A",{href:!0});var g$t=s(wY);vyr=r(g$t,"from_pretrained()"),g$t.forEach(t),Fyr=r($re," class method or the "),AY=n($re,"A",{href:!0});var h$t=s(AY);Tyr=r(h$t,"from_config()"),h$t.forEach(t),Myr=r($re,` class
method.`),$re.forEach(t),Eyr=i(jl),tx=n(jl,"P",{});var uze=s(tx);Cyr=r(uze,"This class cannot be instantiated directly using "),xMe=n(uze,"CODE",{});var p$t=s(xMe);wyr=r(p$t,"__init__()"),p$t.forEach(t),Ayr=r(uze," (throws an error)."),uze.forEach(t),Lyr=i(jl),qt=n(jl,"DIV",{class:!0});var VA=s(qt);T(ax.$$.fragment,VA),yyr=i(VA),$Me=n(VA,"P",{});var _$t=s($Me);xyr=r(_$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_$t.forEach(t),$yr=i(VA),Ac=n(VA,"P",{});var kre=s(Ac);kyr=r(kre,`Note:
Loading a model from its configuration file does `),kMe=n(kre,"STRONG",{});var u$t=s(kMe);Syr=r(u$t,"not"),u$t.forEach(t),Ryr=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(kre,"A",{href:!0});var b$t=s(LY);Pyr=r(b$t,"from_pretrained()"),b$t.forEach(t),Byr=r(kre," to load the model weights."),kre.forEach(t),Iyr=i(VA),T(gC.$$.fragment,VA),VA.forEach(t),Nyr=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(nx.$$.fragment,Dl),qyr=i(Dl),SMe=n(Dl,"P",{});var v$t=s(SMe);jyr=r(v$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),v$t.forEach(t),Dyr=i(Dl),hn=n(Dl,"P",{});var XA=s(hn);Gyr=r(XA,"The model class to instantiate is selected based on the "),RMe=n(XA,"CODE",{});var F$t=s(RMe);Oyr=r(F$t,"model_type"),F$t.forEach(t),Vyr=r(XA,` property of the config object (either
passed as an argument or loaded from `),PMe=n(XA,"CODE",{});var T$t=s(PMe);Xyr=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),zyr=r(XA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BMe=n(XA,"CODE",{});var M$t=s(BMe);Qyr=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),Wyr=r(XA,":"),XA.forEach(t),Hyr=i(Dl),sx=n(Dl,"UL",{});var bze=s(sx);hC=n(bze,"LI",{});var Qqe=s(hC);IMe=n(Qqe,"STRONG",{});var E$t=s(IMe);Uyr=r(E$t,"bert"),E$t.forEach(t),Jyr=r(Qqe," \u2014 "),yY=n(Qqe,"A",{href:!0});var C$t=s(yY);Yyr=r(C$t,"TFBertForNextSentencePrediction"),C$t.forEach(t),Kyr=r(Qqe," (BERT model)"),Qqe.forEach(t),Zyr=i(bze),pC=n(bze,"LI",{});var Wqe=s(pC);NMe=n(Wqe,"STRONG",{});var w$t=s(NMe);e8r=r(w$t,"mobilebert"),w$t.forEach(t),o8r=r(Wqe," \u2014 "),xY=n(Wqe,"A",{href:!0});var A$t=s(xY);r8r=r(A$t,"TFMobileBertForNextSentencePrediction"),A$t.forEach(t),t8r=r(Wqe," (MobileBERT model)"),Wqe.forEach(t),bze.forEach(t),a8r=i(Dl),T(_C.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),cVe=i(f),Lc=n(f,"H2",{class:!0});var vze=s(Lc);uC=n(vze,"A",{id:!0,class:!0,href:!0});var L$t=s(uC);qMe=n(L$t,"SPAN",{});var y$t=s(qMe);T(lx.$$.fragment,y$t),y$t.forEach(t),L$t.forEach(t),n8r=i(vze),jMe=n(vze,"SPAN",{});var x$t=s(jMe);s8r=r(x$t,"TFAutoModelForTableQuestionAnswering"),x$t.forEach(t),vze.forEach(t),fVe=i(f),dr=n(f,"DIV",{class:!0});var Gl=s(dr);T(ix.$$.fragment,Gl),l8r=i(Gl),yc=n(Gl,"P",{});var Sre=s(yc);i8r=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=n(Sre,"A",{href:!0});var $$t=s($Y);d8r=r($$t,"from_pretrained()"),$$t.forEach(t),c8r=r(Sre," class method or the "),kY=n(Sre,"A",{href:!0});var k$t=s(kY);f8r=r(k$t,"from_config()"),k$t.forEach(t),m8r=r(Sre,` class
method.`),Sre.forEach(t),g8r=i(Gl),dx=n(Gl,"P",{});var Fze=s(dx);h8r=r(Fze,"This class cannot be instantiated directly using "),DMe=n(Fze,"CODE",{});var S$t=s(DMe);p8r=r(S$t,"__init__()"),S$t.forEach(t),_8r=r(Fze," (throws an error)."),Fze.forEach(t),u8r=i(Gl),jt=n(Gl,"DIV",{class:!0});var zA=s(jt);T(cx.$$.fragment,zA),b8r=i(zA),GMe=n(zA,"P",{});var R$t=s(GMe);v8r=r(R$t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),R$t.forEach(t),F8r=i(zA),xc=n(zA,"P",{});var Rre=s(xc);T8r=r(Rre,`Note:
Loading a model from its configuration file does `),OMe=n(Rre,"STRONG",{});var P$t=s(OMe);M8r=r(P$t,"not"),P$t.forEach(t),E8r=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(Rre,"A",{href:!0});var B$t=s(SY);C8r=r(B$t,"from_pretrained()"),B$t.forEach(t),w8r=r(Rre," to load the model weights."),Rre.forEach(t),A8r=i(zA),T(bC.$$.fragment,zA),zA.forEach(t),L8r=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(fx.$$.fragment,Ol),y8r=i(Ol),VMe=n(Ol,"P",{});var I$t=s(VMe);x8r=r(I$t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),I$t.forEach(t),$8r=i(Ol),pn=n(Ol,"P",{});var QA=s(pn);k8r=r(QA,"The model class to instantiate is selected based on the "),XMe=n(QA,"CODE",{});var N$t=s(XMe);S8r=r(N$t,"model_type"),N$t.forEach(t),R8r=r(QA,` property of the config object (either
passed as an argument or loaded from `),zMe=n(QA,"CODE",{});var q$t=s(zMe);P8r=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),B8r=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QMe=n(QA,"CODE",{});var j$t=s(QMe);I8r=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),N8r=r(QA,":"),QA.forEach(t),q8r=i(Ol),WMe=n(Ol,"UL",{});var D$t=s(WMe);vC=n(D$t,"LI",{});var Hqe=s(vC);HMe=n(Hqe,"STRONG",{});var G$t=s(HMe);j8r=r(G$t,"tapas"),G$t.forEach(t),D8r=r(Hqe," \u2014 "),RY=n(Hqe,"A",{href:!0});var O$t=s(RY);G8r=r(O$t,"TFTapasForQuestionAnswering"),O$t.forEach(t),O8r=r(Hqe," (TAPAS model)"),Hqe.forEach(t),D$t.forEach(t),V8r=i(Ol),T(FC.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),mVe=i(f),$c=n(f,"H2",{class:!0});var Tze=s($c);TC=n(Tze,"A",{id:!0,class:!0,href:!0});var V$t=s(TC);UMe=n(V$t,"SPAN",{});var X$t=s(UMe);T(mx.$$.fragment,X$t),X$t.forEach(t),V$t.forEach(t),X8r=i(Tze),JMe=n(Tze,"SPAN",{});var z$t=s(JMe);z8r=r(z$t,"TFAutoModelForTokenClassification"),z$t.forEach(t),Tze.forEach(t),gVe=i(f),cr=n(f,"DIV",{class:!0});var Vl=s(cr);T(gx.$$.fragment,Vl),Q8r=i(Vl),kc=n(Vl,"P",{});var Pre=s(kc);W8r=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=n(Pre,"A",{href:!0});var Q$t=s(PY);H8r=r(Q$t,"from_pretrained()"),Q$t.forEach(t),U8r=r(Pre," class method or the "),BY=n(Pre,"A",{href:!0});var W$t=s(BY);J8r=r(W$t,"from_config()"),W$t.forEach(t),Y8r=r(Pre,` class
method.`),Pre.forEach(t),K8r=i(Vl),hx=n(Vl,"P",{});var Mze=s(hx);Z8r=r(Mze,"This class cannot be instantiated directly using "),YMe=n(Mze,"CODE",{});var H$t=s(YMe);e9r=r(H$t,"__init__()"),H$t.forEach(t),o9r=r(Mze," (throws an error)."),Mze.forEach(t),r9r=i(Vl),Dt=n(Vl,"DIV",{class:!0});var WA=s(Dt);T(px.$$.fragment,WA),t9r=i(WA),KMe=n(WA,"P",{});var U$t=s(KMe);a9r=r(U$t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),U$t.forEach(t),n9r=i(WA),Sc=n(WA,"P",{});var Bre=s(Sc);s9r=r(Bre,`Note:
Loading a model from its configuration file does `),ZMe=n(Bre,"STRONG",{});var J$t=s(ZMe);l9r=r(J$t,"not"),J$t.forEach(t),i9r=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(Bre,"A",{href:!0});var Y$t=s(IY);d9r=r(Y$t,"from_pretrained()"),Y$t.forEach(t),c9r=r(Bre," to load the model weights."),Bre.forEach(t),f9r=i(WA),T(MC.$$.fragment,WA),WA.forEach(t),m9r=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(_x.$$.fragment,Xl),g9r=i(Xl),eEe=n(Xl,"P",{});var K$t=s(eEe);h9r=r(K$t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),K$t.forEach(t),p9r=i(Xl),_n=n(Xl,"P",{});var HA=s(_n);_9r=r(HA,"The model class to instantiate is selected based on the "),oEe=n(HA,"CODE",{});var Z$t=s(oEe);u9r=r(Z$t,"model_type"),Z$t.forEach(t),b9r=r(HA,` property of the config object (either
passed as an argument or loaded from `),rEe=n(HA,"CODE",{});var ekt=s(rEe);v9r=r(ekt,"pretrained_model_name_or_path"),ekt.forEach(t),F9r=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=n(HA,"CODE",{});var okt=s(tEe);T9r=r(okt,"pretrained_model_name_or_path"),okt.forEach(t),M9r=r(HA,":"),HA.forEach(t),E9r=i(Xl),de=n(Xl,"UL",{});var me=s(de);EC=n(me,"LI",{});var Uqe=s(EC);aEe=n(Uqe,"STRONG",{});var rkt=s(aEe);C9r=r(rkt,"albert"),rkt.forEach(t),w9r=r(Uqe," \u2014 "),NY=n(Uqe,"A",{href:!0});var tkt=s(NY);A9r=r(tkt,"TFAlbertForTokenClassification"),tkt.forEach(t),L9r=r(Uqe," (ALBERT model)"),Uqe.forEach(t),y9r=i(me),CC=n(me,"LI",{});var Jqe=s(CC);nEe=n(Jqe,"STRONG",{});var akt=s(nEe);x9r=r(akt,"bert"),akt.forEach(t),$9r=r(Jqe," \u2014 "),qY=n(Jqe,"A",{href:!0});var nkt=s(qY);k9r=r(nkt,"TFBertForTokenClassification"),nkt.forEach(t),S9r=r(Jqe," (BERT model)"),Jqe.forEach(t),R9r=i(me),wC=n(me,"LI",{});var Yqe=s(wC);sEe=n(Yqe,"STRONG",{});var skt=s(sEe);P9r=r(skt,"camembert"),skt.forEach(t),B9r=r(Yqe," \u2014 "),jY=n(Yqe,"A",{href:!0});var lkt=s(jY);I9r=r(lkt,"TFCamembertForTokenClassification"),lkt.forEach(t),N9r=r(Yqe," (CamemBERT model)"),Yqe.forEach(t),q9r=i(me),AC=n(me,"LI",{});var Kqe=s(AC);lEe=n(Kqe,"STRONG",{});var ikt=s(lEe);j9r=r(ikt,"convbert"),ikt.forEach(t),D9r=r(Kqe," \u2014 "),DY=n(Kqe,"A",{href:!0});var dkt=s(DY);G9r=r(dkt,"TFConvBertForTokenClassification"),dkt.forEach(t),O9r=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),V9r=i(me),LC=n(me,"LI",{});var Zqe=s(LC);iEe=n(Zqe,"STRONG",{});var ckt=s(iEe);X9r=r(ckt,"deberta"),ckt.forEach(t),z9r=r(Zqe," \u2014 "),GY=n(Zqe,"A",{href:!0});var fkt=s(GY);Q9r=r(fkt,"TFDebertaForTokenClassification"),fkt.forEach(t),W9r=r(Zqe," (DeBERTa model)"),Zqe.forEach(t),H9r=i(me),yC=n(me,"LI",{});var eje=s(yC);dEe=n(eje,"STRONG",{});var mkt=s(dEe);U9r=r(mkt,"deberta-v2"),mkt.forEach(t),J9r=r(eje," \u2014 "),OY=n(eje,"A",{href:!0});var gkt=s(OY);Y9r=r(gkt,"TFDebertaV2ForTokenClassification"),gkt.forEach(t),K9r=r(eje," (DeBERTa-v2 model)"),eje.forEach(t),Z9r=i(me),xC=n(me,"LI",{});var oje=s(xC);cEe=n(oje,"STRONG",{});var hkt=s(cEe);exr=r(hkt,"distilbert"),hkt.forEach(t),oxr=r(oje," \u2014 "),VY=n(oje,"A",{href:!0});var pkt=s(VY);rxr=r(pkt,"TFDistilBertForTokenClassification"),pkt.forEach(t),txr=r(oje," (DistilBERT model)"),oje.forEach(t),axr=i(me),$C=n(me,"LI",{});var rje=s($C);fEe=n(rje,"STRONG",{});var _kt=s(fEe);nxr=r(_kt,"electra"),_kt.forEach(t),sxr=r(rje," \u2014 "),XY=n(rje,"A",{href:!0});var ukt=s(XY);lxr=r(ukt,"TFElectraForTokenClassification"),ukt.forEach(t),ixr=r(rje," (ELECTRA model)"),rje.forEach(t),dxr=i(me),kC=n(me,"LI",{});var tje=s(kC);mEe=n(tje,"STRONG",{});var bkt=s(mEe);cxr=r(bkt,"flaubert"),bkt.forEach(t),fxr=r(tje," \u2014 "),zY=n(tje,"A",{href:!0});var vkt=s(zY);mxr=r(vkt,"TFFlaubertForTokenClassification"),vkt.forEach(t),gxr=r(tje," (FlauBERT model)"),tje.forEach(t),hxr=i(me),SC=n(me,"LI",{});var aje=s(SC);gEe=n(aje,"STRONG",{});var Fkt=s(gEe);pxr=r(Fkt,"funnel"),Fkt.forEach(t),_xr=r(aje," \u2014 "),QY=n(aje,"A",{href:!0});var Tkt=s(QY);uxr=r(Tkt,"TFFunnelForTokenClassification"),Tkt.forEach(t),bxr=r(aje," (Funnel Transformer model)"),aje.forEach(t),vxr=i(me),RC=n(me,"LI",{});var nje=s(RC);hEe=n(nje,"STRONG",{});var Mkt=s(hEe);Fxr=r(Mkt,"layoutlm"),Mkt.forEach(t),Txr=r(nje," \u2014 "),WY=n(nje,"A",{href:!0});var Ekt=s(WY);Mxr=r(Ekt,"TFLayoutLMForTokenClassification"),Ekt.forEach(t),Exr=r(nje," (LayoutLM model)"),nje.forEach(t),Cxr=i(me),PC=n(me,"LI",{});var sje=s(PC);pEe=n(sje,"STRONG",{});var Ckt=s(pEe);wxr=r(Ckt,"longformer"),Ckt.forEach(t),Axr=r(sje," \u2014 "),HY=n(sje,"A",{href:!0});var wkt=s(HY);Lxr=r(wkt,"TFLongformerForTokenClassification"),wkt.forEach(t),yxr=r(sje," (Longformer model)"),sje.forEach(t),xxr=i(me),BC=n(me,"LI",{});var lje=s(BC);_Ee=n(lje,"STRONG",{});var Akt=s(_Ee);$xr=r(Akt,"mobilebert"),Akt.forEach(t),kxr=r(lje," \u2014 "),UY=n(lje,"A",{href:!0});var Lkt=s(UY);Sxr=r(Lkt,"TFMobileBertForTokenClassification"),Lkt.forEach(t),Rxr=r(lje," (MobileBERT model)"),lje.forEach(t),Pxr=i(me),IC=n(me,"LI",{});var ije=s(IC);uEe=n(ije,"STRONG",{});var ykt=s(uEe);Bxr=r(ykt,"mpnet"),ykt.forEach(t),Ixr=r(ije," \u2014 "),JY=n(ije,"A",{href:!0});var xkt=s(JY);Nxr=r(xkt,"TFMPNetForTokenClassification"),xkt.forEach(t),qxr=r(ije," (MPNet model)"),ije.forEach(t),jxr=i(me),NC=n(me,"LI",{});var dje=s(NC);bEe=n(dje,"STRONG",{});var $kt=s(bEe);Dxr=r($kt,"rembert"),$kt.forEach(t),Gxr=r(dje," \u2014 "),YY=n(dje,"A",{href:!0});var kkt=s(YY);Oxr=r(kkt,"TFRemBertForTokenClassification"),kkt.forEach(t),Vxr=r(dje," (RemBERT model)"),dje.forEach(t),Xxr=i(me),qC=n(me,"LI",{});var cje=s(qC);vEe=n(cje,"STRONG",{});var Skt=s(vEe);zxr=r(Skt,"roberta"),Skt.forEach(t),Qxr=r(cje," \u2014 "),KY=n(cje,"A",{href:!0});var Rkt=s(KY);Wxr=r(Rkt,"TFRobertaForTokenClassification"),Rkt.forEach(t),Hxr=r(cje," (RoBERTa model)"),cje.forEach(t),Uxr=i(me),jC=n(me,"LI",{});var fje=s(jC);FEe=n(fje,"STRONG",{});var Pkt=s(FEe);Jxr=r(Pkt,"roformer"),Pkt.forEach(t),Yxr=r(fje," \u2014 "),ZY=n(fje,"A",{href:!0});var Bkt=s(ZY);Kxr=r(Bkt,"TFRoFormerForTokenClassification"),Bkt.forEach(t),Zxr=r(fje," (RoFormer model)"),fje.forEach(t),e$r=i(me),DC=n(me,"LI",{});var mje=s(DC);TEe=n(mje,"STRONG",{});var Ikt=s(TEe);o$r=r(Ikt,"xlm"),Ikt.forEach(t),r$r=r(mje," \u2014 "),eK=n(mje,"A",{href:!0});var Nkt=s(eK);t$r=r(Nkt,"TFXLMForTokenClassification"),Nkt.forEach(t),a$r=r(mje," (XLM model)"),mje.forEach(t),n$r=i(me),GC=n(me,"LI",{});var gje=s(GC);MEe=n(gje,"STRONG",{});var qkt=s(MEe);s$r=r(qkt,"xlm-roberta"),qkt.forEach(t),l$r=r(gje," \u2014 "),oK=n(gje,"A",{href:!0});var jkt=s(oK);i$r=r(jkt,"TFXLMRobertaForTokenClassification"),jkt.forEach(t),d$r=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),c$r=i(me),OC=n(me,"LI",{});var hje=s(OC);EEe=n(hje,"STRONG",{});var Dkt=s(EEe);f$r=r(Dkt,"xlnet"),Dkt.forEach(t),m$r=r(hje," \u2014 "),rK=n(hje,"A",{href:!0});var Gkt=s(rK);g$r=r(Gkt,"TFXLNetForTokenClassification"),Gkt.forEach(t),h$r=r(hje," (XLNet model)"),hje.forEach(t),me.forEach(t),p$r=i(Xl),T(VC.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),hVe=i(f),Rc=n(f,"H2",{class:!0});var Eze=s(Rc);XC=n(Eze,"A",{id:!0,class:!0,href:!0});var Okt=s(XC);CEe=n(Okt,"SPAN",{});var Vkt=s(CEe);T(ux.$$.fragment,Vkt),Vkt.forEach(t),Okt.forEach(t),_$r=i(Eze),wEe=n(Eze,"SPAN",{});var Xkt=s(wEe);u$r=r(Xkt,"TFAutoModelForQuestionAnswering"),Xkt.forEach(t),Eze.forEach(t),pVe=i(f),fr=n(f,"DIV",{class:!0});var zl=s(fr);T(bx.$$.fragment,zl),b$r=i(zl),Pc=n(zl,"P",{});var Ire=s(Pc);v$r=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=n(Ire,"A",{href:!0});var zkt=s(tK);F$r=r(zkt,"from_pretrained()"),zkt.forEach(t),T$r=r(Ire," class method or the "),aK=n(Ire,"A",{href:!0});var Qkt=s(aK);M$r=r(Qkt,"from_config()"),Qkt.forEach(t),E$r=r(Ire,` class
method.`),Ire.forEach(t),C$r=i(zl),vx=n(zl,"P",{});var Cze=s(vx);w$r=r(Cze,"This class cannot be instantiated directly using "),AEe=n(Cze,"CODE",{});var Wkt=s(AEe);A$r=r(Wkt,"__init__()"),Wkt.forEach(t),L$r=r(Cze," (throws an error)."),Cze.forEach(t),y$r=i(zl),Gt=n(zl,"DIV",{class:!0});var UA=s(Gt);T(Fx.$$.fragment,UA),x$r=i(UA),LEe=n(UA,"P",{});var Hkt=s(LEe);$$r=r(Hkt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hkt.forEach(t),k$r=i(UA),Bc=n(UA,"P",{});var Nre=s(Bc);S$r=r(Nre,`Note:
Loading a model from its configuration file does `),yEe=n(Nre,"STRONG",{});var Ukt=s(yEe);R$r=r(Ukt,"not"),Ukt.forEach(t),P$r=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(Nre,"A",{href:!0});var Jkt=s(nK);B$r=r(Jkt,"from_pretrained()"),Jkt.forEach(t),I$r=r(Nre," to load the model weights."),Nre.forEach(t),N$r=i(UA),T(zC.$$.fragment,UA),UA.forEach(t),q$r=i(zl),jr=n(zl,"DIV",{class:!0});var Ql=s(jr);T(Tx.$$.fragment,Ql),j$r=i(Ql),xEe=n(Ql,"P",{});var Ykt=s(xEe);D$r=r(Ykt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ykt.forEach(t),G$r=i(Ql),un=n(Ql,"P",{});var JA=s(un);O$r=r(JA,"The model class to instantiate is selected based on the "),$Ee=n(JA,"CODE",{});var Kkt=s($Ee);V$r=r(Kkt,"model_type"),Kkt.forEach(t),X$r=r(JA,` property of the config object (either
passed as an argument or loaded from `),kEe=n(JA,"CODE",{});var Zkt=s(kEe);z$r=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),Q$r=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SEe=n(JA,"CODE",{});var eSt=s(SEe);W$r=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),H$r=r(JA,":"),JA.forEach(t),U$r=i(Ql),ce=n(Ql,"UL",{});var ge=s(ce);QC=n(ge,"LI",{});var pje=s(QC);REe=n(pje,"STRONG",{});var oSt=s(REe);J$r=r(oSt,"albert"),oSt.forEach(t),Y$r=r(pje," \u2014 "),sK=n(pje,"A",{href:!0});var rSt=s(sK);K$r=r(rSt,"TFAlbertForQuestionAnswering"),rSt.forEach(t),Z$r=r(pje," (ALBERT model)"),pje.forEach(t),ekr=i(ge),WC=n(ge,"LI",{});var _je=s(WC);PEe=n(_je,"STRONG",{});var tSt=s(PEe);okr=r(tSt,"bert"),tSt.forEach(t),rkr=r(_je," \u2014 "),lK=n(_je,"A",{href:!0});var aSt=s(lK);tkr=r(aSt,"TFBertForQuestionAnswering"),aSt.forEach(t),akr=r(_je," (BERT model)"),_je.forEach(t),nkr=i(ge),HC=n(ge,"LI",{});var uje=s(HC);BEe=n(uje,"STRONG",{});var nSt=s(BEe);skr=r(nSt,"camembert"),nSt.forEach(t),lkr=r(uje," \u2014 "),iK=n(uje,"A",{href:!0});var sSt=s(iK);ikr=r(sSt,"TFCamembertForQuestionAnswering"),sSt.forEach(t),dkr=r(uje," (CamemBERT model)"),uje.forEach(t),ckr=i(ge),UC=n(ge,"LI",{});var bje=s(UC);IEe=n(bje,"STRONG",{});var lSt=s(IEe);fkr=r(lSt,"convbert"),lSt.forEach(t),mkr=r(bje," \u2014 "),dK=n(bje,"A",{href:!0});var iSt=s(dK);gkr=r(iSt,"TFConvBertForQuestionAnswering"),iSt.forEach(t),hkr=r(bje," (ConvBERT model)"),bje.forEach(t),pkr=i(ge),JC=n(ge,"LI",{});var vje=s(JC);NEe=n(vje,"STRONG",{});var dSt=s(NEe);_kr=r(dSt,"deberta"),dSt.forEach(t),ukr=r(vje," \u2014 "),cK=n(vje,"A",{href:!0});var cSt=s(cK);bkr=r(cSt,"TFDebertaForQuestionAnswering"),cSt.forEach(t),vkr=r(vje," (DeBERTa model)"),vje.forEach(t),Fkr=i(ge),YC=n(ge,"LI",{});var Fje=s(YC);qEe=n(Fje,"STRONG",{});var fSt=s(qEe);Tkr=r(fSt,"deberta-v2"),fSt.forEach(t),Mkr=r(Fje," \u2014 "),fK=n(Fje,"A",{href:!0});var mSt=s(fK);Ekr=r(mSt,"TFDebertaV2ForQuestionAnswering"),mSt.forEach(t),Ckr=r(Fje," (DeBERTa-v2 model)"),Fje.forEach(t),wkr=i(ge),KC=n(ge,"LI",{});var Tje=s(KC);jEe=n(Tje,"STRONG",{});var gSt=s(jEe);Akr=r(gSt,"distilbert"),gSt.forEach(t),Lkr=r(Tje," \u2014 "),mK=n(Tje,"A",{href:!0});var hSt=s(mK);ykr=r(hSt,"TFDistilBertForQuestionAnswering"),hSt.forEach(t),xkr=r(Tje," (DistilBERT model)"),Tje.forEach(t),$kr=i(ge),ZC=n(ge,"LI",{});var Mje=s(ZC);DEe=n(Mje,"STRONG",{});var pSt=s(DEe);kkr=r(pSt,"electra"),pSt.forEach(t),Skr=r(Mje," \u2014 "),gK=n(Mje,"A",{href:!0});var _St=s(gK);Rkr=r(_St,"TFElectraForQuestionAnswering"),_St.forEach(t),Pkr=r(Mje," (ELECTRA model)"),Mje.forEach(t),Bkr=i(ge),e5=n(ge,"LI",{});var Eje=s(e5);GEe=n(Eje,"STRONG",{});var uSt=s(GEe);Ikr=r(uSt,"flaubert"),uSt.forEach(t),Nkr=r(Eje," \u2014 "),hK=n(Eje,"A",{href:!0});var bSt=s(hK);qkr=r(bSt,"TFFlaubertForQuestionAnsweringSimple"),bSt.forEach(t),jkr=r(Eje," (FlauBERT model)"),Eje.forEach(t),Dkr=i(ge),o5=n(ge,"LI",{});var Cje=s(o5);OEe=n(Cje,"STRONG",{});var vSt=s(OEe);Gkr=r(vSt,"funnel"),vSt.forEach(t),Okr=r(Cje," \u2014 "),pK=n(Cje,"A",{href:!0});var FSt=s(pK);Vkr=r(FSt,"TFFunnelForQuestionAnswering"),FSt.forEach(t),Xkr=r(Cje," (Funnel Transformer model)"),Cje.forEach(t),zkr=i(ge),r5=n(ge,"LI",{});var wje=s(r5);VEe=n(wje,"STRONG",{});var TSt=s(VEe);Qkr=r(TSt,"gptj"),TSt.forEach(t),Wkr=r(wje," \u2014 "),_K=n(wje,"A",{href:!0});var MSt=s(_K);Hkr=r(MSt,"TFGPTJForQuestionAnswering"),MSt.forEach(t),Ukr=r(wje," (GPT-J model)"),wje.forEach(t),Jkr=i(ge),t5=n(ge,"LI",{});var Aje=s(t5);XEe=n(Aje,"STRONG",{});var ESt=s(XEe);Ykr=r(ESt,"longformer"),ESt.forEach(t),Kkr=r(Aje," \u2014 "),uK=n(Aje,"A",{href:!0});var CSt=s(uK);Zkr=r(CSt,"TFLongformerForQuestionAnswering"),CSt.forEach(t),eSr=r(Aje," (Longformer model)"),Aje.forEach(t),oSr=i(ge),a5=n(ge,"LI",{});var Lje=s(a5);zEe=n(Lje,"STRONG",{});var wSt=s(zEe);rSr=r(wSt,"mobilebert"),wSt.forEach(t),tSr=r(Lje," \u2014 "),bK=n(Lje,"A",{href:!0});var ASt=s(bK);aSr=r(ASt,"TFMobileBertForQuestionAnswering"),ASt.forEach(t),nSr=r(Lje," (MobileBERT model)"),Lje.forEach(t),sSr=i(ge),n5=n(ge,"LI",{});var yje=s(n5);QEe=n(yje,"STRONG",{});var LSt=s(QEe);lSr=r(LSt,"mpnet"),LSt.forEach(t),iSr=r(yje," \u2014 "),vK=n(yje,"A",{href:!0});var ySt=s(vK);dSr=r(ySt,"TFMPNetForQuestionAnswering"),ySt.forEach(t),cSr=r(yje," (MPNet model)"),yje.forEach(t),fSr=i(ge),s5=n(ge,"LI",{});var xje=s(s5);WEe=n(xje,"STRONG",{});var xSt=s(WEe);mSr=r(xSt,"rembert"),xSt.forEach(t),gSr=r(xje," \u2014 "),FK=n(xje,"A",{href:!0});var $St=s(FK);hSr=r($St,"TFRemBertForQuestionAnswering"),$St.forEach(t),pSr=r(xje," (RemBERT model)"),xje.forEach(t),_Sr=i(ge),l5=n(ge,"LI",{});var $je=s(l5);HEe=n($je,"STRONG",{});var kSt=s(HEe);uSr=r(kSt,"roberta"),kSt.forEach(t),bSr=r($je," \u2014 "),TK=n($je,"A",{href:!0});var SSt=s(TK);vSr=r(SSt,"TFRobertaForQuestionAnswering"),SSt.forEach(t),FSr=r($je," (RoBERTa model)"),$je.forEach(t),TSr=i(ge),i5=n(ge,"LI",{});var kje=s(i5);UEe=n(kje,"STRONG",{});var RSt=s(UEe);MSr=r(RSt,"roformer"),RSt.forEach(t),ESr=r(kje," \u2014 "),MK=n(kje,"A",{href:!0});var PSt=s(MK);CSr=r(PSt,"TFRoFormerForQuestionAnswering"),PSt.forEach(t),wSr=r(kje," (RoFormer model)"),kje.forEach(t),ASr=i(ge),d5=n(ge,"LI",{});var Sje=s(d5);JEe=n(Sje,"STRONG",{});var BSt=s(JEe);LSr=r(BSt,"xlm"),BSt.forEach(t),ySr=r(Sje," \u2014 "),EK=n(Sje,"A",{href:!0});var ISt=s(EK);xSr=r(ISt,"TFXLMForQuestionAnsweringSimple"),ISt.forEach(t),$Sr=r(Sje," (XLM model)"),Sje.forEach(t),kSr=i(ge),c5=n(ge,"LI",{});var Rje=s(c5);YEe=n(Rje,"STRONG",{});var NSt=s(YEe);SSr=r(NSt,"xlm-roberta"),NSt.forEach(t),RSr=r(Rje," \u2014 "),CK=n(Rje,"A",{href:!0});var qSt=s(CK);PSr=r(qSt,"TFXLMRobertaForQuestionAnswering"),qSt.forEach(t),BSr=r(Rje," (XLM-RoBERTa model)"),Rje.forEach(t),ISr=i(ge),f5=n(ge,"LI",{});var Pje=s(f5);KEe=n(Pje,"STRONG",{});var jSt=s(KEe);NSr=r(jSt,"xlnet"),jSt.forEach(t),qSr=r(Pje," \u2014 "),wK=n(Pje,"A",{href:!0});var DSt=s(wK);jSr=r(DSt,"TFXLNetForQuestionAnsweringSimple"),DSt.forEach(t),DSr=r(Pje," (XLNet model)"),Pje.forEach(t),ge.forEach(t),GSr=i(Ql),T(m5.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),_Ve=i(f),Ic=n(f,"H2",{class:!0});var wze=s(Ic);g5=n(wze,"A",{id:!0,class:!0,href:!0});var GSt=s(g5);ZEe=n(GSt,"SPAN",{});var OSt=s(ZEe);T(Mx.$$.fragment,OSt),OSt.forEach(t),GSt.forEach(t),OSr=i(wze),e4e=n(wze,"SPAN",{});var VSt=s(e4e);VSr=r(VSt,"TFAutoModelForVision2Seq"),VSt.forEach(t),wze.forEach(t),uVe=i(f),mr=n(f,"DIV",{class:!0});var Wl=s(mr);T(Ex.$$.fragment,Wl),XSr=i(Wl),Nc=n(Wl,"P",{});var qre=s(Nc);zSr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=n(qre,"A",{href:!0});var XSt=s(AK);QSr=r(XSt,"from_pretrained()"),XSt.forEach(t),WSr=r(qre," class method or the "),LK=n(qre,"A",{href:!0});var zSt=s(LK);HSr=r(zSt,"from_config()"),zSt.forEach(t),USr=r(qre,` class
method.`),qre.forEach(t),JSr=i(Wl),Cx=n(Wl,"P",{});var Aze=s(Cx);YSr=r(Aze,"This class cannot be instantiated directly using "),o4e=n(Aze,"CODE",{});var QSt=s(o4e);KSr=r(QSt,"__init__()"),QSt.forEach(t),ZSr=r(Aze," (throws an error)."),Aze.forEach(t),eRr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var YA=s(Ot);T(wx.$$.fragment,YA),oRr=i(YA),r4e=n(YA,"P",{});var WSt=s(r4e);rRr=r(WSt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WSt.forEach(t),tRr=i(YA),qc=n(YA,"P",{});var jre=s(qc);aRr=r(jre,`Note:
Loading a model from its configuration file does `),t4e=n(jre,"STRONG",{});var HSt=s(t4e);nRr=r(HSt,"not"),HSt.forEach(t),sRr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(jre,"A",{href:!0});var USt=s(yK);lRr=r(USt,"from_pretrained()"),USt.forEach(t),iRr=r(jre," to load the model weights."),jre.forEach(t),dRr=i(YA),T(h5.$$.fragment,YA),YA.forEach(t),cRr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Hl=s(Dr);T(Ax.$$.fragment,Hl),fRr=i(Hl),a4e=n(Hl,"P",{});var JSt=s(a4e);mRr=r(JSt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),JSt.forEach(t),gRr=i(Hl),bn=n(Hl,"P",{});var KA=s(bn);hRr=r(KA,"The model class to instantiate is selected based on the "),n4e=n(KA,"CODE",{});var YSt=s(n4e);pRr=r(YSt,"model_type"),YSt.forEach(t),_Rr=r(KA,` property of the config object (either
passed as an argument or loaded from `),s4e=n(KA,"CODE",{});var KSt=s(s4e);uRr=r(KSt,"pretrained_model_name_or_path"),KSt.forEach(t),bRr=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l4e=n(KA,"CODE",{});var ZSt=s(l4e);vRr=r(ZSt,"pretrained_model_name_or_path"),ZSt.forEach(t),FRr=r(KA,":"),KA.forEach(t),TRr=i(Hl),i4e=n(Hl,"UL",{});var eRt=s(i4e);p5=n(eRt,"LI",{});var Bje=s(p5);d4e=n(Bje,"STRONG",{});var oRt=s(d4e);MRr=r(oRt,"vision-encoder-decoder"),oRt.forEach(t),ERr=r(Bje," \u2014 "),xK=n(Bje,"A",{href:!0});var rRt=s(xK);CRr=r(rRt,"TFVisionEncoderDecoderModel"),rRt.forEach(t),wRr=r(Bje," (Vision Encoder decoder model)"),Bje.forEach(t),eRt.forEach(t),ARr=i(Hl),T(_5.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),bVe=i(f),jc=n(f,"H2",{class:!0});var Lze=s(jc);u5=n(Lze,"A",{id:!0,class:!0,href:!0});var tRt=s(u5);c4e=n(tRt,"SPAN",{});var aRt=s(c4e);T(Lx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),LRr=i(Lze),f4e=n(Lze,"SPAN",{});var nRt=s(f4e);yRr=r(nRt,"TFAutoModelForSpeechSeq2Seq"),nRt.forEach(t),Lze.forEach(t),vVe=i(f),gr=n(f,"DIV",{class:!0});var Ul=s(gr);T(yx.$$.fragment,Ul),xRr=i(Ul),Dc=n(Ul,"P",{});var Dre=s(Dc);$Rr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=n(Dre,"A",{href:!0});var sRt=s($K);kRr=r(sRt,"from_pretrained()"),sRt.forEach(t),SRr=r(Dre," class method or the "),kK=n(Dre,"A",{href:!0});var lRt=s(kK);RRr=r(lRt,"from_config()"),lRt.forEach(t),PRr=r(Dre,` class
method.`),Dre.forEach(t),BRr=i(Ul),xx=n(Ul,"P",{});var yze=s(xx);IRr=r(yze,"This class cannot be instantiated directly using "),m4e=n(yze,"CODE",{});var iRt=s(m4e);NRr=r(iRt,"__init__()"),iRt.forEach(t),qRr=r(yze," (throws an error)."),yze.forEach(t),jRr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var ZA=s(Vt);T($x.$$.fragment,ZA),DRr=i(ZA),g4e=n(ZA,"P",{});var dRt=s(g4e);GRr=r(dRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dRt.forEach(t),ORr=i(ZA),Gc=n(ZA,"P",{});var Gre=s(Gc);VRr=r(Gre,`Note:
Loading a model from its configuration file does `),h4e=n(Gre,"STRONG",{});var cRt=s(h4e);XRr=r(cRt,"not"),cRt.forEach(t),zRr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(Gre,"A",{href:!0});var fRt=s(SK);QRr=r(fRt,"from_pretrained()"),fRt.forEach(t),WRr=r(Gre," to load the model weights."),Gre.forEach(t),HRr=i(ZA),T(b5.$$.fragment,ZA),ZA.forEach(t),URr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(kx.$$.fragment,Jl),JRr=i(Jl),p4e=n(Jl,"P",{});var mRt=s(p4e);YRr=r(mRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mRt.forEach(t),KRr=i(Jl),vn=n(Jl,"P",{});var eL=s(vn);ZRr=r(eL,"The model class to instantiate is selected based on the "),_4e=n(eL,"CODE",{});var gRt=s(_4e);ePr=r(gRt,"model_type"),gRt.forEach(t),oPr=r(eL,` property of the config object (either
passed as an argument or loaded from `),u4e=n(eL,"CODE",{});var hRt=s(u4e);rPr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),tPr=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b4e=n(eL,"CODE",{});var pRt=s(b4e);aPr=r(pRt,"pretrained_model_name_or_path"),pRt.forEach(t),nPr=r(eL,":"),eL.forEach(t),sPr=i(Jl),v4e=n(Jl,"UL",{});var _Rt=s(v4e);v5=n(_Rt,"LI",{});var Ije=s(v5);F4e=n(Ije,"STRONG",{});var uRt=s(F4e);lPr=r(uRt,"speech_to_text"),uRt.forEach(t),iPr=r(Ije," \u2014 "),RK=n(Ije,"A",{href:!0});var bRt=s(RK);dPr=r(bRt,"TFSpeech2TextForConditionalGeneration"),bRt.forEach(t),cPr=r(Ije," (Speech2Text model)"),Ije.forEach(t),_Rt.forEach(t),fPr=i(Jl),T(F5.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),FVe=i(f),Oc=n(f,"H2",{class:!0});var xze=s(Oc);T5=n(xze,"A",{id:!0,class:!0,href:!0});var vRt=s(T5);T4e=n(vRt,"SPAN",{});var FRt=s(T4e);T(Sx.$$.fragment,FRt),FRt.forEach(t),vRt.forEach(t),mPr=i(xze),M4e=n(xze,"SPAN",{});var TRt=s(M4e);gPr=r(TRt,"FlaxAutoModel"),TRt.forEach(t),xze.forEach(t),TVe=i(f),hr=n(f,"DIV",{class:!0});var Yl=s(hr);T(Rx.$$.fragment,Yl),hPr=i(Yl),Vc=n(Yl,"P",{});var Ore=s(Vc);pPr=r(Ore,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=n(Ore,"A",{href:!0});var MRt=s(PK);_Pr=r(MRt,"from_pretrained()"),MRt.forEach(t),uPr=r(Ore," class method or the "),BK=n(Ore,"A",{href:!0});var ERt=s(BK);bPr=r(ERt,"from_config()"),ERt.forEach(t),vPr=r(Ore,` class
method.`),Ore.forEach(t),FPr=i(Yl),Px=n(Yl,"P",{});var $ze=s(Px);TPr=r($ze,"This class cannot be instantiated directly using "),E4e=n($ze,"CODE",{});var CRt=s(E4e);MPr=r(CRt,"__init__()"),CRt.forEach(t),EPr=r($ze," (throws an error)."),$ze.forEach(t),CPr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var oL=s(Xt);T(Bx.$$.fragment,oL),wPr=i(oL),C4e=n(oL,"P",{});var wRt=s(C4e);APr=r(wRt,"Instantiates one of the base model classes of the library from a configuration."),wRt.forEach(t),LPr=i(oL),Xc=n(oL,"P",{});var Vre=s(Xc);yPr=r(Vre,`Note:
Loading a model from its configuration file does `),w4e=n(Vre,"STRONG",{});var ARt=s(w4e);xPr=r(ARt,"not"),ARt.forEach(t),$Pr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Vre,"A",{href:!0});var LRt=s(IK);kPr=r(LRt,"from_pretrained()"),LRt.forEach(t),SPr=r(Vre," to load the model weights."),Vre.forEach(t),RPr=i(oL),T(M5.$$.fragment,oL),oL.forEach(t),PPr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(Ix.$$.fragment,Kl),BPr=i(Kl),A4e=n(Kl,"P",{});var yRt=s(A4e);IPr=r(yRt,"Instantiate one of the base model classes of the library from a pretrained model."),yRt.forEach(t),NPr=i(Kl),Fn=n(Kl,"P",{});var rL=s(Fn);qPr=r(rL,"The model class to instantiate is selected based on the "),L4e=n(rL,"CODE",{});var xRt=s(L4e);jPr=r(xRt,"model_type"),xRt.forEach(t),DPr=r(rL,` property of the config object (either
passed as an argument or loaded from `),y4e=n(rL,"CODE",{});var $Rt=s(y4e);GPr=r($Rt,"pretrained_model_name_or_path"),$Rt.forEach(t),OPr=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x4e=n(rL,"CODE",{});var kRt=s(x4e);VPr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),XPr=r(rL,":"),rL.forEach(t),zPr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);E5=n(ae,"LI",{});var Nje=s(E5);$4e=n(Nje,"STRONG",{});var SRt=s($4e);QPr=r(SRt,"albert"),SRt.forEach(t),WPr=r(Nje," \u2014 "),NK=n(Nje,"A",{href:!0});var RRt=s(NK);HPr=r(RRt,"FlaxAlbertModel"),RRt.forEach(t),UPr=r(Nje," (ALBERT model)"),Nje.forEach(t),JPr=i(ae),C5=n(ae,"LI",{});var qje=s(C5);k4e=n(qje,"STRONG",{});var PRt=s(k4e);YPr=r(PRt,"bart"),PRt.forEach(t),KPr=r(qje," \u2014 "),qK=n(qje,"A",{href:!0});var BRt=s(qK);ZPr=r(BRt,"FlaxBartModel"),BRt.forEach(t),eBr=r(qje," (BART model)"),qje.forEach(t),oBr=i(ae),w5=n(ae,"LI",{});var jje=s(w5);S4e=n(jje,"STRONG",{});var IRt=s(S4e);rBr=r(IRt,"beit"),IRt.forEach(t),tBr=r(jje," \u2014 "),jK=n(jje,"A",{href:!0});var NRt=s(jK);aBr=r(NRt,"FlaxBeitModel"),NRt.forEach(t),nBr=r(jje," (BEiT model)"),jje.forEach(t),sBr=i(ae),A5=n(ae,"LI",{});var Dje=s(A5);R4e=n(Dje,"STRONG",{});var qRt=s(R4e);lBr=r(qRt,"bert"),qRt.forEach(t),iBr=r(Dje," \u2014 "),DK=n(Dje,"A",{href:!0});var jRt=s(DK);dBr=r(jRt,"FlaxBertModel"),jRt.forEach(t),cBr=r(Dje," (BERT model)"),Dje.forEach(t),fBr=i(ae),L5=n(ae,"LI",{});var Gje=s(L5);P4e=n(Gje,"STRONG",{});var DRt=s(P4e);mBr=r(DRt,"big_bird"),DRt.forEach(t),gBr=r(Gje," \u2014 "),GK=n(Gje,"A",{href:!0});var GRt=s(GK);hBr=r(GRt,"FlaxBigBirdModel"),GRt.forEach(t),pBr=r(Gje," (BigBird model)"),Gje.forEach(t),_Br=i(ae),y5=n(ae,"LI",{});var Oje=s(y5);B4e=n(Oje,"STRONG",{});var ORt=s(B4e);uBr=r(ORt,"blenderbot"),ORt.forEach(t),bBr=r(Oje," \u2014 "),OK=n(Oje,"A",{href:!0});var VRt=s(OK);vBr=r(VRt,"FlaxBlenderbotModel"),VRt.forEach(t),FBr=r(Oje," (Blenderbot model)"),Oje.forEach(t),TBr=i(ae),x5=n(ae,"LI",{});var Vje=s(x5);I4e=n(Vje,"STRONG",{});var XRt=s(I4e);MBr=r(XRt,"blenderbot-small"),XRt.forEach(t),EBr=r(Vje," \u2014 "),VK=n(Vje,"A",{href:!0});var zRt=s(VK);CBr=r(zRt,"FlaxBlenderbotSmallModel"),zRt.forEach(t),wBr=r(Vje," (BlenderbotSmall model)"),Vje.forEach(t),ABr=i(ae),$5=n(ae,"LI",{});var Xje=s($5);N4e=n(Xje,"STRONG",{});var QRt=s(N4e);LBr=r(QRt,"clip"),QRt.forEach(t),yBr=r(Xje," \u2014 "),XK=n(Xje,"A",{href:!0});var WRt=s(XK);xBr=r(WRt,"FlaxCLIPModel"),WRt.forEach(t),$Br=r(Xje," (CLIP model)"),Xje.forEach(t),kBr=i(ae),k5=n(ae,"LI",{});var zje=s(k5);q4e=n(zje,"STRONG",{});var HRt=s(q4e);SBr=r(HRt,"distilbert"),HRt.forEach(t),RBr=r(zje," \u2014 "),zK=n(zje,"A",{href:!0});var URt=s(zK);PBr=r(URt,"FlaxDistilBertModel"),URt.forEach(t),BBr=r(zje," (DistilBERT model)"),zje.forEach(t),IBr=i(ae),S5=n(ae,"LI",{});var Qje=s(S5);j4e=n(Qje,"STRONG",{});var JRt=s(j4e);NBr=r(JRt,"electra"),JRt.forEach(t),qBr=r(Qje," \u2014 "),QK=n(Qje,"A",{href:!0});var YRt=s(QK);jBr=r(YRt,"FlaxElectraModel"),YRt.forEach(t),DBr=r(Qje," (ELECTRA model)"),Qje.forEach(t),GBr=i(ae),R5=n(ae,"LI",{});var Wje=s(R5);D4e=n(Wje,"STRONG",{});var KRt=s(D4e);OBr=r(KRt,"gpt2"),KRt.forEach(t),VBr=r(Wje," \u2014 "),WK=n(Wje,"A",{href:!0});var ZRt=s(WK);XBr=r(ZRt,"FlaxGPT2Model"),ZRt.forEach(t),zBr=r(Wje," (OpenAI GPT-2 model)"),Wje.forEach(t),QBr=i(ae),P5=n(ae,"LI",{});var Hje=s(P5);G4e=n(Hje,"STRONG",{});var ePt=s(G4e);WBr=r(ePt,"gpt_neo"),ePt.forEach(t),HBr=r(Hje," \u2014 "),HK=n(Hje,"A",{href:!0});var oPt=s(HK);UBr=r(oPt,"FlaxGPTNeoModel"),oPt.forEach(t),JBr=r(Hje," (GPT Neo model)"),Hje.forEach(t),YBr=i(ae),B5=n(ae,"LI",{});var Uje=s(B5);O4e=n(Uje,"STRONG",{});var rPt=s(O4e);KBr=r(rPt,"gptj"),rPt.forEach(t),ZBr=r(Uje," \u2014 "),UK=n(Uje,"A",{href:!0});var tPt=s(UK);eIr=r(tPt,"FlaxGPTJModel"),tPt.forEach(t),oIr=r(Uje," (GPT-J model)"),Uje.forEach(t),rIr=i(ae),I5=n(ae,"LI",{});var Jje=s(I5);V4e=n(Jje,"STRONG",{});var aPt=s(V4e);tIr=r(aPt,"longt5"),aPt.forEach(t),aIr=r(Jje," \u2014 "),JK=n(Jje,"A",{href:!0});var nPt=s(JK);nIr=r(nPt,"FlaxLongT5Model"),nPt.forEach(t),sIr=r(Jje," (LongT5 model)"),Jje.forEach(t),lIr=i(ae),N5=n(ae,"LI",{});var Yje=s(N5);X4e=n(Yje,"STRONG",{});var sPt=s(X4e);iIr=r(sPt,"marian"),sPt.forEach(t),dIr=r(Yje," \u2014 "),YK=n(Yje,"A",{href:!0});var lPt=s(YK);cIr=r(lPt,"FlaxMarianModel"),lPt.forEach(t),fIr=r(Yje," (Marian model)"),Yje.forEach(t),mIr=i(ae),q5=n(ae,"LI",{});var Kje=s(q5);z4e=n(Kje,"STRONG",{});var iPt=s(z4e);gIr=r(iPt,"mbart"),iPt.forEach(t),hIr=r(Kje," \u2014 "),KK=n(Kje,"A",{href:!0});var dPt=s(KK);pIr=r(dPt,"FlaxMBartModel"),dPt.forEach(t),_Ir=r(Kje," (mBART model)"),Kje.forEach(t),uIr=i(ae),j5=n(ae,"LI",{});var Zje=s(j5);Q4e=n(Zje,"STRONG",{});var cPt=s(Q4e);bIr=r(cPt,"mt5"),cPt.forEach(t),vIr=r(Zje," \u2014 "),ZK=n(Zje,"A",{href:!0});var fPt=s(ZK);FIr=r(fPt,"FlaxMT5Model"),fPt.forEach(t),TIr=r(Zje," (MT5 model)"),Zje.forEach(t),MIr=i(ae),D5=n(ae,"LI",{});var eDe=s(D5);W4e=n(eDe,"STRONG",{});var mPt=s(W4e);EIr=r(mPt,"opt"),mPt.forEach(t),CIr=r(eDe," \u2014 "),eZ=n(eDe,"A",{href:!0});var gPt=s(eZ);wIr=r(gPt,"FlaxOPTModel"),gPt.forEach(t),AIr=r(eDe," (OPT model)"),eDe.forEach(t),LIr=i(ae),G5=n(ae,"LI",{});var oDe=s(G5);H4e=n(oDe,"STRONG",{});var hPt=s(H4e);yIr=r(hPt,"pegasus"),hPt.forEach(t),xIr=r(oDe," \u2014 "),oZ=n(oDe,"A",{href:!0});var pPt=s(oZ);$Ir=r(pPt,"FlaxPegasusModel"),pPt.forEach(t),kIr=r(oDe," (Pegasus model)"),oDe.forEach(t),SIr=i(ae),O5=n(ae,"LI",{});var rDe=s(O5);U4e=n(rDe,"STRONG",{});var _Pt=s(U4e);RIr=r(_Pt,"roberta"),_Pt.forEach(t),PIr=r(rDe," \u2014 "),rZ=n(rDe,"A",{href:!0});var uPt=s(rZ);BIr=r(uPt,"FlaxRobertaModel"),uPt.forEach(t),IIr=r(rDe," (RoBERTa model)"),rDe.forEach(t),NIr=i(ae),V5=n(ae,"LI",{});var tDe=s(V5);J4e=n(tDe,"STRONG",{});var bPt=s(J4e);qIr=r(bPt,"roformer"),bPt.forEach(t),jIr=r(tDe," \u2014 "),tZ=n(tDe,"A",{href:!0});var vPt=s(tZ);DIr=r(vPt,"FlaxRoFormerModel"),vPt.forEach(t),GIr=r(tDe," (RoFormer model)"),tDe.forEach(t),OIr=i(ae),X5=n(ae,"LI",{});var aDe=s(X5);Y4e=n(aDe,"STRONG",{});var FPt=s(Y4e);VIr=r(FPt,"t5"),FPt.forEach(t),XIr=r(aDe," \u2014 "),aZ=n(aDe,"A",{href:!0});var TPt=s(aZ);zIr=r(TPt,"FlaxT5Model"),TPt.forEach(t),QIr=r(aDe," (T5 model)"),aDe.forEach(t),WIr=i(ae),z5=n(ae,"LI",{});var nDe=s(z5);K4e=n(nDe,"STRONG",{});var MPt=s(K4e);HIr=r(MPt,"vision-text-dual-encoder"),MPt.forEach(t),UIr=r(nDe," \u2014 "),nZ=n(nDe,"A",{href:!0});var EPt=s(nZ);JIr=r(EPt,"FlaxVisionTextDualEncoderModel"),EPt.forEach(t),YIr=r(nDe," (VisionTextDualEncoder model)"),nDe.forEach(t),KIr=i(ae),Q5=n(ae,"LI",{});var sDe=s(Q5);Z4e=n(sDe,"STRONG",{});var CPt=s(Z4e);ZIr=r(CPt,"vit"),CPt.forEach(t),eNr=r(sDe," \u2014 "),sZ=n(sDe,"A",{href:!0});var wPt=s(sZ);oNr=r(wPt,"FlaxViTModel"),wPt.forEach(t),rNr=r(sDe," (ViT model)"),sDe.forEach(t),tNr=i(ae),W5=n(ae,"LI",{});var lDe=s(W5);eCe=n(lDe,"STRONG",{});var APt=s(eCe);aNr=r(APt,"wav2vec2"),APt.forEach(t),nNr=r(lDe," \u2014 "),lZ=n(lDe,"A",{href:!0});var LPt=s(lZ);sNr=r(LPt,"FlaxWav2Vec2Model"),LPt.forEach(t),lNr=r(lDe," (Wav2Vec2 model)"),lDe.forEach(t),iNr=i(ae),H5=n(ae,"LI",{});var iDe=s(H5);oCe=n(iDe,"STRONG",{});var yPt=s(oCe);dNr=r(yPt,"xglm"),yPt.forEach(t),cNr=r(iDe," \u2014 "),iZ=n(iDe,"A",{href:!0});var xPt=s(iZ);fNr=r(xPt,"FlaxXGLMModel"),xPt.forEach(t),mNr=r(iDe," (XGLM model)"),iDe.forEach(t),gNr=i(ae),U5=n(ae,"LI",{});var dDe=s(U5);rCe=n(dDe,"STRONG",{});var $Pt=s(rCe);hNr=r($Pt,"xlm-roberta"),$Pt.forEach(t),pNr=r(dDe," \u2014 "),dZ=n(dDe,"A",{href:!0});var kPt=s(dZ);_Nr=r(kPt,"FlaxXLMRobertaModel"),kPt.forEach(t),uNr=r(dDe," (XLM-RoBERTa model)"),dDe.forEach(t),ae.forEach(t),bNr=i(Kl),T(J5.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),MVe=i(f),zc=n(f,"H2",{class:!0});var kze=s(zc);Y5=n(kze,"A",{id:!0,class:!0,href:!0});var SPt=s(Y5);tCe=n(SPt,"SPAN",{});var RPt=s(tCe);T(Nx.$$.fragment,RPt),RPt.forEach(t),SPt.forEach(t),vNr=i(kze),aCe=n(kze,"SPAN",{});var PPt=s(aCe);FNr=r(PPt,"FlaxAutoModelForCausalLM"),PPt.forEach(t),kze.forEach(t),EVe=i(f),pr=n(f,"DIV",{class:!0});var Zl=s(pr);T(qx.$$.fragment,Zl),TNr=i(Zl),Qc=n(Zl,"P",{});var Xre=s(Qc);MNr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=n(Xre,"A",{href:!0});var BPt=s(cZ);ENr=r(BPt,"from_pretrained()"),BPt.forEach(t),CNr=r(Xre," class method or the "),fZ=n(Xre,"A",{href:!0});var IPt=s(fZ);wNr=r(IPt,"from_config()"),IPt.forEach(t),ANr=r(Xre,` class
method.`),Xre.forEach(t),LNr=i(Zl),jx=n(Zl,"P",{});var Sze=s(jx);yNr=r(Sze,"This class cannot be instantiated directly using "),nCe=n(Sze,"CODE",{});var NPt=s(nCe);xNr=r(NPt,"__init__()"),NPt.forEach(t),$Nr=r(Sze," (throws an error)."),Sze.forEach(t),kNr=i(Zl),zt=n(Zl,"DIV",{class:!0});var tL=s(zt);T(Dx.$$.fragment,tL),SNr=i(tL),sCe=n(tL,"P",{});var qPt=s(sCe);RNr=r(qPt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qPt.forEach(t),PNr=i(tL),Wc=n(tL,"P",{});var zre=s(Wc);BNr=r(zre,`Note:
Loading a model from its configuration file does `),lCe=n(zre,"STRONG",{});var jPt=s(lCe);INr=r(jPt,"not"),jPt.forEach(t),NNr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=n(zre,"A",{href:!0});var DPt=s(mZ);qNr=r(DPt,"from_pretrained()"),DPt.forEach(t),jNr=r(zre," to load the model weights."),zre.forEach(t),DNr=i(tL),T(K5.$$.fragment,tL),tL.forEach(t),GNr=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(Gx.$$.fragment,ei),ONr=i(ei),iCe=n(ei,"P",{});var GPt=s(iCe);VNr=r(GPt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GPt.forEach(t),XNr=i(ei),Tn=n(ei,"P",{});var aL=s(Tn);zNr=r(aL,"The model class to instantiate is selected based on the "),dCe=n(aL,"CODE",{});var OPt=s(dCe);QNr=r(OPt,"model_type"),OPt.forEach(t),WNr=r(aL,` property of the config object (either
passed as an argument or loaded from `),cCe=n(aL,"CODE",{});var VPt=s(cCe);HNr=r(VPt,"pretrained_model_name_or_path"),VPt.forEach(t),UNr=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=n(aL,"CODE",{});var XPt=s(fCe);JNr=r(XPt,"pretrained_model_name_or_path"),XPt.forEach(t),YNr=r(aL,":"),aL.forEach(t),KNr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);Z5=n(Ne,"LI",{});var cDe=s(Z5);mCe=n(cDe,"STRONG",{});var zPt=s(mCe);ZNr=r(zPt,"bart"),zPt.forEach(t),eqr=r(cDe," \u2014 "),gZ=n(cDe,"A",{href:!0});var QPt=s(gZ);oqr=r(QPt,"FlaxBartForCausalLM"),QPt.forEach(t),rqr=r(cDe," (BART model)"),cDe.forEach(t),tqr=i(Ne),e3=n(Ne,"LI",{});var fDe=s(e3);gCe=n(fDe,"STRONG",{});var WPt=s(gCe);aqr=r(WPt,"bert"),WPt.forEach(t),nqr=r(fDe," \u2014 "),hZ=n(fDe,"A",{href:!0});var HPt=s(hZ);sqr=r(HPt,"FlaxBertForCausalLM"),HPt.forEach(t),lqr=r(fDe," (BERT model)"),fDe.forEach(t),iqr=i(Ne),o3=n(Ne,"LI",{});var mDe=s(o3);hCe=n(mDe,"STRONG",{});var UPt=s(hCe);dqr=r(UPt,"big_bird"),UPt.forEach(t),cqr=r(mDe," \u2014 "),pZ=n(mDe,"A",{href:!0});var JPt=s(pZ);fqr=r(JPt,"FlaxBigBirdForCausalLM"),JPt.forEach(t),mqr=r(mDe," (BigBird model)"),mDe.forEach(t),gqr=i(Ne),r3=n(Ne,"LI",{});var gDe=s(r3);pCe=n(gDe,"STRONG",{});var YPt=s(pCe);hqr=r(YPt,"electra"),YPt.forEach(t),pqr=r(gDe," \u2014 "),_Z=n(gDe,"A",{href:!0});var KPt=s(_Z);_qr=r(KPt,"FlaxElectraForCausalLM"),KPt.forEach(t),uqr=r(gDe," (ELECTRA model)"),gDe.forEach(t),bqr=i(Ne),t3=n(Ne,"LI",{});var hDe=s(t3);_Ce=n(hDe,"STRONG",{});var ZPt=s(_Ce);vqr=r(ZPt,"gpt2"),ZPt.forEach(t),Fqr=r(hDe," \u2014 "),uZ=n(hDe,"A",{href:!0});var eBt=s(uZ);Tqr=r(eBt,"FlaxGPT2LMHeadModel"),eBt.forEach(t),Mqr=r(hDe," (OpenAI GPT-2 model)"),hDe.forEach(t),Eqr=i(Ne),a3=n(Ne,"LI",{});var pDe=s(a3);uCe=n(pDe,"STRONG",{});var oBt=s(uCe);Cqr=r(oBt,"gpt_neo"),oBt.forEach(t),wqr=r(pDe," \u2014 "),bZ=n(pDe,"A",{href:!0});var rBt=s(bZ);Aqr=r(rBt,"FlaxGPTNeoForCausalLM"),rBt.forEach(t),Lqr=r(pDe," (GPT Neo model)"),pDe.forEach(t),yqr=i(Ne),n3=n(Ne,"LI",{});var _De=s(n3);bCe=n(_De,"STRONG",{});var tBt=s(bCe);xqr=r(tBt,"gptj"),tBt.forEach(t),$qr=r(_De," \u2014 "),vZ=n(_De,"A",{href:!0});var aBt=s(vZ);kqr=r(aBt,"FlaxGPTJForCausalLM"),aBt.forEach(t),Sqr=r(_De," (GPT-J model)"),_De.forEach(t),Rqr=i(Ne),s3=n(Ne,"LI",{});var uDe=s(s3);vCe=n(uDe,"STRONG",{});var nBt=s(vCe);Pqr=r(nBt,"opt"),nBt.forEach(t),Bqr=r(uDe," \u2014 "),FZ=n(uDe,"A",{href:!0});var sBt=s(FZ);Iqr=r(sBt,"FlaxOPTForCausalLM"),sBt.forEach(t),Nqr=r(uDe," (OPT model)"),uDe.forEach(t),qqr=i(Ne),l3=n(Ne,"LI",{});var bDe=s(l3);FCe=n(bDe,"STRONG",{});var lBt=s(FCe);jqr=r(lBt,"roberta"),lBt.forEach(t),Dqr=r(bDe," \u2014 "),TZ=n(bDe,"A",{href:!0});var iBt=s(TZ);Gqr=r(iBt,"FlaxRobertaForCausalLM"),iBt.forEach(t),Oqr=r(bDe," (RoBERTa model)"),bDe.forEach(t),Vqr=i(Ne),i3=n(Ne,"LI",{});var vDe=s(i3);TCe=n(vDe,"STRONG",{});var dBt=s(TCe);Xqr=r(dBt,"xglm"),dBt.forEach(t),zqr=r(vDe," \u2014 "),MZ=n(vDe,"A",{href:!0});var cBt=s(MZ);Qqr=r(cBt,"FlaxXGLMForCausalLM"),cBt.forEach(t),Wqr=r(vDe," (XGLM model)"),vDe.forEach(t),Ne.forEach(t),Hqr=i(ei),T(d3.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),CVe=i(f),Hc=n(f,"H2",{class:!0});var Rze=s(Hc);c3=n(Rze,"A",{id:!0,class:!0,href:!0});var fBt=s(c3);MCe=n(fBt,"SPAN",{});var mBt=s(MCe);T(Ox.$$.fragment,mBt),mBt.forEach(t),fBt.forEach(t),Uqr=i(Rze),ECe=n(Rze,"SPAN",{});var gBt=s(ECe);Jqr=r(gBt,"FlaxAutoModelForPreTraining"),gBt.forEach(t),Rze.forEach(t),wVe=i(f),_r=n(f,"DIV",{class:!0});var oi=s(_r);T(Vx.$$.fragment,oi),Yqr=i(oi),Uc=n(oi,"P",{});var Qre=s(Uc);Kqr=r(Qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=n(Qre,"A",{href:!0});var hBt=s(EZ);Zqr=r(hBt,"from_pretrained()"),hBt.forEach(t),ejr=r(Qre," class method or the "),CZ=n(Qre,"A",{href:!0});var pBt=s(CZ);ojr=r(pBt,"from_config()"),pBt.forEach(t),rjr=r(Qre,` class
method.`),Qre.forEach(t),tjr=i(oi),Xx=n(oi,"P",{});var Pze=s(Xx);ajr=r(Pze,"This class cannot be instantiated directly using "),CCe=n(Pze,"CODE",{});var _Bt=s(CCe);njr=r(_Bt,"__init__()"),_Bt.forEach(t),sjr=r(Pze," (throws an error)."),Pze.forEach(t),ljr=i(oi),Qt=n(oi,"DIV",{class:!0});var nL=s(Qt);T(zx.$$.fragment,nL),ijr=i(nL),wCe=n(nL,"P",{});var uBt=s(wCe);djr=r(uBt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uBt.forEach(t),cjr=i(nL),Jc=n(nL,"P",{});var Wre=s(Jc);fjr=r(Wre,`Note:
Loading a model from its configuration file does `),ACe=n(Wre,"STRONG",{});var bBt=s(ACe);mjr=r(bBt,"not"),bBt.forEach(t),gjr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Wre,"A",{href:!0});var vBt=s(wZ);hjr=r(vBt,"from_pretrained()"),vBt.forEach(t),pjr=r(Wre," to load the model weights."),Wre.forEach(t),_jr=i(nL),T(f3.$$.fragment,nL),nL.forEach(t),ujr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Qx.$$.fragment,ri),bjr=i(ri),LCe=n(ri,"P",{});var FBt=s(LCe);vjr=r(FBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FBt.forEach(t),Fjr=i(ri),Mn=n(ri,"P",{});var sL=s(Mn);Tjr=r(sL,"The model class to instantiate is selected based on the "),yCe=n(sL,"CODE",{});var TBt=s(yCe);Mjr=r(TBt,"model_type"),TBt.forEach(t),Ejr=r(sL,` property of the config object (either
passed as an argument or loaded from `),xCe=n(sL,"CODE",{});var MBt=s(xCe);Cjr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),wjr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ce=n(sL,"CODE",{});var EBt=s($Ce);Ajr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),Ljr=r(sL,":"),sL.forEach(t),yjr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);m3=n(we,"LI",{});var FDe=s(m3);kCe=n(FDe,"STRONG",{});var CBt=s(kCe);xjr=r(CBt,"albert"),CBt.forEach(t),$jr=r(FDe," \u2014 "),AZ=n(FDe,"A",{href:!0});var wBt=s(AZ);kjr=r(wBt,"FlaxAlbertForPreTraining"),wBt.forEach(t),Sjr=r(FDe," (ALBERT model)"),FDe.forEach(t),Rjr=i(we),g3=n(we,"LI",{});var TDe=s(g3);SCe=n(TDe,"STRONG",{});var ABt=s(SCe);Pjr=r(ABt,"bart"),ABt.forEach(t),Bjr=r(TDe," \u2014 "),LZ=n(TDe,"A",{href:!0});var LBt=s(LZ);Ijr=r(LBt,"FlaxBartForConditionalGeneration"),LBt.forEach(t),Njr=r(TDe," (BART model)"),TDe.forEach(t),qjr=i(we),h3=n(we,"LI",{});var MDe=s(h3);RCe=n(MDe,"STRONG",{});var yBt=s(RCe);jjr=r(yBt,"bert"),yBt.forEach(t),Djr=r(MDe," \u2014 "),yZ=n(MDe,"A",{href:!0});var xBt=s(yZ);Gjr=r(xBt,"FlaxBertForPreTraining"),xBt.forEach(t),Ojr=r(MDe," (BERT model)"),MDe.forEach(t),Vjr=i(we),p3=n(we,"LI",{});var EDe=s(p3);PCe=n(EDe,"STRONG",{});var $Bt=s(PCe);Xjr=r($Bt,"big_bird"),$Bt.forEach(t),zjr=r(EDe," \u2014 "),xZ=n(EDe,"A",{href:!0});var kBt=s(xZ);Qjr=r(kBt,"FlaxBigBirdForPreTraining"),kBt.forEach(t),Wjr=r(EDe," (BigBird model)"),EDe.forEach(t),Hjr=i(we),_3=n(we,"LI",{});var CDe=s(_3);BCe=n(CDe,"STRONG",{});var SBt=s(BCe);Ujr=r(SBt,"electra"),SBt.forEach(t),Jjr=r(CDe," \u2014 "),$Z=n(CDe,"A",{href:!0});var RBt=s($Z);Yjr=r(RBt,"FlaxElectraForPreTraining"),RBt.forEach(t),Kjr=r(CDe," (ELECTRA model)"),CDe.forEach(t),Zjr=i(we),u3=n(we,"LI",{});var wDe=s(u3);ICe=n(wDe,"STRONG",{});var PBt=s(ICe);eDr=r(PBt,"longt5"),PBt.forEach(t),oDr=r(wDe," \u2014 "),kZ=n(wDe,"A",{href:!0});var BBt=s(kZ);rDr=r(BBt,"FlaxLongT5ForConditionalGeneration"),BBt.forEach(t),tDr=r(wDe," (LongT5 model)"),wDe.forEach(t),aDr=i(we),b3=n(we,"LI",{});var ADe=s(b3);NCe=n(ADe,"STRONG",{});var IBt=s(NCe);nDr=r(IBt,"mbart"),IBt.forEach(t),sDr=r(ADe," \u2014 "),SZ=n(ADe,"A",{href:!0});var NBt=s(SZ);lDr=r(NBt,"FlaxMBartForConditionalGeneration"),NBt.forEach(t),iDr=r(ADe," (mBART model)"),ADe.forEach(t),dDr=i(we),v3=n(we,"LI",{});var LDe=s(v3);qCe=n(LDe,"STRONG",{});var qBt=s(qCe);cDr=r(qBt,"mt5"),qBt.forEach(t),fDr=r(LDe," \u2014 "),RZ=n(LDe,"A",{href:!0});var jBt=s(RZ);mDr=r(jBt,"FlaxMT5ForConditionalGeneration"),jBt.forEach(t),gDr=r(LDe," (MT5 model)"),LDe.forEach(t),hDr=i(we),F3=n(we,"LI",{});var yDe=s(F3);jCe=n(yDe,"STRONG",{});var DBt=s(jCe);pDr=r(DBt,"roberta"),DBt.forEach(t),_Dr=r(yDe," \u2014 "),PZ=n(yDe,"A",{href:!0});var GBt=s(PZ);uDr=r(GBt,"FlaxRobertaForMaskedLM"),GBt.forEach(t),bDr=r(yDe," (RoBERTa model)"),yDe.forEach(t),vDr=i(we),T3=n(we,"LI",{});var xDe=s(T3);DCe=n(xDe,"STRONG",{});var OBt=s(DCe);FDr=r(OBt,"roformer"),OBt.forEach(t),TDr=r(xDe," \u2014 "),BZ=n(xDe,"A",{href:!0});var VBt=s(BZ);MDr=r(VBt,"FlaxRoFormerForMaskedLM"),VBt.forEach(t),EDr=r(xDe," (RoFormer model)"),xDe.forEach(t),CDr=i(we),M3=n(we,"LI",{});var $De=s(M3);GCe=n($De,"STRONG",{});var XBt=s(GCe);wDr=r(XBt,"t5"),XBt.forEach(t),ADr=r($De," \u2014 "),IZ=n($De,"A",{href:!0});var zBt=s(IZ);LDr=r(zBt,"FlaxT5ForConditionalGeneration"),zBt.forEach(t),yDr=r($De," (T5 model)"),$De.forEach(t),xDr=i(we),E3=n(we,"LI",{});var kDe=s(E3);OCe=n(kDe,"STRONG",{});var QBt=s(OCe);$Dr=r(QBt,"wav2vec2"),QBt.forEach(t),kDr=r(kDe," \u2014 "),NZ=n(kDe,"A",{href:!0});var WBt=s(NZ);SDr=r(WBt,"FlaxWav2Vec2ForPreTraining"),WBt.forEach(t),RDr=r(kDe," (Wav2Vec2 model)"),kDe.forEach(t),PDr=i(we),C3=n(we,"LI",{});var SDe=s(C3);VCe=n(SDe,"STRONG",{});var HBt=s(VCe);BDr=r(HBt,"xlm-roberta"),HBt.forEach(t),IDr=r(SDe," \u2014 "),qZ=n(SDe,"A",{href:!0});var UBt=s(qZ);NDr=r(UBt,"FlaxXLMRobertaForMaskedLM"),UBt.forEach(t),qDr=r(SDe," (XLM-RoBERTa model)"),SDe.forEach(t),we.forEach(t),jDr=i(ri),T(w3.$$.fragment,ri),ri.forEach(t),oi.forEach(t),AVe=i(f),Yc=n(f,"H2",{class:!0});var Bze=s(Yc);A3=n(Bze,"A",{id:!0,class:!0,href:!0});var JBt=s(A3);XCe=n(JBt,"SPAN",{});var YBt=s(XCe);T(Wx.$$.fragment,YBt),YBt.forEach(t),JBt.forEach(t),DDr=i(Bze),zCe=n(Bze,"SPAN",{});var KBt=s(zCe);GDr=r(KBt,"FlaxAutoModelForMaskedLM"),KBt.forEach(t),Bze.forEach(t),LVe=i(f),ur=n(f,"DIV",{class:!0});var ti=s(ur);T(Hx.$$.fragment,ti),ODr=i(ti),Kc=n(ti,"P",{});var Hre=s(Kc);VDr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=n(Hre,"A",{href:!0});var ZBt=s(jZ);XDr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),zDr=r(Hre," class method or the "),DZ=n(Hre,"A",{href:!0});var eIt=s(DZ);QDr=r(eIt,"from_config()"),eIt.forEach(t),WDr=r(Hre,` class
method.`),Hre.forEach(t),HDr=i(ti),Ux=n(ti,"P",{});var Ize=s(Ux);UDr=r(Ize,"This class cannot be instantiated directly using "),QCe=n(Ize,"CODE",{});var oIt=s(QCe);JDr=r(oIt,"__init__()"),oIt.forEach(t),YDr=r(Ize," (throws an error)."),Ize.forEach(t),KDr=i(ti),Wt=n(ti,"DIV",{class:!0});var lL=s(Wt);T(Jx.$$.fragment,lL),ZDr=i(lL),WCe=n(lL,"P",{});var rIt=s(WCe);eGr=r(rIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rIt.forEach(t),oGr=i(lL),Zc=n(lL,"P",{});var Ure=s(Zc);rGr=r(Ure,`Note:
Loading a model from its configuration file does `),HCe=n(Ure,"STRONG",{});var tIt=s(HCe);tGr=r(tIt,"not"),tIt.forEach(t),aGr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(Ure,"A",{href:!0});var aIt=s(GZ);nGr=r(aIt,"from_pretrained()"),aIt.forEach(t),sGr=r(Ure," to load the model weights."),Ure.forEach(t),lGr=i(lL),T(L3.$$.fragment,lL),lL.forEach(t),iGr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(Yx.$$.fragment,ai),dGr=i(ai),UCe=n(ai,"P",{});var nIt=s(UCe);cGr=r(nIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nIt.forEach(t),fGr=i(ai),En=n(ai,"P",{});var iL=s(En);mGr=r(iL,"The model class to instantiate is selected based on the "),JCe=n(iL,"CODE",{});var sIt=s(JCe);gGr=r(sIt,"model_type"),sIt.forEach(t),hGr=r(iL,` property of the config object (either
passed as an argument or loaded from `),YCe=n(iL,"CODE",{});var lIt=s(YCe);pGr=r(lIt,"pretrained_model_name_or_path"),lIt.forEach(t),_Gr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=n(iL,"CODE",{});var iIt=s(KCe);uGr=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),bGr=r(iL,":"),iL.forEach(t),vGr=i(ai),$e=n(ai,"UL",{});var qe=s($e);y3=n(qe,"LI",{});var RDe=s(y3);ZCe=n(RDe,"STRONG",{});var dIt=s(ZCe);FGr=r(dIt,"albert"),dIt.forEach(t),TGr=r(RDe," \u2014 "),OZ=n(RDe,"A",{href:!0});var cIt=s(OZ);MGr=r(cIt,"FlaxAlbertForMaskedLM"),cIt.forEach(t),EGr=r(RDe," (ALBERT model)"),RDe.forEach(t),CGr=i(qe),x3=n(qe,"LI",{});var PDe=s(x3);e5e=n(PDe,"STRONG",{});var fIt=s(e5e);wGr=r(fIt,"bart"),fIt.forEach(t),AGr=r(PDe," \u2014 "),VZ=n(PDe,"A",{href:!0});var mIt=s(VZ);LGr=r(mIt,"FlaxBartForConditionalGeneration"),mIt.forEach(t),yGr=r(PDe," (BART model)"),PDe.forEach(t),xGr=i(qe),$3=n(qe,"LI",{});var BDe=s($3);o5e=n(BDe,"STRONG",{});var gIt=s(o5e);$Gr=r(gIt,"bert"),gIt.forEach(t),kGr=r(BDe," \u2014 "),XZ=n(BDe,"A",{href:!0});var hIt=s(XZ);SGr=r(hIt,"FlaxBertForMaskedLM"),hIt.forEach(t),RGr=r(BDe," (BERT model)"),BDe.forEach(t),PGr=i(qe),k3=n(qe,"LI",{});var IDe=s(k3);r5e=n(IDe,"STRONG",{});var pIt=s(r5e);BGr=r(pIt,"big_bird"),pIt.forEach(t),IGr=r(IDe," \u2014 "),zZ=n(IDe,"A",{href:!0});var _It=s(zZ);NGr=r(_It,"FlaxBigBirdForMaskedLM"),_It.forEach(t),qGr=r(IDe," (BigBird model)"),IDe.forEach(t),jGr=i(qe),S3=n(qe,"LI",{});var NDe=s(S3);t5e=n(NDe,"STRONG",{});var uIt=s(t5e);DGr=r(uIt,"distilbert"),uIt.forEach(t),GGr=r(NDe," \u2014 "),QZ=n(NDe,"A",{href:!0});var bIt=s(QZ);OGr=r(bIt,"FlaxDistilBertForMaskedLM"),bIt.forEach(t),VGr=r(NDe," (DistilBERT model)"),NDe.forEach(t),XGr=i(qe),R3=n(qe,"LI",{});var qDe=s(R3);a5e=n(qDe,"STRONG",{});var vIt=s(a5e);zGr=r(vIt,"electra"),vIt.forEach(t),QGr=r(qDe," \u2014 "),WZ=n(qDe,"A",{href:!0});var FIt=s(WZ);WGr=r(FIt,"FlaxElectraForMaskedLM"),FIt.forEach(t),HGr=r(qDe," (ELECTRA model)"),qDe.forEach(t),UGr=i(qe),P3=n(qe,"LI",{});var jDe=s(P3);n5e=n(jDe,"STRONG",{});var TIt=s(n5e);JGr=r(TIt,"mbart"),TIt.forEach(t),YGr=r(jDe," \u2014 "),HZ=n(jDe,"A",{href:!0});var MIt=s(HZ);KGr=r(MIt,"FlaxMBartForConditionalGeneration"),MIt.forEach(t),ZGr=r(jDe," (mBART model)"),jDe.forEach(t),eOr=i(qe),B3=n(qe,"LI",{});var DDe=s(B3);s5e=n(DDe,"STRONG",{});var EIt=s(s5e);oOr=r(EIt,"roberta"),EIt.forEach(t),rOr=r(DDe," \u2014 "),UZ=n(DDe,"A",{href:!0});var CIt=s(UZ);tOr=r(CIt,"FlaxRobertaForMaskedLM"),CIt.forEach(t),aOr=r(DDe," (RoBERTa model)"),DDe.forEach(t),nOr=i(qe),I3=n(qe,"LI",{});var GDe=s(I3);l5e=n(GDe,"STRONG",{});var wIt=s(l5e);sOr=r(wIt,"roformer"),wIt.forEach(t),lOr=r(GDe," \u2014 "),JZ=n(GDe,"A",{href:!0});var AIt=s(JZ);iOr=r(AIt,"FlaxRoFormerForMaskedLM"),AIt.forEach(t),dOr=r(GDe," (RoFormer model)"),GDe.forEach(t),cOr=i(qe),N3=n(qe,"LI",{});var ODe=s(N3);i5e=n(ODe,"STRONG",{});var LIt=s(i5e);fOr=r(LIt,"xlm-roberta"),LIt.forEach(t),mOr=r(ODe," \u2014 "),YZ=n(ODe,"A",{href:!0});var yIt=s(YZ);gOr=r(yIt,"FlaxXLMRobertaForMaskedLM"),yIt.forEach(t),hOr=r(ODe," (XLM-RoBERTa model)"),ODe.forEach(t),qe.forEach(t),pOr=i(ai),T(q3.$$.fragment,ai),ai.forEach(t),ti.forEach(t),yVe=i(f),ef=n(f,"H2",{class:!0});var Nze=s(ef);j3=n(Nze,"A",{id:!0,class:!0,href:!0});var xIt=s(j3);d5e=n(xIt,"SPAN",{});var $It=s(d5e);T(Kx.$$.fragment,$It),$It.forEach(t),xIt.forEach(t),_Or=i(Nze),c5e=n(Nze,"SPAN",{});var kIt=s(c5e);uOr=r(kIt,"FlaxAutoModelForSeq2SeqLM"),kIt.forEach(t),Nze.forEach(t),xVe=i(f),br=n(f,"DIV",{class:!0});var ni=s(br);T(Zx.$$.fragment,ni),bOr=i(ni),of=n(ni,"P",{});var Jre=s(of);vOr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=n(Jre,"A",{href:!0});var SIt=s(KZ);FOr=r(SIt,"from_pretrained()"),SIt.forEach(t),TOr=r(Jre," class method or the "),ZZ=n(Jre,"A",{href:!0});var RIt=s(ZZ);MOr=r(RIt,"from_config()"),RIt.forEach(t),EOr=r(Jre,` class
method.`),Jre.forEach(t),COr=i(ni),e$=n(ni,"P",{});var qze=s(e$);wOr=r(qze,"This class cannot be instantiated directly using "),f5e=n(qze,"CODE",{});var PIt=s(f5e);AOr=r(PIt,"__init__()"),PIt.forEach(t),LOr=r(qze," (throws an error)."),qze.forEach(t),yOr=i(ni),Ht=n(ni,"DIV",{class:!0});var dL=s(Ht);T(o$.$$.fragment,dL),xOr=i(dL),m5e=n(dL,"P",{});var BIt=s(m5e);$Or=r(BIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BIt.forEach(t),kOr=i(dL),rf=n(dL,"P",{});var Yre=s(rf);SOr=r(Yre,`Note:
Loading a model from its configuration file does `),g5e=n(Yre,"STRONG",{});var IIt=s(g5e);ROr=r(IIt,"not"),IIt.forEach(t),POr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=n(Yre,"A",{href:!0});var NIt=s(eee);BOr=r(NIt,"from_pretrained()"),NIt.forEach(t),IOr=r(Yre," to load the model weights."),Yre.forEach(t),NOr=i(dL),T(D3.$$.fragment,dL),dL.forEach(t),qOr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(r$.$$.fragment,si),jOr=i(si),h5e=n(si,"P",{});var qIt=s(h5e);DOr=r(qIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qIt.forEach(t),GOr=i(si),Cn=n(si,"P",{});var cL=s(Cn);OOr=r(cL,"The model class to instantiate is selected based on the "),p5e=n(cL,"CODE",{});var jIt=s(p5e);VOr=r(jIt,"model_type"),jIt.forEach(t),XOr=r(cL,` property of the config object (either
passed as an argument or loaded from `),_5e=n(cL,"CODE",{});var DIt=s(_5e);zOr=r(DIt,"pretrained_model_name_or_path"),DIt.forEach(t),QOr=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u5e=n(cL,"CODE",{});var GIt=s(u5e);WOr=r(GIt,"pretrained_model_name_or_path"),GIt.forEach(t),HOr=r(cL,":"),cL.forEach(t),UOr=i(si),ke=n(si,"UL",{});var je=s(ke);G3=n(je,"LI",{});var VDe=s(G3);b5e=n(VDe,"STRONG",{});var OIt=s(b5e);JOr=r(OIt,"bart"),OIt.forEach(t),YOr=r(VDe," \u2014 "),oee=n(VDe,"A",{href:!0});var VIt=s(oee);KOr=r(VIt,"FlaxBartForConditionalGeneration"),VIt.forEach(t),ZOr=r(VDe," (BART model)"),VDe.forEach(t),eVr=i(je),O3=n(je,"LI",{});var XDe=s(O3);v5e=n(XDe,"STRONG",{});var XIt=s(v5e);oVr=r(XIt,"blenderbot"),XIt.forEach(t),rVr=r(XDe," \u2014 "),ree=n(XDe,"A",{href:!0});var zIt=s(ree);tVr=r(zIt,"FlaxBlenderbotForConditionalGeneration"),zIt.forEach(t),aVr=r(XDe," (Blenderbot model)"),XDe.forEach(t),nVr=i(je),V3=n(je,"LI",{});var zDe=s(V3);F5e=n(zDe,"STRONG",{});var QIt=s(F5e);sVr=r(QIt,"blenderbot-small"),QIt.forEach(t),lVr=r(zDe," \u2014 "),tee=n(zDe,"A",{href:!0});var WIt=s(tee);iVr=r(WIt,"FlaxBlenderbotSmallForConditionalGeneration"),WIt.forEach(t),dVr=r(zDe," (BlenderbotSmall model)"),zDe.forEach(t),cVr=i(je),X3=n(je,"LI",{});var QDe=s(X3);T5e=n(QDe,"STRONG",{});var HIt=s(T5e);fVr=r(HIt,"encoder-decoder"),HIt.forEach(t),mVr=r(QDe," \u2014 "),aee=n(QDe,"A",{href:!0});var UIt=s(aee);gVr=r(UIt,"FlaxEncoderDecoderModel"),UIt.forEach(t),hVr=r(QDe," (Encoder decoder model)"),QDe.forEach(t),pVr=i(je),z3=n(je,"LI",{});var WDe=s(z3);M5e=n(WDe,"STRONG",{});var JIt=s(M5e);_Vr=r(JIt,"longt5"),JIt.forEach(t),uVr=r(WDe," \u2014 "),nee=n(WDe,"A",{href:!0});var YIt=s(nee);bVr=r(YIt,"FlaxLongT5ForConditionalGeneration"),YIt.forEach(t),vVr=r(WDe," (LongT5 model)"),WDe.forEach(t),FVr=i(je),Q3=n(je,"LI",{});var HDe=s(Q3);E5e=n(HDe,"STRONG",{});var KIt=s(E5e);TVr=r(KIt,"marian"),KIt.forEach(t),MVr=r(HDe," \u2014 "),see=n(HDe,"A",{href:!0});var ZIt=s(see);EVr=r(ZIt,"FlaxMarianMTModel"),ZIt.forEach(t),CVr=r(HDe," (Marian model)"),HDe.forEach(t),wVr=i(je),W3=n(je,"LI",{});var UDe=s(W3);C5e=n(UDe,"STRONG",{});var eNt=s(C5e);AVr=r(eNt,"mbart"),eNt.forEach(t),LVr=r(UDe," \u2014 "),lee=n(UDe,"A",{href:!0});var oNt=s(lee);yVr=r(oNt,"FlaxMBartForConditionalGeneration"),oNt.forEach(t),xVr=r(UDe," (mBART model)"),UDe.forEach(t),$Vr=i(je),H3=n(je,"LI",{});var JDe=s(H3);w5e=n(JDe,"STRONG",{});var rNt=s(w5e);kVr=r(rNt,"mt5"),rNt.forEach(t),SVr=r(JDe," \u2014 "),iee=n(JDe,"A",{href:!0});var tNt=s(iee);RVr=r(tNt,"FlaxMT5ForConditionalGeneration"),tNt.forEach(t),PVr=r(JDe," (MT5 model)"),JDe.forEach(t),BVr=i(je),U3=n(je,"LI",{});var YDe=s(U3);A5e=n(YDe,"STRONG",{});var aNt=s(A5e);IVr=r(aNt,"pegasus"),aNt.forEach(t),NVr=r(YDe," \u2014 "),dee=n(YDe,"A",{href:!0});var nNt=s(dee);qVr=r(nNt,"FlaxPegasusForConditionalGeneration"),nNt.forEach(t),jVr=r(YDe," (Pegasus model)"),YDe.forEach(t),DVr=i(je),J3=n(je,"LI",{});var KDe=s(J3);L5e=n(KDe,"STRONG",{});var sNt=s(L5e);GVr=r(sNt,"t5"),sNt.forEach(t),OVr=r(KDe," \u2014 "),cee=n(KDe,"A",{href:!0});var lNt=s(cee);VVr=r(lNt,"FlaxT5ForConditionalGeneration"),lNt.forEach(t),XVr=r(KDe," (T5 model)"),KDe.forEach(t),je.forEach(t),zVr=i(si),T(Y3.$$.fragment,si),si.forEach(t),ni.forEach(t),$Ve=i(f),tf=n(f,"H2",{class:!0});var jze=s(tf);K3=n(jze,"A",{id:!0,class:!0,href:!0});var iNt=s(K3);y5e=n(iNt,"SPAN",{});var dNt=s(y5e);T(t$.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),QVr=i(jze),x5e=n(jze,"SPAN",{});var cNt=s(x5e);WVr=r(cNt,"FlaxAutoModelForSequenceClassification"),cNt.forEach(t),jze.forEach(t),kVe=i(f),vr=n(f,"DIV",{class:!0});var li=s(vr);T(a$.$$.fragment,li),HVr=i(li),af=n(li,"P",{});var Kre=s(af);UVr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=n(Kre,"A",{href:!0});var fNt=s(fee);JVr=r(fNt,"from_pretrained()"),fNt.forEach(t),YVr=r(Kre," class method or the "),mee=n(Kre,"A",{href:!0});var mNt=s(mee);KVr=r(mNt,"from_config()"),mNt.forEach(t),ZVr=r(Kre,` class
method.`),Kre.forEach(t),eXr=i(li),n$=n(li,"P",{});var Dze=s(n$);oXr=r(Dze,"This class cannot be instantiated directly using "),$5e=n(Dze,"CODE",{});var gNt=s($5e);rXr=r(gNt,"__init__()"),gNt.forEach(t),tXr=r(Dze," (throws an error)."),Dze.forEach(t),aXr=i(li),Ut=n(li,"DIV",{class:!0});var fL=s(Ut);T(s$.$$.fragment,fL),nXr=i(fL),k5e=n(fL,"P",{});var hNt=s(k5e);sXr=r(hNt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hNt.forEach(t),lXr=i(fL),nf=n(fL,"P",{});var Zre=s(nf);iXr=r(Zre,`Note:
Loading a model from its configuration file does `),S5e=n(Zre,"STRONG",{});var pNt=s(S5e);dXr=r(pNt,"not"),pNt.forEach(t),cXr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(Zre,"A",{href:!0});var _Nt=s(gee);fXr=r(_Nt,"from_pretrained()"),_Nt.forEach(t),mXr=r(Zre," to load the model weights."),Zre.forEach(t),gXr=i(fL),T(Z3.$$.fragment,fL),fL.forEach(t),hXr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(l$.$$.fragment,ii),pXr=i(ii),R5e=n(ii,"P",{});var uNt=s(R5e);_Xr=r(uNt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uNt.forEach(t),uXr=i(ii),wn=n(ii,"P",{});var mL=s(wn);bXr=r(mL,"The model class to instantiate is selected based on the "),P5e=n(mL,"CODE",{});var bNt=s(P5e);vXr=r(bNt,"model_type"),bNt.forEach(t),FXr=r(mL,` property of the config object (either
passed as an argument or loaded from `),B5e=n(mL,"CODE",{});var vNt=s(B5e);TXr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),MXr=r(mL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I5e=n(mL,"CODE",{});var FNt=s(I5e);EXr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),CXr=r(mL,":"),mL.forEach(t),wXr=i(ii),Se=n(ii,"UL",{});var De=s(Se);e0=n(De,"LI",{});var ZDe=s(e0);N5e=n(ZDe,"STRONG",{});var TNt=s(N5e);AXr=r(TNt,"albert"),TNt.forEach(t),LXr=r(ZDe," \u2014 "),hee=n(ZDe,"A",{href:!0});var MNt=s(hee);yXr=r(MNt,"FlaxAlbertForSequenceClassification"),MNt.forEach(t),xXr=r(ZDe," (ALBERT model)"),ZDe.forEach(t),$Xr=i(De),o0=n(De,"LI",{});var eGe=s(o0);q5e=n(eGe,"STRONG",{});var ENt=s(q5e);kXr=r(ENt,"bart"),ENt.forEach(t),SXr=r(eGe," \u2014 "),pee=n(eGe,"A",{href:!0});var CNt=s(pee);RXr=r(CNt,"FlaxBartForSequenceClassification"),CNt.forEach(t),PXr=r(eGe," (BART model)"),eGe.forEach(t),BXr=i(De),r0=n(De,"LI",{});var oGe=s(r0);j5e=n(oGe,"STRONG",{});var wNt=s(j5e);IXr=r(wNt,"bert"),wNt.forEach(t),NXr=r(oGe," \u2014 "),_ee=n(oGe,"A",{href:!0});var ANt=s(_ee);qXr=r(ANt,"FlaxBertForSequenceClassification"),ANt.forEach(t),jXr=r(oGe," (BERT model)"),oGe.forEach(t),DXr=i(De),t0=n(De,"LI",{});var rGe=s(t0);D5e=n(rGe,"STRONG",{});var LNt=s(D5e);GXr=r(LNt,"big_bird"),LNt.forEach(t),OXr=r(rGe," \u2014 "),uee=n(rGe,"A",{href:!0});var yNt=s(uee);VXr=r(yNt,"FlaxBigBirdForSequenceClassification"),yNt.forEach(t),XXr=r(rGe," (BigBird model)"),rGe.forEach(t),zXr=i(De),a0=n(De,"LI",{});var tGe=s(a0);G5e=n(tGe,"STRONG",{});var xNt=s(G5e);QXr=r(xNt,"distilbert"),xNt.forEach(t),WXr=r(tGe," \u2014 "),bee=n(tGe,"A",{href:!0});var $Nt=s(bee);HXr=r($Nt,"FlaxDistilBertForSequenceClassification"),$Nt.forEach(t),UXr=r(tGe," (DistilBERT model)"),tGe.forEach(t),JXr=i(De),n0=n(De,"LI",{});var aGe=s(n0);O5e=n(aGe,"STRONG",{});var kNt=s(O5e);YXr=r(kNt,"electra"),kNt.forEach(t),KXr=r(aGe," \u2014 "),vee=n(aGe,"A",{href:!0});var SNt=s(vee);ZXr=r(SNt,"FlaxElectraForSequenceClassification"),SNt.forEach(t),ezr=r(aGe," (ELECTRA model)"),aGe.forEach(t),ozr=i(De),s0=n(De,"LI",{});var nGe=s(s0);V5e=n(nGe,"STRONG",{});var RNt=s(V5e);rzr=r(RNt,"mbart"),RNt.forEach(t),tzr=r(nGe," \u2014 "),Fee=n(nGe,"A",{href:!0});var PNt=s(Fee);azr=r(PNt,"FlaxMBartForSequenceClassification"),PNt.forEach(t),nzr=r(nGe," (mBART model)"),nGe.forEach(t),szr=i(De),l0=n(De,"LI",{});var sGe=s(l0);X5e=n(sGe,"STRONG",{});var BNt=s(X5e);lzr=r(BNt,"roberta"),BNt.forEach(t),izr=r(sGe," \u2014 "),Tee=n(sGe,"A",{href:!0});var INt=s(Tee);dzr=r(INt,"FlaxRobertaForSequenceClassification"),INt.forEach(t),czr=r(sGe," (RoBERTa model)"),sGe.forEach(t),fzr=i(De),i0=n(De,"LI",{});var lGe=s(i0);z5e=n(lGe,"STRONG",{});var NNt=s(z5e);mzr=r(NNt,"roformer"),NNt.forEach(t),gzr=r(lGe," \u2014 "),Mee=n(lGe,"A",{href:!0});var qNt=s(Mee);hzr=r(qNt,"FlaxRoFormerForSequenceClassification"),qNt.forEach(t),pzr=r(lGe," (RoFormer model)"),lGe.forEach(t),_zr=i(De),d0=n(De,"LI",{});var iGe=s(d0);Q5e=n(iGe,"STRONG",{});var jNt=s(Q5e);uzr=r(jNt,"xlm-roberta"),jNt.forEach(t),bzr=r(iGe," \u2014 "),Eee=n(iGe,"A",{href:!0});var DNt=s(Eee);vzr=r(DNt,"FlaxXLMRobertaForSequenceClassification"),DNt.forEach(t),Fzr=r(iGe," (XLM-RoBERTa model)"),iGe.forEach(t),De.forEach(t),Tzr=i(ii),T(c0.$$.fragment,ii),ii.forEach(t),li.forEach(t),SVe=i(f),sf=n(f,"H2",{class:!0});var Gze=s(sf);f0=n(Gze,"A",{id:!0,class:!0,href:!0});var GNt=s(f0);W5e=n(GNt,"SPAN",{});var ONt=s(W5e);T(i$.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),Mzr=i(Gze),H5e=n(Gze,"SPAN",{});var VNt=s(H5e);Ezr=r(VNt,"FlaxAutoModelForQuestionAnswering"),VNt.forEach(t),Gze.forEach(t),RVe=i(f),Fr=n(f,"DIV",{class:!0});var di=s(Fr);T(d$.$$.fragment,di),Czr=i(di),lf=n(di,"P",{});var ete=s(lf);wzr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=n(ete,"A",{href:!0});var XNt=s(Cee);Azr=r(XNt,"from_pretrained()"),XNt.forEach(t),Lzr=r(ete," class method or the "),wee=n(ete,"A",{href:!0});var zNt=s(wee);yzr=r(zNt,"from_config()"),zNt.forEach(t),xzr=r(ete,` class
method.`),ete.forEach(t),$zr=i(di),c$=n(di,"P",{});var Oze=s(c$);kzr=r(Oze,"This class cannot be instantiated directly using "),U5e=n(Oze,"CODE",{});var QNt=s(U5e);Szr=r(QNt,"__init__()"),QNt.forEach(t),Rzr=r(Oze," (throws an error)."),Oze.forEach(t),Pzr=i(di),Jt=n(di,"DIV",{class:!0});var gL=s(Jt);T(f$.$$.fragment,gL),Bzr=i(gL),J5e=n(gL,"P",{});var WNt=s(J5e);Izr=r(WNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WNt.forEach(t),Nzr=i(gL),df=n(gL,"P",{});var ote=s(df);qzr=r(ote,`Note:
Loading a model from its configuration file does `),Y5e=n(ote,"STRONG",{});var HNt=s(Y5e);jzr=r(HNt,"not"),HNt.forEach(t),Dzr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=n(ote,"A",{href:!0});var UNt=s(Aee);Gzr=r(UNt,"from_pretrained()"),UNt.forEach(t),Ozr=r(ote," to load the model weights."),ote.forEach(t),Vzr=i(gL),T(m0.$$.fragment,gL),gL.forEach(t),Xzr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(m$.$$.fragment,ci),zzr=i(ci),K5e=n(ci,"P",{});var JNt=s(K5e);Qzr=r(JNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JNt.forEach(t),Wzr=i(ci),An=n(ci,"P",{});var hL=s(An);Hzr=r(hL,"The model class to instantiate is selected based on the "),Z5e=n(hL,"CODE",{});var YNt=s(Z5e);Uzr=r(YNt,"model_type"),YNt.forEach(t),Jzr=r(hL,` property of the config object (either
passed as an argument or loaded from `),e3e=n(hL,"CODE",{});var KNt=s(e3e);Yzr=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),Kzr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o3e=n(hL,"CODE",{});var ZNt=s(o3e);Zzr=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),eQr=r(hL,":"),hL.forEach(t),oQr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);g0=n(Ge,"LI",{});var dGe=s(g0);r3e=n(dGe,"STRONG",{});var eqt=s(r3e);rQr=r(eqt,"albert"),eqt.forEach(t),tQr=r(dGe," \u2014 "),Lee=n(dGe,"A",{href:!0});var oqt=s(Lee);aQr=r(oqt,"FlaxAlbertForQuestionAnswering"),oqt.forEach(t),nQr=r(dGe," (ALBERT model)"),dGe.forEach(t),sQr=i(Ge),h0=n(Ge,"LI",{});var cGe=s(h0);t3e=n(cGe,"STRONG",{});var rqt=s(t3e);lQr=r(rqt,"bart"),rqt.forEach(t),iQr=r(cGe," \u2014 "),yee=n(cGe,"A",{href:!0});var tqt=s(yee);dQr=r(tqt,"FlaxBartForQuestionAnswering"),tqt.forEach(t),cQr=r(cGe," (BART model)"),cGe.forEach(t),fQr=i(Ge),p0=n(Ge,"LI",{});var fGe=s(p0);a3e=n(fGe,"STRONG",{});var aqt=s(a3e);mQr=r(aqt,"bert"),aqt.forEach(t),gQr=r(fGe," \u2014 "),xee=n(fGe,"A",{href:!0});var nqt=s(xee);hQr=r(nqt,"FlaxBertForQuestionAnswering"),nqt.forEach(t),pQr=r(fGe," (BERT model)"),fGe.forEach(t),_Qr=i(Ge),_0=n(Ge,"LI",{});var mGe=s(_0);n3e=n(mGe,"STRONG",{});var sqt=s(n3e);uQr=r(sqt,"big_bird"),sqt.forEach(t),bQr=r(mGe," \u2014 "),$ee=n(mGe,"A",{href:!0});var lqt=s($ee);vQr=r(lqt,"FlaxBigBirdForQuestionAnswering"),lqt.forEach(t),FQr=r(mGe," (BigBird model)"),mGe.forEach(t),TQr=i(Ge),u0=n(Ge,"LI",{});var gGe=s(u0);s3e=n(gGe,"STRONG",{});var iqt=s(s3e);MQr=r(iqt,"distilbert"),iqt.forEach(t),EQr=r(gGe," \u2014 "),kee=n(gGe,"A",{href:!0});var dqt=s(kee);CQr=r(dqt,"FlaxDistilBertForQuestionAnswering"),dqt.forEach(t),wQr=r(gGe," (DistilBERT model)"),gGe.forEach(t),AQr=i(Ge),b0=n(Ge,"LI",{});var hGe=s(b0);l3e=n(hGe,"STRONG",{});var cqt=s(l3e);LQr=r(cqt,"electra"),cqt.forEach(t),yQr=r(hGe," \u2014 "),See=n(hGe,"A",{href:!0});var fqt=s(See);xQr=r(fqt,"FlaxElectraForQuestionAnswering"),fqt.forEach(t),$Qr=r(hGe," (ELECTRA model)"),hGe.forEach(t),kQr=i(Ge),v0=n(Ge,"LI",{});var pGe=s(v0);i3e=n(pGe,"STRONG",{});var mqt=s(i3e);SQr=r(mqt,"mbart"),mqt.forEach(t),RQr=r(pGe," \u2014 "),Ree=n(pGe,"A",{href:!0});var gqt=s(Ree);PQr=r(gqt,"FlaxMBartForQuestionAnswering"),gqt.forEach(t),BQr=r(pGe," (mBART model)"),pGe.forEach(t),IQr=i(Ge),F0=n(Ge,"LI",{});var _Ge=s(F0);d3e=n(_Ge,"STRONG",{});var hqt=s(d3e);NQr=r(hqt,"roberta"),hqt.forEach(t),qQr=r(_Ge," \u2014 "),Pee=n(_Ge,"A",{href:!0});var pqt=s(Pee);jQr=r(pqt,"FlaxRobertaForQuestionAnswering"),pqt.forEach(t),DQr=r(_Ge," (RoBERTa model)"),_Ge.forEach(t),GQr=i(Ge),T0=n(Ge,"LI",{});var uGe=s(T0);c3e=n(uGe,"STRONG",{});var _qt=s(c3e);OQr=r(_qt,"roformer"),_qt.forEach(t),VQr=r(uGe," \u2014 "),Bee=n(uGe,"A",{href:!0});var uqt=s(Bee);XQr=r(uqt,"FlaxRoFormerForQuestionAnswering"),uqt.forEach(t),zQr=r(uGe," (RoFormer model)"),uGe.forEach(t),QQr=i(Ge),M0=n(Ge,"LI",{});var bGe=s(M0);f3e=n(bGe,"STRONG",{});var bqt=s(f3e);WQr=r(bqt,"xlm-roberta"),bqt.forEach(t),HQr=r(bGe," \u2014 "),Iee=n(bGe,"A",{href:!0});var vqt=s(Iee);UQr=r(vqt,"FlaxXLMRobertaForQuestionAnswering"),vqt.forEach(t),JQr=r(bGe," (XLM-RoBERTa model)"),bGe.forEach(t),Ge.forEach(t),YQr=i(ci),T(E0.$$.fragment,ci),ci.forEach(t),di.forEach(t),PVe=i(f),cf=n(f,"H2",{class:!0});var Vze=s(cf);C0=n(Vze,"A",{id:!0,class:!0,href:!0});var Fqt=s(C0);m3e=n(Fqt,"SPAN",{});var Tqt=s(m3e);T(g$.$$.fragment,Tqt),Tqt.forEach(t),Fqt.forEach(t),KQr=i(Vze),g3e=n(Vze,"SPAN",{});var Mqt=s(g3e);ZQr=r(Mqt,"FlaxAutoModelForTokenClassification"),Mqt.forEach(t),Vze.forEach(t),BVe=i(f),Tr=n(f,"DIV",{class:!0});var fi=s(Tr);T(h$.$$.fragment,fi),eWr=i(fi),ff=n(fi,"P",{});var rte=s(ff);oWr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=n(rte,"A",{href:!0});var Eqt=s(Nee);rWr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),tWr=r(rte," class method or the "),qee=n(rte,"A",{href:!0});var Cqt=s(qee);aWr=r(Cqt,"from_config()"),Cqt.forEach(t),nWr=r(rte,` class
method.`),rte.forEach(t),sWr=i(fi),p$=n(fi,"P",{});var Xze=s(p$);lWr=r(Xze,"This class cannot be instantiated directly using "),h3e=n(Xze,"CODE",{});var wqt=s(h3e);iWr=r(wqt,"__init__()"),wqt.forEach(t),dWr=r(Xze," (throws an error)."),Xze.forEach(t),cWr=i(fi),Yt=n(fi,"DIV",{class:!0});var pL=s(Yt);T(_$.$$.fragment,pL),fWr=i(pL),p3e=n(pL,"P",{});var Aqt=s(p3e);mWr=r(Aqt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aqt.forEach(t),gWr=i(pL),mf=n(pL,"P",{});var tte=s(mf);hWr=r(tte,`Note:
Loading a model from its configuration file does `),_3e=n(tte,"STRONG",{});var Lqt=s(_3e);pWr=r(Lqt,"not"),Lqt.forEach(t),_Wr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=n(tte,"A",{href:!0});var yqt=s(jee);uWr=r(yqt,"from_pretrained()"),yqt.forEach(t),bWr=r(tte," to load the model weights."),tte.forEach(t),vWr=i(pL),T(w0.$$.fragment,pL),pL.forEach(t),FWr=i(fi),Ur=n(fi,"DIV",{class:!0});var mi=s(Ur);T(u$.$$.fragment,mi),TWr=i(mi),u3e=n(mi,"P",{});var xqt=s(u3e);MWr=r(xqt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xqt.forEach(t),EWr=i(mi),Ln=n(mi,"P",{});var _L=s(Ln);CWr=r(_L,"The model class to instantiate is selected based on the "),b3e=n(_L,"CODE",{});var $qt=s(b3e);wWr=r($qt,"model_type"),$qt.forEach(t),AWr=r(_L,` property of the config object (either
passed as an argument or loaded from `),v3e=n(_L,"CODE",{});var kqt=s(v3e);LWr=r(kqt,"pretrained_model_name_or_path"),kqt.forEach(t),yWr=r(_L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F3e=n(_L,"CODE",{});var Sqt=s(F3e);xWr=r(Sqt,"pretrained_model_name_or_path"),Sqt.forEach(t),$Wr=r(_L,":"),_L.forEach(t),kWr=i(mi),Ve=n(mi,"UL",{});var To=s(Ve);A0=n(To,"LI",{});var vGe=s(A0);T3e=n(vGe,"STRONG",{});var Rqt=s(T3e);SWr=r(Rqt,"albert"),Rqt.forEach(t),RWr=r(vGe," \u2014 "),Dee=n(vGe,"A",{href:!0});var Pqt=s(Dee);PWr=r(Pqt,"FlaxAlbertForTokenClassification"),Pqt.forEach(t),BWr=r(vGe," (ALBERT model)"),vGe.forEach(t),IWr=i(To),L0=n(To,"LI",{});var FGe=s(L0);M3e=n(FGe,"STRONG",{});var Bqt=s(M3e);NWr=r(Bqt,"bert"),Bqt.forEach(t),qWr=r(FGe," \u2014 "),Gee=n(FGe,"A",{href:!0});var Iqt=s(Gee);jWr=r(Iqt,"FlaxBertForTokenClassification"),Iqt.forEach(t),DWr=r(FGe," (BERT model)"),FGe.forEach(t),GWr=i(To),y0=n(To,"LI",{});var TGe=s(y0);E3e=n(TGe,"STRONG",{});var Nqt=s(E3e);OWr=r(Nqt,"big_bird"),Nqt.forEach(t),VWr=r(TGe," \u2014 "),Oee=n(TGe,"A",{href:!0});var qqt=s(Oee);XWr=r(qqt,"FlaxBigBirdForTokenClassification"),qqt.forEach(t),zWr=r(TGe," (BigBird model)"),TGe.forEach(t),QWr=i(To),x0=n(To,"LI",{});var MGe=s(x0);C3e=n(MGe,"STRONG",{});var jqt=s(C3e);WWr=r(jqt,"distilbert"),jqt.forEach(t),HWr=r(MGe," \u2014 "),Vee=n(MGe,"A",{href:!0});var Dqt=s(Vee);UWr=r(Dqt,"FlaxDistilBertForTokenClassification"),Dqt.forEach(t),JWr=r(MGe," (DistilBERT model)"),MGe.forEach(t),YWr=i(To),$0=n(To,"LI",{});var EGe=s($0);w3e=n(EGe,"STRONG",{});var Gqt=s(w3e);KWr=r(Gqt,"electra"),Gqt.forEach(t),ZWr=r(EGe," \u2014 "),Xee=n(EGe,"A",{href:!0});var Oqt=s(Xee);eHr=r(Oqt,"FlaxElectraForTokenClassification"),Oqt.forEach(t),oHr=r(EGe," (ELECTRA model)"),EGe.forEach(t),rHr=i(To),k0=n(To,"LI",{});var CGe=s(k0);A3e=n(CGe,"STRONG",{});var Vqt=s(A3e);tHr=r(Vqt,"roberta"),Vqt.forEach(t),aHr=r(CGe," \u2014 "),zee=n(CGe,"A",{href:!0});var Xqt=s(zee);nHr=r(Xqt,"FlaxRobertaForTokenClassification"),Xqt.forEach(t),sHr=r(CGe," (RoBERTa model)"),CGe.forEach(t),lHr=i(To),S0=n(To,"LI",{});var wGe=s(S0);L3e=n(wGe,"STRONG",{});var zqt=s(L3e);iHr=r(zqt,"roformer"),zqt.forEach(t),dHr=r(wGe," \u2014 "),Qee=n(wGe,"A",{href:!0});var Qqt=s(Qee);cHr=r(Qqt,"FlaxRoFormerForTokenClassification"),Qqt.forEach(t),fHr=r(wGe," (RoFormer model)"),wGe.forEach(t),mHr=i(To),R0=n(To,"LI",{});var AGe=s(R0);y3e=n(AGe,"STRONG",{});var Wqt=s(y3e);gHr=r(Wqt,"xlm-roberta"),Wqt.forEach(t),hHr=r(AGe," \u2014 "),Wee=n(AGe,"A",{href:!0});var Hqt=s(Wee);pHr=r(Hqt,"FlaxXLMRobertaForTokenClassification"),Hqt.forEach(t),_Hr=r(AGe," (XLM-RoBERTa model)"),AGe.forEach(t),To.forEach(t),uHr=i(mi),T(P0.$$.fragment,mi),mi.forEach(t),fi.forEach(t),IVe=i(f),gf=n(f,"H2",{class:!0});var zze=s(gf);B0=n(zze,"A",{id:!0,class:!0,href:!0});var Uqt=s(B0);x3e=n(Uqt,"SPAN",{});var Jqt=s(x3e);T(b$.$$.fragment,Jqt),Jqt.forEach(t),Uqt.forEach(t),bHr=i(zze),$3e=n(zze,"SPAN",{});var Yqt=s($3e);vHr=r(Yqt,"FlaxAutoModelForMultipleChoice"),Yqt.forEach(t),zze.forEach(t),NVe=i(f),Mr=n(f,"DIV",{class:!0});var gi=s(Mr);T(v$.$$.fragment,gi),FHr=i(gi),hf=n(gi,"P",{});var ate=s(hf);THr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=n(ate,"A",{href:!0});var Kqt=s(Hee);MHr=r(Kqt,"from_pretrained()"),Kqt.forEach(t),EHr=r(ate," class method or the "),Uee=n(ate,"A",{href:!0});var Zqt=s(Uee);CHr=r(Zqt,"from_config()"),Zqt.forEach(t),wHr=r(ate,` class
method.`),ate.forEach(t),AHr=i(gi),F$=n(gi,"P",{});var Qze=s(F$);LHr=r(Qze,"This class cannot be instantiated directly using "),k3e=n(Qze,"CODE",{});var ejt=s(k3e);yHr=r(ejt,"__init__()"),ejt.forEach(t),xHr=r(Qze," (throws an error)."),Qze.forEach(t),$Hr=i(gi),Kt=n(gi,"DIV",{class:!0});var uL=s(Kt);T(T$.$$.fragment,uL),kHr=i(uL),S3e=n(uL,"P",{});var ojt=s(S3e);SHr=r(ojt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ojt.forEach(t),RHr=i(uL),pf=n(uL,"P",{});var nte=s(pf);PHr=r(nte,`Note:
Loading a model from its configuration file does `),R3e=n(nte,"STRONG",{});var rjt=s(R3e);BHr=r(rjt,"not"),rjt.forEach(t),IHr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(nte,"A",{href:!0});var tjt=s(Jee);NHr=r(tjt,"from_pretrained()"),tjt.forEach(t),qHr=r(nte," to load the model weights."),nte.forEach(t),jHr=i(uL),T(I0.$$.fragment,uL),uL.forEach(t),DHr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(M$.$$.fragment,hi),GHr=i(hi),P3e=n(hi,"P",{});var ajt=s(P3e);OHr=r(ajt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ajt.forEach(t),VHr=i(hi),yn=n(hi,"P",{});var bL=s(yn);XHr=r(bL,"The model class to instantiate is selected based on the "),B3e=n(bL,"CODE",{});var njt=s(B3e);zHr=r(njt,"model_type"),njt.forEach(t),QHr=r(bL,` property of the config object (either
passed as an argument or loaded from `),I3e=n(bL,"CODE",{});var sjt=s(I3e);WHr=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),HHr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N3e=n(bL,"CODE",{});var ljt=s(N3e);UHr=r(ljt,"pretrained_model_name_or_path"),ljt.forEach(t),JHr=r(bL,":"),bL.forEach(t),YHr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);N0=n(Mo,"LI",{});var LGe=s(N0);q3e=n(LGe,"STRONG",{});var ijt=s(q3e);KHr=r(ijt,"albert"),ijt.forEach(t),ZHr=r(LGe," \u2014 "),Yee=n(LGe,"A",{href:!0});var djt=s(Yee);eUr=r(djt,"FlaxAlbertForMultipleChoice"),djt.forEach(t),oUr=r(LGe," (ALBERT model)"),LGe.forEach(t),rUr=i(Mo),q0=n(Mo,"LI",{});var yGe=s(q0);j3e=n(yGe,"STRONG",{});var cjt=s(j3e);tUr=r(cjt,"bert"),cjt.forEach(t),aUr=r(yGe," \u2014 "),Kee=n(yGe,"A",{href:!0});var fjt=s(Kee);nUr=r(fjt,"FlaxBertForMultipleChoice"),fjt.forEach(t),sUr=r(yGe," (BERT model)"),yGe.forEach(t),lUr=i(Mo),j0=n(Mo,"LI",{});var xGe=s(j0);D3e=n(xGe,"STRONG",{});var mjt=s(D3e);iUr=r(mjt,"big_bird"),mjt.forEach(t),dUr=r(xGe," \u2014 "),Zee=n(xGe,"A",{href:!0});var gjt=s(Zee);cUr=r(gjt,"FlaxBigBirdForMultipleChoice"),gjt.forEach(t),fUr=r(xGe," (BigBird model)"),xGe.forEach(t),mUr=i(Mo),D0=n(Mo,"LI",{});var $Ge=s(D0);G3e=n($Ge,"STRONG",{});var hjt=s(G3e);gUr=r(hjt,"distilbert"),hjt.forEach(t),hUr=r($Ge," \u2014 "),eoe=n($Ge,"A",{href:!0});var pjt=s(eoe);pUr=r(pjt,"FlaxDistilBertForMultipleChoice"),pjt.forEach(t),_Ur=r($Ge," (DistilBERT model)"),$Ge.forEach(t),uUr=i(Mo),G0=n(Mo,"LI",{});var kGe=s(G0);O3e=n(kGe,"STRONG",{});var _jt=s(O3e);bUr=r(_jt,"electra"),_jt.forEach(t),vUr=r(kGe," \u2014 "),ooe=n(kGe,"A",{href:!0});var ujt=s(ooe);FUr=r(ujt,"FlaxElectraForMultipleChoice"),ujt.forEach(t),TUr=r(kGe," (ELECTRA model)"),kGe.forEach(t),MUr=i(Mo),O0=n(Mo,"LI",{});var SGe=s(O0);V3e=n(SGe,"STRONG",{});var bjt=s(V3e);EUr=r(bjt,"roberta"),bjt.forEach(t),CUr=r(SGe," \u2014 "),roe=n(SGe,"A",{href:!0});var vjt=s(roe);wUr=r(vjt,"FlaxRobertaForMultipleChoice"),vjt.forEach(t),AUr=r(SGe," (RoBERTa model)"),SGe.forEach(t),LUr=i(Mo),V0=n(Mo,"LI",{});var RGe=s(V0);X3e=n(RGe,"STRONG",{});var Fjt=s(X3e);yUr=r(Fjt,"roformer"),Fjt.forEach(t),xUr=r(RGe," \u2014 "),toe=n(RGe,"A",{href:!0});var Tjt=s(toe);$Ur=r(Tjt,"FlaxRoFormerForMultipleChoice"),Tjt.forEach(t),kUr=r(RGe," (RoFormer model)"),RGe.forEach(t),SUr=i(Mo),X0=n(Mo,"LI",{});var PGe=s(X0);z3e=n(PGe,"STRONG",{});var Mjt=s(z3e);RUr=r(Mjt,"xlm-roberta"),Mjt.forEach(t),PUr=r(PGe," \u2014 "),aoe=n(PGe,"A",{href:!0});var Ejt=s(aoe);BUr=r(Ejt,"FlaxXLMRobertaForMultipleChoice"),Ejt.forEach(t),IUr=r(PGe," (XLM-RoBERTa model)"),PGe.forEach(t),Mo.forEach(t),NUr=i(hi),T(z0.$$.fragment,hi),hi.forEach(t),gi.forEach(t),qVe=i(f),_f=n(f,"H2",{class:!0});var Wze=s(_f);Q0=n(Wze,"A",{id:!0,class:!0,href:!0});var Cjt=s(Q0);Q3e=n(Cjt,"SPAN",{});var wjt=s(Q3e);T(E$.$$.fragment,wjt),wjt.forEach(t),Cjt.forEach(t),qUr=i(Wze),W3e=n(Wze,"SPAN",{});var Ajt=s(W3e);jUr=r(Ajt,"FlaxAutoModelForNextSentencePrediction"),Ajt.forEach(t),Wze.forEach(t),jVe=i(f),Er=n(f,"DIV",{class:!0});var pi=s(Er);T(C$.$$.fragment,pi),DUr=i(pi),uf=n(pi,"P",{});var ste=s(uf);GUr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=n(ste,"A",{href:!0});var Ljt=s(noe);OUr=r(Ljt,"from_pretrained()"),Ljt.forEach(t),VUr=r(ste," class method or the "),soe=n(ste,"A",{href:!0});var yjt=s(soe);XUr=r(yjt,"from_config()"),yjt.forEach(t),zUr=r(ste,` class
method.`),ste.forEach(t),QUr=i(pi),w$=n(pi,"P",{});var Hze=s(w$);WUr=r(Hze,"This class cannot be instantiated directly using "),H3e=n(Hze,"CODE",{});var xjt=s(H3e);HUr=r(xjt,"__init__()"),xjt.forEach(t),UUr=r(Hze," (throws an error)."),Hze.forEach(t),JUr=i(pi),Zt=n(pi,"DIV",{class:!0});var vL=s(Zt);T(A$.$$.fragment,vL),YUr=i(vL),U3e=n(vL,"P",{});var $jt=s(U3e);KUr=r($jt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$jt.forEach(t),ZUr=i(vL),bf=n(vL,"P",{});var lte=s(bf);eJr=r(lte,`Note:
Loading a model from its configuration file does `),J3e=n(lte,"STRONG",{});var kjt=s(J3e);oJr=r(kjt,"not"),kjt.forEach(t),rJr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=n(lte,"A",{href:!0});var Sjt=s(loe);tJr=r(Sjt,"from_pretrained()"),Sjt.forEach(t),aJr=r(lte," to load the model weights."),lte.forEach(t),nJr=i(vL),T(W0.$$.fragment,vL),vL.forEach(t),sJr=i(pi),Yr=n(pi,"DIV",{class:!0});var _i=s(Yr);T(L$.$$.fragment,_i),lJr=i(_i),Y3e=n(_i,"P",{});var Rjt=s(Y3e);iJr=r(Rjt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rjt.forEach(t),dJr=i(_i),xn=n(_i,"P",{});var FL=s(xn);cJr=r(FL,"The model class to instantiate is selected based on the "),K3e=n(FL,"CODE",{});var Pjt=s(K3e);fJr=r(Pjt,"model_type"),Pjt.forEach(t),mJr=r(FL,` property of the config object (either
passed as an argument or loaded from `),Z3e=n(FL,"CODE",{});var Bjt=s(Z3e);gJr=r(Bjt,"pretrained_model_name_or_path"),Bjt.forEach(t),hJr=r(FL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e0e=n(FL,"CODE",{});var Ijt=s(e0e);pJr=r(Ijt,"pretrained_model_name_or_path"),Ijt.forEach(t),_Jr=r(FL,":"),FL.forEach(t),uJr=i(_i),o0e=n(_i,"UL",{});var Njt=s(o0e);H0=n(Njt,"LI",{});var BGe=s(H0);r0e=n(BGe,"STRONG",{});var qjt=s(r0e);bJr=r(qjt,"bert"),qjt.forEach(t),vJr=r(BGe," \u2014 "),ioe=n(BGe,"A",{href:!0});var jjt=s(ioe);FJr=r(jjt,"FlaxBertForNextSentencePrediction"),jjt.forEach(t),TJr=r(BGe," (BERT model)"),BGe.forEach(t),Njt.forEach(t),MJr=i(_i),T(U0.$$.fragment,_i),_i.forEach(t),pi.forEach(t),DVe=i(f),vf=n(f,"H2",{class:!0});var Uze=s(vf);J0=n(Uze,"A",{id:!0,class:!0,href:!0});var Djt=s(J0);t0e=n(Djt,"SPAN",{});var Gjt=s(t0e);T(y$.$$.fragment,Gjt),Gjt.forEach(t),Djt.forEach(t),EJr=i(Uze),a0e=n(Uze,"SPAN",{});var Ojt=s(a0e);CJr=r(Ojt,"FlaxAutoModelForImageClassification"),Ojt.forEach(t),Uze.forEach(t),GVe=i(f),Cr=n(f,"DIV",{class:!0});var ui=s(Cr);T(x$.$$.fragment,ui),wJr=i(ui),Ff=n(ui,"P",{});var ite=s(Ff);AJr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=n(ite,"A",{href:!0});var Vjt=s(doe);LJr=r(Vjt,"from_pretrained()"),Vjt.forEach(t),yJr=r(ite," class method or the "),coe=n(ite,"A",{href:!0});var Xjt=s(coe);xJr=r(Xjt,"from_config()"),Xjt.forEach(t),$Jr=r(ite,` class
method.`),ite.forEach(t),kJr=i(ui),$$=n(ui,"P",{});var Jze=s($$);SJr=r(Jze,"This class cannot be instantiated directly using "),n0e=n(Jze,"CODE",{});var zjt=s(n0e);RJr=r(zjt,"__init__()"),zjt.forEach(t),PJr=r(Jze," (throws an error)."),Jze.forEach(t),BJr=i(ui),ea=n(ui,"DIV",{class:!0});var TL=s(ea);T(k$.$$.fragment,TL),IJr=i(TL),s0e=n(TL,"P",{});var Qjt=s(s0e);NJr=r(Qjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Qjt.forEach(t),qJr=i(TL),Tf=n(TL,"P",{});var dte=s(Tf);jJr=r(dte,`Note:
Loading a model from its configuration file does `),l0e=n(dte,"STRONG",{});var Wjt=s(l0e);DJr=r(Wjt,"not"),Wjt.forEach(t),GJr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(dte,"A",{href:!0});var Hjt=s(foe);OJr=r(Hjt,"from_pretrained()"),Hjt.forEach(t),VJr=r(dte," to load the model weights."),dte.forEach(t),XJr=i(TL),T(Y0.$$.fragment,TL),TL.forEach(t),zJr=i(ui),Kr=n(ui,"DIV",{class:!0});var bi=s(Kr);T(S$.$$.fragment,bi),QJr=i(bi),i0e=n(bi,"P",{});var Ujt=s(i0e);WJr=r(Ujt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ujt.forEach(t),HJr=i(bi),$n=n(bi,"P",{});var ML=s($n);UJr=r(ML,"The model class to instantiate is selected based on the "),d0e=n(ML,"CODE",{});var Jjt=s(d0e);JJr=r(Jjt,"model_type"),Jjt.forEach(t),YJr=r(ML,` property of the config object (either
passed as an argument or loaded from `),c0e=n(ML,"CODE",{});var Yjt=s(c0e);KJr=r(Yjt,"pretrained_model_name_or_path"),Yjt.forEach(t),ZJr=r(ML,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f0e=n(ML,"CODE",{});var Kjt=s(f0e);eYr=r(Kjt,"pretrained_model_name_or_path"),Kjt.forEach(t),oYr=r(ML,":"),ML.forEach(t),rYr=i(bi),R$=n(bi,"UL",{});var Yze=s(R$);K0=n(Yze,"LI",{});var IGe=s(K0);m0e=n(IGe,"STRONG",{});var Zjt=s(m0e);tYr=r(Zjt,"beit"),Zjt.forEach(t),aYr=r(IGe," \u2014 "),moe=n(IGe,"A",{href:!0});var eDt=s(moe);nYr=r(eDt,"FlaxBeitForImageClassification"),eDt.forEach(t),sYr=r(IGe," (BEiT model)"),IGe.forEach(t),lYr=i(Yze),Z0=n(Yze,"LI",{});var NGe=s(Z0);g0e=n(NGe,"STRONG",{});var oDt=s(g0e);iYr=r(oDt,"vit"),oDt.forEach(t),dYr=r(NGe," \u2014 "),goe=n(NGe,"A",{href:!0});var rDt=s(goe);cYr=r(rDt,"FlaxViTForImageClassification"),rDt.forEach(t),fYr=r(NGe," (ViT model)"),NGe.forEach(t),Yze.forEach(t),mYr=i(bi),T(ew.$$.fragment,bi),bi.forEach(t),ui.forEach(t),OVe=i(f),Mf=n(f,"H2",{class:!0});var Kze=s(Mf);ow=n(Kze,"A",{id:!0,class:!0,href:!0});var tDt=s(ow);h0e=n(tDt,"SPAN",{});var aDt=s(h0e);T(P$.$$.fragment,aDt),aDt.forEach(t),tDt.forEach(t),gYr=i(Kze),p0e=n(Kze,"SPAN",{});var nDt=s(p0e);hYr=r(nDt,"FlaxAutoModelForVision2Seq"),nDt.forEach(t),Kze.forEach(t),VVe=i(f),wr=n(f,"DIV",{class:!0});var vi=s(wr);T(B$.$$.fragment,vi),pYr=i(vi),Ef=n(vi,"P",{});var cte=s(Ef);_Yr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=n(cte,"A",{href:!0});var sDt=s(hoe);uYr=r(sDt,"from_pretrained()"),sDt.forEach(t),bYr=r(cte," class method or the "),poe=n(cte,"A",{href:!0});var lDt=s(poe);vYr=r(lDt,"from_config()"),lDt.forEach(t),FYr=r(cte,` class
method.`),cte.forEach(t),TYr=i(vi),I$=n(vi,"P",{});var Zze=s(I$);MYr=r(Zze,"This class cannot be instantiated directly using "),_0e=n(Zze,"CODE",{});var iDt=s(_0e);EYr=r(iDt,"__init__()"),iDt.forEach(t),CYr=r(Zze," (throws an error)."),Zze.forEach(t),wYr=i(vi),oa=n(vi,"DIV",{class:!0});var EL=s(oa);T(N$.$$.fragment,EL),AYr=i(EL),u0e=n(EL,"P",{});var dDt=s(u0e);LYr=r(dDt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dDt.forEach(t),yYr=i(EL),Cf=n(EL,"P",{});var fte=s(Cf);xYr=r(fte,`Note:
Loading a model from its configuration file does `),b0e=n(fte,"STRONG",{});var cDt=s(b0e);$Yr=r(cDt,"not"),cDt.forEach(t),kYr=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(fte,"A",{href:!0});var fDt=s(_oe);SYr=r(fDt,"from_pretrained()"),fDt.forEach(t),RYr=r(fte," to load the model weights."),fte.forEach(t),PYr=i(EL),T(rw.$$.fragment,EL),EL.forEach(t),BYr=i(vi),Zr=n(vi,"DIV",{class:!0});var Fi=s(Zr);T(q$.$$.fragment,Fi),IYr=i(Fi),v0e=n(Fi,"P",{});var mDt=s(v0e);NYr=r(mDt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mDt.forEach(t),qYr=i(Fi),kn=n(Fi,"P",{});var CL=s(kn);jYr=r(CL,"The model class to instantiate is selected based on the "),F0e=n(CL,"CODE",{});var gDt=s(F0e);DYr=r(gDt,"model_type"),gDt.forEach(t),GYr=r(CL,` property of the config object (either
passed as an argument or loaded from `),T0e=n(CL,"CODE",{});var hDt=s(T0e);OYr=r(hDt,"pretrained_model_name_or_path"),hDt.forEach(t),VYr=r(CL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M0e=n(CL,"CODE",{});var pDt=s(M0e);XYr=r(pDt,"pretrained_model_name_or_path"),pDt.forEach(t),zYr=r(CL,":"),CL.forEach(t),QYr=i(Fi),E0e=n(Fi,"UL",{});var _Dt=s(E0e);tw=n(_Dt,"LI",{});var qGe=s(tw);C0e=n(qGe,"STRONG",{});var uDt=s(C0e);WYr=r(uDt,"vision-encoder-decoder"),uDt.forEach(t),HYr=r(qGe," \u2014 "),uoe=n(qGe,"A",{href:!0});var bDt=s(uoe);UYr=r(bDt,"FlaxVisionEncoderDecoderModel"),bDt.forEach(t),JYr=r(qGe," (Vision Encoder decoder model)"),qGe.forEach(t),_Dt.forEach(t),YYr=i(Fi),T(aw.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(COt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Rn,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertModel"),c(Sf,"id","extending-the-auto-classes"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Pf,"id","transformers.AutoConfig"),c(Pf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pf,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(iS,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(dS,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertConfig"),c(cS,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartConfig"),c(fS,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitConfig"),c(mS,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertConfig"),c(gS,"href","/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(hS,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdConfig"),c(pS,"href","/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(_S,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(uS,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(bS,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomConfig"),c(vS,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertConfig"),c(FS,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineConfig"),c(TS,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPConfig"),c(MS,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertConfig"),c(ES,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextConfig"),c(CS,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLConfig"),c(wS,"href","/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtConfig"),c(AS,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(LS,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(yS,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(xS,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaConfig"),c($S,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(kS,"href","/docs/transformers/pr_17776/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(SS,"href","/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTConfig"),c(RS,"href","/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrConfig"),c(PS,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertConfig"),c(BS,"href","/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRConfig"),c(IS,"href","/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTConfig"),c(NS,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraConfig"),c(qS,"href","/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(jS,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertConfig"),c(DS,"href","/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaConfig"),c(GS,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetConfig"),c(OS,"href","/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTConfig"),c(VS,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelConfig"),c(XS,"href","/docs/transformers/pr_17776/en/model_doc/glpn#transformers.GLPNConfig"),c(zS,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Config"),c(QS,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(WS,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(HS,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJConfig"),c(US,"href","/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertConfig"),c(JS,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertConfig"),c(YS,"href","/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(KS,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(ZS,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(eR,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(oR,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDConfig"),c(rR,"href","/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitConfig"),c(tR,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerConfig"),c(aR,"href","/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Config"),c(nR,"href","/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeConfig"),c(sR,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertConfig"),c(lR,"href","/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100Config"),c(iR,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianConfig"),c(dR,"href","/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(cR,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartConfig"),c(fR,"href","/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTConfig"),c(mR,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(gR,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(hR,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetConfig"),c(pR,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Config"),c(_R,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaConfig"),c(uR,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(bR,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(vR,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTConfig"),c(FR,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusConfig"),c(TR,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverConfig"),c(MR,"href","/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartConfig"),c(ER,"href","/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(CR,"href","/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(wR,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(AR,"href","/docs/transformers/pr_17776/en/model_doc/rag#transformers.RagConfig"),c(LR,"href","/docs/transformers/pr_17776/en/model_doc/realm#transformers.RealmConfig"),c(yR,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerConfig"),c(xR,"href","/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetConfig"),c($R,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertConfig"),c(kR,"href","/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetConfig"),c(SR,"href","/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertConfig"),c(RR,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaConfig"),c(PR,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerConfig"),c(BR,"href","/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerConfig"),c(IR,"href","/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWConfig"),c(NR,"href","/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDConfig"),c(qR,"href","/docs/transformers/pr_17776/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(jR,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(DR,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(GR,"href","/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterConfig"),c(OR,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(VR,"href","/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinConfig"),c(XR,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Config"),c(zR,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasConfig"),c(QR,"href","/docs/transformers/pr_17776/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(WR,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(HR,"href","/docs/transformers/pr_17776/en/model_doc/trocr#transformers.TrOCRConfig"),c(UR,"href","/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(JR,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(YR,"href","/docs/transformers/pr_17776/en/model_doc/van#transformers.VanConfig"),c(KR,"href","/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltConfig"),c(ZR,"href","/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(eP,"href","/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(oP,"href","/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(rP,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTConfig"),c(tP,"href","/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(aP,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(nP,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(sP,"href","/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMConfig"),c(lP,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMConfig"),c(iP,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMConfig"),c(dP,"href","/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(cP,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(fP,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(mP,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetConfig"),c(gP,"href","/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosConfig"),c(hP,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"id","transformers.AutoTokenizer"),c(Vg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(pP,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(_P,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertTokenizer"),c(uP,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(bP,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartTokenizer"),c(vP,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartTokenizerFast"),c(FP,"href","/docs/transformers/pr_17776/en/model_doc/barthez#transformers.BarthezTokenizer"),c(TP,"href","/docs/transformers/pr_17776/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(MP,"href","/docs/transformers/pr_17776/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(EP,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizer"),c(CP,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizerFast"),c(wP,"href","/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(AP,"href","/docs/transformers/pr_17776/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(LP,"href","/docs/transformers/pr_17776/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(yP,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(xP,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c($P,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(kP,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(SP,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(RP,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(PP,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(BP,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(IP,"href","/docs/transformers/pr_17776/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(NP,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertTokenizer"),c(qP,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(jP,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineTokenizer"),c(DP,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPTokenizer"),c(GP,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(OP,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(VP,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(XP,"href","/docs/transformers/pr_17776/en/model_doc/cpm#transformers.CpmTokenizer"),c(zP,"href","/docs/transformers/pr_17776/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(QP,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(WP,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HP,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UP,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaTokenizer"),c(JP,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(YP,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(KP,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(ZP,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(eB,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(rB,"href","/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(tB,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraTokenizer"),c(aB,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(nB,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(sB,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetTokenizer"),c(lB,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(iB,"href","/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(dB,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelTokenizer"),c(cB,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(fB,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mB,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(gB,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(hB,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(pB,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(_B,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(uB,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(bB,"href","/docs/transformers/pr_17776/en/model_doc/herbert#transformers.HerbertTokenizer"),c(vB,"href","/docs/transformers/pr_17776/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TB,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MB,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(EB,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(CB,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(wB,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(AB,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(LB,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(yB,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(xB,"href","/docs/transformers/pr_17776/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c($B,"href","/docs/transformers/pr_17776/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(kB,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDTokenizer"),c(SB,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDTokenizerFast"),c(RB,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerTokenizer"),c(PB,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(BB,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Tokenizer"),c(IB,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5TokenizerFast"),c(NB,"href","/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeTokenizer"),c(qB,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(jB,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(DB,"href","/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(GB,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianTokenizer"),c(OB,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartTokenizer"),c(VB,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(XB,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(zB,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(QB,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizer"),c(WB,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizerFast"),c(HB,"href","/docs/transformers/pr_17776/en/model_doc/mluke#transformers.MLukeTokenizer"),c(UB,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(JB,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(YB,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(KB,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(ZB,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Tokenizer"),c(eI,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5TokenizerFast"),c(oI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizer"),c(rI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizerFast"),c(tI,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertTokenizer"),c(aI,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nI,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(sI,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(lI,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iI,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(dI,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(cI,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(fI,"href","/docs/transformers/pr_17776/en/model_doc/phobert#transformers.PhobertTokenizer"),c(mI,"href","/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartTokenizer"),c(gI,"href","/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(hI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizer"),c(pI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizerFast"),c(_I,"href","/docs/transformers/pr_17776/en/model_doc/rag#transformers.RagTokenizer"),c(uI,"href","/docs/transformers/pr_17776/en/model_doc/realm#transformers.RealmTokenizer"),c(bI,"href","/docs/transformers/pr_17776/en/model_doc/realm#transformers.RealmTokenizerFast"),c(vI,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerTokenizer"),c(FI,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(TI,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertTokenizer"),c(MI,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(EI,"href","/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(CI,"href","/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(wI,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AI,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LI,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(yI,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(xI,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c($I,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(kI,"href","/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterTokenizer"),c(SI,"href","/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(RI,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(PI,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(BI,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Tokenizer"),c(II,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5TokenizerFast"),c(NI,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasTokenizer"),c(qI,"href","/docs/transformers/pr_17776/en/model_doc/tapex#transformers.TapexTokenizer"),c(jI,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(DI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizer"),c(GI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizerFast"),c(OI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizer"),c(VI,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertTokenizerFast"),c(XI,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(zI,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(QI,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(WI,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMTokenizer"),c(HI,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(UI,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMTokenizer"),c(JI,"href","/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(YI,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(KI,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(ZI,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizer"),c(eN,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(oN,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(rN,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(tN,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertTokenizer"),c(aN,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wh,"id","transformers.AutoFeatureExtractor"),c(wh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(nN,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(sN,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dN,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fN,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(mN,"href","/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(hN,"href","/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(pN,"href","/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(_N,"href","/docs/transformers/pr_17776/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(uN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bN,"href","/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(FN,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(TN,"href","/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(MN,"href","/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(CN,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wN,"href","/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yN,"href","/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($N,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(RN,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PN,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(NN,"href","/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"id","transformers.AutoProcessor"),c(lp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lp,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(qN,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jN,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPProcessor"),c(DN,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(GN,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(ON,"href","/docs/transformers/pr_17776/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(VN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(XN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zN,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(QN,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(WN,"href","/docs/transformers/pr_17776/en/model_doc/trocr#transformers.TrOCRProcessor"),c(HN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(JN,"href","/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltProcessor"),c(YN,"href","/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(KN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZN,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eq,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yp,"id","transformers.AutoModel"),c(yp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yp,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(oq,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rq,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tq,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aq,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertModel"),c(nq,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartModel"),c(sq,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitModel"),c(lq,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertModel"),c(iq,"href","/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dq,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdModel"),c(cq,"href","/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(fq,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(mq,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gq,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomModel"),c(hq,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertModel"),c(pq,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineModel"),c(_q,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.CLIPModel"),c(uq,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertModel"),c(bq,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextModel"),c(vq,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLModel"),c(Fq,"href","/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtModel"),c(Tq,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Mq,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Eq,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Cq,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaModel"),c(wq,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Aq,"href","/docs/transformers/pr_17776/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Lq,"href","/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTModel"),c(yq,"href","/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrModel"),c(xq,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertModel"),c($q,"href","/docs/transformers/pr_17776/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(kq,"href","/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTModel"),c(Sq,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraModel"),c(Rq,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertModel"),c(Pq,"href","/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaModel"),c(Bq,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetModel"),c(Iq,"href","/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTModel"),c(Nq,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelModel"),c(qq,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelBaseModel"),c(jq,"href","/docs/transformers/pr_17776/en/model_doc/glpn#transformers.GLPNModel"),c(Dq,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2Model"),c(Gq,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Oq,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Vq,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJModel"),c(Xq,"href","/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertModel"),c(zq,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertModel"),c(Qq,"href","/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Wq,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Hq,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Uq,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Jq,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDModel"),c(Yq,"href","/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitModel"),c(Kq,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerModel"),c(Zq,"href","/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5Model"),c(ej,"href","/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeModel"),c(oj,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertModel"),c(rj,"href","/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100Model"),c(tj,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianModel"),c(aj,"href","/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerModel"),c(nj,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartModel"),c(sj,"href","/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTModel"),c(lj,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ij,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertModel"),c(dj,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetModel"),c(cj,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5Model"),c(fj,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaModel"),c(mj,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerModel"),c(gj,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(hj,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTModel"),c(pj,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusModel"),c(_j,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverModel"),c(uj,"href","/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartModel"),c(bj,"href","/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerModel"),c(vj,"href","/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Fj,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Tj,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerModel"),c(Mj,"href","/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetModel"),c(Ej,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertModel"),c(Cj,"href","/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetModel"),c(wj,"href","/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertModel"),c(Aj,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaModel"),c(Lj,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerModel"),c(yj,"href","/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerModel"),c(xj,"href","/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWModel"),c($j,"href","/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDModel"),c(kj,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Sj,"href","/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterModel"),c(Rj,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Pj,"href","/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinModel"),c(Bj,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5Model"),c(Ij,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasModel"),c(Nj,"href","/docs/transformers/pr_17776/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(qj,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(jj,"href","/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Dj,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Gj,"href","/docs/transformers/pr_17776/en/model_doc/van#transformers.VanModel"),c(Oj,"href","/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltModel"),c(Vj,"href","/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Xj,"href","/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertModel"),c(zj,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTModel"),c(Qj,"href","/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Wj,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Hj,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Uj,"href","/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMModel"),c(Jj,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMModel"),c(Yj,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMModel"),c(Kj,"href","/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Zj,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(eD,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(oD,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetModel"),c(rD,"href","/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosModel"),c(tD,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoModelForPreTraining"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(aD,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nD,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sD,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lD,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForPreTraining"),c(iD,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(dD,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForPreTraining"),c(cD,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(fD,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForCausalLM"),c(mD,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(gD,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hD,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(pD,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(_D,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(uD,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForPreTraining"),c(vD,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(FD,"href","/docs/transformers/pr_17776/en/model_doc/flava#transformers.FlavaForPreTraining"),c(TD,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForPreTraining"),c(MD,"href","/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(CD,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wD,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(AD,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(LD,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(yD,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xD,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($D,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kD,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SD,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(RD,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(PD,"href","/docs/transformers/pr_17776/en/model_doc/retribert#transformers.RetriBertModel"),c(BD,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(ID,"href","/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(ND,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(qD,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(jD,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(DD,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(GD,"href","/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(OD,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(VD,"href","/docs/transformers/pr_17776/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(XD,"href","/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(zD,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(QD,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(WD,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HD,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(UD,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(JD,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C7,"id","transformers.AutoModelForCausalLM"),c(C7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C7,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(YD,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForCausalLM"),c(oG,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertLMHeadModel"),c(rG,"href","/docs/transformers/pr_17776/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(tG,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(aG,"href","/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(nG,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(sG,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(lG,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForCausalLM"),c(iG,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(dG,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(cG,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(fG,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForCausalLM"),c(mG,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(gG,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(hG,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(pG,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(_G,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianForCausalLM"),c(uG,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bG,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(vG,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FG,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.OPTForCausalLM"),c(TG,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(MG,"href","/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(EG,"href","/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(CG,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(wG,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(AG,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(LG,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(yG,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(xG,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c($G,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(kG,"href","/docs/transformers/pr_17776/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(SG,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(RG,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PG,"href","/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(BG,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(IG,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(NG,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m1,"id","transformers.AutoModelForMaskedLM"),c(m1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m1,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(qG,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jG,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DG,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GG,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(OG,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(VG,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForMaskedLM"),c(XG,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(zG,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(WG,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(HG,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(UG,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(JG,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(YG,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(KG,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(ZG,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(eO,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(oO,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(rO,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(tO,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(aO,"href","/docs/transformers/pr_17776/en/model_doc/luke#transformers.LukeForMaskedLM"),c(nO,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(sO,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(lO,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(iO,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(dO,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(cO,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(fO,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(mO,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(gO,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(hO,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(pO,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(_O,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(uO,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(bO,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(vO,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FO,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TO,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MO,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z1,"id","transformers.AutoModelForSeq2SeqLM"),c(Z1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(EO,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CO,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wO,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AO,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(LO,"href","/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(xO,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c($O,"href","/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(kO,"href","/docs/transformers/pr_17776/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17776/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(PO,"href","/docs/transformers/pr_17776/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(BO,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.MarianMTModel"),c(IO,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(NO,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(qO,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(jO,"href","/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(DO,"href","/docs/transformers/pr_17776/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(GO,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_17776/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F2,"id","transformers.AutoModelForSequenceClassification"),c(F2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F2,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(VO,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XO,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zO,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17776/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c($V,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vb,"id","transformers.AutoModelForMultipleChoice"),c(vb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vb,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(GV,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(zV,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForMultipleChoice"),c(QV,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(WV,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(HV,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(iX,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(dX,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(cX,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(fX,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(mX,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(gX,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(hX,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(pX,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(_X,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(uX,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zb,"id","transformers.AutoModelForNextSentencePrediction"),c(Zb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zb,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(FX,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(CX,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(wX,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(AX,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(LX,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(yX,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dv,"id","transformers.AutoModelForTokenClassification"),c(dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dv,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(xX,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(RX,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForTokenClassification"),c(PX,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(BX,"href","/docs/transformers/pr_17776/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(IX,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(NX,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForTokenClassification"),c(qX,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(jX,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(DX,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(GX,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(OX,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(VX,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(XX,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(zX,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(QX,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(WX,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(HX,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(UX,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(JX,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(YX,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(KX,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(ez,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(oz,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(rz,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(tz,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(az,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(nz,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(sz,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(lz,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(iz,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(dz,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(cz,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(fz,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(mz,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(gz,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uv,"id","transformers.AutoModelForQuestionAnswering"),c(Uv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uv,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(hz,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pz,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_z,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uz,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17776/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Mz,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17776/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(kz,"href","/docs/transformers/pr_17776/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17776/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Bz,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17776/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(jz,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17776/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Oz,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Vz,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Xz,"href","/docs/transformers/pr_17776/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17776/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17776/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17776/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17776/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17776/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(eQ,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(oQ,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(rQ,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(tQ,"href","/docs/transformers/pr_17776/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForTableQuestionAnswering"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fd,"class","relative group"),c(aQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lQ,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zF,"id","transformers.AutoModelForImageClassification"),c(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zF,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitForImageClassification"),c(mQ,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gQ,"href","/docs/transformers/pr_17776/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hQ,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(pQ,"href","/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTForImageClassification"),c(_Q,"href","/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(uQ,"href","/docs/transformers/pr_17776/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bQ,"href","/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitForImageClassification"),c(vQ,"href","/docs/transformers/pr_17776/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FQ,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(TQ,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(MQ,"href","/docs/transformers/pr_17776/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(EQ,"href","/docs/transformers/pr_17776/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(CQ,"href","/docs/transformers/pr_17776/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(wQ,"href","/docs/transformers/pr_17776/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(AQ,"href","/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(LQ,"href","/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinForImageClassification"),c(yQ,"href","/docs/transformers/pr_17776/en/model_doc/van#transformers.VanForImageClassification"),c(xQ,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l6,"id","transformers.AutoModelForVision2Seq"),c(l6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l6,"href","#transformers.AutoModelForVision2Seq"),c(ud,"class","relative group"),c($Q,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m6,"id","transformers.AutoModelForVisualQuestionAnswering"),c(m6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m6,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NQ,"href","/docs/transformers/pr_17776/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u6,"id","transformers.AutoModelForAudioClassification"),c(u6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u6,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(qQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(OQ,"href","/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(VQ,"href","/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(XQ,"href","/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(zQ,"href","/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(QQ,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(WQ,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(HQ,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UQ,"href","/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($6,"id","transformers.AutoModelForAudioFrameClassification"),c($6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($6,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(JQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KQ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZQ,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(eW,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(oW,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(rW,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(tW,"href","/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j6,"id","transformers.AutoModelForCTC"),c(j6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j6,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(aW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(iW,"href","/docs/transformers/pr_17776/en/model_doc/hubert#transformers.HubertForCTC"),c(dW,"href","/docs/transformers/pr_17776/en/model_doc/mctct#transformers.MCTCTForCTC"),c(cW,"href","/docs/transformers/pr_17776/en/model_doc/sew#transformers.SEWForCTC"),c(fW,"href","/docs/transformers/pr_17776/en/model_doc/sew-d#transformers.SEWDForCTC"),c(mW,"href","/docs/transformers/pr_17776/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(gW,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(hW,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(pW,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(_W,"href","/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z6,"id","transformers.AutoModelForSpeechSeq2Seq"),c(Z6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z6,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(uW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FW,"href","/docs/transformers/pr_17776/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(TW,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nT,"id","transformers.AutoModelForAudioXVector"),c(nT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nT,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(MW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(AW,"href","/docs/transformers/pr_17776/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(LW,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(yW,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(xW,"href","/docs/transformers/pr_17776/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hT,"id","transformers.AutoModelForMaskedImageModeling"),c(hT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hT,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c($W,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/pr_17776/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(PW,"href","/docs/transformers/pr_17776/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(BW,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TT,"id","transformers.AutoModelForObjectDetection"),c(TT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TT,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(IW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DW,"href","/docs/transformers/pr_17776/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LT,"id","transformers.AutoModelForImageSegmentation"),c(LT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LT,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(GW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_17776/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ST,"id","transformers.AutoModelForSemanticSegmentation"),c(ST,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ST,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(zW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HW,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(UW,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JW,"href","/docs/transformers/pr_17776/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YW,"href","/docs/transformers/pr_17776/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.AutoModelForInstanceSegmentation"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(KW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZW,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/pr_17776/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zT,"id","transformers.TFAutoModel"),c(zT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zT,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(rH,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertModel"),c(sH,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.TFBartModel"),c(lH,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertModel"),c(iH,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(dH,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(cH,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertModel"),c(fH,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.TFCLIPModel"),c(mH,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertModel"),c(gH,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.TFConvNextModel"),c(hH,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pH,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_H,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaModel"),c(uH,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bH,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(vH,"href","/docs/transformers/pr_17776/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(FH,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraModel"),c(TH,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(MH,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelModel"),c(EH,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(CH,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2Model"),c(wH,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJModel"),c(AH,"href","/docs/transformers/pr_17776/en/model_doc/hubert#transformers.TFHubertModel"),c(LH,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(yH,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.TFLEDModel"),c(xH,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerModel"),c($H,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.TFLxmertModel"),c(kH,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.TFMarianModel"),c(SH,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.TFMBartModel"),c(RH,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(PH,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetModel"),c(BH,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.TFMT5Model"),c(IH,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(NH,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.TFOPTModel"),c(qH,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.TFPegasusModel"),c(jH,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertModel"),c(DH,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaModel"),c(GH,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerModel"),c(OH,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(VH,"href","/docs/transformers/pr_17776/en/model_doc/swin#transformers.TFSwinModel"),c(XH,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.TFT5Model"),c(zH,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasModel"),c(QH,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(WH,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.TFViTModel"),c(HH,"href","/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(UH,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(JH,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMModel"),c(YH,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(KH,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DM,"id","transformers.TFAutoModelForPreTraining"),c(DM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DM,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(ZH,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rU,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(tU,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(aU,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForPreTraining"),c(nU,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(sU,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(lU,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iU,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(dU,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cU,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(fU,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(mU,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(gU,"href","/docs/transformers/pr_17776/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(hU,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(pU,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(_U,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(uU,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(bU,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(vU,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(FU,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TU,"href","/docs/transformers/pr_17776/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(MU,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(EU,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(CU,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mE,"id","transformers.TFAutoModelForCausalLM"),c(mE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mE,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(wU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(xU,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c($U,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(kU,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(SU,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(RU,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(PU,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(BU,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(IU,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(NU,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(qU,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(jU,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(DU,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yE,"id","transformers.TFAutoModelForImageClassification"),c(yE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yE,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17776/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(zU,"href","/docs/transformers/pr_17776/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(QU,"href","/docs/transformers/pr_17776/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(WU,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BE,"id","transformers.TFAutoModelForMaskedLM"),c(BE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BE,"href","#transformers.TFAutoModelForMaskedLM"),c(mc,"class","relative group"),c(HU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JU,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YU,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(KU,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(oJ,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(tJ,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(aJ,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(nJ,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(sJ,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(lJ,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(iJ,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(dJ,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(cJ,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(fJ,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(mJ,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(gJ,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(hJ,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(pJ,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(_J,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a4,"id","transformers.TFAutoModelForSeq2SeqLM"),c(a4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(a4,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(pc,"class","relative group"),c(uJ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(TJ,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(MJ,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(EJ,"href","/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(CJ,"href","/docs/transformers/pr_17776/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(wJ,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.TFMarianMTModel"),c(AJ,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(LJ,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(yJ,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(xJ,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u4,"id","transformers.TFAutoModelForSequenceClassification"),c(u4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u4,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c($J,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(PJ,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(BJ,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(IJ,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(NJ,"href","/docs/transformers/pr_17776/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(zJ,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(UJ,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(JJ,"href","/docs/transformers/pr_17776/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(YJ,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(KJ,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(ZJ,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(eY,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(oY,"href","/docs/transformers/pr_17776/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(rY,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(tY,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(aY,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q4,"id","transformers.TFAutoModelForMultipleChoice"),c(Q4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q4,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(nY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iY,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(dY,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(cY,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(fY,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(mY,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(gY,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(hY,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(pY,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(_Y,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(uY,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(bY,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(vY,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(FY,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(TY,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(MY,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(EY,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(CY,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mC,"id","transformers.TFAutoModelForNextSentencePrediction"),c(mC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mC,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(wY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(xY,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uC,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c($Y,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RY,"href","/docs/transformers/pr_17776/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TC,"id","transformers.TFAutoModelForTokenClassification"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(PY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(qY,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(jY,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(DY,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(GY,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(OY,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(VY,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(XY,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(zY,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(QY,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(WY,"href","/docs/transformers/pr_17776/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(HY,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(UY,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(JY,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(YY,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(KY,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(ZY,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(eK,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(oK,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(rK,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XC,"id","transformers.TFAutoModelForQuestionAnswering"),c(XC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(tK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(lK,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(iK,"href","/docs/transformers/pr_17776/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(dK,"href","/docs/transformers/pr_17776/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(cK,"href","/docs/transformers/pr_17776/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17776/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(mK,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(gK,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(hK,"href","/docs/transformers/pr_17776/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(pK,"href","/docs/transformers/pr_17776/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(_K,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(uK,"href","/docs/transformers/pr_17776/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(bK,"href","/docs/transformers/pr_17776/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(vK,"href","/docs/transformers/pr_17776/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(FK,"href","/docs/transformers/pr_17776/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(TK,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(MK,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(EK,"href","/docs/transformers/pr_17776/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(CK,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(wK,"href","/docs/transformers/pr_17776/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g5,"id","transformers.TFAutoModelForVision2Seq"),c(g5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g5,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c(AK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(u5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c($K,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17776/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T5,"id","transformers.FlaxAutoModel"),c(T5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T5,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertModel"),c(qK,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartModel"),c(jK,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.FlaxBeitModel"),c(DK,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertModel"),c(GK,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(OK,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(VK,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(XK,"href","/docs/transformers/pr_17776/en/model_doc/clip#transformers.FlaxCLIPModel"),c(zK,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(QK,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraModel"),c(WK,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(HK,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(UK,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(JK,"href","/docs/transformers/pr_17776/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(YK,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.FlaxMarianModel"),c(KK,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartModel"),c(ZK,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.FlaxMT5Model"),c(eZ,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.FlaxOPTModel"),c(oZ,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(rZ,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(tZ,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(aZ,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.FlaxT5Model"),c(nZ,"href","/docs/transformers/pr_17776/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(sZ,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.FlaxViTModel"),c(lZ,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(iZ,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(dZ,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y5,"id","transformers.FlaxAutoModelForCausalLM"),c(Y5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y5,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(cZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gZ,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(hZ,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(pZ,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(_Z,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(uZ,"href","/docs/transformers/pr_17776/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(bZ,"href","/docs/transformers/pr_17776/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(vZ,"href","/docs/transformers/pr_17776/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(FZ,"href","/docs/transformers/pr_17776/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(TZ,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(MZ,"href","/docs/transformers/pr_17776/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c3,"id","transformers.FlaxAutoModelForPreTraining"),c(c3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c3,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(EZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AZ,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(LZ,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(yZ,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(xZ,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c($Z,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(kZ,"href","/docs/transformers/pr_17776/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(SZ,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(RZ,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(PZ,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(BZ,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(IZ,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(NZ,"href","/docs/transformers/pr_17776/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(qZ,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A3,"id","transformers.FlaxAutoModelForMaskedLM"),c(A3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A3,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(jZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OZ,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(VZ,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(XZ,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(zZ,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(QZ,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(WZ,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(HZ,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(UZ,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(JZ,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(YZ,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j3,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(j3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j3,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(ef,"class","relative group"),c(KZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZZ,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oee,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ree,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(tee,"href","/docs/transformers/pr_17776/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(aee,"href","/docs/transformers/pr_17776/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(nee,"href","/docs/transformers/pr_17776/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(see,"href","/docs/transformers/pr_17776/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(lee,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(iee,"href","/docs/transformers/pr_17776/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(dee,"href","/docs/transformers/pr_17776/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17776/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(K3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tf,"class","relative group"),c(fee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(pee,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(_ee,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(uee,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(bee,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(vee,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Fee,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Tee,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Mee,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Eee,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f0,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(f0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f0,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sf,"class","relative group"),c(Cee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lee,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(yee,"href","/docs/transformers/pr_17776/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(xee,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c($ee,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(kee,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(See,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Ree,"href","/docs/transformers/pr_17776/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Pee,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Bee,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Iee,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C0,"id","transformers.FlaxAutoModelForTokenClassification"),c(C0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C0,"href","#transformers.FlaxAutoModelForTokenClassification"),c(cf,"class","relative group"),c(Nee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dee,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Gee,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Oee,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Vee,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Xee,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(zee,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Qee,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Wee,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B0,"id","transformers.FlaxAutoModelForMultipleChoice"),c(B0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B0,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Hee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jee,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yee,"href","/docs/transformers/pr_17776/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Kee,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Zee,"href","/docs/transformers/pr_17776/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(eoe,"href","/docs/transformers/pr_17776/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(ooe,"href","/docs/transformers/pr_17776/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(roe,"href","/docs/transformers/pr_17776/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(toe,"href","/docs/transformers/pr_17776/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(aoe,"href","/docs/transformers/pr_17776/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q0,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Q0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q0,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(_f,"class","relative group"),c(noe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(soe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(loe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ioe,"href","/docs/transformers/pr_17776/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J0,"id","transformers.FlaxAutoModelForImageClassification"),c(J0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J0,"href","#transformers.FlaxAutoModelForImageClassification"),c(vf,"class","relative group"),c(doe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/pr_17776/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(goe,"href","/docs/transformers/pr_17776/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ow,"id","transformers.FlaxAutoModelForVision2Seq"),c(ow,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ow,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Mf,"class","relative group"),c(hoe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/pr_17776/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uoe,"href","/docs/transformers/pr_17776/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ti),b(f,yf,u),b(f,at,u),e(at,Mi),e(at,Ei),e(Ei,wL),e(at,xf),b(f,Oe,u),b(f,Qe,u),e(Qe,Ci),e(Qe,Rn),e(Rn,AL),e(Qe,Pn),e(Qe,Bn),e(Bn,LL),e(Qe,wi),e(Qe,In),e(In,yL),e(Qe,Ai),b(f,$f,u),M(xa,f,u),b(f,We,u),b(f,Ae,u),e(Ae,rS),e(Ae,Li),e(Li,tS),e(Ae,aS),b(f,Co,u),b(f,$a,u),e($a,nS),e($a,kf),e(kf,sS),e($a,eQe),b(f,jGe,u),b(f,yi,u),e(yi,Sf),e(Sf,mte),M(xL,mte,null),e(yi,oQe),e(yi,gte),e(gte,rQe),b(f,DGe,u),b(f,Nn,u),e(Nn,tQe),e(Nn,hte),e(hte,aQe),e(Nn,nQe),e(Nn,pte),e(pte,sQe),e(Nn,lQe),b(f,GGe,u),M($L,f,u),b(f,OGe,u),b(f,lS,u),e(lS,iQe),b(f,VGe,u),M(Rf,f,u),b(f,XGe,u),b(f,xi,u),e(xi,Pf),e(Pf,_te),M(kL,_te,null),e(xi,dQe),e(xi,ute),e(ute,cQe),b(f,zGe,u),b(f,wo,u),M(SL,wo,null),e(wo,fQe),e(wo,RL),e(RL,mQe),e(RL,iS),e(iS,gQe),e(RL,hQe),e(wo,pQe),e(wo,PL),e(PL,_Qe),e(PL,bte),e(bte,uQe),e(PL,bQe),e(wo,vQe),e(wo,Ar),M(BL,Ar,null),e(Ar,FQe),e(Ar,vte),e(vte,TQe),e(Ar,MQe),e(Ar,$i),e($i,EQe),e($i,Fte),e(Fte,CQe),e($i,wQe),e($i,Tte),e(Tte,AQe),e($i,LQe),e(Ar,yQe),e(Ar,A),e(A,Bf),e(Bf,Mte),e(Mte,xQe),e(Bf,$Qe),e(Bf,dS),e(dS,kQe),e(Bf,SQe),e(A,RQe),e(A,If),e(If,Ete),e(Ete,PQe),e(If,BQe),e(If,cS),e(cS,IQe),e(If,NQe),e(A,qQe),e(A,Nf),e(Nf,Cte),e(Cte,jQe),e(Nf,DQe),e(Nf,fS),e(fS,GQe),e(Nf,OQe),e(A,VQe),e(A,qf),e(qf,wte),e(wte,XQe),e(qf,zQe),e(qf,mS),e(mS,QQe),e(qf,WQe),e(A,HQe),e(A,jf),e(jf,Ate),e(Ate,UQe),e(jf,JQe),e(jf,gS),e(gS,YQe),e(jf,KQe),e(A,ZQe),e(A,Df),e(Df,Lte),e(Lte,eWe),e(Df,oWe),e(Df,hS),e(hS,rWe),e(Df,tWe),e(A,aWe),e(A,Gf),e(Gf,yte),e(yte,nWe),e(Gf,sWe),e(Gf,pS),e(pS,lWe),e(Gf,iWe),e(A,dWe),e(A,Of),e(Of,xte),e(xte,cWe),e(Of,fWe),e(Of,_S),e(_S,mWe),e(Of,gWe),e(A,hWe),e(A,Vf),e(Vf,$te),e($te,pWe),e(Vf,_We),e(Vf,uS),e(uS,uWe),e(Vf,bWe),e(A,vWe),e(A,Xf),e(Xf,kte),e(kte,FWe),e(Xf,TWe),e(Xf,bS),e(bS,MWe),e(Xf,EWe),e(A,CWe),e(A,zf),e(zf,Ste),e(Ste,wWe),e(zf,AWe),e(zf,vS),e(vS,LWe),e(zf,yWe),e(A,xWe),e(A,Qf),e(Qf,Rte),e(Rte,$We),e(Qf,kWe),e(Qf,FS),e(FS,SWe),e(Qf,RWe),e(A,PWe),e(A,Wf),e(Wf,Pte),e(Pte,BWe),e(Wf,IWe),e(Wf,TS),e(TS,NWe),e(Wf,qWe),e(A,jWe),e(A,Hf),e(Hf,Bte),e(Bte,DWe),e(Hf,GWe),e(Hf,MS),e(MS,OWe),e(Hf,VWe),e(A,XWe),e(A,Uf),e(Uf,Ite),e(Ite,zWe),e(Uf,QWe),e(Uf,ES),e(ES,WWe),e(Uf,HWe),e(A,UWe),e(A,Jf),e(Jf,Nte),e(Nte,JWe),e(Jf,YWe),e(Jf,CS),e(CS,KWe),e(Jf,ZWe),e(A,eHe),e(A,Yf),e(Yf,qte),e(qte,oHe),e(Yf,rHe),e(Yf,wS),e(wS,tHe),e(Yf,aHe),e(A,nHe),e(A,Kf),e(Kf,jte),e(jte,sHe),e(Kf,lHe),e(Kf,AS),e(AS,iHe),e(Kf,dHe),e(A,cHe),e(A,Zf),e(Zf,Dte),e(Dte,fHe),e(Zf,mHe),e(Zf,LS),e(LS,gHe),e(Zf,hHe),e(A,pHe),e(A,em),e(em,Gte),e(Gte,_He),e(em,uHe),e(em,yS),e(yS,bHe),e(em,vHe),e(A,FHe),e(A,om),e(om,Ote),e(Ote,THe),e(om,MHe),e(om,xS),e(xS,EHe),e(om,CHe),e(A,wHe),e(A,rm),e(rm,Vte),e(Vte,AHe),e(rm,LHe),e(rm,$S),e($S,yHe),e(rm,xHe),e(A,$He),e(A,tm),e(tm,Xte),e(Xte,kHe),e(tm,SHe),e(tm,kS),e(kS,RHe),e(tm,PHe),e(A,BHe),e(A,am),e(am,zte),e(zte,IHe),e(am,NHe),e(am,SS),e(SS,qHe),e(am,jHe),e(A,DHe),e(A,nm),e(nm,Qte),e(Qte,GHe),e(nm,OHe),e(nm,RS),e(RS,VHe),e(nm,XHe),e(A,zHe),e(A,sm),e(sm,Wte),e(Wte,QHe),e(sm,WHe),e(sm,PS),e(PS,HHe),e(sm,UHe),e(A,JHe),e(A,lm),e(lm,Hte),e(Hte,YHe),e(lm,KHe),e(lm,BS),e(BS,ZHe),e(lm,eUe),e(A,oUe),e(A,im),e(im,Ute),e(Ute,rUe),e(im,tUe),e(im,IS),e(IS,aUe),e(im,nUe),e(A,sUe),e(A,dm),e(dm,Jte),e(Jte,lUe),e(dm,iUe),e(dm,NS),e(NS,dUe),e(dm,cUe),e(A,fUe),e(A,cm),e(cm,Yte),e(Yte,mUe),e(cm,gUe),e(cm,qS),e(qS,hUe),e(cm,pUe),e(A,_Ue),e(A,fm),e(fm,Kte),e(Kte,uUe),e(fm,bUe),e(fm,jS),e(jS,vUe),e(fm,FUe),e(A,TUe),e(A,mm),e(mm,Zte),e(Zte,MUe),e(mm,EUe),e(mm,DS),e(DS,CUe),e(mm,wUe),e(A,AUe),e(A,gm),e(gm,eae),e(eae,LUe),e(gm,yUe),e(gm,GS),e(GS,xUe),e(gm,$Ue),e(A,kUe),e(A,hm),e(hm,oae),e(oae,SUe),e(hm,RUe),e(hm,OS),e(OS,PUe),e(hm,BUe),e(A,IUe),e(A,pm),e(pm,rae),e(rae,NUe),e(pm,qUe),e(pm,VS),e(VS,jUe),e(pm,DUe),e(A,GUe),e(A,_m),e(_m,tae),e(tae,OUe),e(_m,VUe),e(_m,XS),e(XS,XUe),e(_m,zUe),e(A,QUe),e(A,um),e(um,aae),e(aae,WUe),e(um,HUe),e(um,zS),e(zS,UUe),e(um,JUe),e(A,YUe),e(A,bm),e(bm,nae),e(nae,KUe),e(bm,ZUe),e(bm,QS),e(QS,eJe),e(bm,oJe),e(A,rJe),e(A,vm),e(vm,sae),e(sae,tJe),e(vm,aJe),e(vm,WS),e(WS,nJe),e(vm,sJe),e(A,lJe),e(A,Fm),e(Fm,lae),e(lae,iJe),e(Fm,dJe),e(Fm,HS),e(HS,cJe),e(Fm,fJe),e(A,mJe),e(A,Tm),e(Tm,iae),e(iae,gJe),e(Tm,hJe),e(Tm,US),e(US,pJe),e(Tm,_Je),e(A,uJe),e(A,Mm),e(Mm,dae),e(dae,bJe),e(Mm,vJe),e(Mm,JS),e(JS,FJe),e(Mm,TJe),e(A,MJe),e(A,Em),e(Em,cae),e(cae,EJe),e(Em,CJe),e(Em,YS),e(YS,wJe),e(Em,AJe),e(A,LJe),e(A,Cm),e(Cm,fae),e(fae,yJe),e(Cm,xJe),e(Cm,KS),e(KS,$Je),e(Cm,kJe),e(A,SJe),e(A,wm),e(wm,mae),e(mae,RJe),e(wm,PJe),e(wm,ZS),e(ZS,BJe),e(wm,IJe),e(A,NJe),e(A,Am),e(Am,gae),e(gae,qJe),e(Am,jJe),e(Am,eR),e(eR,DJe),e(Am,GJe),e(A,OJe),e(A,Lm),e(Lm,hae),e(hae,VJe),e(Lm,XJe),e(Lm,oR),e(oR,zJe),e(Lm,QJe),e(A,WJe),e(A,ym),e(ym,pae),e(pae,HJe),e(ym,UJe),e(ym,rR),e(rR,JJe),e(ym,YJe),e(A,KJe),e(A,xm),e(xm,_ae),e(_ae,ZJe),e(xm,eYe),e(xm,tR),e(tR,oYe),e(xm,rYe),e(A,tYe),e(A,$m),e($m,uae),e(uae,aYe),e($m,nYe),e($m,aR),e(aR,sYe),e($m,lYe),e(A,iYe),e(A,km),e(km,bae),e(bae,dYe),e(km,cYe),e(km,nR),e(nR,fYe),e(km,mYe),e(A,gYe),e(A,Sm),e(Sm,vae),e(vae,hYe),e(Sm,pYe),e(Sm,sR),e(sR,_Ye),e(Sm,uYe),e(A,bYe),e(A,Rm),e(Rm,Fae),e(Fae,vYe),e(Rm,FYe),e(Rm,lR),e(lR,TYe),e(Rm,MYe),e(A,EYe),e(A,Pm),e(Pm,Tae),e(Tae,CYe),e(Pm,wYe),e(Pm,iR),e(iR,AYe),e(Pm,LYe),e(A,yYe),e(A,Bm),e(Bm,Mae),e(Mae,xYe),e(Bm,$Ye),e(Bm,dR),e(dR,kYe),e(Bm,SYe),e(A,RYe),e(A,Im),e(Im,Eae),e(Eae,PYe),e(Im,BYe),e(Im,cR),e(cR,IYe),e(Im,NYe),e(A,qYe),e(A,Nm),e(Nm,Cae),e(Cae,jYe),e(Nm,DYe),e(Nm,fR),e(fR,GYe),e(Nm,OYe),e(A,VYe),e(A,qm),e(qm,wae),e(wae,XYe),e(qm,zYe),e(qm,mR),e(mR,QYe),e(qm,WYe),e(A,HYe),e(A,jm),e(jm,Aae),e(Aae,UYe),e(jm,JYe),e(jm,gR),e(gR,YYe),e(jm,KYe),e(A,ZYe),e(A,Dm),e(Dm,Lae),e(Lae,eKe),e(Dm,oKe),e(Dm,hR),e(hR,rKe),e(Dm,tKe),e(A,aKe),e(A,Gm),e(Gm,yae),e(yae,nKe),e(Gm,sKe),e(Gm,pR),e(pR,lKe),e(Gm,iKe),e(A,dKe),e(A,Om),e(Om,xae),e(xae,cKe),e(Om,fKe),e(Om,_R),e(_R,mKe),e(Om,gKe),e(A,hKe),e(A,Vm),e(Vm,$ae),e($ae,pKe),e(Vm,_Ke),e(Vm,uR),e(uR,uKe),e(Vm,bKe),e(A,vKe),e(A,Xm),e(Xm,kae),e(kae,FKe),e(Xm,TKe),e(Xm,bR),e(bR,MKe),e(Xm,EKe),e(A,CKe),e(A,zm),e(zm,Sae),e(Sae,wKe),e(zm,AKe),e(zm,vR),e(vR,LKe),e(zm,yKe),e(A,xKe),e(A,Qm),e(Qm,Rae),e(Rae,$Ke),e(Qm,kKe),e(Qm,FR),e(FR,SKe),e(Qm,RKe),e(A,PKe),e(A,Wm),e(Wm,Pae),e(Pae,BKe),e(Wm,IKe),e(Wm,TR),e(TR,NKe),e(Wm,qKe),e(A,jKe),e(A,Hm),e(Hm,Bae),e(Bae,DKe),e(Hm,GKe),e(Hm,MR),e(MR,OKe),e(Hm,VKe),e(A,XKe),e(A,Um),e(Um,Iae),e(Iae,zKe),e(Um,QKe),e(Um,ER),e(ER,WKe),e(Um,HKe),e(A,UKe),e(A,Jm),e(Jm,Nae),e(Nae,JKe),e(Jm,YKe),e(Jm,CR),e(CR,KKe),e(Jm,ZKe),e(A,eZe),e(A,Ym),e(Ym,qae),e(qae,oZe),e(Ym,rZe),e(Ym,wR),e(wR,tZe),e(Ym,aZe),e(A,nZe),e(A,Km),e(Km,jae),e(jae,sZe),e(Km,lZe),e(Km,AR),e(AR,iZe),e(Km,dZe),e(A,cZe),e(A,Zm),e(Zm,Dae),e(Dae,fZe),e(Zm,mZe),e(Zm,LR),e(LR,gZe),e(Zm,hZe),e(A,pZe),e(A,eg),e(eg,Gae),e(Gae,_Ze),e(eg,uZe),e(eg,yR),e(yR,bZe),e(eg,vZe),e(A,FZe),e(A,og),e(og,Oae),e(Oae,TZe),e(og,MZe),e(og,xR),e(xR,EZe),e(og,CZe),e(A,wZe),e(A,rg),e(rg,Vae),e(Vae,AZe),e(rg,LZe),e(rg,$R),e($R,yZe),e(rg,xZe),e(A,$Ze),e(A,tg),e(tg,Xae),e(Xae,kZe),e(tg,SZe),e(tg,kR),e(kR,RZe),e(tg,PZe),e(A,BZe),e(A,ag),e(ag,zae),e(zae,IZe),e(ag,NZe),e(ag,SR),e(SR,qZe),e(ag,jZe),e(A,DZe),e(A,ng),e(ng,Qae),e(Qae,GZe),e(ng,OZe),e(ng,RR),e(RR,VZe),e(ng,XZe),e(A,zZe),e(A,sg),e(sg,Wae),e(Wae,QZe),e(sg,WZe),e(sg,PR),e(PR,HZe),e(sg,UZe),e(A,JZe),e(A,lg),e(lg,Hae),e(Hae,YZe),e(lg,KZe),e(lg,BR),e(BR,ZZe),e(lg,eeo),e(A,oeo),e(A,ig),e(ig,Uae),e(Uae,reo),e(ig,teo),e(ig,IR),e(IR,aeo),e(ig,neo),e(A,seo),e(A,dg),e(dg,Jae),e(Jae,leo),e(dg,ieo),e(dg,NR),e(NR,deo),e(dg,ceo),e(A,feo),e(A,cg),e(cg,Yae),e(Yae,meo),e(cg,geo),e(cg,qR),e(qR,heo),e(cg,peo),e(A,_eo),e(A,fg),e(fg,Kae),e(Kae,ueo),e(fg,beo),e(fg,jR),e(jR,veo),e(fg,Feo),e(A,Teo),e(A,mg),e(mg,Zae),e(Zae,Meo),e(mg,Eeo),e(mg,DR),e(DR,Ceo),e(mg,weo),e(A,Aeo),e(A,gg),e(gg,ene),e(ene,Leo),e(gg,yeo),e(gg,GR),e(GR,xeo),e(gg,$eo),e(A,keo),e(A,hg),e(hg,one),e(one,Seo),e(hg,Reo),e(hg,OR),e(OR,Peo),e(hg,Beo),e(A,Ieo),e(A,pg),e(pg,rne),e(rne,Neo),e(pg,qeo),e(pg,VR),e(VR,jeo),e(pg,Deo),e(A,Geo),e(A,_g),e(_g,tne),e(tne,Oeo),e(_g,Veo),e(_g,XR),e(XR,Xeo),e(_g,zeo),e(A,Qeo),e(A,ug),e(ug,ane),e(ane,Weo),e(ug,Heo),e(ug,zR),e(zR,Ueo),e(ug,Jeo),e(A,Yeo),e(A,bg),e(bg,nne),e(nne,Keo),e(bg,Zeo),e(bg,QR),e(QR,eoo),e(bg,ooo),e(A,roo),e(A,vg),e(vg,sne),e(sne,too),e(vg,aoo),e(vg,WR),e(WR,noo),e(vg,soo),e(A,loo),e(A,Fg),e(Fg,lne),e(lne,ioo),e(Fg,doo),e(Fg,HR),e(HR,coo),e(Fg,foo),e(A,moo),e(A,Tg),e(Tg,ine),e(ine,goo),e(Tg,hoo),e(Tg,UR),e(UR,poo),e(Tg,_oo),e(A,uoo),e(A,Mg),e(Mg,dne),e(dne,boo),e(Mg,voo),e(Mg,JR),e(JR,Foo),e(Mg,Too),e(A,Moo),e(A,Eg),e(Eg,cne),e(cne,Eoo),e(Eg,Coo),e(Eg,YR),e(YR,woo),e(Eg,Aoo),e(A,Loo),e(A,Cg),e(Cg,fne),e(fne,yoo),e(Cg,xoo),e(Cg,KR),e(KR,$oo),e(Cg,koo),e(A,Soo),e(A,wg),e(wg,mne),e(mne,Roo),e(wg,Poo),e(wg,ZR),e(ZR,Boo),e(wg,Ioo),e(A,Noo),e(A,Ag),e(Ag,gne),e(gne,qoo),e(Ag,joo),e(Ag,eP),e(eP,Doo),e(Ag,Goo),e(A,Ooo),e(A,Lg),e(Lg,hne),e(hne,Voo),e(Lg,Xoo),e(Lg,oP),e(oP,zoo),e(Lg,Qoo),e(A,Woo),e(A,yg),e(yg,pne),e(pne,Hoo),e(yg,Uoo),e(yg,rP),e(rP,Joo),e(yg,Yoo),e(A,Koo),e(A,xg),e(xg,_ne),e(_ne,Zoo),e(xg,ero),e(xg,tP),e(tP,oro),e(xg,rro),e(A,tro),e(A,$g),e($g,une),e(une,aro),e($g,nro),e($g,aP),e(aP,sro),e($g,lro),e(A,iro),e(A,kg),e(kg,bne),e(bne,dro),e(kg,cro),e(kg,nP),e(nP,fro),e(kg,mro),e(A,gro),e(A,Sg),e(Sg,vne),e(vne,hro),e(Sg,pro),e(Sg,sP),e(sP,_ro),e(Sg,uro),e(A,bro),e(A,Rg),e(Rg,Fne),e(Fne,vro),e(Rg,Fro),e(Rg,lP),e(lP,Tro),e(Rg,Mro),e(A,Ero),e(A,Pg),e(Pg,Tne),e(Tne,Cro),e(Pg,wro),e(Pg,iP),e(iP,Aro),e(Pg,Lro),e(A,yro),e(A,Bg),e(Bg,Mne),e(Mne,xro),e(Bg,$ro),e(Bg,dP),e(dP,kro),e(Bg,Sro),e(A,Rro),e(A,Ig),e(Ig,Ene),e(Ene,Pro),e(Ig,Bro),e(Ig,cP),e(cP,Iro),e(Ig,Nro),e(A,qro),e(A,Ng),e(Ng,Cne),e(Cne,jro),e(Ng,Dro),e(Ng,fP),e(fP,Gro),e(Ng,Oro),e(A,Vro),e(A,qg),e(qg,wne),e(wne,Xro),e(qg,zro),e(qg,mP),e(mP,Qro),e(qg,Wro),e(A,Hro),e(A,jg),e(jg,Ane),e(Ane,Uro),e(jg,Jro),e(jg,gP),e(gP,Yro),e(jg,Kro),e(A,Zro),e(A,Dg),e(Dg,Lne),e(Lne,eto),e(Dg,oto),e(Dg,hP),e(hP,rto),e(Dg,tto),e(Ar,ato),M(Gg,Ar,null),e(wo,nto),e(wo,Og),M(IL,Og,null),e(Og,sto),e(Og,yne),e(yne,lto),b(f,QGe,u),b(f,ki,u),e(ki,Vg),e(Vg,xne),M(NL,xne,null),e(ki,ito),e(ki,$ne),e($ne,dto),b(f,WGe,u),b(f,Ao,u),M(qL,Ao,null),e(Ao,cto),e(Ao,jL),e(jL,fto),e(jL,pP),e(pP,mto),e(jL,gto),e(Ao,hto),e(Ao,DL),e(DL,pto),e(DL,kne),e(kne,_to),e(DL,uto),e(Ao,bto),e(Ao,Lr),M(GL,Lr,null),e(Lr,vto),e(Lr,Sne),e(Sne,Fto),e(Lr,Tto),e(Lr,ka),e(ka,Mto),e(ka,Rne),e(Rne,Eto),e(ka,Cto),e(ka,Pne),e(Pne,wto),e(ka,Ato),e(ka,Bne),e(Bne,Lto),e(ka,yto),e(Lr,xto),e(Lr,k),e(k,qn),e(qn,Ine),e(Ine,$to),e(qn,kto),e(qn,_P),e(_P,Sto),e(qn,Rto),e(qn,uP),e(uP,Pto),e(qn,Bto),e(k,Ito),e(k,jn),e(jn,Nne),e(Nne,Nto),e(jn,qto),e(jn,bP),e(bP,jto),e(jn,Dto),e(jn,vP),e(vP,Gto),e(jn,Oto),e(k,Vto),e(k,Dn),e(Dn,qne),e(qne,Xto),e(Dn,zto),e(Dn,FP),e(FP,Qto),e(Dn,Wto),e(Dn,TP),e(TP,Hto),e(Dn,Uto),e(k,Jto),e(k,Xg),e(Xg,jne),e(jne,Yto),e(Xg,Kto),e(Xg,MP),e(MP,Zto),e(Xg,eao),e(k,oao),e(k,Gn),e(Gn,Dne),e(Dne,rao),e(Gn,tao),e(Gn,EP),e(EP,aao),e(Gn,nao),e(Gn,CP),e(CP,sao),e(Gn,lao),e(k,iao),e(k,zg),e(zg,Gne),e(Gne,dao),e(zg,cao),e(zg,wP),e(wP,fao),e(zg,mao),e(k,gao),e(k,Qg),e(Qg,One),e(One,hao),e(Qg,pao),e(Qg,AP),e(AP,_ao),e(Qg,uao),e(k,bao),e(k,Wg),e(Wg,Vne),e(Vne,vao),e(Wg,Fao),e(Wg,LP),e(LP,Tao),e(Wg,Mao),e(k,Eao),e(k,On),e(On,Xne),e(Xne,Cao),e(On,wao),e(On,yP),e(yP,Aao),e(On,Lao),e(On,xP),e(xP,yao),e(On,xao),e(k,$ao),e(k,Vn),e(Vn,zne),e(zne,kao),e(Vn,Sao),e(Vn,$P),e($P,Rao),e(Vn,Pao),e(Vn,kP),e(kP,Bao),e(Vn,Iao),e(k,Nao),e(k,Xn),e(Xn,Qne),e(Qne,qao),e(Xn,jao),e(Xn,SP),e(SP,Dao),e(Xn,Gao),e(Xn,RP),e(RP,Oao),e(Xn,Vao),e(k,Xao),e(k,Hg),e(Hg,Wne),e(Wne,zao),e(Hg,Qao),e(Hg,PP),e(PP,Wao),e(Hg,Hao),e(k,Uao),e(k,Ug),e(Ug,Hne),e(Hne,Jao),e(Ug,Yao),e(Ug,BP),e(BP,Kao),e(Ug,Zao),e(k,eno),e(k,Jg),e(Jg,Une),e(Une,ono),e(Jg,rno),e(Jg,IP),e(IP,tno),e(Jg,ano),e(k,nno),e(k,zn),e(zn,Jne),e(Jne,sno),e(zn,lno),e(zn,NP),e(NP,ino),e(zn,dno),e(zn,qP),e(qP,cno),e(zn,fno),e(k,mno),e(k,Yg),e(Yg,Yne),e(Yne,gno),e(Yg,hno),e(Yg,jP),e(jP,pno),e(Yg,_no),e(k,uno),e(k,Qn),e(Qn,Kne),e(Kne,bno),e(Qn,vno),e(Qn,DP),e(DP,Fno),e(Qn,Tno),e(Qn,GP),e(GP,Mno),e(Qn,Eno),e(k,Cno),e(k,Wn),e(Wn,Zne),e(Zne,wno),e(Wn,Ano),e(Wn,OP),e(OP,Lno),e(Wn,yno),e(Wn,VP),e(VP,xno),e(Wn,$no),e(k,kno),e(k,Hn),e(Hn,ese),e(ese,Sno),e(Hn,Rno),e(Hn,XP),e(XP,Pno),e(Hn,Bno),e(Hn,zP),e(zP,Ino),e(Hn,Nno),e(k,qno),e(k,Kg),e(Kg,ose),e(ose,jno),e(Kg,Dno),e(Kg,QP),e(QP,Gno),e(Kg,Ono),e(k,Vno),e(k,Un),e(Un,rse),e(rse,Xno),e(Un,zno),e(Un,WP),e(WP,Qno),e(Un,Wno),e(Un,HP),e(HP,Hno),e(Un,Uno),e(k,Jno),e(k,Jn),e(Jn,tse),e(tse,Yno),e(Jn,Kno),e(Jn,UP),e(UP,Zno),e(Jn,eso),e(Jn,JP),e(JP,oso),e(Jn,rso),e(k,tso),e(k,Yn),e(Yn,ase),e(ase,aso),e(Yn,nso),e(Yn,YP),e(YP,sso),e(Yn,lso),e(Yn,KP),e(KP,iso),e(Yn,dso),e(k,cso),e(k,Kn),e(Kn,nse),e(nse,fso),e(Kn,mso),e(Kn,ZP),e(ZP,gso),e(Kn,hso),e(Kn,eB),e(eB,pso),e(Kn,_so),e(k,uso),e(k,Zn),e(Zn,sse),e(sse,bso),e(Zn,vso),e(Zn,oB),e(oB,Fso),e(Zn,Tso),e(Zn,rB),e(rB,Mso),e(Zn,Eso),e(k,Cso),e(k,es),e(es,lse),e(lse,wso),e(es,Aso),e(es,tB),e(tB,Lso),e(es,yso),e(es,aB),e(aB,xso),e(es,$so),e(k,kso),e(k,Zg),e(Zg,ise),e(ise,Sso),e(Zg,Rso),e(Zg,nB),e(nB,Pso),e(Zg,Bso),e(k,Iso),e(k,os),e(os,dse),e(dse,Nso),e(os,qso),e(os,sB),e(sB,jso),e(os,Dso),e(os,lB),e(lB,Gso),e(os,Oso),e(k,Vso),e(k,eh),e(eh,cse),e(cse,Xso),e(eh,zso),e(eh,iB),e(iB,Qso),e(eh,Wso),e(k,Hso),e(k,rs),e(rs,fse),e(fse,Uso),e(rs,Jso),e(rs,dB),e(dB,Yso),e(rs,Kso),e(rs,cB),e(cB,Zso),e(rs,elo),e(k,olo),e(k,ts),e(ts,mse),e(mse,rlo),e(ts,tlo),e(ts,fB),e(fB,alo),e(ts,nlo),e(ts,mB),e(mB,slo),e(ts,llo),e(k,ilo),e(k,as),e(as,gse),e(gse,dlo),e(as,clo),e(as,gB),e(gB,flo),e(as,mlo),e(as,hB),e(hB,glo),e(as,hlo),e(k,plo),e(k,oh),e(oh,hse),e(hse,_lo),e(oh,ulo),e(oh,pB),e(pB,blo),e(oh,vlo),e(k,Flo),e(k,ns),e(ns,pse),e(pse,Tlo),e(ns,Mlo),e(ns,_B),e(_B,Elo),e(ns,Clo),e(ns,uB),e(uB,wlo),e(ns,Alo),e(k,Llo),e(k,ss),e(ss,_se),e(_se,ylo),e(ss,xlo),e(ss,bB),e(bB,$lo),e(ss,klo),e(ss,vB),e(vB,Slo),e(ss,Rlo),e(k,Plo),e(k,rh),e(rh,use),e(use,Blo),e(rh,Ilo),e(rh,FB),e(FB,Nlo),e(rh,qlo),e(k,jlo),e(k,ls),e(ls,bse),e(bse,Dlo),e(ls,Glo),e(ls,TB),e(TB,Olo),e(ls,Vlo),e(ls,MB),e(MB,Xlo),e(ls,zlo),e(k,Qlo),e(k,is),e(is,vse),e(vse,Wlo),e(is,Hlo),e(is,EB),e(EB,Ulo),e(is,Jlo),e(is,CB),e(CB,Ylo),e(is,Klo),e(k,Zlo),e(k,ds),e(ds,Fse),e(Fse,eio),e(ds,oio),e(ds,wB),e(wB,rio),e(ds,tio),e(ds,AB),e(AB,aio),e(ds,nio),e(k,sio),e(k,cs),e(cs,Tse),e(Tse,lio),e(cs,iio),e(cs,LB),e(LB,dio),e(cs,cio),e(cs,yB),e(yB,fio),e(cs,mio),e(k,gio),e(k,fs),e(fs,Mse),e(Mse,hio),e(fs,pio),e(fs,xB),e(xB,_io),e(fs,uio),e(fs,$B),e($B,bio),e(fs,vio),e(k,Fio),e(k,ms),e(ms,Ese),e(Ese,Tio),e(ms,Mio),e(ms,kB),e(kB,Eio),e(ms,Cio),e(ms,SB),e(SB,wio),e(ms,Aio),e(k,Lio),e(k,gs),e(gs,Cse),e(Cse,yio),e(gs,xio),e(gs,RB),e(RB,$io),e(gs,kio),e(gs,PB),e(PB,Sio),e(gs,Rio),e(k,Pio),e(k,hs),e(hs,wse),e(wse,Bio),e(hs,Iio),e(hs,BB),e(BB,Nio),e(hs,qio),e(hs,IB),e(IB,jio),e(hs,Dio),e(k,Gio),e(k,th),e(th,Ase),e(Ase,Oio),e(th,Vio),e(th,NB),e(NB,Xio),e(th,zio),e(k,Qio),e(k,ps),e(ps,Lse),e(Lse,Wio),e(ps,Hio),e(ps,qB),e(qB,Uio),e(ps,Jio),e(ps,jB),e(jB,Yio),e(ps,Kio),e(k,Zio),e(k,ah),e(ah,yse),e(yse,edo),e(ah,odo),e(ah,DB),e(DB,rdo),e(ah,tdo),e(k,ado),e(k,nh),e(nh,xse),e(xse,ndo),e(nh,sdo),e(nh,GB),e(GB,ldo),e(nh,ido),e(k,ddo),e(k,_s),e(_s,$se),e($se,cdo),e(_s,fdo),e(_s,OB),e(OB,mdo),e(_s,gdo),e(_s,VB),e(VB,hdo),e(_s,pdo),e(k,_do),e(k,us),e(us,kse),e(kse,udo),e(us,bdo),e(us,XB),e(XB,vdo),e(us,Fdo),e(us,zB),e(zB,Tdo),e(us,Mdo),e(k,Edo),e(k,bs),e(bs,Sse),e(Sse,Cdo),e(bs,wdo),e(bs,QB),e(QB,Ado),e(bs,Ldo),e(bs,WB),e(WB,ydo),e(bs,xdo),e(k,$do),e(k,sh),e(sh,Rse),e(Rse,kdo),e(sh,Sdo),e(sh,HB),e(HB,Rdo),e(sh,Pdo),e(k,Bdo),e(k,vs),e(vs,Pse),e(Pse,Ido),e(vs,Ndo),e(vs,UB),e(UB,qdo),e(vs,jdo),e(vs,JB),e(JB,Ddo),e(vs,Gdo),e(k,Odo),e(k,Fs),e(Fs,Bse),e(Bse,Vdo),e(Fs,Xdo),e(Fs,YB),e(YB,zdo),e(Fs,Qdo),e(Fs,KB),e(KB,Wdo),e(Fs,Hdo),e(k,Udo),e(k,Ts),e(Ts,Ise),e(Ise,Jdo),e(Ts,Ydo),e(Ts,ZB),e(ZB,Kdo),e(Ts,Zdo),e(Ts,eI),e(eI,eco),e(Ts,oco),e(k,rco),e(k,Ms),e(Ms,Nse),e(Nse,tco),e(Ms,aco),e(Ms,oI),e(oI,nco),e(Ms,sco),e(Ms,rI),e(rI,lco),e(Ms,ico),e(k,dco),e(k,Es),e(Es,qse),e(qse,cco),e(Es,fco),e(Es,tI),e(tI,mco),e(Es,gco),e(Es,aI),e(aI,hco),e(Es,pco),e(k,_co),e(k,Cs),e(Cs,jse),e(jse,uco),e(Cs,bco),e(Cs,nI),e(nI,vco),e(Cs,Fco),e(Cs,sI),e(sI,Tco),e(Cs,Mco),e(k,Eco),e(k,lh),e(lh,Dse),e(Dse,Cco),e(lh,wco),e(lh,lI),e(lI,Aco),e(lh,Lco),e(k,yco),e(k,ws),e(ws,Gse),e(Gse,xco),e(ws,$co),e(ws,iI),e(iI,kco),e(ws,Sco),e(ws,dI),e(dI,Rco),e(ws,Pco),e(k,Bco),e(k,ih),e(ih,Ose),e(Ose,Ico),e(ih,Nco),e(ih,cI),e(cI,qco),e(ih,jco),e(k,Dco),e(k,dh),e(dh,Vse),e(Vse,Gco),e(dh,Oco),e(dh,fI),e(fI,Vco),e(dh,Xco),e(k,zco),e(k,ch),e(ch,Xse),e(Xse,Qco),e(ch,Wco),e(ch,mI),e(mI,Hco),e(ch,Uco),e(k,Jco),e(k,fh),e(fh,zse),e(zse,Yco),e(fh,Kco),e(fh,gI),e(gI,Zco),e(fh,efo),e(k,ofo),e(k,As),e(As,Qse),e(Qse,rfo),e(As,tfo),e(As,hI),e(hI,afo),e(As,nfo),e(As,pI),e(pI,sfo),e(As,lfo),e(k,ifo),e(k,mh),e(mh,Wse),e(Wse,dfo),e(mh,cfo),e(mh,_I),e(_I,ffo),e(mh,mfo),e(k,gfo),e(k,Ls),e(Ls,Hse),e(Hse,hfo),e(Ls,pfo),e(Ls,uI),e(uI,_fo),e(Ls,ufo),e(Ls,bI),e(bI,bfo),e(Ls,vfo),e(k,Ffo),e(k,ys),e(ys,Use),e(Use,Tfo),e(ys,Mfo),e(ys,vI),e(vI,Efo),e(ys,Cfo),e(ys,FI),e(FI,wfo),e(ys,Afo),e(k,Lfo),e(k,xs),e(xs,Jse),e(Jse,yfo),e(xs,xfo),e(xs,TI),e(TI,$fo),e(xs,kfo),e(xs,MI),e(MI,Sfo),e(xs,Rfo),e(k,Pfo),e(k,$s),e($s,Yse),e(Yse,Bfo),e($s,Ifo),e($s,EI),e(EI,Nfo),e($s,qfo),e($s,CI),e(CI,jfo),e($s,Dfo),e(k,Gfo),e(k,ks),e(ks,Kse),e(Kse,Ofo),e(ks,Vfo),e(ks,wI),e(wI,Xfo),e(ks,zfo),e(ks,AI),e(AI,Qfo),e(ks,Wfo),e(k,Hfo),e(k,Ss),e(Ss,Zse),e(Zse,Ufo),e(Ss,Jfo),e(Ss,LI),e(LI,Yfo),e(Ss,Kfo),e(Ss,yI),e(yI,Zfo),e(Ss,emo),e(k,omo),e(k,gh),e(gh,ele),e(ele,rmo),e(gh,tmo),e(gh,xI),e(xI,amo),e(gh,nmo),e(k,smo),e(k,hh),e(hh,ole),e(ole,lmo),e(hh,imo),e(hh,$I),e($I,dmo),e(hh,cmo),e(k,fmo),e(k,Rs),e(Rs,rle),e(rle,mmo),e(Rs,gmo),e(Rs,kI),e(kI,hmo),e(Rs,pmo),e(Rs,SI),e(SI,_mo),e(Rs,umo),e(k,bmo),e(k,Ps),e(Ps,tle),e(tle,vmo),e(Ps,Fmo),e(Ps,RI),e(RI,Tmo),e(Ps,Mmo),e(Ps,PI),e(PI,Emo),e(Ps,Cmo),e(k,wmo),e(k,Bs),e(Bs,ale),e(ale,Amo),e(Bs,Lmo),e(Bs,BI),e(BI,ymo),e(Bs,xmo),e(Bs,II),e(II,$mo),e(Bs,kmo),e(k,Smo),e(k,ph),e(ph,nle),e(nle,Rmo),e(ph,Pmo),e(ph,NI),e(NI,Bmo),e(ph,Imo),e(k,Nmo),e(k,_h),e(_h,sle),e(sle,qmo),e(_h,jmo),e(_h,qI),e(qI,Dmo),e(_h,Gmo),e(k,Omo),e(k,uh),e(uh,lle),e(lle,Vmo),e(uh,Xmo),e(uh,jI),e(jI,zmo),e(uh,Qmo),e(k,Wmo),e(k,Is),e(Is,ile),e(ile,Hmo),e(Is,Umo),e(Is,DI),e(DI,Jmo),e(Is,Ymo),e(Is,GI),e(GI,Kmo),e(Is,Zmo),e(k,ego),e(k,Ns),e(Ns,dle),e(dle,ogo),e(Ns,rgo),e(Ns,OI),e(OI,tgo),e(Ns,ago),e(Ns,VI),e(VI,ngo),e(Ns,sgo),e(k,lgo),e(k,bh),e(bh,cle),e(cle,igo),e(bh,dgo),e(bh,XI),e(XI,cgo),e(bh,fgo),e(k,mgo),e(k,vh),e(vh,fle),e(fle,ggo),e(vh,hgo),e(vh,zI),e(zI,pgo),e(vh,_go),e(k,ugo),e(k,Fh),e(Fh,mle),e(mle,bgo),e(Fh,vgo),e(Fh,QI),e(QI,Fgo),e(Fh,Tgo),e(k,Mgo),e(k,qs),e(qs,gle),e(gle,Ego),e(qs,Cgo),e(qs,WI),e(WI,wgo),e(qs,Ago),e(qs,HI),e(HI,Lgo),e(qs,ygo),e(k,xgo),e(k,Th),e(Th,hle),e(hle,$go),e(Th,kgo),e(Th,UI),e(UI,Sgo),e(Th,Rgo),e(k,Pgo),e(k,Mh),e(Mh,ple),e(ple,Bgo),e(Mh,Igo),e(Mh,JI),e(JI,Ngo),e(Mh,qgo),e(k,jgo),e(k,js),e(js,_le),e(_le,Dgo),e(js,Ggo),e(js,YI),e(YI,Ogo),e(js,Vgo),e(js,KI),e(KI,Xgo),e(js,zgo),e(k,Qgo),e(k,Ds),e(Ds,ule),e(ule,Wgo),e(Ds,Hgo),e(Ds,ZI),e(ZI,Ugo),e(Ds,Jgo),e(Ds,eN),e(eN,Ygo),e(Ds,Kgo),e(k,Zgo),e(k,Gs),e(Gs,ble),e(ble,eho),e(Gs,oho),e(Gs,oN),e(oN,rho),e(Gs,tho),e(Gs,rN),e(rN,aho),e(Gs,nho),e(k,sho),e(k,Os),e(Os,vle),e(vle,lho),e(Os,iho),e(Os,tN),e(tN,dho),e(Os,cho),e(Os,aN),e(aN,fho),e(Os,mho),e(Lr,gho),M(Eh,Lr,null),e(Ao,hho),e(Ao,Ch),M(OL,Ch,null),e(Ch,pho),e(Ch,Fle),e(Fle,_ho),b(f,HGe,u),b(f,Si,u),e(Si,wh),e(wh,Tle),M(VL,Tle,null),e(Si,uho),e(Si,Mle),e(Mle,bho),b(f,UGe,u),b(f,Lo,u),M(XL,Lo,null),e(Lo,vho),e(Lo,zL),e(zL,Fho),e(zL,nN),e(nN,Tho),e(zL,Mho),e(Lo,Eho),e(Lo,QL),e(QL,Cho),e(QL,Ele),e(Ele,who),e(QL,Aho),e(Lo,Lho),e(Lo,He),M(WL,He,null),e(He,yho),e(He,Cle),e(Cle,xho),e(He,$ho),e(He,Sa),e(Sa,kho),e(Sa,wle),e(wle,Sho),e(Sa,Rho),e(Sa,Ale),e(Ale,Pho),e(Sa,Bho),e(Sa,Lle),e(Lle,Iho),e(Sa,Nho),e(He,qho),e(He,Y),e(Y,Ah),e(Ah,yle),e(yle,jho),e(Ah,Dho),e(Ah,sN),e(sN,Gho),e(Ah,Oho),e(Y,Vho),e(Y,Lh),e(Lh,xle),e(xle,Xho),e(Lh,zho),e(Lh,lN),e(lN,Qho),e(Lh,Who),e(Y,Hho),e(Y,yh),e(yh,$le),e($le,Uho),e(yh,Jho),e(yh,iN),e(iN,Yho),e(yh,Kho),e(Y,Zho),e(Y,xh),e(xh,kle),e(kle,epo),e(xh,opo),e(xh,dN),e(dN,rpo),e(xh,tpo),e(Y,apo),e(Y,$h),e($h,Sle),e(Sle,npo),e($h,spo),e($h,cN),e(cN,lpo),e($h,ipo),e(Y,dpo),e(Y,kh),e(kh,Rle),e(Rle,cpo),e(kh,fpo),e(kh,fN),e(fN,mpo),e(kh,gpo),e(Y,hpo),e(Y,Sh),e(Sh,Ple),e(Ple,ppo),e(Sh,_po),e(Sh,mN),e(mN,upo),e(Sh,bpo),e(Y,vpo),e(Y,Rh),e(Rh,Ble),e(Ble,Fpo),e(Rh,Tpo),e(Rh,gN),e(gN,Mpo),e(Rh,Epo),e(Y,Cpo),e(Y,Ph),e(Ph,Ile),e(Ile,wpo),e(Ph,Apo),e(Ph,hN),e(hN,Lpo),e(Ph,ypo),e(Y,xpo),e(Y,Bh),e(Bh,Nle),e(Nle,$po),e(Bh,kpo),e(Bh,pN),e(pN,Spo),e(Bh,Rpo),e(Y,Ppo),e(Y,Ih),e(Ih,qle),e(qle,Bpo),e(Ih,Ipo),e(Ih,_N),e(_N,Npo),e(Ih,qpo),e(Y,jpo),e(Y,Nh),e(Nh,jle),e(jle,Dpo),e(Nh,Gpo),e(Nh,uN),e(uN,Opo),e(Nh,Vpo),e(Y,Xpo),e(Y,qh),e(qh,Dle),e(Dle,zpo),e(qh,Qpo),e(qh,bN),e(bN,Wpo),e(qh,Hpo),e(Y,Upo),e(Y,jh),e(jh,Gle),e(Gle,Jpo),e(jh,Ypo),e(jh,vN),e(vN,Kpo),e(jh,Zpo),e(Y,e_o),e(Y,Dh),e(Dh,Ole),e(Ole,o_o),e(Dh,r_o),e(Dh,FN),e(FN,t_o),e(Dh,a_o),e(Y,n_o),e(Y,Gh),e(Gh,Vle),e(Vle,s_o),e(Gh,l_o),e(Gh,TN),e(TN,i_o),e(Gh,d_o),e(Y,c_o),e(Y,Oh),e(Oh,Xle),e(Xle,f_o),e(Oh,m_o),e(Oh,MN),e(MN,g_o),e(Oh,h_o),e(Y,p_o),e(Y,Vh),e(Vh,zle),e(zle,__o),e(Vh,u_o),e(Vh,EN),e(EN,b_o),e(Vh,v_o),e(Y,F_o),e(Y,Xh),e(Xh,Qle),e(Qle,T_o),e(Xh,M_o),e(Xh,CN),e(CN,E_o),e(Xh,C_o),e(Y,w_o),e(Y,zh),e(zh,Wle),e(Wle,A_o),e(zh,L_o),e(zh,wN),e(wN,y_o),e(zh,x_o),e(Y,$_o),e(Y,Qh),e(Qh,Hle),e(Hle,k_o),e(Qh,S_o),e(Qh,AN),e(AN,R_o),e(Qh,P_o),e(Y,B_o),e(Y,Wh),e(Wh,Ule),e(Ule,I_o),e(Wh,N_o),e(Wh,LN),e(LN,q_o),e(Wh,j_o),e(Y,D_o),e(Y,Hh),e(Hh,Jle),e(Jle,G_o),e(Hh,O_o),e(Hh,yN),e(yN,V_o),e(Hh,X_o),e(Y,z_o),e(Y,Uh),e(Uh,Yle),e(Yle,Q_o),e(Uh,W_o),e(Uh,xN),e(xN,H_o),e(Uh,U_o),e(Y,J_o),e(Y,Jh),e(Jh,Kle),e(Kle,Y_o),e(Jh,K_o),e(Jh,$N),e($N,Z_o),e(Jh,euo),e(Y,ouo),e(Y,Yh),e(Yh,Zle),e(Zle,ruo),e(Yh,tuo),e(Yh,kN),e(kN,auo),e(Yh,nuo),e(Y,suo),e(Y,Kh),e(Kh,eie),e(eie,luo),e(Kh,iuo),e(Kh,SN),e(SN,duo),e(Kh,cuo),e(Y,fuo),e(Y,Zh),e(Zh,oie),e(oie,muo),e(Zh,guo),e(Zh,RN),e(RN,huo),e(Zh,puo),e(Y,_uo),e(Y,ep),e(ep,rie),e(rie,uuo),e(ep,buo),e(ep,PN),e(PN,vuo),e(ep,Fuo),e(Y,Tuo),e(Y,op),e(op,tie),e(tie,Muo),e(op,Euo),e(op,BN),e(BN,Cuo),e(op,wuo),e(Y,Auo),e(Y,rp),e(rp,aie),e(aie,Luo),e(rp,yuo),e(rp,IN),e(IN,xuo),e(rp,$uo),e(Y,kuo),e(Y,tp),e(tp,nie),e(nie,Suo),e(tp,Ruo),e(tp,NN),e(NN,Puo),e(tp,Buo),e(He,Iuo),M(ap,He,null),e(He,Nuo),M(np,He,null),e(Lo,quo),e(Lo,sp),M(HL,sp,null),e(sp,juo),e(sp,sie),e(sie,Duo),b(f,JGe,u),b(f,Ri,u),e(Ri,lp),e(lp,lie),M(UL,lie,null),e(Ri,Guo),e(Ri,iie),e(iie,Ouo),b(f,YGe,u),b(f,yo,u),M(JL,yo,null),e(yo,Vuo),e(yo,YL),e(YL,Xuo),e(YL,qN),e(qN,zuo),e(YL,Quo),e(yo,Wuo),e(yo,KL),e(KL,Huo),e(KL,die),e(die,Uuo),e(KL,Juo),e(yo,Yuo),e(yo,Ue),M(ZL,Ue,null),e(Ue,Kuo),e(Ue,cie),e(cie,Zuo),e(Ue,e7o),e(Ue,Pi),e(Pi,o7o),e(Pi,fie),e(fie,r7o),e(Pi,t7o),e(Pi,mie),e(mie,a7o),e(Pi,n7o),e(Ue,s7o),e(Ue,he),e(he,ip),e(ip,gie),e(gie,l7o),e(ip,i7o),e(ip,jN),e(jN,d7o),e(ip,c7o),e(he,f7o),e(he,dp),e(dp,hie),e(hie,m7o),e(dp,g7o),e(dp,pie),e(pie,h7o),e(dp,p7o),e(he,_7o),e(he,cp),e(cp,_ie),e(_ie,u7o),e(cp,b7o),e(cp,DN),e(DN,v7o),e(cp,F7o),e(he,T7o),e(he,fp),e(fp,uie),e(uie,M7o),e(fp,E7o),e(fp,GN),e(GN,C7o),e(fp,w7o),e(he,A7o),e(he,mp),e(mp,bie),e(bie,L7o),e(mp,y7o),e(mp,ON),e(ON,x7o),e(mp,$7o),e(he,k7o),e(he,gp),e(gp,vie),e(vie,S7o),e(gp,R7o),e(gp,VN),e(VN,P7o),e(gp,B7o),e(he,I7o),e(he,hp),e(hp,Fie),e(Fie,N7o),e(hp,q7o),e(hp,XN),e(XN,j7o),e(hp,D7o),e(he,G7o),e(he,pp),e(pp,Tie),e(Tie,O7o),e(pp,V7o),e(pp,zN),e(zN,X7o),e(pp,z7o),e(he,Q7o),e(he,_p),e(_p,Mie),e(Mie,W7o),e(_p,H7o),e(_p,QN),e(QN,U7o),e(_p,J7o),e(he,Y7o),e(he,up),e(up,Eie),e(Eie,K7o),e(up,Z7o),e(up,WN),e(WN,e1o),e(up,o1o),e(he,r1o),e(he,bp),e(bp,Cie),e(Cie,t1o),e(bp,a1o),e(bp,HN),e(HN,n1o),e(bp,s1o),e(he,l1o),e(he,vp),e(vp,wie),e(wie,i1o),e(vp,d1o),e(vp,UN),e(UN,c1o),e(vp,f1o),e(he,m1o),e(he,Fp),e(Fp,Aie),e(Aie,g1o),e(Fp,h1o),e(Fp,JN),e(JN,p1o),e(Fp,_1o),e(he,u1o),e(he,Tp),e(Tp,Lie),e(Lie,b1o),e(Tp,v1o),e(Tp,YN),e(YN,F1o),e(Tp,T1o),e(he,M1o),e(he,Mp),e(Mp,yie),e(yie,E1o),e(Mp,C1o),e(Mp,KN),e(KN,w1o),e(Mp,A1o),e(he,L1o),e(he,Ep),e(Ep,xie),e(xie,y1o),e(Ep,x1o),e(Ep,ZN),e(ZN,$1o),e(Ep,k1o),e(he,S1o),e(he,Cp),e(Cp,$ie),e($ie,R1o),e(Cp,P1o),e(Cp,eq),e(eq,B1o),e(Cp,I1o),e(Ue,N1o),M(wp,Ue,null),e(Ue,q1o),M(Ap,Ue,null),e(yo,j1o),e(yo,Lp),M(ey,Lp,null),e(Lp,D1o),e(Lp,kie),e(kie,G1o),b(f,KGe,u),b(f,Bi,u),e(Bi,yp),e(yp,Sie),M(oy,Sie,null),e(Bi,O1o),e(Bi,Rie),e(Rie,V1o),b(f,ZGe,u),b(f,xo,u),M(ry,xo,null),e(xo,X1o),e(xo,Ii),e(Ii,z1o),e(Ii,oq),e(oq,Q1o),e(Ii,W1o),e(Ii,rq),e(rq,H1o),e(Ii,U1o),e(xo,J1o),e(xo,ty),e(ty,Y1o),e(ty,Pie),e(Pie,K1o),e(ty,Z1o),e(xo,e2o),e(xo,nt),M(ay,nt,null),e(nt,o2o),e(nt,Bie),e(Bie,r2o),e(nt,t2o),e(nt,Ni),e(Ni,a2o),e(Ni,Iie),e(Iie,n2o),e(Ni,s2o),e(Ni,tq),e(tq,l2o),e(Ni,i2o),e(nt,d2o),M(xp,nt,null),e(xo,c2o),e(xo,Je),M(ny,Je,null),e(Je,f2o),e(Je,Nie),e(Nie,m2o),e(Je,g2o),e(Je,Ra),e(Ra,h2o),e(Ra,qie),e(qie,p2o),e(Ra,_2o),e(Ra,jie),e(jie,u2o),e(Ra,b2o),e(Ra,Die),e(Die,v2o),e(Ra,F2o),e(Je,T2o),e(Je,y),e(y,$p),e($p,Gie),e(Gie,M2o),e($p,E2o),e($p,aq),e(aq,C2o),e($p,w2o),e(y,A2o),e(y,kp),e(kp,Oie),e(Oie,L2o),e(kp,y2o),e(kp,nq),e(nq,x2o),e(kp,$2o),e(y,k2o),e(y,Sp),e(Sp,Vie),e(Vie,S2o),e(Sp,R2o),e(Sp,sq),e(sq,P2o),e(Sp,B2o),e(y,I2o),e(y,Rp),e(Rp,Xie),e(Xie,N2o),e(Rp,q2o),e(Rp,lq),e(lq,j2o),e(Rp,D2o),e(y,G2o),e(y,Pp),e(Pp,zie),e(zie,O2o),e(Pp,V2o),e(Pp,iq),e(iq,X2o),e(Pp,z2o),e(y,Q2o),e(y,Bp),e(Bp,Qie),e(Qie,W2o),e(Bp,H2o),e(Bp,dq),e(dq,U2o),e(Bp,J2o),e(y,Y2o),e(y,Ip),e(Ip,Wie),e(Wie,K2o),e(Ip,Z2o),e(Ip,cq),e(cq,ebo),e(Ip,obo),e(y,rbo),e(y,Np),e(Np,Hie),e(Hie,tbo),e(Np,abo),e(Np,fq),e(fq,nbo),e(Np,sbo),e(y,lbo),e(y,qp),e(qp,Uie),e(Uie,ibo),e(qp,dbo),e(qp,mq),e(mq,cbo),e(qp,fbo),e(y,mbo),e(y,jp),e(jp,Jie),e(Jie,gbo),e(jp,hbo),e(jp,gq),e(gq,pbo),e(jp,_bo),e(y,ubo),e(y,Dp),e(Dp,Yie),e(Yie,bbo),e(Dp,vbo),e(Dp,hq),e(hq,Fbo),e(Dp,Tbo),e(y,Mbo),e(y,Gp),e(Gp,Kie),e(Kie,Ebo),e(Gp,Cbo),e(Gp,pq),e(pq,wbo),e(Gp,Abo),e(y,Lbo),e(y,Op),e(Op,Zie),e(Zie,ybo),e(Op,xbo),e(Op,_q),e(_q,$bo),e(Op,kbo),e(y,Sbo),e(y,Vp),e(Vp,ede),e(ede,Rbo),e(Vp,Pbo),e(Vp,uq),e(uq,Bbo),e(Vp,Ibo),e(y,Nbo),e(y,Xp),e(Xp,ode),e(ode,qbo),e(Xp,jbo),e(Xp,bq),e(bq,Dbo),e(Xp,Gbo),e(y,Obo),e(y,zp),e(zp,rde),e(rde,Vbo),e(zp,Xbo),e(zp,vq),e(vq,zbo),e(zp,Qbo),e(y,Wbo),e(y,Qp),e(Qp,tde),e(tde,Hbo),e(Qp,Ubo),e(Qp,Fq),e(Fq,Jbo),e(Qp,Ybo),e(y,Kbo),e(y,Wp),e(Wp,ade),e(ade,Zbo),e(Wp,evo),e(Wp,Tq),e(Tq,ovo),e(Wp,rvo),e(y,tvo),e(y,Hp),e(Hp,nde),e(nde,avo),e(Hp,nvo),e(Hp,Mq),e(Mq,svo),e(Hp,lvo),e(y,ivo),e(y,Up),e(Up,sde),e(sde,dvo),e(Up,cvo),e(Up,Eq),e(Eq,fvo),e(Up,mvo),e(y,gvo),e(y,Jp),e(Jp,lde),e(lde,hvo),e(Jp,pvo),e(Jp,Cq),e(Cq,_vo),e(Jp,uvo),e(y,bvo),e(y,Yp),e(Yp,ide),e(ide,vvo),e(Yp,Fvo),e(Yp,wq),e(wq,Tvo),e(Yp,Mvo),e(y,Evo),e(y,Kp),e(Kp,dde),e(dde,Cvo),e(Kp,wvo),e(Kp,Aq),e(Aq,Avo),e(Kp,Lvo),e(y,yvo),e(y,Zp),e(Zp,cde),e(cde,xvo),e(Zp,$vo),e(Zp,Lq),e(Lq,kvo),e(Zp,Svo),e(y,Rvo),e(y,e_),e(e_,fde),e(fde,Pvo),e(e_,Bvo),e(e_,yq),e(yq,Ivo),e(e_,Nvo),e(y,qvo),e(y,o_),e(o_,mde),e(mde,jvo),e(o_,Dvo),e(o_,xq),e(xq,Gvo),e(o_,Ovo),e(y,Vvo),e(y,r_),e(r_,gde),e(gde,Xvo),e(r_,zvo),e(r_,$q),e($q,Qvo),e(r_,Wvo),e(y,Hvo),e(y,t_),e(t_,hde),e(hde,Uvo),e(t_,Jvo),e(t_,kq),e(kq,Yvo),e(t_,Kvo),e(y,Zvo),e(y,a_),e(a_,pde),e(pde,eFo),e(a_,oFo),e(a_,Sq),e(Sq,rFo),e(a_,tFo),e(y,aFo),e(y,n_),e(n_,_de),e(_de,nFo),e(n_,sFo),e(n_,Rq),e(Rq,lFo),e(n_,iFo),e(y,dFo),e(y,s_),e(s_,ude),e(ude,cFo),e(s_,fFo),e(s_,Pq),e(Pq,mFo),e(s_,gFo),e(y,hFo),e(y,l_),e(l_,bde),e(bde,pFo),e(l_,_Fo),e(l_,Bq),e(Bq,uFo),e(l_,bFo),e(y,vFo),e(y,i_),e(i_,vde),e(vde,FFo),e(i_,TFo),e(i_,Iq),e(Iq,MFo),e(i_,EFo),e(y,CFo),e(y,Vs),e(Vs,Fde),e(Fde,wFo),e(Vs,AFo),e(Vs,Nq),e(Nq,LFo),e(Vs,yFo),e(Vs,qq),e(qq,xFo),e(Vs,$Fo),e(y,kFo),e(y,d_),e(d_,Tde),e(Tde,SFo),e(d_,RFo),e(d_,jq),e(jq,PFo),e(d_,BFo),e(y,IFo),e(y,c_),e(c_,Mde),e(Mde,NFo),e(c_,qFo),e(c_,Dq),e(Dq,jFo),e(c_,DFo),e(y,GFo),e(y,f_),e(f_,Ede),e(Ede,OFo),e(f_,VFo),e(f_,Gq),e(Gq,XFo),e(f_,zFo),e(y,QFo),e(y,m_),e(m_,Cde),e(Cde,WFo),e(m_,HFo),e(m_,Oq),e(Oq,UFo),e(m_,JFo),e(y,YFo),e(y,g_),e(g_,wde),e(wde,KFo),e(g_,ZFo),e(g_,Vq),e(Vq,e6o),e(g_,o6o),e(y,r6o),e(y,h_),e(h_,Ade),e(Ade,t6o),e(h_,a6o),e(h_,Xq),e(Xq,n6o),e(h_,s6o),e(y,l6o),e(y,p_),e(p_,Lde),e(Lde,i6o),e(p_,d6o),e(p_,zq),e(zq,c6o),e(p_,f6o),e(y,m6o),e(y,__),e(__,yde),e(yde,g6o),e(__,h6o),e(__,Qq),e(Qq,p6o),e(__,_6o),e(y,u6o),e(y,u_),e(u_,xde),e(xde,b6o),e(u_,v6o),e(u_,Wq),e(Wq,F6o),e(u_,T6o),e(y,M6o),e(y,b_),e(b_,$de),e($de,E6o),e(b_,C6o),e(b_,Hq),e(Hq,w6o),e(b_,A6o),e(y,L6o),e(y,v_),e(v_,kde),e(kde,y6o),e(v_,x6o),e(v_,Uq),e(Uq,$6o),e(v_,k6o),e(y,S6o),e(y,F_),e(F_,Sde),e(Sde,R6o),e(F_,P6o),e(F_,Jq),e(Jq,B6o),e(F_,I6o),e(y,N6o),e(y,T_),e(T_,Rde),e(Rde,q6o),e(T_,j6o),e(T_,Yq),e(Yq,D6o),e(T_,G6o),e(y,O6o),e(y,M_),e(M_,Pde),e(Pde,V6o),e(M_,X6o),e(M_,Kq),e(Kq,z6o),e(M_,Q6o),e(y,W6o),e(y,E_),e(E_,Bde),e(Bde,H6o),e(E_,U6o),e(E_,Zq),e(Zq,J6o),e(E_,Y6o),e(y,K6o),e(y,C_),e(C_,Ide),e(Ide,Z6o),e(C_,eTo),e(C_,ej),e(ej,oTo),e(C_,rTo),e(y,tTo),e(y,w_),e(w_,Nde),e(Nde,aTo),e(w_,nTo),e(w_,oj),e(oj,sTo),e(w_,lTo),e(y,iTo),e(y,A_),e(A_,qde),e(qde,dTo),e(A_,cTo),e(A_,rj),e(rj,fTo),e(A_,mTo),e(y,gTo),e(y,L_),e(L_,jde),e(jde,hTo),e(L_,pTo),e(L_,tj),e(tj,_To),e(L_,uTo),e(y,bTo),e(y,y_),e(y_,Dde),e(Dde,vTo),e(y_,FTo),e(y_,aj),e(aj,TTo),e(y_,MTo),e(y,ETo),e(y,x_),e(x_,Gde),e(Gde,CTo),e(x_,wTo),e(x_,nj),e(nj,ATo),e(x_,LTo),e(y,yTo),e(y,$_),e($_,Ode),e(Ode,xTo),e($_,$To),e($_,sj),e(sj,kTo),e($_,STo),e(y,RTo),e(y,k_),e(k_,Vde),e(Vde,PTo),e(k_,BTo),e(k_,lj),e(lj,ITo),e(k_,NTo),e(y,qTo),e(y,S_),e(S_,Xde),e(Xde,jTo),e(S_,DTo),e(S_,ij),e(ij,GTo),e(S_,OTo),e(y,VTo),e(y,R_),e(R_,zde),e(zde,XTo),e(R_,zTo),e(R_,dj),e(dj,QTo),e(R_,WTo),e(y,HTo),e(y,P_),e(P_,Qde),e(Qde,UTo),e(P_,JTo),e(P_,cj),e(cj,YTo),e(P_,KTo),e(y,ZTo),e(y,B_),e(B_,Wde),e(Wde,eMo),e(B_,oMo),e(B_,fj),e(fj,rMo),e(B_,tMo),e(y,aMo),e(y,I_),e(I_,Hde),e(Hde,nMo),e(I_,sMo),e(I_,mj),e(mj,lMo),e(I_,iMo),e(y,dMo),e(y,N_),e(N_,Ude),e(Ude,cMo),e(N_,fMo),e(N_,gj),e(gj,mMo),e(N_,gMo),e(y,hMo),e(y,q_),e(q_,Jde),e(Jde,pMo),e(q_,_Mo),e(q_,hj),e(hj,uMo),e(q_,bMo),e(y,vMo),e(y,j_),e(j_,Yde),e(Yde,FMo),e(j_,TMo),e(j_,pj),e(pj,MMo),e(j_,EMo),e(y,CMo),e(y,D_),e(D_,Kde),e(Kde,wMo),e(D_,AMo),e(D_,_j),e(_j,LMo),e(D_,yMo),e(y,xMo),e(y,G_),e(G_,Zde),e(Zde,$Mo),e(G_,kMo),e(G_,uj),e(uj,SMo),e(G_,RMo),e(y,PMo),e(y,O_),e(O_,ece),e(ece,BMo),e(O_,IMo),e(O_,bj),e(bj,NMo),e(O_,qMo),e(y,jMo),e(y,V_),e(V_,oce),e(oce,DMo),e(V_,GMo),e(V_,vj),e(vj,OMo),e(V_,VMo),e(y,XMo),e(y,X_),e(X_,rce),e(rce,zMo),e(X_,QMo),e(X_,Fj),e(Fj,WMo),e(X_,HMo),e(y,UMo),e(y,z_),e(z_,tce),e(tce,JMo),e(z_,YMo),e(z_,Tj),e(Tj,KMo),e(z_,ZMo),e(y,eEo),e(y,Q_),e(Q_,ace),e(ace,oEo),e(Q_,rEo),e(Q_,Mj),e(Mj,tEo),e(Q_,aEo),e(y,nEo),e(y,W_),e(W_,nce),e(nce,sEo),e(W_,lEo),e(W_,Ej),e(Ej,iEo),e(W_,dEo),e(y,cEo),e(y,H_),e(H_,sce),e(sce,fEo),e(H_,mEo),e(H_,Cj),e(Cj,gEo),e(H_,hEo),e(y,pEo),e(y,U_),e(U_,lce),e(lce,_Eo),e(U_,uEo),e(U_,wj),e(wj,bEo),e(U_,vEo),e(y,FEo),e(y,J_),e(J_,ice),e(ice,TEo),e(J_,MEo),e(J_,Aj),e(Aj,EEo),e(J_,CEo),e(y,wEo),e(y,Y_),e(Y_,dce),e(dce,AEo),e(Y_,LEo),e(Y_,Lj),e(Lj,yEo),e(Y_,xEo),e(y,$Eo),e(y,K_),e(K_,cce),e(cce,kEo),e(K_,SEo),e(K_,yj),e(yj,REo),e(K_,PEo),e(y,BEo),e(y,Z_),e(Z_,fce),e(fce,IEo),e(Z_,NEo),e(Z_,xj),e(xj,qEo),e(Z_,jEo),e(y,DEo),e(y,eu),e(eu,mce),e(mce,GEo),e(eu,OEo),e(eu,$j),e($j,VEo),e(eu,XEo),e(y,zEo),e(y,ou),e(ou,gce),e(gce,QEo),e(ou,WEo),e(ou,kj),e(kj,HEo),e(ou,UEo),e(y,JEo),e(y,ru),e(ru,hce),e(hce,YEo),e(ru,KEo),e(ru,Sj),e(Sj,ZEo),e(ru,e4o),e(y,o4o),e(y,tu),e(tu,pce),e(pce,r4o),e(tu,t4o),e(tu,Rj),e(Rj,a4o),e(tu,n4o),e(y,s4o),e(y,au),e(au,_ce),e(_ce,l4o),e(au,i4o),e(au,Pj),e(Pj,d4o),e(au,c4o),e(y,f4o),e(y,nu),e(nu,uce),e(uce,m4o),e(nu,g4o),e(nu,Bj),e(Bj,h4o),e(nu,p4o),e(y,_4o),e(y,su),e(su,bce),e(bce,u4o),e(su,b4o),e(su,Ij),e(Ij,v4o),e(su,F4o),e(y,T4o),e(y,lu),e(lu,vce),e(vce,M4o),e(lu,E4o),e(lu,Nj),e(Nj,C4o),e(lu,w4o),e(y,A4o),e(y,iu),e(iu,Fce),e(Fce,L4o),e(iu,y4o),e(iu,qj),e(qj,x4o),e(iu,$4o),e(y,k4o),e(y,du),e(du,Tce),e(Tce,S4o),e(du,R4o),e(du,jj),e(jj,P4o),e(du,B4o),e(y,I4o),e(y,cu),e(cu,Mce),e(Mce,N4o),e(cu,q4o),e(cu,Dj),e(Dj,j4o),e(cu,D4o),e(y,G4o),e(y,fu),e(fu,Ece),e(Ece,O4o),e(fu,V4o),e(fu,Gj),e(Gj,X4o),e(fu,z4o),e(y,Q4o),e(y,mu),e(mu,Cce),e(Cce,W4o),e(mu,H4o),e(mu,Oj),e(Oj,U4o),e(mu,J4o),e(y,Y4o),e(y,gu),e(gu,wce),e(wce,K4o),e(gu,Z4o),e(gu,Vj),e(Vj,eCo),e(gu,oCo),e(y,rCo),e(y,hu),e(hu,Ace),e(Ace,tCo),e(hu,aCo),e(hu,Xj),e(Xj,nCo),e(hu,sCo),e(y,lCo),e(y,pu),e(pu,Lce),e(Lce,iCo),e(pu,dCo),e(pu,zj),e(zj,cCo),e(pu,fCo),e(y,mCo),e(y,_u),e(_u,yce),e(yce,gCo),e(_u,hCo),e(_u,Qj),e(Qj,pCo),e(_u,_Co),e(y,uCo),e(y,uu),e(uu,xce),e(xce,bCo),e(uu,vCo),e(uu,Wj),e(Wj,FCo),e(uu,TCo),e(y,MCo),e(y,bu),e(bu,$ce),e($ce,ECo),e(bu,CCo),e(bu,Hj),e(Hj,wCo),e(bu,ACo),e(y,LCo),e(y,vu),e(vu,kce),e(kce,yCo),e(vu,xCo),e(vu,Uj),e(Uj,$Co),e(vu,kCo),e(y,SCo),e(y,Fu),e(Fu,Sce),e(Sce,RCo),e(Fu,PCo),e(Fu,Jj),e(Jj,BCo),e(Fu,ICo),e(y,NCo),e(y,Tu),e(Tu,Rce),e(Rce,qCo),e(Tu,jCo),e(Tu,Yj),e(Yj,DCo),e(Tu,GCo),e(y,OCo),e(y,Mu),e(Mu,Pce),e(Pce,VCo),e(Mu,XCo),e(Mu,Kj),e(Kj,zCo),e(Mu,QCo),e(y,WCo),e(y,Eu),e(Eu,Bce),e(Bce,HCo),e(Eu,UCo),e(Eu,Zj),e(Zj,JCo),e(Eu,YCo),e(y,KCo),e(y,Cu),e(Cu,Ice),e(Ice,ZCo),e(Cu,e5o),e(Cu,eD),e(eD,o5o),e(Cu,r5o),e(y,t5o),e(y,wu),e(wu,Nce),e(Nce,a5o),e(wu,n5o),e(wu,oD),e(oD,s5o),e(wu,l5o),e(y,i5o),e(y,Au),e(Au,qce),e(qce,d5o),e(Au,c5o),e(Au,rD),e(rD,f5o),e(Au,m5o),e(y,g5o),e(y,Lu),e(Lu,jce),e(jce,h5o),e(Lu,p5o),e(Lu,tD),e(tD,_5o),e(Lu,u5o),e(Je,b5o),e(Je,yu),e(yu,v5o),e(yu,Dce),e(Dce,F5o),e(yu,T5o),e(yu,Gce),e(Gce,M5o),e(Je,E5o),M(xu,Je,null),b(f,eOe,u),b(f,qi,u),e(qi,$u),e($u,Oce),M(sy,Oce,null),e(qi,C5o),e(qi,Vce),e(Vce,w5o),b(f,oOe,u),b(f,$o,u),M(ly,$o,null),e($o,A5o),e($o,ji),e(ji,L5o),e(ji,aD),e(aD,y5o),e(ji,x5o),e(ji,nD),e(nD,$5o),e(ji,k5o),e($o,S5o),e($o,iy),e(iy,R5o),e(iy,Xce),e(Xce,P5o),e(iy,B5o),e($o,I5o),e($o,st),M(dy,st,null),e(st,N5o),e(st,zce),e(zce,q5o),e(st,j5o),e(st,Di),e(Di,D5o),e(Di,Qce),e(Qce,G5o),e(Di,O5o),e(Di,sD),e(sD,V5o),e(Di,X5o),e(st,z5o),M(ku,st,null),e($o,Q5o),e($o,Ye),M(cy,Ye,null),e(Ye,W5o),e(Ye,Wce),e(Wce,H5o),e(Ye,U5o),e(Ye,Pa),e(Pa,J5o),e(Pa,Hce),e(Hce,Y5o),e(Pa,K5o),e(Pa,Uce),e(Uce,Z5o),e(Pa,e3o),e(Pa,Jce),e(Jce,o3o),e(Pa,r3o),e(Ye,t3o),e(Ye,G),e(G,Su),e(Su,Yce),e(Yce,a3o),e(Su,n3o),e(Su,lD),e(lD,s3o),e(Su,l3o),e(G,i3o),e(G,Ru),e(Ru,Kce),e(Kce,d3o),e(Ru,c3o),e(Ru,iD),e(iD,f3o),e(Ru,m3o),e(G,g3o),e(G,Pu),e(Pu,Zce),e(Zce,h3o),e(Pu,p3o),e(Pu,dD),e(dD,_3o),e(Pu,u3o),e(G,b3o),e(G,Bu),e(Bu,efe),e(efe,v3o),e(Bu,F3o),e(Bu,cD),e(cD,T3o),e(Bu,M3o),e(G,E3o),e(G,Iu),e(Iu,ofe),e(ofe,C3o),e(Iu,w3o),e(Iu,fD),e(fD,A3o),e(Iu,L3o),e(G,y3o),e(G,Nu),e(Nu,rfe),e(rfe,x3o),e(Nu,$3o),e(Nu,mD),e(mD,k3o),e(Nu,S3o),e(G,R3o),e(G,qu),e(qu,tfe),e(tfe,P3o),e(qu,B3o),e(qu,gD),e(gD,I3o),e(qu,N3o),e(G,q3o),e(G,ju),e(ju,afe),e(afe,j3o),e(ju,D3o),e(ju,hD),e(hD,G3o),e(ju,O3o),e(G,V3o),e(G,Du),e(Du,nfe),e(nfe,X3o),e(Du,z3o),e(Du,pD),e(pD,Q3o),e(Du,W3o),e(G,H3o),e(G,Gu),e(Gu,sfe),e(sfe,U3o),e(Gu,J3o),e(Gu,_D),e(_D,Y3o),e(Gu,K3o),e(G,Z3o),e(G,Ou),e(Ou,lfe),e(lfe,e0o),e(Ou,o0o),e(Ou,uD),e(uD,r0o),e(Ou,t0o),e(G,a0o),e(G,Vu),e(Vu,ife),e(ife,n0o),e(Vu,s0o),e(Vu,bD),e(bD,l0o),e(Vu,i0o),e(G,d0o),e(G,Xu),e(Xu,dfe),e(dfe,c0o),e(Xu,f0o),e(Xu,vD),e(vD,m0o),e(Xu,g0o),e(G,h0o),e(G,zu),e(zu,cfe),e(cfe,p0o),e(zu,_0o),e(zu,FD),e(FD,u0o),e(zu,b0o),e(G,v0o),e(G,Qu),e(Qu,ffe),e(ffe,F0o),e(Qu,T0o),e(Qu,TD),e(TD,M0o),e(Qu,E0o),e(G,C0o),e(G,Wu),e(Wu,mfe),e(mfe,w0o),e(Wu,A0o),e(Wu,MD),e(MD,L0o),e(Wu,y0o),e(G,x0o),e(G,Hu),e(Hu,gfe),e(gfe,$0o),e(Hu,k0o),e(Hu,ED),e(ED,S0o),e(Hu,R0o),e(G,P0o),e(G,Uu),e(Uu,hfe),e(hfe,B0o),e(Uu,I0o),e(Uu,CD),e(CD,N0o),e(Uu,q0o),e(G,j0o),e(G,Ju),e(Ju,pfe),e(pfe,D0o),e(Ju,G0o),e(Ju,wD),e(wD,O0o),e(Ju,V0o),e(G,X0o),e(G,Yu),e(Yu,_fe),e(_fe,z0o),e(Yu,Q0o),e(Yu,AD),e(AD,W0o),e(Yu,H0o),e(G,U0o),e(G,Ku),e(Ku,ufe),e(ufe,J0o),e(Ku,Y0o),e(Ku,LD),e(LD,K0o),e(Ku,Z0o),e(G,ewo),e(G,Zu),e(Zu,bfe),e(bfe,owo),e(Zu,rwo),e(Zu,yD),e(yD,two),e(Zu,awo),e(G,nwo),e(G,e7),e(e7,vfe),e(vfe,swo),e(e7,lwo),e(e7,xD),e(xD,iwo),e(e7,dwo),e(G,cwo),e(G,o7),e(o7,Ffe),e(Ffe,fwo),e(o7,mwo),e(o7,$D),e($D,gwo),e(o7,hwo),e(G,pwo),e(G,r7),e(r7,Tfe),e(Tfe,_wo),e(r7,uwo),e(r7,kD),e(kD,bwo),e(r7,vwo),e(G,Fwo),e(G,t7),e(t7,Mfe),e(Mfe,Two),e(t7,Mwo),e(t7,SD),e(SD,Ewo),e(t7,Cwo),e(G,wwo),e(G,a7),e(a7,Efe),e(Efe,Awo),e(a7,Lwo),e(a7,RD),e(RD,ywo),e(a7,xwo),e(G,$wo),e(G,n7),e(n7,Cfe),e(Cfe,kwo),e(n7,Swo),e(n7,PD),e(PD,Rwo),e(n7,Pwo),e(G,Bwo),e(G,s7),e(s7,wfe),e(wfe,Iwo),e(s7,Nwo),e(s7,BD),e(BD,qwo),e(s7,jwo),e(G,Dwo),e(G,l7),e(l7,Afe),e(Afe,Gwo),e(l7,Owo),e(l7,ID),e(ID,Vwo),e(l7,Xwo),e(G,zwo),e(G,i7),e(i7,Lfe),e(Lfe,Qwo),e(i7,Wwo),e(i7,ND),e(ND,Hwo),e(i7,Uwo),e(G,Jwo),e(G,d7),e(d7,yfe),e(yfe,Ywo),e(d7,Kwo),e(d7,qD),e(qD,Zwo),e(d7,eAo),e(G,oAo),e(G,c7),e(c7,xfe),e(xfe,rAo),e(c7,tAo),e(c7,jD),e(jD,aAo),e(c7,nAo),e(G,sAo),e(G,f7),e(f7,$fe),e($fe,lAo),e(f7,iAo),e(f7,DD),e(DD,dAo),e(f7,cAo),e(G,fAo),e(G,m7),e(m7,kfe),e(kfe,mAo),e(m7,gAo),e(m7,GD),e(GD,hAo),e(m7,pAo),e(G,_Ao),e(G,g7),e(g7,Sfe),e(Sfe,uAo),e(g7,bAo),e(g7,OD),e(OD,vAo),e(g7,FAo),e(G,TAo),e(G,h7),e(h7,Rfe),e(Rfe,MAo),e(h7,EAo),e(h7,VD),e(VD,CAo),e(h7,wAo),e(G,AAo),e(G,p7),e(p7,Pfe),e(Pfe,LAo),e(p7,yAo),e(p7,XD),e(XD,xAo),e(p7,$Ao),e(G,kAo),e(G,_7),e(_7,Bfe),e(Bfe,SAo),e(_7,RAo),e(_7,zD),e(zD,PAo),e(_7,BAo),e(G,IAo),e(G,u7),e(u7,Ife),e(Ife,NAo),e(u7,qAo),e(u7,QD),e(QD,jAo),e(u7,DAo),e(G,GAo),e(G,b7),e(b7,Nfe),e(Nfe,OAo),e(b7,VAo),e(b7,WD),e(WD,XAo),e(b7,zAo),e(G,QAo),e(G,v7),e(v7,qfe),e(qfe,WAo),e(v7,HAo),e(v7,HD),e(HD,UAo),e(v7,JAo),e(G,YAo),e(G,F7),e(F7,jfe),e(jfe,KAo),e(F7,ZAo),e(F7,UD),e(UD,eLo),e(F7,oLo),e(G,rLo),e(G,T7),e(T7,Dfe),e(Dfe,tLo),e(T7,aLo),e(T7,JD),e(JD,nLo),e(T7,sLo),e(Ye,lLo),e(Ye,M7),e(M7,iLo),e(M7,Gfe),e(Gfe,dLo),e(M7,cLo),e(M7,Ofe),e(Ofe,fLo),e(Ye,mLo),M(E7,Ye,null),b(f,rOe,u),b(f,Gi,u),e(Gi,C7),e(C7,Vfe),M(fy,Vfe,null),e(Gi,gLo),e(Gi,Xfe),e(Xfe,hLo),b(f,tOe,u),b(f,ko,u),M(my,ko,null),e(ko,pLo),e(ko,Oi),e(Oi,_Lo),e(Oi,YD),e(YD,uLo),e(Oi,bLo),e(Oi,KD),e(KD,vLo),e(Oi,FLo),e(ko,TLo),e(ko,gy),e(gy,MLo),e(gy,zfe),e(zfe,ELo),e(gy,CLo),e(ko,wLo),e(ko,lt),M(hy,lt,null),e(lt,ALo),e(lt,Qfe),e(Qfe,LLo),e(lt,yLo),e(lt,Vi),e(Vi,xLo),e(Vi,Wfe),e(Wfe,$Lo),e(Vi,kLo),e(Vi,ZD),e(ZD,SLo),e(Vi,RLo),e(lt,PLo),M(w7,lt,null),e(ko,BLo),e(ko,Ke),M(py,Ke,null),e(Ke,ILo),e(Ke,Hfe),e(Hfe,NLo),e(Ke,qLo),e(Ke,Ba),e(Ba,jLo),e(Ba,Ufe),e(Ufe,DLo),e(Ba,GLo),e(Ba,Jfe),e(Jfe,OLo),e(Ba,VLo),e(Ba,Yfe),e(Yfe,XLo),e(Ba,zLo),e(Ke,QLo),e(Ke,z),e(z,A7),e(A7,Kfe),e(Kfe,WLo),e(A7,HLo),e(A7,eG),e(eG,ULo),e(A7,JLo),e(z,YLo),e(z,L7),e(L7,Zfe),e(Zfe,KLo),e(L7,ZLo),e(L7,oG),e(oG,eyo),e(L7,oyo),e(z,ryo),e(z,y7),e(y7,eme),e(eme,tyo),e(y7,ayo),e(y7,rG),e(rG,nyo),e(y7,syo),e(z,lyo),e(z,x7),e(x7,ome),e(ome,iyo),e(x7,dyo),e(x7,tG),e(tG,cyo),e(x7,fyo),e(z,myo),e(z,$7),e($7,rme),e(rme,gyo),e($7,hyo),e($7,aG),e(aG,pyo),e($7,_yo),e(z,uyo),e(z,k7),e(k7,tme),e(tme,byo),e(k7,vyo),e(k7,nG),e(nG,Fyo),e(k7,Tyo),e(z,Myo),e(z,S7),e(S7,ame),e(ame,Eyo),e(S7,Cyo),e(S7,sG),e(sG,wyo),e(S7,Ayo),e(z,Lyo),e(z,R7),e(R7,nme),e(nme,yyo),e(R7,xyo),e(R7,lG),e(lG,$yo),e(R7,kyo),e(z,Syo),e(z,P7),e(P7,sme),e(sme,Ryo),e(P7,Pyo),e(P7,iG),e(iG,Byo),e(P7,Iyo),e(z,Nyo),e(z,B7),e(B7,lme),e(lme,qyo),e(B7,jyo),e(B7,dG),e(dG,Dyo),e(B7,Gyo),e(z,Oyo),e(z,I7),e(I7,ime),e(ime,Vyo),e(I7,Xyo),e(I7,cG),e(cG,zyo),e(I7,Qyo),e(z,Wyo),e(z,N7),e(N7,dme),e(dme,Hyo),e(N7,Uyo),e(N7,fG),e(fG,Jyo),e(N7,Yyo),e(z,Kyo),e(z,q7),e(q7,cme),e(cme,Zyo),e(q7,e8o),e(q7,mG),e(mG,o8o),e(q7,r8o),e(z,t8o),e(z,j7),e(j7,fme),e(fme,a8o),e(j7,n8o),e(j7,gG),e(gG,s8o),e(j7,l8o),e(z,i8o),e(z,D7),e(D7,mme),e(mme,d8o),e(D7,c8o),e(D7,hG),e(hG,f8o),e(D7,m8o),e(z,g8o),e(z,G7),e(G7,gme),e(gme,h8o),e(G7,p8o),e(G7,pG),e(pG,_8o),e(G7,u8o),e(z,b8o),e(z,O7),e(O7,hme),e(hme,v8o),e(O7,F8o),e(O7,_G),e(_G,T8o),e(O7,M8o),e(z,E8o),e(z,V7),e(V7,pme),e(pme,C8o),e(V7,w8o),e(V7,uG),e(uG,A8o),e(V7,L8o),e(z,y8o),e(z,X7),e(X7,_me),e(_me,x8o),e(X7,$8o),e(X7,bG),e(bG,k8o),e(X7,S8o),e(z,R8o),e(z,z7),e(z7,ume),e(ume,P8o),e(z7,B8o),e(z7,vG),e(vG,I8o),e(z7,N8o),e(z,q8o),e(z,Q7),e(Q7,bme),e(bme,j8o),e(Q7,D8o),e(Q7,FG),e(FG,G8o),e(Q7,O8o),e(z,V8o),e(z,W7),e(W7,vme),e(vme,X8o),e(W7,z8o),e(W7,TG),e(TG,Q8o),e(W7,W8o),e(z,H8o),e(z,H7),e(H7,Fme),e(Fme,U8o),e(H7,J8o),e(H7,MG),e(MG,Y8o),e(H7,K8o),e(z,Z8o),e(z,U7),e(U7,Tme),e(Tme,e9o),e(U7,o9o),e(U7,EG),e(EG,r9o),e(U7,t9o),e(z,a9o),e(z,J7),e(J7,Mme),e(Mme,n9o),e(J7,s9o),e(J7,CG),e(CG,l9o),e(J7,i9o),e(z,d9o),e(z,Y7),e(Y7,Eme),e(Eme,c9o),e(Y7,f9o),e(Y7,wG),e(wG,m9o),e(Y7,g9o),e(z,h9o),e(z,K7),e(K7,Cme),e(Cme,p9o),e(K7,_9o),e(K7,AG),e(AG,u9o),e(K7,b9o),e(z,v9o),e(z,Z7),e(Z7,wme),e(wme,F9o),e(Z7,T9o),e(Z7,LG),e(LG,M9o),e(Z7,E9o),e(z,C9o),e(z,e1),e(e1,Ame),e(Ame,w9o),e(e1,A9o),e(e1,yG),e(yG,L9o),e(e1,y9o),e(z,x9o),e(z,o1),e(o1,Lme),e(Lme,$9o),e(o1,k9o),e(o1,xG),e(xG,S9o),e(o1,R9o),e(z,P9o),e(z,r1),e(r1,yme),e(yme,B9o),e(r1,I9o),e(r1,$G),e($G,N9o),e(r1,q9o),e(z,j9o),e(z,t1),e(t1,xme),e(xme,D9o),e(t1,G9o),e(t1,kG),e(kG,O9o),e(t1,V9o),e(z,X9o),e(z,a1),e(a1,$me),e($me,z9o),e(a1,Q9o),e(a1,SG),e(SG,W9o),e(a1,H9o),e(z,U9o),e(z,n1),e(n1,kme),e(kme,J9o),e(n1,Y9o),e(n1,RG),e(RG,K9o),e(n1,Z9o),e(z,exo),e(z,s1),e(s1,Sme),e(Sme,oxo),e(s1,rxo),e(s1,PG),e(PG,txo),e(s1,axo),e(z,nxo),e(z,l1),e(l1,Rme),e(Rme,sxo),e(l1,lxo),e(l1,BG),e(BG,ixo),e(l1,dxo),e(z,cxo),e(z,i1),e(i1,Pme),e(Pme,fxo),e(i1,mxo),e(i1,IG),e(IG,gxo),e(i1,hxo),e(z,pxo),e(z,d1),e(d1,Bme),e(Bme,_xo),e(d1,uxo),e(d1,NG),e(NG,bxo),e(d1,vxo),e(Ke,Fxo),e(Ke,c1),e(c1,Txo),e(c1,Ime),e(Ime,Mxo),e(c1,Exo),e(c1,Nme),e(Nme,Cxo),e(Ke,wxo),M(f1,Ke,null),b(f,aOe,u),b(f,Xi,u),e(Xi,m1),e(m1,qme),M(_y,qme,null),e(Xi,Axo),e(Xi,jme),e(jme,Lxo),b(f,nOe,u),b(f,So,u),M(uy,So,null),e(So,yxo),e(So,zi),e(zi,xxo),e(zi,qG),e(qG,$xo),e(zi,kxo),e(zi,jG),e(jG,Sxo),e(zi,Rxo),e(So,Pxo),e(So,by),e(by,Bxo),e(by,Dme),e(Dme,Ixo),e(by,Nxo),e(So,qxo),e(So,it),M(vy,it,null),e(it,jxo),e(it,Gme),e(Gme,Dxo),e(it,Gxo),e(it,Qi),e(Qi,Oxo),e(Qi,Ome),e(Ome,Vxo),e(Qi,Xxo),e(Qi,DG),e(DG,zxo),e(Qi,Qxo),e(it,Wxo),M(g1,it,null),e(So,Hxo),e(So,Ze),M(Fy,Ze,null),e(Ze,Uxo),e(Ze,Vme),e(Vme,Jxo),e(Ze,Yxo),e(Ze,Ia),e(Ia,Kxo),e(Ia,Xme),e(Xme,Zxo),e(Ia,e$o),e(Ia,zme),e(zme,o$o),e(Ia,r$o),e(Ia,Qme),e(Qme,t$o),e(Ia,a$o),e(Ze,n$o),e(Ze,Q),e(Q,h1),e(h1,Wme),e(Wme,s$o),e(h1,l$o),e(h1,GG),e(GG,i$o),e(h1,d$o),e(Q,c$o),e(Q,p1),e(p1,Hme),e(Hme,f$o),e(p1,m$o),e(p1,OG),e(OG,g$o),e(p1,h$o),e(Q,p$o),e(Q,_1),e(_1,Ume),e(Ume,_$o),e(_1,u$o),e(_1,VG),e(VG,b$o),e(_1,v$o),e(Q,F$o),e(Q,u1),e(u1,Jme),e(Jme,T$o),e(u1,M$o),e(u1,XG),e(XG,E$o),e(u1,C$o),e(Q,w$o),e(Q,b1),e(b1,Yme),e(Yme,A$o),e(b1,L$o),e(b1,zG),e(zG,y$o),e(b1,x$o),e(Q,$$o),e(Q,v1),e(v1,Kme),e(Kme,k$o),e(v1,S$o),e(v1,QG),e(QG,R$o),e(v1,P$o),e(Q,B$o),e(Q,F1),e(F1,Zme),e(Zme,I$o),e(F1,N$o),e(F1,WG),e(WG,q$o),e(F1,j$o),e(Q,D$o),e(Q,T1),e(T1,ege),e(ege,G$o),e(T1,O$o),e(T1,HG),e(HG,V$o),e(T1,X$o),e(Q,z$o),e(Q,M1),e(M1,oge),e(oge,Q$o),e(M1,W$o),e(M1,UG),e(UG,H$o),e(M1,U$o),e(Q,J$o),e(Q,E1),e(E1,rge),e(rge,Y$o),e(E1,K$o),e(E1,JG),e(JG,Z$o),e(E1,eko),e(Q,oko),e(Q,C1),e(C1,tge),e(tge,rko),e(C1,tko),e(C1,YG),e(YG,ako),e(C1,nko),e(Q,sko),e(Q,w1),e(w1,age),e(age,lko),e(w1,iko),e(w1,KG),e(KG,dko),e(w1,cko),e(Q,fko),e(Q,A1),e(A1,nge),e(nge,mko),e(A1,gko),e(A1,ZG),e(ZG,hko),e(A1,pko),e(Q,_ko),e(Q,L1),e(L1,sge),e(sge,uko),e(L1,bko),e(L1,eO),e(eO,vko),e(L1,Fko),e(Q,Tko),e(Q,y1),e(y1,lge),e(lge,Mko),e(y1,Eko),e(y1,oO),e(oO,Cko),e(y1,wko),e(Q,Ako),e(Q,x1),e(x1,ige),e(ige,Lko),e(x1,yko),e(x1,rO),e(rO,xko),e(x1,$ko),e(Q,kko),e(Q,$1),e($1,dge),e(dge,Sko),e($1,Rko),e($1,tO),e(tO,Pko),e($1,Bko),e(Q,Iko),e(Q,k1),e(k1,cge),e(cge,Nko),e(k1,qko),e(k1,aO),e(aO,jko),e(k1,Dko),e(Q,Gko),e(Q,S1),e(S1,fge),e(fge,Oko),e(S1,Vko),e(S1,nO),e(nO,Xko),e(S1,zko),e(Q,Qko),e(Q,R1),e(R1,mge),e(mge,Wko),e(R1,Hko),e(R1,sO),e(sO,Uko),e(R1,Jko),e(Q,Yko),e(Q,P1),e(P1,gge),e(gge,Kko),e(P1,Zko),e(P1,lO),e(lO,eSo),e(P1,oSo),e(Q,rSo),e(Q,B1),e(B1,hge),e(hge,tSo),e(B1,aSo),e(B1,iO),e(iO,nSo),e(B1,sSo),e(Q,lSo),e(Q,I1),e(I1,pge),e(pge,iSo),e(I1,dSo),e(I1,dO),e(dO,cSo),e(I1,fSo),e(Q,mSo),e(Q,N1),e(N1,_ge),e(_ge,gSo),e(N1,hSo),e(N1,cO),e(cO,pSo),e(N1,_So),e(Q,uSo),e(Q,q1),e(q1,uge),e(uge,bSo),e(q1,vSo),e(q1,fO),e(fO,FSo),e(q1,TSo),e(Q,MSo),e(Q,j1),e(j1,bge),e(bge,ESo),e(j1,CSo),e(j1,mO),e(mO,wSo),e(j1,ASo),e(Q,LSo),e(Q,D1),e(D1,vge),e(vge,ySo),e(D1,xSo),e(D1,gO),e(gO,$So),e(D1,kSo),e(Q,SSo),e(Q,G1),e(G1,Fge),e(Fge,RSo),e(G1,PSo),e(G1,hO),e(hO,BSo),e(G1,ISo),e(Q,NSo),e(Q,O1),e(O1,Tge),e(Tge,qSo),e(O1,jSo),e(O1,pO),e(pO,DSo),e(O1,GSo),e(Q,OSo),e(Q,V1),e(V1,Mge),e(Mge,VSo),e(V1,XSo),e(V1,_O),e(_O,zSo),e(V1,QSo),e(Q,WSo),e(Q,X1),e(X1,Ege),e(Ege,HSo),e(X1,USo),e(X1,uO),e(uO,JSo),e(X1,YSo),e(Q,KSo),e(Q,z1),e(z1,Cge),e(Cge,ZSo),e(z1,eRo),e(z1,bO),e(bO,oRo),e(z1,rRo),e(Q,tRo),e(Q,Q1),e(Q1,wge),e(wge,aRo),e(Q1,nRo),e(Q1,Age),e(Age,sRo),e(Q1,lRo),e(Q,iRo),e(Q,W1),e(W1,Lge),e(Lge,dRo),e(W1,cRo),e(W1,vO),e(vO,fRo),e(W1,mRo),e(Q,gRo),e(Q,H1),e(H1,yge),e(yge,hRo),e(H1,pRo),e(H1,FO),e(FO,_Ro),e(H1,uRo),e(Q,bRo),e(Q,U1),e(U1,xge),e(xge,vRo),e(U1,FRo),e(U1,TO),e(TO,TRo),e(U1,MRo),e(Q,ERo),e(Q,J1),e(J1,$ge),e($ge,CRo),e(J1,wRo),e(J1,MO),e(MO,ARo),e(J1,LRo),e(Ze,yRo),e(Ze,Y1),e(Y1,xRo),e(Y1,kge),e(kge,$Ro),e(Y1,kRo),e(Y1,Sge),e(Sge,SRo),e(Ze,RRo),M(K1,Ze,null),b(f,sOe,u),b(f,Wi,u),e(Wi,Z1),e(Z1,Rge),M(Ty,Rge,null),e(Wi,PRo),e(Wi,Pge),e(Pge,BRo),b(f,lOe,u),b(f,Ro,u),M(My,Ro,null),e(Ro,IRo),e(Ro,Hi),e(Hi,NRo),e(Hi,EO),e(EO,qRo),e(Hi,jRo),e(Hi,CO),e(CO,DRo),e(Hi,GRo),e(Ro,ORo),e(Ro,Ey),e(Ey,VRo),e(Ey,Bge),e(Bge,XRo),e(Ey,zRo),e(Ro,QRo),e(Ro,dt),M(Cy,dt,null),e(dt,WRo),e(dt,Ige),e(Ige,HRo),e(dt,URo),e(dt,Ui),e(Ui,JRo),e(Ui,Nge),e(Nge,YRo),e(Ui,KRo),e(Ui,wO),e(wO,ZRo),e(Ui,ePo),e(dt,oPo),M(e2,dt,null),e(Ro,rPo),e(Ro,eo),M(wy,eo,null),e(eo,tPo),e(eo,qge),e(qge,aPo),e(eo,nPo),e(eo,Na),e(Na,sPo),e(Na,jge),e(jge,lPo),e(Na,iPo),e(Na,Dge),e(Dge,dPo),e(Na,cPo),e(Na,Gge),e(Gge,fPo),e(Na,mPo),e(eo,gPo),e(eo,pe),e(pe,o2),e(o2,Oge),e(Oge,hPo),e(o2,pPo),e(o2,AO),e(AO,_Po),e(o2,uPo),e(pe,bPo),e(pe,r2),e(r2,Vge),e(Vge,vPo),e(r2,FPo),e(r2,LO),e(LO,TPo),e(r2,MPo),e(pe,EPo),e(pe,t2),e(t2,Xge),e(Xge,CPo),e(t2,wPo),e(t2,yO),e(yO,APo),e(t2,LPo),e(pe,yPo),e(pe,a2),e(a2,zge),e(zge,xPo),e(a2,$Po),e(a2,xO),e(xO,kPo),e(a2,SPo),e(pe,RPo),e(pe,n2),e(n2,Qge),e(Qge,PPo),e(n2,BPo),e(n2,$O),e($O,IPo),e(n2,NPo),e(pe,qPo),e(pe,s2),e(s2,Wge),e(Wge,jPo),e(s2,DPo),e(s2,kO),e(kO,GPo),e(s2,OPo),e(pe,VPo),e(pe,l2),e(l2,Hge),e(Hge,XPo),e(l2,zPo),e(l2,SO),e(SO,QPo),e(l2,WPo),e(pe,HPo),e(pe,i2),e(i2,Uge),e(Uge,UPo),e(i2,JPo),e(i2,RO),e(RO,YPo),e(i2,KPo),e(pe,ZPo),e(pe,d2),e(d2,Jge),e(Jge,eBo),e(d2,oBo),e(d2,PO),e(PO,rBo),e(d2,tBo),e(pe,aBo),e(pe,c2),e(c2,Yge),e(Yge,nBo),e(c2,sBo),e(c2,BO),e(BO,lBo),e(c2,iBo),e(pe,dBo),e(pe,f2),e(f2,Kge),e(Kge,cBo),e(f2,fBo),e(f2,IO),e(IO,mBo),e(f2,gBo),e(pe,hBo),e(pe,m2),e(m2,Zge),e(Zge,pBo),e(m2,_Bo),e(m2,NO),e(NO,uBo),e(m2,bBo),e(pe,vBo),e(pe,g2),e(g2,ehe),e(ehe,FBo),e(g2,TBo),e(g2,qO),e(qO,MBo),e(g2,EBo),e(pe,CBo),e(pe,h2),e(h2,ohe),e(ohe,wBo),e(h2,ABo),e(h2,jO),e(jO,LBo),e(h2,yBo),e(pe,xBo),e(pe,p2),e(p2,rhe),e(rhe,$Bo),e(p2,kBo),e(p2,DO),e(DO,SBo),e(p2,RBo),e(pe,PBo),e(pe,_2),e(_2,the),e(the,BBo),e(_2,IBo),e(_2,GO),e(GO,NBo),e(_2,qBo),e(pe,jBo),e(pe,u2),e(u2,ahe),e(ahe,DBo),e(u2,GBo),e(u2,OO),e(OO,OBo),e(u2,VBo),e(eo,XBo),e(eo,b2),e(b2,zBo),e(b2,nhe),e(nhe,QBo),e(b2,WBo),e(b2,she),e(she,HBo),e(eo,UBo),M(v2,eo,null),b(f,iOe,u),b(f,Ji,u),e(Ji,F2),e(F2,lhe),M(Ay,lhe,null),e(Ji,JBo),e(Ji,ihe),e(ihe,YBo),b(f,dOe,u),b(f,Po,u),M(Ly,Po,null),e(Po,KBo),e(Po,Yi),e(Yi,ZBo),e(Yi,VO),e(VO,eIo),e(Yi,oIo),e(Yi,XO),e(XO,rIo),e(Yi,tIo),e(Po,aIo),e(Po,yy),e(yy,nIo),e(yy,dhe),e(dhe,sIo),e(yy,lIo),e(Po,iIo),e(Po,ct),M(xy,ct,null),e(ct,dIo),e(ct,che),e(che,cIo),e(ct,fIo),e(ct,Ki),e(Ki,mIo),e(Ki,fhe),e(fhe,gIo),e(Ki,hIo),e(Ki,zO),e(zO,pIo),e(Ki,_Io),e(ct,uIo),M(T2,ct,null),e(Po,bIo),e(Po,oo),M($y,oo,null),e(oo,vIo),e(oo,mhe),e(mhe,FIo),e(oo,TIo),e(oo,qa),e(qa,MIo),e(qa,ghe),e(ghe,EIo),e(qa,CIo),e(qa,hhe),e(hhe,wIo),e(qa,AIo),e(qa,phe),e(phe,LIo),e(qa,yIo),e(oo,xIo),e(oo,N),e(N,M2),e(M2,_he),e(_he,$Io),e(M2,kIo),e(M2,QO),e(QO,SIo),e(M2,RIo),e(N,PIo),e(N,E2),e(E2,uhe),e(uhe,BIo),e(E2,IIo),e(E2,WO),e(WO,NIo),e(E2,qIo),e(N,jIo),e(N,C2),e(C2,bhe),e(bhe,DIo),e(C2,GIo),e(C2,HO),e(HO,OIo),e(C2,VIo),e(N,XIo),e(N,w2),e(w2,vhe),e(vhe,zIo),e(w2,QIo),e(w2,UO),e(UO,WIo),e(w2,HIo),e(N,UIo),e(N,A2),e(A2,Fhe),e(Fhe,JIo),e(A2,YIo),e(A2,JO),e(JO,KIo),e(A2,ZIo),e(N,eNo),e(N,L2),e(L2,The),e(The,oNo),e(L2,rNo),e(L2,YO),e(YO,tNo),e(L2,aNo),e(N,nNo),e(N,y2),e(y2,Mhe),e(Mhe,sNo),e(y2,lNo),e(y2,KO),e(KO,iNo),e(y2,dNo),e(N,cNo),e(N,x2),e(x2,Ehe),e(Ehe,fNo),e(x2,mNo),e(x2,ZO),e(ZO,gNo),e(x2,hNo),e(N,pNo),e(N,$2),e($2,Che),e(Che,_No),e($2,uNo),e($2,eV),e(eV,bNo),e($2,vNo),e(N,FNo),e(N,k2),e(k2,whe),e(whe,TNo),e(k2,MNo),e(k2,oV),e(oV,ENo),e(k2,CNo),e(N,wNo),e(N,S2),e(S2,Ahe),e(Ahe,ANo),e(S2,LNo),e(S2,rV),e(rV,yNo),e(S2,xNo),e(N,$No),e(N,R2),e(R2,Lhe),e(Lhe,kNo),e(R2,SNo),e(R2,tV),e(tV,RNo),e(R2,PNo),e(N,BNo),e(N,P2),e(P2,yhe),e(yhe,INo),e(P2,NNo),e(P2,aV),e(aV,qNo),e(P2,jNo),e(N,DNo),e(N,B2),e(B2,xhe),e(xhe,GNo),e(B2,ONo),e(B2,nV),e(nV,VNo),e(B2,XNo),e(N,zNo),e(N,I2),e(I2,$he),e($he,QNo),e(I2,WNo),e(I2,sV),e(sV,HNo),e(I2,UNo),e(N,JNo),e(N,N2),e(N2,khe),e(khe,YNo),e(N2,KNo),e(N2,lV),e(lV,ZNo),e(N2,eqo),e(N,oqo),e(N,q2),e(q2,She),e(She,rqo),e(q2,tqo),e(q2,iV),e(iV,aqo),e(q2,nqo),e(N,sqo),e(N,j2),e(j2,Rhe),e(Rhe,lqo),e(j2,iqo),e(j2,dV),e(dV,dqo),e(j2,cqo),e(N,fqo),e(N,D2),e(D2,Phe),e(Phe,mqo),e(D2,gqo),e(D2,cV),e(cV,hqo),e(D2,pqo),e(N,_qo),e(N,G2),e(G2,Bhe),e(Bhe,uqo),e(G2,bqo),e(G2,fV),e(fV,vqo),e(G2,Fqo),e(N,Tqo),e(N,O2),e(O2,Ihe),e(Ihe,Mqo),e(O2,Eqo),e(O2,mV),e(mV,Cqo),e(O2,wqo),e(N,Aqo),e(N,V2),e(V2,Nhe),e(Nhe,Lqo),e(V2,yqo),e(V2,gV),e(gV,xqo),e(V2,$qo),e(N,kqo),e(N,X2),e(X2,qhe),e(qhe,Sqo),e(X2,Rqo),e(X2,hV),e(hV,Pqo),e(X2,Bqo),e(N,Iqo),e(N,z2),e(z2,jhe),e(jhe,Nqo),e(z2,qqo),e(z2,pV),e(pV,jqo),e(z2,Dqo),e(N,Gqo),e(N,Q2),e(Q2,Dhe),e(Dhe,Oqo),e(Q2,Vqo),e(Q2,_V),e(_V,Xqo),e(Q2,zqo),e(N,Qqo),e(N,W2),e(W2,Ghe),e(Ghe,Wqo),e(W2,Hqo),e(W2,uV),e(uV,Uqo),e(W2,Jqo),e(N,Yqo),e(N,H2),e(H2,Ohe),e(Ohe,Kqo),e(H2,Zqo),e(H2,bV),e(bV,ejo),e(H2,ojo),e(N,rjo),e(N,U2),e(U2,Vhe),e(Vhe,tjo),e(U2,ajo),e(U2,vV),e(vV,njo),e(U2,sjo),e(N,ljo),e(N,J2),e(J2,Xhe),e(Xhe,ijo),e(J2,djo),e(J2,FV),e(FV,cjo),e(J2,fjo),e(N,mjo),e(N,Y2),e(Y2,zhe),e(zhe,gjo),e(Y2,hjo),e(Y2,TV),e(TV,pjo),e(Y2,_jo),e(N,ujo),e(N,K2),e(K2,Qhe),e(Qhe,bjo),e(K2,vjo),e(K2,MV),e(MV,Fjo),e(K2,Tjo),e(N,Mjo),e(N,Z2),e(Z2,Whe),e(Whe,Ejo),e(Z2,Cjo),e(Z2,EV),e(EV,wjo),e(Z2,Ajo),e(N,Ljo),e(N,eb),e(eb,Hhe),e(Hhe,yjo),e(eb,xjo),e(eb,CV),e(CV,$jo),e(eb,kjo),e(N,Sjo),e(N,ob),e(ob,Uhe),e(Uhe,Rjo),e(ob,Pjo),e(ob,wV),e(wV,Bjo),e(ob,Ijo),e(N,Njo),e(N,rb),e(rb,Jhe),e(Jhe,qjo),e(rb,jjo),e(rb,AV),e(AV,Djo),e(rb,Gjo),e(N,Ojo),e(N,tb),e(tb,Yhe),e(Yhe,Vjo),e(tb,Xjo),e(tb,LV),e(LV,zjo),e(tb,Qjo),e(N,Wjo),e(N,ab),e(ab,Khe),e(Khe,Hjo),e(ab,Ujo),e(ab,yV),e(yV,Jjo),e(ab,Yjo),e(N,Kjo),e(N,nb),e(nb,Zhe),e(Zhe,Zjo),e(nb,eDo),e(nb,xV),e(xV,oDo),e(nb,rDo),e(N,tDo),e(N,sb),e(sb,epe),e(epe,aDo),e(sb,nDo),e(sb,$V),e($V,sDo),e(sb,lDo),e(N,iDo),e(N,lb),e(lb,ope),e(ope,dDo),e(lb,cDo),e(lb,kV),e(kV,fDo),e(lb,mDo),e(N,gDo),e(N,ib),e(ib,rpe),e(rpe,hDo),e(ib,pDo),e(ib,SV),e(SV,_Do),e(ib,uDo),e(N,bDo),e(N,db),e(db,tpe),e(tpe,vDo),e(db,FDo),e(db,RV),e(RV,TDo),e(db,MDo),e(N,EDo),e(N,cb),e(cb,ape),e(ape,CDo),e(cb,wDo),e(cb,PV),e(PV,ADo),e(cb,LDo),e(N,yDo),e(N,fb),e(fb,npe),e(npe,xDo),e(fb,$Do),e(fb,BV),e(BV,kDo),e(fb,SDo),e(N,RDo),e(N,mb),e(mb,spe),e(spe,PDo),e(mb,BDo),e(mb,IV),e(IV,IDo),e(mb,NDo),e(N,qDo),e(N,gb),e(gb,lpe),e(lpe,jDo),e(gb,DDo),e(gb,NV),e(NV,GDo),e(gb,ODo),e(N,VDo),e(N,hb),e(hb,ipe),e(ipe,XDo),e(hb,zDo),e(hb,qV),e(qV,QDo),e(hb,WDo),e(N,HDo),e(N,pb),e(pb,dpe),e(dpe,UDo),e(pb,JDo),e(pb,jV),e(jV,YDo),e(pb,KDo),e(N,ZDo),e(N,_b),e(_b,cpe),e(cpe,eGo),e(_b,oGo),e(_b,DV),e(DV,rGo),e(_b,tGo),e(oo,aGo),e(oo,ub),e(ub,nGo),e(ub,fpe),e(fpe,sGo),e(ub,lGo),e(ub,mpe),e(mpe,iGo),e(oo,dGo),M(bb,oo,null),b(f,cOe,u),b(f,Zi,u),e(Zi,vb),e(vb,gpe),M(ky,gpe,null),e(Zi,cGo),e(Zi,hpe),e(hpe,fGo),b(f,fOe,u),b(f,Bo,u),M(Sy,Bo,null),e(Bo,mGo),e(Bo,ed),e(ed,gGo),e(ed,GV),e(GV,hGo),e(ed,pGo),e(ed,OV),e(OV,_Go),e(ed,uGo),e(Bo,bGo),e(Bo,Ry),e(Ry,vGo),e(Ry,ppe),e(ppe,FGo),e(Ry,TGo),e(Bo,MGo),e(Bo,ft),M(Py,ft,null),e(ft,EGo),e(ft,_pe),e(_pe,CGo),e(ft,wGo),e(ft,od),e(od,AGo),e(od,upe),e(upe,LGo),e(od,yGo),e(od,VV),e(VV,xGo),e(od,$Go),e(ft,kGo),M(Fb,ft,null),e(Bo,SGo),e(Bo,ro),M(By,ro,null),e(ro,RGo),e(ro,bpe),e(bpe,PGo),e(ro,BGo),e(ro,ja),e(ja,IGo),e(ja,vpe),e(vpe,NGo),e(ja,qGo),e(ja,Fpe),e(Fpe,jGo),e(ja,DGo),e(ja,Tpe),e(Tpe,GGo),e(ja,OGo),e(ro,VGo),e(ro,Z),e(Z,Tb),e(Tb,Mpe),e(Mpe,XGo),e(Tb,zGo),e(Tb,XV),e(XV,QGo),e(Tb,WGo),e(Z,HGo),e(Z,Mb),e(Mb,Epe),e(Epe,UGo),e(Mb,JGo),e(Mb,zV),e(zV,YGo),e(Mb,KGo),e(Z,ZGo),e(Z,Eb),e(Eb,Cpe),e(Cpe,eOo),e(Eb,oOo),e(Eb,QV),e(QV,rOo),e(Eb,tOo),e(Z,aOo),e(Z,Cb),e(Cb,wpe),e(wpe,nOo),e(Cb,sOo),e(Cb,WV),e(WV,lOo),e(Cb,iOo),e(Z,dOo),e(Z,wb),e(wb,Ape),e(Ape,cOo),e(wb,fOo),e(wb,HV),e(HV,mOo),e(wb,gOo),e(Z,hOo),e(Z,Ab),e(Ab,Lpe),e(Lpe,pOo),e(Ab,_Oo),e(Ab,UV),e(UV,uOo),e(Ab,bOo),e(Z,vOo),e(Z,Lb),e(Lb,ype),e(ype,FOo),e(Lb,TOo),e(Lb,JV),e(JV,MOo),e(Lb,EOo),e(Z,COo),e(Z,yb),e(yb,xpe),e(xpe,wOo),e(yb,AOo),e(yb,YV),e(YV,LOo),e(yb,yOo),e(Z,xOo),e(Z,xb),e(xb,$pe),e($pe,$Oo),e(xb,kOo),e(xb,KV),e(KV,SOo),e(xb,ROo),e(Z,POo),e(Z,$b),e($b,kpe),e(kpe,BOo),e($b,IOo),e($b,ZV),e(ZV,NOo),e($b,qOo),e(Z,jOo),e(Z,kb),e(kb,Spe),e(Spe,DOo),e(kb,GOo),e(kb,eX),e(eX,OOo),e(kb,VOo),e(Z,XOo),e(Z,Sb),e(Sb,Rpe),e(Rpe,zOo),e(Sb,QOo),e(Sb,oX),e(oX,WOo),e(Sb,HOo),e(Z,UOo),e(Z,Rb),e(Rb,Ppe),e(Ppe,JOo),e(Rb,YOo),e(Rb,rX),e(rX,KOo),e(Rb,ZOo),e(Z,eVo),e(Z,Pb),e(Pb,Bpe),e(Bpe,oVo),e(Pb,rVo),e(Pb,tX),e(tX,tVo),e(Pb,aVo),e(Z,nVo),e(Z,Bb),e(Bb,Ipe),e(Ipe,sVo),e(Bb,lVo),e(Bb,aX),e(aX,iVo),e(Bb,dVo),e(Z,cVo),e(Z,Ib),e(Ib,Npe),e(Npe,fVo),e(Ib,mVo),e(Ib,nX),e(nX,gVo),e(Ib,hVo),e(Z,pVo),e(Z,Nb),e(Nb,qpe),e(qpe,_Vo),e(Nb,uVo),e(Nb,sX),e(sX,bVo),e(Nb,vVo),e(Z,FVo),e(Z,qb),e(qb,jpe),e(jpe,TVo),e(qb,MVo),e(qb,lX),e(lX,EVo),e(qb,CVo),e(Z,wVo),e(Z,jb),e(jb,Dpe),e(Dpe,AVo),e(jb,LVo),e(jb,iX),e(iX,yVo),e(jb,xVo),e(Z,$Vo),e(Z,Db),e(Db,Gpe),e(Gpe,kVo),e(Db,SVo),e(Db,dX),e(dX,RVo),e(Db,PVo),e(Z,BVo),e(Z,Gb),e(Gb,Ope),e(Ope,IVo),e(Gb,NVo),e(Gb,cX),e(cX,qVo),e(Gb,jVo),e(Z,DVo),e(Z,Ob),e(Ob,Vpe),e(Vpe,GVo),e(Ob,OVo),e(Ob,fX),e(fX,VVo),e(Ob,XVo),e(Z,zVo),e(Z,Vb),e(Vb,Xpe),e(Xpe,QVo),e(Vb,WVo),e(Vb,mX),e(mX,HVo),e(Vb,UVo),e(Z,JVo),e(Z,Xb),e(Xb,zpe),e(zpe,YVo),e(Xb,KVo),e(Xb,gX),e(gX,ZVo),e(Xb,eXo),e(Z,oXo),e(Z,zb),e(zb,Qpe),e(Qpe,rXo),e(zb,tXo),e(zb,hX),e(hX,aXo),e(zb,nXo),e(Z,sXo),e(Z,Qb),e(Qb,Wpe),e(Wpe,lXo),e(Qb,iXo),e(Qb,pX),e(pX,dXo),e(Qb,cXo),e(Z,fXo),e(Z,Wb),e(Wb,Hpe),e(Hpe,mXo),e(Wb,gXo),e(Wb,_X),e(_X,hXo),e(Wb,pXo),e(Z,_Xo),e(Z,Hb),e(Hb,Upe),e(Upe,uXo),e(Hb,bXo),e(Hb,uX),e(uX,vXo),e(Hb,FXo),e(Z,TXo),e(Z,Ub),e(Ub,Jpe),e(Jpe,MXo),e(Ub,EXo),e(Ub,bX),e(bX,CXo),e(Ub,wXo),e(Z,AXo),e(Z,Jb),e(Jb,Ype),e(Ype,LXo),e(Jb,yXo),e(Jb,vX),e(vX,xXo),e(Jb,$Xo),e(ro,kXo),e(ro,Yb),e(Yb,SXo),e(Yb,Kpe),e(Kpe,RXo),e(Yb,PXo),e(Yb,Zpe),e(Zpe,BXo),e(ro,IXo),M(Kb,ro,null),b(f,mOe,u),b(f,rd,u),e(rd,Zb),e(Zb,e_e),M(Iy,e_e,null),e(rd,NXo),e(rd,o_e),e(o_e,qXo),b(f,gOe,u),b(f,Io,u),M(Ny,Io,null),e(Io,jXo),e(Io,td),e(td,DXo),e(td,FX),e(FX,GXo),e(td,OXo),e(td,TX),e(TX,VXo),e(td,XXo),e(Io,zXo),e(Io,qy),e(qy,QXo),e(qy,r_e),e(r_e,WXo),e(qy,HXo),e(Io,UXo),e(Io,mt),M(jy,mt,null),e(mt,JXo),e(mt,t_e),e(t_e,YXo),e(mt,KXo),e(mt,ad),e(ad,ZXo),e(ad,a_e),e(a_e,ezo),e(ad,ozo),e(ad,MX),e(MX,rzo),e(ad,tzo),e(mt,azo),M(ev,mt,null),e(Io,nzo),e(Io,to),M(Dy,to,null),e(to,szo),e(to,n_e),e(n_e,lzo),e(to,izo),e(to,Da),e(Da,dzo),e(Da,s_e),e(s_e,czo),e(Da,fzo),e(Da,l_e),e(l_e,mzo),e(Da,gzo),e(Da,i_e),e(i_e,hzo),e(Da,pzo),e(to,_zo),e(to,No),e(No,ov),e(ov,d_e),e(d_e,uzo),e(ov,bzo),e(ov,EX),e(EX,vzo),e(ov,Fzo),e(No,Tzo),e(No,rv),e(rv,c_e),e(c_e,Mzo),e(rv,Ezo),e(rv,CX),e(CX,Czo),e(rv,wzo),e(No,Azo),e(No,tv),e(tv,f_e),e(f_e,Lzo),e(tv,yzo),e(tv,wX),e(wX,xzo),e(tv,$zo),e(No,kzo),e(No,av),e(av,m_e),e(m_e,Szo),e(av,Rzo),e(av,AX),e(AX,Pzo),e(av,Bzo),e(No,Izo),e(No,nv),e(nv,g_e),e(g_e,Nzo),e(nv,qzo),e(nv,LX),e(LX,jzo),e(nv,Dzo),e(No,Gzo),e(No,sv),e(sv,h_e),e(h_e,Ozo),e(sv,Vzo),e(sv,yX),e(yX,Xzo),e(sv,zzo),e(to,Qzo),e(to,lv),e(lv,Wzo),e(lv,p_e),e(p_e,Hzo),e(lv,Uzo),e(lv,__e),e(__e,Jzo),e(to,Yzo),M(iv,to,null),b(f,hOe,u),b(f,nd,u),e(nd,dv),e(dv,u_e),M(Gy,u_e,null),e(nd,Kzo),e(nd,b_e),e(b_e,Zzo),b(f,pOe,u),b(f,qo,u),M(Oy,qo,null),e(qo,eQo),e(qo,sd),e(sd,oQo),e(sd,xX),e(xX,rQo),e(sd,tQo),e(sd,$X),e($X,aQo),e(sd,nQo),e(qo,sQo),e(qo,Vy),e(Vy,lQo),e(Vy,v_e),e(v_e,iQo),e(Vy,dQo),e(qo,cQo),e(qo,gt),M(Xy,gt,null),e(gt,fQo),e(gt,F_e),e(F_e,mQo),e(gt,gQo),e(gt,ld),e(ld,hQo),e(ld,T_e),e(T_e,pQo),e(ld,_Qo),e(ld,kX),e(kX,uQo),e(ld,bQo),e(gt,vQo),M(cv,gt,null),e(qo,FQo),e(qo,ao),M(zy,ao,null),e(ao,TQo),e(ao,M_e),e(M_e,MQo),e(ao,EQo),e(ao,Ga),e(Ga,CQo),e(Ga,E_e),e(E_e,wQo),e(Ga,AQo),e(Ga,C_e),e(C_e,LQo),e(Ga,yQo),e(Ga,w_e),e(w_e,xQo),e(Ga,$Qo),e(ao,kQo),e(ao,H),e(H,fv),e(fv,A_e),e(A_e,SQo),e(fv,RQo),e(fv,SX),e(SX,PQo),e(fv,BQo),e(H,IQo),e(H,mv),e(mv,L_e),e(L_e,NQo),e(mv,qQo),e(mv,RX),e(RX,jQo),e(mv,DQo),e(H,GQo),e(H,gv),e(gv,y_e),e(y_e,OQo),e(gv,VQo),e(gv,PX),e(PX,XQo),e(gv,zQo),e(H,QQo),e(H,hv),e(hv,x_e),e(x_e,WQo),e(hv,HQo),e(hv,BX),e(BX,UQo),e(hv,JQo),e(H,YQo),e(H,pv),e(pv,$_e),e($_e,KQo),e(pv,ZQo),e(pv,IX),e(IX,eWo),e(pv,oWo),e(H,rWo),e(H,_v),e(_v,k_e),e(k_e,tWo),e(_v,aWo),e(_v,NX),e(NX,nWo),e(_v,sWo),e(H,lWo),e(H,uv),e(uv,S_e),e(S_e,iWo),e(uv,dWo),e(uv,qX),e(qX,cWo),e(uv,fWo),e(H,mWo),e(H,bv),e(bv,R_e),e(R_e,gWo),e(bv,hWo),e(bv,jX),e(jX,pWo),e(bv,_Wo),e(H,uWo),e(H,vv),e(vv,P_e),e(P_e,bWo),e(vv,vWo),e(vv,DX),e(DX,FWo),e(vv,TWo),e(H,MWo),e(H,Fv),e(Fv,B_e),e(B_e,EWo),e(Fv,CWo),e(Fv,GX),e(GX,wWo),e(Fv,AWo),e(H,LWo),e(H,Tv),e(Tv,I_e),e(I_e,yWo),e(Tv,xWo),e(Tv,OX),e(OX,$Wo),e(Tv,kWo),e(H,SWo),e(H,Mv),e(Mv,N_e),e(N_e,RWo),e(Mv,PWo),e(Mv,VX),e(VX,BWo),e(Mv,IWo),e(H,NWo),e(H,Ev),e(Ev,q_e),e(q_e,qWo),e(Ev,jWo),e(Ev,XX),e(XX,DWo),e(Ev,GWo),e(H,OWo),e(H,Cv),e(Cv,j_e),e(j_e,VWo),e(Cv,XWo),e(Cv,zX),e(zX,zWo),e(Cv,QWo),e(H,WWo),e(H,wv),e(wv,D_e),e(D_e,HWo),e(wv,UWo),e(wv,QX),e(QX,JWo),e(wv,YWo),e(H,KWo),e(H,Av),e(Av,G_e),e(G_e,ZWo),e(Av,eHo),e(Av,WX),e(WX,oHo),e(Av,rHo),e(H,tHo),e(H,Lv),e(Lv,O_e),e(O_e,aHo),e(Lv,nHo),e(Lv,HX),e(HX,sHo),e(Lv,lHo),e(H,iHo),e(H,yv),e(yv,V_e),e(V_e,dHo),e(yv,cHo),e(yv,UX),e(UX,fHo),e(yv,mHo),e(H,gHo),e(H,xv),e(xv,X_e),e(X_e,hHo),e(xv,pHo),e(xv,JX),e(JX,_Ho),e(xv,uHo),e(H,bHo),e(H,$v),e($v,z_e),e(z_e,vHo),e($v,FHo),e($v,YX),e(YX,THo),e($v,MHo),e(H,EHo),e(H,kv),e(kv,Q_e),e(Q_e,CHo),e(kv,wHo),e(kv,KX),e(KX,AHo),e(kv,LHo),e(H,yHo),e(H,Sv),e(Sv,W_e),e(W_e,xHo),e(Sv,$Ho),e(Sv,ZX),e(ZX,kHo),e(Sv,SHo),e(H,RHo),e(H,Rv),e(Rv,H_e),e(H_e,PHo),e(Rv,BHo),e(Rv,ez),e(ez,IHo),e(Rv,NHo),e(H,qHo),e(H,Pv),e(Pv,U_e),e(U_e,jHo),e(Pv,DHo),e(Pv,oz),e(oz,GHo),e(Pv,OHo),e(H,VHo),e(H,Bv),e(Bv,J_e),e(J_e,XHo),e(Bv,zHo),e(Bv,rz),e(rz,QHo),e(Bv,WHo),e(H,HHo),e(H,Iv),e(Iv,Y_e),e(Y_e,UHo),e(Iv,JHo),e(Iv,tz),e(tz,YHo),e(Iv,KHo),e(H,ZHo),e(H,Nv),e(Nv,K_e),e(K_e,eUo),e(Nv,oUo),e(Nv,az),e(az,rUo),e(Nv,tUo),e(H,aUo),e(H,qv),e(qv,Z_e),e(Z_e,nUo),e(qv,sUo),e(qv,nz),e(nz,lUo),e(qv,iUo),e(H,dUo),e(H,jv),e(jv,eue),e(eue,cUo),e(jv,fUo),e(jv,sz),e(sz,mUo),e(jv,gUo),e(H,hUo),e(H,Dv),e(Dv,oue),e(oue,pUo),e(Dv,_Uo),e(Dv,lz),e(lz,uUo),e(Dv,bUo),e(H,vUo),e(H,Gv),e(Gv,rue),e(rue,FUo),e(Gv,TUo),e(Gv,iz),e(iz,MUo),e(Gv,EUo),e(H,CUo),e(H,Ov),e(Ov,tue),e(tue,wUo),e(Ov,AUo),e(Ov,dz),e(dz,LUo),e(Ov,yUo),e(H,xUo),e(H,Vv),e(Vv,aue),e(aue,$Uo),e(Vv,kUo),e(Vv,cz),e(cz,SUo),e(Vv,RUo),e(H,PUo),e(H,Xv),e(Xv,nue),e(nue,BUo),e(Xv,IUo),e(Xv,fz),e(fz,NUo),e(Xv,qUo),e(H,jUo),e(H,zv),e(zv,sue),e(sue,DUo),e(zv,GUo),e(zv,mz),e(mz,OUo),e(zv,VUo),e(H,XUo),e(H,Qv),e(Qv,lue),e(lue,zUo),e(Qv,QUo),e(Qv,gz),e(gz,WUo),e(Qv,HUo),e(ao,UUo),e(ao,Wv),e(Wv,JUo),e(Wv,iue),e(iue,YUo),e(Wv,KUo),e(Wv,due),e(due,ZUo),e(ao,eJo),M(Hv,ao,null),b(f,_Oe,u),b(f,id,u),e(id,Uv),e(Uv,cue),M(Qy,cue,null),e(id,oJo),e(id,fue),e(fue,rJo),b(f,uOe,u),b(f,jo,u),M(Wy,jo,null),e(jo,tJo),e(jo,dd),e(dd,aJo),e(dd,hz),e(hz,nJo),e(dd,sJo),e(dd,pz),e(pz,lJo),e(dd,iJo),e(jo,dJo),e(jo,Hy),e(Hy,cJo),e(Hy,mue),e(mue,fJo),e(Hy,mJo),e(jo,gJo),e(jo,ht),M(Uy,ht,null),e(ht,hJo),e(ht,gue),e(gue,pJo),e(ht,_Jo),e(ht,cd),e(cd,uJo),e(cd,hue),e(hue,bJo),e(cd,vJo),e(cd,_z),e(_z,FJo),e(cd,TJo),e(ht,MJo),M(Jv,ht,null),e(jo,EJo),e(jo,no),M(Jy,no,null),e(no,CJo),e(no,pue),e(pue,wJo),e(no,AJo),e(no,Oa),e(Oa,LJo),e(Oa,_ue),e(_ue,yJo),e(Oa,xJo),e(Oa,uue),e(uue,$Jo),e(Oa,kJo),e(Oa,bue),e(bue,SJo),e(Oa,RJo),e(no,PJo),e(no,V),e(V,Yv),e(Yv,vue),e(vue,BJo),e(Yv,IJo),e(Yv,uz),e(uz,NJo),e(Yv,qJo),e(V,jJo),e(V,Kv),e(Kv,Fue),e(Fue,DJo),e(Kv,GJo),e(Kv,bz),e(bz,OJo),e(Kv,VJo),e(V,XJo),e(V,Zv),e(Zv,Tue),e(Tue,zJo),e(Zv,QJo),e(Zv,vz),e(vz,WJo),e(Zv,HJo),e(V,UJo),e(V,eF),e(eF,Mue),e(Mue,JJo),e(eF,YJo),e(eF,Fz),e(Fz,KJo),e(eF,ZJo),e(V,eYo),e(V,oF),e(oF,Eue),e(Eue,oYo),e(oF,rYo),e(oF,Tz),e(Tz,tYo),e(oF,aYo),e(V,nYo),e(V,rF),e(rF,Cue),e(Cue,sYo),e(rF,lYo),e(rF,Mz),e(Mz,iYo),e(rF,dYo),e(V,cYo),e(V,tF),e(tF,wue),e(wue,fYo),e(tF,mYo),e(tF,Ez),e(Ez,gYo),e(tF,hYo),e(V,pYo),e(V,aF),e(aF,Aue),e(Aue,_Yo),e(aF,uYo),e(aF,Cz),e(Cz,bYo),e(aF,vYo),e(V,FYo),e(V,nF),e(nF,Lue),e(Lue,TYo),e(nF,MYo),e(nF,wz),e(wz,EYo),e(nF,CYo),e(V,wYo),e(V,sF),e(sF,yue),e(yue,AYo),e(sF,LYo),e(sF,Az),e(Az,yYo),e(sF,xYo),e(V,$Yo),e(V,lF),e(lF,xue),e(xue,kYo),e(lF,SYo),e(lF,Lz),e(Lz,RYo),e(lF,PYo),e(V,BYo),e(V,iF),e(iF,$ue),e($ue,IYo),e(iF,NYo),e(iF,yz),e(yz,qYo),e(iF,jYo),e(V,DYo),e(V,dF),e(dF,kue),e(kue,GYo),e(dF,OYo),e(dF,xz),e(xz,VYo),e(dF,XYo),e(V,zYo),e(V,cF),e(cF,Sue),e(Sue,QYo),e(cF,WYo),e(cF,$z),e($z,HYo),e(cF,UYo),e(V,JYo),e(V,fF),e(fF,Rue),e(Rue,YYo),e(fF,KYo),e(fF,kz),e(kz,ZYo),e(fF,eKo),e(V,oKo),e(V,mF),e(mF,Pue),e(Pue,rKo),e(mF,tKo),e(mF,Sz),e(Sz,aKo),e(mF,nKo),e(V,sKo),e(V,gF),e(gF,Bue),e(Bue,lKo),e(gF,iKo),e(gF,Rz),e(Rz,dKo),e(gF,cKo),e(V,fKo),e(V,hF),e(hF,Iue),e(Iue,mKo),e(hF,gKo),e(hF,Pz),e(Pz,hKo),e(hF,pKo),e(V,_Ko),e(V,pF),e(pF,Nue),e(Nue,uKo),e(pF,bKo),e(pF,Bz),e(Bz,vKo),e(pF,FKo),e(V,TKo),e(V,_F),e(_F,que),e(que,MKo),e(_F,EKo),e(_F,Iz),e(Iz,CKo),e(_F,wKo),e(V,AKo),e(V,uF),e(uF,jue),e(jue,LKo),e(uF,yKo),e(uF,Nz),e(Nz,xKo),e(uF,$Ko),e(V,kKo),e(V,bF),e(bF,Due),e(Due,SKo),e(bF,RKo),e(bF,qz),e(qz,PKo),e(bF,BKo),e(V,IKo),e(V,vF),e(vF,Gue),e(Gue,NKo),e(vF,qKo),e(vF,jz),e(jz,jKo),e(vF,DKo),e(V,GKo),e(V,FF),e(FF,Oue),e(Oue,OKo),e(FF,VKo),e(FF,Dz),e(Dz,XKo),e(FF,zKo),e(V,QKo),e(V,TF),e(TF,Vue),e(Vue,WKo),e(TF,HKo),e(TF,Gz),e(Gz,UKo),e(TF,JKo),e(V,YKo),e(V,MF),e(MF,Xue),e(Xue,KKo),e(MF,ZKo),e(MF,Oz),e(Oz,eZo),e(MF,oZo),e(V,rZo),e(V,EF),e(EF,zue),e(zue,tZo),e(EF,aZo),e(EF,Vz),e(Vz,nZo),e(EF,sZo),e(V,lZo),e(V,CF),e(CF,Que),e(Que,iZo),e(CF,dZo),e(CF,Xz),e(Xz,cZo),e(CF,fZo),e(V,mZo),e(V,wF),e(wF,Wue),e(Wue,gZo),e(wF,hZo),e(wF,zz),e(zz,pZo),e(wF,_Zo),e(V,uZo),e(V,AF),e(AF,Hue),e(Hue,bZo),e(AF,vZo),e(AF,Qz),e(Qz,FZo),e(AF,TZo),e(V,MZo),e(V,LF),e(LF,Uue),e(Uue,EZo),e(LF,CZo),e(LF,Wz),e(Wz,wZo),e(LF,AZo),e(V,LZo),e(V,yF),e(yF,Jue),e(Jue,yZo),e(yF,xZo),e(yF,Hz),e(Hz,$Zo),e(yF,kZo),e(V,SZo),e(V,xF),e(xF,Yue),e(Yue,RZo),e(xF,PZo),e(xF,Uz),e(Uz,BZo),e(xF,IZo),e(V,NZo),e(V,$F),e($F,Kue),e(Kue,qZo),e($F,jZo),e($F,Jz),e(Jz,DZo),e($F,GZo),e(V,OZo),e(V,kF),e(kF,Zue),e(Zue,VZo),e(kF,XZo),e(kF,Yz),e(Yz,zZo),e(kF,QZo),e(V,WZo),e(V,SF),e(SF,e7e),e(e7e,HZo),e(SF,UZo),e(SF,Kz),e(Kz,JZo),e(SF,YZo),e(V,KZo),e(V,RF),e(RF,o7e),e(o7e,ZZo),e(RF,eer),e(RF,Zz),e(Zz,oer),e(RF,rer),e(V,ter),e(V,PF),e(PF,r7e),e(r7e,aer),e(PF,ner),e(PF,eQ),e(eQ,ser),e(PF,ler),e(V,ier),e(V,BF),e(BF,t7e),e(t7e,der),e(BF,cer),e(BF,oQ),e(oQ,fer),e(BF,mer),e(V,ger),e(V,IF),e(IF,a7e),e(a7e,her),e(IF,per),e(IF,rQ),e(rQ,_er),e(IF,uer),e(V,ber),e(V,NF),e(NF,n7e),e(n7e,ver),e(NF,Fer),e(NF,tQ),e(tQ,Ter),e(NF,Mer),e(no,Eer),e(no,qF),e(qF,Cer),e(qF,s7e),e(s7e,wer),e(qF,Aer),e(qF,l7e),e(l7e,Ler),e(no,yer),M(jF,no,null),b(f,bOe,u),b(f,fd,u),e(fd,DF),e(DF,i7e),M(Yy,i7e,null),e(fd,xer),e(fd,d7e),e(d7e,$er),b(f,vOe,u),b(f,Do,u),M(Ky,Do,null),e(Do,ker),e(Do,md),e(md,Ser),e(md,aQ),e(aQ,Rer),e(md,Per),e(md,nQ),e(nQ,Ber),e(md,Ier),e(Do,Ner),e(Do,Zy),e(Zy,qer),e(Zy,c7e),e(c7e,jer),e(Zy,Der),e(Do,Ger),e(Do,pt),M(e8,pt,null),e(pt,Oer),e(pt,f7e),e(f7e,Ver),e(pt,Xer),e(pt,gd),e(gd,zer),e(gd,m7e),e(m7e,Qer),e(gd,Wer),e(gd,sQ),e(sQ,Her),e(gd,Uer),e(pt,Jer),M(GF,pt,null),e(Do,Yer),e(Do,so),M(o8,so,null),e(so,Ker),e(so,g7e),e(g7e,Zer),e(so,eor),e(so,Va),e(Va,oor),e(Va,h7e),e(h7e,ror),e(Va,tor),e(Va,p7e),e(p7e,aor),e(Va,nor),e(Va,_7e),e(_7e,sor),e(Va,lor),e(so,ior),e(so,u7e),e(u7e,OF),e(OF,b7e),e(b7e,dor),e(OF,cor),e(OF,lQ),e(lQ,mor),e(OF,gor),e(so,hor),e(so,VF),e(VF,por),e(VF,v7e),e(v7e,_or),e(VF,uor),e(VF,F7e),e(F7e,bor),e(so,vor),M(XF,so,null),b(f,FOe,u),b(f,hd,u),e(hd,zF),e(zF,T7e),M(r8,T7e,null),e(hd,For),e(hd,M7e),e(M7e,Tor),b(f,TOe,u),b(f,Go,u),M(t8,Go,null),e(Go,Mor),e(Go,pd),e(pd,Eor),e(pd,iQ),e(iQ,Cor),e(pd,wor),e(pd,dQ),e(dQ,Aor),e(pd,Lor),e(Go,yor),e(Go,a8),e(a8,xor),e(a8,E7e),e(E7e,$or),e(a8,kor),e(Go,Sor),e(Go,_t),M(n8,_t,null),e(_t,Ror),e(_t,C7e),e(C7e,Por),e(_t,Bor),e(_t,_d),e(_d,Ior),e(_d,w7e),e(w7e,Nor),e(_d,qor),e(_d,cQ),e(cQ,jor),e(_d,Dor),e(_t,Gor),M(QF,_t,null),e(Go,Oor),e(Go,lo),M(s8,lo,null),e(lo,Vor),e(lo,A7e),e(A7e,Xor),e(lo,zor),e(lo,Xa),e(Xa,Qor),e(Xa,L7e),e(L7e,Wor),e(Xa,Hor),e(Xa,y7e),e(y7e,Uor),e(Xa,Jor),e(Xa,x7e),e(x7e,Yor),e(Xa,Kor),e(lo,Zor),e(lo,Fe),e(Fe,WF),e(WF,$7e),e($7e,err),e(WF,orr),e(WF,fQ),e(fQ,rrr),e(WF,trr),e(Fe,arr),e(Fe,HF),e(HF,k7e),e(k7e,nrr),e(HF,srr),e(HF,mQ),e(mQ,lrr),e(HF,irr),e(Fe,drr),e(Fe,UF),e(UF,S7e),e(S7e,crr),e(UF,frr),e(UF,gQ),e(gQ,mrr),e(UF,grr),e(Fe,hrr),e(Fe,JF),e(JF,R7e),e(R7e,prr),e(JF,_rr),e(JF,hQ),e(hQ,urr),e(JF,brr),e(Fe,vrr),e(Fe,Xs),e(Xs,P7e),e(P7e,Frr),e(Xs,Trr),e(Xs,pQ),e(pQ,Mrr),e(Xs,Err),e(Xs,_Q),e(_Q,Crr),e(Xs,wrr),e(Fe,Arr),e(Fe,YF),e(YF,B7e),e(B7e,Lrr),e(YF,yrr),e(YF,uQ),e(uQ,xrr),e(YF,$rr),e(Fe,krr),e(Fe,zs),e(zs,I7e),e(I7e,Srr),e(zs,Rrr),e(zs,bQ),e(bQ,Prr),e(zs,Brr),e(zs,vQ),e(vQ,Irr),e(zs,Nrr),e(Fe,qrr),e(Fe,ut),e(ut,N7e),e(N7e,jrr),e(ut,Drr),e(ut,FQ),e(FQ,Grr),e(ut,Orr),e(ut,TQ),e(TQ,Vrr),e(ut,Xrr),e(ut,MQ),e(MQ,zrr),e(ut,Qrr),e(Fe,Wrr),e(Fe,KF),e(KF,q7e),e(q7e,Hrr),e(KF,Urr),e(KF,EQ),e(EQ,Jrr),e(KF,Yrr),e(Fe,Krr),e(Fe,ZF),e(ZF,j7e),e(j7e,Zrr),e(ZF,etr),e(ZF,CQ),e(CQ,otr),e(ZF,rtr),e(Fe,ttr),e(Fe,e6),e(e6,D7e),e(D7e,atr),e(e6,ntr),e(e6,wQ),e(wQ,str),e(e6,ltr),e(Fe,itr),e(Fe,o6),e(o6,G7e),e(G7e,dtr),e(o6,ctr),e(o6,AQ),e(AQ,ftr),e(o6,mtr),e(Fe,gtr),e(Fe,r6),e(r6,O7e),e(O7e,htr),e(r6,ptr),e(r6,LQ),e(LQ,_tr),e(r6,utr),e(Fe,btr),e(Fe,t6),e(t6,V7e),e(V7e,vtr),e(t6,Ftr),e(t6,yQ),e(yQ,Ttr),e(t6,Mtr),e(Fe,Etr),e(Fe,a6),e(a6,X7e),e(X7e,Ctr),e(a6,wtr),e(a6,xQ),e(xQ,Atr),e(a6,Ltr),e(lo,ytr),e(lo,n6),e(n6,xtr),e(n6,z7e),e(z7e,$tr),e(n6,ktr),e(n6,Q7e),e(Q7e,Str),e(lo,Rtr),M(s6,lo,null),b(f,MOe,u),b(f,ud,u),e(ud,l6),e(l6,W7e),M(l8,W7e,null),e(ud,Ptr),e(ud,H7e),e(H7e,Btr),b(f,EOe,u),b(f,Oo,u),M(i8,Oo,null),e(Oo,Itr),e(Oo,bd),e(bd,Ntr),e(bd,$Q),e($Q,qtr),e(bd,jtr),e(bd,kQ),e(kQ,Dtr),e(bd,Gtr),e(Oo,Otr),e(Oo,d8),e(d8,Vtr),e(d8,U7e),e(U7e,Xtr),e(d8,ztr),e(Oo,Qtr),e(Oo,bt),M(c8,bt,null),e(bt,Wtr),e(bt,J7e),e(J7e,Htr),e(bt,Utr),e(bt,vd),e(vd,Jtr),e(vd,Y7e),e(Y7e,Ytr),e(vd,Ktr),e(vd,SQ),e(SQ,Ztr),e(vd,ear),e(bt,oar),M(i6,bt,null),e(Oo,rar),e(Oo,io),M(f8,io,null),e(io,tar),e(io,K7e),e(K7e,aar),e(io,nar),e(io,za),e(za,sar),e(za,Z7e),e(Z7e,lar),e(za,iar),e(za,e1e),e(e1e,dar),e(za,car),e(za,o1e),e(o1e,far),e(za,mar),e(io,gar),e(io,r1e),e(r1e,d6),e(d6,t1e),e(t1e,har),e(d6,par),e(d6,RQ),e(RQ,_ar),e(d6,uar),e(io,bar),e(io,c6),e(c6,Far),e(c6,a1e),e(a1e,Tar),e(c6,Mar),e(c6,n1e),e(n1e,Ear),e(io,Car),M(f6,io,null),b(f,COe,u),b(f,Fd,u),e(Fd,m6),e(m6,s1e),M(m8,s1e,null),e(Fd,war),e(Fd,l1e),e(l1e,Aar),b(f,wOe,u),b(f,Vo,u),M(g8,Vo,null),e(Vo,Lar),e(Vo,Td),e(Td,yar),e(Td,PQ),e(PQ,xar),e(Td,$ar),e(Td,BQ),e(BQ,kar),e(Td,Sar),e(Vo,Rar),e(Vo,h8),e(h8,Par),e(h8,i1e),e(i1e,Bar),e(h8,Iar),e(Vo,Nar),e(Vo,vt),M(p8,vt,null),e(vt,qar),e(vt,d1e),e(d1e,jar),e(vt,Dar),e(vt,Md),e(Md,Gar),e(Md,c1e),e(c1e,Oar),e(Md,Var),e(Md,IQ),e(IQ,Xar),e(Md,zar),e(vt,Qar),M(g6,vt,null),e(Vo,War),e(Vo,co),M(_8,co,null),e(co,Har),e(co,f1e),e(f1e,Uar),e(co,Jar),e(co,Qa),e(Qa,Yar),e(Qa,m1e),e(m1e,Kar),e(Qa,Zar),e(Qa,g1e),e(g1e,enr),e(Qa,onr),e(Qa,h1e),e(h1e,rnr),e(Qa,tnr),e(co,anr),e(co,p1e),e(p1e,h6),e(h6,_1e),e(_1e,nnr),e(h6,snr),e(h6,NQ),e(NQ,lnr),e(h6,inr),e(co,dnr),e(co,p6),e(p6,cnr),e(p6,u1e),e(u1e,fnr),e(p6,mnr),e(p6,b1e),e(b1e,gnr),e(co,hnr),M(_6,co,null),b(f,AOe,u),b(f,Ed,u),e(Ed,u6),e(u6,v1e),M(u8,v1e,null),e(Ed,pnr),e(Ed,F1e),e(F1e,_nr),b(f,LOe,u),b(f,Xo,u),M(b8,Xo,null),e(Xo,unr),e(Xo,Cd),e(Cd,bnr),e(Cd,qQ),e(qQ,vnr),e(Cd,Fnr),e(Cd,jQ),e(jQ,Tnr),e(Cd,Mnr),e(Xo,Enr),e(Xo,v8),e(v8,Cnr),e(v8,T1e),e(T1e,wnr),e(v8,Anr),e(Xo,Lnr),e(Xo,Ft),M(F8,Ft,null),e(Ft,ynr),e(Ft,M1e),e(M1e,xnr),e(Ft,$nr),e(Ft,wd),e(wd,knr),e(wd,E1e),e(E1e,Snr),e(wd,Rnr),e(wd,DQ),e(DQ,Pnr),e(wd,Bnr),e(Ft,Inr),M(b6,Ft,null),e(Xo,Nnr),e(Xo,fo),M(T8,fo,null),e(fo,qnr),e(fo,C1e),e(C1e,jnr),e(fo,Dnr),e(fo,Wa),e(Wa,Gnr),e(Wa,w1e),e(w1e,Onr),e(Wa,Vnr),e(Wa,A1e),e(A1e,Xnr),e(Wa,znr),e(Wa,L1e),e(L1e,Qnr),e(Wa,Wnr),e(fo,Hnr),e(fo,Pe),e(Pe,v6),e(v6,y1e),e(y1e,Unr),e(v6,Jnr),e(v6,GQ),e(GQ,Ynr),e(v6,Knr),e(Pe,Znr),e(Pe,F6),e(F6,x1e),e(x1e,esr),e(F6,osr),e(F6,OQ),e(OQ,rsr),e(F6,tsr),e(Pe,asr),e(Pe,T6),e(T6,$1e),e($1e,nsr),e(T6,ssr),e(T6,VQ),e(VQ,lsr),e(T6,isr),e(Pe,dsr),e(Pe,M6),e(M6,k1e),e(k1e,csr),e(M6,fsr),e(M6,XQ),e(XQ,msr),e(M6,gsr),e(Pe,hsr),e(Pe,E6),e(E6,S1e),e(S1e,psr),e(E6,_sr),e(E6,zQ),e(zQ,usr),e(E6,bsr),e(Pe,vsr),e(Pe,C6),e(C6,R1e),e(R1e,Fsr),e(C6,Tsr),e(C6,QQ),e(QQ,Msr),e(C6,Esr),e(Pe,Csr),e(Pe,w6),e(w6,P1e),e(P1e,wsr),e(w6,Asr),e(w6,WQ),e(WQ,Lsr),e(w6,ysr),e(Pe,xsr),e(Pe,A6),e(A6,B1e),e(B1e,$sr),e(A6,ksr),e(A6,HQ),e(HQ,Ssr),e(A6,Rsr),e(Pe,Psr),e(Pe,L6),e(L6,I1e),e(I1e,Bsr),e(L6,Isr),e(L6,UQ),e(UQ,Nsr),e(L6,qsr),e(fo,jsr),e(fo,y6),e(y6,Dsr),e(y6,N1e),e(N1e,Gsr),e(y6,Osr),e(y6,q1e),e(q1e,Vsr),e(fo,Xsr),M(x6,fo,null),b(f,yOe,u),b(f,Ad,u),e(Ad,$6),e($6,j1e),M(M8,j1e,null),e(Ad,zsr),e(Ad,D1e),e(D1e,Qsr),b(f,xOe,u),b(f,zo,u),M(E8,zo,null),e(zo,Wsr),e(zo,Ld),e(Ld,Hsr),e(Ld,JQ),e(JQ,Usr),e(Ld,Jsr),e(Ld,YQ),e(YQ,Ysr),e(Ld,Ksr),e(zo,Zsr),e(zo,C8),e(C8,elr),e(C8,G1e),e(G1e,olr),e(C8,rlr),e(zo,tlr),e(zo,Tt),M(w8,Tt,null),e(Tt,alr),e(Tt,O1e),e(O1e,nlr),e(Tt,slr),e(Tt,yd),e(yd,llr),e(yd,V1e),e(V1e,ilr),e(yd,dlr),e(yd,KQ),e(KQ,clr),e(yd,flr),e(Tt,mlr),M(k6,Tt,null),e(zo,glr),e(zo,mo),M(A8,mo,null),e(mo,hlr),e(mo,X1e),e(X1e,plr),e(mo,_lr),e(mo,Ha),e(Ha,ulr),e(Ha,z1e),e(z1e,blr),e(Ha,vlr),e(Ha,Q1e),e(Q1e,Flr),e(Ha,Tlr),e(Ha,W1e),e(W1e,Mlr),e(Ha,Elr),e(mo,Clr),e(mo,et),e(et,S6),e(S6,H1e),e(H1e,wlr),e(S6,Alr),e(S6,ZQ),e(ZQ,Llr),e(S6,ylr),e(et,xlr),e(et,R6),e(R6,U1e),e(U1e,$lr),e(R6,klr),e(R6,eW),e(eW,Slr),e(R6,Rlr),e(et,Plr),e(et,P6),e(P6,J1e),e(J1e,Blr),e(P6,Ilr),e(P6,oW),e(oW,Nlr),e(P6,qlr),e(et,jlr),e(et,B6),e(B6,Y1e),e(Y1e,Dlr),e(B6,Glr),e(B6,rW),e(rW,Olr),e(B6,Vlr),e(et,Xlr),e(et,I6),e(I6,K1e),e(K1e,zlr),e(I6,Qlr),e(I6,tW),e(tW,Wlr),e(I6,Hlr),e(mo,Ulr),e(mo,N6),e(N6,Jlr),e(N6,Z1e),e(Z1e,Ylr),e(N6,Klr),e(N6,e2e),e(e2e,Zlr),e(mo,eir),M(q6,mo,null),b(f,$Oe,u),b(f,xd,u),e(xd,j6),e(j6,o2e),M(L8,o2e,null),e(xd,oir),e(xd,r2e),e(r2e,rir),b(f,kOe,u),b(f,Qo,u),M(y8,Qo,null),e(Qo,tir),e(Qo,$d),e($d,air),e($d,aW),e(aW,nir),e($d,sir),e($d,nW),e(nW,lir),e($d,iir),e(Qo,dir),e(Qo,x8),e(x8,cir),e(x8,t2e),e(t2e,fir),e(x8,mir),e(Qo,gir),e(Qo,Mt),M($8,Mt,null),e(Mt,hir),e(Mt,a2e),e(a2e,pir),e(Mt,_ir),e(Mt,kd),e(kd,uir),e(kd,n2e),e(n2e,bir),e(kd,vir),e(kd,sW),e(sW,Fir),e(kd,Tir),e(Mt,Mir),M(D6,Mt,null),e(Qo,Eir),e(Qo,go),M(k8,go,null),e(go,Cir),e(go,s2e),e(s2e,wir),e(go,Air),e(go,Ua),e(Ua,Lir),e(Ua,l2e),e(l2e,yir),e(Ua,xir),e(Ua,i2e),e(i2e,$ir),e(Ua,kir),e(Ua,d2e),e(d2e,Sir),e(Ua,Rir),e(go,Pir),e(go,Le),e(Le,G6),e(G6,c2e),e(c2e,Bir),e(G6,Iir),e(G6,lW),e(lW,Nir),e(G6,qir),e(Le,jir),e(Le,O6),e(O6,f2e),e(f2e,Dir),e(O6,Gir),e(O6,iW),e(iW,Oir),e(O6,Vir),e(Le,Xir),e(Le,V6),e(V6,m2e),e(m2e,zir),e(V6,Qir),e(V6,dW),e(dW,Wir),e(V6,Hir),e(Le,Uir),e(Le,X6),e(X6,g2e),e(g2e,Jir),e(X6,Yir),e(X6,cW),e(cW,Kir),e(X6,Zir),e(Le,edr),e(Le,z6),e(z6,h2e),e(h2e,odr),e(z6,rdr),e(z6,fW),e(fW,tdr),e(z6,adr),e(Le,ndr),e(Le,Q6),e(Q6,p2e),e(p2e,sdr),e(Q6,ldr),e(Q6,mW),e(mW,idr),e(Q6,ddr),e(Le,cdr),e(Le,W6),e(W6,_2e),e(_2e,fdr),e(W6,mdr),e(W6,gW),e(gW,gdr),e(W6,hdr),e(Le,pdr),e(Le,H6),e(H6,u2e),e(u2e,_dr),e(H6,udr),e(H6,hW),e(hW,bdr),e(H6,vdr),e(Le,Fdr),e(Le,U6),e(U6,b2e),e(b2e,Tdr),e(U6,Mdr),e(U6,pW),e(pW,Edr),e(U6,Cdr),e(Le,wdr),e(Le,J6),e(J6,v2e),e(v2e,Adr),e(J6,Ldr),e(J6,_W),e(_W,ydr),e(J6,xdr),e(go,$dr),e(go,Y6),e(Y6,kdr),e(Y6,F2e),e(F2e,Sdr),e(Y6,Rdr),e(Y6,T2e),e(T2e,Pdr),e(go,Bdr),M(K6,go,null),b(f,SOe,u),b(f,Sd,u),e(Sd,Z6),e(Z6,M2e),M(S8,M2e,null),e(Sd,Idr),e(Sd,E2e),e(E2e,Ndr),b(f,ROe,u),b(f,Wo,u),M(R8,Wo,null),e(Wo,qdr),e(Wo,Rd),e(Rd,jdr),e(Rd,uW),e(uW,Ddr),e(Rd,Gdr),e(Rd,bW),e(bW,Odr),e(Rd,Vdr),e(Wo,Xdr),e(Wo,P8),e(P8,zdr),e(P8,C2e),e(C2e,Qdr),e(P8,Wdr),e(Wo,Hdr),e(Wo,Et),M(B8,Et,null),e(Et,Udr),e(Et,w2e),e(w2e,Jdr),e(Et,Ydr),e(Et,Pd),e(Pd,Kdr),e(Pd,A2e),e(A2e,Zdr),e(Pd,ecr),e(Pd,vW),e(vW,ocr),e(Pd,rcr),e(Et,tcr),M(eT,Et,null),e(Wo,acr),e(Wo,ho),M(I8,ho,null),e(ho,ncr),e(ho,L2e),e(L2e,scr),e(ho,lcr),e(ho,Ja),e(Ja,icr),e(Ja,y2e),e(y2e,dcr),e(Ja,ccr),e(Ja,x2e),e(x2e,fcr),e(Ja,mcr),e(Ja,$2e),e($2e,gcr),e(Ja,hcr),e(ho,pcr),e(ho,N8),e(N8,oT),e(oT,k2e),e(k2e,_cr),e(oT,ucr),e(oT,FW),e(FW,bcr),e(oT,vcr),e(N8,Fcr),e(N8,rT),e(rT,S2e),e(S2e,Tcr),e(rT,Mcr),e(rT,TW),e(TW,Ecr),e(rT,Ccr),e(ho,wcr),e(ho,tT),e(tT,Acr),e(tT,R2e),e(R2e,Lcr),e(tT,ycr),e(tT,P2e),e(P2e,xcr),e(ho,$cr),M(aT,ho,null),b(f,POe,u),b(f,Bd,u),e(Bd,nT),e(nT,B2e),M(q8,B2e,null),e(Bd,kcr),e(Bd,I2e),e(I2e,Scr),b(f,BOe,u),b(f,Ho,u),M(j8,Ho,null),e(Ho,Rcr),e(Ho,Id),e(Id,Pcr),e(Id,MW),e(MW,Bcr),e(Id,Icr),e(Id,EW),e(EW,Ncr),e(Id,qcr),e(Ho,jcr),e(Ho,D8),e(D8,Dcr),e(D8,N2e),e(N2e,Gcr),e(D8,Ocr),e(Ho,Vcr),e(Ho,Ct),M(G8,Ct,null),e(Ct,Xcr),e(Ct,q2e),e(q2e,zcr),e(Ct,Qcr),e(Ct,Nd),e(Nd,Wcr),e(Nd,j2e),e(j2e,Hcr),e(Nd,Ucr),e(Nd,CW),e(CW,Jcr),e(Nd,Ycr),e(Ct,Kcr),M(sT,Ct,null),e(Ho,Zcr),e(Ho,po),M(O8,po,null),e(po,efr),e(po,D2e),e(D2e,ofr),e(po,rfr),e(po,Ya),e(Ya,tfr),e(Ya,G2e),e(G2e,afr),e(Ya,nfr),e(Ya,O2e),e(O2e,sfr),e(Ya,lfr),e(Ya,V2e),e(V2e,ifr),e(Ya,dfr),e(po,cfr),e(po,ot),e(ot,lT),e(lT,X2e),e(X2e,ffr),e(lT,mfr),e(lT,wW),e(wW,gfr),e(lT,hfr),e(ot,pfr),e(ot,iT),e(iT,z2e),e(z2e,_fr),e(iT,ufr),e(iT,AW),e(AW,bfr),e(iT,vfr),e(ot,Ffr),e(ot,dT),e(dT,Q2e),e(Q2e,Tfr),e(dT,Mfr),e(dT,LW),e(LW,Efr),e(dT,Cfr),e(ot,wfr),e(ot,cT),e(cT,W2e),e(W2e,Afr),e(cT,Lfr),e(cT,yW),e(yW,yfr),e(cT,xfr),e(ot,$fr),e(ot,fT),e(fT,H2e),e(H2e,kfr),e(fT,Sfr),e(fT,xW),e(xW,Rfr),e(fT,Pfr),e(po,Bfr),e(po,mT),e(mT,Ifr),e(mT,U2e),e(U2e,Nfr),e(mT,qfr),e(mT,J2e),e(J2e,jfr),e(po,Dfr),M(gT,po,null),b(f,IOe,u),b(f,qd,u),e(qd,hT),e(hT,Y2e),M(V8,Y2e,null),e(qd,Gfr),e(qd,K2e),e(K2e,Ofr),b(f,NOe,u),b(f,Uo,u),M(X8,Uo,null),e(Uo,Vfr),e(Uo,jd),e(jd,Xfr),e(jd,$W),e($W,zfr),e(jd,Qfr),e(jd,kW),e(kW,Wfr),e(jd,Hfr),e(Uo,Ufr),e(Uo,z8),e(z8,Jfr),e(z8,Z2e),e(Z2e,Yfr),e(z8,Kfr),e(Uo,Zfr),e(Uo,wt),M(Q8,wt,null),e(wt,emr),e(wt,ebe),e(ebe,omr),e(wt,rmr),e(wt,Dd),e(Dd,tmr),e(Dd,obe),e(obe,amr),e(Dd,nmr),e(Dd,SW),e(SW,smr),e(Dd,lmr),e(wt,imr),M(pT,wt,null),e(Uo,dmr),e(Uo,_o),M(W8,_o,null),e(_o,cmr),e(_o,rbe),e(rbe,fmr),e(_o,mmr),e(_o,Ka),e(Ka,gmr),e(Ka,tbe),e(tbe,hmr),e(Ka,pmr),e(Ka,abe),e(abe,_mr),e(Ka,umr),e(Ka,nbe),e(nbe,bmr),e(Ka,vmr),e(_o,Fmr),e(_o,Gd),e(Gd,_T),e(_T,sbe),e(sbe,Tmr),e(_T,Mmr),e(_T,RW),e(RW,Emr),e(_T,Cmr),e(Gd,wmr),e(Gd,uT),e(uT,lbe),e(lbe,Amr),e(uT,Lmr),e(uT,PW),e(PW,ymr),e(uT,xmr),e(Gd,$mr),e(Gd,bT),e(bT,ibe),e(ibe,kmr),e(bT,Smr),e(bT,BW),e(BW,Rmr),e(bT,Pmr),e(_o,Bmr),e(_o,vT),e(vT,Imr),e(vT,dbe),e(dbe,Nmr),e(vT,qmr),e(vT,cbe),e(cbe,jmr),e(_o,Dmr),M(FT,_o,null),b(f,qOe,u),b(f,Od,u),e(Od,TT),e(TT,fbe),M(H8,fbe,null),e(Od,Gmr),e(Od,mbe),e(mbe,Omr),b(f,jOe,u),b(f,Jo,u),M(U8,Jo,null),e(Jo,Vmr),e(Jo,Vd),e(Vd,Xmr),e(Vd,IW),e(IW,zmr),e(Vd,Qmr),e(Vd,NW),e(NW,Wmr),e(Vd,Hmr),e(Jo,Umr),e(Jo,J8),e(J8,Jmr),e(J8,gbe),e(gbe,Ymr),e(J8,Kmr),e(Jo,Zmr),e(Jo,At),M(Y8,At,null),e(At,egr),e(At,hbe),e(hbe,ogr),e(At,rgr),e(At,Xd),e(Xd,tgr),e(Xd,pbe),e(pbe,agr),e(Xd,ngr),e(Xd,qW),e(qW,sgr),e(Xd,lgr),e(At,igr),M(MT,At,null),e(Jo,dgr),e(Jo,uo),M(K8,uo,null),e(uo,cgr),e(uo,_be),e(_be,fgr),e(uo,mgr),e(uo,Za),e(Za,ggr),e(Za,ube),e(ube,hgr),e(Za,pgr),e(Za,bbe),e(bbe,_gr),e(Za,ugr),e(Za,vbe),e(vbe,bgr),e(Za,vgr),e(uo,Fgr),e(uo,Z8),e(Z8,ET),e(ET,Fbe),e(Fbe,Tgr),e(ET,Mgr),e(ET,jW),e(jW,Egr),e(ET,Cgr),e(Z8,wgr),e(Z8,CT),e(CT,Tbe),e(Tbe,Agr),e(CT,Lgr),e(CT,DW),e(DW,ygr),e(CT,xgr),e(uo,$gr),e(uo,wT),e(wT,kgr),e(wT,Mbe),e(Mbe,Sgr),e(wT,Rgr),e(wT,Ebe),e(Ebe,Pgr),e(uo,Bgr),M(AT,uo,null),b(f,DOe,u),b(f,zd,u),e(zd,LT),e(LT,Cbe),M(e9,Cbe,null),e(zd,Igr),e(zd,wbe),e(wbe,Ngr),b(f,GOe,u),b(f,Yo,u),M(o9,Yo,null),e(Yo,qgr),e(Yo,Qd),e(Qd,jgr),e(Qd,GW),e(GW,Dgr),e(Qd,Ggr),e(Qd,OW),e(OW,Ogr),e(Qd,Vgr),e(Yo,Xgr),e(Yo,r9),e(r9,zgr),e(r9,Abe),e(Abe,Qgr),e(r9,Wgr),e(Yo,Hgr),e(Yo,Lt),M(t9,Lt,null),e(Lt,Ugr),e(Lt,Lbe),e(Lbe,Jgr),e(Lt,Ygr),e(Lt,Wd),e(Wd,Kgr),e(Wd,ybe),e(ybe,Zgr),e(Wd,ehr),e(Wd,VW),e(VW,ohr),e(Wd,rhr),e(Lt,thr),M(yT,Lt,null),e(Yo,ahr),e(Yo,bo),M(a9,bo,null),e(bo,nhr),e(bo,xbe),e(xbe,shr),e(bo,lhr),e(bo,en),e(en,ihr),e(en,$be),e($be,dhr),e(en,chr),e(en,kbe),e(kbe,fhr),e(en,mhr),e(en,Sbe),e(Sbe,ghr),e(en,hhr),e(bo,phr),e(bo,Rbe),e(Rbe,xT),e(xT,Pbe),e(Pbe,_hr),e(xT,uhr),e(xT,XW),e(XW,bhr),e(xT,vhr),e(bo,Fhr),e(bo,$T),e($T,Thr),e($T,Bbe),e(Bbe,Mhr),e($T,Ehr),e($T,Ibe),e(Ibe,Chr),e(bo,whr),M(kT,bo,null),b(f,OOe,u),b(f,Hd,u),e(Hd,ST),e(ST,Nbe),M(n9,Nbe,null),e(Hd,Ahr),e(Hd,qbe),e(qbe,Lhr),b(f,VOe,u),b(f,Ko,u),M(s9,Ko,null),e(Ko,yhr),e(Ko,Ud),e(Ud,xhr),e(Ud,zW),e(zW,$hr),e(Ud,khr),e(Ud,QW),e(QW,Shr),e(Ud,Rhr),e(Ko,Phr),e(Ko,l9),e(l9,Bhr),e(l9,jbe),e(jbe,Ihr),e(l9,Nhr),e(Ko,qhr),e(Ko,yt),M(i9,yt,null),e(yt,jhr),e(yt,Dbe),e(Dbe,Dhr),e(yt,Ghr),e(yt,Jd),e(Jd,Ohr),e(Jd,Gbe),e(Gbe,Vhr),e(Jd,Xhr),e(Jd,WW),e(WW,zhr),e(Jd,Qhr),e(yt,Whr),M(RT,yt,null),e(Ko,Hhr),e(Ko,vo),M(d9,vo,null),e(vo,Uhr),e(vo,Obe),e(Obe,Jhr),e(vo,Yhr),e(vo,on),e(on,Khr),e(on,Vbe),e(Vbe,Zhr),e(on,epr),e(on,Xbe),e(Xbe,opr),e(on,rpr),e(on,zbe),e(zbe,tpr),e(on,apr),e(vo,npr),e(vo,rn),e(rn,PT),e(PT,Qbe),e(Qbe,spr),e(PT,lpr),e(PT,HW),e(HW,ipr),e(PT,dpr),e(rn,cpr),e(rn,BT),e(BT,Wbe),e(Wbe,fpr),e(BT,mpr),e(BT,UW),e(UW,gpr),e(BT,hpr),e(rn,ppr),e(rn,IT),e(IT,Hbe),e(Hbe,_pr),e(IT,upr),e(IT,JW),e(JW,bpr),e(IT,vpr),e(rn,Fpr),e(rn,NT),e(NT,Ube),e(Ube,Tpr),e(NT,Mpr),e(NT,YW),e(YW,Epr),e(NT,Cpr),e(vo,wpr),e(vo,qT),e(qT,Apr),e(qT,Jbe),e(Jbe,Lpr),e(qT,ypr),e(qT,Ybe),e(Ybe,xpr),e(vo,$pr),M(jT,vo,null),b(f,XOe,u),b(f,Yd,u),e(Yd,DT),e(DT,Kbe),M(c9,Kbe,null),e(Yd,kpr),e(Yd,Zbe),e(Zbe,Spr),b(f,zOe,u),b(f,Zo,u),M(f9,Zo,null),e(Zo,Rpr),e(Zo,Kd),e(Kd,Ppr),e(Kd,KW),e(KW,Bpr),e(Kd,Ipr),e(Kd,ZW),e(ZW,Npr),e(Kd,qpr),e(Zo,jpr),e(Zo,m9),e(m9,Dpr),e(m9,eve),e(eve,Gpr),e(m9,Opr),e(Zo,Vpr),e(Zo,xt),M(g9,xt,null),e(xt,Xpr),e(xt,ove),e(ove,zpr),e(xt,Qpr),e(xt,Zd),e(Zd,Wpr),e(Zd,rve),e(rve,Hpr),e(Zd,Upr),e(Zd,eH),e(eH,Jpr),e(Zd,Ypr),e(xt,Kpr),M(GT,xt,null),e(Zo,Zpr),e(Zo,Fo),M(h9,Fo,null),e(Fo,e_r),e(Fo,tve),e(tve,o_r),e(Fo,r_r),e(Fo,tn),e(tn,t_r),e(tn,ave),e(ave,a_r),e(tn,n_r),e(tn,nve),e(nve,s_r),e(tn,l_r),e(tn,sve),e(sve,i_r),e(tn,d_r),e(Fo,c_r),e(Fo,lve),e(lve,OT),e(OT,ive),e(ive,f_r),e(OT,m_r),e(OT,oH),e(oH,g_r),e(OT,h_r),e(Fo,p_r),e(Fo,VT),e(VT,__r),e(VT,dve),e(dve,u_r),e(VT,b_r),e(VT,cve),e(cve,v_r),e(Fo,F_r),M(XT,Fo,null),b(f,QOe,u),b(f,ec,u),e(ec,zT),e(zT,fve),M(p9,fve,null),e(ec,T_r),e(ec,mve),e(mve,M_r),b(f,WOe,u),b(f,er,u),M(_9,er,null),e(er,E_r),e(er,oc),e(oc,C_r),e(oc,rH),e(rH,w_r),e(oc,A_r),e(oc,tH),e(tH,L_r),e(oc,y_r),e(er,x_r),e(er,u9),e(u9,$_r),e(u9,gve),e(gve,k_r),e(u9,S_r),e(er,R_r),e(er,$t),M(b9,$t,null),e($t,P_r),e($t,hve),e(hve,B_r),e($t,I_r),e($t,rc),e(rc,N_r),e(rc,pve),e(pve,q_r),e(rc,j_r),e(rc,aH),e(aH,D_r),e(rc,G_r),e($t,O_r),M(QT,$t,null),e(er,V_r),e(er,yr),M(v9,yr,null),e(yr,X_r),e(yr,_ve),e(_ve,z_r),e(yr,Q_r),e(yr,an),e(an,W_r),e(an,uve),e(uve,H_r),e(an,U_r),e(an,bve),e(bve,J_r),e(an,Y_r),e(an,vve),e(vve,K_r),e(an,Z_r),e(yr,eur),e(yr,j),e(j,WT),e(WT,Fve),e(Fve,our),e(WT,rur),e(WT,nH),e(nH,tur),e(WT,aur),e(j,nur),e(j,HT),e(HT,Tve),e(Tve,sur),e(HT,lur),e(HT,sH),e(sH,iur),e(HT,dur),e(j,cur),e(j,UT),e(UT,Mve),e(Mve,fur),e(UT,mur),e(UT,lH),e(lH,gur),e(UT,hur),e(j,pur),e(j,JT),e(JT,Eve),e(Eve,_ur),e(JT,uur),e(JT,iH),e(iH,bur),e(JT,vur),e(j,Fur),e(j,YT),e(YT,Cve),e(Cve,Tur),e(YT,Mur),e(YT,dH),e(dH,Eur),e(YT,Cur),e(j,wur),e(j,KT),e(KT,wve),e(wve,Aur),e(KT,Lur),e(KT,cH),e(cH,yur),e(KT,xur),e(j,$ur),e(j,ZT),e(ZT,Ave),e(Ave,kur),e(ZT,Sur),e(ZT,fH),e(fH,Rur),e(ZT,Pur),e(j,Bur),e(j,eM),e(eM,Lve),e(Lve,Iur),e(eM,Nur),e(eM,mH),e(mH,qur),e(eM,jur),e(j,Dur),e(j,oM),e(oM,yve),e(yve,Gur),e(oM,Our),e(oM,gH),e(gH,Vur),e(oM,Xur),e(j,zur),e(j,rM),e(rM,xve),e(xve,Qur),e(rM,Wur),e(rM,hH),e(hH,Hur),e(rM,Uur),e(j,Jur),e(j,tM),e(tM,$ve),e($ve,Yur),e(tM,Kur),e(tM,pH),e(pH,Zur),e(tM,e7r),e(j,o7r),e(j,aM),e(aM,kve),e(kve,r7r),e(aM,t7r),e(aM,_H),e(_H,a7r),e(aM,n7r),e(j,s7r),e(j,nM),e(nM,Sve),e(Sve,l7r),e(nM,i7r),e(nM,uH),e(uH,d7r),e(nM,c7r),e(j,f7r),e(j,sM),e(sM,Rve),e(Rve,m7r),e(sM,g7r),e(sM,bH),e(bH,h7r),e(sM,p7r),e(j,_7r),e(j,lM),e(lM,Pve),e(Pve,u7r),e(lM,b7r),e(lM,vH),e(vH,v7r),e(lM,F7r),e(j,T7r),e(j,iM),e(iM,Bve),e(Bve,M7r),e(iM,E7r),e(iM,FH),e(FH,C7r),e(iM,w7r),e(j,A7r),e(j,dM),e(dM,Ive),e(Ive,L7r),e(dM,y7r),e(dM,TH),e(TH,x7r),e(dM,$7r),e(j,k7r),e(j,Qs),e(Qs,Nve),e(Nve,S7r),e(Qs,R7r),e(Qs,MH),e(MH,P7r),e(Qs,B7r),e(Qs,EH),e(EH,I7r),e(Qs,N7r),e(j,q7r),e(j,cM),e(cM,qve),e(qve,j7r),e(cM,D7r),e(cM,CH),e(CH,G7r),e(cM,O7r),e(j,V7r),e(j,fM),e(fM,jve),e(jve,X7r),e(fM,z7r),e(fM,wH),e(wH,Q7r),e(fM,W7r),e(j,H7r),e(j,mM),e(mM,Dve),e(Dve,U7r),e(mM,J7r),e(mM,AH),e(AH,Y7r),e(mM,K7r),e(j,Z7r),e(j,gM),e(gM,Gve),e(Gve,e1r),e(gM,o1r),e(gM,LH),e(LH,r1r),e(gM,t1r),e(j,a1r),e(j,hM),e(hM,Ove),e(Ove,n1r),e(hM,s1r),e(hM,yH),e(yH,l1r),e(hM,i1r),e(j,d1r),e(j,pM),e(pM,Vve),e(Vve,c1r),e(pM,f1r),e(pM,xH),e(xH,m1r),e(pM,g1r),e(j,h1r),e(j,_M),e(_M,Xve),e(Xve,p1r),e(_M,_1r),e(_M,$H),e($H,u1r),e(_M,b1r),e(j,v1r),e(j,uM),e(uM,zve),e(zve,F1r),e(uM,T1r),e(uM,kH),e(kH,M1r),e(uM,E1r),e(j,C1r),e(j,bM),e(bM,Qve),e(Qve,w1r),e(bM,A1r),e(bM,SH),e(SH,L1r),e(bM,y1r),e(j,x1r),e(j,vM),e(vM,Wve),e(Wve,$1r),e(vM,k1r),e(vM,RH),e(RH,S1r),e(vM,R1r),e(j,P1r),e(j,FM),e(FM,Hve),e(Hve,B1r),e(FM,I1r),e(FM,PH),e(PH,N1r),e(FM,q1r),e(j,j1r),e(j,TM),e(TM,Uve),e(Uve,D1r),e(TM,G1r),e(TM,BH),e(BH,O1r),e(TM,V1r),e(j,X1r),e(j,MM),e(MM,Jve),e(Jve,z1r),e(MM,Q1r),e(MM,IH),e(IH,W1r),e(MM,H1r),e(j,U1r),e(j,EM),e(EM,Yve),e(Yve,J1r),e(EM,Y1r),e(EM,NH),e(NH,K1r),e(EM,Z1r),e(j,e2r),e(j,CM),e(CM,Kve),e(Kve,o2r),e(CM,r2r),e(CM,qH),e(qH,t2r),e(CM,a2r),e(j,n2r),e(j,wM),e(wM,Zve),e(Zve,s2r),e(wM,l2r),e(wM,jH),e(jH,i2r),e(wM,d2r),e(j,c2r),e(j,AM),e(AM,eFe),e(eFe,f2r),e(AM,m2r),e(AM,DH),e(DH,g2r),e(AM,h2r),e(j,p2r),e(j,LM),e(LM,oFe),e(oFe,_2r),e(LM,u2r),e(LM,GH),e(GH,b2r),e(LM,v2r),e(j,F2r),e(j,yM),e(yM,rFe),e(rFe,T2r),e(yM,M2r),e(yM,OH),e(OH,E2r),e(yM,C2r),e(j,w2r),e(j,xM),e(xM,tFe),e(tFe,A2r),e(xM,L2r),e(xM,VH),e(VH,y2r),e(xM,x2r),e(j,$2r),e(j,$M),e($M,aFe),e(aFe,k2r),e($M,S2r),e($M,XH),e(XH,R2r),e($M,P2r),e(j,B2r),e(j,kM),e(kM,nFe),e(nFe,I2r),e(kM,N2r),e(kM,zH),e(zH,q2r),e(kM,j2r),e(j,D2r),e(j,SM),e(SM,sFe),e(sFe,G2r),e(SM,O2r),e(SM,QH),e(QH,V2r),e(SM,X2r),e(j,z2r),e(j,RM),e(RM,lFe),e(lFe,Q2r),e(RM,W2r),e(RM,WH),e(WH,H2r),e(RM,U2r),e(j,J2r),e(j,PM),e(PM,iFe),e(iFe,Y2r),e(PM,K2r),e(PM,HH),e(HH,Z2r),e(PM,ebr),e(j,obr),e(j,BM),e(BM,dFe),e(dFe,rbr),e(BM,tbr),e(BM,UH),e(UH,abr),e(BM,nbr),e(j,sbr),e(j,IM),e(IM,cFe),e(cFe,lbr),e(IM,ibr),e(IM,JH),e(JH,dbr),e(IM,cbr),e(j,fbr),e(j,NM),e(NM,fFe),e(fFe,mbr),e(NM,gbr),e(NM,YH),e(YH,hbr),e(NM,pbr),e(j,_br),e(j,qM),e(qM,mFe),e(mFe,ubr),e(qM,bbr),e(qM,KH),e(KH,vbr),e(qM,Fbr),e(yr,Tbr),M(jM,yr,null),b(f,HOe,u),b(f,tc,u),e(tc,DM),e(DM,gFe),M(F9,gFe,null),e(tc,Mbr),e(tc,hFe),e(hFe,Ebr),b(f,UOe,u),b(f,or,u),M(T9,or,null),e(or,Cbr),e(or,ac),e(ac,wbr),e(ac,ZH),e(ZH,Abr),e(ac,Lbr),e(ac,eU),e(eU,ybr),e(ac,xbr),e(or,$br),e(or,M9),e(M9,kbr),e(M9,pFe),e(pFe,Sbr),e(M9,Rbr),e(or,Pbr),e(or,kt),M(E9,kt,null),e(kt,Bbr),e(kt,_Fe),e(_Fe,Ibr),e(kt,Nbr),e(kt,nc),e(nc,qbr),e(nc,uFe),e(uFe,jbr),e(nc,Dbr),e(nc,oU),e(oU,Gbr),e(nc,Obr),e(kt,Vbr),M(GM,kt,null),e(or,Xbr),e(or,xr),M(C9,xr,null),e(xr,zbr),e(xr,bFe),e(bFe,Qbr),e(xr,Wbr),e(xr,nn),e(nn,Hbr),e(nn,vFe),e(vFe,Ubr),e(nn,Jbr),e(nn,FFe),e(FFe,Ybr),e(nn,Kbr),e(nn,TFe),e(TFe,Zbr),e(nn,evr),e(xr,ovr),e(xr,se),e(se,OM),e(OM,MFe),e(MFe,rvr),e(OM,tvr),e(OM,rU),e(rU,avr),e(OM,nvr),e(se,svr),e(se,VM),e(VM,EFe),e(EFe,lvr),e(VM,ivr),e(VM,tU),e(tU,dvr),e(VM,cvr),e(se,fvr),e(se,XM),e(XM,CFe),e(CFe,mvr),e(XM,gvr),e(XM,aU),e(aU,hvr),e(XM,pvr),e(se,_vr),e(se,zM),e(zM,wFe),e(wFe,uvr),e(zM,bvr),e(zM,nU),e(nU,vvr),e(zM,Fvr),e(se,Tvr),e(se,QM),e(QM,AFe),e(AFe,Mvr),e(QM,Evr),e(QM,sU),e(sU,Cvr),e(QM,wvr),e(se,Avr),e(se,WM),e(WM,LFe),e(LFe,Lvr),e(WM,yvr),e(WM,lU),e(lU,xvr),e(WM,$vr),e(se,kvr),e(se,HM),e(HM,yFe),e(yFe,Svr),e(HM,Rvr),e(HM,iU),e(iU,Pvr),e(HM,Bvr),e(se,Ivr),e(se,UM),e(UM,xFe),e(xFe,Nvr),e(UM,qvr),e(UM,dU),e(dU,jvr),e(UM,Dvr),e(se,Gvr),e(se,JM),e(JM,$Fe),e($Fe,Ovr),e(JM,Vvr),e(JM,cU),e(cU,Xvr),e(JM,zvr),e(se,Qvr),e(se,YM),e(YM,kFe),e(kFe,Wvr),e(YM,Hvr),e(YM,fU),e(fU,Uvr),e(YM,Jvr),e(se,Yvr),e(se,KM),e(KM,SFe),e(SFe,Kvr),e(KM,Zvr),e(KM,mU),e(mU,eFr),e(KM,oFr),e(se,rFr),e(se,ZM),e(ZM,RFe),e(RFe,tFr),e(ZM,aFr),e(ZM,gU),e(gU,nFr),e(ZM,sFr),e(se,lFr),e(se,eE),e(eE,PFe),e(PFe,iFr),e(eE,dFr),e(eE,hU),e(hU,cFr),e(eE,fFr),e(se,mFr),e(se,oE),e(oE,BFe),e(BFe,gFr),e(oE,hFr),e(oE,pU),e(pU,pFr),e(oE,_Fr),e(se,uFr),e(se,rE),e(rE,IFe),e(IFe,bFr),e(rE,vFr),e(rE,_U),e(_U,FFr),e(rE,TFr),e(se,MFr),e(se,tE),e(tE,NFe),e(NFe,EFr),e(tE,CFr),e(tE,uU),e(uU,wFr),e(tE,AFr),e(se,LFr),e(se,aE),e(aE,qFe),e(qFe,yFr),e(aE,xFr),e(aE,bU),e(bU,$Fr),e(aE,kFr),e(se,SFr),e(se,nE),e(nE,jFe),e(jFe,RFr),e(nE,PFr),e(nE,vU),e(vU,BFr),e(nE,IFr),e(se,NFr),e(se,sE),e(sE,DFe),e(DFe,qFr),e(sE,jFr),e(sE,FU),e(FU,DFr),e(sE,GFr),e(se,OFr),e(se,lE),e(lE,GFe),e(GFe,VFr),e(lE,XFr),e(lE,TU),e(TU,zFr),e(lE,QFr),e(se,WFr),e(se,iE),e(iE,OFe),e(OFe,HFr),e(iE,UFr),e(iE,MU),e(MU,JFr),e(iE,YFr),e(se,KFr),e(se,dE),e(dE,VFe),e(VFe,ZFr),e(dE,e6r),e(dE,EU),e(EU,o6r),e(dE,r6r),e(se,t6r),e(se,cE),e(cE,XFe),e(XFe,a6r),e(cE,n6r),e(cE,CU),e(CU,s6r),e(cE,l6r),e(xr,i6r),M(fE,xr,null),b(f,JOe,u),b(f,sc,u),e(sc,mE),e(mE,zFe),M(w9,zFe,null),e(sc,d6r),e(sc,QFe),e(QFe,c6r),b(f,YOe,u),b(f,rr,u),M(A9,rr,null),e(rr,f6r),e(rr,lc),e(lc,m6r),e(lc,wU),e(wU,g6r),e(lc,h6r),e(lc,AU),e(AU,p6r),e(lc,_6r),e(rr,u6r),e(rr,L9),e(L9,b6r),e(L9,WFe),e(WFe,v6r),e(L9,F6r),e(rr,T6r),e(rr,St),M(y9,St,null),e(St,M6r),e(St,HFe),e(HFe,E6r),e(St,C6r),e(St,ic),e(ic,w6r),e(ic,UFe),e(UFe,A6r),e(ic,L6r),e(ic,LU),e(LU,y6r),e(ic,x6r),e(St,$6r),M(gE,St,null),e(rr,k6r),e(rr,$r),M(x9,$r,null),e($r,S6r),e($r,JFe),e(JFe,R6r),e($r,P6r),e($r,sn),e(sn,B6r),e(sn,YFe),e(YFe,I6r),e(sn,N6r),e(sn,KFe),e(KFe,q6r),e(sn,j6r),e(sn,ZFe),e(ZFe,D6r),e(sn,G6r),e($r,O6r),e($r,Me),e(Me,hE),e(hE,e6e),e(e6e,V6r),e(hE,X6r),e(hE,yU),e(yU,z6r),e(hE,Q6r),e(Me,W6r),e(Me,pE),e(pE,o6e),e(o6e,H6r),e(pE,U6r),e(pE,xU),e(xU,J6r),e(pE,Y6r),e(Me,K6r),e(Me,_E),e(_E,r6e),e(r6e,Z6r),e(_E,eTr),e(_E,$U),e($U,oTr),e(_E,rTr),e(Me,tTr),e(Me,uE),e(uE,t6e),e(t6e,aTr),e(uE,nTr),e(uE,kU),e(kU,sTr),e(uE,lTr),e(Me,iTr),e(Me,bE),e(bE,a6e),e(a6e,dTr),e(bE,cTr),e(bE,SU),e(SU,fTr),e(bE,mTr),e(Me,gTr),e(Me,vE),e(vE,n6e),e(n6e,hTr),e(vE,pTr),e(vE,RU),e(RU,_Tr),e(vE,uTr),e(Me,bTr),e(Me,FE),e(FE,s6e),e(s6e,vTr),e(FE,FTr),e(FE,PU),e(PU,TTr),e(FE,MTr),e(Me,ETr),e(Me,TE),e(TE,l6e),e(l6e,CTr),e(TE,wTr),e(TE,BU),e(BU,ATr),e(TE,LTr),e(Me,yTr),e(Me,ME),e(ME,i6e),e(i6e,xTr),e(ME,$Tr),e(ME,IU),e(IU,kTr),e(ME,STr),e(Me,RTr),e(Me,EE),e(EE,d6e),e(d6e,PTr),e(EE,BTr),e(EE,NU),e(NU,ITr),e(EE,NTr),e(Me,qTr),e(Me,CE),e(CE,c6e),e(c6e,jTr),e(CE,DTr),e(CE,qU),e(qU,GTr),e(CE,OTr),e(Me,VTr),e(Me,wE),e(wE,f6e),e(f6e,XTr),e(wE,zTr),e(wE,jU),e(jU,QTr),e(wE,WTr),e(Me,HTr),e(Me,AE),e(AE,m6e),e(m6e,UTr),e(AE,JTr),e(AE,DU),e(DU,YTr),e(AE,KTr),e($r,ZTr),M(LE,$r,null),b(f,KOe,u),b(f,dc,u),e(dc,yE),e(yE,g6e),M($9,g6e,null),e(dc,eMr),e(dc,h6e),e(h6e,oMr),b(f,ZOe,u),b(f,tr,u),M(k9,tr,null),e(tr,rMr),e(tr,cc),e(cc,tMr),e(cc,GU),e(GU,aMr),e(cc,nMr),e(cc,OU),e(OU,sMr),e(cc,lMr),e(tr,iMr),e(tr,S9),e(S9,dMr),e(S9,p6e),e(p6e,cMr),e(S9,fMr),e(tr,mMr),e(tr,Rt),M(R9,Rt,null),e(Rt,gMr),e(Rt,_6e),e(_6e,hMr),e(Rt,pMr),e(Rt,fc),e(fc,_Mr),e(fc,u6e),e(u6e,uMr),e(fc,bMr),e(fc,VU),e(VU,vMr),e(fc,FMr),e(Rt,TMr),M(xE,Rt,null),e(tr,MMr),e(tr,kr),M(P9,kr,null),e(kr,EMr),e(kr,b6e),e(b6e,CMr),e(kr,wMr),e(kr,ln),e(ln,AMr),e(ln,v6e),e(v6e,LMr),e(ln,yMr),e(ln,F6e),e(F6e,xMr),e(ln,$Mr),e(ln,T6e),e(T6e,kMr),e(ln,SMr),e(kr,RMr),e(kr,dn),e(dn,$E),e($E,M6e),e(M6e,PMr),e($E,BMr),e($E,XU),e(XU,IMr),e($E,NMr),e(dn,qMr),e(dn,kE),e(kE,E6e),e(E6e,jMr),e(kE,DMr),e(kE,zU),e(zU,GMr),e(kE,OMr),e(dn,VMr),e(dn,SE),e(SE,C6e),e(C6e,XMr),e(SE,zMr),e(SE,QU),e(QU,QMr),e(SE,WMr),e(dn,HMr),e(dn,RE),e(RE,w6e),e(w6e,UMr),e(RE,JMr),e(RE,WU),e(WU,YMr),e(RE,KMr),e(kr,ZMr),M(PE,kr,null),b(f,eVe,u),b(f,mc,u),e(mc,BE),e(BE,A6e),M(B9,A6e,null),e(mc,eEr),e(mc,L6e),e(L6e,oEr),b(f,oVe,u),b(f,ar,u),M(I9,ar,null),e(ar,rEr),e(ar,gc),e(gc,tEr),e(gc,HU),e(HU,aEr),e(gc,nEr),e(gc,UU),e(UU,sEr),e(gc,lEr),e(ar,iEr),e(ar,N9),e(N9,dEr),e(N9,y6e),e(y6e,cEr),e(N9,fEr),e(ar,mEr),e(ar,Pt),M(q9,Pt,null),e(Pt,gEr),e(Pt,x6e),e(x6e,hEr),e(Pt,pEr),e(Pt,hc),e(hc,_Er),e(hc,$6e),e($6e,uEr),e(hc,bEr),e(hc,JU),e(JU,vEr),e(hc,FEr),e(Pt,TEr),M(IE,Pt,null),e(ar,MEr),e(ar,Sr),M(j9,Sr,null),e(Sr,EEr),e(Sr,k6e),e(k6e,CEr),e(Sr,wEr),e(Sr,cn),e(cn,AEr),e(cn,S6e),e(S6e,LEr),e(cn,yEr),e(cn,R6e),e(R6e,xEr),e(cn,$Er),e(cn,P6e),e(P6e,kEr),e(cn,SEr),e(Sr,REr),e(Sr,ie),e(ie,NE),e(NE,B6e),e(B6e,PEr),e(NE,BEr),e(NE,YU),e(YU,IEr),e(NE,NEr),e(ie,qEr),e(ie,qE),e(qE,I6e),e(I6e,jEr),e(qE,DEr),e(qE,KU),e(KU,GEr),e(qE,OEr),e(ie,VEr),e(ie,jE),e(jE,N6e),e(N6e,XEr),e(jE,zEr),e(jE,ZU),e(ZU,QEr),e(jE,WEr),e(ie,HEr),e(ie,DE),e(DE,q6e),e(q6e,UEr),e(DE,JEr),e(DE,eJ),e(eJ,YEr),e(DE,KEr),e(ie,ZEr),e(ie,GE),e(GE,j6e),e(j6e,e4r),e(GE,o4r),e(GE,oJ),e(oJ,r4r),e(GE,t4r),e(ie,a4r),e(ie,OE),e(OE,D6e),e(D6e,n4r),e(OE,s4r),e(OE,rJ),e(rJ,l4r),e(OE,i4r),e(ie,d4r),e(ie,VE),e(VE,G6e),e(G6e,c4r),e(VE,f4r),e(VE,tJ),e(tJ,m4r),e(VE,g4r),e(ie,h4r),e(ie,XE),e(XE,O6e),e(O6e,p4r),e(XE,_4r),e(XE,aJ),e(aJ,u4r),e(XE,b4r),e(ie,v4r),e(ie,zE),e(zE,V6e),e(V6e,F4r),e(zE,T4r),e(zE,nJ),e(nJ,M4r),e(zE,E4r),e(ie,C4r),e(ie,QE),e(QE,X6e),e(X6e,w4r),e(QE,A4r),e(QE,sJ),e(sJ,L4r),e(QE,y4r),e(ie,x4r),e(ie,WE),e(WE,z6e),e(z6e,$4r),e(WE,k4r),e(WE,lJ),e(lJ,S4r),e(WE,R4r),e(ie,P4r),e(ie,HE),e(HE,Q6e),e(Q6e,B4r),e(HE,I4r),e(HE,iJ),e(iJ,N4r),e(HE,q4r),e(ie,j4r),e(ie,UE),e(UE,W6e),e(W6e,D4r),e(UE,G4r),e(UE,dJ),e(dJ,O4r),e(UE,V4r),e(ie,X4r),e(ie,JE),e(JE,H6e),e(H6e,z4r),e(JE,Q4r),e(JE,cJ),e(cJ,W4r),e(JE,H4r),e(ie,U4r),e(ie,YE),e(YE,U6e),e(U6e,J4r),e(YE,Y4r),e(YE,fJ),e(fJ,K4r),e(YE,Z4r),e(ie,eCr),e(ie,KE),e(KE,J6e),e(J6e,oCr),e(KE,rCr),e(KE,mJ),e(mJ,tCr),e(KE,aCr),e(ie,nCr),e(ie,ZE),e(ZE,Y6e),e(Y6e,sCr),e(ZE,lCr),e(ZE,gJ),e(gJ,iCr),e(ZE,dCr),e(ie,cCr),e(ie,e4),e(e4,K6e),e(K6e,fCr),e(e4,mCr),e(e4,hJ),e(hJ,gCr),e(e4,hCr),e(ie,pCr),e(ie,o4),e(o4,Z6e),e(Z6e,_Cr),e(o4,uCr),e(o4,pJ),e(pJ,bCr),e(o4,vCr),e(ie,FCr),e(ie,r4),e(r4,eTe),e(eTe,TCr),e(r4,MCr),e(r4,_J),e(_J,ECr),e(r4,CCr),e(Sr,wCr),M(t4,Sr,null),b(f,rVe,u),b(f,pc,u),e(pc,a4),e(a4,oTe),M(D9,oTe,null),e(pc,ACr),e(pc,rTe),e(rTe,LCr),b(f,tVe,u),b(f,nr,u),M(G9,nr,null),e(nr,yCr),e(nr,_c),e(_c,xCr),e(_c,uJ),e(uJ,$Cr),e(_c,kCr),e(_c,bJ),e(bJ,SCr),e(_c,RCr),e(nr,PCr),e(nr,O9),e(O9,BCr),e(O9,tTe),e(tTe,ICr),e(O9,NCr),e(nr,qCr),e(nr,Bt),M(V9,Bt,null),e(Bt,jCr),e(Bt,aTe),e(aTe,DCr),e(Bt,GCr),e(Bt,uc),e(uc,OCr),e(uc,nTe),e(nTe,VCr),e(uc,XCr),e(uc,vJ),e(vJ,zCr),e(uc,QCr),e(Bt,WCr),M(n4,Bt,null),e(nr,HCr),e(nr,Rr),M(X9,Rr,null),e(Rr,UCr),e(Rr,sTe),e(sTe,JCr),e(Rr,YCr),e(Rr,fn),e(fn,KCr),e(fn,lTe),e(lTe,ZCr),e(fn,e5r),e(fn,iTe),e(iTe,o5r),e(fn,r5r),e(fn,dTe),e(dTe,t5r),e(fn,a5r),e(Rr,n5r),e(Rr,ye),e(ye,s4),e(s4,cTe),e(cTe,s5r),e(s4,l5r),e(s4,FJ),e(FJ,i5r),e(s4,d5r),e(ye,c5r),e(ye,l4),e(l4,fTe),e(fTe,f5r),e(l4,m5r),e(l4,TJ),e(TJ,g5r),e(l4,h5r),e(ye,p5r),e(ye,i4),e(i4,mTe),e(mTe,_5r),e(i4,u5r),e(i4,MJ),e(MJ,b5r),e(i4,v5r),e(ye,F5r),e(ye,d4),e(d4,gTe),e(gTe,T5r),e(d4,M5r),e(d4,EJ),e(EJ,E5r),e(d4,C5r),e(ye,w5r),e(ye,c4),e(c4,hTe),e(hTe,A5r),e(c4,L5r),e(c4,CJ),e(CJ,y5r),e(c4,x5r),e(ye,$5r),e(ye,f4),e(f4,pTe),e(pTe,k5r),e(f4,S5r),e(f4,wJ),e(wJ,R5r),e(f4,P5r),e(ye,B5r),e(ye,m4),e(m4,_Te),e(_Te,I5r),e(m4,N5r),e(m4,AJ),e(AJ,q5r),e(m4,j5r),e(ye,D5r),e(ye,g4),e(g4,uTe),e(uTe,G5r),e(g4,O5r),e(g4,LJ),e(LJ,V5r),e(g4,X5r),e(ye,z5r),e(ye,h4),e(h4,bTe),e(bTe,Q5r),e(h4,W5r),e(h4,yJ),e(yJ,H5r),e(h4,U5r),e(ye,J5r),e(ye,p4),e(p4,vTe),e(vTe,Y5r),e(p4,K5r),e(p4,xJ),e(xJ,Z5r),e(p4,e3r),e(Rr,o3r),M(_4,Rr,null),b(f,aVe,u),b(f,bc,u),e(bc,u4),e(u4,FTe),M(z9,FTe,null),e(bc,r3r),e(bc,TTe),e(TTe,t3r),b(f,nVe,u),b(f,sr,u),M(Q9,sr,null),e(sr,a3r),e(sr,vc),e(vc,n3r),e(vc,$J),e($J,s3r),e(vc,l3r),e(vc,kJ),e(kJ,i3r),e(vc,d3r),e(sr,c3r),e(sr,W9),e(W9,f3r),e(W9,MTe),e(MTe,m3r),e(W9,g3r),e(sr,h3r),e(sr,It),M(H9,It,null),e(It,p3r),e(It,ETe),e(ETe,_3r),e(It,u3r),e(It,Fc),e(Fc,b3r),e(Fc,CTe),e(CTe,v3r),e(Fc,F3r),e(Fc,SJ),e(SJ,T3r),e(Fc,M3r),e(It,E3r),M(b4,It,null),e(sr,C3r),e(sr,Pr),M(U9,Pr,null),e(Pr,w3r),e(Pr,wTe),e(wTe,A3r),e(Pr,L3r),e(Pr,mn),e(mn,y3r),e(mn,ATe),e(ATe,x3r),e(mn,$3r),e(mn,LTe),e(LTe,k3r),e(mn,S3r),e(mn,yTe),e(yTe,R3r),e(mn,P3r),e(Pr,B3r),e(Pr,te),e(te,v4),e(v4,xTe),e(xTe,I3r),e(v4,N3r),e(v4,RJ),e(RJ,q3r),e(v4,j3r),e(te,D3r),e(te,F4),e(F4,$Te),e($Te,G3r),e(F4,O3r),e(F4,PJ),e(PJ,V3r),e(F4,X3r),e(te,z3r),e(te,T4),e(T4,kTe),e(kTe,Q3r),e(T4,W3r),e(T4,BJ),e(BJ,H3r),e(T4,U3r),e(te,J3r),e(te,M4),e(M4,STe),e(STe,Y3r),e(M4,K3r),e(M4,IJ),e(IJ,Z3r),e(M4,e0r),e(te,o0r),e(te,E4),e(E4,RTe),e(RTe,r0r),e(E4,t0r),e(E4,NJ),e(NJ,a0r),e(E4,n0r),e(te,s0r),e(te,C4),e(C4,PTe),e(PTe,l0r),e(C4,i0r),e(C4,qJ),e(qJ,d0r),e(C4,c0r),e(te,f0r),e(te,w4),e(w4,BTe),e(BTe,m0r),e(w4,g0r),e(w4,jJ),e(jJ,h0r),e(w4,p0r),e(te,_0r),e(te,A4),e(A4,ITe),e(ITe,u0r),e(A4,b0r),e(A4,DJ),e(DJ,v0r),e(A4,F0r),e(te,T0r),e(te,L4),e(L4,NTe),e(NTe,M0r),e(L4,E0r),e(L4,GJ),e(GJ,C0r),e(L4,w0r),e(te,A0r),e(te,y4),e(y4,qTe),e(qTe,L0r),e(y4,y0r),e(y4,OJ),e(OJ,x0r),e(y4,$0r),e(te,k0r),e(te,x4),e(x4,jTe),e(jTe,S0r),e(x4,R0r),e(x4,VJ),e(VJ,P0r),e(x4,B0r),e(te,I0r),e(te,$4),e($4,DTe),e(DTe,N0r),e($4,q0r),e($4,XJ),e(XJ,j0r),e($4,D0r),e(te,G0r),e(te,k4),e(k4,GTe),e(GTe,O0r),e(k4,V0r),e(k4,zJ),e(zJ,X0r),e(k4,z0r),e(te,Q0r),e(te,S4),e(S4,OTe),e(OTe,W0r),e(S4,H0r),e(S4,QJ),e(QJ,U0r),e(S4,J0r),e(te,Y0r),e(te,R4),e(R4,VTe),e(VTe,K0r),e(R4,Z0r),e(R4,WJ),e(WJ,ewr),e(R4,owr),e(te,rwr),e(te,P4),e(P4,XTe),e(XTe,twr),e(P4,awr),e(P4,HJ),e(HJ,nwr),e(P4,swr),e(te,lwr),e(te,B4),e(B4,zTe),e(zTe,iwr),e(B4,dwr),e(B4,UJ),e(UJ,cwr),e(B4,fwr),e(te,mwr),e(te,I4),e(I4,QTe),e(QTe,gwr),e(I4,hwr),e(I4,JJ),e(JJ,pwr),e(I4,_wr),e(te,uwr),e(te,N4),e(N4,WTe),e(WTe,bwr),e(N4,vwr),e(N4,YJ),e(YJ,Fwr),e(N4,Twr),e(te,Mwr),e(te,q4),e(q4,HTe),e(HTe,Ewr),e(q4,Cwr),e(q4,KJ),e(KJ,wwr),e(q4,Awr),e(te,Lwr),e(te,j4),e(j4,UTe),e(UTe,ywr),e(j4,xwr),e(j4,ZJ),e(ZJ,$wr),e(j4,kwr),e(te,Swr),e(te,D4),e(D4,JTe),e(JTe,Rwr),e(D4,Pwr),e(D4,eY),e(eY,Bwr),e(D4,Iwr),e(te,Nwr),e(te,G4),e(G4,YTe),e(YTe,qwr),e(G4,jwr),e(G4,oY),e(oY,Dwr),e(G4,Gwr),e(te,Owr),e(te,O4),e(O4,KTe),e(KTe,Vwr),e(O4,Xwr),e(O4,rY),e(rY,zwr),e(O4,Qwr),e(te,Wwr),e(te,V4),e(V4,ZTe),e(ZTe,Hwr),e(V4,Uwr),e(V4,tY),e(tY,Jwr),e(V4,Ywr),e(te,Kwr),e(te,X4),e(X4,eMe),e(eMe,Zwr),e(X4,eAr),e(X4,aY),e(aY,oAr),e(X4,rAr),e(Pr,tAr),M(z4,Pr,null),b(f,sVe,u),b(f,Tc,u),e(Tc,Q4),e(Q4,oMe),M(J9,oMe,null),e(Tc,aAr),e(Tc,rMe),e(rMe,nAr),b(f,lVe,u),b(f,lr,u),M(Y9,lr,null),e(lr,sAr),e(lr,Mc),e(Mc,lAr),e(Mc,nY),e(nY,iAr),e(Mc,dAr),e(Mc,sY),e(sY,cAr),e(Mc,fAr),e(lr,mAr),e(lr,K9),e(K9,gAr),e(K9,tMe),e(tMe,hAr),e(K9,pAr),e(lr,_Ar),e(lr,Nt),M(Z9,Nt,null),e(Nt,uAr),e(Nt,aMe),e(aMe,bAr),e(Nt,vAr),e(Nt,Ec),e(Ec,FAr),e(Ec,nMe),e(nMe,TAr),e(Ec,MAr),e(Ec,lY),e(lY,EAr),e(Ec,CAr),e(Nt,wAr),M(W4,Nt,null),e(lr,AAr),e(lr,Br),M(ex,Br,null),e(Br,LAr),e(Br,sMe),e(sMe,yAr),e(Br,xAr),e(Br,gn),e(gn,$Ar),e(gn,lMe),e(lMe,kAr),e(gn,SAr),e(gn,iMe),e(iMe,RAr),e(gn,PAr),e(gn,dMe),e(dMe,BAr),e(gn,IAr),e(Br,NAr),e(Br,_e),e(_e,H4),e(H4,cMe),e(cMe,qAr),e(H4,jAr),e(H4,iY),e(iY,DAr),e(H4,GAr),e(_e,OAr),e(_e,U4),e(U4,fMe),e(fMe,VAr),e(U4,XAr),e(U4,dY),e(dY,zAr),e(U4,QAr),e(_e,WAr),e(_e,J4),e(J4,mMe),e(mMe,HAr),e(J4,UAr),e(J4,cY),e(cY,JAr),e(J4,YAr),e(_e,KAr),e(_e,Y4),e(Y4,gMe),e(gMe,ZAr),e(Y4,eLr),e(Y4,fY),e(fY,oLr),e(Y4,rLr),e(_e,tLr),e(_e,K4),e(K4,hMe),e(hMe,aLr),e(K4,nLr),e(K4,mY),e(mY,sLr),e(K4,lLr),e(_e,iLr),e(_e,Z4),e(Z4,pMe),e(pMe,dLr),e(Z4,cLr),e(Z4,gY),e(gY,fLr),e(Z4,mLr),e(_e,gLr),e(_e,eC),e(eC,_Me),e(_Me,hLr),e(eC,pLr),e(eC,hY),e(hY,_Lr),e(eC,uLr),e(_e,bLr),e(_e,oC),e(oC,uMe),e(uMe,vLr),e(oC,FLr),e(oC,pY),e(pY,TLr),e(oC,MLr),e(_e,ELr),e(_e,rC),e(rC,bMe),e(bMe,CLr),e(rC,wLr),e(rC,_Y),e(_Y,ALr),e(rC,LLr),e(_e,yLr),e(_e,tC),e(tC,vMe),e(vMe,xLr),e(tC,$Lr),e(tC,uY),e(uY,kLr),e(tC,SLr),e(_e,RLr),e(_e,aC),e(aC,FMe),e(FMe,PLr),e(aC,BLr),e(aC,bY),e(bY,ILr),e(aC,NLr),e(_e,qLr),e(_e,nC),e(nC,TMe),e(TMe,jLr),e(nC,DLr),e(nC,vY),e(vY,GLr),e(nC,OLr),e(_e,VLr),e(_e,sC),e(sC,MMe),e(MMe,XLr),e(sC,zLr),e(sC,FY),e(FY,QLr),e(sC,WLr),e(_e,HLr),e(_e,lC),e(lC,EMe),e(EMe,ULr),e(lC,JLr),e(lC,TY),e(TY,YLr),e(lC,KLr),e(_e,ZLr),e(_e,iC),e(iC,CMe),e(CMe,eyr),e(iC,oyr),e(iC,MY),e(MY,ryr),e(iC,tyr),e(_e,ayr),e(_e,dC),e(dC,wMe),e(wMe,nyr),e(dC,syr),e(dC,EY),e(EY,lyr),e(dC,iyr),e(_e,dyr),e(_e,cC),e(cC,AMe),e(AMe,cyr),e(cC,fyr),e(cC,CY),e(CY,myr),e(cC,gyr),e(Br,hyr),M(fC,Br,null),b(f,iVe,u),b(f,Cc,u),e(Cc,mC),e(mC,LMe),M(ox,LMe,null),e(Cc,pyr),e(Cc,yMe),e(yMe,_yr),b(f,dVe,u),b(f,ir,u),M(rx,ir,null),e(ir,uyr),e(ir,wc),e(wc,byr),e(wc,wY),e(wY,vyr),e(wc,Fyr),e(wc,AY),e(AY,Tyr),e(wc,Myr),e(ir,Eyr),e(ir,tx),e(tx,Cyr),e(tx,xMe),e(xMe,wyr),e(tx,Ayr),e(ir,Lyr),e(ir,qt),M(ax,qt,null),e(qt,yyr),e(qt,$Me),e($Me,xyr),e(qt,$yr),e(qt,Ac),e(Ac,kyr),e(Ac,kMe),e(kMe,Syr),e(Ac,Ryr),e(Ac,LY),e(LY,Pyr),e(Ac,Byr),e(qt,Iyr),M(gC,qt,null),e(ir,Nyr),e(ir,Ir),M(nx,Ir,null),e(Ir,qyr),e(Ir,SMe),e(SMe,jyr),e(Ir,Dyr),e(Ir,hn),e(hn,Gyr),e(hn,RMe),e(RMe,Oyr),e(hn,Vyr),e(hn,PMe),e(PMe,Xyr),e(hn,zyr),e(hn,BMe),e(BMe,Qyr),e(hn,Wyr),e(Ir,Hyr),e(Ir,sx),e(sx,hC),e(hC,IMe),e(IMe,Uyr),e(hC,Jyr),e(hC,yY),e(yY,Yyr),e(hC,Kyr),e(sx,Zyr),e(sx,pC),e(pC,NMe),e(NMe,e8r),e(pC,o8r),e(pC,xY),e(xY,r8r),e(pC,t8r),e(Ir,a8r),M(_C,Ir,null),b(f,cVe,u),b(f,Lc,u),e(Lc,uC),e(uC,qMe),M(lx,qMe,null),e(Lc,n8r),e(Lc,jMe),e(jMe,s8r),b(f,fVe,u),b(f,dr,u),M(ix,dr,null),e(dr,l8r),e(dr,yc),e(yc,i8r),e(yc,$Y),e($Y,d8r),e(yc,c8r),e(yc,kY),e(kY,f8r),e(yc,m8r),e(dr,g8r),e(dr,dx),e(dx,h8r),e(dx,DMe),e(DMe,p8r),e(dx,_8r),e(dr,u8r),e(dr,jt),M(cx,jt,null),e(jt,b8r),e(jt,GMe),e(GMe,v8r),e(jt,F8r),e(jt,xc),e(xc,T8r),e(xc,OMe),e(OMe,M8r),e(xc,E8r),e(xc,SY),e(SY,C8r),e(xc,w8r),e(jt,A8r),M(bC,jt,null),e(dr,L8r),e(dr,Nr),M(fx,Nr,null),e(Nr,y8r),e(Nr,VMe),e(VMe,x8r),e(Nr,$8r),e(Nr,pn),e(pn,k8r),e(pn,XMe),e(XMe,S8r),e(pn,R8r),e(pn,zMe),e(zMe,P8r),e(pn,B8r),e(pn,QMe),e(QMe,I8r),e(pn,N8r),e(Nr,q8r),e(Nr,WMe),e(WMe,vC),e(vC,HMe),e(HMe,j8r),e(vC,D8r),e(vC,RY),e(RY,G8r),e(vC,O8r),e(Nr,V8r),M(FC,Nr,null),b(f,mVe,u),b(f,$c,u),e($c,TC),e(TC,UMe),M(mx,UMe,null),e($c,X8r),e($c,JMe),e(JMe,z8r),b(f,gVe,u),b(f,cr,u),M(gx,cr,null),e(cr,Q8r),e(cr,kc),e(kc,W8r),e(kc,PY),e(PY,H8r),e(kc,U8r),e(kc,BY),e(BY,J8r),e(kc,Y8r),e(cr,K8r),e(cr,hx),e(hx,Z8r),e(hx,YMe),e(YMe,e9r),e(hx,o9r),e(cr,r9r),e(cr,Dt),M(px,Dt,null),e(Dt,t9r),e(Dt,KMe),e(KMe,a9r),e(Dt,n9r),e(Dt,Sc),e(Sc,s9r),e(Sc,ZMe),e(ZMe,l9r),e(Sc,i9r),e(Sc,IY),e(IY,d9r),e(Sc,c9r),e(Dt,f9r),M(MC,Dt,null),e(cr,m9r),e(cr,qr),M(_x,qr,null),e(qr,g9r),e(qr,eEe),e(eEe,h9r),e(qr,p9r),e(qr,_n),e(_n,_9r),e(_n,oEe),e(oEe,u9r),e(_n,b9r),e(_n,rEe),e(rEe,v9r),e(_n,F9r),e(_n,tEe),e(tEe,T9r),e(_n,M9r),e(qr,E9r),e(qr,de),e(de,EC),e(EC,aEe),e(aEe,C9r),e(EC,w9r),e(EC,NY),e(NY,A9r),e(EC,L9r),e(de,y9r),e(de,CC),e(CC,nEe),e(nEe,x9r),e(CC,$9r),e(CC,qY),e(qY,k9r),e(CC,S9r),e(de,R9r),e(de,wC),e(wC,sEe),e(sEe,P9r),e(wC,B9r),e(wC,jY),e(jY,I9r),e(wC,N9r),e(de,q9r),e(de,AC),e(AC,lEe),e(lEe,j9r),e(AC,D9r),e(AC,DY),e(DY,G9r),e(AC,O9r),e(de,V9r),e(de,LC),e(LC,iEe),e(iEe,X9r),e(LC,z9r),e(LC,GY),e(GY,Q9r),e(LC,W9r),e(de,H9r),e(de,yC),e(yC,dEe),e(dEe,U9r),e(yC,J9r),e(yC,OY),e(OY,Y9r),e(yC,K9r),e(de,Z9r),e(de,xC),e(xC,cEe),e(cEe,exr),e(xC,oxr),e(xC,VY),e(VY,rxr),e(xC,txr),e(de,axr),e(de,$C),e($C,fEe),e(fEe,nxr),e($C,sxr),e($C,XY),e(XY,lxr),e($C,ixr),e(de,dxr),e(de,kC),e(kC,mEe),e(mEe,cxr),e(kC,fxr),e(kC,zY),e(zY,mxr),e(kC,gxr),e(de,hxr),e(de,SC),e(SC,gEe),e(gEe,pxr),e(SC,_xr),e(SC,QY),e(QY,uxr),e(SC,bxr),e(de,vxr),e(de,RC),e(RC,hEe),e(hEe,Fxr),e(RC,Txr),e(RC,WY),e(WY,Mxr),e(RC,Exr),e(de,Cxr),e(de,PC),e(PC,pEe),e(pEe,wxr),e(PC,Axr),e(PC,HY),e(HY,Lxr),e(PC,yxr),e(de,xxr),e(de,BC),e(BC,_Ee),e(_Ee,$xr),e(BC,kxr),e(BC,UY),e(UY,Sxr),e(BC,Rxr),e(de,Pxr),e(de,IC),e(IC,uEe),e(uEe,Bxr),e(IC,Ixr),e(IC,JY),e(JY,Nxr),e(IC,qxr),e(de,jxr),e(de,NC),e(NC,bEe),e(bEe,Dxr),e(NC,Gxr),e(NC,YY),e(YY,Oxr),e(NC,Vxr),e(de,Xxr),e(de,qC),e(qC,vEe),e(vEe,zxr),e(qC,Qxr),e(qC,KY),e(KY,Wxr),e(qC,Hxr),e(de,Uxr),e(de,jC),e(jC,FEe),e(FEe,Jxr),e(jC,Yxr),e(jC,ZY),e(ZY,Kxr),e(jC,Zxr),e(de,e$r),e(de,DC),e(DC,TEe),e(TEe,o$r),e(DC,r$r),e(DC,eK),e(eK,t$r),e(DC,a$r),e(de,n$r),e(de,GC),e(GC,MEe),e(MEe,s$r),e(GC,l$r),e(GC,oK),e(oK,i$r),e(GC,d$r),e(de,c$r),e(de,OC),e(OC,EEe),e(EEe,f$r),e(OC,m$r),e(OC,rK),e(rK,g$r),e(OC,h$r),e(qr,p$r),M(VC,qr,null),b(f,hVe,u),b(f,Rc,u),e(Rc,XC),e(XC,CEe),M(ux,CEe,null),e(Rc,_$r),e(Rc,wEe),e(wEe,u$r),b(f,pVe,u),b(f,fr,u),M(bx,fr,null),e(fr,b$r),e(fr,Pc),e(Pc,v$r),e(Pc,tK),e(tK,F$r),e(Pc,T$r),e(Pc,aK),e(aK,M$r),e(Pc,E$r),e(fr,C$r),e(fr,vx),e(vx,w$r),e(vx,AEe),e(AEe,A$r),e(vx,L$r),e(fr,y$r),e(fr,Gt),M(Fx,Gt,null),e(Gt,x$r),e(Gt,LEe),e(LEe,$$r),e(Gt,k$r),e(Gt,Bc),e(Bc,S$r),e(Bc,yEe),e(yEe,R$r),e(Bc,P$r),e(Bc,nK),e(nK,B$r),e(Bc,I$r),e(Gt,N$r),M(zC,Gt,null),e(fr,q$r),e(fr,jr),M(Tx,jr,null),e(jr,j$r),e(jr,xEe),e(xEe,D$r),e(jr,G$r),e(jr,un),e(un,O$r),e(un,$Ee),e($Ee,V$r),e(un,X$r),e(un,kEe),e(kEe,z$r),e(un,Q$r),e(un,SEe),e(SEe,W$r),e(un,H$r),e(jr,U$r),e(jr,ce),e(ce,QC),e(QC,REe),e(REe,J$r),e(QC,Y$r),e(QC,sK),e(sK,K$r),e(QC,Z$r),e(ce,ekr),e(ce,WC),e(WC,PEe),e(PEe,okr),e(WC,rkr),e(WC,lK),e(lK,tkr),e(WC,akr),e(ce,nkr),e(ce,HC),e(HC,BEe),e(BEe,skr),e(HC,lkr),e(HC,iK),e(iK,ikr),e(HC,dkr),e(ce,ckr),e(ce,UC),e(UC,IEe),e(IEe,fkr),e(UC,mkr),e(UC,dK),e(dK,gkr),e(UC,hkr),e(ce,pkr),e(ce,JC),e(JC,NEe),e(NEe,_kr),e(JC,ukr),e(JC,cK),e(cK,bkr),e(JC,vkr),e(ce,Fkr),e(ce,YC),e(YC,qEe),e(qEe,Tkr),e(YC,Mkr),e(YC,fK),e(fK,Ekr),e(YC,Ckr),e(ce,wkr),e(ce,KC),e(KC,jEe),e(jEe,Akr),e(KC,Lkr),e(KC,mK),e(mK,ykr),e(KC,xkr),e(ce,$kr),e(ce,ZC),e(ZC,DEe),e(DEe,kkr),e(ZC,Skr),e(ZC,gK),e(gK,Rkr),e(ZC,Pkr),e(ce,Bkr),e(ce,e5),e(e5,GEe),e(GEe,Ikr),e(e5,Nkr),e(e5,hK),e(hK,qkr),e(e5,jkr),e(ce,Dkr),e(ce,o5),e(o5,OEe),e(OEe,Gkr),e(o5,Okr),e(o5,pK),e(pK,Vkr),e(o5,Xkr),e(ce,zkr),e(ce,r5),e(r5,VEe),e(VEe,Qkr),e(r5,Wkr),e(r5,_K),e(_K,Hkr),e(r5,Ukr),e(ce,Jkr),e(ce,t5),e(t5,XEe),e(XEe,Ykr),e(t5,Kkr),e(t5,uK),e(uK,Zkr),e(t5,eSr),e(ce,oSr),e(ce,a5),e(a5,zEe),e(zEe,rSr),e(a5,tSr),e(a5,bK),e(bK,aSr),e(a5,nSr),e(ce,sSr),e(ce,n5),e(n5,QEe),e(QEe,lSr),e(n5,iSr),e(n5,vK),e(vK,dSr),e(n5,cSr),e(ce,fSr),e(ce,s5),e(s5,WEe),e(WEe,mSr),e(s5,gSr),e(s5,FK),e(FK,hSr),e(s5,pSr),e(ce,_Sr),e(ce,l5),e(l5,HEe),e(HEe,uSr),e(l5,bSr),e(l5,TK),e(TK,vSr),e(l5,FSr),e(ce,TSr),e(ce,i5),e(i5,UEe),e(UEe,MSr),e(i5,ESr),e(i5,MK),e(MK,CSr),e(i5,wSr),e(ce,ASr),e(ce,d5),e(d5,JEe),e(JEe,LSr),e(d5,ySr),e(d5,EK),e(EK,xSr),e(d5,$Sr),e(ce,kSr),e(ce,c5),e(c5,YEe),e(YEe,SSr),e(c5,RSr),e(c5,CK),e(CK,PSr),e(c5,BSr),e(ce,ISr),e(ce,f5),e(f5,KEe),e(KEe,NSr),e(f5,qSr),e(f5,wK),e(wK,jSr),e(f5,DSr),e(jr,GSr),M(m5,jr,null),b(f,_Ve,u),b(f,Ic,u),e(Ic,g5),e(g5,ZEe),M(Mx,ZEe,null),e(Ic,OSr),e(Ic,e4e),e(e4e,VSr),b(f,uVe,u),b(f,mr,u),M(Ex,mr,null),e(mr,XSr),e(mr,Nc),e(Nc,zSr),e(Nc,AK),e(AK,QSr),e(Nc,WSr),e(Nc,LK),e(LK,HSr),e(Nc,USr),e(mr,JSr),e(mr,Cx),e(Cx,YSr),e(Cx,o4e),e(o4e,KSr),e(Cx,ZSr),e(mr,eRr),e(mr,Ot),M(wx,Ot,null),e(Ot,oRr),e(Ot,r4e),e(r4e,rRr),e(Ot,tRr),e(Ot,qc),e(qc,aRr),e(qc,t4e),e(t4e,nRr),e(qc,sRr),e(qc,yK),e(yK,lRr),e(qc,iRr),e(Ot,dRr),M(h5,Ot,null),e(mr,cRr),e(mr,Dr),M(Ax,Dr,null),e(Dr,fRr),e(Dr,a4e),e(a4e,mRr),e(Dr,gRr),e(Dr,bn),e(bn,hRr),e(bn,n4e),e(n4e,pRr),e(bn,_Rr),e(bn,s4e),e(s4e,uRr),e(bn,bRr),e(bn,l4e),e(l4e,vRr),e(bn,FRr),e(Dr,TRr),e(Dr,i4e),e(i4e,p5),e(p5,d4e),e(d4e,MRr),e(p5,ERr),e(p5,xK),e(xK,CRr),e(p5,wRr),e(Dr,ARr),M(_5,Dr,null),b(f,bVe,u),b(f,jc,u),e(jc,u5),e(u5,c4e),M(Lx,c4e,null),e(jc,LRr),e(jc,f4e),e(f4e,yRr),b(f,vVe,u),b(f,gr,u),M(yx,gr,null),e(gr,xRr),e(gr,Dc),e(Dc,$Rr),e(Dc,$K),e($K,kRr),e(Dc,SRr),e(Dc,kK),e(kK,RRr),e(Dc,PRr),e(gr,BRr),e(gr,xx),e(xx,IRr),e(xx,m4e),e(m4e,NRr),e(xx,qRr),e(gr,jRr),e(gr,Vt),M($x,Vt,null),e(Vt,DRr),e(Vt,g4e),e(g4e,GRr),e(Vt,ORr),e(Vt,Gc),e(Gc,VRr),e(Gc,h4e),e(h4e,XRr),e(Gc,zRr),e(Gc,SK),e(SK,QRr),e(Gc,WRr),e(Vt,HRr),M(b5,Vt,null),e(gr,URr),e(gr,Gr),M(kx,Gr,null),e(Gr,JRr),e(Gr,p4e),e(p4e,YRr),e(Gr,KRr),e(Gr,vn),e(vn,ZRr),e(vn,_4e),e(_4e,ePr),e(vn,oPr),e(vn,u4e),e(u4e,rPr),e(vn,tPr),e(vn,b4e),e(b4e,aPr),e(vn,nPr),e(Gr,sPr),e(Gr,v4e),e(v4e,v5),e(v5,F4e),e(F4e,lPr),e(v5,iPr),e(v5,RK),e(RK,dPr),e(v5,cPr),e(Gr,fPr),M(F5,Gr,null),b(f,FVe,u),b(f,Oc,u),e(Oc,T5),e(T5,T4e),M(Sx,T4e,null),e(Oc,mPr),e(Oc,M4e),e(M4e,gPr),b(f,TVe,u),b(f,hr,u),M(Rx,hr,null),e(hr,hPr),e(hr,Vc),e(Vc,pPr),e(Vc,PK),e(PK,_Pr),e(Vc,uPr),e(Vc,BK),e(BK,bPr),e(Vc,vPr),e(hr,FPr),e(hr,Px),e(Px,TPr),e(Px,E4e),e(E4e,MPr),e(Px,EPr),e(hr,CPr),e(hr,Xt),M(Bx,Xt,null),e(Xt,wPr),e(Xt,C4e),e(C4e,APr),e(Xt,LPr),e(Xt,Xc),e(Xc,yPr),e(Xc,w4e),e(w4e,xPr),e(Xc,$Pr),e(Xc,IK),e(IK,kPr),e(Xc,SPr),e(Xt,RPr),M(M5,Xt,null),e(hr,PPr),e(hr,Or),M(Ix,Or,null),e(Or,BPr),e(Or,A4e),e(A4e,IPr),e(Or,NPr),e(Or,Fn),e(Fn,qPr),e(Fn,L4e),e(L4e,jPr),e(Fn,DPr),e(Fn,y4e),e(y4e,GPr),e(Fn,OPr),e(Fn,x4e),e(x4e,VPr),e(Fn,XPr),e(Or,zPr),e(Or,oe),e(oe,E5),e(E5,$4e),e($4e,QPr),e(E5,WPr),e(E5,NK),e(NK,HPr),e(E5,UPr),e(oe,JPr),e(oe,C5),e(C5,k4e),e(k4e,YPr),e(C5,KPr),e(C5,qK),e(qK,ZPr),e(C5,eBr),e(oe,oBr),e(oe,w5),e(w5,S4e),e(S4e,rBr),e(w5,tBr),e(w5,jK),e(jK,aBr),e(w5,nBr),e(oe,sBr),e(oe,A5),e(A5,R4e),e(R4e,lBr),e(A5,iBr),e(A5,DK),e(DK,dBr),e(A5,cBr),e(oe,fBr),e(oe,L5),e(L5,P4e),e(P4e,mBr),e(L5,gBr),e(L5,GK),e(GK,hBr),e(L5,pBr),e(oe,_Br),e(oe,y5),e(y5,B4e),e(B4e,uBr),e(y5,bBr),e(y5,OK),e(OK,vBr),e(y5,FBr),e(oe,TBr),e(oe,x5),e(x5,I4e),e(I4e,MBr),e(x5,EBr),e(x5,VK),e(VK,CBr),e(x5,wBr),e(oe,ABr),e(oe,$5),e($5,N4e),e(N4e,LBr),e($5,yBr),e($5,XK),e(XK,xBr),e($5,$Br),e(oe,kBr),e(oe,k5),e(k5,q4e),e(q4e,SBr),e(k5,RBr),e(k5,zK),e(zK,PBr),e(k5,BBr),e(oe,IBr),e(oe,S5),e(S5,j4e),e(j4e,NBr),e(S5,qBr),e(S5,QK),e(QK,jBr),e(S5,DBr),e(oe,GBr),e(oe,R5),e(R5,D4e),e(D4e,OBr),e(R5,VBr),e(R5,WK),e(WK,XBr),e(R5,zBr),e(oe,QBr),e(oe,P5),e(P5,G4e),e(G4e,WBr),e(P5,HBr),e(P5,HK),e(HK,UBr),e(P5,JBr),e(oe,YBr),e(oe,B5),e(B5,O4e),e(O4e,KBr),e(B5,ZBr),e(B5,UK),e(UK,eIr),e(B5,oIr),e(oe,rIr),e(oe,I5),e(I5,V4e),e(V4e,tIr),e(I5,aIr),e(I5,JK),e(JK,nIr),e(I5,sIr),e(oe,lIr),e(oe,N5),e(N5,X4e),e(X4e,iIr),e(N5,dIr),e(N5,YK),e(YK,cIr),e(N5,fIr),e(oe,mIr),e(oe,q5),e(q5,z4e),e(z4e,gIr),e(q5,hIr),e(q5,KK),e(KK,pIr),e(q5,_Ir),e(oe,uIr),e(oe,j5),e(j5,Q4e),e(Q4e,bIr),e(j5,vIr),e(j5,ZK),e(ZK,FIr),e(j5,TIr),e(oe,MIr),e(oe,D5),e(D5,W4e),e(W4e,EIr),e(D5,CIr),e(D5,eZ),e(eZ,wIr),e(D5,AIr),e(oe,LIr),e(oe,G5),e(G5,H4e),e(H4e,yIr),e(G5,xIr),e(G5,oZ),e(oZ,$Ir),e(G5,kIr),e(oe,SIr),e(oe,O5),e(O5,U4e),e(U4e,RIr),e(O5,PIr),e(O5,rZ),e(rZ,BIr),e(O5,IIr),e(oe,NIr),e(oe,V5),e(V5,J4e),e(J4e,qIr),e(V5,jIr),e(V5,tZ),e(tZ,DIr),e(V5,GIr),e(oe,OIr),e(oe,X5),e(X5,Y4e),e(Y4e,VIr),e(X5,XIr),e(X5,aZ),e(aZ,zIr),e(X5,QIr),e(oe,WIr),e(oe,z5),e(z5,K4e),e(K4e,HIr),e(z5,UIr),e(z5,nZ),e(nZ,JIr),e(z5,YIr),e(oe,KIr),e(oe,Q5),e(Q5,Z4e),e(Z4e,ZIr),e(Q5,eNr),e(Q5,sZ),e(sZ,oNr),e(Q5,rNr),e(oe,tNr),e(oe,W5),e(W5,eCe),e(eCe,aNr),e(W5,nNr),e(W5,lZ),e(lZ,sNr),e(W5,lNr),e(oe,iNr),e(oe,H5),e(H5,oCe),e(oCe,dNr),e(H5,cNr),e(H5,iZ),e(iZ,fNr),e(H5,mNr),e(oe,gNr),e(oe,U5),e(U5,rCe),e(rCe,hNr),e(U5,pNr),e(U5,dZ),e(dZ,_Nr),e(U5,uNr),e(Or,bNr),M(J5,Or,null),b(f,MVe,u),b(f,zc,u),e(zc,Y5),e(Y5,tCe),M(Nx,tCe,null),e(zc,vNr),e(zc,aCe),e(aCe,FNr),b(f,EVe,u),b(f,pr,u),M(qx,pr,null),e(pr,TNr),e(pr,Qc),e(Qc,MNr),e(Qc,cZ),e(cZ,ENr),e(Qc,CNr),e(Qc,fZ),e(fZ,wNr),e(Qc,ANr),e(pr,LNr),e(pr,jx),e(jx,yNr),e(jx,nCe),e(nCe,xNr),e(jx,$Nr),e(pr,kNr),e(pr,zt),M(Dx,zt,null),e(zt,SNr),e(zt,sCe),e(sCe,RNr),e(zt,PNr),e(zt,Wc),e(Wc,BNr),e(Wc,lCe),e(lCe,INr),e(Wc,NNr),e(Wc,mZ),e(mZ,qNr),e(Wc,jNr),e(zt,DNr),M(K5,zt,null),e(pr,GNr),e(pr,Vr),M(Gx,Vr,null),e(Vr,ONr),e(Vr,iCe),e(iCe,VNr),e(Vr,XNr),e(Vr,Tn),e(Tn,zNr),e(Tn,dCe),e(dCe,QNr),e(Tn,WNr),e(Tn,cCe),e(cCe,HNr),e(Tn,UNr),e(Tn,fCe),e(fCe,JNr),e(Tn,YNr),e(Vr,KNr),e(Vr,xe),e(xe,Z5),e(Z5,mCe),e(mCe,ZNr),e(Z5,eqr),e(Z5,gZ),e(gZ,oqr),e(Z5,rqr),e(xe,tqr),e(xe,e3),e(e3,gCe),e(gCe,aqr),e(e3,nqr),e(e3,hZ),e(hZ,sqr),e(e3,lqr),e(xe,iqr),e(xe,o3),e(o3,hCe),e(hCe,dqr),e(o3,cqr),e(o3,pZ),e(pZ,fqr),e(o3,mqr),e(xe,gqr),e(xe,r3),e(r3,pCe),e(pCe,hqr),e(r3,pqr),e(r3,_Z),e(_Z,_qr),e(r3,uqr),e(xe,bqr),e(xe,t3),e(t3,_Ce),e(_Ce,vqr),e(t3,Fqr),e(t3,uZ),e(uZ,Tqr),e(t3,Mqr),e(xe,Eqr),e(xe,a3),e(a3,uCe),e(uCe,Cqr),e(a3,wqr),e(a3,bZ),e(bZ,Aqr),e(a3,Lqr),e(xe,yqr),e(xe,n3),e(n3,bCe),e(bCe,xqr),e(n3,$qr),e(n3,vZ),e(vZ,kqr),e(n3,Sqr),e(xe,Rqr),e(xe,s3),e(s3,vCe),e(vCe,Pqr),e(s3,Bqr),e(s3,FZ),e(FZ,Iqr),e(s3,Nqr),e(xe,qqr),e(xe,l3),e(l3,FCe),e(FCe,jqr),e(l3,Dqr),e(l3,TZ),e(TZ,Gqr),e(l3,Oqr),e(xe,Vqr),e(xe,i3),e(i3,TCe),e(TCe,Xqr),e(i3,zqr),e(i3,MZ),e(MZ,Qqr),e(i3,Wqr),e(Vr,Hqr),M(d3,Vr,null),b(f,CVe,u),b(f,Hc,u),e(Hc,c3),e(c3,MCe),M(Ox,MCe,null),e(Hc,Uqr),e(Hc,ECe),e(ECe,Jqr),b(f,wVe,u),b(f,_r,u),M(Vx,_r,null),e(_r,Yqr),e(_r,Uc),e(Uc,Kqr),e(Uc,EZ),e(EZ,Zqr),e(Uc,ejr),e(Uc,CZ),e(CZ,ojr),e(Uc,rjr),e(_r,tjr),e(_r,Xx),e(Xx,ajr),e(Xx,CCe),e(CCe,njr),e(Xx,sjr),e(_r,ljr),e(_r,Qt),M(zx,Qt,null),e(Qt,ijr),e(Qt,wCe),e(wCe,djr),e(Qt,cjr),e(Qt,Jc),e(Jc,fjr),e(Jc,ACe),e(ACe,mjr),e(Jc,gjr),e(Jc,wZ),e(wZ,hjr),e(Jc,pjr),e(Qt,_jr),M(f3,Qt,null),e(_r,ujr),e(_r,Xr),M(Qx,Xr,null),e(Xr,bjr),e(Xr,LCe),e(LCe,vjr),e(Xr,Fjr),e(Xr,Mn),e(Mn,Tjr),e(Mn,yCe),e(yCe,Mjr),e(Mn,Ejr),e(Mn,xCe),e(xCe,Cjr),e(Mn,wjr),e(Mn,$Ce),e($Ce,Ajr),e(Mn,Ljr),e(Xr,yjr),e(Xr,Ee),e(Ee,m3),e(m3,kCe),e(kCe,xjr),e(m3,$jr),e(m3,AZ),e(AZ,kjr),e(m3,Sjr),e(Ee,Rjr),e(Ee,g3),e(g3,SCe),e(SCe,Pjr),e(g3,Bjr),e(g3,LZ),e(LZ,Ijr),e(g3,Njr),e(Ee,qjr),e(Ee,h3),e(h3,RCe),e(RCe,jjr),e(h3,Djr),e(h3,yZ),e(yZ,Gjr),e(h3,Ojr),e(Ee,Vjr),e(Ee,p3),e(p3,PCe),e(PCe,Xjr),e(p3,zjr),e(p3,xZ),e(xZ,Qjr),e(p3,Wjr),e(Ee,Hjr),e(Ee,_3),e(_3,BCe),e(BCe,Ujr),e(_3,Jjr),e(_3,$Z),e($Z,Yjr),e(_3,Kjr),e(Ee,Zjr),e(Ee,u3),e(u3,ICe),e(ICe,eDr),e(u3,oDr),e(u3,kZ),e(kZ,rDr),e(u3,tDr),e(Ee,aDr),e(Ee,b3),e(b3,NCe),e(NCe,nDr),e(b3,sDr),e(b3,SZ),e(SZ,lDr),e(b3,iDr),e(Ee,dDr),e(Ee,v3),e(v3,qCe),e(qCe,cDr),e(v3,fDr),e(v3,RZ),e(RZ,mDr),e(v3,gDr),e(Ee,hDr),e(Ee,F3),e(F3,jCe),e(jCe,pDr),e(F3,_Dr),e(F3,PZ),e(PZ,uDr),e(F3,bDr),e(Ee,vDr),e(Ee,T3),e(T3,DCe),e(DCe,FDr),e(T3,TDr),e(T3,BZ),e(BZ,MDr),e(T3,EDr),e(Ee,CDr),e(Ee,M3),e(M3,GCe),e(GCe,wDr),e(M3,ADr),e(M3,IZ),e(IZ,LDr),e(M3,yDr),e(Ee,xDr),e(Ee,E3),e(E3,OCe),e(OCe,$Dr),e(E3,kDr),e(E3,NZ),e(NZ,SDr),e(E3,RDr),e(Ee,PDr),e(Ee,C3),e(C3,VCe),e(VCe,BDr),e(C3,IDr),e(C3,qZ),e(qZ,NDr),e(C3,qDr),e(Xr,jDr),M(w3,Xr,null),b(f,AVe,u),b(f,Yc,u),e(Yc,A3),e(A3,XCe),M(Wx,XCe,null),e(Yc,DDr),e(Yc,zCe),e(zCe,GDr),b(f,LVe,u),b(f,ur,u),M(Hx,ur,null),e(ur,ODr),e(ur,Kc),e(Kc,VDr),e(Kc,jZ),e(jZ,XDr),e(Kc,zDr),e(Kc,DZ),e(DZ,QDr),e(Kc,WDr),e(ur,HDr),e(ur,Ux),e(Ux,UDr),e(Ux,QCe),e(QCe,JDr),e(Ux,YDr),e(ur,KDr),e(ur,Wt),M(Jx,Wt,null),e(Wt,ZDr),e(Wt,WCe),e(WCe,eGr),e(Wt,oGr),e(Wt,Zc),e(Zc,rGr),e(Zc,HCe),e(HCe,tGr),e(Zc,aGr),e(Zc,GZ),e(GZ,nGr),e(Zc,sGr),e(Wt,lGr),M(L3,Wt,null),e(ur,iGr),e(ur,zr),M(Yx,zr,null),e(zr,dGr),e(zr,UCe),e(UCe,cGr),e(zr,fGr),e(zr,En),e(En,mGr),e(En,JCe),e(JCe,gGr),e(En,hGr),e(En,YCe),e(YCe,pGr),e(En,_Gr),e(En,KCe),e(KCe,uGr),e(En,bGr),e(zr,vGr),e(zr,$e),e($e,y3),e(y3,ZCe),e(ZCe,FGr),e(y3,TGr),e(y3,OZ),e(OZ,MGr),e(y3,EGr),e($e,CGr),e($e,x3),e(x3,e5e),e(e5e,wGr),e(x3,AGr),e(x3,VZ),e(VZ,LGr),e(x3,yGr),e($e,xGr),e($e,$3),e($3,o5e),e(o5e,$Gr),e($3,kGr),e($3,XZ),e(XZ,SGr),e($3,RGr),e($e,PGr),e($e,k3),e(k3,r5e),e(r5e,BGr),e(k3,IGr),e(k3,zZ),e(zZ,NGr),e(k3,qGr),e($e,jGr),e($e,S3),e(S3,t5e),e(t5e,DGr),e(S3,GGr),e(S3,QZ),e(QZ,OGr),e(S3,VGr),e($e,XGr),e($e,R3),e(R3,a5e),e(a5e,zGr),e(R3,QGr),e(R3,WZ),e(WZ,WGr),e(R3,HGr),e($e,UGr),e($e,P3),e(P3,n5e),e(n5e,JGr),e(P3,YGr),e(P3,HZ),e(HZ,KGr),e(P3,ZGr),e($e,eOr),e($e,B3),e(B3,s5e),e(s5e,oOr),e(B3,rOr),e(B3,UZ),e(UZ,tOr),e(B3,aOr),e($e,nOr),e($e,I3),e(I3,l5e),e(l5e,sOr),e(I3,lOr),e(I3,JZ),e(JZ,iOr),e(I3,dOr),e($e,cOr),e($e,N3),e(N3,i5e),e(i5e,fOr),e(N3,mOr),e(N3,YZ),e(YZ,gOr),e(N3,hOr),e(zr,pOr),M(q3,zr,null),b(f,yVe,u),b(f,ef,u),e(ef,j3),e(j3,d5e),M(Kx,d5e,null),e(ef,_Or),e(ef,c5e),e(c5e,uOr),b(f,xVe,u),b(f,br,u),M(Zx,br,null),e(br,bOr),e(br,of),e(of,vOr),e(of,KZ),e(KZ,FOr),e(of,TOr),e(of,ZZ),e(ZZ,MOr),e(of,EOr),e(br,COr),e(br,e$),e(e$,wOr),e(e$,f5e),e(f5e,AOr),e(e$,LOr),e(br,yOr),e(br,Ht),M(o$,Ht,null),e(Ht,xOr),e(Ht,m5e),e(m5e,$Or),e(Ht,kOr),e(Ht,rf),e(rf,SOr),e(rf,g5e),e(g5e,ROr),e(rf,POr),e(rf,eee),e(eee,BOr),e(rf,IOr),e(Ht,NOr),M(D3,Ht,null),e(br,qOr),e(br,Qr),M(r$,Qr,null),e(Qr,jOr),e(Qr,h5e),e(h5e,DOr),e(Qr,GOr),e(Qr,Cn),e(Cn,OOr),e(Cn,p5e),e(p5e,VOr),e(Cn,XOr),e(Cn,_5e),e(_5e,zOr),e(Cn,QOr),e(Cn,u5e),e(u5e,WOr),e(Cn,HOr),e(Qr,UOr),e(Qr,ke),e(ke,G3),e(G3,b5e),e(b5e,JOr),e(G3,YOr),e(G3,oee),e(oee,KOr),e(G3,ZOr),e(ke,eVr),e(ke,O3),e(O3,v5e),e(v5e,oVr),e(O3,rVr),e(O3,ree),e(ree,tVr),e(O3,aVr),e(ke,nVr),e(ke,V3),e(V3,F5e),e(F5e,sVr),e(V3,lVr),e(V3,tee),e(tee,iVr),e(V3,dVr),e(ke,cVr),e(ke,X3),e(X3,T5e),e(T5e,fVr),e(X3,mVr),e(X3,aee),e(aee,gVr),e(X3,hVr),e(ke,pVr),e(ke,z3),e(z3,M5e),e(M5e,_Vr),e(z3,uVr),e(z3,nee),e(nee,bVr),e(z3,vVr),e(ke,FVr),e(ke,Q3),e(Q3,E5e),e(E5e,TVr),e(Q3,MVr),e(Q3,see),e(see,EVr),e(Q3,CVr),e(ke,wVr),e(ke,W3),e(W3,C5e),e(C5e,AVr),e(W3,LVr),e(W3,lee),e(lee,yVr),e(W3,xVr),e(ke,$Vr),e(ke,H3),e(H3,w5e),e(w5e,kVr),e(H3,SVr),e(H3,iee),e(iee,RVr),e(H3,PVr),e(ke,BVr),e(ke,U3),e(U3,A5e),e(A5e,IVr),e(U3,NVr),e(U3,dee),e(dee,qVr),e(U3,jVr),e(ke,DVr),e(ke,J3),e(J3,L5e),e(L5e,GVr),e(J3,OVr),e(J3,cee),e(cee,VVr),e(J3,XVr),e(Qr,zVr),M(Y3,Qr,null),b(f,$Ve,u),b(f,tf,u),e(tf,K3),e(K3,y5e),M(t$,y5e,null),e(tf,QVr),e(tf,x5e),e(x5e,WVr),b(f,kVe,u),b(f,vr,u),M(a$,vr,null),e(vr,HVr),e(vr,af),e(af,UVr),e(af,fee),e(fee,JVr),e(af,YVr),e(af,mee),e(mee,KVr),e(af,ZVr),e(vr,eXr),e(vr,n$),e(n$,oXr),e(n$,$5e),e($5e,rXr),e(n$,tXr),e(vr,aXr),e(vr,Ut),M(s$,Ut,null),e(Ut,nXr),e(Ut,k5e),e(k5e,sXr),e(Ut,lXr),e(Ut,nf),e(nf,iXr),e(nf,S5e),e(S5e,dXr),e(nf,cXr),e(nf,gee),e(gee,fXr),e(nf,mXr),e(Ut,gXr),M(Z3,Ut,null),e(vr,hXr),e(vr,Wr),M(l$,Wr,null),e(Wr,pXr),e(Wr,R5e),e(R5e,_Xr),e(Wr,uXr),e(Wr,wn),e(wn,bXr),e(wn,P5e),e(P5e,vXr),e(wn,FXr),e(wn,B5e),e(B5e,TXr),e(wn,MXr),e(wn,I5e),e(I5e,EXr),e(wn,CXr),e(Wr,wXr),e(Wr,Se),e(Se,e0),e(e0,N5e),e(N5e,AXr),e(e0,LXr),e(e0,hee),e(hee,yXr),e(e0,xXr),e(Se,$Xr),e(Se,o0),e(o0,q5e),e(q5e,kXr),e(o0,SXr),e(o0,pee),e(pee,RXr),e(o0,PXr),e(Se,BXr),e(Se,r0),e(r0,j5e),e(j5e,IXr),e(r0,NXr),e(r0,_ee),e(_ee,qXr),e(r0,jXr),e(Se,DXr),e(Se,t0),e(t0,D5e),e(D5e,GXr),e(t0,OXr),e(t0,uee),e(uee,VXr),e(t0,XXr),e(Se,zXr),e(Se,a0),e(a0,G5e),e(G5e,QXr),e(a0,WXr),e(a0,bee),e(bee,HXr),e(a0,UXr),e(Se,JXr),e(Se,n0),e(n0,O5e),e(O5e,YXr),e(n0,KXr),e(n0,vee),e(vee,ZXr),e(n0,ezr),e(Se,ozr),e(Se,s0),e(s0,V5e),e(V5e,rzr),e(s0,tzr),e(s0,Fee),e(Fee,azr),e(s0,nzr),e(Se,szr),e(Se,l0),e(l0,X5e),e(X5e,lzr),e(l0,izr),e(l0,Tee),e(Tee,dzr),e(l0,czr),e(Se,fzr),e(Se,i0),e(i0,z5e),e(z5e,mzr),e(i0,gzr),e(i0,Mee),e(Mee,hzr),e(i0,pzr),e(Se,_zr),e(Se,d0),e(d0,Q5e),e(Q5e,uzr),e(d0,bzr),e(d0,Eee),e(Eee,vzr),e(d0,Fzr),e(Wr,Tzr),M(c0,Wr,null),b(f,SVe,u),b(f,sf,u),e(sf,f0),e(f0,W5e),M(i$,W5e,null),e(sf,Mzr),e(sf,H5e),e(H5e,Ezr),b(f,RVe,u),b(f,Fr,u),M(d$,Fr,null),e(Fr,Czr),e(Fr,lf),e(lf,wzr),e(lf,Cee),e(Cee,Azr),e(lf,Lzr),e(lf,wee),e(wee,yzr),e(lf,xzr),e(Fr,$zr),e(Fr,c$),e(c$,kzr),e(c$,U5e),e(U5e,Szr),e(c$,Rzr),e(Fr,Pzr),e(Fr,Jt),M(f$,Jt,null),e(Jt,Bzr),e(Jt,J5e),e(J5e,Izr),e(Jt,Nzr),e(Jt,df),e(df,qzr),e(df,Y5e),e(Y5e,jzr),e(df,Dzr),e(df,Aee),e(Aee,Gzr),e(df,Ozr),e(Jt,Vzr),M(m0,Jt,null),e(Fr,Xzr),e(Fr,Hr),M(m$,Hr,null),e(Hr,zzr),e(Hr,K5e),e(K5e,Qzr),e(Hr,Wzr),e(Hr,An),e(An,Hzr),e(An,Z5e),e(Z5e,Uzr),e(An,Jzr),e(An,e3e),e(e3e,Yzr),e(An,Kzr),e(An,o3e),e(o3e,Zzr),e(An,eQr),e(Hr,oQr),e(Hr,Re),e(Re,g0),e(g0,r3e),e(r3e,rQr),e(g0,tQr),e(g0,Lee),e(Lee,aQr),e(g0,nQr),e(Re,sQr),e(Re,h0),e(h0,t3e),e(t3e,lQr),e(h0,iQr),e(h0,yee),e(yee,dQr),e(h0,cQr),e(Re,fQr),e(Re,p0),e(p0,a3e),e(a3e,mQr),e(p0,gQr),e(p0,xee),e(xee,hQr),e(p0,pQr),e(Re,_Qr),e(Re,_0),e(_0,n3e),e(n3e,uQr),e(_0,bQr),e(_0,$ee),e($ee,vQr),e(_0,FQr),e(Re,TQr),e(Re,u0),e(u0,s3e),e(s3e,MQr),e(u0,EQr),e(u0,kee),e(kee,CQr),e(u0,wQr),e(Re,AQr),e(Re,b0),e(b0,l3e),e(l3e,LQr),e(b0,yQr),e(b0,See),e(See,xQr),e(b0,$Qr),e(Re,kQr),e(Re,v0),e(v0,i3e),e(i3e,SQr),e(v0,RQr),e(v0,Ree),e(Ree,PQr),e(v0,BQr),e(Re,IQr),e(Re,F0),e(F0,d3e),e(d3e,NQr),e(F0,qQr),e(F0,Pee),e(Pee,jQr),e(F0,DQr),e(Re,GQr),e(Re,T0),e(T0,c3e),e(c3e,OQr),e(T0,VQr),e(T0,Bee),e(Bee,XQr),e(T0,zQr),e(Re,QQr),e(Re,M0),e(M0,f3e),e(f3e,WQr),e(M0,HQr),e(M0,Iee),e(Iee,UQr),e(M0,JQr),e(Hr,YQr),M(E0,Hr,null),b(f,PVe,u),b(f,cf,u),e(cf,C0),e(C0,m3e),M(g$,m3e,null),e(cf,KQr),e(cf,g3e),e(g3e,ZQr),b(f,BVe,u),b(f,Tr,u),M(h$,Tr,null),e(Tr,eWr),e(Tr,ff),e(ff,oWr),e(ff,Nee),e(Nee,rWr),e(ff,tWr),e(ff,qee),e(qee,aWr),e(ff,nWr),e(Tr,sWr),e(Tr,p$),e(p$,lWr),e(p$,h3e),e(h3e,iWr),e(p$,dWr),e(Tr,cWr),e(Tr,Yt),M(_$,Yt,null),e(Yt,fWr),e(Yt,p3e),e(p3e,mWr),e(Yt,gWr),e(Yt,mf),e(mf,hWr),e(mf,_3e),e(_3e,pWr),e(mf,_Wr),e(mf,jee),e(jee,uWr),e(mf,bWr),e(Yt,vWr),M(w0,Yt,null),e(Tr,FWr),e(Tr,Ur),M(u$,Ur,null),e(Ur,TWr),e(Ur,u3e),e(u3e,MWr),e(Ur,EWr),e(Ur,Ln),e(Ln,CWr),e(Ln,b3e),e(b3e,wWr),e(Ln,AWr),e(Ln,v3e),e(v3e,LWr),e(Ln,yWr),e(Ln,F3e),e(F3e,xWr),e(Ln,$Wr),e(Ur,kWr),e(Ur,Ve),e(Ve,A0),e(A0,T3e),e(T3e,SWr),e(A0,RWr),e(A0,Dee),e(Dee,PWr),e(A0,BWr),e(Ve,IWr),e(Ve,L0),e(L0,M3e),e(M3e,NWr),e(L0,qWr),e(L0,Gee),e(Gee,jWr),e(L0,DWr),e(Ve,GWr),e(Ve,y0),e(y0,E3e),e(E3e,OWr),e(y0,VWr),e(y0,Oee),e(Oee,XWr),e(y0,zWr),e(Ve,QWr),e(Ve,x0),e(x0,C3e),e(C3e,WWr),e(x0,HWr),e(x0,Vee),e(Vee,UWr),e(x0,JWr),e(Ve,YWr),e(Ve,$0),e($0,w3e),e(w3e,KWr),e($0,ZWr),e($0,Xee),e(Xee,eHr),e($0,oHr),e(Ve,rHr),e(Ve,k0),e(k0,A3e),e(A3e,tHr),e(k0,aHr),e(k0,zee),e(zee,nHr),e(k0,sHr),e(Ve,lHr),e(Ve,S0),e(S0,L3e),e(L3e,iHr),e(S0,dHr),e(S0,Qee),e(Qee,cHr),e(S0,fHr),e(Ve,mHr),e(Ve,R0),e(R0,y3e),e(y3e,gHr),e(R0,hHr),e(R0,Wee),e(Wee,pHr),e(R0,_Hr),e(Ur,uHr),M(P0,Ur,null),b(f,IVe,u),b(f,gf,u),e(gf,B0),e(B0,x3e),M(b$,x3e,null),e(gf,bHr),e(gf,$3e),e($3e,vHr),b(f,NVe,u),b(f,Mr,u),M(v$,Mr,null),e(Mr,FHr),e(Mr,hf),e(hf,THr),e(hf,Hee),e(Hee,MHr),e(hf,EHr),e(hf,Uee),e(Uee,CHr),e(hf,wHr),e(Mr,AHr),e(Mr,F$),e(F$,LHr),e(F$,k3e),e(k3e,yHr),e(F$,xHr),e(Mr,$Hr),e(Mr,Kt),M(T$,Kt,null),e(Kt,kHr),e(Kt,S3e),e(S3e,SHr),e(Kt,RHr),e(Kt,pf),e(pf,PHr),e(pf,R3e),e(R3e,BHr),e(pf,IHr),e(pf,Jee),e(Jee,NHr),e(pf,qHr),e(Kt,jHr),M(I0,Kt,null),e(Mr,DHr),e(Mr,Jr),M(M$,Jr,null),e(Jr,GHr),e(Jr,P3e),e(P3e,OHr),e(Jr,VHr),e(Jr,yn),e(yn,XHr),e(yn,B3e),e(B3e,zHr),e(yn,QHr),e(yn,I3e),e(I3e,WHr),e(yn,HHr),e(yn,N3e),e(N3e,UHr),e(yn,JHr),e(Jr,YHr),e(Jr,Xe),e(Xe,N0),e(N0,q3e),e(q3e,KHr),e(N0,ZHr),e(N0,Yee),e(Yee,eUr),e(N0,oUr),e(Xe,rUr),e(Xe,q0),e(q0,j3e),e(j3e,tUr),e(q0,aUr),e(q0,Kee),e(Kee,nUr),e(q0,sUr),e(Xe,lUr),e(Xe,j0),e(j0,D3e),e(D3e,iUr),e(j0,dUr),e(j0,Zee),e(Zee,cUr),e(j0,fUr),e(Xe,mUr),e(Xe,D0),e(D0,G3e),e(G3e,gUr),e(D0,hUr),e(D0,eoe),e(eoe,pUr),e(D0,_Ur),e(Xe,uUr),e(Xe,G0),e(G0,O3e),e(O3e,bUr),e(G0,vUr),e(G0,ooe),e(ooe,FUr),e(G0,TUr),e(Xe,MUr),e(Xe,O0),e(O0,V3e),e(V3e,EUr),e(O0,CUr),e(O0,roe),e(roe,wUr),e(O0,AUr),e(Xe,LUr),e(Xe,V0),e(V0,X3e),e(X3e,yUr),e(V0,xUr),e(V0,toe),e(toe,$Ur),e(V0,kUr),e(Xe,SUr),e(Xe,X0),e(X0,z3e),e(z3e,RUr),e(X0,PUr),e(X0,aoe),e(aoe,BUr),e(X0,IUr),e(Jr,NUr),M(z0,Jr,null),b(f,qVe,u),b(f,_f,u),e(_f,Q0),e(Q0,Q3e),M(E$,Q3e,null),e(_f,qUr),e(_f,W3e),e(W3e,jUr),b(f,jVe,u),b(f,Er,u),M(C$,Er,null),e(Er,DUr),e(Er,uf),e(uf,GUr),e(uf,noe),e(noe,OUr),e(uf,VUr),e(uf,soe),e(soe,XUr),e(uf,zUr),e(Er,QUr),e(Er,w$),e(w$,WUr),e(w$,H3e),e(H3e,HUr),e(w$,UUr),e(Er,JUr),e(Er,Zt),M(A$,Zt,null),e(Zt,YUr),e(Zt,U3e),e(U3e,KUr),e(Zt,ZUr),e(Zt,bf),e(bf,eJr),e(bf,J3e),e(J3e,oJr),e(bf,rJr),e(bf,loe),e(loe,tJr),e(bf,aJr),e(Zt,nJr),M(W0,Zt,null),e(Er,sJr),e(Er,Yr),M(L$,Yr,null),e(Yr,lJr),e(Yr,Y3e),e(Y3e,iJr),e(Yr,dJr),e(Yr,xn),e(xn,cJr),e(xn,K3e),e(K3e,fJr),e(xn,mJr),e(xn,Z3e),e(Z3e,gJr),e(xn,hJr),e(xn,e0e),e(e0e,pJr),e(xn,_Jr),e(Yr,uJr),e(Yr,o0e),e(o0e,H0),e(H0,r0e),e(r0e,bJr),e(H0,vJr),e(H0,ioe),e(ioe,FJr),e(H0,TJr),e(Yr,MJr),M(U0,Yr,null),b(f,DVe,u),b(f,vf,u),e(vf,J0),e(J0,t0e),M(y$,t0e,null),e(vf,EJr),e(vf,a0e),e(a0e,CJr),b(f,GVe,u),b(f,Cr,u),M(x$,Cr,null),e(Cr,wJr),e(Cr,Ff),e(Ff,AJr),e(Ff,doe),e(doe,LJr),e(Ff,yJr),e(Ff,coe),e(coe,xJr),e(Ff,$Jr),e(Cr,kJr),e(Cr,$$),e($$,SJr),e($$,n0e),e(n0e,RJr),e($$,PJr),e(Cr,BJr),e(Cr,ea),M(k$,ea,null),e(ea,IJr),e(ea,s0e),e(s0e,NJr),e(ea,qJr),e(ea,Tf),e(Tf,jJr),e(Tf,l0e),e(l0e,DJr),e(Tf,GJr),e(Tf,foe),e(foe,OJr),e(Tf,VJr),e(ea,XJr),M(Y0,ea,null),e(Cr,zJr),e(Cr,Kr),M(S$,Kr,null),e(Kr,QJr),e(Kr,i0e),e(i0e,WJr),e(Kr,HJr),e(Kr,$n),e($n,UJr),e($n,d0e),e(d0e,JJr),e($n,YJr),e($n,c0e),e(c0e,KJr),e($n,ZJr),e($n,f0e),e(f0e,eYr),e($n,oYr),e(Kr,rYr),e(Kr,R$),e(R$,K0),e(K0,m0e),e(m0e,tYr),e(K0,aYr),e(K0,moe),e(moe,nYr),e(K0,sYr),e(R$,lYr),e(R$,Z0),e(Z0,g0e),e(g0e,iYr),e(Z0,dYr),e(Z0,goe),e(goe,cYr),e(Z0,fYr),e(Kr,mYr),M(ew,Kr,null),b(f,OVe,u),b(f,Mf,u),e(Mf,ow),e(ow,h0e),M(P$,h0e,null),e(Mf,gYr),e(Mf,p0e),e(p0e,hYr),b(f,VVe,u),b(f,wr,u),M(B$,wr,null),e(wr,pYr),e(wr,Ef),e(Ef,_Yr),e(Ef,hoe),e(hoe,uYr),e(Ef,bYr),e(Ef,poe),e(poe,vYr),e(Ef,FYr),e(wr,TYr),e(wr,I$),e(I$,MYr),e(I$,_0e),e(_0e,EYr),e(I$,CYr),e(wr,wYr),e(wr,oa),M(N$,oa,null),e(oa,AYr),e(oa,u0e),e(u0e,LYr),e(oa,yYr),e(oa,Cf),e(Cf,xYr),e(Cf,b0e),e(b0e,$Yr),e(Cf,kYr),e(Cf,_oe),e(_oe,SYr),e(Cf,RYr),e(oa,PYr),M(rw,oa,null),e(wr,BYr),e(wr,Zr),M(q$,Zr,null),e(Zr,IYr),e(Zr,v0e),e(v0e,NYr),e(Zr,qYr),e(Zr,kn),e(kn,jYr),e(kn,F0e),e(F0e,DYr),e(kn,GYr),e(kn,T0e),e(T0e,OYr),e(kn,VYr),e(kn,M0e),e(M0e,XYr),e(kn,zYr),e(Zr,QYr),e(Zr,E0e),e(E0e,tw),e(tw,C0e),e(C0e,WYr),e(tw,HYr),e(tw,uoe),e(uoe,UYr),e(tw,JYr),e(Zr,YYr),M(aw,Zr,null),XVe=!0},p(f,[u]){const j$={};u&2&&(j$.$$scope={dirty:u,ctx:f}),Rf.$set(j$);const w0e={};u&2&&(w0e.$$scope={dirty:u,ctx:f}),Gg.$set(w0e);const A0e={};u&2&&(A0e.$$scope={dirty:u,ctx:f}),Eh.$set(A0e);const L0e={};u&2&&(L0e.$$scope={dirty:u,ctx:f}),ap.$set(L0e);const D$={};u&2&&(D$.$$scope={dirty:u,ctx:f}),np.$set(D$);const y0e={};u&2&&(y0e.$$scope={dirty:u,ctx:f}),wp.$set(y0e);const Sn={};u&2&&(Sn.$$scope={dirty:u,ctx:f}),Ap.$set(Sn);const x0e={};u&2&&(x0e.$$scope={dirty:u,ctx:f}),xp.$set(x0e);const $0e={};u&2&&($0e.$$scope={dirty:u,ctx:f}),xu.$set($0e);const k0e={};u&2&&(k0e.$$scope={dirty:u,ctx:f}),ku.$set(k0e);const G$={};u&2&&(G$.$$scope={dirty:u,ctx:f}),E7.$set(G$);const S0e={};u&2&&(S0e.$$scope={dirty:u,ctx:f}),w7.$set(S0e);const O$={};u&2&&(O$.$$scope={dirty:u,ctx:f}),f1.$set(O$);const R0e={};u&2&&(R0e.$$scope={dirty:u,ctx:f}),g1.$set(R0e);const V$={};u&2&&(V$.$$scope={dirty:u,ctx:f}),K1.$set(V$);const P0e={};u&2&&(P0e.$$scope={dirty:u,ctx:f}),e2.$set(P0e);const B0e={};u&2&&(B0e.$$scope={dirty:u,ctx:f}),v2.$set(B0e);const I0e={};u&2&&(I0e.$$scope={dirty:u,ctx:f}),T2.$set(I0e);const wf={};u&2&&(wf.$$scope={dirty:u,ctx:f}),bb.$set(wf);const N0e={};u&2&&(N0e.$$scope={dirty:u,ctx:f}),Fb.$set(N0e);const q0e={};u&2&&(q0e.$$scope={dirty:u,ctx:f}),Kb.$set(q0e);const j0e={};u&2&&(j0e.$$scope={dirty:u,ctx:f}),ev.$set(j0e);const X$={};u&2&&(X$.$$scope={dirty:u,ctx:f}),iv.$set(X$);const D0e={};u&2&&(D0e.$$scope={dirty:u,ctx:f}),cv.$set(D0e);const G0e={};u&2&&(G0e.$$scope={dirty:u,ctx:f}),Hv.$set(G0e);const O0e={};u&2&&(O0e.$$scope={dirty:u,ctx:f}),Jv.$set(O0e);const rt={};u&2&&(rt.$$scope={dirty:u,ctx:f}),jF.$set(rt);const z$={};u&2&&(z$.$$scope={dirty:u,ctx:f}),GF.$set(z$);const V0e={};u&2&&(V0e.$$scope={dirty:u,ctx:f}),XF.$set(V0e);const Q$={};u&2&&(Q$.$$scope={dirty:u,ctx:f}),QF.$set(Q$);const X0e={};u&2&&(X0e.$$scope={dirty:u,ctx:f}),s6.$set(X0e);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),i6.$set(tt);const z0e={};u&2&&(z0e.$$scope={dirty:u,ctx:f}),f6.$set(z0e);const Af={};u&2&&(Af.$$scope={dirty:u,ctx:f}),g6.$set(Af);const Q0e={};u&2&&(Q0e.$$scope={dirty:u,ctx:f}),_6.$set(Q0e);const W0e={};u&2&&(W0e.$$scope={dirty:u,ctx:f}),b6.$set(W0e);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),x6.$set(L);const nw={};u&2&&(nw.$$scope={dirty:u,ctx:f}),k6.$set(nw);const H0e={};u&2&&(H0e.$$scope={dirty:u,ctx:f}),q6.$set(H0e);const U0e={};u&2&&(U0e.$$scope={dirty:u,ctx:f}),D6.$set(U0e);const sw={};u&2&&(sw.$$scope={dirty:u,ctx:f}),K6.$set(sw);const J0e={};u&2&&(J0e.$$scope={dirty:u,ctx:f}),eT.$set(J0e);const Y0e={};u&2&&(Y0e.$$scope={dirty:u,ctx:f}),aT.$set(Y0e);const lw={};u&2&&(lw.$$scope={dirty:u,ctx:f}),sT.$set(lw);const K0e={};u&2&&(K0e.$$scope={dirty:u,ctx:f}),gT.$set(K0e);const Z0e={};u&2&&(Z0e.$$scope={dirty:u,ctx:f}),pT.$set(Z0e);const iw={};u&2&&(iw.$$scope={dirty:u,ctx:f}),FT.$set(iw);const ewe={};u&2&&(ewe.$$scope={dirty:u,ctx:f}),MT.$set(ewe);const owe={};u&2&&(owe.$$scope={dirty:u,ctx:f}),AT.$set(owe);const dw={};u&2&&(dw.$$scope={dirty:u,ctx:f}),yT.$set(dw);const rwe={};u&2&&(rwe.$$scope={dirty:u,ctx:f}),kT.$set(rwe);const twe={};u&2&&(twe.$$scope={dirty:u,ctx:f}),RT.$set(twe);const cw={};u&2&&(cw.$$scope={dirty:u,ctx:f}),jT.$set(cw);const awe={};u&2&&(awe.$$scope={dirty:u,ctx:f}),GT.$set(awe);const nwe={};u&2&&(nwe.$$scope={dirty:u,ctx:f}),XT.$set(nwe);const fw={};u&2&&(fw.$$scope={dirty:u,ctx:f}),QT.$set(fw);const swe={};u&2&&(swe.$$scope={dirty:u,ctx:f}),jM.$set(swe);const lwe={};u&2&&(lwe.$$scope={dirty:u,ctx:f}),GM.$set(lwe);const mw={};u&2&&(mw.$$scope={dirty:u,ctx:f}),fE.$set(mw);const iwe={};u&2&&(iwe.$$scope={dirty:u,ctx:f}),gE.$set(iwe);const dwe={};u&2&&(dwe.$$scope={dirty:u,ctx:f}),LE.$set(dwe);const gw={};u&2&&(gw.$$scope={dirty:u,ctx:f}),xE.$set(gw);const cwe={};u&2&&(cwe.$$scope={dirty:u,ctx:f}),PE.$set(cwe);const fwe={};u&2&&(fwe.$$scope={dirty:u,ctx:f}),IE.$set(fwe);const hw={};u&2&&(hw.$$scope={dirty:u,ctx:f}),t4.$set(hw);const mwe={};u&2&&(mwe.$$scope={dirty:u,ctx:f}),n4.$set(mwe);const gwe={};u&2&&(gwe.$$scope={dirty:u,ctx:f}),_4.$set(gwe);const pw={};u&2&&(pw.$$scope={dirty:u,ctx:f}),b4.$set(pw);const hwe={};u&2&&(hwe.$$scope={dirty:u,ctx:f}),z4.$set(hwe);const pwe={};u&2&&(pwe.$$scope={dirty:u,ctx:f}),W4.$set(pwe);const _w={};u&2&&(_w.$$scope={dirty:u,ctx:f}),fC.$set(_w);const _we={};u&2&&(_we.$$scope={dirty:u,ctx:f}),gC.$set(_we);const uwe={};u&2&&(uwe.$$scope={dirty:u,ctx:f}),_C.$set(uwe);const uw={};u&2&&(uw.$$scope={dirty:u,ctx:f}),bC.$set(uw);const bwe={};u&2&&(bwe.$$scope={dirty:u,ctx:f}),FC.$set(bwe);const vwe={};u&2&&(vwe.$$scope={dirty:u,ctx:f}),MC.$set(vwe);const bw={};u&2&&(bw.$$scope={dirty:u,ctx:f}),VC.$set(bw);const Fwe={};u&2&&(Fwe.$$scope={dirty:u,ctx:f}),zC.$set(Fwe);const Twe={};u&2&&(Twe.$$scope={dirty:u,ctx:f}),m5.$set(Twe);const vw={};u&2&&(vw.$$scope={dirty:u,ctx:f}),h5.$set(vw);const Mwe={};u&2&&(Mwe.$$scope={dirty:u,ctx:f}),_5.$set(Mwe);const Ewe={};u&2&&(Ewe.$$scope={dirty:u,ctx:f}),b5.$set(Ewe);const Fw={};u&2&&(Fw.$$scope={dirty:u,ctx:f}),F5.$set(Fw);const Cwe={};u&2&&(Cwe.$$scope={dirty:u,ctx:f}),M5.$set(Cwe);const wwe={};u&2&&(wwe.$$scope={dirty:u,ctx:f}),J5.$set(wwe);const Tw={};u&2&&(Tw.$$scope={dirty:u,ctx:f}),K5.$set(Tw);const Awe={};u&2&&(Awe.$$scope={dirty:u,ctx:f}),d3.$set(Awe);const Lwe={};u&2&&(Lwe.$$scope={dirty:u,ctx:f}),f3.$set(Lwe);const Mw={};u&2&&(Mw.$$scope={dirty:u,ctx:f}),w3.$set(Mw);const ywe={};u&2&&(ywe.$$scope={dirty:u,ctx:f}),L3.$set(ywe);const xwe={};u&2&&(xwe.$$scope={dirty:u,ctx:f}),q3.$set(xwe);const Ew={};u&2&&(Ew.$$scope={dirty:u,ctx:f}),D3.$set(Ew);const $we={};u&2&&($we.$$scope={dirty:u,ctx:f}),Y3.$set($we);const kwe={};u&2&&(kwe.$$scope={dirty:u,ctx:f}),Z3.$set(kwe);const Cw={};u&2&&(Cw.$$scope={dirty:u,ctx:f}),c0.$set(Cw);const Swe={};u&2&&(Swe.$$scope={dirty:u,ctx:f}),m0.$set(Swe);const Rwe={};u&2&&(Rwe.$$scope={dirty:u,ctx:f}),E0.$set(Rwe);const ww={};u&2&&(ww.$$scope={dirty:u,ctx:f}),w0.$set(ww);const Pwe={};u&2&&(Pwe.$$scope={dirty:u,ctx:f}),P0.$set(Pwe);const Bwe={};u&2&&(Bwe.$$scope={dirty:u,ctx:f}),I0.$set(Bwe);const Aw={};u&2&&(Aw.$$scope={dirty:u,ctx:f}),z0.$set(Aw);const Iwe={};u&2&&(Iwe.$$scope={dirty:u,ctx:f}),W0.$set(Iwe);const Nwe={};u&2&&(Nwe.$$scope={dirty:u,ctx:f}),U0.$set(Nwe);const Lw={};u&2&&(Lw.$$scope={dirty:u,ctx:f}),Y0.$set(Lw);const qwe={};u&2&&(qwe.$$scope={dirty:u,ctx:f}),ew.$set(qwe);const jwe={};u&2&&(jwe.$$scope={dirty:u,ctx:f}),rw.$set(jwe);const yw={};u&2&&(yw.$$scope={dirty:u,ctx:f}),aw.$set(yw)},i(f){XVe||(E(d.$$.fragment,f),E(xa.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(Rf.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(BL.$$.fragment,f),E(Gg.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(qL.$$.fragment,f),E(GL.$$.fragment,f),E(Eh.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(WL.$$.fragment,f),E(ap.$$.fragment,f),E(np.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(ZL.$$.fragment,f),E(wp.$$.fragment,f),E(Ap.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ay.$$.fragment,f),E(xp.$$.fragment,f),E(ny.$$.fragment,f),E(xu.$$.fragment,f),E(sy.$$.fragment,f),E(ly.$$.fragment,f),E(dy.$$.fragment,f),E(ku.$$.fragment,f),E(cy.$$.fragment,f),E(E7.$$.fragment,f),E(fy.$$.fragment,f),E(my.$$.fragment,f),E(hy.$$.fragment,f),E(w7.$$.fragment,f),E(py.$$.fragment,f),E(f1.$$.fragment,f),E(_y.$$.fragment,f),E(uy.$$.fragment,f),E(vy.$$.fragment,f),E(g1.$$.fragment,f),E(Fy.$$.fragment,f),E(K1.$$.fragment,f),E(Ty.$$.fragment,f),E(My.$$.fragment,f),E(Cy.$$.fragment,f),E(e2.$$.fragment,f),E(wy.$$.fragment,f),E(v2.$$.fragment,f),E(Ay.$$.fragment,f),E(Ly.$$.fragment,f),E(xy.$$.fragment,f),E(T2.$$.fragment,f),E($y.$$.fragment,f),E(bb.$$.fragment,f),E(ky.$$.fragment,f),E(Sy.$$.fragment,f),E(Py.$$.fragment,f),E(Fb.$$.fragment,f),E(By.$$.fragment,f),E(Kb.$$.fragment,f),E(Iy.$$.fragment,f),E(Ny.$$.fragment,f),E(jy.$$.fragment,f),E(ev.$$.fragment,f),E(Dy.$$.fragment,f),E(iv.$$.fragment,f),E(Gy.$$.fragment,f),E(Oy.$$.fragment,f),E(Xy.$$.fragment,f),E(cv.$$.fragment,f),E(zy.$$.fragment,f),E(Hv.$$.fragment,f),E(Qy.$$.fragment,f),E(Wy.$$.fragment,f),E(Uy.$$.fragment,f),E(Jv.$$.fragment,f),E(Jy.$$.fragment,f),E(jF.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(e8.$$.fragment,f),E(GF.$$.fragment,f),E(o8.$$.fragment,f),E(XF.$$.fragment,f),E(r8.$$.fragment,f),E(t8.$$.fragment,f),E(n8.$$.fragment,f),E(QF.$$.fragment,f),E(s8.$$.fragment,f),E(s6.$$.fragment,f),E(l8.$$.fragment,f),E(i8.$$.fragment,f),E(c8.$$.fragment,f),E(i6.$$.fragment,f),E(f8.$$.fragment,f),E(f6.$$.fragment,f),E(m8.$$.fragment,f),E(g8.$$.fragment,f),E(p8.$$.fragment,f),E(g6.$$.fragment,f),E(_8.$$.fragment,f),E(_6.$$.fragment,f),E(u8.$$.fragment,f),E(b8.$$.fragment,f),E(F8.$$.fragment,f),E(b6.$$.fragment,f),E(T8.$$.fragment,f),E(x6.$$.fragment,f),E(M8.$$.fragment,f),E(E8.$$.fragment,f),E(w8.$$.fragment,f),E(k6.$$.fragment,f),E(A8.$$.fragment,f),E(q6.$$.fragment,f),E(L8.$$.fragment,f),E(y8.$$.fragment,f),E($8.$$.fragment,f),E(D6.$$.fragment,f),E(k8.$$.fragment,f),E(K6.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(B8.$$.fragment,f),E(eT.$$.fragment,f),E(I8.$$.fragment,f),E(aT.$$.fragment,f),E(q8.$$.fragment,f),E(j8.$$.fragment,f),E(G8.$$.fragment,f),E(sT.$$.fragment,f),E(O8.$$.fragment,f),E(gT.$$.fragment,f),E(V8.$$.fragment,f),E(X8.$$.fragment,f),E(Q8.$$.fragment,f),E(pT.$$.fragment,f),E(W8.$$.fragment,f),E(FT.$$.fragment,f),E(H8.$$.fragment,f),E(U8.$$.fragment,f),E(Y8.$$.fragment,f),E(MT.$$.fragment,f),E(K8.$$.fragment,f),E(AT.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(yT.$$.fragment,f),E(a9.$$.fragment,f),E(kT.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(RT.$$.fragment,f),E(d9.$$.fragment,f),E(jT.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(GT.$$.fragment,f),E(h9.$$.fragment,f),E(XT.$$.fragment,f),E(p9.$$.fragment,f),E(_9.$$.fragment,f),E(b9.$$.fragment,f),E(QT.$$.fragment,f),E(v9.$$.fragment,f),E(jM.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(GM.$$.fragment,f),E(C9.$$.fragment,f),E(fE.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(y9.$$.fragment,f),E(gE.$$.fragment,f),E(x9.$$.fragment,f),E(LE.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(R9.$$.fragment,f),E(xE.$$.fragment,f),E(P9.$$.fragment,f),E(PE.$$.fragment,f),E(B9.$$.fragment,f),E(I9.$$.fragment,f),E(q9.$$.fragment,f),E(IE.$$.fragment,f),E(j9.$$.fragment,f),E(t4.$$.fragment,f),E(D9.$$.fragment,f),E(G9.$$.fragment,f),E(V9.$$.fragment,f),E(n4.$$.fragment,f),E(X9.$$.fragment,f),E(_4.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(H9.$$.fragment,f),E(b4.$$.fragment,f),E(U9.$$.fragment,f),E(z4.$$.fragment,f),E(J9.$$.fragment,f),E(Y9.$$.fragment,f),E(Z9.$$.fragment,f),E(W4.$$.fragment,f),E(ex.$$.fragment,f),E(fC.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(gC.$$.fragment,f),E(nx.$$.fragment,f),E(_C.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(bC.$$.fragment,f),E(fx.$$.fragment,f),E(FC.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(MC.$$.fragment,f),E(_x.$$.fragment,f),E(VC.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(zC.$$.fragment,f),E(Tx.$$.fragment,f),E(m5.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(h5.$$.fragment,f),E(Ax.$$.fragment,f),E(_5.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(b5.$$.fragment,f),E(kx.$$.fragment,f),E(F5.$$.fragment,f),E(Sx.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(M5.$$.fragment,f),E(Ix.$$.fragment,f),E(J5.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(Dx.$$.fragment,f),E(K5.$$.fragment,f),E(Gx.$$.fragment,f),E(d3.$$.fragment,f),E(Ox.$$.fragment,f),E(Vx.$$.fragment,f),E(zx.$$.fragment,f),E(f3.$$.fragment,f),E(Qx.$$.fragment,f),E(w3.$$.fragment,f),E(Wx.$$.fragment,f),E(Hx.$$.fragment,f),E(Jx.$$.fragment,f),E(L3.$$.fragment,f),E(Yx.$$.fragment,f),E(q3.$$.fragment,f),E(Kx.$$.fragment,f),E(Zx.$$.fragment,f),E(o$.$$.fragment,f),E(D3.$$.fragment,f),E(r$.$$.fragment,f),E(Y3.$$.fragment,f),E(t$.$$.fragment,f),E(a$.$$.fragment,f),E(s$.$$.fragment,f),E(Z3.$$.fragment,f),E(l$.$$.fragment,f),E(c0.$$.fragment,f),E(i$.$$.fragment,f),E(d$.$$.fragment,f),E(f$.$$.fragment,f),E(m0.$$.fragment,f),E(m$.$$.fragment,f),E(E0.$$.fragment,f),E(g$.$$.fragment,f),E(h$.$$.fragment,f),E(_$.$$.fragment,f),E(w0.$$.fragment,f),E(u$.$$.fragment,f),E(P0.$$.fragment,f),E(b$.$$.fragment,f),E(v$.$$.fragment,f),E(T$.$$.fragment,f),E(I0.$$.fragment,f),E(M$.$$.fragment,f),E(z0.$$.fragment,f),E(E$.$$.fragment,f),E(C$.$$.fragment,f),E(A$.$$.fragment,f),E(W0.$$.fragment,f),E(L$.$$.fragment,f),E(U0.$$.fragment,f),E(y$.$$.fragment,f),E(x$.$$.fragment,f),E(k$.$$.fragment,f),E(Y0.$$.fragment,f),E(S$.$$.fragment,f),E(ew.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(rw.$$.fragment,f),E(q$.$$.fragment,f),E(aw.$$.fragment,f),XVe=!0)},o(f){C(d.$$.fragment,f),C(xa.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(Rf.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(BL.$$.fragment,f),C(Gg.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(qL.$$.fragment,f),C(GL.$$.fragment,f),C(Eh.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(WL.$$.fragment,f),C(ap.$$.fragment,f),C(np.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(ZL.$$.fragment,f),C(wp.$$.fragment,f),C(Ap.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ay.$$.fragment,f),C(xp.$$.fragment,f),C(ny.$$.fragment,f),C(xu.$$.fragment,f),C(sy.$$.fragment,f),C(ly.$$.fragment,f),C(dy.$$.fragment,f),C(ku.$$.fragment,f),C(cy.$$.fragment,f),C(E7.$$.fragment,f),C(fy.$$.fragment,f),C(my.$$.fragment,f),C(hy.$$.fragment,f),C(w7.$$.fragment,f),C(py.$$.fragment,f),C(f1.$$.fragment,f),C(_y.$$.fragment,f),C(uy.$$.fragment,f),C(vy.$$.fragment,f),C(g1.$$.fragment,f),C(Fy.$$.fragment,f),C(K1.$$.fragment,f),C(Ty.$$.fragment,f),C(My.$$.fragment,f),C(Cy.$$.fragment,f),C(e2.$$.fragment,f),C(wy.$$.fragment,f),C(v2.$$.fragment,f),C(Ay.$$.fragment,f),C(Ly.$$.fragment,f),C(xy.$$.fragment,f),C(T2.$$.fragment,f),C($y.$$.fragment,f),C(bb.$$.fragment,f),C(ky.$$.fragment,f),C(Sy.$$.fragment,f),C(Py.$$.fragment,f),C(Fb.$$.fragment,f),C(By.$$.fragment,f),C(Kb.$$.fragment,f),C(Iy.$$.fragment,f),C(Ny.$$.fragment,f),C(jy.$$.fragment,f),C(ev.$$.fragment,f),C(Dy.$$.fragment,f),C(iv.$$.fragment,f),C(Gy.$$.fragment,f),C(Oy.$$.fragment,f),C(Xy.$$.fragment,f),C(cv.$$.fragment,f),C(zy.$$.fragment,f),C(Hv.$$.fragment,f),C(Qy.$$.fragment,f),C(Wy.$$.fragment,f),C(Uy.$$.fragment,f),C(Jv.$$.fragment,f),C(Jy.$$.fragment,f),C(jF.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(e8.$$.fragment,f),C(GF.$$.fragment,f),C(o8.$$.fragment,f),C(XF.$$.fragment,f),C(r8.$$.fragment,f),C(t8.$$.fragment,f),C(n8.$$.fragment,f),C(QF.$$.fragment,f),C(s8.$$.fragment,f),C(s6.$$.fragment,f),C(l8.$$.fragment,f),C(i8.$$.fragment,f),C(c8.$$.fragment,f),C(i6.$$.fragment,f),C(f8.$$.fragment,f),C(f6.$$.fragment,f),C(m8.$$.fragment,f),C(g8.$$.fragment,f),C(p8.$$.fragment,f),C(g6.$$.fragment,f),C(_8.$$.fragment,f),C(_6.$$.fragment,f),C(u8.$$.fragment,f),C(b8.$$.fragment,f),C(F8.$$.fragment,f),C(b6.$$.fragment,f),C(T8.$$.fragment,f),C(x6.$$.fragment,f),C(M8.$$.fragment,f),C(E8.$$.fragment,f),C(w8.$$.fragment,f),C(k6.$$.fragment,f),C(A8.$$.fragment,f),C(q6.$$.fragment,f),C(L8.$$.fragment,f),C(y8.$$.fragment,f),C($8.$$.fragment,f),C(D6.$$.fragment,f),C(k8.$$.fragment,f),C(K6.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(B8.$$.fragment,f),C(eT.$$.fragment,f),C(I8.$$.fragment,f),C(aT.$$.fragment,f),C(q8.$$.fragment,f),C(j8.$$.fragment,f),C(G8.$$.fragment,f),C(sT.$$.fragment,f),C(O8.$$.fragment,f),C(gT.$$.fragment,f),C(V8.$$.fragment,f),C(X8.$$.fragment,f),C(Q8.$$.fragment,f),C(pT.$$.fragment,f),C(W8.$$.fragment,f),C(FT.$$.fragment,f),C(H8.$$.fragment,f),C(U8.$$.fragment,f),C(Y8.$$.fragment,f),C(MT.$$.fragment,f),C(K8.$$.fragment,f),C(AT.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(yT.$$.fragment,f),C(a9.$$.fragment,f),C(kT.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(RT.$$.fragment,f),C(d9.$$.fragment,f),C(jT.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(GT.$$.fragment,f),C(h9.$$.fragment,f),C(XT.$$.fragment,f),C(p9.$$.fragment,f),C(_9.$$.fragment,f),C(b9.$$.fragment,f),C(QT.$$.fragment,f),C(v9.$$.fragment,f),C(jM.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(GM.$$.fragment,f),C(C9.$$.fragment,f),C(fE.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(y9.$$.fragment,f),C(gE.$$.fragment,f),C(x9.$$.fragment,f),C(LE.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(R9.$$.fragment,f),C(xE.$$.fragment,f),C(P9.$$.fragment,f),C(PE.$$.fragment,f),C(B9.$$.fragment,f),C(I9.$$.fragment,f),C(q9.$$.fragment,f),C(IE.$$.fragment,f),C(j9.$$.fragment,f),C(t4.$$.fragment,f),C(D9.$$.fragment,f),C(G9.$$.fragment,f),C(V9.$$.fragment,f),C(n4.$$.fragment,f),C(X9.$$.fragment,f),C(_4.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(H9.$$.fragment,f),C(b4.$$.fragment,f),C(U9.$$.fragment,f),C(z4.$$.fragment,f),C(J9.$$.fragment,f),C(Y9.$$.fragment,f),C(Z9.$$.fragment,f),C(W4.$$.fragment,f),C(ex.$$.fragment,f),C(fC.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(gC.$$.fragment,f),C(nx.$$.fragment,f),C(_C.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(bC.$$.fragment,f),C(fx.$$.fragment,f),C(FC.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(MC.$$.fragment,f),C(_x.$$.fragment,f),C(VC.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(zC.$$.fragment,f),C(Tx.$$.fragment,f),C(m5.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(h5.$$.fragment,f),C(Ax.$$.fragment,f),C(_5.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(b5.$$.fragment,f),C(kx.$$.fragment,f),C(F5.$$.fragment,f),C(Sx.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(M5.$$.fragment,f),C(Ix.$$.fragment,f),C(J5.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(Dx.$$.fragment,f),C(K5.$$.fragment,f),C(Gx.$$.fragment,f),C(d3.$$.fragment,f),C(Ox.$$.fragment,f),C(Vx.$$.fragment,f),C(zx.$$.fragment,f),C(f3.$$.fragment,f),C(Qx.$$.fragment,f),C(w3.$$.fragment,f),C(Wx.$$.fragment,f),C(Hx.$$.fragment,f),C(Jx.$$.fragment,f),C(L3.$$.fragment,f),C(Yx.$$.fragment,f),C(q3.$$.fragment,f),C(Kx.$$.fragment,f),C(Zx.$$.fragment,f),C(o$.$$.fragment,f),C(D3.$$.fragment,f),C(r$.$$.fragment,f),C(Y3.$$.fragment,f),C(t$.$$.fragment,f),C(a$.$$.fragment,f),C(s$.$$.fragment,f),C(Z3.$$.fragment,f),C(l$.$$.fragment,f),C(c0.$$.fragment,f),C(i$.$$.fragment,f),C(d$.$$.fragment,f),C(f$.$$.fragment,f),C(m0.$$.fragment,f),C(m$.$$.fragment,f),C(E0.$$.fragment,f),C(g$.$$.fragment,f),C(h$.$$.fragment,f),C(_$.$$.fragment,f),C(w0.$$.fragment,f),C(u$.$$.fragment,f),C(P0.$$.fragment,f),C(b$.$$.fragment,f),C(v$.$$.fragment,f),C(T$.$$.fragment,f),C(I0.$$.fragment,f),C(M$.$$.fragment,f),C(z0.$$.fragment,f),C(E$.$$.fragment,f),C(C$.$$.fragment,f),C(A$.$$.fragment,f),C(W0.$$.fragment,f),C(L$.$$.fragment,f),C(U0.$$.fragment,f),C(y$.$$.fragment,f),C(x$.$$.fragment,f),C(k$.$$.fragment,f),C(Y0.$$.fragment,f),C(S$.$$.fragment,f),C(ew.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(rw.$$.fragment,f),C(q$.$$.fragment,f),C(aw.$$.fragment,f),XVe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(yf),f&&t(at),f&&t(Oe),f&&t(Qe),f&&t($f),w(xa,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t($a),f&&t(jGe),f&&t(yi),w(xL),f&&t(DGe),f&&t(Nn),f&&t(GGe),w($L,f),f&&t(OGe),f&&t(lS),f&&t(VGe),w(Rf,f),f&&t(XGe),f&&t(xi),w(kL),f&&t(zGe),f&&t(wo),w(SL),w(BL),w(Gg),w(IL),f&&t(QGe),f&&t(ki),w(NL),f&&t(WGe),f&&t(Ao),w(qL),w(GL),w(Eh),w(OL),f&&t(HGe),f&&t(Si),w(VL),f&&t(UGe),f&&t(Lo),w(XL),w(WL),w(ap),w(np),w(HL),f&&t(JGe),f&&t(Ri),w(UL),f&&t(YGe),f&&t(yo),w(JL),w(ZL),w(wp),w(Ap),w(ey),f&&t(KGe),f&&t(Bi),w(oy),f&&t(ZGe),f&&t(xo),w(ry),w(ay),w(xp),w(ny),w(xu),f&&t(eOe),f&&t(qi),w(sy),f&&t(oOe),f&&t($o),w(ly),w(dy),w(ku),w(cy),w(E7),f&&t(rOe),f&&t(Gi),w(fy),f&&t(tOe),f&&t(ko),w(my),w(hy),w(w7),w(py),w(f1),f&&t(aOe),f&&t(Xi),w(_y),f&&t(nOe),f&&t(So),w(uy),w(vy),w(g1),w(Fy),w(K1),f&&t(sOe),f&&t(Wi),w(Ty),f&&t(lOe),f&&t(Ro),w(My),w(Cy),w(e2),w(wy),w(v2),f&&t(iOe),f&&t(Ji),w(Ay),f&&t(dOe),f&&t(Po),w(Ly),w(xy),w(T2),w($y),w(bb),f&&t(cOe),f&&t(Zi),w(ky),f&&t(fOe),f&&t(Bo),w(Sy),w(Py),w(Fb),w(By),w(Kb),f&&t(mOe),f&&t(rd),w(Iy),f&&t(gOe),f&&t(Io),w(Ny),w(jy),w(ev),w(Dy),w(iv),f&&t(hOe),f&&t(nd),w(Gy),f&&t(pOe),f&&t(qo),w(Oy),w(Xy),w(cv),w(zy),w(Hv),f&&t(_Oe),f&&t(id),w(Qy),f&&t(uOe),f&&t(jo),w(Wy),w(Uy),w(Jv),w(Jy),w(jF),f&&t(bOe),f&&t(fd),w(Yy),f&&t(vOe),f&&t(Do),w(Ky),w(e8),w(GF),w(o8),w(XF),f&&t(FOe),f&&t(hd),w(r8),f&&t(TOe),f&&t(Go),w(t8),w(n8),w(QF),w(s8),w(s6),f&&t(MOe),f&&t(ud),w(l8),f&&t(EOe),f&&t(Oo),w(i8),w(c8),w(i6),w(f8),w(f6),f&&t(COe),f&&t(Fd),w(m8),f&&t(wOe),f&&t(Vo),w(g8),w(p8),w(g6),w(_8),w(_6),f&&t(AOe),f&&t(Ed),w(u8),f&&t(LOe),f&&t(Xo),w(b8),w(F8),w(b6),w(T8),w(x6),f&&t(yOe),f&&t(Ad),w(M8),f&&t(xOe),f&&t(zo),w(E8),w(w8),w(k6),w(A8),w(q6),f&&t($Oe),f&&t(xd),w(L8),f&&t(kOe),f&&t(Qo),w(y8),w($8),w(D6),w(k8),w(K6),f&&t(SOe),f&&t(Sd),w(S8),f&&t(ROe),f&&t(Wo),w(R8),w(B8),w(eT),w(I8),w(aT),f&&t(POe),f&&t(Bd),w(q8),f&&t(BOe),f&&t(Ho),w(j8),w(G8),w(sT),w(O8),w(gT),f&&t(IOe),f&&t(qd),w(V8),f&&t(NOe),f&&t(Uo),w(X8),w(Q8),w(pT),w(W8),w(FT),f&&t(qOe),f&&t(Od),w(H8),f&&t(jOe),f&&t(Jo),w(U8),w(Y8),w(MT),w(K8),w(AT),f&&t(DOe),f&&t(zd),w(e9),f&&t(GOe),f&&t(Yo),w(o9),w(t9),w(yT),w(a9),w(kT),f&&t(OOe),f&&t(Hd),w(n9),f&&t(VOe),f&&t(Ko),w(s9),w(i9),w(RT),w(d9),w(jT),f&&t(XOe),f&&t(Yd),w(c9),f&&t(zOe),f&&t(Zo),w(f9),w(g9),w(GT),w(h9),w(XT),f&&t(QOe),f&&t(ec),w(p9),f&&t(WOe),f&&t(er),w(_9),w(b9),w(QT),w(v9),w(jM),f&&t(HOe),f&&t(tc),w(F9),f&&t(UOe),f&&t(or),w(T9),w(E9),w(GM),w(C9),w(fE),f&&t(JOe),f&&t(sc),w(w9),f&&t(YOe),f&&t(rr),w(A9),w(y9),w(gE),w(x9),w(LE),f&&t(KOe),f&&t(dc),w($9),f&&t(ZOe),f&&t(tr),w(k9),w(R9),w(xE),w(P9),w(PE),f&&t(eVe),f&&t(mc),w(B9),f&&t(oVe),f&&t(ar),w(I9),w(q9),w(IE),w(j9),w(t4),f&&t(rVe),f&&t(pc),w(D9),f&&t(tVe),f&&t(nr),w(G9),w(V9),w(n4),w(X9),w(_4),f&&t(aVe),f&&t(bc),w(z9),f&&t(nVe),f&&t(sr),w(Q9),w(H9),w(b4),w(U9),w(z4),f&&t(sVe),f&&t(Tc),w(J9),f&&t(lVe),f&&t(lr),w(Y9),w(Z9),w(W4),w(ex),w(fC),f&&t(iVe),f&&t(Cc),w(ox),f&&t(dVe),f&&t(ir),w(rx),w(ax),w(gC),w(nx),w(_C),f&&t(cVe),f&&t(Lc),w(lx),f&&t(fVe),f&&t(dr),w(ix),w(cx),w(bC),w(fx),w(FC),f&&t(mVe),f&&t($c),w(mx),f&&t(gVe),f&&t(cr),w(gx),w(px),w(MC),w(_x),w(VC),f&&t(hVe),f&&t(Rc),w(ux),f&&t(pVe),f&&t(fr),w(bx),w(Fx),w(zC),w(Tx),w(m5),f&&t(_Ve),f&&t(Ic),w(Mx),f&&t(uVe),f&&t(mr),w(Ex),w(wx),w(h5),w(Ax),w(_5),f&&t(bVe),f&&t(jc),w(Lx),f&&t(vVe),f&&t(gr),w(yx),w($x),w(b5),w(kx),w(F5),f&&t(FVe),f&&t(Oc),w(Sx),f&&t(TVe),f&&t(hr),w(Rx),w(Bx),w(M5),w(Ix),w(J5),f&&t(MVe),f&&t(zc),w(Nx),f&&t(EVe),f&&t(pr),w(qx),w(Dx),w(K5),w(Gx),w(d3),f&&t(CVe),f&&t(Hc),w(Ox),f&&t(wVe),f&&t(_r),w(Vx),w(zx),w(f3),w(Qx),w(w3),f&&t(AVe),f&&t(Yc),w(Wx),f&&t(LVe),f&&t(ur),w(Hx),w(Jx),w(L3),w(Yx),w(q3),f&&t(yVe),f&&t(ef),w(Kx),f&&t(xVe),f&&t(br),w(Zx),w(o$),w(D3),w(r$),w(Y3),f&&t($Ve),f&&t(tf),w(t$),f&&t(kVe),f&&t(vr),w(a$),w(s$),w(Z3),w(l$),w(c0),f&&t(SVe),f&&t(sf),w(i$),f&&t(RVe),f&&t(Fr),w(d$),w(f$),w(m0),w(m$),w(E0),f&&t(PVe),f&&t(cf),w(g$),f&&t(BVe),f&&t(Tr),w(h$),w(_$),w(w0),w(u$),w(P0),f&&t(IVe),f&&t(gf),w(b$),f&&t(NVe),f&&t(Mr),w(v$),w(T$),w(I0),w(M$),w(z0),f&&t(qVe),f&&t(_f),w(E$),f&&t(jVe),f&&t(Er),w(C$),w(A$),w(W0),w(L$),w(U0),f&&t(DVe),f&&t(vf),w(y$),f&&t(GVe),f&&t(Cr),w(x$),w(k$),w(Y0),w(S$),w(ew),f&&t(OVe),f&&t(Mf),w(P$),f&&t(VVe),f&&t(wr),w(B$),w(N$),w(rw),w(q$),w(aw)}}}const COt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function wOt(x){return EDt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class SOt extends vDt{constructor(g){super();FDt(this,g,wOt,EOt,TDt,{})}}export{SOt as default,COt as metadata};
