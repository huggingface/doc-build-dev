import{S as DIt,i as GIt,s as OIt,e as a,k as l,w as F,t as o,M as VIt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as XIt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as oUr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function zIt(L){let g,v,p,m,u,d,h,Eo,vi,Af,at,Fi,Ti,iA,yf,Ge,We,Mi,Sn,dA,Rn,Pn,cA,Ei,Bn,fA,Ci,Lf,La;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),vi=a("code"),Af=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Fi=a("code"),Ti=o('"new-model"'),iA=o(")."),yf=l(),Ge=a("p"),We=o("Likewise, if your "),Mi=a("code"),Sn=o("NewModel"),dA=o(" is a subclass of "),Rn=a("a"),Pn=o("PreTrainedModel"),cA=o(`, make sure its
`),Ei=a("code"),Bn=o("config_class"),fA=o(` attribute is set to the same class you use when registering the model (here
`),Ci=a("code"),Lf=o("NewModelConfig"),La=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var Nk=s(p);m=r(Nk,"NewModelConfig"),Nk.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var wi=s(d);h=r(wi,"PretrainedConfig"),wi.forEach(t),Eo=r(Ae,`, make sure its
`),vi=n(Ae,"CODE",{});var qk=s(vi);Af=r(qk,"model_type"),qk.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Fi=n(Ae,"CODE",{});var jk=s(Fi);Ti=r(jk,'"new-model"'),jk.forEach(t),iA=r(Ae,")."),Ae.forEach(t),yf=i(Qe),Ge=n(Qe,"P",{});var Co=s(Ge);We=r(Co,"Likewise, if your "),Mi=n(Co,"CODE",{});var xa=s(Mi);Sn=r(xa,"NewModel"),xa.forEach(t),dA=r(Co," is a subclass of "),Rn=n(Co,"A",{href:!0});var Dk=s(Rn);Pn=r(Dk,"PreTrainedModel"),Dk.forEach(t),cA=r(Co,`, make sure its
`),Ei=n(Co,"CODE",{});var xf=s(Ei);Bn=r(xf,"config_class"),xf.forEach(t),fA=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ci=n(Co,"CODE",{});var Gk=s(Ci);Lf=r(Gk,"NewModelConfig"),Gk.forEach(t),La=r(Co,")."),Co.forEach(t),this.h()},h(){c(Rn,"href","/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Eo),e(g,vi),e(vi,Af),e(g,at),e(g,Fi),e(Fi,Ti),e(g,iA),b(Qe,yf,Ae),b(Qe,Ge,Ae),e(Ge,We),e(Ge,Mi),e(Mi,Sn),e(Ge,dA),e(Ge,Rn),e(Rn,Pn),e(Ge,cA),e(Ge,Ei),e(Ei,Bn),e(Ge,fA),e(Ge,Ci),e(Ci,Lf),e(Ge,La)},d(Qe){Qe&&t(g),Qe&&t(yf),Qe&&t(Ge)}}}function WIt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QIt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HIt(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function UIt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JIt(L){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function YIt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KIt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZIt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Nt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ENt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ANt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Nt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function INt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ONt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZNt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _qt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $qt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Iqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Oqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vqt(L){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xqt(L){let g,v,p,m,u,d,h,Eo,vi,Af,at,Fi,Ti,iA,yf,Ge,We,Mi,Sn,dA,Rn,Pn,cA,Ei,Bn,fA,Ci,Lf,La,Qe,Ae,Nk,wi,qk,jk,Co,xa,Dk,xf,Gk,qXe,EDe,Ai,$f,Lre,mA,jXe,xre,DXe,CDe,In,GXe,$re,OXe,VXe,kre,XXe,zXe,wDe,gA,ADe,Ok,WXe,yDe,kf,LDe,yi,Sf,Sre,hA,QXe,Rre,HXe,xDe,wo,pA,UXe,uA,JXe,Vk,YXe,KXe,ZXe,_A,eze,Pre,oze,rze,tze,wr,bA,aze,Bre,nze,sze,Li,lze,Ire,ize,dze,Nre,cze,fze,mze,A,Rf,qre,gze,hze,Xk,pze,uze,_ze,Pf,jre,bze,vze,zk,Fze,Tze,Mze,Bf,Dre,Eze,Cze,Wk,wze,Aze,yze,If,Gre,Lze,xze,Qk,$ze,kze,Sze,Nf,Ore,Rze,Pze,Hk,Bze,Ize,Nze,qf,Vre,qze,jze,Uk,Dze,Gze,Oze,jf,Xre,Vze,Xze,Jk,zze,Wze,Qze,Df,zre,Hze,Uze,Yk,Jze,Yze,Kze,Gf,Wre,Zze,eWe,Kk,oWe,rWe,tWe,Of,Qre,aWe,nWe,Zk,sWe,lWe,iWe,Vf,Hre,dWe,cWe,eS,fWe,mWe,gWe,Xf,Ure,hWe,pWe,oS,uWe,_We,bWe,zf,Jre,vWe,FWe,rS,TWe,MWe,EWe,Wf,Yre,CWe,wWe,tS,AWe,yWe,LWe,Qf,Kre,xWe,$We,aS,kWe,SWe,RWe,Hf,Zre,PWe,BWe,nS,IWe,NWe,qWe,Uf,ete,jWe,DWe,sS,GWe,OWe,VWe,Jf,ote,XWe,zWe,lS,WWe,QWe,HWe,Yf,rte,UWe,JWe,iS,YWe,KWe,ZWe,Kf,tte,eQe,oQe,dS,rQe,tQe,aQe,Zf,ate,nQe,sQe,cS,lQe,iQe,dQe,em,nte,cQe,fQe,fS,mQe,gQe,hQe,om,ste,pQe,uQe,mS,_Qe,bQe,vQe,rm,lte,FQe,TQe,gS,MQe,EQe,CQe,tm,ite,wQe,AQe,hS,yQe,LQe,xQe,am,dte,$Qe,kQe,pS,SQe,RQe,PQe,nm,cte,BQe,IQe,uS,NQe,qQe,jQe,sm,fte,DQe,GQe,_S,OQe,VQe,XQe,lm,mte,zQe,WQe,bS,QQe,HQe,UQe,im,gte,JQe,YQe,vS,KQe,ZQe,eHe,dm,hte,oHe,rHe,FS,tHe,aHe,nHe,cm,pte,sHe,lHe,TS,iHe,dHe,cHe,fm,ute,fHe,mHe,MS,gHe,hHe,pHe,mm,_te,uHe,_He,ES,bHe,vHe,FHe,gm,bte,THe,MHe,CS,EHe,CHe,wHe,hm,vte,AHe,yHe,wS,LHe,xHe,$He,pm,Fte,kHe,SHe,AS,RHe,PHe,BHe,um,Tte,IHe,NHe,yS,qHe,jHe,DHe,_m,Mte,GHe,OHe,LS,VHe,XHe,zHe,bm,Ete,WHe,QHe,xS,HHe,UHe,JHe,vm,Cte,YHe,KHe,$S,ZHe,eUe,oUe,Fm,wte,rUe,tUe,kS,aUe,nUe,sUe,Tm,Ate,lUe,iUe,SS,dUe,cUe,fUe,Mm,yte,mUe,gUe,RS,hUe,pUe,uUe,Em,Lte,_Ue,bUe,PS,vUe,FUe,TUe,Cm,xte,MUe,EUe,BS,CUe,wUe,AUe,wm,$te,yUe,LUe,IS,xUe,$Ue,kUe,Am,kte,SUe,RUe,NS,PUe,BUe,IUe,ym,Ste,NUe,qUe,qS,jUe,DUe,GUe,Lm,Rte,OUe,VUe,jS,XUe,zUe,WUe,xm,Pte,QUe,HUe,DS,UUe,JUe,YUe,$m,Bte,KUe,ZUe,GS,eJe,oJe,rJe,km,Ite,tJe,aJe,OS,nJe,sJe,lJe,Sm,Nte,iJe,dJe,VS,cJe,fJe,mJe,Rm,qte,gJe,hJe,XS,pJe,uJe,_Je,Pm,jte,bJe,vJe,zS,FJe,TJe,MJe,Bm,Dte,EJe,CJe,WS,wJe,AJe,yJe,Im,Gte,LJe,xJe,QS,$Je,kJe,SJe,Nm,Ote,RJe,PJe,HS,BJe,IJe,NJe,qm,Vte,qJe,jJe,US,DJe,GJe,OJe,jm,Xte,VJe,XJe,JS,zJe,WJe,QJe,Dm,zte,HJe,UJe,YS,JJe,YJe,KJe,Gm,Wte,ZJe,eYe,KS,oYe,rYe,tYe,Om,Qte,aYe,nYe,ZS,sYe,lYe,iYe,Vm,Hte,dYe,cYe,eR,fYe,mYe,gYe,Xm,Ute,hYe,pYe,oR,uYe,_Ye,bYe,zm,Jte,vYe,FYe,rR,TYe,MYe,EYe,Wm,Yte,CYe,wYe,tR,AYe,yYe,LYe,Qm,Kte,xYe,$Ye,aR,kYe,SYe,RYe,Hm,Zte,PYe,BYe,nR,IYe,NYe,qYe,Um,eae,jYe,DYe,sR,GYe,OYe,VYe,Jm,oae,XYe,zYe,lR,WYe,QYe,HYe,Ym,rae,UYe,JYe,iR,YYe,KYe,ZYe,Km,tae,eKe,oKe,dR,rKe,tKe,aKe,Zm,aae,nKe,sKe,cR,lKe,iKe,dKe,eg,nae,cKe,fKe,fR,mKe,gKe,hKe,og,sae,pKe,uKe,mR,_Ke,bKe,vKe,rg,lae,FKe,TKe,gR,MKe,EKe,CKe,tg,iae,wKe,AKe,hR,yKe,LKe,xKe,ag,dae,$Ke,kKe,pR,SKe,RKe,PKe,ng,cae,BKe,IKe,uR,NKe,qKe,jKe,sg,fae,DKe,GKe,_R,OKe,VKe,XKe,lg,mae,zKe,WKe,bR,QKe,HKe,UKe,ig,gae,JKe,YKe,vR,KKe,ZKe,eZe,dg,hae,oZe,rZe,FR,tZe,aZe,nZe,cg,pae,sZe,lZe,TR,iZe,dZe,cZe,fg,uae,fZe,mZe,MR,gZe,hZe,pZe,mg,_ae,uZe,_Ze,ER,bZe,vZe,FZe,gg,bae,TZe,MZe,CR,EZe,CZe,wZe,hg,vae,AZe,yZe,wR,LZe,xZe,$Ze,pg,Fae,kZe,SZe,AR,RZe,PZe,BZe,ug,Tae,IZe,NZe,yR,qZe,jZe,DZe,_g,Mae,GZe,OZe,LR,VZe,XZe,zZe,bg,Eae,WZe,QZe,xR,HZe,UZe,JZe,vg,Cae,YZe,KZe,$R,ZZe,eeo,oeo,Fg,wae,reo,teo,kR,aeo,neo,seo,Tg,Aae,leo,ieo,SR,deo,ceo,feo,Mg,yae,meo,geo,RR,heo,peo,ueo,Eg,Lae,_eo,beo,PR,veo,Feo,Teo,Cg,xae,Meo,Eeo,BR,Ceo,weo,Aeo,wg,$ae,yeo,Leo,IR,xeo,$eo,keo,Ag,kae,Seo,Reo,NR,Peo,Beo,Ieo,yg,Sae,Neo,qeo,qR,jeo,Deo,Geo,Lg,Rae,Oeo,Veo,jR,Xeo,zeo,Weo,xg,Pae,Qeo,Heo,DR,Ueo,Jeo,Yeo,$g,Bae,Keo,Zeo,GR,eoo,ooo,roo,kg,Iae,too,aoo,OR,noo,soo,loo,Sg,Nae,ioo,doo,VR,coo,foo,moo,Rg,qae,goo,hoo,XR,poo,uoo,_oo,Pg,jae,boo,voo,zR,Foo,Too,Moo,Bg,Dae,Eoo,Coo,WR,woo,Aoo,yoo,Ig,Gae,Loo,xoo,QR,$oo,koo,Soo,Ng,Roo,qg,vA,Poo,Oae,Boo,$De,xi,jg,Vae,FA,Ioo,Xae,Noo,kDe,Ao,TA,qoo,MA,joo,HR,Doo,Goo,Ooo,EA,Voo,zae,Xoo,zoo,Woo,Ar,CA,Qoo,Wae,Hoo,Uoo,$a,Joo,Qae,Yoo,Koo,Hae,Zoo,ero,Uae,oro,rro,tro,k,Nn,Jae,aro,nro,UR,sro,lro,JR,iro,dro,cro,qn,Yae,fro,mro,YR,gro,hro,KR,pro,uro,_ro,jn,Kae,bro,vro,ZR,Fro,Tro,eP,Mro,Ero,Cro,Dg,Zae,wro,Aro,oP,yro,Lro,xro,Dn,ene,$ro,kro,rP,Sro,Rro,tP,Pro,Bro,Iro,Gg,one,Nro,qro,aP,jro,Dro,Gro,Og,rne,Oro,Vro,nP,Xro,zro,Wro,Vg,tne,Qro,Hro,sP,Uro,Jro,Yro,Gn,ane,Kro,Zro,lP,eto,oto,iP,rto,tto,ato,On,nne,nto,sto,dP,lto,ito,cP,dto,cto,fto,Vn,sne,mto,gto,fP,hto,pto,mP,uto,_to,bto,Xg,lne,vto,Fto,gP,Tto,Mto,Eto,zg,ine,Cto,wto,hP,Ato,yto,Lto,Wg,dne,xto,$to,pP,kto,Sto,Rto,Xn,cne,Pto,Bto,uP,Ito,Nto,_P,qto,jto,Dto,Qg,fne,Gto,Oto,bP,Vto,Xto,zto,zn,mne,Wto,Qto,vP,Hto,Uto,FP,Jto,Yto,Kto,Wn,gne,Zto,eao,TP,oao,rao,MP,tao,aao,nao,Qn,hne,sao,lao,EP,iao,dao,CP,cao,fao,mao,Hg,pne,gao,hao,wP,pao,uao,_ao,Hn,une,bao,vao,AP,Fao,Tao,yP,Mao,Eao,Cao,Un,_ne,wao,Aao,LP,yao,Lao,xP,xao,$ao,kao,Jn,bne,Sao,Rao,$P,Pao,Bao,kP,Iao,Nao,qao,Yn,vne,jao,Dao,SP,Gao,Oao,RP,Vao,Xao,zao,Kn,Fne,Wao,Qao,PP,Hao,Uao,BP,Jao,Yao,Kao,Zn,Tne,Zao,eno,IP,ono,rno,NP,tno,ano,nno,Ug,Mne,sno,lno,qP,ino,dno,cno,es,Ene,fno,mno,jP,gno,hno,DP,pno,uno,_no,Jg,Cne,bno,vno,GP,Fno,Tno,Mno,os,wne,Eno,Cno,OP,wno,Ano,VP,yno,Lno,xno,rs,Ane,$no,kno,XP,Sno,Rno,zP,Pno,Bno,Ino,ts,yne,Nno,qno,WP,jno,Dno,QP,Gno,Ono,Vno,Yg,Lne,Xno,zno,HP,Wno,Qno,Hno,as,xne,Uno,Jno,UP,Yno,Kno,JP,Zno,eso,oso,ns,$ne,rso,tso,YP,aso,nso,KP,sso,lso,iso,Kg,kne,dso,cso,ZP,fso,mso,gso,ss,Sne,hso,pso,eB,uso,_so,oB,bso,vso,Fso,ls,Rne,Tso,Mso,rB,Eso,Cso,tB,wso,Aso,yso,is,Pne,Lso,xso,aB,$so,kso,nB,Sso,Rso,Pso,ds,Bne,Bso,Iso,sB,Nso,qso,lB,jso,Dso,Gso,cs,Ine,Oso,Vso,iB,Xso,zso,dB,Wso,Qso,Hso,fs,Nne,Uso,Jso,cB,Yso,Kso,fB,Zso,elo,olo,ms,qne,rlo,tlo,mB,alo,nlo,gB,slo,llo,ilo,Zg,jne,dlo,clo,hB,flo,mlo,glo,gs,Dne,hlo,plo,pB,ulo,_lo,uB,blo,vlo,Flo,eh,Gne,Tlo,Mlo,_B,Elo,Clo,wlo,oh,One,Alo,ylo,bB,Llo,xlo,$lo,hs,Vne,klo,Slo,vB,Rlo,Plo,FB,Blo,Ilo,Nlo,ps,Xne,qlo,jlo,TB,Dlo,Glo,MB,Olo,Vlo,Xlo,us,zne,zlo,Wlo,EB,Qlo,Hlo,CB,Ulo,Jlo,Ylo,rh,Wne,Klo,Zlo,wB,eio,oio,rio,_s,Qne,tio,aio,AB,nio,sio,yB,lio,iio,dio,bs,Hne,cio,fio,LB,mio,gio,xB,hio,pio,uio,vs,Une,_io,bio,$B,vio,Fio,kB,Tio,Mio,Eio,Fs,Jne,Cio,wio,SB,Aio,yio,RB,Lio,xio,$io,Ts,Yne,kio,Sio,PB,Rio,Pio,BB,Bio,Iio,Nio,th,Kne,qio,jio,IB,Dio,Gio,Oio,Ms,Zne,Vio,Xio,NB,zio,Wio,qB,Qio,Hio,Uio,ah,ese,Jio,Yio,jB,Kio,Zio,edo,nh,ose,odo,rdo,DB,tdo,ado,ndo,sh,rse,sdo,ldo,GB,ido,ddo,cdo,lh,tse,fdo,mdo,OB,gdo,hdo,pdo,Es,ase,udo,_do,VB,bdo,vdo,XB,Fdo,Tdo,Mdo,ih,nse,Edo,Cdo,zB,wdo,Ado,ydo,Cs,sse,Ldo,xdo,WB,$do,kdo,QB,Sdo,Rdo,Pdo,ws,lse,Bdo,Ido,HB,Ndo,qdo,UB,jdo,Ddo,Gdo,As,ise,Odo,Vdo,JB,Xdo,zdo,YB,Wdo,Qdo,Hdo,ys,dse,Udo,Jdo,KB,Ydo,Kdo,ZB,Zdo,eco,oco,Ls,cse,rco,tco,eI,aco,nco,oI,sco,lco,ico,xs,fse,dco,cco,rI,fco,mco,tI,gco,hco,pco,dh,mse,uco,_co,aI,bco,vco,Fco,ch,gse,Tco,Mco,nI,Eco,Cco,wco,$s,hse,Aco,yco,sI,Lco,xco,lI,$co,kco,Sco,ks,pse,Rco,Pco,iI,Bco,Ico,dI,Nco,qco,jco,Ss,use,Dco,Gco,cI,Oco,Vco,fI,Xco,zco,Wco,fh,_se,Qco,Hco,mI,Uco,Jco,Yco,mh,bse,Kco,Zco,gI,efo,ofo,rfo,gh,vse,tfo,afo,hI,nfo,sfo,lfo,Rs,Fse,ifo,dfo,pI,cfo,ffo,uI,mfo,gfo,hfo,Ps,Tse,pfo,ufo,_I,_fo,bfo,bI,vfo,Ffo,Tfo,hh,Mse,Mfo,Efo,vI,Cfo,wfo,Afo,ph,Ese,yfo,Lfo,FI,xfo,$fo,kfo,uh,Cse,Sfo,Rfo,TI,Pfo,Bfo,Ifo,Bs,wse,Nfo,qfo,MI,jfo,Dfo,EI,Gfo,Ofo,Vfo,_h,Ase,Xfo,zfo,CI,Wfo,Qfo,Hfo,bh,yse,Ufo,Jfo,wI,Yfo,Kfo,Zfo,Is,Lse,emo,omo,AI,rmo,tmo,yI,amo,nmo,smo,Ns,xse,lmo,imo,LI,dmo,cmo,xI,fmo,mmo,gmo,qs,$se,hmo,pmo,$I,umo,_mo,kI,bmo,vmo,Fmo,js,kse,Tmo,Mmo,SI,Emo,Cmo,RI,wmo,Amo,ymo,vh,Lmo,Fh,wA,xmo,Sse,$mo,SDe,$i,Th,Rse,AA,kmo,Pse,Smo,RDe,yo,yA,Rmo,LA,Pmo,PI,Bmo,Imo,Nmo,xA,qmo,Bse,jmo,Dmo,Gmo,He,$A,Omo,Ise,Vmo,Xmo,ka,zmo,Nse,Wmo,Qmo,qse,Hmo,Umo,jse,Jmo,Ymo,Kmo,Y,Mh,Dse,Zmo,ego,BI,ogo,rgo,tgo,Eh,Gse,ago,ngo,II,sgo,lgo,igo,Ch,Ose,dgo,cgo,NI,fgo,mgo,ggo,wh,Vse,hgo,pgo,qI,ugo,_go,bgo,Ah,Xse,vgo,Fgo,jI,Tgo,Mgo,Ego,yh,zse,Cgo,wgo,DI,Ago,ygo,Lgo,Lh,Wse,xgo,$go,GI,kgo,Sgo,Rgo,xh,Qse,Pgo,Bgo,OI,Igo,Ngo,qgo,$h,Hse,jgo,Dgo,VI,Ggo,Ogo,Vgo,kh,Use,Xgo,zgo,XI,Wgo,Qgo,Hgo,Sh,Jse,Ugo,Jgo,zI,Ygo,Kgo,Zgo,Rh,Yse,eho,oho,WI,rho,tho,aho,Ph,Kse,nho,sho,QI,lho,iho,dho,Bh,Zse,cho,fho,HI,mho,gho,hho,Ih,ele,pho,uho,UI,_ho,bho,vho,Nh,ole,Fho,Tho,JI,Mho,Eho,Cho,qh,rle,who,Aho,YI,yho,Lho,xho,jh,tle,$ho,kho,KI,Sho,Rho,Pho,Dh,ale,Bho,Iho,ZI,Nho,qho,jho,Gh,nle,Dho,Gho,eN,Oho,Vho,Xho,Oh,sle,zho,Who,oN,Qho,Hho,Uho,Vh,lle,Jho,Yho,rN,Kho,Zho,epo,Xh,ile,opo,rpo,tN,tpo,apo,npo,zh,dle,spo,lpo,aN,ipo,dpo,cpo,Wh,cle,fpo,mpo,nN,gpo,hpo,ppo,Qh,fle,upo,_po,sN,bpo,vpo,Fpo,Hh,mle,Tpo,Mpo,lN,Epo,Cpo,wpo,Uh,gle,Apo,ypo,iN,Lpo,xpo,$po,Jh,hle,kpo,Spo,dN,Rpo,Ppo,Bpo,Yh,ple,Ipo,Npo,cN,qpo,jpo,Dpo,Kh,ule,Gpo,Opo,fN,Vpo,Xpo,zpo,Zh,_le,Wpo,Qpo,mN,Hpo,Upo,Jpo,ep,Ypo,op,Kpo,rp,kA,Zpo,ble,euo,PDe,ki,tp,vle,SA,ouo,Fle,ruo,BDe,Lo,RA,tuo,PA,auo,gN,nuo,suo,luo,BA,iuo,Tle,duo,cuo,fuo,Ue,IA,muo,Mle,guo,huo,Si,puo,Ele,uuo,_uo,Cle,buo,vuo,Fuo,he,ap,wle,Tuo,Muo,hN,Euo,Cuo,wuo,np,Ale,Auo,yuo,yle,Luo,xuo,$uo,sp,Lle,kuo,Suo,pN,Ruo,Puo,Buo,lp,xle,Iuo,Nuo,uN,quo,juo,Duo,ip,$le,Guo,Ouo,_N,Vuo,Xuo,zuo,dp,kle,Wuo,Quo,bN,Huo,Uuo,Juo,cp,Sle,Yuo,Kuo,vN,Zuo,e_o,o_o,fp,Rle,r_o,t_o,FN,a_o,n_o,s_o,mp,Ple,l_o,i_o,TN,d_o,c_o,f_o,gp,Ble,m_o,g_o,MN,h_o,p_o,u_o,hp,Ile,__o,b_o,EN,v_o,F_o,T_o,pp,Nle,M_o,E_o,CN,C_o,w_o,A_o,up,qle,y_o,L_o,wN,x_o,$_o,k_o,_p,jle,S_o,R_o,AN,P_o,B_o,I_o,bp,Dle,N_o,q_o,yN,j_o,D_o,G_o,vp,Gle,O_o,V_o,LN,X_o,z_o,W_o,Fp,Ole,Q_o,H_o,xN,U_o,J_o,Y_o,Tp,K_o,Mp,Z_o,Ep,NA,e1o,Vle,o1o,IDe,Ri,Cp,Xle,qA,r1o,zle,t1o,NDe,xo,jA,a1o,Pi,n1o,$N,s1o,l1o,kN,i1o,d1o,c1o,DA,f1o,Wle,m1o,g1o,h1o,nt,GA,p1o,Qle,u1o,_1o,Bi,b1o,Hle,v1o,F1o,SN,T1o,M1o,E1o,wp,C1o,Je,OA,w1o,Ule,A1o,y1o,Sa,L1o,Jle,x1o,$1o,Yle,k1o,S1o,Kle,R1o,P1o,B1o,x,Ap,Zle,I1o,N1o,RN,q1o,j1o,D1o,yp,eie,G1o,O1o,PN,V1o,X1o,z1o,Lp,oie,W1o,Q1o,BN,H1o,U1o,J1o,xp,rie,Y1o,K1o,IN,Z1o,ebo,obo,$p,tie,rbo,tbo,NN,abo,nbo,sbo,kp,aie,lbo,ibo,qN,dbo,cbo,fbo,Sp,nie,mbo,gbo,jN,hbo,pbo,ubo,Rp,sie,_bo,bbo,DN,vbo,Fbo,Tbo,Pp,lie,Mbo,Ebo,GN,Cbo,wbo,Abo,Bp,iie,ybo,Lbo,ON,xbo,$bo,kbo,Ip,die,Sbo,Rbo,VN,Pbo,Bbo,Ibo,Np,cie,Nbo,qbo,XN,jbo,Dbo,Gbo,qp,fie,Obo,Vbo,zN,Xbo,zbo,Wbo,jp,mie,Qbo,Hbo,WN,Ubo,Jbo,Ybo,Dp,gie,Kbo,Zbo,QN,e2o,o2o,r2o,Gp,hie,t2o,a2o,HN,n2o,s2o,l2o,Op,pie,i2o,d2o,UN,c2o,f2o,m2o,Vp,uie,g2o,h2o,JN,p2o,u2o,_2o,Xp,_ie,b2o,v2o,YN,F2o,T2o,M2o,zp,bie,E2o,C2o,KN,w2o,A2o,y2o,Wp,vie,L2o,x2o,ZN,$2o,k2o,S2o,Qp,Fie,R2o,P2o,eq,B2o,I2o,N2o,Hp,Tie,q2o,j2o,oq,D2o,G2o,O2o,Up,Mie,V2o,X2o,rq,z2o,W2o,Q2o,Jp,Eie,H2o,U2o,tq,J2o,Y2o,K2o,Yp,Cie,Z2o,evo,aq,ovo,rvo,tvo,Kp,wie,avo,nvo,nq,svo,lvo,ivo,Zp,Aie,dvo,cvo,sq,fvo,mvo,gvo,eu,yie,hvo,pvo,lq,uvo,_vo,bvo,ou,Lie,vvo,Fvo,iq,Tvo,Mvo,Evo,ru,xie,Cvo,wvo,dq,Avo,yvo,Lvo,tu,$ie,xvo,$vo,cq,kvo,Svo,Rvo,au,kie,Pvo,Bvo,fq,Ivo,Nvo,qvo,Ds,Sie,jvo,Dvo,mq,Gvo,Ovo,gq,Vvo,Xvo,zvo,nu,Rie,Wvo,Qvo,hq,Hvo,Uvo,Jvo,su,Pie,Yvo,Kvo,pq,Zvo,e3o,o3o,lu,Bie,r3o,t3o,uq,a3o,n3o,s3o,iu,Iie,l3o,i3o,_q,d3o,c3o,f3o,du,Nie,m3o,g3o,bq,h3o,p3o,u3o,cu,qie,_3o,b3o,vq,v3o,F3o,T3o,fu,jie,M3o,E3o,Fq,C3o,w3o,A3o,mu,Die,y3o,L3o,Tq,x3o,$3o,k3o,gu,Gie,S3o,R3o,Mq,P3o,B3o,I3o,hu,Oie,N3o,q3o,Eq,j3o,D3o,G3o,pu,Vie,O3o,V3o,Cq,X3o,z3o,W3o,uu,Xie,Q3o,H3o,wq,U3o,J3o,Y3o,_u,zie,K3o,Z3o,Aq,eFo,oFo,rFo,bu,Wie,tFo,aFo,yq,nFo,sFo,lFo,vu,Qie,iFo,dFo,Lq,cFo,fFo,mFo,Fu,Hie,gFo,hFo,xq,pFo,uFo,_Fo,Tu,Uie,bFo,vFo,$q,FFo,TFo,MFo,Mu,Jie,EFo,CFo,kq,wFo,AFo,yFo,Eu,Yie,LFo,xFo,Sq,$Fo,kFo,SFo,Cu,Kie,RFo,PFo,Rq,BFo,IFo,NFo,wu,Zie,qFo,jFo,Pq,DFo,GFo,OFo,Au,ede,VFo,XFo,Bq,zFo,WFo,QFo,yu,ode,HFo,UFo,Iq,JFo,YFo,KFo,Lu,rde,ZFo,e6o,Nq,o6o,r6o,t6o,xu,tde,a6o,n6o,qq,s6o,l6o,i6o,$u,ade,d6o,c6o,jq,f6o,m6o,g6o,ku,nde,h6o,p6o,Dq,u6o,_6o,b6o,Su,sde,v6o,F6o,Gq,T6o,M6o,E6o,Ru,lde,C6o,w6o,Oq,A6o,y6o,L6o,Pu,ide,x6o,$6o,Vq,k6o,S6o,R6o,Bu,dde,P6o,B6o,Xq,I6o,N6o,q6o,Iu,cde,j6o,D6o,zq,G6o,O6o,V6o,Nu,fde,X6o,z6o,Wq,W6o,Q6o,H6o,qu,mde,U6o,J6o,Qq,Y6o,K6o,Z6o,ju,gde,eTo,oTo,Hq,rTo,tTo,aTo,Du,hde,nTo,sTo,Uq,lTo,iTo,dTo,Gu,pde,cTo,fTo,Jq,mTo,gTo,hTo,Ou,ude,pTo,uTo,Yq,_To,bTo,vTo,Vu,_de,FTo,TTo,Kq,MTo,ETo,CTo,Xu,bde,wTo,ATo,Zq,yTo,LTo,xTo,zu,vde,$To,kTo,ej,STo,RTo,PTo,Wu,Fde,BTo,ITo,oj,NTo,qTo,jTo,Qu,Tde,DTo,GTo,rj,OTo,VTo,XTo,Hu,Mde,zTo,WTo,tj,QTo,HTo,UTo,Uu,Ede,JTo,YTo,aj,KTo,ZTo,e7o,Ju,Cde,o7o,r7o,nj,t7o,a7o,n7o,Yu,wde,s7o,l7o,sj,i7o,d7o,c7o,Ku,Ade,f7o,m7o,lj,g7o,h7o,p7o,Zu,yde,u7o,_7o,ij,b7o,v7o,F7o,e_,Lde,T7o,M7o,dj,E7o,C7o,w7o,o_,xde,A7o,y7o,cj,L7o,x7o,$7o,r_,$de,k7o,S7o,fj,R7o,P7o,B7o,t_,kde,I7o,N7o,mj,q7o,j7o,D7o,a_,Sde,G7o,O7o,gj,V7o,X7o,z7o,n_,Rde,W7o,Q7o,hj,H7o,U7o,J7o,s_,Pde,Y7o,K7o,pj,Z7o,e9o,o9o,l_,Bde,r9o,t9o,uj,a9o,n9o,s9o,i_,Ide,l9o,i9o,_j,d9o,c9o,f9o,d_,Nde,m9o,g9o,bj,h9o,p9o,u9o,c_,qde,_9o,b9o,vj,v9o,F9o,T9o,f_,jde,M9o,E9o,Fj,C9o,w9o,A9o,m_,Dde,y9o,L9o,Tj,x9o,$9o,k9o,g_,Gde,S9o,R9o,Mj,P9o,B9o,I9o,h_,Ode,N9o,q9o,Ej,j9o,D9o,G9o,p_,Vde,O9o,V9o,Cj,X9o,z9o,W9o,u_,Xde,Q9o,H9o,wj,U9o,J9o,Y9o,__,zde,K9o,Z9o,Aj,eMo,oMo,rMo,b_,Wde,tMo,aMo,yj,nMo,sMo,lMo,v_,Qde,iMo,dMo,Lj,cMo,fMo,mMo,F_,Hde,gMo,hMo,xj,pMo,uMo,_Mo,T_,Ude,bMo,vMo,$j,FMo,TMo,MMo,M_,EMo,Jde,CMo,wMo,Yde,AMo,yMo,E_,qDe,Ii,C_,Kde,VA,LMo,Zde,xMo,jDe,$o,XA,$Mo,Ni,kMo,kj,SMo,RMo,Sj,PMo,BMo,IMo,zA,NMo,ece,qMo,jMo,DMo,st,WA,GMo,oce,OMo,VMo,qi,XMo,rce,zMo,WMo,Rj,QMo,HMo,UMo,w_,JMo,Ye,QA,YMo,tce,KMo,ZMo,Ra,e4o,ace,o4o,r4o,nce,t4o,a4o,sce,n4o,s4o,l4o,G,A_,lce,i4o,d4o,Pj,c4o,f4o,m4o,y_,ice,g4o,h4o,Bj,p4o,u4o,_4o,L_,dce,b4o,v4o,Ij,F4o,T4o,M4o,x_,cce,E4o,C4o,Nj,w4o,A4o,y4o,$_,fce,L4o,x4o,qj,$4o,k4o,S4o,k_,mce,R4o,P4o,jj,B4o,I4o,N4o,S_,gce,q4o,j4o,Dj,D4o,G4o,O4o,R_,hce,V4o,X4o,Gj,z4o,W4o,Q4o,P_,pce,H4o,U4o,Oj,J4o,Y4o,K4o,B_,uce,Z4o,eEo,Vj,oEo,rEo,tEo,I_,_ce,aEo,nEo,Xj,sEo,lEo,iEo,N_,bce,dEo,cEo,zj,fEo,mEo,gEo,q_,vce,hEo,pEo,Wj,uEo,_Eo,bEo,j_,Fce,vEo,FEo,Qj,TEo,MEo,EEo,D_,Tce,CEo,wEo,Hj,AEo,yEo,LEo,G_,Mce,xEo,$Eo,Uj,kEo,SEo,REo,O_,Ece,PEo,BEo,Jj,IEo,NEo,qEo,V_,Cce,jEo,DEo,Yj,GEo,OEo,VEo,X_,wce,XEo,zEo,Kj,WEo,QEo,HEo,z_,Ace,UEo,JEo,Zj,YEo,KEo,ZEo,W_,yce,eCo,oCo,eD,rCo,tCo,aCo,Q_,Lce,nCo,sCo,oD,lCo,iCo,dCo,H_,xce,cCo,fCo,rD,mCo,gCo,hCo,U_,$ce,pCo,uCo,tD,_Co,bCo,vCo,J_,kce,FCo,TCo,aD,MCo,ECo,CCo,Y_,Sce,wCo,ACo,nD,yCo,LCo,xCo,K_,Rce,$Co,kCo,sD,SCo,RCo,PCo,Z_,Pce,BCo,ICo,lD,NCo,qCo,jCo,e1,Bce,DCo,GCo,iD,OCo,VCo,XCo,o1,Ice,zCo,WCo,dD,QCo,HCo,UCo,r1,Nce,JCo,YCo,cD,KCo,ZCo,e5o,t1,qce,o5o,r5o,fD,t5o,a5o,n5o,a1,jce,s5o,l5o,mD,i5o,d5o,c5o,n1,Dce,f5o,m5o,gD,g5o,h5o,p5o,s1,Gce,u5o,_5o,hD,b5o,v5o,F5o,l1,Oce,T5o,M5o,pD,E5o,C5o,w5o,i1,Vce,A5o,y5o,uD,L5o,x5o,$5o,d1,Xce,k5o,S5o,_D,R5o,P5o,B5o,c1,zce,I5o,N5o,bD,q5o,j5o,D5o,f1,Wce,G5o,O5o,vD,V5o,X5o,z5o,m1,Qce,W5o,Q5o,FD,H5o,U5o,J5o,g1,Hce,Y5o,K5o,TD,Z5o,e0o,o0o,h1,Uce,r0o,t0o,MD,a0o,n0o,s0o,p1,l0o,Jce,i0o,d0o,Yce,c0o,f0o,u1,DDe,ji,_1,Kce,HA,m0o,Zce,g0o,GDe,ko,UA,h0o,Di,p0o,ED,u0o,_0o,CD,b0o,v0o,F0o,JA,T0o,efe,M0o,E0o,C0o,lt,YA,w0o,ofe,A0o,y0o,Gi,L0o,rfe,x0o,$0o,wD,k0o,S0o,R0o,b1,P0o,Ke,KA,B0o,tfe,I0o,N0o,Pa,q0o,afe,j0o,D0o,nfe,G0o,O0o,sfe,V0o,X0o,z0o,z,v1,lfe,W0o,Q0o,AD,H0o,U0o,J0o,F1,ife,Y0o,K0o,yD,Z0o,ewo,owo,T1,dfe,rwo,two,LD,awo,nwo,swo,M1,cfe,lwo,iwo,xD,dwo,cwo,fwo,E1,ffe,mwo,gwo,$D,hwo,pwo,uwo,C1,mfe,_wo,bwo,kD,vwo,Fwo,Two,w1,gfe,Mwo,Ewo,SD,Cwo,wwo,Awo,A1,hfe,ywo,Lwo,RD,xwo,$wo,kwo,y1,pfe,Swo,Rwo,PD,Pwo,Bwo,Iwo,L1,ufe,Nwo,qwo,BD,jwo,Dwo,Gwo,x1,_fe,Owo,Vwo,ID,Xwo,zwo,Wwo,$1,bfe,Qwo,Hwo,ND,Uwo,Jwo,Ywo,k1,vfe,Kwo,Zwo,qD,eAo,oAo,rAo,S1,Ffe,tAo,aAo,jD,nAo,sAo,lAo,R1,Tfe,iAo,dAo,DD,cAo,fAo,mAo,P1,Mfe,gAo,hAo,GD,pAo,uAo,_Ao,B1,Efe,bAo,vAo,OD,FAo,TAo,MAo,I1,Cfe,EAo,CAo,VD,wAo,AAo,yAo,N1,wfe,LAo,xAo,XD,$Ao,kAo,SAo,q1,Afe,RAo,PAo,zD,BAo,IAo,NAo,j1,yfe,qAo,jAo,WD,DAo,GAo,OAo,D1,Lfe,VAo,XAo,QD,zAo,WAo,QAo,G1,xfe,HAo,UAo,HD,JAo,YAo,KAo,O1,$fe,ZAo,eyo,UD,oyo,ryo,tyo,V1,kfe,ayo,nyo,JD,syo,lyo,iyo,X1,Sfe,dyo,cyo,YD,fyo,myo,gyo,z1,Rfe,hyo,pyo,KD,uyo,_yo,byo,W1,Pfe,vyo,Fyo,ZD,Tyo,Myo,Eyo,Q1,Bfe,Cyo,wyo,eG,Ayo,yyo,Lyo,H1,Ife,xyo,$yo,oG,kyo,Syo,Ryo,U1,Nfe,Pyo,Byo,rG,Iyo,Nyo,qyo,J1,qfe,jyo,Dyo,tG,Gyo,Oyo,Vyo,Y1,jfe,Xyo,zyo,aG,Wyo,Qyo,Hyo,K1,Dfe,Uyo,Jyo,nG,Yyo,Kyo,Zyo,Z1,Gfe,eLo,oLo,sG,rLo,tLo,aLo,eb,Ofe,nLo,sLo,lG,lLo,iLo,dLo,ob,Vfe,cLo,fLo,iG,mLo,gLo,hLo,rb,Xfe,pLo,uLo,dG,_Lo,bLo,vLo,tb,FLo,zfe,TLo,MLo,Wfe,ELo,CLo,ab,ODe,Oi,nb,Qfe,ZA,wLo,Hfe,ALo,VDe,So,ey,yLo,Vi,LLo,cG,xLo,$Lo,fG,kLo,SLo,RLo,oy,PLo,Ufe,BLo,ILo,NLo,it,ry,qLo,Jfe,jLo,DLo,Xi,GLo,Yfe,OLo,VLo,mG,XLo,zLo,WLo,sb,QLo,Ze,ty,HLo,Kfe,ULo,JLo,Ba,YLo,Zfe,KLo,ZLo,eme,e8o,o8o,ome,r8o,t8o,a8o,Q,lb,rme,n8o,s8o,gG,l8o,i8o,d8o,ib,tme,c8o,f8o,hG,m8o,g8o,h8o,db,ame,p8o,u8o,pG,_8o,b8o,v8o,cb,nme,F8o,T8o,uG,M8o,E8o,C8o,fb,sme,w8o,A8o,_G,y8o,L8o,x8o,mb,lme,$8o,k8o,bG,S8o,R8o,P8o,gb,ime,B8o,I8o,vG,N8o,q8o,j8o,hb,dme,D8o,G8o,FG,O8o,V8o,X8o,pb,cme,z8o,W8o,TG,Q8o,H8o,U8o,ub,fme,J8o,Y8o,MG,K8o,Z8o,exo,_b,mme,oxo,rxo,EG,txo,axo,nxo,bb,gme,sxo,lxo,CG,ixo,dxo,cxo,vb,hme,fxo,mxo,wG,gxo,hxo,pxo,Fb,pme,uxo,_xo,AG,bxo,vxo,Fxo,Tb,ume,Txo,Mxo,yG,Exo,Cxo,wxo,Mb,_me,Axo,yxo,LG,Lxo,xxo,$xo,Eb,bme,kxo,Sxo,xG,Rxo,Pxo,Bxo,Cb,vme,Ixo,Nxo,$G,qxo,jxo,Dxo,wb,Fme,Gxo,Oxo,kG,Vxo,Xxo,zxo,Ab,Tme,Wxo,Qxo,SG,Hxo,Uxo,Jxo,yb,Mme,Yxo,Kxo,RG,Zxo,e$o,o$o,Lb,Eme,r$o,t$o,PG,a$o,n$o,s$o,xb,Cme,l$o,i$o,BG,d$o,c$o,f$o,$b,wme,m$o,g$o,IG,h$o,p$o,u$o,kb,Ame,_$o,b$o,NG,v$o,F$o,T$o,Sb,yme,M$o,E$o,qG,C$o,w$o,A$o,Rb,Lme,y$o,L$o,jG,x$o,$$o,k$o,Pb,xme,S$o,R$o,DG,P$o,B$o,I$o,Bb,$me,N$o,q$o,GG,j$o,D$o,G$o,Ib,kme,O$o,V$o,OG,X$o,z$o,W$o,Nb,Sme,Q$o,H$o,VG,U$o,J$o,Y$o,qb,Rme,K$o,Z$o,Pme,eko,oko,rko,jb,Bme,tko,ako,XG,nko,sko,lko,Db,Ime,iko,dko,zG,cko,fko,mko,Gb,Nme,gko,hko,WG,pko,uko,_ko,Ob,qme,bko,vko,QG,Fko,Tko,Mko,Vb,Eko,jme,Cko,wko,Dme,Ako,yko,Xb,XDe,zi,zb,Gme,ay,Lko,Ome,xko,zDe,Ro,ny,$ko,Wi,kko,HG,Sko,Rko,UG,Pko,Bko,Iko,sy,Nko,Vme,qko,jko,Dko,dt,ly,Gko,Xme,Oko,Vko,Qi,Xko,zme,zko,Wko,JG,Qko,Hko,Uko,Wb,Jko,eo,iy,Yko,Wme,Kko,Zko,Ia,eSo,Qme,oSo,rSo,Hme,tSo,aSo,Ume,nSo,sSo,lSo,ue,Qb,Jme,iSo,dSo,YG,cSo,fSo,mSo,Hb,Yme,gSo,hSo,KG,pSo,uSo,_So,Ub,Kme,bSo,vSo,ZG,FSo,TSo,MSo,Jb,Zme,ESo,CSo,eO,wSo,ASo,ySo,Yb,ege,LSo,xSo,oO,$So,kSo,SSo,Kb,oge,RSo,PSo,rO,BSo,ISo,NSo,Zb,rge,qSo,jSo,tO,DSo,GSo,OSo,e2,tge,VSo,XSo,aO,zSo,WSo,QSo,o2,age,HSo,USo,nO,JSo,YSo,KSo,r2,nge,ZSo,eRo,sO,oRo,rRo,tRo,t2,sge,aRo,nRo,lO,sRo,lRo,iRo,a2,lge,dRo,cRo,iO,fRo,mRo,gRo,n2,ige,hRo,pRo,dO,uRo,_Ro,bRo,s2,dge,vRo,FRo,cO,TRo,MRo,ERo,l2,cge,CRo,wRo,fO,ARo,yRo,LRo,i2,fge,xRo,$Ro,mO,kRo,SRo,RRo,d2,PRo,mge,BRo,IRo,gge,NRo,qRo,c2,WDe,Hi,f2,hge,dy,jRo,pge,DRo,QDe,Po,cy,GRo,Ui,ORo,gO,VRo,XRo,hO,zRo,WRo,QRo,fy,HRo,uge,URo,JRo,YRo,ct,my,KRo,_ge,ZRo,ePo,Ji,oPo,bge,rPo,tPo,pO,aPo,nPo,sPo,m2,lPo,oo,gy,iPo,vge,dPo,cPo,Na,fPo,Fge,mPo,gPo,Tge,hPo,pPo,Mge,uPo,_Po,bPo,N,g2,Ege,vPo,FPo,uO,TPo,MPo,EPo,h2,Cge,CPo,wPo,_O,APo,yPo,LPo,p2,wge,xPo,$Po,bO,kPo,SPo,RPo,u2,Age,PPo,BPo,vO,IPo,NPo,qPo,_2,yge,jPo,DPo,FO,GPo,OPo,VPo,b2,Lge,XPo,zPo,TO,WPo,QPo,HPo,v2,xge,UPo,JPo,MO,YPo,KPo,ZPo,F2,$ge,eBo,oBo,EO,rBo,tBo,aBo,T2,kge,nBo,sBo,CO,lBo,iBo,dBo,M2,Sge,cBo,fBo,wO,mBo,gBo,hBo,E2,Rge,pBo,uBo,AO,_Bo,bBo,vBo,C2,Pge,FBo,TBo,yO,MBo,EBo,CBo,w2,Bge,wBo,ABo,LO,yBo,LBo,xBo,A2,Ige,$Bo,kBo,xO,SBo,RBo,PBo,y2,Nge,BBo,IBo,$O,NBo,qBo,jBo,L2,qge,DBo,GBo,kO,OBo,VBo,XBo,x2,jge,zBo,WBo,SO,QBo,HBo,UBo,$2,Dge,JBo,YBo,RO,KBo,ZBo,eIo,k2,Gge,oIo,rIo,PO,tIo,aIo,nIo,S2,Oge,sIo,lIo,BO,iIo,dIo,cIo,R2,Vge,fIo,mIo,IO,gIo,hIo,pIo,P2,Xge,uIo,_Io,NO,bIo,vIo,FIo,B2,zge,TIo,MIo,qO,EIo,CIo,wIo,I2,Wge,AIo,yIo,jO,LIo,xIo,$Io,N2,Qge,kIo,SIo,DO,RIo,PIo,BIo,q2,Hge,IIo,NIo,GO,qIo,jIo,DIo,j2,Uge,GIo,OIo,OO,VIo,XIo,zIo,D2,Jge,WIo,QIo,VO,HIo,UIo,JIo,G2,Yge,YIo,KIo,XO,ZIo,eNo,oNo,O2,Kge,rNo,tNo,zO,aNo,nNo,sNo,V2,Zge,lNo,iNo,WO,dNo,cNo,fNo,X2,ehe,mNo,gNo,QO,hNo,pNo,uNo,z2,ohe,_No,bNo,HO,vNo,FNo,TNo,W2,rhe,MNo,ENo,UO,CNo,wNo,ANo,Q2,the,yNo,LNo,JO,xNo,$No,kNo,H2,ahe,SNo,RNo,YO,PNo,BNo,INo,U2,nhe,NNo,qNo,KO,jNo,DNo,GNo,J2,she,ONo,VNo,ZO,XNo,zNo,WNo,Y2,lhe,QNo,HNo,eV,UNo,JNo,YNo,K2,ihe,KNo,ZNo,oV,eqo,oqo,rqo,Z2,dhe,tqo,aqo,rV,nqo,sqo,lqo,ev,che,iqo,dqo,tV,cqo,fqo,mqo,ov,fhe,gqo,hqo,aV,pqo,uqo,_qo,rv,mhe,bqo,vqo,nV,Fqo,Tqo,Mqo,tv,ghe,Eqo,Cqo,sV,wqo,Aqo,yqo,av,hhe,Lqo,xqo,lV,$qo,kqo,Sqo,nv,phe,Rqo,Pqo,iV,Bqo,Iqo,Nqo,sv,uhe,qqo,jqo,dV,Dqo,Gqo,Oqo,lv,Vqo,_he,Xqo,zqo,bhe,Wqo,Qqo,iv,HDe,Yi,dv,vhe,hy,Hqo,Fhe,Uqo,UDe,Bo,py,Jqo,Ki,Yqo,cV,Kqo,Zqo,fV,ejo,ojo,rjo,uy,tjo,The,ajo,njo,sjo,ft,_y,ljo,Mhe,ijo,djo,Zi,cjo,Ehe,fjo,mjo,mV,gjo,hjo,pjo,cv,ujo,ro,by,_jo,Che,bjo,vjo,qa,Fjo,whe,Tjo,Mjo,Ahe,Ejo,Cjo,yhe,wjo,Ajo,yjo,Z,fv,Lhe,Ljo,xjo,gV,$jo,kjo,Sjo,mv,xhe,Rjo,Pjo,hV,Bjo,Ijo,Njo,gv,$he,qjo,jjo,pV,Djo,Gjo,Ojo,hv,khe,Vjo,Xjo,uV,zjo,Wjo,Qjo,pv,She,Hjo,Ujo,_V,Jjo,Yjo,Kjo,uv,Rhe,Zjo,eDo,bV,oDo,rDo,tDo,_v,Phe,aDo,nDo,vV,sDo,lDo,iDo,bv,Bhe,dDo,cDo,FV,fDo,mDo,gDo,vv,Ihe,hDo,pDo,TV,uDo,_Do,bDo,Fv,Nhe,vDo,FDo,MV,TDo,MDo,EDo,Tv,qhe,CDo,wDo,EV,ADo,yDo,LDo,Mv,jhe,xDo,$Do,CV,kDo,SDo,RDo,Ev,Dhe,PDo,BDo,wV,IDo,NDo,qDo,Cv,Ghe,jDo,DDo,AV,GDo,ODo,VDo,wv,Ohe,XDo,zDo,yV,WDo,QDo,HDo,Av,Vhe,UDo,JDo,LV,YDo,KDo,ZDo,yv,Xhe,eGo,oGo,xV,rGo,tGo,aGo,Lv,zhe,nGo,sGo,$V,lGo,iGo,dGo,xv,Whe,cGo,fGo,kV,mGo,gGo,hGo,$v,Qhe,pGo,uGo,SV,_Go,bGo,vGo,kv,Hhe,FGo,TGo,RV,MGo,EGo,CGo,Sv,Uhe,wGo,AGo,PV,yGo,LGo,xGo,Rv,Jhe,$Go,kGo,BV,SGo,RGo,PGo,Pv,Yhe,BGo,IGo,IV,NGo,qGo,jGo,Bv,Khe,DGo,GGo,NV,OGo,VGo,XGo,Iv,Zhe,zGo,WGo,qV,QGo,HGo,UGo,Nv,epe,JGo,YGo,jV,KGo,ZGo,eOo,qv,ope,oOo,rOo,DV,tOo,aOo,nOo,jv,rpe,sOo,lOo,GV,iOo,dOo,cOo,Dv,fOo,tpe,mOo,gOo,ape,hOo,pOo,Gv,JDe,ed,Ov,npe,vy,uOo,spe,_Oo,YDe,Io,Fy,bOo,od,vOo,OV,FOo,TOo,VV,MOo,EOo,COo,Ty,wOo,lpe,AOo,yOo,LOo,mt,My,xOo,ipe,$Oo,kOo,rd,SOo,dpe,ROo,POo,XV,BOo,IOo,NOo,Vv,qOo,to,Ey,jOo,cpe,DOo,GOo,ja,OOo,fpe,VOo,XOo,mpe,zOo,WOo,gpe,QOo,HOo,UOo,Zr,Xv,hpe,JOo,YOo,zV,KOo,ZOo,eVo,zv,ppe,oVo,rVo,WV,tVo,aVo,nVo,Wv,upe,sVo,lVo,QV,iVo,dVo,cVo,Qv,_pe,fVo,mVo,HV,gVo,hVo,pVo,Hv,bpe,uVo,_Vo,UV,bVo,vVo,FVo,Uv,TVo,vpe,MVo,EVo,Fpe,CVo,wVo,Jv,KDe,td,Yv,Tpe,Cy,AVo,Mpe,yVo,ZDe,No,wy,LVo,ad,xVo,JV,$Vo,kVo,YV,SVo,RVo,PVo,Ay,BVo,Epe,IVo,NVo,qVo,gt,yy,jVo,Cpe,DVo,GVo,nd,OVo,wpe,VVo,XVo,KV,zVo,WVo,QVo,Kv,HVo,ao,Ly,UVo,Ape,JVo,YVo,Da,KVo,ype,ZVo,eXo,Lpe,oXo,rXo,xpe,tXo,aXo,nXo,H,Zv,$pe,sXo,lXo,ZV,iXo,dXo,cXo,e3,kpe,fXo,mXo,eX,gXo,hXo,pXo,o3,Spe,uXo,_Xo,oX,bXo,vXo,FXo,r3,Rpe,TXo,MXo,rX,EXo,CXo,wXo,t3,Ppe,AXo,yXo,tX,LXo,xXo,$Xo,a3,Bpe,kXo,SXo,aX,RXo,PXo,BXo,n3,Ipe,IXo,NXo,nX,qXo,jXo,DXo,s3,Npe,GXo,OXo,sX,VXo,XXo,zXo,l3,qpe,WXo,QXo,lX,HXo,UXo,JXo,i3,jpe,YXo,KXo,iX,ZXo,ezo,ozo,d3,Dpe,rzo,tzo,dX,azo,nzo,szo,c3,Gpe,lzo,izo,cX,dzo,czo,fzo,f3,Ope,mzo,gzo,fX,hzo,pzo,uzo,m3,Vpe,_zo,bzo,mX,vzo,Fzo,Tzo,g3,Xpe,Mzo,Ezo,gX,Czo,wzo,Azo,h3,zpe,yzo,Lzo,hX,xzo,$zo,kzo,p3,Wpe,Szo,Rzo,pX,Pzo,Bzo,Izo,u3,Qpe,Nzo,qzo,uX,jzo,Dzo,Gzo,_3,Hpe,Ozo,Vzo,_X,Xzo,zzo,Wzo,b3,Upe,Qzo,Hzo,bX,Uzo,Jzo,Yzo,v3,Jpe,Kzo,Zzo,vX,eWo,oWo,rWo,F3,Ype,tWo,aWo,FX,nWo,sWo,lWo,T3,Kpe,iWo,dWo,TX,cWo,fWo,mWo,M3,Zpe,gWo,hWo,MX,pWo,uWo,_Wo,E3,eue,bWo,vWo,EX,FWo,TWo,MWo,C3,oue,EWo,CWo,CX,wWo,AWo,yWo,w3,rue,LWo,xWo,wX,$Wo,kWo,SWo,A3,tue,RWo,PWo,AX,BWo,IWo,NWo,y3,aue,qWo,jWo,yX,DWo,GWo,OWo,L3,nue,VWo,XWo,LX,zWo,WWo,QWo,x3,sue,HWo,UWo,xX,JWo,YWo,KWo,$3,lue,ZWo,eQo,$X,oQo,rQo,tQo,k3,iue,aQo,nQo,kX,sQo,lQo,iQo,S3,due,dQo,cQo,SX,fQo,mQo,gQo,R3,cue,hQo,pQo,RX,uQo,_Qo,bQo,P3,vQo,fue,FQo,TQo,mue,MQo,EQo,B3,eGe,sd,I3,gue,xy,CQo,hue,wQo,oGe,qo,$y,AQo,ld,yQo,PX,LQo,xQo,BX,$Qo,kQo,SQo,ky,RQo,pue,PQo,BQo,IQo,ht,Sy,NQo,uue,qQo,jQo,id,DQo,_ue,GQo,OQo,IX,VQo,XQo,zQo,N3,WQo,no,Ry,QQo,bue,HQo,UQo,Ga,JQo,vue,YQo,KQo,Fue,ZQo,eHo,Tue,oHo,rHo,tHo,V,q3,Mue,aHo,nHo,NX,sHo,lHo,iHo,j3,Eue,dHo,cHo,qX,fHo,mHo,gHo,D3,Cue,hHo,pHo,jX,uHo,_Ho,bHo,G3,wue,vHo,FHo,DX,THo,MHo,EHo,O3,Aue,CHo,wHo,GX,AHo,yHo,LHo,V3,yue,xHo,$Ho,OX,kHo,SHo,RHo,X3,Lue,PHo,BHo,VX,IHo,NHo,qHo,z3,xue,jHo,DHo,XX,GHo,OHo,VHo,W3,$ue,XHo,zHo,zX,WHo,QHo,HHo,Q3,kue,UHo,JHo,WX,YHo,KHo,ZHo,H3,Sue,eUo,oUo,QX,rUo,tUo,aUo,U3,Rue,nUo,sUo,HX,lUo,iUo,dUo,J3,Pue,cUo,fUo,UX,mUo,gUo,hUo,Y3,Bue,pUo,uUo,JX,_Uo,bUo,vUo,K3,Iue,FUo,TUo,YX,MUo,EUo,CUo,Z3,Nue,wUo,AUo,KX,yUo,LUo,xUo,eF,que,$Uo,kUo,ZX,SUo,RUo,PUo,oF,jue,BUo,IUo,ez,NUo,qUo,jUo,rF,Due,DUo,GUo,oz,OUo,VUo,XUo,tF,Gue,zUo,WUo,rz,QUo,HUo,UUo,aF,Oue,JUo,YUo,tz,KUo,ZUo,eJo,nF,Vue,oJo,rJo,az,tJo,aJo,nJo,sF,Xue,sJo,lJo,nz,iJo,dJo,cJo,lF,zue,fJo,mJo,sz,gJo,hJo,pJo,iF,Wue,uJo,_Jo,lz,bJo,vJo,FJo,dF,Que,TJo,MJo,iz,EJo,CJo,wJo,cF,Hue,AJo,yJo,dz,LJo,xJo,$Jo,fF,Uue,kJo,SJo,cz,RJo,PJo,BJo,mF,Jue,IJo,NJo,fz,qJo,jJo,DJo,gF,Yue,GJo,OJo,mz,VJo,XJo,zJo,hF,Kue,WJo,QJo,gz,HJo,UJo,JJo,pF,Zue,YJo,KJo,hz,ZJo,eYo,oYo,uF,e_e,rYo,tYo,pz,aYo,nYo,sYo,_F,o_e,lYo,iYo,uz,dYo,cYo,fYo,bF,r_e,mYo,gYo,_z,hYo,pYo,uYo,vF,t_e,_Yo,bYo,bz,vYo,FYo,TYo,FF,a_e,MYo,EYo,vz,CYo,wYo,AYo,TF,n_e,yYo,LYo,Fz,xYo,$Yo,kYo,MF,s_e,SYo,RYo,Tz,PYo,BYo,IYo,EF,l_e,NYo,qYo,Mz,jYo,DYo,GYo,CF,OYo,i_e,VYo,XYo,d_e,zYo,WYo,wF,rGe,dd,AF,c_e,Py,QYo,f_e,HYo,tGe,jo,By,UYo,cd,JYo,Ez,YYo,KYo,Cz,ZYo,eKo,oKo,Iy,rKo,m_e,tKo,aKo,nKo,pt,Ny,sKo,g_e,lKo,iKo,fd,dKo,h_e,cKo,fKo,wz,mKo,gKo,hKo,yF,pKo,so,qy,uKo,p_e,_Ko,bKo,Oa,vKo,u_e,FKo,TKo,__e,MKo,EKo,b_e,CKo,wKo,AKo,v_e,LF,F_e,yKo,LKo,Az,xKo,$Ko,kKo,xF,SKo,T_e,RKo,PKo,M_e,BKo,IKo,$F,aGe,md,kF,E_e,jy,NKo,C_e,qKo,nGe,Do,Dy,jKo,gd,DKo,yz,GKo,OKo,Lz,VKo,XKo,zKo,Gy,WKo,w_e,QKo,HKo,UKo,ut,Oy,JKo,A_e,YKo,KKo,hd,ZKo,y_e,eZo,oZo,xz,rZo,tZo,aZo,SF,nZo,lo,Vy,sZo,L_e,lZo,iZo,Va,dZo,x_e,cZo,fZo,$_e,mZo,gZo,k_e,hZo,pZo,uZo,ve,RF,S_e,_Zo,bZo,$z,vZo,FZo,TZo,PF,R_e,MZo,EZo,kz,CZo,wZo,AZo,BF,P_e,yZo,LZo,Sz,xZo,$Zo,kZo,IF,B_e,SZo,RZo,Rz,PZo,BZo,IZo,Gs,I_e,NZo,qZo,Pz,jZo,DZo,Bz,GZo,OZo,VZo,NF,N_e,XZo,zZo,Iz,WZo,QZo,HZo,Os,q_e,UZo,JZo,Nz,YZo,KZo,qz,ZZo,eer,oer,_t,j_e,rer,ter,jz,aer,ner,Dz,ser,ler,Gz,ier,der,cer,qF,D_e,fer,mer,Oz,ger,her,per,jF,G_e,uer,_er,Vz,ber,ver,Fer,DF,O_e,Ter,Mer,Xz,Eer,Cer,wer,GF,V_e,Aer,yer,zz,Ler,xer,$er,OF,X_e,ker,Ser,Wz,Rer,Per,Ber,VF,z_e,Ier,Ner,Qz,qer,jer,Der,XF,W_e,Ger,Oer,Hz,Ver,Xer,zer,zF,Wer,Q_e,Qer,Her,H_e,Uer,Jer,WF,sGe,pd,QF,U_e,Xy,Yer,J_e,Ker,lGe,Go,zy,Zer,ud,eor,Uz,oor,ror,Jz,tor,aor,nor,Wy,sor,Y_e,lor,ior,dor,bt,Qy,cor,K_e,mor,gor,_d,hor,Z_e,por,uor,Yz,_or,bor,vor,HF,For,io,Hy,Tor,e1e,Mor,Eor,Xa,Cor,o1e,wor,Aor,r1e,yor,Lor,t1e,xor,$or,kor,a1e,UF,n1e,Sor,Ror,Kz,Por,Bor,Ior,JF,Nor,s1e,qor,jor,l1e,Dor,Gor,YF,iGe,bd,KF,i1e,Uy,Oor,d1e,Vor,dGe,Oo,Jy,Xor,vd,zor,Zz,Wor,Qor,eW,Hor,Uor,Jor,Yy,Yor,c1e,Kor,Zor,err,vt,Ky,orr,f1e,rrr,trr,Fd,arr,m1e,nrr,srr,oW,lrr,irr,drr,ZF,crr,co,Zy,frr,g1e,mrr,grr,za,hrr,h1e,prr,urr,p1e,_rr,brr,u1e,vrr,Frr,Trr,_1e,e6,b1e,Mrr,Err,rW,Crr,wrr,Arr,o6,yrr,v1e,Lrr,xrr,F1e,$rr,krr,r6,cGe,Td,t6,T1e,eL,Srr,M1e,Rrr,fGe,Vo,oL,Prr,Md,Brr,tW,Irr,Nrr,aW,qrr,jrr,Drr,rL,Grr,E1e,Orr,Vrr,Xrr,Ft,tL,zrr,C1e,Wrr,Qrr,Ed,Hrr,w1e,Urr,Jrr,nW,Yrr,Krr,Zrr,a6,etr,fo,aL,otr,A1e,rtr,ttr,Wa,atr,y1e,ntr,str,L1e,ltr,itr,x1e,dtr,ctr,ftr,Re,n6,$1e,mtr,gtr,sW,htr,ptr,utr,s6,k1e,_tr,btr,lW,vtr,Ftr,Ttr,l6,S1e,Mtr,Etr,iW,Ctr,wtr,Atr,i6,R1e,ytr,Ltr,dW,xtr,$tr,ktr,d6,P1e,Str,Rtr,cW,Ptr,Btr,Itr,c6,B1e,Ntr,qtr,fW,jtr,Dtr,Gtr,f6,I1e,Otr,Vtr,mW,Xtr,ztr,Wtr,m6,N1e,Qtr,Htr,gW,Utr,Jtr,Ytr,g6,q1e,Ktr,Ztr,hW,ear,oar,rar,h6,tar,j1e,aar,nar,D1e,sar,lar,p6,mGe,Cd,u6,G1e,nL,iar,O1e,dar,gGe,Xo,sL,car,wd,far,pW,mar,gar,uW,har,par,uar,lL,_ar,V1e,bar,Far,Tar,Tt,iL,Mar,X1e,Ear,Car,Ad,war,z1e,Aar,yar,_W,Lar,xar,$ar,_6,kar,mo,dL,Sar,W1e,Rar,Par,Qa,Bar,Q1e,Iar,Nar,H1e,qar,jar,U1e,Dar,Gar,Oar,et,b6,J1e,Var,Xar,bW,zar,War,Qar,v6,Y1e,Har,Uar,vW,Jar,Yar,Kar,F6,K1e,Zar,enr,FW,onr,rnr,tnr,T6,Z1e,anr,nnr,TW,snr,lnr,inr,M6,ebe,dnr,cnr,MW,fnr,mnr,gnr,E6,hnr,obe,pnr,unr,rbe,_nr,bnr,C6,hGe,yd,w6,tbe,cL,vnr,abe,Fnr,pGe,zo,fL,Tnr,Ld,Mnr,EW,Enr,Cnr,CW,wnr,Anr,ynr,mL,Lnr,nbe,xnr,$nr,knr,Mt,gL,Snr,sbe,Rnr,Pnr,xd,Bnr,lbe,Inr,Nnr,wW,qnr,jnr,Dnr,A6,Gnr,go,hL,Onr,ibe,Vnr,Xnr,Ha,znr,dbe,Wnr,Qnr,cbe,Hnr,Unr,fbe,Jnr,Ynr,Knr,ye,y6,mbe,Znr,esr,AW,osr,rsr,tsr,L6,gbe,asr,nsr,yW,ssr,lsr,isr,x6,hbe,dsr,csr,LW,fsr,msr,gsr,$6,pbe,hsr,psr,xW,usr,_sr,bsr,k6,ube,vsr,Fsr,$W,Tsr,Msr,Esr,S6,_be,Csr,wsr,kW,Asr,ysr,Lsr,R6,bbe,xsr,$sr,SW,ksr,Ssr,Rsr,P6,vbe,Psr,Bsr,RW,Isr,Nsr,qsr,B6,Fbe,jsr,Dsr,PW,Gsr,Osr,Vsr,I6,Tbe,Xsr,zsr,BW,Wsr,Qsr,Hsr,N6,Usr,Mbe,Jsr,Ysr,Ebe,Ksr,Zsr,q6,uGe,$d,j6,Cbe,pL,elr,wbe,olr,_Ge,Wo,uL,rlr,kd,tlr,IW,alr,nlr,NW,slr,llr,ilr,_L,dlr,Abe,clr,flr,mlr,Et,bL,glr,ybe,hlr,plr,Sd,ulr,Lbe,_lr,blr,qW,vlr,Flr,Tlr,D6,Mlr,ho,vL,Elr,xbe,Clr,wlr,Ua,Alr,$be,ylr,Llr,kbe,xlr,$lr,Sbe,klr,Slr,Rlr,FL,G6,Rbe,Plr,Blr,jW,Ilr,Nlr,qlr,O6,Pbe,jlr,Dlr,DW,Glr,Olr,Vlr,V6,Xlr,Bbe,zlr,Wlr,Ibe,Qlr,Hlr,X6,bGe,Rd,z6,Nbe,TL,Ulr,qbe,Jlr,vGe,Qo,ML,Ylr,Pd,Klr,GW,Zlr,eir,OW,oir,rir,tir,EL,air,jbe,nir,sir,lir,Ct,CL,iir,Dbe,dir,cir,Bd,fir,Gbe,mir,gir,VW,hir,pir,uir,W6,_ir,po,wL,bir,Obe,vir,Fir,Ja,Tir,Vbe,Mir,Eir,Xbe,Cir,wir,zbe,Air,yir,Lir,ot,Q6,Wbe,xir,$ir,XW,kir,Sir,Rir,H6,Qbe,Pir,Bir,zW,Iir,Nir,qir,U6,Hbe,jir,Dir,WW,Gir,Oir,Vir,J6,Ube,Xir,zir,QW,Wir,Qir,Hir,Y6,Jbe,Uir,Jir,HW,Yir,Kir,Zir,K6,edr,Ybe,odr,rdr,Kbe,tdr,adr,Z6,FGe,Id,eT,Zbe,AL,ndr,e2e,sdr,TGe,Ho,yL,ldr,Nd,idr,UW,ddr,cdr,JW,fdr,mdr,gdr,LL,hdr,o2e,pdr,udr,_dr,wt,xL,bdr,r2e,vdr,Fdr,qd,Tdr,t2e,Mdr,Edr,YW,Cdr,wdr,Adr,oT,ydr,uo,$L,Ldr,a2e,xdr,$dr,Ya,kdr,n2e,Sdr,Rdr,s2e,Pdr,Bdr,l2e,Idr,Ndr,qdr,jd,rT,i2e,jdr,Ddr,KW,Gdr,Odr,Vdr,tT,d2e,Xdr,zdr,ZW,Wdr,Qdr,Hdr,aT,c2e,Udr,Jdr,eQ,Ydr,Kdr,Zdr,nT,ecr,f2e,ocr,rcr,m2e,tcr,acr,sT,MGe,Dd,lT,g2e,kL,ncr,h2e,scr,EGe,Uo,SL,lcr,Gd,icr,oQ,dcr,ccr,rQ,fcr,mcr,gcr,RL,hcr,p2e,pcr,ucr,_cr,At,PL,bcr,u2e,vcr,Fcr,Od,Tcr,_2e,Mcr,Ecr,tQ,Ccr,wcr,Acr,iT,ycr,_o,BL,Lcr,b2e,xcr,$cr,Ka,kcr,v2e,Scr,Rcr,F2e,Pcr,Bcr,T2e,Icr,Ncr,qcr,IL,dT,M2e,jcr,Dcr,aQ,Gcr,Ocr,Vcr,cT,E2e,Xcr,zcr,nQ,Wcr,Qcr,Hcr,fT,Ucr,C2e,Jcr,Ycr,w2e,Kcr,Zcr,mT,CGe,Vd,gT,A2e,NL,efr,y2e,ofr,wGe,Jo,qL,rfr,Xd,tfr,sQ,afr,nfr,lQ,sfr,lfr,ifr,jL,dfr,L2e,cfr,ffr,mfr,yt,DL,gfr,x2e,hfr,pfr,zd,ufr,$2e,_fr,bfr,iQ,vfr,Ffr,Tfr,hT,Mfr,bo,GL,Efr,k2e,Cfr,wfr,Za,Afr,S2e,yfr,Lfr,R2e,xfr,$fr,P2e,kfr,Sfr,Rfr,B2e,pT,I2e,Pfr,Bfr,dQ,Ifr,Nfr,qfr,uT,jfr,N2e,Dfr,Gfr,q2e,Ofr,Vfr,_T,AGe,Wd,bT,j2e,OL,Xfr,D2e,zfr,yGe,Yo,VL,Wfr,Qd,Qfr,cQ,Hfr,Ufr,fQ,Jfr,Yfr,Kfr,XL,Zfr,G2e,emr,omr,rmr,Lt,zL,tmr,O2e,amr,nmr,Hd,smr,V2e,lmr,imr,mQ,dmr,cmr,fmr,vT,mmr,vo,WL,gmr,X2e,hmr,pmr,en,umr,z2e,_mr,bmr,W2e,vmr,Fmr,Q2e,Tmr,Mmr,Emr,on,FT,H2e,Cmr,wmr,gQ,Amr,ymr,Lmr,TT,U2e,xmr,$mr,hQ,kmr,Smr,Rmr,MT,J2e,Pmr,Bmr,pQ,Imr,Nmr,qmr,ET,Y2e,jmr,Dmr,uQ,Gmr,Omr,Vmr,CT,Xmr,K2e,zmr,Wmr,Z2e,Qmr,Hmr,wT,LGe,Ud,AT,eve,QL,Umr,ove,Jmr,xGe,Ko,HL,Ymr,Jd,Kmr,_Q,Zmr,egr,bQ,ogr,rgr,tgr,UL,agr,rve,ngr,sgr,lgr,xt,JL,igr,tve,dgr,cgr,Yd,fgr,ave,mgr,ggr,vQ,hgr,pgr,ugr,yT,_gr,Fo,YL,bgr,nve,vgr,Fgr,rn,Tgr,sve,Mgr,Egr,lve,Cgr,wgr,ive,Agr,ygr,Lgr,dve,LT,cve,xgr,$gr,FQ,kgr,Sgr,Rgr,xT,Pgr,fve,Bgr,Igr,mve,Ngr,qgr,$T,$Ge,Kd,kT,gve,KL,jgr,hve,Dgr,kGe,Zo,ZL,Ggr,Zd,Ogr,TQ,Vgr,Xgr,MQ,zgr,Wgr,Qgr,e8,Hgr,pve,Ugr,Jgr,Ygr,$t,o8,Kgr,uve,Zgr,ehr,ec,ohr,_ve,rhr,thr,EQ,ahr,nhr,shr,ST,lhr,yr,r8,ihr,bve,dhr,chr,tn,fhr,vve,mhr,ghr,Fve,hhr,phr,Tve,uhr,_hr,bhr,q,RT,Mve,vhr,Fhr,CQ,Thr,Mhr,Ehr,PT,Eve,Chr,whr,wQ,Ahr,yhr,Lhr,BT,Cve,xhr,$hr,AQ,khr,Shr,Rhr,IT,wve,Phr,Bhr,yQ,Ihr,Nhr,qhr,NT,Ave,jhr,Dhr,LQ,Ghr,Ohr,Vhr,qT,yve,Xhr,zhr,xQ,Whr,Qhr,Hhr,jT,Lve,Uhr,Jhr,$Q,Yhr,Khr,Zhr,DT,xve,epr,opr,kQ,rpr,tpr,apr,GT,$ve,npr,spr,SQ,lpr,ipr,dpr,OT,kve,cpr,fpr,RQ,mpr,gpr,hpr,VT,Sve,ppr,upr,PQ,_pr,bpr,vpr,XT,Rve,Fpr,Tpr,BQ,Mpr,Epr,Cpr,zT,Pve,wpr,Apr,IQ,ypr,Lpr,xpr,WT,Bve,$pr,kpr,NQ,Spr,Rpr,Ppr,QT,Ive,Bpr,Ipr,qQ,Npr,qpr,jpr,HT,Nve,Dpr,Gpr,jQ,Opr,Vpr,Xpr,UT,qve,zpr,Wpr,DQ,Qpr,Hpr,Upr,Vs,jve,Jpr,Ypr,GQ,Kpr,Zpr,OQ,eur,our,rur,JT,Dve,tur,aur,VQ,nur,sur,lur,YT,Gve,iur,dur,XQ,cur,fur,mur,KT,Ove,gur,hur,zQ,pur,uur,_ur,ZT,Vve,bur,vur,WQ,Fur,Tur,Mur,e7,Xve,Eur,Cur,QQ,wur,Aur,yur,o7,zve,Lur,xur,HQ,$ur,kur,Sur,r7,Wve,Rur,Pur,UQ,Bur,Iur,Nur,t7,Qve,qur,jur,JQ,Dur,Gur,Our,a7,Hve,Vur,Xur,YQ,zur,Wur,Qur,n7,Uve,Hur,Uur,KQ,Jur,Yur,Kur,s7,Jve,Zur,e_r,ZQ,o_r,r_r,t_r,l7,Yve,a_r,n_r,eH,s_r,l_r,i_r,i7,Kve,d_r,c_r,oH,f_r,m_r,g_r,d7,Zve,h_r,p_r,rH,u_r,__r,b_r,c7,e3e,v_r,F_r,tH,T_r,M_r,E_r,f7,o3e,C_r,w_r,aH,A_r,y_r,L_r,m7,r3e,x_r,$_r,nH,k_r,S_r,R_r,g7,t3e,P_r,B_r,sH,I_r,N_r,q_r,h7,a3e,j_r,D_r,lH,G_r,O_r,V_r,p7,n3e,X_r,z_r,iH,W_r,Q_r,H_r,u7,s3e,U_r,J_r,dH,Y_r,K_r,Z_r,_7,l3e,e1r,o1r,cH,r1r,t1r,a1r,b7,i3e,n1r,s1r,fH,l1r,i1r,d1r,v7,d3e,c1r,f1r,mH,m1r,g1r,h1r,F7,c3e,p1r,u1r,gH,_1r,b1r,v1r,T7,f3e,F1r,T1r,hH,M1r,E1r,C1r,M7,m3e,w1r,A1r,pH,y1r,L1r,x1r,E7,g3e,$1r,k1r,uH,S1r,R1r,P1r,C7,h3e,B1r,I1r,_H,N1r,q1r,j1r,w7,SGe,oc,A7,p3e,t8,D1r,u3e,G1r,RGe,er,a8,O1r,rc,V1r,bH,X1r,z1r,vH,W1r,Q1r,H1r,n8,U1r,_3e,J1r,Y1r,K1r,kt,s8,Z1r,b3e,ebr,obr,tc,rbr,v3e,tbr,abr,FH,nbr,sbr,lbr,y7,ibr,Lr,l8,dbr,F3e,cbr,fbr,an,mbr,T3e,gbr,hbr,M3e,pbr,ubr,E3e,_br,bbr,vbr,se,L7,C3e,Fbr,Tbr,TH,Mbr,Ebr,Cbr,x7,w3e,wbr,Abr,MH,ybr,Lbr,xbr,$7,A3e,$br,kbr,EH,Sbr,Rbr,Pbr,k7,y3e,Bbr,Ibr,CH,Nbr,qbr,jbr,S7,L3e,Dbr,Gbr,wH,Obr,Vbr,Xbr,R7,x3e,zbr,Wbr,AH,Qbr,Hbr,Ubr,P7,$3e,Jbr,Ybr,yH,Kbr,Zbr,e2r,B7,k3e,o2r,r2r,LH,t2r,a2r,n2r,I7,S3e,s2r,l2r,xH,i2r,d2r,c2r,N7,R3e,f2r,m2r,$H,g2r,h2r,p2r,q7,P3e,u2r,_2r,kH,b2r,v2r,F2r,j7,B3e,T2r,M2r,SH,E2r,C2r,w2r,D7,I3e,A2r,y2r,RH,L2r,x2r,$2r,G7,N3e,k2r,S2r,PH,R2r,P2r,B2r,O7,q3e,I2r,N2r,BH,q2r,j2r,D2r,V7,j3e,G2r,O2r,IH,V2r,X2r,z2r,X7,D3e,W2r,Q2r,NH,H2r,U2r,J2r,z7,G3e,Y2r,K2r,qH,Z2r,evr,ovr,W7,O3e,rvr,tvr,jH,avr,nvr,svr,Q7,V3e,lvr,ivr,DH,dvr,cvr,fvr,H7,X3e,mvr,gvr,GH,hvr,pvr,uvr,U7,z3e,_vr,bvr,OH,vvr,Fvr,Tvr,J7,W3e,Mvr,Evr,VH,Cvr,wvr,Avr,Y7,PGe,ac,K7,Q3e,i8,yvr,H3e,Lvr,BGe,or,d8,xvr,nc,$vr,XH,kvr,Svr,zH,Rvr,Pvr,Bvr,c8,Ivr,U3e,Nvr,qvr,jvr,St,f8,Dvr,J3e,Gvr,Ovr,sc,Vvr,Y3e,Xvr,zvr,WH,Wvr,Qvr,Hvr,Z7,Uvr,xr,m8,Jvr,K3e,Yvr,Kvr,nn,Zvr,Z3e,e3r,o3r,eFe,r3r,t3r,oFe,a3r,n3r,s3r,Me,e9,rFe,l3r,i3r,QH,d3r,c3r,f3r,o9,tFe,m3r,g3r,HH,h3r,p3r,u3r,r9,aFe,_3r,b3r,UH,v3r,F3r,T3r,t9,nFe,M3r,E3r,JH,C3r,w3r,A3r,a9,sFe,y3r,L3r,YH,x3r,$3r,k3r,n9,lFe,S3r,R3r,KH,P3r,B3r,I3r,s9,iFe,N3r,q3r,ZH,j3r,D3r,G3r,l9,dFe,O3r,V3r,eU,X3r,z3r,W3r,i9,cFe,Q3r,H3r,oU,U3r,J3r,Y3r,d9,fFe,K3r,Z3r,rU,eFr,oFr,rFr,c9,mFe,tFr,aFr,tU,nFr,sFr,lFr,f9,gFe,iFr,dFr,aU,cFr,fFr,mFr,m9,hFe,gFr,hFr,nU,pFr,uFr,_Fr,g9,IGe,lc,h9,pFe,g8,bFr,uFe,vFr,NGe,rr,h8,FFr,ic,TFr,sU,MFr,EFr,lU,CFr,wFr,AFr,p8,yFr,_Fe,LFr,xFr,$Fr,Rt,u8,kFr,bFe,SFr,RFr,dc,PFr,vFe,BFr,IFr,iU,NFr,qFr,jFr,p9,DFr,$r,_8,GFr,FFe,OFr,VFr,sn,XFr,TFe,zFr,WFr,MFe,QFr,HFr,EFe,UFr,JFr,YFr,ln,u9,CFe,KFr,ZFr,dU,e6r,o6r,r6r,_9,wFe,t6r,a6r,cU,n6r,s6r,l6r,b9,AFe,i6r,d6r,fU,c6r,f6r,m6r,v9,yFe,g6r,h6r,mU,p6r,u6r,_6r,F9,qGe,cc,T9,LFe,b8,b6r,xFe,v6r,jGe,tr,v8,F6r,fc,T6r,gU,M6r,E6r,hU,C6r,w6r,A6r,F8,y6r,$Fe,L6r,x6r,$6r,Pt,T8,k6r,kFe,S6r,R6r,mc,P6r,SFe,B6r,I6r,pU,N6r,q6r,j6r,M9,D6r,kr,M8,G6r,RFe,O6r,V6r,dn,X6r,PFe,z6r,W6r,BFe,Q6r,H6r,IFe,U6r,J6r,Y6r,ie,E9,NFe,K6r,Z6r,uU,eTr,oTr,rTr,C9,qFe,tTr,aTr,_U,nTr,sTr,lTr,w9,jFe,iTr,dTr,bU,cTr,fTr,mTr,A9,DFe,gTr,hTr,vU,pTr,uTr,_Tr,y9,GFe,bTr,vTr,FU,FTr,TTr,MTr,L9,OFe,ETr,CTr,TU,wTr,ATr,yTr,x9,VFe,LTr,xTr,MU,$Tr,kTr,STr,$9,XFe,RTr,PTr,EU,BTr,ITr,NTr,k9,zFe,qTr,jTr,CU,DTr,GTr,OTr,S9,WFe,VTr,XTr,wU,zTr,WTr,QTr,R9,QFe,HTr,UTr,AU,JTr,YTr,KTr,P9,HFe,ZTr,e7r,yU,o7r,r7r,t7r,B9,UFe,a7r,n7r,LU,s7r,l7r,i7r,I9,JFe,d7r,c7r,xU,f7r,m7r,g7r,N9,YFe,h7r,p7r,$U,u7r,_7r,b7r,q9,KFe,v7r,F7r,kU,T7r,M7r,E7r,j9,ZFe,C7r,w7r,SU,A7r,y7r,L7r,D9,e6e,x7r,$7r,RU,k7r,S7r,R7r,G9,o6e,P7r,B7r,PU,I7r,N7r,q7r,O9,r6e,j7r,D7r,BU,G7r,O7r,V7r,V9,DGe,gc,X9,t6e,E8,X7r,a6e,z7r,GGe,ar,C8,W7r,hc,Q7r,IU,H7r,U7r,NU,J7r,Y7r,K7r,w8,Z7r,n6e,e9r,o9r,r9r,Bt,A8,t9r,s6e,a9r,n9r,pc,s9r,l6e,l9r,i9r,qU,d9r,c9r,f9r,z9,m9r,Sr,y8,g9r,i6e,h9r,p9r,cn,u9r,d6e,_9r,b9r,c6e,v9r,F9r,f6e,T9r,M9r,E9r,Le,W9,m6e,C9r,w9r,jU,A9r,y9r,L9r,Q9,g6e,x9r,$9r,DU,k9r,S9r,R9r,H9,h6e,P9r,B9r,GU,I9r,N9r,q9r,U9,p6e,j9r,D9r,OU,G9r,O9r,V9r,J9,u6e,X9r,z9r,VU,W9r,Q9r,H9r,Y9,_6e,U9r,J9r,XU,Y9r,K9r,Z9r,K9,b6e,eMr,oMr,zU,rMr,tMr,aMr,Z9,v6e,nMr,sMr,WU,lMr,iMr,dMr,eM,F6e,cMr,fMr,QU,mMr,gMr,hMr,oM,T6e,pMr,uMr,HU,_Mr,bMr,vMr,rM,OGe,uc,tM,M6e,L8,FMr,E6e,TMr,VGe,nr,x8,MMr,_c,EMr,UU,CMr,wMr,JU,AMr,yMr,LMr,$8,xMr,C6e,$Mr,kMr,SMr,It,k8,RMr,w6e,PMr,BMr,bc,IMr,A6e,NMr,qMr,YU,jMr,DMr,GMr,aM,OMr,Rr,S8,VMr,y6e,XMr,zMr,fn,WMr,L6e,QMr,HMr,x6e,UMr,JMr,$6e,YMr,KMr,ZMr,re,nM,k6e,e4r,o4r,KU,r4r,t4r,a4r,sM,S6e,n4r,s4r,ZU,l4r,i4r,d4r,lM,R6e,c4r,f4r,eJ,m4r,g4r,h4r,iM,P6e,p4r,u4r,oJ,_4r,b4r,v4r,dM,B6e,F4r,T4r,rJ,M4r,E4r,C4r,cM,I6e,w4r,A4r,tJ,y4r,L4r,x4r,fM,N6e,$4r,k4r,aJ,S4r,R4r,P4r,mM,q6e,B4r,I4r,nJ,N4r,q4r,j4r,gM,j6e,D4r,G4r,sJ,O4r,V4r,X4r,hM,D6e,z4r,W4r,lJ,Q4r,H4r,U4r,pM,G6e,J4r,Y4r,iJ,K4r,Z4r,eEr,uM,O6e,oEr,rEr,dJ,tEr,aEr,nEr,_M,V6e,sEr,lEr,cJ,iEr,dEr,cEr,bM,X6e,fEr,mEr,fJ,gEr,hEr,pEr,vM,z6e,uEr,_Er,mJ,bEr,vEr,FEr,FM,W6e,TEr,MEr,gJ,EEr,CEr,wEr,TM,Q6e,AEr,yEr,hJ,LEr,xEr,$Er,MM,H6e,kEr,SEr,pJ,REr,PEr,BEr,EM,U6e,IEr,NEr,uJ,qEr,jEr,DEr,CM,J6e,GEr,OEr,_J,VEr,XEr,zEr,wM,Y6e,WEr,QEr,bJ,HEr,UEr,JEr,AM,K6e,YEr,KEr,vJ,ZEr,eCr,oCr,yM,Z6e,rCr,tCr,FJ,aCr,nCr,sCr,LM,eTe,lCr,iCr,TJ,dCr,cCr,fCr,xM,oTe,mCr,gCr,MJ,hCr,pCr,uCr,$M,rTe,_Cr,bCr,EJ,vCr,FCr,TCr,kM,XGe,vc,SM,tTe,R8,MCr,aTe,ECr,zGe,sr,P8,CCr,Fc,wCr,CJ,ACr,yCr,wJ,LCr,xCr,$Cr,B8,kCr,nTe,SCr,RCr,PCr,Nt,I8,BCr,sTe,ICr,NCr,Tc,qCr,lTe,jCr,DCr,AJ,GCr,OCr,VCr,RM,XCr,Pr,N8,zCr,iTe,WCr,QCr,mn,HCr,dTe,UCr,JCr,cTe,YCr,KCr,fTe,ZCr,e5r,o5r,pe,PM,mTe,r5r,t5r,yJ,a5r,n5r,s5r,BM,gTe,l5r,i5r,LJ,d5r,c5r,f5r,IM,hTe,m5r,g5r,xJ,h5r,p5r,u5r,NM,pTe,_5r,b5r,$J,v5r,F5r,T5r,qM,uTe,M5r,E5r,kJ,C5r,w5r,A5r,jM,_Te,y5r,L5r,SJ,x5r,$5r,k5r,DM,bTe,S5r,R5r,RJ,P5r,B5r,I5r,GM,vTe,N5r,q5r,PJ,j5r,D5r,G5r,OM,FTe,O5r,V5r,BJ,X5r,z5r,W5r,VM,TTe,Q5r,H5r,IJ,U5r,J5r,Y5r,XM,MTe,K5r,Z5r,NJ,e0r,o0r,r0r,zM,ETe,t0r,a0r,qJ,n0r,s0r,l0r,WM,CTe,i0r,d0r,jJ,c0r,f0r,m0r,QM,wTe,g0r,h0r,DJ,p0r,u0r,_0r,HM,ATe,b0r,v0r,GJ,F0r,T0r,M0r,UM,yTe,E0r,C0r,OJ,w0r,A0r,y0r,JM,LTe,L0r,x0r,VJ,$0r,k0r,S0r,YM,WGe,Mc,KM,xTe,q8,R0r,$Te,P0r,QGe,lr,j8,B0r,Ec,I0r,XJ,N0r,q0r,zJ,j0r,D0r,G0r,D8,O0r,kTe,V0r,X0r,z0r,qt,G8,W0r,STe,Q0r,H0r,Cc,U0r,RTe,J0r,Y0r,WJ,K0r,Z0r,ewr,ZM,owr,Br,O8,rwr,PTe,twr,awr,gn,nwr,BTe,swr,lwr,ITe,iwr,dwr,NTe,cwr,fwr,mwr,V8,e4,qTe,gwr,hwr,QJ,pwr,uwr,_wr,o4,jTe,bwr,vwr,HJ,Fwr,Twr,Mwr,r4,HGe,wc,t4,DTe,X8,Ewr,GTe,Cwr,UGe,ir,z8,wwr,Ac,Awr,UJ,ywr,Lwr,JJ,xwr,$wr,kwr,W8,Swr,OTe,Rwr,Pwr,Bwr,jt,Q8,Iwr,VTe,Nwr,qwr,yc,jwr,XTe,Dwr,Gwr,YJ,Owr,Vwr,Xwr,a4,zwr,Ir,H8,Wwr,zTe,Qwr,Hwr,hn,Uwr,WTe,Jwr,Ywr,QTe,Kwr,Zwr,HTe,eAr,oAr,rAr,UTe,n4,JTe,tAr,aAr,KJ,nAr,sAr,lAr,s4,JGe,Lc,l4,YTe,U8,iAr,KTe,dAr,YGe,dr,J8,cAr,xc,fAr,ZJ,mAr,gAr,eY,hAr,pAr,uAr,Y8,_Ar,ZTe,bAr,vAr,FAr,Dt,K8,TAr,e7e,MAr,EAr,$c,CAr,o7e,wAr,AAr,oY,yAr,LAr,xAr,i4,$Ar,Nr,Z8,kAr,r7e,SAr,RAr,pn,PAr,t7e,BAr,IAr,a7e,NAr,qAr,n7e,jAr,DAr,GAr,de,d4,s7e,OAr,VAr,rY,XAr,zAr,WAr,c4,l7e,QAr,HAr,tY,UAr,JAr,YAr,f4,i7e,KAr,ZAr,aY,eyr,oyr,ryr,m4,d7e,tyr,ayr,nY,nyr,syr,lyr,g4,c7e,iyr,dyr,sY,cyr,fyr,myr,h4,f7e,gyr,hyr,lY,pyr,uyr,_yr,p4,m7e,byr,vyr,iY,Fyr,Tyr,Myr,u4,g7e,Eyr,Cyr,dY,wyr,Ayr,yyr,_4,h7e,Lyr,xyr,cY,$yr,kyr,Syr,b4,p7e,Ryr,Pyr,fY,Byr,Iyr,Nyr,v4,u7e,qyr,jyr,mY,Dyr,Gyr,Oyr,F4,_7e,Vyr,Xyr,gY,zyr,Wyr,Qyr,T4,b7e,Hyr,Uyr,hY,Jyr,Yyr,Kyr,M4,v7e,Zyr,eLr,pY,oLr,rLr,tLr,E4,F7e,aLr,nLr,uY,sLr,lLr,iLr,C4,T7e,dLr,cLr,_Y,fLr,mLr,gLr,w4,M7e,hLr,pLr,bY,uLr,_Lr,bLr,A4,E7e,vLr,FLr,vY,TLr,MLr,ELr,y4,C7e,CLr,wLr,FY,ALr,yLr,LLr,L4,w7e,xLr,$Lr,TY,kLr,SLr,RLr,x4,KGe,kc,$4,A7e,ex,PLr,y7e,BLr,ZGe,cr,ox,ILr,Sc,NLr,MY,qLr,jLr,EY,DLr,GLr,OLr,rx,VLr,L7e,XLr,zLr,WLr,Gt,tx,QLr,x7e,HLr,ULr,Rc,JLr,$7e,YLr,KLr,CY,ZLr,e8r,o8r,k4,r8r,qr,ax,t8r,k7e,a8r,n8r,un,s8r,S7e,l8r,i8r,R7e,d8r,c8r,P7e,f8r,m8r,g8r,ce,S4,B7e,h8r,p8r,wY,u8r,_8r,b8r,R4,I7e,v8r,F8r,AY,T8r,M8r,E8r,P4,N7e,C8r,w8r,yY,A8r,y8r,L8r,B4,q7e,x8r,$8r,LY,k8r,S8r,R8r,I4,j7e,P8r,B8r,xY,I8r,N8r,q8r,N4,D7e,j8r,D8r,$Y,G8r,O8r,V8r,q4,G7e,X8r,z8r,kY,W8r,Q8r,H8r,j4,O7e,U8r,J8r,SY,Y8r,K8r,Z8r,D4,V7e,exr,oxr,RY,rxr,txr,axr,G4,X7e,nxr,sxr,PY,lxr,ixr,dxr,O4,z7e,cxr,fxr,BY,mxr,gxr,hxr,V4,W7e,pxr,uxr,IY,_xr,bxr,vxr,X4,Q7e,Fxr,Txr,NY,Mxr,Exr,Cxr,z4,H7e,wxr,Axr,qY,yxr,Lxr,xxr,W4,U7e,$xr,kxr,jY,Sxr,Rxr,Pxr,Q4,J7e,Bxr,Ixr,DY,Nxr,qxr,jxr,H4,Y7e,Dxr,Gxr,GY,Oxr,Vxr,Xxr,U4,K7e,zxr,Wxr,OY,Qxr,Hxr,Uxr,J4,Z7e,Jxr,Yxr,VY,Kxr,Zxr,e$r,Y4,e9e,o$r,r$r,XY,t$r,a$r,n$r,K4,eOe,Pc,Z4,o9e,nx,s$r,r9e,l$r,oOe,fr,sx,i$r,Bc,d$r,zY,c$r,f$r,WY,m$r,g$r,h$r,lx,p$r,t9e,u$r,_$r,b$r,Ot,ix,v$r,a9e,F$r,T$r,Ic,M$r,n9e,E$r,C$r,QY,w$r,A$r,y$r,eE,L$r,jr,dx,x$r,s9e,$$r,k$r,_n,S$r,l9e,R$r,P$r,i9e,B$r,I$r,d9e,N$r,q$r,j$r,c9e,oE,f9e,D$r,G$r,HY,O$r,V$r,X$r,rE,rOe,Nc,tE,m9e,cx,z$r,g9e,W$r,tOe,mr,fx,Q$r,qc,H$r,UY,U$r,J$r,JY,Y$r,K$r,Z$r,mx,ekr,h9e,okr,rkr,tkr,Vt,gx,akr,p9e,nkr,skr,jc,lkr,u9e,ikr,dkr,YY,ckr,fkr,mkr,aE,gkr,Dr,hx,hkr,_9e,pkr,ukr,bn,_kr,b9e,bkr,vkr,v9e,Fkr,Tkr,F9e,Mkr,Ekr,Ckr,T9e,nE,M9e,wkr,Akr,KY,ykr,Lkr,xkr,sE,aOe,Dc,lE,E9e,px,$kr,C9e,kkr,nOe,gr,ux,Skr,Gc,Rkr,ZY,Pkr,Bkr,eK,Ikr,Nkr,qkr,_x,jkr,w9e,Dkr,Gkr,Okr,Xt,bx,Vkr,A9e,Xkr,zkr,Oc,Wkr,y9e,Qkr,Hkr,oK,Ukr,Jkr,Ykr,iE,Kkr,Gr,vx,Zkr,L9e,eSr,oSr,vn,rSr,x9e,tSr,aSr,$9e,nSr,sSr,k9e,lSr,iSr,dSr,te,dE,S9e,cSr,fSr,rK,mSr,gSr,hSr,cE,R9e,pSr,uSr,tK,_Sr,bSr,vSr,fE,P9e,FSr,TSr,aK,MSr,ESr,CSr,mE,B9e,wSr,ASr,nK,ySr,LSr,xSr,gE,I9e,$Sr,kSr,sK,SSr,RSr,PSr,hE,N9e,BSr,ISr,lK,NSr,qSr,jSr,pE,q9e,DSr,GSr,iK,OSr,VSr,XSr,uE,j9e,zSr,WSr,dK,QSr,HSr,USr,_E,D9e,JSr,YSr,cK,KSr,ZSr,eRr,bE,G9e,oRr,rRr,fK,tRr,aRr,nRr,vE,O9e,sRr,lRr,mK,iRr,dRr,cRr,FE,V9e,fRr,mRr,gK,gRr,hRr,pRr,TE,X9e,uRr,_Rr,hK,bRr,vRr,FRr,ME,z9e,TRr,MRr,pK,ERr,CRr,wRr,EE,W9e,ARr,yRr,uK,LRr,xRr,$Rr,CE,Q9e,kRr,SRr,_K,RRr,PRr,BRr,wE,H9e,IRr,NRr,bK,qRr,jRr,DRr,AE,U9e,GRr,ORr,vK,VRr,XRr,zRr,yE,J9e,WRr,QRr,FK,HRr,URr,JRr,LE,Y9e,YRr,KRr,TK,ZRr,ePr,oPr,xE,K9e,rPr,tPr,MK,aPr,nPr,sPr,$E,Z9e,lPr,iPr,EK,dPr,cPr,fPr,kE,eMe,mPr,gPr,CK,hPr,pPr,uPr,SE,oMe,_Pr,bPr,wK,vPr,FPr,TPr,RE,rMe,MPr,EPr,AK,CPr,wPr,APr,PE,tMe,yPr,LPr,yK,xPr,$Pr,kPr,BE,sOe,Vc,IE,aMe,Fx,SPr,nMe,RPr,lOe,hr,Tx,PPr,Xc,BPr,LK,IPr,NPr,xK,qPr,jPr,DPr,Mx,GPr,sMe,OPr,VPr,XPr,zt,Ex,zPr,lMe,WPr,QPr,zc,HPr,iMe,UPr,JPr,$K,YPr,KPr,ZPr,NE,eBr,Or,Cx,oBr,dMe,rBr,tBr,Fn,aBr,cMe,nBr,sBr,fMe,lBr,iBr,mMe,dBr,cBr,fBr,xe,qE,gMe,mBr,gBr,kK,hBr,pBr,uBr,jE,hMe,_Br,bBr,SK,vBr,FBr,TBr,DE,pMe,MBr,EBr,RK,CBr,wBr,ABr,GE,uMe,yBr,LBr,PK,xBr,$Br,kBr,OE,_Me,SBr,RBr,BK,PBr,BBr,IBr,VE,bMe,NBr,qBr,IK,jBr,DBr,GBr,XE,vMe,OBr,VBr,NK,XBr,zBr,WBr,zE,FMe,QBr,HBr,qK,UBr,JBr,YBr,WE,TMe,KBr,ZBr,jK,eIr,oIr,rIr,QE,MMe,tIr,aIr,DK,nIr,sIr,lIr,HE,iOe,Wc,UE,EMe,wx,iIr,CMe,dIr,dOe,pr,Ax,cIr,Qc,fIr,GK,mIr,gIr,OK,hIr,pIr,uIr,yx,_Ir,wMe,bIr,vIr,FIr,Wt,Lx,TIr,AMe,MIr,EIr,Hc,CIr,yMe,wIr,AIr,VK,yIr,LIr,xIr,JE,$Ir,Vr,xx,kIr,LMe,SIr,RIr,Tn,PIr,xMe,BIr,IIr,$Me,NIr,qIr,kMe,jIr,DIr,GIr,Ee,YE,SMe,OIr,VIr,XK,XIr,zIr,WIr,KE,RMe,QIr,HIr,zK,UIr,JIr,YIr,ZE,PMe,KIr,ZIr,WK,eNr,oNr,rNr,eC,BMe,tNr,aNr,QK,nNr,sNr,lNr,oC,IMe,iNr,dNr,HK,cNr,fNr,mNr,rC,NMe,gNr,hNr,UK,pNr,uNr,_Nr,tC,qMe,bNr,vNr,JK,FNr,TNr,MNr,aC,jMe,ENr,CNr,YK,wNr,ANr,yNr,nC,DMe,LNr,xNr,KK,$Nr,kNr,SNr,sC,GMe,RNr,PNr,ZK,BNr,INr,NNr,lC,OMe,qNr,jNr,eZ,DNr,GNr,ONr,iC,VMe,VNr,XNr,oZ,zNr,WNr,QNr,dC,cOe,Uc,cC,XMe,$x,HNr,zMe,UNr,fOe,ur,kx,JNr,Jc,YNr,rZ,KNr,ZNr,tZ,eqr,oqr,rqr,Sx,tqr,WMe,aqr,nqr,sqr,Qt,Rx,lqr,QMe,iqr,dqr,Yc,cqr,HMe,fqr,mqr,aZ,gqr,hqr,pqr,fC,uqr,Xr,Px,_qr,UMe,bqr,vqr,Mn,Fqr,JMe,Tqr,Mqr,YMe,Eqr,Cqr,KMe,wqr,Aqr,yqr,$e,mC,ZMe,Lqr,xqr,nZ,$qr,kqr,Sqr,gC,e4e,Rqr,Pqr,sZ,Bqr,Iqr,Nqr,hC,o4e,qqr,jqr,lZ,Dqr,Gqr,Oqr,pC,r4e,Vqr,Xqr,iZ,zqr,Wqr,Qqr,uC,t4e,Hqr,Uqr,dZ,Jqr,Yqr,Kqr,_C,a4e,Zqr,ejr,cZ,ojr,rjr,tjr,bC,n4e,ajr,njr,fZ,sjr,ljr,ijr,vC,s4e,djr,cjr,mZ,fjr,mjr,gjr,FC,l4e,hjr,pjr,gZ,ujr,_jr,bjr,TC,i4e,vjr,Fjr,hZ,Tjr,Mjr,Ejr,MC,mOe,Kc,EC,d4e,Bx,Cjr,c4e,wjr,gOe,_r,Ix,Ajr,Zc,yjr,pZ,Ljr,xjr,uZ,$jr,kjr,Sjr,Nx,Rjr,f4e,Pjr,Bjr,Ijr,Ht,qx,Njr,m4e,qjr,jjr,ef,Djr,g4e,Gjr,Ojr,_Z,Vjr,Xjr,zjr,CC,Wjr,zr,jx,Qjr,h4e,Hjr,Ujr,En,Jjr,p4e,Yjr,Kjr,u4e,Zjr,eDr,_4e,oDr,rDr,tDr,Pe,wC,b4e,aDr,nDr,bZ,sDr,lDr,iDr,AC,v4e,dDr,cDr,vZ,fDr,mDr,gDr,yC,F4e,hDr,pDr,FZ,uDr,_Dr,bDr,LC,T4e,vDr,FDr,TZ,TDr,MDr,EDr,xC,M4e,CDr,wDr,MZ,ADr,yDr,LDr,$C,E4e,xDr,$Dr,EZ,kDr,SDr,RDr,kC,C4e,PDr,BDr,CZ,IDr,NDr,qDr,SC,w4e,jDr,DDr,wZ,GDr,ODr,VDr,RC,A4e,XDr,zDr,AZ,WDr,QDr,HDr,PC,hOe,of,BC,y4e,Dx,UDr,L4e,JDr,pOe,br,Gx,YDr,rf,KDr,yZ,ZDr,eGr,LZ,oGr,rGr,tGr,Ox,aGr,x4e,nGr,sGr,lGr,Ut,Vx,iGr,$4e,dGr,cGr,tf,fGr,k4e,mGr,gGr,xZ,hGr,pGr,uGr,IC,_Gr,Wr,Xx,bGr,S4e,vGr,FGr,Cn,TGr,R4e,MGr,EGr,P4e,CGr,wGr,B4e,AGr,yGr,LGr,ke,NC,I4e,xGr,$Gr,$Z,kGr,SGr,RGr,qC,N4e,PGr,BGr,kZ,IGr,NGr,qGr,jC,q4e,jGr,DGr,SZ,GGr,OGr,VGr,DC,j4e,XGr,zGr,RZ,WGr,QGr,HGr,GC,D4e,UGr,JGr,PZ,YGr,KGr,ZGr,OC,G4e,eOr,oOr,BZ,rOr,tOr,aOr,VC,O4e,nOr,sOr,IZ,lOr,iOr,dOr,XC,V4e,cOr,fOr,NZ,mOr,gOr,hOr,zC,X4e,pOr,uOr,qZ,_Or,bOr,vOr,WC,z4e,FOr,TOr,jZ,MOr,EOr,COr,QC,uOe,af,HC,W4e,zx,wOr,Q4e,AOr,_Oe,vr,Wx,yOr,nf,LOr,DZ,xOr,$Or,GZ,kOr,SOr,ROr,Qx,POr,H4e,BOr,IOr,NOr,Jt,Hx,qOr,U4e,jOr,DOr,sf,GOr,J4e,OOr,VOr,OZ,XOr,zOr,WOr,UC,QOr,Qr,Ux,HOr,Y4e,UOr,JOr,wn,YOr,K4e,KOr,ZOr,Z4e,eVr,oVr,eEe,rVr,tVr,aVr,Se,JC,oEe,nVr,sVr,VZ,lVr,iVr,dVr,YC,rEe,cVr,fVr,XZ,mVr,gVr,hVr,KC,tEe,pVr,uVr,zZ,_Vr,bVr,vVr,ZC,aEe,FVr,TVr,WZ,MVr,EVr,CVr,e5,nEe,wVr,AVr,QZ,yVr,LVr,xVr,o5,sEe,$Vr,kVr,HZ,SVr,RVr,PVr,r5,lEe,BVr,IVr,UZ,NVr,qVr,jVr,t5,iEe,DVr,GVr,JZ,OVr,VVr,XVr,a5,dEe,zVr,WVr,YZ,QVr,HVr,UVr,n5,cEe,JVr,YVr,KZ,KVr,ZVr,eXr,s5,bOe,lf,l5,fEe,Jx,oXr,mEe,rXr,vOe,Fr,Yx,tXr,df,aXr,ZZ,nXr,sXr,eee,lXr,iXr,dXr,Kx,cXr,gEe,fXr,mXr,gXr,Yt,Zx,hXr,hEe,pXr,uXr,cf,_Xr,pEe,bXr,vXr,oee,FXr,TXr,MXr,i5,EXr,Hr,e$,CXr,uEe,wXr,AXr,An,yXr,_Ee,LXr,xXr,bEe,$Xr,kXr,vEe,SXr,RXr,PXr,Oe,d5,FEe,BXr,IXr,ree,NXr,qXr,jXr,c5,TEe,DXr,GXr,tee,OXr,VXr,XXr,f5,MEe,zXr,WXr,aee,QXr,HXr,UXr,m5,EEe,JXr,YXr,nee,KXr,ZXr,ezr,g5,CEe,ozr,rzr,see,tzr,azr,nzr,h5,wEe,szr,lzr,lee,izr,dzr,czr,p5,AEe,fzr,mzr,iee,gzr,hzr,pzr,u5,yEe,uzr,_zr,dee,bzr,vzr,Fzr,_5,FOe,ff,b5,LEe,o$,Tzr,xEe,Mzr,TOe,Tr,r$,Ezr,mf,Czr,cee,wzr,Azr,fee,yzr,Lzr,xzr,t$,$zr,$Ee,kzr,Szr,Rzr,Kt,a$,Pzr,kEe,Bzr,Izr,gf,Nzr,SEe,qzr,jzr,mee,Dzr,Gzr,Ozr,v5,Vzr,Ur,n$,Xzr,REe,zzr,Wzr,yn,Qzr,PEe,Hzr,Uzr,BEe,Jzr,Yzr,IEe,Kzr,Zzr,eWr,Ve,F5,NEe,oWr,rWr,gee,tWr,aWr,nWr,T5,qEe,sWr,lWr,hee,iWr,dWr,cWr,M5,jEe,fWr,mWr,pee,gWr,hWr,pWr,E5,DEe,uWr,_Wr,uee,bWr,vWr,FWr,C5,GEe,TWr,MWr,_ee,EWr,CWr,wWr,w5,OEe,AWr,yWr,bee,LWr,xWr,$Wr,A5,VEe,kWr,SWr,vee,RWr,PWr,BWr,y5,XEe,IWr,NWr,Fee,qWr,jWr,DWr,L5,MOe,hf,x5,zEe,s$,GWr,WEe,OWr,EOe,Mr,l$,VWr,pf,XWr,Tee,zWr,WWr,Mee,QWr,HWr,UWr,i$,JWr,QEe,YWr,KWr,ZWr,Zt,d$,eQr,HEe,oQr,rQr,uf,tQr,UEe,aQr,nQr,Eee,sQr,lQr,iQr,$5,dQr,Jr,c$,cQr,JEe,fQr,mQr,Ln,gQr,YEe,hQr,pQr,KEe,uQr,_Qr,ZEe,bQr,vQr,FQr,eCe,k5,oCe,TQr,MQr,Cee,EQr,CQr,wQr,S5,COe,_f,R5,rCe,f$,AQr,tCe,yQr,wOe,Er,m$,LQr,bf,xQr,wee,$Qr,kQr,Aee,SQr,RQr,PQr,g$,BQr,aCe,IQr,NQr,qQr,ea,h$,jQr,nCe,DQr,GQr,vf,OQr,sCe,VQr,XQr,yee,zQr,WQr,QQr,P5,HQr,Yr,p$,UQr,lCe,JQr,YQr,xn,KQr,iCe,ZQr,eHr,dCe,oHr,rHr,cCe,tHr,aHr,nHr,u$,B5,fCe,sHr,lHr,Lee,iHr,dHr,cHr,I5,mCe,fHr,mHr,xee,gHr,hHr,pHr,N5,AOe,Ff,q5,gCe,_$,uHr,hCe,_Hr,yOe,Cr,b$,bHr,Tf,vHr,$ee,FHr,THr,kee,MHr,EHr,CHr,v$,wHr,pCe,AHr,yHr,LHr,oa,F$,xHr,uCe,$Hr,kHr,Mf,SHr,_Ce,RHr,PHr,See,BHr,IHr,NHr,j5,qHr,Kr,T$,jHr,bCe,DHr,GHr,$n,OHr,vCe,VHr,XHr,FCe,zHr,WHr,TCe,QHr,HHr,UHr,MCe,D5,ECe,JHr,YHr,Ree,KHr,ZHr,eUr,G5,LOe;return d=new oe({}),La=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),mA=new oe({}),gA=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),kf=new oUr({props:{warning:!0,$$slots:{default:[zIt]},$$scope:{ctx:L}}}),hA=new oe({}),pA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/configuration_auto.py#L591"}}),bA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/configuration_auto.py#L614"}}),Ng=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[WIt]},$$scope:{ctx:L}}}),vA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/configuration_auto.py#L737"}}),FA=new oe({}),TA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/tokenization_auto.py#L392"}}),CA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17639/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/tokenization_auto.py#L406"}}),vh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[QIt]},$$scope:{ctx:L}}}),wA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/tokenization_auto.py#L605"}}),AA=new oe({}),yA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),$A=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17639/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),ep=new oUr({props:{$$slots:{default:[HIt]},$$scope:{ctx:L}}}),op=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[UIt]},$$scope:{ctx:L}}}),kA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),SA=new oe({}),RA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/processing_auto.py#L88"}}),IA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/processing_auto.py#L102"}}),Tp=new oUr({props:{$$slots:{default:[JIt]},$$scope:{ctx:L}}}),Mp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[YIt]},$$scope:{ctx:L}}}),NA=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/processing_auto.py#L255"}}),qA=new oe({}),jA=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L755"}}),GA=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),wp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[KIt]},$$scope:{ctx:L}}}),OA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),E_=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[ZIt]},$$scope:{ctx:L}}}),VA=new oe({}),XA=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L762"}}),WA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),w_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[eNt]},$$scope:{ctx:L}}}),QA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),u1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[oNt]},$$scope:{ctx:L}}}),HA=new oe({}),UA=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L777"}}),YA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),b1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[rNt]},$$scope:{ctx:L}}}),KA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),ab=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[tNt]},$$scope:{ctx:L}}}),ZA=new oe({}),ey=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L784"}}),ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),sb=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[aNt]},$$scope:{ctx:L}}}),ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),Xb=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[nNt]},$$scope:{ctx:L}}}),ay=new oe({}),ny=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L791"}}),ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),Wb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[sNt]},$$scope:{ctx:L}}}),iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),c2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[lNt]},$$scope:{ctx:L}}}),dy=new oe({}),cy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L800"}}),my=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),m2=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[iNt]},$$scope:{ctx:L}}}),gy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),iv=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[dNt]},$$scope:{ctx:L}}}),hy=new oe({}),py=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L845"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),cv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[cNt]},$$scope:{ctx:L}}}),by=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),Gv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[fNt]},$$scope:{ctx:L}}}),vy=new oe({}),Fy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L852"}}),My=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),Vv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[mNt]},$$scope:{ctx:L}}}),Ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),Jv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[gNt]},$$scope:{ctx:L}}}),Cy=new oe({}),wy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L838"}}),yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),Kv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[hNt]},$$scope:{ctx:L}}}),Ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),B3=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[pNt]},$$scope:{ctx:L}}}),xy=new oe({}),$y=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L809"}}),Sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),N3=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[uNt]},$$scope:{ctx:L}}}),Ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),wF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[_Nt]},$$scope:{ctx:L}}}),Py=new oe({}),By=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L816"}}),Ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),yF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[bNt]},$$scope:{ctx:L}}}),qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),$F=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[vNt]},$$scope:{ctx:L}}}),jy=new oe({}),Dy=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L861"}}),Oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),SF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[FNt]},$$scope:{ctx:L}}}),Vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),WF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[TNt]},$$scope:{ctx:L}}}),Xy=new oe({}),zy=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L900"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),HF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[MNt]},$$scope:{ctx:L}}}),Hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),YF=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[ENt]},$$scope:{ctx:L}}}),Uy=new oe({}),Jy=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L827"}}),Ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),ZF=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[CNt]},$$scope:{ctx:L}}}),Zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[wNt]},$$scope:{ctx:L}}}),eL=new oe({}),oL=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L907"}}),tL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[ANt]},$$scope:{ctx:L}}}),aL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),p6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[yNt]},$$scope:{ctx:L}}}),nL=new oe({}),sL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L930"}}),iL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),_6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[LNt]},$$scope:{ctx:L}}}),dL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),C6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[xNt]},$$scope:{ctx:L}}}),cL=new oe({}),fL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L914"}}),gL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),A6=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[$Nt]},$$scope:{ctx:L}}}),hL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),q6=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[kNt]},$$scope:{ctx:L}}}),pL=new oe({}),uL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L921"}}),bL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),D6=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[SNt]},$$scope:{ctx:L}}}),vL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),X6=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[RNt]},$$scope:{ctx:L}}}),TL=new oe({}),ML=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L939"}}),CL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),W6=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[PNt]},$$scope:{ctx:L}}}),wL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),Z6=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[BNt]},$$scope:{ctx:L}}}),AL=new oe({}),yL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L946"}}),xL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),oT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[INt]},$$scope:{ctx:L}}}),$L=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),sT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[NNt]},$$scope:{ctx:L}}}),kL=new oe({}),SL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L893"}}),PL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),iT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[qNt]},$$scope:{ctx:L}}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),mT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[jNt]},$$scope:{ctx:L}}}),NL=new oe({}),qL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L868"}}),DL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),hT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[DNt]},$$scope:{ctx:L}}}),GL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),_T=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[GNt]},$$scope:{ctx:L}}}),OL=new oe({}),VL=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L875"}}),zL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),vT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[ONt]},$$scope:{ctx:L}}}),WL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),wT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[VNt]},$$scope:{ctx:L}}}),QL=new oe({}),HL=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_auto.py#L884"}}),JL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),yT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[XNt]},$$scope:{ctx:L}}}),YL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),$T=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[zNt]},$$scope:{ctx:L}}}),KL=new oe({}),ZL=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),o8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),ST=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[WNt]},$$scope:{ctx:L}}}),r8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),w7=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[QNt]},$$scope:{ctx:L}}}),t8=new oe({}),a8=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),s8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),y7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[HNt]},$$scope:{ctx:L}}}),l8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),Y7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[UNt]},$$scope:{ctx:L}}}),i8=new oe({}),d8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),f8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),Z7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[JNt]},$$scope:{ctx:L}}}),m8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),g9=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[YNt]},$$scope:{ctx:L}}}),g8=new oe({}),h8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),u8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),p9=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[KNt]},$$scope:{ctx:L}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),F9=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[ZNt]},$$scope:{ctx:L}}}),b8=new oe({}),v8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),T8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),M9=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[eqt]},$$scope:{ctx:L}}}),M8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),V9=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[oqt]},$$scope:{ctx:L}}}),E8=new oe({}),C8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),A8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),z9=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[rqt]},$$scope:{ctx:L}}}),y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),rM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[tqt]},$$scope:{ctx:L}}}),L8=new oe({}),x8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),k8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),aM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[aqt]},$$scope:{ctx:L}}}),S8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),kM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[nqt]},$$scope:{ctx:L}}}),R8=new oe({}),P8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),I8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),RM=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[sqt]},$$scope:{ctx:L}}}),N8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),YM=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[lqt]},$$scope:{ctx:L}}}),q8=new oe({}),j8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),G8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),ZM=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[iqt]},$$scope:{ctx:L}}}),O8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),r4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[dqt]},$$scope:{ctx:L}}}),X8=new oe({}),z8=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),Q8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),a4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[cqt]},$$scope:{ctx:L}}}),H8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),s4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[fqt]},$$scope:{ctx:L}}}),U8=new oe({}),J8=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),K8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),i4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[mqt]},$$scope:{ctx:L}}}),Z8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),x4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[gqt]},$$scope:{ctx:L}}}),ex=new oe({}),ox=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),tx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),k4=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[hqt]},$$scope:{ctx:L}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),K4=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[pqt]},$$scope:{ctx:L}}}),nx=new oe({}),sx=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),ix=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),eE=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[uqt]},$$scope:{ctx:L}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),rE=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[_qt]},$$scope:{ctx:L}}}),cx=new oe({}),fx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),gx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),aE=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[bqt]},$$scope:{ctx:L}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),sE=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[vqt]},$$scope:{ctx:L}}}),px=new oe({}),ux=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L243"}}),bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),iE=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Fqt]},$$scope:{ctx:L}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),BE=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Tqt]},$$scope:{ctx:L}}}),Fx=new oe({}),Tx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L257"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),NE=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Mqt]},$$scope:{ctx:L}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),HE=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Eqt]},$$scope:{ctx:L}}}),wx=new oe({}),Ax=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L250"}}),Lx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),JE=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Cqt]},$$scope:{ctx:L}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),dC=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[wqt]},$$scope:{ctx:L}}}),$x=new oe({}),kx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Aqt]},$$scope:{ctx:L}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),MC=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[yqt]},$$scope:{ctx:L}}}),Bx=new oe({}),Ix=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L271"}}),qx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),CC=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Lqt]},$$scope:{ctx:L}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[xqt]},$$scope:{ctx:L}}}),Dx=new oe({}),Gx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L280"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),IC=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[$qt]},$$scope:{ctx:L}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),QC=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[kqt]},$$scope:{ctx:L}}}),zx=new oe({}),Wx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L289"}}),Hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),UC=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Sqt]},$$scope:{ctx:L}}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Rqt]},$$scope:{ctx:L}}}),Jx=new oe({}),Yx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L296"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Pqt]},$$scope:{ctx:L}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),_5=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Bqt]},$$scope:{ctx:L}}}),o$=new oe({}),r$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L305"}}),a$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),v5=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Iqt]},$$scope:{ctx:L}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),L5=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Nqt]},$$scope:{ctx:L}}}),s$=new oe({}),l$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L312"}}),d$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),$5=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[qqt]},$$scope:{ctx:L}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),S5=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[jqt]},$$scope:{ctx:L}}}),f$=new oe({}),m$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L321"}}),h$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),P5=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Dqt]},$$scope:{ctx:L}}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),N5=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Gqt]},$$scope:{ctx:L}}}),_$=new oe({}),b$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/modeling_flax_auto.py#L330"}}),F$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L389"}}),j5=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Oqt]},$$scope:{ctx:L}}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17639/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17639/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17639/src/transformers/models/auto/auto_factory.py#L417"}}),G5=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Vqt]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),vi=o("Auto Classes"),Af=l(),at=a("p"),Fi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ti=a("code"),iA=o("from_pretrained()"),yf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Ge=l(),We=a("p"),Mi=o("Instantiating one of "),Sn=a("a"),dA=o("AutoConfig"),Rn=o(", "),Pn=a("a"),cA=o("AutoModel"),Ei=o(`, and
`),Bn=a("a"),fA=o("AutoTokenizer"),Ci=o(" will directly create a class of the relevant architecture. For instance"),Lf=l(),F(La.$$.fragment),Qe=l(),Ae=a("p"),Nk=o("will create a model that is an instance of "),wi=a("a"),qk=o("BertModel"),jk=o("."),Co=l(),xa=a("p"),Dk=o("There is one class of "),xf=a("code"),Gk=o("AutoModel"),qXe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),EDe=l(),Ai=a("h2"),$f=a("a"),Lre=a("span"),F(mA.$$.fragment),jXe=l(),xre=a("span"),DXe=o("Extending the Auto Classes"),CDe=l(),In=a("p"),GXe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),$re=a("code"),OXe=o("NewModel"),VXe=o(", make sure you have a "),kre=a("code"),XXe=o("NewModelConfig"),zXe=o(` then you can add those to the auto
classes like this:`),wDe=l(),F(gA.$$.fragment),ADe=l(),Ok=a("p"),WXe=o("You will then be able to use the auto classes like you would usually do!"),yDe=l(),F(kf.$$.fragment),LDe=l(),yi=a("h2"),Sf=a("a"),Sre=a("span"),F(hA.$$.fragment),QXe=l(),Rre=a("span"),HXe=o("AutoConfig"),xDe=l(),wo=a("div"),F(pA.$$.fragment),UXe=l(),uA=a("p"),JXe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Vk=a("a"),YXe=o("from_pretrained()"),KXe=o(" class method."),ZXe=l(),_A=a("p"),eze=o("This class cannot be instantiated directly using "),Pre=a("code"),oze=o("__init__()"),rze=o(" (throws an error)."),tze=l(),wr=a("div"),F(bA.$$.fragment),aze=l(),Bre=a("p"),nze=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),sze=l(),Li=a("p"),lze=o("The configuration class to instantiate is selected based on the "),Ire=a("code"),ize=o("model_type"),dze=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Nre=a("code"),cze=o("pretrained_model_name_or_path"),fze=o(":"),mze=l(),A=a("ul"),Rf=a("li"),qre=a("strong"),gze=o("albert"),hze=o(" \u2014 "),Xk=a("a"),pze=o("AlbertConfig"),uze=o(" (ALBERT model)"),_ze=l(),Pf=a("li"),jre=a("strong"),bze=o("bart"),vze=o(" \u2014 "),zk=a("a"),Fze=o("BartConfig"),Tze=o(" (BART model)"),Mze=l(),Bf=a("li"),Dre=a("strong"),Eze=o("beit"),Cze=o(" \u2014 "),Wk=a("a"),wze=o("BeitConfig"),Aze=o(" (BEiT model)"),yze=l(),If=a("li"),Gre=a("strong"),Lze=o("bert"),xze=o(" \u2014 "),Qk=a("a"),$ze=o("BertConfig"),kze=o(" (BERT model)"),Sze=l(),Nf=a("li"),Ore=a("strong"),Rze=o("bert-generation"),Pze=o(" \u2014 "),Hk=a("a"),Bze=o("BertGenerationConfig"),Ize=o(" (Bert Generation model)"),Nze=l(),qf=a("li"),Vre=a("strong"),qze=o("big_bird"),jze=o(" \u2014 "),Uk=a("a"),Dze=o("BigBirdConfig"),Gze=o(" (BigBird model)"),Oze=l(),jf=a("li"),Xre=a("strong"),Vze=o("bigbird_pegasus"),Xze=o(" \u2014 "),Jk=a("a"),zze=o("BigBirdPegasusConfig"),Wze=o(" (BigBird-Pegasus model)"),Qze=l(),Df=a("li"),zre=a("strong"),Hze=o("blenderbot"),Uze=o(" \u2014 "),Yk=a("a"),Jze=o("BlenderbotConfig"),Yze=o(" (Blenderbot model)"),Kze=l(),Gf=a("li"),Wre=a("strong"),Zze=o("blenderbot-small"),eWe=o(" \u2014 "),Kk=a("a"),oWe=o("BlenderbotSmallConfig"),rWe=o(" (BlenderbotSmall model)"),tWe=l(),Of=a("li"),Qre=a("strong"),aWe=o("bloom"),nWe=o(" \u2014 "),Zk=a("a"),sWe=o("BloomConfig"),lWe=o(" (BLOOM model)"),iWe=l(),Vf=a("li"),Hre=a("strong"),dWe=o("camembert"),cWe=o(" \u2014 "),eS=a("a"),fWe=o("CamembertConfig"),mWe=o(" (CamemBERT model)"),gWe=l(),Xf=a("li"),Ure=a("strong"),hWe=o("canine"),pWe=o(" \u2014 "),oS=a("a"),uWe=o("CanineConfig"),_We=o(" (CANINE model)"),bWe=l(),zf=a("li"),Jre=a("strong"),vWe=o("clip"),FWe=o(" \u2014 "),rS=a("a"),TWe=o("CLIPConfig"),MWe=o(" (CLIP model)"),EWe=l(),Wf=a("li"),Yre=a("strong"),CWe=o("convbert"),wWe=o(" \u2014 "),tS=a("a"),AWe=o("ConvBertConfig"),yWe=o(" (ConvBERT model)"),LWe=l(),Qf=a("li"),Kre=a("strong"),xWe=o("convnext"),$We=o(" \u2014 "),aS=a("a"),kWe=o("ConvNextConfig"),SWe=o(" (ConvNeXT model)"),RWe=l(),Hf=a("li"),Zre=a("strong"),PWe=o("ctrl"),BWe=o(" \u2014 "),nS=a("a"),IWe=o("CTRLConfig"),NWe=o(" (CTRL model)"),qWe=l(),Uf=a("li"),ete=a("strong"),jWe=o("cvt"),DWe=o(" \u2014 "),sS=a("a"),GWe=o("CvtConfig"),OWe=o(" (CvT model)"),VWe=l(),Jf=a("li"),ote=a("strong"),XWe=o("data2vec-audio"),zWe=o(" \u2014 "),lS=a("a"),WWe=o("Data2VecAudioConfig"),QWe=o(" (Data2VecAudio model)"),HWe=l(),Yf=a("li"),rte=a("strong"),UWe=o("data2vec-text"),JWe=o(" \u2014 "),iS=a("a"),YWe=o("Data2VecTextConfig"),KWe=o(" (Data2VecText model)"),ZWe=l(),Kf=a("li"),tte=a("strong"),eQe=o("data2vec-vision"),oQe=o(" \u2014 "),dS=a("a"),rQe=o("Data2VecVisionConfig"),tQe=o(" (Data2VecVision model)"),aQe=l(),Zf=a("li"),ate=a("strong"),nQe=o("deberta"),sQe=o(" \u2014 "),cS=a("a"),lQe=o("DebertaConfig"),iQe=o(" (DeBERTa model)"),dQe=l(),em=a("li"),nte=a("strong"),cQe=o("deberta-v2"),fQe=o(" \u2014 "),fS=a("a"),mQe=o("DebertaV2Config"),gQe=o(" (DeBERTa-v2 model)"),hQe=l(),om=a("li"),ste=a("strong"),pQe=o("decision_transformer"),uQe=o(" \u2014 "),mS=a("a"),_Qe=o("DecisionTransformerConfig"),bQe=o(" (Decision Transformer model)"),vQe=l(),rm=a("li"),lte=a("strong"),FQe=o("deit"),TQe=o(" \u2014 "),gS=a("a"),MQe=o("DeiTConfig"),EQe=o(" (DeiT model)"),CQe=l(),tm=a("li"),ite=a("strong"),wQe=o("detr"),AQe=o(" \u2014 "),hS=a("a"),yQe=o("DetrConfig"),LQe=o(" (DETR model)"),xQe=l(),am=a("li"),dte=a("strong"),$Qe=o("distilbert"),kQe=o(" \u2014 "),pS=a("a"),SQe=o("DistilBertConfig"),RQe=o(" (DistilBERT model)"),PQe=l(),nm=a("li"),cte=a("strong"),BQe=o("dpr"),IQe=o(" \u2014 "),uS=a("a"),NQe=o("DPRConfig"),qQe=o(" (DPR model)"),jQe=l(),sm=a("li"),fte=a("strong"),DQe=o("dpt"),GQe=o(" \u2014 "),_S=a("a"),OQe=o("DPTConfig"),VQe=o(" (DPT model)"),XQe=l(),lm=a("li"),mte=a("strong"),zQe=o("electra"),WQe=o(" \u2014 "),bS=a("a"),QQe=o("ElectraConfig"),HQe=o(" (ELECTRA model)"),UQe=l(),im=a("li"),gte=a("strong"),JQe=o("encoder-decoder"),YQe=o(" \u2014 "),vS=a("a"),KQe=o("EncoderDecoderConfig"),ZQe=o(" (Encoder decoder model)"),eHe=l(),dm=a("li"),hte=a("strong"),oHe=o("flaubert"),rHe=o(" \u2014 "),FS=a("a"),tHe=o("FlaubertConfig"),aHe=o(" (FlauBERT model)"),nHe=l(),cm=a("li"),pte=a("strong"),sHe=o("flava"),lHe=o(" \u2014 "),TS=a("a"),iHe=o("FlavaConfig"),dHe=o(" (FLAVA model)"),cHe=l(),fm=a("li"),ute=a("strong"),fHe=o("fnet"),mHe=o(" \u2014 "),MS=a("a"),gHe=o("FNetConfig"),hHe=o(" (FNet model)"),pHe=l(),mm=a("li"),_te=a("strong"),uHe=o("fsmt"),_He=o(" \u2014 "),ES=a("a"),bHe=o("FSMTConfig"),vHe=o(" (FairSeq Machine-Translation model)"),FHe=l(),gm=a("li"),bte=a("strong"),THe=o("funnel"),MHe=o(" \u2014 "),CS=a("a"),EHe=o("FunnelConfig"),CHe=o(" (Funnel Transformer model)"),wHe=l(),hm=a("li"),vte=a("strong"),AHe=o("glpn"),yHe=o(" \u2014 "),wS=a("a"),LHe=o("GLPNConfig"),xHe=o(" (GLPN model)"),$He=l(),pm=a("li"),Fte=a("strong"),kHe=o("gpt2"),SHe=o(" \u2014 "),AS=a("a"),RHe=o("GPT2Config"),PHe=o(" (OpenAI GPT-2 model)"),BHe=l(),um=a("li"),Tte=a("strong"),IHe=o("gpt_neo"),NHe=o(" \u2014 "),yS=a("a"),qHe=o("GPTNeoConfig"),jHe=o(" (GPT Neo model)"),DHe=l(),_m=a("li"),Mte=a("strong"),GHe=o("gpt_neox"),OHe=o(" \u2014 "),LS=a("a"),VHe=o("GPTNeoXConfig"),XHe=o(" (GPT NeoX model)"),zHe=l(),bm=a("li"),Ete=a("strong"),WHe=o("gptj"),QHe=o(" \u2014 "),xS=a("a"),HHe=o("GPTJConfig"),UHe=o(" (GPT-J model)"),JHe=l(),vm=a("li"),Cte=a("strong"),YHe=o("hubert"),KHe=o(" \u2014 "),$S=a("a"),ZHe=o("HubertConfig"),eUe=o(" (Hubert model)"),oUe=l(),Fm=a("li"),wte=a("strong"),rUe=o("ibert"),tUe=o(" \u2014 "),kS=a("a"),aUe=o("IBertConfig"),nUe=o(" (I-BERT model)"),sUe=l(),Tm=a("li"),Ate=a("strong"),lUe=o("imagegpt"),iUe=o(" \u2014 "),SS=a("a"),dUe=o("ImageGPTConfig"),cUe=o(" (ImageGPT model)"),fUe=l(),Mm=a("li"),yte=a("strong"),mUe=o("layoutlm"),gUe=o(" \u2014 "),RS=a("a"),hUe=o("LayoutLMConfig"),pUe=o(" (LayoutLM model)"),uUe=l(),Em=a("li"),Lte=a("strong"),_Ue=o("layoutlmv2"),bUe=o(" \u2014 "),PS=a("a"),vUe=o("LayoutLMv2Config"),FUe=o(" (LayoutLMv2 model)"),TUe=l(),Cm=a("li"),xte=a("strong"),MUe=o("layoutlmv3"),EUe=o(" \u2014 "),BS=a("a"),CUe=o("LayoutLMv3Config"),wUe=o(" (LayoutLMv3 model)"),AUe=l(),wm=a("li"),$te=a("strong"),yUe=o("led"),LUe=o(" \u2014 "),IS=a("a"),xUe=o("LEDConfig"),$Ue=o(" (LED model)"),kUe=l(),Am=a("li"),kte=a("strong"),SUe=o("levit"),RUe=o(" \u2014 "),NS=a("a"),PUe=o("LevitConfig"),BUe=o(" (LeViT model)"),IUe=l(),ym=a("li"),Ste=a("strong"),NUe=o("longformer"),qUe=o(" \u2014 "),qS=a("a"),jUe=o("LongformerConfig"),DUe=o(" (Longformer model)"),GUe=l(),Lm=a("li"),Rte=a("strong"),OUe=o("luke"),VUe=o(" \u2014 "),jS=a("a"),XUe=o("LukeConfig"),zUe=o(" (LUKE model)"),WUe=l(),xm=a("li"),Pte=a("strong"),QUe=o("lxmert"),HUe=o(" \u2014 "),DS=a("a"),UUe=o("LxmertConfig"),JUe=o(" (LXMERT model)"),YUe=l(),$m=a("li"),Bte=a("strong"),KUe=o("m2m_100"),ZUe=o(" \u2014 "),GS=a("a"),eJe=o("M2M100Config"),oJe=o(" (M2M100 model)"),rJe=l(),km=a("li"),Ite=a("strong"),tJe=o("marian"),aJe=o(" \u2014 "),OS=a("a"),nJe=o("MarianConfig"),sJe=o(" (Marian model)"),lJe=l(),Sm=a("li"),Nte=a("strong"),iJe=o("maskformer"),dJe=o(" \u2014 "),VS=a("a"),cJe=o("MaskFormerConfig"),fJe=o(" (MaskFormer model)"),mJe=l(),Rm=a("li"),qte=a("strong"),gJe=o("mbart"),hJe=o(" \u2014 "),XS=a("a"),pJe=o("MBartConfig"),uJe=o(" (mBART model)"),_Je=l(),Pm=a("li"),jte=a("strong"),bJe=o("mctct"),vJe=o(" \u2014 "),zS=a("a"),FJe=o("MCTCTConfig"),TJe=o(" (M-CTC-T model)"),MJe=l(),Bm=a("li"),Dte=a("strong"),EJe=o("megatron-bert"),CJe=o(" \u2014 "),WS=a("a"),wJe=o("MegatronBertConfig"),AJe=o(" (Megatron-BERT model)"),yJe=l(),Im=a("li"),Gte=a("strong"),LJe=o("mobilebert"),xJe=o(" \u2014 "),QS=a("a"),$Je=o("MobileBertConfig"),kJe=o(" (MobileBERT model)"),SJe=l(),Nm=a("li"),Ote=a("strong"),RJe=o("mpnet"),PJe=o(" \u2014 "),HS=a("a"),BJe=o("MPNetConfig"),IJe=o(" (MPNet model)"),NJe=l(),qm=a("li"),Vte=a("strong"),qJe=o("mt5"),jJe=o(" \u2014 "),US=a("a"),DJe=o("MT5Config"),GJe=o(" (MT5 model)"),OJe=l(),jm=a("li"),Xte=a("strong"),VJe=o("nystromformer"),XJe=o(" \u2014 "),JS=a("a"),zJe=o("NystromformerConfig"),WJe=o(" (Nystr\xF6mformer model)"),QJe=l(),Dm=a("li"),zte=a("strong"),HJe=o("openai-gpt"),UJe=o(" \u2014 "),YS=a("a"),JJe=o("OpenAIGPTConfig"),YJe=o(" (OpenAI GPT model)"),KJe=l(),Gm=a("li"),Wte=a("strong"),ZJe=o("opt"),eYe=o(" \u2014 "),KS=a("a"),oYe=o("OPTConfig"),rYe=o(" (OPT model)"),tYe=l(),Om=a("li"),Qte=a("strong"),aYe=o("pegasus"),nYe=o(" \u2014 "),ZS=a("a"),sYe=o("PegasusConfig"),lYe=o(" (Pegasus model)"),iYe=l(),Vm=a("li"),Hte=a("strong"),dYe=o("perceiver"),cYe=o(" \u2014 "),eR=a("a"),fYe=o("PerceiverConfig"),mYe=o(" (Perceiver model)"),gYe=l(),Xm=a("li"),Ute=a("strong"),hYe=o("plbart"),pYe=o(" \u2014 "),oR=a("a"),uYe=o("PLBartConfig"),_Ye=o(" (PLBart model)"),bYe=l(),zm=a("li"),Jte=a("strong"),vYe=o("poolformer"),FYe=o(" \u2014 "),rR=a("a"),TYe=o("PoolFormerConfig"),MYe=o(" (PoolFormer model)"),EYe=l(),Wm=a("li"),Yte=a("strong"),CYe=o("prophetnet"),wYe=o(" \u2014 "),tR=a("a"),AYe=o("ProphetNetConfig"),yYe=o(" (ProphetNet model)"),LYe=l(),Qm=a("li"),Kte=a("strong"),xYe=o("qdqbert"),$Ye=o(" \u2014 "),aR=a("a"),kYe=o("QDQBertConfig"),SYe=o(" (QDQBert model)"),RYe=l(),Hm=a("li"),Zte=a("strong"),PYe=o("rag"),BYe=o(" \u2014 "),nR=a("a"),IYe=o("RagConfig"),NYe=o(" (RAG model)"),qYe=l(),Um=a("li"),eae=a("strong"),jYe=o("realm"),DYe=o(" \u2014 "),sR=a("a"),GYe=o("RealmConfig"),OYe=o(" (REALM model)"),VYe=l(),Jm=a("li"),oae=a("strong"),XYe=o("reformer"),zYe=o(" \u2014 "),lR=a("a"),WYe=o("ReformerConfig"),QYe=o(" (Reformer model)"),HYe=l(),Ym=a("li"),rae=a("strong"),UYe=o("regnet"),JYe=o(" \u2014 "),iR=a("a"),YYe=o("RegNetConfig"),KYe=o(" (RegNet model)"),ZYe=l(),Km=a("li"),tae=a("strong"),eKe=o("rembert"),oKe=o(" \u2014 "),dR=a("a"),rKe=o("RemBertConfig"),tKe=o(" (RemBERT model)"),aKe=l(),Zm=a("li"),aae=a("strong"),nKe=o("resnet"),sKe=o(" \u2014 "),cR=a("a"),lKe=o("ResNetConfig"),iKe=o(" (ResNet model)"),dKe=l(),eg=a("li"),nae=a("strong"),cKe=o("retribert"),fKe=o(" \u2014 "),fR=a("a"),mKe=o("RetriBertConfig"),gKe=o(" (RetriBERT model)"),hKe=l(),og=a("li"),sae=a("strong"),pKe=o("roberta"),uKe=o(" \u2014 "),mR=a("a"),_Ke=o("RobertaConfig"),bKe=o(" (RoBERTa model)"),vKe=l(),rg=a("li"),lae=a("strong"),FKe=o("roformer"),TKe=o(" \u2014 "),gR=a("a"),MKe=o("RoFormerConfig"),EKe=o(" (RoFormer model)"),CKe=l(),tg=a("li"),iae=a("strong"),wKe=o("segformer"),AKe=o(" \u2014 "),hR=a("a"),yKe=o("SegformerConfig"),LKe=o(" (SegFormer model)"),xKe=l(),ag=a("li"),dae=a("strong"),$Ke=o("sew"),kKe=o(" \u2014 "),pR=a("a"),SKe=o("SEWConfig"),RKe=o(" (SEW model)"),PKe=l(),ng=a("li"),cae=a("strong"),BKe=o("sew-d"),IKe=o(" \u2014 "),uR=a("a"),NKe=o("SEWDConfig"),qKe=o(" (SEW-D model)"),jKe=l(),sg=a("li"),fae=a("strong"),DKe=o("speech-encoder-decoder"),GKe=o(" \u2014 "),_R=a("a"),OKe=o("SpeechEncoderDecoderConfig"),VKe=o(" (Speech Encoder decoder model)"),XKe=l(),lg=a("li"),mae=a("strong"),zKe=o("speech_to_text"),WKe=o(" \u2014 "),bR=a("a"),QKe=o("Speech2TextConfig"),HKe=o(" (Speech2Text model)"),UKe=l(),ig=a("li"),gae=a("strong"),JKe=o("speech_to_text_2"),YKe=o(" \u2014 "),vR=a("a"),KKe=o("Speech2Text2Config"),ZKe=o(" (Speech2Text2 model)"),eZe=l(),dg=a("li"),hae=a("strong"),oZe=o("splinter"),rZe=o(" \u2014 "),FR=a("a"),tZe=o("SplinterConfig"),aZe=o(" (Splinter model)"),nZe=l(),cg=a("li"),pae=a("strong"),sZe=o("squeezebert"),lZe=o(" \u2014 "),TR=a("a"),iZe=o("SqueezeBertConfig"),dZe=o(" (SqueezeBERT model)"),cZe=l(),fg=a("li"),uae=a("strong"),fZe=o("swin"),mZe=o(" \u2014 "),MR=a("a"),gZe=o("SwinConfig"),hZe=o(" (Swin Transformer model)"),pZe=l(),mg=a("li"),_ae=a("strong"),uZe=o("t5"),_Ze=o(" \u2014 "),ER=a("a"),bZe=o("T5Config"),vZe=o(" (T5 model)"),FZe=l(),gg=a("li"),bae=a("strong"),TZe=o("tapas"),MZe=o(" \u2014 "),CR=a("a"),EZe=o("TapasConfig"),CZe=o(" (TAPAS model)"),wZe=l(),hg=a("li"),vae=a("strong"),AZe=o("trajectory_transformer"),yZe=o(" \u2014 "),wR=a("a"),LZe=o("TrajectoryTransformerConfig"),xZe=o(" (Trajectory Transformer model)"),$Ze=l(),pg=a("li"),Fae=a("strong"),kZe=o("transfo-xl"),SZe=o(" \u2014 "),AR=a("a"),RZe=o("TransfoXLConfig"),PZe=o(" (Transformer-XL model)"),BZe=l(),ug=a("li"),Tae=a("strong"),IZe=o("trocr"),NZe=o(" \u2014 "),yR=a("a"),qZe=o("TrOCRConfig"),jZe=o(" (TrOCR model)"),DZe=l(),_g=a("li"),Mae=a("strong"),GZe=o("unispeech"),OZe=o(" \u2014 "),LR=a("a"),VZe=o("UniSpeechConfig"),XZe=o(" (UniSpeech model)"),zZe=l(),bg=a("li"),Eae=a("strong"),WZe=o("unispeech-sat"),QZe=o(" \u2014 "),xR=a("a"),HZe=o("UniSpeechSatConfig"),UZe=o(" (UniSpeechSat model)"),JZe=l(),vg=a("li"),Cae=a("strong"),YZe=o("van"),KZe=o(" \u2014 "),$R=a("a"),ZZe=o("VanConfig"),eeo=o(" (VAN model)"),oeo=l(),Fg=a("li"),wae=a("strong"),reo=o("vilt"),teo=o(" \u2014 "),kR=a("a"),aeo=o("ViltConfig"),neo=o(" (ViLT model)"),seo=l(),Tg=a("li"),Aae=a("strong"),leo=o("vision-encoder-decoder"),ieo=o(" \u2014 "),SR=a("a"),deo=o("VisionEncoderDecoderConfig"),ceo=o(" (Vision Encoder decoder model)"),feo=l(),Mg=a("li"),yae=a("strong"),meo=o("vision-text-dual-encoder"),geo=o(" \u2014 "),RR=a("a"),heo=o("VisionTextDualEncoderConfig"),peo=o(" (VisionTextDualEncoder model)"),ueo=l(),Eg=a("li"),Lae=a("strong"),_eo=o("visual_bert"),beo=o(" \u2014 "),PR=a("a"),veo=o("VisualBertConfig"),Feo=o(" (VisualBERT model)"),Teo=l(),Cg=a("li"),xae=a("strong"),Meo=o("vit"),Eeo=o(" \u2014 "),BR=a("a"),Ceo=o("ViTConfig"),weo=o(" (ViT model)"),Aeo=l(),wg=a("li"),$ae=a("strong"),yeo=o("vit_mae"),Leo=o(" \u2014 "),IR=a("a"),xeo=o("ViTMAEConfig"),$eo=o(" (ViTMAE model)"),keo=l(),Ag=a("li"),kae=a("strong"),Seo=o("wav2vec2"),Reo=o(" \u2014 "),NR=a("a"),Peo=o("Wav2Vec2Config"),Beo=o(" (Wav2Vec2 model)"),Ieo=l(),yg=a("li"),Sae=a("strong"),Neo=o("wav2vec2-conformer"),qeo=o(" \u2014 "),qR=a("a"),jeo=o("Wav2Vec2ConformerConfig"),Deo=o(" (Wav2Vec2-Conformer model)"),Geo=l(),Lg=a("li"),Rae=a("strong"),Oeo=o("wavlm"),Veo=o(" \u2014 "),jR=a("a"),Xeo=o("WavLMConfig"),zeo=o(" (WavLM model)"),Weo=l(),xg=a("li"),Pae=a("strong"),Qeo=o("xglm"),Heo=o(" \u2014 "),DR=a("a"),Ueo=o("XGLMConfig"),Jeo=o(" (XGLM model)"),Yeo=l(),$g=a("li"),Bae=a("strong"),Keo=o("xlm"),Zeo=o(" \u2014 "),GR=a("a"),eoo=o("XLMConfig"),ooo=o(" (XLM model)"),roo=l(),kg=a("li"),Iae=a("strong"),too=o("xlm-prophetnet"),aoo=o(" \u2014 "),OR=a("a"),noo=o("XLMProphetNetConfig"),soo=o(" (XLM-ProphetNet model)"),loo=l(),Sg=a("li"),Nae=a("strong"),ioo=o("xlm-roberta"),doo=o(" \u2014 "),VR=a("a"),coo=o("XLMRobertaConfig"),foo=o(" (XLM-RoBERTa model)"),moo=l(),Rg=a("li"),qae=a("strong"),goo=o("xlm-roberta-xl"),hoo=o(" \u2014 "),XR=a("a"),poo=o("XLMRobertaXLConfig"),uoo=o(" (XLM-RoBERTa-XL model)"),_oo=l(),Pg=a("li"),jae=a("strong"),boo=o("xlnet"),voo=o(" \u2014 "),zR=a("a"),Foo=o("XLNetConfig"),Too=o(" (XLNet model)"),Moo=l(),Bg=a("li"),Dae=a("strong"),Eoo=o("yolos"),Coo=o(" \u2014 "),WR=a("a"),woo=o("YolosConfig"),Aoo=o(" (YOLOS model)"),yoo=l(),Ig=a("li"),Gae=a("strong"),Loo=o("yoso"),xoo=o(" \u2014 "),QR=a("a"),$oo=o("YosoConfig"),koo=o(" (YOSO model)"),Soo=l(),F(Ng.$$.fragment),Roo=l(),qg=a("div"),F(vA.$$.fragment),Poo=l(),Oae=a("p"),Boo=o("Register a new configuration for this class."),$De=l(),xi=a("h2"),jg=a("a"),Vae=a("span"),F(FA.$$.fragment),Ioo=l(),Xae=a("span"),Noo=o("AutoTokenizer"),kDe=l(),Ao=a("div"),F(TA.$$.fragment),qoo=l(),MA=a("p"),joo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),HR=a("a"),Doo=o("AutoTokenizer.from_pretrained()"),Goo=o(" class method."),Ooo=l(),EA=a("p"),Voo=o("This class cannot be instantiated directly using "),zae=a("code"),Xoo=o("__init__()"),zoo=o(" (throws an error)."),Woo=l(),Ar=a("div"),F(CA.$$.fragment),Qoo=l(),Wae=a("p"),Hoo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Uoo=l(),$a=a("p"),Joo=o("The tokenizer class to instantiate is selected based on the "),Qae=a("code"),Yoo=o("model_type"),Koo=o(` property of the config object (either
passed as an argument or loaded from `),Hae=a("code"),Zoo=o("pretrained_model_name_or_path"),ero=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uae=a("code"),oro=o("pretrained_model_name_or_path"),rro=o(":"),tro=l(),k=a("ul"),Nn=a("li"),Jae=a("strong"),aro=o("albert"),nro=o(" \u2014 "),UR=a("a"),sro=o("AlbertTokenizer"),lro=o(" or "),JR=a("a"),iro=o("AlbertTokenizerFast"),dro=o(" (ALBERT model)"),cro=l(),qn=a("li"),Yae=a("strong"),fro=o("bart"),mro=o(" \u2014 "),YR=a("a"),gro=o("BartTokenizer"),hro=o(" or "),KR=a("a"),pro=o("BartTokenizerFast"),uro=o(" (BART model)"),_ro=l(),jn=a("li"),Kae=a("strong"),bro=o("barthez"),vro=o(" \u2014 "),ZR=a("a"),Fro=o("BarthezTokenizer"),Tro=o(" or "),eP=a("a"),Mro=o("BarthezTokenizerFast"),Ero=o(" (BARThez model)"),Cro=l(),Dg=a("li"),Zae=a("strong"),wro=o("bartpho"),Aro=o(" \u2014 "),oP=a("a"),yro=o("BartphoTokenizer"),Lro=o(" (BARTpho model)"),xro=l(),Dn=a("li"),ene=a("strong"),$ro=o("bert"),kro=o(" \u2014 "),rP=a("a"),Sro=o("BertTokenizer"),Rro=o(" or "),tP=a("a"),Pro=o("BertTokenizerFast"),Bro=o(" (BERT model)"),Iro=l(),Gg=a("li"),one=a("strong"),Nro=o("bert-generation"),qro=o(" \u2014 "),aP=a("a"),jro=o("BertGenerationTokenizer"),Dro=o(" (Bert Generation model)"),Gro=l(),Og=a("li"),rne=a("strong"),Oro=o("bert-japanese"),Vro=o(" \u2014 "),nP=a("a"),Xro=o("BertJapaneseTokenizer"),zro=o(" (BertJapanese model)"),Wro=l(),Vg=a("li"),tne=a("strong"),Qro=o("bertweet"),Hro=o(" \u2014 "),sP=a("a"),Uro=o("BertweetTokenizer"),Jro=o(" (BERTweet model)"),Yro=l(),Gn=a("li"),ane=a("strong"),Kro=o("big_bird"),Zro=o(" \u2014 "),lP=a("a"),eto=o("BigBirdTokenizer"),oto=o(" or "),iP=a("a"),rto=o("BigBirdTokenizerFast"),tto=o(" (BigBird model)"),ato=l(),On=a("li"),nne=a("strong"),nto=o("bigbird_pegasus"),sto=o(" \u2014 "),dP=a("a"),lto=o("PegasusTokenizer"),ito=o(" or "),cP=a("a"),dto=o("PegasusTokenizerFast"),cto=o(" (BigBird-Pegasus model)"),fto=l(),Vn=a("li"),sne=a("strong"),mto=o("blenderbot"),gto=o(" \u2014 "),fP=a("a"),hto=o("BlenderbotTokenizer"),pto=o(" or "),mP=a("a"),uto=o("BlenderbotTokenizerFast"),_to=o(" (Blenderbot model)"),bto=l(),Xg=a("li"),lne=a("strong"),vto=o("blenderbot-small"),Fto=o(" \u2014 "),gP=a("a"),Tto=o("BlenderbotSmallTokenizer"),Mto=o(" (BlenderbotSmall model)"),Eto=l(),zg=a("li"),ine=a("strong"),Cto=o("bloom"),wto=o(" \u2014 "),hP=a("a"),Ato=o("BloomTokenizerFast"),yto=o(" (BLOOM model)"),Lto=l(),Wg=a("li"),dne=a("strong"),xto=o("byt5"),$to=o(" \u2014 "),pP=a("a"),kto=o("ByT5Tokenizer"),Sto=o(" (ByT5 model)"),Rto=l(),Xn=a("li"),cne=a("strong"),Pto=o("camembert"),Bto=o(" \u2014 "),uP=a("a"),Ito=o("CamembertTokenizer"),Nto=o(" or "),_P=a("a"),qto=o("CamembertTokenizerFast"),jto=o(" (CamemBERT model)"),Dto=l(),Qg=a("li"),fne=a("strong"),Gto=o("canine"),Oto=o(" \u2014 "),bP=a("a"),Vto=o("CanineTokenizer"),Xto=o(" (CANINE model)"),zto=l(),zn=a("li"),mne=a("strong"),Wto=o("clip"),Qto=o(" \u2014 "),vP=a("a"),Hto=o("CLIPTokenizer"),Uto=o(" or "),FP=a("a"),Jto=o("CLIPTokenizerFast"),Yto=o(" (CLIP model)"),Kto=l(),Wn=a("li"),gne=a("strong"),Zto=o("convbert"),eao=o(" \u2014 "),TP=a("a"),oao=o("ConvBertTokenizer"),rao=o(" or "),MP=a("a"),tao=o("ConvBertTokenizerFast"),aao=o(" (ConvBERT model)"),nao=l(),Qn=a("li"),hne=a("strong"),sao=o("cpm"),lao=o(" \u2014 "),EP=a("a"),iao=o("CpmTokenizer"),dao=o(" or "),CP=a("a"),cao=o("CpmTokenizerFast"),fao=o(" (CPM model)"),mao=l(),Hg=a("li"),pne=a("strong"),gao=o("ctrl"),hao=o(" \u2014 "),wP=a("a"),pao=o("CTRLTokenizer"),uao=o(" (CTRL model)"),_ao=l(),Hn=a("li"),une=a("strong"),bao=o("data2vec-text"),vao=o(" \u2014 "),AP=a("a"),Fao=o("RobertaTokenizer"),Tao=o(" or "),yP=a("a"),Mao=o("RobertaTokenizerFast"),Eao=o(" (Data2VecText model)"),Cao=l(),Un=a("li"),_ne=a("strong"),wao=o("deberta"),Aao=o(" \u2014 "),LP=a("a"),yao=o("DebertaTokenizer"),Lao=o(" or "),xP=a("a"),xao=o("DebertaTokenizerFast"),$ao=o(" (DeBERTa model)"),kao=l(),Jn=a("li"),bne=a("strong"),Sao=o("deberta-v2"),Rao=o(" \u2014 "),$P=a("a"),Pao=o("DebertaV2Tokenizer"),Bao=o(" or "),kP=a("a"),Iao=o("DebertaV2TokenizerFast"),Nao=o(" (DeBERTa-v2 model)"),qao=l(),Yn=a("li"),vne=a("strong"),jao=o("distilbert"),Dao=o(" \u2014 "),SP=a("a"),Gao=o("DistilBertTokenizer"),Oao=o(" or "),RP=a("a"),Vao=o("DistilBertTokenizerFast"),Xao=o(" (DistilBERT model)"),zao=l(),Kn=a("li"),Fne=a("strong"),Wao=o("dpr"),Qao=o(" \u2014 "),PP=a("a"),Hao=o("DPRQuestionEncoderTokenizer"),Uao=o(" or "),BP=a("a"),Jao=o("DPRQuestionEncoderTokenizerFast"),Yao=o(" (DPR model)"),Kao=l(),Zn=a("li"),Tne=a("strong"),Zao=o("electra"),eno=o(" \u2014 "),IP=a("a"),ono=o("ElectraTokenizer"),rno=o(" or "),NP=a("a"),tno=o("ElectraTokenizerFast"),ano=o(" (ELECTRA model)"),nno=l(),Ug=a("li"),Mne=a("strong"),sno=o("flaubert"),lno=o(" \u2014 "),qP=a("a"),ino=o("FlaubertTokenizer"),dno=o(" (FlauBERT model)"),cno=l(),es=a("li"),Ene=a("strong"),fno=o("fnet"),mno=o(" \u2014 "),jP=a("a"),gno=o("FNetTokenizer"),hno=o(" or "),DP=a("a"),pno=o("FNetTokenizerFast"),uno=o(" (FNet model)"),_no=l(),Jg=a("li"),Cne=a("strong"),bno=o("fsmt"),vno=o(" \u2014 "),GP=a("a"),Fno=o("FSMTTokenizer"),Tno=o(" (FairSeq Machine-Translation model)"),Mno=l(),os=a("li"),wne=a("strong"),Eno=o("funnel"),Cno=o(" \u2014 "),OP=a("a"),wno=o("FunnelTokenizer"),Ano=o(" or "),VP=a("a"),yno=o("FunnelTokenizerFast"),Lno=o(" (Funnel Transformer model)"),xno=l(),rs=a("li"),Ane=a("strong"),$no=o("gpt2"),kno=o(" \u2014 "),XP=a("a"),Sno=o("GPT2Tokenizer"),Rno=o(" or "),zP=a("a"),Pno=o("GPT2TokenizerFast"),Bno=o(" (OpenAI GPT-2 model)"),Ino=l(),ts=a("li"),yne=a("strong"),Nno=o("gpt_neo"),qno=o(" \u2014 "),WP=a("a"),jno=o("GPT2Tokenizer"),Dno=o(" or "),QP=a("a"),Gno=o("GPT2TokenizerFast"),Ono=o(" (GPT Neo model)"),Vno=l(),Yg=a("li"),Lne=a("strong"),Xno=o("gpt_neox"),zno=o(" \u2014 "),HP=a("a"),Wno=o("GPTNeoXTokenizerFast"),Qno=o(" (GPT NeoX model)"),Hno=l(),as=a("li"),xne=a("strong"),Uno=o("gptj"),Jno=o(" \u2014 "),UP=a("a"),Yno=o("GPT2Tokenizer"),Kno=o(" or "),JP=a("a"),Zno=o("GPT2TokenizerFast"),eso=o(" (GPT-J model)"),oso=l(),ns=a("li"),$ne=a("strong"),rso=o("herbert"),tso=o(" \u2014 "),YP=a("a"),aso=o("HerbertTokenizer"),nso=o(" or "),KP=a("a"),sso=o("HerbertTokenizerFast"),lso=o(" (HerBERT model)"),iso=l(),Kg=a("li"),kne=a("strong"),dso=o("hubert"),cso=o(" \u2014 "),ZP=a("a"),fso=o("Wav2Vec2CTCTokenizer"),mso=o(" (Hubert model)"),gso=l(),ss=a("li"),Sne=a("strong"),hso=o("ibert"),pso=o(" \u2014 "),eB=a("a"),uso=o("RobertaTokenizer"),_so=o(" or "),oB=a("a"),bso=o("RobertaTokenizerFast"),vso=o(" (I-BERT model)"),Fso=l(),ls=a("li"),Rne=a("strong"),Tso=o("layoutlm"),Mso=o(" \u2014 "),rB=a("a"),Eso=o("LayoutLMTokenizer"),Cso=o(" or "),tB=a("a"),wso=o("LayoutLMTokenizerFast"),Aso=o(" (LayoutLM model)"),yso=l(),is=a("li"),Pne=a("strong"),Lso=o("layoutlmv2"),xso=o(" \u2014 "),aB=a("a"),$so=o("LayoutLMv2Tokenizer"),kso=o(" or "),nB=a("a"),Sso=o("LayoutLMv2TokenizerFast"),Rso=o(" (LayoutLMv2 model)"),Pso=l(),ds=a("li"),Bne=a("strong"),Bso=o("layoutlmv3"),Iso=o(" \u2014 "),sB=a("a"),Nso=o("LayoutLMv3Tokenizer"),qso=o(" or "),lB=a("a"),jso=o("LayoutLMv3TokenizerFast"),Dso=o(" (LayoutLMv3 model)"),Gso=l(),cs=a("li"),Ine=a("strong"),Oso=o("layoutxlm"),Vso=o(" \u2014 "),iB=a("a"),Xso=o("LayoutXLMTokenizer"),zso=o(" or "),dB=a("a"),Wso=o("LayoutXLMTokenizerFast"),Qso=o(" (LayoutXLM model)"),Hso=l(),fs=a("li"),Nne=a("strong"),Uso=o("led"),Jso=o(" \u2014 "),cB=a("a"),Yso=o("LEDTokenizer"),Kso=o(" or "),fB=a("a"),Zso=o("LEDTokenizerFast"),elo=o(" (LED model)"),olo=l(),ms=a("li"),qne=a("strong"),rlo=o("longformer"),tlo=o(" \u2014 "),mB=a("a"),alo=o("LongformerTokenizer"),nlo=o(" or "),gB=a("a"),slo=o("LongformerTokenizerFast"),llo=o(" (Longformer model)"),ilo=l(),Zg=a("li"),jne=a("strong"),dlo=o("luke"),clo=o(" \u2014 "),hB=a("a"),flo=o("LukeTokenizer"),mlo=o(" (LUKE model)"),glo=l(),gs=a("li"),Dne=a("strong"),hlo=o("lxmert"),plo=o(" \u2014 "),pB=a("a"),ulo=o("LxmertTokenizer"),_lo=o(" or "),uB=a("a"),blo=o("LxmertTokenizerFast"),vlo=o(" (LXMERT model)"),Flo=l(),eh=a("li"),Gne=a("strong"),Tlo=o("m2m_100"),Mlo=o(" \u2014 "),_B=a("a"),Elo=o("M2M100Tokenizer"),Clo=o(" (M2M100 model)"),wlo=l(),oh=a("li"),One=a("strong"),Alo=o("marian"),ylo=o(" \u2014 "),bB=a("a"),Llo=o("MarianTokenizer"),xlo=o(" (Marian model)"),$lo=l(),hs=a("li"),Vne=a("strong"),klo=o("mbart"),Slo=o(" \u2014 "),vB=a("a"),Rlo=o("MBartTokenizer"),Plo=o(" or "),FB=a("a"),Blo=o("MBartTokenizerFast"),Ilo=o(" (mBART model)"),Nlo=l(),ps=a("li"),Xne=a("strong"),qlo=o("mbart50"),jlo=o(" \u2014 "),TB=a("a"),Dlo=o("MBart50Tokenizer"),Glo=o(" or "),MB=a("a"),Olo=o("MBart50TokenizerFast"),Vlo=o(" (mBART-50 model)"),Xlo=l(),us=a("li"),zne=a("strong"),zlo=o("megatron-bert"),Wlo=o(" \u2014 "),EB=a("a"),Qlo=o("BertTokenizer"),Hlo=o(" or "),CB=a("a"),Ulo=o("BertTokenizerFast"),Jlo=o(" (Megatron-BERT model)"),Ylo=l(),rh=a("li"),Wne=a("strong"),Klo=o("mluke"),Zlo=o(" \u2014 "),wB=a("a"),eio=o("MLukeTokenizer"),oio=o(" (mLUKE model)"),rio=l(),_s=a("li"),Qne=a("strong"),tio=o("mobilebert"),aio=o(" \u2014 "),AB=a("a"),nio=o("MobileBertTokenizer"),sio=o(" or "),yB=a("a"),lio=o("MobileBertTokenizerFast"),iio=o(" (MobileBERT model)"),dio=l(),bs=a("li"),Hne=a("strong"),cio=o("mpnet"),fio=o(" \u2014 "),LB=a("a"),mio=o("MPNetTokenizer"),gio=o(" or "),xB=a("a"),hio=o("MPNetTokenizerFast"),pio=o(" (MPNet model)"),uio=l(),vs=a("li"),Une=a("strong"),_io=o("mt5"),bio=o(" \u2014 "),$B=a("a"),vio=o("MT5Tokenizer"),Fio=o(" or "),kB=a("a"),Tio=o("MT5TokenizerFast"),Mio=o(" (MT5 model)"),Eio=l(),Fs=a("li"),Jne=a("strong"),Cio=o("nystromformer"),wio=o(" \u2014 "),SB=a("a"),Aio=o("AlbertTokenizer"),yio=o(" or "),RB=a("a"),Lio=o("AlbertTokenizerFast"),xio=o(" (Nystr\xF6mformer model)"),$io=l(),Ts=a("li"),Yne=a("strong"),kio=o("openai-gpt"),Sio=o(" \u2014 "),PB=a("a"),Rio=o("OpenAIGPTTokenizer"),Pio=o(" or "),BB=a("a"),Bio=o("OpenAIGPTTokenizerFast"),Iio=o(" (OpenAI GPT model)"),Nio=l(),th=a("li"),Kne=a("strong"),qio=o("opt"),jio=o(" \u2014 "),IB=a("a"),Dio=o("GPT2Tokenizer"),Gio=o(" (OPT model)"),Oio=l(),Ms=a("li"),Zne=a("strong"),Vio=o("pegasus"),Xio=o(" \u2014 "),NB=a("a"),zio=o("PegasusTokenizer"),Wio=o(" or "),qB=a("a"),Qio=o("PegasusTokenizerFast"),Hio=o(" (Pegasus model)"),Uio=l(),ah=a("li"),ese=a("strong"),Jio=o("perceiver"),Yio=o(" \u2014 "),jB=a("a"),Kio=o("PerceiverTokenizer"),Zio=o(" (Perceiver model)"),edo=l(),nh=a("li"),ose=a("strong"),odo=o("phobert"),rdo=o(" \u2014 "),DB=a("a"),tdo=o("PhobertTokenizer"),ado=o(" (PhoBERT model)"),ndo=l(),sh=a("li"),rse=a("strong"),sdo=o("plbart"),ldo=o(" \u2014 "),GB=a("a"),ido=o("PLBartTokenizer"),ddo=o(" (PLBart model)"),cdo=l(),lh=a("li"),tse=a("strong"),fdo=o("prophetnet"),mdo=o(" \u2014 "),OB=a("a"),gdo=o("ProphetNetTokenizer"),hdo=o(" (ProphetNet model)"),pdo=l(),Es=a("li"),ase=a("strong"),udo=o("qdqbert"),_do=o(" \u2014 "),VB=a("a"),bdo=o("BertTokenizer"),vdo=o(" or "),XB=a("a"),Fdo=o("BertTokenizerFast"),Tdo=o(" (QDQBert model)"),Mdo=l(),ih=a("li"),nse=a("strong"),Edo=o("rag"),Cdo=o(" \u2014 "),zB=a("a"),wdo=o("RagTokenizer"),Ado=o(" (RAG model)"),ydo=l(),Cs=a("li"),sse=a("strong"),Ldo=o("realm"),xdo=o(" \u2014 "),WB=a("a"),$do=o("RealmTokenizer"),kdo=o(" or "),QB=a("a"),Sdo=o("RealmTokenizerFast"),Rdo=o(" (REALM model)"),Pdo=l(),ws=a("li"),lse=a("strong"),Bdo=o("reformer"),Ido=o(" \u2014 "),HB=a("a"),Ndo=o("ReformerTokenizer"),qdo=o(" or "),UB=a("a"),jdo=o("ReformerTokenizerFast"),Ddo=o(" (Reformer model)"),Gdo=l(),As=a("li"),ise=a("strong"),Odo=o("rembert"),Vdo=o(" \u2014 "),JB=a("a"),Xdo=o("RemBertTokenizer"),zdo=o(" or "),YB=a("a"),Wdo=o("RemBertTokenizerFast"),Qdo=o(" (RemBERT model)"),Hdo=l(),ys=a("li"),dse=a("strong"),Udo=o("retribert"),Jdo=o(" \u2014 "),KB=a("a"),Ydo=o("RetriBertTokenizer"),Kdo=o(" or "),ZB=a("a"),Zdo=o("RetriBertTokenizerFast"),eco=o(" (RetriBERT model)"),oco=l(),Ls=a("li"),cse=a("strong"),rco=o("roberta"),tco=o(" \u2014 "),eI=a("a"),aco=o("RobertaTokenizer"),nco=o(" or "),oI=a("a"),sco=o("RobertaTokenizerFast"),lco=o(" (RoBERTa model)"),ico=l(),xs=a("li"),fse=a("strong"),dco=o("roformer"),cco=o(" \u2014 "),rI=a("a"),fco=o("RoFormerTokenizer"),mco=o(" or "),tI=a("a"),gco=o("RoFormerTokenizerFast"),hco=o(" (RoFormer model)"),pco=l(),dh=a("li"),mse=a("strong"),uco=o("speech_to_text"),_co=o(" \u2014 "),aI=a("a"),bco=o("Speech2TextTokenizer"),vco=o(" (Speech2Text model)"),Fco=l(),ch=a("li"),gse=a("strong"),Tco=o("speech_to_text_2"),Mco=o(" \u2014 "),nI=a("a"),Eco=o("Speech2Text2Tokenizer"),Cco=o(" (Speech2Text2 model)"),wco=l(),$s=a("li"),hse=a("strong"),Aco=o("splinter"),yco=o(" \u2014 "),sI=a("a"),Lco=o("SplinterTokenizer"),xco=o(" or "),lI=a("a"),$co=o("SplinterTokenizerFast"),kco=o(" (Splinter model)"),Sco=l(),ks=a("li"),pse=a("strong"),Rco=o("squeezebert"),Pco=o(" \u2014 "),iI=a("a"),Bco=o("SqueezeBertTokenizer"),Ico=o(" or "),dI=a("a"),Nco=o("SqueezeBertTokenizerFast"),qco=o(" (SqueezeBERT model)"),jco=l(),Ss=a("li"),use=a("strong"),Dco=o("t5"),Gco=o(" \u2014 "),cI=a("a"),Oco=o("T5Tokenizer"),Vco=o(" or "),fI=a("a"),Xco=o("T5TokenizerFast"),zco=o(" (T5 model)"),Wco=l(),fh=a("li"),_se=a("strong"),Qco=o("tapas"),Hco=o(" \u2014 "),mI=a("a"),Uco=o("TapasTokenizer"),Jco=o(" (TAPAS model)"),Yco=l(),mh=a("li"),bse=a("strong"),Kco=o("tapex"),Zco=o(" \u2014 "),gI=a("a"),efo=o("TapexTokenizer"),ofo=o(" (TAPEX model)"),rfo=l(),gh=a("li"),vse=a("strong"),tfo=o("transfo-xl"),afo=o(" \u2014 "),hI=a("a"),nfo=o("TransfoXLTokenizer"),sfo=o(" (Transformer-XL model)"),lfo=l(),Rs=a("li"),Fse=a("strong"),ifo=o("vilt"),dfo=o(" \u2014 "),pI=a("a"),cfo=o("BertTokenizer"),ffo=o(" or "),uI=a("a"),mfo=o("BertTokenizerFast"),gfo=o(" (ViLT model)"),hfo=l(),Ps=a("li"),Tse=a("strong"),pfo=o("visual_bert"),ufo=o(" \u2014 "),_I=a("a"),_fo=o("BertTokenizer"),bfo=o(" or "),bI=a("a"),vfo=o("BertTokenizerFast"),Ffo=o(" (VisualBERT model)"),Tfo=l(),hh=a("li"),Mse=a("strong"),Mfo=o("wav2vec2"),Efo=o(" \u2014 "),vI=a("a"),Cfo=o("Wav2Vec2CTCTokenizer"),wfo=o(" (Wav2Vec2 model)"),Afo=l(),ph=a("li"),Ese=a("strong"),yfo=o("wav2vec2-conformer"),Lfo=o(" \u2014 "),FI=a("a"),xfo=o("Wav2Vec2CTCTokenizer"),$fo=o(" (Wav2Vec2-Conformer model)"),kfo=l(),uh=a("li"),Cse=a("strong"),Sfo=o("wav2vec2_phoneme"),Rfo=o(" \u2014 "),TI=a("a"),Pfo=o("Wav2Vec2PhonemeCTCTokenizer"),Bfo=o(" (Wav2Vec2Phoneme model)"),Ifo=l(),Bs=a("li"),wse=a("strong"),Nfo=o("xglm"),qfo=o(" \u2014 "),MI=a("a"),jfo=o("XGLMTokenizer"),Dfo=o(" or "),EI=a("a"),Gfo=o("XGLMTokenizerFast"),Ofo=o(" (XGLM model)"),Vfo=l(),_h=a("li"),Ase=a("strong"),Xfo=o("xlm"),zfo=o(" \u2014 "),CI=a("a"),Wfo=o("XLMTokenizer"),Qfo=o(" (XLM model)"),Hfo=l(),bh=a("li"),yse=a("strong"),Ufo=o("xlm-prophetnet"),Jfo=o(" \u2014 "),wI=a("a"),Yfo=o("XLMProphetNetTokenizer"),Kfo=o(" (XLM-ProphetNet model)"),Zfo=l(),Is=a("li"),Lse=a("strong"),emo=o("xlm-roberta"),omo=o(" \u2014 "),AI=a("a"),rmo=o("XLMRobertaTokenizer"),tmo=o(" or "),yI=a("a"),amo=o("XLMRobertaTokenizerFast"),nmo=o(" (XLM-RoBERTa model)"),smo=l(),Ns=a("li"),xse=a("strong"),lmo=o("xlm-roberta-xl"),imo=o(" \u2014 "),LI=a("a"),dmo=o("RobertaTokenizer"),cmo=o(" or "),xI=a("a"),fmo=o("RobertaTokenizerFast"),mmo=o(" (XLM-RoBERTa-XL model)"),gmo=l(),qs=a("li"),$se=a("strong"),hmo=o("xlnet"),pmo=o(" \u2014 "),$I=a("a"),umo=o("XLNetTokenizer"),_mo=o(" or "),kI=a("a"),bmo=o("XLNetTokenizerFast"),vmo=o(" (XLNet model)"),Fmo=l(),js=a("li"),kse=a("strong"),Tmo=o("yoso"),Mmo=o(" \u2014 "),SI=a("a"),Emo=o("AlbertTokenizer"),Cmo=o(" or "),RI=a("a"),wmo=o("AlbertTokenizerFast"),Amo=o(" (YOSO model)"),ymo=l(),F(vh.$$.fragment),Lmo=l(),Fh=a("div"),F(wA.$$.fragment),xmo=l(),Sse=a("p"),$mo=o("Register a new tokenizer in this mapping."),SDe=l(),$i=a("h2"),Th=a("a"),Rse=a("span"),F(AA.$$.fragment),kmo=l(),Pse=a("span"),Smo=o("AutoFeatureExtractor"),RDe=l(),yo=a("div"),F(yA.$$.fragment),Rmo=l(),LA=a("p"),Pmo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),PI=a("a"),Bmo=o("AutoFeatureExtractor.from_pretrained()"),Imo=o(" class method."),Nmo=l(),xA=a("p"),qmo=o("This class cannot be instantiated directly using "),Bse=a("code"),jmo=o("__init__()"),Dmo=o(" (throws an error)."),Gmo=l(),He=a("div"),F($A.$$.fragment),Omo=l(),Ise=a("p"),Vmo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Xmo=l(),ka=a("p"),zmo=o("The feature extractor class to instantiate is selected based on the "),Nse=a("code"),Wmo=o("model_type"),Qmo=o(` property of the config object
(either passed as an argument or loaded from `),qse=a("code"),Hmo=o("pretrained_model_name_or_path"),Umo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),jse=a("code"),Jmo=o("pretrained_model_name_or_path"),Ymo=o(":"),Kmo=l(),Y=a("ul"),Mh=a("li"),Dse=a("strong"),Zmo=o("beit"),ego=o(" \u2014 "),BI=a("a"),ogo=o("BeitFeatureExtractor"),rgo=o(" (BEiT model)"),tgo=l(),Eh=a("li"),Gse=a("strong"),ago=o("clip"),ngo=o(" \u2014 "),II=a("a"),sgo=o("CLIPFeatureExtractor"),lgo=o(" (CLIP model)"),igo=l(),Ch=a("li"),Ose=a("strong"),dgo=o("convnext"),cgo=o(" \u2014 "),NI=a("a"),fgo=o("ConvNextFeatureExtractor"),mgo=o(" (ConvNeXT model)"),ggo=l(),wh=a("li"),Vse=a("strong"),hgo=o("cvt"),pgo=o(" \u2014 "),qI=a("a"),ugo=o("ConvNextFeatureExtractor"),_go=o(" (CvT model)"),bgo=l(),Ah=a("li"),Xse=a("strong"),vgo=o("data2vec-audio"),Fgo=o(" \u2014 "),jI=a("a"),Tgo=o("Wav2Vec2FeatureExtractor"),Mgo=o(" (Data2VecAudio model)"),Ego=l(),yh=a("li"),zse=a("strong"),Cgo=o("data2vec-vision"),wgo=o(" \u2014 "),DI=a("a"),Ago=o("BeitFeatureExtractor"),ygo=o(" (Data2VecVision model)"),Lgo=l(),Lh=a("li"),Wse=a("strong"),xgo=o("deit"),$go=o(" \u2014 "),GI=a("a"),kgo=o("DeiTFeatureExtractor"),Sgo=o(" (DeiT model)"),Rgo=l(),xh=a("li"),Qse=a("strong"),Pgo=o("detr"),Bgo=o(" \u2014 "),OI=a("a"),Igo=o("DetrFeatureExtractor"),Ngo=o(" (DETR model)"),qgo=l(),$h=a("li"),Hse=a("strong"),jgo=o("dpt"),Dgo=o(" \u2014 "),VI=a("a"),Ggo=o("DPTFeatureExtractor"),Ogo=o(" (DPT model)"),Vgo=l(),kh=a("li"),Use=a("strong"),Xgo=o("flava"),zgo=o(" \u2014 "),XI=a("a"),Wgo=o("FlavaFeatureExtractor"),Qgo=o(" (FLAVA model)"),Hgo=l(),Sh=a("li"),Jse=a("strong"),Ugo=o("glpn"),Jgo=o(" \u2014 "),zI=a("a"),Ygo=o("GLPNFeatureExtractor"),Kgo=o(" (GLPN model)"),Zgo=l(),Rh=a("li"),Yse=a("strong"),eho=o("hubert"),oho=o(" \u2014 "),WI=a("a"),rho=o("Wav2Vec2FeatureExtractor"),tho=o(" (Hubert model)"),aho=l(),Ph=a("li"),Kse=a("strong"),nho=o("imagegpt"),sho=o(" \u2014 "),QI=a("a"),lho=o("ImageGPTFeatureExtractor"),iho=o(" (ImageGPT model)"),dho=l(),Bh=a("li"),Zse=a("strong"),cho=o("layoutlmv2"),fho=o(" \u2014 "),HI=a("a"),mho=o("LayoutLMv2FeatureExtractor"),gho=o(" (LayoutLMv2 model)"),hho=l(),Ih=a("li"),ele=a("strong"),pho=o("layoutlmv3"),uho=o(" \u2014 "),UI=a("a"),_ho=o("LayoutLMv3FeatureExtractor"),bho=o(" (LayoutLMv3 model)"),vho=l(),Nh=a("li"),ole=a("strong"),Fho=o("levit"),Tho=o(" \u2014 "),JI=a("a"),Mho=o("LevitFeatureExtractor"),Eho=o(" (LeViT model)"),Cho=l(),qh=a("li"),rle=a("strong"),who=o("maskformer"),Aho=o(" \u2014 "),YI=a("a"),yho=o("MaskFormerFeatureExtractor"),Lho=o(" (MaskFormer model)"),xho=l(),jh=a("li"),tle=a("strong"),$ho=o("mctct"),kho=o(" \u2014 "),KI=a("a"),Sho=o("MCTCTFeatureExtractor"),Rho=o(" (M-CTC-T model)"),Pho=l(),Dh=a("li"),ale=a("strong"),Bho=o("perceiver"),Iho=o(" \u2014 "),ZI=a("a"),Nho=o("PerceiverFeatureExtractor"),qho=o(" (Perceiver model)"),jho=l(),Gh=a("li"),nle=a("strong"),Dho=o("poolformer"),Gho=o(" \u2014 "),eN=a("a"),Oho=o("PoolFormerFeatureExtractor"),Vho=o(" (PoolFormer model)"),Xho=l(),Oh=a("li"),sle=a("strong"),zho=o("regnet"),Who=o(" \u2014 "),oN=a("a"),Qho=o("ConvNextFeatureExtractor"),Hho=o(" (RegNet model)"),Uho=l(),Vh=a("li"),lle=a("strong"),Jho=o("resnet"),Yho=o(" \u2014 "),rN=a("a"),Kho=o("ConvNextFeatureExtractor"),Zho=o(" (ResNet model)"),epo=l(),Xh=a("li"),ile=a("strong"),opo=o("segformer"),rpo=o(" \u2014 "),tN=a("a"),tpo=o("SegformerFeatureExtractor"),apo=o(" (SegFormer model)"),npo=l(),zh=a("li"),dle=a("strong"),spo=o("speech_to_text"),lpo=o(" \u2014 "),aN=a("a"),ipo=o("Speech2TextFeatureExtractor"),dpo=o(" (Speech2Text model)"),cpo=l(),Wh=a("li"),cle=a("strong"),fpo=o("swin"),mpo=o(" \u2014 "),nN=a("a"),gpo=o("ViTFeatureExtractor"),hpo=o(" (Swin Transformer model)"),ppo=l(),Qh=a("li"),fle=a("strong"),upo=o("van"),_po=o(" \u2014 "),sN=a("a"),bpo=o("ConvNextFeatureExtractor"),vpo=o(" (VAN model)"),Fpo=l(),Hh=a("li"),mle=a("strong"),Tpo=o("vilt"),Mpo=o(" \u2014 "),lN=a("a"),Epo=o("ViltFeatureExtractor"),Cpo=o(" (ViLT model)"),wpo=l(),Uh=a("li"),gle=a("strong"),Apo=o("vit"),ypo=o(" \u2014 "),iN=a("a"),Lpo=o("ViTFeatureExtractor"),xpo=o(" (ViT model)"),$po=l(),Jh=a("li"),hle=a("strong"),kpo=o("vit_mae"),Spo=o(" \u2014 "),dN=a("a"),Rpo=o("ViTFeatureExtractor"),Ppo=o(" (ViTMAE model)"),Bpo=l(),Yh=a("li"),ple=a("strong"),Ipo=o("wav2vec2"),Npo=o(" \u2014 "),cN=a("a"),qpo=o("Wav2Vec2FeatureExtractor"),jpo=o(" (Wav2Vec2 model)"),Dpo=l(),Kh=a("li"),ule=a("strong"),Gpo=o("wav2vec2-conformer"),Opo=o(" \u2014 "),fN=a("a"),Vpo=o("Wav2Vec2FeatureExtractor"),Xpo=o(" (Wav2Vec2-Conformer model)"),zpo=l(),Zh=a("li"),_le=a("strong"),Wpo=o("yolos"),Qpo=o(" \u2014 "),mN=a("a"),Hpo=o("YolosFeatureExtractor"),Upo=o(" (YOLOS model)"),Jpo=l(),F(ep.$$.fragment),Ypo=l(),F(op.$$.fragment),Kpo=l(),rp=a("div"),F(kA.$$.fragment),Zpo=l(),ble=a("p"),euo=o("Register a new feature extractor for this class."),PDe=l(),ki=a("h2"),tp=a("a"),vle=a("span"),F(SA.$$.fragment),ouo=l(),Fle=a("span"),ruo=o("AutoProcessor"),BDe=l(),Lo=a("div"),F(RA.$$.fragment),tuo=l(),PA=a("p"),auo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),gN=a("a"),nuo=o("AutoProcessor.from_pretrained()"),suo=o(" class method."),luo=l(),BA=a("p"),iuo=o("This class cannot be instantiated directly using "),Tle=a("code"),duo=o("__init__()"),cuo=o(" (throws an error)."),fuo=l(),Ue=a("div"),F(IA.$$.fragment),muo=l(),Mle=a("p"),guo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),huo=l(),Si=a("p"),puo=o("The processor class to instantiate is selected based on the "),Ele=a("code"),uuo=o("model_type"),_uo=o(` property of the config object (either
passed as an argument or loaded from `),Cle=a("code"),buo=o("pretrained_model_name_or_path"),vuo=o(" if possible):"),Fuo=l(),he=a("ul"),ap=a("li"),wle=a("strong"),Tuo=o("clip"),Muo=o(" \u2014 "),hN=a("a"),Euo=o("CLIPProcessor"),Cuo=o(" (CLIP model)"),wuo=l(),np=a("li"),Ale=a("strong"),Auo=o("flava"),yuo=o(" \u2014 "),yle=a("code"),Luo=o("FLAVAProcessor"),xuo=o(" (FLAVA model)"),$uo=l(),sp=a("li"),Lle=a("strong"),kuo=o("layoutlmv2"),Suo=o(" \u2014 "),pN=a("a"),Ruo=o("LayoutLMv2Processor"),Puo=o(" (LayoutLMv2 model)"),Buo=l(),lp=a("li"),xle=a("strong"),Iuo=o("layoutlmv3"),Nuo=o(" \u2014 "),uN=a("a"),quo=o("LayoutLMv3Processor"),juo=o(" (LayoutLMv3 model)"),Duo=l(),ip=a("li"),$le=a("strong"),Guo=o("layoutxlm"),Ouo=o(" \u2014 "),_N=a("a"),Vuo=o("LayoutXLMProcessor"),Xuo=o(" (LayoutXLM model)"),zuo=l(),dp=a("li"),kle=a("strong"),Wuo=o("sew"),Quo=o(" \u2014 "),bN=a("a"),Huo=o("Wav2Vec2Processor"),Uuo=o(" (SEW model)"),Juo=l(),cp=a("li"),Sle=a("strong"),Yuo=o("sew-d"),Kuo=o(" \u2014 "),vN=a("a"),Zuo=o("Wav2Vec2Processor"),e_o=o(" (SEW-D model)"),o_o=l(),fp=a("li"),Rle=a("strong"),r_o=o("speech_to_text"),t_o=o(" \u2014 "),FN=a("a"),a_o=o("Speech2TextProcessor"),n_o=o(" (Speech2Text model)"),s_o=l(),mp=a("li"),Ple=a("strong"),l_o=o("speech_to_text_2"),i_o=o(" \u2014 "),TN=a("a"),d_o=o("Speech2Text2Processor"),c_o=o(" (Speech2Text2 model)"),f_o=l(),gp=a("li"),Ble=a("strong"),m_o=o("trocr"),g_o=o(" \u2014 "),MN=a("a"),h_o=o("TrOCRProcessor"),p_o=o(" (TrOCR model)"),u_o=l(),hp=a("li"),Ile=a("strong"),__o=o("unispeech"),b_o=o(" \u2014 "),EN=a("a"),v_o=o("Wav2Vec2Processor"),F_o=o(" (UniSpeech model)"),T_o=l(),pp=a("li"),Nle=a("strong"),M_o=o("unispeech-sat"),E_o=o(" \u2014 "),CN=a("a"),C_o=o("Wav2Vec2Processor"),w_o=o(" (UniSpeechSat model)"),A_o=l(),up=a("li"),qle=a("strong"),y_o=o("vilt"),L_o=o(" \u2014 "),wN=a("a"),x_o=o("ViltProcessor"),$_o=o(" (ViLT model)"),k_o=l(),_p=a("li"),jle=a("strong"),S_o=o("vision-text-dual-encoder"),R_o=o(" \u2014 "),AN=a("a"),P_o=o("VisionTextDualEncoderProcessor"),B_o=o(" (VisionTextDualEncoder model)"),I_o=l(),bp=a("li"),Dle=a("strong"),N_o=o("wav2vec2"),q_o=o(" \u2014 "),yN=a("a"),j_o=o("Wav2Vec2Processor"),D_o=o(" (Wav2Vec2 model)"),G_o=l(),vp=a("li"),Gle=a("strong"),O_o=o("wav2vec2-conformer"),V_o=o(" \u2014 "),LN=a("a"),X_o=o("Wav2Vec2Processor"),z_o=o(" (Wav2Vec2-Conformer model)"),W_o=l(),Fp=a("li"),Ole=a("strong"),Q_o=o("wavlm"),H_o=o(" \u2014 "),xN=a("a"),U_o=o("Wav2Vec2Processor"),J_o=o(" (WavLM model)"),Y_o=l(),F(Tp.$$.fragment),K_o=l(),F(Mp.$$.fragment),Z_o=l(),Ep=a("div"),F(NA.$$.fragment),e1o=l(),Vle=a("p"),o1o=o("Register a new processor for this class."),IDe=l(),Ri=a("h2"),Cp=a("a"),Xle=a("span"),F(qA.$$.fragment),r1o=l(),zle=a("span"),t1o=o("AutoModel"),NDe=l(),xo=a("div"),F(jA.$$.fragment),a1o=l(),Pi=a("p"),n1o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),$N=a("a"),s1o=o("from_pretrained()"),l1o=o(" class method or the "),kN=a("a"),i1o=o("from_config()"),d1o=o(` class
method.`),c1o=l(),DA=a("p"),f1o=o("This class cannot be instantiated directly using "),Wle=a("code"),m1o=o("__init__()"),g1o=o(" (throws an error)."),h1o=l(),nt=a("div"),F(GA.$$.fragment),p1o=l(),Qle=a("p"),u1o=o("Instantiates one of the base model classes of the library from a configuration."),_1o=l(),Bi=a("p"),b1o=o(`Note:
Loading a model from its configuration file does `),Hle=a("strong"),v1o=o("not"),F1o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SN=a("a"),T1o=o("from_pretrained()"),M1o=o(" to load the model weights."),E1o=l(),F(wp.$$.fragment),C1o=l(),Je=a("div"),F(OA.$$.fragment),w1o=l(),Ule=a("p"),A1o=o("Instantiate one of the base model classes of the library from a pretrained model."),y1o=l(),Sa=a("p"),L1o=o("The model class to instantiate is selected based on the "),Jle=a("code"),x1o=o("model_type"),$1o=o(` property of the config object (either
passed as an argument or loaded from `),Yle=a("code"),k1o=o("pretrained_model_name_or_path"),S1o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kle=a("code"),R1o=o("pretrained_model_name_or_path"),P1o=o(":"),B1o=l(),x=a("ul"),Ap=a("li"),Zle=a("strong"),I1o=o("albert"),N1o=o(" \u2014 "),RN=a("a"),q1o=o("AlbertModel"),j1o=o(" (ALBERT model)"),D1o=l(),yp=a("li"),eie=a("strong"),G1o=o("bart"),O1o=o(" \u2014 "),PN=a("a"),V1o=o("BartModel"),X1o=o(" (BART model)"),z1o=l(),Lp=a("li"),oie=a("strong"),W1o=o("beit"),Q1o=o(" \u2014 "),BN=a("a"),H1o=o("BeitModel"),U1o=o(" (BEiT model)"),J1o=l(),xp=a("li"),rie=a("strong"),Y1o=o("bert"),K1o=o(" \u2014 "),IN=a("a"),Z1o=o("BertModel"),ebo=o(" (BERT model)"),obo=l(),$p=a("li"),tie=a("strong"),rbo=o("bert-generation"),tbo=o(" \u2014 "),NN=a("a"),abo=o("BertGenerationEncoder"),nbo=o(" (Bert Generation model)"),sbo=l(),kp=a("li"),aie=a("strong"),lbo=o("big_bird"),ibo=o(" \u2014 "),qN=a("a"),dbo=o("BigBirdModel"),cbo=o(" (BigBird model)"),fbo=l(),Sp=a("li"),nie=a("strong"),mbo=o("bigbird_pegasus"),gbo=o(" \u2014 "),jN=a("a"),hbo=o("BigBirdPegasusModel"),pbo=o(" (BigBird-Pegasus model)"),ubo=l(),Rp=a("li"),sie=a("strong"),_bo=o("blenderbot"),bbo=o(" \u2014 "),DN=a("a"),vbo=o("BlenderbotModel"),Fbo=o(" (Blenderbot model)"),Tbo=l(),Pp=a("li"),lie=a("strong"),Mbo=o("blenderbot-small"),Ebo=o(" \u2014 "),GN=a("a"),Cbo=o("BlenderbotSmallModel"),wbo=o(" (BlenderbotSmall model)"),Abo=l(),Bp=a("li"),iie=a("strong"),ybo=o("bloom"),Lbo=o(" \u2014 "),ON=a("a"),xbo=o("BloomModel"),$bo=o(" (BLOOM model)"),kbo=l(),Ip=a("li"),die=a("strong"),Sbo=o("camembert"),Rbo=o(" \u2014 "),VN=a("a"),Pbo=o("CamembertModel"),Bbo=o(" (CamemBERT model)"),Ibo=l(),Np=a("li"),cie=a("strong"),Nbo=o("canine"),qbo=o(" \u2014 "),XN=a("a"),jbo=o("CanineModel"),Dbo=o(" (CANINE model)"),Gbo=l(),qp=a("li"),fie=a("strong"),Obo=o("clip"),Vbo=o(" \u2014 "),zN=a("a"),Xbo=o("CLIPModel"),zbo=o(" (CLIP model)"),Wbo=l(),jp=a("li"),mie=a("strong"),Qbo=o("convbert"),Hbo=o(" \u2014 "),WN=a("a"),Ubo=o("ConvBertModel"),Jbo=o(" (ConvBERT model)"),Ybo=l(),Dp=a("li"),gie=a("strong"),Kbo=o("convnext"),Zbo=o(" \u2014 "),QN=a("a"),e2o=o("ConvNextModel"),o2o=o(" (ConvNeXT model)"),r2o=l(),Gp=a("li"),hie=a("strong"),t2o=o("ctrl"),a2o=o(" \u2014 "),HN=a("a"),n2o=o("CTRLModel"),s2o=o(" (CTRL model)"),l2o=l(),Op=a("li"),pie=a("strong"),i2o=o("cvt"),d2o=o(" \u2014 "),UN=a("a"),c2o=o("CvtModel"),f2o=o(" (CvT model)"),m2o=l(),Vp=a("li"),uie=a("strong"),g2o=o("data2vec-audio"),h2o=o(" \u2014 "),JN=a("a"),p2o=o("Data2VecAudioModel"),u2o=o(" (Data2VecAudio model)"),_2o=l(),Xp=a("li"),_ie=a("strong"),b2o=o("data2vec-text"),v2o=o(" \u2014 "),YN=a("a"),F2o=o("Data2VecTextModel"),T2o=o(" (Data2VecText model)"),M2o=l(),zp=a("li"),bie=a("strong"),E2o=o("data2vec-vision"),C2o=o(" \u2014 "),KN=a("a"),w2o=o("Data2VecVisionModel"),A2o=o(" (Data2VecVision model)"),y2o=l(),Wp=a("li"),vie=a("strong"),L2o=o("deberta"),x2o=o(" \u2014 "),ZN=a("a"),$2o=o("DebertaModel"),k2o=o(" (DeBERTa model)"),S2o=l(),Qp=a("li"),Fie=a("strong"),R2o=o("deberta-v2"),P2o=o(" \u2014 "),eq=a("a"),B2o=o("DebertaV2Model"),I2o=o(" (DeBERTa-v2 model)"),N2o=l(),Hp=a("li"),Tie=a("strong"),q2o=o("decision_transformer"),j2o=o(" \u2014 "),oq=a("a"),D2o=o("DecisionTransformerModel"),G2o=o(" (Decision Transformer model)"),O2o=l(),Up=a("li"),Mie=a("strong"),V2o=o("deit"),X2o=o(" \u2014 "),rq=a("a"),z2o=o("DeiTModel"),W2o=o(" (DeiT model)"),Q2o=l(),Jp=a("li"),Eie=a("strong"),H2o=o("detr"),U2o=o(" \u2014 "),tq=a("a"),J2o=o("DetrModel"),Y2o=o(" (DETR model)"),K2o=l(),Yp=a("li"),Cie=a("strong"),Z2o=o("distilbert"),evo=o(" \u2014 "),aq=a("a"),ovo=o("DistilBertModel"),rvo=o(" (DistilBERT model)"),tvo=l(),Kp=a("li"),wie=a("strong"),avo=o("dpr"),nvo=o(" \u2014 "),nq=a("a"),svo=o("DPRQuestionEncoder"),lvo=o(" (DPR model)"),ivo=l(),Zp=a("li"),Aie=a("strong"),dvo=o("dpt"),cvo=o(" \u2014 "),sq=a("a"),fvo=o("DPTModel"),mvo=o(" (DPT model)"),gvo=l(),eu=a("li"),yie=a("strong"),hvo=o("electra"),pvo=o(" \u2014 "),lq=a("a"),uvo=o("ElectraModel"),_vo=o(" (ELECTRA model)"),bvo=l(),ou=a("li"),Lie=a("strong"),vvo=o("flaubert"),Fvo=o(" \u2014 "),iq=a("a"),Tvo=o("FlaubertModel"),Mvo=o(" (FlauBERT model)"),Evo=l(),ru=a("li"),xie=a("strong"),Cvo=o("flava"),wvo=o(" \u2014 "),dq=a("a"),Avo=o("FlavaModel"),yvo=o(" (FLAVA model)"),Lvo=l(),tu=a("li"),$ie=a("strong"),xvo=o("fnet"),$vo=o(" \u2014 "),cq=a("a"),kvo=o("FNetModel"),Svo=o(" (FNet model)"),Rvo=l(),au=a("li"),kie=a("strong"),Pvo=o("fsmt"),Bvo=o(" \u2014 "),fq=a("a"),Ivo=o("FSMTModel"),Nvo=o(" (FairSeq Machine-Translation model)"),qvo=l(),Ds=a("li"),Sie=a("strong"),jvo=o("funnel"),Dvo=o(" \u2014 "),mq=a("a"),Gvo=o("FunnelModel"),Ovo=o(" or "),gq=a("a"),Vvo=o("FunnelBaseModel"),Xvo=o(" (Funnel Transformer model)"),zvo=l(),nu=a("li"),Rie=a("strong"),Wvo=o("glpn"),Qvo=o(" \u2014 "),hq=a("a"),Hvo=o("GLPNModel"),Uvo=o(" (GLPN model)"),Jvo=l(),su=a("li"),Pie=a("strong"),Yvo=o("gpt2"),Kvo=o(" \u2014 "),pq=a("a"),Zvo=o("GPT2Model"),e3o=o(" (OpenAI GPT-2 model)"),o3o=l(),lu=a("li"),Bie=a("strong"),r3o=o("gpt_neo"),t3o=o(" \u2014 "),uq=a("a"),a3o=o("GPTNeoModel"),n3o=o(" (GPT Neo model)"),s3o=l(),iu=a("li"),Iie=a("strong"),l3o=o("gpt_neox"),i3o=o(" \u2014 "),_q=a("a"),d3o=o("GPTNeoXModel"),c3o=o(" (GPT NeoX model)"),f3o=l(),du=a("li"),Nie=a("strong"),m3o=o("gptj"),g3o=o(" \u2014 "),bq=a("a"),h3o=o("GPTJModel"),p3o=o(" (GPT-J model)"),u3o=l(),cu=a("li"),qie=a("strong"),_3o=o("hubert"),b3o=o(" \u2014 "),vq=a("a"),v3o=o("HubertModel"),F3o=o(" (Hubert model)"),T3o=l(),fu=a("li"),jie=a("strong"),M3o=o("ibert"),E3o=o(" \u2014 "),Fq=a("a"),C3o=o("IBertModel"),w3o=o(" (I-BERT model)"),A3o=l(),mu=a("li"),Die=a("strong"),y3o=o("imagegpt"),L3o=o(" \u2014 "),Tq=a("a"),x3o=o("ImageGPTModel"),$3o=o(" (ImageGPT model)"),k3o=l(),gu=a("li"),Gie=a("strong"),S3o=o("layoutlm"),R3o=o(" \u2014 "),Mq=a("a"),P3o=o("LayoutLMModel"),B3o=o(" (LayoutLM model)"),I3o=l(),hu=a("li"),Oie=a("strong"),N3o=o("layoutlmv2"),q3o=o(" \u2014 "),Eq=a("a"),j3o=o("LayoutLMv2Model"),D3o=o(" (LayoutLMv2 model)"),G3o=l(),pu=a("li"),Vie=a("strong"),O3o=o("layoutlmv3"),V3o=o(" \u2014 "),Cq=a("a"),X3o=o("LayoutLMv3Model"),z3o=o(" (LayoutLMv3 model)"),W3o=l(),uu=a("li"),Xie=a("strong"),Q3o=o("led"),H3o=o(" \u2014 "),wq=a("a"),U3o=o("LEDModel"),J3o=o(" (LED model)"),Y3o=l(),_u=a("li"),zie=a("strong"),K3o=o("levit"),Z3o=o(" \u2014 "),Aq=a("a"),eFo=o("LevitModel"),oFo=o(" (LeViT model)"),rFo=l(),bu=a("li"),Wie=a("strong"),tFo=o("longformer"),aFo=o(" \u2014 "),yq=a("a"),nFo=o("LongformerModel"),sFo=o(" (Longformer model)"),lFo=l(),vu=a("li"),Qie=a("strong"),iFo=o("luke"),dFo=o(" \u2014 "),Lq=a("a"),cFo=o("LukeModel"),fFo=o(" (LUKE model)"),mFo=l(),Fu=a("li"),Hie=a("strong"),gFo=o("lxmert"),hFo=o(" \u2014 "),xq=a("a"),pFo=o("LxmertModel"),uFo=o(" (LXMERT model)"),_Fo=l(),Tu=a("li"),Uie=a("strong"),bFo=o("m2m_100"),vFo=o(" \u2014 "),$q=a("a"),FFo=o("M2M100Model"),TFo=o(" (M2M100 model)"),MFo=l(),Mu=a("li"),Jie=a("strong"),EFo=o("marian"),CFo=o(" \u2014 "),kq=a("a"),wFo=o("MarianModel"),AFo=o(" (Marian model)"),yFo=l(),Eu=a("li"),Yie=a("strong"),LFo=o("maskformer"),xFo=o(" \u2014 "),Sq=a("a"),$Fo=o("MaskFormerModel"),kFo=o(" (MaskFormer model)"),SFo=l(),Cu=a("li"),Kie=a("strong"),RFo=o("mbart"),PFo=o(" \u2014 "),Rq=a("a"),BFo=o("MBartModel"),IFo=o(" (mBART model)"),NFo=l(),wu=a("li"),Zie=a("strong"),qFo=o("mctct"),jFo=o(" \u2014 "),Pq=a("a"),DFo=o("MCTCTModel"),GFo=o(" (M-CTC-T model)"),OFo=l(),Au=a("li"),ede=a("strong"),VFo=o("megatron-bert"),XFo=o(" \u2014 "),Bq=a("a"),zFo=o("MegatronBertModel"),WFo=o(" (Megatron-BERT model)"),QFo=l(),yu=a("li"),ode=a("strong"),HFo=o("mobilebert"),UFo=o(" \u2014 "),Iq=a("a"),JFo=o("MobileBertModel"),YFo=o(" (MobileBERT model)"),KFo=l(),Lu=a("li"),rde=a("strong"),ZFo=o("mpnet"),e6o=o(" \u2014 "),Nq=a("a"),o6o=o("MPNetModel"),r6o=o(" (MPNet model)"),t6o=l(),xu=a("li"),tde=a("strong"),a6o=o("mt5"),n6o=o(" \u2014 "),qq=a("a"),s6o=o("MT5Model"),l6o=o(" (MT5 model)"),i6o=l(),$u=a("li"),ade=a("strong"),d6o=o("nystromformer"),c6o=o(" \u2014 "),jq=a("a"),f6o=o("NystromformerModel"),m6o=o(" (Nystr\xF6mformer model)"),g6o=l(),ku=a("li"),nde=a("strong"),h6o=o("openai-gpt"),p6o=o(" \u2014 "),Dq=a("a"),u6o=o("OpenAIGPTModel"),_6o=o(" (OpenAI GPT model)"),b6o=l(),Su=a("li"),sde=a("strong"),v6o=o("opt"),F6o=o(" \u2014 "),Gq=a("a"),T6o=o("OPTModel"),M6o=o(" (OPT model)"),E6o=l(),Ru=a("li"),lde=a("strong"),C6o=o("pegasus"),w6o=o(" \u2014 "),Oq=a("a"),A6o=o("PegasusModel"),y6o=o(" (Pegasus model)"),L6o=l(),Pu=a("li"),ide=a("strong"),x6o=o("perceiver"),$6o=o(" \u2014 "),Vq=a("a"),k6o=o("PerceiverModel"),S6o=o(" (Perceiver model)"),R6o=l(),Bu=a("li"),dde=a("strong"),P6o=o("plbart"),B6o=o(" \u2014 "),Xq=a("a"),I6o=o("PLBartModel"),N6o=o(" (PLBart model)"),q6o=l(),Iu=a("li"),cde=a("strong"),j6o=o("poolformer"),D6o=o(" \u2014 "),zq=a("a"),G6o=o("PoolFormerModel"),O6o=o(" (PoolFormer model)"),V6o=l(),Nu=a("li"),fde=a("strong"),X6o=o("prophetnet"),z6o=o(" \u2014 "),Wq=a("a"),W6o=o("ProphetNetModel"),Q6o=o(" (ProphetNet model)"),H6o=l(),qu=a("li"),mde=a("strong"),U6o=o("qdqbert"),J6o=o(" \u2014 "),Qq=a("a"),Y6o=o("QDQBertModel"),K6o=o(" (QDQBert model)"),Z6o=l(),ju=a("li"),gde=a("strong"),eTo=o("reformer"),oTo=o(" \u2014 "),Hq=a("a"),rTo=o("ReformerModel"),tTo=o(" (Reformer model)"),aTo=l(),Du=a("li"),hde=a("strong"),nTo=o("regnet"),sTo=o(" \u2014 "),Uq=a("a"),lTo=o("RegNetModel"),iTo=o(" (RegNet model)"),dTo=l(),Gu=a("li"),pde=a("strong"),cTo=o("rembert"),fTo=o(" \u2014 "),Jq=a("a"),mTo=o("RemBertModel"),gTo=o(" (RemBERT model)"),hTo=l(),Ou=a("li"),ude=a("strong"),pTo=o("resnet"),uTo=o(" \u2014 "),Yq=a("a"),_To=o("ResNetModel"),bTo=o(" (ResNet model)"),vTo=l(),Vu=a("li"),_de=a("strong"),FTo=o("retribert"),TTo=o(" \u2014 "),Kq=a("a"),MTo=o("RetriBertModel"),ETo=o(" (RetriBERT model)"),CTo=l(),Xu=a("li"),bde=a("strong"),wTo=o("roberta"),ATo=o(" \u2014 "),Zq=a("a"),yTo=o("RobertaModel"),LTo=o(" (RoBERTa model)"),xTo=l(),zu=a("li"),vde=a("strong"),$To=o("roformer"),kTo=o(" \u2014 "),ej=a("a"),STo=o("RoFormerModel"),RTo=o(" (RoFormer model)"),PTo=l(),Wu=a("li"),Fde=a("strong"),BTo=o("segformer"),ITo=o(" \u2014 "),oj=a("a"),NTo=o("SegformerModel"),qTo=o(" (SegFormer model)"),jTo=l(),Qu=a("li"),Tde=a("strong"),DTo=o("sew"),GTo=o(" \u2014 "),rj=a("a"),OTo=o("SEWModel"),VTo=o(" (SEW model)"),XTo=l(),Hu=a("li"),Mde=a("strong"),zTo=o("sew-d"),WTo=o(" \u2014 "),tj=a("a"),QTo=o("SEWDModel"),HTo=o(" (SEW-D model)"),UTo=l(),Uu=a("li"),Ede=a("strong"),JTo=o("speech_to_text"),YTo=o(" \u2014 "),aj=a("a"),KTo=o("Speech2TextModel"),ZTo=o(" (Speech2Text model)"),e7o=l(),Ju=a("li"),Cde=a("strong"),o7o=o("splinter"),r7o=o(" \u2014 "),nj=a("a"),t7o=o("SplinterModel"),a7o=o(" (Splinter model)"),n7o=l(),Yu=a("li"),wde=a("strong"),s7o=o("squeezebert"),l7o=o(" \u2014 "),sj=a("a"),i7o=o("SqueezeBertModel"),d7o=o(" (SqueezeBERT model)"),c7o=l(),Ku=a("li"),Ade=a("strong"),f7o=o("swin"),m7o=o(" \u2014 "),lj=a("a"),g7o=o("SwinModel"),h7o=o(" (Swin Transformer model)"),p7o=l(),Zu=a("li"),yde=a("strong"),u7o=o("t5"),_7o=o(" \u2014 "),ij=a("a"),b7o=o("T5Model"),v7o=o(" (T5 model)"),F7o=l(),e_=a("li"),Lde=a("strong"),T7o=o("tapas"),M7o=o(" \u2014 "),dj=a("a"),E7o=o("TapasModel"),C7o=o(" (TAPAS model)"),w7o=l(),o_=a("li"),xde=a("strong"),A7o=o("trajectory_transformer"),y7o=o(" \u2014 "),cj=a("a"),L7o=o("TrajectoryTransformerModel"),x7o=o(" (Trajectory Transformer model)"),$7o=l(),r_=a("li"),$de=a("strong"),k7o=o("transfo-xl"),S7o=o(" \u2014 "),fj=a("a"),R7o=o("TransfoXLModel"),P7o=o(" (Transformer-XL model)"),B7o=l(),t_=a("li"),kde=a("strong"),I7o=o("unispeech"),N7o=o(" \u2014 "),mj=a("a"),q7o=o("UniSpeechModel"),j7o=o(" (UniSpeech model)"),D7o=l(),a_=a("li"),Sde=a("strong"),G7o=o("unispeech-sat"),O7o=o(" \u2014 "),gj=a("a"),V7o=o("UniSpeechSatModel"),X7o=o(" (UniSpeechSat model)"),z7o=l(),n_=a("li"),Rde=a("strong"),W7o=o("van"),Q7o=o(" \u2014 "),hj=a("a"),H7o=o("VanModel"),U7o=o(" (VAN model)"),J7o=l(),s_=a("li"),Pde=a("strong"),Y7o=o("vilt"),K7o=o(" \u2014 "),pj=a("a"),Z7o=o("ViltModel"),e9o=o(" (ViLT model)"),o9o=l(),l_=a("li"),Bde=a("strong"),r9o=o("vision-text-dual-encoder"),t9o=o(" \u2014 "),uj=a("a"),a9o=o("VisionTextDualEncoderModel"),n9o=o(" (VisionTextDualEncoder model)"),s9o=l(),i_=a("li"),Ide=a("strong"),l9o=o("visual_bert"),i9o=o(" \u2014 "),_j=a("a"),d9o=o("VisualBertModel"),c9o=o(" (VisualBERT model)"),f9o=l(),d_=a("li"),Nde=a("strong"),m9o=o("vit"),g9o=o(" \u2014 "),bj=a("a"),h9o=o("ViTModel"),p9o=o(" (ViT model)"),u9o=l(),c_=a("li"),qde=a("strong"),_9o=o("vit_mae"),b9o=o(" \u2014 "),vj=a("a"),v9o=o("ViTMAEModel"),F9o=o(" (ViTMAE model)"),T9o=l(),f_=a("li"),jde=a("strong"),M9o=o("wav2vec2"),E9o=o(" \u2014 "),Fj=a("a"),C9o=o("Wav2Vec2Model"),w9o=o(" (Wav2Vec2 model)"),A9o=l(),m_=a("li"),Dde=a("strong"),y9o=o("wav2vec2-conformer"),L9o=o(" \u2014 "),Tj=a("a"),x9o=o("Wav2Vec2ConformerModel"),$9o=o(" (Wav2Vec2-Conformer model)"),k9o=l(),g_=a("li"),Gde=a("strong"),S9o=o("wavlm"),R9o=o(" \u2014 "),Mj=a("a"),P9o=o("WavLMModel"),B9o=o(" (WavLM model)"),I9o=l(),h_=a("li"),Ode=a("strong"),N9o=o("xglm"),q9o=o(" \u2014 "),Ej=a("a"),j9o=o("XGLMModel"),D9o=o(" (XGLM model)"),G9o=l(),p_=a("li"),Vde=a("strong"),O9o=o("xlm"),V9o=o(" \u2014 "),Cj=a("a"),X9o=o("XLMModel"),z9o=o(" (XLM model)"),W9o=l(),u_=a("li"),Xde=a("strong"),Q9o=o("xlm-prophetnet"),H9o=o(" \u2014 "),wj=a("a"),U9o=o("XLMProphetNetModel"),J9o=o(" (XLM-ProphetNet model)"),Y9o=l(),__=a("li"),zde=a("strong"),K9o=o("xlm-roberta"),Z9o=o(" \u2014 "),Aj=a("a"),eMo=o("XLMRobertaModel"),oMo=o(" (XLM-RoBERTa model)"),rMo=l(),b_=a("li"),Wde=a("strong"),tMo=o("xlm-roberta-xl"),aMo=o(" \u2014 "),yj=a("a"),nMo=o("XLMRobertaXLModel"),sMo=o(" (XLM-RoBERTa-XL model)"),lMo=l(),v_=a("li"),Qde=a("strong"),iMo=o("xlnet"),dMo=o(" \u2014 "),Lj=a("a"),cMo=o("XLNetModel"),fMo=o(" (XLNet model)"),mMo=l(),F_=a("li"),Hde=a("strong"),gMo=o("yolos"),hMo=o(" \u2014 "),xj=a("a"),pMo=o("YolosModel"),uMo=o(" (YOLOS model)"),_Mo=l(),T_=a("li"),Ude=a("strong"),bMo=o("yoso"),vMo=o(" \u2014 "),$j=a("a"),FMo=o("YosoModel"),TMo=o(" (YOSO model)"),MMo=l(),M_=a("p"),EMo=o("The model is set in evaluation mode by default using "),Jde=a("code"),CMo=o("model.eval()"),wMo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yde=a("code"),AMo=o("model.train()"),yMo=l(),F(E_.$$.fragment),qDe=l(),Ii=a("h2"),C_=a("a"),Kde=a("span"),F(VA.$$.fragment),LMo=l(),Zde=a("span"),xMo=o("AutoModelForPreTraining"),jDe=l(),$o=a("div"),F(XA.$$.fragment),$Mo=l(),Ni=a("p"),kMo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kj=a("a"),SMo=o("from_pretrained()"),RMo=o(" class method or the "),Sj=a("a"),PMo=o("from_config()"),BMo=o(` class
method.`),IMo=l(),zA=a("p"),NMo=o("This class cannot be instantiated directly using "),ece=a("code"),qMo=o("__init__()"),jMo=o(" (throws an error)."),DMo=l(),st=a("div"),F(WA.$$.fragment),GMo=l(),oce=a("p"),OMo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),VMo=l(),qi=a("p"),XMo=o(`Note:
Loading a model from its configuration file does `),rce=a("strong"),zMo=o("not"),WMo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rj=a("a"),QMo=o("from_pretrained()"),HMo=o(" to load the model weights."),UMo=l(),F(w_.$$.fragment),JMo=l(),Ye=a("div"),F(QA.$$.fragment),YMo=l(),tce=a("p"),KMo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZMo=l(),Ra=a("p"),e4o=o("The model class to instantiate is selected based on the "),ace=a("code"),o4o=o("model_type"),r4o=o(` property of the config object (either
passed as an argument or loaded from `),nce=a("code"),t4o=o("pretrained_model_name_or_path"),a4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sce=a("code"),n4o=o("pretrained_model_name_or_path"),s4o=o(":"),l4o=l(),G=a("ul"),A_=a("li"),lce=a("strong"),i4o=o("albert"),d4o=o(" \u2014 "),Pj=a("a"),c4o=o("AlbertForPreTraining"),f4o=o(" (ALBERT model)"),m4o=l(),y_=a("li"),ice=a("strong"),g4o=o("bart"),h4o=o(" \u2014 "),Bj=a("a"),p4o=o("BartForConditionalGeneration"),u4o=o(" (BART model)"),_4o=l(),L_=a("li"),dce=a("strong"),b4o=o("bert"),v4o=o(" \u2014 "),Ij=a("a"),F4o=o("BertForPreTraining"),T4o=o(" (BERT model)"),M4o=l(),x_=a("li"),cce=a("strong"),E4o=o("big_bird"),C4o=o(" \u2014 "),Nj=a("a"),w4o=o("BigBirdForPreTraining"),A4o=o(" (BigBird model)"),y4o=l(),$_=a("li"),fce=a("strong"),L4o=o("bloom"),x4o=o(" \u2014 "),qj=a("a"),$4o=o("BloomForCausalLM"),k4o=o(" (BLOOM model)"),S4o=l(),k_=a("li"),mce=a("strong"),R4o=o("camembert"),P4o=o(" \u2014 "),jj=a("a"),B4o=o("CamembertForMaskedLM"),I4o=o(" (CamemBERT model)"),N4o=l(),S_=a("li"),gce=a("strong"),q4o=o("ctrl"),j4o=o(" \u2014 "),Dj=a("a"),D4o=o("CTRLLMHeadModel"),G4o=o(" (CTRL model)"),O4o=l(),R_=a("li"),hce=a("strong"),V4o=o("data2vec-text"),X4o=o(" \u2014 "),Gj=a("a"),z4o=o("Data2VecTextForMaskedLM"),W4o=o(" (Data2VecText model)"),Q4o=l(),P_=a("li"),pce=a("strong"),H4o=o("deberta"),U4o=o(" \u2014 "),Oj=a("a"),J4o=o("DebertaForMaskedLM"),Y4o=o(" (DeBERTa model)"),K4o=l(),B_=a("li"),uce=a("strong"),Z4o=o("deberta-v2"),eEo=o(" \u2014 "),Vj=a("a"),oEo=o("DebertaV2ForMaskedLM"),rEo=o(" (DeBERTa-v2 model)"),tEo=l(),I_=a("li"),_ce=a("strong"),aEo=o("distilbert"),nEo=o(" \u2014 "),Xj=a("a"),sEo=o("DistilBertForMaskedLM"),lEo=o(" (DistilBERT model)"),iEo=l(),N_=a("li"),bce=a("strong"),dEo=o("electra"),cEo=o(" \u2014 "),zj=a("a"),fEo=o("ElectraForPreTraining"),mEo=o(" (ELECTRA model)"),gEo=l(),q_=a("li"),vce=a("strong"),hEo=o("flaubert"),pEo=o(" \u2014 "),Wj=a("a"),uEo=o("FlaubertWithLMHeadModel"),_Eo=o(" (FlauBERT model)"),bEo=l(),j_=a("li"),Fce=a("strong"),vEo=o("flava"),FEo=o(" \u2014 "),Qj=a("a"),TEo=o("FlavaForPreTraining"),MEo=o(" (FLAVA model)"),EEo=l(),D_=a("li"),Tce=a("strong"),CEo=o("fnet"),wEo=o(" \u2014 "),Hj=a("a"),AEo=o("FNetForPreTraining"),yEo=o(" (FNet model)"),LEo=l(),G_=a("li"),Mce=a("strong"),xEo=o("fsmt"),$Eo=o(" \u2014 "),Uj=a("a"),kEo=o("FSMTForConditionalGeneration"),SEo=o(" (FairSeq Machine-Translation model)"),REo=l(),O_=a("li"),Ece=a("strong"),PEo=o("funnel"),BEo=o(" \u2014 "),Jj=a("a"),IEo=o("FunnelForPreTraining"),NEo=o(" (Funnel Transformer model)"),qEo=l(),V_=a("li"),Cce=a("strong"),jEo=o("gpt2"),DEo=o(" \u2014 "),Yj=a("a"),GEo=o("GPT2LMHeadModel"),OEo=o(" (OpenAI GPT-2 model)"),VEo=l(),X_=a("li"),wce=a("strong"),XEo=o("ibert"),zEo=o(" \u2014 "),Kj=a("a"),WEo=o("IBertForMaskedLM"),QEo=o(" (I-BERT model)"),HEo=l(),z_=a("li"),Ace=a("strong"),UEo=o("layoutlm"),JEo=o(" \u2014 "),Zj=a("a"),YEo=o("LayoutLMForMaskedLM"),KEo=o(" (LayoutLM model)"),ZEo=l(),W_=a("li"),yce=a("strong"),eCo=o("longformer"),oCo=o(" \u2014 "),eD=a("a"),rCo=o("LongformerForMaskedLM"),tCo=o(" (Longformer model)"),aCo=l(),Q_=a("li"),Lce=a("strong"),nCo=o("lxmert"),sCo=o(" \u2014 "),oD=a("a"),lCo=o("LxmertForPreTraining"),iCo=o(" (LXMERT model)"),dCo=l(),H_=a("li"),xce=a("strong"),cCo=o("megatron-bert"),fCo=o(" \u2014 "),rD=a("a"),mCo=o("MegatronBertForPreTraining"),gCo=o(" (Megatron-BERT model)"),hCo=l(),U_=a("li"),$ce=a("strong"),pCo=o("mobilebert"),uCo=o(" \u2014 "),tD=a("a"),_Co=o("MobileBertForPreTraining"),bCo=o(" (MobileBERT model)"),vCo=l(),J_=a("li"),kce=a("strong"),FCo=o("mpnet"),TCo=o(" \u2014 "),aD=a("a"),MCo=o("MPNetForMaskedLM"),ECo=o(" (MPNet model)"),CCo=l(),Y_=a("li"),Sce=a("strong"),wCo=o("openai-gpt"),ACo=o(" \u2014 "),nD=a("a"),yCo=o("OpenAIGPTLMHeadModel"),LCo=o(" (OpenAI GPT model)"),xCo=l(),K_=a("li"),Rce=a("strong"),$Co=o("retribert"),kCo=o(" \u2014 "),sD=a("a"),SCo=o("RetriBertModel"),RCo=o(" (RetriBERT model)"),PCo=l(),Z_=a("li"),Pce=a("strong"),BCo=o("roberta"),ICo=o(" \u2014 "),lD=a("a"),NCo=o("RobertaForMaskedLM"),qCo=o(" (RoBERTa model)"),jCo=l(),e1=a("li"),Bce=a("strong"),DCo=o("splinter"),GCo=o(" \u2014 "),iD=a("a"),OCo=o("SplinterForPreTraining"),VCo=o(" (Splinter model)"),XCo=l(),o1=a("li"),Ice=a("strong"),zCo=o("squeezebert"),WCo=o(" \u2014 "),dD=a("a"),QCo=o("SqueezeBertForMaskedLM"),HCo=o(" (SqueezeBERT model)"),UCo=l(),r1=a("li"),Nce=a("strong"),JCo=o("t5"),YCo=o(" \u2014 "),cD=a("a"),KCo=o("T5ForConditionalGeneration"),ZCo=o(" (T5 model)"),e5o=l(),t1=a("li"),qce=a("strong"),o5o=o("tapas"),r5o=o(" \u2014 "),fD=a("a"),t5o=o("TapasForMaskedLM"),a5o=o(" (TAPAS model)"),n5o=l(),a1=a("li"),jce=a("strong"),s5o=o("transfo-xl"),l5o=o(" \u2014 "),mD=a("a"),i5o=o("TransfoXLLMHeadModel"),d5o=o(" (Transformer-XL model)"),c5o=l(),n1=a("li"),Dce=a("strong"),f5o=o("unispeech"),m5o=o(" \u2014 "),gD=a("a"),g5o=o("UniSpeechForPreTraining"),h5o=o(" (UniSpeech model)"),p5o=l(),s1=a("li"),Gce=a("strong"),u5o=o("unispeech-sat"),_5o=o(" \u2014 "),hD=a("a"),b5o=o("UniSpeechSatForPreTraining"),v5o=o(" (UniSpeechSat model)"),F5o=l(),l1=a("li"),Oce=a("strong"),T5o=o("visual_bert"),M5o=o(" \u2014 "),pD=a("a"),E5o=o("VisualBertForPreTraining"),C5o=o(" (VisualBERT model)"),w5o=l(),i1=a("li"),Vce=a("strong"),A5o=o("vit_mae"),y5o=o(" \u2014 "),uD=a("a"),L5o=o("ViTMAEForPreTraining"),x5o=o(" (ViTMAE model)"),$5o=l(),d1=a("li"),Xce=a("strong"),k5o=o("wav2vec2"),S5o=o(" \u2014 "),_D=a("a"),R5o=o("Wav2Vec2ForPreTraining"),P5o=o(" (Wav2Vec2 model)"),B5o=l(),c1=a("li"),zce=a("strong"),I5o=o("wav2vec2-conformer"),N5o=o(" \u2014 "),bD=a("a"),q5o=o("Wav2Vec2ConformerForPreTraining"),j5o=o(" (Wav2Vec2-Conformer model)"),D5o=l(),f1=a("li"),Wce=a("strong"),G5o=o("xlm"),O5o=o(" \u2014 "),vD=a("a"),V5o=o("XLMWithLMHeadModel"),X5o=o(" (XLM model)"),z5o=l(),m1=a("li"),Qce=a("strong"),W5o=o("xlm-roberta"),Q5o=o(" \u2014 "),FD=a("a"),H5o=o("XLMRobertaForMaskedLM"),U5o=o(" (XLM-RoBERTa model)"),J5o=l(),g1=a("li"),Hce=a("strong"),Y5o=o("xlm-roberta-xl"),K5o=o(" \u2014 "),TD=a("a"),Z5o=o("XLMRobertaXLForMaskedLM"),e0o=o(" (XLM-RoBERTa-XL model)"),o0o=l(),h1=a("li"),Uce=a("strong"),r0o=o("xlnet"),t0o=o(" \u2014 "),MD=a("a"),a0o=o("XLNetLMHeadModel"),n0o=o(" (XLNet model)"),s0o=l(),p1=a("p"),l0o=o("The model is set in evaluation mode by default using "),Jce=a("code"),i0o=o("model.eval()"),d0o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yce=a("code"),c0o=o("model.train()"),f0o=l(),F(u1.$$.fragment),DDe=l(),ji=a("h2"),_1=a("a"),Kce=a("span"),F(HA.$$.fragment),m0o=l(),Zce=a("span"),g0o=o("AutoModelForCausalLM"),GDe=l(),ko=a("div"),F(UA.$$.fragment),h0o=l(),Di=a("p"),p0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ED=a("a"),u0o=o("from_pretrained()"),_0o=o(" class method or the "),CD=a("a"),b0o=o("from_config()"),v0o=o(` class
method.`),F0o=l(),JA=a("p"),T0o=o("This class cannot be instantiated directly using "),efe=a("code"),M0o=o("__init__()"),E0o=o(" (throws an error)."),C0o=l(),lt=a("div"),F(YA.$$.fragment),w0o=l(),ofe=a("p"),A0o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),y0o=l(),Gi=a("p"),L0o=o(`Note:
Loading a model from its configuration file does `),rfe=a("strong"),x0o=o("not"),$0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wD=a("a"),k0o=o("from_pretrained()"),S0o=o(" to load the model weights."),R0o=l(),F(b1.$$.fragment),P0o=l(),Ke=a("div"),F(KA.$$.fragment),B0o=l(),tfe=a("p"),I0o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),N0o=l(),Pa=a("p"),q0o=o("The model class to instantiate is selected based on the "),afe=a("code"),j0o=o("model_type"),D0o=o(` property of the config object (either
passed as an argument or loaded from `),nfe=a("code"),G0o=o("pretrained_model_name_or_path"),O0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sfe=a("code"),V0o=o("pretrained_model_name_or_path"),X0o=o(":"),z0o=l(),z=a("ul"),v1=a("li"),lfe=a("strong"),W0o=o("bart"),Q0o=o(" \u2014 "),AD=a("a"),H0o=o("BartForCausalLM"),U0o=o(" (BART model)"),J0o=l(),F1=a("li"),ife=a("strong"),Y0o=o("bert"),K0o=o(" \u2014 "),yD=a("a"),Z0o=o("BertLMHeadModel"),ewo=o(" (BERT model)"),owo=l(),T1=a("li"),dfe=a("strong"),rwo=o("bert-generation"),two=o(" \u2014 "),LD=a("a"),awo=o("BertGenerationDecoder"),nwo=o(" (Bert Generation model)"),swo=l(),M1=a("li"),cfe=a("strong"),lwo=o("big_bird"),iwo=o(" \u2014 "),xD=a("a"),dwo=o("BigBirdForCausalLM"),cwo=o(" (BigBird model)"),fwo=l(),E1=a("li"),ffe=a("strong"),mwo=o("bigbird_pegasus"),gwo=o(" \u2014 "),$D=a("a"),hwo=o("BigBirdPegasusForCausalLM"),pwo=o(" (BigBird-Pegasus model)"),uwo=l(),C1=a("li"),mfe=a("strong"),_wo=o("blenderbot"),bwo=o(" \u2014 "),kD=a("a"),vwo=o("BlenderbotForCausalLM"),Fwo=o(" (Blenderbot model)"),Two=l(),w1=a("li"),gfe=a("strong"),Mwo=o("blenderbot-small"),Ewo=o(" \u2014 "),SD=a("a"),Cwo=o("BlenderbotSmallForCausalLM"),wwo=o(" (BlenderbotSmall model)"),Awo=l(),A1=a("li"),hfe=a("strong"),ywo=o("bloom"),Lwo=o(" \u2014 "),RD=a("a"),xwo=o("BloomForCausalLM"),$wo=o(" (BLOOM model)"),kwo=l(),y1=a("li"),pfe=a("strong"),Swo=o("camembert"),Rwo=o(" \u2014 "),PD=a("a"),Pwo=o("CamembertForCausalLM"),Bwo=o(" (CamemBERT model)"),Iwo=l(),L1=a("li"),ufe=a("strong"),Nwo=o("ctrl"),qwo=o(" \u2014 "),BD=a("a"),jwo=o("CTRLLMHeadModel"),Dwo=o(" (CTRL model)"),Gwo=l(),x1=a("li"),_fe=a("strong"),Owo=o("data2vec-text"),Vwo=o(" \u2014 "),ID=a("a"),Xwo=o("Data2VecTextForCausalLM"),zwo=o(" (Data2VecText model)"),Wwo=l(),$1=a("li"),bfe=a("strong"),Qwo=o("electra"),Hwo=o(" \u2014 "),ND=a("a"),Uwo=o("ElectraForCausalLM"),Jwo=o(" (ELECTRA model)"),Ywo=l(),k1=a("li"),vfe=a("strong"),Kwo=o("gpt2"),Zwo=o(" \u2014 "),qD=a("a"),eAo=o("GPT2LMHeadModel"),oAo=o(" (OpenAI GPT-2 model)"),rAo=l(),S1=a("li"),Ffe=a("strong"),tAo=o("gpt_neo"),aAo=o(" \u2014 "),jD=a("a"),nAo=o("GPTNeoForCausalLM"),sAo=o(" (GPT Neo model)"),lAo=l(),R1=a("li"),Tfe=a("strong"),iAo=o("gpt_neox"),dAo=o(" \u2014 "),DD=a("a"),cAo=o("GPTNeoXForCausalLM"),fAo=o(" (GPT NeoX model)"),mAo=l(),P1=a("li"),Mfe=a("strong"),gAo=o("gptj"),hAo=o(" \u2014 "),GD=a("a"),pAo=o("GPTJForCausalLM"),uAo=o(" (GPT-J model)"),_Ao=l(),B1=a("li"),Efe=a("strong"),bAo=o("marian"),vAo=o(" \u2014 "),OD=a("a"),FAo=o("MarianForCausalLM"),TAo=o(" (Marian model)"),MAo=l(),I1=a("li"),Cfe=a("strong"),EAo=o("mbart"),CAo=o(" \u2014 "),VD=a("a"),wAo=o("MBartForCausalLM"),AAo=o(" (mBART model)"),yAo=l(),N1=a("li"),wfe=a("strong"),LAo=o("megatron-bert"),xAo=o(" \u2014 "),XD=a("a"),$Ao=o("MegatronBertForCausalLM"),kAo=o(" (Megatron-BERT model)"),SAo=l(),q1=a("li"),Afe=a("strong"),RAo=o("openai-gpt"),PAo=o(" \u2014 "),zD=a("a"),BAo=o("OpenAIGPTLMHeadModel"),IAo=o(" (OpenAI GPT model)"),NAo=l(),j1=a("li"),yfe=a("strong"),qAo=o("opt"),jAo=o(" \u2014 "),WD=a("a"),DAo=o("OPTForCausalLM"),GAo=o(" (OPT model)"),OAo=l(),D1=a("li"),Lfe=a("strong"),VAo=o("pegasus"),XAo=o(" \u2014 "),QD=a("a"),zAo=o("PegasusForCausalLM"),WAo=o(" (Pegasus model)"),QAo=l(),G1=a("li"),xfe=a("strong"),HAo=o("plbart"),UAo=o(" \u2014 "),HD=a("a"),JAo=o("PLBartForCausalLM"),YAo=o(" (PLBart model)"),KAo=l(),O1=a("li"),$fe=a("strong"),ZAo=o("prophetnet"),eyo=o(" \u2014 "),UD=a("a"),oyo=o("ProphetNetForCausalLM"),ryo=o(" (ProphetNet model)"),tyo=l(),V1=a("li"),kfe=a("strong"),ayo=o("qdqbert"),nyo=o(" \u2014 "),JD=a("a"),syo=o("QDQBertLMHeadModel"),lyo=o(" (QDQBert model)"),iyo=l(),X1=a("li"),Sfe=a("strong"),dyo=o("reformer"),cyo=o(" \u2014 "),YD=a("a"),fyo=o("ReformerModelWithLMHead"),myo=o(" (Reformer model)"),gyo=l(),z1=a("li"),Rfe=a("strong"),hyo=o("rembert"),pyo=o(" \u2014 "),KD=a("a"),uyo=o("RemBertForCausalLM"),_yo=o(" (RemBERT model)"),byo=l(),W1=a("li"),Pfe=a("strong"),vyo=o("roberta"),Fyo=o(" \u2014 "),ZD=a("a"),Tyo=o("RobertaForCausalLM"),Myo=o(" (RoBERTa model)"),Eyo=l(),Q1=a("li"),Bfe=a("strong"),Cyo=o("roformer"),wyo=o(" \u2014 "),eG=a("a"),Ayo=o("RoFormerForCausalLM"),yyo=o(" (RoFormer model)"),Lyo=l(),H1=a("li"),Ife=a("strong"),xyo=o("speech_to_text_2"),$yo=o(" \u2014 "),oG=a("a"),kyo=o("Speech2Text2ForCausalLM"),Syo=o(" (Speech2Text2 model)"),Ryo=l(),U1=a("li"),Nfe=a("strong"),Pyo=o("transfo-xl"),Byo=o(" \u2014 "),rG=a("a"),Iyo=o("TransfoXLLMHeadModel"),Nyo=o(" (Transformer-XL model)"),qyo=l(),J1=a("li"),qfe=a("strong"),jyo=o("trocr"),Dyo=o(" \u2014 "),tG=a("a"),Gyo=o("TrOCRForCausalLM"),Oyo=o(" (TrOCR model)"),Vyo=l(),Y1=a("li"),jfe=a("strong"),Xyo=o("xglm"),zyo=o(" \u2014 "),aG=a("a"),Wyo=o("XGLMForCausalLM"),Qyo=o(" (XGLM model)"),Hyo=l(),K1=a("li"),Dfe=a("strong"),Uyo=o("xlm"),Jyo=o(" \u2014 "),nG=a("a"),Yyo=o("XLMWithLMHeadModel"),Kyo=o(" (XLM model)"),Zyo=l(),Z1=a("li"),Gfe=a("strong"),eLo=o("xlm-prophetnet"),oLo=o(" \u2014 "),sG=a("a"),rLo=o("XLMProphetNetForCausalLM"),tLo=o(" (XLM-ProphetNet model)"),aLo=l(),eb=a("li"),Ofe=a("strong"),nLo=o("xlm-roberta"),sLo=o(" \u2014 "),lG=a("a"),lLo=o("XLMRobertaForCausalLM"),iLo=o(" (XLM-RoBERTa model)"),dLo=l(),ob=a("li"),Vfe=a("strong"),cLo=o("xlm-roberta-xl"),fLo=o(" \u2014 "),iG=a("a"),mLo=o("XLMRobertaXLForCausalLM"),gLo=o(" (XLM-RoBERTa-XL model)"),hLo=l(),rb=a("li"),Xfe=a("strong"),pLo=o("xlnet"),uLo=o(" \u2014 "),dG=a("a"),_Lo=o("XLNetLMHeadModel"),bLo=o(" (XLNet model)"),vLo=l(),tb=a("p"),FLo=o("The model is set in evaluation mode by default using "),zfe=a("code"),TLo=o("model.eval()"),MLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wfe=a("code"),ELo=o("model.train()"),CLo=l(),F(ab.$$.fragment),ODe=l(),Oi=a("h2"),nb=a("a"),Qfe=a("span"),F(ZA.$$.fragment),wLo=l(),Hfe=a("span"),ALo=o("AutoModelForMaskedLM"),VDe=l(),So=a("div"),F(ey.$$.fragment),yLo=l(),Vi=a("p"),LLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cG=a("a"),xLo=o("from_pretrained()"),$Lo=o(" class method or the "),fG=a("a"),kLo=o("from_config()"),SLo=o(` class
method.`),RLo=l(),oy=a("p"),PLo=o("This class cannot be instantiated directly using "),Ufe=a("code"),BLo=o("__init__()"),ILo=o(" (throws an error)."),NLo=l(),it=a("div"),F(ry.$$.fragment),qLo=l(),Jfe=a("p"),jLo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),DLo=l(),Xi=a("p"),GLo=o(`Note:
Loading a model from its configuration file does `),Yfe=a("strong"),OLo=o("not"),VLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mG=a("a"),XLo=o("from_pretrained()"),zLo=o(" to load the model weights."),WLo=l(),F(sb.$$.fragment),QLo=l(),Ze=a("div"),F(ty.$$.fragment),HLo=l(),Kfe=a("p"),ULo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),JLo=l(),Ba=a("p"),YLo=o("The model class to instantiate is selected based on the "),Zfe=a("code"),KLo=o("model_type"),ZLo=o(` property of the config object (either
passed as an argument or loaded from `),eme=a("code"),e8o=o("pretrained_model_name_or_path"),o8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ome=a("code"),r8o=o("pretrained_model_name_or_path"),t8o=o(":"),a8o=l(),Q=a("ul"),lb=a("li"),rme=a("strong"),n8o=o("albert"),s8o=o(" \u2014 "),gG=a("a"),l8o=o("AlbertForMaskedLM"),i8o=o(" (ALBERT model)"),d8o=l(),ib=a("li"),tme=a("strong"),c8o=o("bart"),f8o=o(" \u2014 "),hG=a("a"),m8o=o("BartForConditionalGeneration"),g8o=o(" (BART model)"),h8o=l(),db=a("li"),ame=a("strong"),p8o=o("bert"),u8o=o(" \u2014 "),pG=a("a"),_8o=o("BertForMaskedLM"),b8o=o(" (BERT model)"),v8o=l(),cb=a("li"),nme=a("strong"),F8o=o("big_bird"),T8o=o(" \u2014 "),uG=a("a"),M8o=o("BigBirdForMaskedLM"),E8o=o(" (BigBird model)"),C8o=l(),fb=a("li"),sme=a("strong"),w8o=o("camembert"),A8o=o(" \u2014 "),_G=a("a"),y8o=o("CamembertForMaskedLM"),L8o=o(" (CamemBERT model)"),x8o=l(),mb=a("li"),lme=a("strong"),$8o=o("convbert"),k8o=o(" \u2014 "),bG=a("a"),S8o=o("ConvBertForMaskedLM"),R8o=o(" (ConvBERT model)"),P8o=l(),gb=a("li"),ime=a("strong"),B8o=o("data2vec-text"),I8o=o(" \u2014 "),vG=a("a"),N8o=o("Data2VecTextForMaskedLM"),q8o=o(" (Data2VecText model)"),j8o=l(),hb=a("li"),dme=a("strong"),D8o=o("deberta"),G8o=o(" \u2014 "),FG=a("a"),O8o=o("DebertaForMaskedLM"),V8o=o(" (DeBERTa model)"),X8o=l(),pb=a("li"),cme=a("strong"),z8o=o("deberta-v2"),W8o=o(" \u2014 "),TG=a("a"),Q8o=o("DebertaV2ForMaskedLM"),H8o=o(" (DeBERTa-v2 model)"),U8o=l(),ub=a("li"),fme=a("strong"),J8o=o("distilbert"),Y8o=o(" \u2014 "),MG=a("a"),K8o=o("DistilBertForMaskedLM"),Z8o=o(" (DistilBERT model)"),exo=l(),_b=a("li"),mme=a("strong"),oxo=o("electra"),rxo=o(" \u2014 "),EG=a("a"),txo=o("ElectraForMaskedLM"),axo=o(" (ELECTRA model)"),nxo=l(),bb=a("li"),gme=a("strong"),sxo=o("flaubert"),lxo=o(" \u2014 "),CG=a("a"),ixo=o("FlaubertWithLMHeadModel"),dxo=o(" (FlauBERT model)"),cxo=l(),vb=a("li"),hme=a("strong"),fxo=o("fnet"),mxo=o(" \u2014 "),wG=a("a"),gxo=o("FNetForMaskedLM"),hxo=o(" (FNet model)"),pxo=l(),Fb=a("li"),pme=a("strong"),uxo=o("funnel"),_xo=o(" \u2014 "),AG=a("a"),bxo=o("FunnelForMaskedLM"),vxo=o(" (Funnel Transformer model)"),Fxo=l(),Tb=a("li"),ume=a("strong"),Txo=o("ibert"),Mxo=o(" \u2014 "),yG=a("a"),Exo=o("IBertForMaskedLM"),Cxo=o(" (I-BERT model)"),wxo=l(),Mb=a("li"),_me=a("strong"),Axo=o("layoutlm"),yxo=o(" \u2014 "),LG=a("a"),Lxo=o("LayoutLMForMaskedLM"),xxo=o(" (LayoutLM model)"),$xo=l(),Eb=a("li"),bme=a("strong"),kxo=o("longformer"),Sxo=o(" \u2014 "),xG=a("a"),Rxo=o("LongformerForMaskedLM"),Pxo=o(" (Longformer model)"),Bxo=l(),Cb=a("li"),vme=a("strong"),Ixo=o("luke"),Nxo=o(" \u2014 "),$G=a("a"),qxo=o("LukeForMaskedLM"),jxo=o(" (LUKE model)"),Dxo=l(),wb=a("li"),Fme=a("strong"),Gxo=o("mbart"),Oxo=o(" \u2014 "),kG=a("a"),Vxo=o("MBartForConditionalGeneration"),Xxo=o(" (mBART model)"),zxo=l(),Ab=a("li"),Tme=a("strong"),Wxo=o("megatron-bert"),Qxo=o(" \u2014 "),SG=a("a"),Hxo=o("MegatronBertForMaskedLM"),Uxo=o(" (Megatron-BERT model)"),Jxo=l(),yb=a("li"),Mme=a("strong"),Yxo=o("mobilebert"),Kxo=o(" \u2014 "),RG=a("a"),Zxo=o("MobileBertForMaskedLM"),e$o=o(" (MobileBERT model)"),o$o=l(),Lb=a("li"),Eme=a("strong"),r$o=o("mpnet"),t$o=o(" \u2014 "),PG=a("a"),a$o=o("MPNetForMaskedLM"),n$o=o(" (MPNet model)"),s$o=l(),xb=a("li"),Cme=a("strong"),l$o=o("nystromformer"),i$o=o(" \u2014 "),BG=a("a"),d$o=o("NystromformerForMaskedLM"),c$o=o(" (Nystr\xF6mformer model)"),f$o=l(),$b=a("li"),wme=a("strong"),m$o=o("perceiver"),g$o=o(" \u2014 "),IG=a("a"),h$o=o("PerceiverForMaskedLM"),p$o=o(" (Perceiver model)"),u$o=l(),kb=a("li"),Ame=a("strong"),_$o=o("qdqbert"),b$o=o(" \u2014 "),NG=a("a"),v$o=o("QDQBertForMaskedLM"),F$o=o(" (QDQBert model)"),T$o=l(),Sb=a("li"),yme=a("strong"),M$o=o("reformer"),E$o=o(" \u2014 "),qG=a("a"),C$o=o("ReformerForMaskedLM"),w$o=o(" (Reformer model)"),A$o=l(),Rb=a("li"),Lme=a("strong"),y$o=o("rembert"),L$o=o(" \u2014 "),jG=a("a"),x$o=o("RemBertForMaskedLM"),$$o=o(" (RemBERT model)"),k$o=l(),Pb=a("li"),xme=a("strong"),S$o=o("roberta"),R$o=o(" \u2014 "),DG=a("a"),P$o=o("RobertaForMaskedLM"),B$o=o(" (RoBERTa model)"),I$o=l(),Bb=a("li"),$me=a("strong"),N$o=o("roformer"),q$o=o(" \u2014 "),GG=a("a"),j$o=o("RoFormerForMaskedLM"),D$o=o(" (RoFormer model)"),G$o=l(),Ib=a("li"),kme=a("strong"),O$o=o("squeezebert"),V$o=o(" \u2014 "),OG=a("a"),X$o=o("SqueezeBertForMaskedLM"),z$o=o(" (SqueezeBERT model)"),W$o=l(),Nb=a("li"),Sme=a("strong"),Q$o=o("tapas"),H$o=o(" \u2014 "),VG=a("a"),U$o=o("TapasForMaskedLM"),J$o=o(" (TAPAS model)"),Y$o=l(),qb=a("li"),Rme=a("strong"),K$o=o("wav2vec2"),Z$o=o(" \u2014 "),Pme=a("code"),eko=o("Wav2Vec2ForMaskedLM"),oko=o(" (Wav2Vec2 model)"),rko=l(),jb=a("li"),Bme=a("strong"),tko=o("xlm"),ako=o(" \u2014 "),XG=a("a"),nko=o("XLMWithLMHeadModel"),sko=o(" (XLM model)"),lko=l(),Db=a("li"),Ime=a("strong"),iko=o("xlm-roberta"),dko=o(" \u2014 "),zG=a("a"),cko=o("XLMRobertaForMaskedLM"),fko=o(" (XLM-RoBERTa model)"),mko=l(),Gb=a("li"),Nme=a("strong"),gko=o("xlm-roberta-xl"),hko=o(" \u2014 "),WG=a("a"),pko=o("XLMRobertaXLForMaskedLM"),uko=o(" (XLM-RoBERTa-XL model)"),_ko=l(),Ob=a("li"),qme=a("strong"),bko=o("yoso"),vko=o(" \u2014 "),QG=a("a"),Fko=o("YosoForMaskedLM"),Tko=o(" (YOSO model)"),Mko=l(),Vb=a("p"),Eko=o("The model is set in evaluation mode by default using "),jme=a("code"),Cko=o("model.eval()"),wko=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dme=a("code"),Ako=o("model.train()"),yko=l(),F(Xb.$$.fragment),XDe=l(),zi=a("h2"),zb=a("a"),Gme=a("span"),F(ay.$$.fragment),Lko=l(),Ome=a("span"),xko=o("AutoModelForSeq2SeqLM"),zDe=l(),Ro=a("div"),F(ny.$$.fragment),$ko=l(),Wi=a("p"),kko=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HG=a("a"),Sko=o("from_pretrained()"),Rko=o(" class method or the "),UG=a("a"),Pko=o("from_config()"),Bko=o(` class
method.`),Iko=l(),sy=a("p"),Nko=o("This class cannot be instantiated directly using "),Vme=a("code"),qko=o("__init__()"),jko=o(" (throws an error)."),Dko=l(),dt=a("div"),F(ly.$$.fragment),Gko=l(),Xme=a("p"),Oko=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Vko=l(),Qi=a("p"),Xko=o(`Note:
Loading a model from its configuration file does `),zme=a("strong"),zko=o("not"),Wko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JG=a("a"),Qko=o("from_pretrained()"),Hko=o(" to load the model weights."),Uko=l(),F(Wb.$$.fragment),Jko=l(),eo=a("div"),F(iy.$$.fragment),Yko=l(),Wme=a("p"),Kko=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Zko=l(),Ia=a("p"),eSo=o("The model class to instantiate is selected based on the "),Qme=a("code"),oSo=o("model_type"),rSo=o(` property of the config object (either
passed as an argument or loaded from `),Hme=a("code"),tSo=o("pretrained_model_name_or_path"),aSo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ume=a("code"),nSo=o("pretrained_model_name_or_path"),sSo=o(":"),lSo=l(),ue=a("ul"),Qb=a("li"),Jme=a("strong"),iSo=o("bart"),dSo=o(" \u2014 "),YG=a("a"),cSo=o("BartForConditionalGeneration"),fSo=o(" (BART model)"),mSo=l(),Hb=a("li"),Yme=a("strong"),gSo=o("bigbird_pegasus"),hSo=o(" \u2014 "),KG=a("a"),pSo=o("BigBirdPegasusForConditionalGeneration"),uSo=o(" (BigBird-Pegasus model)"),_So=l(),Ub=a("li"),Kme=a("strong"),bSo=o("blenderbot"),vSo=o(" \u2014 "),ZG=a("a"),FSo=o("BlenderbotForConditionalGeneration"),TSo=o(" (Blenderbot model)"),MSo=l(),Jb=a("li"),Zme=a("strong"),ESo=o("blenderbot-small"),CSo=o(" \u2014 "),eO=a("a"),wSo=o("BlenderbotSmallForConditionalGeneration"),ASo=o(" (BlenderbotSmall model)"),ySo=l(),Yb=a("li"),ege=a("strong"),LSo=o("encoder-decoder"),xSo=o(" \u2014 "),oO=a("a"),$So=o("EncoderDecoderModel"),kSo=o(" (Encoder decoder model)"),SSo=l(),Kb=a("li"),oge=a("strong"),RSo=o("fsmt"),PSo=o(" \u2014 "),rO=a("a"),BSo=o("FSMTForConditionalGeneration"),ISo=o(" (FairSeq Machine-Translation model)"),NSo=l(),Zb=a("li"),rge=a("strong"),qSo=o("led"),jSo=o(" \u2014 "),tO=a("a"),DSo=o("LEDForConditionalGeneration"),GSo=o(" (LED model)"),OSo=l(),e2=a("li"),tge=a("strong"),VSo=o("m2m_100"),XSo=o(" \u2014 "),aO=a("a"),zSo=o("M2M100ForConditionalGeneration"),WSo=o(" (M2M100 model)"),QSo=l(),o2=a("li"),age=a("strong"),HSo=o("marian"),USo=o(" \u2014 "),nO=a("a"),JSo=o("MarianMTModel"),YSo=o(" (Marian model)"),KSo=l(),r2=a("li"),nge=a("strong"),ZSo=o("mbart"),eRo=o(" \u2014 "),sO=a("a"),oRo=o("MBartForConditionalGeneration"),rRo=o(" (mBART model)"),tRo=l(),t2=a("li"),sge=a("strong"),aRo=o("mt5"),nRo=o(" \u2014 "),lO=a("a"),sRo=o("MT5ForConditionalGeneration"),lRo=o(" (MT5 model)"),iRo=l(),a2=a("li"),lge=a("strong"),dRo=o("pegasus"),cRo=o(" \u2014 "),iO=a("a"),fRo=o("PegasusForConditionalGeneration"),mRo=o(" (Pegasus model)"),gRo=l(),n2=a("li"),ige=a("strong"),hRo=o("plbart"),pRo=o(" \u2014 "),dO=a("a"),uRo=o("PLBartForConditionalGeneration"),_Ro=o(" (PLBart model)"),bRo=l(),s2=a("li"),dge=a("strong"),vRo=o("prophetnet"),FRo=o(" \u2014 "),cO=a("a"),TRo=o("ProphetNetForConditionalGeneration"),MRo=o(" (ProphetNet model)"),ERo=l(),l2=a("li"),cge=a("strong"),CRo=o("t5"),wRo=o(" \u2014 "),fO=a("a"),ARo=o("T5ForConditionalGeneration"),yRo=o(" (T5 model)"),LRo=l(),i2=a("li"),fge=a("strong"),xRo=o("xlm-prophetnet"),$Ro=o(" \u2014 "),mO=a("a"),kRo=o("XLMProphetNetForConditionalGeneration"),SRo=o(" (XLM-ProphetNet model)"),RRo=l(),d2=a("p"),PRo=o("The model is set in evaluation mode by default using "),mge=a("code"),BRo=o("model.eval()"),IRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gge=a("code"),NRo=o("model.train()"),qRo=l(),F(c2.$$.fragment),WDe=l(),Hi=a("h2"),f2=a("a"),hge=a("span"),F(dy.$$.fragment),jRo=l(),pge=a("span"),DRo=o("AutoModelForSequenceClassification"),QDe=l(),Po=a("div"),F(cy.$$.fragment),GRo=l(),Ui=a("p"),ORo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gO=a("a"),VRo=o("from_pretrained()"),XRo=o(" class method or the "),hO=a("a"),zRo=o("from_config()"),WRo=o(` class
method.`),QRo=l(),fy=a("p"),HRo=o("This class cannot be instantiated directly using "),uge=a("code"),URo=o("__init__()"),JRo=o(" (throws an error)."),YRo=l(),ct=a("div"),F(my.$$.fragment),KRo=l(),_ge=a("p"),ZRo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ePo=l(),Ji=a("p"),oPo=o(`Note:
Loading a model from its configuration file does `),bge=a("strong"),rPo=o("not"),tPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pO=a("a"),aPo=o("from_pretrained()"),nPo=o(" to load the model weights."),sPo=l(),F(m2.$$.fragment),lPo=l(),oo=a("div"),F(gy.$$.fragment),iPo=l(),vge=a("p"),dPo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cPo=l(),Na=a("p"),fPo=o("The model class to instantiate is selected based on the "),Fge=a("code"),mPo=o("model_type"),gPo=o(` property of the config object (either
passed as an argument or loaded from `),Tge=a("code"),hPo=o("pretrained_model_name_or_path"),pPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mge=a("code"),uPo=o("pretrained_model_name_or_path"),_Po=o(":"),bPo=l(),N=a("ul"),g2=a("li"),Ege=a("strong"),vPo=o("albert"),FPo=o(" \u2014 "),uO=a("a"),TPo=o("AlbertForSequenceClassification"),MPo=o(" (ALBERT model)"),EPo=l(),h2=a("li"),Cge=a("strong"),CPo=o("bart"),wPo=o(" \u2014 "),_O=a("a"),APo=o("BartForSequenceClassification"),yPo=o(" (BART model)"),LPo=l(),p2=a("li"),wge=a("strong"),xPo=o("bert"),$Po=o(" \u2014 "),bO=a("a"),kPo=o("BertForSequenceClassification"),SPo=o(" (BERT model)"),RPo=l(),u2=a("li"),Age=a("strong"),PPo=o("big_bird"),BPo=o(" \u2014 "),vO=a("a"),IPo=o("BigBirdForSequenceClassification"),NPo=o(" (BigBird model)"),qPo=l(),_2=a("li"),yge=a("strong"),jPo=o("bigbird_pegasus"),DPo=o(" \u2014 "),FO=a("a"),GPo=o("BigBirdPegasusForSequenceClassification"),OPo=o(" (BigBird-Pegasus model)"),VPo=l(),b2=a("li"),Lge=a("strong"),XPo=o("bloom"),zPo=o(" \u2014 "),TO=a("a"),WPo=o("BloomForSequenceClassification"),QPo=o(" (BLOOM model)"),HPo=l(),v2=a("li"),xge=a("strong"),UPo=o("camembert"),JPo=o(" \u2014 "),MO=a("a"),YPo=o("CamembertForSequenceClassification"),KPo=o(" (CamemBERT model)"),ZPo=l(),F2=a("li"),$ge=a("strong"),eBo=o("canine"),oBo=o(" \u2014 "),EO=a("a"),rBo=o("CanineForSequenceClassification"),tBo=o(" (CANINE model)"),aBo=l(),T2=a("li"),kge=a("strong"),nBo=o("convbert"),sBo=o(" \u2014 "),CO=a("a"),lBo=o("ConvBertForSequenceClassification"),iBo=o(" (ConvBERT model)"),dBo=l(),M2=a("li"),Sge=a("strong"),cBo=o("ctrl"),fBo=o(" \u2014 "),wO=a("a"),mBo=o("CTRLForSequenceClassification"),gBo=o(" (CTRL model)"),hBo=l(),E2=a("li"),Rge=a("strong"),pBo=o("data2vec-text"),uBo=o(" \u2014 "),AO=a("a"),_Bo=o("Data2VecTextForSequenceClassification"),bBo=o(" (Data2VecText model)"),vBo=l(),C2=a("li"),Pge=a("strong"),FBo=o("deberta"),TBo=o(" \u2014 "),yO=a("a"),MBo=o("DebertaForSequenceClassification"),EBo=o(" (DeBERTa model)"),CBo=l(),w2=a("li"),Bge=a("strong"),wBo=o("deberta-v2"),ABo=o(" \u2014 "),LO=a("a"),yBo=o("DebertaV2ForSequenceClassification"),LBo=o(" (DeBERTa-v2 model)"),xBo=l(),A2=a("li"),Ige=a("strong"),$Bo=o("distilbert"),kBo=o(" \u2014 "),xO=a("a"),SBo=o("DistilBertForSequenceClassification"),RBo=o(" (DistilBERT model)"),PBo=l(),y2=a("li"),Nge=a("strong"),BBo=o("electra"),IBo=o(" \u2014 "),$O=a("a"),NBo=o("ElectraForSequenceClassification"),qBo=o(" (ELECTRA model)"),jBo=l(),L2=a("li"),qge=a("strong"),DBo=o("flaubert"),GBo=o(" \u2014 "),kO=a("a"),OBo=o("FlaubertForSequenceClassification"),VBo=o(" (FlauBERT model)"),XBo=l(),x2=a("li"),jge=a("strong"),zBo=o("fnet"),WBo=o(" \u2014 "),SO=a("a"),QBo=o("FNetForSequenceClassification"),HBo=o(" (FNet model)"),UBo=l(),$2=a("li"),Dge=a("strong"),JBo=o("funnel"),YBo=o(" \u2014 "),RO=a("a"),KBo=o("FunnelForSequenceClassification"),ZBo=o(" (Funnel Transformer model)"),eIo=l(),k2=a("li"),Gge=a("strong"),oIo=o("gpt2"),rIo=o(" \u2014 "),PO=a("a"),tIo=o("GPT2ForSequenceClassification"),aIo=o(" (OpenAI GPT-2 model)"),nIo=l(),S2=a("li"),Oge=a("strong"),sIo=o("gpt_neo"),lIo=o(" \u2014 "),BO=a("a"),iIo=o("GPTNeoForSequenceClassification"),dIo=o(" (GPT Neo model)"),cIo=l(),R2=a("li"),Vge=a("strong"),fIo=o("gptj"),mIo=o(" \u2014 "),IO=a("a"),gIo=o("GPTJForSequenceClassification"),hIo=o(" (GPT-J model)"),pIo=l(),P2=a("li"),Xge=a("strong"),uIo=o("ibert"),_Io=o(" \u2014 "),NO=a("a"),bIo=o("IBertForSequenceClassification"),vIo=o(" (I-BERT model)"),FIo=l(),B2=a("li"),zge=a("strong"),TIo=o("layoutlm"),MIo=o(" \u2014 "),qO=a("a"),EIo=o("LayoutLMForSequenceClassification"),CIo=o(" (LayoutLM model)"),wIo=l(),I2=a("li"),Wge=a("strong"),AIo=o("layoutlmv2"),yIo=o(" \u2014 "),jO=a("a"),LIo=o("LayoutLMv2ForSequenceClassification"),xIo=o(" (LayoutLMv2 model)"),$Io=l(),N2=a("li"),Qge=a("strong"),kIo=o("layoutlmv3"),SIo=o(" \u2014 "),DO=a("a"),RIo=o("LayoutLMv3ForSequenceClassification"),PIo=o(" (LayoutLMv3 model)"),BIo=l(),q2=a("li"),Hge=a("strong"),IIo=o("led"),NIo=o(" \u2014 "),GO=a("a"),qIo=o("LEDForSequenceClassification"),jIo=o(" (LED model)"),DIo=l(),j2=a("li"),Uge=a("strong"),GIo=o("longformer"),OIo=o(" \u2014 "),OO=a("a"),VIo=o("LongformerForSequenceClassification"),XIo=o(" (Longformer model)"),zIo=l(),D2=a("li"),Jge=a("strong"),WIo=o("mbart"),QIo=o(" \u2014 "),VO=a("a"),HIo=o("MBartForSequenceClassification"),UIo=o(" (mBART model)"),JIo=l(),G2=a("li"),Yge=a("strong"),YIo=o("megatron-bert"),KIo=o(" \u2014 "),XO=a("a"),ZIo=o("MegatronBertForSequenceClassification"),eNo=o(" (Megatron-BERT model)"),oNo=l(),O2=a("li"),Kge=a("strong"),rNo=o("mobilebert"),tNo=o(" \u2014 "),zO=a("a"),aNo=o("MobileBertForSequenceClassification"),nNo=o(" (MobileBERT model)"),sNo=l(),V2=a("li"),Zge=a("strong"),lNo=o("mpnet"),iNo=o(" \u2014 "),WO=a("a"),dNo=o("MPNetForSequenceClassification"),cNo=o(" (MPNet model)"),fNo=l(),X2=a("li"),ehe=a("strong"),mNo=o("nystromformer"),gNo=o(" \u2014 "),QO=a("a"),hNo=o("NystromformerForSequenceClassification"),pNo=o(" (Nystr\xF6mformer model)"),uNo=l(),z2=a("li"),ohe=a("strong"),_No=o("openai-gpt"),bNo=o(" \u2014 "),HO=a("a"),vNo=o("OpenAIGPTForSequenceClassification"),FNo=o(" (OpenAI GPT model)"),TNo=l(),W2=a("li"),rhe=a("strong"),MNo=o("perceiver"),ENo=o(" \u2014 "),UO=a("a"),CNo=o("PerceiverForSequenceClassification"),wNo=o(" (Perceiver model)"),ANo=l(),Q2=a("li"),the=a("strong"),yNo=o("plbart"),LNo=o(" \u2014 "),JO=a("a"),xNo=o("PLBartForSequenceClassification"),$No=o(" (PLBart model)"),kNo=l(),H2=a("li"),ahe=a("strong"),SNo=o("qdqbert"),RNo=o(" \u2014 "),YO=a("a"),PNo=o("QDQBertForSequenceClassification"),BNo=o(" (QDQBert model)"),INo=l(),U2=a("li"),nhe=a("strong"),NNo=o("reformer"),qNo=o(" \u2014 "),KO=a("a"),jNo=o("ReformerForSequenceClassification"),DNo=o(" (Reformer model)"),GNo=l(),J2=a("li"),she=a("strong"),ONo=o("rembert"),VNo=o(" \u2014 "),ZO=a("a"),XNo=o("RemBertForSequenceClassification"),zNo=o(" (RemBERT model)"),WNo=l(),Y2=a("li"),lhe=a("strong"),QNo=o("roberta"),HNo=o(" \u2014 "),eV=a("a"),UNo=o("RobertaForSequenceClassification"),JNo=o(" (RoBERTa model)"),YNo=l(),K2=a("li"),ihe=a("strong"),KNo=o("roformer"),ZNo=o(" \u2014 "),oV=a("a"),eqo=o("RoFormerForSequenceClassification"),oqo=o(" (RoFormer model)"),rqo=l(),Z2=a("li"),dhe=a("strong"),tqo=o("squeezebert"),aqo=o(" \u2014 "),rV=a("a"),nqo=o("SqueezeBertForSequenceClassification"),sqo=o(" (SqueezeBERT model)"),lqo=l(),ev=a("li"),che=a("strong"),iqo=o("tapas"),dqo=o(" \u2014 "),tV=a("a"),cqo=o("TapasForSequenceClassification"),fqo=o(" (TAPAS model)"),mqo=l(),ov=a("li"),fhe=a("strong"),gqo=o("transfo-xl"),hqo=o(" \u2014 "),aV=a("a"),pqo=o("TransfoXLForSequenceClassification"),uqo=o(" (Transformer-XL model)"),_qo=l(),rv=a("li"),mhe=a("strong"),bqo=o("xlm"),vqo=o(" \u2014 "),nV=a("a"),Fqo=o("XLMForSequenceClassification"),Tqo=o(" (XLM model)"),Mqo=l(),tv=a("li"),ghe=a("strong"),Eqo=o("xlm-roberta"),Cqo=o(" \u2014 "),sV=a("a"),wqo=o("XLMRobertaForSequenceClassification"),Aqo=o(" (XLM-RoBERTa model)"),yqo=l(),av=a("li"),hhe=a("strong"),Lqo=o("xlm-roberta-xl"),xqo=o(" \u2014 "),lV=a("a"),$qo=o("XLMRobertaXLForSequenceClassification"),kqo=o(" (XLM-RoBERTa-XL model)"),Sqo=l(),nv=a("li"),phe=a("strong"),Rqo=o("xlnet"),Pqo=o(" \u2014 "),iV=a("a"),Bqo=o("XLNetForSequenceClassification"),Iqo=o(" (XLNet model)"),Nqo=l(),sv=a("li"),uhe=a("strong"),qqo=o("yoso"),jqo=o(" \u2014 "),dV=a("a"),Dqo=o("YosoForSequenceClassification"),Gqo=o(" (YOSO model)"),Oqo=l(),lv=a("p"),Vqo=o("The model is set in evaluation mode by default using "),_he=a("code"),Xqo=o("model.eval()"),zqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bhe=a("code"),Wqo=o("model.train()"),Qqo=l(),F(iv.$$.fragment),HDe=l(),Yi=a("h2"),dv=a("a"),vhe=a("span"),F(hy.$$.fragment),Hqo=l(),Fhe=a("span"),Uqo=o("AutoModelForMultipleChoice"),UDe=l(),Bo=a("div"),F(py.$$.fragment),Jqo=l(),Ki=a("p"),Yqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cV=a("a"),Kqo=o("from_pretrained()"),Zqo=o(" class method or the "),fV=a("a"),ejo=o("from_config()"),ojo=o(` class
method.`),rjo=l(),uy=a("p"),tjo=o("This class cannot be instantiated directly using "),The=a("code"),ajo=o("__init__()"),njo=o(" (throws an error)."),sjo=l(),ft=a("div"),F(_y.$$.fragment),ljo=l(),Mhe=a("p"),ijo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),djo=l(),Zi=a("p"),cjo=o(`Note:
Loading a model from its configuration file does `),Ehe=a("strong"),fjo=o("not"),mjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mV=a("a"),gjo=o("from_pretrained()"),hjo=o(" to load the model weights."),pjo=l(),F(cv.$$.fragment),ujo=l(),ro=a("div"),F(by.$$.fragment),_jo=l(),Che=a("p"),bjo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),vjo=l(),qa=a("p"),Fjo=o("The model class to instantiate is selected based on the "),whe=a("code"),Tjo=o("model_type"),Mjo=o(` property of the config object (either
passed as an argument or loaded from `),Ahe=a("code"),Ejo=o("pretrained_model_name_or_path"),Cjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yhe=a("code"),wjo=o("pretrained_model_name_or_path"),Ajo=o(":"),yjo=l(),Z=a("ul"),fv=a("li"),Lhe=a("strong"),Ljo=o("albert"),xjo=o(" \u2014 "),gV=a("a"),$jo=o("AlbertForMultipleChoice"),kjo=o(" (ALBERT model)"),Sjo=l(),mv=a("li"),xhe=a("strong"),Rjo=o("bert"),Pjo=o(" \u2014 "),hV=a("a"),Bjo=o("BertForMultipleChoice"),Ijo=o(" (BERT model)"),Njo=l(),gv=a("li"),$he=a("strong"),qjo=o("big_bird"),jjo=o(" \u2014 "),pV=a("a"),Djo=o("BigBirdForMultipleChoice"),Gjo=o(" (BigBird model)"),Ojo=l(),hv=a("li"),khe=a("strong"),Vjo=o("camembert"),Xjo=o(" \u2014 "),uV=a("a"),zjo=o("CamembertForMultipleChoice"),Wjo=o(" (CamemBERT model)"),Qjo=l(),pv=a("li"),She=a("strong"),Hjo=o("canine"),Ujo=o(" \u2014 "),_V=a("a"),Jjo=o("CanineForMultipleChoice"),Yjo=o(" (CANINE model)"),Kjo=l(),uv=a("li"),Rhe=a("strong"),Zjo=o("convbert"),eDo=o(" \u2014 "),bV=a("a"),oDo=o("ConvBertForMultipleChoice"),rDo=o(" (ConvBERT model)"),tDo=l(),_v=a("li"),Phe=a("strong"),aDo=o("data2vec-text"),nDo=o(" \u2014 "),vV=a("a"),sDo=o("Data2VecTextForMultipleChoice"),lDo=o(" (Data2VecText model)"),iDo=l(),bv=a("li"),Bhe=a("strong"),dDo=o("deberta-v2"),cDo=o(" \u2014 "),FV=a("a"),fDo=o("DebertaV2ForMultipleChoice"),mDo=o(" (DeBERTa-v2 model)"),gDo=l(),vv=a("li"),Ihe=a("strong"),hDo=o("distilbert"),pDo=o(" \u2014 "),TV=a("a"),uDo=o("DistilBertForMultipleChoice"),_Do=o(" (DistilBERT model)"),bDo=l(),Fv=a("li"),Nhe=a("strong"),vDo=o("electra"),FDo=o(" \u2014 "),MV=a("a"),TDo=o("ElectraForMultipleChoice"),MDo=o(" (ELECTRA model)"),EDo=l(),Tv=a("li"),qhe=a("strong"),CDo=o("flaubert"),wDo=o(" \u2014 "),EV=a("a"),ADo=o("FlaubertForMultipleChoice"),yDo=o(" (FlauBERT model)"),LDo=l(),Mv=a("li"),jhe=a("strong"),xDo=o("fnet"),$Do=o(" \u2014 "),CV=a("a"),kDo=o("FNetForMultipleChoice"),SDo=o(" (FNet model)"),RDo=l(),Ev=a("li"),Dhe=a("strong"),PDo=o("funnel"),BDo=o(" \u2014 "),wV=a("a"),IDo=o("FunnelForMultipleChoice"),NDo=o(" (Funnel Transformer model)"),qDo=l(),Cv=a("li"),Ghe=a("strong"),jDo=o("ibert"),DDo=o(" \u2014 "),AV=a("a"),GDo=o("IBertForMultipleChoice"),ODo=o(" (I-BERT model)"),VDo=l(),wv=a("li"),Ohe=a("strong"),XDo=o("longformer"),zDo=o(" \u2014 "),yV=a("a"),WDo=o("LongformerForMultipleChoice"),QDo=o(" (Longformer model)"),HDo=l(),Av=a("li"),Vhe=a("strong"),UDo=o("megatron-bert"),JDo=o(" \u2014 "),LV=a("a"),YDo=o("MegatronBertForMultipleChoice"),KDo=o(" (Megatron-BERT model)"),ZDo=l(),yv=a("li"),Xhe=a("strong"),eGo=o("mobilebert"),oGo=o(" \u2014 "),xV=a("a"),rGo=o("MobileBertForMultipleChoice"),tGo=o(" (MobileBERT model)"),aGo=l(),Lv=a("li"),zhe=a("strong"),nGo=o("mpnet"),sGo=o(" \u2014 "),$V=a("a"),lGo=o("MPNetForMultipleChoice"),iGo=o(" (MPNet model)"),dGo=l(),xv=a("li"),Whe=a("strong"),cGo=o("nystromformer"),fGo=o(" \u2014 "),kV=a("a"),mGo=o("NystromformerForMultipleChoice"),gGo=o(" (Nystr\xF6mformer model)"),hGo=l(),$v=a("li"),Qhe=a("strong"),pGo=o("qdqbert"),uGo=o(" \u2014 "),SV=a("a"),_Go=o("QDQBertForMultipleChoice"),bGo=o(" (QDQBert model)"),vGo=l(),kv=a("li"),Hhe=a("strong"),FGo=o("rembert"),TGo=o(" \u2014 "),RV=a("a"),MGo=o("RemBertForMultipleChoice"),EGo=o(" (RemBERT model)"),CGo=l(),Sv=a("li"),Uhe=a("strong"),wGo=o("roberta"),AGo=o(" \u2014 "),PV=a("a"),yGo=o("RobertaForMultipleChoice"),LGo=o(" (RoBERTa model)"),xGo=l(),Rv=a("li"),Jhe=a("strong"),$Go=o("roformer"),kGo=o(" \u2014 "),BV=a("a"),SGo=o("RoFormerForMultipleChoice"),RGo=o(" (RoFormer model)"),PGo=l(),Pv=a("li"),Yhe=a("strong"),BGo=o("squeezebert"),IGo=o(" \u2014 "),IV=a("a"),NGo=o("SqueezeBertForMultipleChoice"),qGo=o(" (SqueezeBERT model)"),jGo=l(),Bv=a("li"),Khe=a("strong"),DGo=o("xlm"),GGo=o(" \u2014 "),NV=a("a"),OGo=o("XLMForMultipleChoice"),VGo=o(" (XLM model)"),XGo=l(),Iv=a("li"),Zhe=a("strong"),zGo=o("xlm-roberta"),WGo=o(" \u2014 "),qV=a("a"),QGo=o("XLMRobertaForMultipleChoice"),HGo=o(" (XLM-RoBERTa model)"),UGo=l(),Nv=a("li"),epe=a("strong"),JGo=o("xlm-roberta-xl"),YGo=o(" \u2014 "),jV=a("a"),KGo=o("XLMRobertaXLForMultipleChoice"),ZGo=o(" (XLM-RoBERTa-XL model)"),eOo=l(),qv=a("li"),ope=a("strong"),oOo=o("xlnet"),rOo=o(" \u2014 "),DV=a("a"),tOo=o("XLNetForMultipleChoice"),aOo=o(" (XLNet model)"),nOo=l(),jv=a("li"),rpe=a("strong"),sOo=o("yoso"),lOo=o(" \u2014 "),GV=a("a"),iOo=o("YosoForMultipleChoice"),dOo=o(" (YOSO model)"),cOo=l(),Dv=a("p"),fOo=o("The model is set in evaluation mode by default using "),tpe=a("code"),mOo=o("model.eval()"),gOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ape=a("code"),hOo=o("model.train()"),pOo=l(),F(Gv.$$.fragment),JDe=l(),ed=a("h2"),Ov=a("a"),npe=a("span"),F(vy.$$.fragment),uOo=l(),spe=a("span"),_Oo=o("AutoModelForNextSentencePrediction"),YDe=l(),Io=a("div"),F(Fy.$$.fragment),bOo=l(),od=a("p"),vOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OV=a("a"),FOo=o("from_pretrained()"),TOo=o(" class method or the "),VV=a("a"),MOo=o("from_config()"),EOo=o(` class
method.`),COo=l(),Ty=a("p"),wOo=o("This class cannot be instantiated directly using "),lpe=a("code"),AOo=o("__init__()"),yOo=o(" (throws an error)."),LOo=l(),mt=a("div"),F(My.$$.fragment),xOo=l(),ipe=a("p"),$Oo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),kOo=l(),rd=a("p"),SOo=o(`Note:
Loading a model from its configuration file does `),dpe=a("strong"),ROo=o("not"),POo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XV=a("a"),BOo=o("from_pretrained()"),IOo=o(" to load the model weights."),NOo=l(),F(Vv.$$.fragment),qOo=l(),to=a("div"),F(Ey.$$.fragment),jOo=l(),cpe=a("p"),DOo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),GOo=l(),ja=a("p"),OOo=o("The model class to instantiate is selected based on the "),fpe=a("code"),VOo=o("model_type"),XOo=o(` property of the config object (either
passed as an argument or loaded from `),mpe=a("code"),zOo=o("pretrained_model_name_or_path"),WOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gpe=a("code"),QOo=o("pretrained_model_name_or_path"),HOo=o(":"),UOo=l(),Zr=a("ul"),Xv=a("li"),hpe=a("strong"),JOo=o("bert"),YOo=o(" \u2014 "),zV=a("a"),KOo=o("BertForNextSentencePrediction"),ZOo=o(" (BERT model)"),eVo=l(),zv=a("li"),ppe=a("strong"),oVo=o("fnet"),rVo=o(" \u2014 "),WV=a("a"),tVo=o("FNetForNextSentencePrediction"),aVo=o(" (FNet model)"),nVo=l(),Wv=a("li"),upe=a("strong"),sVo=o("megatron-bert"),lVo=o(" \u2014 "),QV=a("a"),iVo=o("MegatronBertForNextSentencePrediction"),dVo=o(" (Megatron-BERT model)"),cVo=l(),Qv=a("li"),_pe=a("strong"),fVo=o("mobilebert"),mVo=o(" \u2014 "),HV=a("a"),gVo=o("MobileBertForNextSentencePrediction"),hVo=o(" (MobileBERT model)"),pVo=l(),Hv=a("li"),bpe=a("strong"),uVo=o("qdqbert"),_Vo=o(" \u2014 "),UV=a("a"),bVo=o("QDQBertForNextSentencePrediction"),vVo=o(" (QDQBert model)"),FVo=l(),Uv=a("p"),TVo=o("The model is set in evaluation mode by default using "),vpe=a("code"),MVo=o("model.eval()"),EVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fpe=a("code"),CVo=o("model.train()"),wVo=l(),F(Jv.$$.fragment),KDe=l(),td=a("h2"),Yv=a("a"),Tpe=a("span"),F(Cy.$$.fragment),AVo=l(),Mpe=a("span"),yVo=o("AutoModelForTokenClassification"),ZDe=l(),No=a("div"),F(wy.$$.fragment),LVo=l(),ad=a("p"),xVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JV=a("a"),$Vo=o("from_pretrained()"),kVo=o(" class method or the "),YV=a("a"),SVo=o("from_config()"),RVo=o(` class
method.`),PVo=l(),Ay=a("p"),BVo=o("This class cannot be instantiated directly using "),Epe=a("code"),IVo=o("__init__()"),NVo=o(" (throws an error)."),qVo=l(),gt=a("div"),F(yy.$$.fragment),jVo=l(),Cpe=a("p"),DVo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),GVo=l(),nd=a("p"),OVo=o(`Note:
Loading a model from its configuration file does `),wpe=a("strong"),VVo=o("not"),XVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KV=a("a"),zVo=o("from_pretrained()"),WVo=o(" to load the model weights."),QVo=l(),F(Kv.$$.fragment),HVo=l(),ao=a("div"),F(Ly.$$.fragment),UVo=l(),Ape=a("p"),JVo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),YVo=l(),Da=a("p"),KVo=o("The model class to instantiate is selected based on the "),ype=a("code"),ZVo=o("model_type"),eXo=o(` property of the config object (either
passed as an argument or loaded from `),Lpe=a("code"),oXo=o("pretrained_model_name_or_path"),rXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xpe=a("code"),tXo=o("pretrained_model_name_or_path"),aXo=o(":"),nXo=l(),H=a("ul"),Zv=a("li"),$pe=a("strong"),sXo=o("albert"),lXo=o(" \u2014 "),ZV=a("a"),iXo=o("AlbertForTokenClassification"),dXo=o(" (ALBERT model)"),cXo=l(),e3=a("li"),kpe=a("strong"),fXo=o("bert"),mXo=o(" \u2014 "),eX=a("a"),gXo=o("BertForTokenClassification"),hXo=o(" (BERT model)"),pXo=l(),o3=a("li"),Spe=a("strong"),uXo=o("big_bird"),_Xo=o(" \u2014 "),oX=a("a"),bXo=o("BigBirdForTokenClassification"),vXo=o(" (BigBird model)"),FXo=l(),r3=a("li"),Rpe=a("strong"),TXo=o("bloom"),MXo=o(" \u2014 "),rX=a("a"),EXo=o("BloomForTokenClassification"),CXo=o(" (BLOOM model)"),wXo=l(),t3=a("li"),Ppe=a("strong"),AXo=o("camembert"),yXo=o(" \u2014 "),tX=a("a"),LXo=o("CamembertForTokenClassification"),xXo=o(" (CamemBERT model)"),$Xo=l(),a3=a("li"),Bpe=a("strong"),kXo=o("canine"),SXo=o(" \u2014 "),aX=a("a"),RXo=o("CanineForTokenClassification"),PXo=o(" (CANINE model)"),BXo=l(),n3=a("li"),Ipe=a("strong"),IXo=o("convbert"),NXo=o(" \u2014 "),nX=a("a"),qXo=o("ConvBertForTokenClassification"),jXo=o(" (ConvBERT model)"),DXo=l(),s3=a("li"),Npe=a("strong"),GXo=o("data2vec-text"),OXo=o(" \u2014 "),sX=a("a"),VXo=o("Data2VecTextForTokenClassification"),XXo=o(" (Data2VecText model)"),zXo=l(),l3=a("li"),qpe=a("strong"),WXo=o("deberta"),QXo=o(" \u2014 "),lX=a("a"),HXo=o("DebertaForTokenClassification"),UXo=o(" (DeBERTa model)"),JXo=l(),i3=a("li"),jpe=a("strong"),YXo=o("deberta-v2"),KXo=o(" \u2014 "),iX=a("a"),ZXo=o("DebertaV2ForTokenClassification"),ezo=o(" (DeBERTa-v2 model)"),ozo=l(),d3=a("li"),Dpe=a("strong"),rzo=o("distilbert"),tzo=o(" \u2014 "),dX=a("a"),azo=o("DistilBertForTokenClassification"),nzo=o(" (DistilBERT model)"),szo=l(),c3=a("li"),Gpe=a("strong"),lzo=o("electra"),izo=o(" \u2014 "),cX=a("a"),dzo=o("ElectraForTokenClassification"),czo=o(" (ELECTRA model)"),fzo=l(),f3=a("li"),Ope=a("strong"),mzo=o("flaubert"),gzo=o(" \u2014 "),fX=a("a"),hzo=o("FlaubertForTokenClassification"),pzo=o(" (FlauBERT model)"),uzo=l(),m3=a("li"),Vpe=a("strong"),_zo=o("fnet"),bzo=o(" \u2014 "),mX=a("a"),vzo=o("FNetForTokenClassification"),Fzo=o(" (FNet model)"),Tzo=l(),g3=a("li"),Xpe=a("strong"),Mzo=o("funnel"),Ezo=o(" \u2014 "),gX=a("a"),Czo=o("FunnelForTokenClassification"),wzo=o(" (Funnel Transformer model)"),Azo=l(),h3=a("li"),zpe=a("strong"),yzo=o("gpt2"),Lzo=o(" \u2014 "),hX=a("a"),xzo=o("GPT2ForTokenClassification"),$zo=o(" (OpenAI GPT-2 model)"),kzo=l(),p3=a("li"),Wpe=a("strong"),Szo=o("ibert"),Rzo=o(" \u2014 "),pX=a("a"),Pzo=o("IBertForTokenClassification"),Bzo=o(" (I-BERT model)"),Izo=l(),u3=a("li"),Qpe=a("strong"),Nzo=o("layoutlm"),qzo=o(" \u2014 "),uX=a("a"),jzo=o("LayoutLMForTokenClassification"),Dzo=o(" (LayoutLM model)"),Gzo=l(),_3=a("li"),Hpe=a("strong"),Ozo=o("layoutlmv2"),Vzo=o(" \u2014 "),_X=a("a"),Xzo=o("LayoutLMv2ForTokenClassification"),zzo=o(" (LayoutLMv2 model)"),Wzo=l(),b3=a("li"),Upe=a("strong"),Qzo=o("layoutlmv3"),Hzo=o(" \u2014 "),bX=a("a"),Uzo=o("LayoutLMv3ForTokenClassification"),Jzo=o(" (LayoutLMv3 model)"),Yzo=l(),v3=a("li"),Jpe=a("strong"),Kzo=o("longformer"),Zzo=o(" \u2014 "),vX=a("a"),eWo=o("LongformerForTokenClassification"),oWo=o(" (Longformer model)"),rWo=l(),F3=a("li"),Ype=a("strong"),tWo=o("megatron-bert"),aWo=o(" \u2014 "),FX=a("a"),nWo=o("MegatronBertForTokenClassification"),sWo=o(" (Megatron-BERT model)"),lWo=l(),T3=a("li"),Kpe=a("strong"),iWo=o("mobilebert"),dWo=o(" \u2014 "),TX=a("a"),cWo=o("MobileBertForTokenClassification"),fWo=o(" (MobileBERT model)"),mWo=l(),M3=a("li"),Zpe=a("strong"),gWo=o("mpnet"),hWo=o(" \u2014 "),MX=a("a"),pWo=o("MPNetForTokenClassification"),uWo=o(" (MPNet model)"),_Wo=l(),E3=a("li"),eue=a("strong"),bWo=o("nystromformer"),vWo=o(" \u2014 "),EX=a("a"),FWo=o("NystromformerForTokenClassification"),TWo=o(" (Nystr\xF6mformer model)"),MWo=l(),C3=a("li"),oue=a("strong"),EWo=o("qdqbert"),CWo=o(" \u2014 "),CX=a("a"),wWo=o("QDQBertForTokenClassification"),AWo=o(" (QDQBert model)"),yWo=l(),w3=a("li"),rue=a("strong"),LWo=o("rembert"),xWo=o(" \u2014 "),wX=a("a"),$Wo=o("RemBertForTokenClassification"),kWo=o(" (RemBERT model)"),SWo=l(),A3=a("li"),tue=a("strong"),RWo=o("roberta"),PWo=o(" \u2014 "),AX=a("a"),BWo=o("RobertaForTokenClassification"),IWo=o(" (RoBERTa model)"),NWo=l(),y3=a("li"),aue=a("strong"),qWo=o("roformer"),jWo=o(" \u2014 "),yX=a("a"),DWo=o("RoFormerForTokenClassification"),GWo=o(" (RoFormer model)"),OWo=l(),L3=a("li"),nue=a("strong"),VWo=o("squeezebert"),XWo=o(" \u2014 "),LX=a("a"),zWo=o("SqueezeBertForTokenClassification"),WWo=o(" (SqueezeBERT model)"),QWo=l(),x3=a("li"),sue=a("strong"),HWo=o("xlm"),UWo=o(" \u2014 "),xX=a("a"),JWo=o("XLMForTokenClassification"),YWo=o(" (XLM model)"),KWo=l(),$3=a("li"),lue=a("strong"),ZWo=o("xlm-roberta"),eQo=o(" \u2014 "),$X=a("a"),oQo=o("XLMRobertaForTokenClassification"),rQo=o(" (XLM-RoBERTa model)"),tQo=l(),k3=a("li"),iue=a("strong"),aQo=o("xlm-roberta-xl"),nQo=o(" \u2014 "),kX=a("a"),sQo=o("XLMRobertaXLForTokenClassification"),lQo=o(" (XLM-RoBERTa-XL model)"),iQo=l(),S3=a("li"),due=a("strong"),dQo=o("xlnet"),cQo=o(" \u2014 "),SX=a("a"),fQo=o("XLNetForTokenClassification"),mQo=o(" (XLNet model)"),gQo=l(),R3=a("li"),cue=a("strong"),hQo=o("yoso"),pQo=o(" \u2014 "),RX=a("a"),uQo=o("YosoForTokenClassification"),_Qo=o(" (YOSO model)"),bQo=l(),P3=a("p"),vQo=o("The model is set in evaluation mode by default using "),fue=a("code"),FQo=o("model.eval()"),TQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mue=a("code"),MQo=o("model.train()"),EQo=l(),F(B3.$$.fragment),eGe=l(),sd=a("h2"),I3=a("a"),gue=a("span"),F(xy.$$.fragment),CQo=l(),hue=a("span"),wQo=o("AutoModelForQuestionAnswering"),oGe=l(),qo=a("div"),F($y.$$.fragment),AQo=l(),ld=a("p"),yQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),PX=a("a"),LQo=o("from_pretrained()"),xQo=o(" class method or the "),BX=a("a"),$Qo=o("from_config()"),kQo=o(` class
method.`),SQo=l(),ky=a("p"),RQo=o("This class cannot be instantiated directly using "),pue=a("code"),PQo=o("__init__()"),BQo=o(" (throws an error)."),IQo=l(),ht=a("div"),F(Sy.$$.fragment),NQo=l(),uue=a("p"),qQo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),jQo=l(),id=a("p"),DQo=o(`Note:
Loading a model from its configuration file does `),_ue=a("strong"),GQo=o("not"),OQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IX=a("a"),VQo=o("from_pretrained()"),XQo=o(" to load the model weights."),zQo=l(),F(N3.$$.fragment),WQo=l(),no=a("div"),F(Ry.$$.fragment),QQo=l(),bue=a("p"),HQo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),UQo=l(),Ga=a("p"),JQo=o("The model class to instantiate is selected based on the "),vue=a("code"),YQo=o("model_type"),KQo=o(` property of the config object (either
passed as an argument or loaded from `),Fue=a("code"),ZQo=o("pretrained_model_name_or_path"),eHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tue=a("code"),oHo=o("pretrained_model_name_or_path"),rHo=o(":"),tHo=l(),V=a("ul"),q3=a("li"),Mue=a("strong"),aHo=o("albert"),nHo=o(" \u2014 "),NX=a("a"),sHo=o("AlbertForQuestionAnswering"),lHo=o(" (ALBERT model)"),iHo=l(),j3=a("li"),Eue=a("strong"),dHo=o("bart"),cHo=o(" \u2014 "),qX=a("a"),fHo=o("BartForQuestionAnswering"),mHo=o(" (BART model)"),gHo=l(),D3=a("li"),Cue=a("strong"),hHo=o("bert"),pHo=o(" \u2014 "),jX=a("a"),uHo=o("BertForQuestionAnswering"),_Ho=o(" (BERT model)"),bHo=l(),G3=a("li"),wue=a("strong"),vHo=o("big_bird"),FHo=o(" \u2014 "),DX=a("a"),THo=o("BigBirdForQuestionAnswering"),MHo=o(" (BigBird model)"),EHo=l(),O3=a("li"),Aue=a("strong"),CHo=o("bigbird_pegasus"),wHo=o(" \u2014 "),GX=a("a"),AHo=o("BigBirdPegasusForQuestionAnswering"),yHo=o(" (BigBird-Pegasus model)"),LHo=l(),V3=a("li"),yue=a("strong"),xHo=o("camembert"),$Ho=o(" \u2014 "),OX=a("a"),kHo=o("CamembertForQuestionAnswering"),SHo=o(" (CamemBERT model)"),RHo=l(),X3=a("li"),Lue=a("strong"),PHo=o("canine"),BHo=o(" \u2014 "),VX=a("a"),IHo=o("CanineForQuestionAnswering"),NHo=o(" (CANINE model)"),qHo=l(),z3=a("li"),xue=a("strong"),jHo=o("convbert"),DHo=o(" \u2014 "),XX=a("a"),GHo=o("ConvBertForQuestionAnswering"),OHo=o(" (ConvBERT model)"),VHo=l(),W3=a("li"),$ue=a("strong"),XHo=o("data2vec-text"),zHo=o(" \u2014 "),zX=a("a"),WHo=o("Data2VecTextForQuestionAnswering"),QHo=o(" (Data2VecText model)"),HHo=l(),Q3=a("li"),kue=a("strong"),UHo=o("deberta"),JHo=o(" \u2014 "),WX=a("a"),YHo=o("DebertaForQuestionAnswering"),KHo=o(" (DeBERTa model)"),ZHo=l(),H3=a("li"),Sue=a("strong"),eUo=o("deberta-v2"),oUo=o(" \u2014 "),QX=a("a"),rUo=o("DebertaV2ForQuestionAnswering"),tUo=o(" (DeBERTa-v2 model)"),aUo=l(),U3=a("li"),Rue=a("strong"),nUo=o("distilbert"),sUo=o(" \u2014 "),HX=a("a"),lUo=o("DistilBertForQuestionAnswering"),iUo=o(" (DistilBERT model)"),dUo=l(),J3=a("li"),Pue=a("strong"),cUo=o("electra"),fUo=o(" \u2014 "),UX=a("a"),mUo=o("ElectraForQuestionAnswering"),gUo=o(" (ELECTRA model)"),hUo=l(),Y3=a("li"),Bue=a("strong"),pUo=o("flaubert"),uUo=o(" \u2014 "),JX=a("a"),_Uo=o("FlaubertForQuestionAnsweringSimple"),bUo=o(" (FlauBERT model)"),vUo=l(),K3=a("li"),Iue=a("strong"),FUo=o("fnet"),TUo=o(" \u2014 "),YX=a("a"),MUo=o("FNetForQuestionAnswering"),EUo=o(" (FNet model)"),CUo=l(),Z3=a("li"),Nue=a("strong"),wUo=o("funnel"),AUo=o(" \u2014 "),KX=a("a"),yUo=o("FunnelForQuestionAnswering"),LUo=o(" (Funnel Transformer model)"),xUo=l(),eF=a("li"),que=a("strong"),$Uo=o("gptj"),kUo=o(" \u2014 "),ZX=a("a"),SUo=o("GPTJForQuestionAnswering"),RUo=o(" (GPT-J model)"),PUo=l(),oF=a("li"),jue=a("strong"),BUo=o("ibert"),IUo=o(" \u2014 "),ez=a("a"),NUo=o("IBertForQuestionAnswering"),qUo=o(" (I-BERT model)"),jUo=l(),rF=a("li"),Due=a("strong"),DUo=o("layoutlmv2"),GUo=o(" \u2014 "),oz=a("a"),OUo=o("LayoutLMv2ForQuestionAnswering"),VUo=o(" (LayoutLMv2 model)"),XUo=l(),tF=a("li"),Gue=a("strong"),zUo=o("layoutlmv3"),WUo=o(" \u2014 "),rz=a("a"),QUo=o("LayoutLMv3ForQuestionAnswering"),HUo=o(" (LayoutLMv3 model)"),UUo=l(),aF=a("li"),Oue=a("strong"),JUo=o("led"),YUo=o(" \u2014 "),tz=a("a"),KUo=o("LEDForQuestionAnswering"),ZUo=o(" (LED model)"),eJo=l(),nF=a("li"),Vue=a("strong"),oJo=o("longformer"),rJo=o(" \u2014 "),az=a("a"),tJo=o("LongformerForQuestionAnswering"),aJo=o(" (Longformer model)"),nJo=l(),sF=a("li"),Xue=a("strong"),sJo=o("lxmert"),lJo=o(" \u2014 "),nz=a("a"),iJo=o("LxmertForQuestionAnswering"),dJo=o(" (LXMERT model)"),cJo=l(),lF=a("li"),zue=a("strong"),fJo=o("mbart"),mJo=o(" \u2014 "),sz=a("a"),gJo=o("MBartForQuestionAnswering"),hJo=o(" (mBART model)"),pJo=l(),iF=a("li"),Wue=a("strong"),uJo=o("megatron-bert"),_Jo=o(" \u2014 "),lz=a("a"),bJo=o("MegatronBertForQuestionAnswering"),vJo=o(" (Megatron-BERT model)"),FJo=l(),dF=a("li"),Que=a("strong"),TJo=o("mobilebert"),MJo=o(" \u2014 "),iz=a("a"),EJo=o("MobileBertForQuestionAnswering"),CJo=o(" (MobileBERT model)"),wJo=l(),cF=a("li"),Hue=a("strong"),AJo=o("mpnet"),yJo=o(" \u2014 "),dz=a("a"),LJo=o("MPNetForQuestionAnswering"),xJo=o(" (MPNet model)"),$Jo=l(),fF=a("li"),Uue=a("strong"),kJo=o("nystromformer"),SJo=o(" \u2014 "),cz=a("a"),RJo=o("NystromformerForQuestionAnswering"),PJo=o(" (Nystr\xF6mformer model)"),BJo=l(),mF=a("li"),Jue=a("strong"),IJo=o("qdqbert"),NJo=o(" \u2014 "),fz=a("a"),qJo=o("QDQBertForQuestionAnswering"),jJo=o(" (QDQBert model)"),DJo=l(),gF=a("li"),Yue=a("strong"),GJo=o("reformer"),OJo=o(" \u2014 "),mz=a("a"),VJo=o("ReformerForQuestionAnswering"),XJo=o(" (Reformer model)"),zJo=l(),hF=a("li"),Kue=a("strong"),WJo=o("rembert"),QJo=o(" \u2014 "),gz=a("a"),HJo=o("RemBertForQuestionAnswering"),UJo=o(" (RemBERT model)"),JJo=l(),pF=a("li"),Zue=a("strong"),YJo=o("roberta"),KJo=o(" \u2014 "),hz=a("a"),ZJo=o("RobertaForQuestionAnswering"),eYo=o(" (RoBERTa model)"),oYo=l(),uF=a("li"),e_e=a("strong"),rYo=o("roformer"),tYo=o(" \u2014 "),pz=a("a"),aYo=o("RoFormerForQuestionAnswering"),nYo=o(" (RoFormer model)"),sYo=l(),_F=a("li"),o_e=a("strong"),lYo=o("splinter"),iYo=o(" \u2014 "),uz=a("a"),dYo=o("SplinterForQuestionAnswering"),cYo=o(" (Splinter model)"),fYo=l(),bF=a("li"),r_e=a("strong"),mYo=o("squeezebert"),gYo=o(" \u2014 "),_z=a("a"),hYo=o("SqueezeBertForQuestionAnswering"),pYo=o(" (SqueezeBERT model)"),uYo=l(),vF=a("li"),t_e=a("strong"),_Yo=o("xlm"),bYo=o(" \u2014 "),bz=a("a"),vYo=o("XLMForQuestionAnsweringSimple"),FYo=o(" (XLM model)"),TYo=l(),FF=a("li"),a_e=a("strong"),MYo=o("xlm-roberta"),EYo=o(" \u2014 "),vz=a("a"),CYo=o("XLMRobertaForQuestionAnswering"),wYo=o(" (XLM-RoBERTa model)"),AYo=l(),TF=a("li"),n_e=a("strong"),yYo=o("xlm-roberta-xl"),LYo=o(" \u2014 "),Fz=a("a"),xYo=o("XLMRobertaXLForQuestionAnswering"),$Yo=o(" (XLM-RoBERTa-XL model)"),kYo=l(),MF=a("li"),s_e=a("strong"),SYo=o("xlnet"),RYo=o(" \u2014 "),Tz=a("a"),PYo=o("XLNetForQuestionAnsweringSimple"),BYo=o(" (XLNet model)"),IYo=l(),EF=a("li"),l_e=a("strong"),NYo=o("yoso"),qYo=o(" \u2014 "),Mz=a("a"),jYo=o("YosoForQuestionAnswering"),DYo=o(" (YOSO model)"),GYo=l(),CF=a("p"),OYo=o("The model is set in evaluation mode by default using "),i_e=a("code"),VYo=o("model.eval()"),XYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d_e=a("code"),zYo=o("model.train()"),WYo=l(),F(wF.$$.fragment),rGe=l(),dd=a("h2"),AF=a("a"),c_e=a("span"),F(Py.$$.fragment),QYo=l(),f_e=a("span"),HYo=o("AutoModelForTableQuestionAnswering"),tGe=l(),jo=a("div"),F(By.$$.fragment),UYo=l(),cd=a("p"),JYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Ez=a("a"),YYo=o("from_pretrained()"),KYo=o(" class method or the "),Cz=a("a"),ZYo=o("from_config()"),eKo=o(` class
method.`),oKo=l(),Iy=a("p"),rKo=o("This class cannot be instantiated directly using "),m_e=a("code"),tKo=o("__init__()"),aKo=o(" (throws an error)."),nKo=l(),pt=a("div"),F(Ny.$$.fragment),sKo=l(),g_e=a("p"),lKo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),iKo=l(),fd=a("p"),dKo=o(`Note:
Loading a model from its configuration file does `),h_e=a("strong"),cKo=o("not"),fKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wz=a("a"),mKo=o("from_pretrained()"),gKo=o(" to load the model weights."),hKo=l(),F(yF.$$.fragment),pKo=l(),so=a("div"),F(qy.$$.fragment),uKo=l(),p_e=a("p"),_Ko=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),bKo=l(),Oa=a("p"),vKo=o("The model class to instantiate is selected based on the "),u_e=a("code"),FKo=o("model_type"),TKo=o(` property of the config object (either
passed as an argument or loaded from `),__e=a("code"),MKo=o("pretrained_model_name_or_path"),EKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=a("code"),CKo=o("pretrained_model_name_or_path"),wKo=o(":"),AKo=l(),v_e=a("ul"),LF=a("li"),F_e=a("strong"),yKo=o("tapas"),LKo=o(" \u2014 "),Az=a("a"),xKo=o("TapasForQuestionAnswering"),$Ko=o(" (TAPAS model)"),kKo=l(),xF=a("p"),SKo=o("The model is set in evaluation mode by default using "),T_e=a("code"),RKo=o("model.eval()"),PKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M_e=a("code"),BKo=o("model.train()"),IKo=l(),F($F.$$.fragment),aGe=l(),md=a("h2"),kF=a("a"),E_e=a("span"),F(jy.$$.fragment),NKo=l(),C_e=a("span"),qKo=o("AutoModelForImageClassification"),nGe=l(),Do=a("div"),F(Dy.$$.fragment),jKo=l(),gd=a("p"),DKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),yz=a("a"),GKo=o("from_pretrained()"),OKo=o(" class method or the "),Lz=a("a"),VKo=o("from_config()"),XKo=o(` class
method.`),zKo=l(),Gy=a("p"),WKo=o("This class cannot be instantiated directly using "),w_e=a("code"),QKo=o("__init__()"),HKo=o(" (throws an error)."),UKo=l(),ut=a("div"),F(Oy.$$.fragment),JKo=l(),A_e=a("p"),YKo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),KKo=l(),hd=a("p"),ZKo=o(`Note:
Loading a model from its configuration file does `),y_e=a("strong"),eZo=o("not"),oZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xz=a("a"),rZo=o("from_pretrained()"),tZo=o(" to load the model weights."),aZo=l(),F(SF.$$.fragment),nZo=l(),lo=a("div"),F(Vy.$$.fragment),sZo=l(),L_e=a("p"),lZo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),iZo=l(),Va=a("p"),dZo=o("The model class to instantiate is selected based on the "),x_e=a("code"),cZo=o("model_type"),fZo=o(` property of the config object (either
passed as an argument or loaded from `),$_e=a("code"),mZo=o("pretrained_model_name_or_path"),gZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k_e=a("code"),hZo=o("pretrained_model_name_or_path"),pZo=o(":"),uZo=l(),ve=a("ul"),RF=a("li"),S_e=a("strong"),_Zo=o("beit"),bZo=o(" \u2014 "),$z=a("a"),vZo=o("BeitForImageClassification"),FZo=o(" (BEiT model)"),TZo=l(),PF=a("li"),R_e=a("strong"),MZo=o("convnext"),EZo=o(" \u2014 "),kz=a("a"),CZo=o("ConvNextForImageClassification"),wZo=o(" (ConvNeXT model)"),AZo=l(),BF=a("li"),P_e=a("strong"),yZo=o("cvt"),LZo=o(" \u2014 "),Sz=a("a"),xZo=o("CvtForImageClassification"),$Zo=o(" (CvT model)"),kZo=l(),IF=a("li"),B_e=a("strong"),SZo=o("data2vec-vision"),RZo=o(" \u2014 "),Rz=a("a"),PZo=o("Data2VecVisionForImageClassification"),BZo=o(" (Data2VecVision model)"),IZo=l(),Gs=a("li"),I_e=a("strong"),NZo=o("deit"),qZo=o(" \u2014 "),Pz=a("a"),jZo=o("DeiTForImageClassification"),DZo=o(" or "),Bz=a("a"),GZo=o("DeiTForImageClassificationWithTeacher"),OZo=o(" (DeiT model)"),VZo=l(),NF=a("li"),N_e=a("strong"),XZo=o("imagegpt"),zZo=o(" \u2014 "),Iz=a("a"),WZo=o("ImageGPTForImageClassification"),QZo=o(" (ImageGPT model)"),HZo=l(),Os=a("li"),q_e=a("strong"),UZo=o("levit"),JZo=o(" \u2014 "),Nz=a("a"),YZo=o("LevitForImageClassification"),KZo=o(" or "),qz=a("a"),ZZo=o("LevitForImageClassificationWithTeacher"),eer=o(" (LeViT model)"),oer=l(),_t=a("li"),j_e=a("strong"),rer=o("perceiver"),ter=o(" \u2014 "),jz=a("a"),aer=o("PerceiverForImageClassificationLearned"),ner=o(" or "),Dz=a("a"),ser=o("PerceiverForImageClassificationFourier"),ler=o(" or "),Gz=a("a"),ier=o("PerceiverForImageClassificationConvProcessing"),der=o(" (Perceiver model)"),cer=l(),qF=a("li"),D_e=a("strong"),fer=o("poolformer"),mer=o(" \u2014 "),Oz=a("a"),ger=o("PoolFormerForImageClassification"),her=o(" (PoolFormer model)"),per=l(),jF=a("li"),G_e=a("strong"),uer=o("regnet"),_er=o(" \u2014 "),Vz=a("a"),ber=o("RegNetForImageClassification"),ver=o(" (RegNet model)"),Fer=l(),DF=a("li"),O_e=a("strong"),Ter=o("resnet"),Mer=o(" \u2014 "),Xz=a("a"),Eer=o("ResNetForImageClassification"),Cer=o(" (ResNet model)"),wer=l(),GF=a("li"),V_e=a("strong"),Aer=o("segformer"),yer=o(" \u2014 "),zz=a("a"),Ler=o("SegformerForImageClassification"),xer=o(" (SegFormer model)"),$er=l(),OF=a("li"),X_e=a("strong"),ker=o("swin"),Ser=o(" \u2014 "),Wz=a("a"),Rer=o("SwinForImageClassification"),Per=o(" (Swin Transformer model)"),Ber=l(),VF=a("li"),z_e=a("strong"),Ier=o("van"),Ner=o(" \u2014 "),Qz=a("a"),qer=o("VanForImageClassification"),jer=o(" (VAN model)"),Der=l(),XF=a("li"),W_e=a("strong"),Ger=o("vit"),Oer=o(" \u2014 "),Hz=a("a"),Ver=o("ViTForImageClassification"),Xer=o(" (ViT model)"),zer=l(),zF=a("p"),Wer=o("The model is set in evaluation mode by default using "),Q_e=a("code"),Qer=o("model.eval()"),Her=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H_e=a("code"),Uer=o("model.train()"),Jer=l(),F(WF.$$.fragment),sGe=l(),pd=a("h2"),QF=a("a"),U_e=a("span"),F(Xy.$$.fragment),Yer=l(),J_e=a("span"),Ker=o("AutoModelForVision2Seq"),lGe=l(),Go=a("div"),F(zy.$$.fragment),Zer=l(),ud=a("p"),eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Uz=a("a"),oor=o("from_pretrained()"),ror=o(" class method or the "),Jz=a("a"),tor=o("from_config()"),aor=o(` class
method.`),nor=l(),Wy=a("p"),sor=o("This class cannot be instantiated directly using "),Y_e=a("code"),lor=o("__init__()"),ior=o(" (throws an error)."),dor=l(),bt=a("div"),F(Qy.$$.fragment),cor=l(),K_e=a("p"),mor=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),gor=l(),_d=a("p"),hor=o(`Note:
Loading a model from its configuration file does `),Z_e=a("strong"),por=o("not"),uor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yz=a("a"),_or=o("from_pretrained()"),bor=o(" to load the model weights."),vor=l(),F(HF.$$.fragment),For=l(),io=a("div"),F(Hy.$$.fragment),Tor=l(),e1e=a("p"),Mor=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Eor=l(),Xa=a("p"),Cor=o("The model class to instantiate is selected based on the "),o1e=a("code"),wor=o("model_type"),Aor=o(` property of the config object (either
passed as an argument or loaded from `),r1e=a("code"),yor=o("pretrained_model_name_or_path"),Lor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t1e=a("code"),xor=o("pretrained_model_name_or_path"),$or=o(":"),kor=l(),a1e=a("ul"),UF=a("li"),n1e=a("strong"),Sor=o("vision-encoder-decoder"),Ror=o(" \u2014 "),Kz=a("a"),Por=o("VisionEncoderDecoderModel"),Bor=o(" (Vision Encoder decoder model)"),Ior=l(),JF=a("p"),Nor=o("The model is set in evaluation mode by default using "),s1e=a("code"),qor=o("model.eval()"),jor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=a("code"),Dor=o("model.train()"),Gor=l(),F(YF.$$.fragment),iGe=l(),bd=a("h2"),KF=a("a"),i1e=a("span"),F(Uy.$$.fragment),Oor=l(),d1e=a("span"),Vor=o("AutoModelForVisualQuestionAnswering"),dGe=l(),Oo=a("div"),F(Jy.$$.fragment),Xor=l(),vd=a("p"),zor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Zz=a("a"),Wor=o("from_pretrained()"),Qor=o(" class method or the "),eW=a("a"),Hor=o("from_config()"),Uor=o(` class
method.`),Jor=l(),Yy=a("p"),Yor=o("This class cannot be instantiated directly using "),c1e=a("code"),Kor=o("__init__()"),Zor=o(" (throws an error)."),err=l(),vt=a("div"),F(Ky.$$.fragment),orr=l(),f1e=a("p"),rrr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),trr=l(),Fd=a("p"),arr=o(`Note:
Loading a model from its configuration file does `),m1e=a("strong"),nrr=o("not"),srr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=a("a"),lrr=o("from_pretrained()"),irr=o(" to load the model weights."),drr=l(),F(ZF.$$.fragment),crr=l(),co=a("div"),F(Zy.$$.fragment),frr=l(),g1e=a("p"),mrr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),grr=l(),za=a("p"),hrr=o("The model class to instantiate is selected based on the "),h1e=a("code"),prr=o("model_type"),urr=o(` property of the config object (either
passed as an argument or loaded from `),p1e=a("code"),_rr=o("pretrained_model_name_or_path"),brr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u1e=a("code"),vrr=o("pretrained_model_name_or_path"),Frr=o(":"),Trr=l(),_1e=a("ul"),e6=a("li"),b1e=a("strong"),Mrr=o("vilt"),Err=o(" \u2014 "),rW=a("a"),Crr=o("ViltForQuestionAnswering"),wrr=o(" (ViLT model)"),Arr=l(),o6=a("p"),yrr=o("The model is set in evaluation mode by default using "),v1e=a("code"),Lrr=o("model.eval()"),xrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=a("code"),$rr=o("model.train()"),krr=l(),F(r6.$$.fragment),cGe=l(),Td=a("h2"),t6=a("a"),T1e=a("span"),F(eL.$$.fragment),Srr=l(),M1e=a("span"),Rrr=o("AutoModelForAudioClassification"),fGe=l(),Vo=a("div"),F(oL.$$.fragment),Prr=l(),Md=a("p"),Brr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),tW=a("a"),Irr=o("from_pretrained()"),Nrr=o(" class method or the "),aW=a("a"),qrr=o("from_config()"),jrr=o(` class
method.`),Drr=l(),rL=a("p"),Grr=o("This class cannot be instantiated directly using "),E1e=a("code"),Orr=o("__init__()"),Vrr=o(" (throws an error)."),Xrr=l(),Ft=a("div"),F(tL.$$.fragment),zrr=l(),C1e=a("p"),Wrr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Qrr=l(),Ed=a("p"),Hrr=o(`Note:
Loading a model from its configuration file does `),w1e=a("strong"),Urr=o("not"),Jrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nW=a("a"),Yrr=o("from_pretrained()"),Krr=o(" to load the model weights."),Zrr=l(),F(a6.$$.fragment),etr=l(),fo=a("div"),F(aL.$$.fragment),otr=l(),A1e=a("p"),rtr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),ttr=l(),Wa=a("p"),atr=o("The model class to instantiate is selected based on the "),y1e=a("code"),ntr=o("model_type"),str=o(` property of the config object (either
passed as an argument or loaded from `),L1e=a("code"),ltr=o("pretrained_model_name_or_path"),itr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=a("code"),dtr=o("pretrained_model_name_or_path"),ctr=o(":"),ftr=l(),Re=a("ul"),n6=a("li"),$1e=a("strong"),mtr=o("data2vec-audio"),gtr=o(" \u2014 "),sW=a("a"),htr=o("Data2VecAudioForSequenceClassification"),ptr=o(" (Data2VecAudio model)"),utr=l(),s6=a("li"),k1e=a("strong"),_tr=o("hubert"),btr=o(" \u2014 "),lW=a("a"),vtr=o("HubertForSequenceClassification"),Ftr=o(" (Hubert model)"),Ttr=l(),l6=a("li"),S1e=a("strong"),Mtr=o("sew"),Etr=o(" \u2014 "),iW=a("a"),Ctr=o("SEWForSequenceClassification"),wtr=o(" (SEW model)"),Atr=l(),i6=a("li"),R1e=a("strong"),ytr=o("sew-d"),Ltr=o(" \u2014 "),dW=a("a"),xtr=o("SEWDForSequenceClassification"),$tr=o(" (SEW-D model)"),ktr=l(),d6=a("li"),P1e=a("strong"),Str=o("unispeech"),Rtr=o(" \u2014 "),cW=a("a"),Ptr=o("UniSpeechForSequenceClassification"),Btr=o(" (UniSpeech model)"),Itr=l(),c6=a("li"),B1e=a("strong"),Ntr=o("unispeech-sat"),qtr=o(" \u2014 "),fW=a("a"),jtr=o("UniSpeechSatForSequenceClassification"),Dtr=o(" (UniSpeechSat model)"),Gtr=l(),f6=a("li"),I1e=a("strong"),Otr=o("wav2vec2"),Vtr=o(" \u2014 "),mW=a("a"),Xtr=o("Wav2Vec2ForSequenceClassification"),ztr=o(" (Wav2Vec2 model)"),Wtr=l(),m6=a("li"),N1e=a("strong"),Qtr=o("wav2vec2-conformer"),Htr=o(" \u2014 "),gW=a("a"),Utr=o("Wav2Vec2ConformerForSequenceClassification"),Jtr=o(" (Wav2Vec2-Conformer model)"),Ytr=l(),g6=a("li"),q1e=a("strong"),Ktr=o("wavlm"),Ztr=o(" \u2014 "),hW=a("a"),ear=o("WavLMForSequenceClassification"),oar=o(" (WavLM model)"),rar=l(),h6=a("p"),tar=o("The model is set in evaluation mode by default using "),j1e=a("code"),aar=o("model.eval()"),nar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D1e=a("code"),sar=o("model.train()"),lar=l(),F(p6.$$.fragment),mGe=l(),Cd=a("h2"),u6=a("a"),G1e=a("span"),F(nL.$$.fragment),iar=l(),O1e=a("span"),dar=o("AutoModelForAudioFrameClassification"),gGe=l(),Xo=a("div"),F(sL.$$.fragment),car=l(),wd=a("p"),far=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),pW=a("a"),mar=o("from_pretrained()"),gar=o(" class method or the "),uW=a("a"),har=o("from_config()"),par=o(` class
method.`),uar=l(),lL=a("p"),_ar=o("This class cannot be instantiated directly using "),V1e=a("code"),bar=o("__init__()"),Far=o(" (throws an error)."),Tar=l(),Tt=a("div"),F(iL.$$.fragment),Mar=l(),X1e=a("p"),Ear=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Car=l(),Ad=a("p"),war=o(`Note:
Loading a model from its configuration file does `),z1e=a("strong"),Aar=o("not"),yar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_W=a("a"),Lar=o("from_pretrained()"),xar=o(" to load the model weights."),$ar=l(),F(_6.$$.fragment),kar=l(),mo=a("div"),F(dL.$$.fragment),Sar=l(),W1e=a("p"),Rar=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Par=l(),Qa=a("p"),Bar=o("The model class to instantiate is selected based on the "),Q1e=a("code"),Iar=o("model_type"),Nar=o(` property of the config object (either
passed as an argument or loaded from `),H1e=a("code"),qar=o("pretrained_model_name_or_path"),jar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=a("code"),Dar=o("pretrained_model_name_or_path"),Gar=o(":"),Oar=l(),et=a("ul"),b6=a("li"),J1e=a("strong"),Var=o("data2vec-audio"),Xar=o(" \u2014 "),bW=a("a"),zar=o("Data2VecAudioForAudioFrameClassification"),War=o(" (Data2VecAudio model)"),Qar=l(),v6=a("li"),Y1e=a("strong"),Har=o("unispeech-sat"),Uar=o(" \u2014 "),vW=a("a"),Jar=o("UniSpeechSatForAudioFrameClassification"),Yar=o(" (UniSpeechSat model)"),Kar=l(),F6=a("li"),K1e=a("strong"),Zar=o("wav2vec2"),enr=o(" \u2014 "),FW=a("a"),onr=o("Wav2Vec2ForAudioFrameClassification"),rnr=o(" (Wav2Vec2 model)"),tnr=l(),T6=a("li"),Z1e=a("strong"),anr=o("wav2vec2-conformer"),nnr=o(" \u2014 "),TW=a("a"),snr=o("Wav2Vec2ConformerForAudioFrameClassification"),lnr=o(" (Wav2Vec2-Conformer model)"),inr=l(),M6=a("li"),ebe=a("strong"),dnr=o("wavlm"),cnr=o(" \u2014 "),MW=a("a"),fnr=o("WavLMForAudioFrameClassification"),mnr=o(" (WavLM model)"),gnr=l(),E6=a("p"),hnr=o("The model is set in evaluation mode by default using "),obe=a("code"),pnr=o("model.eval()"),unr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rbe=a("code"),_nr=o("model.train()"),bnr=l(),F(C6.$$.fragment),hGe=l(),yd=a("h2"),w6=a("a"),tbe=a("span"),F(cL.$$.fragment),vnr=l(),abe=a("span"),Fnr=o("AutoModelForCTC"),pGe=l(),zo=a("div"),F(fL.$$.fragment),Tnr=l(),Ld=a("p"),Mnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),EW=a("a"),Enr=o("from_pretrained()"),Cnr=o(" class method or the "),CW=a("a"),wnr=o("from_config()"),Anr=o(` class
method.`),ynr=l(),mL=a("p"),Lnr=o("This class cannot be instantiated directly using "),nbe=a("code"),xnr=o("__init__()"),$nr=o(" (throws an error)."),knr=l(),Mt=a("div"),F(gL.$$.fragment),Snr=l(),sbe=a("p"),Rnr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Pnr=l(),xd=a("p"),Bnr=o(`Note:
Loading a model from its configuration file does `),lbe=a("strong"),Inr=o("not"),Nnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wW=a("a"),qnr=o("from_pretrained()"),jnr=o(" to load the model weights."),Dnr=l(),F(A6.$$.fragment),Gnr=l(),go=a("div"),F(hL.$$.fragment),Onr=l(),ibe=a("p"),Vnr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Xnr=l(),Ha=a("p"),znr=o("The model class to instantiate is selected based on the "),dbe=a("code"),Wnr=o("model_type"),Qnr=o(` property of the config object (either
passed as an argument or loaded from `),cbe=a("code"),Hnr=o("pretrained_model_name_or_path"),Unr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fbe=a("code"),Jnr=o("pretrained_model_name_or_path"),Ynr=o(":"),Knr=l(),ye=a("ul"),y6=a("li"),mbe=a("strong"),Znr=o("data2vec-audio"),esr=o(" \u2014 "),AW=a("a"),osr=o("Data2VecAudioForCTC"),rsr=o(" (Data2VecAudio model)"),tsr=l(),L6=a("li"),gbe=a("strong"),asr=o("hubert"),nsr=o(" \u2014 "),yW=a("a"),ssr=o("HubertForCTC"),lsr=o(" (Hubert model)"),isr=l(),x6=a("li"),hbe=a("strong"),dsr=o("mctct"),csr=o(" \u2014 "),LW=a("a"),fsr=o("MCTCTForCTC"),msr=o(" (M-CTC-T model)"),gsr=l(),$6=a("li"),pbe=a("strong"),hsr=o("sew"),psr=o(" \u2014 "),xW=a("a"),usr=o("SEWForCTC"),_sr=o(" (SEW model)"),bsr=l(),k6=a("li"),ube=a("strong"),vsr=o("sew-d"),Fsr=o(" \u2014 "),$W=a("a"),Tsr=o("SEWDForCTC"),Msr=o(" (SEW-D model)"),Esr=l(),S6=a("li"),_be=a("strong"),Csr=o("unispeech"),wsr=o(" \u2014 "),kW=a("a"),Asr=o("UniSpeechForCTC"),ysr=o(" (UniSpeech model)"),Lsr=l(),R6=a("li"),bbe=a("strong"),xsr=o("unispeech-sat"),$sr=o(" \u2014 "),SW=a("a"),ksr=o("UniSpeechSatForCTC"),Ssr=o(" (UniSpeechSat model)"),Rsr=l(),P6=a("li"),vbe=a("strong"),Psr=o("wav2vec2"),Bsr=o(" \u2014 "),RW=a("a"),Isr=o("Wav2Vec2ForCTC"),Nsr=o(" (Wav2Vec2 model)"),qsr=l(),B6=a("li"),Fbe=a("strong"),jsr=o("wav2vec2-conformer"),Dsr=o(" \u2014 "),PW=a("a"),Gsr=o("Wav2Vec2ConformerForCTC"),Osr=o(" (Wav2Vec2-Conformer model)"),Vsr=l(),I6=a("li"),Tbe=a("strong"),Xsr=o("wavlm"),zsr=o(" \u2014 "),BW=a("a"),Wsr=o("WavLMForCTC"),Qsr=o(" (WavLM model)"),Hsr=l(),N6=a("p"),Usr=o("The model is set in evaluation mode by default using "),Mbe=a("code"),Jsr=o("model.eval()"),Ysr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=a("code"),Ksr=o("model.train()"),Zsr=l(),F(q6.$$.fragment),uGe=l(),$d=a("h2"),j6=a("a"),Cbe=a("span"),F(pL.$$.fragment),elr=l(),wbe=a("span"),olr=o("AutoModelForSpeechSeq2Seq"),_Ge=l(),Wo=a("div"),F(uL.$$.fragment),rlr=l(),kd=a("p"),tlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),IW=a("a"),alr=o("from_pretrained()"),nlr=o(" class method or the "),NW=a("a"),slr=o("from_config()"),llr=o(` class
method.`),ilr=l(),_L=a("p"),dlr=o("This class cannot be instantiated directly using "),Abe=a("code"),clr=o("__init__()"),flr=o(" (throws an error)."),mlr=l(),Et=a("div"),F(bL.$$.fragment),glr=l(),ybe=a("p"),hlr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),plr=l(),Sd=a("p"),ulr=o(`Note:
Loading a model from its configuration file does `),Lbe=a("strong"),_lr=o("not"),blr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),vlr=o("from_pretrained()"),Flr=o(" to load the model weights."),Tlr=l(),F(D6.$$.fragment),Mlr=l(),ho=a("div"),F(vL.$$.fragment),Elr=l(),xbe=a("p"),Clr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),wlr=l(),Ua=a("p"),Alr=o("The model class to instantiate is selected based on the "),$be=a("code"),ylr=o("model_type"),Llr=o(` property of the config object (either
passed as an argument or loaded from `),kbe=a("code"),xlr=o("pretrained_model_name_or_path"),$lr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=a("code"),klr=o("pretrained_model_name_or_path"),Slr=o(":"),Rlr=l(),FL=a("ul"),G6=a("li"),Rbe=a("strong"),Plr=o("speech-encoder-decoder"),Blr=o(" \u2014 "),jW=a("a"),Ilr=o("SpeechEncoderDecoderModel"),Nlr=o(" (Speech Encoder decoder model)"),qlr=l(),O6=a("li"),Pbe=a("strong"),jlr=o("speech_to_text"),Dlr=o(" \u2014 "),DW=a("a"),Glr=o("Speech2TextForConditionalGeneration"),Olr=o(" (Speech2Text model)"),Vlr=l(),V6=a("p"),Xlr=o("The model is set in evaluation mode by default using "),Bbe=a("code"),zlr=o("model.eval()"),Wlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=a("code"),Qlr=o("model.train()"),Hlr=l(),F(X6.$$.fragment),bGe=l(),Rd=a("h2"),z6=a("a"),Nbe=a("span"),F(TL.$$.fragment),Ulr=l(),qbe=a("span"),Jlr=o("AutoModelForAudioXVector"),vGe=l(),Qo=a("div"),F(ML.$$.fragment),Ylr=l(),Pd=a("p"),Klr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),GW=a("a"),Zlr=o("from_pretrained()"),eir=o(" class method or the "),OW=a("a"),oir=o("from_config()"),rir=o(` class
method.`),tir=l(),EL=a("p"),air=o("This class cannot be instantiated directly using "),jbe=a("code"),nir=o("__init__()"),sir=o(" (throws an error)."),lir=l(),Ct=a("div"),F(CL.$$.fragment),iir=l(),Dbe=a("p"),dir=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),cir=l(),Bd=a("p"),fir=o(`Note:
Loading a model from its configuration file does `),Gbe=a("strong"),mir=o("not"),gir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),hir=o("from_pretrained()"),pir=o(" to load the model weights."),uir=l(),F(W6.$$.fragment),_ir=l(),po=a("div"),F(wL.$$.fragment),bir=l(),Obe=a("p"),vir=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Fir=l(),Ja=a("p"),Tir=o("The model class to instantiate is selected based on the "),Vbe=a("code"),Mir=o("model_type"),Eir=o(` property of the config object (either
passed as an argument or loaded from `),Xbe=a("code"),Cir=o("pretrained_model_name_or_path"),wir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=a("code"),Air=o("pretrained_model_name_or_path"),yir=o(":"),Lir=l(),ot=a("ul"),Q6=a("li"),Wbe=a("strong"),xir=o("data2vec-audio"),$ir=o(" \u2014 "),XW=a("a"),kir=o("Data2VecAudioForXVector"),Sir=o(" (Data2VecAudio model)"),Rir=l(),H6=a("li"),Qbe=a("strong"),Pir=o("unispeech-sat"),Bir=o(" \u2014 "),zW=a("a"),Iir=o("UniSpeechSatForXVector"),Nir=o(" (UniSpeechSat model)"),qir=l(),U6=a("li"),Hbe=a("strong"),jir=o("wav2vec2"),Dir=o(" \u2014 "),WW=a("a"),Gir=o("Wav2Vec2ForXVector"),Oir=o(" (Wav2Vec2 model)"),Vir=l(),J6=a("li"),Ube=a("strong"),Xir=o("wav2vec2-conformer"),zir=o(" \u2014 "),QW=a("a"),Wir=o("Wav2Vec2ConformerForXVector"),Qir=o(" (Wav2Vec2-Conformer model)"),Hir=l(),Y6=a("li"),Jbe=a("strong"),Uir=o("wavlm"),Jir=o(" \u2014 "),HW=a("a"),Yir=o("WavLMForXVector"),Kir=o(" (WavLM model)"),Zir=l(),K6=a("p"),edr=o("The model is set in evaluation mode by default using "),Ybe=a("code"),odr=o("model.eval()"),rdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kbe=a("code"),tdr=o("model.train()"),adr=l(),F(Z6.$$.fragment),FGe=l(),Id=a("h2"),eT=a("a"),Zbe=a("span"),F(AL.$$.fragment),ndr=l(),e2e=a("span"),sdr=o("AutoModelForMaskedImageModeling"),TGe=l(),Ho=a("div"),F(yL.$$.fragment),ldr=l(),Nd=a("p"),idr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),UW=a("a"),ddr=o("from_pretrained()"),cdr=o(" class method or the "),JW=a("a"),fdr=o("from_config()"),mdr=o(` class
method.`),gdr=l(),LL=a("p"),hdr=o("This class cannot be instantiated directly using "),o2e=a("code"),pdr=o("__init__()"),udr=o(" (throws an error)."),_dr=l(),wt=a("div"),F(xL.$$.fragment),bdr=l(),r2e=a("p"),vdr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Fdr=l(),qd=a("p"),Tdr=o(`Note:
Loading a model from its configuration file does `),t2e=a("strong"),Mdr=o("not"),Edr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),Cdr=o("from_pretrained()"),wdr=o(" to load the model weights."),Adr=l(),F(oT.$$.fragment),ydr=l(),uo=a("div"),F($L.$$.fragment),Ldr=l(),a2e=a("p"),xdr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),$dr=l(),Ya=a("p"),kdr=o("The model class to instantiate is selected based on the "),n2e=a("code"),Sdr=o("model_type"),Rdr=o(` property of the config object (either
passed as an argument or loaded from `),s2e=a("code"),Pdr=o("pretrained_model_name_or_path"),Bdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l2e=a("code"),Idr=o("pretrained_model_name_or_path"),Ndr=o(":"),qdr=l(),jd=a("ul"),rT=a("li"),i2e=a("strong"),jdr=o("deit"),Ddr=o(" \u2014 "),KW=a("a"),Gdr=o("DeiTForMaskedImageModeling"),Odr=o(" (DeiT model)"),Vdr=l(),tT=a("li"),d2e=a("strong"),Xdr=o("swin"),zdr=o(" \u2014 "),ZW=a("a"),Wdr=o("SwinForMaskedImageModeling"),Qdr=o(" (Swin Transformer model)"),Hdr=l(),aT=a("li"),c2e=a("strong"),Udr=o("vit"),Jdr=o(" \u2014 "),eQ=a("a"),Ydr=o("ViTForMaskedImageModeling"),Kdr=o(" (ViT model)"),Zdr=l(),nT=a("p"),ecr=o("The model is set in evaluation mode by default using "),f2e=a("code"),ocr=o("model.eval()"),rcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m2e=a("code"),tcr=o("model.train()"),acr=l(),F(sT.$$.fragment),MGe=l(),Dd=a("h2"),lT=a("a"),g2e=a("span"),F(kL.$$.fragment),ncr=l(),h2e=a("span"),scr=o("AutoModelForObjectDetection"),EGe=l(),Uo=a("div"),F(SL.$$.fragment),lcr=l(),Gd=a("p"),icr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),oQ=a("a"),dcr=o("from_pretrained()"),ccr=o(" class method or the "),rQ=a("a"),fcr=o("from_config()"),mcr=o(` class
method.`),gcr=l(),RL=a("p"),hcr=o("This class cannot be instantiated directly using "),p2e=a("code"),pcr=o("__init__()"),ucr=o(" (throws an error)."),_cr=l(),At=a("div"),F(PL.$$.fragment),bcr=l(),u2e=a("p"),vcr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Fcr=l(),Od=a("p"),Tcr=o(`Note:
Loading a model from its configuration file does `),_2e=a("strong"),Mcr=o("not"),Ecr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tQ=a("a"),Ccr=o("from_pretrained()"),wcr=o(" to load the model weights."),Acr=l(),F(iT.$$.fragment),ycr=l(),_o=a("div"),F(BL.$$.fragment),Lcr=l(),b2e=a("p"),xcr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),$cr=l(),Ka=a("p"),kcr=o("The model class to instantiate is selected based on the "),v2e=a("code"),Scr=o("model_type"),Rcr=o(` property of the config object (either
passed as an argument or loaded from `),F2e=a("code"),Pcr=o("pretrained_model_name_or_path"),Bcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T2e=a("code"),Icr=o("pretrained_model_name_or_path"),Ncr=o(":"),qcr=l(),IL=a("ul"),dT=a("li"),M2e=a("strong"),jcr=o("detr"),Dcr=o(" \u2014 "),aQ=a("a"),Gcr=o("DetrForObjectDetection"),Ocr=o(" (DETR model)"),Vcr=l(),cT=a("li"),E2e=a("strong"),Xcr=o("yolos"),zcr=o(" \u2014 "),nQ=a("a"),Wcr=o("YolosForObjectDetection"),Qcr=o(" (YOLOS model)"),Hcr=l(),fT=a("p"),Ucr=o("The model is set in evaluation mode by default using "),C2e=a("code"),Jcr=o("model.eval()"),Ycr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w2e=a("code"),Kcr=o("model.train()"),Zcr=l(),F(mT.$$.fragment),CGe=l(),Vd=a("h2"),gT=a("a"),A2e=a("span"),F(NL.$$.fragment),efr=l(),y2e=a("span"),ofr=o("AutoModelForImageSegmentation"),wGe=l(),Jo=a("div"),F(qL.$$.fragment),rfr=l(),Xd=a("p"),tfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),sQ=a("a"),afr=o("from_pretrained()"),nfr=o(" class method or the "),lQ=a("a"),sfr=o("from_config()"),lfr=o(` class
method.`),ifr=l(),jL=a("p"),dfr=o("This class cannot be instantiated directly using "),L2e=a("code"),cfr=o("__init__()"),ffr=o(" (throws an error)."),mfr=l(),yt=a("div"),F(DL.$$.fragment),gfr=l(),x2e=a("p"),hfr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),pfr=l(),zd=a("p"),ufr=o(`Note:
Loading a model from its configuration file does `),$2e=a("strong"),_fr=o("not"),bfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iQ=a("a"),vfr=o("from_pretrained()"),Ffr=o(" to load the model weights."),Tfr=l(),F(hT.$$.fragment),Mfr=l(),bo=a("div"),F(GL.$$.fragment),Efr=l(),k2e=a("p"),Cfr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),wfr=l(),Za=a("p"),Afr=o("The model class to instantiate is selected based on the "),S2e=a("code"),yfr=o("model_type"),Lfr=o(` property of the config object (either
passed as an argument or loaded from `),R2e=a("code"),xfr=o("pretrained_model_name_or_path"),$fr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P2e=a("code"),kfr=o("pretrained_model_name_or_path"),Sfr=o(":"),Rfr=l(),B2e=a("ul"),pT=a("li"),I2e=a("strong"),Pfr=o("detr"),Bfr=o(" \u2014 "),dQ=a("a"),Ifr=o("DetrForSegmentation"),Nfr=o(" (DETR model)"),qfr=l(),uT=a("p"),jfr=o("The model is set in evaluation mode by default using "),N2e=a("code"),Dfr=o("model.eval()"),Gfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=a("code"),Ofr=o("model.train()"),Vfr=l(),F(_T.$$.fragment),AGe=l(),Wd=a("h2"),bT=a("a"),j2e=a("span"),F(OL.$$.fragment),Xfr=l(),D2e=a("span"),zfr=o("AutoModelForSemanticSegmentation"),yGe=l(),Yo=a("div"),F(VL.$$.fragment),Wfr=l(),Qd=a("p"),Qfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),cQ=a("a"),Hfr=o("from_pretrained()"),Ufr=o(" class method or the "),fQ=a("a"),Jfr=o("from_config()"),Yfr=o(` class
method.`),Kfr=l(),XL=a("p"),Zfr=o("This class cannot be instantiated directly using "),G2e=a("code"),emr=o("__init__()"),omr=o(" (throws an error)."),rmr=l(),Lt=a("div"),F(zL.$$.fragment),tmr=l(),O2e=a("p"),amr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),nmr=l(),Hd=a("p"),smr=o(`Note:
Loading a model from its configuration file does `),V2e=a("strong"),lmr=o("not"),imr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mQ=a("a"),dmr=o("from_pretrained()"),cmr=o(" to load the model weights."),fmr=l(),F(vT.$$.fragment),mmr=l(),vo=a("div"),F(WL.$$.fragment),gmr=l(),X2e=a("p"),hmr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),pmr=l(),en=a("p"),umr=o("The model class to instantiate is selected based on the "),z2e=a("code"),_mr=o("model_type"),bmr=o(` property of the config object (either
passed as an argument or loaded from `),W2e=a("code"),vmr=o("pretrained_model_name_or_path"),Fmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q2e=a("code"),Tmr=o("pretrained_model_name_or_path"),Mmr=o(":"),Emr=l(),on=a("ul"),FT=a("li"),H2e=a("strong"),Cmr=o("beit"),wmr=o(" \u2014 "),gQ=a("a"),Amr=o("BeitForSemanticSegmentation"),ymr=o(" (BEiT model)"),Lmr=l(),TT=a("li"),U2e=a("strong"),xmr=o("data2vec-vision"),$mr=o(" \u2014 "),hQ=a("a"),kmr=o("Data2VecVisionForSemanticSegmentation"),Smr=o(" (Data2VecVision model)"),Rmr=l(),MT=a("li"),J2e=a("strong"),Pmr=o("dpt"),Bmr=o(" \u2014 "),pQ=a("a"),Imr=o("DPTForSemanticSegmentation"),Nmr=o(" (DPT model)"),qmr=l(),ET=a("li"),Y2e=a("strong"),jmr=o("segformer"),Dmr=o(" \u2014 "),uQ=a("a"),Gmr=o("SegformerForSemanticSegmentation"),Omr=o(" (SegFormer model)"),Vmr=l(),CT=a("p"),Xmr=o("The model is set in evaluation mode by default using "),K2e=a("code"),zmr=o("model.eval()"),Wmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z2e=a("code"),Qmr=o("model.train()"),Hmr=l(),F(wT.$$.fragment),LGe=l(),Ud=a("h2"),AT=a("a"),eve=a("span"),F(QL.$$.fragment),Umr=l(),ove=a("span"),Jmr=o("AutoModelForInstanceSegmentation"),xGe=l(),Ko=a("div"),F(HL.$$.fragment),Ymr=l(),Jd=a("p"),Kmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),_Q=a("a"),Zmr=o("from_pretrained()"),egr=o(" class method or the "),bQ=a("a"),ogr=o("from_config()"),rgr=o(` class
method.`),tgr=l(),UL=a("p"),agr=o("This class cannot be instantiated directly using "),rve=a("code"),ngr=o("__init__()"),sgr=o(" (throws an error)."),lgr=l(),xt=a("div"),F(JL.$$.fragment),igr=l(),tve=a("p"),dgr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),cgr=l(),Yd=a("p"),fgr=o(`Note:
Loading a model from its configuration file does `),ave=a("strong"),mgr=o("not"),ggr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vQ=a("a"),hgr=o("from_pretrained()"),pgr=o(" to load the model weights."),ugr=l(),F(yT.$$.fragment),_gr=l(),Fo=a("div"),F(YL.$$.fragment),bgr=l(),nve=a("p"),vgr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Fgr=l(),rn=a("p"),Tgr=o("The model class to instantiate is selected based on the "),sve=a("code"),Mgr=o("model_type"),Egr=o(` property of the config object (either
passed as an argument or loaded from `),lve=a("code"),Cgr=o("pretrained_model_name_or_path"),wgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ive=a("code"),Agr=o("pretrained_model_name_or_path"),ygr=o(":"),Lgr=l(),dve=a("ul"),LT=a("li"),cve=a("strong"),xgr=o("maskformer"),$gr=o(" \u2014 "),FQ=a("a"),kgr=o("MaskFormerForInstanceSegmentation"),Sgr=o(" (MaskFormer model)"),Rgr=l(),xT=a("p"),Pgr=o("The model is set in evaluation mode by default using "),fve=a("code"),Bgr=o("model.eval()"),Igr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mve=a("code"),Ngr=o("model.train()"),qgr=l(),F($T.$$.fragment),$Ge=l(),Kd=a("h2"),kT=a("a"),gve=a("span"),F(KL.$$.fragment),jgr=l(),hve=a("span"),Dgr=o("TFAutoModel"),kGe=l(),Zo=a("div"),F(ZL.$$.fragment),Ggr=l(),Zd=a("p"),Ogr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),TQ=a("a"),Vgr=o("from_pretrained()"),Xgr=o(" class method or the "),MQ=a("a"),zgr=o("from_config()"),Wgr=o(` class
method.`),Qgr=l(),e8=a("p"),Hgr=o("This class cannot be instantiated directly using "),pve=a("code"),Ugr=o("__init__()"),Jgr=o(" (throws an error)."),Ygr=l(),$t=a("div"),F(o8.$$.fragment),Kgr=l(),uve=a("p"),Zgr=o("Instantiates one of the base model classes of the library from a configuration."),ehr=l(),ec=a("p"),ohr=o(`Note:
Loading a model from its configuration file does `),_ve=a("strong"),rhr=o("not"),thr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EQ=a("a"),ahr=o("from_pretrained()"),nhr=o(" to load the model weights."),shr=l(),F(ST.$$.fragment),lhr=l(),yr=a("div"),F(r8.$$.fragment),ihr=l(),bve=a("p"),dhr=o("Instantiate one of the base model classes of the library from a pretrained model."),chr=l(),tn=a("p"),fhr=o("The model class to instantiate is selected based on the "),vve=a("code"),mhr=o("model_type"),ghr=o(` property of the config object (either
passed as an argument or loaded from `),Fve=a("code"),hhr=o("pretrained_model_name_or_path"),phr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tve=a("code"),uhr=o("pretrained_model_name_or_path"),_hr=o(":"),bhr=l(),q=a("ul"),RT=a("li"),Mve=a("strong"),vhr=o("albert"),Fhr=o(" \u2014 "),CQ=a("a"),Thr=o("TFAlbertModel"),Mhr=o(" (ALBERT model)"),Ehr=l(),PT=a("li"),Eve=a("strong"),Chr=o("bart"),whr=o(" \u2014 "),wQ=a("a"),Ahr=o("TFBartModel"),yhr=o(" (BART model)"),Lhr=l(),BT=a("li"),Cve=a("strong"),xhr=o("bert"),$hr=o(" \u2014 "),AQ=a("a"),khr=o("TFBertModel"),Shr=o(" (BERT model)"),Rhr=l(),IT=a("li"),wve=a("strong"),Phr=o("blenderbot"),Bhr=o(" \u2014 "),yQ=a("a"),Ihr=o("TFBlenderbotModel"),Nhr=o(" (Blenderbot model)"),qhr=l(),NT=a("li"),Ave=a("strong"),jhr=o("blenderbot-small"),Dhr=o(" \u2014 "),LQ=a("a"),Ghr=o("TFBlenderbotSmallModel"),Ohr=o(" (BlenderbotSmall model)"),Vhr=l(),qT=a("li"),yve=a("strong"),Xhr=o("camembert"),zhr=o(" \u2014 "),xQ=a("a"),Whr=o("TFCamembertModel"),Qhr=o(" (CamemBERT model)"),Hhr=l(),jT=a("li"),Lve=a("strong"),Uhr=o("clip"),Jhr=o(" \u2014 "),$Q=a("a"),Yhr=o("TFCLIPModel"),Khr=o(" (CLIP model)"),Zhr=l(),DT=a("li"),xve=a("strong"),epr=o("convbert"),opr=o(" \u2014 "),kQ=a("a"),rpr=o("TFConvBertModel"),tpr=o(" (ConvBERT model)"),apr=l(),GT=a("li"),$ve=a("strong"),npr=o("convnext"),spr=o(" \u2014 "),SQ=a("a"),lpr=o("TFConvNextModel"),ipr=o(" (ConvNeXT model)"),dpr=l(),OT=a("li"),kve=a("strong"),cpr=o("ctrl"),fpr=o(" \u2014 "),RQ=a("a"),mpr=o("TFCTRLModel"),gpr=o(" (CTRL model)"),hpr=l(),VT=a("li"),Sve=a("strong"),ppr=o("data2vec-vision"),upr=o(" \u2014 "),PQ=a("a"),_pr=o("TFData2VecVisionModel"),bpr=o(" (Data2VecVision model)"),vpr=l(),XT=a("li"),Rve=a("strong"),Fpr=o("deberta"),Tpr=o(" \u2014 "),BQ=a("a"),Mpr=o("TFDebertaModel"),Epr=o(" (DeBERTa model)"),Cpr=l(),zT=a("li"),Pve=a("strong"),wpr=o("deberta-v2"),Apr=o(" \u2014 "),IQ=a("a"),ypr=o("TFDebertaV2Model"),Lpr=o(" (DeBERTa-v2 model)"),xpr=l(),WT=a("li"),Bve=a("strong"),$pr=o("distilbert"),kpr=o(" \u2014 "),NQ=a("a"),Spr=o("TFDistilBertModel"),Rpr=o(" (DistilBERT model)"),Ppr=l(),QT=a("li"),Ive=a("strong"),Bpr=o("dpr"),Ipr=o(" \u2014 "),qQ=a("a"),Npr=o("TFDPRQuestionEncoder"),qpr=o(" (DPR model)"),jpr=l(),HT=a("li"),Nve=a("strong"),Dpr=o("electra"),Gpr=o(" \u2014 "),jQ=a("a"),Opr=o("TFElectraModel"),Vpr=o(" (ELECTRA model)"),Xpr=l(),UT=a("li"),qve=a("strong"),zpr=o("flaubert"),Wpr=o(" \u2014 "),DQ=a("a"),Qpr=o("TFFlaubertModel"),Hpr=o(" (FlauBERT model)"),Upr=l(),Vs=a("li"),jve=a("strong"),Jpr=o("funnel"),Ypr=o(" \u2014 "),GQ=a("a"),Kpr=o("TFFunnelModel"),Zpr=o(" or "),OQ=a("a"),eur=o("TFFunnelBaseModel"),our=o(" (Funnel Transformer model)"),rur=l(),JT=a("li"),Dve=a("strong"),tur=o("gpt2"),aur=o(" \u2014 "),VQ=a("a"),nur=o("TFGPT2Model"),sur=o(" (OpenAI GPT-2 model)"),lur=l(),YT=a("li"),Gve=a("strong"),iur=o("gptj"),dur=o(" \u2014 "),XQ=a("a"),cur=o("TFGPTJModel"),fur=o(" (GPT-J model)"),mur=l(),KT=a("li"),Ove=a("strong"),gur=o("hubert"),hur=o(" \u2014 "),zQ=a("a"),pur=o("TFHubertModel"),uur=o(" (Hubert model)"),_ur=l(),ZT=a("li"),Vve=a("strong"),bur=o("layoutlm"),vur=o(" \u2014 "),WQ=a("a"),Fur=o("TFLayoutLMModel"),Tur=o(" (LayoutLM model)"),Mur=l(),e7=a("li"),Xve=a("strong"),Eur=o("led"),Cur=o(" \u2014 "),QQ=a("a"),wur=o("TFLEDModel"),Aur=o(" (LED model)"),yur=l(),o7=a("li"),zve=a("strong"),Lur=o("longformer"),xur=o(" \u2014 "),HQ=a("a"),$ur=o("TFLongformerModel"),kur=o(" (Longformer model)"),Sur=l(),r7=a("li"),Wve=a("strong"),Rur=o("lxmert"),Pur=o(" \u2014 "),UQ=a("a"),Bur=o("TFLxmertModel"),Iur=o(" (LXMERT model)"),Nur=l(),t7=a("li"),Qve=a("strong"),qur=o("marian"),jur=o(" \u2014 "),JQ=a("a"),Dur=o("TFMarianModel"),Gur=o(" (Marian model)"),Our=l(),a7=a("li"),Hve=a("strong"),Vur=o("mbart"),Xur=o(" \u2014 "),YQ=a("a"),zur=o("TFMBartModel"),Wur=o(" (mBART model)"),Qur=l(),n7=a("li"),Uve=a("strong"),Hur=o("mobilebert"),Uur=o(" \u2014 "),KQ=a("a"),Jur=o("TFMobileBertModel"),Yur=o(" (MobileBERT model)"),Kur=l(),s7=a("li"),Jve=a("strong"),Zur=o("mpnet"),e_r=o(" \u2014 "),ZQ=a("a"),o_r=o("TFMPNetModel"),r_r=o(" (MPNet model)"),t_r=l(),l7=a("li"),Yve=a("strong"),a_r=o("mt5"),n_r=o(" \u2014 "),eH=a("a"),s_r=o("TFMT5Model"),l_r=o(" (MT5 model)"),i_r=l(),i7=a("li"),Kve=a("strong"),d_r=o("openai-gpt"),c_r=o(" \u2014 "),oH=a("a"),f_r=o("TFOpenAIGPTModel"),m_r=o(" (OpenAI GPT model)"),g_r=l(),d7=a("li"),Zve=a("strong"),h_r=o("opt"),p_r=o(" \u2014 "),rH=a("a"),u_r=o("TFOPTModel"),__r=o(" (OPT model)"),b_r=l(),c7=a("li"),e3e=a("strong"),v_r=o("pegasus"),F_r=o(" \u2014 "),tH=a("a"),T_r=o("TFPegasusModel"),M_r=o(" (Pegasus model)"),E_r=l(),f7=a("li"),o3e=a("strong"),C_r=o("rembert"),w_r=o(" \u2014 "),aH=a("a"),A_r=o("TFRemBertModel"),y_r=o(" (RemBERT model)"),L_r=l(),m7=a("li"),r3e=a("strong"),x_r=o("roberta"),$_r=o(" \u2014 "),nH=a("a"),k_r=o("TFRobertaModel"),S_r=o(" (RoBERTa model)"),R_r=l(),g7=a("li"),t3e=a("strong"),P_r=o("roformer"),B_r=o(" \u2014 "),sH=a("a"),I_r=o("TFRoFormerModel"),N_r=o(" (RoFormer model)"),q_r=l(),h7=a("li"),a3e=a("strong"),j_r=o("speech_to_text"),D_r=o(" \u2014 "),lH=a("a"),G_r=o("TFSpeech2TextModel"),O_r=o(" (Speech2Text model)"),V_r=l(),p7=a("li"),n3e=a("strong"),X_r=o("swin"),z_r=o(" \u2014 "),iH=a("a"),W_r=o("TFSwinModel"),Q_r=o(" (Swin Transformer model)"),H_r=l(),u7=a("li"),s3e=a("strong"),U_r=o("t5"),J_r=o(" \u2014 "),dH=a("a"),Y_r=o("TFT5Model"),K_r=o(" (T5 model)"),Z_r=l(),_7=a("li"),l3e=a("strong"),e1r=o("tapas"),o1r=o(" \u2014 "),cH=a("a"),r1r=o("TFTapasModel"),t1r=o(" (TAPAS model)"),a1r=l(),b7=a("li"),i3e=a("strong"),n1r=o("transfo-xl"),s1r=o(" \u2014 "),fH=a("a"),l1r=o("TFTransfoXLModel"),i1r=o(" (Transformer-XL model)"),d1r=l(),v7=a("li"),d3e=a("strong"),c1r=o("vit"),f1r=o(" \u2014 "),mH=a("a"),m1r=o("TFViTModel"),g1r=o(" (ViT model)"),h1r=l(),F7=a("li"),c3e=a("strong"),p1r=o("vit_mae"),u1r=o(" \u2014 "),gH=a("a"),_1r=o("TFViTMAEModel"),b1r=o(" (ViTMAE model)"),v1r=l(),T7=a("li"),f3e=a("strong"),F1r=o("wav2vec2"),T1r=o(" \u2014 "),hH=a("a"),M1r=o("TFWav2Vec2Model"),E1r=o(" (Wav2Vec2 model)"),C1r=l(),M7=a("li"),m3e=a("strong"),w1r=o("xlm"),A1r=o(" \u2014 "),pH=a("a"),y1r=o("TFXLMModel"),L1r=o(" (XLM model)"),x1r=l(),E7=a("li"),g3e=a("strong"),$1r=o("xlm-roberta"),k1r=o(" \u2014 "),uH=a("a"),S1r=o("TFXLMRobertaModel"),R1r=o(" (XLM-RoBERTa model)"),P1r=l(),C7=a("li"),h3e=a("strong"),B1r=o("xlnet"),I1r=o(" \u2014 "),_H=a("a"),N1r=o("TFXLNetModel"),q1r=o(" (XLNet model)"),j1r=l(),F(w7.$$.fragment),SGe=l(),oc=a("h2"),A7=a("a"),p3e=a("span"),F(t8.$$.fragment),D1r=l(),u3e=a("span"),G1r=o("TFAutoModelForPreTraining"),RGe=l(),er=a("div"),F(a8.$$.fragment),O1r=l(),rc=a("p"),V1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),bH=a("a"),X1r=o("from_pretrained()"),z1r=o(" class method or the "),vH=a("a"),W1r=o("from_config()"),Q1r=o(` class
method.`),H1r=l(),n8=a("p"),U1r=o("This class cannot be instantiated directly using "),_3e=a("code"),J1r=o("__init__()"),Y1r=o(" (throws an error)."),K1r=l(),kt=a("div"),F(s8.$$.fragment),Z1r=l(),b3e=a("p"),ebr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),obr=l(),tc=a("p"),rbr=o(`Note:
Loading a model from its configuration file does `),v3e=a("strong"),tbr=o("not"),abr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=a("a"),nbr=o("from_pretrained()"),sbr=o(" to load the model weights."),lbr=l(),F(y7.$$.fragment),ibr=l(),Lr=a("div"),F(l8.$$.fragment),dbr=l(),F3e=a("p"),cbr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),fbr=l(),an=a("p"),mbr=o("The model class to instantiate is selected based on the "),T3e=a("code"),gbr=o("model_type"),hbr=o(` property of the config object (either
passed as an argument or loaded from `),M3e=a("code"),pbr=o("pretrained_model_name_or_path"),ubr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E3e=a("code"),_br=o("pretrained_model_name_or_path"),bbr=o(":"),vbr=l(),se=a("ul"),L7=a("li"),C3e=a("strong"),Fbr=o("albert"),Tbr=o(" \u2014 "),TH=a("a"),Mbr=o("TFAlbertForPreTraining"),Ebr=o(" (ALBERT model)"),Cbr=l(),x7=a("li"),w3e=a("strong"),wbr=o("bart"),Abr=o(" \u2014 "),MH=a("a"),ybr=o("TFBartForConditionalGeneration"),Lbr=o(" (BART model)"),xbr=l(),$7=a("li"),A3e=a("strong"),$br=o("bert"),kbr=o(" \u2014 "),EH=a("a"),Sbr=o("TFBertForPreTraining"),Rbr=o(" (BERT model)"),Pbr=l(),k7=a("li"),y3e=a("strong"),Bbr=o("camembert"),Ibr=o(" \u2014 "),CH=a("a"),Nbr=o("TFCamembertForMaskedLM"),qbr=o(" (CamemBERT model)"),jbr=l(),S7=a("li"),L3e=a("strong"),Dbr=o("ctrl"),Gbr=o(" \u2014 "),wH=a("a"),Obr=o("TFCTRLLMHeadModel"),Vbr=o(" (CTRL model)"),Xbr=l(),R7=a("li"),x3e=a("strong"),zbr=o("distilbert"),Wbr=o(" \u2014 "),AH=a("a"),Qbr=o("TFDistilBertForMaskedLM"),Hbr=o(" (DistilBERT model)"),Ubr=l(),P7=a("li"),$3e=a("strong"),Jbr=o("electra"),Ybr=o(" \u2014 "),yH=a("a"),Kbr=o("TFElectraForPreTraining"),Zbr=o(" (ELECTRA model)"),e2r=l(),B7=a("li"),k3e=a("strong"),o2r=o("flaubert"),r2r=o(" \u2014 "),LH=a("a"),t2r=o("TFFlaubertWithLMHeadModel"),a2r=o(" (FlauBERT model)"),n2r=l(),I7=a("li"),S3e=a("strong"),s2r=o("funnel"),l2r=o(" \u2014 "),xH=a("a"),i2r=o("TFFunnelForPreTraining"),d2r=o(" (Funnel Transformer model)"),c2r=l(),N7=a("li"),R3e=a("strong"),f2r=o("gpt2"),m2r=o(" \u2014 "),$H=a("a"),g2r=o("TFGPT2LMHeadModel"),h2r=o(" (OpenAI GPT-2 model)"),p2r=l(),q7=a("li"),P3e=a("strong"),u2r=o("layoutlm"),_2r=o(" \u2014 "),kH=a("a"),b2r=o("TFLayoutLMForMaskedLM"),v2r=o(" (LayoutLM model)"),F2r=l(),j7=a("li"),B3e=a("strong"),T2r=o("lxmert"),M2r=o(" \u2014 "),SH=a("a"),E2r=o("TFLxmertForPreTraining"),C2r=o(" (LXMERT model)"),w2r=l(),D7=a("li"),I3e=a("strong"),A2r=o("mobilebert"),y2r=o(" \u2014 "),RH=a("a"),L2r=o("TFMobileBertForPreTraining"),x2r=o(" (MobileBERT model)"),$2r=l(),G7=a("li"),N3e=a("strong"),k2r=o("mpnet"),S2r=o(" \u2014 "),PH=a("a"),R2r=o("TFMPNetForMaskedLM"),P2r=o(" (MPNet model)"),B2r=l(),O7=a("li"),q3e=a("strong"),I2r=o("openai-gpt"),N2r=o(" \u2014 "),BH=a("a"),q2r=o("TFOpenAIGPTLMHeadModel"),j2r=o(" (OpenAI GPT model)"),D2r=l(),V7=a("li"),j3e=a("strong"),G2r=o("roberta"),O2r=o(" \u2014 "),IH=a("a"),V2r=o("TFRobertaForMaskedLM"),X2r=o(" (RoBERTa model)"),z2r=l(),X7=a("li"),D3e=a("strong"),W2r=o("t5"),Q2r=o(" \u2014 "),NH=a("a"),H2r=o("TFT5ForConditionalGeneration"),U2r=o(" (T5 model)"),J2r=l(),z7=a("li"),G3e=a("strong"),Y2r=o("tapas"),K2r=o(" \u2014 "),qH=a("a"),Z2r=o("TFTapasForMaskedLM"),evr=o(" (TAPAS model)"),ovr=l(),W7=a("li"),O3e=a("strong"),rvr=o("transfo-xl"),tvr=o(" \u2014 "),jH=a("a"),avr=o("TFTransfoXLLMHeadModel"),nvr=o(" (Transformer-XL model)"),svr=l(),Q7=a("li"),V3e=a("strong"),lvr=o("vit_mae"),ivr=o(" \u2014 "),DH=a("a"),dvr=o("TFViTMAEForPreTraining"),cvr=o(" (ViTMAE model)"),fvr=l(),H7=a("li"),X3e=a("strong"),mvr=o("xlm"),gvr=o(" \u2014 "),GH=a("a"),hvr=o("TFXLMWithLMHeadModel"),pvr=o(" (XLM model)"),uvr=l(),U7=a("li"),z3e=a("strong"),_vr=o("xlm-roberta"),bvr=o(" \u2014 "),OH=a("a"),vvr=o("TFXLMRobertaForMaskedLM"),Fvr=o(" (XLM-RoBERTa model)"),Tvr=l(),J7=a("li"),W3e=a("strong"),Mvr=o("xlnet"),Evr=o(" \u2014 "),VH=a("a"),Cvr=o("TFXLNetLMHeadModel"),wvr=o(" (XLNet model)"),Avr=l(),F(Y7.$$.fragment),PGe=l(),ac=a("h2"),K7=a("a"),Q3e=a("span"),F(i8.$$.fragment),yvr=l(),H3e=a("span"),Lvr=o("TFAutoModelForCausalLM"),BGe=l(),or=a("div"),F(d8.$$.fragment),xvr=l(),nc=a("p"),$vr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),XH=a("a"),kvr=o("from_pretrained()"),Svr=o(" class method or the "),zH=a("a"),Rvr=o("from_config()"),Pvr=o(` class
method.`),Bvr=l(),c8=a("p"),Ivr=o("This class cannot be instantiated directly using "),U3e=a("code"),Nvr=o("__init__()"),qvr=o(" (throws an error)."),jvr=l(),St=a("div"),F(f8.$$.fragment),Dvr=l(),J3e=a("p"),Gvr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Ovr=l(),sc=a("p"),Vvr=o(`Note:
Loading a model from its configuration file does `),Y3e=a("strong"),Xvr=o("not"),zvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WH=a("a"),Wvr=o("from_pretrained()"),Qvr=o(" to load the model weights."),Hvr=l(),F(Z7.$$.fragment),Uvr=l(),xr=a("div"),F(m8.$$.fragment),Jvr=l(),K3e=a("p"),Yvr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Kvr=l(),nn=a("p"),Zvr=o("The model class to instantiate is selected based on the "),Z3e=a("code"),e3r=o("model_type"),o3r=o(` property of the config object (either
passed as an argument or loaded from `),eFe=a("code"),r3r=o("pretrained_model_name_or_path"),t3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=a("code"),a3r=o("pretrained_model_name_or_path"),n3r=o(":"),s3r=l(),Me=a("ul"),e9=a("li"),rFe=a("strong"),l3r=o("bert"),i3r=o(" \u2014 "),QH=a("a"),d3r=o("TFBertLMHeadModel"),c3r=o(" (BERT model)"),f3r=l(),o9=a("li"),tFe=a("strong"),m3r=o("camembert"),g3r=o(" \u2014 "),HH=a("a"),h3r=o("TFCamembertForCausalLM"),p3r=o(" (CamemBERT model)"),u3r=l(),r9=a("li"),aFe=a("strong"),_3r=o("ctrl"),b3r=o(" \u2014 "),UH=a("a"),v3r=o("TFCTRLLMHeadModel"),F3r=o(" (CTRL model)"),T3r=l(),t9=a("li"),nFe=a("strong"),M3r=o("gpt2"),E3r=o(" \u2014 "),JH=a("a"),C3r=o("TFGPT2LMHeadModel"),w3r=o(" (OpenAI GPT-2 model)"),A3r=l(),a9=a("li"),sFe=a("strong"),y3r=o("gptj"),L3r=o(" \u2014 "),YH=a("a"),x3r=o("TFGPTJForCausalLM"),$3r=o(" (GPT-J model)"),k3r=l(),n9=a("li"),lFe=a("strong"),S3r=o("openai-gpt"),R3r=o(" \u2014 "),KH=a("a"),P3r=o("TFOpenAIGPTLMHeadModel"),B3r=o(" (OpenAI GPT model)"),I3r=l(),s9=a("li"),iFe=a("strong"),N3r=o("opt"),q3r=o(" \u2014 "),ZH=a("a"),j3r=o("TFOPTForCausalLM"),D3r=o(" (OPT model)"),G3r=l(),l9=a("li"),dFe=a("strong"),O3r=o("rembert"),V3r=o(" \u2014 "),eU=a("a"),X3r=o("TFRemBertForCausalLM"),z3r=o(" (RemBERT model)"),W3r=l(),i9=a("li"),cFe=a("strong"),Q3r=o("roberta"),H3r=o(" \u2014 "),oU=a("a"),U3r=o("TFRobertaForCausalLM"),J3r=o(" (RoBERTa model)"),Y3r=l(),d9=a("li"),fFe=a("strong"),K3r=o("roformer"),Z3r=o(" \u2014 "),rU=a("a"),eFr=o("TFRoFormerForCausalLM"),oFr=o(" (RoFormer model)"),rFr=l(),c9=a("li"),mFe=a("strong"),tFr=o("transfo-xl"),aFr=o(" \u2014 "),tU=a("a"),nFr=o("TFTransfoXLLMHeadModel"),sFr=o(" (Transformer-XL model)"),lFr=l(),f9=a("li"),gFe=a("strong"),iFr=o("xlm"),dFr=o(" \u2014 "),aU=a("a"),cFr=o("TFXLMWithLMHeadModel"),fFr=o(" (XLM model)"),mFr=l(),m9=a("li"),hFe=a("strong"),gFr=o("xlnet"),hFr=o(" \u2014 "),nU=a("a"),pFr=o("TFXLNetLMHeadModel"),uFr=o(" (XLNet model)"),_Fr=l(),F(g9.$$.fragment),IGe=l(),lc=a("h2"),h9=a("a"),pFe=a("span"),F(g8.$$.fragment),bFr=l(),uFe=a("span"),vFr=o("TFAutoModelForImageClassification"),NGe=l(),rr=a("div"),F(h8.$$.fragment),FFr=l(),ic=a("p"),TFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),sU=a("a"),MFr=o("from_pretrained()"),EFr=o(" class method or the "),lU=a("a"),CFr=o("from_config()"),wFr=o(` class
method.`),AFr=l(),p8=a("p"),yFr=o("This class cannot be instantiated directly using "),_Fe=a("code"),LFr=o("__init__()"),xFr=o(" (throws an error)."),$Fr=l(),Rt=a("div"),F(u8.$$.fragment),kFr=l(),bFe=a("p"),SFr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),RFr=l(),dc=a("p"),PFr=o(`Note:
Loading a model from its configuration file does `),vFe=a("strong"),BFr=o("not"),IFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iU=a("a"),NFr=o("from_pretrained()"),qFr=o(" to load the model weights."),jFr=l(),F(p9.$$.fragment),DFr=l(),$r=a("div"),F(_8.$$.fragment),GFr=l(),FFe=a("p"),OFr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),VFr=l(),sn=a("p"),XFr=o("The model class to instantiate is selected based on the "),TFe=a("code"),zFr=o("model_type"),WFr=o(` property of the config object (either
passed as an argument or loaded from `),MFe=a("code"),QFr=o("pretrained_model_name_or_path"),HFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EFe=a("code"),UFr=o("pretrained_model_name_or_path"),JFr=o(":"),YFr=l(),ln=a("ul"),u9=a("li"),CFe=a("strong"),KFr=o("convnext"),ZFr=o(" \u2014 "),dU=a("a"),e6r=o("TFConvNextForImageClassification"),o6r=o(" (ConvNeXT model)"),r6r=l(),_9=a("li"),wFe=a("strong"),t6r=o("data2vec-vision"),a6r=o(" \u2014 "),cU=a("a"),n6r=o("TFData2VecVisionForImageClassification"),s6r=o(" (Data2VecVision model)"),l6r=l(),b9=a("li"),AFe=a("strong"),i6r=o("swin"),d6r=o(" \u2014 "),fU=a("a"),c6r=o("TFSwinForImageClassification"),f6r=o(" (Swin Transformer model)"),m6r=l(),v9=a("li"),yFe=a("strong"),g6r=o("vit"),h6r=o(" \u2014 "),mU=a("a"),p6r=o("TFViTForImageClassification"),u6r=o(" (ViT model)"),_6r=l(),F(F9.$$.fragment),qGe=l(),cc=a("h2"),T9=a("a"),LFe=a("span"),F(b8.$$.fragment),b6r=l(),xFe=a("span"),v6r=o("TFAutoModelForMaskedLM"),jGe=l(),tr=a("div"),F(v8.$$.fragment),F6r=l(),fc=a("p"),T6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gU=a("a"),M6r=o("from_pretrained()"),E6r=o(" class method or the "),hU=a("a"),C6r=o("from_config()"),w6r=o(` class
method.`),A6r=l(),F8=a("p"),y6r=o("This class cannot be instantiated directly using "),$Fe=a("code"),L6r=o("__init__()"),x6r=o(" (throws an error)."),$6r=l(),Pt=a("div"),F(T8.$$.fragment),k6r=l(),kFe=a("p"),S6r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),R6r=l(),mc=a("p"),P6r=o(`Note:
Loading a model from its configuration file does `),SFe=a("strong"),B6r=o("not"),I6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pU=a("a"),N6r=o("from_pretrained()"),q6r=o(" to load the model weights."),j6r=l(),F(M9.$$.fragment),D6r=l(),kr=a("div"),F(M8.$$.fragment),G6r=l(),RFe=a("p"),O6r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),V6r=l(),dn=a("p"),X6r=o("The model class to instantiate is selected based on the "),PFe=a("code"),z6r=o("model_type"),W6r=o(` property of the config object (either
passed as an argument or loaded from `),BFe=a("code"),Q6r=o("pretrained_model_name_or_path"),H6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IFe=a("code"),U6r=o("pretrained_model_name_or_path"),J6r=o(":"),Y6r=l(),ie=a("ul"),E9=a("li"),NFe=a("strong"),K6r=o("albert"),Z6r=o(" \u2014 "),uU=a("a"),eTr=o("TFAlbertForMaskedLM"),oTr=o(" (ALBERT model)"),rTr=l(),C9=a("li"),qFe=a("strong"),tTr=o("bert"),aTr=o(" \u2014 "),_U=a("a"),nTr=o("TFBertForMaskedLM"),sTr=o(" (BERT model)"),lTr=l(),w9=a("li"),jFe=a("strong"),iTr=o("camembert"),dTr=o(" \u2014 "),bU=a("a"),cTr=o("TFCamembertForMaskedLM"),fTr=o(" (CamemBERT model)"),mTr=l(),A9=a("li"),DFe=a("strong"),gTr=o("convbert"),hTr=o(" \u2014 "),vU=a("a"),pTr=o("TFConvBertForMaskedLM"),uTr=o(" (ConvBERT model)"),_Tr=l(),y9=a("li"),GFe=a("strong"),bTr=o("deberta"),vTr=o(" \u2014 "),FU=a("a"),FTr=o("TFDebertaForMaskedLM"),TTr=o(" (DeBERTa model)"),MTr=l(),L9=a("li"),OFe=a("strong"),ETr=o("deberta-v2"),CTr=o(" \u2014 "),TU=a("a"),wTr=o("TFDebertaV2ForMaskedLM"),ATr=o(" (DeBERTa-v2 model)"),yTr=l(),x9=a("li"),VFe=a("strong"),LTr=o("distilbert"),xTr=o(" \u2014 "),MU=a("a"),$Tr=o("TFDistilBertForMaskedLM"),kTr=o(" (DistilBERT model)"),STr=l(),$9=a("li"),XFe=a("strong"),RTr=o("electra"),PTr=o(" \u2014 "),EU=a("a"),BTr=o("TFElectraForMaskedLM"),ITr=o(" (ELECTRA model)"),NTr=l(),k9=a("li"),zFe=a("strong"),qTr=o("flaubert"),jTr=o(" \u2014 "),CU=a("a"),DTr=o("TFFlaubertWithLMHeadModel"),GTr=o(" (FlauBERT model)"),OTr=l(),S9=a("li"),WFe=a("strong"),VTr=o("funnel"),XTr=o(" \u2014 "),wU=a("a"),zTr=o("TFFunnelForMaskedLM"),WTr=o(" (Funnel Transformer model)"),QTr=l(),R9=a("li"),QFe=a("strong"),HTr=o("layoutlm"),UTr=o(" \u2014 "),AU=a("a"),JTr=o("TFLayoutLMForMaskedLM"),YTr=o(" (LayoutLM model)"),KTr=l(),P9=a("li"),HFe=a("strong"),ZTr=o("longformer"),e7r=o(" \u2014 "),yU=a("a"),o7r=o("TFLongformerForMaskedLM"),r7r=o(" (Longformer model)"),t7r=l(),B9=a("li"),UFe=a("strong"),a7r=o("mobilebert"),n7r=o(" \u2014 "),LU=a("a"),s7r=o("TFMobileBertForMaskedLM"),l7r=o(" (MobileBERT model)"),i7r=l(),I9=a("li"),JFe=a("strong"),d7r=o("mpnet"),c7r=o(" \u2014 "),xU=a("a"),f7r=o("TFMPNetForMaskedLM"),m7r=o(" (MPNet model)"),g7r=l(),N9=a("li"),YFe=a("strong"),h7r=o("rembert"),p7r=o(" \u2014 "),$U=a("a"),u7r=o("TFRemBertForMaskedLM"),_7r=o(" (RemBERT model)"),b7r=l(),q9=a("li"),KFe=a("strong"),v7r=o("roberta"),F7r=o(" \u2014 "),kU=a("a"),T7r=o("TFRobertaForMaskedLM"),M7r=o(" (RoBERTa model)"),E7r=l(),j9=a("li"),ZFe=a("strong"),C7r=o("roformer"),w7r=o(" \u2014 "),SU=a("a"),A7r=o("TFRoFormerForMaskedLM"),y7r=o(" (RoFormer model)"),L7r=l(),D9=a("li"),e6e=a("strong"),x7r=o("tapas"),$7r=o(" \u2014 "),RU=a("a"),k7r=o("TFTapasForMaskedLM"),S7r=o(" (TAPAS model)"),R7r=l(),G9=a("li"),o6e=a("strong"),P7r=o("xlm"),B7r=o(" \u2014 "),PU=a("a"),I7r=o("TFXLMWithLMHeadModel"),N7r=o(" (XLM model)"),q7r=l(),O9=a("li"),r6e=a("strong"),j7r=o("xlm-roberta"),D7r=o(" \u2014 "),BU=a("a"),G7r=o("TFXLMRobertaForMaskedLM"),O7r=o(" (XLM-RoBERTa model)"),V7r=l(),F(V9.$$.fragment),DGe=l(),gc=a("h2"),X9=a("a"),t6e=a("span"),F(E8.$$.fragment),X7r=l(),a6e=a("span"),z7r=o("TFAutoModelForSeq2SeqLM"),GGe=l(),ar=a("div"),F(C8.$$.fragment),W7r=l(),hc=a("p"),Q7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),IU=a("a"),H7r=o("from_pretrained()"),U7r=o(" class method or the "),NU=a("a"),J7r=o("from_config()"),Y7r=o(` class
method.`),K7r=l(),w8=a("p"),Z7r=o("This class cannot be instantiated directly using "),n6e=a("code"),e9r=o("__init__()"),o9r=o(" (throws an error)."),r9r=l(),Bt=a("div"),F(A8.$$.fragment),t9r=l(),s6e=a("p"),a9r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),n9r=l(),pc=a("p"),s9r=o(`Note:
Loading a model from its configuration file does `),l6e=a("strong"),l9r=o("not"),i9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=a("a"),d9r=o("from_pretrained()"),c9r=o(" to load the model weights."),f9r=l(),F(z9.$$.fragment),m9r=l(),Sr=a("div"),F(y8.$$.fragment),g9r=l(),i6e=a("p"),h9r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),p9r=l(),cn=a("p"),u9r=o("The model class to instantiate is selected based on the "),d6e=a("code"),_9r=o("model_type"),b9r=o(` property of the config object (either
passed as an argument or loaded from `),c6e=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f6e=a("code"),T9r=o("pretrained_model_name_or_path"),M9r=o(":"),E9r=l(),Le=a("ul"),W9=a("li"),m6e=a("strong"),C9r=o("bart"),w9r=o(" \u2014 "),jU=a("a"),A9r=o("TFBartForConditionalGeneration"),y9r=o(" (BART model)"),L9r=l(),Q9=a("li"),g6e=a("strong"),x9r=o("blenderbot"),$9r=o(" \u2014 "),DU=a("a"),k9r=o("TFBlenderbotForConditionalGeneration"),S9r=o(" (Blenderbot model)"),R9r=l(),H9=a("li"),h6e=a("strong"),P9r=o("blenderbot-small"),B9r=o(" \u2014 "),GU=a("a"),I9r=o("TFBlenderbotSmallForConditionalGeneration"),N9r=o(" (BlenderbotSmall model)"),q9r=l(),U9=a("li"),p6e=a("strong"),j9r=o("encoder-decoder"),D9r=o(" \u2014 "),OU=a("a"),G9r=o("TFEncoderDecoderModel"),O9r=o(" (Encoder decoder model)"),V9r=l(),J9=a("li"),u6e=a("strong"),X9r=o("led"),z9r=o(" \u2014 "),VU=a("a"),W9r=o("TFLEDForConditionalGeneration"),Q9r=o(" (LED model)"),H9r=l(),Y9=a("li"),_6e=a("strong"),U9r=o("marian"),J9r=o(" \u2014 "),XU=a("a"),Y9r=o("TFMarianMTModel"),K9r=o(" (Marian model)"),Z9r=l(),K9=a("li"),b6e=a("strong"),eMr=o("mbart"),oMr=o(" \u2014 "),zU=a("a"),rMr=o("TFMBartForConditionalGeneration"),tMr=o(" (mBART model)"),aMr=l(),Z9=a("li"),v6e=a("strong"),nMr=o("mt5"),sMr=o(" \u2014 "),WU=a("a"),lMr=o("TFMT5ForConditionalGeneration"),iMr=o(" (MT5 model)"),dMr=l(),eM=a("li"),F6e=a("strong"),cMr=o("pegasus"),fMr=o(" \u2014 "),QU=a("a"),mMr=o("TFPegasusForConditionalGeneration"),gMr=o(" (Pegasus model)"),hMr=l(),oM=a("li"),T6e=a("strong"),pMr=o("t5"),uMr=o(" \u2014 "),HU=a("a"),_Mr=o("TFT5ForConditionalGeneration"),bMr=o(" (T5 model)"),vMr=l(),F(rM.$$.fragment),OGe=l(),uc=a("h2"),tM=a("a"),M6e=a("span"),F(L8.$$.fragment),FMr=l(),E6e=a("span"),TMr=o("TFAutoModelForSequenceClassification"),VGe=l(),nr=a("div"),F(x8.$$.fragment),MMr=l(),_c=a("p"),EMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),UU=a("a"),CMr=o("from_pretrained()"),wMr=o(" class method or the "),JU=a("a"),AMr=o("from_config()"),yMr=o(` class
method.`),LMr=l(),$8=a("p"),xMr=o("This class cannot be instantiated directly using "),C6e=a("code"),$Mr=o("__init__()"),kMr=o(" (throws an error)."),SMr=l(),It=a("div"),F(k8.$$.fragment),RMr=l(),w6e=a("p"),PMr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),BMr=l(),bc=a("p"),IMr=o(`Note:
Loading a model from its configuration file does `),A6e=a("strong"),NMr=o("not"),qMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YU=a("a"),jMr=o("from_pretrained()"),DMr=o(" to load the model weights."),GMr=l(),F(aM.$$.fragment),OMr=l(),Rr=a("div"),F(S8.$$.fragment),VMr=l(),y6e=a("p"),XMr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),zMr=l(),fn=a("p"),WMr=o("The model class to instantiate is selected based on the "),L6e=a("code"),QMr=o("model_type"),HMr=o(` property of the config object (either
passed as an argument or loaded from `),x6e=a("code"),UMr=o("pretrained_model_name_or_path"),JMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$6e=a("code"),YMr=o("pretrained_model_name_or_path"),KMr=o(":"),ZMr=l(),re=a("ul"),nM=a("li"),k6e=a("strong"),e4r=o("albert"),o4r=o(" \u2014 "),KU=a("a"),r4r=o("TFAlbertForSequenceClassification"),t4r=o(" (ALBERT model)"),a4r=l(),sM=a("li"),S6e=a("strong"),n4r=o("bert"),s4r=o(" \u2014 "),ZU=a("a"),l4r=o("TFBertForSequenceClassification"),i4r=o(" (BERT model)"),d4r=l(),lM=a("li"),R6e=a("strong"),c4r=o("camembert"),f4r=o(" \u2014 "),eJ=a("a"),m4r=o("TFCamembertForSequenceClassification"),g4r=o(" (CamemBERT model)"),h4r=l(),iM=a("li"),P6e=a("strong"),p4r=o("convbert"),u4r=o(" \u2014 "),oJ=a("a"),_4r=o("TFConvBertForSequenceClassification"),b4r=o(" (ConvBERT model)"),v4r=l(),dM=a("li"),B6e=a("strong"),F4r=o("ctrl"),T4r=o(" \u2014 "),rJ=a("a"),M4r=o("TFCTRLForSequenceClassification"),E4r=o(" (CTRL model)"),C4r=l(),cM=a("li"),I6e=a("strong"),w4r=o("deberta"),A4r=o(" \u2014 "),tJ=a("a"),y4r=o("TFDebertaForSequenceClassification"),L4r=o(" (DeBERTa model)"),x4r=l(),fM=a("li"),N6e=a("strong"),$4r=o("deberta-v2"),k4r=o(" \u2014 "),aJ=a("a"),S4r=o("TFDebertaV2ForSequenceClassification"),R4r=o(" (DeBERTa-v2 model)"),P4r=l(),mM=a("li"),q6e=a("strong"),B4r=o("distilbert"),I4r=o(" \u2014 "),nJ=a("a"),N4r=o("TFDistilBertForSequenceClassification"),q4r=o(" (DistilBERT model)"),j4r=l(),gM=a("li"),j6e=a("strong"),D4r=o("electra"),G4r=o(" \u2014 "),sJ=a("a"),O4r=o("TFElectraForSequenceClassification"),V4r=o(" (ELECTRA model)"),X4r=l(),hM=a("li"),D6e=a("strong"),z4r=o("flaubert"),W4r=o(" \u2014 "),lJ=a("a"),Q4r=o("TFFlaubertForSequenceClassification"),H4r=o(" (FlauBERT model)"),U4r=l(),pM=a("li"),G6e=a("strong"),J4r=o("funnel"),Y4r=o(" \u2014 "),iJ=a("a"),K4r=o("TFFunnelForSequenceClassification"),Z4r=o(" (Funnel Transformer model)"),eEr=l(),uM=a("li"),O6e=a("strong"),oEr=o("gpt2"),rEr=o(" \u2014 "),dJ=a("a"),tEr=o("TFGPT2ForSequenceClassification"),aEr=o(" (OpenAI GPT-2 model)"),nEr=l(),_M=a("li"),V6e=a("strong"),sEr=o("gptj"),lEr=o(" \u2014 "),cJ=a("a"),iEr=o("TFGPTJForSequenceClassification"),dEr=o(" (GPT-J model)"),cEr=l(),bM=a("li"),X6e=a("strong"),fEr=o("layoutlm"),mEr=o(" \u2014 "),fJ=a("a"),gEr=o("TFLayoutLMForSequenceClassification"),hEr=o(" (LayoutLM model)"),pEr=l(),vM=a("li"),z6e=a("strong"),uEr=o("longformer"),_Er=o(" \u2014 "),mJ=a("a"),bEr=o("TFLongformerForSequenceClassification"),vEr=o(" (Longformer model)"),FEr=l(),FM=a("li"),W6e=a("strong"),TEr=o("mobilebert"),MEr=o(" \u2014 "),gJ=a("a"),EEr=o("TFMobileBertForSequenceClassification"),CEr=o(" (MobileBERT model)"),wEr=l(),TM=a("li"),Q6e=a("strong"),AEr=o("mpnet"),yEr=o(" \u2014 "),hJ=a("a"),LEr=o("TFMPNetForSequenceClassification"),xEr=o(" (MPNet model)"),$Er=l(),MM=a("li"),H6e=a("strong"),kEr=o("openai-gpt"),SEr=o(" \u2014 "),pJ=a("a"),REr=o("TFOpenAIGPTForSequenceClassification"),PEr=o(" (OpenAI GPT model)"),BEr=l(),EM=a("li"),U6e=a("strong"),IEr=o("rembert"),NEr=o(" \u2014 "),uJ=a("a"),qEr=o("TFRemBertForSequenceClassification"),jEr=o(" (RemBERT model)"),DEr=l(),CM=a("li"),J6e=a("strong"),GEr=o("roberta"),OEr=o(" \u2014 "),_J=a("a"),VEr=o("TFRobertaForSequenceClassification"),XEr=o(" (RoBERTa model)"),zEr=l(),wM=a("li"),Y6e=a("strong"),WEr=o("roformer"),QEr=o(" \u2014 "),bJ=a("a"),HEr=o("TFRoFormerForSequenceClassification"),UEr=o(" (RoFormer model)"),JEr=l(),AM=a("li"),K6e=a("strong"),YEr=o("tapas"),KEr=o(" \u2014 "),vJ=a("a"),ZEr=o("TFTapasForSequenceClassification"),eCr=o(" (TAPAS model)"),oCr=l(),yM=a("li"),Z6e=a("strong"),rCr=o("transfo-xl"),tCr=o(" \u2014 "),FJ=a("a"),aCr=o("TFTransfoXLForSequenceClassification"),nCr=o(" (Transformer-XL model)"),sCr=l(),LM=a("li"),eTe=a("strong"),lCr=o("xlm"),iCr=o(" \u2014 "),TJ=a("a"),dCr=o("TFXLMForSequenceClassification"),cCr=o(" (XLM model)"),fCr=l(),xM=a("li"),oTe=a("strong"),mCr=o("xlm-roberta"),gCr=o(" \u2014 "),MJ=a("a"),hCr=o("TFXLMRobertaForSequenceClassification"),pCr=o(" (XLM-RoBERTa model)"),uCr=l(),$M=a("li"),rTe=a("strong"),_Cr=o("xlnet"),bCr=o(" \u2014 "),EJ=a("a"),vCr=o("TFXLNetForSequenceClassification"),FCr=o(" (XLNet model)"),TCr=l(),F(kM.$$.fragment),XGe=l(),vc=a("h2"),SM=a("a"),tTe=a("span"),F(R8.$$.fragment),MCr=l(),aTe=a("span"),ECr=o("TFAutoModelForMultipleChoice"),zGe=l(),sr=a("div"),F(P8.$$.fragment),CCr=l(),Fc=a("p"),wCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),CJ=a("a"),ACr=o("from_pretrained()"),yCr=o(" class method or the "),wJ=a("a"),LCr=o("from_config()"),xCr=o(` class
method.`),$Cr=l(),B8=a("p"),kCr=o("This class cannot be instantiated directly using "),nTe=a("code"),SCr=o("__init__()"),RCr=o(" (throws an error)."),PCr=l(),Nt=a("div"),F(I8.$$.fragment),BCr=l(),sTe=a("p"),ICr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),NCr=l(),Tc=a("p"),qCr=o(`Note:
Loading a model from its configuration file does `),lTe=a("strong"),jCr=o("not"),DCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AJ=a("a"),GCr=o("from_pretrained()"),OCr=o(" to load the model weights."),VCr=l(),F(RM.$$.fragment),XCr=l(),Pr=a("div"),F(N8.$$.fragment),zCr=l(),iTe=a("p"),WCr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),QCr=l(),mn=a("p"),HCr=o("The model class to instantiate is selected based on the "),dTe=a("code"),UCr=o("model_type"),JCr=o(` property of the config object (either
passed as an argument or loaded from `),cTe=a("code"),YCr=o("pretrained_model_name_or_path"),KCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fTe=a("code"),ZCr=o("pretrained_model_name_or_path"),e5r=o(":"),o5r=l(),pe=a("ul"),PM=a("li"),mTe=a("strong"),r5r=o("albert"),t5r=o(" \u2014 "),yJ=a("a"),a5r=o("TFAlbertForMultipleChoice"),n5r=o(" (ALBERT model)"),s5r=l(),BM=a("li"),gTe=a("strong"),l5r=o("bert"),i5r=o(" \u2014 "),LJ=a("a"),d5r=o("TFBertForMultipleChoice"),c5r=o(" (BERT model)"),f5r=l(),IM=a("li"),hTe=a("strong"),m5r=o("camembert"),g5r=o(" \u2014 "),xJ=a("a"),h5r=o("TFCamembertForMultipleChoice"),p5r=o(" (CamemBERT model)"),u5r=l(),NM=a("li"),pTe=a("strong"),_5r=o("convbert"),b5r=o(" \u2014 "),$J=a("a"),v5r=o("TFConvBertForMultipleChoice"),F5r=o(" (ConvBERT model)"),T5r=l(),qM=a("li"),uTe=a("strong"),M5r=o("distilbert"),E5r=o(" \u2014 "),kJ=a("a"),C5r=o("TFDistilBertForMultipleChoice"),w5r=o(" (DistilBERT model)"),A5r=l(),jM=a("li"),_Te=a("strong"),y5r=o("electra"),L5r=o(" \u2014 "),SJ=a("a"),x5r=o("TFElectraForMultipleChoice"),$5r=o(" (ELECTRA model)"),k5r=l(),DM=a("li"),bTe=a("strong"),S5r=o("flaubert"),R5r=o(" \u2014 "),RJ=a("a"),P5r=o("TFFlaubertForMultipleChoice"),B5r=o(" (FlauBERT model)"),I5r=l(),GM=a("li"),vTe=a("strong"),N5r=o("funnel"),q5r=o(" \u2014 "),PJ=a("a"),j5r=o("TFFunnelForMultipleChoice"),D5r=o(" (Funnel Transformer model)"),G5r=l(),OM=a("li"),FTe=a("strong"),O5r=o("longformer"),V5r=o(" \u2014 "),BJ=a("a"),X5r=o("TFLongformerForMultipleChoice"),z5r=o(" (Longformer model)"),W5r=l(),VM=a("li"),TTe=a("strong"),Q5r=o("mobilebert"),H5r=o(" \u2014 "),IJ=a("a"),U5r=o("TFMobileBertForMultipleChoice"),J5r=o(" (MobileBERT model)"),Y5r=l(),XM=a("li"),MTe=a("strong"),K5r=o("mpnet"),Z5r=o(" \u2014 "),NJ=a("a"),e0r=o("TFMPNetForMultipleChoice"),o0r=o(" (MPNet model)"),r0r=l(),zM=a("li"),ETe=a("strong"),t0r=o("rembert"),a0r=o(" \u2014 "),qJ=a("a"),n0r=o("TFRemBertForMultipleChoice"),s0r=o(" (RemBERT model)"),l0r=l(),WM=a("li"),CTe=a("strong"),i0r=o("roberta"),d0r=o(" \u2014 "),jJ=a("a"),c0r=o("TFRobertaForMultipleChoice"),f0r=o(" (RoBERTa model)"),m0r=l(),QM=a("li"),wTe=a("strong"),g0r=o("roformer"),h0r=o(" \u2014 "),DJ=a("a"),p0r=o("TFRoFormerForMultipleChoice"),u0r=o(" (RoFormer model)"),_0r=l(),HM=a("li"),ATe=a("strong"),b0r=o("xlm"),v0r=o(" \u2014 "),GJ=a("a"),F0r=o("TFXLMForMultipleChoice"),T0r=o(" (XLM model)"),M0r=l(),UM=a("li"),yTe=a("strong"),E0r=o("xlm-roberta"),C0r=o(" \u2014 "),OJ=a("a"),w0r=o("TFXLMRobertaForMultipleChoice"),A0r=o(" (XLM-RoBERTa model)"),y0r=l(),JM=a("li"),LTe=a("strong"),L0r=o("xlnet"),x0r=o(" \u2014 "),VJ=a("a"),$0r=o("TFXLNetForMultipleChoice"),k0r=o(" (XLNet model)"),S0r=l(),F(YM.$$.fragment),WGe=l(),Mc=a("h2"),KM=a("a"),xTe=a("span"),F(q8.$$.fragment),R0r=l(),$Te=a("span"),P0r=o("TFAutoModelForNextSentencePrediction"),QGe=l(),lr=a("div"),F(j8.$$.fragment),B0r=l(),Ec=a("p"),I0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),XJ=a("a"),N0r=o("from_pretrained()"),q0r=o(" class method or the "),zJ=a("a"),j0r=o("from_config()"),D0r=o(` class
method.`),G0r=l(),D8=a("p"),O0r=o("This class cannot be instantiated directly using "),kTe=a("code"),V0r=o("__init__()"),X0r=o(" (throws an error)."),z0r=l(),qt=a("div"),F(G8.$$.fragment),W0r=l(),STe=a("p"),Q0r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),H0r=l(),Cc=a("p"),U0r=o(`Note:
Loading a model from its configuration file does `),RTe=a("strong"),J0r=o("not"),Y0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=a("a"),K0r=o("from_pretrained()"),Z0r=o(" to load the model weights."),ewr=l(),F(ZM.$$.fragment),owr=l(),Br=a("div"),F(O8.$$.fragment),rwr=l(),PTe=a("p"),twr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),awr=l(),gn=a("p"),nwr=o("The model class to instantiate is selected based on the "),BTe=a("code"),swr=o("model_type"),lwr=o(` property of the config object (either
passed as an argument or loaded from `),ITe=a("code"),iwr=o("pretrained_model_name_or_path"),dwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=a("code"),cwr=o("pretrained_model_name_or_path"),fwr=o(":"),mwr=l(),V8=a("ul"),e4=a("li"),qTe=a("strong"),gwr=o("bert"),hwr=o(" \u2014 "),QJ=a("a"),pwr=o("TFBertForNextSentencePrediction"),uwr=o(" (BERT model)"),_wr=l(),o4=a("li"),jTe=a("strong"),bwr=o("mobilebert"),vwr=o(" \u2014 "),HJ=a("a"),Fwr=o("TFMobileBertForNextSentencePrediction"),Twr=o(" (MobileBERT model)"),Mwr=l(),F(r4.$$.fragment),HGe=l(),wc=a("h2"),t4=a("a"),DTe=a("span"),F(X8.$$.fragment),Ewr=l(),GTe=a("span"),Cwr=o("TFAutoModelForTableQuestionAnswering"),UGe=l(),ir=a("div"),F(z8.$$.fragment),wwr=l(),Ac=a("p"),Awr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),UJ=a("a"),ywr=o("from_pretrained()"),Lwr=o(" class method or the "),JJ=a("a"),xwr=o("from_config()"),$wr=o(` class
method.`),kwr=l(),W8=a("p"),Swr=o("This class cannot be instantiated directly using "),OTe=a("code"),Rwr=o("__init__()"),Pwr=o(" (throws an error)."),Bwr=l(),jt=a("div"),F(Q8.$$.fragment),Iwr=l(),VTe=a("p"),Nwr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),qwr=l(),yc=a("p"),jwr=o(`Note:
Loading a model from its configuration file does `),XTe=a("strong"),Dwr=o("not"),Gwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),Owr=o("from_pretrained()"),Vwr=o(" to load the model weights."),Xwr=l(),F(a4.$$.fragment),zwr=l(),Ir=a("div"),F(H8.$$.fragment),Wwr=l(),zTe=a("p"),Qwr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Hwr=l(),hn=a("p"),Uwr=o("The model class to instantiate is selected based on the "),WTe=a("code"),Jwr=o("model_type"),Ywr=o(` property of the config object (either
passed as an argument or loaded from `),QTe=a("code"),Kwr=o("pretrained_model_name_or_path"),Zwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HTe=a("code"),eAr=o("pretrained_model_name_or_path"),oAr=o(":"),rAr=l(),UTe=a("ul"),n4=a("li"),JTe=a("strong"),tAr=o("tapas"),aAr=o(" \u2014 "),KJ=a("a"),nAr=o("TFTapasForQuestionAnswering"),sAr=o(" (TAPAS model)"),lAr=l(),F(s4.$$.fragment),JGe=l(),Lc=a("h2"),l4=a("a"),YTe=a("span"),F(U8.$$.fragment),iAr=l(),KTe=a("span"),dAr=o("TFAutoModelForTokenClassification"),YGe=l(),dr=a("div"),F(J8.$$.fragment),cAr=l(),xc=a("p"),fAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ZJ=a("a"),mAr=o("from_pretrained()"),gAr=o(" class method or the "),eY=a("a"),hAr=o("from_config()"),pAr=o(` class
method.`),uAr=l(),Y8=a("p"),_Ar=o("This class cannot be instantiated directly using "),ZTe=a("code"),bAr=o("__init__()"),vAr=o(" (throws an error)."),FAr=l(),Dt=a("div"),F(K8.$$.fragment),TAr=l(),e7e=a("p"),MAr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),EAr=l(),$c=a("p"),CAr=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),wAr=o("not"),AAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oY=a("a"),yAr=o("from_pretrained()"),LAr=o(" to load the model weights."),xAr=l(),F(i4.$$.fragment),$Ar=l(),Nr=a("div"),F(Z8.$$.fragment),kAr=l(),r7e=a("p"),SAr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),RAr=l(),pn=a("p"),PAr=o("The model class to instantiate is selected based on the "),t7e=a("code"),BAr=o("model_type"),IAr=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),NAr=o("pretrained_model_name_or_path"),qAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),jAr=o("pretrained_model_name_or_path"),DAr=o(":"),GAr=l(),de=a("ul"),d4=a("li"),s7e=a("strong"),OAr=o("albert"),VAr=o(" \u2014 "),rY=a("a"),XAr=o("TFAlbertForTokenClassification"),zAr=o(" (ALBERT model)"),WAr=l(),c4=a("li"),l7e=a("strong"),QAr=o("bert"),HAr=o(" \u2014 "),tY=a("a"),UAr=o("TFBertForTokenClassification"),JAr=o(" (BERT model)"),YAr=l(),f4=a("li"),i7e=a("strong"),KAr=o("camembert"),ZAr=o(" \u2014 "),aY=a("a"),eyr=o("TFCamembertForTokenClassification"),oyr=o(" (CamemBERT model)"),ryr=l(),m4=a("li"),d7e=a("strong"),tyr=o("convbert"),ayr=o(" \u2014 "),nY=a("a"),nyr=o("TFConvBertForTokenClassification"),syr=o(" (ConvBERT model)"),lyr=l(),g4=a("li"),c7e=a("strong"),iyr=o("deberta"),dyr=o(" \u2014 "),sY=a("a"),cyr=o("TFDebertaForTokenClassification"),fyr=o(" (DeBERTa model)"),myr=l(),h4=a("li"),f7e=a("strong"),gyr=o("deberta-v2"),hyr=o(" \u2014 "),lY=a("a"),pyr=o("TFDebertaV2ForTokenClassification"),uyr=o(" (DeBERTa-v2 model)"),_yr=l(),p4=a("li"),m7e=a("strong"),byr=o("distilbert"),vyr=o(" \u2014 "),iY=a("a"),Fyr=o("TFDistilBertForTokenClassification"),Tyr=o(" (DistilBERT model)"),Myr=l(),u4=a("li"),g7e=a("strong"),Eyr=o("electra"),Cyr=o(" \u2014 "),dY=a("a"),wyr=o("TFElectraForTokenClassification"),Ayr=o(" (ELECTRA model)"),yyr=l(),_4=a("li"),h7e=a("strong"),Lyr=o("flaubert"),xyr=o(" \u2014 "),cY=a("a"),$yr=o("TFFlaubertForTokenClassification"),kyr=o(" (FlauBERT model)"),Syr=l(),b4=a("li"),p7e=a("strong"),Ryr=o("funnel"),Pyr=o(" \u2014 "),fY=a("a"),Byr=o("TFFunnelForTokenClassification"),Iyr=o(" (Funnel Transformer model)"),Nyr=l(),v4=a("li"),u7e=a("strong"),qyr=o("layoutlm"),jyr=o(" \u2014 "),mY=a("a"),Dyr=o("TFLayoutLMForTokenClassification"),Gyr=o(" (LayoutLM model)"),Oyr=l(),F4=a("li"),_7e=a("strong"),Vyr=o("longformer"),Xyr=o(" \u2014 "),gY=a("a"),zyr=o("TFLongformerForTokenClassification"),Wyr=o(" (Longformer model)"),Qyr=l(),T4=a("li"),b7e=a("strong"),Hyr=o("mobilebert"),Uyr=o(" \u2014 "),hY=a("a"),Jyr=o("TFMobileBertForTokenClassification"),Yyr=o(" (MobileBERT model)"),Kyr=l(),M4=a("li"),v7e=a("strong"),Zyr=o("mpnet"),eLr=o(" \u2014 "),pY=a("a"),oLr=o("TFMPNetForTokenClassification"),rLr=o(" (MPNet model)"),tLr=l(),E4=a("li"),F7e=a("strong"),aLr=o("rembert"),nLr=o(" \u2014 "),uY=a("a"),sLr=o("TFRemBertForTokenClassification"),lLr=o(" (RemBERT model)"),iLr=l(),C4=a("li"),T7e=a("strong"),dLr=o("roberta"),cLr=o(" \u2014 "),_Y=a("a"),fLr=o("TFRobertaForTokenClassification"),mLr=o(" (RoBERTa model)"),gLr=l(),w4=a("li"),M7e=a("strong"),hLr=o("roformer"),pLr=o(" \u2014 "),bY=a("a"),uLr=o("TFRoFormerForTokenClassification"),_Lr=o(" (RoFormer model)"),bLr=l(),A4=a("li"),E7e=a("strong"),vLr=o("xlm"),FLr=o(" \u2014 "),vY=a("a"),TLr=o("TFXLMForTokenClassification"),MLr=o(" (XLM model)"),ELr=l(),y4=a("li"),C7e=a("strong"),CLr=o("xlm-roberta"),wLr=o(" \u2014 "),FY=a("a"),ALr=o("TFXLMRobertaForTokenClassification"),yLr=o(" (XLM-RoBERTa model)"),LLr=l(),L4=a("li"),w7e=a("strong"),xLr=o("xlnet"),$Lr=o(" \u2014 "),TY=a("a"),kLr=o("TFXLNetForTokenClassification"),SLr=o(" (XLNet model)"),RLr=l(),F(x4.$$.fragment),KGe=l(),kc=a("h2"),$4=a("a"),A7e=a("span"),F(ex.$$.fragment),PLr=l(),y7e=a("span"),BLr=o("TFAutoModelForQuestionAnswering"),ZGe=l(),cr=a("div"),F(ox.$$.fragment),ILr=l(),Sc=a("p"),NLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),MY=a("a"),qLr=o("from_pretrained()"),jLr=o(" class method or the "),EY=a("a"),DLr=o("from_config()"),GLr=o(` class
method.`),OLr=l(),rx=a("p"),VLr=o("This class cannot be instantiated directly using "),L7e=a("code"),XLr=o("__init__()"),zLr=o(" (throws an error)."),WLr=l(),Gt=a("div"),F(tx.$$.fragment),QLr=l(),x7e=a("p"),HLr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ULr=l(),Rc=a("p"),JLr=o(`Note:
Loading a model from its configuration file does `),$7e=a("strong"),YLr=o("not"),KLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CY=a("a"),ZLr=o("from_pretrained()"),e8r=o(" to load the model weights."),o8r=l(),F(k4.$$.fragment),r8r=l(),qr=a("div"),F(ax.$$.fragment),t8r=l(),k7e=a("p"),a8r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),n8r=l(),un=a("p"),s8r=o("The model class to instantiate is selected based on the "),S7e=a("code"),l8r=o("model_type"),i8r=o(` property of the config object (either
passed as an argument or loaded from `),R7e=a("code"),d8r=o("pretrained_model_name_or_path"),c8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P7e=a("code"),f8r=o("pretrained_model_name_or_path"),m8r=o(":"),g8r=l(),ce=a("ul"),S4=a("li"),B7e=a("strong"),h8r=o("albert"),p8r=o(" \u2014 "),wY=a("a"),u8r=o("TFAlbertForQuestionAnswering"),_8r=o(" (ALBERT model)"),b8r=l(),R4=a("li"),I7e=a("strong"),v8r=o("bert"),F8r=o(" \u2014 "),AY=a("a"),T8r=o("TFBertForQuestionAnswering"),M8r=o(" (BERT model)"),E8r=l(),P4=a("li"),N7e=a("strong"),C8r=o("camembert"),w8r=o(" \u2014 "),yY=a("a"),A8r=o("TFCamembertForQuestionAnswering"),y8r=o(" (CamemBERT model)"),L8r=l(),B4=a("li"),q7e=a("strong"),x8r=o("convbert"),$8r=o(" \u2014 "),LY=a("a"),k8r=o("TFConvBertForQuestionAnswering"),S8r=o(" (ConvBERT model)"),R8r=l(),I4=a("li"),j7e=a("strong"),P8r=o("deberta"),B8r=o(" \u2014 "),xY=a("a"),I8r=o("TFDebertaForQuestionAnswering"),N8r=o(" (DeBERTa model)"),q8r=l(),N4=a("li"),D7e=a("strong"),j8r=o("deberta-v2"),D8r=o(" \u2014 "),$Y=a("a"),G8r=o("TFDebertaV2ForQuestionAnswering"),O8r=o(" (DeBERTa-v2 model)"),V8r=l(),q4=a("li"),G7e=a("strong"),X8r=o("distilbert"),z8r=o(" \u2014 "),kY=a("a"),W8r=o("TFDistilBertForQuestionAnswering"),Q8r=o(" (DistilBERT model)"),H8r=l(),j4=a("li"),O7e=a("strong"),U8r=o("electra"),J8r=o(" \u2014 "),SY=a("a"),Y8r=o("TFElectraForQuestionAnswering"),K8r=o(" (ELECTRA model)"),Z8r=l(),D4=a("li"),V7e=a("strong"),exr=o("flaubert"),oxr=o(" \u2014 "),RY=a("a"),rxr=o("TFFlaubertForQuestionAnsweringSimple"),txr=o(" (FlauBERT model)"),axr=l(),G4=a("li"),X7e=a("strong"),nxr=o("funnel"),sxr=o(" \u2014 "),PY=a("a"),lxr=o("TFFunnelForQuestionAnswering"),ixr=o(" (Funnel Transformer model)"),dxr=l(),O4=a("li"),z7e=a("strong"),cxr=o("gptj"),fxr=o(" \u2014 "),BY=a("a"),mxr=o("TFGPTJForQuestionAnswering"),gxr=o(" (GPT-J model)"),hxr=l(),V4=a("li"),W7e=a("strong"),pxr=o("longformer"),uxr=o(" \u2014 "),IY=a("a"),_xr=o("TFLongformerForQuestionAnswering"),bxr=o(" (Longformer model)"),vxr=l(),X4=a("li"),Q7e=a("strong"),Fxr=o("mobilebert"),Txr=o(" \u2014 "),NY=a("a"),Mxr=o("TFMobileBertForQuestionAnswering"),Exr=o(" (MobileBERT model)"),Cxr=l(),z4=a("li"),H7e=a("strong"),wxr=o("mpnet"),Axr=o(" \u2014 "),qY=a("a"),yxr=o("TFMPNetForQuestionAnswering"),Lxr=o(" (MPNet model)"),xxr=l(),W4=a("li"),U7e=a("strong"),$xr=o("rembert"),kxr=o(" \u2014 "),jY=a("a"),Sxr=o("TFRemBertForQuestionAnswering"),Rxr=o(" (RemBERT model)"),Pxr=l(),Q4=a("li"),J7e=a("strong"),Bxr=o("roberta"),Ixr=o(" \u2014 "),DY=a("a"),Nxr=o("TFRobertaForQuestionAnswering"),qxr=o(" (RoBERTa model)"),jxr=l(),H4=a("li"),Y7e=a("strong"),Dxr=o("roformer"),Gxr=o(" \u2014 "),GY=a("a"),Oxr=o("TFRoFormerForQuestionAnswering"),Vxr=o(" (RoFormer model)"),Xxr=l(),U4=a("li"),K7e=a("strong"),zxr=o("xlm"),Wxr=o(" \u2014 "),OY=a("a"),Qxr=o("TFXLMForQuestionAnsweringSimple"),Hxr=o(" (XLM model)"),Uxr=l(),J4=a("li"),Z7e=a("strong"),Jxr=o("xlm-roberta"),Yxr=o(" \u2014 "),VY=a("a"),Kxr=o("TFXLMRobertaForQuestionAnswering"),Zxr=o(" (XLM-RoBERTa model)"),e$r=l(),Y4=a("li"),e9e=a("strong"),o$r=o("xlnet"),r$r=o(" \u2014 "),XY=a("a"),t$r=o("TFXLNetForQuestionAnsweringSimple"),a$r=o(" (XLNet model)"),n$r=l(),F(K4.$$.fragment),eOe=l(),Pc=a("h2"),Z4=a("a"),o9e=a("span"),F(nx.$$.fragment),s$r=l(),r9e=a("span"),l$r=o("TFAutoModelForVision2Seq"),oOe=l(),fr=a("div"),F(sx.$$.fragment),i$r=l(),Bc=a("p"),d$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),zY=a("a"),c$r=o("from_pretrained()"),f$r=o(" class method or the "),WY=a("a"),m$r=o("from_config()"),g$r=o(` class
method.`),h$r=l(),lx=a("p"),p$r=o("This class cannot be instantiated directly using "),t9e=a("code"),u$r=o("__init__()"),_$r=o(" (throws an error)."),b$r=l(),Ot=a("div"),F(ix.$$.fragment),v$r=l(),a9e=a("p"),F$r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),T$r=l(),Ic=a("p"),M$r=o(`Note:
Loading a model from its configuration file does `),n9e=a("strong"),E$r=o("not"),C$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=a("a"),w$r=o("from_pretrained()"),A$r=o(" to load the model weights."),y$r=l(),F(eE.$$.fragment),L$r=l(),jr=a("div"),F(dx.$$.fragment),x$r=l(),s9e=a("p"),$$r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),k$r=l(),_n=a("p"),S$r=o("The model class to instantiate is selected based on the "),l9e=a("code"),R$r=o("model_type"),P$r=o(` property of the config object (either
passed as an argument or loaded from `),i9e=a("code"),B$r=o("pretrained_model_name_or_path"),I$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d9e=a("code"),N$r=o("pretrained_model_name_or_path"),q$r=o(":"),j$r=l(),c9e=a("ul"),oE=a("li"),f9e=a("strong"),D$r=o("vision-encoder-decoder"),G$r=o(" \u2014 "),HY=a("a"),O$r=o("TFVisionEncoderDecoderModel"),V$r=o(" (Vision Encoder decoder model)"),X$r=l(),F(rE.$$.fragment),rOe=l(),Nc=a("h2"),tE=a("a"),m9e=a("span"),F(cx.$$.fragment),z$r=l(),g9e=a("span"),W$r=o("TFAutoModelForSpeechSeq2Seq"),tOe=l(),mr=a("div"),F(fx.$$.fragment),Q$r=l(),qc=a("p"),H$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),UY=a("a"),U$r=o("from_pretrained()"),J$r=o(" class method or the "),JY=a("a"),Y$r=o("from_config()"),K$r=o(` class
method.`),Z$r=l(),mx=a("p"),ekr=o("This class cannot be instantiated directly using "),h9e=a("code"),okr=o("__init__()"),rkr=o(" (throws an error)."),tkr=l(),Vt=a("div"),F(gx.$$.fragment),akr=l(),p9e=a("p"),nkr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),skr=l(),jc=a("p"),lkr=o(`Note:
Loading a model from its configuration file does `),u9e=a("strong"),ikr=o("not"),dkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=a("a"),ckr=o("from_pretrained()"),fkr=o(" to load the model weights."),mkr=l(),F(aE.$$.fragment),gkr=l(),Dr=a("div"),F(hx.$$.fragment),hkr=l(),_9e=a("p"),pkr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),ukr=l(),bn=a("p"),_kr=o("The model class to instantiate is selected based on the "),b9e=a("code"),bkr=o("model_type"),vkr=o(` property of the config object (either
passed as an argument or loaded from `),v9e=a("code"),Fkr=o("pretrained_model_name_or_path"),Tkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F9e=a("code"),Mkr=o("pretrained_model_name_or_path"),Ekr=o(":"),Ckr=l(),T9e=a("ul"),nE=a("li"),M9e=a("strong"),wkr=o("speech_to_text"),Akr=o(" \u2014 "),KY=a("a"),ykr=o("TFSpeech2TextForConditionalGeneration"),Lkr=o(" (Speech2Text model)"),xkr=l(),F(sE.$$.fragment),aOe=l(),Dc=a("h2"),lE=a("a"),E9e=a("span"),F(px.$$.fragment),$kr=l(),C9e=a("span"),kkr=o("FlaxAutoModel"),nOe=l(),gr=a("div"),F(ux.$$.fragment),Skr=l(),Gc=a("p"),Rkr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ZY=a("a"),Pkr=o("from_pretrained()"),Bkr=o(" class method or the "),eK=a("a"),Ikr=o("from_config()"),Nkr=o(` class
method.`),qkr=l(),_x=a("p"),jkr=o("This class cannot be instantiated directly using "),w9e=a("code"),Dkr=o("__init__()"),Gkr=o(" (throws an error)."),Okr=l(),Xt=a("div"),F(bx.$$.fragment),Vkr=l(),A9e=a("p"),Xkr=o("Instantiates one of the base model classes of the library from a configuration."),zkr=l(),Oc=a("p"),Wkr=o(`Note:
Loading a model from its configuration file does `),y9e=a("strong"),Qkr=o("not"),Hkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oK=a("a"),Ukr=o("from_pretrained()"),Jkr=o(" to load the model weights."),Ykr=l(),F(iE.$$.fragment),Kkr=l(),Gr=a("div"),F(vx.$$.fragment),Zkr=l(),L9e=a("p"),eSr=o("Instantiate one of the base model classes of the library from a pretrained model."),oSr=l(),vn=a("p"),rSr=o("The model class to instantiate is selected based on the "),x9e=a("code"),tSr=o("model_type"),aSr=o(` property of the config object (either
passed as an argument or loaded from `),$9e=a("code"),nSr=o("pretrained_model_name_or_path"),sSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k9e=a("code"),lSr=o("pretrained_model_name_or_path"),iSr=o(":"),dSr=l(),te=a("ul"),dE=a("li"),S9e=a("strong"),cSr=o("albert"),fSr=o(" \u2014 "),rK=a("a"),mSr=o("FlaxAlbertModel"),gSr=o(" (ALBERT model)"),hSr=l(),cE=a("li"),R9e=a("strong"),pSr=o("bart"),uSr=o(" \u2014 "),tK=a("a"),_Sr=o("FlaxBartModel"),bSr=o(" (BART model)"),vSr=l(),fE=a("li"),P9e=a("strong"),FSr=o("beit"),TSr=o(" \u2014 "),aK=a("a"),MSr=o("FlaxBeitModel"),ESr=o(" (BEiT model)"),CSr=l(),mE=a("li"),B9e=a("strong"),wSr=o("bert"),ASr=o(" \u2014 "),nK=a("a"),ySr=o("FlaxBertModel"),LSr=o(" (BERT model)"),xSr=l(),gE=a("li"),I9e=a("strong"),$Sr=o("big_bird"),kSr=o(" \u2014 "),sK=a("a"),SSr=o("FlaxBigBirdModel"),RSr=o(" (BigBird model)"),PSr=l(),hE=a("li"),N9e=a("strong"),BSr=o("blenderbot"),ISr=o(" \u2014 "),lK=a("a"),NSr=o("FlaxBlenderbotModel"),qSr=o(" (Blenderbot model)"),jSr=l(),pE=a("li"),q9e=a("strong"),DSr=o("blenderbot-small"),GSr=o(" \u2014 "),iK=a("a"),OSr=o("FlaxBlenderbotSmallModel"),VSr=o(" (BlenderbotSmall model)"),XSr=l(),uE=a("li"),j9e=a("strong"),zSr=o("clip"),WSr=o(" \u2014 "),dK=a("a"),QSr=o("FlaxCLIPModel"),HSr=o(" (CLIP model)"),USr=l(),_E=a("li"),D9e=a("strong"),JSr=o("distilbert"),YSr=o(" \u2014 "),cK=a("a"),KSr=o("FlaxDistilBertModel"),ZSr=o(" (DistilBERT model)"),eRr=l(),bE=a("li"),G9e=a("strong"),oRr=o("electra"),rRr=o(" \u2014 "),fK=a("a"),tRr=o("FlaxElectraModel"),aRr=o(" (ELECTRA model)"),nRr=l(),vE=a("li"),O9e=a("strong"),sRr=o("gpt2"),lRr=o(" \u2014 "),mK=a("a"),iRr=o("FlaxGPT2Model"),dRr=o(" (OpenAI GPT-2 model)"),cRr=l(),FE=a("li"),V9e=a("strong"),fRr=o("gpt_neo"),mRr=o(" \u2014 "),gK=a("a"),gRr=o("FlaxGPTNeoModel"),hRr=o(" (GPT Neo model)"),pRr=l(),TE=a("li"),X9e=a("strong"),uRr=o("gptj"),_Rr=o(" \u2014 "),hK=a("a"),bRr=o("FlaxGPTJModel"),vRr=o(" (GPT-J model)"),FRr=l(),ME=a("li"),z9e=a("strong"),TRr=o("marian"),MRr=o(" \u2014 "),pK=a("a"),ERr=o("FlaxMarianModel"),CRr=o(" (Marian model)"),wRr=l(),EE=a("li"),W9e=a("strong"),ARr=o("mbart"),yRr=o(" \u2014 "),uK=a("a"),LRr=o("FlaxMBartModel"),xRr=o(" (mBART model)"),$Rr=l(),CE=a("li"),Q9e=a("strong"),kRr=o("mt5"),SRr=o(" \u2014 "),_K=a("a"),RRr=o("FlaxMT5Model"),PRr=o(" (MT5 model)"),BRr=l(),wE=a("li"),H9e=a("strong"),IRr=o("opt"),NRr=o(" \u2014 "),bK=a("a"),qRr=o("FlaxOPTModel"),jRr=o(" (OPT model)"),DRr=l(),AE=a("li"),U9e=a("strong"),GRr=o("pegasus"),ORr=o(" \u2014 "),vK=a("a"),VRr=o("FlaxPegasusModel"),XRr=o(" (Pegasus model)"),zRr=l(),yE=a("li"),J9e=a("strong"),WRr=o("roberta"),QRr=o(" \u2014 "),FK=a("a"),HRr=o("FlaxRobertaModel"),URr=o(" (RoBERTa model)"),JRr=l(),LE=a("li"),Y9e=a("strong"),YRr=o("roformer"),KRr=o(" \u2014 "),TK=a("a"),ZRr=o("FlaxRoFormerModel"),ePr=o(" (RoFormer model)"),oPr=l(),xE=a("li"),K9e=a("strong"),rPr=o("t5"),tPr=o(" \u2014 "),MK=a("a"),aPr=o("FlaxT5Model"),nPr=o(" (T5 model)"),sPr=l(),$E=a("li"),Z9e=a("strong"),lPr=o("vision-text-dual-encoder"),iPr=o(" \u2014 "),EK=a("a"),dPr=o("FlaxVisionTextDualEncoderModel"),cPr=o(" (VisionTextDualEncoder model)"),fPr=l(),kE=a("li"),eMe=a("strong"),mPr=o("vit"),gPr=o(" \u2014 "),CK=a("a"),hPr=o("FlaxViTModel"),pPr=o(" (ViT model)"),uPr=l(),SE=a("li"),oMe=a("strong"),_Pr=o("wav2vec2"),bPr=o(" \u2014 "),wK=a("a"),vPr=o("FlaxWav2Vec2Model"),FPr=o(" (Wav2Vec2 model)"),TPr=l(),RE=a("li"),rMe=a("strong"),MPr=o("xglm"),EPr=o(" \u2014 "),AK=a("a"),CPr=o("FlaxXGLMModel"),wPr=o(" (XGLM model)"),APr=l(),PE=a("li"),tMe=a("strong"),yPr=o("xlm-roberta"),LPr=o(" \u2014 "),yK=a("a"),xPr=o("FlaxXLMRobertaModel"),$Pr=o(" (XLM-RoBERTa model)"),kPr=l(),F(BE.$$.fragment),sOe=l(),Vc=a("h2"),IE=a("a"),aMe=a("span"),F(Fx.$$.fragment),SPr=l(),nMe=a("span"),RPr=o("FlaxAutoModelForCausalLM"),lOe=l(),hr=a("div"),F(Tx.$$.fragment),PPr=l(),Xc=a("p"),BPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),LK=a("a"),IPr=o("from_pretrained()"),NPr=o(" class method or the "),xK=a("a"),qPr=o("from_config()"),jPr=o(` class
method.`),DPr=l(),Mx=a("p"),GPr=o("This class cannot be instantiated directly using "),sMe=a("code"),OPr=o("__init__()"),VPr=o(" (throws an error)."),XPr=l(),zt=a("div"),F(Ex.$$.fragment),zPr=l(),lMe=a("p"),WPr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),QPr=l(),zc=a("p"),HPr=o(`Note:
Loading a model from its configuration file does `),iMe=a("strong"),UPr=o("not"),JPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$K=a("a"),YPr=o("from_pretrained()"),KPr=o(" to load the model weights."),ZPr=l(),F(NE.$$.fragment),eBr=l(),Or=a("div"),F(Cx.$$.fragment),oBr=l(),dMe=a("p"),rBr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),tBr=l(),Fn=a("p"),aBr=o("The model class to instantiate is selected based on the "),cMe=a("code"),nBr=o("model_type"),sBr=o(` property of the config object (either
passed as an argument or loaded from `),fMe=a("code"),lBr=o("pretrained_model_name_or_path"),iBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mMe=a("code"),dBr=o("pretrained_model_name_or_path"),cBr=o(":"),fBr=l(),xe=a("ul"),qE=a("li"),gMe=a("strong"),mBr=o("bart"),gBr=o(" \u2014 "),kK=a("a"),hBr=o("FlaxBartForCausalLM"),pBr=o(" (BART model)"),uBr=l(),jE=a("li"),hMe=a("strong"),_Br=o("bert"),bBr=o(" \u2014 "),SK=a("a"),vBr=o("FlaxBertForCausalLM"),FBr=o(" (BERT model)"),TBr=l(),DE=a("li"),pMe=a("strong"),MBr=o("big_bird"),EBr=o(" \u2014 "),RK=a("a"),CBr=o("FlaxBigBirdForCausalLM"),wBr=o(" (BigBird model)"),ABr=l(),GE=a("li"),uMe=a("strong"),yBr=o("electra"),LBr=o(" \u2014 "),PK=a("a"),xBr=o("FlaxElectraForCausalLM"),$Br=o(" (ELECTRA model)"),kBr=l(),OE=a("li"),_Me=a("strong"),SBr=o("gpt2"),RBr=o(" \u2014 "),BK=a("a"),PBr=o("FlaxGPT2LMHeadModel"),BBr=o(" (OpenAI GPT-2 model)"),IBr=l(),VE=a("li"),bMe=a("strong"),NBr=o("gpt_neo"),qBr=o(" \u2014 "),IK=a("a"),jBr=o("FlaxGPTNeoForCausalLM"),DBr=o(" (GPT Neo model)"),GBr=l(),XE=a("li"),vMe=a("strong"),OBr=o("gptj"),VBr=o(" \u2014 "),NK=a("a"),XBr=o("FlaxGPTJForCausalLM"),zBr=o(" (GPT-J model)"),WBr=l(),zE=a("li"),FMe=a("strong"),QBr=o("opt"),HBr=o(" \u2014 "),qK=a("a"),UBr=o("FlaxOPTForCausalLM"),JBr=o(" (OPT model)"),YBr=l(),WE=a("li"),TMe=a("strong"),KBr=o("roberta"),ZBr=o(" \u2014 "),jK=a("a"),eIr=o("FlaxRobertaForCausalLM"),oIr=o(" (RoBERTa model)"),rIr=l(),QE=a("li"),MMe=a("strong"),tIr=o("xglm"),aIr=o(" \u2014 "),DK=a("a"),nIr=o("FlaxXGLMForCausalLM"),sIr=o(" (XGLM model)"),lIr=l(),F(HE.$$.fragment),iOe=l(),Wc=a("h2"),UE=a("a"),EMe=a("span"),F(wx.$$.fragment),iIr=l(),CMe=a("span"),dIr=o("FlaxAutoModelForPreTraining"),dOe=l(),pr=a("div"),F(Ax.$$.fragment),cIr=l(),Qc=a("p"),fIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),GK=a("a"),mIr=o("from_pretrained()"),gIr=o(" class method or the "),OK=a("a"),hIr=o("from_config()"),pIr=o(` class
method.`),uIr=l(),yx=a("p"),_Ir=o("This class cannot be instantiated directly using "),wMe=a("code"),bIr=o("__init__()"),vIr=o(" (throws an error)."),FIr=l(),Wt=a("div"),F(Lx.$$.fragment),TIr=l(),AMe=a("p"),MIr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),EIr=l(),Hc=a("p"),CIr=o(`Note:
Loading a model from its configuration file does `),yMe=a("strong"),wIr=o("not"),AIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=a("a"),yIr=o("from_pretrained()"),LIr=o(" to load the model weights."),xIr=l(),F(JE.$$.fragment),$Ir=l(),Vr=a("div"),F(xx.$$.fragment),kIr=l(),LMe=a("p"),SIr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),RIr=l(),Tn=a("p"),PIr=o("The model class to instantiate is selected based on the "),xMe=a("code"),BIr=o("model_type"),IIr=o(` property of the config object (either
passed as an argument or loaded from `),$Me=a("code"),NIr=o("pretrained_model_name_or_path"),qIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kMe=a("code"),jIr=o("pretrained_model_name_or_path"),DIr=o(":"),GIr=l(),Ee=a("ul"),YE=a("li"),SMe=a("strong"),OIr=o("albert"),VIr=o(" \u2014 "),XK=a("a"),XIr=o("FlaxAlbertForPreTraining"),zIr=o(" (ALBERT model)"),WIr=l(),KE=a("li"),RMe=a("strong"),QIr=o("bart"),HIr=o(" \u2014 "),zK=a("a"),UIr=o("FlaxBartForConditionalGeneration"),JIr=o(" (BART model)"),YIr=l(),ZE=a("li"),PMe=a("strong"),KIr=o("bert"),ZIr=o(" \u2014 "),WK=a("a"),eNr=o("FlaxBertForPreTraining"),oNr=o(" (BERT model)"),rNr=l(),eC=a("li"),BMe=a("strong"),tNr=o("big_bird"),aNr=o(" \u2014 "),QK=a("a"),nNr=o("FlaxBigBirdForPreTraining"),sNr=o(" (BigBird model)"),lNr=l(),oC=a("li"),IMe=a("strong"),iNr=o("electra"),dNr=o(" \u2014 "),HK=a("a"),cNr=o("FlaxElectraForPreTraining"),fNr=o(" (ELECTRA model)"),mNr=l(),rC=a("li"),NMe=a("strong"),gNr=o("mbart"),hNr=o(" \u2014 "),UK=a("a"),pNr=o("FlaxMBartForConditionalGeneration"),uNr=o(" (mBART model)"),_Nr=l(),tC=a("li"),qMe=a("strong"),bNr=o("mt5"),vNr=o(" \u2014 "),JK=a("a"),FNr=o("FlaxMT5ForConditionalGeneration"),TNr=o(" (MT5 model)"),MNr=l(),aC=a("li"),jMe=a("strong"),ENr=o("roberta"),CNr=o(" \u2014 "),YK=a("a"),wNr=o("FlaxRobertaForMaskedLM"),ANr=o(" (RoBERTa model)"),yNr=l(),nC=a("li"),DMe=a("strong"),LNr=o("roformer"),xNr=o(" \u2014 "),KK=a("a"),$Nr=o("FlaxRoFormerForMaskedLM"),kNr=o(" (RoFormer model)"),SNr=l(),sC=a("li"),GMe=a("strong"),RNr=o("t5"),PNr=o(" \u2014 "),ZK=a("a"),BNr=o("FlaxT5ForConditionalGeneration"),INr=o(" (T5 model)"),NNr=l(),lC=a("li"),OMe=a("strong"),qNr=o("wav2vec2"),jNr=o(" \u2014 "),eZ=a("a"),DNr=o("FlaxWav2Vec2ForPreTraining"),GNr=o(" (Wav2Vec2 model)"),ONr=l(),iC=a("li"),VMe=a("strong"),VNr=o("xlm-roberta"),XNr=o(" \u2014 "),oZ=a("a"),zNr=o("FlaxXLMRobertaForMaskedLM"),WNr=o(" (XLM-RoBERTa model)"),QNr=l(),F(dC.$$.fragment),cOe=l(),Uc=a("h2"),cC=a("a"),XMe=a("span"),F($x.$$.fragment),HNr=l(),zMe=a("span"),UNr=o("FlaxAutoModelForMaskedLM"),fOe=l(),ur=a("div"),F(kx.$$.fragment),JNr=l(),Jc=a("p"),YNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),rZ=a("a"),KNr=o("from_pretrained()"),ZNr=o(" class method or the "),tZ=a("a"),eqr=o("from_config()"),oqr=o(` class
method.`),rqr=l(),Sx=a("p"),tqr=o("This class cannot be instantiated directly using "),WMe=a("code"),aqr=o("__init__()"),nqr=o(" (throws an error)."),sqr=l(),Qt=a("div"),F(Rx.$$.fragment),lqr=l(),QMe=a("p"),iqr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dqr=l(),Yc=a("p"),cqr=o(`Note:
Loading a model from its configuration file does `),HMe=a("strong"),fqr=o("not"),mqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aZ=a("a"),gqr=o("from_pretrained()"),hqr=o(" to load the model weights."),pqr=l(),F(fC.$$.fragment),uqr=l(),Xr=a("div"),F(Px.$$.fragment),_qr=l(),UMe=a("p"),bqr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),vqr=l(),Mn=a("p"),Fqr=o("The model class to instantiate is selected based on the "),JMe=a("code"),Tqr=o("model_type"),Mqr=o(` property of the config object (either
passed as an argument or loaded from `),YMe=a("code"),Eqr=o("pretrained_model_name_or_path"),Cqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=a("code"),wqr=o("pretrained_model_name_or_path"),Aqr=o(":"),yqr=l(),$e=a("ul"),mC=a("li"),ZMe=a("strong"),Lqr=o("albert"),xqr=o(" \u2014 "),nZ=a("a"),$qr=o("FlaxAlbertForMaskedLM"),kqr=o(" (ALBERT model)"),Sqr=l(),gC=a("li"),e4e=a("strong"),Rqr=o("bart"),Pqr=o(" \u2014 "),sZ=a("a"),Bqr=o("FlaxBartForConditionalGeneration"),Iqr=o(" (BART model)"),Nqr=l(),hC=a("li"),o4e=a("strong"),qqr=o("bert"),jqr=o(" \u2014 "),lZ=a("a"),Dqr=o("FlaxBertForMaskedLM"),Gqr=o(" (BERT model)"),Oqr=l(),pC=a("li"),r4e=a("strong"),Vqr=o("big_bird"),Xqr=o(" \u2014 "),iZ=a("a"),zqr=o("FlaxBigBirdForMaskedLM"),Wqr=o(" (BigBird model)"),Qqr=l(),uC=a("li"),t4e=a("strong"),Hqr=o("distilbert"),Uqr=o(" \u2014 "),dZ=a("a"),Jqr=o("FlaxDistilBertForMaskedLM"),Yqr=o(" (DistilBERT model)"),Kqr=l(),_C=a("li"),a4e=a("strong"),Zqr=o("electra"),ejr=o(" \u2014 "),cZ=a("a"),ojr=o("FlaxElectraForMaskedLM"),rjr=o(" (ELECTRA model)"),tjr=l(),bC=a("li"),n4e=a("strong"),ajr=o("mbart"),njr=o(" \u2014 "),fZ=a("a"),sjr=o("FlaxMBartForConditionalGeneration"),ljr=o(" (mBART model)"),ijr=l(),vC=a("li"),s4e=a("strong"),djr=o("roberta"),cjr=o(" \u2014 "),mZ=a("a"),fjr=o("FlaxRobertaForMaskedLM"),mjr=o(" (RoBERTa model)"),gjr=l(),FC=a("li"),l4e=a("strong"),hjr=o("roformer"),pjr=o(" \u2014 "),gZ=a("a"),ujr=o("FlaxRoFormerForMaskedLM"),_jr=o(" (RoFormer model)"),bjr=l(),TC=a("li"),i4e=a("strong"),vjr=o("xlm-roberta"),Fjr=o(" \u2014 "),hZ=a("a"),Tjr=o("FlaxXLMRobertaForMaskedLM"),Mjr=o(" (XLM-RoBERTa model)"),Ejr=l(),F(MC.$$.fragment),mOe=l(),Kc=a("h2"),EC=a("a"),d4e=a("span"),F(Bx.$$.fragment),Cjr=l(),c4e=a("span"),wjr=o("FlaxAutoModelForSeq2SeqLM"),gOe=l(),_r=a("div"),F(Ix.$$.fragment),Ajr=l(),Zc=a("p"),yjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),pZ=a("a"),Ljr=o("from_pretrained()"),xjr=o(" class method or the "),uZ=a("a"),$jr=o("from_config()"),kjr=o(` class
method.`),Sjr=l(),Nx=a("p"),Rjr=o("This class cannot be instantiated directly using "),f4e=a("code"),Pjr=o("__init__()"),Bjr=o(" (throws an error)."),Ijr=l(),Ht=a("div"),F(qx.$$.fragment),Njr=l(),m4e=a("p"),qjr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),jjr=l(),ef=a("p"),Djr=o(`Note:
Loading a model from its configuration file does `),g4e=a("strong"),Gjr=o("not"),Ojr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=a("a"),Vjr=o("from_pretrained()"),Xjr=o(" to load the model weights."),zjr=l(),F(CC.$$.fragment),Wjr=l(),zr=a("div"),F(jx.$$.fragment),Qjr=l(),h4e=a("p"),Hjr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Ujr=l(),En=a("p"),Jjr=o("The model class to instantiate is selected based on the "),p4e=a("code"),Yjr=o("model_type"),Kjr=o(` property of the config object (either
passed as an argument or loaded from `),u4e=a("code"),Zjr=o("pretrained_model_name_or_path"),eDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_4e=a("code"),oDr=o("pretrained_model_name_or_path"),rDr=o(":"),tDr=l(),Pe=a("ul"),wC=a("li"),b4e=a("strong"),aDr=o("bart"),nDr=o(" \u2014 "),bZ=a("a"),sDr=o("FlaxBartForConditionalGeneration"),lDr=o(" (BART model)"),iDr=l(),AC=a("li"),v4e=a("strong"),dDr=o("blenderbot"),cDr=o(" \u2014 "),vZ=a("a"),fDr=o("FlaxBlenderbotForConditionalGeneration"),mDr=o(" (Blenderbot model)"),gDr=l(),yC=a("li"),F4e=a("strong"),hDr=o("blenderbot-small"),pDr=o(" \u2014 "),FZ=a("a"),uDr=o("FlaxBlenderbotSmallForConditionalGeneration"),_Dr=o(" (BlenderbotSmall model)"),bDr=l(),LC=a("li"),T4e=a("strong"),vDr=o("encoder-decoder"),FDr=o(" \u2014 "),TZ=a("a"),TDr=o("FlaxEncoderDecoderModel"),MDr=o(" (Encoder decoder model)"),EDr=l(),xC=a("li"),M4e=a("strong"),CDr=o("marian"),wDr=o(" \u2014 "),MZ=a("a"),ADr=o("FlaxMarianMTModel"),yDr=o(" (Marian model)"),LDr=l(),$C=a("li"),E4e=a("strong"),xDr=o("mbart"),$Dr=o(" \u2014 "),EZ=a("a"),kDr=o("FlaxMBartForConditionalGeneration"),SDr=o(" (mBART model)"),RDr=l(),kC=a("li"),C4e=a("strong"),PDr=o("mt5"),BDr=o(" \u2014 "),CZ=a("a"),IDr=o("FlaxMT5ForConditionalGeneration"),NDr=o(" (MT5 model)"),qDr=l(),SC=a("li"),w4e=a("strong"),jDr=o("pegasus"),DDr=o(" \u2014 "),wZ=a("a"),GDr=o("FlaxPegasusForConditionalGeneration"),ODr=o(" (Pegasus model)"),VDr=l(),RC=a("li"),A4e=a("strong"),XDr=o("t5"),zDr=o(" \u2014 "),AZ=a("a"),WDr=o("FlaxT5ForConditionalGeneration"),QDr=o(" (T5 model)"),HDr=l(),F(PC.$$.fragment),hOe=l(),of=a("h2"),BC=a("a"),y4e=a("span"),F(Dx.$$.fragment),UDr=l(),L4e=a("span"),JDr=o("FlaxAutoModelForSequenceClassification"),pOe=l(),br=a("div"),F(Gx.$$.fragment),YDr=l(),rf=a("p"),KDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),yZ=a("a"),ZDr=o("from_pretrained()"),eGr=o(" class method or the "),LZ=a("a"),oGr=o("from_config()"),rGr=o(` class
method.`),tGr=l(),Ox=a("p"),aGr=o("This class cannot be instantiated directly using "),x4e=a("code"),nGr=o("__init__()"),sGr=o(" (throws an error)."),lGr=l(),Ut=a("div"),F(Vx.$$.fragment),iGr=l(),$4e=a("p"),dGr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),cGr=l(),tf=a("p"),fGr=o(`Note:
Loading a model from its configuration file does `),k4e=a("strong"),mGr=o("not"),gGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xZ=a("a"),hGr=o("from_pretrained()"),pGr=o(" to load the model weights."),uGr=l(),F(IC.$$.fragment),_Gr=l(),Wr=a("div"),F(Xx.$$.fragment),bGr=l(),S4e=a("p"),vGr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),FGr=l(),Cn=a("p"),TGr=o("The model class to instantiate is selected based on the "),R4e=a("code"),MGr=o("model_type"),EGr=o(` property of the config object (either
passed as an argument or loaded from `),P4e=a("code"),CGr=o("pretrained_model_name_or_path"),wGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=a("code"),AGr=o("pretrained_model_name_or_path"),yGr=o(":"),LGr=l(),ke=a("ul"),NC=a("li"),I4e=a("strong"),xGr=o("albert"),$Gr=o(" \u2014 "),$Z=a("a"),kGr=o("FlaxAlbertForSequenceClassification"),SGr=o(" (ALBERT model)"),RGr=l(),qC=a("li"),N4e=a("strong"),PGr=o("bart"),BGr=o(" \u2014 "),kZ=a("a"),IGr=o("FlaxBartForSequenceClassification"),NGr=o(" (BART model)"),qGr=l(),jC=a("li"),q4e=a("strong"),jGr=o("bert"),DGr=o(" \u2014 "),SZ=a("a"),GGr=o("FlaxBertForSequenceClassification"),OGr=o(" (BERT model)"),VGr=l(),DC=a("li"),j4e=a("strong"),XGr=o("big_bird"),zGr=o(" \u2014 "),RZ=a("a"),WGr=o("FlaxBigBirdForSequenceClassification"),QGr=o(" (BigBird model)"),HGr=l(),GC=a("li"),D4e=a("strong"),UGr=o("distilbert"),JGr=o(" \u2014 "),PZ=a("a"),YGr=o("FlaxDistilBertForSequenceClassification"),KGr=o(" (DistilBERT model)"),ZGr=l(),OC=a("li"),G4e=a("strong"),eOr=o("electra"),oOr=o(" \u2014 "),BZ=a("a"),rOr=o("FlaxElectraForSequenceClassification"),tOr=o(" (ELECTRA model)"),aOr=l(),VC=a("li"),O4e=a("strong"),nOr=o("mbart"),sOr=o(" \u2014 "),IZ=a("a"),lOr=o("FlaxMBartForSequenceClassification"),iOr=o(" (mBART model)"),dOr=l(),XC=a("li"),V4e=a("strong"),cOr=o("roberta"),fOr=o(" \u2014 "),NZ=a("a"),mOr=o("FlaxRobertaForSequenceClassification"),gOr=o(" (RoBERTa model)"),hOr=l(),zC=a("li"),X4e=a("strong"),pOr=o("roformer"),uOr=o(" \u2014 "),qZ=a("a"),_Or=o("FlaxRoFormerForSequenceClassification"),bOr=o(" (RoFormer model)"),vOr=l(),WC=a("li"),z4e=a("strong"),FOr=o("xlm-roberta"),TOr=o(" \u2014 "),jZ=a("a"),MOr=o("FlaxXLMRobertaForSequenceClassification"),EOr=o(" (XLM-RoBERTa model)"),COr=l(),F(QC.$$.fragment),uOe=l(),af=a("h2"),HC=a("a"),W4e=a("span"),F(zx.$$.fragment),wOr=l(),Q4e=a("span"),AOr=o("FlaxAutoModelForQuestionAnswering"),_Oe=l(),vr=a("div"),F(Wx.$$.fragment),yOr=l(),nf=a("p"),LOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DZ=a("a"),xOr=o("from_pretrained()"),$Or=o(" class method or the "),GZ=a("a"),kOr=o("from_config()"),SOr=o(` class
method.`),ROr=l(),Qx=a("p"),POr=o("This class cannot be instantiated directly using "),H4e=a("code"),BOr=o("__init__()"),IOr=o(" (throws an error)."),NOr=l(),Jt=a("div"),F(Hx.$$.fragment),qOr=l(),U4e=a("p"),jOr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),DOr=l(),sf=a("p"),GOr=o(`Note:
Loading a model from its configuration file does `),J4e=a("strong"),OOr=o("not"),VOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OZ=a("a"),XOr=o("from_pretrained()"),zOr=o(" to load the model weights."),WOr=l(),F(UC.$$.fragment),QOr=l(),Qr=a("div"),F(Ux.$$.fragment),HOr=l(),Y4e=a("p"),UOr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JOr=l(),wn=a("p"),YOr=o("The model class to instantiate is selected based on the "),K4e=a("code"),KOr=o("model_type"),ZOr=o(` property of the config object (either
passed as an argument or loaded from `),Z4e=a("code"),eVr=o("pretrained_model_name_or_path"),oVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eEe=a("code"),rVr=o("pretrained_model_name_or_path"),tVr=o(":"),aVr=l(),Se=a("ul"),JC=a("li"),oEe=a("strong"),nVr=o("albert"),sVr=o(" \u2014 "),VZ=a("a"),lVr=o("FlaxAlbertForQuestionAnswering"),iVr=o(" (ALBERT model)"),dVr=l(),YC=a("li"),rEe=a("strong"),cVr=o("bart"),fVr=o(" \u2014 "),XZ=a("a"),mVr=o("FlaxBartForQuestionAnswering"),gVr=o(" (BART model)"),hVr=l(),KC=a("li"),tEe=a("strong"),pVr=o("bert"),uVr=o(" \u2014 "),zZ=a("a"),_Vr=o("FlaxBertForQuestionAnswering"),bVr=o(" (BERT model)"),vVr=l(),ZC=a("li"),aEe=a("strong"),FVr=o("big_bird"),TVr=o(" \u2014 "),WZ=a("a"),MVr=o("FlaxBigBirdForQuestionAnswering"),EVr=o(" (BigBird model)"),CVr=l(),e5=a("li"),nEe=a("strong"),wVr=o("distilbert"),AVr=o(" \u2014 "),QZ=a("a"),yVr=o("FlaxDistilBertForQuestionAnswering"),LVr=o(" (DistilBERT model)"),xVr=l(),o5=a("li"),sEe=a("strong"),$Vr=o("electra"),kVr=o(" \u2014 "),HZ=a("a"),SVr=o("FlaxElectraForQuestionAnswering"),RVr=o(" (ELECTRA model)"),PVr=l(),r5=a("li"),lEe=a("strong"),BVr=o("mbart"),IVr=o(" \u2014 "),UZ=a("a"),NVr=o("FlaxMBartForQuestionAnswering"),qVr=o(" (mBART model)"),jVr=l(),t5=a("li"),iEe=a("strong"),DVr=o("roberta"),GVr=o(" \u2014 "),JZ=a("a"),OVr=o("FlaxRobertaForQuestionAnswering"),VVr=o(" (RoBERTa model)"),XVr=l(),a5=a("li"),dEe=a("strong"),zVr=o("roformer"),WVr=o(" \u2014 "),YZ=a("a"),QVr=o("FlaxRoFormerForQuestionAnswering"),HVr=o(" (RoFormer model)"),UVr=l(),n5=a("li"),cEe=a("strong"),JVr=o("xlm-roberta"),YVr=o(" \u2014 "),KZ=a("a"),KVr=o("FlaxXLMRobertaForQuestionAnswering"),ZVr=o(" (XLM-RoBERTa model)"),eXr=l(),F(s5.$$.fragment),bOe=l(),lf=a("h2"),l5=a("a"),fEe=a("span"),F(Jx.$$.fragment),oXr=l(),mEe=a("span"),rXr=o("FlaxAutoModelForTokenClassification"),vOe=l(),Fr=a("div"),F(Yx.$$.fragment),tXr=l(),df=a("p"),aXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ZZ=a("a"),nXr=o("from_pretrained()"),sXr=o(" class method or the "),eee=a("a"),lXr=o("from_config()"),iXr=o(` class
method.`),dXr=l(),Kx=a("p"),cXr=o("This class cannot be instantiated directly using "),gEe=a("code"),fXr=o("__init__()"),mXr=o(" (throws an error)."),gXr=l(),Yt=a("div"),F(Zx.$$.fragment),hXr=l(),hEe=a("p"),pXr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),uXr=l(),cf=a("p"),_Xr=o(`Note:
Loading a model from its configuration file does `),pEe=a("strong"),bXr=o("not"),vXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oee=a("a"),FXr=o("from_pretrained()"),TXr=o(" to load the model weights."),MXr=l(),F(i5.$$.fragment),EXr=l(),Hr=a("div"),F(e$.$$.fragment),CXr=l(),uEe=a("p"),wXr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),AXr=l(),An=a("p"),yXr=o("The model class to instantiate is selected based on the "),_Ee=a("code"),LXr=o("model_type"),xXr=o(` property of the config object (either
passed as an argument or loaded from `),bEe=a("code"),$Xr=o("pretrained_model_name_or_path"),kXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vEe=a("code"),SXr=o("pretrained_model_name_or_path"),RXr=o(":"),PXr=l(),Oe=a("ul"),d5=a("li"),FEe=a("strong"),BXr=o("albert"),IXr=o(" \u2014 "),ree=a("a"),NXr=o("FlaxAlbertForTokenClassification"),qXr=o(" (ALBERT model)"),jXr=l(),c5=a("li"),TEe=a("strong"),DXr=o("bert"),GXr=o(" \u2014 "),tee=a("a"),OXr=o("FlaxBertForTokenClassification"),VXr=o(" (BERT model)"),XXr=l(),f5=a("li"),MEe=a("strong"),zXr=o("big_bird"),WXr=o(" \u2014 "),aee=a("a"),QXr=o("FlaxBigBirdForTokenClassification"),HXr=o(" (BigBird model)"),UXr=l(),m5=a("li"),EEe=a("strong"),JXr=o("distilbert"),YXr=o(" \u2014 "),nee=a("a"),KXr=o("FlaxDistilBertForTokenClassification"),ZXr=o(" (DistilBERT model)"),ezr=l(),g5=a("li"),CEe=a("strong"),ozr=o("electra"),rzr=o(" \u2014 "),see=a("a"),tzr=o("FlaxElectraForTokenClassification"),azr=o(" (ELECTRA model)"),nzr=l(),h5=a("li"),wEe=a("strong"),szr=o("roberta"),lzr=o(" \u2014 "),lee=a("a"),izr=o("FlaxRobertaForTokenClassification"),dzr=o(" (RoBERTa model)"),czr=l(),p5=a("li"),AEe=a("strong"),fzr=o("roformer"),mzr=o(" \u2014 "),iee=a("a"),gzr=o("FlaxRoFormerForTokenClassification"),hzr=o(" (RoFormer model)"),pzr=l(),u5=a("li"),yEe=a("strong"),uzr=o("xlm-roberta"),_zr=o(" \u2014 "),dee=a("a"),bzr=o("FlaxXLMRobertaForTokenClassification"),vzr=o(" (XLM-RoBERTa model)"),Fzr=l(),F(_5.$$.fragment),FOe=l(),ff=a("h2"),b5=a("a"),LEe=a("span"),F(o$.$$.fragment),Tzr=l(),xEe=a("span"),Mzr=o("FlaxAutoModelForMultipleChoice"),TOe=l(),Tr=a("div"),F(r$.$$.fragment),Ezr=l(),mf=a("p"),Czr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cee=a("a"),wzr=o("from_pretrained()"),Azr=o(" class method or the "),fee=a("a"),yzr=o("from_config()"),Lzr=o(` class
method.`),xzr=l(),t$=a("p"),$zr=o("This class cannot be instantiated directly using "),$Ee=a("code"),kzr=o("__init__()"),Szr=o(" (throws an error)."),Rzr=l(),Kt=a("div"),F(a$.$$.fragment),Pzr=l(),kEe=a("p"),Bzr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Izr=l(),gf=a("p"),Nzr=o(`Note:
Loading a model from its configuration file does `),SEe=a("strong"),qzr=o("not"),jzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mee=a("a"),Dzr=o("from_pretrained()"),Gzr=o(" to load the model weights."),Ozr=l(),F(v5.$$.fragment),Vzr=l(),Ur=a("div"),F(n$.$$.fragment),Xzr=l(),REe=a("p"),zzr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Wzr=l(),yn=a("p"),Qzr=o("The model class to instantiate is selected based on the "),PEe=a("code"),Hzr=o("model_type"),Uzr=o(` property of the config object (either
passed as an argument or loaded from `),BEe=a("code"),Jzr=o("pretrained_model_name_or_path"),Yzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=a("code"),Kzr=o("pretrained_model_name_or_path"),Zzr=o(":"),eWr=l(),Ve=a("ul"),F5=a("li"),NEe=a("strong"),oWr=o("albert"),rWr=o(" \u2014 "),gee=a("a"),tWr=o("FlaxAlbertForMultipleChoice"),aWr=o(" (ALBERT model)"),nWr=l(),T5=a("li"),qEe=a("strong"),sWr=o("bert"),lWr=o(" \u2014 "),hee=a("a"),iWr=o("FlaxBertForMultipleChoice"),dWr=o(" (BERT model)"),cWr=l(),M5=a("li"),jEe=a("strong"),fWr=o("big_bird"),mWr=o(" \u2014 "),pee=a("a"),gWr=o("FlaxBigBirdForMultipleChoice"),hWr=o(" (BigBird model)"),pWr=l(),E5=a("li"),DEe=a("strong"),uWr=o("distilbert"),_Wr=o(" \u2014 "),uee=a("a"),bWr=o("FlaxDistilBertForMultipleChoice"),vWr=o(" (DistilBERT model)"),FWr=l(),C5=a("li"),GEe=a("strong"),TWr=o("electra"),MWr=o(" \u2014 "),_ee=a("a"),EWr=o("FlaxElectraForMultipleChoice"),CWr=o(" (ELECTRA model)"),wWr=l(),w5=a("li"),OEe=a("strong"),AWr=o("roberta"),yWr=o(" \u2014 "),bee=a("a"),LWr=o("FlaxRobertaForMultipleChoice"),xWr=o(" (RoBERTa model)"),$Wr=l(),A5=a("li"),VEe=a("strong"),kWr=o("roformer"),SWr=o(" \u2014 "),vee=a("a"),RWr=o("FlaxRoFormerForMultipleChoice"),PWr=o(" (RoFormer model)"),BWr=l(),y5=a("li"),XEe=a("strong"),IWr=o("xlm-roberta"),NWr=o(" \u2014 "),Fee=a("a"),qWr=o("FlaxXLMRobertaForMultipleChoice"),jWr=o(" (XLM-RoBERTa model)"),DWr=l(),F(L5.$$.fragment),MOe=l(),hf=a("h2"),x5=a("a"),zEe=a("span"),F(s$.$$.fragment),GWr=l(),WEe=a("span"),OWr=o("FlaxAutoModelForNextSentencePrediction"),EOe=l(),Mr=a("div"),F(l$.$$.fragment),VWr=l(),pf=a("p"),XWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Tee=a("a"),zWr=o("from_pretrained()"),WWr=o(" class method or the "),Mee=a("a"),QWr=o("from_config()"),HWr=o(` class
method.`),UWr=l(),i$=a("p"),JWr=o("This class cannot be instantiated directly using "),QEe=a("code"),YWr=o("__init__()"),KWr=o(" (throws an error)."),ZWr=l(),Zt=a("div"),F(d$.$$.fragment),eQr=l(),HEe=a("p"),oQr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),rQr=l(),uf=a("p"),tQr=o(`Note:
Loading a model from its configuration file does `),UEe=a("strong"),aQr=o("not"),nQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=a("a"),sQr=o("from_pretrained()"),lQr=o(" to load the model weights."),iQr=l(),F($5.$$.fragment),dQr=l(),Jr=a("div"),F(c$.$$.fragment),cQr=l(),JEe=a("p"),fQr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),mQr=l(),Ln=a("p"),gQr=o("The model class to instantiate is selected based on the "),YEe=a("code"),hQr=o("model_type"),pQr=o(` property of the config object (either
passed as an argument or loaded from `),KEe=a("code"),uQr=o("pretrained_model_name_or_path"),_Qr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZEe=a("code"),bQr=o("pretrained_model_name_or_path"),vQr=o(":"),FQr=l(),eCe=a("ul"),k5=a("li"),oCe=a("strong"),TQr=o("bert"),MQr=o(" \u2014 "),Cee=a("a"),EQr=o("FlaxBertForNextSentencePrediction"),CQr=o(" (BERT model)"),wQr=l(),F(S5.$$.fragment),COe=l(),_f=a("h2"),R5=a("a"),rCe=a("span"),F(f$.$$.fragment),AQr=l(),tCe=a("span"),yQr=o("FlaxAutoModelForImageClassification"),wOe=l(),Er=a("div"),F(m$.$$.fragment),LQr=l(),bf=a("p"),xQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),wee=a("a"),$Qr=o("from_pretrained()"),kQr=o(" class method or the "),Aee=a("a"),SQr=o("from_config()"),RQr=o(` class
method.`),PQr=l(),g$=a("p"),BQr=o("This class cannot be instantiated directly using "),aCe=a("code"),IQr=o("__init__()"),NQr=o(" (throws an error)."),qQr=l(),ea=a("div"),F(h$.$$.fragment),jQr=l(),nCe=a("p"),DQr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),GQr=l(),vf=a("p"),OQr=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),VQr=o("not"),XQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yee=a("a"),zQr=o("from_pretrained()"),WQr=o(" to load the model weights."),QQr=l(),F(P5.$$.fragment),HQr=l(),Yr=a("div"),F(p$.$$.fragment),UQr=l(),lCe=a("p"),JQr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),YQr=l(),xn=a("p"),KQr=o("The model class to instantiate is selected based on the "),iCe=a("code"),ZQr=o("model_type"),eHr=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),oHr=o("pretrained_model_name_or_path"),rHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=a("code"),tHr=o("pretrained_model_name_or_path"),aHr=o(":"),nHr=l(),u$=a("ul"),B5=a("li"),fCe=a("strong"),sHr=o("beit"),lHr=o(" \u2014 "),Lee=a("a"),iHr=o("FlaxBeitForImageClassification"),dHr=o(" (BEiT model)"),cHr=l(),I5=a("li"),mCe=a("strong"),fHr=o("vit"),mHr=o(" \u2014 "),xee=a("a"),gHr=o("FlaxViTForImageClassification"),hHr=o(" (ViT model)"),pHr=l(),F(N5.$$.fragment),AOe=l(),Ff=a("h2"),q5=a("a"),gCe=a("span"),F(_$.$$.fragment),uHr=l(),hCe=a("span"),_Hr=o("FlaxAutoModelForVision2Seq"),yOe=l(),Cr=a("div"),F(b$.$$.fragment),bHr=l(),Tf=a("p"),vHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$ee=a("a"),FHr=o("from_pretrained()"),THr=o(" class method or the "),kee=a("a"),MHr=o("from_config()"),EHr=o(` class
method.`),CHr=l(),v$=a("p"),wHr=o("This class cannot be instantiated directly using "),pCe=a("code"),AHr=o("__init__()"),yHr=o(" (throws an error)."),LHr=l(),oa=a("div"),F(F$.$$.fragment),xHr=l(),uCe=a("p"),$Hr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),kHr=l(),Mf=a("p"),SHr=o(`Note:
Loading a model from its configuration file does `),_Ce=a("strong"),RHr=o("not"),PHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),See=a("a"),BHr=o("from_pretrained()"),IHr=o(" to load the model weights."),NHr=l(),F(j5.$$.fragment),qHr=l(),Kr=a("div"),F(T$.$$.fragment),jHr=l(),bCe=a("p"),DHr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),GHr=l(),$n=a("p"),OHr=o("The model class to instantiate is selected based on the "),vCe=a("code"),VHr=o("model_type"),XHr=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),zHr=o("pretrained_model_name_or_path"),WHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),QHr=o("pretrained_model_name_or_path"),HHr=o(":"),UHr=l(),MCe=a("ul"),D5=a("li"),ECe=a("strong"),JHr=o("vision-encoder-decoder"),YHr=o(" \u2014 "),Ree=a("a"),KHr=o("FlaxVisionEncoderDecoderModel"),ZHr=o(" (Vision Encoder decoder model)"),eUr=l(),F(G5.$$.fragment),this.h()},l(f){const _=VIt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var M$=s(p);m=n(M$,"A",{id:!0,class:!0,href:!0});var CCe=s(m);u=n(CCe,"SPAN",{});var wCe=s(u);T(d.$$.fragment,wCe),wCe.forEach(t),CCe.forEach(t),h=i(M$),Eo=n(M$,"SPAN",{});var ACe=s(Eo);vi=r(ACe,"Auto Classes"),ACe.forEach(t),M$.forEach(t),Af=i(f),at=n(f,"P",{});var E$=s(at);Fi=r(E$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ti=n(E$,"CODE",{});var yCe=s(Ti);iA=r(yCe,"from_pretrained()"),yCe.forEach(t),yf=r(E$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),E$.forEach(t),Ge=i(f),We=n(f,"P",{});var kn=s(We);Mi=r(kn,"Instantiating one of "),Sn=n(kn,"A",{href:!0});var LCe=s(Sn);dA=r(LCe,"AutoConfig"),LCe.forEach(t),Rn=r(kn,", "),Pn=n(kn,"A",{href:!0});var xCe=s(Pn);cA=r(xCe,"AutoModel"),xCe.forEach(t),Ei=r(kn,`, and
`),Bn=n(kn,"A",{href:!0});var $Ce=s(Bn);fA=r($Ce,"AutoTokenizer"),$Ce.forEach(t),Ci=r(kn," will directly create a class of the relevant architecture. For instance"),kn.forEach(t),Lf=i(f),T(La.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var C$=s(Ae);Nk=r(C$,"will create a model that is an instance of "),wi=n(C$,"A",{href:!0});var kCe=s(wi);qk=r(kCe,"BertModel"),kCe.forEach(t),jk=r(C$,"."),C$.forEach(t),Co=i(f),xa=n(f,"P",{});var w$=s(xa);Dk=r(w$,"There is one class of "),xf=n(w$,"CODE",{});var SCe=s(xf);Gk=r(SCe,"AutoModel"),SCe.forEach(t),qXe=r(w$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),w$.forEach(t),EDe=i(f),Ai=n(f,"H2",{class:!0});var A$=s(Ai);$f=n(A$,"A",{id:!0,class:!0,href:!0});var RCe=s($f);Lre=n(RCe,"SPAN",{});var PCe=s(Lre);T(mA.$$.fragment,PCe),PCe.forEach(t),RCe.forEach(t),jXe=i(A$),xre=n(A$,"SPAN",{});var BCe=s(xre);DXe=r(BCe,"Extending the Auto Classes"),BCe.forEach(t),A$.forEach(t),CDe=i(f),In=n(f,"P",{});var Ef=s(In);GXe=r(Ef,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),$re=n(Ef,"CODE",{});var ICe=s($re);OXe=r(ICe,"NewModel"),ICe.forEach(t),VXe=r(Ef,", make sure you have a "),kre=n(Ef,"CODE",{});var NCe=s(kre);XXe=r(NCe,"NewModelConfig"),NCe.forEach(t),zXe=r(Ef,` then you can add those to the auto
classes like this:`),Ef.forEach(t),wDe=i(f),T(gA.$$.fragment,f),ADe=i(f),Ok=n(f,"P",{});var qCe=s(Ok);WXe=r(qCe,"You will then be able to use the auto classes like you would usually do!"),qCe.forEach(t),yDe=i(f),T(kf.$$.fragment,f),LDe=i(f),yi=n(f,"H2",{class:!0});var y$=s(yi);Sf=n(y$,"A",{id:!0,class:!0,href:!0});var jCe=s(Sf);Sre=n(jCe,"SPAN",{});var DCe=s(Sre);T(hA.$$.fragment,DCe),DCe.forEach(t),jCe.forEach(t),QXe=i(y$),Rre=n(y$,"SPAN",{});var GCe=s(Rre);HXe=r(GCe,"AutoConfig"),GCe.forEach(t),y$.forEach(t),xDe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(pA.$$.fragment,rt),UXe=i(rt),uA=n(rt,"P",{});var L$=s(uA);JXe=r(L$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Vk=n(L$,"A",{href:!0});var OCe=s(Vk);YXe=r(OCe,"from_pretrained()"),OCe.forEach(t),KXe=r(L$," class method."),L$.forEach(t),ZXe=i(rt),_A=n(rt,"P",{});var x$=s(_A);eze=r(x$,"This class cannot be instantiated directly using "),Pre=n(x$,"CODE",{});var VCe=s(Pre);oze=r(VCe,"__init__()"),VCe.forEach(t),rze=r(x$," (throws an error)."),x$.forEach(t),tze=i(rt),wr=n(rt,"DIV",{class:!0});var tt=s(wr);T(bA.$$.fragment,tt),aze=i(tt),Bre=n(tt,"P",{});var XCe=s(Bre);nze=r(XCe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),XCe.forEach(t),sze=i(tt),Li=n(tt,"P",{});var Cf=s(Li);lze=r(Cf,"The configuration class to instantiate is selected based on the "),Ire=n(Cf,"CODE",{});var zCe=s(Ire);ize=r(zCe,"model_type"),zCe.forEach(t),dze=r(Cf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Nre=n(Cf,"CODE",{});var WCe=s(Nre);cze=r(WCe,"pretrained_model_name_or_path"),WCe.forEach(t),fze=r(Cf,":"),Cf.forEach(t),mze=i(tt),A=n(tt,"UL",{});var y=s(A);Rf=n(y,"LI",{});var O5=s(Rf);qre=n(O5,"STRONG",{});var QCe=s(qre);gze=r(QCe,"albert"),QCe.forEach(t),hze=r(O5," \u2014 "),Xk=n(O5,"A",{href:!0});var HCe=s(Xk);pze=r(HCe,"AlbertConfig"),HCe.forEach(t),uze=r(O5," (ALBERT model)"),O5.forEach(t),_ze=i(y),Pf=n(y,"LI",{});var V5=s(Pf);jre=n(V5,"STRONG",{});var UCe=s(jre);bze=r(UCe,"bart"),UCe.forEach(t),vze=r(V5," \u2014 "),zk=n(V5,"A",{href:!0});var JCe=s(zk);Fze=r(JCe,"BartConfig"),JCe.forEach(t),Tze=r(V5," (BART model)"),V5.forEach(t),Mze=i(y),Bf=n(y,"LI",{});var X5=s(Bf);Dre=n(X5,"STRONG",{});var YCe=s(Dre);Eze=r(YCe,"beit"),YCe.forEach(t),Cze=r(X5," \u2014 "),Wk=n(X5,"A",{href:!0});var KCe=s(Wk);wze=r(KCe,"BeitConfig"),KCe.forEach(t),Aze=r(X5," (BEiT model)"),X5.forEach(t),yze=i(y),If=n(y,"LI",{});var z5=s(If);Gre=n(z5,"STRONG",{});var ZCe=s(Gre);Lze=r(ZCe,"bert"),ZCe.forEach(t),xze=r(z5," \u2014 "),Qk=n(z5,"A",{href:!0});var e5e=s(Qk);$ze=r(e5e,"BertConfig"),e5e.forEach(t),kze=r(z5," (BERT model)"),z5.forEach(t),Sze=i(y),Nf=n(y,"LI",{});var W5=s(Nf);Ore=n(W5,"STRONG",{});var o5e=s(Ore);Rze=r(o5e,"bert-generation"),o5e.forEach(t),Pze=r(W5," \u2014 "),Hk=n(W5,"A",{href:!0});var r5e=s(Hk);Bze=r(r5e,"BertGenerationConfig"),r5e.forEach(t),Ize=r(W5," (Bert Generation model)"),W5.forEach(t),Nze=i(y),qf=n(y,"LI",{});var Q5=s(qf);Vre=n(Q5,"STRONG",{});var t5e=s(Vre);qze=r(t5e,"big_bird"),t5e.forEach(t),jze=r(Q5," \u2014 "),Uk=n(Q5,"A",{href:!0});var a5e=s(Uk);Dze=r(a5e,"BigBirdConfig"),a5e.forEach(t),Gze=r(Q5," (BigBird model)"),Q5.forEach(t),Oze=i(y),jf=n(y,"LI",{});var H5=s(jf);Xre=n(H5,"STRONG",{});var n5e=s(Xre);Vze=r(n5e,"bigbird_pegasus"),n5e.forEach(t),Xze=r(H5," \u2014 "),Jk=n(H5,"A",{href:!0});var s5e=s(Jk);zze=r(s5e,"BigBirdPegasusConfig"),s5e.forEach(t),Wze=r(H5," (BigBird-Pegasus model)"),H5.forEach(t),Qze=i(y),Df=n(y,"LI",{});var U5=s(Df);zre=n(U5,"STRONG",{});var l5e=s(zre);Hze=r(l5e,"blenderbot"),l5e.forEach(t),Uze=r(U5," \u2014 "),Yk=n(U5,"A",{href:!0});var i5e=s(Yk);Jze=r(i5e,"BlenderbotConfig"),i5e.forEach(t),Yze=r(U5," (Blenderbot model)"),U5.forEach(t),Kze=i(y),Gf=n(y,"LI",{});var J5=s(Gf);Wre=n(J5,"STRONG",{});var d5e=s(Wre);Zze=r(d5e,"blenderbot-small"),d5e.forEach(t),eWe=r(J5," \u2014 "),Kk=n(J5,"A",{href:!0});var c5e=s(Kk);oWe=r(c5e,"BlenderbotSmallConfig"),c5e.forEach(t),rWe=r(J5," (BlenderbotSmall model)"),J5.forEach(t),tWe=i(y),Of=n(y,"LI",{});var Y5=s(Of);Qre=n(Y5,"STRONG",{});var f5e=s(Qre);aWe=r(f5e,"bloom"),f5e.forEach(t),nWe=r(Y5," \u2014 "),Zk=n(Y5,"A",{href:!0});var m5e=s(Zk);sWe=r(m5e,"BloomConfig"),m5e.forEach(t),lWe=r(Y5," (BLOOM model)"),Y5.forEach(t),iWe=i(y),Vf=n(y,"LI",{});var K5=s(Vf);Hre=n(K5,"STRONG",{});var g5e=s(Hre);dWe=r(g5e,"camembert"),g5e.forEach(t),cWe=r(K5," \u2014 "),eS=n(K5,"A",{href:!0});var h5e=s(eS);fWe=r(h5e,"CamembertConfig"),h5e.forEach(t),mWe=r(K5," (CamemBERT model)"),K5.forEach(t),gWe=i(y),Xf=n(y,"LI",{});var Z5=s(Xf);Ure=n(Z5,"STRONG",{});var p5e=s(Ure);hWe=r(p5e,"canine"),p5e.forEach(t),pWe=r(Z5," \u2014 "),oS=n(Z5,"A",{href:!0});var u5e=s(oS);uWe=r(u5e,"CanineConfig"),u5e.forEach(t),_We=r(Z5," (CANINE model)"),Z5.forEach(t),bWe=i(y),zf=n(y,"LI",{});var e0=s(zf);Jre=n(e0,"STRONG",{});var _5e=s(Jre);vWe=r(_5e,"clip"),_5e.forEach(t),FWe=r(e0," \u2014 "),rS=n(e0,"A",{href:!0});var b5e=s(rS);TWe=r(b5e,"CLIPConfig"),b5e.forEach(t),MWe=r(e0," (CLIP model)"),e0.forEach(t),EWe=i(y),Wf=n(y,"LI",{});var o0=s(Wf);Yre=n(o0,"STRONG",{});var v5e=s(Yre);CWe=r(v5e,"convbert"),v5e.forEach(t),wWe=r(o0," \u2014 "),tS=n(o0,"A",{href:!0});var F5e=s(tS);AWe=r(F5e,"ConvBertConfig"),F5e.forEach(t),yWe=r(o0," (ConvBERT model)"),o0.forEach(t),LWe=i(y),Qf=n(y,"LI",{});var r0=s(Qf);Kre=n(r0,"STRONG",{});var T5e=s(Kre);xWe=r(T5e,"convnext"),T5e.forEach(t),$We=r(r0," \u2014 "),aS=n(r0,"A",{href:!0});var M5e=s(aS);kWe=r(M5e,"ConvNextConfig"),M5e.forEach(t),SWe=r(r0," (ConvNeXT model)"),r0.forEach(t),RWe=i(y),Hf=n(y,"LI",{});var t0=s(Hf);Zre=n(t0,"STRONG",{});var E5e=s(Zre);PWe=r(E5e,"ctrl"),E5e.forEach(t),BWe=r(t0," \u2014 "),nS=n(t0,"A",{href:!0});var C5e=s(nS);IWe=r(C5e,"CTRLConfig"),C5e.forEach(t),NWe=r(t0," (CTRL model)"),t0.forEach(t),qWe=i(y),Uf=n(y,"LI",{});var a0=s(Uf);ete=n(a0,"STRONG",{});var w5e=s(ete);jWe=r(w5e,"cvt"),w5e.forEach(t),DWe=r(a0," \u2014 "),sS=n(a0,"A",{href:!0});var A5e=s(sS);GWe=r(A5e,"CvtConfig"),A5e.forEach(t),OWe=r(a0," (CvT model)"),a0.forEach(t),VWe=i(y),Jf=n(y,"LI",{});var n0=s(Jf);ote=n(n0,"STRONG",{});var y5e=s(ote);XWe=r(y5e,"data2vec-audio"),y5e.forEach(t),zWe=r(n0," \u2014 "),lS=n(n0,"A",{href:!0});var L5e=s(lS);WWe=r(L5e,"Data2VecAudioConfig"),L5e.forEach(t),QWe=r(n0," (Data2VecAudio model)"),n0.forEach(t),HWe=i(y),Yf=n(y,"LI",{});var s0=s(Yf);rte=n(s0,"STRONG",{});var x5e=s(rte);UWe=r(x5e,"data2vec-text"),x5e.forEach(t),JWe=r(s0," \u2014 "),iS=n(s0,"A",{href:!0});var $5e=s(iS);YWe=r($5e,"Data2VecTextConfig"),$5e.forEach(t),KWe=r(s0," (Data2VecText model)"),s0.forEach(t),ZWe=i(y),Kf=n(y,"LI",{});var l0=s(Kf);tte=n(l0,"STRONG",{});var k5e=s(tte);eQe=r(k5e,"data2vec-vision"),k5e.forEach(t),oQe=r(l0," \u2014 "),dS=n(l0,"A",{href:!0});var S5e=s(dS);rQe=r(S5e,"Data2VecVisionConfig"),S5e.forEach(t),tQe=r(l0," (Data2VecVision model)"),l0.forEach(t),aQe=i(y),Zf=n(y,"LI",{});var i0=s(Zf);ate=n(i0,"STRONG",{});var R5e=s(ate);nQe=r(R5e,"deberta"),R5e.forEach(t),sQe=r(i0," \u2014 "),cS=n(i0,"A",{href:!0});var P5e=s(cS);lQe=r(P5e,"DebertaConfig"),P5e.forEach(t),iQe=r(i0," (DeBERTa model)"),i0.forEach(t),dQe=i(y),em=n(y,"LI",{});var d0=s(em);nte=n(d0,"STRONG",{});var B5e=s(nte);cQe=r(B5e,"deberta-v2"),B5e.forEach(t),fQe=r(d0," \u2014 "),fS=n(d0,"A",{href:!0});var I5e=s(fS);mQe=r(I5e,"DebertaV2Config"),I5e.forEach(t),gQe=r(d0," (DeBERTa-v2 model)"),d0.forEach(t),hQe=i(y),om=n(y,"LI",{});var c0=s(om);ste=n(c0,"STRONG",{});var N5e=s(ste);pQe=r(N5e,"decision_transformer"),N5e.forEach(t),uQe=r(c0," \u2014 "),mS=n(c0,"A",{href:!0});var q5e=s(mS);_Qe=r(q5e,"DecisionTransformerConfig"),q5e.forEach(t),bQe=r(c0," (Decision Transformer model)"),c0.forEach(t),vQe=i(y),rm=n(y,"LI",{});var f0=s(rm);lte=n(f0,"STRONG",{});var rUr=s(lte);FQe=r(rUr,"deit"),rUr.forEach(t),TQe=r(f0," \u2014 "),gS=n(f0,"A",{href:!0});var tUr=s(gS);MQe=r(tUr,"DeiTConfig"),tUr.forEach(t),EQe=r(f0," (DeiT model)"),f0.forEach(t),CQe=i(y),tm=n(y,"LI",{});var j5e=s(tm);ite=n(j5e,"STRONG",{});var aUr=s(ite);wQe=r(aUr,"detr"),aUr.forEach(t),AQe=r(j5e," \u2014 "),hS=n(j5e,"A",{href:!0});var nUr=s(hS);yQe=r(nUr,"DetrConfig"),nUr.forEach(t),LQe=r(j5e," (DETR model)"),j5e.forEach(t),xQe=i(y),am=n(y,"LI",{});var D5e=s(am);dte=n(D5e,"STRONG",{});var sUr=s(dte);$Qe=r(sUr,"distilbert"),sUr.forEach(t),kQe=r(D5e," \u2014 "),pS=n(D5e,"A",{href:!0});var lUr=s(pS);SQe=r(lUr,"DistilBertConfig"),lUr.forEach(t),RQe=r(D5e," (DistilBERT model)"),D5e.forEach(t),PQe=i(y),nm=n(y,"LI",{});var G5e=s(nm);cte=n(G5e,"STRONG",{});var iUr=s(cte);BQe=r(iUr,"dpr"),iUr.forEach(t),IQe=r(G5e," \u2014 "),uS=n(G5e,"A",{href:!0});var dUr=s(uS);NQe=r(dUr,"DPRConfig"),dUr.forEach(t),qQe=r(G5e," (DPR model)"),G5e.forEach(t),jQe=i(y),sm=n(y,"LI",{});var O5e=s(sm);fte=n(O5e,"STRONG",{});var cUr=s(fte);DQe=r(cUr,"dpt"),cUr.forEach(t),GQe=r(O5e," \u2014 "),_S=n(O5e,"A",{href:!0});var fUr=s(_S);OQe=r(fUr,"DPTConfig"),fUr.forEach(t),VQe=r(O5e," (DPT model)"),O5e.forEach(t),XQe=i(y),lm=n(y,"LI",{});var V5e=s(lm);mte=n(V5e,"STRONG",{});var mUr=s(mte);zQe=r(mUr,"electra"),mUr.forEach(t),WQe=r(V5e," \u2014 "),bS=n(V5e,"A",{href:!0});var gUr=s(bS);QQe=r(gUr,"ElectraConfig"),gUr.forEach(t),HQe=r(V5e," (ELECTRA model)"),V5e.forEach(t),UQe=i(y),im=n(y,"LI",{});var X5e=s(im);gte=n(X5e,"STRONG",{});var hUr=s(gte);JQe=r(hUr,"encoder-decoder"),hUr.forEach(t),YQe=r(X5e," \u2014 "),vS=n(X5e,"A",{href:!0});var pUr=s(vS);KQe=r(pUr,"EncoderDecoderConfig"),pUr.forEach(t),ZQe=r(X5e," (Encoder decoder model)"),X5e.forEach(t),eHe=i(y),dm=n(y,"LI",{});var z5e=s(dm);hte=n(z5e,"STRONG",{});var uUr=s(hte);oHe=r(uUr,"flaubert"),uUr.forEach(t),rHe=r(z5e," \u2014 "),FS=n(z5e,"A",{href:!0});var _Ur=s(FS);tHe=r(_Ur,"FlaubertConfig"),_Ur.forEach(t),aHe=r(z5e," (FlauBERT model)"),z5e.forEach(t),nHe=i(y),cm=n(y,"LI",{});var W5e=s(cm);pte=n(W5e,"STRONG",{});var bUr=s(pte);sHe=r(bUr,"flava"),bUr.forEach(t),lHe=r(W5e," \u2014 "),TS=n(W5e,"A",{href:!0});var vUr=s(TS);iHe=r(vUr,"FlavaConfig"),vUr.forEach(t),dHe=r(W5e," (FLAVA model)"),W5e.forEach(t),cHe=i(y),fm=n(y,"LI",{});var Q5e=s(fm);ute=n(Q5e,"STRONG",{});var FUr=s(ute);fHe=r(FUr,"fnet"),FUr.forEach(t),mHe=r(Q5e," \u2014 "),MS=n(Q5e,"A",{href:!0});var TUr=s(MS);gHe=r(TUr,"FNetConfig"),TUr.forEach(t),hHe=r(Q5e," (FNet model)"),Q5e.forEach(t),pHe=i(y),mm=n(y,"LI",{});var H5e=s(mm);_te=n(H5e,"STRONG",{});var MUr=s(_te);uHe=r(MUr,"fsmt"),MUr.forEach(t),_He=r(H5e," \u2014 "),ES=n(H5e,"A",{href:!0});var EUr=s(ES);bHe=r(EUr,"FSMTConfig"),EUr.forEach(t),vHe=r(H5e," (FairSeq Machine-Translation model)"),H5e.forEach(t),FHe=i(y),gm=n(y,"LI",{});var U5e=s(gm);bte=n(U5e,"STRONG",{});var CUr=s(bte);THe=r(CUr,"funnel"),CUr.forEach(t),MHe=r(U5e," \u2014 "),CS=n(U5e,"A",{href:!0});var wUr=s(CS);EHe=r(wUr,"FunnelConfig"),wUr.forEach(t),CHe=r(U5e," (Funnel Transformer model)"),U5e.forEach(t),wHe=i(y),hm=n(y,"LI",{});var J5e=s(hm);vte=n(J5e,"STRONG",{});var AUr=s(vte);AHe=r(AUr,"glpn"),AUr.forEach(t),yHe=r(J5e," \u2014 "),wS=n(J5e,"A",{href:!0});var yUr=s(wS);LHe=r(yUr,"GLPNConfig"),yUr.forEach(t),xHe=r(J5e," (GLPN model)"),J5e.forEach(t),$He=i(y),pm=n(y,"LI",{});var Y5e=s(pm);Fte=n(Y5e,"STRONG",{});var LUr=s(Fte);kHe=r(LUr,"gpt2"),LUr.forEach(t),SHe=r(Y5e," \u2014 "),AS=n(Y5e,"A",{href:!0});var xUr=s(AS);RHe=r(xUr,"GPT2Config"),xUr.forEach(t),PHe=r(Y5e," (OpenAI GPT-2 model)"),Y5e.forEach(t),BHe=i(y),um=n(y,"LI",{});var K5e=s(um);Tte=n(K5e,"STRONG",{});var $Ur=s(Tte);IHe=r($Ur,"gpt_neo"),$Ur.forEach(t),NHe=r(K5e," \u2014 "),yS=n(K5e,"A",{href:!0});var kUr=s(yS);qHe=r(kUr,"GPTNeoConfig"),kUr.forEach(t),jHe=r(K5e," (GPT Neo model)"),K5e.forEach(t),DHe=i(y),_m=n(y,"LI",{});var Z5e=s(_m);Mte=n(Z5e,"STRONG",{});var SUr=s(Mte);GHe=r(SUr,"gpt_neox"),SUr.forEach(t),OHe=r(Z5e," \u2014 "),LS=n(Z5e,"A",{href:!0});var RUr=s(LS);VHe=r(RUr,"GPTNeoXConfig"),RUr.forEach(t),XHe=r(Z5e," (GPT NeoX model)"),Z5e.forEach(t),zHe=i(y),bm=n(y,"LI",{});var e0e=s(bm);Ete=n(e0e,"STRONG",{});var PUr=s(Ete);WHe=r(PUr,"gptj"),PUr.forEach(t),QHe=r(e0e," \u2014 "),xS=n(e0e,"A",{href:!0});var BUr=s(xS);HHe=r(BUr,"GPTJConfig"),BUr.forEach(t),UHe=r(e0e," (GPT-J model)"),e0e.forEach(t),JHe=i(y),vm=n(y,"LI",{});var o0e=s(vm);Cte=n(o0e,"STRONG",{});var IUr=s(Cte);YHe=r(IUr,"hubert"),IUr.forEach(t),KHe=r(o0e," \u2014 "),$S=n(o0e,"A",{href:!0});var NUr=s($S);ZHe=r(NUr,"HubertConfig"),NUr.forEach(t),eUe=r(o0e," (Hubert model)"),o0e.forEach(t),oUe=i(y),Fm=n(y,"LI",{});var r0e=s(Fm);wte=n(r0e,"STRONG",{});var qUr=s(wte);rUe=r(qUr,"ibert"),qUr.forEach(t),tUe=r(r0e," \u2014 "),kS=n(r0e,"A",{href:!0});var jUr=s(kS);aUe=r(jUr,"IBertConfig"),jUr.forEach(t),nUe=r(r0e," (I-BERT model)"),r0e.forEach(t),sUe=i(y),Tm=n(y,"LI",{});var t0e=s(Tm);Ate=n(t0e,"STRONG",{});var DUr=s(Ate);lUe=r(DUr,"imagegpt"),DUr.forEach(t),iUe=r(t0e," \u2014 "),SS=n(t0e,"A",{href:!0});var GUr=s(SS);dUe=r(GUr,"ImageGPTConfig"),GUr.forEach(t),cUe=r(t0e," (ImageGPT model)"),t0e.forEach(t),fUe=i(y),Mm=n(y,"LI",{});var a0e=s(Mm);yte=n(a0e,"STRONG",{});var OUr=s(yte);mUe=r(OUr,"layoutlm"),OUr.forEach(t),gUe=r(a0e," \u2014 "),RS=n(a0e,"A",{href:!0});var VUr=s(RS);hUe=r(VUr,"LayoutLMConfig"),VUr.forEach(t),pUe=r(a0e," (LayoutLM model)"),a0e.forEach(t),uUe=i(y),Em=n(y,"LI",{});var n0e=s(Em);Lte=n(n0e,"STRONG",{});var XUr=s(Lte);_Ue=r(XUr,"layoutlmv2"),XUr.forEach(t),bUe=r(n0e," \u2014 "),PS=n(n0e,"A",{href:!0});var zUr=s(PS);vUe=r(zUr,"LayoutLMv2Config"),zUr.forEach(t),FUe=r(n0e," (LayoutLMv2 model)"),n0e.forEach(t),TUe=i(y),Cm=n(y,"LI",{});var s0e=s(Cm);xte=n(s0e,"STRONG",{});var WUr=s(xte);MUe=r(WUr,"layoutlmv3"),WUr.forEach(t),EUe=r(s0e," \u2014 "),BS=n(s0e,"A",{href:!0});var QUr=s(BS);CUe=r(QUr,"LayoutLMv3Config"),QUr.forEach(t),wUe=r(s0e," (LayoutLMv3 model)"),s0e.forEach(t),AUe=i(y),wm=n(y,"LI",{});var l0e=s(wm);$te=n(l0e,"STRONG",{});var HUr=s($te);yUe=r(HUr,"led"),HUr.forEach(t),LUe=r(l0e," \u2014 "),IS=n(l0e,"A",{href:!0});var UUr=s(IS);xUe=r(UUr,"LEDConfig"),UUr.forEach(t),$Ue=r(l0e," (LED model)"),l0e.forEach(t),kUe=i(y),Am=n(y,"LI",{});var i0e=s(Am);kte=n(i0e,"STRONG",{});var JUr=s(kte);SUe=r(JUr,"levit"),JUr.forEach(t),RUe=r(i0e," \u2014 "),NS=n(i0e,"A",{href:!0});var YUr=s(NS);PUe=r(YUr,"LevitConfig"),YUr.forEach(t),BUe=r(i0e," (LeViT model)"),i0e.forEach(t),IUe=i(y),ym=n(y,"LI",{});var d0e=s(ym);Ste=n(d0e,"STRONG",{});var KUr=s(Ste);NUe=r(KUr,"longformer"),KUr.forEach(t),qUe=r(d0e," \u2014 "),qS=n(d0e,"A",{href:!0});var ZUr=s(qS);jUe=r(ZUr,"LongformerConfig"),ZUr.forEach(t),DUe=r(d0e," (Longformer model)"),d0e.forEach(t),GUe=i(y),Lm=n(y,"LI",{});var c0e=s(Lm);Rte=n(c0e,"STRONG",{});var eJr=s(Rte);OUe=r(eJr,"luke"),eJr.forEach(t),VUe=r(c0e," \u2014 "),jS=n(c0e,"A",{href:!0});var oJr=s(jS);XUe=r(oJr,"LukeConfig"),oJr.forEach(t),zUe=r(c0e," (LUKE model)"),c0e.forEach(t),WUe=i(y),xm=n(y,"LI",{});var f0e=s(xm);Pte=n(f0e,"STRONG",{});var rJr=s(Pte);QUe=r(rJr,"lxmert"),rJr.forEach(t),HUe=r(f0e," \u2014 "),DS=n(f0e,"A",{href:!0});var tJr=s(DS);UUe=r(tJr,"LxmertConfig"),tJr.forEach(t),JUe=r(f0e," (LXMERT model)"),f0e.forEach(t),YUe=i(y),$m=n(y,"LI",{});var m0e=s($m);Bte=n(m0e,"STRONG",{});var aJr=s(Bte);KUe=r(aJr,"m2m_100"),aJr.forEach(t),ZUe=r(m0e," \u2014 "),GS=n(m0e,"A",{href:!0});var nJr=s(GS);eJe=r(nJr,"M2M100Config"),nJr.forEach(t),oJe=r(m0e," (M2M100 model)"),m0e.forEach(t),rJe=i(y),km=n(y,"LI",{});var g0e=s(km);Ite=n(g0e,"STRONG",{});var sJr=s(Ite);tJe=r(sJr,"marian"),sJr.forEach(t),aJe=r(g0e," \u2014 "),OS=n(g0e,"A",{href:!0});var lJr=s(OS);nJe=r(lJr,"MarianConfig"),lJr.forEach(t),sJe=r(g0e," (Marian model)"),g0e.forEach(t),lJe=i(y),Sm=n(y,"LI",{});var h0e=s(Sm);Nte=n(h0e,"STRONG",{});var iJr=s(Nte);iJe=r(iJr,"maskformer"),iJr.forEach(t),dJe=r(h0e," \u2014 "),VS=n(h0e,"A",{href:!0});var dJr=s(VS);cJe=r(dJr,"MaskFormerConfig"),dJr.forEach(t),fJe=r(h0e," (MaskFormer model)"),h0e.forEach(t),mJe=i(y),Rm=n(y,"LI",{});var p0e=s(Rm);qte=n(p0e,"STRONG",{});var cJr=s(qte);gJe=r(cJr,"mbart"),cJr.forEach(t),hJe=r(p0e," \u2014 "),XS=n(p0e,"A",{href:!0});var fJr=s(XS);pJe=r(fJr,"MBartConfig"),fJr.forEach(t),uJe=r(p0e," (mBART model)"),p0e.forEach(t),_Je=i(y),Pm=n(y,"LI",{});var u0e=s(Pm);jte=n(u0e,"STRONG",{});var mJr=s(jte);bJe=r(mJr,"mctct"),mJr.forEach(t),vJe=r(u0e," \u2014 "),zS=n(u0e,"A",{href:!0});var gJr=s(zS);FJe=r(gJr,"MCTCTConfig"),gJr.forEach(t),TJe=r(u0e," (M-CTC-T model)"),u0e.forEach(t),MJe=i(y),Bm=n(y,"LI",{});var _0e=s(Bm);Dte=n(_0e,"STRONG",{});var hJr=s(Dte);EJe=r(hJr,"megatron-bert"),hJr.forEach(t),CJe=r(_0e," \u2014 "),WS=n(_0e,"A",{href:!0});var pJr=s(WS);wJe=r(pJr,"MegatronBertConfig"),pJr.forEach(t),AJe=r(_0e," (Megatron-BERT model)"),_0e.forEach(t),yJe=i(y),Im=n(y,"LI",{});var b0e=s(Im);Gte=n(b0e,"STRONG",{});var uJr=s(Gte);LJe=r(uJr,"mobilebert"),uJr.forEach(t),xJe=r(b0e," \u2014 "),QS=n(b0e,"A",{href:!0});var _Jr=s(QS);$Je=r(_Jr,"MobileBertConfig"),_Jr.forEach(t),kJe=r(b0e," (MobileBERT model)"),b0e.forEach(t),SJe=i(y),Nm=n(y,"LI",{});var v0e=s(Nm);Ote=n(v0e,"STRONG",{});var bJr=s(Ote);RJe=r(bJr,"mpnet"),bJr.forEach(t),PJe=r(v0e," \u2014 "),HS=n(v0e,"A",{href:!0});var vJr=s(HS);BJe=r(vJr,"MPNetConfig"),vJr.forEach(t),IJe=r(v0e," (MPNet model)"),v0e.forEach(t),NJe=i(y),qm=n(y,"LI",{});var F0e=s(qm);Vte=n(F0e,"STRONG",{});var FJr=s(Vte);qJe=r(FJr,"mt5"),FJr.forEach(t),jJe=r(F0e," \u2014 "),US=n(F0e,"A",{href:!0});var TJr=s(US);DJe=r(TJr,"MT5Config"),TJr.forEach(t),GJe=r(F0e," (MT5 model)"),F0e.forEach(t),OJe=i(y),jm=n(y,"LI",{});var T0e=s(jm);Xte=n(T0e,"STRONG",{});var MJr=s(Xte);VJe=r(MJr,"nystromformer"),MJr.forEach(t),XJe=r(T0e," \u2014 "),JS=n(T0e,"A",{href:!0});var EJr=s(JS);zJe=r(EJr,"NystromformerConfig"),EJr.forEach(t),WJe=r(T0e," (Nystr\xF6mformer model)"),T0e.forEach(t),QJe=i(y),Dm=n(y,"LI",{});var M0e=s(Dm);zte=n(M0e,"STRONG",{});var CJr=s(zte);HJe=r(CJr,"openai-gpt"),CJr.forEach(t),UJe=r(M0e," \u2014 "),YS=n(M0e,"A",{href:!0});var wJr=s(YS);JJe=r(wJr,"OpenAIGPTConfig"),wJr.forEach(t),YJe=r(M0e," (OpenAI GPT model)"),M0e.forEach(t),KJe=i(y),Gm=n(y,"LI",{});var E0e=s(Gm);Wte=n(E0e,"STRONG",{});var AJr=s(Wte);ZJe=r(AJr,"opt"),AJr.forEach(t),eYe=r(E0e," \u2014 "),KS=n(E0e,"A",{href:!0});var yJr=s(KS);oYe=r(yJr,"OPTConfig"),yJr.forEach(t),rYe=r(E0e," (OPT model)"),E0e.forEach(t),tYe=i(y),Om=n(y,"LI",{});var C0e=s(Om);Qte=n(C0e,"STRONG",{});var LJr=s(Qte);aYe=r(LJr,"pegasus"),LJr.forEach(t),nYe=r(C0e," \u2014 "),ZS=n(C0e,"A",{href:!0});var xJr=s(ZS);sYe=r(xJr,"PegasusConfig"),xJr.forEach(t),lYe=r(C0e," (Pegasus model)"),C0e.forEach(t),iYe=i(y),Vm=n(y,"LI",{});var w0e=s(Vm);Hte=n(w0e,"STRONG",{});var $Jr=s(Hte);dYe=r($Jr,"perceiver"),$Jr.forEach(t),cYe=r(w0e," \u2014 "),eR=n(w0e,"A",{href:!0});var kJr=s(eR);fYe=r(kJr,"PerceiverConfig"),kJr.forEach(t),mYe=r(w0e," (Perceiver model)"),w0e.forEach(t),gYe=i(y),Xm=n(y,"LI",{});var A0e=s(Xm);Ute=n(A0e,"STRONG",{});var SJr=s(Ute);hYe=r(SJr,"plbart"),SJr.forEach(t),pYe=r(A0e," \u2014 "),oR=n(A0e,"A",{href:!0});var RJr=s(oR);uYe=r(RJr,"PLBartConfig"),RJr.forEach(t),_Ye=r(A0e," (PLBart model)"),A0e.forEach(t),bYe=i(y),zm=n(y,"LI",{});var y0e=s(zm);Jte=n(y0e,"STRONG",{});var PJr=s(Jte);vYe=r(PJr,"poolformer"),PJr.forEach(t),FYe=r(y0e," \u2014 "),rR=n(y0e,"A",{href:!0});var BJr=s(rR);TYe=r(BJr,"PoolFormerConfig"),BJr.forEach(t),MYe=r(y0e," (PoolFormer model)"),y0e.forEach(t),EYe=i(y),Wm=n(y,"LI",{});var L0e=s(Wm);Yte=n(L0e,"STRONG",{});var IJr=s(Yte);CYe=r(IJr,"prophetnet"),IJr.forEach(t),wYe=r(L0e," \u2014 "),tR=n(L0e,"A",{href:!0});var NJr=s(tR);AYe=r(NJr,"ProphetNetConfig"),NJr.forEach(t),yYe=r(L0e," (ProphetNet model)"),L0e.forEach(t),LYe=i(y),Qm=n(y,"LI",{});var x0e=s(Qm);Kte=n(x0e,"STRONG",{});var qJr=s(Kte);xYe=r(qJr,"qdqbert"),qJr.forEach(t),$Ye=r(x0e," \u2014 "),aR=n(x0e,"A",{href:!0});var jJr=s(aR);kYe=r(jJr,"QDQBertConfig"),jJr.forEach(t),SYe=r(x0e," (QDQBert model)"),x0e.forEach(t),RYe=i(y),Hm=n(y,"LI",{});var $0e=s(Hm);Zte=n($0e,"STRONG",{});var DJr=s(Zte);PYe=r(DJr,"rag"),DJr.forEach(t),BYe=r($0e," \u2014 "),nR=n($0e,"A",{href:!0});var GJr=s(nR);IYe=r(GJr,"RagConfig"),GJr.forEach(t),NYe=r($0e," (RAG model)"),$0e.forEach(t),qYe=i(y),Um=n(y,"LI",{});var k0e=s(Um);eae=n(k0e,"STRONG",{});var OJr=s(eae);jYe=r(OJr,"realm"),OJr.forEach(t),DYe=r(k0e," \u2014 "),sR=n(k0e,"A",{href:!0});var VJr=s(sR);GYe=r(VJr,"RealmConfig"),VJr.forEach(t),OYe=r(k0e," (REALM model)"),k0e.forEach(t),VYe=i(y),Jm=n(y,"LI",{});var S0e=s(Jm);oae=n(S0e,"STRONG",{});var XJr=s(oae);XYe=r(XJr,"reformer"),XJr.forEach(t),zYe=r(S0e," \u2014 "),lR=n(S0e,"A",{href:!0});var zJr=s(lR);WYe=r(zJr,"ReformerConfig"),zJr.forEach(t),QYe=r(S0e," (Reformer model)"),S0e.forEach(t),HYe=i(y),Ym=n(y,"LI",{});var R0e=s(Ym);rae=n(R0e,"STRONG",{});var WJr=s(rae);UYe=r(WJr,"regnet"),WJr.forEach(t),JYe=r(R0e," \u2014 "),iR=n(R0e,"A",{href:!0});var QJr=s(iR);YYe=r(QJr,"RegNetConfig"),QJr.forEach(t),KYe=r(R0e," (RegNet model)"),R0e.forEach(t),ZYe=i(y),Km=n(y,"LI",{});var P0e=s(Km);tae=n(P0e,"STRONG",{});var HJr=s(tae);eKe=r(HJr,"rembert"),HJr.forEach(t),oKe=r(P0e," \u2014 "),dR=n(P0e,"A",{href:!0});var UJr=s(dR);rKe=r(UJr,"RemBertConfig"),UJr.forEach(t),tKe=r(P0e," (RemBERT model)"),P0e.forEach(t),aKe=i(y),Zm=n(y,"LI",{});var B0e=s(Zm);aae=n(B0e,"STRONG",{});var JJr=s(aae);nKe=r(JJr,"resnet"),JJr.forEach(t),sKe=r(B0e," \u2014 "),cR=n(B0e,"A",{href:!0});var YJr=s(cR);lKe=r(YJr,"ResNetConfig"),YJr.forEach(t),iKe=r(B0e," (ResNet model)"),B0e.forEach(t),dKe=i(y),eg=n(y,"LI",{});var I0e=s(eg);nae=n(I0e,"STRONG",{});var KJr=s(nae);cKe=r(KJr,"retribert"),KJr.forEach(t),fKe=r(I0e," \u2014 "),fR=n(I0e,"A",{href:!0});var ZJr=s(fR);mKe=r(ZJr,"RetriBertConfig"),ZJr.forEach(t),gKe=r(I0e," (RetriBERT model)"),I0e.forEach(t),hKe=i(y),og=n(y,"LI",{});var N0e=s(og);sae=n(N0e,"STRONG",{});var eYr=s(sae);pKe=r(eYr,"roberta"),eYr.forEach(t),uKe=r(N0e," \u2014 "),mR=n(N0e,"A",{href:!0});var oYr=s(mR);_Ke=r(oYr,"RobertaConfig"),oYr.forEach(t),bKe=r(N0e," (RoBERTa model)"),N0e.forEach(t),vKe=i(y),rg=n(y,"LI",{});var q0e=s(rg);lae=n(q0e,"STRONG",{});var rYr=s(lae);FKe=r(rYr,"roformer"),rYr.forEach(t),TKe=r(q0e," \u2014 "),gR=n(q0e,"A",{href:!0});var tYr=s(gR);MKe=r(tYr,"RoFormerConfig"),tYr.forEach(t),EKe=r(q0e," (RoFormer model)"),q0e.forEach(t),CKe=i(y),tg=n(y,"LI",{});var j0e=s(tg);iae=n(j0e,"STRONG",{});var aYr=s(iae);wKe=r(aYr,"segformer"),aYr.forEach(t),AKe=r(j0e," \u2014 "),hR=n(j0e,"A",{href:!0});var nYr=s(hR);yKe=r(nYr,"SegformerConfig"),nYr.forEach(t),LKe=r(j0e," (SegFormer model)"),j0e.forEach(t),xKe=i(y),ag=n(y,"LI",{});var D0e=s(ag);dae=n(D0e,"STRONG",{});var sYr=s(dae);$Ke=r(sYr,"sew"),sYr.forEach(t),kKe=r(D0e," \u2014 "),pR=n(D0e,"A",{href:!0});var lYr=s(pR);SKe=r(lYr,"SEWConfig"),lYr.forEach(t),RKe=r(D0e," (SEW model)"),D0e.forEach(t),PKe=i(y),ng=n(y,"LI",{});var G0e=s(ng);cae=n(G0e,"STRONG",{});var iYr=s(cae);BKe=r(iYr,"sew-d"),iYr.forEach(t),IKe=r(G0e," \u2014 "),uR=n(G0e,"A",{href:!0});var dYr=s(uR);NKe=r(dYr,"SEWDConfig"),dYr.forEach(t),qKe=r(G0e," (SEW-D model)"),G0e.forEach(t),jKe=i(y),sg=n(y,"LI",{});var O0e=s(sg);fae=n(O0e,"STRONG",{});var cYr=s(fae);DKe=r(cYr,"speech-encoder-decoder"),cYr.forEach(t),GKe=r(O0e," \u2014 "),_R=n(O0e,"A",{href:!0});var fYr=s(_R);OKe=r(fYr,"SpeechEncoderDecoderConfig"),fYr.forEach(t),VKe=r(O0e," (Speech Encoder decoder model)"),O0e.forEach(t),XKe=i(y),lg=n(y,"LI",{});var V0e=s(lg);mae=n(V0e,"STRONG",{});var mYr=s(mae);zKe=r(mYr,"speech_to_text"),mYr.forEach(t),WKe=r(V0e," \u2014 "),bR=n(V0e,"A",{href:!0});var gYr=s(bR);QKe=r(gYr,"Speech2TextConfig"),gYr.forEach(t),HKe=r(V0e," (Speech2Text model)"),V0e.forEach(t),UKe=i(y),ig=n(y,"LI",{});var X0e=s(ig);gae=n(X0e,"STRONG",{});var hYr=s(gae);JKe=r(hYr,"speech_to_text_2"),hYr.forEach(t),YKe=r(X0e," \u2014 "),vR=n(X0e,"A",{href:!0});var pYr=s(vR);KKe=r(pYr,"Speech2Text2Config"),pYr.forEach(t),ZKe=r(X0e," (Speech2Text2 model)"),X0e.forEach(t),eZe=i(y),dg=n(y,"LI",{});var z0e=s(dg);hae=n(z0e,"STRONG",{});var uYr=s(hae);oZe=r(uYr,"splinter"),uYr.forEach(t),rZe=r(z0e," \u2014 "),FR=n(z0e,"A",{href:!0});var _Yr=s(FR);tZe=r(_Yr,"SplinterConfig"),_Yr.forEach(t),aZe=r(z0e," (Splinter model)"),z0e.forEach(t),nZe=i(y),cg=n(y,"LI",{});var W0e=s(cg);pae=n(W0e,"STRONG",{});var bYr=s(pae);sZe=r(bYr,"squeezebert"),bYr.forEach(t),lZe=r(W0e," \u2014 "),TR=n(W0e,"A",{href:!0});var vYr=s(TR);iZe=r(vYr,"SqueezeBertConfig"),vYr.forEach(t),dZe=r(W0e," (SqueezeBERT model)"),W0e.forEach(t),cZe=i(y),fg=n(y,"LI",{});var Q0e=s(fg);uae=n(Q0e,"STRONG",{});var FYr=s(uae);fZe=r(FYr,"swin"),FYr.forEach(t),mZe=r(Q0e," \u2014 "),MR=n(Q0e,"A",{href:!0});var TYr=s(MR);gZe=r(TYr,"SwinConfig"),TYr.forEach(t),hZe=r(Q0e," (Swin Transformer model)"),Q0e.forEach(t),pZe=i(y),mg=n(y,"LI",{});var H0e=s(mg);_ae=n(H0e,"STRONG",{});var MYr=s(_ae);uZe=r(MYr,"t5"),MYr.forEach(t),_Ze=r(H0e," \u2014 "),ER=n(H0e,"A",{href:!0});var EYr=s(ER);bZe=r(EYr,"T5Config"),EYr.forEach(t),vZe=r(H0e," (T5 model)"),H0e.forEach(t),FZe=i(y),gg=n(y,"LI",{});var U0e=s(gg);bae=n(U0e,"STRONG",{});var CYr=s(bae);TZe=r(CYr,"tapas"),CYr.forEach(t),MZe=r(U0e," \u2014 "),CR=n(U0e,"A",{href:!0});var wYr=s(CR);EZe=r(wYr,"TapasConfig"),wYr.forEach(t),CZe=r(U0e," (TAPAS model)"),U0e.forEach(t),wZe=i(y),hg=n(y,"LI",{});var J0e=s(hg);vae=n(J0e,"STRONG",{});var AYr=s(vae);AZe=r(AYr,"trajectory_transformer"),AYr.forEach(t),yZe=r(J0e," \u2014 "),wR=n(J0e,"A",{href:!0});var yYr=s(wR);LZe=r(yYr,"TrajectoryTransformerConfig"),yYr.forEach(t),xZe=r(J0e," (Trajectory Transformer model)"),J0e.forEach(t),$Ze=i(y),pg=n(y,"LI",{});var Y0e=s(pg);Fae=n(Y0e,"STRONG",{});var LYr=s(Fae);kZe=r(LYr,"transfo-xl"),LYr.forEach(t),SZe=r(Y0e," \u2014 "),AR=n(Y0e,"A",{href:!0});var xYr=s(AR);RZe=r(xYr,"TransfoXLConfig"),xYr.forEach(t),PZe=r(Y0e," (Transformer-XL model)"),Y0e.forEach(t),BZe=i(y),ug=n(y,"LI",{});var K0e=s(ug);Tae=n(K0e,"STRONG",{});var $Yr=s(Tae);IZe=r($Yr,"trocr"),$Yr.forEach(t),NZe=r(K0e," \u2014 "),yR=n(K0e,"A",{href:!0});var kYr=s(yR);qZe=r(kYr,"TrOCRConfig"),kYr.forEach(t),jZe=r(K0e," (TrOCR model)"),K0e.forEach(t),DZe=i(y),_g=n(y,"LI",{});var Z0e=s(_g);Mae=n(Z0e,"STRONG",{});var SYr=s(Mae);GZe=r(SYr,"unispeech"),SYr.forEach(t),OZe=r(Z0e," \u2014 "),LR=n(Z0e,"A",{href:!0});var RYr=s(LR);VZe=r(RYr,"UniSpeechConfig"),RYr.forEach(t),XZe=r(Z0e," (UniSpeech model)"),Z0e.forEach(t),zZe=i(y),bg=n(y,"LI",{});var ewe=s(bg);Eae=n(ewe,"STRONG",{});var PYr=s(Eae);WZe=r(PYr,"unispeech-sat"),PYr.forEach(t),QZe=r(ewe," \u2014 "),xR=n(ewe,"A",{href:!0});var BYr=s(xR);HZe=r(BYr,"UniSpeechSatConfig"),BYr.forEach(t),UZe=r(ewe," (UniSpeechSat model)"),ewe.forEach(t),JZe=i(y),vg=n(y,"LI",{});var owe=s(vg);Cae=n(owe,"STRONG",{});var IYr=s(Cae);YZe=r(IYr,"van"),IYr.forEach(t),KZe=r(owe," \u2014 "),$R=n(owe,"A",{href:!0});var NYr=s($R);ZZe=r(NYr,"VanConfig"),NYr.forEach(t),eeo=r(owe," (VAN model)"),owe.forEach(t),oeo=i(y),Fg=n(y,"LI",{});var rwe=s(Fg);wae=n(rwe,"STRONG",{});var qYr=s(wae);reo=r(qYr,"vilt"),qYr.forEach(t),teo=r(rwe," \u2014 "),kR=n(rwe,"A",{href:!0});var jYr=s(kR);aeo=r(jYr,"ViltConfig"),jYr.forEach(t),neo=r(rwe," (ViLT model)"),rwe.forEach(t),seo=i(y),Tg=n(y,"LI",{});var twe=s(Tg);Aae=n(twe,"STRONG",{});var DYr=s(Aae);leo=r(DYr,"vision-encoder-decoder"),DYr.forEach(t),ieo=r(twe," \u2014 "),SR=n(twe,"A",{href:!0});var GYr=s(SR);deo=r(GYr,"VisionEncoderDecoderConfig"),GYr.forEach(t),ceo=r(twe," (Vision Encoder decoder model)"),twe.forEach(t),feo=i(y),Mg=n(y,"LI",{});var awe=s(Mg);yae=n(awe,"STRONG",{});var OYr=s(yae);meo=r(OYr,"vision-text-dual-encoder"),OYr.forEach(t),geo=r(awe," \u2014 "),RR=n(awe,"A",{href:!0});var VYr=s(RR);heo=r(VYr,"VisionTextDualEncoderConfig"),VYr.forEach(t),peo=r(awe," (VisionTextDualEncoder model)"),awe.forEach(t),ueo=i(y),Eg=n(y,"LI",{});var nwe=s(Eg);Lae=n(nwe,"STRONG",{});var XYr=s(Lae);_eo=r(XYr,"visual_bert"),XYr.forEach(t),beo=r(nwe," \u2014 "),PR=n(nwe,"A",{href:!0});var zYr=s(PR);veo=r(zYr,"VisualBertConfig"),zYr.forEach(t),Feo=r(nwe," (VisualBERT model)"),nwe.forEach(t),Teo=i(y),Cg=n(y,"LI",{});var swe=s(Cg);xae=n(swe,"STRONG",{});var WYr=s(xae);Meo=r(WYr,"vit"),WYr.forEach(t),Eeo=r(swe," \u2014 "),BR=n(swe,"A",{href:!0});var QYr=s(BR);Ceo=r(QYr,"ViTConfig"),QYr.forEach(t),weo=r(swe," (ViT model)"),swe.forEach(t),Aeo=i(y),wg=n(y,"LI",{});var lwe=s(wg);$ae=n(lwe,"STRONG",{});var HYr=s($ae);yeo=r(HYr,"vit_mae"),HYr.forEach(t),Leo=r(lwe," \u2014 "),IR=n(lwe,"A",{href:!0});var UYr=s(IR);xeo=r(UYr,"ViTMAEConfig"),UYr.forEach(t),$eo=r(lwe," (ViTMAE model)"),lwe.forEach(t),keo=i(y),Ag=n(y,"LI",{});var iwe=s(Ag);kae=n(iwe,"STRONG",{});var JYr=s(kae);Seo=r(JYr,"wav2vec2"),JYr.forEach(t),Reo=r(iwe," \u2014 "),NR=n(iwe,"A",{href:!0});var YYr=s(NR);Peo=r(YYr,"Wav2Vec2Config"),YYr.forEach(t),Beo=r(iwe," (Wav2Vec2 model)"),iwe.forEach(t),Ieo=i(y),yg=n(y,"LI",{});var dwe=s(yg);Sae=n(dwe,"STRONG",{});var KYr=s(Sae);Neo=r(KYr,"wav2vec2-conformer"),KYr.forEach(t),qeo=r(dwe," \u2014 "),qR=n(dwe,"A",{href:!0});var ZYr=s(qR);jeo=r(ZYr,"Wav2Vec2ConformerConfig"),ZYr.forEach(t),Deo=r(dwe," (Wav2Vec2-Conformer model)"),dwe.forEach(t),Geo=i(y),Lg=n(y,"LI",{});var cwe=s(Lg);Rae=n(cwe,"STRONG",{});var eKr=s(Rae);Oeo=r(eKr,"wavlm"),eKr.forEach(t),Veo=r(cwe," \u2014 "),jR=n(cwe,"A",{href:!0});var oKr=s(jR);Xeo=r(oKr,"WavLMConfig"),oKr.forEach(t),zeo=r(cwe," (WavLM model)"),cwe.forEach(t),Weo=i(y),xg=n(y,"LI",{});var fwe=s(xg);Pae=n(fwe,"STRONG",{});var rKr=s(Pae);Qeo=r(rKr,"xglm"),rKr.forEach(t),Heo=r(fwe," \u2014 "),DR=n(fwe,"A",{href:!0});var tKr=s(DR);Ueo=r(tKr,"XGLMConfig"),tKr.forEach(t),Jeo=r(fwe," (XGLM model)"),fwe.forEach(t),Yeo=i(y),$g=n(y,"LI",{});var mwe=s($g);Bae=n(mwe,"STRONG",{});var aKr=s(Bae);Keo=r(aKr,"xlm"),aKr.forEach(t),Zeo=r(mwe," \u2014 "),GR=n(mwe,"A",{href:!0});var nKr=s(GR);eoo=r(nKr,"XLMConfig"),nKr.forEach(t),ooo=r(mwe," (XLM model)"),mwe.forEach(t),roo=i(y),kg=n(y,"LI",{});var gwe=s(kg);Iae=n(gwe,"STRONG",{});var sKr=s(Iae);too=r(sKr,"xlm-prophetnet"),sKr.forEach(t),aoo=r(gwe," \u2014 "),OR=n(gwe,"A",{href:!0});var lKr=s(OR);noo=r(lKr,"XLMProphetNetConfig"),lKr.forEach(t),soo=r(gwe," (XLM-ProphetNet model)"),gwe.forEach(t),loo=i(y),Sg=n(y,"LI",{});var hwe=s(Sg);Nae=n(hwe,"STRONG",{});var iKr=s(Nae);ioo=r(iKr,"xlm-roberta"),iKr.forEach(t),doo=r(hwe," \u2014 "),VR=n(hwe,"A",{href:!0});var dKr=s(VR);coo=r(dKr,"XLMRobertaConfig"),dKr.forEach(t),foo=r(hwe," (XLM-RoBERTa model)"),hwe.forEach(t),moo=i(y),Rg=n(y,"LI",{});var pwe=s(Rg);qae=n(pwe,"STRONG",{});var cKr=s(qae);goo=r(cKr,"xlm-roberta-xl"),cKr.forEach(t),hoo=r(pwe," \u2014 "),XR=n(pwe,"A",{href:!0});var fKr=s(XR);poo=r(fKr,"XLMRobertaXLConfig"),fKr.forEach(t),uoo=r(pwe," (XLM-RoBERTa-XL model)"),pwe.forEach(t),_oo=i(y),Pg=n(y,"LI",{});var uwe=s(Pg);jae=n(uwe,"STRONG",{});var mKr=s(jae);boo=r(mKr,"xlnet"),mKr.forEach(t),voo=r(uwe," \u2014 "),zR=n(uwe,"A",{href:!0});var gKr=s(zR);Foo=r(gKr,"XLNetConfig"),gKr.forEach(t),Too=r(uwe," (XLNet model)"),uwe.forEach(t),Moo=i(y),Bg=n(y,"LI",{});var _we=s(Bg);Dae=n(_we,"STRONG",{});var hKr=s(Dae);Eoo=r(hKr,"yolos"),hKr.forEach(t),Coo=r(_we," \u2014 "),WR=n(_we,"A",{href:!0});var pKr=s(WR);woo=r(pKr,"YolosConfig"),pKr.forEach(t),Aoo=r(_we," (YOLOS model)"),_we.forEach(t),yoo=i(y),Ig=n(y,"LI",{});var bwe=s(Ig);Gae=n(bwe,"STRONG",{});var uKr=s(Gae);Loo=r(uKr,"yoso"),uKr.forEach(t),xoo=r(bwe," \u2014 "),QR=n(bwe,"A",{href:!0});var _Kr=s(QR);$oo=r(_Kr,"YosoConfig"),_Kr.forEach(t),koo=r(bwe," (YOSO model)"),bwe.forEach(t),y.forEach(t),Soo=i(tt),T(Ng.$$.fragment,tt),tt.forEach(t),Roo=i(rt),qg=n(rt,"DIV",{class:!0});var xOe=s(qg);T(vA.$$.fragment,xOe),Poo=i(xOe),Oae=n(xOe,"P",{});var bKr=s(Oae);Boo=r(bKr,"Register a new configuration for this class."),bKr.forEach(t),xOe.forEach(t),rt.forEach(t),$De=i(f),xi=n(f,"H2",{class:!0});var $Oe=s(xi);jg=n($Oe,"A",{id:!0,class:!0,href:!0});var vKr=s(jg);Vae=n(vKr,"SPAN",{});var FKr=s(Vae);T(FA.$$.fragment,FKr),FKr.forEach(t),vKr.forEach(t),Ioo=i($Oe),Xae=n($Oe,"SPAN",{});var TKr=s(Xae);Noo=r(TKr,"AutoTokenizer"),TKr.forEach(t),$Oe.forEach(t),kDe=i(f),Ao=n(f,"DIV",{class:!0});var Xs=s(Ao);T(TA.$$.fragment,Xs),qoo=i(Xs),MA=n(Xs,"P",{});var kOe=s(MA);joo=r(kOe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),HR=n(kOe,"A",{href:!0});var MKr=s(HR);Doo=r(MKr,"AutoTokenizer.from_pretrained()"),MKr.forEach(t),Goo=r(kOe," class method."),kOe.forEach(t),Ooo=i(Xs),EA=n(Xs,"P",{});var SOe=s(EA);Voo=r(SOe,"This class cannot be instantiated directly using "),zae=n(SOe,"CODE",{});var EKr=s(zae);Xoo=r(EKr,"__init__()"),EKr.forEach(t),zoo=r(SOe," (throws an error)."),SOe.forEach(t),Woo=i(Xs),Ar=n(Xs,"DIV",{class:!0});var zs=s(Ar);T(CA.$$.fragment,zs),Qoo=i(zs),Wae=n(zs,"P",{});var CKr=s(Wae);Hoo=r(CKr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),CKr.forEach(t),Uoo=i(zs),$a=n(zs,"P",{});var m0=s($a);Joo=r(m0,"The tokenizer class to instantiate is selected based on the "),Qae=n(m0,"CODE",{});var wKr=s(Qae);Yoo=r(wKr,"model_type"),wKr.forEach(t),Koo=r(m0,` property of the config object (either
passed as an argument or loaded from `),Hae=n(m0,"CODE",{});var AKr=s(Hae);Zoo=r(AKr,"pretrained_model_name_or_path"),AKr.forEach(t),ero=r(m0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uae=n(m0,"CODE",{});var yKr=s(Uae);oro=r(yKr,"pretrained_model_name_or_path"),yKr.forEach(t),rro=r(m0,":"),m0.forEach(t),tro=i(zs),k=n(zs,"UL",{});var S=s(k);Nn=n(S,"LI",{});var $$=s(Nn);Jae=n($$,"STRONG",{});var LKr=s(Jae);aro=r(LKr,"albert"),LKr.forEach(t),nro=r($$," \u2014 "),UR=n($$,"A",{href:!0});var xKr=s(UR);sro=r(xKr,"AlbertTokenizer"),xKr.forEach(t),lro=r($$," or "),JR=n($$,"A",{href:!0});var $Kr=s(JR);iro=r($Kr,"AlbertTokenizerFast"),$Kr.forEach(t),dro=r($$," (ALBERT model)"),$$.forEach(t),cro=i(S),qn=n(S,"LI",{});var k$=s(qn);Yae=n(k$,"STRONG",{});var kKr=s(Yae);fro=r(kKr,"bart"),kKr.forEach(t),mro=r(k$," \u2014 "),YR=n(k$,"A",{href:!0});var SKr=s(YR);gro=r(SKr,"BartTokenizer"),SKr.forEach(t),hro=r(k$," or "),KR=n(k$,"A",{href:!0});var RKr=s(KR);pro=r(RKr,"BartTokenizerFast"),RKr.forEach(t),uro=r(k$," (BART model)"),k$.forEach(t),_ro=i(S),jn=n(S,"LI",{});var S$=s(jn);Kae=n(S$,"STRONG",{});var PKr=s(Kae);bro=r(PKr,"barthez"),PKr.forEach(t),vro=r(S$," \u2014 "),ZR=n(S$,"A",{href:!0});var BKr=s(ZR);Fro=r(BKr,"BarthezTokenizer"),BKr.forEach(t),Tro=r(S$," or "),eP=n(S$,"A",{href:!0});var IKr=s(eP);Mro=r(IKr,"BarthezTokenizerFast"),IKr.forEach(t),Ero=r(S$," (BARThez model)"),S$.forEach(t),Cro=i(S),Dg=n(S,"LI",{});var vwe=s(Dg);Zae=n(vwe,"STRONG",{});var NKr=s(Zae);wro=r(NKr,"bartpho"),NKr.forEach(t),Aro=r(vwe," \u2014 "),oP=n(vwe,"A",{href:!0});var qKr=s(oP);yro=r(qKr,"BartphoTokenizer"),qKr.forEach(t),Lro=r(vwe," (BARTpho model)"),vwe.forEach(t),xro=i(S),Dn=n(S,"LI",{});var R$=s(Dn);ene=n(R$,"STRONG",{});var jKr=s(ene);$ro=r(jKr,"bert"),jKr.forEach(t),kro=r(R$," \u2014 "),rP=n(R$,"A",{href:!0});var DKr=s(rP);Sro=r(DKr,"BertTokenizer"),DKr.forEach(t),Rro=r(R$," or "),tP=n(R$,"A",{href:!0});var GKr=s(tP);Pro=r(GKr,"BertTokenizerFast"),GKr.forEach(t),Bro=r(R$," (BERT model)"),R$.forEach(t),Iro=i(S),Gg=n(S,"LI",{});var Fwe=s(Gg);one=n(Fwe,"STRONG",{});var OKr=s(one);Nro=r(OKr,"bert-generation"),OKr.forEach(t),qro=r(Fwe," \u2014 "),aP=n(Fwe,"A",{href:!0});var VKr=s(aP);jro=r(VKr,"BertGenerationTokenizer"),VKr.forEach(t),Dro=r(Fwe," (Bert Generation model)"),Fwe.forEach(t),Gro=i(S),Og=n(S,"LI",{});var Twe=s(Og);rne=n(Twe,"STRONG",{});var XKr=s(rne);Oro=r(XKr,"bert-japanese"),XKr.forEach(t),Vro=r(Twe," \u2014 "),nP=n(Twe,"A",{href:!0});var zKr=s(nP);Xro=r(zKr,"BertJapaneseTokenizer"),zKr.forEach(t),zro=r(Twe," (BertJapanese model)"),Twe.forEach(t),Wro=i(S),Vg=n(S,"LI",{});var Mwe=s(Vg);tne=n(Mwe,"STRONG",{});var WKr=s(tne);Qro=r(WKr,"bertweet"),WKr.forEach(t),Hro=r(Mwe," \u2014 "),sP=n(Mwe,"A",{href:!0});var QKr=s(sP);Uro=r(QKr,"BertweetTokenizer"),QKr.forEach(t),Jro=r(Mwe," (BERTweet model)"),Mwe.forEach(t),Yro=i(S),Gn=n(S,"LI",{});var P$=s(Gn);ane=n(P$,"STRONG",{});var HKr=s(ane);Kro=r(HKr,"big_bird"),HKr.forEach(t),Zro=r(P$," \u2014 "),lP=n(P$,"A",{href:!0});var UKr=s(lP);eto=r(UKr,"BigBirdTokenizer"),UKr.forEach(t),oto=r(P$," or "),iP=n(P$,"A",{href:!0});var JKr=s(iP);rto=r(JKr,"BigBirdTokenizerFast"),JKr.forEach(t),tto=r(P$," (BigBird model)"),P$.forEach(t),ato=i(S),On=n(S,"LI",{});var B$=s(On);nne=n(B$,"STRONG",{});var YKr=s(nne);nto=r(YKr,"bigbird_pegasus"),YKr.forEach(t),sto=r(B$," \u2014 "),dP=n(B$,"A",{href:!0});var KKr=s(dP);lto=r(KKr,"PegasusTokenizer"),KKr.forEach(t),ito=r(B$," or "),cP=n(B$,"A",{href:!0});var ZKr=s(cP);dto=r(ZKr,"PegasusTokenizerFast"),ZKr.forEach(t),cto=r(B$," (BigBird-Pegasus model)"),B$.forEach(t),fto=i(S),Vn=n(S,"LI",{});var I$=s(Vn);sne=n(I$,"STRONG",{});var eZr=s(sne);mto=r(eZr,"blenderbot"),eZr.forEach(t),gto=r(I$," \u2014 "),fP=n(I$,"A",{href:!0});var oZr=s(fP);hto=r(oZr,"BlenderbotTokenizer"),oZr.forEach(t),pto=r(I$," or "),mP=n(I$,"A",{href:!0});var rZr=s(mP);uto=r(rZr,"BlenderbotTokenizerFast"),rZr.forEach(t),_to=r(I$," (Blenderbot model)"),I$.forEach(t),bto=i(S),Xg=n(S,"LI",{});var Ewe=s(Xg);lne=n(Ewe,"STRONG",{});var tZr=s(lne);vto=r(tZr,"blenderbot-small"),tZr.forEach(t),Fto=r(Ewe," \u2014 "),gP=n(Ewe,"A",{href:!0});var aZr=s(gP);Tto=r(aZr,"BlenderbotSmallTokenizer"),aZr.forEach(t),Mto=r(Ewe," (BlenderbotSmall model)"),Ewe.forEach(t),Eto=i(S),zg=n(S,"LI",{});var Cwe=s(zg);ine=n(Cwe,"STRONG",{});var nZr=s(ine);Cto=r(nZr,"bloom"),nZr.forEach(t),wto=r(Cwe," \u2014 "),hP=n(Cwe,"A",{href:!0});var sZr=s(hP);Ato=r(sZr,"BloomTokenizerFast"),sZr.forEach(t),yto=r(Cwe," (BLOOM model)"),Cwe.forEach(t),Lto=i(S),Wg=n(S,"LI",{});var wwe=s(Wg);dne=n(wwe,"STRONG",{});var lZr=s(dne);xto=r(lZr,"byt5"),lZr.forEach(t),$to=r(wwe," \u2014 "),pP=n(wwe,"A",{href:!0});var iZr=s(pP);kto=r(iZr,"ByT5Tokenizer"),iZr.forEach(t),Sto=r(wwe," (ByT5 model)"),wwe.forEach(t),Rto=i(S),Xn=n(S,"LI",{});var N$=s(Xn);cne=n(N$,"STRONG",{});var dZr=s(cne);Pto=r(dZr,"camembert"),dZr.forEach(t),Bto=r(N$," \u2014 "),uP=n(N$,"A",{href:!0});var cZr=s(uP);Ito=r(cZr,"CamembertTokenizer"),cZr.forEach(t),Nto=r(N$," or "),_P=n(N$,"A",{href:!0});var fZr=s(_P);qto=r(fZr,"CamembertTokenizerFast"),fZr.forEach(t),jto=r(N$," (CamemBERT model)"),N$.forEach(t),Dto=i(S),Qg=n(S,"LI",{});var Awe=s(Qg);fne=n(Awe,"STRONG",{});var mZr=s(fne);Gto=r(mZr,"canine"),mZr.forEach(t),Oto=r(Awe," \u2014 "),bP=n(Awe,"A",{href:!0});var gZr=s(bP);Vto=r(gZr,"CanineTokenizer"),gZr.forEach(t),Xto=r(Awe," (CANINE model)"),Awe.forEach(t),zto=i(S),zn=n(S,"LI",{});var q$=s(zn);mne=n(q$,"STRONG",{});var hZr=s(mne);Wto=r(hZr,"clip"),hZr.forEach(t),Qto=r(q$," \u2014 "),vP=n(q$,"A",{href:!0});var pZr=s(vP);Hto=r(pZr,"CLIPTokenizer"),pZr.forEach(t),Uto=r(q$," or "),FP=n(q$,"A",{href:!0});var uZr=s(FP);Jto=r(uZr,"CLIPTokenizerFast"),uZr.forEach(t),Yto=r(q$," (CLIP model)"),q$.forEach(t),Kto=i(S),Wn=n(S,"LI",{});var j$=s(Wn);gne=n(j$,"STRONG",{});var _Zr=s(gne);Zto=r(_Zr,"convbert"),_Zr.forEach(t),eao=r(j$," \u2014 "),TP=n(j$,"A",{href:!0});var bZr=s(TP);oao=r(bZr,"ConvBertTokenizer"),bZr.forEach(t),rao=r(j$," or "),MP=n(j$,"A",{href:!0});var vZr=s(MP);tao=r(vZr,"ConvBertTokenizerFast"),vZr.forEach(t),aao=r(j$," (ConvBERT model)"),j$.forEach(t),nao=i(S),Qn=n(S,"LI",{});var D$=s(Qn);hne=n(D$,"STRONG",{});var FZr=s(hne);sao=r(FZr,"cpm"),FZr.forEach(t),lao=r(D$," \u2014 "),EP=n(D$,"A",{href:!0});var TZr=s(EP);iao=r(TZr,"CpmTokenizer"),TZr.forEach(t),dao=r(D$," or "),CP=n(D$,"A",{href:!0});var MZr=s(CP);cao=r(MZr,"CpmTokenizerFast"),MZr.forEach(t),fao=r(D$," (CPM model)"),D$.forEach(t),mao=i(S),Hg=n(S,"LI",{});var ywe=s(Hg);pne=n(ywe,"STRONG",{});var EZr=s(pne);gao=r(EZr,"ctrl"),EZr.forEach(t),hao=r(ywe," \u2014 "),wP=n(ywe,"A",{href:!0});var CZr=s(wP);pao=r(CZr,"CTRLTokenizer"),CZr.forEach(t),uao=r(ywe," (CTRL model)"),ywe.forEach(t),_ao=i(S),Hn=n(S,"LI",{});var G$=s(Hn);une=n(G$,"STRONG",{});var wZr=s(une);bao=r(wZr,"data2vec-text"),wZr.forEach(t),vao=r(G$," \u2014 "),AP=n(G$,"A",{href:!0});var AZr=s(AP);Fao=r(AZr,"RobertaTokenizer"),AZr.forEach(t),Tao=r(G$," or "),yP=n(G$,"A",{href:!0});var yZr=s(yP);Mao=r(yZr,"RobertaTokenizerFast"),yZr.forEach(t),Eao=r(G$," (Data2VecText model)"),G$.forEach(t),Cao=i(S),Un=n(S,"LI",{});var O$=s(Un);_ne=n(O$,"STRONG",{});var LZr=s(_ne);wao=r(LZr,"deberta"),LZr.forEach(t),Aao=r(O$," \u2014 "),LP=n(O$,"A",{href:!0});var xZr=s(LP);yao=r(xZr,"DebertaTokenizer"),xZr.forEach(t),Lao=r(O$," or "),xP=n(O$,"A",{href:!0});var $Zr=s(xP);xao=r($Zr,"DebertaTokenizerFast"),$Zr.forEach(t),$ao=r(O$," (DeBERTa model)"),O$.forEach(t),kao=i(S),Jn=n(S,"LI",{});var V$=s(Jn);bne=n(V$,"STRONG",{});var kZr=s(bne);Sao=r(kZr,"deberta-v2"),kZr.forEach(t),Rao=r(V$," \u2014 "),$P=n(V$,"A",{href:!0});var SZr=s($P);Pao=r(SZr,"DebertaV2Tokenizer"),SZr.forEach(t),Bao=r(V$," or "),kP=n(V$,"A",{href:!0});var RZr=s(kP);Iao=r(RZr,"DebertaV2TokenizerFast"),RZr.forEach(t),Nao=r(V$," (DeBERTa-v2 model)"),V$.forEach(t),qao=i(S),Yn=n(S,"LI",{});var X$=s(Yn);vne=n(X$,"STRONG",{});var PZr=s(vne);jao=r(PZr,"distilbert"),PZr.forEach(t),Dao=r(X$," \u2014 "),SP=n(X$,"A",{href:!0});var BZr=s(SP);Gao=r(BZr,"DistilBertTokenizer"),BZr.forEach(t),Oao=r(X$," or "),RP=n(X$,"A",{href:!0});var IZr=s(RP);Vao=r(IZr,"DistilBertTokenizerFast"),IZr.forEach(t),Xao=r(X$," (DistilBERT model)"),X$.forEach(t),zao=i(S),Kn=n(S,"LI",{});var z$=s(Kn);Fne=n(z$,"STRONG",{});var NZr=s(Fne);Wao=r(NZr,"dpr"),NZr.forEach(t),Qao=r(z$," \u2014 "),PP=n(z$,"A",{href:!0});var qZr=s(PP);Hao=r(qZr,"DPRQuestionEncoderTokenizer"),qZr.forEach(t),Uao=r(z$," or "),BP=n(z$,"A",{href:!0});var jZr=s(BP);Jao=r(jZr,"DPRQuestionEncoderTokenizerFast"),jZr.forEach(t),Yao=r(z$," (DPR model)"),z$.forEach(t),Kao=i(S),Zn=n(S,"LI",{});var W$=s(Zn);Tne=n(W$,"STRONG",{});var DZr=s(Tne);Zao=r(DZr,"electra"),DZr.forEach(t),eno=r(W$," \u2014 "),IP=n(W$,"A",{href:!0});var GZr=s(IP);ono=r(GZr,"ElectraTokenizer"),GZr.forEach(t),rno=r(W$," or "),NP=n(W$,"A",{href:!0});var OZr=s(NP);tno=r(OZr,"ElectraTokenizerFast"),OZr.forEach(t),ano=r(W$," (ELECTRA model)"),W$.forEach(t),nno=i(S),Ug=n(S,"LI",{});var Lwe=s(Ug);Mne=n(Lwe,"STRONG",{});var VZr=s(Mne);sno=r(VZr,"flaubert"),VZr.forEach(t),lno=r(Lwe," \u2014 "),qP=n(Lwe,"A",{href:!0});var XZr=s(qP);ino=r(XZr,"FlaubertTokenizer"),XZr.forEach(t),dno=r(Lwe," (FlauBERT model)"),Lwe.forEach(t),cno=i(S),es=n(S,"LI",{});var Q$=s(es);Ene=n(Q$,"STRONG",{});var zZr=s(Ene);fno=r(zZr,"fnet"),zZr.forEach(t),mno=r(Q$," \u2014 "),jP=n(Q$,"A",{href:!0});var WZr=s(jP);gno=r(WZr,"FNetTokenizer"),WZr.forEach(t),hno=r(Q$," or "),DP=n(Q$,"A",{href:!0});var QZr=s(DP);pno=r(QZr,"FNetTokenizerFast"),QZr.forEach(t),uno=r(Q$," (FNet model)"),Q$.forEach(t),_no=i(S),Jg=n(S,"LI",{});var xwe=s(Jg);Cne=n(xwe,"STRONG",{});var HZr=s(Cne);bno=r(HZr,"fsmt"),HZr.forEach(t),vno=r(xwe," \u2014 "),GP=n(xwe,"A",{href:!0});var UZr=s(GP);Fno=r(UZr,"FSMTTokenizer"),UZr.forEach(t),Tno=r(xwe," (FairSeq Machine-Translation model)"),xwe.forEach(t),Mno=i(S),os=n(S,"LI",{});var H$=s(os);wne=n(H$,"STRONG",{});var JZr=s(wne);Eno=r(JZr,"funnel"),JZr.forEach(t),Cno=r(H$," \u2014 "),OP=n(H$,"A",{href:!0});var YZr=s(OP);wno=r(YZr,"FunnelTokenizer"),YZr.forEach(t),Ano=r(H$," or "),VP=n(H$,"A",{href:!0});var KZr=s(VP);yno=r(KZr,"FunnelTokenizerFast"),KZr.forEach(t),Lno=r(H$," (Funnel Transformer model)"),H$.forEach(t),xno=i(S),rs=n(S,"LI",{});var U$=s(rs);Ane=n(U$,"STRONG",{});var ZZr=s(Ane);$no=r(ZZr,"gpt2"),ZZr.forEach(t),kno=r(U$," \u2014 "),XP=n(U$,"A",{href:!0});var eet=s(XP);Sno=r(eet,"GPT2Tokenizer"),eet.forEach(t),Rno=r(U$," or "),zP=n(U$,"A",{href:!0});var oet=s(zP);Pno=r(oet,"GPT2TokenizerFast"),oet.forEach(t),Bno=r(U$," (OpenAI GPT-2 model)"),U$.forEach(t),Ino=i(S),ts=n(S,"LI",{});var J$=s(ts);yne=n(J$,"STRONG",{});var ret=s(yne);Nno=r(ret,"gpt_neo"),ret.forEach(t),qno=r(J$," \u2014 "),WP=n(J$,"A",{href:!0});var tet=s(WP);jno=r(tet,"GPT2Tokenizer"),tet.forEach(t),Dno=r(J$," or "),QP=n(J$,"A",{href:!0});var aet=s(QP);Gno=r(aet,"GPT2TokenizerFast"),aet.forEach(t),Ono=r(J$," (GPT Neo model)"),J$.forEach(t),Vno=i(S),Yg=n(S,"LI",{});var $we=s(Yg);Lne=n($we,"STRONG",{});var net=s(Lne);Xno=r(net,"gpt_neox"),net.forEach(t),zno=r($we," \u2014 "),HP=n($we,"A",{href:!0});var set=s(HP);Wno=r(set,"GPTNeoXTokenizerFast"),set.forEach(t),Qno=r($we," (GPT NeoX model)"),$we.forEach(t),Hno=i(S),as=n(S,"LI",{});var Y$=s(as);xne=n(Y$,"STRONG",{});var iet=s(xne);Uno=r(iet,"gptj"),iet.forEach(t),Jno=r(Y$," \u2014 "),UP=n(Y$,"A",{href:!0});var det=s(UP);Yno=r(det,"GPT2Tokenizer"),det.forEach(t),Kno=r(Y$," or "),JP=n(Y$,"A",{href:!0});var cet=s(JP);Zno=r(cet,"GPT2TokenizerFast"),cet.forEach(t),eso=r(Y$," (GPT-J model)"),Y$.forEach(t),oso=i(S),ns=n(S,"LI",{});var K$=s(ns);$ne=n(K$,"STRONG",{});var fet=s($ne);rso=r(fet,"herbert"),fet.forEach(t),tso=r(K$," \u2014 "),YP=n(K$,"A",{href:!0});var met=s(YP);aso=r(met,"HerbertTokenizer"),met.forEach(t),nso=r(K$," or "),KP=n(K$,"A",{href:!0});var get=s(KP);sso=r(get,"HerbertTokenizerFast"),get.forEach(t),lso=r(K$," (HerBERT model)"),K$.forEach(t),iso=i(S),Kg=n(S,"LI",{});var kwe=s(Kg);kne=n(kwe,"STRONG",{});var het=s(kne);dso=r(het,"hubert"),het.forEach(t),cso=r(kwe," \u2014 "),ZP=n(kwe,"A",{href:!0});var pet=s(ZP);fso=r(pet,"Wav2Vec2CTCTokenizer"),pet.forEach(t),mso=r(kwe," (Hubert model)"),kwe.forEach(t),gso=i(S),ss=n(S,"LI",{});var Z$=s(ss);Sne=n(Z$,"STRONG",{});var uet=s(Sne);hso=r(uet,"ibert"),uet.forEach(t),pso=r(Z$," \u2014 "),eB=n(Z$,"A",{href:!0});var _et=s(eB);uso=r(_et,"RobertaTokenizer"),_et.forEach(t),_so=r(Z$," or "),oB=n(Z$,"A",{href:!0});var bet=s(oB);bso=r(bet,"RobertaTokenizerFast"),bet.forEach(t),vso=r(Z$," (I-BERT model)"),Z$.forEach(t),Fso=i(S),ls=n(S,"LI",{});var ek=s(ls);Rne=n(ek,"STRONG",{});var vet=s(Rne);Tso=r(vet,"layoutlm"),vet.forEach(t),Mso=r(ek," \u2014 "),rB=n(ek,"A",{href:!0});var Fet=s(rB);Eso=r(Fet,"LayoutLMTokenizer"),Fet.forEach(t),Cso=r(ek," or "),tB=n(ek,"A",{href:!0});var Tet=s(tB);wso=r(Tet,"LayoutLMTokenizerFast"),Tet.forEach(t),Aso=r(ek," (LayoutLM model)"),ek.forEach(t),yso=i(S),is=n(S,"LI",{});var ok=s(is);Pne=n(ok,"STRONG",{});var Met=s(Pne);Lso=r(Met,"layoutlmv2"),Met.forEach(t),xso=r(ok," \u2014 "),aB=n(ok,"A",{href:!0});var Eet=s(aB);$so=r(Eet,"LayoutLMv2Tokenizer"),Eet.forEach(t),kso=r(ok," or "),nB=n(ok,"A",{href:!0});var Cet=s(nB);Sso=r(Cet,"LayoutLMv2TokenizerFast"),Cet.forEach(t),Rso=r(ok," (LayoutLMv2 model)"),ok.forEach(t),Pso=i(S),ds=n(S,"LI",{});var rk=s(ds);Bne=n(rk,"STRONG",{});var wet=s(Bne);Bso=r(wet,"layoutlmv3"),wet.forEach(t),Iso=r(rk," \u2014 "),sB=n(rk,"A",{href:!0});var Aet=s(sB);Nso=r(Aet,"LayoutLMv3Tokenizer"),Aet.forEach(t),qso=r(rk," or "),lB=n(rk,"A",{href:!0});var yet=s(lB);jso=r(yet,"LayoutLMv3TokenizerFast"),yet.forEach(t),Dso=r(rk," (LayoutLMv3 model)"),rk.forEach(t),Gso=i(S),cs=n(S,"LI",{});var tk=s(cs);Ine=n(tk,"STRONG",{});var Let=s(Ine);Oso=r(Let,"layoutxlm"),Let.forEach(t),Vso=r(tk," \u2014 "),iB=n(tk,"A",{href:!0});var xet=s(iB);Xso=r(xet,"LayoutXLMTokenizer"),xet.forEach(t),zso=r(tk," or "),dB=n(tk,"A",{href:!0});var $et=s(dB);Wso=r($et,"LayoutXLMTokenizerFast"),$et.forEach(t),Qso=r(tk," (LayoutXLM model)"),tk.forEach(t),Hso=i(S),fs=n(S,"LI",{});var ak=s(fs);Nne=n(ak,"STRONG",{});var ket=s(Nne);Uso=r(ket,"led"),ket.forEach(t),Jso=r(ak," \u2014 "),cB=n(ak,"A",{href:!0});var Set=s(cB);Yso=r(Set,"LEDTokenizer"),Set.forEach(t),Kso=r(ak," or "),fB=n(ak,"A",{href:!0});var Ret=s(fB);Zso=r(Ret,"LEDTokenizerFast"),Ret.forEach(t),elo=r(ak," (LED model)"),ak.forEach(t),olo=i(S),ms=n(S,"LI",{});var nk=s(ms);qne=n(nk,"STRONG",{});var Pet=s(qne);rlo=r(Pet,"longformer"),Pet.forEach(t),tlo=r(nk," \u2014 "),mB=n(nk,"A",{href:!0});var Bet=s(mB);alo=r(Bet,"LongformerTokenizer"),Bet.forEach(t),nlo=r(nk," or "),gB=n(nk,"A",{href:!0});var Iet=s(gB);slo=r(Iet,"LongformerTokenizerFast"),Iet.forEach(t),llo=r(nk," (Longformer model)"),nk.forEach(t),ilo=i(S),Zg=n(S,"LI",{});var Swe=s(Zg);jne=n(Swe,"STRONG",{});var Net=s(jne);dlo=r(Net,"luke"),Net.forEach(t),clo=r(Swe," \u2014 "),hB=n(Swe,"A",{href:!0});var qet=s(hB);flo=r(qet,"LukeTokenizer"),qet.forEach(t),mlo=r(Swe," (LUKE model)"),Swe.forEach(t),glo=i(S),gs=n(S,"LI",{});var sk=s(gs);Dne=n(sk,"STRONG",{});var jet=s(Dne);hlo=r(jet,"lxmert"),jet.forEach(t),plo=r(sk," \u2014 "),pB=n(sk,"A",{href:!0});var Det=s(pB);ulo=r(Det,"LxmertTokenizer"),Det.forEach(t),_lo=r(sk," or "),uB=n(sk,"A",{href:!0});var Get=s(uB);blo=r(Get,"LxmertTokenizerFast"),Get.forEach(t),vlo=r(sk," (LXMERT model)"),sk.forEach(t),Flo=i(S),eh=n(S,"LI",{});var Rwe=s(eh);Gne=n(Rwe,"STRONG",{});var Oet=s(Gne);Tlo=r(Oet,"m2m_100"),Oet.forEach(t),Mlo=r(Rwe," \u2014 "),_B=n(Rwe,"A",{href:!0});var Vet=s(_B);Elo=r(Vet,"M2M100Tokenizer"),Vet.forEach(t),Clo=r(Rwe," (M2M100 model)"),Rwe.forEach(t),wlo=i(S),oh=n(S,"LI",{});var Pwe=s(oh);One=n(Pwe,"STRONG",{});var Xet=s(One);Alo=r(Xet,"marian"),Xet.forEach(t),ylo=r(Pwe," \u2014 "),bB=n(Pwe,"A",{href:!0});var zet=s(bB);Llo=r(zet,"MarianTokenizer"),zet.forEach(t),xlo=r(Pwe," (Marian model)"),Pwe.forEach(t),$lo=i(S),hs=n(S,"LI",{});var lk=s(hs);Vne=n(lk,"STRONG",{});var Wet=s(Vne);klo=r(Wet,"mbart"),Wet.forEach(t),Slo=r(lk," \u2014 "),vB=n(lk,"A",{href:!0});var Qet=s(vB);Rlo=r(Qet,"MBartTokenizer"),Qet.forEach(t),Plo=r(lk," or "),FB=n(lk,"A",{href:!0});var Het=s(FB);Blo=r(Het,"MBartTokenizerFast"),Het.forEach(t),Ilo=r(lk," (mBART model)"),lk.forEach(t),Nlo=i(S),ps=n(S,"LI",{});var ik=s(ps);Xne=n(ik,"STRONG",{});var Uet=s(Xne);qlo=r(Uet,"mbart50"),Uet.forEach(t),jlo=r(ik," \u2014 "),TB=n(ik,"A",{href:!0});var Jet=s(TB);Dlo=r(Jet,"MBart50Tokenizer"),Jet.forEach(t),Glo=r(ik," or "),MB=n(ik,"A",{href:!0});var Yet=s(MB);Olo=r(Yet,"MBart50TokenizerFast"),Yet.forEach(t),Vlo=r(ik," (mBART-50 model)"),ik.forEach(t),Xlo=i(S),us=n(S,"LI",{});var dk=s(us);zne=n(dk,"STRONG",{});var Ket=s(zne);zlo=r(Ket,"megatron-bert"),Ket.forEach(t),Wlo=r(dk," \u2014 "),EB=n(dk,"A",{href:!0});var Zet=s(EB);Qlo=r(Zet,"BertTokenizer"),Zet.forEach(t),Hlo=r(dk," or "),CB=n(dk,"A",{href:!0});var eot=s(CB);Ulo=r(eot,"BertTokenizerFast"),eot.forEach(t),Jlo=r(dk," (Megatron-BERT model)"),dk.forEach(t),Ylo=i(S),rh=n(S,"LI",{});var Bwe=s(rh);Wne=n(Bwe,"STRONG",{});var oot=s(Wne);Klo=r(oot,"mluke"),oot.forEach(t),Zlo=r(Bwe," \u2014 "),wB=n(Bwe,"A",{href:!0});var rot=s(wB);eio=r(rot,"MLukeTokenizer"),rot.forEach(t),oio=r(Bwe," (mLUKE model)"),Bwe.forEach(t),rio=i(S),_s=n(S,"LI",{});var ck=s(_s);Qne=n(ck,"STRONG",{});var tot=s(Qne);tio=r(tot,"mobilebert"),tot.forEach(t),aio=r(ck," \u2014 "),AB=n(ck,"A",{href:!0});var aot=s(AB);nio=r(aot,"MobileBertTokenizer"),aot.forEach(t),sio=r(ck," or "),yB=n(ck,"A",{href:!0});var not=s(yB);lio=r(not,"MobileBertTokenizerFast"),not.forEach(t),iio=r(ck," (MobileBERT model)"),ck.forEach(t),dio=i(S),bs=n(S,"LI",{});var fk=s(bs);Hne=n(fk,"STRONG",{});var sot=s(Hne);cio=r(sot,"mpnet"),sot.forEach(t),fio=r(fk," \u2014 "),LB=n(fk,"A",{href:!0});var lot=s(LB);mio=r(lot,"MPNetTokenizer"),lot.forEach(t),gio=r(fk," or "),xB=n(fk,"A",{href:!0});var iot=s(xB);hio=r(iot,"MPNetTokenizerFast"),iot.forEach(t),pio=r(fk," (MPNet model)"),fk.forEach(t),uio=i(S),vs=n(S,"LI",{});var mk=s(vs);Une=n(mk,"STRONG",{});var dot=s(Une);_io=r(dot,"mt5"),dot.forEach(t),bio=r(mk," \u2014 "),$B=n(mk,"A",{href:!0});var cot=s($B);vio=r(cot,"MT5Tokenizer"),cot.forEach(t),Fio=r(mk," or "),kB=n(mk,"A",{href:!0});var fot=s(kB);Tio=r(fot,"MT5TokenizerFast"),fot.forEach(t),Mio=r(mk," (MT5 model)"),mk.forEach(t),Eio=i(S),Fs=n(S,"LI",{});var gk=s(Fs);Jne=n(gk,"STRONG",{});var mot=s(Jne);Cio=r(mot,"nystromformer"),mot.forEach(t),wio=r(gk," \u2014 "),SB=n(gk,"A",{href:!0});var got=s(SB);Aio=r(got,"AlbertTokenizer"),got.forEach(t),yio=r(gk," or "),RB=n(gk,"A",{href:!0});var hot=s(RB);Lio=r(hot,"AlbertTokenizerFast"),hot.forEach(t),xio=r(gk," (Nystr\xF6mformer model)"),gk.forEach(t),$io=i(S),Ts=n(S,"LI",{});var hk=s(Ts);Yne=n(hk,"STRONG",{});var pot=s(Yne);kio=r(pot,"openai-gpt"),pot.forEach(t),Sio=r(hk," \u2014 "),PB=n(hk,"A",{href:!0});var uot=s(PB);Rio=r(uot,"OpenAIGPTTokenizer"),uot.forEach(t),Pio=r(hk," or "),BB=n(hk,"A",{href:!0});var _ot=s(BB);Bio=r(_ot,"OpenAIGPTTokenizerFast"),_ot.forEach(t),Iio=r(hk," (OpenAI GPT model)"),hk.forEach(t),Nio=i(S),th=n(S,"LI",{});var Iwe=s(th);Kne=n(Iwe,"STRONG",{});var bot=s(Kne);qio=r(bot,"opt"),bot.forEach(t),jio=r(Iwe," \u2014 "),IB=n(Iwe,"A",{href:!0});var vot=s(IB);Dio=r(vot,"GPT2Tokenizer"),vot.forEach(t),Gio=r(Iwe," (OPT model)"),Iwe.forEach(t),Oio=i(S),Ms=n(S,"LI",{});var pk=s(Ms);Zne=n(pk,"STRONG",{});var Fot=s(Zne);Vio=r(Fot,"pegasus"),Fot.forEach(t),Xio=r(pk," \u2014 "),NB=n(pk,"A",{href:!0});var Tot=s(NB);zio=r(Tot,"PegasusTokenizer"),Tot.forEach(t),Wio=r(pk," or "),qB=n(pk,"A",{href:!0});var Mot=s(qB);Qio=r(Mot,"PegasusTokenizerFast"),Mot.forEach(t),Hio=r(pk," (Pegasus model)"),pk.forEach(t),Uio=i(S),ah=n(S,"LI",{});var Nwe=s(ah);ese=n(Nwe,"STRONG",{});var Eot=s(ese);Jio=r(Eot,"perceiver"),Eot.forEach(t),Yio=r(Nwe," \u2014 "),jB=n(Nwe,"A",{href:!0});var Cot=s(jB);Kio=r(Cot,"PerceiverTokenizer"),Cot.forEach(t),Zio=r(Nwe," (Perceiver model)"),Nwe.forEach(t),edo=i(S),nh=n(S,"LI",{});var qwe=s(nh);ose=n(qwe,"STRONG",{});var wot=s(ose);odo=r(wot,"phobert"),wot.forEach(t),rdo=r(qwe," \u2014 "),DB=n(qwe,"A",{href:!0});var Aot=s(DB);tdo=r(Aot,"PhobertTokenizer"),Aot.forEach(t),ado=r(qwe," (PhoBERT model)"),qwe.forEach(t),ndo=i(S),sh=n(S,"LI",{});var jwe=s(sh);rse=n(jwe,"STRONG",{});var yot=s(rse);sdo=r(yot,"plbart"),yot.forEach(t),ldo=r(jwe," \u2014 "),GB=n(jwe,"A",{href:!0});var Lot=s(GB);ido=r(Lot,"PLBartTokenizer"),Lot.forEach(t),ddo=r(jwe," (PLBart model)"),jwe.forEach(t),cdo=i(S),lh=n(S,"LI",{});var Dwe=s(lh);tse=n(Dwe,"STRONG",{});var xot=s(tse);fdo=r(xot,"prophetnet"),xot.forEach(t),mdo=r(Dwe," \u2014 "),OB=n(Dwe,"A",{href:!0});var $ot=s(OB);gdo=r($ot,"ProphetNetTokenizer"),$ot.forEach(t),hdo=r(Dwe," (ProphetNet model)"),Dwe.forEach(t),pdo=i(S),Es=n(S,"LI",{});var uk=s(Es);ase=n(uk,"STRONG",{});var kot=s(ase);udo=r(kot,"qdqbert"),kot.forEach(t),_do=r(uk," \u2014 "),VB=n(uk,"A",{href:!0});var Sot=s(VB);bdo=r(Sot,"BertTokenizer"),Sot.forEach(t),vdo=r(uk," or "),XB=n(uk,"A",{href:!0});var Rot=s(XB);Fdo=r(Rot,"BertTokenizerFast"),Rot.forEach(t),Tdo=r(uk," (QDQBert model)"),uk.forEach(t),Mdo=i(S),ih=n(S,"LI",{});var Gwe=s(ih);nse=n(Gwe,"STRONG",{});var Pot=s(nse);Edo=r(Pot,"rag"),Pot.forEach(t),Cdo=r(Gwe," \u2014 "),zB=n(Gwe,"A",{href:!0});var Bot=s(zB);wdo=r(Bot,"RagTokenizer"),Bot.forEach(t),Ado=r(Gwe," (RAG model)"),Gwe.forEach(t),ydo=i(S),Cs=n(S,"LI",{});var _k=s(Cs);sse=n(_k,"STRONG",{});var Iot=s(sse);Ldo=r(Iot,"realm"),Iot.forEach(t),xdo=r(_k," \u2014 "),WB=n(_k,"A",{href:!0});var Not=s(WB);$do=r(Not,"RealmTokenizer"),Not.forEach(t),kdo=r(_k," or "),QB=n(_k,"A",{href:!0});var qot=s(QB);Sdo=r(qot,"RealmTokenizerFast"),qot.forEach(t),Rdo=r(_k," (REALM model)"),_k.forEach(t),Pdo=i(S),ws=n(S,"LI",{});var bk=s(ws);lse=n(bk,"STRONG",{});var jot=s(lse);Bdo=r(jot,"reformer"),jot.forEach(t),Ido=r(bk," \u2014 "),HB=n(bk,"A",{href:!0});var Dot=s(HB);Ndo=r(Dot,"ReformerTokenizer"),Dot.forEach(t),qdo=r(bk," or "),UB=n(bk,"A",{href:!0});var Got=s(UB);jdo=r(Got,"ReformerTokenizerFast"),Got.forEach(t),Ddo=r(bk," (Reformer model)"),bk.forEach(t),Gdo=i(S),As=n(S,"LI",{});var vk=s(As);ise=n(vk,"STRONG",{});var Oot=s(ise);Odo=r(Oot,"rembert"),Oot.forEach(t),Vdo=r(vk," \u2014 "),JB=n(vk,"A",{href:!0});var Vot=s(JB);Xdo=r(Vot,"RemBertTokenizer"),Vot.forEach(t),zdo=r(vk," or "),YB=n(vk,"A",{href:!0});var Xot=s(YB);Wdo=r(Xot,"RemBertTokenizerFast"),Xot.forEach(t),Qdo=r(vk," (RemBERT model)"),vk.forEach(t),Hdo=i(S),ys=n(S,"LI",{});var Fk=s(ys);dse=n(Fk,"STRONG",{});var zot=s(dse);Udo=r(zot,"retribert"),zot.forEach(t),Jdo=r(Fk," \u2014 "),KB=n(Fk,"A",{href:!0});var Wot=s(KB);Ydo=r(Wot,"RetriBertTokenizer"),Wot.forEach(t),Kdo=r(Fk," or "),ZB=n(Fk,"A",{href:!0});var Qot=s(ZB);Zdo=r(Qot,"RetriBertTokenizerFast"),Qot.forEach(t),eco=r(Fk," (RetriBERT model)"),Fk.forEach(t),oco=i(S),Ls=n(S,"LI",{});var Tk=s(Ls);cse=n(Tk,"STRONG",{});var Hot=s(cse);rco=r(Hot,"roberta"),Hot.forEach(t),tco=r(Tk," \u2014 "),eI=n(Tk,"A",{href:!0});var Uot=s(eI);aco=r(Uot,"RobertaTokenizer"),Uot.forEach(t),nco=r(Tk," or "),oI=n(Tk,"A",{href:!0});var Jot=s(oI);sco=r(Jot,"RobertaTokenizerFast"),Jot.forEach(t),lco=r(Tk," (RoBERTa model)"),Tk.forEach(t),ico=i(S),xs=n(S,"LI",{});var Mk=s(xs);fse=n(Mk,"STRONG",{});var Yot=s(fse);dco=r(Yot,"roformer"),Yot.forEach(t),cco=r(Mk," \u2014 "),rI=n(Mk,"A",{href:!0});var Kot=s(rI);fco=r(Kot,"RoFormerTokenizer"),Kot.forEach(t),mco=r(Mk," or "),tI=n(Mk,"A",{href:!0});var Zot=s(tI);gco=r(Zot,"RoFormerTokenizerFast"),Zot.forEach(t),hco=r(Mk," (RoFormer model)"),Mk.forEach(t),pco=i(S),dh=n(S,"LI",{});var Owe=s(dh);mse=n(Owe,"STRONG",{});var ert=s(mse);uco=r(ert,"speech_to_text"),ert.forEach(t),_co=r(Owe," \u2014 "),aI=n(Owe,"A",{href:!0});var ort=s(aI);bco=r(ort,"Speech2TextTokenizer"),ort.forEach(t),vco=r(Owe," (Speech2Text model)"),Owe.forEach(t),Fco=i(S),ch=n(S,"LI",{});var Vwe=s(ch);gse=n(Vwe,"STRONG",{});var rrt=s(gse);Tco=r(rrt,"speech_to_text_2"),rrt.forEach(t),Mco=r(Vwe," \u2014 "),nI=n(Vwe,"A",{href:!0});var trt=s(nI);Eco=r(trt,"Speech2Text2Tokenizer"),trt.forEach(t),Cco=r(Vwe," (Speech2Text2 model)"),Vwe.forEach(t),wco=i(S),$s=n(S,"LI",{});var Ek=s($s);hse=n(Ek,"STRONG",{});var art=s(hse);Aco=r(art,"splinter"),art.forEach(t),yco=r(Ek," \u2014 "),sI=n(Ek,"A",{href:!0});var nrt=s(sI);Lco=r(nrt,"SplinterTokenizer"),nrt.forEach(t),xco=r(Ek," or "),lI=n(Ek,"A",{href:!0});var srt=s(lI);$co=r(srt,"SplinterTokenizerFast"),srt.forEach(t),kco=r(Ek," (Splinter model)"),Ek.forEach(t),Sco=i(S),ks=n(S,"LI",{});var Ck=s(ks);pse=n(Ck,"STRONG",{});var lrt=s(pse);Rco=r(lrt,"squeezebert"),lrt.forEach(t),Pco=r(Ck," \u2014 "),iI=n(Ck,"A",{href:!0});var irt=s(iI);Bco=r(irt,"SqueezeBertTokenizer"),irt.forEach(t),Ico=r(Ck," or "),dI=n(Ck,"A",{href:!0});var drt=s(dI);Nco=r(drt,"SqueezeBertTokenizerFast"),drt.forEach(t),qco=r(Ck," (SqueezeBERT model)"),Ck.forEach(t),jco=i(S),Ss=n(S,"LI",{});var wk=s(Ss);use=n(wk,"STRONG",{});var crt=s(use);Dco=r(crt,"t5"),crt.forEach(t),Gco=r(wk," \u2014 "),cI=n(wk,"A",{href:!0});var frt=s(cI);Oco=r(frt,"T5Tokenizer"),frt.forEach(t),Vco=r(wk," or "),fI=n(wk,"A",{href:!0});var mrt=s(fI);Xco=r(mrt,"T5TokenizerFast"),mrt.forEach(t),zco=r(wk," (T5 model)"),wk.forEach(t),Wco=i(S),fh=n(S,"LI",{});var Xwe=s(fh);_se=n(Xwe,"STRONG",{});var grt=s(_se);Qco=r(grt,"tapas"),grt.forEach(t),Hco=r(Xwe," \u2014 "),mI=n(Xwe,"A",{href:!0});var hrt=s(mI);Uco=r(hrt,"TapasTokenizer"),hrt.forEach(t),Jco=r(Xwe," (TAPAS model)"),Xwe.forEach(t),Yco=i(S),mh=n(S,"LI",{});var zwe=s(mh);bse=n(zwe,"STRONG",{});var prt=s(bse);Kco=r(prt,"tapex"),prt.forEach(t),Zco=r(zwe," \u2014 "),gI=n(zwe,"A",{href:!0});var urt=s(gI);efo=r(urt,"TapexTokenizer"),urt.forEach(t),ofo=r(zwe," (TAPEX model)"),zwe.forEach(t),rfo=i(S),gh=n(S,"LI",{});var Wwe=s(gh);vse=n(Wwe,"STRONG",{});var _rt=s(vse);tfo=r(_rt,"transfo-xl"),_rt.forEach(t),afo=r(Wwe," \u2014 "),hI=n(Wwe,"A",{href:!0});var brt=s(hI);nfo=r(brt,"TransfoXLTokenizer"),brt.forEach(t),sfo=r(Wwe," (Transformer-XL model)"),Wwe.forEach(t),lfo=i(S),Rs=n(S,"LI",{});var Ak=s(Rs);Fse=n(Ak,"STRONG",{});var vrt=s(Fse);ifo=r(vrt,"vilt"),vrt.forEach(t),dfo=r(Ak," \u2014 "),pI=n(Ak,"A",{href:!0});var Frt=s(pI);cfo=r(Frt,"BertTokenizer"),Frt.forEach(t),ffo=r(Ak," or "),uI=n(Ak,"A",{href:!0});var Trt=s(uI);mfo=r(Trt,"BertTokenizerFast"),Trt.forEach(t),gfo=r(Ak," (ViLT model)"),Ak.forEach(t),hfo=i(S),Ps=n(S,"LI",{});var yk=s(Ps);Tse=n(yk,"STRONG",{});var Mrt=s(Tse);pfo=r(Mrt,"visual_bert"),Mrt.forEach(t),ufo=r(yk," \u2014 "),_I=n(yk,"A",{href:!0});var Ert=s(_I);_fo=r(Ert,"BertTokenizer"),Ert.forEach(t),bfo=r(yk," or "),bI=n(yk,"A",{href:!0});var Crt=s(bI);vfo=r(Crt,"BertTokenizerFast"),Crt.forEach(t),Ffo=r(yk," (VisualBERT model)"),yk.forEach(t),Tfo=i(S),hh=n(S,"LI",{});var Qwe=s(hh);Mse=n(Qwe,"STRONG",{});var wrt=s(Mse);Mfo=r(wrt,"wav2vec2"),wrt.forEach(t),Efo=r(Qwe," \u2014 "),vI=n(Qwe,"A",{href:!0});var Art=s(vI);Cfo=r(Art,"Wav2Vec2CTCTokenizer"),Art.forEach(t),wfo=r(Qwe," (Wav2Vec2 model)"),Qwe.forEach(t),Afo=i(S),ph=n(S,"LI",{});var Hwe=s(ph);Ese=n(Hwe,"STRONG",{});var yrt=s(Ese);yfo=r(yrt,"wav2vec2-conformer"),yrt.forEach(t),Lfo=r(Hwe," \u2014 "),FI=n(Hwe,"A",{href:!0});var Lrt=s(FI);xfo=r(Lrt,"Wav2Vec2CTCTokenizer"),Lrt.forEach(t),$fo=r(Hwe," (Wav2Vec2-Conformer model)"),Hwe.forEach(t),kfo=i(S),uh=n(S,"LI",{});var Uwe=s(uh);Cse=n(Uwe,"STRONG",{});var xrt=s(Cse);Sfo=r(xrt,"wav2vec2_phoneme"),xrt.forEach(t),Rfo=r(Uwe," \u2014 "),TI=n(Uwe,"A",{href:!0});var $rt=s(TI);Pfo=r($rt,"Wav2Vec2PhonemeCTCTokenizer"),$rt.forEach(t),Bfo=r(Uwe," (Wav2Vec2Phoneme model)"),Uwe.forEach(t),Ifo=i(S),Bs=n(S,"LI",{});var Lk=s(Bs);wse=n(Lk,"STRONG",{});var krt=s(wse);Nfo=r(krt,"xglm"),krt.forEach(t),qfo=r(Lk," \u2014 "),MI=n(Lk,"A",{href:!0});var Srt=s(MI);jfo=r(Srt,"XGLMTokenizer"),Srt.forEach(t),Dfo=r(Lk," or "),EI=n(Lk,"A",{href:!0});var Rrt=s(EI);Gfo=r(Rrt,"XGLMTokenizerFast"),Rrt.forEach(t),Ofo=r(Lk," (XGLM model)"),Lk.forEach(t),Vfo=i(S),_h=n(S,"LI",{});var Jwe=s(_h);Ase=n(Jwe,"STRONG",{});var Prt=s(Ase);Xfo=r(Prt,"xlm"),Prt.forEach(t),zfo=r(Jwe," \u2014 "),CI=n(Jwe,"A",{href:!0});var Brt=s(CI);Wfo=r(Brt,"XLMTokenizer"),Brt.forEach(t),Qfo=r(Jwe," (XLM model)"),Jwe.forEach(t),Hfo=i(S),bh=n(S,"LI",{});var Ywe=s(bh);yse=n(Ywe,"STRONG",{});var Irt=s(yse);Ufo=r(Irt,"xlm-prophetnet"),Irt.forEach(t),Jfo=r(Ywe," \u2014 "),wI=n(Ywe,"A",{href:!0});var Nrt=s(wI);Yfo=r(Nrt,"XLMProphetNetTokenizer"),Nrt.forEach(t),Kfo=r(Ywe," (XLM-ProphetNet model)"),Ywe.forEach(t),Zfo=i(S),Is=n(S,"LI",{});var xk=s(Is);Lse=n(xk,"STRONG",{});var qrt=s(Lse);emo=r(qrt,"xlm-roberta"),qrt.forEach(t),omo=r(xk," \u2014 "),AI=n(xk,"A",{href:!0});var jrt=s(AI);rmo=r(jrt,"XLMRobertaTokenizer"),jrt.forEach(t),tmo=r(xk," or "),yI=n(xk,"A",{href:!0});var Drt=s(yI);amo=r(Drt,"XLMRobertaTokenizerFast"),Drt.forEach(t),nmo=r(xk," (XLM-RoBERTa model)"),xk.forEach(t),smo=i(S),Ns=n(S,"LI",{});var $k=s(Ns);xse=n($k,"STRONG",{});var Grt=s(xse);lmo=r(Grt,"xlm-roberta-xl"),Grt.forEach(t),imo=r($k," \u2014 "),LI=n($k,"A",{href:!0});var Ort=s(LI);dmo=r(Ort,"RobertaTokenizer"),Ort.forEach(t),cmo=r($k," or "),xI=n($k,"A",{href:!0});var Vrt=s(xI);fmo=r(Vrt,"RobertaTokenizerFast"),Vrt.forEach(t),mmo=r($k," (XLM-RoBERTa-XL model)"),$k.forEach(t),gmo=i(S),qs=n(S,"LI",{});var kk=s(qs);$se=n(kk,"STRONG",{});var Xrt=s($se);hmo=r(Xrt,"xlnet"),Xrt.forEach(t),pmo=r(kk," \u2014 "),$I=n(kk,"A",{href:!0});var zrt=s($I);umo=r(zrt,"XLNetTokenizer"),zrt.forEach(t),_mo=r(kk," or "),kI=n(kk,"A",{href:!0});var Wrt=s(kI);bmo=r(Wrt,"XLNetTokenizerFast"),Wrt.forEach(t),vmo=r(kk," (XLNet model)"),kk.forEach(t),Fmo=i(S),js=n(S,"LI",{});var Sk=s(js);kse=n(Sk,"STRONG",{});var Qrt=s(kse);Tmo=r(Qrt,"yoso"),Qrt.forEach(t),Mmo=r(Sk," \u2014 "),SI=n(Sk,"A",{href:!0});var Hrt=s(SI);Emo=r(Hrt,"AlbertTokenizer"),Hrt.forEach(t),Cmo=r(Sk," or "),RI=n(Sk,"A",{href:!0});var Urt=s(RI);wmo=r(Urt,"AlbertTokenizerFast"),Urt.forEach(t),Amo=r(Sk," (YOSO model)"),Sk.forEach(t),S.forEach(t),ymo=i(zs),T(vh.$$.fragment,zs),zs.forEach(t),Lmo=i(Xs),Fh=n(Xs,"DIV",{class:!0});var ROe=s(Fh);T(wA.$$.fragment,ROe),xmo=i(ROe),Sse=n(ROe,"P",{});var Jrt=s(Sse);$mo=r(Jrt,"Register a new tokenizer in this mapping."),Jrt.forEach(t),ROe.forEach(t),Xs.forEach(t),SDe=i(f),$i=n(f,"H2",{class:!0});var POe=s($i);Th=n(POe,"A",{id:!0,class:!0,href:!0});var Yrt=s(Th);Rse=n(Yrt,"SPAN",{});var Krt=s(Rse);T(AA.$$.fragment,Krt),Krt.forEach(t),Yrt.forEach(t),kmo=i(POe),Pse=n(POe,"SPAN",{});var Zrt=s(Pse);Smo=r(Zrt,"AutoFeatureExtractor"),Zrt.forEach(t),POe.forEach(t),RDe=i(f),yo=n(f,"DIV",{class:!0});var Ws=s(yo);T(yA.$$.fragment,Ws),Rmo=i(Ws),LA=n(Ws,"P",{});var BOe=s(LA);Pmo=r(BOe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),PI=n(BOe,"A",{href:!0});var ett=s(PI);Bmo=r(ett,"AutoFeatureExtractor.from_pretrained()"),ett.forEach(t),Imo=r(BOe," class method."),BOe.forEach(t),Nmo=i(Ws),xA=n(Ws,"P",{});var IOe=s(xA);qmo=r(IOe,"This class cannot be instantiated directly using "),Bse=n(IOe,"CODE",{});var ott=s(Bse);jmo=r(ott,"__init__()"),ott.forEach(t),Dmo=r(IOe," (throws an error)."),IOe.forEach(t),Gmo=i(Ws),He=n(Ws,"DIV",{class:!0});var ra=s(He);T($A.$$.fragment,ra),Omo=i(ra),Ise=n(ra,"P",{});var rtt=s(Ise);Vmo=r(rtt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),rtt.forEach(t),Xmo=i(ra),ka=n(ra,"P",{});var g0=s(ka);zmo=r(g0,"The feature extractor class to instantiate is selected based on the "),Nse=n(g0,"CODE",{});var ttt=s(Nse);Wmo=r(ttt,"model_type"),ttt.forEach(t),Qmo=r(g0,` property of the config object
(either passed as an argument or loaded from `),qse=n(g0,"CODE",{});var att=s(qse);Hmo=r(att,"pretrained_model_name_or_path"),att.forEach(t),Umo=r(g0,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),jse=n(g0,"CODE",{});var ntt=s(jse);Jmo=r(ntt,"pretrained_model_name_or_path"),ntt.forEach(t),Ymo=r(g0,":"),g0.forEach(t),Kmo=i(ra),Y=n(ra,"UL",{});var K=s(Y);Mh=n(K,"LI",{});var Kwe=s(Mh);Dse=n(Kwe,"STRONG",{});var stt=s(Dse);Zmo=r(stt,"beit"),stt.forEach(t),ego=r(Kwe," \u2014 "),BI=n(Kwe,"A",{href:!0});var ltt=s(BI);ogo=r(ltt,"BeitFeatureExtractor"),ltt.forEach(t),rgo=r(Kwe," (BEiT model)"),Kwe.forEach(t),tgo=i(K),Eh=n(K,"LI",{});var Zwe=s(Eh);Gse=n(Zwe,"STRONG",{});var itt=s(Gse);ago=r(itt,"clip"),itt.forEach(t),ngo=r(Zwe," \u2014 "),II=n(Zwe,"A",{href:!0});var dtt=s(II);sgo=r(dtt,"CLIPFeatureExtractor"),dtt.forEach(t),lgo=r(Zwe," (CLIP model)"),Zwe.forEach(t),igo=i(K),Ch=n(K,"LI",{});var eAe=s(Ch);Ose=n(eAe,"STRONG",{});var ctt=s(Ose);dgo=r(ctt,"convnext"),ctt.forEach(t),cgo=r(eAe," \u2014 "),NI=n(eAe,"A",{href:!0});var ftt=s(NI);fgo=r(ftt,"ConvNextFeatureExtractor"),ftt.forEach(t),mgo=r(eAe," (ConvNeXT model)"),eAe.forEach(t),ggo=i(K),wh=n(K,"LI",{});var oAe=s(wh);Vse=n(oAe,"STRONG",{});var mtt=s(Vse);hgo=r(mtt,"cvt"),mtt.forEach(t),pgo=r(oAe," \u2014 "),qI=n(oAe,"A",{href:!0});var gtt=s(qI);ugo=r(gtt,"ConvNextFeatureExtractor"),gtt.forEach(t),_go=r(oAe," (CvT model)"),oAe.forEach(t),bgo=i(K),Ah=n(K,"LI",{});var rAe=s(Ah);Xse=n(rAe,"STRONG",{});var htt=s(Xse);vgo=r(htt,"data2vec-audio"),htt.forEach(t),Fgo=r(rAe," \u2014 "),jI=n(rAe,"A",{href:!0});var ptt=s(jI);Tgo=r(ptt,"Wav2Vec2FeatureExtractor"),ptt.forEach(t),Mgo=r(rAe," (Data2VecAudio model)"),rAe.forEach(t),Ego=i(K),yh=n(K,"LI",{});var tAe=s(yh);zse=n(tAe,"STRONG",{});var utt=s(zse);Cgo=r(utt,"data2vec-vision"),utt.forEach(t),wgo=r(tAe," \u2014 "),DI=n(tAe,"A",{href:!0});var _tt=s(DI);Ago=r(_tt,"BeitFeatureExtractor"),_tt.forEach(t),ygo=r(tAe," (Data2VecVision model)"),tAe.forEach(t),Lgo=i(K),Lh=n(K,"LI",{});var aAe=s(Lh);Wse=n(aAe,"STRONG",{});var btt=s(Wse);xgo=r(btt,"deit"),btt.forEach(t),$go=r(aAe," \u2014 "),GI=n(aAe,"A",{href:!0});var vtt=s(GI);kgo=r(vtt,"DeiTFeatureExtractor"),vtt.forEach(t),Sgo=r(aAe," (DeiT model)"),aAe.forEach(t),Rgo=i(K),xh=n(K,"LI",{});var nAe=s(xh);Qse=n(nAe,"STRONG",{});var Ftt=s(Qse);Pgo=r(Ftt,"detr"),Ftt.forEach(t),Bgo=r(nAe," \u2014 "),OI=n(nAe,"A",{href:!0});var Ttt=s(OI);Igo=r(Ttt,"DetrFeatureExtractor"),Ttt.forEach(t),Ngo=r(nAe," (DETR model)"),nAe.forEach(t),qgo=i(K),$h=n(K,"LI",{});var sAe=s($h);Hse=n(sAe,"STRONG",{});var Mtt=s(Hse);jgo=r(Mtt,"dpt"),Mtt.forEach(t),Dgo=r(sAe," \u2014 "),VI=n(sAe,"A",{href:!0});var Ett=s(VI);Ggo=r(Ett,"DPTFeatureExtractor"),Ett.forEach(t),Ogo=r(sAe," (DPT model)"),sAe.forEach(t),Vgo=i(K),kh=n(K,"LI",{});var lAe=s(kh);Use=n(lAe,"STRONG",{});var Ctt=s(Use);Xgo=r(Ctt,"flava"),Ctt.forEach(t),zgo=r(lAe," \u2014 "),XI=n(lAe,"A",{href:!0});var wtt=s(XI);Wgo=r(wtt,"FlavaFeatureExtractor"),wtt.forEach(t),Qgo=r(lAe," (FLAVA model)"),lAe.forEach(t),Hgo=i(K),Sh=n(K,"LI",{});var iAe=s(Sh);Jse=n(iAe,"STRONG",{});var Att=s(Jse);Ugo=r(Att,"glpn"),Att.forEach(t),Jgo=r(iAe," \u2014 "),zI=n(iAe,"A",{href:!0});var ytt=s(zI);Ygo=r(ytt,"GLPNFeatureExtractor"),ytt.forEach(t),Kgo=r(iAe," (GLPN model)"),iAe.forEach(t),Zgo=i(K),Rh=n(K,"LI",{});var dAe=s(Rh);Yse=n(dAe,"STRONG",{});var Ltt=s(Yse);eho=r(Ltt,"hubert"),Ltt.forEach(t),oho=r(dAe," \u2014 "),WI=n(dAe,"A",{href:!0});var xtt=s(WI);rho=r(xtt,"Wav2Vec2FeatureExtractor"),xtt.forEach(t),tho=r(dAe," (Hubert model)"),dAe.forEach(t),aho=i(K),Ph=n(K,"LI",{});var cAe=s(Ph);Kse=n(cAe,"STRONG",{});var $tt=s(Kse);nho=r($tt,"imagegpt"),$tt.forEach(t),sho=r(cAe," \u2014 "),QI=n(cAe,"A",{href:!0});var ktt=s(QI);lho=r(ktt,"ImageGPTFeatureExtractor"),ktt.forEach(t),iho=r(cAe," (ImageGPT model)"),cAe.forEach(t),dho=i(K),Bh=n(K,"LI",{});var fAe=s(Bh);Zse=n(fAe,"STRONG",{});var Stt=s(Zse);cho=r(Stt,"layoutlmv2"),Stt.forEach(t),fho=r(fAe," \u2014 "),HI=n(fAe,"A",{href:!0});var Rtt=s(HI);mho=r(Rtt,"LayoutLMv2FeatureExtractor"),Rtt.forEach(t),gho=r(fAe," (LayoutLMv2 model)"),fAe.forEach(t),hho=i(K),Ih=n(K,"LI",{});var mAe=s(Ih);ele=n(mAe,"STRONG",{});var Ptt=s(ele);pho=r(Ptt,"layoutlmv3"),Ptt.forEach(t),uho=r(mAe," \u2014 "),UI=n(mAe,"A",{href:!0});var Btt=s(UI);_ho=r(Btt,"LayoutLMv3FeatureExtractor"),Btt.forEach(t),bho=r(mAe," (LayoutLMv3 model)"),mAe.forEach(t),vho=i(K),Nh=n(K,"LI",{});var gAe=s(Nh);ole=n(gAe,"STRONG",{});var Itt=s(ole);Fho=r(Itt,"levit"),Itt.forEach(t),Tho=r(gAe," \u2014 "),JI=n(gAe,"A",{href:!0});var Ntt=s(JI);Mho=r(Ntt,"LevitFeatureExtractor"),Ntt.forEach(t),Eho=r(gAe," (LeViT model)"),gAe.forEach(t),Cho=i(K),qh=n(K,"LI",{});var hAe=s(qh);rle=n(hAe,"STRONG",{});var qtt=s(rle);who=r(qtt,"maskformer"),qtt.forEach(t),Aho=r(hAe," \u2014 "),YI=n(hAe,"A",{href:!0});var jtt=s(YI);yho=r(jtt,"MaskFormerFeatureExtractor"),jtt.forEach(t),Lho=r(hAe," (MaskFormer model)"),hAe.forEach(t),xho=i(K),jh=n(K,"LI",{});var pAe=s(jh);tle=n(pAe,"STRONG",{});var Dtt=s(tle);$ho=r(Dtt,"mctct"),Dtt.forEach(t),kho=r(pAe," \u2014 "),KI=n(pAe,"A",{href:!0});var Gtt=s(KI);Sho=r(Gtt,"MCTCTFeatureExtractor"),Gtt.forEach(t),Rho=r(pAe," (M-CTC-T model)"),pAe.forEach(t),Pho=i(K),Dh=n(K,"LI",{});var uAe=s(Dh);ale=n(uAe,"STRONG",{});var Ott=s(ale);Bho=r(Ott,"perceiver"),Ott.forEach(t),Iho=r(uAe," \u2014 "),ZI=n(uAe,"A",{href:!0});var Vtt=s(ZI);Nho=r(Vtt,"PerceiverFeatureExtractor"),Vtt.forEach(t),qho=r(uAe," (Perceiver model)"),uAe.forEach(t),jho=i(K),Gh=n(K,"LI",{});var _Ae=s(Gh);nle=n(_Ae,"STRONG",{});var Xtt=s(nle);Dho=r(Xtt,"poolformer"),Xtt.forEach(t),Gho=r(_Ae," \u2014 "),eN=n(_Ae,"A",{href:!0});var ztt=s(eN);Oho=r(ztt,"PoolFormerFeatureExtractor"),ztt.forEach(t),Vho=r(_Ae," (PoolFormer model)"),_Ae.forEach(t),Xho=i(K),Oh=n(K,"LI",{});var bAe=s(Oh);sle=n(bAe,"STRONG",{});var Wtt=s(sle);zho=r(Wtt,"regnet"),Wtt.forEach(t),Who=r(bAe," \u2014 "),oN=n(bAe,"A",{href:!0});var Qtt=s(oN);Qho=r(Qtt,"ConvNextFeatureExtractor"),Qtt.forEach(t),Hho=r(bAe," (RegNet model)"),bAe.forEach(t),Uho=i(K),Vh=n(K,"LI",{});var vAe=s(Vh);lle=n(vAe,"STRONG",{});var Htt=s(lle);Jho=r(Htt,"resnet"),Htt.forEach(t),Yho=r(vAe," \u2014 "),rN=n(vAe,"A",{href:!0});var Utt=s(rN);Kho=r(Utt,"ConvNextFeatureExtractor"),Utt.forEach(t),Zho=r(vAe," (ResNet model)"),vAe.forEach(t),epo=i(K),Xh=n(K,"LI",{});var FAe=s(Xh);ile=n(FAe,"STRONG",{});var Jtt=s(ile);opo=r(Jtt,"segformer"),Jtt.forEach(t),rpo=r(FAe," \u2014 "),tN=n(FAe,"A",{href:!0});var Ytt=s(tN);tpo=r(Ytt,"SegformerFeatureExtractor"),Ytt.forEach(t),apo=r(FAe," (SegFormer model)"),FAe.forEach(t),npo=i(K),zh=n(K,"LI",{});var TAe=s(zh);dle=n(TAe,"STRONG",{});var Ktt=s(dle);spo=r(Ktt,"speech_to_text"),Ktt.forEach(t),lpo=r(TAe," \u2014 "),aN=n(TAe,"A",{href:!0});var Ztt=s(aN);ipo=r(Ztt,"Speech2TextFeatureExtractor"),Ztt.forEach(t),dpo=r(TAe," (Speech2Text model)"),TAe.forEach(t),cpo=i(K),Wh=n(K,"LI",{});var MAe=s(Wh);cle=n(MAe,"STRONG",{});var eat=s(cle);fpo=r(eat,"swin"),eat.forEach(t),mpo=r(MAe," \u2014 "),nN=n(MAe,"A",{href:!0});var oat=s(nN);gpo=r(oat,"ViTFeatureExtractor"),oat.forEach(t),hpo=r(MAe," (Swin Transformer model)"),MAe.forEach(t),ppo=i(K),Qh=n(K,"LI",{});var EAe=s(Qh);fle=n(EAe,"STRONG",{});var rat=s(fle);upo=r(rat,"van"),rat.forEach(t),_po=r(EAe," \u2014 "),sN=n(EAe,"A",{href:!0});var tat=s(sN);bpo=r(tat,"ConvNextFeatureExtractor"),tat.forEach(t),vpo=r(EAe," (VAN model)"),EAe.forEach(t),Fpo=i(K),Hh=n(K,"LI",{});var CAe=s(Hh);mle=n(CAe,"STRONG",{});var aat=s(mle);Tpo=r(aat,"vilt"),aat.forEach(t),Mpo=r(CAe," \u2014 "),lN=n(CAe,"A",{href:!0});var nat=s(lN);Epo=r(nat,"ViltFeatureExtractor"),nat.forEach(t),Cpo=r(CAe," (ViLT model)"),CAe.forEach(t),wpo=i(K),Uh=n(K,"LI",{});var wAe=s(Uh);gle=n(wAe,"STRONG",{});var sat=s(gle);Apo=r(sat,"vit"),sat.forEach(t),ypo=r(wAe," \u2014 "),iN=n(wAe,"A",{href:!0});var lat=s(iN);Lpo=r(lat,"ViTFeatureExtractor"),lat.forEach(t),xpo=r(wAe," (ViT model)"),wAe.forEach(t),$po=i(K),Jh=n(K,"LI",{});var AAe=s(Jh);hle=n(AAe,"STRONG",{});var iat=s(hle);kpo=r(iat,"vit_mae"),iat.forEach(t),Spo=r(AAe," \u2014 "),dN=n(AAe,"A",{href:!0});var dat=s(dN);Rpo=r(dat,"ViTFeatureExtractor"),dat.forEach(t),Ppo=r(AAe," (ViTMAE model)"),AAe.forEach(t),Bpo=i(K),Yh=n(K,"LI",{});var yAe=s(Yh);ple=n(yAe,"STRONG",{});var cat=s(ple);Ipo=r(cat,"wav2vec2"),cat.forEach(t),Npo=r(yAe," \u2014 "),cN=n(yAe,"A",{href:!0});var fat=s(cN);qpo=r(fat,"Wav2Vec2FeatureExtractor"),fat.forEach(t),jpo=r(yAe," (Wav2Vec2 model)"),yAe.forEach(t),Dpo=i(K),Kh=n(K,"LI",{});var LAe=s(Kh);ule=n(LAe,"STRONG",{});var mat=s(ule);Gpo=r(mat,"wav2vec2-conformer"),mat.forEach(t),Opo=r(LAe," \u2014 "),fN=n(LAe,"A",{href:!0});var gat=s(fN);Vpo=r(gat,"Wav2Vec2FeatureExtractor"),gat.forEach(t),Xpo=r(LAe," (Wav2Vec2-Conformer model)"),LAe.forEach(t),zpo=i(K),Zh=n(K,"LI",{});var xAe=s(Zh);_le=n(xAe,"STRONG",{});var hat=s(_le);Wpo=r(hat,"yolos"),hat.forEach(t),Qpo=r(xAe," \u2014 "),mN=n(xAe,"A",{href:!0});var pat=s(mN);Hpo=r(pat,"YolosFeatureExtractor"),pat.forEach(t),Upo=r(xAe," (YOLOS model)"),xAe.forEach(t),K.forEach(t),Jpo=i(ra),T(ep.$$.fragment,ra),Ypo=i(ra),T(op.$$.fragment,ra),ra.forEach(t),Kpo=i(Ws),rp=n(Ws,"DIV",{class:!0});var NOe=s(rp);T(kA.$$.fragment,NOe),Zpo=i(NOe),ble=n(NOe,"P",{});var uat=s(ble);euo=r(uat,"Register a new feature extractor for this class."),uat.forEach(t),NOe.forEach(t),Ws.forEach(t),PDe=i(f),ki=n(f,"H2",{class:!0});var qOe=s(ki);tp=n(qOe,"A",{id:!0,class:!0,href:!0});var _at=s(tp);vle=n(_at,"SPAN",{});var bat=s(vle);T(SA.$$.fragment,bat),bat.forEach(t),_at.forEach(t),ouo=i(qOe),Fle=n(qOe,"SPAN",{});var vat=s(Fle);ruo=r(vat,"AutoProcessor"),vat.forEach(t),qOe.forEach(t),BDe=i(f),Lo=n(f,"DIV",{class:!0});var Qs=s(Lo);T(RA.$$.fragment,Qs),tuo=i(Qs),PA=n(Qs,"P",{});var jOe=s(PA);auo=r(jOe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),gN=n(jOe,"A",{href:!0});var Fat=s(gN);nuo=r(Fat,"AutoProcessor.from_pretrained()"),Fat.forEach(t),suo=r(jOe," class method."),jOe.forEach(t),luo=i(Qs),BA=n(Qs,"P",{});var DOe=s(BA);iuo=r(DOe,"This class cannot be instantiated directly using "),Tle=n(DOe,"CODE",{});var Tat=s(Tle);duo=r(Tat,"__init__()"),Tat.forEach(t),cuo=r(DOe," (throws an error)."),DOe.forEach(t),fuo=i(Qs),Ue=n(Qs,"DIV",{class:!0});var ta=s(Ue);T(IA.$$.fragment,ta),muo=i(ta),Mle=n(ta,"P",{});var Mat=s(Mle);guo=r(Mat,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Mat.forEach(t),huo=i(ta),Si=n(ta,"P",{});var Pee=s(Si);puo=r(Pee,"The processor class to instantiate is selected based on the "),Ele=n(Pee,"CODE",{});var Eat=s(Ele);uuo=r(Eat,"model_type"),Eat.forEach(t),_uo=r(Pee,` property of the config object (either
passed as an argument or loaded from `),Cle=n(Pee,"CODE",{});var Cat=s(Cle);buo=r(Cat,"pretrained_model_name_or_path"),Cat.forEach(t),vuo=r(Pee," if possible):"),Pee.forEach(t),Fuo=i(ta),he=n(ta,"UL",{});var _e=s(he);ap=n(_e,"LI",{});var $Ae=s(ap);wle=n($Ae,"STRONG",{});var wat=s(wle);Tuo=r(wat,"clip"),wat.forEach(t),Muo=r($Ae," \u2014 "),hN=n($Ae,"A",{href:!0});var Aat=s(hN);Euo=r(Aat,"CLIPProcessor"),Aat.forEach(t),Cuo=r($Ae," (CLIP model)"),$Ae.forEach(t),wuo=i(_e),np=n(_e,"LI",{});var kAe=s(np);Ale=n(kAe,"STRONG",{});var yat=s(Ale);Auo=r(yat,"flava"),yat.forEach(t),yuo=r(kAe," \u2014 "),yle=n(kAe,"CODE",{});var Lat=s(yle);Luo=r(Lat,"FLAVAProcessor"),Lat.forEach(t),xuo=r(kAe," (FLAVA model)"),kAe.forEach(t),$uo=i(_e),sp=n(_e,"LI",{});var SAe=s(sp);Lle=n(SAe,"STRONG",{});var xat=s(Lle);kuo=r(xat,"layoutlmv2"),xat.forEach(t),Suo=r(SAe," \u2014 "),pN=n(SAe,"A",{href:!0});var $at=s(pN);Ruo=r($at,"LayoutLMv2Processor"),$at.forEach(t),Puo=r(SAe," (LayoutLMv2 model)"),SAe.forEach(t),Buo=i(_e),lp=n(_e,"LI",{});var RAe=s(lp);xle=n(RAe,"STRONG",{});var kat=s(xle);Iuo=r(kat,"layoutlmv3"),kat.forEach(t),Nuo=r(RAe," \u2014 "),uN=n(RAe,"A",{href:!0});var Sat=s(uN);quo=r(Sat,"LayoutLMv3Processor"),Sat.forEach(t),juo=r(RAe," (LayoutLMv3 model)"),RAe.forEach(t),Duo=i(_e),ip=n(_e,"LI",{});var PAe=s(ip);$le=n(PAe,"STRONG",{});var Rat=s($le);Guo=r(Rat,"layoutxlm"),Rat.forEach(t),Ouo=r(PAe," \u2014 "),_N=n(PAe,"A",{href:!0});var Pat=s(_N);Vuo=r(Pat,"LayoutXLMProcessor"),Pat.forEach(t),Xuo=r(PAe," (LayoutXLM model)"),PAe.forEach(t),zuo=i(_e),dp=n(_e,"LI",{});var BAe=s(dp);kle=n(BAe,"STRONG",{});var Bat=s(kle);Wuo=r(Bat,"sew"),Bat.forEach(t),Quo=r(BAe," \u2014 "),bN=n(BAe,"A",{href:!0});var Iat=s(bN);Huo=r(Iat,"Wav2Vec2Processor"),Iat.forEach(t),Uuo=r(BAe," (SEW model)"),BAe.forEach(t),Juo=i(_e),cp=n(_e,"LI",{});var IAe=s(cp);Sle=n(IAe,"STRONG",{});var Nat=s(Sle);Yuo=r(Nat,"sew-d"),Nat.forEach(t),Kuo=r(IAe," \u2014 "),vN=n(IAe,"A",{href:!0});var qat=s(vN);Zuo=r(qat,"Wav2Vec2Processor"),qat.forEach(t),e_o=r(IAe," (SEW-D model)"),IAe.forEach(t),o_o=i(_e),fp=n(_e,"LI",{});var NAe=s(fp);Rle=n(NAe,"STRONG",{});var jat=s(Rle);r_o=r(jat,"speech_to_text"),jat.forEach(t),t_o=r(NAe," \u2014 "),FN=n(NAe,"A",{href:!0});var Dat=s(FN);a_o=r(Dat,"Speech2TextProcessor"),Dat.forEach(t),n_o=r(NAe," (Speech2Text model)"),NAe.forEach(t),s_o=i(_e),mp=n(_e,"LI",{});var qAe=s(mp);Ple=n(qAe,"STRONG",{});var Gat=s(Ple);l_o=r(Gat,"speech_to_text_2"),Gat.forEach(t),i_o=r(qAe," \u2014 "),TN=n(qAe,"A",{href:!0});var Oat=s(TN);d_o=r(Oat,"Speech2Text2Processor"),Oat.forEach(t),c_o=r(qAe," (Speech2Text2 model)"),qAe.forEach(t),f_o=i(_e),gp=n(_e,"LI",{});var jAe=s(gp);Ble=n(jAe,"STRONG",{});var Vat=s(Ble);m_o=r(Vat,"trocr"),Vat.forEach(t),g_o=r(jAe," \u2014 "),MN=n(jAe,"A",{href:!0});var Xat=s(MN);h_o=r(Xat,"TrOCRProcessor"),Xat.forEach(t),p_o=r(jAe," (TrOCR model)"),jAe.forEach(t),u_o=i(_e),hp=n(_e,"LI",{});var DAe=s(hp);Ile=n(DAe,"STRONG",{});var zat=s(Ile);__o=r(zat,"unispeech"),zat.forEach(t),b_o=r(DAe," \u2014 "),EN=n(DAe,"A",{href:!0});var Wat=s(EN);v_o=r(Wat,"Wav2Vec2Processor"),Wat.forEach(t),F_o=r(DAe," (UniSpeech model)"),DAe.forEach(t),T_o=i(_e),pp=n(_e,"LI",{});var GAe=s(pp);Nle=n(GAe,"STRONG",{});var Qat=s(Nle);M_o=r(Qat,"unispeech-sat"),Qat.forEach(t),E_o=r(GAe," \u2014 "),CN=n(GAe,"A",{href:!0});var Hat=s(CN);C_o=r(Hat,"Wav2Vec2Processor"),Hat.forEach(t),w_o=r(GAe," (UniSpeechSat model)"),GAe.forEach(t),A_o=i(_e),up=n(_e,"LI",{});var OAe=s(up);qle=n(OAe,"STRONG",{});var Uat=s(qle);y_o=r(Uat,"vilt"),Uat.forEach(t),L_o=r(OAe," \u2014 "),wN=n(OAe,"A",{href:!0});var Jat=s(wN);x_o=r(Jat,"ViltProcessor"),Jat.forEach(t),$_o=r(OAe," (ViLT model)"),OAe.forEach(t),k_o=i(_e),_p=n(_e,"LI",{});var VAe=s(_p);jle=n(VAe,"STRONG",{});var Yat=s(jle);S_o=r(Yat,"vision-text-dual-encoder"),Yat.forEach(t),R_o=r(VAe," \u2014 "),AN=n(VAe,"A",{href:!0});var Kat=s(AN);P_o=r(Kat,"VisionTextDualEncoderProcessor"),Kat.forEach(t),B_o=r(VAe," (VisionTextDualEncoder model)"),VAe.forEach(t),I_o=i(_e),bp=n(_e,"LI",{});var XAe=s(bp);Dle=n(XAe,"STRONG",{});var Zat=s(Dle);N_o=r(Zat,"wav2vec2"),Zat.forEach(t),q_o=r(XAe," \u2014 "),yN=n(XAe,"A",{href:!0});var ent=s(yN);j_o=r(ent,"Wav2Vec2Processor"),ent.forEach(t),D_o=r(XAe," (Wav2Vec2 model)"),XAe.forEach(t),G_o=i(_e),vp=n(_e,"LI",{});var zAe=s(vp);Gle=n(zAe,"STRONG",{});var ont=s(Gle);O_o=r(ont,"wav2vec2-conformer"),ont.forEach(t),V_o=r(zAe," \u2014 "),LN=n(zAe,"A",{href:!0});var rnt=s(LN);X_o=r(rnt,"Wav2Vec2Processor"),rnt.forEach(t),z_o=r(zAe," (Wav2Vec2-Conformer model)"),zAe.forEach(t),W_o=i(_e),Fp=n(_e,"LI",{});var WAe=s(Fp);Ole=n(WAe,"STRONG",{});var tnt=s(Ole);Q_o=r(tnt,"wavlm"),tnt.forEach(t),H_o=r(WAe," \u2014 "),xN=n(WAe,"A",{href:!0});var ant=s(xN);U_o=r(ant,"Wav2Vec2Processor"),ant.forEach(t),J_o=r(WAe," (WavLM model)"),WAe.forEach(t),_e.forEach(t),Y_o=i(ta),T(Tp.$$.fragment,ta),K_o=i(ta),T(Mp.$$.fragment,ta),ta.forEach(t),Z_o=i(Qs),Ep=n(Qs,"DIV",{class:!0});var GOe=s(Ep);T(NA.$$.fragment,GOe),e1o=i(GOe),Vle=n(GOe,"P",{});var nnt=s(Vle);o1o=r(nnt,"Register a new processor for this class."),nnt.forEach(t),GOe.forEach(t),Qs.forEach(t),IDe=i(f),Ri=n(f,"H2",{class:!0});var OOe=s(Ri);Cp=n(OOe,"A",{id:!0,class:!0,href:!0});var snt=s(Cp);Xle=n(snt,"SPAN",{});var lnt=s(Xle);T(qA.$$.fragment,lnt),lnt.forEach(t),snt.forEach(t),r1o=i(OOe),zle=n(OOe,"SPAN",{});var int=s(zle);t1o=r(int,"AutoModel"),int.forEach(t),OOe.forEach(t),NDe=i(f),xo=n(f,"DIV",{class:!0});var Hs=s(xo);T(jA.$$.fragment,Hs),a1o=i(Hs),Pi=n(Hs,"P",{});var Bee=s(Pi);n1o=r(Bee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),$N=n(Bee,"A",{href:!0});var dnt=s($N);s1o=r(dnt,"from_pretrained()"),dnt.forEach(t),l1o=r(Bee," class method or the "),kN=n(Bee,"A",{href:!0});var cnt=s(kN);i1o=r(cnt,"from_config()"),cnt.forEach(t),d1o=r(Bee,` class
method.`),Bee.forEach(t),c1o=i(Hs),DA=n(Hs,"P",{});var VOe=s(DA);f1o=r(VOe,"This class cannot be instantiated directly using "),Wle=n(VOe,"CODE",{});var fnt=s(Wle);m1o=r(fnt,"__init__()"),fnt.forEach(t),g1o=r(VOe," (throws an error)."),VOe.forEach(t),h1o=i(Hs),nt=n(Hs,"DIV",{class:!0});var h0=s(nt);T(GA.$$.fragment,h0),p1o=i(h0),Qle=n(h0,"P",{});var mnt=s(Qle);u1o=r(mnt,"Instantiates one of the base model classes of the library from a configuration."),mnt.forEach(t),_1o=i(h0),Bi=n(h0,"P",{});var Iee=s(Bi);b1o=r(Iee,`Note:
Loading a model from its configuration file does `),Hle=n(Iee,"STRONG",{});var gnt=s(Hle);v1o=r(gnt,"not"),gnt.forEach(t),F1o=r(Iee,` load the model weights. It only affects the
model\u2019s configuration. Use `),SN=n(Iee,"A",{href:!0});var hnt=s(SN);T1o=r(hnt,"from_pretrained()"),hnt.forEach(t),M1o=r(Iee," to load the model weights."),Iee.forEach(t),E1o=i(h0),T(wp.$$.fragment,h0),h0.forEach(t),C1o=i(Hs),Je=n(Hs,"DIV",{class:!0});var aa=s(Je);T(OA.$$.fragment,aa),w1o=i(aa),Ule=n(aa,"P",{});var pnt=s(Ule);A1o=r(pnt,"Instantiate one of the base model classes of the library from a pretrained model."),pnt.forEach(t),y1o=i(aa),Sa=n(aa,"P",{});var p0=s(Sa);L1o=r(p0,"The model class to instantiate is selected based on the "),Jle=n(p0,"CODE",{});var unt=s(Jle);x1o=r(unt,"model_type"),unt.forEach(t),$1o=r(p0,` property of the config object (either
passed as an argument or loaded from `),Yle=n(p0,"CODE",{});var _nt=s(Yle);k1o=r(_nt,"pretrained_model_name_or_path"),_nt.forEach(t),S1o=r(p0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kle=n(p0,"CODE",{});var bnt=s(Kle);R1o=r(bnt,"pretrained_model_name_or_path"),bnt.forEach(t),P1o=r(p0,":"),p0.forEach(t),B1o=i(aa),x=n(aa,"UL",{});var $=s(x);Ap=n($,"LI",{});var QAe=s(Ap);Zle=n(QAe,"STRONG",{});var vnt=s(Zle);I1o=r(vnt,"albert"),vnt.forEach(t),N1o=r(QAe," \u2014 "),RN=n(QAe,"A",{href:!0});var Fnt=s(RN);q1o=r(Fnt,"AlbertModel"),Fnt.forEach(t),j1o=r(QAe," (ALBERT model)"),QAe.forEach(t),D1o=i($),yp=n($,"LI",{});var HAe=s(yp);eie=n(HAe,"STRONG",{});var Tnt=s(eie);G1o=r(Tnt,"bart"),Tnt.forEach(t),O1o=r(HAe," \u2014 "),PN=n(HAe,"A",{href:!0});var Mnt=s(PN);V1o=r(Mnt,"BartModel"),Mnt.forEach(t),X1o=r(HAe," (BART model)"),HAe.forEach(t),z1o=i($),Lp=n($,"LI",{});var UAe=s(Lp);oie=n(UAe,"STRONG",{});var Ent=s(oie);W1o=r(Ent,"beit"),Ent.forEach(t),Q1o=r(UAe," \u2014 "),BN=n(UAe,"A",{href:!0});var Cnt=s(BN);H1o=r(Cnt,"BeitModel"),Cnt.forEach(t),U1o=r(UAe," (BEiT model)"),UAe.forEach(t),J1o=i($),xp=n($,"LI",{});var JAe=s(xp);rie=n(JAe,"STRONG",{});var wnt=s(rie);Y1o=r(wnt,"bert"),wnt.forEach(t),K1o=r(JAe," \u2014 "),IN=n(JAe,"A",{href:!0});var Ant=s(IN);Z1o=r(Ant,"BertModel"),Ant.forEach(t),ebo=r(JAe," (BERT model)"),JAe.forEach(t),obo=i($),$p=n($,"LI",{});var YAe=s($p);tie=n(YAe,"STRONG",{});var ynt=s(tie);rbo=r(ynt,"bert-generation"),ynt.forEach(t),tbo=r(YAe," \u2014 "),NN=n(YAe,"A",{href:!0});var Lnt=s(NN);abo=r(Lnt,"BertGenerationEncoder"),Lnt.forEach(t),nbo=r(YAe," (Bert Generation model)"),YAe.forEach(t),sbo=i($),kp=n($,"LI",{});var KAe=s(kp);aie=n(KAe,"STRONG",{});var xnt=s(aie);lbo=r(xnt,"big_bird"),xnt.forEach(t),ibo=r(KAe," \u2014 "),qN=n(KAe,"A",{href:!0});var $nt=s(qN);dbo=r($nt,"BigBirdModel"),$nt.forEach(t),cbo=r(KAe," (BigBird model)"),KAe.forEach(t),fbo=i($),Sp=n($,"LI",{});var ZAe=s(Sp);nie=n(ZAe,"STRONG",{});var knt=s(nie);mbo=r(knt,"bigbird_pegasus"),knt.forEach(t),gbo=r(ZAe," \u2014 "),jN=n(ZAe,"A",{href:!0});var Snt=s(jN);hbo=r(Snt,"BigBirdPegasusModel"),Snt.forEach(t),pbo=r(ZAe," (BigBird-Pegasus model)"),ZAe.forEach(t),ubo=i($),Rp=n($,"LI",{});var eye=s(Rp);sie=n(eye,"STRONG",{});var Rnt=s(sie);_bo=r(Rnt,"blenderbot"),Rnt.forEach(t),bbo=r(eye," \u2014 "),DN=n(eye,"A",{href:!0});var Pnt=s(DN);vbo=r(Pnt,"BlenderbotModel"),Pnt.forEach(t),Fbo=r(eye," (Blenderbot model)"),eye.forEach(t),Tbo=i($),Pp=n($,"LI",{});var oye=s(Pp);lie=n(oye,"STRONG",{});var Bnt=s(lie);Mbo=r(Bnt,"blenderbot-small"),Bnt.forEach(t),Ebo=r(oye," \u2014 "),GN=n(oye,"A",{href:!0});var Int=s(GN);Cbo=r(Int,"BlenderbotSmallModel"),Int.forEach(t),wbo=r(oye," (BlenderbotSmall model)"),oye.forEach(t),Abo=i($),Bp=n($,"LI",{});var rye=s(Bp);iie=n(rye,"STRONG",{});var Nnt=s(iie);ybo=r(Nnt,"bloom"),Nnt.forEach(t),Lbo=r(rye," \u2014 "),ON=n(rye,"A",{href:!0});var qnt=s(ON);xbo=r(qnt,"BloomModel"),qnt.forEach(t),$bo=r(rye," (BLOOM model)"),rye.forEach(t),kbo=i($),Ip=n($,"LI",{});var tye=s(Ip);die=n(tye,"STRONG",{});var jnt=s(die);Sbo=r(jnt,"camembert"),jnt.forEach(t),Rbo=r(tye," \u2014 "),VN=n(tye,"A",{href:!0});var Dnt=s(VN);Pbo=r(Dnt,"CamembertModel"),Dnt.forEach(t),Bbo=r(tye," (CamemBERT model)"),tye.forEach(t),Ibo=i($),Np=n($,"LI",{});var aye=s(Np);cie=n(aye,"STRONG",{});var Gnt=s(cie);Nbo=r(Gnt,"canine"),Gnt.forEach(t),qbo=r(aye," \u2014 "),XN=n(aye,"A",{href:!0});var Ont=s(XN);jbo=r(Ont,"CanineModel"),Ont.forEach(t),Dbo=r(aye," (CANINE model)"),aye.forEach(t),Gbo=i($),qp=n($,"LI",{});var nye=s(qp);fie=n(nye,"STRONG",{});var Vnt=s(fie);Obo=r(Vnt,"clip"),Vnt.forEach(t),Vbo=r(nye," \u2014 "),zN=n(nye,"A",{href:!0});var Xnt=s(zN);Xbo=r(Xnt,"CLIPModel"),Xnt.forEach(t),zbo=r(nye," (CLIP model)"),nye.forEach(t),Wbo=i($),jp=n($,"LI",{});var sye=s(jp);mie=n(sye,"STRONG",{});var znt=s(mie);Qbo=r(znt,"convbert"),znt.forEach(t),Hbo=r(sye," \u2014 "),WN=n(sye,"A",{href:!0});var Wnt=s(WN);Ubo=r(Wnt,"ConvBertModel"),Wnt.forEach(t),Jbo=r(sye," (ConvBERT model)"),sye.forEach(t),Ybo=i($),Dp=n($,"LI",{});var lye=s(Dp);gie=n(lye,"STRONG",{});var Qnt=s(gie);Kbo=r(Qnt,"convnext"),Qnt.forEach(t),Zbo=r(lye," \u2014 "),QN=n(lye,"A",{href:!0});var Hnt=s(QN);e2o=r(Hnt,"ConvNextModel"),Hnt.forEach(t),o2o=r(lye," (ConvNeXT model)"),lye.forEach(t),r2o=i($),Gp=n($,"LI",{});var iye=s(Gp);hie=n(iye,"STRONG",{});var Unt=s(hie);t2o=r(Unt,"ctrl"),Unt.forEach(t),a2o=r(iye," \u2014 "),HN=n(iye,"A",{href:!0});var Jnt=s(HN);n2o=r(Jnt,"CTRLModel"),Jnt.forEach(t),s2o=r(iye," (CTRL model)"),iye.forEach(t),l2o=i($),Op=n($,"LI",{});var dye=s(Op);pie=n(dye,"STRONG",{});var Ynt=s(pie);i2o=r(Ynt,"cvt"),Ynt.forEach(t),d2o=r(dye," \u2014 "),UN=n(dye,"A",{href:!0});var Knt=s(UN);c2o=r(Knt,"CvtModel"),Knt.forEach(t),f2o=r(dye," (CvT model)"),dye.forEach(t),m2o=i($),Vp=n($,"LI",{});var cye=s(Vp);uie=n(cye,"STRONG",{});var Znt=s(uie);g2o=r(Znt,"data2vec-audio"),Znt.forEach(t),h2o=r(cye," \u2014 "),JN=n(cye,"A",{href:!0});var est=s(JN);p2o=r(est,"Data2VecAudioModel"),est.forEach(t),u2o=r(cye," (Data2VecAudio model)"),cye.forEach(t),_2o=i($),Xp=n($,"LI",{});var fye=s(Xp);_ie=n(fye,"STRONG",{});var ost=s(_ie);b2o=r(ost,"data2vec-text"),ost.forEach(t),v2o=r(fye," \u2014 "),YN=n(fye,"A",{href:!0});var rst=s(YN);F2o=r(rst,"Data2VecTextModel"),rst.forEach(t),T2o=r(fye," (Data2VecText model)"),fye.forEach(t),M2o=i($),zp=n($,"LI",{});var mye=s(zp);bie=n(mye,"STRONG",{});var tst=s(bie);E2o=r(tst,"data2vec-vision"),tst.forEach(t),C2o=r(mye," \u2014 "),KN=n(mye,"A",{href:!0});var ast=s(KN);w2o=r(ast,"Data2VecVisionModel"),ast.forEach(t),A2o=r(mye," (Data2VecVision model)"),mye.forEach(t),y2o=i($),Wp=n($,"LI",{});var gye=s(Wp);vie=n(gye,"STRONG",{});var nst=s(vie);L2o=r(nst,"deberta"),nst.forEach(t),x2o=r(gye," \u2014 "),ZN=n(gye,"A",{href:!0});var sst=s(ZN);$2o=r(sst,"DebertaModel"),sst.forEach(t),k2o=r(gye," (DeBERTa model)"),gye.forEach(t),S2o=i($),Qp=n($,"LI",{});var hye=s(Qp);Fie=n(hye,"STRONG",{});var lst=s(Fie);R2o=r(lst,"deberta-v2"),lst.forEach(t),P2o=r(hye," \u2014 "),eq=n(hye,"A",{href:!0});var ist=s(eq);B2o=r(ist,"DebertaV2Model"),ist.forEach(t),I2o=r(hye," (DeBERTa-v2 model)"),hye.forEach(t),N2o=i($),Hp=n($,"LI",{});var pye=s(Hp);Tie=n(pye,"STRONG",{});var dst=s(Tie);q2o=r(dst,"decision_transformer"),dst.forEach(t),j2o=r(pye," \u2014 "),oq=n(pye,"A",{href:!0});var cst=s(oq);D2o=r(cst,"DecisionTransformerModel"),cst.forEach(t),G2o=r(pye," (Decision Transformer model)"),pye.forEach(t),O2o=i($),Up=n($,"LI",{});var uye=s(Up);Mie=n(uye,"STRONG",{});var fst=s(Mie);V2o=r(fst,"deit"),fst.forEach(t),X2o=r(uye," \u2014 "),rq=n(uye,"A",{href:!0});var mst=s(rq);z2o=r(mst,"DeiTModel"),mst.forEach(t),W2o=r(uye," (DeiT model)"),uye.forEach(t),Q2o=i($),Jp=n($,"LI",{});var _ye=s(Jp);Eie=n(_ye,"STRONG",{});var gst=s(Eie);H2o=r(gst,"detr"),gst.forEach(t),U2o=r(_ye," \u2014 "),tq=n(_ye,"A",{href:!0});var hst=s(tq);J2o=r(hst,"DetrModel"),hst.forEach(t),Y2o=r(_ye," (DETR model)"),_ye.forEach(t),K2o=i($),Yp=n($,"LI",{});var bye=s(Yp);Cie=n(bye,"STRONG",{});var pst=s(Cie);Z2o=r(pst,"distilbert"),pst.forEach(t),evo=r(bye," \u2014 "),aq=n(bye,"A",{href:!0});var ust=s(aq);ovo=r(ust,"DistilBertModel"),ust.forEach(t),rvo=r(bye," (DistilBERT model)"),bye.forEach(t),tvo=i($),Kp=n($,"LI",{});var vye=s(Kp);wie=n(vye,"STRONG",{});var _st=s(wie);avo=r(_st,"dpr"),_st.forEach(t),nvo=r(vye," \u2014 "),nq=n(vye,"A",{href:!0});var bst=s(nq);svo=r(bst,"DPRQuestionEncoder"),bst.forEach(t),lvo=r(vye," (DPR model)"),vye.forEach(t),ivo=i($),Zp=n($,"LI",{});var Fye=s(Zp);Aie=n(Fye,"STRONG",{});var vst=s(Aie);dvo=r(vst,"dpt"),vst.forEach(t),cvo=r(Fye," \u2014 "),sq=n(Fye,"A",{href:!0});var Fst=s(sq);fvo=r(Fst,"DPTModel"),Fst.forEach(t),mvo=r(Fye," (DPT model)"),Fye.forEach(t),gvo=i($),eu=n($,"LI",{});var Tye=s(eu);yie=n(Tye,"STRONG",{});var Tst=s(yie);hvo=r(Tst,"electra"),Tst.forEach(t),pvo=r(Tye," \u2014 "),lq=n(Tye,"A",{href:!0});var Mst=s(lq);uvo=r(Mst,"ElectraModel"),Mst.forEach(t),_vo=r(Tye," (ELECTRA model)"),Tye.forEach(t),bvo=i($),ou=n($,"LI",{});var Mye=s(ou);Lie=n(Mye,"STRONG",{});var Est=s(Lie);vvo=r(Est,"flaubert"),Est.forEach(t),Fvo=r(Mye," \u2014 "),iq=n(Mye,"A",{href:!0});var Cst=s(iq);Tvo=r(Cst,"FlaubertModel"),Cst.forEach(t),Mvo=r(Mye," (FlauBERT model)"),Mye.forEach(t),Evo=i($),ru=n($,"LI",{});var Eye=s(ru);xie=n(Eye,"STRONG",{});var wst=s(xie);Cvo=r(wst,"flava"),wst.forEach(t),wvo=r(Eye," \u2014 "),dq=n(Eye,"A",{href:!0});var Ast=s(dq);Avo=r(Ast,"FlavaModel"),Ast.forEach(t),yvo=r(Eye," (FLAVA model)"),Eye.forEach(t),Lvo=i($),tu=n($,"LI",{});var Cye=s(tu);$ie=n(Cye,"STRONG",{});var yst=s($ie);xvo=r(yst,"fnet"),yst.forEach(t),$vo=r(Cye," \u2014 "),cq=n(Cye,"A",{href:!0});var Lst=s(cq);kvo=r(Lst,"FNetModel"),Lst.forEach(t),Svo=r(Cye," (FNet model)"),Cye.forEach(t),Rvo=i($),au=n($,"LI",{});var wye=s(au);kie=n(wye,"STRONG",{});var xst=s(kie);Pvo=r(xst,"fsmt"),xst.forEach(t),Bvo=r(wye," \u2014 "),fq=n(wye,"A",{href:!0});var $st=s(fq);Ivo=r($st,"FSMTModel"),$st.forEach(t),Nvo=r(wye," (FairSeq Machine-Translation model)"),wye.forEach(t),qvo=i($),Ds=n($,"LI",{});var Rk=s(Ds);Sie=n(Rk,"STRONG",{});var kst=s(Sie);jvo=r(kst,"funnel"),kst.forEach(t),Dvo=r(Rk," \u2014 "),mq=n(Rk,"A",{href:!0});var Sst=s(mq);Gvo=r(Sst,"FunnelModel"),Sst.forEach(t),Ovo=r(Rk," or "),gq=n(Rk,"A",{href:!0});var Rst=s(gq);Vvo=r(Rst,"FunnelBaseModel"),Rst.forEach(t),Xvo=r(Rk," (Funnel Transformer model)"),Rk.forEach(t),zvo=i($),nu=n($,"LI",{});var Aye=s(nu);Rie=n(Aye,"STRONG",{});var Pst=s(Rie);Wvo=r(Pst,"glpn"),Pst.forEach(t),Qvo=r(Aye," \u2014 "),hq=n(Aye,"A",{href:!0});var Bst=s(hq);Hvo=r(Bst,"GLPNModel"),Bst.forEach(t),Uvo=r(Aye," (GLPN model)"),Aye.forEach(t),Jvo=i($),su=n($,"LI",{});var yye=s(su);Pie=n(yye,"STRONG",{});var Ist=s(Pie);Yvo=r(Ist,"gpt2"),Ist.forEach(t),Kvo=r(yye," \u2014 "),pq=n(yye,"A",{href:!0});var Nst=s(pq);Zvo=r(Nst,"GPT2Model"),Nst.forEach(t),e3o=r(yye," (OpenAI GPT-2 model)"),yye.forEach(t),o3o=i($),lu=n($,"LI",{});var Lye=s(lu);Bie=n(Lye,"STRONG",{});var qst=s(Bie);r3o=r(qst,"gpt_neo"),qst.forEach(t),t3o=r(Lye," \u2014 "),uq=n(Lye,"A",{href:!0});var jst=s(uq);a3o=r(jst,"GPTNeoModel"),jst.forEach(t),n3o=r(Lye," (GPT Neo model)"),Lye.forEach(t),s3o=i($),iu=n($,"LI",{});var xye=s(iu);Iie=n(xye,"STRONG",{});var Dst=s(Iie);l3o=r(Dst,"gpt_neox"),Dst.forEach(t),i3o=r(xye," \u2014 "),_q=n(xye,"A",{href:!0});var Gst=s(_q);d3o=r(Gst,"GPTNeoXModel"),Gst.forEach(t),c3o=r(xye," (GPT NeoX model)"),xye.forEach(t),f3o=i($),du=n($,"LI",{});var $ye=s(du);Nie=n($ye,"STRONG",{});var Ost=s(Nie);m3o=r(Ost,"gptj"),Ost.forEach(t),g3o=r($ye," \u2014 "),bq=n($ye,"A",{href:!0});var Vst=s(bq);h3o=r(Vst,"GPTJModel"),Vst.forEach(t),p3o=r($ye," (GPT-J model)"),$ye.forEach(t),u3o=i($),cu=n($,"LI",{});var kye=s(cu);qie=n(kye,"STRONG",{});var Xst=s(qie);_3o=r(Xst,"hubert"),Xst.forEach(t),b3o=r(kye," \u2014 "),vq=n(kye,"A",{href:!0});var zst=s(vq);v3o=r(zst,"HubertModel"),zst.forEach(t),F3o=r(kye," (Hubert model)"),kye.forEach(t),T3o=i($),fu=n($,"LI",{});var Sye=s(fu);jie=n(Sye,"STRONG",{});var Wst=s(jie);M3o=r(Wst,"ibert"),Wst.forEach(t),E3o=r(Sye," \u2014 "),Fq=n(Sye,"A",{href:!0});var Qst=s(Fq);C3o=r(Qst,"IBertModel"),Qst.forEach(t),w3o=r(Sye," (I-BERT model)"),Sye.forEach(t),A3o=i($),mu=n($,"LI",{});var Rye=s(mu);Die=n(Rye,"STRONG",{});var Hst=s(Die);y3o=r(Hst,"imagegpt"),Hst.forEach(t),L3o=r(Rye," \u2014 "),Tq=n(Rye,"A",{href:!0});var Ust=s(Tq);x3o=r(Ust,"ImageGPTModel"),Ust.forEach(t),$3o=r(Rye," (ImageGPT model)"),Rye.forEach(t),k3o=i($),gu=n($,"LI",{});var Pye=s(gu);Gie=n(Pye,"STRONG",{});var Jst=s(Gie);S3o=r(Jst,"layoutlm"),Jst.forEach(t),R3o=r(Pye," \u2014 "),Mq=n(Pye,"A",{href:!0});var Yst=s(Mq);P3o=r(Yst,"LayoutLMModel"),Yst.forEach(t),B3o=r(Pye," (LayoutLM model)"),Pye.forEach(t),I3o=i($),hu=n($,"LI",{});var Bye=s(hu);Oie=n(Bye,"STRONG",{});var Kst=s(Oie);N3o=r(Kst,"layoutlmv2"),Kst.forEach(t),q3o=r(Bye," \u2014 "),Eq=n(Bye,"A",{href:!0});var Zst=s(Eq);j3o=r(Zst,"LayoutLMv2Model"),Zst.forEach(t),D3o=r(Bye," (LayoutLMv2 model)"),Bye.forEach(t),G3o=i($),pu=n($,"LI",{});var Iye=s(pu);Vie=n(Iye,"STRONG",{});var elt=s(Vie);O3o=r(elt,"layoutlmv3"),elt.forEach(t),V3o=r(Iye," \u2014 "),Cq=n(Iye,"A",{href:!0});var olt=s(Cq);X3o=r(olt,"LayoutLMv3Model"),olt.forEach(t),z3o=r(Iye," (LayoutLMv3 model)"),Iye.forEach(t),W3o=i($),uu=n($,"LI",{});var Nye=s(uu);Xie=n(Nye,"STRONG",{});var rlt=s(Xie);Q3o=r(rlt,"led"),rlt.forEach(t),H3o=r(Nye," \u2014 "),wq=n(Nye,"A",{href:!0});var tlt=s(wq);U3o=r(tlt,"LEDModel"),tlt.forEach(t),J3o=r(Nye," (LED model)"),Nye.forEach(t),Y3o=i($),_u=n($,"LI",{});var qye=s(_u);zie=n(qye,"STRONG",{});var alt=s(zie);K3o=r(alt,"levit"),alt.forEach(t),Z3o=r(qye," \u2014 "),Aq=n(qye,"A",{href:!0});var nlt=s(Aq);eFo=r(nlt,"LevitModel"),nlt.forEach(t),oFo=r(qye," (LeViT model)"),qye.forEach(t),rFo=i($),bu=n($,"LI",{});var jye=s(bu);Wie=n(jye,"STRONG",{});var slt=s(Wie);tFo=r(slt,"longformer"),slt.forEach(t),aFo=r(jye," \u2014 "),yq=n(jye,"A",{href:!0});var llt=s(yq);nFo=r(llt,"LongformerModel"),llt.forEach(t),sFo=r(jye," (Longformer model)"),jye.forEach(t),lFo=i($),vu=n($,"LI",{});var Dye=s(vu);Qie=n(Dye,"STRONG",{});var ilt=s(Qie);iFo=r(ilt,"luke"),ilt.forEach(t),dFo=r(Dye," \u2014 "),Lq=n(Dye,"A",{href:!0});var dlt=s(Lq);cFo=r(dlt,"LukeModel"),dlt.forEach(t),fFo=r(Dye," (LUKE model)"),Dye.forEach(t),mFo=i($),Fu=n($,"LI",{});var Gye=s(Fu);Hie=n(Gye,"STRONG",{});var clt=s(Hie);gFo=r(clt,"lxmert"),clt.forEach(t),hFo=r(Gye," \u2014 "),xq=n(Gye,"A",{href:!0});var flt=s(xq);pFo=r(flt,"LxmertModel"),flt.forEach(t),uFo=r(Gye," (LXMERT model)"),Gye.forEach(t),_Fo=i($),Tu=n($,"LI",{});var Oye=s(Tu);Uie=n(Oye,"STRONG",{});var mlt=s(Uie);bFo=r(mlt,"m2m_100"),mlt.forEach(t),vFo=r(Oye," \u2014 "),$q=n(Oye,"A",{href:!0});var glt=s($q);FFo=r(glt,"M2M100Model"),glt.forEach(t),TFo=r(Oye," (M2M100 model)"),Oye.forEach(t),MFo=i($),Mu=n($,"LI",{});var Vye=s(Mu);Jie=n(Vye,"STRONG",{});var hlt=s(Jie);EFo=r(hlt,"marian"),hlt.forEach(t),CFo=r(Vye," \u2014 "),kq=n(Vye,"A",{href:!0});var plt=s(kq);wFo=r(plt,"MarianModel"),plt.forEach(t),AFo=r(Vye," (Marian model)"),Vye.forEach(t),yFo=i($),Eu=n($,"LI",{});var Xye=s(Eu);Yie=n(Xye,"STRONG",{});var ult=s(Yie);LFo=r(ult,"maskformer"),ult.forEach(t),xFo=r(Xye," \u2014 "),Sq=n(Xye,"A",{href:!0});var _lt=s(Sq);$Fo=r(_lt,"MaskFormerModel"),_lt.forEach(t),kFo=r(Xye," (MaskFormer model)"),Xye.forEach(t),SFo=i($),Cu=n($,"LI",{});var zye=s(Cu);Kie=n(zye,"STRONG",{});var blt=s(Kie);RFo=r(blt,"mbart"),blt.forEach(t),PFo=r(zye," \u2014 "),Rq=n(zye,"A",{href:!0});var vlt=s(Rq);BFo=r(vlt,"MBartModel"),vlt.forEach(t),IFo=r(zye," (mBART model)"),zye.forEach(t),NFo=i($),wu=n($,"LI",{});var Wye=s(wu);Zie=n(Wye,"STRONG",{});var Flt=s(Zie);qFo=r(Flt,"mctct"),Flt.forEach(t),jFo=r(Wye," \u2014 "),Pq=n(Wye,"A",{href:!0});var Tlt=s(Pq);DFo=r(Tlt,"MCTCTModel"),Tlt.forEach(t),GFo=r(Wye," (M-CTC-T model)"),Wye.forEach(t),OFo=i($),Au=n($,"LI",{});var Qye=s(Au);ede=n(Qye,"STRONG",{});var Mlt=s(ede);VFo=r(Mlt,"megatron-bert"),Mlt.forEach(t),XFo=r(Qye," \u2014 "),Bq=n(Qye,"A",{href:!0});var Elt=s(Bq);zFo=r(Elt,"MegatronBertModel"),Elt.forEach(t),WFo=r(Qye," (Megatron-BERT model)"),Qye.forEach(t),QFo=i($),yu=n($,"LI",{});var Hye=s(yu);ode=n(Hye,"STRONG",{});var Clt=s(ode);HFo=r(Clt,"mobilebert"),Clt.forEach(t),UFo=r(Hye," \u2014 "),Iq=n(Hye,"A",{href:!0});var wlt=s(Iq);JFo=r(wlt,"MobileBertModel"),wlt.forEach(t),YFo=r(Hye," (MobileBERT model)"),Hye.forEach(t),KFo=i($),Lu=n($,"LI",{});var Uye=s(Lu);rde=n(Uye,"STRONG",{});var Alt=s(rde);ZFo=r(Alt,"mpnet"),Alt.forEach(t),e6o=r(Uye," \u2014 "),Nq=n(Uye,"A",{href:!0});var ylt=s(Nq);o6o=r(ylt,"MPNetModel"),ylt.forEach(t),r6o=r(Uye," (MPNet model)"),Uye.forEach(t),t6o=i($),xu=n($,"LI",{});var Jye=s(xu);tde=n(Jye,"STRONG",{});var Llt=s(tde);a6o=r(Llt,"mt5"),Llt.forEach(t),n6o=r(Jye," \u2014 "),qq=n(Jye,"A",{href:!0});var xlt=s(qq);s6o=r(xlt,"MT5Model"),xlt.forEach(t),l6o=r(Jye," (MT5 model)"),Jye.forEach(t),i6o=i($),$u=n($,"LI",{});var Yye=s($u);ade=n(Yye,"STRONG",{});var $lt=s(ade);d6o=r($lt,"nystromformer"),$lt.forEach(t),c6o=r(Yye," \u2014 "),jq=n(Yye,"A",{href:!0});var klt=s(jq);f6o=r(klt,"NystromformerModel"),klt.forEach(t),m6o=r(Yye," (Nystr\xF6mformer model)"),Yye.forEach(t),g6o=i($),ku=n($,"LI",{});var Kye=s(ku);nde=n(Kye,"STRONG",{});var Slt=s(nde);h6o=r(Slt,"openai-gpt"),Slt.forEach(t),p6o=r(Kye," \u2014 "),Dq=n(Kye,"A",{href:!0});var Rlt=s(Dq);u6o=r(Rlt,"OpenAIGPTModel"),Rlt.forEach(t),_6o=r(Kye," (OpenAI GPT model)"),Kye.forEach(t),b6o=i($),Su=n($,"LI",{});var Zye=s(Su);sde=n(Zye,"STRONG",{});var Plt=s(sde);v6o=r(Plt,"opt"),Plt.forEach(t),F6o=r(Zye," \u2014 "),Gq=n(Zye,"A",{href:!0});var Blt=s(Gq);T6o=r(Blt,"OPTModel"),Blt.forEach(t),M6o=r(Zye," (OPT model)"),Zye.forEach(t),E6o=i($),Ru=n($,"LI",{});var eLe=s(Ru);lde=n(eLe,"STRONG",{});var Ilt=s(lde);C6o=r(Ilt,"pegasus"),Ilt.forEach(t),w6o=r(eLe," \u2014 "),Oq=n(eLe,"A",{href:!0});var Nlt=s(Oq);A6o=r(Nlt,"PegasusModel"),Nlt.forEach(t),y6o=r(eLe," (Pegasus model)"),eLe.forEach(t),L6o=i($),Pu=n($,"LI",{});var oLe=s(Pu);ide=n(oLe,"STRONG",{});var qlt=s(ide);x6o=r(qlt,"perceiver"),qlt.forEach(t),$6o=r(oLe," \u2014 "),Vq=n(oLe,"A",{href:!0});var jlt=s(Vq);k6o=r(jlt,"PerceiverModel"),jlt.forEach(t),S6o=r(oLe," (Perceiver model)"),oLe.forEach(t),R6o=i($),Bu=n($,"LI",{});var rLe=s(Bu);dde=n(rLe,"STRONG",{});var Dlt=s(dde);P6o=r(Dlt,"plbart"),Dlt.forEach(t),B6o=r(rLe," \u2014 "),Xq=n(rLe,"A",{href:!0});var Glt=s(Xq);I6o=r(Glt,"PLBartModel"),Glt.forEach(t),N6o=r(rLe," (PLBart model)"),rLe.forEach(t),q6o=i($),Iu=n($,"LI",{});var tLe=s(Iu);cde=n(tLe,"STRONG",{});var Olt=s(cde);j6o=r(Olt,"poolformer"),Olt.forEach(t),D6o=r(tLe," \u2014 "),zq=n(tLe,"A",{href:!0});var Vlt=s(zq);G6o=r(Vlt,"PoolFormerModel"),Vlt.forEach(t),O6o=r(tLe," (PoolFormer model)"),tLe.forEach(t),V6o=i($),Nu=n($,"LI",{});var aLe=s(Nu);fde=n(aLe,"STRONG",{});var Xlt=s(fde);X6o=r(Xlt,"prophetnet"),Xlt.forEach(t),z6o=r(aLe," \u2014 "),Wq=n(aLe,"A",{href:!0});var zlt=s(Wq);W6o=r(zlt,"ProphetNetModel"),zlt.forEach(t),Q6o=r(aLe," (ProphetNet model)"),aLe.forEach(t),H6o=i($),qu=n($,"LI",{});var nLe=s(qu);mde=n(nLe,"STRONG",{});var Wlt=s(mde);U6o=r(Wlt,"qdqbert"),Wlt.forEach(t),J6o=r(nLe," \u2014 "),Qq=n(nLe,"A",{href:!0});var Qlt=s(Qq);Y6o=r(Qlt,"QDQBertModel"),Qlt.forEach(t),K6o=r(nLe," (QDQBert model)"),nLe.forEach(t),Z6o=i($),ju=n($,"LI",{});var sLe=s(ju);gde=n(sLe,"STRONG",{});var Hlt=s(gde);eTo=r(Hlt,"reformer"),Hlt.forEach(t),oTo=r(sLe," \u2014 "),Hq=n(sLe,"A",{href:!0});var Ult=s(Hq);rTo=r(Ult,"ReformerModel"),Ult.forEach(t),tTo=r(sLe," (Reformer model)"),sLe.forEach(t),aTo=i($),Du=n($,"LI",{});var lLe=s(Du);hde=n(lLe,"STRONG",{});var Jlt=s(hde);nTo=r(Jlt,"regnet"),Jlt.forEach(t),sTo=r(lLe," \u2014 "),Uq=n(lLe,"A",{href:!0});var Ylt=s(Uq);lTo=r(Ylt,"RegNetModel"),Ylt.forEach(t),iTo=r(lLe," (RegNet model)"),lLe.forEach(t),dTo=i($),Gu=n($,"LI",{});var iLe=s(Gu);pde=n(iLe,"STRONG",{});var Klt=s(pde);cTo=r(Klt,"rembert"),Klt.forEach(t),fTo=r(iLe," \u2014 "),Jq=n(iLe,"A",{href:!0});var Zlt=s(Jq);mTo=r(Zlt,"RemBertModel"),Zlt.forEach(t),gTo=r(iLe," (RemBERT model)"),iLe.forEach(t),hTo=i($),Ou=n($,"LI",{});var dLe=s(Ou);ude=n(dLe,"STRONG",{});var eit=s(ude);pTo=r(eit,"resnet"),eit.forEach(t),uTo=r(dLe," \u2014 "),Yq=n(dLe,"A",{href:!0});var oit=s(Yq);_To=r(oit,"ResNetModel"),oit.forEach(t),bTo=r(dLe," (ResNet model)"),dLe.forEach(t),vTo=i($),Vu=n($,"LI",{});var cLe=s(Vu);_de=n(cLe,"STRONG",{});var rit=s(_de);FTo=r(rit,"retribert"),rit.forEach(t),TTo=r(cLe," \u2014 "),Kq=n(cLe,"A",{href:!0});var tit=s(Kq);MTo=r(tit,"RetriBertModel"),tit.forEach(t),ETo=r(cLe," (RetriBERT model)"),cLe.forEach(t),CTo=i($),Xu=n($,"LI",{});var fLe=s(Xu);bde=n(fLe,"STRONG",{});var ait=s(bde);wTo=r(ait,"roberta"),ait.forEach(t),ATo=r(fLe," \u2014 "),Zq=n(fLe,"A",{href:!0});var nit=s(Zq);yTo=r(nit,"RobertaModel"),nit.forEach(t),LTo=r(fLe," (RoBERTa model)"),fLe.forEach(t),xTo=i($),zu=n($,"LI",{});var mLe=s(zu);vde=n(mLe,"STRONG",{});var sit=s(vde);$To=r(sit,"roformer"),sit.forEach(t),kTo=r(mLe," \u2014 "),ej=n(mLe,"A",{href:!0});var lit=s(ej);STo=r(lit,"RoFormerModel"),lit.forEach(t),RTo=r(mLe," (RoFormer model)"),mLe.forEach(t),PTo=i($),Wu=n($,"LI",{});var gLe=s(Wu);Fde=n(gLe,"STRONG",{});var iit=s(Fde);BTo=r(iit,"segformer"),iit.forEach(t),ITo=r(gLe," \u2014 "),oj=n(gLe,"A",{href:!0});var dit=s(oj);NTo=r(dit,"SegformerModel"),dit.forEach(t),qTo=r(gLe," (SegFormer model)"),gLe.forEach(t),jTo=i($),Qu=n($,"LI",{});var hLe=s(Qu);Tde=n(hLe,"STRONG",{});var cit=s(Tde);DTo=r(cit,"sew"),cit.forEach(t),GTo=r(hLe," \u2014 "),rj=n(hLe,"A",{href:!0});var fit=s(rj);OTo=r(fit,"SEWModel"),fit.forEach(t),VTo=r(hLe," (SEW model)"),hLe.forEach(t),XTo=i($),Hu=n($,"LI",{});var pLe=s(Hu);Mde=n(pLe,"STRONG",{});var mit=s(Mde);zTo=r(mit,"sew-d"),mit.forEach(t),WTo=r(pLe," \u2014 "),tj=n(pLe,"A",{href:!0});var git=s(tj);QTo=r(git,"SEWDModel"),git.forEach(t),HTo=r(pLe," (SEW-D model)"),pLe.forEach(t),UTo=i($),Uu=n($,"LI",{});var uLe=s(Uu);Ede=n(uLe,"STRONG",{});var hit=s(Ede);JTo=r(hit,"speech_to_text"),hit.forEach(t),YTo=r(uLe," \u2014 "),aj=n(uLe,"A",{href:!0});var pit=s(aj);KTo=r(pit,"Speech2TextModel"),pit.forEach(t),ZTo=r(uLe," (Speech2Text model)"),uLe.forEach(t),e7o=i($),Ju=n($,"LI",{});var _Le=s(Ju);Cde=n(_Le,"STRONG",{});var uit=s(Cde);o7o=r(uit,"splinter"),uit.forEach(t),r7o=r(_Le," \u2014 "),nj=n(_Le,"A",{href:!0});var _it=s(nj);t7o=r(_it,"SplinterModel"),_it.forEach(t),a7o=r(_Le," (Splinter model)"),_Le.forEach(t),n7o=i($),Yu=n($,"LI",{});var bLe=s(Yu);wde=n(bLe,"STRONG",{});var bit=s(wde);s7o=r(bit,"squeezebert"),bit.forEach(t),l7o=r(bLe," \u2014 "),sj=n(bLe,"A",{href:!0});var vit=s(sj);i7o=r(vit,"SqueezeBertModel"),vit.forEach(t),d7o=r(bLe," (SqueezeBERT model)"),bLe.forEach(t),c7o=i($),Ku=n($,"LI",{});var vLe=s(Ku);Ade=n(vLe,"STRONG",{});var Fit=s(Ade);f7o=r(Fit,"swin"),Fit.forEach(t),m7o=r(vLe," \u2014 "),lj=n(vLe,"A",{href:!0});var Tit=s(lj);g7o=r(Tit,"SwinModel"),Tit.forEach(t),h7o=r(vLe," (Swin Transformer model)"),vLe.forEach(t),p7o=i($),Zu=n($,"LI",{});var FLe=s(Zu);yde=n(FLe,"STRONG",{});var Mit=s(yde);u7o=r(Mit,"t5"),Mit.forEach(t),_7o=r(FLe," \u2014 "),ij=n(FLe,"A",{href:!0});var Eit=s(ij);b7o=r(Eit,"T5Model"),Eit.forEach(t),v7o=r(FLe," (T5 model)"),FLe.forEach(t),F7o=i($),e_=n($,"LI",{});var TLe=s(e_);Lde=n(TLe,"STRONG",{});var Cit=s(Lde);T7o=r(Cit,"tapas"),Cit.forEach(t),M7o=r(TLe," \u2014 "),dj=n(TLe,"A",{href:!0});var wit=s(dj);E7o=r(wit,"TapasModel"),wit.forEach(t),C7o=r(TLe," (TAPAS model)"),TLe.forEach(t),w7o=i($),o_=n($,"LI",{});var MLe=s(o_);xde=n(MLe,"STRONG",{});var Ait=s(xde);A7o=r(Ait,"trajectory_transformer"),Ait.forEach(t),y7o=r(MLe," \u2014 "),cj=n(MLe,"A",{href:!0});var yit=s(cj);L7o=r(yit,"TrajectoryTransformerModel"),yit.forEach(t),x7o=r(MLe," (Trajectory Transformer model)"),MLe.forEach(t),$7o=i($),r_=n($,"LI",{});var ELe=s(r_);$de=n(ELe,"STRONG",{});var Lit=s($de);k7o=r(Lit,"transfo-xl"),Lit.forEach(t),S7o=r(ELe," \u2014 "),fj=n(ELe,"A",{href:!0});var xit=s(fj);R7o=r(xit,"TransfoXLModel"),xit.forEach(t),P7o=r(ELe," (Transformer-XL model)"),ELe.forEach(t),B7o=i($),t_=n($,"LI",{});var CLe=s(t_);kde=n(CLe,"STRONG",{});var $it=s(kde);I7o=r($it,"unispeech"),$it.forEach(t),N7o=r(CLe," \u2014 "),mj=n(CLe,"A",{href:!0});var kit=s(mj);q7o=r(kit,"UniSpeechModel"),kit.forEach(t),j7o=r(CLe," (UniSpeech model)"),CLe.forEach(t),D7o=i($),a_=n($,"LI",{});var wLe=s(a_);Sde=n(wLe,"STRONG",{});var Sit=s(Sde);G7o=r(Sit,"unispeech-sat"),Sit.forEach(t),O7o=r(wLe," \u2014 "),gj=n(wLe,"A",{href:!0});var Rit=s(gj);V7o=r(Rit,"UniSpeechSatModel"),Rit.forEach(t),X7o=r(wLe," (UniSpeechSat model)"),wLe.forEach(t),z7o=i($),n_=n($,"LI",{});var ALe=s(n_);Rde=n(ALe,"STRONG",{});var Pit=s(Rde);W7o=r(Pit,"van"),Pit.forEach(t),Q7o=r(ALe," \u2014 "),hj=n(ALe,"A",{href:!0});var Bit=s(hj);H7o=r(Bit,"VanModel"),Bit.forEach(t),U7o=r(ALe," (VAN model)"),ALe.forEach(t),J7o=i($),s_=n($,"LI",{});var yLe=s(s_);Pde=n(yLe,"STRONG",{});var Iit=s(Pde);Y7o=r(Iit,"vilt"),Iit.forEach(t),K7o=r(yLe," \u2014 "),pj=n(yLe,"A",{href:!0});var Nit=s(pj);Z7o=r(Nit,"ViltModel"),Nit.forEach(t),e9o=r(yLe," (ViLT model)"),yLe.forEach(t),o9o=i($),l_=n($,"LI",{});var LLe=s(l_);Bde=n(LLe,"STRONG",{});var qit=s(Bde);r9o=r(qit,"vision-text-dual-encoder"),qit.forEach(t),t9o=r(LLe," \u2014 "),uj=n(LLe,"A",{href:!0});var jit=s(uj);a9o=r(jit,"VisionTextDualEncoderModel"),jit.forEach(t),n9o=r(LLe," (VisionTextDualEncoder model)"),LLe.forEach(t),s9o=i($),i_=n($,"LI",{});var xLe=s(i_);Ide=n(xLe,"STRONG",{});var Dit=s(Ide);l9o=r(Dit,"visual_bert"),Dit.forEach(t),i9o=r(xLe," \u2014 "),_j=n(xLe,"A",{href:!0});var Git=s(_j);d9o=r(Git,"VisualBertModel"),Git.forEach(t),c9o=r(xLe," (VisualBERT model)"),xLe.forEach(t),f9o=i($),d_=n($,"LI",{});var $Le=s(d_);Nde=n($Le,"STRONG",{});var Oit=s(Nde);m9o=r(Oit,"vit"),Oit.forEach(t),g9o=r($Le," \u2014 "),bj=n($Le,"A",{href:!0});var Vit=s(bj);h9o=r(Vit,"ViTModel"),Vit.forEach(t),p9o=r($Le," (ViT model)"),$Le.forEach(t),u9o=i($),c_=n($,"LI",{});var kLe=s(c_);qde=n(kLe,"STRONG",{});var Xit=s(qde);_9o=r(Xit,"vit_mae"),Xit.forEach(t),b9o=r(kLe," \u2014 "),vj=n(kLe,"A",{href:!0});var zit=s(vj);v9o=r(zit,"ViTMAEModel"),zit.forEach(t),F9o=r(kLe," (ViTMAE model)"),kLe.forEach(t),T9o=i($),f_=n($,"LI",{});var SLe=s(f_);jde=n(SLe,"STRONG",{});var Wit=s(jde);M9o=r(Wit,"wav2vec2"),Wit.forEach(t),E9o=r(SLe," \u2014 "),Fj=n(SLe,"A",{href:!0});var Qit=s(Fj);C9o=r(Qit,"Wav2Vec2Model"),Qit.forEach(t),w9o=r(SLe," (Wav2Vec2 model)"),SLe.forEach(t),A9o=i($),m_=n($,"LI",{});var RLe=s(m_);Dde=n(RLe,"STRONG",{});var Hit=s(Dde);y9o=r(Hit,"wav2vec2-conformer"),Hit.forEach(t),L9o=r(RLe," \u2014 "),Tj=n(RLe,"A",{href:!0});var Uit=s(Tj);x9o=r(Uit,"Wav2Vec2ConformerModel"),Uit.forEach(t),$9o=r(RLe," (Wav2Vec2-Conformer model)"),RLe.forEach(t),k9o=i($),g_=n($,"LI",{});var PLe=s(g_);Gde=n(PLe,"STRONG",{});var Jit=s(Gde);S9o=r(Jit,"wavlm"),Jit.forEach(t),R9o=r(PLe," \u2014 "),Mj=n(PLe,"A",{href:!0});var Yit=s(Mj);P9o=r(Yit,"WavLMModel"),Yit.forEach(t),B9o=r(PLe," (WavLM model)"),PLe.forEach(t),I9o=i($),h_=n($,"LI",{});var BLe=s(h_);Ode=n(BLe,"STRONG",{});var Kit=s(Ode);N9o=r(Kit,"xglm"),Kit.forEach(t),q9o=r(BLe," \u2014 "),Ej=n(BLe,"A",{href:!0});var Zit=s(Ej);j9o=r(Zit,"XGLMModel"),Zit.forEach(t),D9o=r(BLe," (XGLM model)"),BLe.forEach(t),G9o=i($),p_=n($,"LI",{});var ILe=s(p_);Vde=n(ILe,"STRONG",{});var edt=s(Vde);O9o=r(edt,"xlm"),edt.forEach(t),V9o=r(ILe," \u2014 "),Cj=n(ILe,"A",{href:!0});var odt=s(Cj);X9o=r(odt,"XLMModel"),odt.forEach(t),z9o=r(ILe," (XLM model)"),ILe.forEach(t),W9o=i($),u_=n($,"LI",{});var NLe=s(u_);Xde=n(NLe,"STRONG",{});var rdt=s(Xde);Q9o=r(rdt,"xlm-prophetnet"),rdt.forEach(t),H9o=r(NLe," \u2014 "),wj=n(NLe,"A",{href:!0});var tdt=s(wj);U9o=r(tdt,"XLMProphetNetModel"),tdt.forEach(t),J9o=r(NLe," (XLM-ProphetNet model)"),NLe.forEach(t),Y9o=i($),__=n($,"LI",{});var qLe=s(__);zde=n(qLe,"STRONG",{});var adt=s(zde);K9o=r(adt,"xlm-roberta"),adt.forEach(t),Z9o=r(qLe," \u2014 "),Aj=n(qLe,"A",{href:!0});var ndt=s(Aj);eMo=r(ndt,"XLMRobertaModel"),ndt.forEach(t),oMo=r(qLe," (XLM-RoBERTa model)"),qLe.forEach(t),rMo=i($),b_=n($,"LI",{});var jLe=s(b_);Wde=n(jLe,"STRONG",{});var sdt=s(Wde);tMo=r(sdt,"xlm-roberta-xl"),sdt.forEach(t),aMo=r(jLe," \u2014 "),yj=n(jLe,"A",{href:!0});var ldt=s(yj);nMo=r(ldt,"XLMRobertaXLModel"),ldt.forEach(t),sMo=r(jLe," (XLM-RoBERTa-XL model)"),jLe.forEach(t),lMo=i($),v_=n($,"LI",{});var DLe=s(v_);Qde=n(DLe,"STRONG",{});var idt=s(Qde);iMo=r(idt,"xlnet"),idt.forEach(t),dMo=r(DLe," \u2014 "),Lj=n(DLe,"A",{href:!0});var ddt=s(Lj);cMo=r(ddt,"XLNetModel"),ddt.forEach(t),fMo=r(DLe," (XLNet model)"),DLe.forEach(t),mMo=i($),F_=n($,"LI",{});var GLe=s(F_);Hde=n(GLe,"STRONG",{});var cdt=s(Hde);gMo=r(cdt,"yolos"),cdt.forEach(t),hMo=r(GLe," \u2014 "),xj=n(GLe,"A",{href:!0});var fdt=s(xj);pMo=r(fdt,"YolosModel"),fdt.forEach(t),uMo=r(GLe," (YOLOS model)"),GLe.forEach(t),_Mo=i($),T_=n($,"LI",{});var OLe=s(T_);Ude=n(OLe,"STRONG",{});var mdt=s(Ude);bMo=r(mdt,"yoso"),mdt.forEach(t),vMo=r(OLe," \u2014 "),$j=n(OLe,"A",{href:!0});var gdt=s($j);FMo=r(gdt,"YosoModel"),gdt.forEach(t),TMo=r(OLe," (YOSO model)"),OLe.forEach(t),$.forEach(t),MMo=i(aa),M_=n(aa,"P",{});var VLe=s(M_);EMo=r(VLe,"The model is set in evaluation mode by default using "),Jde=n(VLe,"CODE",{});var hdt=s(Jde);CMo=r(hdt,"model.eval()"),hdt.forEach(t),wMo=r(VLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yde=n(VLe,"CODE",{});var pdt=s(Yde);AMo=r(pdt,"model.train()"),pdt.forEach(t),VLe.forEach(t),yMo=i(aa),T(E_.$$.fragment,aa),aa.forEach(t),Hs.forEach(t),qDe=i(f),Ii=n(f,"H2",{class:!0});var XOe=s(Ii);C_=n(XOe,"A",{id:!0,class:!0,href:!0});var udt=s(C_);Kde=n(udt,"SPAN",{});var _dt=s(Kde);T(VA.$$.fragment,_dt),_dt.forEach(t),udt.forEach(t),LMo=i(XOe),Zde=n(XOe,"SPAN",{});var bdt=s(Zde);xMo=r(bdt,"AutoModelForPreTraining"),bdt.forEach(t),XOe.forEach(t),jDe=i(f),$o=n(f,"DIV",{class:!0});var Us=s($o);T(XA.$$.fragment,Us),$Mo=i(Us),Ni=n(Us,"P",{});var Nee=s(Ni);kMo=r(Nee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kj=n(Nee,"A",{href:!0});var vdt=s(kj);SMo=r(vdt,"from_pretrained()"),vdt.forEach(t),RMo=r(Nee," class method or the "),Sj=n(Nee,"A",{href:!0});var Fdt=s(Sj);PMo=r(Fdt,"from_config()"),Fdt.forEach(t),BMo=r(Nee,` class
method.`),Nee.forEach(t),IMo=i(Us),zA=n(Us,"P",{});var zOe=s(zA);NMo=r(zOe,"This class cannot be instantiated directly using "),ece=n(zOe,"CODE",{});var Tdt=s(ece);qMo=r(Tdt,"__init__()"),Tdt.forEach(t),jMo=r(zOe," (throws an error)."),zOe.forEach(t),DMo=i(Us),st=n(Us,"DIV",{class:!0});var u0=s(st);T(WA.$$.fragment,u0),GMo=i(u0),oce=n(u0,"P",{});var Mdt=s(oce);OMo=r(Mdt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Mdt.forEach(t),VMo=i(u0),qi=n(u0,"P",{});var qee=s(qi);XMo=r(qee,`Note:
Loading a model from its configuration file does `),rce=n(qee,"STRONG",{});var Edt=s(rce);zMo=r(Edt,"not"),Edt.forEach(t),WMo=r(qee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rj=n(qee,"A",{href:!0});var Cdt=s(Rj);QMo=r(Cdt,"from_pretrained()"),Cdt.forEach(t),HMo=r(qee," to load the model weights."),qee.forEach(t),UMo=i(u0),T(w_.$$.fragment,u0),u0.forEach(t),JMo=i(Us),Ye=n(Us,"DIV",{class:!0});var na=s(Ye);T(QA.$$.fragment,na),YMo=i(na),tce=n(na,"P",{});var wdt=s(tce);KMo=r(wdt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),wdt.forEach(t),ZMo=i(na),Ra=n(na,"P",{});var _0=s(Ra);e4o=r(_0,"The model class to instantiate is selected based on the "),ace=n(_0,"CODE",{});var Adt=s(ace);o4o=r(Adt,"model_type"),Adt.forEach(t),r4o=r(_0,` property of the config object (either
passed as an argument or loaded from `),nce=n(_0,"CODE",{});var ydt=s(nce);t4o=r(ydt,"pretrained_model_name_or_path"),ydt.forEach(t),a4o=r(_0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sce=n(_0,"CODE",{});var Ldt=s(sce);n4o=r(Ldt,"pretrained_model_name_or_path"),Ldt.forEach(t),s4o=r(_0,":"),_0.forEach(t),l4o=i(na),G=n(na,"UL",{});var O=s(G);A_=n(O,"LI",{});var XLe=s(A_);lce=n(XLe,"STRONG",{});var xdt=s(lce);i4o=r(xdt,"albert"),xdt.forEach(t),d4o=r(XLe," \u2014 "),Pj=n(XLe,"A",{href:!0});var $dt=s(Pj);c4o=r($dt,"AlbertForPreTraining"),$dt.forEach(t),f4o=r(XLe," (ALBERT model)"),XLe.forEach(t),m4o=i(O),y_=n(O,"LI",{});var zLe=s(y_);ice=n(zLe,"STRONG",{});var kdt=s(ice);g4o=r(kdt,"bart"),kdt.forEach(t),h4o=r(zLe," \u2014 "),Bj=n(zLe,"A",{href:!0});var Sdt=s(Bj);p4o=r(Sdt,"BartForConditionalGeneration"),Sdt.forEach(t),u4o=r(zLe," (BART model)"),zLe.forEach(t),_4o=i(O),L_=n(O,"LI",{});var WLe=s(L_);dce=n(WLe,"STRONG",{});var Rdt=s(dce);b4o=r(Rdt,"bert"),Rdt.forEach(t),v4o=r(WLe," \u2014 "),Ij=n(WLe,"A",{href:!0});var Pdt=s(Ij);F4o=r(Pdt,"BertForPreTraining"),Pdt.forEach(t),T4o=r(WLe," (BERT model)"),WLe.forEach(t),M4o=i(O),x_=n(O,"LI",{});var QLe=s(x_);cce=n(QLe,"STRONG",{});var Bdt=s(cce);E4o=r(Bdt,"big_bird"),Bdt.forEach(t),C4o=r(QLe," \u2014 "),Nj=n(QLe,"A",{href:!0});var Idt=s(Nj);w4o=r(Idt,"BigBirdForPreTraining"),Idt.forEach(t),A4o=r(QLe," (BigBird model)"),QLe.forEach(t),y4o=i(O),$_=n(O,"LI",{});var HLe=s($_);fce=n(HLe,"STRONG",{});var Ndt=s(fce);L4o=r(Ndt,"bloom"),Ndt.forEach(t),x4o=r(HLe," \u2014 "),qj=n(HLe,"A",{href:!0});var qdt=s(qj);$4o=r(qdt,"BloomForCausalLM"),qdt.forEach(t),k4o=r(HLe," (BLOOM model)"),HLe.forEach(t),S4o=i(O),k_=n(O,"LI",{});var ULe=s(k_);mce=n(ULe,"STRONG",{});var jdt=s(mce);R4o=r(jdt,"camembert"),jdt.forEach(t),P4o=r(ULe," \u2014 "),jj=n(ULe,"A",{href:!0});var Ddt=s(jj);B4o=r(Ddt,"CamembertForMaskedLM"),Ddt.forEach(t),I4o=r(ULe," (CamemBERT model)"),ULe.forEach(t),N4o=i(O),S_=n(O,"LI",{});var JLe=s(S_);gce=n(JLe,"STRONG",{});var Gdt=s(gce);q4o=r(Gdt,"ctrl"),Gdt.forEach(t),j4o=r(JLe," \u2014 "),Dj=n(JLe,"A",{href:!0});var Odt=s(Dj);D4o=r(Odt,"CTRLLMHeadModel"),Odt.forEach(t),G4o=r(JLe," (CTRL model)"),JLe.forEach(t),O4o=i(O),R_=n(O,"LI",{});var YLe=s(R_);hce=n(YLe,"STRONG",{});var Vdt=s(hce);V4o=r(Vdt,"data2vec-text"),Vdt.forEach(t),X4o=r(YLe," \u2014 "),Gj=n(YLe,"A",{href:!0});var Xdt=s(Gj);z4o=r(Xdt,"Data2VecTextForMaskedLM"),Xdt.forEach(t),W4o=r(YLe," (Data2VecText model)"),YLe.forEach(t),Q4o=i(O),P_=n(O,"LI",{});var KLe=s(P_);pce=n(KLe,"STRONG",{});var zdt=s(pce);H4o=r(zdt,"deberta"),zdt.forEach(t),U4o=r(KLe," \u2014 "),Oj=n(KLe,"A",{href:!0});var Wdt=s(Oj);J4o=r(Wdt,"DebertaForMaskedLM"),Wdt.forEach(t),Y4o=r(KLe," (DeBERTa model)"),KLe.forEach(t),K4o=i(O),B_=n(O,"LI",{});var ZLe=s(B_);uce=n(ZLe,"STRONG",{});var Qdt=s(uce);Z4o=r(Qdt,"deberta-v2"),Qdt.forEach(t),eEo=r(ZLe," \u2014 "),Vj=n(ZLe,"A",{href:!0});var Hdt=s(Vj);oEo=r(Hdt,"DebertaV2ForMaskedLM"),Hdt.forEach(t),rEo=r(ZLe," (DeBERTa-v2 model)"),ZLe.forEach(t),tEo=i(O),I_=n(O,"LI",{});var e8e=s(I_);_ce=n(e8e,"STRONG",{});var Udt=s(_ce);aEo=r(Udt,"distilbert"),Udt.forEach(t),nEo=r(e8e," \u2014 "),Xj=n(e8e,"A",{href:!0});var Jdt=s(Xj);sEo=r(Jdt,"DistilBertForMaskedLM"),Jdt.forEach(t),lEo=r(e8e," (DistilBERT model)"),e8e.forEach(t),iEo=i(O),N_=n(O,"LI",{});var o8e=s(N_);bce=n(o8e,"STRONG",{});var Ydt=s(bce);dEo=r(Ydt,"electra"),Ydt.forEach(t),cEo=r(o8e," \u2014 "),zj=n(o8e,"A",{href:!0});var Kdt=s(zj);fEo=r(Kdt,"ElectraForPreTraining"),Kdt.forEach(t),mEo=r(o8e," (ELECTRA model)"),o8e.forEach(t),gEo=i(O),q_=n(O,"LI",{});var r8e=s(q_);vce=n(r8e,"STRONG",{});var Zdt=s(vce);hEo=r(Zdt,"flaubert"),Zdt.forEach(t),pEo=r(r8e," \u2014 "),Wj=n(r8e,"A",{href:!0});var ect=s(Wj);uEo=r(ect,"FlaubertWithLMHeadModel"),ect.forEach(t),_Eo=r(r8e," (FlauBERT model)"),r8e.forEach(t),bEo=i(O),j_=n(O,"LI",{});var t8e=s(j_);Fce=n(t8e,"STRONG",{});var oct=s(Fce);vEo=r(oct,"flava"),oct.forEach(t),FEo=r(t8e," \u2014 "),Qj=n(t8e,"A",{href:!0});var rct=s(Qj);TEo=r(rct,"FlavaForPreTraining"),rct.forEach(t),MEo=r(t8e," (FLAVA model)"),t8e.forEach(t),EEo=i(O),D_=n(O,"LI",{});var a8e=s(D_);Tce=n(a8e,"STRONG",{});var tct=s(Tce);CEo=r(tct,"fnet"),tct.forEach(t),wEo=r(a8e," \u2014 "),Hj=n(a8e,"A",{href:!0});var act=s(Hj);AEo=r(act,"FNetForPreTraining"),act.forEach(t),yEo=r(a8e," (FNet model)"),a8e.forEach(t),LEo=i(O),G_=n(O,"LI",{});var n8e=s(G_);Mce=n(n8e,"STRONG",{});var nct=s(Mce);xEo=r(nct,"fsmt"),nct.forEach(t),$Eo=r(n8e," \u2014 "),Uj=n(n8e,"A",{href:!0});var sct=s(Uj);kEo=r(sct,"FSMTForConditionalGeneration"),sct.forEach(t),SEo=r(n8e," (FairSeq Machine-Translation model)"),n8e.forEach(t),REo=i(O),O_=n(O,"LI",{});var s8e=s(O_);Ece=n(s8e,"STRONG",{});var lct=s(Ece);PEo=r(lct,"funnel"),lct.forEach(t),BEo=r(s8e," \u2014 "),Jj=n(s8e,"A",{href:!0});var ict=s(Jj);IEo=r(ict,"FunnelForPreTraining"),ict.forEach(t),NEo=r(s8e," (Funnel Transformer model)"),s8e.forEach(t),qEo=i(O),V_=n(O,"LI",{});var l8e=s(V_);Cce=n(l8e,"STRONG",{});var dct=s(Cce);jEo=r(dct,"gpt2"),dct.forEach(t),DEo=r(l8e," \u2014 "),Yj=n(l8e,"A",{href:!0});var cct=s(Yj);GEo=r(cct,"GPT2LMHeadModel"),cct.forEach(t),OEo=r(l8e," (OpenAI GPT-2 model)"),l8e.forEach(t),VEo=i(O),X_=n(O,"LI",{});var i8e=s(X_);wce=n(i8e,"STRONG",{});var fct=s(wce);XEo=r(fct,"ibert"),fct.forEach(t),zEo=r(i8e," \u2014 "),Kj=n(i8e,"A",{href:!0});var mct=s(Kj);WEo=r(mct,"IBertForMaskedLM"),mct.forEach(t),QEo=r(i8e," (I-BERT model)"),i8e.forEach(t),HEo=i(O),z_=n(O,"LI",{});var d8e=s(z_);Ace=n(d8e,"STRONG",{});var gct=s(Ace);UEo=r(gct,"layoutlm"),gct.forEach(t),JEo=r(d8e," \u2014 "),Zj=n(d8e,"A",{href:!0});var hct=s(Zj);YEo=r(hct,"LayoutLMForMaskedLM"),hct.forEach(t),KEo=r(d8e," (LayoutLM model)"),d8e.forEach(t),ZEo=i(O),W_=n(O,"LI",{});var c8e=s(W_);yce=n(c8e,"STRONG",{});var pct=s(yce);eCo=r(pct,"longformer"),pct.forEach(t),oCo=r(c8e," \u2014 "),eD=n(c8e,"A",{href:!0});var uct=s(eD);rCo=r(uct,"LongformerForMaskedLM"),uct.forEach(t),tCo=r(c8e," (Longformer model)"),c8e.forEach(t),aCo=i(O),Q_=n(O,"LI",{});var f8e=s(Q_);Lce=n(f8e,"STRONG",{});var _ct=s(Lce);nCo=r(_ct,"lxmert"),_ct.forEach(t),sCo=r(f8e," \u2014 "),oD=n(f8e,"A",{href:!0});var bct=s(oD);lCo=r(bct,"LxmertForPreTraining"),bct.forEach(t),iCo=r(f8e," (LXMERT model)"),f8e.forEach(t),dCo=i(O),H_=n(O,"LI",{});var m8e=s(H_);xce=n(m8e,"STRONG",{});var vct=s(xce);cCo=r(vct,"megatron-bert"),vct.forEach(t),fCo=r(m8e," \u2014 "),rD=n(m8e,"A",{href:!0});var Fct=s(rD);mCo=r(Fct,"MegatronBertForPreTraining"),Fct.forEach(t),gCo=r(m8e," (Megatron-BERT model)"),m8e.forEach(t),hCo=i(O),U_=n(O,"LI",{});var g8e=s(U_);$ce=n(g8e,"STRONG",{});var Tct=s($ce);pCo=r(Tct,"mobilebert"),Tct.forEach(t),uCo=r(g8e," \u2014 "),tD=n(g8e,"A",{href:!0});var Mct=s(tD);_Co=r(Mct,"MobileBertForPreTraining"),Mct.forEach(t),bCo=r(g8e," (MobileBERT model)"),g8e.forEach(t),vCo=i(O),J_=n(O,"LI",{});var h8e=s(J_);kce=n(h8e,"STRONG",{});var Ect=s(kce);FCo=r(Ect,"mpnet"),Ect.forEach(t),TCo=r(h8e," \u2014 "),aD=n(h8e,"A",{href:!0});var Cct=s(aD);MCo=r(Cct,"MPNetForMaskedLM"),Cct.forEach(t),ECo=r(h8e," (MPNet model)"),h8e.forEach(t),CCo=i(O),Y_=n(O,"LI",{});var p8e=s(Y_);Sce=n(p8e,"STRONG",{});var wct=s(Sce);wCo=r(wct,"openai-gpt"),wct.forEach(t),ACo=r(p8e," \u2014 "),nD=n(p8e,"A",{href:!0});var Act=s(nD);yCo=r(Act,"OpenAIGPTLMHeadModel"),Act.forEach(t),LCo=r(p8e," (OpenAI GPT model)"),p8e.forEach(t),xCo=i(O),K_=n(O,"LI",{});var u8e=s(K_);Rce=n(u8e,"STRONG",{});var yct=s(Rce);$Co=r(yct,"retribert"),yct.forEach(t),kCo=r(u8e," \u2014 "),sD=n(u8e,"A",{href:!0});var Lct=s(sD);SCo=r(Lct,"RetriBertModel"),Lct.forEach(t),RCo=r(u8e," (RetriBERT model)"),u8e.forEach(t),PCo=i(O),Z_=n(O,"LI",{});var _8e=s(Z_);Pce=n(_8e,"STRONG",{});var xct=s(Pce);BCo=r(xct,"roberta"),xct.forEach(t),ICo=r(_8e," \u2014 "),lD=n(_8e,"A",{href:!0});var $ct=s(lD);NCo=r($ct,"RobertaForMaskedLM"),$ct.forEach(t),qCo=r(_8e," (RoBERTa model)"),_8e.forEach(t),jCo=i(O),e1=n(O,"LI",{});var b8e=s(e1);Bce=n(b8e,"STRONG",{});var kct=s(Bce);DCo=r(kct,"splinter"),kct.forEach(t),GCo=r(b8e," \u2014 "),iD=n(b8e,"A",{href:!0});var Sct=s(iD);OCo=r(Sct,"SplinterForPreTraining"),Sct.forEach(t),VCo=r(b8e," (Splinter model)"),b8e.forEach(t),XCo=i(O),o1=n(O,"LI",{});var v8e=s(o1);Ice=n(v8e,"STRONG",{});var Rct=s(Ice);zCo=r(Rct,"squeezebert"),Rct.forEach(t),WCo=r(v8e," \u2014 "),dD=n(v8e,"A",{href:!0});var Pct=s(dD);QCo=r(Pct,"SqueezeBertForMaskedLM"),Pct.forEach(t),HCo=r(v8e," (SqueezeBERT model)"),v8e.forEach(t),UCo=i(O),r1=n(O,"LI",{});var F8e=s(r1);Nce=n(F8e,"STRONG",{});var Bct=s(Nce);JCo=r(Bct,"t5"),Bct.forEach(t),YCo=r(F8e," \u2014 "),cD=n(F8e,"A",{href:!0});var Ict=s(cD);KCo=r(Ict,"T5ForConditionalGeneration"),Ict.forEach(t),ZCo=r(F8e," (T5 model)"),F8e.forEach(t),e5o=i(O),t1=n(O,"LI",{});var T8e=s(t1);qce=n(T8e,"STRONG",{});var Nct=s(qce);o5o=r(Nct,"tapas"),Nct.forEach(t),r5o=r(T8e," \u2014 "),fD=n(T8e,"A",{href:!0});var qct=s(fD);t5o=r(qct,"TapasForMaskedLM"),qct.forEach(t),a5o=r(T8e," (TAPAS model)"),T8e.forEach(t),n5o=i(O),a1=n(O,"LI",{});var M8e=s(a1);jce=n(M8e,"STRONG",{});var jct=s(jce);s5o=r(jct,"transfo-xl"),jct.forEach(t),l5o=r(M8e," \u2014 "),mD=n(M8e,"A",{href:!0});var Dct=s(mD);i5o=r(Dct,"TransfoXLLMHeadModel"),Dct.forEach(t),d5o=r(M8e," (Transformer-XL model)"),M8e.forEach(t),c5o=i(O),n1=n(O,"LI",{});var E8e=s(n1);Dce=n(E8e,"STRONG",{});var Gct=s(Dce);f5o=r(Gct,"unispeech"),Gct.forEach(t),m5o=r(E8e," \u2014 "),gD=n(E8e,"A",{href:!0});var Oct=s(gD);g5o=r(Oct,"UniSpeechForPreTraining"),Oct.forEach(t),h5o=r(E8e," (UniSpeech model)"),E8e.forEach(t),p5o=i(O),s1=n(O,"LI",{});var C8e=s(s1);Gce=n(C8e,"STRONG",{});var Vct=s(Gce);u5o=r(Vct,"unispeech-sat"),Vct.forEach(t),_5o=r(C8e," \u2014 "),hD=n(C8e,"A",{href:!0});var Xct=s(hD);b5o=r(Xct,"UniSpeechSatForPreTraining"),Xct.forEach(t),v5o=r(C8e," (UniSpeechSat model)"),C8e.forEach(t),F5o=i(O),l1=n(O,"LI",{});var w8e=s(l1);Oce=n(w8e,"STRONG",{});var zct=s(Oce);T5o=r(zct,"visual_bert"),zct.forEach(t),M5o=r(w8e," \u2014 "),pD=n(w8e,"A",{href:!0});var Wct=s(pD);E5o=r(Wct,"VisualBertForPreTraining"),Wct.forEach(t),C5o=r(w8e," (VisualBERT model)"),w8e.forEach(t),w5o=i(O),i1=n(O,"LI",{});var A8e=s(i1);Vce=n(A8e,"STRONG",{});var Qct=s(Vce);A5o=r(Qct,"vit_mae"),Qct.forEach(t),y5o=r(A8e," \u2014 "),uD=n(A8e,"A",{href:!0});var Hct=s(uD);L5o=r(Hct,"ViTMAEForPreTraining"),Hct.forEach(t),x5o=r(A8e," (ViTMAE model)"),A8e.forEach(t),$5o=i(O),d1=n(O,"LI",{});var y8e=s(d1);Xce=n(y8e,"STRONG",{});var Uct=s(Xce);k5o=r(Uct,"wav2vec2"),Uct.forEach(t),S5o=r(y8e," \u2014 "),_D=n(y8e,"A",{href:!0});var Jct=s(_D);R5o=r(Jct,"Wav2Vec2ForPreTraining"),Jct.forEach(t),P5o=r(y8e," (Wav2Vec2 model)"),y8e.forEach(t),B5o=i(O),c1=n(O,"LI",{});var L8e=s(c1);zce=n(L8e,"STRONG",{});var Yct=s(zce);I5o=r(Yct,"wav2vec2-conformer"),Yct.forEach(t),N5o=r(L8e," \u2014 "),bD=n(L8e,"A",{href:!0});var Kct=s(bD);q5o=r(Kct,"Wav2Vec2ConformerForPreTraining"),Kct.forEach(t),j5o=r(L8e," (Wav2Vec2-Conformer model)"),L8e.forEach(t),D5o=i(O),f1=n(O,"LI",{});var x8e=s(f1);Wce=n(x8e,"STRONG",{});var Zct=s(Wce);G5o=r(Zct,"xlm"),Zct.forEach(t),O5o=r(x8e," \u2014 "),vD=n(x8e,"A",{href:!0});var eft=s(vD);V5o=r(eft,"XLMWithLMHeadModel"),eft.forEach(t),X5o=r(x8e," (XLM model)"),x8e.forEach(t),z5o=i(O),m1=n(O,"LI",{});var $8e=s(m1);Qce=n($8e,"STRONG",{});var oft=s(Qce);W5o=r(oft,"xlm-roberta"),oft.forEach(t),Q5o=r($8e," \u2014 "),FD=n($8e,"A",{href:!0});var rft=s(FD);H5o=r(rft,"XLMRobertaForMaskedLM"),rft.forEach(t),U5o=r($8e," (XLM-RoBERTa model)"),$8e.forEach(t),J5o=i(O),g1=n(O,"LI",{});var k8e=s(g1);Hce=n(k8e,"STRONG",{});var tft=s(Hce);Y5o=r(tft,"xlm-roberta-xl"),tft.forEach(t),K5o=r(k8e," \u2014 "),TD=n(k8e,"A",{href:!0});var aft=s(TD);Z5o=r(aft,"XLMRobertaXLForMaskedLM"),aft.forEach(t),e0o=r(k8e," (XLM-RoBERTa-XL model)"),k8e.forEach(t),o0o=i(O),h1=n(O,"LI",{});var S8e=s(h1);Uce=n(S8e,"STRONG",{});var nft=s(Uce);r0o=r(nft,"xlnet"),nft.forEach(t),t0o=r(S8e," \u2014 "),MD=n(S8e,"A",{href:!0});var sft=s(MD);a0o=r(sft,"XLNetLMHeadModel"),sft.forEach(t),n0o=r(S8e," (XLNet model)"),S8e.forEach(t),O.forEach(t),s0o=i(na),p1=n(na,"P",{});var R8e=s(p1);l0o=r(R8e,"The model is set in evaluation mode by default using "),Jce=n(R8e,"CODE",{});var lft=s(Jce);i0o=r(lft,"model.eval()"),lft.forEach(t),d0o=r(R8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yce=n(R8e,"CODE",{});var ift=s(Yce);c0o=r(ift,"model.train()"),ift.forEach(t),R8e.forEach(t),f0o=i(na),T(u1.$$.fragment,na),na.forEach(t),Us.forEach(t),DDe=i(f),ji=n(f,"H2",{class:!0});var WOe=s(ji);_1=n(WOe,"A",{id:!0,class:!0,href:!0});var dft=s(_1);Kce=n(dft,"SPAN",{});var cft=s(Kce);T(HA.$$.fragment,cft),cft.forEach(t),dft.forEach(t),m0o=i(WOe),Zce=n(WOe,"SPAN",{});var fft=s(Zce);g0o=r(fft,"AutoModelForCausalLM"),fft.forEach(t),WOe.forEach(t),GDe=i(f),ko=n(f,"DIV",{class:!0});var Js=s(ko);T(UA.$$.fragment,Js),h0o=i(Js),Di=n(Js,"P",{});var jee=s(Di);p0o=r(jee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ED=n(jee,"A",{href:!0});var mft=s(ED);u0o=r(mft,"from_pretrained()"),mft.forEach(t),_0o=r(jee," class method or the "),CD=n(jee,"A",{href:!0});var gft=s(CD);b0o=r(gft,"from_config()"),gft.forEach(t),v0o=r(jee,` class
method.`),jee.forEach(t),F0o=i(Js),JA=n(Js,"P",{});var QOe=s(JA);T0o=r(QOe,"This class cannot be instantiated directly using "),efe=n(QOe,"CODE",{});var hft=s(efe);M0o=r(hft,"__init__()"),hft.forEach(t),E0o=r(QOe," (throws an error)."),QOe.forEach(t),C0o=i(Js),lt=n(Js,"DIV",{class:!0});var b0=s(lt);T(YA.$$.fragment,b0),w0o=i(b0),ofe=n(b0,"P",{});var pft=s(ofe);A0o=r(pft,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),pft.forEach(t),y0o=i(b0),Gi=n(b0,"P",{});var Dee=s(Gi);L0o=r(Dee,`Note:
Loading a model from its configuration file does `),rfe=n(Dee,"STRONG",{});var uft=s(rfe);x0o=r(uft,"not"),uft.forEach(t),$0o=r(Dee,` load the model weights. It only affects the
model\u2019s configuration. Use `),wD=n(Dee,"A",{href:!0});var _ft=s(wD);k0o=r(_ft,"from_pretrained()"),_ft.forEach(t),S0o=r(Dee," to load the model weights."),Dee.forEach(t),R0o=i(b0),T(b1.$$.fragment,b0),b0.forEach(t),P0o=i(Js),Ke=n(Js,"DIV",{class:!0});var sa=s(Ke);T(KA.$$.fragment,sa),B0o=i(sa),tfe=n(sa,"P",{});var bft=s(tfe);I0o=r(bft,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),bft.forEach(t),N0o=i(sa),Pa=n(sa,"P",{});var v0=s(Pa);q0o=r(v0,"The model class to instantiate is selected based on the "),afe=n(v0,"CODE",{});var vft=s(afe);j0o=r(vft,"model_type"),vft.forEach(t),D0o=r(v0,` property of the config object (either
passed as an argument or loaded from `),nfe=n(v0,"CODE",{});var Fft=s(nfe);G0o=r(Fft,"pretrained_model_name_or_path"),Fft.forEach(t),O0o=r(v0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sfe=n(v0,"CODE",{});var Tft=s(sfe);V0o=r(Tft,"pretrained_model_name_or_path"),Tft.forEach(t),X0o=r(v0,":"),v0.forEach(t),z0o=i(sa),z=n(sa,"UL",{});var W=s(z);v1=n(W,"LI",{});var P8e=s(v1);lfe=n(P8e,"STRONG",{});var Mft=s(lfe);W0o=r(Mft,"bart"),Mft.forEach(t),Q0o=r(P8e," \u2014 "),AD=n(P8e,"A",{href:!0});var Eft=s(AD);H0o=r(Eft,"BartForCausalLM"),Eft.forEach(t),U0o=r(P8e," (BART model)"),P8e.forEach(t),J0o=i(W),F1=n(W,"LI",{});var B8e=s(F1);ife=n(B8e,"STRONG",{});var Cft=s(ife);Y0o=r(Cft,"bert"),Cft.forEach(t),K0o=r(B8e," \u2014 "),yD=n(B8e,"A",{href:!0});var wft=s(yD);Z0o=r(wft,"BertLMHeadModel"),wft.forEach(t),ewo=r(B8e," (BERT model)"),B8e.forEach(t),owo=i(W),T1=n(W,"LI",{});var I8e=s(T1);dfe=n(I8e,"STRONG",{});var Aft=s(dfe);rwo=r(Aft,"bert-generation"),Aft.forEach(t),two=r(I8e," \u2014 "),LD=n(I8e,"A",{href:!0});var yft=s(LD);awo=r(yft,"BertGenerationDecoder"),yft.forEach(t),nwo=r(I8e," (Bert Generation model)"),I8e.forEach(t),swo=i(W),M1=n(W,"LI",{});var N8e=s(M1);cfe=n(N8e,"STRONG",{});var Lft=s(cfe);lwo=r(Lft,"big_bird"),Lft.forEach(t),iwo=r(N8e," \u2014 "),xD=n(N8e,"A",{href:!0});var xft=s(xD);dwo=r(xft,"BigBirdForCausalLM"),xft.forEach(t),cwo=r(N8e," (BigBird model)"),N8e.forEach(t),fwo=i(W),E1=n(W,"LI",{});var q8e=s(E1);ffe=n(q8e,"STRONG",{});var $ft=s(ffe);mwo=r($ft,"bigbird_pegasus"),$ft.forEach(t),gwo=r(q8e," \u2014 "),$D=n(q8e,"A",{href:!0});var kft=s($D);hwo=r(kft,"BigBirdPegasusForCausalLM"),kft.forEach(t),pwo=r(q8e," (BigBird-Pegasus model)"),q8e.forEach(t),uwo=i(W),C1=n(W,"LI",{});var j8e=s(C1);mfe=n(j8e,"STRONG",{});var Sft=s(mfe);_wo=r(Sft,"blenderbot"),Sft.forEach(t),bwo=r(j8e," \u2014 "),kD=n(j8e,"A",{href:!0});var Rft=s(kD);vwo=r(Rft,"BlenderbotForCausalLM"),Rft.forEach(t),Fwo=r(j8e," (Blenderbot model)"),j8e.forEach(t),Two=i(W),w1=n(W,"LI",{});var D8e=s(w1);gfe=n(D8e,"STRONG",{});var Pft=s(gfe);Mwo=r(Pft,"blenderbot-small"),Pft.forEach(t),Ewo=r(D8e," \u2014 "),SD=n(D8e,"A",{href:!0});var Bft=s(SD);Cwo=r(Bft,"BlenderbotSmallForCausalLM"),Bft.forEach(t),wwo=r(D8e," (BlenderbotSmall model)"),D8e.forEach(t),Awo=i(W),A1=n(W,"LI",{});var G8e=s(A1);hfe=n(G8e,"STRONG",{});var Ift=s(hfe);ywo=r(Ift,"bloom"),Ift.forEach(t),Lwo=r(G8e," \u2014 "),RD=n(G8e,"A",{href:!0});var Nft=s(RD);xwo=r(Nft,"BloomForCausalLM"),Nft.forEach(t),$wo=r(G8e," (BLOOM model)"),G8e.forEach(t),kwo=i(W),y1=n(W,"LI",{});var O8e=s(y1);pfe=n(O8e,"STRONG",{});var qft=s(pfe);Swo=r(qft,"camembert"),qft.forEach(t),Rwo=r(O8e," \u2014 "),PD=n(O8e,"A",{href:!0});var jft=s(PD);Pwo=r(jft,"CamembertForCausalLM"),jft.forEach(t),Bwo=r(O8e," (CamemBERT model)"),O8e.forEach(t),Iwo=i(W),L1=n(W,"LI",{});var V8e=s(L1);ufe=n(V8e,"STRONG",{});var Dft=s(ufe);Nwo=r(Dft,"ctrl"),Dft.forEach(t),qwo=r(V8e," \u2014 "),BD=n(V8e,"A",{href:!0});var Gft=s(BD);jwo=r(Gft,"CTRLLMHeadModel"),Gft.forEach(t),Dwo=r(V8e," (CTRL model)"),V8e.forEach(t),Gwo=i(W),x1=n(W,"LI",{});var X8e=s(x1);_fe=n(X8e,"STRONG",{});var Oft=s(_fe);Owo=r(Oft,"data2vec-text"),Oft.forEach(t),Vwo=r(X8e," \u2014 "),ID=n(X8e,"A",{href:!0});var Vft=s(ID);Xwo=r(Vft,"Data2VecTextForCausalLM"),Vft.forEach(t),zwo=r(X8e," (Data2VecText model)"),X8e.forEach(t),Wwo=i(W),$1=n(W,"LI",{});var z8e=s($1);bfe=n(z8e,"STRONG",{});var Xft=s(bfe);Qwo=r(Xft,"electra"),Xft.forEach(t),Hwo=r(z8e," \u2014 "),ND=n(z8e,"A",{href:!0});var zft=s(ND);Uwo=r(zft,"ElectraForCausalLM"),zft.forEach(t),Jwo=r(z8e," (ELECTRA model)"),z8e.forEach(t),Ywo=i(W),k1=n(W,"LI",{});var W8e=s(k1);vfe=n(W8e,"STRONG",{});var Wft=s(vfe);Kwo=r(Wft,"gpt2"),Wft.forEach(t),Zwo=r(W8e," \u2014 "),qD=n(W8e,"A",{href:!0});var Qft=s(qD);eAo=r(Qft,"GPT2LMHeadModel"),Qft.forEach(t),oAo=r(W8e," (OpenAI GPT-2 model)"),W8e.forEach(t),rAo=i(W),S1=n(W,"LI",{});var Q8e=s(S1);Ffe=n(Q8e,"STRONG",{});var Hft=s(Ffe);tAo=r(Hft,"gpt_neo"),Hft.forEach(t),aAo=r(Q8e," \u2014 "),jD=n(Q8e,"A",{href:!0});var Uft=s(jD);nAo=r(Uft,"GPTNeoForCausalLM"),Uft.forEach(t),sAo=r(Q8e," (GPT Neo model)"),Q8e.forEach(t),lAo=i(W),R1=n(W,"LI",{});var H8e=s(R1);Tfe=n(H8e,"STRONG",{});var Jft=s(Tfe);iAo=r(Jft,"gpt_neox"),Jft.forEach(t),dAo=r(H8e," \u2014 "),DD=n(H8e,"A",{href:!0});var Yft=s(DD);cAo=r(Yft,"GPTNeoXForCausalLM"),Yft.forEach(t),fAo=r(H8e," (GPT NeoX model)"),H8e.forEach(t),mAo=i(W),P1=n(W,"LI",{});var U8e=s(P1);Mfe=n(U8e,"STRONG",{});var Kft=s(Mfe);gAo=r(Kft,"gptj"),Kft.forEach(t),hAo=r(U8e," \u2014 "),GD=n(U8e,"A",{href:!0});var Zft=s(GD);pAo=r(Zft,"GPTJForCausalLM"),Zft.forEach(t),uAo=r(U8e," (GPT-J model)"),U8e.forEach(t),_Ao=i(W),B1=n(W,"LI",{});var J8e=s(B1);Efe=n(J8e,"STRONG",{});var emt=s(Efe);bAo=r(emt,"marian"),emt.forEach(t),vAo=r(J8e," \u2014 "),OD=n(J8e,"A",{href:!0});var omt=s(OD);FAo=r(omt,"MarianForCausalLM"),omt.forEach(t),TAo=r(J8e," (Marian model)"),J8e.forEach(t),MAo=i(W),I1=n(W,"LI",{});var Y8e=s(I1);Cfe=n(Y8e,"STRONG",{});var rmt=s(Cfe);EAo=r(rmt,"mbart"),rmt.forEach(t),CAo=r(Y8e," \u2014 "),VD=n(Y8e,"A",{href:!0});var tmt=s(VD);wAo=r(tmt,"MBartForCausalLM"),tmt.forEach(t),AAo=r(Y8e," (mBART model)"),Y8e.forEach(t),yAo=i(W),N1=n(W,"LI",{});var K8e=s(N1);wfe=n(K8e,"STRONG",{});var amt=s(wfe);LAo=r(amt,"megatron-bert"),amt.forEach(t),xAo=r(K8e," \u2014 "),XD=n(K8e,"A",{href:!0});var nmt=s(XD);$Ao=r(nmt,"MegatronBertForCausalLM"),nmt.forEach(t),kAo=r(K8e," (Megatron-BERT model)"),K8e.forEach(t),SAo=i(W),q1=n(W,"LI",{});var Z8e=s(q1);Afe=n(Z8e,"STRONG",{});var smt=s(Afe);RAo=r(smt,"openai-gpt"),smt.forEach(t),PAo=r(Z8e," \u2014 "),zD=n(Z8e,"A",{href:!0});var lmt=s(zD);BAo=r(lmt,"OpenAIGPTLMHeadModel"),lmt.forEach(t),IAo=r(Z8e," (OpenAI GPT model)"),Z8e.forEach(t),NAo=i(W),j1=n(W,"LI",{});var exe=s(j1);yfe=n(exe,"STRONG",{});var imt=s(yfe);qAo=r(imt,"opt"),imt.forEach(t),jAo=r(exe," \u2014 "),WD=n(exe,"A",{href:!0});var dmt=s(WD);DAo=r(dmt,"OPTForCausalLM"),dmt.forEach(t),GAo=r(exe," (OPT model)"),exe.forEach(t),OAo=i(W),D1=n(W,"LI",{});var oxe=s(D1);Lfe=n(oxe,"STRONG",{});var cmt=s(Lfe);VAo=r(cmt,"pegasus"),cmt.forEach(t),XAo=r(oxe," \u2014 "),QD=n(oxe,"A",{href:!0});var fmt=s(QD);zAo=r(fmt,"PegasusForCausalLM"),fmt.forEach(t),WAo=r(oxe," (Pegasus model)"),oxe.forEach(t),QAo=i(W),G1=n(W,"LI",{});var rxe=s(G1);xfe=n(rxe,"STRONG",{});var mmt=s(xfe);HAo=r(mmt,"plbart"),mmt.forEach(t),UAo=r(rxe," \u2014 "),HD=n(rxe,"A",{href:!0});var gmt=s(HD);JAo=r(gmt,"PLBartForCausalLM"),gmt.forEach(t),YAo=r(rxe," (PLBart model)"),rxe.forEach(t),KAo=i(W),O1=n(W,"LI",{});var txe=s(O1);$fe=n(txe,"STRONG",{});var hmt=s($fe);ZAo=r(hmt,"prophetnet"),hmt.forEach(t),eyo=r(txe," \u2014 "),UD=n(txe,"A",{href:!0});var pmt=s(UD);oyo=r(pmt,"ProphetNetForCausalLM"),pmt.forEach(t),ryo=r(txe," (ProphetNet model)"),txe.forEach(t),tyo=i(W),V1=n(W,"LI",{});var axe=s(V1);kfe=n(axe,"STRONG",{});var umt=s(kfe);ayo=r(umt,"qdqbert"),umt.forEach(t),nyo=r(axe," \u2014 "),JD=n(axe,"A",{href:!0});var _mt=s(JD);syo=r(_mt,"QDQBertLMHeadModel"),_mt.forEach(t),lyo=r(axe," (QDQBert model)"),axe.forEach(t),iyo=i(W),X1=n(W,"LI",{});var nxe=s(X1);Sfe=n(nxe,"STRONG",{});var bmt=s(Sfe);dyo=r(bmt,"reformer"),bmt.forEach(t),cyo=r(nxe," \u2014 "),YD=n(nxe,"A",{href:!0});var vmt=s(YD);fyo=r(vmt,"ReformerModelWithLMHead"),vmt.forEach(t),myo=r(nxe," (Reformer model)"),nxe.forEach(t),gyo=i(W),z1=n(W,"LI",{});var sxe=s(z1);Rfe=n(sxe,"STRONG",{});var Fmt=s(Rfe);hyo=r(Fmt,"rembert"),Fmt.forEach(t),pyo=r(sxe," \u2014 "),KD=n(sxe,"A",{href:!0});var Tmt=s(KD);uyo=r(Tmt,"RemBertForCausalLM"),Tmt.forEach(t),_yo=r(sxe," (RemBERT model)"),sxe.forEach(t),byo=i(W),W1=n(W,"LI",{});var lxe=s(W1);Pfe=n(lxe,"STRONG",{});var Mmt=s(Pfe);vyo=r(Mmt,"roberta"),Mmt.forEach(t),Fyo=r(lxe," \u2014 "),ZD=n(lxe,"A",{href:!0});var Emt=s(ZD);Tyo=r(Emt,"RobertaForCausalLM"),Emt.forEach(t),Myo=r(lxe," (RoBERTa model)"),lxe.forEach(t),Eyo=i(W),Q1=n(W,"LI",{});var ixe=s(Q1);Bfe=n(ixe,"STRONG",{});var Cmt=s(Bfe);Cyo=r(Cmt,"roformer"),Cmt.forEach(t),wyo=r(ixe," \u2014 "),eG=n(ixe,"A",{href:!0});var wmt=s(eG);Ayo=r(wmt,"RoFormerForCausalLM"),wmt.forEach(t),yyo=r(ixe," (RoFormer model)"),ixe.forEach(t),Lyo=i(W),H1=n(W,"LI",{});var dxe=s(H1);Ife=n(dxe,"STRONG",{});var Amt=s(Ife);xyo=r(Amt,"speech_to_text_2"),Amt.forEach(t),$yo=r(dxe," \u2014 "),oG=n(dxe,"A",{href:!0});var ymt=s(oG);kyo=r(ymt,"Speech2Text2ForCausalLM"),ymt.forEach(t),Syo=r(dxe," (Speech2Text2 model)"),dxe.forEach(t),Ryo=i(W),U1=n(W,"LI",{});var cxe=s(U1);Nfe=n(cxe,"STRONG",{});var Lmt=s(Nfe);Pyo=r(Lmt,"transfo-xl"),Lmt.forEach(t),Byo=r(cxe," \u2014 "),rG=n(cxe,"A",{href:!0});var xmt=s(rG);Iyo=r(xmt,"TransfoXLLMHeadModel"),xmt.forEach(t),Nyo=r(cxe," (Transformer-XL model)"),cxe.forEach(t),qyo=i(W),J1=n(W,"LI",{});var fxe=s(J1);qfe=n(fxe,"STRONG",{});var $mt=s(qfe);jyo=r($mt,"trocr"),$mt.forEach(t),Dyo=r(fxe," \u2014 "),tG=n(fxe,"A",{href:!0});var kmt=s(tG);Gyo=r(kmt,"TrOCRForCausalLM"),kmt.forEach(t),Oyo=r(fxe," (TrOCR model)"),fxe.forEach(t),Vyo=i(W),Y1=n(W,"LI",{});var mxe=s(Y1);jfe=n(mxe,"STRONG",{});var Smt=s(jfe);Xyo=r(Smt,"xglm"),Smt.forEach(t),zyo=r(mxe," \u2014 "),aG=n(mxe,"A",{href:!0});var Rmt=s(aG);Wyo=r(Rmt,"XGLMForCausalLM"),Rmt.forEach(t),Qyo=r(mxe," (XGLM model)"),mxe.forEach(t),Hyo=i(W),K1=n(W,"LI",{});var gxe=s(K1);Dfe=n(gxe,"STRONG",{});var Pmt=s(Dfe);Uyo=r(Pmt,"xlm"),Pmt.forEach(t),Jyo=r(gxe," \u2014 "),nG=n(gxe,"A",{href:!0});var Bmt=s(nG);Yyo=r(Bmt,"XLMWithLMHeadModel"),Bmt.forEach(t),Kyo=r(gxe," (XLM model)"),gxe.forEach(t),Zyo=i(W),Z1=n(W,"LI",{});var hxe=s(Z1);Gfe=n(hxe,"STRONG",{});var Imt=s(Gfe);eLo=r(Imt,"xlm-prophetnet"),Imt.forEach(t),oLo=r(hxe," \u2014 "),sG=n(hxe,"A",{href:!0});var Nmt=s(sG);rLo=r(Nmt,"XLMProphetNetForCausalLM"),Nmt.forEach(t),tLo=r(hxe," (XLM-ProphetNet model)"),hxe.forEach(t),aLo=i(W),eb=n(W,"LI",{});var pxe=s(eb);Ofe=n(pxe,"STRONG",{});var qmt=s(Ofe);nLo=r(qmt,"xlm-roberta"),qmt.forEach(t),sLo=r(pxe," \u2014 "),lG=n(pxe,"A",{href:!0});var jmt=s(lG);lLo=r(jmt,"XLMRobertaForCausalLM"),jmt.forEach(t),iLo=r(pxe," (XLM-RoBERTa model)"),pxe.forEach(t),dLo=i(W),ob=n(W,"LI",{});var uxe=s(ob);Vfe=n(uxe,"STRONG",{});var Dmt=s(Vfe);cLo=r(Dmt,"xlm-roberta-xl"),Dmt.forEach(t),fLo=r(uxe," \u2014 "),iG=n(uxe,"A",{href:!0});var Gmt=s(iG);mLo=r(Gmt,"XLMRobertaXLForCausalLM"),Gmt.forEach(t),gLo=r(uxe," (XLM-RoBERTa-XL model)"),uxe.forEach(t),hLo=i(W),rb=n(W,"LI",{});var _xe=s(rb);Xfe=n(_xe,"STRONG",{});var Omt=s(Xfe);pLo=r(Omt,"xlnet"),Omt.forEach(t),uLo=r(_xe," \u2014 "),dG=n(_xe,"A",{href:!0});var Vmt=s(dG);_Lo=r(Vmt,"XLNetLMHeadModel"),Vmt.forEach(t),bLo=r(_xe," (XLNet model)"),_xe.forEach(t),W.forEach(t),vLo=i(sa),tb=n(sa,"P",{});var bxe=s(tb);FLo=r(bxe,"The model is set in evaluation mode by default using "),zfe=n(bxe,"CODE",{});var Xmt=s(zfe);TLo=r(Xmt,"model.eval()"),Xmt.forEach(t),MLo=r(bxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wfe=n(bxe,"CODE",{});var zmt=s(Wfe);ELo=r(zmt,"model.train()"),zmt.forEach(t),bxe.forEach(t),CLo=i(sa),T(ab.$$.fragment,sa),sa.forEach(t),Js.forEach(t),ODe=i(f),Oi=n(f,"H2",{class:!0});var HOe=s(Oi);nb=n(HOe,"A",{id:!0,class:!0,href:!0});var Wmt=s(nb);Qfe=n(Wmt,"SPAN",{});var Qmt=s(Qfe);T(ZA.$$.fragment,Qmt),Qmt.forEach(t),Wmt.forEach(t),wLo=i(HOe),Hfe=n(HOe,"SPAN",{});var Hmt=s(Hfe);ALo=r(Hmt,"AutoModelForMaskedLM"),Hmt.forEach(t),HOe.forEach(t),VDe=i(f),So=n(f,"DIV",{class:!0});var Ys=s(So);T(ey.$$.fragment,Ys),yLo=i(Ys),Vi=n(Ys,"P",{});var Gee=s(Vi);LLo=r(Gee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),cG=n(Gee,"A",{href:!0});var Umt=s(cG);xLo=r(Umt,"from_pretrained()"),Umt.forEach(t),$Lo=r(Gee," class method or the "),fG=n(Gee,"A",{href:!0});var Jmt=s(fG);kLo=r(Jmt,"from_config()"),Jmt.forEach(t),SLo=r(Gee,` class
method.`),Gee.forEach(t),RLo=i(Ys),oy=n(Ys,"P",{});var UOe=s(oy);PLo=r(UOe,"This class cannot be instantiated directly using "),Ufe=n(UOe,"CODE",{});var Ymt=s(Ufe);BLo=r(Ymt,"__init__()"),Ymt.forEach(t),ILo=r(UOe," (throws an error)."),UOe.forEach(t),NLo=i(Ys),it=n(Ys,"DIV",{class:!0});var F0=s(it);T(ry.$$.fragment,F0),qLo=i(F0),Jfe=n(F0,"P",{});var Kmt=s(Jfe);jLo=r(Kmt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Kmt.forEach(t),DLo=i(F0),Xi=n(F0,"P",{});var Oee=s(Xi);GLo=r(Oee,`Note:
Loading a model from its configuration file does `),Yfe=n(Oee,"STRONG",{});var Zmt=s(Yfe);OLo=r(Zmt,"not"),Zmt.forEach(t),VLo=r(Oee,` load the model weights. It only affects the
model\u2019s configuration. Use `),mG=n(Oee,"A",{href:!0});var egt=s(mG);XLo=r(egt,"from_pretrained()"),egt.forEach(t),zLo=r(Oee," to load the model weights."),Oee.forEach(t),WLo=i(F0),T(sb.$$.fragment,F0),F0.forEach(t),QLo=i(Ys),Ze=n(Ys,"DIV",{class:!0});var la=s(Ze);T(ty.$$.fragment,la),HLo=i(la),Kfe=n(la,"P",{});var ogt=s(Kfe);ULo=r(ogt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ogt.forEach(t),JLo=i(la),Ba=n(la,"P",{});var T0=s(Ba);YLo=r(T0,"The model class to instantiate is selected based on the "),Zfe=n(T0,"CODE",{});var rgt=s(Zfe);KLo=r(rgt,"model_type"),rgt.forEach(t),ZLo=r(T0,` property of the config object (either
passed as an argument or loaded from `),eme=n(T0,"CODE",{});var tgt=s(eme);e8o=r(tgt,"pretrained_model_name_or_path"),tgt.forEach(t),o8o=r(T0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ome=n(T0,"CODE",{});var agt=s(ome);r8o=r(agt,"pretrained_model_name_or_path"),agt.forEach(t),t8o=r(T0,":"),T0.forEach(t),a8o=i(la),Q=n(la,"UL",{});var U=s(Q);lb=n(U,"LI",{});var vxe=s(lb);rme=n(vxe,"STRONG",{});var ngt=s(rme);n8o=r(ngt,"albert"),ngt.forEach(t),s8o=r(vxe," \u2014 "),gG=n(vxe,"A",{href:!0});var sgt=s(gG);l8o=r(sgt,"AlbertForMaskedLM"),sgt.forEach(t),i8o=r(vxe," (ALBERT model)"),vxe.forEach(t),d8o=i(U),ib=n(U,"LI",{});var Fxe=s(ib);tme=n(Fxe,"STRONG",{});var lgt=s(tme);c8o=r(lgt,"bart"),lgt.forEach(t),f8o=r(Fxe," \u2014 "),hG=n(Fxe,"A",{href:!0});var igt=s(hG);m8o=r(igt,"BartForConditionalGeneration"),igt.forEach(t),g8o=r(Fxe," (BART model)"),Fxe.forEach(t),h8o=i(U),db=n(U,"LI",{});var Txe=s(db);ame=n(Txe,"STRONG",{});var dgt=s(ame);p8o=r(dgt,"bert"),dgt.forEach(t),u8o=r(Txe," \u2014 "),pG=n(Txe,"A",{href:!0});var cgt=s(pG);_8o=r(cgt,"BertForMaskedLM"),cgt.forEach(t),b8o=r(Txe," (BERT model)"),Txe.forEach(t),v8o=i(U),cb=n(U,"LI",{});var Mxe=s(cb);nme=n(Mxe,"STRONG",{});var fgt=s(nme);F8o=r(fgt,"big_bird"),fgt.forEach(t),T8o=r(Mxe," \u2014 "),uG=n(Mxe,"A",{href:!0});var mgt=s(uG);M8o=r(mgt,"BigBirdForMaskedLM"),mgt.forEach(t),E8o=r(Mxe," (BigBird model)"),Mxe.forEach(t),C8o=i(U),fb=n(U,"LI",{});var Exe=s(fb);sme=n(Exe,"STRONG",{});var ggt=s(sme);w8o=r(ggt,"camembert"),ggt.forEach(t),A8o=r(Exe," \u2014 "),_G=n(Exe,"A",{href:!0});var hgt=s(_G);y8o=r(hgt,"CamembertForMaskedLM"),hgt.forEach(t),L8o=r(Exe," (CamemBERT model)"),Exe.forEach(t),x8o=i(U),mb=n(U,"LI",{});var Cxe=s(mb);lme=n(Cxe,"STRONG",{});var pgt=s(lme);$8o=r(pgt,"convbert"),pgt.forEach(t),k8o=r(Cxe," \u2014 "),bG=n(Cxe,"A",{href:!0});var ugt=s(bG);S8o=r(ugt,"ConvBertForMaskedLM"),ugt.forEach(t),R8o=r(Cxe," (ConvBERT model)"),Cxe.forEach(t),P8o=i(U),gb=n(U,"LI",{});var wxe=s(gb);ime=n(wxe,"STRONG",{});var _gt=s(ime);B8o=r(_gt,"data2vec-text"),_gt.forEach(t),I8o=r(wxe," \u2014 "),vG=n(wxe,"A",{href:!0});var bgt=s(vG);N8o=r(bgt,"Data2VecTextForMaskedLM"),bgt.forEach(t),q8o=r(wxe," (Data2VecText model)"),wxe.forEach(t),j8o=i(U),hb=n(U,"LI",{});var Axe=s(hb);dme=n(Axe,"STRONG",{});var vgt=s(dme);D8o=r(vgt,"deberta"),vgt.forEach(t),G8o=r(Axe," \u2014 "),FG=n(Axe,"A",{href:!0});var Fgt=s(FG);O8o=r(Fgt,"DebertaForMaskedLM"),Fgt.forEach(t),V8o=r(Axe," (DeBERTa model)"),Axe.forEach(t),X8o=i(U),pb=n(U,"LI",{});var yxe=s(pb);cme=n(yxe,"STRONG",{});var Tgt=s(cme);z8o=r(Tgt,"deberta-v2"),Tgt.forEach(t),W8o=r(yxe," \u2014 "),TG=n(yxe,"A",{href:!0});var Mgt=s(TG);Q8o=r(Mgt,"DebertaV2ForMaskedLM"),Mgt.forEach(t),H8o=r(yxe," (DeBERTa-v2 model)"),yxe.forEach(t),U8o=i(U),ub=n(U,"LI",{});var Lxe=s(ub);fme=n(Lxe,"STRONG",{});var Egt=s(fme);J8o=r(Egt,"distilbert"),Egt.forEach(t),Y8o=r(Lxe," \u2014 "),MG=n(Lxe,"A",{href:!0});var Cgt=s(MG);K8o=r(Cgt,"DistilBertForMaskedLM"),Cgt.forEach(t),Z8o=r(Lxe," (DistilBERT model)"),Lxe.forEach(t),exo=i(U),_b=n(U,"LI",{});var xxe=s(_b);mme=n(xxe,"STRONG",{});var wgt=s(mme);oxo=r(wgt,"electra"),wgt.forEach(t),rxo=r(xxe," \u2014 "),EG=n(xxe,"A",{href:!0});var Agt=s(EG);txo=r(Agt,"ElectraForMaskedLM"),Agt.forEach(t),axo=r(xxe," (ELECTRA model)"),xxe.forEach(t),nxo=i(U),bb=n(U,"LI",{});var $xe=s(bb);gme=n($xe,"STRONG",{});var ygt=s(gme);sxo=r(ygt,"flaubert"),ygt.forEach(t),lxo=r($xe," \u2014 "),CG=n($xe,"A",{href:!0});var Lgt=s(CG);ixo=r(Lgt,"FlaubertWithLMHeadModel"),Lgt.forEach(t),dxo=r($xe," (FlauBERT model)"),$xe.forEach(t),cxo=i(U),vb=n(U,"LI",{});var kxe=s(vb);hme=n(kxe,"STRONG",{});var xgt=s(hme);fxo=r(xgt,"fnet"),xgt.forEach(t),mxo=r(kxe," \u2014 "),wG=n(kxe,"A",{href:!0});var $gt=s(wG);gxo=r($gt,"FNetForMaskedLM"),$gt.forEach(t),hxo=r(kxe," (FNet model)"),kxe.forEach(t),pxo=i(U),Fb=n(U,"LI",{});var Sxe=s(Fb);pme=n(Sxe,"STRONG",{});var kgt=s(pme);uxo=r(kgt,"funnel"),kgt.forEach(t),_xo=r(Sxe," \u2014 "),AG=n(Sxe,"A",{href:!0});var Sgt=s(AG);bxo=r(Sgt,"FunnelForMaskedLM"),Sgt.forEach(t),vxo=r(Sxe," (Funnel Transformer model)"),Sxe.forEach(t),Fxo=i(U),Tb=n(U,"LI",{});var Rxe=s(Tb);ume=n(Rxe,"STRONG",{});var Rgt=s(ume);Txo=r(Rgt,"ibert"),Rgt.forEach(t),Mxo=r(Rxe," \u2014 "),yG=n(Rxe,"A",{href:!0});var Pgt=s(yG);Exo=r(Pgt,"IBertForMaskedLM"),Pgt.forEach(t),Cxo=r(Rxe," (I-BERT model)"),Rxe.forEach(t),wxo=i(U),Mb=n(U,"LI",{});var Pxe=s(Mb);_me=n(Pxe,"STRONG",{});var Bgt=s(_me);Axo=r(Bgt,"layoutlm"),Bgt.forEach(t),yxo=r(Pxe," \u2014 "),LG=n(Pxe,"A",{href:!0});var Igt=s(LG);Lxo=r(Igt,"LayoutLMForMaskedLM"),Igt.forEach(t),xxo=r(Pxe," (LayoutLM model)"),Pxe.forEach(t),$xo=i(U),Eb=n(U,"LI",{});var Bxe=s(Eb);bme=n(Bxe,"STRONG",{});var Ngt=s(bme);kxo=r(Ngt,"longformer"),Ngt.forEach(t),Sxo=r(Bxe," \u2014 "),xG=n(Bxe,"A",{href:!0});var qgt=s(xG);Rxo=r(qgt,"LongformerForMaskedLM"),qgt.forEach(t),Pxo=r(Bxe," (Longformer model)"),Bxe.forEach(t),Bxo=i(U),Cb=n(U,"LI",{});var Ixe=s(Cb);vme=n(Ixe,"STRONG",{});var jgt=s(vme);Ixo=r(jgt,"luke"),jgt.forEach(t),Nxo=r(Ixe," \u2014 "),$G=n(Ixe,"A",{href:!0});var Dgt=s($G);qxo=r(Dgt,"LukeForMaskedLM"),Dgt.forEach(t),jxo=r(Ixe," (LUKE model)"),Ixe.forEach(t),Dxo=i(U),wb=n(U,"LI",{});var Nxe=s(wb);Fme=n(Nxe,"STRONG",{});var Ggt=s(Fme);Gxo=r(Ggt,"mbart"),Ggt.forEach(t),Oxo=r(Nxe," \u2014 "),kG=n(Nxe,"A",{href:!0});var Ogt=s(kG);Vxo=r(Ogt,"MBartForConditionalGeneration"),Ogt.forEach(t),Xxo=r(Nxe," (mBART model)"),Nxe.forEach(t),zxo=i(U),Ab=n(U,"LI",{});var qxe=s(Ab);Tme=n(qxe,"STRONG",{});var Vgt=s(Tme);Wxo=r(Vgt,"megatron-bert"),Vgt.forEach(t),Qxo=r(qxe," \u2014 "),SG=n(qxe,"A",{href:!0});var Xgt=s(SG);Hxo=r(Xgt,"MegatronBertForMaskedLM"),Xgt.forEach(t),Uxo=r(qxe," (Megatron-BERT model)"),qxe.forEach(t),Jxo=i(U),yb=n(U,"LI",{});var jxe=s(yb);Mme=n(jxe,"STRONG",{});var zgt=s(Mme);Yxo=r(zgt,"mobilebert"),zgt.forEach(t),Kxo=r(jxe," \u2014 "),RG=n(jxe,"A",{href:!0});var Wgt=s(RG);Zxo=r(Wgt,"MobileBertForMaskedLM"),Wgt.forEach(t),e$o=r(jxe," (MobileBERT model)"),jxe.forEach(t),o$o=i(U),Lb=n(U,"LI",{});var Dxe=s(Lb);Eme=n(Dxe,"STRONG",{});var Qgt=s(Eme);r$o=r(Qgt,"mpnet"),Qgt.forEach(t),t$o=r(Dxe," \u2014 "),PG=n(Dxe,"A",{href:!0});var Hgt=s(PG);a$o=r(Hgt,"MPNetForMaskedLM"),Hgt.forEach(t),n$o=r(Dxe," (MPNet model)"),Dxe.forEach(t),s$o=i(U),xb=n(U,"LI",{});var Gxe=s(xb);Cme=n(Gxe,"STRONG",{});var Ugt=s(Cme);l$o=r(Ugt,"nystromformer"),Ugt.forEach(t),i$o=r(Gxe," \u2014 "),BG=n(Gxe,"A",{href:!0});var Jgt=s(BG);d$o=r(Jgt,"NystromformerForMaskedLM"),Jgt.forEach(t),c$o=r(Gxe," (Nystr\xF6mformer model)"),Gxe.forEach(t),f$o=i(U),$b=n(U,"LI",{});var Oxe=s($b);wme=n(Oxe,"STRONG",{});var Ygt=s(wme);m$o=r(Ygt,"perceiver"),Ygt.forEach(t),g$o=r(Oxe," \u2014 "),IG=n(Oxe,"A",{href:!0});var Kgt=s(IG);h$o=r(Kgt,"PerceiverForMaskedLM"),Kgt.forEach(t),p$o=r(Oxe," (Perceiver model)"),Oxe.forEach(t),u$o=i(U),kb=n(U,"LI",{});var Vxe=s(kb);Ame=n(Vxe,"STRONG",{});var Zgt=s(Ame);_$o=r(Zgt,"qdqbert"),Zgt.forEach(t),b$o=r(Vxe," \u2014 "),NG=n(Vxe,"A",{href:!0});var eht=s(NG);v$o=r(eht,"QDQBertForMaskedLM"),eht.forEach(t),F$o=r(Vxe," (QDQBert model)"),Vxe.forEach(t),T$o=i(U),Sb=n(U,"LI",{});var Xxe=s(Sb);yme=n(Xxe,"STRONG",{});var oht=s(yme);M$o=r(oht,"reformer"),oht.forEach(t),E$o=r(Xxe," \u2014 "),qG=n(Xxe,"A",{href:!0});var rht=s(qG);C$o=r(rht,"ReformerForMaskedLM"),rht.forEach(t),w$o=r(Xxe," (Reformer model)"),Xxe.forEach(t),A$o=i(U),Rb=n(U,"LI",{});var zxe=s(Rb);Lme=n(zxe,"STRONG",{});var tht=s(Lme);y$o=r(tht,"rembert"),tht.forEach(t),L$o=r(zxe," \u2014 "),jG=n(zxe,"A",{href:!0});var aht=s(jG);x$o=r(aht,"RemBertForMaskedLM"),aht.forEach(t),$$o=r(zxe," (RemBERT model)"),zxe.forEach(t),k$o=i(U),Pb=n(U,"LI",{});var Wxe=s(Pb);xme=n(Wxe,"STRONG",{});var nht=s(xme);S$o=r(nht,"roberta"),nht.forEach(t),R$o=r(Wxe," \u2014 "),DG=n(Wxe,"A",{href:!0});var sht=s(DG);P$o=r(sht,"RobertaForMaskedLM"),sht.forEach(t),B$o=r(Wxe," (RoBERTa model)"),Wxe.forEach(t),I$o=i(U),Bb=n(U,"LI",{});var Qxe=s(Bb);$me=n(Qxe,"STRONG",{});var lht=s($me);N$o=r(lht,"roformer"),lht.forEach(t),q$o=r(Qxe," \u2014 "),GG=n(Qxe,"A",{href:!0});var iht=s(GG);j$o=r(iht,"RoFormerForMaskedLM"),iht.forEach(t),D$o=r(Qxe," (RoFormer model)"),Qxe.forEach(t),G$o=i(U),Ib=n(U,"LI",{});var Hxe=s(Ib);kme=n(Hxe,"STRONG",{});var dht=s(kme);O$o=r(dht,"squeezebert"),dht.forEach(t),V$o=r(Hxe," \u2014 "),OG=n(Hxe,"A",{href:!0});var cht=s(OG);X$o=r(cht,"SqueezeBertForMaskedLM"),cht.forEach(t),z$o=r(Hxe," (SqueezeBERT model)"),Hxe.forEach(t),W$o=i(U),Nb=n(U,"LI",{});var Uxe=s(Nb);Sme=n(Uxe,"STRONG",{});var fht=s(Sme);Q$o=r(fht,"tapas"),fht.forEach(t),H$o=r(Uxe," \u2014 "),VG=n(Uxe,"A",{href:!0});var mht=s(VG);U$o=r(mht,"TapasForMaskedLM"),mht.forEach(t),J$o=r(Uxe," (TAPAS model)"),Uxe.forEach(t),Y$o=i(U),qb=n(U,"LI",{});var Jxe=s(qb);Rme=n(Jxe,"STRONG",{});var ght=s(Rme);K$o=r(ght,"wav2vec2"),ght.forEach(t),Z$o=r(Jxe," \u2014 "),Pme=n(Jxe,"CODE",{});var hht=s(Pme);eko=r(hht,"Wav2Vec2ForMaskedLM"),hht.forEach(t),oko=r(Jxe," (Wav2Vec2 model)"),Jxe.forEach(t),rko=i(U),jb=n(U,"LI",{});var Yxe=s(jb);Bme=n(Yxe,"STRONG",{});var pht=s(Bme);tko=r(pht,"xlm"),pht.forEach(t),ako=r(Yxe," \u2014 "),XG=n(Yxe,"A",{href:!0});var uht=s(XG);nko=r(uht,"XLMWithLMHeadModel"),uht.forEach(t),sko=r(Yxe," (XLM model)"),Yxe.forEach(t),lko=i(U),Db=n(U,"LI",{});var Kxe=s(Db);Ime=n(Kxe,"STRONG",{});var _ht=s(Ime);iko=r(_ht,"xlm-roberta"),_ht.forEach(t),dko=r(Kxe," \u2014 "),zG=n(Kxe,"A",{href:!0});var bht=s(zG);cko=r(bht,"XLMRobertaForMaskedLM"),bht.forEach(t),fko=r(Kxe," (XLM-RoBERTa model)"),Kxe.forEach(t),mko=i(U),Gb=n(U,"LI",{});var Zxe=s(Gb);Nme=n(Zxe,"STRONG",{});var vht=s(Nme);gko=r(vht,"xlm-roberta-xl"),vht.forEach(t),hko=r(Zxe," \u2014 "),WG=n(Zxe,"A",{href:!0});var Fht=s(WG);pko=r(Fht,"XLMRobertaXLForMaskedLM"),Fht.forEach(t),uko=r(Zxe," (XLM-RoBERTa-XL model)"),Zxe.forEach(t),_ko=i(U),Ob=n(U,"LI",{});var e$e=s(Ob);qme=n(e$e,"STRONG",{});var Tht=s(qme);bko=r(Tht,"yoso"),Tht.forEach(t),vko=r(e$e," \u2014 "),QG=n(e$e,"A",{href:!0});var Mht=s(QG);Fko=r(Mht,"YosoForMaskedLM"),Mht.forEach(t),Tko=r(e$e," (YOSO model)"),e$e.forEach(t),U.forEach(t),Mko=i(la),Vb=n(la,"P",{});var o$e=s(Vb);Eko=r(o$e,"The model is set in evaluation mode by default using "),jme=n(o$e,"CODE",{});var Eht=s(jme);Cko=r(Eht,"model.eval()"),Eht.forEach(t),wko=r(o$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dme=n(o$e,"CODE",{});var Cht=s(Dme);Ako=r(Cht,"model.train()"),Cht.forEach(t),o$e.forEach(t),yko=i(la),T(Xb.$$.fragment,la),la.forEach(t),Ys.forEach(t),XDe=i(f),zi=n(f,"H2",{class:!0});var JOe=s(zi);zb=n(JOe,"A",{id:!0,class:!0,href:!0});var wht=s(zb);Gme=n(wht,"SPAN",{});var Aht=s(Gme);T(ay.$$.fragment,Aht),Aht.forEach(t),wht.forEach(t),Lko=i(JOe),Ome=n(JOe,"SPAN",{});var yht=s(Ome);xko=r(yht,"AutoModelForSeq2SeqLM"),yht.forEach(t),JOe.forEach(t),zDe=i(f),Ro=n(f,"DIV",{class:!0});var Ks=s(Ro);T(ny.$$.fragment,Ks),$ko=i(Ks),Wi=n(Ks,"P",{});var Vee=s(Wi);kko=r(Vee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),HG=n(Vee,"A",{href:!0});var Lht=s(HG);Sko=r(Lht,"from_pretrained()"),Lht.forEach(t),Rko=r(Vee," class method or the "),UG=n(Vee,"A",{href:!0});var xht=s(UG);Pko=r(xht,"from_config()"),xht.forEach(t),Bko=r(Vee,` class
method.`),Vee.forEach(t),Iko=i(Ks),sy=n(Ks,"P",{});var YOe=s(sy);Nko=r(YOe,"This class cannot be instantiated directly using "),Vme=n(YOe,"CODE",{});var $ht=s(Vme);qko=r($ht,"__init__()"),$ht.forEach(t),jko=r(YOe," (throws an error)."),YOe.forEach(t),Dko=i(Ks),dt=n(Ks,"DIV",{class:!0});var M0=s(dt);T(ly.$$.fragment,M0),Gko=i(M0),Xme=n(M0,"P",{});var kht=s(Xme);Oko=r(kht,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),kht.forEach(t),Vko=i(M0),Qi=n(M0,"P",{});var Xee=s(Qi);Xko=r(Xee,`Note:
Loading a model from its configuration file does `),zme=n(Xee,"STRONG",{});var Sht=s(zme);zko=r(Sht,"not"),Sht.forEach(t),Wko=r(Xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),JG=n(Xee,"A",{href:!0});var Rht=s(JG);Qko=r(Rht,"from_pretrained()"),Rht.forEach(t),Hko=r(Xee," to load the model weights."),Xee.forEach(t),Uko=i(M0),T(Wb.$$.fragment,M0),M0.forEach(t),Jko=i(Ks),eo=n(Ks,"DIV",{class:!0});var ia=s(eo);T(iy.$$.fragment,ia),Yko=i(ia),Wme=n(ia,"P",{});var Pht=s(Wme);Kko=r(Pht,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Pht.forEach(t),Zko=i(ia),Ia=n(ia,"P",{});var E0=s(Ia);eSo=r(E0,"The model class to instantiate is selected based on the "),Qme=n(E0,"CODE",{});var Bht=s(Qme);oSo=r(Bht,"model_type"),Bht.forEach(t),rSo=r(E0,` property of the config object (either
passed as an argument or loaded from `),Hme=n(E0,"CODE",{});var Iht=s(Hme);tSo=r(Iht,"pretrained_model_name_or_path"),Iht.forEach(t),aSo=r(E0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ume=n(E0,"CODE",{});var Nht=s(Ume);nSo=r(Nht,"pretrained_model_name_or_path"),Nht.forEach(t),sSo=r(E0,":"),E0.forEach(t),lSo=i(ia),ue=n(ia,"UL",{});var Fe=s(ue);Qb=n(Fe,"LI",{});var r$e=s(Qb);Jme=n(r$e,"STRONG",{});var qht=s(Jme);iSo=r(qht,"bart"),qht.forEach(t),dSo=r(r$e," \u2014 "),YG=n(r$e,"A",{href:!0});var jht=s(YG);cSo=r(jht,"BartForConditionalGeneration"),jht.forEach(t),fSo=r(r$e," (BART model)"),r$e.forEach(t),mSo=i(Fe),Hb=n(Fe,"LI",{});var t$e=s(Hb);Yme=n(t$e,"STRONG",{});var Dht=s(Yme);gSo=r(Dht,"bigbird_pegasus"),Dht.forEach(t),hSo=r(t$e," \u2014 "),KG=n(t$e,"A",{href:!0});var Ght=s(KG);pSo=r(Ght,"BigBirdPegasusForConditionalGeneration"),Ght.forEach(t),uSo=r(t$e," (BigBird-Pegasus model)"),t$e.forEach(t),_So=i(Fe),Ub=n(Fe,"LI",{});var a$e=s(Ub);Kme=n(a$e,"STRONG",{});var Oht=s(Kme);bSo=r(Oht,"blenderbot"),Oht.forEach(t),vSo=r(a$e," \u2014 "),ZG=n(a$e,"A",{href:!0});var Vht=s(ZG);FSo=r(Vht,"BlenderbotForConditionalGeneration"),Vht.forEach(t),TSo=r(a$e," (Blenderbot model)"),a$e.forEach(t),MSo=i(Fe),Jb=n(Fe,"LI",{});var n$e=s(Jb);Zme=n(n$e,"STRONG",{});var Xht=s(Zme);ESo=r(Xht,"blenderbot-small"),Xht.forEach(t),CSo=r(n$e," \u2014 "),eO=n(n$e,"A",{href:!0});var zht=s(eO);wSo=r(zht,"BlenderbotSmallForConditionalGeneration"),zht.forEach(t),ASo=r(n$e," (BlenderbotSmall model)"),n$e.forEach(t),ySo=i(Fe),Yb=n(Fe,"LI",{});var s$e=s(Yb);ege=n(s$e,"STRONG",{});var Wht=s(ege);LSo=r(Wht,"encoder-decoder"),Wht.forEach(t),xSo=r(s$e," \u2014 "),oO=n(s$e,"A",{href:!0});var Qht=s(oO);$So=r(Qht,"EncoderDecoderModel"),Qht.forEach(t),kSo=r(s$e," (Encoder decoder model)"),s$e.forEach(t),SSo=i(Fe),Kb=n(Fe,"LI",{});var l$e=s(Kb);oge=n(l$e,"STRONG",{});var Hht=s(oge);RSo=r(Hht,"fsmt"),Hht.forEach(t),PSo=r(l$e," \u2014 "),rO=n(l$e,"A",{href:!0});var Uht=s(rO);BSo=r(Uht,"FSMTForConditionalGeneration"),Uht.forEach(t),ISo=r(l$e," (FairSeq Machine-Translation model)"),l$e.forEach(t),NSo=i(Fe),Zb=n(Fe,"LI",{});var i$e=s(Zb);rge=n(i$e,"STRONG",{});var Jht=s(rge);qSo=r(Jht,"led"),Jht.forEach(t),jSo=r(i$e," \u2014 "),tO=n(i$e,"A",{href:!0});var Yht=s(tO);DSo=r(Yht,"LEDForConditionalGeneration"),Yht.forEach(t),GSo=r(i$e," (LED model)"),i$e.forEach(t),OSo=i(Fe),e2=n(Fe,"LI",{});var d$e=s(e2);tge=n(d$e,"STRONG",{});var Kht=s(tge);VSo=r(Kht,"m2m_100"),Kht.forEach(t),XSo=r(d$e," \u2014 "),aO=n(d$e,"A",{href:!0});var Zht=s(aO);zSo=r(Zht,"M2M100ForConditionalGeneration"),Zht.forEach(t),WSo=r(d$e," (M2M100 model)"),d$e.forEach(t),QSo=i(Fe),o2=n(Fe,"LI",{});var c$e=s(o2);age=n(c$e,"STRONG",{});var ept=s(age);HSo=r(ept,"marian"),ept.forEach(t),USo=r(c$e," \u2014 "),nO=n(c$e,"A",{href:!0});var opt=s(nO);JSo=r(opt,"MarianMTModel"),opt.forEach(t),YSo=r(c$e," (Marian model)"),c$e.forEach(t),KSo=i(Fe),r2=n(Fe,"LI",{});var f$e=s(r2);nge=n(f$e,"STRONG",{});var rpt=s(nge);ZSo=r(rpt,"mbart"),rpt.forEach(t),eRo=r(f$e," \u2014 "),sO=n(f$e,"A",{href:!0});var tpt=s(sO);oRo=r(tpt,"MBartForConditionalGeneration"),tpt.forEach(t),rRo=r(f$e," (mBART model)"),f$e.forEach(t),tRo=i(Fe),t2=n(Fe,"LI",{});var m$e=s(t2);sge=n(m$e,"STRONG",{});var apt=s(sge);aRo=r(apt,"mt5"),apt.forEach(t),nRo=r(m$e," \u2014 "),lO=n(m$e,"A",{href:!0});var npt=s(lO);sRo=r(npt,"MT5ForConditionalGeneration"),npt.forEach(t),lRo=r(m$e," (MT5 model)"),m$e.forEach(t),iRo=i(Fe),a2=n(Fe,"LI",{});var g$e=s(a2);lge=n(g$e,"STRONG",{});var spt=s(lge);dRo=r(spt,"pegasus"),spt.forEach(t),cRo=r(g$e," \u2014 "),iO=n(g$e,"A",{href:!0});var lpt=s(iO);fRo=r(lpt,"PegasusForConditionalGeneration"),lpt.forEach(t),mRo=r(g$e," (Pegasus model)"),g$e.forEach(t),gRo=i(Fe),n2=n(Fe,"LI",{});var h$e=s(n2);ige=n(h$e,"STRONG",{});var ipt=s(ige);hRo=r(ipt,"plbart"),ipt.forEach(t),pRo=r(h$e," \u2014 "),dO=n(h$e,"A",{href:!0});var dpt=s(dO);uRo=r(dpt,"PLBartForConditionalGeneration"),dpt.forEach(t),_Ro=r(h$e," (PLBart model)"),h$e.forEach(t),bRo=i(Fe),s2=n(Fe,"LI",{});var p$e=s(s2);dge=n(p$e,"STRONG",{});var cpt=s(dge);vRo=r(cpt,"prophetnet"),cpt.forEach(t),FRo=r(p$e," \u2014 "),cO=n(p$e,"A",{href:!0});var fpt=s(cO);TRo=r(fpt,"ProphetNetForConditionalGeneration"),fpt.forEach(t),MRo=r(p$e," (ProphetNet model)"),p$e.forEach(t),ERo=i(Fe),l2=n(Fe,"LI",{});var u$e=s(l2);cge=n(u$e,"STRONG",{});var mpt=s(cge);CRo=r(mpt,"t5"),mpt.forEach(t),wRo=r(u$e," \u2014 "),fO=n(u$e,"A",{href:!0});var gpt=s(fO);ARo=r(gpt,"T5ForConditionalGeneration"),gpt.forEach(t),yRo=r(u$e," (T5 model)"),u$e.forEach(t),LRo=i(Fe),i2=n(Fe,"LI",{});var _$e=s(i2);fge=n(_$e,"STRONG",{});var hpt=s(fge);xRo=r(hpt,"xlm-prophetnet"),hpt.forEach(t),$Ro=r(_$e," \u2014 "),mO=n(_$e,"A",{href:!0});var ppt=s(mO);kRo=r(ppt,"XLMProphetNetForConditionalGeneration"),ppt.forEach(t),SRo=r(_$e," (XLM-ProphetNet model)"),_$e.forEach(t),Fe.forEach(t),RRo=i(ia),d2=n(ia,"P",{});var b$e=s(d2);PRo=r(b$e,"The model is set in evaluation mode by default using "),mge=n(b$e,"CODE",{});var upt=s(mge);BRo=r(upt,"model.eval()"),upt.forEach(t),IRo=r(b$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gge=n(b$e,"CODE",{});var _pt=s(gge);NRo=r(_pt,"model.train()"),_pt.forEach(t),b$e.forEach(t),qRo=i(ia),T(c2.$$.fragment,ia),ia.forEach(t),Ks.forEach(t),WDe=i(f),Hi=n(f,"H2",{class:!0});var KOe=s(Hi);f2=n(KOe,"A",{id:!0,class:!0,href:!0});var bpt=s(f2);hge=n(bpt,"SPAN",{});var vpt=s(hge);T(dy.$$.fragment,vpt),vpt.forEach(t),bpt.forEach(t),jRo=i(KOe),pge=n(KOe,"SPAN",{});var Fpt=s(pge);DRo=r(Fpt,"AutoModelForSequenceClassification"),Fpt.forEach(t),KOe.forEach(t),QDe=i(f),Po=n(f,"DIV",{class:!0});var Zs=s(Po);T(cy.$$.fragment,Zs),GRo=i(Zs),Ui=n(Zs,"P",{});var zee=s(Ui);ORo=r(zee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gO=n(zee,"A",{href:!0});var Tpt=s(gO);VRo=r(Tpt,"from_pretrained()"),Tpt.forEach(t),XRo=r(zee," class method or the "),hO=n(zee,"A",{href:!0});var Mpt=s(hO);zRo=r(Mpt,"from_config()"),Mpt.forEach(t),WRo=r(zee,` class
method.`),zee.forEach(t),QRo=i(Zs),fy=n(Zs,"P",{});var ZOe=s(fy);HRo=r(ZOe,"This class cannot be instantiated directly using "),uge=n(ZOe,"CODE",{});var Ept=s(uge);URo=r(Ept,"__init__()"),Ept.forEach(t),JRo=r(ZOe," (throws an error)."),ZOe.forEach(t),YRo=i(Zs),ct=n(Zs,"DIV",{class:!0});var C0=s(ct);T(my.$$.fragment,C0),KRo=i(C0),_ge=n(C0,"P",{});var Cpt=s(_ge);ZRo=r(Cpt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Cpt.forEach(t),ePo=i(C0),Ji=n(C0,"P",{});var Wee=s(Ji);oPo=r(Wee,`Note:
Loading a model from its configuration file does `),bge=n(Wee,"STRONG",{});var wpt=s(bge);rPo=r(wpt,"not"),wpt.forEach(t),tPo=r(Wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),pO=n(Wee,"A",{href:!0});var Apt=s(pO);aPo=r(Apt,"from_pretrained()"),Apt.forEach(t),nPo=r(Wee," to load the model weights."),Wee.forEach(t),sPo=i(C0),T(m2.$$.fragment,C0),C0.forEach(t),lPo=i(Zs),oo=n(Zs,"DIV",{class:!0});var da=s(oo);T(gy.$$.fragment,da),iPo=i(da),vge=n(da,"P",{});var ypt=s(vge);dPo=r(ypt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ypt.forEach(t),cPo=i(da),Na=n(da,"P",{});var w0=s(Na);fPo=r(w0,"The model class to instantiate is selected based on the "),Fge=n(w0,"CODE",{});var Lpt=s(Fge);mPo=r(Lpt,"model_type"),Lpt.forEach(t),gPo=r(w0,` property of the config object (either
passed as an argument or loaded from `),Tge=n(w0,"CODE",{});var xpt=s(Tge);hPo=r(xpt,"pretrained_model_name_or_path"),xpt.forEach(t),pPo=r(w0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mge=n(w0,"CODE",{});var $pt=s(Mge);uPo=r($pt,"pretrained_model_name_or_path"),$pt.forEach(t),_Po=r(w0,":"),w0.forEach(t),bPo=i(da),N=n(da,"UL",{});var j=s(N);g2=n(j,"LI",{});var v$e=s(g2);Ege=n(v$e,"STRONG",{});var kpt=s(Ege);vPo=r(kpt,"albert"),kpt.forEach(t),FPo=r(v$e," \u2014 "),uO=n(v$e,"A",{href:!0});var Spt=s(uO);TPo=r(Spt,"AlbertForSequenceClassification"),Spt.forEach(t),MPo=r(v$e," (ALBERT model)"),v$e.forEach(t),EPo=i(j),h2=n(j,"LI",{});var F$e=s(h2);Cge=n(F$e,"STRONG",{});var Rpt=s(Cge);CPo=r(Rpt,"bart"),Rpt.forEach(t),wPo=r(F$e," \u2014 "),_O=n(F$e,"A",{href:!0});var Ppt=s(_O);APo=r(Ppt,"BartForSequenceClassification"),Ppt.forEach(t),yPo=r(F$e," (BART model)"),F$e.forEach(t),LPo=i(j),p2=n(j,"LI",{});var T$e=s(p2);wge=n(T$e,"STRONG",{});var Bpt=s(wge);xPo=r(Bpt,"bert"),Bpt.forEach(t),$Po=r(T$e," \u2014 "),bO=n(T$e,"A",{href:!0});var Ipt=s(bO);kPo=r(Ipt,"BertForSequenceClassification"),Ipt.forEach(t),SPo=r(T$e," (BERT model)"),T$e.forEach(t),RPo=i(j),u2=n(j,"LI",{});var M$e=s(u2);Age=n(M$e,"STRONG",{});var Npt=s(Age);PPo=r(Npt,"big_bird"),Npt.forEach(t),BPo=r(M$e," \u2014 "),vO=n(M$e,"A",{href:!0});var qpt=s(vO);IPo=r(qpt,"BigBirdForSequenceClassification"),qpt.forEach(t),NPo=r(M$e," (BigBird model)"),M$e.forEach(t),qPo=i(j),_2=n(j,"LI",{});var E$e=s(_2);yge=n(E$e,"STRONG",{});var jpt=s(yge);jPo=r(jpt,"bigbird_pegasus"),jpt.forEach(t),DPo=r(E$e," \u2014 "),FO=n(E$e,"A",{href:!0});var Dpt=s(FO);GPo=r(Dpt,"BigBirdPegasusForSequenceClassification"),Dpt.forEach(t),OPo=r(E$e," (BigBird-Pegasus model)"),E$e.forEach(t),VPo=i(j),b2=n(j,"LI",{});var C$e=s(b2);Lge=n(C$e,"STRONG",{});var Gpt=s(Lge);XPo=r(Gpt,"bloom"),Gpt.forEach(t),zPo=r(C$e," \u2014 "),TO=n(C$e,"A",{href:!0});var Opt=s(TO);WPo=r(Opt,"BloomForSequenceClassification"),Opt.forEach(t),QPo=r(C$e," (BLOOM model)"),C$e.forEach(t),HPo=i(j),v2=n(j,"LI",{});var w$e=s(v2);xge=n(w$e,"STRONG",{});var Vpt=s(xge);UPo=r(Vpt,"camembert"),Vpt.forEach(t),JPo=r(w$e," \u2014 "),MO=n(w$e,"A",{href:!0});var Xpt=s(MO);YPo=r(Xpt,"CamembertForSequenceClassification"),Xpt.forEach(t),KPo=r(w$e," (CamemBERT model)"),w$e.forEach(t),ZPo=i(j),F2=n(j,"LI",{});var A$e=s(F2);$ge=n(A$e,"STRONG",{});var zpt=s($ge);eBo=r(zpt,"canine"),zpt.forEach(t),oBo=r(A$e," \u2014 "),EO=n(A$e,"A",{href:!0});var Wpt=s(EO);rBo=r(Wpt,"CanineForSequenceClassification"),Wpt.forEach(t),tBo=r(A$e," (CANINE model)"),A$e.forEach(t),aBo=i(j),T2=n(j,"LI",{});var y$e=s(T2);kge=n(y$e,"STRONG",{});var Qpt=s(kge);nBo=r(Qpt,"convbert"),Qpt.forEach(t),sBo=r(y$e," \u2014 "),CO=n(y$e,"A",{href:!0});var Hpt=s(CO);lBo=r(Hpt,"ConvBertForSequenceClassification"),Hpt.forEach(t),iBo=r(y$e," (ConvBERT model)"),y$e.forEach(t),dBo=i(j),M2=n(j,"LI",{});var L$e=s(M2);Sge=n(L$e,"STRONG",{});var Upt=s(Sge);cBo=r(Upt,"ctrl"),Upt.forEach(t),fBo=r(L$e," \u2014 "),wO=n(L$e,"A",{href:!0});var Jpt=s(wO);mBo=r(Jpt,"CTRLForSequenceClassification"),Jpt.forEach(t),gBo=r(L$e," (CTRL model)"),L$e.forEach(t),hBo=i(j),E2=n(j,"LI",{});var x$e=s(E2);Rge=n(x$e,"STRONG",{});var Ypt=s(Rge);pBo=r(Ypt,"data2vec-text"),Ypt.forEach(t),uBo=r(x$e," \u2014 "),AO=n(x$e,"A",{href:!0});var Kpt=s(AO);_Bo=r(Kpt,"Data2VecTextForSequenceClassification"),Kpt.forEach(t),bBo=r(x$e," (Data2VecText model)"),x$e.forEach(t),vBo=i(j),C2=n(j,"LI",{});var $$e=s(C2);Pge=n($$e,"STRONG",{});var Zpt=s(Pge);FBo=r(Zpt,"deberta"),Zpt.forEach(t),TBo=r($$e," \u2014 "),yO=n($$e,"A",{href:!0});var eut=s(yO);MBo=r(eut,"DebertaForSequenceClassification"),eut.forEach(t),EBo=r($$e," (DeBERTa model)"),$$e.forEach(t),CBo=i(j),w2=n(j,"LI",{});var k$e=s(w2);Bge=n(k$e,"STRONG",{});var out=s(Bge);wBo=r(out,"deberta-v2"),out.forEach(t),ABo=r(k$e," \u2014 "),LO=n(k$e,"A",{href:!0});var rut=s(LO);yBo=r(rut,"DebertaV2ForSequenceClassification"),rut.forEach(t),LBo=r(k$e," (DeBERTa-v2 model)"),k$e.forEach(t),xBo=i(j),A2=n(j,"LI",{});var S$e=s(A2);Ige=n(S$e,"STRONG",{});var tut=s(Ige);$Bo=r(tut,"distilbert"),tut.forEach(t),kBo=r(S$e," \u2014 "),xO=n(S$e,"A",{href:!0});var aut=s(xO);SBo=r(aut,"DistilBertForSequenceClassification"),aut.forEach(t),RBo=r(S$e," (DistilBERT model)"),S$e.forEach(t),PBo=i(j),y2=n(j,"LI",{});var R$e=s(y2);Nge=n(R$e,"STRONG",{});var nut=s(Nge);BBo=r(nut,"electra"),nut.forEach(t),IBo=r(R$e," \u2014 "),$O=n(R$e,"A",{href:!0});var sut=s($O);NBo=r(sut,"ElectraForSequenceClassification"),sut.forEach(t),qBo=r(R$e," (ELECTRA model)"),R$e.forEach(t),jBo=i(j),L2=n(j,"LI",{});var P$e=s(L2);qge=n(P$e,"STRONG",{});var lut=s(qge);DBo=r(lut,"flaubert"),lut.forEach(t),GBo=r(P$e," \u2014 "),kO=n(P$e,"A",{href:!0});var iut=s(kO);OBo=r(iut,"FlaubertForSequenceClassification"),iut.forEach(t),VBo=r(P$e," (FlauBERT model)"),P$e.forEach(t),XBo=i(j),x2=n(j,"LI",{});var B$e=s(x2);jge=n(B$e,"STRONG",{});var dut=s(jge);zBo=r(dut,"fnet"),dut.forEach(t),WBo=r(B$e," \u2014 "),SO=n(B$e,"A",{href:!0});var cut=s(SO);QBo=r(cut,"FNetForSequenceClassification"),cut.forEach(t),HBo=r(B$e," (FNet model)"),B$e.forEach(t),UBo=i(j),$2=n(j,"LI",{});var I$e=s($2);Dge=n(I$e,"STRONG",{});var fut=s(Dge);JBo=r(fut,"funnel"),fut.forEach(t),YBo=r(I$e," \u2014 "),RO=n(I$e,"A",{href:!0});var mut=s(RO);KBo=r(mut,"FunnelForSequenceClassification"),mut.forEach(t),ZBo=r(I$e," (Funnel Transformer model)"),I$e.forEach(t),eIo=i(j),k2=n(j,"LI",{});var N$e=s(k2);Gge=n(N$e,"STRONG",{});var gut=s(Gge);oIo=r(gut,"gpt2"),gut.forEach(t),rIo=r(N$e," \u2014 "),PO=n(N$e,"A",{href:!0});var hut=s(PO);tIo=r(hut,"GPT2ForSequenceClassification"),hut.forEach(t),aIo=r(N$e," (OpenAI GPT-2 model)"),N$e.forEach(t),nIo=i(j),S2=n(j,"LI",{});var q$e=s(S2);Oge=n(q$e,"STRONG",{});var put=s(Oge);sIo=r(put,"gpt_neo"),put.forEach(t),lIo=r(q$e," \u2014 "),BO=n(q$e,"A",{href:!0});var uut=s(BO);iIo=r(uut,"GPTNeoForSequenceClassification"),uut.forEach(t),dIo=r(q$e," (GPT Neo model)"),q$e.forEach(t),cIo=i(j),R2=n(j,"LI",{});var j$e=s(R2);Vge=n(j$e,"STRONG",{});var _ut=s(Vge);fIo=r(_ut,"gptj"),_ut.forEach(t),mIo=r(j$e," \u2014 "),IO=n(j$e,"A",{href:!0});var but=s(IO);gIo=r(but,"GPTJForSequenceClassification"),but.forEach(t),hIo=r(j$e," (GPT-J model)"),j$e.forEach(t),pIo=i(j),P2=n(j,"LI",{});var D$e=s(P2);Xge=n(D$e,"STRONG",{});var vut=s(Xge);uIo=r(vut,"ibert"),vut.forEach(t),_Io=r(D$e," \u2014 "),NO=n(D$e,"A",{href:!0});var Fut=s(NO);bIo=r(Fut,"IBertForSequenceClassification"),Fut.forEach(t),vIo=r(D$e," (I-BERT model)"),D$e.forEach(t),FIo=i(j),B2=n(j,"LI",{});var G$e=s(B2);zge=n(G$e,"STRONG",{});var Tut=s(zge);TIo=r(Tut,"layoutlm"),Tut.forEach(t),MIo=r(G$e," \u2014 "),qO=n(G$e,"A",{href:!0});var Mut=s(qO);EIo=r(Mut,"LayoutLMForSequenceClassification"),Mut.forEach(t),CIo=r(G$e," (LayoutLM model)"),G$e.forEach(t),wIo=i(j),I2=n(j,"LI",{});var O$e=s(I2);Wge=n(O$e,"STRONG",{});var Eut=s(Wge);AIo=r(Eut,"layoutlmv2"),Eut.forEach(t),yIo=r(O$e," \u2014 "),jO=n(O$e,"A",{href:!0});var Cut=s(jO);LIo=r(Cut,"LayoutLMv2ForSequenceClassification"),Cut.forEach(t),xIo=r(O$e," (LayoutLMv2 model)"),O$e.forEach(t),$Io=i(j),N2=n(j,"LI",{});var V$e=s(N2);Qge=n(V$e,"STRONG",{});var wut=s(Qge);kIo=r(wut,"layoutlmv3"),wut.forEach(t),SIo=r(V$e," \u2014 "),DO=n(V$e,"A",{href:!0});var Aut=s(DO);RIo=r(Aut,"LayoutLMv3ForSequenceClassification"),Aut.forEach(t),PIo=r(V$e," (LayoutLMv3 model)"),V$e.forEach(t),BIo=i(j),q2=n(j,"LI",{});var X$e=s(q2);Hge=n(X$e,"STRONG",{});var yut=s(Hge);IIo=r(yut,"led"),yut.forEach(t),NIo=r(X$e," \u2014 "),GO=n(X$e,"A",{href:!0});var Lut=s(GO);qIo=r(Lut,"LEDForSequenceClassification"),Lut.forEach(t),jIo=r(X$e," (LED model)"),X$e.forEach(t),DIo=i(j),j2=n(j,"LI",{});var z$e=s(j2);Uge=n(z$e,"STRONG",{});var xut=s(Uge);GIo=r(xut,"longformer"),xut.forEach(t),OIo=r(z$e," \u2014 "),OO=n(z$e,"A",{href:!0});var $ut=s(OO);VIo=r($ut,"LongformerForSequenceClassification"),$ut.forEach(t),XIo=r(z$e," (Longformer model)"),z$e.forEach(t),zIo=i(j),D2=n(j,"LI",{});var W$e=s(D2);Jge=n(W$e,"STRONG",{});var kut=s(Jge);WIo=r(kut,"mbart"),kut.forEach(t),QIo=r(W$e," \u2014 "),VO=n(W$e,"A",{href:!0});var Sut=s(VO);HIo=r(Sut,"MBartForSequenceClassification"),Sut.forEach(t),UIo=r(W$e," (mBART model)"),W$e.forEach(t),JIo=i(j),G2=n(j,"LI",{});var Q$e=s(G2);Yge=n(Q$e,"STRONG",{});var Rut=s(Yge);YIo=r(Rut,"megatron-bert"),Rut.forEach(t),KIo=r(Q$e," \u2014 "),XO=n(Q$e,"A",{href:!0});var Put=s(XO);ZIo=r(Put,"MegatronBertForSequenceClassification"),Put.forEach(t),eNo=r(Q$e," (Megatron-BERT model)"),Q$e.forEach(t),oNo=i(j),O2=n(j,"LI",{});var H$e=s(O2);Kge=n(H$e,"STRONG",{});var But=s(Kge);rNo=r(But,"mobilebert"),But.forEach(t),tNo=r(H$e," \u2014 "),zO=n(H$e,"A",{href:!0});var Iut=s(zO);aNo=r(Iut,"MobileBertForSequenceClassification"),Iut.forEach(t),nNo=r(H$e," (MobileBERT model)"),H$e.forEach(t),sNo=i(j),V2=n(j,"LI",{});var U$e=s(V2);Zge=n(U$e,"STRONG",{});var Nut=s(Zge);lNo=r(Nut,"mpnet"),Nut.forEach(t),iNo=r(U$e," \u2014 "),WO=n(U$e,"A",{href:!0});var qut=s(WO);dNo=r(qut,"MPNetForSequenceClassification"),qut.forEach(t),cNo=r(U$e," (MPNet model)"),U$e.forEach(t),fNo=i(j),X2=n(j,"LI",{});var J$e=s(X2);ehe=n(J$e,"STRONG",{});var jut=s(ehe);mNo=r(jut,"nystromformer"),jut.forEach(t),gNo=r(J$e," \u2014 "),QO=n(J$e,"A",{href:!0});var Dut=s(QO);hNo=r(Dut,"NystromformerForSequenceClassification"),Dut.forEach(t),pNo=r(J$e," (Nystr\xF6mformer model)"),J$e.forEach(t),uNo=i(j),z2=n(j,"LI",{});var Y$e=s(z2);ohe=n(Y$e,"STRONG",{});var Gut=s(ohe);_No=r(Gut,"openai-gpt"),Gut.forEach(t),bNo=r(Y$e," \u2014 "),HO=n(Y$e,"A",{href:!0});var Out=s(HO);vNo=r(Out,"OpenAIGPTForSequenceClassification"),Out.forEach(t),FNo=r(Y$e," (OpenAI GPT model)"),Y$e.forEach(t),TNo=i(j),W2=n(j,"LI",{});var K$e=s(W2);rhe=n(K$e,"STRONG",{});var Vut=s(rhe);MNo=r(Vut,"perceiver"),Vut.forEach(t),ENo=r(K$e," \u2014 "),UO=n(K$e,"A",{href:!0});var Xut=s(UO);CNo=r(Xut,"PerceiverForSequenceClassification"),Xut.forEach(t),wNo=r(K$e," (Perceiver model)"),K$e.forEach(t),ANo=i(j),Q2=n(j,"LI",{});var Z$e=s(Q2);the=n(Z$e,"STRONG",{});var zut=s(the);yNo=r(zut,"plbart"),zut.forEach(t),LNo=r(Z$e," \u2014 "),JO=n(Z$e,"A",{href:!0});var Wut=s(JO);xNo=r(Wut,"PLBartForSequenceClassification"),Wut.forEach(t),$No=r(Z$e," (PLBart model)"),Z$e.forEach(t),kNo=i(j),H2=n(j,"LI",{});var eke=s(H2);ahe=n(eke,"STRONG",{});var Qut=s(ahe);SNo=r(Qut,"qdqbert"),Qut.forEach(t),RNo=r(eke," \u2014 "),YO=n(eke,"A",{href:!0});var Hut=s(YO);PNo=r(Hut,"QDQBertForSequenceClassification"),Hut.forEach(t),BNo=r(eke," (QDQBert model)"),eke.forEach(t),INo=i(j),U2=n(j,"LI",{});var oke=s(U2);nhe=n(oke,"STRONG",{});var Uut=s(nhe);NNo=r(Uut,"reformer"),Uut.forEach(t),qNo=r(oke," \u2014 "),KO=n(oke,"A",{href:!0});var Jut=s(KO);jNo=r(Jut,"ReformerForSequenceClassification"),Jut.forEach(t),DNo=r(oke," (Reformer model)"),oke.forEach(t),GNo=i(j),J2=n(j,"LI",{});var rke=s(J2);she=n(rke,"STRONG",{});var Yut=s(she);ONo=r(Yut,"rembert"),Yut.forEach(t),VNo=r(rke," \u2014 "),ZO=n(rke,"A",{href:!0});var Kut=s(ZO);XNo=r(Kut,"RemBertForSequenceClassification"),Kut.forEach(t),zNo=r(rke," (RemBERT model)"),rke.forEach(t),WNo=i(j),Y2=n(j,"LI",{});var tke=s(Y2);lhe=n(tke,"STRONG",{});var Zut=s(lhe);QNo=r(Zut,"roberta"),Zut.forEach(t),HNo=r(tke," \u2014 "),eV=n(tke,"A",{href:!0});var e_t=s(eV);UNo=r(e_t,"RobertaForSequenceClassification"),e_t.forEach(t),JNo=r(tke," (RoBERTa model)"),tke.forEach(t),YNo=i(j),K2=n(j,"LI",{});var ake=s(K2);ihe=n(ake,"STRONG",{});var o_t=s(ihe);KNo=r(o_t,"roformer"),o_t.forEach(t),ZNo=r(ake," \u2014 "),oV=n(ake,"A",{href:!0});var r_t=s(oV);eqo=r(r_t,"RoFormerForSequenceClassification"),r_t.forEach(t),oqo=r(ake," (RoFormer model)"),ake.forEach(t),rqo=i(j),Z2=n(j,"LI",{});var nke=s(Z2);dhe=n(nke,"STRONG",{});var t_t=s(dhe);tqo=r(t_t,"squeezebert"),t_t.forEach(t),aqo=r(nke," \u2014 "),rV=n(nke,"A",{href:!0});var a_t=s(rV);nqo=r(a_t,"SqueezeBertForSequenceClassification"),a_t.forEach(t),sqo=r(nke," (SqueezeBERT model)"),nke.forEach(t),lqo=i(j),ev=n(j,"LI",{});var ske=s(ev);che=n(ske,"STRONG",{});var n_t=s(che);iqo=r(n_t,"tapas"),n_t.forEach(t),dqo=r(ske," \u2014 "),tV=n(ske,"A",{href:!0});var s_t=s(tV);cqo=r(s_t,"TapasForSequenceClassification"),s_t.forEach(t),fqo=r(ske," (TAPAS model)"),ske.forEach(t),mqo=i(j),ov=n(j,"LI",{});var lke=s(ov);fhe=n(lke,"STRONG",{});var l_t=s(fhe);gqo=r(l_t,"transfo-xl"),l_t.forEach(t),hqo=r(lke," \u2014 "),aV=n(lke,"A",{href:!0});var i_t=s(aV);pqo=r(i_t,"TransfoXLForSequenceClassification"),i_t.forEach(t),uqo=r(lke," (Transformer-XL model)"),lke.forEach(t),_qo=i(j),rv=n(j,"LI",{});var ike=s(rv);mhe=n(ike,"STRONG",{});var d_t=s(mhe);bqo=r(d_t,"xlm"),d_t.forEach(t),vqo=r(ike," \u2014 "),nV=n(ike,"A",{href:!0});var c_t=s(nV);Fqo=r(c_t,"XLMForSequenceClassification"),c_t.forEach(t),Tqo=r(ike," (XLM model)"),ike.forEach(t),Mqo=i(j),tv=n(j,"LI",{});var dke=s(tv);ghe=n(dke,"STRONG",{});var f_t=s(ghe);Eqo=r(f_t,"xlm-roberta"),f_t.forEach(t),Cqo=r(dke," \u2014 "),sV=n(dke,"A",{href:!0});var m_t=s(sV);wqo=r(m_t,"XLMRobertaForSequenceClassification"),m_t.forEach(t),Aqo=r(dke," (XLM-RoBERTa model)"),dke.forEach(t),yqo=i(j),av=n(j,"LI",{});var cke=s(av);hhe=n(cke,"STRONG",{});var g_t=s(hhe);Lqo=r(g_t,"xlm-roberta-xl"),g_t.forEach(t),xqo=r(cke," \u2014 "),lV=n(cke,"A",{href:!0});var h_t=s(lV);$qo=r(h_t,"XLMRobertaXLForSequenceClassification"),h_t.forEach(t),kqo=r(cke," (XLM-RoBERTa-XL model)"),cke.forEach(t),Sqo=i(j),nv=n(j,"LI",{});var fke=s(nv);phe=n(fke,"STRONG",{});var p_t=s(phe);Rqo=r(p_t,"xlnet"),p_t.forEach(t),Pqo=r(fke," \u2014 "),iV=n(fke,"A",{href:!0});var u_t=s(iV);Bqo=r(u_t,"XLNetForSequenceClassification"),u_t.forEach(t),Iqo=r(fke," (XLNet model)"),fke.forEach(t),Nqo=i(j),sv=n(j,"LI",{});var mke=s(sv);uhe=n(mke,"STRONG",{});var __t=s(uhe);qqo=r(__t,"yoso"),__t.forEach(t),jqo=r(mke," \u2014 "),dV=n(mke,"A",{href:!0});var b_t=s(dV);Dqo=r(b_t,"YosoForSequenceClassification"),b_t.forEach(t),Gqo=r(mke," (YOSO model)"),mke.forEach(t),j.forEach(t),Oqo=i(da),lv=n(da,"P",{});var gke=s(lv);Vqo=r(gke,"The model is set in evaluation mode by default using "),_he=n(gke,"CODE",{});var v_t=s(_he);Xqo=r(v_t,"model.eval()"),v_t.forEach(t),zqo=r(gke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bhe=n(gke,"CODE",{});var F_t=s(bhe);Wqo=r(F_t,"model.train()"),F_t.forEach(t),gke.forEach(t),Qqo=i(da),T(iv.$$.fragment,da),da.forEach(t),Zs.forEach(t),HDe=i(f),Yi=n(f,"H2",{class:!0});var eVe=s(Yi);dv=n(eVe,"A",{id:!0,class:!0,href:!0});var T_t=s(dv);vhe=n(T_t,"SPAN",{});var M_t=s(vhe);T(hy.$$.fragment,M_t),M_t.forEach(t),T_t.forEach(t),Hqo=i(eVe),Fhe=n(eVe,"SPAN",{});var E_t=s(Fhe);Uqo=r(E_t,"AutoModelForMultipleChoice"),E_t.forEach(t),eVe.forEach(t),UDe=i(f),Bo=n(f,"DIV",{class:!0});var el=s(Bo);T(py.$$.fragment,el),Jqo=i(el),Ki=n(el,"P",{});var Qee=s(Ki);Yqo=r(Qee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cV=n(Qee,"A",{href:!0});var C_t=s(cV);Kqo=r(C_t,"from_pretrained()"),C_t.forEach(t),Zqo=r(Qee," class method or the "),fV=n(Qee,"A",{href:!0});var w_t=s(fV);ejo=r(w_t,"from_config()"),w_t.forEach(t),ojo=r(Qee,` class
method.`),Qee.forEach(t),rjo=i(el),uy=n(el,"P",{});var oVe=s(uy);tjo=r(oVe,"This class cannot be instantiated directly using "),The=n(oVe,"CODE",{});var A_t=s(The);ajo=r(A_t,"__init__()"),A_t.forEach(t),njo=r(oVe," (throws an error)."),oVe.forEach(t),sjo=i(el),ft=n(el,"DIV",{class:!0});var A0=s(ft);T(_y.$$.fragment,A0),ljo=i(A0),Mhe=n(A0,"P",{});var y_t=s(Mhe);ijo=r(y_t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),y_t.forEach(t),djo=i(A0),Zi=n(A0,"P",{});var Hee=s(Zi);cjo=r(Hee,`Note:
Loading a model from its configuration file does `),Ehe=n(Hee,"STRONG",{});var L_t=s(Ehe);fjo=r(L_t,"not"),L_t.forEach(t),mjo=r(Hee,` load the model weights. It only affects the
model\u2019s configuration. Use `),mV=n(Hee,"A",{href:!0});var x_t=s(mV);gjo=r(x_t,"from_pretrained()"),x_t.forEach(t),hjo=r(Hee," to load the model weights."),Hee.forEach(t),pjo=i(A0),T(cv.$$.fragment,A0),A0.forEach(t),ujo=i(el),ro=n(el,"DIV",{class:!0});var ca=s(ro);T(by.$$.fragment,ca),_jo=i(ca),Che=n(ca,"P",{});var $_t=s(Che);bjo=r($_t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$_t.forEach(t),vjo=i(ca),qa=n(ca,"P",{});var y0=s(qa);Fjo=r(y0,"The model class to instantiate is selected based on the "),whe=n(y0,"CODE",{});var k_t=s(whe);Tjo=r(k_t,"model_type"),k_t.forEach(t),Mjo=r(y0,` property of the config object (either
passed as an argument or loaded from `),Ahe=n(y0,"CODE",{});var S_t=s(Ahe);Ejo=r(S_t,"pretrained_model_name_or_path"),S_t.forEach(t),Cjo=r(y0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yhe=n(y0,"CODE",{});var R_t=s(yhe);wjo=r(R_t,"pretrained_model_name_or_path"),R_t.forEach(t),Ajo=r(y0,":"),y0.forEach(t),yjo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);fv=n(ee,"LI",{});var hke=s(fv);Lhe=n(hke,"STRONG",{});var P_t=s(Lhe);Ljo=r(P_t,"albert"),P_t.forEach(t),xjo=r(hke," \u2014 "),gV=n(hke,"A",{href:!0});var B_t=s(gV);$jo=r(B_t,"AlbertForMultipleChoice"),B_t.forEach(t),kjo=r(hke," (ALBERT model)"),hke.forEach(t),Sjo=i(ee),mv=n(ee,"LI",{});var pke=s(mv);xhe=n(pke,"STRONG",{});var I_t=s(xhe);Rjo=r(I_t,"bert"),I_t.forEach(t),Pjo=r(pke," \u2014 "),hV=n(pke,"A",{href:!0});var N_t=s(hV);Bjo=r(N_t,"BertForMultipleChoice"),N_t.forEach(t),Ijo=r(pke," (BERT model)"),pke.forEach(t),Njo=i(ee),gv=n(ee,"LI",{});var uke=s(gv);$he=n(uke,"STRONG",{});var q_t=s($he);qjo=r(q_t,"big_bird"),q_t.forEach(t),jjo=r(uke," \u2014 "),pV=n(uke,"A",{href:!0});var j_t=s(pV);Djo=r(j_t,"BigBirdForMultipleChoice"),j_t.forEach(t),Gjo=r(uke," (BigBird model)"),uke.forEach(t),Ojo=i(ee),hv=n(ee,"LI",{});var _ke=s(hv);khe=n(_ke,"STRONG",{});var D_t=s(khe);Vjo=r(D_t,"camembert"),D_t.forEach(t),Xjo=r(_ke," \u2014 "),uV=n(_ke,"A",{href:!0});var G_t=s(uV);zjo=r(G_t,"CamembertForMultipleChoice"),G_t.forEach(t),Wjo=r(_ke," (CamemBERT model)"),_ke.forEach(t),Qjo=i(ee),pv=n(ee,"LI",{});var bke=s(pv);She=n(bke,"STRONG",{});var O_t=s(She);Hjo=r(O_t,"canine"),O_t.forEach(t),Ujo=r(bke," \u2014 "),_V=n(bke,"A",{href:!0});var V_t=s(_V);Jjo=r(V_t,"CanineForMultipleChoice"),V_t.forEach(t),Yjo=r(bke," (CANINE model)"),bke.forEach(t),Kjo=i(ee),uv=n(ee,"LI",{});var vke=s(uv);Rhe=n(vke,"STRONG",{});var X_t=s(Rhe);Zjo=r(X_t,"convbert"),X_t.forEach(t),eDo=r(vke," \u2014 "),bV=n(vke,"A",{href:!0});var z_t=s(bV);oDo=r(z_t,"ConvBertForMultipleChoice"),z_t.forEach(t),rDo=r(vke," (ConvBERT model)"),vke.forEach(t),tDo=i(ee),_v=n(ee,"LI",{});var Fke=s(_v);Phe=n(Fke,"STRONG",{});var W_t=s(Phe);aDo=r(W_t,"data2vec-text"),W_t.forEach(t),nDo=r(Fke," \u2014 "),vV=n(Fke,"A",{href:!0});var Q_t=s(vV);sDo=r(Q_t,"Data2VecTextForMultipleChoice"),Q_t.forEach(t),lDo=r(Fke," (Data2VecText model)"),Fke.forEach(t),iDo=i(ee),bv=n(ee,"LI",{});var Tke=s(bv);Bhe=n(Tke,"STRONG",{});var H_t=s(Bhe);dDo=r(H_t,"deberta-v2"),H_t.forEach(t),cDo=r(Tke," \u2014 "),FV=n(Tke,"A",{href:!0});var U_t=s(FV);fDo=r(U_t,"DebertaV2ForMultipleChoice"),U_t.forEach(t),mDo=r(Tke," (DeBERTa-v2 model)"),Tke.forEach(t),gDo=i(ee),vv=n(ee,"LI",{});var Mke=s(vv);Ihe=n(Mke,"STRONG",{});var J_t=s(Ihe);hDo=r(J_t,"distilbert"),J_t.forEach(t),pDo=r(Mke," \u2014 "),TV=n(Mke,"A",{href:!0});var Y_t=s(TV);uDo=r(Y_t,"DistilBertForMultipleChoice"),Y_t.forEach(t),_Do=r(Mke," (DistilBERT model)"),Mke.forEach(t),bDo=i(ee),Fv=n(ee,"LI",{});var Eke=s(Fv);Nhe=n(Eke,"STRONG",{});var K_t=s(Nhe);vDo=r(K_t,"electra"),K_t.forEach(t),FDo=r(Eke," \u2014 "),MV=n(Eke,"A",{href:!0});var Z_t=s(MV);TDo=r(Z_t,"ElectraForMultipleChoice"),Z_t.forEach(t),MDo=r(Eke," (ELECTRA model)"),Eke.forEach(t),EDo=i(ee),Tv=n(ee,"LI",{});var Cke=s(Tv);qhe=n(Cke,"STRONG",{});var e1t=s(qhe);CDo=r(e1t,"flaubert"),e1t.forEach(t),wDo=r(Cke," \u2014 "),EV=n(Cke,"A",{href:!0});var o1t=s(EV);ADo=r(o1t,"FlaubertForMultipleChoice"),o1t.forEach(t),yDo=r(Cke," (FlauBERT model)"),Cke.forEach(t),LDo=i(ee),Mv=n(ee,"LI",{});var wke=s(Mv);jhe=n(wke,"STRONG",{});var r1t=s(jhe);xDo=r(r1t,"fnet"),r1t.forEach(t),$Do=r(wke," \u2014 "),CV=n(wke,"A",{href:!0});var t1t=s(CV);kDo=r(t1t,"FNetForMultipleChoice"),t1t.forEach(t),SDo=r(wke," (FNet model)"),wke.forEach(t),RDo=i(ee),Ev=n(ee,"LI",{});var Ake=s(Ev);Dhe=n(Ake,"STRONG",{});var a1t=s(Dhe);PDo=r(a1t,"funnel"),a1t.forEach(t),BDo=r(Ake," \u2014 "),wV=n(Ake,"A",{href:!0});var n1t=s(wV);IDo=r(n1t,"FunnelForMultipleChoice"),n1t.forEach(t),NDo=r(Ake," (Funnel Transformer model)"),Ake.forEach(t),qDo=i(ee),Cv=n(ee,"LI",{});var yke=s(Cv);Ghe=n(yke,"STRONG",{});var s1t=s(Ghe);jDo=r(s1t,"ibert"),s1t.forEach(t),DDo=r(yke," \u2014 "),AV=n(yke,"A",{href:!0});var l1t=s(AV);GDo=r(l1t,"IBertForMultipleChoice"),l1t.forEach(t),ODo=r(yke," (I-BERT model)"),yke.forEach(t),VDo=i(ee),wv=n(ee,"LI",{});var Lke=s(wv);Ohe=n(Lke,"STRONG",{});var i1t=s(Ohe);XDo=r(i1t,"longformer"),i1t.forEach(t),zDo=r(Lke," \u2014 "),yV=n(Lke,"A",{href:!0});var d1t=s(yV);WDo=r(d1t,"LongformerForMultipleChoice"),d1t.forEach(t),QDo=r(Lke," (Longformer model)"),Lke.forEach(t),HDo=i(ee),Av=n(ee,"LI",{});var xke=s(Av);Vhe=n(xke,"STRONG",{});var c1t=s(Vhe);UDo=r(c1t,"megatron-bert"),c1t.forEach(t),JDo=r(xke," \u2014 "),LV=n(xke,"A",{href:!0});var f1t=s(LV);YDo=r(f1t,"MegatronBertForMultipleChoice"),f1t.forEach(t),KDo=r(xke," (Megatron-BERT model)"),xke.forEach(t),ZDo=i(ee),yv=n(ee,"LI",{});var $ke=s(yv);Xhe=n($ke,"STRONG",{});var m1t=s(Xhe);eGo=r(m1t,"mobilebert"),m1t.forEach(t),oGo=r($ke," \u2014 "),xV=n($ke,"A",{href:!0});var g1t=s(xV);rGo=r(g1t,"MobileBertForMultipleChoice"),g1t.forEach(t),tGo=r($ke," (MobileBERT model)"),$ke.forEach(t),aGo=i(ee),Lv=n(ee,"LI",{});var kke=s(Lv);zhe=n(kke,"STRONG",{});var h1t=s(zhe);nGo=r(h1t,"mpnet"),h1t.forEach(t),sGo=r(kke," \u2014 "),$V=n(kke,"A",{href:!0});var p1t=s($V);lGo=r(p1t,"MPNetForMultipleChoice"),p1t.forEach(t),iGo=r(kke," (MPNet model)"),kke.forEach(t),dGo=i(ee),xv=n(ee,"LI",{});var Ske=s(xv);Whe=n(Ske,"STRONG",{});var u1t=s(Whe);cGo=r(u1t,"nystromformer"),u1t.forEach(t),fGo=r(Ske," \u2014 "),kV=n(Ske,"A",{href:!0});var _1t=s(kV);mGo=r(_1t,"NystromformerForMultipleChoice"),_1t.forEach(t),gGo=r(Ske," (Nystr\xF6mformer model)"),Ske.forEach(t),hGo=i(ee),$v=n(ee,"LI",{});var Rke=s($v);Qhe=n(Rke,"STRONG",{});var b1t=s(Qhe);pGo=r(b1t,"qdqbert"),b1t.forEach(t),uGo=r(Rke," \u2014 "),SV=n(Rke,"A",{href:!0});var v1t=s(SV);_Go=r(v1t,"QDQBertForMultipleChoice"),v1t.forEach(t),bGo=r(Rke," (QDQBert model)"),Rke.forEach(t),vGo=i(ee),kv=n(ee,"LI",{});var Pke=s(kv);Hhe=n(Pke,"STRONG",{});var F1t=s(Hhe);FGo=r(F1t,"rembert"),F1t.forEach(t),TGo=r(Pke," \u2014 "),RV=n(Pke,"A",{href:!0});var T1t=s(RV);MGo=r(T1t,"RemBertForMultipleChoice"),T1t.forEach(t),EGo=r(Pke," (RemBERT model)"),Pke.forEach(t),CGo=i(ee),Sv=n(ee,"LI",{});var Bke=s(Sv);Uhe=n(Bke,"STRONG",{});var M1t=s(Uhe);wGo=r(M1t,"roberta"),M1t.forEach(t),AGo=r(Bke," \u2014 "),PV=n(Bke,"A",{href:!0});var E1t=s(PV);yGo=r(E1t,"RobertaForMultipleChoice"),E1t.forEach(t),LGo=r(Bke," (RoBERTa model)"),Bke.forEach(t),xGo=i(ee),Rv=n(ee,"LI",{});var Ike=s(Rv);Jhe=n(Ike,"STRONG",{});var C1t=s(Jhe);$Go=r(C1t,"roformer"),C1t.forEach(t),kGo=r(Ike," \u2014 "),BV=n(Ike,"A",{href:!0});var w1t=s(BV);SGo=r(w1t,"RoFormerForMultipleChoice"),w1t.forEach(t),RGo=r(Ike," (RoFormer model)"),Ike.forEach(t),PGo=i(ee),Pv=n(ee,"LI",{});var Nke=s(Pv);Yhe=n(Nke,"STRONG",{});var A1t=s(Yhe);BGo=r(A1t,"squeezebert"),A1t.forEach(t),IGo=r(Nke," \u2014 "),IV=n(Nke,"A",{href:!0});var y1t=s(IV);NGo=r(y1t,"SqueezeBertForMultipleChoice"),y1t.forEach(t),qGo=r(Nke," (SqueezeBERT model)"),Nke.forEach(t),jGo=i(ee),Bv=n(ee,"LI",{});var qke=s(Bv);Khe=n(qke,"STRONG",{});var L1t=s(Khe);DGo=r(L1t,"xlm"),L1t.forEach(t),GGo=r(qke," \u2014 "),NV=n(qke,"A",{href:!0});var x1t=s(NV);OGo=r(x1t,"XLMForMultipleChoice"),x1t.forEach(t),VGo=r(qke," (XLM model)"),qke.forEach(t),XGo=i(ee),Iv=n(ee,"LI",{});var jke=s(Iv);Zhe=n(jke,"STRONG",{});var $1t=s(Zhe);zGo=r($1t,"xlm-roberta"),$1t.forEach(t),WGo=r(jke," \u2014 "),qV=n(jke,"A",{href:!0});var k1t=s(qV);QGo=r(k1t,"XLMRobertaForMultipleChoice"),k1t.forEach(t),HGo=r(jke," (XLM-RoBERTa model)"),jke.forEach(t),UGo=i(ee),Nv=n(ee,"LI",{});var Dke=s(Nv);epe=n(Dke,"STRONG",{});var S1t=s(epe);JGo=r(S1t,"xlm-roberta-xl"),S1t.forEach(t),YGo=r(Dke," \u2014 "),jV=n(Dke,"A",{href:!0});var R1t=s(jV);KGo=r(R1t,"XLMRobertaXLForMultipleChoice"),R1t.forEach(t),ZGo=r(Dke," (XLM-RoBERTa-XL model)"),Dke.forEach(t),eOo=i(ee),qv=n(ee,"LI",{});var Gke=s(qv);ope=n(Gke,"STRONG",{});var P1t=s(ope);oOo=r(P1t,"xlnet"),P1t.forEach(t),rOo=r(Gke," \u2014 "),DV=n(Gke,"A",{href:!0});var B1t=s(DV);tOo=r(B1t,"XLNetForMultipleChoice"),B1t.forEach(t),aOo=r(Gke," (XLNet model)"),Gke.forEach(t),nOo=i(ee),jv=n(ee,"LI",{});var Oke=s(jv);rpe=n(Oke,"STRONG",{});var I1t=s(rpe);sOo=r(I1t,"yoso"),I1t.forEach(t),lOo=r(Oke," \u2014 "),GV=n(Oke,"A",{href:!0});var N1t=s(GV);iOo=r(N1t,"YosoForMultipleChoice"),N1t.forEach(t),dOo=r(Oke," (YOSO model)"),Oke.forEach(t),ee.forEach(t),cOo=i(ca),Dv=n(ca,"P",{});var Vke=s(Dv);fOo=r(Vke,"The model is set in evaluation mode by default using "),tpe=n(Vke,"CODE",{});var q1t=s(tpe);mOo=r(q1t,"model.eval()"),q1t.forEach(t),gOo=r(Vke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ape=n(Vke,"CODE",{});var j1t=s(ape);hOo=r(j1t,"model.train()"),j1t.forEach(t),Vke.forEach(t),pOo=i(ca),T(Gv.$$.fragment,ca),ca.forEach(t),el.forEach(t),JDe=i(f),ed=n(f,"H2",{class:!0});var rVe=s(ed);Ov=n(rVe,"A",{id:!0,class:!0,href:!0});var D1t=s(Ov);npe=n(D1t,"SPAN",{});var G1t=s(npe);T(vy.$$.fragment,G1t),G1t.forEach(t),D1t.forEach(t),uOo=i(rVe),spe=n(rVe,"SPAN",{});var O1t=s(spe);_Oo=r(O1t,"AutoModelForNextSentencePrediction"),O1t.forEach(t),rVe.forEach(t),YDe=i(f),Io=n(f,"DIV",{class:!0});var ol=s(Io);T(Fy.$$.fragment,ol),bOo=i(ol),od=n(ol,"P",{});var Uee=s(od);vOo=r(Uee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OV=n(Uee,"A",{href:!0});var V1t=s(OV);FOo=r(V1t,"from_pretrained()"),V1t.forEach(t),TOo=r(Uee," class method or the "),VV=n(Uee,"A",{href:!0});var X1t=s(VV);MOo=r(X1t,"from_config()"),X1t.forEach(t),EOo=r(Uee,` class
method.`),Uee.forEach(t),COo=i(ol),Ty=n(ol,"P",{});var tVe=s(Ty);wOo=r(tVe,"This class cannot be instantiated directly using "),lpe=n(tVe,"CODE",{});var z1t=s(lpe);AOo=r(z1t,"__init__()"),z1t.forEach(t),yOo=r(tVe," (throws an error)."),tVe.forEach(t),LOo=i(ol),mt=n(ol,"DIV",{class:!0});var L0=s(mt);T(My.$$.fragment,L0),xOo=i(L0),ipe=n(L0,"P",{});var W1t=s(ipe);$Oo=r(W1t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),W1t.forEach(t),kOo=i(L0),rd=n(L0,"P",{});var Jee=s(rd);SOo=r(Jee,`Note:
Loading a model from its configuration file does `),dpe=n(Jee,"STRONG",{});var Q1t=s(dpe);ROo=r(Q1t,"not"),Q1t.forEach(t),POo=r(Jee,` load the model weights. It only affects the
model\u2019s configuration. Use `),XV=n(Jee,"A",{href:!0});var H1t=s(XV);BOo=r(H1t,"from_pretrained()"),H1t.forEach(t),IOo=r(Jee," to load the model weights."),Jee.forEach(t),NOo=i(L0),T(Vv.$$.fragment,L0),L0.forEach(t),qOo=i(ol),to=n(ol,"DIV",{class:!0});var fa=s(to);T(Ey.$$.fragment,fa),jOo=i(fa),cpe=n(fa,"P",{});var U1t=s(cpe);DOo=r(U1t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),U1t.forEach(t),GOo=i(fa),ja=n(fa,"P",{});var x0=s(ja);OOo=r(x0,"The model class to instantiate is selected based on the "),fpe=n(x0,"CODE",{});var J1t=s(fpe);VOo=r(J1t,"model_type"),J1t.forEach(t),XOo=r(x0,` property of the config object (either
passed as an argument or loaded from `),mpe=n(x0,"CODE",{});var Y1t=s(mpe);zOo=r(Y1t,"pretrained_model_name_or_path"),Y1t.forEach(t),WOo=r(x0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gpe=n(x0,"CODE",{});var K1t=s(gpe);QOo=r(K1t,"pretrained_model_name_or_path"),K1t.forEach(t),HOo=r(x0,":"),x0.forEach(t),UOo=i(fa),Zr=n(fa,"UL",{});var rl=s(Zr);Xv=n(rl,"LI",{});var Xke=s(Xv);hpe=n(Xke,"STRONG",{});var Z1t=s(hpe);JOo=r(Z1t,"bert"),Z1t.forEach(t),YOo=r(Xke," \u2014 "),zV=n(Xke,"A",{href:!0});var ebt=s(zV);KOo=r(ebt,"BertForNextSentencePrediction"),ebt.forEach(t),ZOo=r(Xke," (BERT model)"),Xke.forEach(t),eVo=i(rl),zv=n(rl,"LI",{});var zke=s(zv);ppe=n(zke,"STRONG",{});var obt=s(ppe);oVo=r(obt,"fnet"),obt.forEach(t),rVo=r(zke," \u2014 "),WV=n(zke,"A",{href:!0});var rbt=s(WV);tVo=r(rbt,"FNetForNextSentencePrediction"),rbt.forEach(t),aVo=r(zke," (FNet model)"),zke.forEach(t),nVo=i(rl),Wv=n(rl,"LI",{});var Wke=s(Wv);upe=n(Wke,"STRONG",{});var tbt=s(upe);sVo=r(tbt,"megatron-bert"),tbt.forEach(t),lVo=r(Wke," \u2014 "),QV=n(Wke,"A",{href:!0});var abt=s(QV);iVo=r(abt,"MegatronBertForNextSentencePrediction"),abt.forEach(t),dVo=r(Wke," (Megatron-BERT model)"),Wke.forEach(t),cVo=i(rl),Qv=n(rl,"LI",{});var Qke=s(Qv);_pe=n(Qke,"STRONG",{});var nbt=s(_pe);fVo=r(nbt,"mobilebert"),nbt.forEach(t),mVo=r(Qke," \u2014 "),HV=n(Qke,"A",{href:!0});var sbt=s(HV);gVo=r(sbt,"MobileBertForNextSentencePrediction"),sbt.forEach(t),hVo=r(Qke," (MobileBERT model)"),Qke.forEach(t),pVo=i(rl),Hv=n(rl,"LI",{});var Hke=s(Hv);bpe=n(Hke,"STRONG",{});var lbt=s(bpe);uVo=r(lbt,"qdqbert"),lbt.forEach(t),_Vo=r(Hke," \u2014 "),UV=n(Hke,"A",{href:!0});var ibt=s(UV);bVo=r(ibt,"QDQBertForNextSentencePrediction"),ibt.forEach(t),vVo=r(Hke," (QDQBert model)"),Hke.forEach(t),rl.forEach(t),FVo=i(fa),Uv=n(fa,"P",{});var Uke=s(Uv);TVo=r(Uke,"The model is set in evaluation mode by default using "),vpe=n(Uke,"CODE",{});var dbt=s(vpe);MVo=r(dbt,"model.eval()"),dbt.forEach(t),EVo=r(Uke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fpe=n(Uke,"CODE",{});var cbt=s(Fpe);CVo=r(cbt,"model.train()"),cbt.forEach(t),Uke.forEach(t),wVo=i(fa),T(Jv.$$.fragment,fa),fa.forEach(t),ol.forEach(t),KDe=i(f),td=n(f,"H2",{class:!0});var aVe=s(td);Yv=n(aVe,"A",{id:!0,class:!0,href:!0});var fbt=s(Yv);Tpe=n(fbt,"SPAN",{});var mbt=s(Tpe);T(Cy.$$.fragment,mbt),mbt.forEach(t),fbt.forEach(t),AVo=i(aVe),Mpe=n(aVe,"SPAN",{});var gbt=s(Mpe);yVo=r(gbt,"AutoModelForTokenClassification"),gbt.forEach(t),aVe.forEach(t),ZDe=i(f),No=n(f,"DIV",{class:!0});var tl=s(No);T(wy.$$.fragment,tl),LVo=i(tl),ad=n(tl,"P",{});var Yee=s(ad);xVo=r(Yee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JV=n(Yee,"A",{href:!0});var hbt=s(JV);$Vo=r(hbt,"from_pretrained()"),hbt.forEach(t),kVo=r(Yee," class method or the "),YV=n(Yee,"A",{href:!0});var pbt=s(YV);SVo=r(pbt,"from_config()"),pbt.forEach(t),RVo=r(Yee,` class
method.`),Yee.forEach(t),PVo=i(tl),Ay=n(tl,"P",{});var nVe=s(Ay);BVo=r(nVe,"This class cannot be instantiated directly using "),Epe=n(nVe,"CODE",{});var ubt=s(Epe);IVo=r(ubt,"__init__()"),ubt.forEach(t),NVo=r(nVe," (throws an error)."),nVe.forEach(t),qVo=i(tl),gt=n(tl,"DIV",{class:!0});var $0=s(gt);T(yy.$$.fragment,$0),jVo=i($0),Cpe=n($0,"P",{});var _bt=s(Cpe);DVo=r(_bt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),_bt.forEach(t),GVo=i($0),nd=n($0,"P",{});var Kee=s(nd);OVo=r(Kee,`Note:
Loading a model from its configuration file does `),wpe=n(Kee,"STRONG",{});var bbt=s(wpe);VVo=r(bbt,"not"),bbt.forEach(t),XVo=r(Kee,` load the model weights. It only affects the
model\u2019s configuration. Use `),KV=n(Kee,"A",{href:!0});var vbt=s(KV);zVo=r(vbt,"from_pretrained()"),vbt.forEach(t),WVo=r(Kee," to load the model weights."),Kee.forEach(t),QVo=i($0),T(Kv.$$.fragment,$0),$0.forEach(t),HVo=i(tl),ao=n(tl,"DIV",{class:!0});var ma=s(ao);T(Ly.$$.fragment,ma),UVo=i(ma),Ape=n(ma,"P",{});var Fbt=s(Ape);JVo=r(Fbt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Fbt.forEach(t),YVo=i(ma),Da=n(ma,"P",{});var k0=s(Da);KVo=r(k0,"The model class to instantiate is selected based on the "),ype=n(k0,"CODE",{});var Tbt=s(ype);ZVo=r(Tbt,"model_type"),Tbt.forEach(t),eXo=r(k0,` property of the config object (either
passed as an argument or loaded from `),Lpe=n(k0,"CODE",{});var Mbt=s(Lpe);oXo=r(Mbt,"pretrained_model_name_or_path"),Mbt.forEach(t),rXo=r(k0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xpe=n(k0,"CODE",{});var Ebt=s(xpe);tXo=r(Ebt,"pretrained_model_name_or_path"),Ebt.forEach(t),aXo=r(k0,":"),k0.forEach(t),nXo=i(ma),H=n(ma,"UL",{});var J=s(H);Zv=n(J,"LI",{});var Jke=s(Zv);$pe=n(Jke,"STRONG",{});var Cbt=s($pe);sXo=r(Cbt,"albert"),Cbt.forEach(t),lXo=r(Jke," \u2014 "),ZV=n(Jke,"A",{href:!0});var wbt=s(ZV);iXo=r(wbt,"AlbertForTokenClassification"),wbt.forEach(t),dXo=r(Jke," (ALBERT model)"),Jke.forEach(t),cXo=i(J),e3=n(J,"LI",{});var Yke=s(e3);kpe=n(Yke,"STRONG",{});var Abt=s(kpe);fXo=r(Abt,"bert"),Abt.forEach(t),mXo=r(Yke," \u2014 "),eX=n(Yke,"A",{href:!0});var ybt=s(eX);gXo=r(ybt,"BertForTokenClassification"),ybt.forEach(t),hXo=r(Yke," (BERT model)"),Yke.forEach(t),pXo=i(J),o3=n(J,"LI",{});var Kke=s(o3);Spe=n(Kke,"STRONG",{});var Lbt=s(Spe);uXo=r(Lbt,"big_bird"),Lbt.forEach(t),_Xo=r(Kke," \u2014 "),oX=n(Kke,"A",{href:!0});var xbt=s(oX);bXo=r(xbt,"BigBirdForTokenClassification"),xbt.forEach(t),vXo=r(Kke," (BigBird model)"),Kke.forEach(t),FXo=i(J),r3=n(J,"LI",{});var Zke=s(r3);Rpe=n(Zke,"STRONG",{});var $bt=s(Rpe);TXo=r($bt,"bloom"),$bt.forEach(t),MXo=r(Zke," \u2014 "),rX=n(Zke,"A",{href:!0});var kbt=s(rX);EXo=r(kbt,"BloomForTokenClassification"),kbt.forEach(t),CXo=r(Zke," (BLOOM model)"),Zke.forEach(t),wXo=i(J),t3=n(J,"LI",{});var eSe=s(t3);Ppe=n(eSe,"STRONG",{});var Sbt=s(Ppe);AXo=r(Sbt,"camembert"),Sbt.forEach(t),yXo=r(eSe," \u2014 "),tX=n(eSe,"A",{href:!0});var Rbt=s(tX);LXo=r(Rbt,"CamembertForTokenClassification"),Rbt.forEach(t),xXo=r(eSe," (CamemBERT model)"),eSe.forEach(t),$Xo=i(J),a3=n(J,"LI",{});var oSe=s(a3);Bpe=n(oSe,"STRONG",{});var Pbt=s(Bpe);kXo=r(Pbt,"canine"),Pbt.forEach(t),SXo=r(oSe," \u2014 "),aX=n(oSe,"A",{href:!0});var Bbt=s(aX);RXo=r(Bbt,"CanineForTokenClassification"),Bbt.forEach(t),PXo=r(oSe," (CANINE model)"),oSe.forEach(t),BXo=i(J),n3=n(J,"LI",{});var rSe=s(n3);Ipe=n(rSe,"STRONG",{});var Ibt=s(Ipe);IXo=r(Ibt,"convbert"),Ibt.forEach(t),NXo=r(rSe," \u2014 "),nX=n(rSe,"A",{href:!0});var Nbt=s(nX);qXo=r(Nbt,"ConvBertForTokenClassification"),Nbt.forEach(t),jXo=r(rSe," (ConvBERT model)"),rSe.forEach(t),DXo=i(J),s3=n(J,"LI",{});var tSe=s(s3);Npe=n(tSe,"STRONG",{});var qbt=s(Npe);GXo=r(qbt,"data2vec-text"),qbt.forEach(t),OXo=r(tSe," \u2014 "),sX=n(tSe,"A",{href:!0});var jbt=s(sX);VXo=r(jbt,"Data2VecTextForTokenClassification"),jbt.forEach(t),XXo=r(tSe," (Data2VecText model)"),tSe.forEach(t),zXo=i(J),l3=n(J,"LI",{});var aSe=s(l3);qpe=n(aSe,"STRONG",{});var Dbt=s(qpe);WXo=r(Dbt,"deberta"),Dbt.forEach(t),QXo=r(aSe," \u2014 "),lX=n(aSe,"A",{href:!0});var Gbt=s(lX);HXo=r(Gbt,"DebertaForTokenClassification"),Gbt.forEach(t),UXo=r(aSe," (DeBERTa model)"),aSe.forEach(t),JXo=i(J),i3=n(J,"LI",{});var nSe=s(i3);jpe=n(nSe,"STRONG",{});var Obt=s(jpe);YXo=r(Obt,"deberta-v2"),Obt.forEach(t),KXo=r(nSe," \u2014 "),iX=n(nSe,"A",{href:!0});var Vbt=s(iX);ZXo=r(Vbt,"DebertaV2ForTokenClassification"),Vbt.forEach(t),ezo=r(nSe," (DeBERTa-v2 model)"),nSe.forEach(t),ozo=i(J),d3=n(J,"LI",{});var sSe=s(d3);Dpe=n(sSe,"STRONG",{});var Xbt=s(Dpe);rzo=r(Xbt,"distilbert"),Xbt.forEach(t),tzo=r(sSe," \u2014 "),dX=n(sSe,"A",{href:!0});var zbt=s(dX);azo=r(zbt,"DistilBertForTokenClassification"),zbt.forEach(t),nzo=r(sSe," (DistilBERT model)"),sSe.forEach(t),szo=i(J),c3=n(J,"LI",{});var lSe=s(c3);Gpe=n(lSe,"STRONG",{});var Wbt=s(Gpe);lzo=r(Wbt,"electra"),Wbt.forEach(t),izo=r(lSe," \u2014 "),cX=n(lSe,"A",{href:!0});var Qbt=s(cX);dzo=r(Qbt,"ElectraForTokenClassification"),Qbt.forEach(t),czo=r(lSe," (ELECTRA model)"),lSe.forEach(t),fzo=i(J),f3=n(J,"LI",{});var iSe=s(f3);Ope=n(iSe,"STRONG",{});var Hbt=s(Ope);mzo=r(Hbt,"flaubert"),Hbt.forEach(t),gzo=r(iSe," \u2014 "),fX=n(iSe,"A",{href:!0});var Ubt=s(fX);hzo=r(Ubt,"FlaubertForTokenClassification"),Ubt.forEach(t),pzo=r(iSe," (FlauBERT model)"),iSe.forEach(t),uzo=i(J),m3=n(J,"LI",{});var dSe=s(m3);Vpe=n(dSe,"STRONG",{});var Jbt=s(Vpe);_zo=r(Jbt,"fnet"),Jbt.forEach(t),bzo=r(dSe," \u2014 "),mX=n(dSe,"A",{href:!0});var Ybt=s(mX);vzo=r(Ybt,"FNetForTokenClassification"),Ybt.forEach(t),Fzo=r(dSe," (FNet model)"),dSe.forEach(t),Tzo=i(J),g3=n(J,"LI",{});var cSe=s(g3);Xpe=n(cSe,"STRONG",{});var Kbt=s(Xpe);Mzo=r(Kbt,"funnel"),Kbt.forEach(t),Ezo=r(cSe," \u2014 "),gX=n(cSe,"A",{href:!0});var Zbt=s(gX);Czo=r(Zbt,"FunnelForTokenClassification"),Zbt.forEach(t),wzo=r(cSe," (Funnel Transformer model)"),cSe.forEach(t),Azo=i(J),h3=n(J,"LI",{});var fSe=s(h3);zpe=n(fSe,"STRONG",{});var e2t=s(zpe);yzo=r(e2t,"gpt2"),e2t.forEach(t),Lzo=r(fSe," \u2014 "),hX=n(fSe,"A",{href:!0});var o2t=s(hX);xzo=r(o2t,"GPT2ForTokenClassification"),o2t.forEach(t),$zo=r(fSe," (OpenAI GPT-2 model)"),fSe.forEach(t),kzo=i(J),p3=n(J,"LI",{});var mSe=s(p3);Wpe=n(mSe,"STRONG",{});var r2t=s(Wpe);Szo=r(r2t,"ibert"),r2t.forEach(t),Rzo=r(mSe," \u2014 "),pX=n(mSe,"A",{href:!0});var t2t=s(pX);Pzo=r(t2t,"IBertForTokenClassification"),t2t.forEach(t),Bzo=r(mSe," (I-BERT model)"),mSe.forEach(t),Izo=i(J),u3=n(J,"LI",{});var gSe=s(u3);Qpe=n(gSe,"STRONG",{});var a2t=s(Qpe);Nzo=r(a2t,"layoutlm"),a2t.forEach(t),qzo=r(gSe," \u2014 "),uX=n(gSe,"A",{href:!0});var n2t=s(uX);jzo=r(n2t,"LayoutLMForTokenClassification"),n2t.forEach(t),Dzo=r(gSe," (LayoutLM model)"),gSe.forEach(t),Gzo=i(J),_3=n(J,"LI",{});var hSe=s(_3);Hpe=n(hSe,"STRONG",{});var s2t=s(Hpe);Ozo=r(s2t,"layoutlmv2"),s2t.forEach(t),Vzo=r(hSe," \u2014 "),_X=n(hSe,"A",{href:!0});var l2t=s(_X);Xzo=r(l2t,"LayoutLMv2ForTokenClassification"),l2t.forEach(t),zzo=r(hSe," (LayoutLMv2 model)"),hSe.forEach(t),Wzo=i(J),b3=n(J,"LI",{});var pSe=s(b3);Upe=n(pSe,"STRONG",{});var i2t=s(Upe);Qzo=r(i2t,"layoutlmv3"),i2t.forEach(t),Hzo=r(pSe," \u2014 "),bX=n(pSe,"A",{href:!0});var d2t=s(bX);Uzo=r(d2t,"LayoutLMv3ForTokenClassification"),d2t.forEach(t),Jzo=r(pSe," (LayoutLMv3 model)"),pSe.forEach(t),Yzo=i(J),v3=n(J,"LI",{});var uSe=s(v3);Jpe=n(uSe,"STRONG",{});var c2t=s(Jpe);Kzo=r(c2t,"longformer"),c2t.forEach(t),Zzo=r(uSe," \u2014 "),vX=n(uSe,"A",{href:!0});var f2t=s(vX);eWo=r(f2t,"LongformerForTokenClassification"),f2t.forEach(t),oWo=r(uSe," (Longformer model)"),uSe.forEach(t),rWo=i(J),F3=n(J,"LI",{});var _Se=s(F3);Ype=n(_Se,"STRONG",{});var m2t=s(Ype);tWo=r(m2t,"megatron-bert"),m2t.forEach(t),aWo=r(_Se," \u2014 "),FX=n(_Se,"A",{href:!0});var g2t=s(FX);nWo=r(g2t,"MegatronBertForTokenClassification"),g2t.forEach(t),sWo=r(_Se," (Megatron-BERT model)"),_Se.forEach(t),lWo=i(J),T3=n(J,"LI",{});var bSe=s(T3);Kpe=n(bSe,"STRONG",{});var h2t=s(Kpe);iWo=r(h2t,"mobilebert"),h2t.forEach(t),dWo=r(bSe," \u2014 "),TX=n(bSe,"A",{href:!0});var p2t=s(TX);cWo=r(p2t,"MobileBertForTokenClassification"),p2t.forEach(t),fWo=r(bSe," (MobileBERT model)"),bSe.forEach(t),mWo=i(J),M3=n(J,"LI",{});var vSe=s(M3);Zpe=n(vSe,"STRONG",{});var u2t=s(Zpe);gWo=r(u2t,"mpnet"),u2t.forEach(t),hWo=r(vSe," \u2014 "),MX=n(vSe,"A",{href:!0});var _2t=s(MX);pWo=r(_2t,"MPNetForTokenClassification"),_2t.forEach(t),uWo=r(vSe," (MPNet model)"),vSe.forEach(t),_Wo=i(J),E3=n(J,"LI",{});var FSe=s(E3);eue=n(FSe,"STRONG",{});var b2t=s(eue);bWo=r(b2t,"nystromformer"),b2t.forEach(t),vWo=r(FSe," \u2014 "),EX=n(FSe,"A",{href:!0});var v2t=s(EX);FWo=r(v2t,"NystromformerForTokenClassification"),v2t.forEach(t),TWo=r(FSe," (Nystr\xF6mformer model)"),FSe.forEach(t),MWo=i(J),C3=n(J,"LI",{});var TSe=s(C3);oue=n(TSe,"STRONG",{});var F2t=s(oue);EWo=r(F2t,"qdqbert"),F2t.forEach(t),CWo=r(TSe," \u2014 "),CX=n(TSe,"A",{href:!0});var T2t=s(CX);wWo=r(T2t,"QDQBertForTokenClassification"),T2t.forEach(t),AWo=r(TSe," (QDQBert model)"),TSe.forEach(t),yWo=i(J),w3=n(J,"LI",{});var MSe=s(w3);rue=n(MSe,"STRONG",{});var M2t=s(rue);LWo=r(M2t,"rembert"),M2t.forEach(t),xWo=r(MSe," \u2014 "),wX=n(MSe,"A",{href:!0});var E2t=s(wX);$Wo=r(E2t,"RemBertForTokenClassification"),E2t.forEach(t),kWo=r(MSe," (RemBERT model)"),MSe.forEach(t),SWo=i(J),A3=n(J,"LI",{});var ESe=s(A3);tue=n(ESe,"STRONG",{});var C2t=s(tue);RWo=r(C2t,"roberta"),C2t.forEach(t),PWo=r(ESe," \u2014 "),AX=n(ESe,"A",{href:!0});var w2t=s(AX);BWo=r(w2t,"RobertaForTokenClassification"),w2t.forEach(t),IWo=r(ESe," (RoBERTa model)"),ESe.forEach(t),NWo=i(J),y3=n(J,"LI",{});var CSe=s(y3);aue=n(CSe,"STRONG",{});var A2t=s(aue);qWo=r(A2t,"roformer"),A2t.forEach(t),jWo=r(CSe," \u2014 "),yX=n(CSe,"A",{href:!0});var y2t=s(yX);DWo=r(y2t,"RoFormerForTokenClassification"),y2t.forEach(t),GWo=r(CSe," (RoFormer model)"),CSe.forEach(t),OWo=i(J),L3=n(J,"LI",{});var wSe=s(L3);nue=n(wSe,"STRONG",{});var L2t=s(nue);VWo=r(L2t,"squeezebert"),L2t.forEach(t),XWo=r(wSe," \u2014 "),LX=n(wSe,"A",{href:!0});var x2t=s(LX);zWo=r(x2t,"SqueezeBertForTokenClassification"),x2t.forEach(t),WWo=r(wSe," (SqueezeBERT model)"),wSe.forEach(t),QWo=i(J),x3=n(J,"LI",{});var ASe=s(x3);sue=n(ASe,"STRONG",{});var $2t=s(sue);HWo=r($2t,"xlm"),$2t.forEach(t),UWo=r(ASe," \u2014 "),xX=n(ASe,"A",{href:!0});var k2t=s(xX);JWo=r(k2t,"XLMForTokenClassification"),k2t.forEach(t),YWo=r(ASe," (XLM model)"),ASe.forEach(t),KWo=i(J),$3=n(J,"LI",{});var ySe=s($3);lue=n(ySe,"STRONG",{});var S2t=s(lue);ZWo=r(S2t,"xlm-roberta"),S2t.forEach(t),eQo=r(ySe," \u2014 "),$X=n(ySe,"A",{href:!0});var R2t=s($X);oQo=r(R2t,"XLMRobertaForTokenClassification"),R2t.forEach(t),rQo=r(ySe," (XLM-RoBERTa model)"),ySe.forEach(t),tQo=i(J),k3=n(J,"LI",{});var LSe=s(k3);iue=n(LSe,"STRONG",{});var P2t=s(iue);aQo=r(P2t,"xlm-roberta-xl"),P2t.forEach(t),nQo=r(LSe," \u2014 "),kX=n(LSe,"A",{href:!0});var B2t=s(kX);sQo=r(B2t,"XLMRobertaXLForTokenClassification"),B2t.forEach(t),lQo=r(LSe," (XLM-RoBERTa-XL model)"),LSe.forEach(t),iQo=i(J),S3=n(J,"LI",{});var xSe=s(S3);due=n(xSe,"STRONG",{});var I2t=s(due);dQo=r(I2t,"xlnet"),I2t.forEach(t),cQo=r(xSe," \u2014 "),SX=n(xSe,"A",{href:!0});var N2t=s(SX);fQo=r(N2t,"XLNetForTokenClassification"),N2t.forEach(t),mQo=r(xSe," (XLNet model)"),xSe.forEach(t),gQo=i(J),R3=n(J,"LI",{});var $Se=s(R3);cue=n($Se,"STRONG",{});var q2t=s(cue);hQo=r(q2t,"yoso"),q2t.forEach(t),pQo=r($Se," \u2014 "),RX=n($Se,"A",{href:!0});var j2t=s(RX);uQo=r(j2t,"YosoForTokenClassification"),j2t.forEach(t),_Qo=r($Se," (YOSO model)"),$Se.forEach(t),J.forEach(t),bQo=i(ma),P3=n(ma,"P",{});var kSe=s(P3);vQo=r(kSe,"The model is set in evaluation mode by default using "),fue=n(kSe,"CODE",{});var D2t=s(fue);FQo=r(D2t,"model.eval()"),D2t.forEach(t),TQo=r(kSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mue=n(kSe,"CODE",{});var G2t=s(mue);MQo=r(G2t,"model.train()"),G2t.forEach(t),kSe.forEach(t),EQo=i(ma),T(B3.$$.fragment,ma),ma.forEach(t),tl.forEach(t),eGe=i(f),sd=n(f,"H2",{class:!0});var sVe=s(sd);I3=n(sVe,"A",{id:!0,class:!0,href:!0});var O2t=s(I3);gue=n(O2t,"SPAN",{});var V2t=s(gue);T(xy.$$.fragment,V2t),V2t.forEach(t),O2t.forEach(t),CQo=i(sVe),hue=n(sVe,"SPAN",{});var X2t=s(hue);wQo=r(X2t,"AutoModelForQuestionAnswering"),X2t.forEach(t),sVe.forEach(t),oGe=i(f),qo=n(f,"DIV",{class:!0});var al=s(qo);T($y.$$.fragment,al),AQo=i(al),ld=n(al,"P",{});var Zee=s(ld);yQo=r(Zee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),PX=n(Zee,"A",{href:!0});var z2t=s(PX);LQo=r(z2t,"from_pretrained()"),z2t.forEach(t),xQo=r(Zee," class method or the "),BX=n(Zee,"A",{href:!0});var W2t=s(BX);$Qo=r(W2t,"from_config()"),W2t.forEach(t),kQo=r(Zee,` class
method.`),Zee.forEach(t),SQo=i(al),ky=n(al,"P",{});var lVe=s(ky);RQo=r(lVe,"This class cannot be instantiated directly using "),pue=n(lVe,"CODE",{});var Q2t=s(pue);PQo=r(Q2t,"__init__()"),Q2t.forEach(t),BQo=r(lVe," (throws an error)."),lVe.forEach(t),IQo=i(al),ht=n(al,"DIV",{class:!0});var S0=s(ht);T(Sy.$$.fragment,S0),NQo=i(S0),uue=n(S0,"P",{});var H2t=s(uue);qQo=r(H2t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),H2t.forEach(t),jQo=i(S0),id=n(S0,"P",{});var eoe=s(id);DQo=r(eoe,`Note:
Loading a model from its configuration file does `),_ue=n(eoe,"STRONG",{});var U2t=s(_ue);GQo=r(U2t,"not"),U2t.forEach(t),OQo=r(eoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IX=n(eoe,"A",{href:!0});var J2t=s(IX);VQo=r(J2t,"from_pretrained()"),J2t.forEach(t),XQo=r(eoe," to load the model weights."),eoe.forEach(t),zQo=i(S0),T(N3.$$.fragment,S0),S0.forEach(t),WQo=i(al),no=n(al,"DIV",{class:!0});var ga=s(no);T(Ry.$$.fragment,ga),QQo=i(ga),bue=n(ga,"P",{});var Y2t=s(bue);HQo=r(Y2t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Y2t.forEach(t),UQo=i(ga),Ga=n(ga,"P",{});var R0=s(Ga);JQo=r(R0,"The model class to instantiate is selected based on the "),vue=n(R0,"CODE",{});var K2t=s(vue);YQo=r(K2t,"model_type"),K2t.forEach(t),KQo=r(R0,` property of the config object (either
passed as an argument or loaded from `),Fue=n(R0,"CODE",{});var Z2t=s(Fue);ZQo=r(Z2t,"pretrained_model_name_or_path"),Z2t.forEach(t),eHo=r(R0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tue=n(R0,"CODE",{});var evt=s(Tue);oHo=r(evt,"pretrained_model_name_or_path"),evt.forEach(t),rHo=r(R0,":"),R0.forEach(t),tHo=i(ga),V=n(ga,"UL",{});var X=s(V);q3=n(X,"LI",{});var SSe=s(q3);Mue=n(SSe,"STRONG",{});var ovt=s(Mue);aHo=r(ovt,"albert"),ovt.forEach(t),nHo=r(SSe," \u2014 "),NX=n(SSe,"A",{href:!0});var rvt=s(NX);sHo=r(rvt,"AlbertForQuestionAnswering"),rvt.forEach(t),lHo=r(SSe," (ALBERT model)"),SSe.forEach(t),iHo=i(X),j3=n(X,"LI",{});var RSe=s(j3);Eue=n(RSe,"STRONG",{});var tvt=s(Eue);dHo=r(tvt,"bart"),tvt.forEach(t),cHo=r(RSe," \u2014 "),qX=n(RSe,"A",{href:!0});var avt=s(qX);fHo=r(avt,"BartForQuestionAnswering"),avt.forEach(t),mHo=r(RSe," (BART model)"),RSe.forEach(t),gHo=i(X),D3=n(X,"LI",{});var PSe=s(D3);Cue=n(PSe,"STRONG",{});var nvt=s(Cue);hHo=r(nvt,"bert"),nvt.forEach(t),pHo=r(PSe," \u2014 "),jX=n(PSe,"A",{href:!0});var svt=s(jX);uHo=r(svt,"BertForQuestionAnswering"),svt.forEach(t),_Ho=r(PSe," (BERT model)"),PSe.forEach(t),bHo=i(X),G3=n(X,"LI",{});var BSe=s(G3);wue=n(BSe,"STRONG",{});var lvt=s(wue);vHo=r(lvt,"big_bird"),lvt.forEach(t),FHo=r(BSe," \u2014 "),DX=n(BSe,"A",{href:!0});var ivt=s(DX);THo=r(ivt,"BigBirdForQuestionAnswering"),ivt.forEach(t),MHo=r(BSe," (BigBird model)"),BSe.forEach(t),EHo=i(X),O3=n(X,"LI",{});var ISe=s(O3);Aue=n(ISe,"STRONG",{});var dvt=s(Aue);CHo=r(dvt,"bigbird_pegasus"),dvt.forEach(t),wHo=r(ISe," \u2014 "),GX=n(ISe,"A",{href:!0});var cvt=s(GX);AHo=r(cvt,"BigBirdPegasusForQuestionAnswering"),cvt.forEach(t),yHo=r(ISe," (BigBird-Pegasus model)"),ISe.forEach(t),LHo=i(X),V3=n(X,"LI",{});var NSe=s(V3);yue=n(NSe,"STRONG",{});var fvt=s(yue);xHo=r(fvt,"camembert"),fvt.forEach(t),$Ho=r(NSe," \u2014 "),OX=n(NSe,"A",{href:!0});var mvt=s(OX);kHo=r(mvt,"CamembertForQuestionAnswering"),mvt.forEach(t),SHo=r(NSe," (CamemBERT model)"),NSe.forEach(t),RHo=i(X),X3=n(X,"LI",{});var qSe=s(X3);Lue=n(qSe,"STRONG",{});var gvt=s(Lue);PHo=r(gvt,"canine"),gvt.forEach(t),BHo=r(qSe," \u2014 "),VX=n(qSe,"A",{href:!0});var hvt=s(VX);IHo=r(hvt,"CanineForQuestionAnswering"),hvt.forEach(t),NHo=r(qSe," (CANINE model)"),qSe.forEach(t),qHo=i(X),z3=n(X,"LI",{});var jSe=s(z3);xue=n(jSe,"STRONG",{});var pvt=s(xue);jHo=r(pvt,"convbert"),pvt.forEach(t),DHo=r(jSe," \u2014 "),XX=n(jSe,"A",{href:!0});var uvt=s(XX);GHo=r(uvt,"ConvBertForQuestionAnswering"),uvt.forEach(t),OHo=r(jSe," (ConvBERT model)"),jSe.forEach(t),VHo=i(X),W3=n(X,"LI",{});var DSe=s(W3);$ue=n(DSe,"STRONG",{});var _vt=s($ue);XHo=r(_vt,"data2vec-text"),_vt.forEach(t),zHo=r(DSe," \u2014 "),zX=n(DSe,"A",{href:!0});var bvt=s(zX);WHo=r(bvt,"Data2VecTextForQuestionAnswering"),bvt.forEach(t),QHo=r(DSe," (Data2VecText model)"),DSe.forEach(t),HHo=i(X),Q3=n(X,"LI",{});var GSe=s(Q3);kue=n(GSe,"STRONG",{});var vvt=s(kue);UHo=r(vvt,"deberta"),vvt.forEach(t),JHo=r(GSe," \u2014 "),WX=n(GSe,"A",{href:!0});var Fvt=s(WX);YHo=r(Fvt,"DebertaForQuestionAnswering"),Fvt.forEach(t),KHo=r(GSe," (DeBERTa model)"),GSe.forEach(t),ZHo=i(X),H3=n(X,"LI",{});var OSe=s(H3);Sue=n(OSe,"STRONG",{});var Tvt=s(Sue);eUo=r(Tvt,"deberta-v2"),Tvt.forEach(t),oUo=r(OSe," \u2014 "),QX=n(OSe,"A",{href:!0});var Mvt=s(QX);rUo=r(Mvt,"DebertaV2ForQuestionAnswering"),Mvt.forEach(t),tUo=r(OSe," (DeBERTa-v2 model)"),OSe.forEach(t),aUo=i(X),U3=n(X,"LI",{});var VSe=s(U3);Rue=n(VSe,"STRONG",{});var Evt=s(Rue);nUo=r(Evt,"distilbert"),Evt.forEach(t),sUo=r(VSe," \u2014 "),HX=n(VSe,"A",{href:!0});var Cvt=s(HX);lUo=r(Cvt,"DistilBertForQuestionAnswering"),Cvt.forEach(t),iUo=r(VSe," (DistilBERT model)"),VSe.forEach(t),dUo=i(X),J3=n(X,"LI",{});var XSe=s(J3);Pue=n(XSe,"STRONG",{});var wvt=s(Pue);cUo=r(wvt,"electra"),wvt.forEach(t),fUo=r(XSe," \u2014 "),UX=n(XSe,"A",{href:!0});var Avt=s(UX);mUo=r(Avt,"ElectraForQuestionAnswering"),Avt.forEach(t),gUo=r(XSe," (ELECTRA model)"),XSe.forEach(t),hUo=i(X),Y3=n(X,"LI",{});var zSe=s(Y3);Bue=n(zSe,"STRONG",{});var yvt=s(Bue);pUo=r(yvt,"flaubert"),yvt.forEach(t),uUo=r(zSe," \u2014 "),JX=n(zSe,"A",{href:!0});var Lvt=s(JX);_Uo=r(Lvt,"FlaubertForQuestionAnsweringSimple"),Lvt.forEach(t),bUo=r(zSe," (FlauBERT model)"),zSe.forEach(t),vUo=i(X),K3=n(X,"LI",{});var WSe=s(K3);Iue=n(WSe,"STRONG",{});var xvt=s(Iue);FUo=r(xvt,"fnet"),xvt.forEach(t),TUo=r(WSe," \u2014 "),YX=n(WSe,"A",{href:!0});var $vt=s(YX);MUo=r($vt,"FNetForQuestionAnswering"),$vt.forEach(t),EUo=r(WSe," (FNet model)"),WSe.forEach(t),CUo=i(X),Z3=n(X,"LI",{});var QSe=s(Z3);Nue=n(QSe,"STRONG",{});var kvt=s(Nue);wUo=r(kvt,"funnel"),kvt.forEach(t),AUo=r(QSe," \u2014 "),KX=n(QSe,"A",{href:!0});var Svt=s(KX);yUo=r(Svt,"FunnelForQuestionAnswering"),Svt.forEach(t),LUo=r(QSe," (Funnel Transformer model)"),QSe.forEach(t),xUo=i(X),eF=n(X,"LI",{});var HSe=s(eF);que=n(HSe,"STRONG",{});var Rvt=s(que);$Uo=r(Rvt,"gptj"),Rvt.forEach(t),kUo=r(HSe," \u2014 "),ZX=n(HSe,"A",{href:!0});var Pvt=s(ZX);SUo=r(Pvt,"GPTJForQuestionAnswering"),Pvt.forEach(t),RUo=r(HSe," (GPT-J model)"),HSe.forEach(t),PUo=i(X),oF=n(X,"LI",{});var USe=s(oF);jue=n(USe,"STRONG",{});var Bvt=s(jue);BUo=r(Bvt,"ibert"),Bvt.forEach(t),IUo=r(USe," \u2014 "),ez=n(USe,"A",{href:!0});var Ivt=s(ez);NUo=r(Ivt,"IBertForQuestionAnswering"),Ivt.forEach(t),qUo=r(USe," (I-BERT model)"),USe.forEach(t),jUo=i(X),rF=n(X,"LI",{});var JSe=s(rF);Due=n(JSe,"STRONG",{});var Nvt=s(Due);DUo=r(Nvt,"layoutlmv2"),Nvt.forEach(t),GUo=r(JSe," \u2014 "),oz=n(JSe,"A",{href:!0});var qvt=s(oz);OUo=r(qvt,"LayoutLMv2ForQuestionAnswering"),qvt.forEach(t),VUo=r(JSe," (LayoutLMv2 model)"),JSe.forEach(t),XUo=i(X),tF=n(X,"LI",{});var YSe=s(tF);Gue=n(YSe,"STRONG",{});var jvt=s(Gue);zUo=r(jvt,"layoutlmv3"),jvt.forEach(t),WUo=r(YSe," \u2014 "),rz=n(YSe,"A",{href:!0});var Dvt=s(rz);QUo=r(Dvt,"LayoutLMv3ForQuestionAnswering"),Dvt.forEach(t),HUo=r(YSe," (LayoutLMv3 model)"),YSe.forEach(t),UUo=i(X),aF=n(X,"LI",{});var KSe=s(aF);Oue=n(KSe,"STRONG",{});var Gvt=s(Oue);JUo=r(Gvt,"led"),Gvt.forEach(t),YUo=r(KSe," \u2014 "),tz=n(KSe,"A",{href:!0});var Ovt=s(tz);KUo=r(Ovt,"LEDForQuestionAnswering"),Ovt.forEach(t),ZUo=r(KSe," (LED model)"),KSe.forEach(t),eJo=i(X),nF=n(X,"LI",{});var ZSe=s(nF);Vue=n(ZSe,"STRONG",{});var Vvt=s(Vue);oJo=r(Vvt,"longformer"),Vvt.forEach(t),rJo=r(ZSe," \u2014 "),az=n(ZSe,"A",{href:!0});var Xvt=s(az);tJo=r(Xvt,"LongformerForQuestionAnswering"),Xvt.forEach(t),aJo=r(ZSe," (Longformer model)"),ZSe.forEach(t),nJo=i(X),sF=n(X,"LI",{});var eRe=s(sF);Xue=n(eRe,"STRONG",{});var zvt=s(Xue);sJo=r(zvt,"lxmert"),zvt.forEach(t),lJo=r(eRe," \u2014 "),nz=n(eRe,"A",{href:!0});var Wvt=s(nz);iJo=r(Wvt,"LxmertForQuestionAnswering"),Wvt.forEach(t),dJo=r(eRe," (LXMERT model)"),eRe.forEach(t),cJo=i(X),lF=n(X,"LI",{});var oRe=s(lF);zue=n(oRe,"STRONG",{});var Qvt=s(zue);fJo=r(Qvt,"mbart"),Qvt.forEach(t),mJo=r(oRe," \u2014 "),sz=n(oRe,"A",{href:!0});var Hvt=s(sz);gJo=r(Hvt,"MBartForQuestionAnswering"),Hvt.forEach(t),hJo=r(oRe," (mBART model)"),oRe.forEach(t),pJo=i(X),iF=n(X,"LI",{});var rRe=s(iF);Wue=n(rRe,"STRONG",{});var Uvt=s(Wue);uJo=r(Uvt,"megatron-bert"),Uvt.forEach(t),_Jo=r(rRe," \u2014 "),lz=n(rRe,"A",{href:!0});var Jvt=s(lz);bJo=r(Jvt,"MegatronBertForQuestionAnswering"),Jvt.forEach(t),vJo=r(rRe," (Megatron-BERT model)"),rRe.forEach(t),FJo=i(X),dF=n(X,"LI",{});var tRe=s(dF);Que=n(tRe,"STRONG",{});var Yvt=s(Que);TJo=r(Yvt,"mobilebert"),Yvt.forEach(t),MJo=r(tRe," \u2014 "),iz=n(tRe,"A",{href:!0});var Kvt=s(iz);EJo=r(Kvt,"MobileBertForQuestionAnswering"),Kvt.forEach(t),CJo=r(tRe," (MobileBERT model)"),tRe.forEach(t),wJo=i(X),cF=n(X,"LI",{});var aRe=s(cF);Hue=n(aRe,"STRONG",{});var Zvt=s(Hue);AJo=r(Zvt,"mpnet"),Zvt.forEach(t),yJo=r(aRe," \u2014 "),dz=n(aRe,"A",{href:!0});var e3t=s(dz);LJo=r(e3t,"MPNetForQuestionAnswering"),e3t.forEach(t),xJo=r(aRe," (MPNet model)"),aRe.forEach(t),$Jo=i(X),fF=n(X,"LI",{});var nRe=s(fF);Uue=n(nRe,"STRONG",{});var o3t=s(Uue);kJo=r(o3t,"nystromformer"),o3t.forEach(t),SJo=r(nRe," \u2014 "),cz=n(nRe,"A",{href:!0});var r3t=s(cz);RJo=r(r3t,"NystromformerForQuestionAnswering"),r3t.forEach(t),PJo=r(nRe," (Nystr\xF6mformer model)"),nRe.forEach(t),BJo=i(X),mF=n(X,"LI",{});var sRe=s(mF);Jue=n(sRe,"STRONG",{});var t3t=s(Jue);IJo=r(t3t,"qdqbert"),t3t.forEach(t),NJo=r(sRe," \u2014 "),fz=n(sRe,"A",{href:!0});var a3t=s(fz);qJo=r(a3t,"QDQBertForQuestionAnswering"),a3t.forEach(t),jJo=r(sRe," (QDQBert model)"),sRe.forEach(t),DJo=i(X),gF=n(X,"LI",{});var lRe=s(gF);Yue=n(lRe,"STRONG",{});var n3t=s(Yue);GJo=r(n3t,"reformer"),n3t.forEach(t),OJo=r(lRe," \u2014 "),mz=n(lRe,"A",{href:!0});var s3t=s(mz);VJo=r(s3t,"ReformerForQuestionAnswering"),s3t.forEach(t),XJo=r(lRe," (Reformer model)"),lRe.forEach(t),zJo=i(X),hF=n(X,"LI",{});var iRe=s(hF);Kue=n(iRe,"STRONG",{});var l3t=s(Kue);WJo=r(l3t,"rembert"),l3t.forEach(t),QJo=r(iRe," \u2014 "),gz=n(iRe,"A",{href:!0});var i3t=s(gz);HJo=r(i3t,"RemBertForQuestionAnswering"),i3t.forEach(t),UJo=r(iRe," (RemBERT model)"),iRe.forEach(t),JJo=i(X),pF=n(X,"LI",{});var dRe=s(pF);Zue=n(dRe,"STRONG",{});var d3t=s(Zue);YJo=r(d3t,"roberta"),d3t.forEach(t),KJo=r(dRe," \u2014 "),hz=n(dRe,"A",{href:!0});var c3t=s(hz);ZJo=r(c3t,"RobertaForQuestionAnswering"),c3t.forEach(t),eYo=r(dRe," (RoBERTa model)"),dRe.forEach(t),oYo=i(X),uF=n(X,"LI",{});var cRe=s(uF);e_e=n(cRe,"STRONG",{});var f3t=s(e_e);rYo=r(f3t,"roformer"),f3t.forEach(t),tYo=r(cRe," \u2014 "),pz=n(cRe,"A",{href:!0});var m3t=s(pz);aYo=r(m3t,"RoFormerForQuestionAnswering"),m3t.forEach(t),nYo=r(cRe," (RoFormer model)"),cRe.forEach(t),sYo=i(X),_F=n(X,"LI",{});var fRe=s(_F);o_e=n(fRe,"STRONG",{});var g3t=s(o_e);lYo=r(g3t,"splinter"),g3t.forEach(t),iYo=r(fRe," \u2014 "),uz=n(fRe,"A",{href:!0});var h3t=s(uz);dYo=r(h3t,"SplinterForQuestionAnswering"),h3t.forEach(t),cYo=r(fRe," (Splinter model)"),fRe.forEach(t),fYo=i(X),bF=n(X,"LI",{});var mRe=s(bF);r_e=n(mRe,"STRONG",{});var p3t=s(r_e);mYo=r(p3t,"squeezebert"),p3t.forEach(t),gYo=r(mRe," \u2014 "),_z=n(mRe,"A",{href:!0});var u3t=s(_z);hYo=r(u3t,"SqueezeBertForQuestionAnswering"),u3t.forEach(t),pYo=r(mRe," (SqueezeBERT model)"),mRe.forEach(t),uYo=i(X),vF=n(X,"LI",{});var gRe=s(vF);t_e=n(gRe,"STRONG",{});var _3t=s(t_e);_Yo=r(_3t,"xlm"),_3t.forEach(t),bYo=r(gRe," \u2014 "),bz=n(gRe,"A",{href:!0});var b3t=s(bz);vYo=r(b3t,"XLMForQuestionAnsweringSimple"),b3t.forEach(t),FYo=r(gRe," (XLM model)"),gRe.forEach(t),TYo=i(X),FF=n(X,"LI",{});var hRe=s(FF);a_e=n(hRe,"STRONG",{});var v3t=s(a_e);MYo=r(v3t,"xlm-roberta"),v3t.forEach(t),EYo=r(hRe," \u2014 "),vz=n(hRe,"A",{href:!0});var F3t=s(vz);CYo=r(F3t,"XLMRobertaForQuestionAnswering"),F3t.forEach(t),wYo=r(hRe," (XLM-RoBERTa model)"),hRe.forEach(t),AYo=i(X),TF=n(X,"LI",{});var pRe=s(TF);n_e=n(pRe,"STRONG",{});var T3t=s(n_e);yYo=r(T3t,"xlm-roberta-xl"),T3t.forEach(t),LYo=r(pRe," \u2014 "),Fz=n(pRe,"A",{href:!0});var M3t=s(Fz);xYo=r(M3t,"XLMRobertaXLForQuestionAnswering"),M3t.forEach(t),$Yo=r(pRe," (XLM-RoBERTa-XL model)"),pRe.forEach(t),kYo=i(X),MF=n(X,"LI",{});var uRe=s(MF);s_e=n(uRe,"STRONG",{});var E3t=s(s_e);SYo=r(E3t,"xlnet"),E3t.forEach(t),RYo=r(uRe," \u2014 "),Tz=n(uRe,"A",{href:!0});var C3t=s(Tz);PYo=r(C3t,"XLNetForQuestionAnsweringSimple"),C3t.forEach(t),BYo=r(uRe," (XLNet model)"),uRe.forEach(t),IYo=i(X),EF=n(X,"LI",{});var _Re=s(EF);l_e=n(_Re,"STRONG",{});var w3t=s(l_e);NYo=r(w3t,"yoso"),w3t.forEach(t),qYo=r(_Re," \u2014 "),Mz=n(_Re,"A",{href:!0});var A3t=s(Mz);jYo=r(A3t,"YosoForQuestionAnswering"),A3t.forEach(t),DYo=r(_Re," (YOSO model)"),_Re.forEach(t),X.forEach(t),GYo=i(ga),CF=n(ga,"P",{});var bRe=s(CF);OYo=r(bRe,"The model is set in evaluation mode by default using "),i_e=n(bRe,"CODE",{});var y3t=s(i_e);VYo=r(y3t,"model.eval()"),y3t.forEach(t),XYo=r(bRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d_e=n(bRe,"CODE",{});var L3t=s(d_e);zYo=r(L3t,"model.train()"),L3t.forEach(t),bRe.forEach(t),WYo=i(ga),T(wF.$$.fragment,ga),ga.forEach(t),al.forEach(t),rGe=i(f),dd=n(f,"H2",{class:!0});var iVe=s(dd);AF=n(iVe,"A",{id:!0,class:!0,href:!0});var x3t=s(AF);c_e=n(x3t,"SPAN",{});var $3t=s(c_e);T(Py.$$.fragment,$3t),$3t.forEach(t),x3t.forEach(t),QYo=i(iVe),f_e=n(iVe,"SPAN",{});var k3t=s(f_e);HYo=r(k3t,"AutoModelForTableQuestionAnswering"),k3t.forEach(t),iVe.forEach(t),tGe=i(f),jo=n(f,"DIV",{class:!0});var nl=s(jo);T(By.$$.fragment,nl),UYo=i(nl),cd=n(nl,"P",{});var ooe=s(cd);JYo=r(ooe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Ez=n(ooe,"A",{href:!0});var S3t=s(Ez);YYo=r(S3t,"from_pretrained()"),S3t.forEach(t),KYo=r(ooe," class method or the "),Cz=n(ooe,"A",{href:!0});var R3t=s(Cz);ZYo=r(R3t,"from_config()"),R3t.forEach(t),eKo=r(ooe,` class
method.`),ooe.forEach(t),oKo=i(nl),Iy=n(nl,"P",{});var dVe=s(Iy);rKo=r(dVe,"This class cannot be instantiated directly using "),m_e=n(dVe,"CODE",{});var P3t=s(m_e);tKo=r(P3t,"__init__()"),P3t.forEach(t),aKo=r(dVe," (throws an error)."),dVe.forEach(t),nKo=i(nl),pt=n(nl,"DIV",{class:!0});var P0=s(pt);T(Ny.$$.fragment,P0),sKo=i(P0),g_e=n(P0,"P",{});var B3t=s(g_e);lKo=r(B3t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),B3t.forEach(t),iKo=i(P0),fd=n(P0,"P",{});var roe=s(fd);dKo=r(roe,`Note:
Loading a model from its configuration file does `),h_e=n(roe,"STRONG",{});var I3t=s(h_e);cKo=r(I3t,"not"),I3t.forEach(t),fKo=r(roe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wz=n(roe,"A",{href:!0});var N3t=s(wz);mKo=r(N3t,"from_pretrained()"),N3t.forEach(t),gKo=r(roe," to load the model weights."),roe.forEach(t),hKo=i(P0),T(yF.$$.fragment,P0),P0.forEach(t),pKo=i(nl),so=n(nl,"DIV",{class:!0});var ha=s(so);T(qy.$$.fragment,ha),uKo=i(ha),p_e=n(ha,"P",{});var q3t=s(p_e);_Ko=r(q3t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),q3t.forEach(t),bKo=i(ha),Oa=n(ha,"P",{});var B0=s(Oa);vKo=r(B0,"The model class to instantiate is selected based on the "),u_e=n(B0,"CODE",{});var j3t=s(u_e);FKo=r(j3t,"model_type"),j3t.forEach(t),TKo=r(B0,` property of the config object (either
passed as an argument or loaded from `),__e=n(B0,"CODE",{});var D3t=s(__e);MKo=r(D3t,"pretrained_model_name_or_path"),D3t.forEach(t),EKo=r(B0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b_e=n(B0,"CODE",{});var G3t=s(b_e);CKo=r(G3t,"pretrained_model_name_or_path"),G3t.forEach(t),wKo=r(B0,":"),B0.forEach(t),AKo=i(ha),v_e=n(ha,"UL",{});var O3t=s(v_e);LF=n(O3t,"LI",{});var vRe=s(LF);F_e=n(vRe,"STRONG",{});var V3t=s(F_e);yKo=r(V3t,"tapas"),V3t.forEach(t),LKo=r(vRe," \u2014 "),Az=n(vRe,"A",{href:!0});var X3t=s(Az);xKo=r(X3t,"TapasForQuestionAnswering"),X3t.forEach(t),$Ko=r(vRe," (TAPAS model)"),vRe.forEach(t),O3t.forEach(t),kKo=i(ha),xF=n(ha,"P",{});var FRe=s(xF);SKo=r(FRe,"The model is set in evaluation mode by default using "),T_e=n(FRe,"CODE",{});var z3t=s(T_e);RKo=r(z3t,"model.eval()"),z3t.forEach(t),PKo=r(FRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),M_e=n(FRe,"CODE",{});var W3t=s(M_e);BKo=r(W3t,"model.train()"),W3t.forEach(t),FRe.forEach(t),IKo=i(ha),T($F.$$.fragment,ha),ha.forEach(t),nl.forEach(t),aGe=i(f),md=n(f,"H2",{class:!0});var cVe=s(md);kF=n(cVe,"A",{id:!0,class:!0,href:!0});var Q3t=s(kF);E_e=n(Q3t,"SPAN",{});var H3t=s(E_e);T(jy.$$.fragment,H3t),H3t.forEach(t),Q3t.forEach(t),NKo=i(cVe),C_e=n(cVe,"SPAN",{});var U3t=s(C_e);qKo=r(U3t,"AutoModelForImageClassification"),U3t.forEach(t),cVe.forEach(t),nGe=i(f),Do=n(f,"DIV",{class:!0});var sl=s(Do);T(Dy.$$.fragment,sl),jKo=i(sl),gd=n(sl,"P",{});var toe=s(gd);DKo=r(toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),yz=n(toe,"A",{href:!0});var J3t=s(yz);GKo=r(J3t,"from_pretrained()"),J3t.forEach(t),OKo=r(toe," class method or the "),Lz=n(toe,"A",{href:!0});var Y3t=s(Lz);VKo=r(Y3t,"from_config()"),Y3t.forEach(t),XKo=r(toe,` class
method.`),toe.forEach(t),zKo=i(sl),Gy=n(sl,"P",{});var fVe=s(Gy);WKo=r(fVe,"This class cannot be instantiated directly using "),w_e=n(fVe,"CODE",{});var K3t=s(w_e);QKo=r(K3t,"__init__()"),K3t.forEach(t),HKo=r(fVe," (throws an error)."),fVe.forEach(t),UKo=i(sl),ut=n(sl,"DIV",{class:!0});var I0=s(ut);T(Oy.$$.fragment,I0),JKo=i(I0),A_e=n(I0,"P",{});var Z3t=s(A_e);YKo=r(Z3t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Z3t.forEach(t),KKo=i(I0),hd=n(I0,"P",{});var aoe=s(hd);ZKo=r(aoe,`Note:
Loading a model from its configuration file does `),y_e=n(aoe,"STRONG",{});var eFt=s(y_e);eZo=r(eFt,"not"),eFt.forEach(t),oZo=r(aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),xz=n(aoe,"A",{href:!0});var oFt=s(xz);rZo=r(oFt,"from_pretrained()"),oFt.forEach(t),tZo=r(aoe," to load the model weights."),aoe.forEach(t),aZo=i(I0),T(SF.$$.fragment,I0),I0.forEach(t),nZo=i(sl),lo=n(sl,"DIV",{class:!0});var pa=s(lo);T(Vy.$$.fragment,pa),sZo=i(pa),L_e=n(pa,"P",{});var rFt=s(L_e);lZo=r(rFt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),rFt.forEach(t),iZo=i(pa),Va=n(pa,"P",{});var N0=s(Va);dZo=r(N0,"The model class to instantiate is selected based on the "),x_e=n(N0,"CODE",{});var tFt=s(x_e);cZo=r(tFt,"model_type"),tFt.forEach(t),fZo=r(N0,` property of the config object (either
passed as an argument or loaded from `),$_e=n(N0,"CODE",{});var aFt=s($_e);mZo=r(aFt,"pretrained_model_name_or_path"),aFt.forEach(t),gZo=r(N0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k_e=n(N0,"CODE",{});var nFt=s(k_e);hZo=r(nFt,"pretrained_model_name_or_path"),nFt.forEach(t),pZo=r(N0,":"),N0.forEach(t),uZo=i(pa),ve=n(pa,"UL",{});var Te=s(ve);RF=n(Te,"LI",{});var TRe=s(RF);S_e=n(TRe,"STRONG",{});var sFt=s(S_e);_Zo=r(sFt,"beit"),sFt.forEach(t),bZo=r(TRe," \u2014 "),$z=n(TRe,"A",{href:!0});var lFt=s($z);vZo=r(lFt,"BeitForImageClassification"),lFt.forEach(t),FZo=r(TRe," (BEiT model)"),TRe.forEach(t),TZo=i(Te),PF=n(Te,"LI",{});var MRe=s(PF);R_e=n(MRe,"STRONG",{});var iFt=s(R_e);MZo=r(iFt,"convnext"),iFt.forEach(t),EZo=r(MRe," \u2014 "),kz=n(MRe,"A",{href:!0});var dFt=s(kz);CZo=r(dFt,"ConvNextForImageClassification"),dFt.forEach(t),wZo=r(MRe," (ConvNeXT model)"),MRe.forEach(t),AZo=i(Te),BF=n(Te,"LI",{});var ERe=s(BF);P_e=n(ERe,"STRONG",{});var cFt=s(P_e);yZo=r(cFt,"cvt"),cFt.forEach(t),LZo=r(ERe," \u2014 "),Sz=n(ERe,"A",{href:!0});var fFt=s(Sz);xZo=r(fFt,"CvtForImageClassification"),fFt.forEach(t),$Zo=r(ERe," (CvT model)"),ERe.forEach(t),kZo=i(Te),IF=n(Te,"LI",{});var CRe=s(IF);B_e=n(CRe,"STRONG",{});var mFt=s(B_e);SZo=r(mFt,"data2vec-vision"),mFt.forEach(t),RZo=r(CRe," \u2014 "),Rz=n(CRe,"A",{href:!0});var gFt=s(Rz);PZo=r(gFt,"Data2VecVisionForImageClassification"),gFt.forEach(t),BZo=r(CRe," (Data2VecVision model)"),CRe.forEach(t),IZo=i(Te),Gs=n(Te,"LI",{});var Pk=s(Gs);I_e=n(Pk,"STRONG",{});var hFt=s(I_e);NZo=r(hFt,"deit"),hFt.forEach(t),qZo=r(Pk," \u2014 "),Pz=n(Pk,"A",{href:!0});var pFt=s(Pz);jZo=r(pFt,"DeiTForImageClassification"),pFt.forEach(t),DZo=r(Pk," or "),Bz=n(Pk,"A",{href:!0});var uFt=s(Bz);GZo=r(uFt,"DeiTForImageClassificationWithTeacher"),uFt.forEach(t),OZo=r(Pk," (DeiT model)"),Pk.forEach(t),VZo=i(Te),NF=n(Te,"LI",{});var wRe=s(NF);N_e=n(wRe,"STRONG",{});var _Ft=s(N_e);XZo=r(_Ft,"imagegpt"),_Ft.forEach(t),zZo=r(wRe," \u2014 "),Iz=n(wRe,"A",{href:!0});var bFt=s(Iz);WZo=r(bFt,"ImageGPTForImageClassification"),bFt.forEach(t),QZo=r(wRe," (ImageGPT model)"),wRe.forEach(t),HZo=i(Te),Os=n(Te,"LI",{});var Bk=s(Os);q_e=n(Bk,"STRONG",{});var vFt=s(q_e);UZo=r(vFt,"levit"),vFt.forEach(t),JZo=r(Bk," \u2014 "),Nz=n(Bk,"A",{href:!0});var FFt=s(Nz);YZo=r(FFt,"LevitForImageClassification"),FFt.forEach(t),KZo=r(Bk," or "),qz=n(Bk,"A",{href:!0});var TFt=s(qz);ZZo=r(TFt,"LevitForImageClassificationWithTeacher"),TFt.forEach(t),eer=r(Bk," (LeViT model)"),Bk.forEach(t),oer=i(Te),_t=n(Te,"LI",{});var wf=s(_t);j_e=n(wf,"STRONG",{});var MFt=s(j_e);rer=r(MFt,"perceiver"),MFt.forEach(t),ter=r(wf," \u2014 "),jz=n(wf,"A",{href:!0});var EFt=s(jz);aer=r(EFt,"PerceiverForImageClassificationLearned"),EFt.forEach(t),ner=r(wf," or "),Dz=n(wf,"A",{href:!0});var CFt=s(Dz);ser=r(CFt,"PerceiverForImageClassificationFourier"),CFt.forEach(t),ler=r(wf," or "),Gz=n(wf,"A",{href:!0});var wFt=s(Gz);ier=r(wFt,"PerceiverForImageClassificationConvProcessing"),wFt.forEach(t),der=r(wf," (Perceiver model)"),wf.forEach(t),cer=i(Te),qF=n(Te,"LI",{});var ARe=s(qF);D_e=n(ARe,"STRONG",{});var AFt=s(D_e);fer=r(AFt,"poolformer"),AFt.forEach(t),mer=r(ARe," \u2014 "),Oz=n(ARe,"A",{href:!0});var yFt=s(Oz);ger=r(yFt,"PoolFormerForImageClassification"),yFt.forEach(t),her=r(ARe," (PoolFormer model)"),ARe.forEach(t),per=i(Te),jF=n(Te,"LI",{});var yRe=s(jF);G_e=n(yRe,"STRONG",{});var LFt=s(G_e);uer=r(LFt,"regnet"),LFt.forEach(t),_er=r(yRe," \u2014 "),Vz=n(yRe,"A",{href:!0});var xFt=s(Vz);ber=r(xFt,"RegNetForImageClassification"),xFt.forEach(t),ver=r(yRe," (RegNet model)"),yRe.forEach(t),Fer=i(Te),DF=n(Te,"LI",{});var LRe=s(DF);O_e=n(LRe,"STRONG",{});var $Ft=s(O_e);Ter=r($Ft,"resnet"),$Ft.forEach(t),Mer=r(LRe," \u2014 "),Xz=n(LRe,"A",{href:!0});var kFt=s(Xz);Eer=r(kFt,"ResNetForImageClassification"),kFt.forEach(t),Cer=r(LRe," (ResNet model)"),LRe.forEach(t),wer=i(Te),GF=n(Te,"LI",{});var xRe=s(GF);V_e=n(xRe,"STRONG",{});var SFt=s(V_e);Aer=r(SFt,"segformer"),SFt.forEach(t),yer=r(xRe," \u2014 "),zz=n(xRe,"A",{href:!0});var RFt=s(zz);Ler=r(RFt,"SegformerForImageClassification"),RFt.forEach(t),xer=r(xRe," (SegFormer model)"),xRe.forEach(t),$er=i(Te),OF=n(Te,"LI",{});var $Re=s(OF);X_e=n($Re,"STRONG",{});var PFt=s(X_e);ker=r(PFt,"swin"),PFt.forEach(t),Ser=r($Re," \u2014 "),Wz=n($Re,"A",{href:!0});var BFt=s(Wz);Rer=r(BFt,"SwinForImageClassification"),BFt.forEach(t),Per=r($Re," (Swin Transformer model)"),$Re.forEach(t),Ber=i(Te),VF=n(Te,"LI",{});var kRe=s(VF);z_e=n(kRe,"STRONG",{});var IFt=s(z_e);Ier=r(IFt,"van"),IFt.forEach(t),Ner=r(kRe," \u2014 "),Qz=n(kRe,"A",{href:!0});var NFt=s(Qz);qer=r(NFt,"VanForImageClassification"),NFt.forEach(t),jer=r(kRe," (VAN model)"),kRe.forEach(t),Der=i(Te),XF=n(Te,"LI",{});var SRe=s(XF);W_e=n(SRe,"STRONG",{});var qFt=s(W_e);Ger=r(qFt,"vit"),qFt.forEach(t),Oer=r(SRe," \u2014 "),Hz=n(SRe,"A",{href:!0});var jFt=s(Hz);Ver=r(jFt,"ViTForImageClassification"),jFt.forEach(t),Xer=r(SRe," (ViT model)"),SRe.forEach(t),Te.forEach(t),zer=i(pa),zF=n(pa,"P",{});var RRe=s(zF);Wer=r(RRe,"The model is set in evaluation mode by default using "),Q_e=n(RRe,"CODE",{});var DFt=s(Q_e);Qer=r(DFt,"model.eval()"),DFt.forEach(t),Her=r(RRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H_e=n(RRe,"CODE",{});var GFt=s(H_e);Uer=r(GFt,"model.train()"),GFt.forEach(t),RRe.forEach(t),Jer=i(pa),T(WF.$$.fragment,pa),pa.forEach(t),sl.forEach(t),sGe=i(f),pd=n(f,"H2",{class:!0});var mVe=s(pd);QF=n(mVe,"A",{id:!0,class:!0,href:!0});var OFt=s(QF);U_e=n(OFt,"SPAN",{});var VFt=s(U_e);T(Xy.$$.fragment,VFt),VFt.forEach(t),OFt.forEach(t),Yer=i(mVe),J_e=n(mVe,"SPAN",{});var XFt=s(J_e);Ker=r(XFt,"AutoModelForVision2Seq"),XFt.forEach(t),mVe.forEach(t),lGe=i(f),Go=n(f,"DIV",{class:!0});var ll=s(Go);T(zy.$$.fragment,ll),Zer=i(ll),ud=n(ll,"P",{});var noe=s(ud);eor=r(noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Uz=n(noe,"A",{href:!0});var zFt=s(Uz);oor=r(zFt,"from_pretrained()"),zFt.forEach(t),ror=r(noe," class method or the "),Jz=n(noe,"A",{href:!0});var WFt=s(Jz);tor=r(WFt,"from_config()"),WFt.forEach(t),aor=r(noe,` class
method.`),noe.forEach(t),nor=i(ll),Wy=n(ll,"P",{});var gVe=s(Wy);sor=r(gVe,"This class cannot be instantiated directly using "),Y_e=n(gVe,"CODE",{});var QFt=s(Y_e);lor=r(QFt,"__init__()"),QFt.forEach(t),ior=r(gVe," (throws an error)."),gVe.forEach(t),dor=i(ll),bt=n(ll,"DIV",{class:!0});var q0=s(bt);T(Qy.$$.fragment,q0),cor=i(q0),K_e=n(q0,"P",{});var HFt=s(K_e);mor=r(HFt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),HFt.forEach(t),gor=i(q0),_d=n(q0,"P",{});var soe=s(_d);hor=r(soe,`Note:
Loading a model from its configuration file does `),Z_e=n(soe,"STRONG",{});var UFt=s(Z_e);por=r(UFt,"not"),UFt.forEach(t),uor=r(soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yz=n(soe,"A",{href:!0});var JFt=s(Yz);_or=r(JFt,"from_pretrained()"),JFt.forEach(t),bor=r(soe," to load the model weights."),soe.forEach(t),vor=i(q0),T(HF.$$.fragment,q0),q0.forEach(t),For=i(ll),io=n(ll,"DIV",{class:!0});var ua=s(io);T(Hy.$$.fragment,ua),Tor=i(ua),e1e=n(ua,"P",{});var YFt=s(e1e);Mor=r(YFt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),YFt.forEach(t),Eor=i(ua),Xa=n(ua,"P",{});var j0=s(Xa);Cor=r(j0,"The model class to instantiate is selected based on the "),o1e=n(j0,"CODE",{});var KFt=s(o1e);wor=r(KFt,"model_type"),KFt.forEach(t),Aor=r(j0,` property of the config object (either
passed as an argument or loaded from `),r1e=n(j0,"CODE",{});var ZFt=s(r1e);yor=r(ZFt,"pretrained_model_name_or_path"),ZFt.forEach(t),Lor=r(j0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t1e=n(j0,"CODE",{});var e6t=s(t1e);xor=r(e6t,"pretrained_model_name_or_path"),e6t.forEach(t),$or=r(j0,":"),j0.forEach(t),kor=i(ua),a1e=n(ua,"UL",{});var o6t=s(a1e);UF=n(o6t,"LI",{});var PRe=s(UF);n1e=n(PRe,"STRONG",{});var r6t=s(n1e);Sor=r(r6t,"vision-encoder-decoder"),r6t.forEach(t),Ror=r(PRe," \u2014 "),Kz=n(PRe,"A",{href:!0});var t6t=s(Kz);Por=r(t6t,"VisionEncoderDecoderModel"),t6t.forEach(t),Bor=r(PRe," (Vision Encoder decoder model)"),PRe.forEach(t),o6t.forEach(t),Ior=i(ua),JF=n(ua,"P",{});var BRe=s(JF);Nor=r(BRe,"The model is set in evaluation mode by default using "),s1e=n(BRe,"CODE",{});var a6t=s(s1e);qor=r(a6t,"model.eval()"),a6t.forEach(t),jor=r(BRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=n(BRe,"CODE",{});var n6t=s(l1e);Dor=r(n6t,"model.train()"),n6t.forEach(t),BRe.forEach(t),Gor=i(ua),T(YF.$$.fragment,ua),ua.forEach(t),ll.forEach(t),iGe=i(f),bd=n(f,"H2",{class:!0});var hVe=s(bd);KF=n(hVe,"A",{id:!0,class:!0,href:!0});var s6t=s(KF);i1e=n(s6t,"SPAN",{});var l6t=s(i1e);T(Uy.$$.fragment,l6t),l6t.forEach(t),s6t.forEach(t),Oor=i(hVe),d1e=n(hVe,"SPAN",{});var i6t=s(d1e);Vor=r(i6t,"AutoModelForVisualQuestionAnswering"),i6t.forEach(t),hVe.forEach(t),dGe=i(f),Oo=n(f,"DIV",{class:!0});var il=s(Oo);T(Jy.$$.fragment,il),Xor=i(il),vd=n(il,"P",{});var loe=s(vd);zor=r(loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Zz=n(loe,"A",{href:!0});var d6t=s(Zz);Wor=r(d6t,"from_pretrained()"),d6t.forEach(t),Qor=r(loe," class method or the "),eW=n(loe,"A",{href:!0});var c6t=s(eW);Hor=r(c6t,"from_config()"),c6t.forEach(t),Uor=r(loe,` class
method.`),loe.forEach(t),Jor=i(il),Yy=n(il,"P",{});var pVe=s(Yy);Yor=r(pVe,"This class cannot be instantiated directly using "),c1e=n(pVe,"CODE",{});var f6t=s(c1e);Kor=r(f6t,"__init__()"),f6t.forEach(t),Zor=r(pVe," (throws an error)."),pVe.forEach(t),err=i(il),vt=n(il,"DIV",{class:!0});var D0=s(vt);T(Ky.$$.fragment,D0),orr=i(D0),f1e=n(D0,"P",{});var m6t=s(f1e);rrr=r(m6t,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),m6t.forEach(t),trr=i(D0),Fd=n(D0,"P",{});var ioe=s(Fd);arr=r(ioe,`Note:
Loading a model from its configuration file does `),m1e=n(ioe,"STRONG",{});var g6t=s(m1e);nrr=r(g6t,"not"),g6t.forEach(t),srr=r(ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=n(ioe,"A",{href:!0});var h6t=s(oW);lrr=r(h6t,"from_pretrained()"),h6t.forEach(t),irr=r(ioe," to load the model weights."),ioe.forEach(t),drr=i(D0),T(ZF.$$.fragment,D0),D0.forEach(t),crr=i(il),co=n(il,"DIV",{class:!0});var _a=s(co);T(Zy.$$.fragment,_a),frr=i(_a),g1e=n(_a,"P",{});var p6t=s(g1e);mrr=r(p6t,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),p6t.forEach(t),grr=i(_a),za=n(_a,"P",{});var G0=s(za);hrr=r(G0,"The model class to instantiate is selected based on the "),h1e=n(G0,"CODE",{});var u6t=s(h1e);prr=r(u6t,"model_type"),u6t.forEach(t),urr=r(G0,` property of the config object (either
passed as an argument or loaded from `),p1e=n(G0,"CODE",{});var _6t=s(p1e);_rr=r(_6t,"pretrained_model_name_or_path"),_6t.forEach(t),brr=r(G0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u1e=n(G0,"CODE",{});var b6t=s(u1e);vrr=r(b6t,"pretrained_model_name_or_path"),b6t.forEach(t),Frr=r(G0,":"),G0.forEach(t),Trr=i(_a),_1e=n(_a,"UL",{});var v6t=s(_1e);e6=n(v6t,"LI",{});var IRe=s(e6);b1e=n(IRe,"STRONG",{});var F6t=s(b1e);Mrr=r(F6t,"vilt"),F6t.forEach(t),Err=r(IRe," \u2014 "),rW=n(IRe,"A",{href:!0});var T6t=s(rW);Crr=r(T6t,"ViltForQuestionAnswering"),T6t.forEach(t),wrr=r(IRe," (ViLT model)"),IRe.forEach(t),v6t.forEach(t),Arr=i(_a),o6=n(_a,"P",{});var NRe=s(o6);yrr=r(NRe,"The model is set in evaluation mode by default using "),v1e=n(NRe,"CODE",{});var M6t=s(v1e);Lrr=r(M6t,"model.eval()"),M6t.forEach(t),xrr=r(NRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=n(NRe,"CODE",{});var E6t=s(F1e);$rr=r(E6t,"model.train()"),E6t.forEach(t),NRe.forEach(t),krr=i(_a),T(r6.$$.fragment,_a),_a.forEach(t),il.forEach(t),cGe=i(f),Td=n(f,"H2",{class:!0});var uVe=s(Td);t6=n(uVe,"A",{id:!0,class:!0,href:!0});var C6t=s(t6);T1e=n(C6t,"SPAN",{});var w6t=s(T1e);T(eL.$$.fragment,w6t),w6t.forEach(t),C6t.forEach(t),Srr=i(uVe),M1e=n(uVe,"SPAN",{});var A6t=s(M1e);Rrr=r(A6t,"AutoModelForAudioClassification"),A6t.forEach(t),uVe.forEach(t),fGe=i(f),Vo=n(f,"DIV",{class:!0});var dl=s(Vo);T(oL.$$.fragment,dl),Prr=i(dl),Md=n(dl,"P",{});var doe=s(Md);Brr=r(doe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),tW=n(doe,"A",{href:!0});var y6t=s(tW);Irr=r(y6t,"from_pretrained()"),y6t.forEach(t),Nrr=r(doe," class method or the "),aW=n(doe,"A",{href:!0});var L6t=s(aW);qrr=r(L6t,"from_config()"),L6t.forEach(t),jrr=r(doe,` class
method.`),doe.forEach(t),Drr=i(dl),rL=n(dl,"P",{});var _Ve=s(rL);Grr=r(_Ve,"This class cannot be instantiated directly using "),E1e=n(_Ve,"CODE",{});var x6t=s(E1e);Orr=r(x6t,"__init__()"),x6t.forEach(t),Vrr=r(_Ve," (throws an error)."),_Ve.forEach(t),Xrr=i(dl),Ft=n(dl,"DIV",{class:!0});var O0=s(Ft);T(tL.$$.fragment,O0),zrr=i(O0),C1e=n(O0,"P",{});var $6t=s(C1e);Wrr=r($6t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$6t.forEach(t),Qrr=i(O0),Ed=n(O0,"P",{});var coe=s(Ed);Hrr=r(coe,`Note:
Loading a model from its configuration file does `),w1e=n(coe,"STRONG",{});var k6t=s(w1e);Urr=r(k6t,"not"),k6t.forEach(t),Jrr=r(coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),nW=n(coe,"A",{href:!0});var S6t=s(nW);Yrr=r(S6t,"from_pretrained()"),S6t.forEach(t),Krr=r(coe," to load the model weights."),coe.forEach(t),Zrr=i(O0),T(a6.$$.fragment,O0),O0.forEach(t),etr=i(dl),fo=n(dl,"DIV",{class:!0});var ba=s(fo);T(aL.$$.fragment,ba),otr=i(ba),A1e=n(ba,"P",{});var R6t=s(A1e);rtr=r(R6t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),R6t.forEach(t),ttr=i(ba),Wa=n(ba,"P",{});var V0=s(Wa);atr=r(V0,"The model class to instantiate is selected based on the "),y1e=n(V0,"CODE",{});var P6t=s(y1e);ntr=r(P6t,"model_type"),P6t.forEach(t),str=r(V0,` property of the config object (either
passed as an argument or loaded from `),L1e=n(V0,"CODE",{});var B6t=s(L1e);ltr=r(B6t,"pretrained_model_name_or_path"),B6t.forEach(t),itr=r(V0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=n(V0,"CODE",{});var I6t=s(x1e);dtr=r(I6t,"pretrained_model_name_or_path"),I6t.forEach(t),ctr=r(V0,":"),V0.forEach(t),ftr=i(ba),Re=n(ba,"UL",{});var Xe=s(Re);n6=n(Xe,"LI",{});var qRe=s(n6);$1e=n(qRe,"STRONG",{});var N6t=s($1e);mtr=r(N6t,"data2vec-audio"),N6t.forEach(t),gtr=r(qRe," \u2014 "),sW=n(qRe,"A",{href:!0});var q6t=s(sW);htr=r(q6t,"Data2VecAudioForSequenceClassification"),q6t.forEach(t),ptr=r(qRe," (Data2VecAudio model)"),qRe.forEach(t),utr=i(Xe),s6=n(Xe,"LI",{});var jRe=s(s6);k1e=n(jRe,"STRONG",{});var j6t=s(k1e);_tr=r(j6t,"hubert"),j6t.forEach(t),btr=r(jRe," \u2014 "),lW=n(jRe,"A",{href:!0});var D6t=s(lW);vtr=r(D6t,"HubertForSequenceClassification"),D6t.forEach(t),Ftr=r(jRe," (Hubert model)"),jRe.forEach(t),Ttr=i(Xe),l6=n(Xe,"LI",{});var DRe=s(l6);S1e=n(DRe,"STRONG",{});var G6t=s(S1e);Mtr=r(G6t,"sew"),G6t.forEach(t),Etr=r(DRe," \u2014 "),iW=n(DRe,"A",{href:!0});var O6t=s(iW);Ctr=r(O6t,"SEWForSequenceClassification"),O6t.forEach(t),wtr=r(DRe," (SEW model)"),DRe.forEach(t),Atr=i(Xe),i6=n(Xe,"LI",{});var GRe=s(i6);R1e=n(GRe,"STRONG",{});var V6t=s(R1e);ytr=r(V6t,"sew-d"),V6t.forEach(t),Ltr=r(GRe," \u2014 "),dW=n(GRe,"A",{href:!0});var X6t=s(dW);xtr=r(X6t,"SEWDForSequenceClassification"),X6t.forEach(t),$tr=r(GRe," (SEW-D model)"),GRe.forEach(t),ktr=i(Xe),d6=n(Xe,"LI",{});var ORe=s(d6);P1e=n(ORe,"STRONG",{});var z6t=s(P1e);Str=r(z6t,"unispeech"),z6t.forEach(t),Rtr=r(ORe," \u2014 "),cW=n(ORe,"A",{href:!0});var W6t=s(cW);Ptr=r(W6t,"UniSpeechForSequenceClassification"),W6t.forEach(t),Btr=r(ORe," (UniSpeech model)"),ORe.forEach(t),Itr=i(Xe),c6=n(Xe,"LI",{});var VRe=s(c6);B1e=n(VRe,"STRONG",{});var Q6t=s(B1e);Ntr=r(Q6t,"unispeech-sat"),Q6t.forEach(t),qtr=r(VRe," \u2014 "),fW=n(VRe,"A",{href:!0});var H6t=s(fW);jtr=r(H6t,"UniSpeechSatForSequenceClassification"),H6t.forEach(t),Dtr=r(VRe," (UniSpeechSat model)"),VRe.forEach(t),Gtr=i(Xe),f6=n(Xe,"LI",{});var XRe=s(f6);I1e=n(XRe,"STRONG",{});var U6t=s(I1e);Otr=r(U6t,"wav2vec2"),U6t.forEach(t),Vtr=r(XRe," \u2014 "),mW=n(XRe,"A",{href:!0});var J6t=s(mW);Xtr=r(J6t,"Wav2Vec2ForSequenceClassification"),J6t.forEach(t),ztr=r(XRe," (Wav2Vec2 model)"),XRe.forEach(t),Wtr=i(Xe),m6=n(Xe,"LI",{});var zRe=s(m6);N1e=n(zRe,"STRONG",{});var Y6t=s(N1e);Qtr=r(Y6t,"wav2vec2-conformer"),Y6t.forEach(t),Htr=r(zRe," \u2014 "),gW=n(zRe,"A",{href:!0});var K6t=s(gW);Utr=r(K6t,"Wav2Vec2ConformerForSequenceClassification"),K6t.forEach(t),Jtr=r(zRe," (Wav2Vec2-Conformer model)"),zRe.forEach(t),Ytr=i(Xe),g6=n(Xe,"LI",{});var WRe=s(g6);q1e=n(WRe,"STRONG",{});var Z6t=s(q1e);Ktr=r(Z6t,"wavlm"),Z6t.forEach(t),Ztr=r(WRe," \u2014 "),hW=n(WRe,"A",{href:!0});var eTt=s(hW);ear=r(eTt,"WavLMForSequenceClassification"),eTt.forEach(t),oar=r(WRe," (WavLM model)"),WRe.forEach(t),Xe.forEach(t),rar=i(ba),h6=n(ba,"P",{});var QRe=s(h6);tar=r(QRe,"The model is set in evaluation mode by default using "),j1e=n(QRe,"CODE",{});var oTt=s(j1e);aar=r(oTt,"model.eval()"),oTt.forEach(t),nar=r(QRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D1e=n(QRe,"CODE",{});var rTt=s(D1e);sar=r(rTt,"model.train()"),rTt.forEach(t),QRe.forEach(t),lar=i(ba),T(p6.$$.fragment,ba),ba.forEach(t),dl.forEach(t),mGe=i(f),Cd=n(f,"H2",{class:!0});var bVe=s(Cd);u6=n(bVe,"A",{id:!0,class:!0,href:!0});var tTt=s(u6);G1e=n(tTt,"SPAN",{});var aTt=s(G1e);T(nL.$$.fragment,aTt),aTt.forEach(t),tTt.forEach(t),iar=i(bVe),O1e=n(bVe,"SPAN",{});var nTt=s(O1e);dar=r(nTt,"AutoModelForAudioFrameClassification"),nTt.forEach(t),bVe.forEach(t),gGe=i(f),Xo=n(f,"DIV",{class:!0});var cl=s(Xo);T(sL.$$.fragment,cl),car=i(cl),wd=n(cl,"P",{});var foe=s(wd);far=r(foe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),pW=n(foe,"A",{href:!0});var sTt=s(pW);mar=r(sTt,"from_pretrained()"),sTt.forEach(t),gar=r(foe," class method or the "),uW=n(foe,"A",{href:!0});var lTt=s(uW);har=r(lTt,"from_config()"),lTt.forEach(t),par=r(foe,` class
method.`),foe.forEach(t),uar=i(cl),lL=n(cl,"P",{});var vVe=s(lL);_ar=r(vVe,"This class cannot be instantiated directly using "),V1e=n(vVe,"CODE",{});var iTt=s(V1e);bar=r(iTt,"__init__()"),iTt.forEach(t),Far=r(vVe," (throws an error)."),vVe.forEach(t),Tar=i(cl),Tt=n(cl,"DIV",{class:!0});var X0=s(Tt);T(iL.$$.fragment,X0),Mar=i(X0),X1e=n(X0,"P",{});var dTt=s(X1e);Ear=r(dTt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),dTt.forEach(t),Car=i(X0),Ad=n(X0,"P",{});var moe=s(Ad);war=r(moe,`Note:
Loading a model from its configuration file does `),z1e=n(moe,"STRONG",{});var cTt=s(z1e);Aar=r(cTt,"not"),cTt.forEach(t),yar=r(moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_W=n(moe,"A",{href:!0});var fTt=s(_W);Lar=r(fTt,"from_pretrained()"),fTt.forEach(t),xar=r(moe," to load the model weights."),moe.forEach(t),$ar=i(X0),T(_6.$$.fragment,X0),X0.forEach(t),kar=i(cl),mo=n(cl,"DIV",{class:!0});var va=s(mo);T(dL.$$.fragment,va),Sar=i(va),W1e=n(va,"P",{});var mTt=s(W1e);Rar=r(mTt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),mTt.forEach(t),Par=i(va),Qa=n(va,"P",{});var z0=s(Qa);Bar=r(z0,"The model class to instantiate is selected based on the "),Q1e=n(z0,"CODE",{});var gTt=s(Q1e);Iar=r(gTt,"model_type"),gTt.forEach(t),Nar=r(z0,` property of the config object (either
passed as an argument or loaded from `),H1e=n(z0,"CODE",{});var hTt=s(H1e);qar=r(hTt,"pretrained_model_name_or_path"),hTt.forEach(t),jar=r(z0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=n(z0,"CODE",{});var pTt=s(U1e);Dar=r(pTt,"pretrained_model_name_or_path"),pTt.forEach(t),Gar=r(z0,":"),z0.forEach(t),Oar=i(va),et=n(va,"UL",{});var fl=s(et);b6=n(fl,"LI",{});var HRe=s(b6);J1e=n(HRe,"STRONG",{});var uTt=s(J1e);Var=r(uTt,"data2vec-audio"),uTt.forEach(t),Xar=r(HRe," \u2014 "),bW=n(HRe,"A",{href:!0});var _Tt=s(bW);zar=r(_Tt,"Data2VecAudioForAudioFrameClassification"),_Tt.forEach(t),War=r(HRe," (Data2VecAudio model)"),HRe.forEach(t),Qar=i(fl),v6=n(fl,"LI",{});var URe=s(v6);Y1e=n(URe,"STRONG",{});var bTt=s(Y1e);Har=r(bTt,"unispeech-sat"),bTt.forEach(t),Uar=r(URe," \u2014 "),vW=n(URe,"A",{href:!0});var vTt=s(vW);Jar=r(vTt,"UniSpeechSatForAudioFrameClassification"),vTt.forEach(t),Yar=r(URe," (UniSpeechSat model)"),URe.forEach(t),Kar=i(fl),F6=n(fl,"LI",{});var JRe=s(F6);K1e=n(JRe,"STRONG",{});var FTt=s(K1e);Zar=r(FTt,"wav2vec2"),FTt.forEach(t),enr=r(JRe," \u2014 "),FW=n(JRe,"A",{href:!0});var TTt=s(FW);onr=r(TTt,"Wav2Vec2ForAudioFrameClassification"),TTt.forEach(t),rnr=r(JRe," (Wav2Vec2 model)"),JRe.forEach(t),tnr=i(fl),T6=n(fl,"LI",{});var YRe=s(T6);Z1e=n(YRe,"STRONG",{});var MTt=s(Z1e);anr=r(MTt,"wav2vec2-conformer"),MTt.forEach(t),nnr=r(YRe," \u2014 "),TW=n(YRe,"A",{href:!0});var ETt=s(TW);snr=r(ETt,"Wav2Vec2ConformerForAudioFrameClassification"),ETt.forEach(t),lnr=r(YRe," (Wav2Vec2-Conformer model)"),YRe.forEach(t),inr=i(fl),M6=n(fl,"LI",{});var KRe=s(M6);ebe=n(KRe,"STRONG",{});var CTt=s(ebe);dnr=r(CTt,"wavlm"),CTt.forEach(t),cnr=r(KRe," \u2014 "),MW=n(KRe,"A",{href:!0});var wTt=s(MW);fnr=r(wTt,"WavLMForAudioFrameClassification"),wTt.forEach(t),mnr=r(KRe," (WavLM model)"),KRe.forEach(t),fl.forEach(t),gnr=i(va),E6=n(va,"P",{});var ZRe=s(E6);hnr=r(ZRe,"The model is set in evaluation mode by default using "),obe=n(ZRe,"CODE",{});var ATt=s(obe);pnr=r(ATt,"model.eval()"),ATt.forEach(t),unr=r(ZRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rbe=n(ZRe,"CODE",{});var yTt=s(rbe);_nr=r(yTt,"model.train()"),yTt.forEach(t),ZRe.forEach(t),bnr=i(va),T(C6.$$.fragment,va),va.forEach(t),cl.forEach(t),hGe=i(f),yd=n(f,"H2",{class:!0});var FVe=s(yd);w6=n(FVe,"A",{id:!0,class:!0,href:!0});var LTt=s(w6);tbe=n(LTt,"SPAN",{});var xTt=s(tbe);T(cL.$$.fragment,xTt),xTt.forEach(t),LTt.forEach(t),vnr=i(FVe),abe=n(FVe,"SPAN",{});var $Tt=s(abe);Fnr=r($Tt,"AutoModelForCTC"),$Tt.forEach(t),FVe.forEach(t),pGe=i(f),zo=n(f,"DIV",{class:!0});var ml=s(zo);T(fL.$$.fragment,ml),Tnr=i(ml),Ld=n(ml,"P",{});var goe=s(Ld);Mnr=r(goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),EW=n(goe,"A",{href:!0});var kTt=s(EW);Enr=r(kTt,"from_pretrained()"),kTt.forEach(t),Cnr=r(goe," class method or the "),CW=n(goe,"A",{href:!0});var STt=s(CW);wnr=r(STt,"from_config()"),STt.forEach(t),Anr=r(goe,` class
method.`),goe.forEach(t),ynr=i(ml),mL=n(ml,"P",{});var TVe=s(mL);Lnr=r(TVe,"This class cannot be instantiated directly using "),nbe=n(TVe,"CODE",{});var RTt=s(nbe);xnr=r(RTt,"__init__()"),RTt.forEach(t),$nr=r(TVe," (throws an error)."),TVe.forEach(t),knr=i(ml),Mt=n(ml,"DIV",{class:!0});var W0=s(Mt);T(gL.$$.fragment,W0),Snr=i(W0),sbe=n(W0,"P",{});var PTt=s(sbe);Rnr=r(PTt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),PTt.forEach(t),Pnr=i(W0),xd=n(W0,"P",{});var hoe=s(xd);Bnr=r(hoe,`Note:
Loading a model from its configuration file does `),lbe=n(hoe,"STRONG",{});var BTt=s(lbe);Inr=r(BTt,"not"),BTt.forEach(t),Nnr=r(hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wW=n(hoe,"A",{href:!0});var ITt=s(wW);qnr=r(ITt,"from_pretrained()"),ITt.forEach(t),jnr=r(hoe," to load the model weights."),hoe.forEach(t),Dnr=i(W0),T(A6.$$.fragment,W0),W0.forEach(t),Gnr=i(ml),go=n(ml,"DIV",{class:!0});var Fa=s(go);T(hL.$$.fragment,Fa),Onr=i(Fa),ibe=n(Fa,"P",{});var NTt=s(ibe);Vnr=r(NTt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),NTt.forEach(t),Xnr=i(Fa),Ha=n(Fa,"P",{});var Q0=s(Ha);znr=r(Q0,"The model class to instantiate is selected based on the "),dbe=n(Q0,"CODE",{});var qTt=s(dbe);Wnr=r(qTt,"model_type"),qTt.forEach(t),Qnr=r(Q0,` property of the config object (either
passed as an argument or loaded from `),cbe=n(Q0,"CODE",{});var jTt=s(cbe);Hnr=r(jTt,"pretrained_model_name_or_path"),jTt.forEach(t),Unr=r(Q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fbe=n(Q0,"CODE",{});var DTt=s(fbe);Jnr=r(DTt,"pretrained_model_name_or_path"),DTt.forEach(t),Ynr=r(Q0,":"),Q0.forEach(t),Knr=i(Fa),ye=n(Fa,"UL",{});var Be=s(ye);y6=n(Be,"LI",{});var ePe=s(y6);mbe=n(ePe,"STRONG",{});var GTt=s(mbe);Znr=r(GTt,"data2vec-audio"),GTt.forEach(t),esr=r(ePe," \u2014 "),AW=n(ePe,"A",{href:!0});var OTt=s(AW);osr=r(OTt,"Data2VecAudioForCTC"),OTt.forEach(t),rsr=r(ePe," (Data2VecAudio model)"),ePe.forEach(t),tsr=i(Be),L6=n(Be,"LI",{});var oPe=s(L6);gbe=n(oPe,"STRONG",{});var VTt=s(gbe);asr=r(VTt,"hubert"),VTt.forEach(t),nsr=r(oPe," \u2014 "),yW=n(oPe,"A",{href:!0});var XTt=s(yW);ssr=r(XTt,"HubertForCTC"),XTt.forEach(t),lsr=r(oPe," (Hubert model)"),oPe.forEach(t),isr=i(Be),x6=n(Be,"LI",{});var rPe=s(x6);hbe=n(rPe,"STRONG",{});var zTt=s(hbe);dsr=r(zTt,"mctct"),zTt.forEach(t),csr=r(rPe," \u2014 "),LW=n(rPe,"A",{href:!0});var WTt=s(LW);fsr=r(WTt,"MCTCTForCTC"),WTt.forEach(t),msr=r(rPe," (M-CTC-T model)"),rPe.forEach(t),gsr=i(Be),$6=n(Be,"LI",{});var tPe=s($6);pbe=n(tPe,"STRONG",{});var QTt=s(pbe);hsr=r(QTt,"sew"),QTt.forEach(t),psr=r(tPe," \u2014 "),xW=n(tPe,"A",{href:!0});var HTt=s(xW);usr=r(HTt,"SEWForCTC"),HTt.forEach(t),_sr=r(tPe," (SEW model)"),tPe.forEach(t),bsr=i(Be),k6=n(Be,"LI",{});var aPe=s(k6);ube=n(aPe,"STRONG",{});var UTt=s(ube);vsr=r(UTt,"sew-d"),UTt.forEach(t),Fsr=r(aPe," \u2014 "),$W=n(aPe,"A",{href:!0});var JTt=s($W);Tsr=r(JTt,"SEWDForCTC"),JTt.forEach(t),Msr=r(aPe," (SEW-D model)"),aPe.forEach(t),Esr=i(Be),S6=n(Be,"LI",{});var nPe=s(S6);_be=n(nPe,"STRONG",{});var YTt=s(_be);Csr=r(YTt,"unispeech"),YTt.forEach(t),wsr=r(nPe," \u2014 "),kW=n(nPe,"A",{href:!0});var KTt=s(kW);Asr=r(KTt,"UniSpeechForCTC"),KTt.forEach(t),ysr=r(nPe," (UniSpeech model)"),nPe.forEach(t),Lsr=i(Be),R6=n(Be,"LI",{});var sPe=s(R6);bbe=n(sPe,"STRONG",{});var ZTt=s(bbe);xsr=r(ZTt,"unispeech-sat"),ZTt.forEach(t),$sr=r(sPe," \u2014 "),SW=n(sPe,"A",{href:!0});var e7t=s(SW);ksr=r(e7t,"UniSpeechSatForCTC"),e7t.forEach(t),Ssr=r(sPe," (UniSpeechSat model)"),sPe.forEach(t),Rsr=i(Be),P6=n(Be,"LI",{});var lPe=s(P6);vbe=n(lPe,"STRONG",{});var o7t=s(vbe);Psr=r(o7t,"wav2vec2"),o7t.forEach(t),Bsr=r(lPe," \u2014 "),RW=n(lPe,"A",{href:!0});var r7t=s(RW);Isr=r(r7t,"Wav2Vec2ForCTC"),r7t.forEach(t),Nsr=r(lPe," (Wav2Vec2 model)"),lPe.forEach(t),qsr=i(Be),B6=n(Be,"LI",{});var iPe=s(B6);Fbe=n(iPe,"STRONG",{});var t7t=s(Fbe);jsr=r(t7t,"wav2vec2-conformer"),t7t.forEach(t),Dsr=r(iPe," \u2014 "),PW=n(iPe,"A",{href:!0});var a7t=s(PW);Gsr=r(a7t,"Wav2Vec2ConformerForCTC"),a7t.forEach(t),Osr=r(iPe," (Wav2Vec2-Conformer model)"),iPe.forEach(t),Vsr=i(Be),I6=n(Be,"LI",{});var dPe=s(I6);Tbe=n(dPe,"STRONG",{});var n7t=s(Tbe);Xsr=r(n7t,"wavlm"),n7t.forEach(t),zsr=r(dPe," \u2014 "),BW=n(dPe,"A",{href:!0});var s7t=s(BW);Wsr=r(s7t,"WavLMForCTC"),s7t.forEach(t),Qsr=r(dPe," (WavLM model)"),dPe.forEach(t),Be.forEach(t),Hsr=i(Fa),N6=n(Fa,"P",{});var cPe=s(N6);Usr=r(cPe,"The model is set in evaluation mode by default using "),Mbe=n(cPe,"CODE",{});var l7t=s(Mbe);Jsr=r(l7t,"model.eval()"),l7t.forEach(t),Ysr=r(cPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=n(cPe,"CODE",{});var i7t=s(Ebe);Ksr=r(i7t,"model.train()"),i7t.forEach(t),cPe.forEach(t),Zsr=i(Fa),T(q6.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),uGe=i(f),$d=n(f,"H2",{class:!0});var MVe=s($d);j6=n(MVe,"A",{id:!0,class:!0,href:!0});var d7t=s(j6);Cbe=n(d7t,"SPAN",{});var c7t=s(Cbe);T(pL.$$.fragment,c7t),c7t.forEach(t),d7t.forEach(t),elr=i(MVe),wbe=n(MVe,"SPAN",{});var f7t=s(wbe);olr=r(f7t,"AutoModelForSpeechSeq2Seq"),f7t.forEach(t),MVe.forEach(t),_Ge=i(f),Wo=n(f,"DIV",{class:!0});var gl=s(Wo);T(uL.$$.fragment,gl),rlr=i(gl),kd=n(gl,"P",{});var poe=s(kd);tlr=r(poe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),IW=n(poe,"A",{href:!0});var m7t=s(IW);alr=r(m7t,"from_pretrained()"),m7t.forEach(t),nlr=r(poe," class method or the "),NW=n(poe,"A",{href:!0});var g7t=s(NW);slr=r(g7t,"from_config()"),g7t.forEach(t),llr=r(poe,` class
method.`),poe.forEach(t),ilr=i(gl),_L=n(gl,"P",{});var EVe=s(_L);dlr=r(EVe,"This class cannot be instantiated directly using "),Abe=n(EVe,"CODE",{});var h7t=s(Abe);clr=r(h7t,"__init__()"),h7t.forEach(t),flr=r(EVe," (throws an error)."),EVe.forEach(t),mlr=i(gl),Et=n(gl,"DIV",{class:!0});var H0=s(Et);T(bL.$$.fragment,H0),glr=i(H0),ybe=n(H0,"P",{});var p7t=s(ybe);hlr=r(p7t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),p7t.forEach(t),plr=i(H0),Sd=n(H0,"P",{});var uoe=s(Sd);ulr=r(uoe,`Note:
Loading a model from its configuration file does `),Lbe=n(uoe,"STRONG",{});var u7t=s(Lbe);_lr=r(u7t,"not"),u7t.forEach(t),blr=r(uoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(uoe,"A",{href:!0});var _7t=s(qW);vlr=r(_7t,"from_pretrained()"),_7t.forEach(t),Flr=r(uoe," to load the model weights."),uoe.forEach(t),Tlr=i(H0),T(D6.$$.fragment,H0),H0.forEach(t),Mlr=i(gl),ho=n(gl,"DIV",{class:!0});var Ta=s(ho);T(vL.$$.fragment,Ta),Elr=i(Ta),xbe=n(Ta,"P",{});var b7t=s(xbe);Clr=r(b7t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),b7t.forEach(t),wlr=i(Ta),Ua=n(Ta,"P",{});var U0=s(Ua);Alr=r(U0,"The model class to instantiate is selected based on the "),$be=n(U0,"CODE",{});var v7t=s($be);ylr=r(v7t,"model_type"),v7t.forEach(t),Llr=r(U0,` property of the config object (either
passed as an argument or loaded from `),kbe=n(U0,"CODE",{});var F7t=s(kbe);xlr=r(F7t,"pretrained_model_name_or_path"),F7t.forEach(t),$lr=r(U0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=n(U0,"CODE",{});var T7t=s(Sbe);klr=r(T7t,"pretrained_model_name_or_path"),T7t.forEach(t),Slr=r(U0,":"),U0.forEach(t),Rlr=i(Ta),FL=n(Ta,"UL",{});var CVe=s(FL);G6=n(CVe,"LI",{});var fPe=s(G6);Rbe=n(fPe,"STRONG",{});var M7t=s(Rbe);Plr=r(M7t,"speech-encoder-decoder"),M7t.forEach(t),Blr=r(fPe," \u2014 "),jW=n(fPe,"A",{href:!0});var E7t=s(jW);Ilr=r(E7t,"SpeechEncoderDecoderModel"),E7t.forEach(t),Nlr=r(fPe," (Speech Encoder decoder model)"),fPe.forEach(t),qlr=i(CVe),O6=n(CVe,"LI",{});var mPe=s(O6);Pbe=n(mPe,"STRONG",{});var C7t=s(Pbe);jlr=r(C7t,"speech_to_text"),C7t.forEach(t),Dlr=r(mPe," \u2014 "),DW=n(mPe,"A",{href:!0});var w7t=s(DW);Glr=r(w7t,"Speech2TextForConditionalGeneration"),w7t.forEach(t),Olr=r(mPe," (Speech2Text model)"),mPe.forEach(t),CVe.forEach(t),Vlr=i(Ta),V6=n(Ta,"P",{});var gPe=s(V6);Xlr=r(gPe,"The model is set in evaluation mode by default using "),Bbe=n(gPe,"CODE",{});var A7t=s(Bbe);zlr=r(A7t,"model.eval()"),A7t.forEach(t),Wlr=r(gPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=n(gPe,"CODE",{});var y7t=s(Ibe);Qlr=r(y7t,"model.train()"),y7t.forEach(t),gPe.forEach(t),Hlr=i(Ta),T(X6.$$.fragment,Ta),Ta.forEach(t),gl.forEach(t),bGe=i(f),Rd=n(f,"H2",{class:!0});var wVe=s(Rd);z6=n(wVe,"A",{id:!0,class:!0,href:!0});var L7t=s(z6);Nbe=n(L7t,"SPAN",{});var x7t=s(Nbe);T(TL.$$.fragment,x7t),x7t.forEach(t),L7t.forEach(t),Ulr=i(wVe),qbe=n(wVe,"SPAN",{});var $7t=s(qbe);Jlr=r($7t,"AutoModelForAudioXVector"),$7t.forEach(t),wVe.forEach(t),vGe=i(f),Qo=n(f,"DIV",{class:!0});var hl=s(Qo);T(ML.$$.fragment,hl),Ylr=i(hl),Pd=n(hl,"P",{});var _oe=s(Pd);Klr=r(_oe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),GW=n(_oe,"A",{href:!0});var k7t=s(GW);Zlr=r(k7t,"from_pretrained()"),k7t.forEach(t),eir=r(_oe," class method or the "),OW=n(_oe,"A",{href:!0});var S7t=s(OW);oir=r(S7t,"from_config()"),S7t.forEach(t),rir=r(_oe,` class
method.`),_oe.forEach(t),tir=i(hl),EL=n(hl,"P",{});var AVe=s(EL);air=r(AVe,"This class cannot be instantiated directly using "),jbe=n(AVe,"CODE",{});var R7t=s(jbe);nir=r(R7t,"__init__()"),R7t.forEach(t),sir=r(AVe," (throws an error)."),AVe.forEach(t),lir=i(hl),Ct=n(hl,"DIV",{class:!0});var J0=s(Ct);T(CL.$$.fragment,J0),iir=i(J0),Dbe=n(J0,"P",{});var P7t=s(Dbe);dir=r(P7t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),P7t.forEach(t),cir=i(J0),Bd=n(J0,"P",{});var boe=s(Bd);fir=r(boe,`Note:
Loading a model from its configuration file does `),Gbe=n(boe,"STRONG",{});var B7t=s(Gbe);mir=r(B7t,"not"),B7t.forEach(t),gir=r(boe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(boe,"A",{href:!0});var I7t=s(VW);hir=r(I7t,"from_pretrained()"),I7t.forEach(t),pir=r(boe," to load the model weights."),boe.forEach(t),uir=i(J0),T(W6.$$.fragment,J0),J0.forEach(t),_ir=i(hl),po=n(hl,"DIV",{class:!0});var Ma=s(po);T(wL.$$.fragment,Ma),bir=i(Ma),Obe=n(Ma,"P",{});var N7t=s(Obe);vir=r(N7t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),N7t.forEach(t),Fir=i(Ma),Ja=n(Ma,"P",{});var Y0=s(Ja);Tir=r(Y0,"The model class to instantiate is selected based on the "),Vbe=n(Y0,"CODE",{});var q7t=s(Vbe);Mir=r(q7t,"model_type"),q7t.forEach(t),Eir=r(Y0,` property of the config object (either
passed as an argument or loaded from `),Xbe=n(Y0,"CODE",{});var j7t=s(Xbe);Cir=r(j7t,"pretrained_model_name_or_path"),j7t.forEach(t),wir=r(Y0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=n(Y0,"CODE",{});var D7t=s(zbe);Air=r(D7t,"pretrained_model_name_or_path"),D7t.forEach(t),yir=r(Y0,":"),Y0.forEach(t),Lir=i(Ma),ot=n(Ma,"UL",{});var pl=s(ot);Q6=n(pl,"LI",{});var hPe=s(Q6);Wbe=n(hPe,"STRONG",{});var G7t=s(Wbe);xir=r(G7t,"data2vec-audio"),G7t.forEach(t),$ir=r(hPe," \u2014 "),XW=n(hPe,"A",{href:!0});var O7t=s(XW);kir=r(O7t,"Data2VecAudioForXVector"),O7t.forEach(t),Sir=r(hPe," (Data2VecAudio model)"),hPe.forEach(t),Rir=i(pl),H6=n(pl,"LI",{});var pPe=s(H6);Qbe=n(pPe,"STRONG",{});var V7t=s(Qbe);Pir=r(V7t,"unispeech-sat"),V7t.forEach(t),Bir=r(pPe," \u2014 "),zW=n(pPe,"A",{href:!0});var X7t=s(zW);Iir=r(X7t,"UniSpeechSatForXVector"),X7t.forEach(t),Nir=r(pPe," (UniSpeechSat model)"),pPe.forEach(t),qir=i(pl),U6=n(pl,"LI",{});var uPe=s(U6);Hbe=n(uPe,"STRONG",{});var z7t=s(Hbe);jir=r(z7t,"wav2vec2"),z7t.forEach(t),Dir=r(uPe," \u2014 "),WW=n(uPe,"A",{href:!0});var W7t=s(WW);Gir=r(W7t,"Wav2Vec2ForXVector"),W7t.forEach(t),Oir=r(uPe," (Wav2Vec2 model)"),uPe.forEach(t),Vir=i(pl),J6=n(pl,"LI",{});var _Pe=s(J6);Ube=n(_Pe,"STRONG",{});var Q7t=s(Ube);Xir=r(Q7t,"wav2vec2-conformer"),Q7t.forEach(t),zir=r(_Pe," \u2014 "),QW=n(_Pe,"A",{href:!0});var H7t=s(QW);Wir=r(H7t,"Wav2Vec2ConformerForXVector"),H7t.forEach(t),Qir=r(_Pe," (Wav2Vec2-Conformer model)"),_Pe.forEach(t),Hir=i(pl),Y6=n(pl,"LI",{});var bPe=s(Y6);Jbe=n(bPe,"STRONG",{});var U7t=s(Jbe);Uir=r(U7t,"wavlm"),U7t.forEach(t),Jir=r(bPe," \u2014 "),HW=n(bPe,"A",{href:!0});var J7t=s(HW);Yir=r(J7t,"WavLMForXVector"),J7t.forEach(t),Kir=r(bPe," (WavLM model)"),bPe.forEach(t),pl.forEach(t),Zir=i(Ma),K6=n(Ma,"P",{});var vPe=s(K6);edr=r(vPe,"The model is set in evaluation mode by default using "),Ybe=n(vPe,"CODE",{});var Y7t=s(Ybe);odr=r(Y7t,"model.eval()"),Y7t.forEach(t),rdr=r(vPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Kbe=n(vPe,"CODE",{});var K7t=s(Kbe);tdr=r(K7t,"model.train()"),K7t.forEach(t),vPe.forEach(t),adr=i(Ma),T(Z6.$$.fragment,Ma),Ma.forEach(t),hl.forEach(t),FGe=i(f),Id=n(f,"H2",{class:!0});var yVe=s(Id);eT=n(yVe,"A",{id:!0,class:!0,href:!0});var Z7t=s(eT);Zbe=n(Z7t,"SPAN",{});var e9t=s(Zbe);T(AL.$$.fragment,e9t),e9t.forEach(t),Z7t.forEach(t),ndr=i(yVe),e2e=n(yVe,"SPAN",{});var o9t=s(e2e);sdr=r(o9t,"AutoModelForMaskedImageModeling"),o9t.forEach(t),yVe.forEach(t),TGe=i(f),Ho=n(f,"DIV",{class:!0});var ul=s(Ho);T(yL.$$.fragment,ul),ldr=i(ul),Nd=n(ul,"P",{});var voe=s(Nd);idr=r(voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),UW=n(voe,"A",{href:!0});var r9t=s(UW);ddr=r(r9t,"from_pretrained()"),r9t.forEach(t),cdr=r(voe," class method or the "),JW=n(voe,"A",{href:!0});var t9t=s(JW);fdr=r(t9t,"from_config()"),t9t.forEach(t),mdr=r(voe,` class
method.`),voe.forEach(t),gdr=i(ul),LL=n(ul,"P",{});var LVe=s(LL);hdr=r(LVe,"This class cannot be instantiated directly using "),o2e=n(LVe,"CODE",{});var a9t=s(o2e);pdr=r(a9t,"__init__()"),a9t.forEach(t),udr=r(LVe," (throws an error)."),LVe.forEach(t),_dr=i(ul),wt=n(ul,"DIV",{class:!0});var K0=s(wt);T(xL.$$.fragment,K0),bdr=i(K0),r2e=n(K0,"P",{});var n9t=s(r2e);vdr=r(n9t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),n9t.forEach(t),Fdr=i(K0),qd=n(K0,"P",{});var Foe=s(qd);Tdr=r(Foe,`Note:
Loading a model from its configuration file does `),t2e=n(Foe,"STRONG",{});var s9t=s(t2e);Mdr=r(s9t,"not"),s9t.forEach(t),Edr=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(Foe,"A",{href:!0});var l9t=s(YW);Cdr=r(l9t,"from_pretrained()"),l9t.forEach(t),wdr=r(Foe," to load the model weights."),Foe.forEach(t),Adr=i(K0),T(oT.$$.fragment,K0),K0.forEach(t),ydr=i(ul),uo=n(ul,"DIV",{class:!0});var Ea=s(uo);T($L.$$.fragment,Ea),Ldr=i(Ea),a2e=n(Ea,"P",{});var i9t=s(a2e);xdr=r(i9t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),i9t.forEach(t),$dr=i(Ea),Ya=n(Ea,"P",{});var Z0=s(Ya);kdr=r(Z0,"The model class to instantiate is selected based on the "),n2e=n(Z0,"CODE",{});var d9t=s(n2e);Sdr=r(d9t,"model_type"),d9t.forEach(t),Rdr=r(Z0,` property of the config object (either
passed as an argument or loaded from `),s2e=n(Z0,"CODE",{});var c9t=s(s2e);Pdr=r(c9t,"pretrained_model_name_or_path"),c9t.forEach(t),Bdr=r(Z0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l2e=n(Z0,"CODE",{});var f9t=s(l2e);Idr=r(f9t,"pretrained_model_name_or_path"),f9t.forEach(t),Ndr=r(Z0,":"),Z0.forEach(t),qdr=i(Ea),jd=n(Ea,"UL",{});var Toe=s(jd);rT=n(Toe,"LI",{});var FPe=s(rT);i2e=n(FPe,"STRONG",{});var m9t=s(i2e);jdr=r(m9t,"deit"),m9t.forEach(t),Ddr=r(FPe," \u2014 "),KW=n(FPe,"A",{href:!0});var g9t=s(KW);Gdr=r(g9t,"DeiTForMaskedImageModeling"),g9t.forEach(t),Odr=r(FPe," (DeiT model)"),FPe.forEach(t),Vdr=i(Toe),tT=n(Toe,"LI",{});var TPe=s(tT);d2e=n(TPe,"STRONG",{});var h9t=s(d2e);Xdr=r(h9t,"swin"),h9t.forEach(t),zdr=r(TPe," \u2014 "),ZW=n(TPe,"A",{href:!0});var p9t=s(ZW);Wdr=r(p9t,"SwinForMaskedImageModeling"),p9t.forEach(t),Qdr=r(TPe," (Swin Transformer model)"),TPe.forEach(t),Hdr=i(Toe),aT=n(Toe,"LI",{});var MPe=s(aT);c2e=n(MPe,"STRONG",{});var u9t=s(c2e);Udr=r(u9t,"vit"),u9t.forEach(t),Jdr=r(MPe," \u2014 "),eQ=n(MPe,"A",{href:!0});var _9t=s(eQ);Ydr=r(_9t,"ViTForMaskedImageModeling"),_9t.forEach(t),Kdr=r(MPe," (ViT model)"),MPe.forEach(t),Toe.forEach(t),Zdr=i(Ea),nT=n(Ea,"P",{});var EPe=s(nT);ecr=r(EPe,"The model is set in evaluation mode by default using "),f2e=n(EPe,"CODE",{});var b9t=s(f2e);ocr=r(b9t,"model.eval()"),b9t.forEach(t),rcr=r(EPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m2e=n(EPe,"CODE",{});var v9t=s(m2e);tcr=r(v9t,"model.train()"),v9t.forEach(t),EPe.forEach(t),acr=i(Ea),T(sT.$$.fragment,Ea),Ea.forEach(t),ul.forEach(t),MGe=i(f),Dd=n(f,"H2",{class:!0});var xVe=s(Dd);lT=n(xVe,"A",{id:!0,class:!0,href:!0});var F9t=s(lT);g2e=n(F9t,"SPAN",{});var T9t=s(g2e);T(kL.$$.fragment,T9t),T9t.forEach(t),F9t.forEach(t),ncr=i(xVe),h2e=n(xVe,"SPAN",{});var M9t=s(h2e);scr=r(M9t,"AutoModelForObjectDetection"),M9t.forEach(t),xVe.forEach(t),EGe=i(f),Uo=n(f,"DIV",{class:!0});var _l=s(Uo);T(SL.$$.fragment,_l),lcr=i(_l),Gd=n(_l,"P",{});var Moe=s(Gd);icr=r(Moe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),oQ=n(Moe,"A",{href:!0});var E9t=s(oQ);dcr=r(E9t,"from_pretrained()"),E9t.forEach(t),ccr=r(Moe," class method or the "),rQ=n(Moe,"A",{href:!0});var C9t=s(rQ);fcr=r(C9t,"from_config()"),C9t.forEach(t),mcr=r(Moe,` class
method.`),Moe.forEach(t),gcr=i(_l),RL=n(_l,"P",{});var $Ve=s(RL);hcr=r($Ve,"This class cannot be instantiated directly using "),p2e=n($Ve,"CODE",{});var w9t=s(p2e);pcr=r(w9t,"__init__()"),w9t.forEach(t),ucr=r($Ve," (throws an error)."),$Ve.forEach(t),_cr=i(_l),At=n(_l,"DIV",{class:!0});var ew=s(At);T(PL.$$.fragment,ew),bcr=i(ew),u2e=n(ew,"P",{});var A9t=s(u2e);vcr=r(A9t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),A9t.forEach(t),Fcr=i(ew),Od=n(ew,"P",{});var Eoe=s(Od);Tcr=r(Eoe,`Note:
Loading a model from its configuration file does `),_2e=n(Eoe,"STRONG",{});var y9t=s(_2e);Mcr=r(y9t,"not"),y9t.forEach(t),Ecr=r(Eoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tQ=n(Eoe,"A",{href:!0});var L9t=s(tQ);Ccr=r(L9t,"from_pretrained()"),L9t.forEach(t),wcr=r(Eoe," to load the model weights."),Eoe.forEach(t),Acr=i(ew),T(iT.$$.fragment,ew),ew.forEach(t),ycr=i(_l),_o=n(_l,"DIV",{class:!0});var Ca=s(_o);T(BL.$$.fragment,Ca),Lcr=i(Ca),b2e=n(Ca,"P",{});var x9t=s(b2e);xcr=r(x9t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),x9t.forEach(t),$cr=i(Ca),Ka=n(Ca,"P",{});var ow=s(Ka);kcr=r(ow,"The model class to instantiate is selected based on the "),v2e=n(ow,"CODE",{});var $9t=s(v2e);Scr=r($9t,"model_type"),$9t.forEach(t),Rcr=r(ow,` property of the config object (either
passed as an argument or loaded from `),F2e=n(ow,"CODE",{});var k9t=s(F2e);Pcr=r(k9t,"pretrained_model_name_or_path"),k9t.forEach(t),Bcr=r(ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T2e=n(ow,"CODE",{});var S9t=s(T2e);Icr=r(S9t,"pretrained_model_name_or_path"),S9t.forEach(t),Ncr=r(ow,":"),ow.forEach(t),qcr=i(Ca),IL=n(Ca,"UL",{});var kVe=s(IL);dT=n(kVe,"LI",{});var CPe=s(dT);M2e=n(CPe,"STRONG",{});var R9t=s(M2e);jcr=r(R9t,"detr"),R9t.forEach(t),Dcr=r(CPe," \u2014 "),aQ=n(CPe,"A",{href:!0});var P9t=s(aQ);Gcr=r(P9t,"DetrForObjectDetection"),P9t.forEach(t),Ocr=r(CPe," (DETR model)"),CPe.forEach(t),Vcr=i(kVe),cT=n(kVe,"LI",{});var wPe=s(cT);E2e=n(wPe,"STRONG",{});var B9t=s(E2e);Xcr=r(B9t,"yolos"),B9t.forEach(t),zcr=r(wPe," \u2014 "),nQ=n(wPe,"A",{href:!0});var I9t=s(nQ);Wcr=r(I9t,"YolosForObjectDetection"),I9t.forEach(t),Qcr=r(wPe," (YOLOS model)"),wPe.forEach(t),kVe.forEach(t),Hcr=i(Ca),fT=n(Ca,"P",{});var APe=s(fT);Ucr=r(APe,"The model is set in evaluation mode by default using "),C2e=n(APe,"CODE",{});var N9t=s(C2e);Jcr=r(N9t,"model.eval()"),N9t.forEach(t),Ycr=r(APe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w2e=n(APe,"CODE",{});var q9t=s(w2e);Kcr=r(q9t,"model.train()"),q9t.forEach(t),APe.forEach(t),Zcr=i(Ca),T(mT.$$.fragment,Ca),Ca.forEach(t),_l.forEach(t),CGe=i(f),Vd=n(f,"H2",{class:!0});var SVe=s(Vd);gT=n(SVe,"A",{id:!0,class:!0,href:!0});var j9t=s(gT);A2e=n(j9t,"SPAN",{});var D9t=s(A2e);T(NL.$$.fragment,D9t),D9t.forEach(t),j9t.forEach(t),efr=i(SVe),y2e=n(SVe,"SPAN",{});var G9t=s(y2e);ofr=r(G9t,"AutoModelForImageSegmentation"),G9t.forEach(t),SVe.forEach(t),wGe=i(f),Jo=n(f,"DIV",{class:!0});var bl=s(Jo);T(qL.$$.fragment,bl),rfr=i(bl),Xd=n(bl,"P",{});var Coe=s(Xd);tfr=r(Coe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),sQ=n(Coe,"A",{href:!0});var O9t=s(sQ);afr=r(O9t,"from_pretrained()"),O9t.forEach(t),nfr=r(Coe," class method or the "),lQ=n(Coe,"A",{href:!0});var V9t=s(lQ);sfr=r(V9t,"from_config()"),V9t.forEach(t),lfr=r(Coe,` class
method.`),Coe.forEach(t),ifr=i(bl),jL=n(bl,"P",{});var RVe=s(jL);dfr=r(RVe,"This class cannot be instantiated directly using "),L2e=n(RVe,"CODE",{});var X9t=s(L2e);cfr=r(X9t,"__init__()"),X9t.forEach(t),ffr=r(RVe," (throws an error)."),RVe.forEach(t),mfr=i(bl),yt=n(bl,"DIV",{class:!0});var rw=s(yt);T(DL.$$.fragment,rw),gfr=i(rw),x2e=n(rw,"P",{});var z9t=s(x2e);hfr=r(z9t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),z9t.forEach(t),pfr=i(rw),zd=n(rw,"P",{});var woe=s(zd);ufr=r(woe,`Note:
Loading a model from its configuration file does `),$2e=n(woe,"STRONG",{});var W9t=s($2e);_fr=r(W9t,"not"),W9t.forEach(t),bfr=r(woe,` load the model weights. It only affects the
model\u2019s configuration. Use `),iQ=n(woe,"A",{href:!0});var Q9t=s(iQ);vfr=r(Q9t,"from_pretrained()"),Q9t.forEach(t),Ffr=r(woe," to load the model weights."),woe.forEach(t),Tfr=i(rw),T(hT.$$.fragment,rw),rw.forEach(t),Mfr=i(bl),bo=n(bl,"DIV",{class:!0});var wa=s(bo);T(GL.$$.fragment,wa),Efr=i(wa),k2e=n(wa,"P",{});var H9t=s(k2e);Cfr=r(H9t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),H9t.forEach(t),wfr=i(wa),Za=n(wa,"P",{});var tw=s(Za);Afr=r(tw,"The model class to instantiate is selected based on the "),S2e=n(tw,"CODE",{});var U9t=s(S2e);yfr=r(U9t,"model_type"),U9t.forEach(t),Lfr=r(tw,` property of the config object (either
passed as an argument or loaded from `),R2e=n(tw,"CODE",{});var J9t=s(R2e);xfr=r(J9t,"pretrained_model_name_or_path"),J9t.forEach(t),$fr=r(tw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P2e=n(tw,"CODE",{});var Y9t=s(P2e);kfr=r(Y9t,"pretrained_model_name_or_path"),Y9t.forEach(t),Sfr=r(tw,":"),tw.forEach(t),Rfr=i(wa),B2e=n(wa,"UL",{});var K9t=s(B2e);pT=n(K9t,"LI",{});var yPe=s(pT);I2e=n(yPe,"STRONG",{});var Z9t=s(I2e);Pfr=r(Z9t,"detr"),Z9t.forEach(t),Bfr=r(yPe," \u2014 "),dQ=n(yPe,"A",{href:!0});var eMt=s(dQ);Ifr=r(eMt,"DetrForSegmentation"),eMt.forEach(t),Nfr=r(yPe," (DETR model)"),yPe.forEach(t),K9t.forEach(t),qfr=i(wa),uT=n(wa,"P",{});var LPe=s(uT);jfr=r(LPe,"The model is set in evaluation mode by default using "),N2e=n(LPe,"CODE",{});var oMt=s(N2e);Dfr=r(oMt,"model.eval()"),oMt.forEach(t),Gfr=r(LPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=n(LPe,"CODE",{});var rMt=s(q2e);Ofr=r(rMt,"model.train()"),rMt.forEach(t),LPe.forEach(t),Vfr=i(wa),T(_T.$$.fragment,wa),wa.forEach(t),bl.forEach(t),AGe=i(f),Wd=n(f,"H2",{class:!0});var PVe=s(Wd);bT=n(PVe,"A",{id:!0,class:!0,href:!0});var tMt=s(bT);j2e=n(tMt,"SPAN",{});var aMt=s(j2e);T(OL.$$.fragment,aMt),aMt.forEach(t),tMt.forEach(t),Xfr=i(PVe),D2e=n(PVe,"SPAN",{});var nMt=s(D2e);zfr=r(nMt,"AutoModelForSemanticSegmentation"),nMt.forEach(t),PVe.forEach(t),yGe=i(f),Yo=n(f,"DIV",{class:!0});var vl=s(Yo);T(VL.$$.fragment,vl),Wfr=i(vl),Qd=n(vl,"P",{});var Aoe=s(Qd);Qfr=r(Aoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),cQ=n(Aoe,"A",{href:!0});var sMt=s(cQ);Hfr=r(sMt,"from_pretrained()"),sMt.forEach(t),Ufr=r(Aoe," class method or the "),fQ=n(Aoe,"A",{href:!0});var lMt=s(fQ);Jfr=r(lMt,"from_config()"),lMt.forEach(t),Yfr=r(Aoe,` class
method.`),Aoe.forEach(t),Kfr=i(vl),XL=n(vl,"P",{});var BVe=s(XL);Zfr=r(BVe,"This class cannot be instantiated directly using "),G2e=n(BVe,"CODE",{});var iMt=s(G2e);emr=r(iMt,"__init__()"),iMt.forEach(t),omr=r(BVe," (throws an error)."),BVe.forEach(t),rmr=i(vl),Lt=n(vl,"DIV",{class:!0});var aw=s(Lt);T(zL.$$.fragment,aw),tmr=i(aw),O2e=n(aw,"P",{});var dMt=s(O2e);amr=r(dMt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),dMt.forEach(t),nmr=i(aw),Hd=n(aw,"P",{});var yoe=s(Hd);smr=r(yoe,`Note:
Loading a model from its configuration file does `),V2e=n(yoe,"STRONG",{});var cMt=s(V2e);lmr=r(cMt,"not"),cMt.forEach(t),imr=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),mQ=n(yoe,"A",{href:!0});var fMt=s(mQ);dmr=r(fMt,"from_pretrained()"),fMt.forEach(t),cmr=r(yoe," to load the model weights."),yoe.forEach(t),fmr=i(aw),T(vT.$$.fragment,aw),aw.forEach(t),mmr=i(vl),vo=n(vl,"DIV",{class:!0});var Aa=s(vo);T(WL.$$.fragment,Aa),gmr=i(Aa),X2e=n(Aa,"P",{});var mMt=s(X2e);hmr=r(mMt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),mMt.forEach(t),pmr=i(Aa),en=n(Aa,"P",{});var nw=s(en);umr=r(nw,"The model class to instantiate is selected based on the "),z2e=n(nw,"CODE",{});var gMt=s(z2e);_mr=r(gMt,"model_type"),gMt.forEach(t),bmr=r(nw,` property of the config object (either
passed as an argument or loaded from `),W2e=n(nw,"CODE",{});var hMt=s(W2e);vmr=r(hMt,"pretrained_model_name_or_path"),hMt.forEach(t),Fmr=r(nw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q2e=n(nw,"CODE",{});var pMt=s(Q2e);Tmr=r(pMt,"pretrained_model_name_or_path"),pMt.forEach(t),Mmr=r(nw,":"),nw.forEach(t),Emr=i(Aa),on=n(Aa,"UL",{});var sw=s(on);FT=n(sw,"LI",{});var xPe=s(FT);H2e=n(xPe,"STRONG",{});var uMt=s(H2e);Cmr=r(uMt,"beit"),uMt.forEach(t),wmr=r(xPe," \u2014 "),gQ=n(xPe,"A",{href:!0});var _Mt=s(gQ);Amr=r(_Mt,"BeitForSemanticSegmentation"),_Mt.forEach(t),ymr=r(xPe," (BEiT model)"),xPe.forEach(t),Lmr=i(sw),TT=n(sw,"LI",{});var $Pe=s(TT);U2e=n($Pe,"STRONG",{});var bMt=s(U2e);xmr=r(bMt,"data2vec-vision"),bMt.forEach(t),$mr=r($Pe," \u2014 "),hQ=n($Pe,"A",{href:!0});var vMt=s(hQ);kmr=r(vMt,"Data2VecVisionForSemanticSegmentation"),vMt.forEach(t),Smr=r($Pe," (Data2VecVision model)"),$Pe.forEach(t),Rmr=i(sw),MT=n(sw,"LI",{});var kPe=s(MT);J2e=n(kPe,"STRONG",{});var FMt=s(J2e);Pmr=r(FMt,"dpt"),FMt.forEach(t),Bmr=r(kPe," \u2014 "),pQ=n(kPe,"A",{href:!0});var TMt=s(pQ);Imr=r(TMt,"DPTForSemanticSegmentation"),TMt.forEach(t),Nmr=r(kPe," (DPT model)"),kPe.forEach(t),qmr=i(sw),ET=n(sw,"LI",{});var SPe=s(ET);Y2e=n(SPe,"STRONG",{});var MMt=s(Y2e);jmr=r(MMt,"segformer"),MMt.forEach(t),Dmr=r(SPe," \u2014 "),uQ=n(SPe,"A",{href:!0});var EMt=s(uQ);Gmr=r(EMt,"SegformerForSemanticSegmentation"),EMt.forEach(t),Omr=r(SPe," (SegFormer model)"),SPe.forEach(t),sw.forEach(t),Vmr=i(Aa),CT=n(Aa,"P",{});var RPe=s(CT);Xmr=r(RPe,"The model is set in evaluation mode by default using "),K2e=n(RPe,"CODE",{});var CMt=s(K2e);zmr=r(CMt,"model.eval()"),CMt.forEach(t),Wmr=r(RPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z2e=n(RPe,"CODE",{});var wMt=s(Z2e);Qmr=r(wMt,"model.train()"),wMt.forEach(t),RPe.forEach(t),Hmr=i(Aa),T(wT.$$.fragment,Aa),Aa.forEach(t),vl.forEach(t),LGe=i(f),Ud=n(f,"H2",{class:!0});var IVe=s(Ud);AT=n(IVe,"A",{id:!0,class:!0,href:!0});var AMt=s(AT);eve=n(AMt,"SPAN",{});var yMt=s(eve);T(QL.$$.fragment,yMt),yMt.forEach(t),AMt.forEach(t),Umr=i(IVe),ove=n(IVe,"SPAN",{});var LMt=s(ove);Jmr=r(LMt,"AutoModelForInstanceSegmentation"),LMt.forEach(t),IVe.forEach(t),xGe=i(f),Ko=n(f,"DIV",{class:!0});var Fl=s(Ko);T(HL.$$.fragment,Fl),Ymr=i(Fl),Jd=n(Fl,"P",{});var Loe=s(Jd);Kmr=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),_Q=n(Loe,"A",{href:!0});var xMt=s(_Q);Zmr=r(xMt,"from_pretrained()"),xMt.forEach(t),egr=r(Loe," class method or the "),bQ=n(Loe,"A",{href:!0});var $Mt=s(bQ);ogr=r($Mt,"from_config()"),$Mt.forEach(t),rgr=r(Loe,` class
method.`),Loe.forEach(t),tgr=i(Fl),UL=n(Fl,"P",{});var NVe=s(UL);agr=r(NVe,"This class cannot be instantiated directly using "),rve=n(NVe,"CODE",{});var kMt=s(rve);ngr=r(kMt,"__init__()"),kMt.forEach(t),sgr=r(NVe," (throws an error)."),NVe.forEach(t),lgr=i(Fl),xt=n(Fl,"DIV",{class:!0});var lw=s(xt);T(JL.$$.fragment,lw),igr=i(lw),tve=n(lw,"P",{});var SMt=s(tve);dgr=r(SMt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),SMt.forEach(t),cgr=i(lw),Yd=n(lw,"P",{});var xoe=s(Yd);fgr=r(xoe,`Note:
Loading a model from its configuration file does `),ave=n(xoe,"STRONG",{});var RMt=s(ave);mgr=r(RMt,"not"),RMt.forEach(t),ggr=r(xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),vQ=n(xoe,"A",{href:!0});var PMt=s(vQ);hgr=r(PMt,"from_pretrained()"),PMt.forEach(t),pgr=r(xoe," to load the model weights."),xoe.forEach(t),ugr=i(lw),T(yT.$$.fragment,lw),lw.forEach(t),_gr=i(Fl),Fo=n(Fl,"DIV",{class:!0});var ya=s(Fo);T(YL.$$.fragment,ya),bgr=i(ya),nve=n(ya,"P",{});var BMt=s(nve);vgr=r(BMt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),BMt.forEach(t),Fgr=i(ya),rn=n(ya,"P",{});var iw=s(rn);Tgr=r(iw,"The model class to instantiate is selected based on the "),sve=n(iw,"CODE",{});var IMt=s(sve);Mgr=r(IMt,"model_type"),IMt.forEach(t),Egr=r(iw,` property of the config object (either
passed as an argument or loaded from `),lve=n(iw,"CODE",{});var NMt=s(lve);Cgr=r(NMt,"pretrained_model_name_or_path"),NMt.forEach(t),wgr=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ive=n(iw,"CODE",{});var qMt=s(ive);Agr=r(qMt,"pretrained_model_name_or_path"),qMt.forEach(t),ygr=r(iw,":"),iw.forEach(t),Lgr=i(ya),dve=n(ya,"UL",{});var jMt=s(dve);LT=n(jMt,"LI",{});var PPe=s(LT);cve=n(PPe,"STRONG",{});var DMt=s(cve);xgr=r(DMt,"maskformer"),DMt.forEach(t),$gr=r(PPe," \u2014 "),FQ=n(PPe,"A",{href:!0});var GMt=s(FQ);kgr=r(GMt,"MaskFormerForInstanceSegmentation"),GMt.forEach(t),Sgr=r(PPe," (MaskFormer model)"),PPe.forEach(t),jMt.forEach(t),Rgr=i(ya),xT=n(ya,"P",{});var BPe=s(xT);Pgr=r(BPe,"The model is set in evaluation mode by default using "),fve=n(BPe,"CODE",{});var OMt=s(fve);Bgr=r(OMt,"model.eval()"),OMt.forEach(t),Igr=r(BPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mve=n(BPe,"CODE",{});var VMt=s(mve);Ngr=r(VMt,"model.train()"),VMt.forEach(t),BPe.forEach(t),qgr=i(ya),T($T.$$.fragment,ya),ya.forEach(t),Fl.forEach(t),$Ge=i(f),Kd=n(f,"H2",{class:!0});var qVe=s(Kd);kT=n(qVe,"A",{id:!0,class:!0,href:!0});var XMt=s(kT);gve=n(XMt,"SPAN",{});var zMt=s(gve);T(KL.$$.fragment,zMt),zMt.forEach(t),XMt.forEach(t),jgr=i(qVe),hve=n(qVe,"SPAN",{});var WMt=s(hve);Dgr=r(WMt,"TFAutoModel"),WMt.forEach(t),qVe.forEach(t),kGe=i(f),Zo=n(f,"DIV",{class:!0});var Tl=s(Zo);T(ZL.$$.fragment,Tl),Ggr=i(Tl),Zd=n(Tl,"P",{});var $oe=s(Zd);Ogr=r($oe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),TQ=n($oe,"A",{href:!0});var QMt=s(TQ);Vgr=r(QMt,"from_pretrained()"),QMt.forEach(t),Xgr=r($oe," class method or the "),MQ=n($oe,"A",{href:!0});var HMt=s(MQ);zgr=r(HMt,"from_config()"),HMt.forEach(t),Wgr=r($oe,` class
method.`),$oe.forEach(t),Qgr=i(Tl),e8=n(Tl,"P",{});var jVe=s(e8);Hgr=r(jVe,"This class cannot be instantiated directly using "),pve=n(jVe,"CODE",{});var UMt=s(pve);Ugr=r(UMt,"__init__()"),UMt.forEach(t),Jgr=r(jVe," (throws an error)."),jVe.forEach(t),Ygr=i(Tl),$t=n(Tl,"DIV",{class:!0});var dw=s($t);T(o8.$$.fragment,dw),Kgr=i(dw),uve=n(dw,"P",{});var JMt=s(uve);Zgr=r(JMt,"Instantiates one of the base model classes of the library from a configuration."),JMt.forEach(t),ehr=i(dw),ec=n(dw,"P",{});var koe=s(ec);ohr=r(koe,`Note:
Loading a model from its configuration file does `),_ve=n(koe,"STRONG",{});var YMt=s(_ve);rhr=r(YMt,"not"),YMt.forEach(t),thr=r(koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),EQ=n(koe,"A",{href:!0});var KMt=s(EQ);ahr=r(KMt,"from_pretrained()"),KMt.forEach(t),nhr=r(koe," to load the model weights."),koe.forEach(t),shr=i(dw),T(ST.$$.fragment,dw),dw.forEach(t),lhr=i(Tl),yr=n(Tl,"DIV",{class:!0});var Ml=s(yr);T(r8.$$.fragment,Ml),ihr=i(Ml),bve=n(Ml,"P",{});var ZMt=s(bve);dhr=r(ZMt,"Instantiate one of the base model classes of the library from a pretrained model."),ZMt.forEach(t),chr=i(Ml),tn=n(Ml,"P",{});var cw=s(tn);fhr=r(cw,"The model class to instantiate is selected based on the "),vve=n(cw,"CODE",{});var e4t=s(vve);mhr=r(e4t,"model_type"),e4t.forEach(t),ghr=r(cw,` property of the config object (either
passed as an argument or loaded from `),Fve=n(cw,"CODE",{});var o4t=s(Fve);hhr=r(o4t,"pretrained_model_name_or_path"),o4t.forEach(t),phr=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tve=n(cw,"CODE",{});var r4t=s(Tve);uhr=r(r4t,"pretrained_model_name_or_path"),r4t.forEach(t),_hr=r(cw,":"),cw.forEach(t),bhr=i(Ml),q=n(Ml,"UL",{});var D=s(q);RT=n(D,"LI",{});var IPe=s(RT);Mve=n(IPe,"STRONG",{});var t4t=s(Mve);vhr=r(t4t,"albert"),t4t.forEach(t),Fhr=r(IPe," \u2014 "),CQ=n(IPe,"A",{href:!0});var a4t=s(CQ);Thr=r(a4t,"TFAlbertModel"),a4t.forEach(t),Mhr=r(IPe," (ALBERT model)"),IPe.forEach(t),Ehr=i(D),PT=n(D,"LI",{});var NPe=s(PT);Eve=n(NPe,"STRONG",{});var n4t=s(Eve);Chr=r(n4t,"bart"),n4t.forEach(t),whr=r(NPe," \u2014 "),wQ=n(NPe,"A",{href:!0});var s4t=s(wQ);Ahr=r(s4t,"TFBartModel"),s4t.forEach(t),yhr=r(NPe," (BART model)"),NPe.forEach(t),Lhr=i(D),BT=n(D,"LI",{});var qPe=s(BT);Cve=n(qPe,"STRONG",{});var l4t=s(Cve);xhr=r(l4t,"bert"),l4t.forEach(t),$hr=r(qPe," \u2014 "),AQ=n(qPe,"A",{href:!0});var i4t=s(AQ);khr=r(i4t,"TFBertModel"),i4t.forEach(t),Shr=r(qPe," (BERT model)"),qPe.forEach(t),Rhr=i(D),IT=n(D,"LI",{});var jPe=s(IT);wve=n(jPe,"STRONG",{});var d4t=s(wve);Phr=r(d4t,"blenderbot"),d4t.forEach(t),Bhr=r(jPe," \u2014 "),yQ=n(jPe,"A",{href:!0});var c4t=s(yQ);Ihr=r(c4t,"TFBlenderbotModel"),c4t.forEach(t),Nhr=r(jPe," (Blenderbot model)"),jPe.forEach(t),qhr=i(D),NT=n(D,"LI",{});var DPe=s(NT);Ave=n(DPe,"STRONG",{});var f4t=s(Ave);jhr=r(f4t,"blenderbot-small"),f4t.forEach(t),Dhr=r(DPe," \u2014 "),LQ=n(DPe,"A",{href:!0});var m4t=s(LQ);Ghr=r(m4t,"TFBlenderbotSmallModel"),m4t.forEach(t),Ohr=r(DPe," (BlenderbotSmall model)"),DPe.forEach(t),Vhr=i(D),qT=n(D,"LI",{});var GPe=s(qT);yve=n(GPe,"STRONG",{});var g4t=s(yve);Xhr=r(g4t,"camembert"),g4t.forEach(t),zhr=r(GPe," \u2014 "),xQ=n(GPe,"A",{href:!0});var h4t=s(xQ);Whr=r(h4t,"TFCamembertModel"),h4t.forEach(t),Qhr=r(GPe," (CamemBERT model)"),GPe.forEach(t),Hhr=i(D),jT=n(D,"LI",{});var OPe=s(jT);Lve=n(OPe,"STRONG",{});var p4t=s(Lve);Uhr=r(p4t,"clip"),p4t.forEach(t),Jhr=r(OPe," \u2014 "),$Q=n(OPe,"A",{href:!0});var u4t=s($Q);Yhr=r(u4t,"TFCLIPModel"),u4t.forEach(t),Khr=r(OPe," (CLIP model)"),OPe.forEach(t),Zhr=i(D),DT=n(D,"LI",{});var VPe=s(DT);xve=n(VPe,"STRONG",{});var _4t=s(xve);epr=r(_4t,"convbert"),_4t.forEach(t),opr=r(VPe," \u2014 "),kQ=n(VPe,"A",{href:!0});var b4t=s(kQ);rpr=r(b4t,"TFConvBertModel"),b4t.forEach(t),tpr=r(VPe," (ConvBERT model)"),VPe.forEach(t),apr=i(D),GT=n(D,"LI",{});var XPe=s(GT);$ve=n(XPe,"STRONG",{});var v4t=s($ve);npr=r(v4t,"convnext"),v4t.forEach(t),spr=r(XPe," \u2014 "),SQ=n(XPe,"A",{href:!0});var F4t=s(SQ);lpr=r(F4t,"TFConvNextModel"),F4t.forEach(t),ipr=r(XPe," (ConvNeXT model)"),XPe.forEach(t),dpr=i(D),OT=n(D,"LI",{});var zPe=s(OT);kve=n(zPe,"STRONG",{});var T4t=s(kve);cpr=r(T4t,"ctrl"),T4t.forEach(t),fpr=r(zPe," \u2014 "),RQ=n(zPe,"A",{href:!0});var M4t=s(RQ);mpr=r(M4t,"TFCTRLModel"),M4t.forEach(t),gpr=r(zPe," (CTRL model)"),zPe.forEach(t),hpr=i(D),VT=n(D,"LI",{});var WPe=s(VT);Sve=n(WPe,"STRONG",{});var E4t=s(Sve);ppr=r(E4t,"data2vec-vision"),E4t.forEach(t),upr=r(WPe," \u2014 "),PQ=n(WPe,"A",{href:!0});var C4t=s(PQ);_pr=r(C4t,"TFData2VecVisionModel"),C4t.forEach(t),bpr=r(WPe," (Data2VecVision model)"),WPe.forEach(t),vpr=i(D),XT=n(D,"LI",{});var QPe=s(XT);Rve=n(QPe,"STRONG",{});var w4t=s(Rve);Fpr=r(w4t,"deberta"),w4t.forEach(t),Tpr=r(QPe," \u2014 "),BQ=n(QPe,"A",{href:!0});var A4t=s(BQ);Mpr=r(A4t,"TFDebertaModel"),A4t.forEach(t),Epr=r(QPe," (DeBERTa model)"),QPe.forEach(t),Cpr=i(D),zT=n(D,"LI",{});var HPe=s(zT);Pve=n(HPe,"STRONG",{});var y4t=s(Pve);wpr=r(y4t,"deberta-v2"),y4t.forEach(t),Apr=r(HPe," \u2014 "),IQ=n(HPe,"A",{href:!0});var L4t=s(IQ);ypr=r(L4t,"TFDebertaV2Model"),L4t.forEach(t),Lpr=r(HPe," (DeBERTa-v2 model)"),HPe.forEach(t),xpr=i(D),WT=n(D,"LI",{});var UPe=s(WT);Bve=n(UPe,"STRONG",{});var x4t=s(Bve);$pr=r(x4t,"distilbert"),x4t.forEach(t),kpr=r(UPe," \u2014 "),NQ=n(UPe,"A",{href:!0});var $4t=s(NQ);Spr=r($4t,"TFDistilBertModel"),$4t.forEach(t),Rpr=r(UPe," (DistilBERT model)"),UPe.forEach(t),Ppr=i(D),QT=n(D,"LI",{});var JPe=s(QT);Ive=n(JPe,"STRONG",{});var k4t=s(Ive);Bpr=r(k4t,"dpr"),k4t.forEach(t),Ipr=r(JPe," \u2014 "),qQ=n(JPe,"A",{href:!0});var S4t=s(qQ);Npr=r(S4t,"TFDPRQuestionEncoder"),S4t.forEach(t),qpr=r(JPe," (DPR model)"),JPe.forEach(t),jpr=i(D),HT=n(D,"LI",{});var YPe=s(HT);Nve=n(YPe,"STRONG",{});var R4t=s(Nve);Dpr=r(R4t,"electra"),R4t.forEach(t),Gpr=r(YPe," \u2014 "),jQ=n(YPe,"A",{href:!0});var P4t=s(jQ);Opr=r(P4t,"TFElectraModel"),P4t.forEach(t),Vpr=r(YPe," (ELECTRA model)"),YPe.forEach(t),Xpr=i(D),UT=n(D,"LI",{});var KPe=s(UT);qve=n(KPe,"STRONG",{});var B4t=s(qve);zpr=r(B4t,"flaubert"),B4t.forEach(t),Wpr=r(KPe," \u2014 "),DQ=n(KPe,"A",{href:!0});var I4t=s(DQ);Qpr=r(I4t,"TFFlaubertModel"),I4t.forEach(t),Hpr=r(KPe," (FlauBERT model)"),KPe.forEach(t),Upr=i(D),Vs=n(D,"LI",{});var Ik=s(Vs);jve=n(Ik,"STRONG",{});var N4t=s(jve);Jpr=r(N4t,"funnel"),N4t.forEach(t),Ypr=r(Ik," \u2014 "),GQ=n(Ik,"A",{href:!0});var q4t=s(GQ);Kpr=r(q4t,"TFFunnelModel"),q4t.forEach(t),Zpr=r(Ik," or "),OQ=n(Ik,"A",{href:!0});var j4t=s(OQ);eur=r(j4t,"TFFunnelBaseModel"),j4t.forEach(t),our=r(Ik," (Funnel Transformer model)"),Ik.forEach(t),rur=i(D),JT=n(D,"LI",{});var ZPe=s(JT);Dve=n(ZPe,"STRONG",{});var D4t=s(Dve);tur=r(D4t,"gpt2"),D4t.forEach(t),aur=r(ZPe," \u2014 "),VQ=n(ZPe,"A",{href:!0});var G4t=s(VQ);nur=r(G4t,"TFGPT2Model"),G4t.forEach(t),sur=r(ZPe," (OpenAI GPT-2 model)"),ZPe.forEach(t),lur=i(D),YT=n(D,"LI",{});var eBe=s(YT);Gve=n(eBe,"STRONG",{});var O4t=s(Gve);iur=r(O4t,"gptj"),O4t.forEach(t),dur=r(eBe," \u2014 "),XQ=n(eBe,"A",{href:!0});var V4t=s(XQ);cur=r(V4t,"TFGPTJModel"),V4t.forEach(t),fur=r(eBe," (GPT-J model)"),eBe.forEach(t),mur=i(D),KT=n(D,"LI",{});var oBe=s(KT);Ove=n(oBe,"STRONG",{});var X4t=s(Ove);gur=r(X4t,"hubert"),X4t.forEach(t),hur=r(oBe," \u2014 "),zQ=n(oBe,"A",{href:!0});var z4t=s(zQ);pur=r(z4t,"TFHubertModel"),z4t.forEach(t),uur=r(oBe," (Hubert model)"),oBe.forEach(t),_ur=i(D),ZT=n(D,"LI",{});var rBe=s(ZT);Vve=n(rBe,"STRONG",{});var W4t=s(Vve);bur=r(W4t,"layoutlm"),W4t.forEach(t),vur=r(rBe," \u2014 "),WQ=n(rBe,"A",{href:!0});var Q4t=s(WQ);Fur=r(Q4t,"TFLayoutLMModel"),Q4t.forEach(t),Tur=r(rBe," (LayoutLM model)"),rBe.forEach(t),Mur=i(D),e7=n(D,"LI",{});var tBe=s(e7);Xve=n(tBe,"STRONG",{});var H4t=s(Xve);Eur=r(H4t,"led"),H4t.forEach(t),Cur=r(tBe," \u2014 "),QQ=n(tBe,"A",{href:!0});var U4t=s(QQ);wur=r(U4t,"TFLEDModel"),U4t.forEach(t),Aur=r(tBe," (LED model)"),tBe.forEach(t),yur=i(D),o7=n(D,"LI",{});var aBe=s(o7);zve=n(aBe,"STRONG",{});var J4t=s(zve);Lur=r(J4t,"longformer"),J4t.forEach(t),xur=r(aBe," \u2014 "),HQ=n(aBe,"A",{href:!0});var Y4t=s(HQ);$ur=r(Y4t,"TFLongformerModel"),Y4t.forEach(t),kur=r(aBe," (Longformer model)"),aBe.forEach(t),Sur=i(D),r7=n(D,"LI",{});var nBe=s(r7);Wve=n(nBe,"STRONG",{});var K4t=s(Wve);Rur=r(K4t,"lxmert"),K4t.forEach(t),Pur=r(nBe," \u2014 "),UQ=n(nBe,"A",{href:!0});var Z4t=s(UQ);Bur=r(Z4t,"TFLxmertModel"),Z4t.forEach(t),Iur=r(nBe," (LXMERT model)"),nBe.forEach(t),Nur=i(D),t7=n(D,"LI",{});var sBe=s(t7);Qve=n(sBe,"STRONG",{});var eEt=s(Qve);qur=r(eEt,"marian"),eEt.forEach(t),jur=r(sBe," \u2014 "),JQ=n(sBe,"A",{href:!0});var oEt=s(JQ);Dur=r(oEt,"TFMarianModel"),oEt.forEach(t),Gur=r(sBe," (Marian model)"),sBe.forEach(t),Our=i(D),a7=n(D,"LI",{});var lBe=s(a7);Hve=n(lBe,"STRONG",{});var rEt=s(Hve);Vur=r(rEt,"mbart"),rEt.forEach(t),Xur=r(lBe," \u2014 "),YQ=n(lBe,"A",{href:!0});var tEt=s(YQ);zur=r(tEt,"TFMBartModel"),tEt.forEach(t),Wur=r(lBe," (mBART model)"),lBe.forEach(t),Qur=i(D),n7=n(D,"LI",{});var iBe=s(n7);Uve=n(iBe,"STRONG",{});var aEt=s(Uve);Hur=r(aEt,"mobilebert"),aEt.forEach(t),Uur=r(iBe," \u2014 "),KQ=n(iBe,"A",{href:!0});var nEt=s(KQ);Jur=r(nEt,"TFMobileBertModel"),nEt.forEach(t),Yur=r(iBe," (MobileBERT model)"),iBe.forEach(t),Kur=i(D),s7=n(D,"LI",{});var dBe=s(s7);Jve=n(dBe,"STRONG",{});var sEt=s(Jve);Zur=r(sEt,"mpnet"),sEt.forEach(t),e_r=r(dBe," \u2014 "),ZQ=n(dBe,"A",{href:!0});var lEt=s(ZQ);o_r=r(lEt,"TFMPNetModel"),lEt.forEach(t),r_r=r(dBe," (MPNet model)"),dBe.forEach(t),t_r=i(D),l7=n(D,"LI",{});var cBe=s(l7);Yve=n(cBe,"STRONG",{});var iEt=s(Yve);a_r=r(iEt,"mt5"),iEt.forEach(t),n_r=r(cBe," \u2014 "),eH=n(cBe,"A",{href:!0});var dEt=s(eH);s_r=r(dEt,"TFMT5Model"),dEt.forEach(t),l_r=r(cBe," (MT5 model)"),cBe.forEach(t),i_r=i(D),i7=n(D,"LI",{});var fBe=s(i7);Kve=n(fBe,"STRONG",{});var cEt=s(Kve);d_r=r(cEt,"openai-gpt"),cEt.forEach(t),c_r=r(fBe," \u2014 "),oH=n(fBe,"A",{href:!0});var fEt=s(oH);f_r=r(fEt,"TFOpenAIGPTModel"),fEt.forEach(t),m_r=r(fBe," (OpenAI GPT model)"),fBe.forEach(t),g_r=i(D),d7=n(D,"LI",{});var mBe=s(d7);Zve=n(mBe,"STRONG",{});var mEt=s(Zve);h_r=r(mEt,"opt"),mEt.forEach(t),p_r=r(mBe," \u2014 "),rH=n(mBe,"A",{href:!0});var gEt=s(rH);u_r=r(gEt,"TFOPTModel"),gEt.forEach(t),__r=r(mBe," (OPT model)"),mBe.forEach(t),b_r=i(D),c7=n(D,"LI",{});var gBe=s(c7);e3e=n(gBe,"STRONG",{});var hEt=s(e3e);v_r=r(hEt,"pegasus"),hEt.forEach(t),F_r=r(gBe," \u2014 "),tH=n(gBe,"A",{href:!0});var pEt=s(tH);T_r=r(pEt,"TFPegasusModel"),pEt.forEach(t),M_r=r(gBe," (Pegasus model)"),gBe.forEach(t),E_r=i(D),f7=n(D,"LI",{});var hBe=s(f7);o3e=n(hBe,"STRONG",{});var uEt=s(o3e);C_r=r(uEt,"rembert"),uEt.forEach(t),w_r=r(hBe," \u2014 "),aH=n(hBe,"A",{href:!0});var _Et=s(aH);A_r=r(_Et,"TFRemBertModel"),_Et.forEach(t),y_r=r(hBe," (RemBERT model)"),hBe.forEach(t),L_r=i(D),m7=n(D,"LI",{});var pBe=s(m7);r3e=n(pBe,"STRONG",{});var bEt=s(r3e);x_r=r(bEt,"roberta"),bEt.forEach(t),$_r=r(pBe," \u2014 "),nH=n(pBe,"A",{href:!0});var vEt=s(nH);k_r=r(vEt,"TFRobertaModel"),vEt.forEach(t),S_r=r(pBe," (RoBERTa model)"),pBe.forEach(t),R_r=i(D),g7=n(D,"LI",{});var uBe=s(g7);t3e=n(uBe,"STRONG",{});var FEt=s(t3e);P_r=r(FEt,"roformer"),FEt.forEach(t),B_r=r(uBe," \u2014 "),sH=n(uBe,"A",{href:!0});var TEt=s(sH);I_r=r(TEt,"TFRoFormerModel"),TEt.forEach(t),N_r=r(uBe," (RoFormer model)"),uBe.forEach(t),q_r=i(D),h7=n(D,"LI",{});var _Be=s(h7);a3e=n(_Be,"STRONG",{});var MEt=s(a3e);j_r=r(MEt,"speech_to_text"),MEt.forEach(t),D_r=r(_Be," \u2014 "),lH=n(_Be,"A",{href:!0});var EEt=s(lH);G_r=r(EEt,"TFSpeech2TextModel"),EEt.forEach(t),O_r=r(_Be," (Speech2Text model)"),_Be.forEach(t),V_r=i(D),p7=n(D,"LI",{});var bBe=s(p7);n3e=n(bBe,"STRONG",{});var CEt=s(n3e);X_r=r(CEt,"swin"),CEt.forEach(t),z_r=r(bBe," \u2014 "),iH=n(bBe,"A",{href:!0});var wEt=s(iH);W_r=r(wEt,"TFSwinModel"),wEt.forEach(t),Q_r=r(bBe," (Swin Transformer model)"),bBe.forEach(t),H_r=i(D),u7=n(D,"LI",{});var vBe=s(u7);s3e=n(vBe,"STRONG",{});var AEt=s(s3e);U_r=r(AEt,"t5"),AEt.forEach(t),J_r=r(vBe," \u2014 "),dH=n(vBe,"A",{href:!0});var yEt=s(dH);Y_r=r(yEt,"TFT5Model"),yEt.forEach(t),K_r=r(vBe," (T5 model)"),vBe.forEach(t),Z_r=i(D),_7=n(D,"LI",{});var FBe=s(_7);l3e=n(FBe,"STRONG",{});var LEt=s(l3e);e1r=r(LEt,"tapas"),LEt.forEach(t),o1r=r(FBe," \u2014 "),cH=n(FBe,"A",{href:!0});var xEt=s(cH);r1r=r(xEt,"TFTapasModel"),xEt.forEach(t),t1r=r(FBe," (TAPAS model)"),FBe.forEach(t),a1r=i(D),b7=n(D,"LI",{});var TBe=s(b7);i3e=n(TBe,"STRONG",{});var $Et=s(i3e);n1r=r($Et,"transfo-xl"),$Et.forEach(t),s1r=r(TBe," \u2014 "),fH=n(TBe,"A",{href:!0});var kEt=s(fH);l1r=r(kEt,"TFTransfoXLModel"),kEt.forEach(t),i1r=r(TBe," (Transformer-XL model)"),TBe.forEach(t),d1r=i(D),v7=n(D,"LI",{});var MBe=s(v7);d3e=n(MBe,"STRONG",{});var SEt=s(d3e);c1r=r(SEt,"vit"),SEt.forEach(t),f1r=r(MBe," \u2014 "),mH=n(MBe,"A",{href:!0});var REt=s(mH);m1r=r(REt,"TFViTModel"),REt.forEach(t),g1r=r(MBe," (ViT model)"),MBe.forEach(t),h1r=i(D),F7=n(D,"LI",{});var EBe=s(F7);c3e=n(EBe,"STRONG",{});var PEt=s(c3e);p1r=r(PEt,"vit_mae"),PEt.forEach(t),u1r=r(EBe," \u2014 "),gH=n(EBe,"A",{href:!0});var BEt=s(gH);_1r=r(BEt,"TFViTMAEModel"),BEt.forEach(t),b1r=r(EBe," (ViTMAE model)"),EBe.forEach(t),v1r=i(D),T7=n(D,"LI",{});var CBe=s(T7);f3e=n(CBe,"STRONG",{});var IEt=s(f3e);F1r=r(IEt,"wav2vec2"),IEt.forEach(t),T1r=r(CBe," \u2014 "),hH=n(CBe,"A",{href:!0});var NEt=s(hH);M1r=r(NEt,"TFWav2Vec2Model"),NEt.forEach(t),E1r=r(CBe," (Wav2Vec2 model)"),CBe.forEach(t),C1r=i(D),M7=n(D,"LI",{});var wBe=s(M7);m3e=n(wBe,"STRONG",{});var qEt=s(m3e);w1r=r(qEt,"xlm"),qEt.forEach(t),A1r=r(wBe," \u2014 "),pH=n(wBe,"A",{href:!0});var jEt=s(pH);y1r=r(jEt,"TFXLMModel"),jEt.forEach(t),L1r=r(wBe," (XLM model)"),wBe.forEach(t),x1r=i(D),E7=n(D,"LI",{});var ABe=s(E7);g3e=n(ABe,"STRONG",{});var DEt=s(g3e);$1r=r(DEt,"xlm-roberta"),DEt.forEach(t),k1r=r(ABe," \u2014 "),uH=n(ABe,"A",{href:!0});var GEt=s(uH);S1r=r(GEt,"TFXLMRobertaModel"),GEt.forEach(t),R1r=r(ABe," (XLM-RoBERTa model)"),ABe.forEach(t),P1r=i(D),C7=n(D,"LI",{});var yBe=s(C7);h3e=n(yBe,"STRONG",{});var OEt=s(h3e);B1r=r(OEt,"xlnet"),OEt.forEach(t),I1r=r(yBe," \u2014 "),_H=n(yBe,"A",{href:!0});var VEt=s(_H);N1r=r(VEt,"TFXLNetModel"),VEt.forEach(t),q1r=r(yBe," (XLNet model)"),yBe.forEach(t),D.forEach(t),j1r=i(Ml),T(w7.$$.fragment,Ml),Ml.forEach(t),Tl.forEach(t),SGe=i(f),oc=n(f,"H2",{class:!0});var DVe=s(oc);A7=n(DVe,"A",{id:!0,class:!0,href:!0});var XEt=s(A7);p3e=n(XEt,"SPAN",{});var zEt=s(p3e);T(t8.$$.fragment,zEt),zEt.forEach(t),XEt.forEach(t),D1r=i(DVe),u3e=n(DVe,"SPAN",{});var WEt=s(u3e);G1r=r(WEt,"TFAutoModelForPreTraining"),WEt.forEach(t),DVe.forEach(t),RGe=i(f),er=n(f,"DIV",{class:!0});var El=s(er);T(a8.$$.fragment,El),O1r=i(El),rc=n(El,"P",{});var Soe=s(rc);V1r=r(Soe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),bH=n(Soe,"A",{href:!0});var QEt=s(bH);X1r=r(QEt,"from_pretrained()"),QEt.forEach(t),z1r=r(Soe," class method or the "),vH=n(Soe,"A",{href:!0});var HEt=s(vH);W1r=r(HEt,"from_config()"),HEt.forEach(t),Q1r=r(Soe,` class
method.`),Soe.forEach(t),H1r=i(El),n8=n(El,"P",{});var GVe=s(n8);U1r=r(GVe,"This class cannot be instantiated directly using "),_3e=n(GVe,"CODE",{});var UEt=s(_3e);J1r=r(UEt,"__init__()"),UEt.forEach(t),Y1r=r(GVe," (throws an error)."),GVe.forEach(t),K1r=i(El),kt=n(El,"DIV",{class:!0});var fw=s(kt);T(s8.$$.fragment,fw),Z1r=i(fw),b3e=n(fw,"P",{});var JEt=s(b3e);ebr=r(JEt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),JEt.forEach(t),obr=i(fw),tc=n(fw,"P",{});var Roe=s(tc);rbr=r(Roe,`Note:
Loading a model from its configuration file does `),v3e=n(Roe,"STRONG",{});var YEt=s(v3e);tbr=r(YEt,"not"),YEt.forEach(t),abr=r(Roe,` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=n(Roe,"A",{href:!0});var KEt=s(FH);nbr=r(KEt,"from_pretrained()"),KEt.forEach(t),sbr=r(Roe," to load the model weights."),Roe.forEach(t),lbr=i(fw),T(y7.$$.fragment,fw),fw.forEach(t),ibr=i(El),Lr=n(El,"DIV",{class:!0});var Cl=s(Lr);T(l8.$$.fragment,Cl),dbr=i(Cl),F3e=n(Cl,"P",{});var ZEt=s(F3e);cbr=r(ZEt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZEt.forEach(t),fbr=i(Cl),an=n(Cl,"P",{});var mw=s(an);mbr=r(mw,"The model class to instantiate is selected based on the "),T3e=n(mw,"CODE",{});var eCt=s(T3e);gbr=r(eCt,"model_type"),eCt.forEach(t),hbr=r(mw,` property of the config object (either
passed as an argument or loaded from `),M3e=n(mw,"CODE",{});var oCt=s(M3e);pbr=r(oCt,"pretrained_model_name_or_path"),oCt.forEach(t),ubr=r(mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E3e=n(mw,"CODE",{});var rCt=s(E3e);_br=r(rCt,"pretrained_model_name_or_path"),rCt.forEach(t),bbr=r(mw,":"),mw.forEach(t),vbr=i(Cl),se=n(Cl,"UL",{});var le=s(se);L7=n(le,"LI",{});var LBe=s(L7);C3e=n(LBe,"STRONG",{});var tCt=s(C3e);Fbr=r(tCt,"albert"),tCt.forEach(t),Tbr=r(LBe," \u2014 "),TH=n(LBe,"A",{href:!0});var aCt=s(TH);Mbr=r(aCt,"TFAlbertForPreTraining"),aCt.forEach(t),Ebr=r(LBe," (ALBERT model)"),LBe.forEach(t),Cbr=i(le),x7=n(le,"LI",{});var xBe=s(x7);w3e=n(xBe,"STRONG",{});var nCt=s(w3e);wbr=r(nCt,"bart"),nCt.forEach(t),Abr=r(xBe," \u2014 "),MH=n(xBe,"A",{href:!0});var sCt=s(MH);ybr=r(sCt,"TFBartForConditionalGeneration"),sCt.forEach(t),Lbr=r(xBe," (BART model)"),xBe.forEach(t),xbr=i(le),$7=n(le,"LI",{});var $Be=s($7);A3e=n($Be,"STRONG",{});var lCt=s(A3e);$br=r(lCt,"bert"),lCt.forEach(t),kbr=r($Be," \u2014 "),EH=n($Be,"A",{href:!0});var iCt=s(EH);Sbr=r(iCt,"TFBertForPreTraining"),iCt.forEach(t),Rbr=r($Be," (BERT model)"),$Be.forEach(t),Pbr=i(le),k7=n(le,"LI",{});var kBe=s(k7);y3e=n(kBe,"STRONG",{});var dCt=s(y3e);Bbr=r(dCt,"camembert"),dCt.forEach(t),Ibr=r(kBe," \u2014 "),CH=n(kBe,"A",{href:!0});var cCt=s(CH);Nbr=r(cCt,"TFCamembertForMaskedLM"),cCt.forEach(t),qbr=r(kBe," (CamemBERT model)"),kBe.forEach(t),jbr=i(le),S7=n(le,"LI",{});var SBe=s(S7);L3e=n(SBe,"STRONG",{});var fCt=s(L3e);Dbr=r(fCt,"ctrl"),fCt.forEach(t),Gbr=r(SBe," \u2014 "),wH=n(SBe,"A",{href:!0});var mCt=s(wH);Obr=r(mCt,"TFCTRLLMHeadModel"),mCt.forEach(t),Vbr=r(SBe," (CTRL model)"),SBe.forEach(t),Xbr=i(le),R7=n(le,"LI",{});var RBe=s(R7);x3e=n(RBe,"STRONG",{});var gCt=s(x3e);zbr=r(gCt,"distilbert"),gCt.forEach(t),Wbr=r(RBe," \u2014 "),AH=n(RBe,"A",{href:!0});var hCt=s(AH);Qbr=r(hCt,"TFDistilBertForMaskedLM"),hCt.forEach(t),Hbr=r(RBe," (DistilBERT model)"),RBe.forEach(t),Ubr=i(le),P7=n(le,"LI",{});var PBe=s(P7);$3e=n(PBe,"STRONG",{});var pCt=s($3e);Jbr=r(pCt,"electra"),pCt.forEach(t),Ybr=r(PBe," \u2014 "),yH=n(PBe,"A",{href:!0});var uCt=s(yH);Kbr=r(uCt,"TFElectraForPreTraining"),uCt.forEach(t),Zbr=r(PBe," (ELECTRA model)"),PBe.forEach(t),e2r=i(le),B7=n(le,"LI",{});var BBe=s(B7);k3e=n(BBe,"STRONG",{});var _Ct=s(k3e);o2r=r(_Ct,"flaubert"),_Ct.forEach(t),r2r=r(BBe," \u2014 "),LH=n(BBe,"A",{href:!0});var bCt=s(LH);t2r=r(bCt,"TFFlaubertWithLMHeadModel"),bCt.forEach(t),a2r=r(BBe," (FlauBERT model)"),BBe.forEach(t),n2r=i(le),I7=n(le,"LI",{});var IBe=s(I7);S3e=n(IBe,"STRONG",{});var vCt=s(S3e);s2r=r(vCt,"funnel"),vCt.forEach(t),l2r=r(IBe," \u2014 "),xH=n(IBe,"A",{href:!0});var FCt=s(xH);i2r=r(FCt,"TFFunnelForPreTraining"),FCt.forEach(t),d2r=r(IBe," (Funnel Transformer model)"),IBe.forEach(t),c2r=i(le),N7=n(le,"LI",{});var NBe=s(N7);R3e=n(NBe,"STRONG",{});var TCt=s(R3e);f2r=r(TCt,"gpt2"),TCt.forEach(t),m2r=r(NBe," \u2014 "),$H=n(NBe,"A",{href:!0});var MCt=s($H);g2r=r(MCt,"TFGPT2LMHeadModel"),MCt.forEach(t),h2r=r(NBe," (OpenAI GPT-2 model)"),NBe.forEach(t),p2r=i(le),q7=n(le,"LI",{});var qBe=s(q7);P3e=n(qBe,"STRONG",{});var ECt=s(P3e);u2r=r(ECt,"layoutlm"),ECt.forEach(t),_2r=r(qBe," \u2014 "),kH=n(qBe,"A",{href:!0});var CCt=s(kH);b2r=r(CCt,"TFLayoutLMForMaskedLM"),CCt.forEach(t),v2r=r(qBe," (LayoutLM model)"),qBe.forEach(t),F2r=i(le),j7=n(le,"LI",{});var jBe=s(j7);B3e=n(jBe,"STRONG",{});var wCt=s(B3e);T2r=r(wCt,"lxmert"),wCt.forEach(t),M2r=r(jBe," \u2014 "),SH=n(jBe,"A",{href:!0});var ACt=s(SH);E2r=r(ACt,"TFLxmertForPreTraining"),ACt.forEach(t),C2r=r(jBe," (LXMERT model)"),jBe.forEach(t),w2r=i(le),D7=n(le,"LI",{});var DBe=s(D7);I3e=n(DBe,"STRONG",{});var yCt=s(I3e);A2r=r(yCt,"mobilebert"),yCt.forEach(t),y2r=r(DBe," \u2014 "),RH=n(DBe,"A",{href:!0});var LCt=s(RH);L2r=r(LCt,"TFMobileBertForPreTraining"),LCt.forEach(t),x2r=r(DBe," (MobileBERT model)"),DBe.forEach(t),$2r=i(le),G7=n(le,"LI",{});var GBe=s(G7);N3e=n(GBe,"STRONG",{});var xCt=s(N3e);k2r=r(xCt,"mpnet"),xCt.forEach(t),S2r=r(GBe," \u2014 "),PH=n(GBe,"A",{href:!0});var $Ct=s(PH);R2r=r($Ct,"TFMPNetForMaskedLM"),$Ct.forEach(t),P2r=r(GBe," (MPNet model)"),GBe.forEach(t),B2r=i(le),O7=n(le,"LI",{});var OBe=s(O7);q3e=n(OBe,"STRONG",{});var kCt=s(q3e);I2r=r(kCt,"openai-gpt"),kCt.forEach(t),N2r=r(OBe," \u2014 "),BH=n(OBe,"A",{href:!0});var SCt=s(BH);q2r=r(SCt,"TFOpenAIGPTLMHeadModel"),SCt.forEach(t),j2r=r(OBe," (OpenAI GPT model)"),OBe.forEach(t),D2r=i(le),V7=n(le,"LI",{});var VBe=s(V7);j3e=n(VBe,"STRONG",{});var RCt=s(j3e);G2r=r(RCt,"roberta"),RCt.forEach(t),O2r=r(VBe," \u2014 "),IH=n(VBe,"A",{href:!0});var PCt=s(IH);V2r=r(PCt,"TFRobertaForMaskedLM"),PCt.forEach(t),X2r=r(VBe," (RoBERTa model)"),VBe.forEach(t),z2r=i(le),X7=n(le,"LI",{});var XBe=s(X7);D3e=n(XBe,"STRONG",{});var BCt=s(D3e);W2r=r(BCt,"t5"),BCt.forEach(t),Q2r=r(XBe," \u2014 "),NH=n(XBe,"A",{href:!0});var ICt=s(NH);H2r=r(ICt,"TFT5ForConditionalGeneration"),ICt.forEach(t),U2r=r(XBe," (T5 model)"),XBe.forEach(t),J2r=i(le),z7=n(le,"LI",{});var zBe=s(z7);G3e=n(zBe,"STRONG",{});var NCt=s(G3e);Y2r=r(NCt,"tapas"),NCt.forEach(t),K2r=r(zBe," \u2014 "),qH=n(zBe,"A",{href:!0});var qCt=s(qH);Z2r=r(qCt,"TFTapasForMaskedLM"),qCt.forEach(t),evr=r(zBe," (TAPAS model)"),zBe.forEach(t),ovr=i(le),W7=n(le,"LI",{});var WBe=s(W7);O3e=n(WBe,"STRONG",{});var jCt=s(O3e);rvr=r(jCt,"transfo-xl"),jCt.forEach(t),tvr=r(WBe," \u2014 "),jH=n(WBe,"A",{href:!0});var DCt=s(jH);avr=r(DCt,"TFTransfoXLLMHeadModel"),DCt.forEach(t),nvr=r(WBe," (Transformer-XL model)"),WBe.forEach(t),svr=i(le),Q7=n(le,"LI",{});var QBe=s(Q7);V3e=n(QBe,"STRONG",{});var GCt=s(V3e);lvr=r(GCt,"vit_mae"),GCt.forEach(t),ivr=r(QBe," \u2014 "),DH=n(QBe,"A",{href:!0});var OCt=s(DH);dvr=r(OCt,"TFViTMAEForPreTraining"),OCt.forEach(t),cvr=r(QBe," (ViTMAE model)"),QBe.forEach(t),fvr=i(le),H7=n(le,"LI",{});var HBe=s(H7);X3e=n(HBe,"STRONG",{});var VCt=s(X3e);mvr=r(VCt,"xlm"),VCt.forEach(t),gvr=r(HBe," \u2014 "),GH=n(HBe,"A",{href:!0});var XCt=s(GH);hvr=r(XCt,"TFXLMWithLMHeadModel"),XCt.forEach(t),pvr=r(HBe," (XLM model)"),HBe.forEach(t),uvr=i(le),U7=n(le,"LI",{});var UBe=s(U7);z3e=n(UBe,"STRONG",{});var zCt=s(z3e);_vr=r(zCt,"xlm-roberta"),zCt.forEach(t),bvr=r(UBe," \u2014 "),OH=n(UBe,"A",{href:!0});var WCt=s(OH);vvr=r(WCt,"TFXLMRobertaForMaskedLM"),WCt.forEach(t),Fvr=r(UBe," (XLM-RoBERTa model)"),UBe.forEach(t),Tvr=i(le),J7=n(le,"LI",{});var JBe=s(J7);W3e=n(JBe,"STRONG",{});var QCt=s(W3e);Mvr=r(QCt,"xlnet"),QCt.forEach(t),Evr=r(JBe," \u2014 "),VH=n(JBe,"A",{href:!0});var HCt=s(VH);Cvr=r(HCt,"TFXLNetLMHeadModel"),HCt.forEach(t),wvr=r(JBe," (XLNet model)"),JBe.forEach(t),le.forEach(t),Avr=i(Cl),T(Y7.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),PGe=i(f),ac=n(f,"H2",{class:!0});var OVe=s(ac);K7=n(OVe,"A",{id:!0,class:!0,href:!0});var UCt=s(K7);Q3e=n(UCt,"SPAN",{});var JCt=s(Q3e);T(i8.$$.fragment,JCt),JCt.forEach(t),UCt.forEach(t),yvr=i(OVe),H3e=n(OVe,"SPAN",{});var YCt=s(H3e);Lvr=r(YCt,"TFAutoModelForCausalLM"),YCt.forEach(t),OVe.forEach(t),BGe=i(f),or=n(f,"DIV",{class:!0});var wl=s(or);T(d8.$$.fragment,wl),xvr=i(wl),nc=n(wl,"P",{});var Poe=s(nc);$vr=r(Poe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),XH=n(Poe,"A",{href:!0});var KCt=s(XH);kvr=r(KCt,"from_pretrained()"),KCt.forEach(t),Svr=r(Poe," class method or the "),zH=n(Poe,"A",{href:!0});var ZCt=s(zH);Rvr=r(ZCt,"from_config()"),ZCt.forEach(t),Pvr=r(Poe,` class
method.`),Poe.forEach(t),Bvr=i(wl),c8=n(wl,"P",{});var VVe=s(c8);Ivr=r(VVe,"This class cannot be instantiated directly using "),U3e=n(VVe,"CODE",{});var e5t=s(U3e);Nvr=r(e5t,"__init__()"),e5t.forEach(t),qvr=r(VVe," (throws an error)."),VVe.forEach(t),jvr=i(wl),St=n(wl,"DIV",{class:!0});var gw=s(St);T(f8.$$.fragment,gw),Dvr=i(gw),J3e=n(gw,"P",{});var o5t=s(J3e);Gvr=r(o5t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),o5t.forEach(t),Ovr=i(gw),sc=n(gw,"P",{});var Boe=s(sc);Vvr=r(Boe,`Note:
Loading a model from its configuration file does `),Y3e=n(Boe,"STRONG",{});var r5t=s(Y3e);Xvr=r(r5t,"not"),r5t.forEach(t),zvr=r(Boe,` load the model weights. It only affects the
model\u2019s configuration. Use `),WH=n(Boe,"A",{href:!0});var t5t=s(WH);Wvr=r(t5t,"from_pretrained()"),t5t.forEach(t),Qvr=r(Boe," to load the model weights."),Boe.forEach(t),Hvr=i(gw),T(Z7.$$.fragment,gw),gw.forEach(t),Uvr=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(m8.$$.fragment,Al),Jvr=i(Al),K3e=n(Al,"P",{});var a5t=s(K3e);Yvr=r(a5t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),a5t.forEach(t),Kvr=i(Al),nn=n(Al,"P",{});var hw=s(nn);Zvr=r(hw,"The model class to instantiate is selected based on the "),Z3e=n(hw,"CODE",{});var n5t=s(Z3e);e3r=r(n5t,"model_type"),n5t.forEach(t),o3r=r(hw,` property of the config object (either
passed as an argument or loaded from `),eFe=n(hw,"CODE",{});var s5t=s(eFe);r3r=r(s5t,"pretrained_model_name_or_path"),s5t.forEach(t),t3r=r(hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oFe=n(hw,"CODE",{});var l5t=s(oFe);a3r=r(l5t,"pretrained_model_name_or_path"),l5t.forEach(t),n3r=r(hw,":"),hw.forEach(t),s3r=i(Al),Me=n(Al,"UL",{});var Ce=s(Me);e9=n(Ce,"LI",{});var YBe=s(e9);rFe=n(YBe,"STRONG",{});var i5t=s(rFe);l3r=r(i5t,"bert"),i5t.forEach(t),i3r=r(YBe," \u2014 "),QH=n(YBe,"A",{href:!0});var d5t=s(QH);d3r=r(d5t,"TFBertLMHeadModel"),d5t.forEach(t),c3r=r(YBe," (BERT model)"),YBe.forEach(t),f3r=i(Ce),o9=n(Ce,"LI",{});var KBe=s(o9);tFe=n(KBe,"STRONG",{});var c5t=s(tFe);m3r=r(c5t,"camembert"),c5t.forEach(t),g3r=r(KBe," \u2014 "),HH=n(KBe,"A",{href:!0});var f5t=s(HH);h3r=r(f5t,"TFCamembertForCausalLM"),f5t.forEach(t),p3r=r(KBe," (CamemBERT model)"),KBe.forEach(t),u3r=i(Ce),r9=n(Ce,"LI",{});var ZBe=s(r9);aFe=n(ZBe,"STRONG",{});var m5t=s(aFe);_3r=r(m5t,"ctrl"),m5t.forEach(t),b3r=r(ZBe," \u2014 "),UH=n(ZBe,"A",{href:!0});var g5t=s(UH);v3r=r(g5t,"TFCTRLLMHeadModel"),g5t.forEach(t),F3r=r(ZBe," (CTRL model)"),ZBe.forEach(t),T3r=i(Ce),t9=n(Ce,"LI",{});var eIe=s(t9);nFe=n(eIe,"STRONG",{});var h5t=s(nFe);M3r=r(h5t,"gpt2"),h5t.forEach(t),E3r=r(eIe," \u2014 "),JH=n(eIe,"A",{href:!0});var p5t=s(JH);C3r=r(p5t,"TFGPT2LMHeadModel"),p5t.forEach(t),w3r=r(eIe," (OpenAI GPT-2 model)"),eIe.forEach(t),A3r=i(Ce),a9=n(Ce,"LI",{});var oIe=s(a9);sFe=n(oIe,"STRONG",{});var u5t=s(sFe);y3r=r(u5t,"gptj"),u5t.forEach(t),L3r=r(oIe," \u2014 "),YH=n(oIe,"A",{href:!0});var _5t=s(YH);x3r=r(_5t,"TFGPTJForCausalLM"),_5t.forEach(t),$3r=r(oIe," (GPT-J model)"),oIe.forEach(t),k3r=i(Ce),n9=n(Ce,"LI",{});var rIe=s(n9);lFe=n(rIe,"STRONG",{});var b5t=s(lFe);S3r=r(b5t,"openai-gpt"),b5t.forEach(t),R3r=r(rIe," \u2014 "),KH=n(rIe,"A",{href:!0});var v5t=s(KH);P3r=r(v5t,"TFOpenAIGPTLMHeadModel"),v5t.forEach(t),B3r=r(rIe," (OpenAI GPT model)"),rIe.forEach(t),I3r=i(Ce),s9=n(Ce,"LI",{});var tIe=s(s9);iFe=n(tIe,"STRONG",{});var F5t=s(iFe);N3r=r(F5t,"opt"),F5t.forEach(t),q3r=r(tIe," \u2014 "),ZH=n(tIe,"A",{href:!0});var T5t=s(ZH);j3r=r(T5t,"TFOPTForCausalLM"),T5t.forEach(t),D3r=r(tIe," (OPT model)"),tIe.forEach(t),G3r=i(Ce),l9=n(Ce,"LI",{});var aIe=s(l9);dFe=n(aIe,"STRONG",{});var M5t=s(dFe);O3r=r(M5t,"rembert"),M5t.forEach(t),V3r=r(aIe," \u2014 "),eU=n(aIe,"A",{href:!0});var E5t=s(eU);X3r=r(E5t,"TFRemBertForCausalLM"),E5t.forEach(t),z3r=r(aIe," (RemBERT model)"),aIe.forEach(t),W3r=i(Ce),i9=n(Ce,"LI",{});var nIe=s(i9);cFe=n(nIe,"STRONG",{});var C5t=s(cFe);Q3r=r(C5t,"roberta"),C5t.forEach(t),H3r=r(nIe," \u2014 "),oU=n(nIe,"A",{href:!0});var w5t=s(oU);U3r=r(w5t,"TFRobertaForCausalLM"),w5t.forEach(t),J3r=r(nIe," (RoBERTa model)"),nIe.forEach(t),Y3r=i(Ce),d9=n(Ce,"LI",{});var sIe=s(d9);fFe=n(sIe,"STRONG",{});var A5t=s(fFe);K3r=r(A5t,"roformer"),A5t.forEach(t),Z3r=r(sIe," \u2014 "),rU=n(sIe,"A",{href:!0});var y5t=s(rU);eFr=r(y5t,"TFRoFormerForCausalLM"),y5t.forEach(t),oFr=r(sIe," (RoFormer model)"),sIe.forEach(t),rFr=i(Ce),c9=n(Ce,"LI",{});var lIe=s(c9);mFe=n(lIe,"STRONG",{});var L5t=s(mFe);tFr=r(L5t,"transfo-xl"),L5t.forEach(t),aFr=r(lIe," \u2014 "),tU=n(lIe,"A",{href:!0});var x5t=s(tU);nFr=r(x5t,"TFTransfoXLLMHeadModel"),x5t.forEach(t),sFr=r(lIe," (Transformer-XL model)"),lIe.forEach(t),lFr=i(Ce),f9=n(Ce,"LI",{});var iIe=s(f9);gFe=n(iIe,"STRONG",{});var $5t=s(gFe);iFr=r($5t,"xlm"),$5t.forEach(t),dFr=r(iIe," \u2014 "),aU=n(iIe,"A",{href:!0});var k5t=s(aU);cFr=r(k5t,"TFXLMWithLMHeadModel"),k5t.forEach(t),fFr=r(iIe," (XLM model)"),iIe.forEach(t),mFr=i(Ce),m9=n(Ce,"LI",{});var dIe=s(m9);hFe=n(dIe,"STRONG",{});var S5t=s(hFe);gFr=r(S5t,"xlnet"),S5t.forEach(t),hFr=r(dIe," \u2014 "),nU=n(dIe,"A",{href:!0});var R5t=s(nU);pFr=r(R5t,"TFXLNetLMHeadModel"),R5t.forEach(t),uFr=r(dIe," (XLNet model)"),dIe.forEach(t),Ce.forEach(t),_Fr=i(Al),T(g9.$$.fragment,Al),Al.forEach(t),wl.forEach(t),IGe=i(f),lc=n(f,"H2",{class:!0});var XVe=s(lc);h9=n(XVe,"A",{id:!0,class:!0,href:!0});var P5t=s(h9);pFe=n(P5t,"SPAN",{});var B5t=s(pFe);T(g8.$$.fragment,B5t),B5t.forEach(t),P5t.forEach(t),bFr=i(XVe),uFe=n(XVe,"SPAN",{});var I5t=s(uFe);vFr=r(I5t,"TFAutoModelForImageClassification"),I5t.forEach(t),XVe.forEach(t),NGe=i(f),rr=n(f,"DIV",{class:!0});var yl=s(rr);T(h8.$$.fragment,yl),FFr=i(yl),ic=n(yl,"P",{});var Ioe=s(ic);TFr=r(Ioe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),sU=n(Ioe,"A",{href:!0});var N5t=s(sU);MFr=r(N5t,"from_pretrained()"),N5t.forEach(t),EFr=r(Ioe," class method or the "),lU=n(Ioe,"A",{href:!0});var q5t=s(lU);CFr=r(q5t,"from_config()"),q5t.forEach(t),wFr=r(Ioe,` class
method.`),Ioe.forEach(t),AFr=i(yl),p8=n(yl,"P",{});var zVe=s(p8);yFr=r(zVe,"This class cannot be instantiated directly using "),_Fe=n(zVe,"CODE",{});var j5t=s(_Fe);LFr=r(j5t,"__init__()"),j5t.forEach(t),xFr=r(zVe," (throws an error)."),zVe.forEach(t),$Fr=i(yl),Rt=n(yl,"DIV",{class:!0});var pw=s(Rt);T(u8.$$.fragment,pw),kFr=i(pw),bFe=n(pw,"P",{});var D5t=s(bFe);SFr=r(D5t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),D5t.forEach(t),RFr=i(pw),dc=n(pw,"P",{});var Noe=s(dc);PFr=r(Noe,`Note:
Loading a model from its configuration file does `),vFe=n(Noe,"STRONG",{});var G5t=s(vFe);BFr=r(G5t,"not"),G5t.forEach(t),IFr=r(Noe,` load the model weights. It only affects the
model\u2019s configuration. Use `),iU=n(Noe,"A",{href:!0});var O5t=s(iU);NFr=r(O5t,"from_pretrained()"),O5t.forEach(t),qFr=r(Noe," to load the model weights."),Noe.forEach(t),jFr=i(pw),T(p9.$$.fragment,pw),pw.forEach(t),DFr=i(yl),$r=n(yl,"DIV",{class:!0});var Ll=s($r);T(_8.$$.fragment,Ll),GFr=i(Ll),FFe=n(Ll,"P",{});var V5t=s(FFe);OFr=r(V5t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),V5t.forEach(t),VFr=i(Ll),sn=n(Ll,"P",{});var uw=s(sn);XFr=r(uw,"The model class to instantiate is selected based on the "),TFe=n(uw,"CODE",{});var X5t=s(TFe);zFr=r(X5t,"model_type"),X5t.forEach(t),WFr=r(uw,` property of the config object (either
passed as an argument or loaded from `),MFe=n(uw,"CODE",{});var z5t=s(MFe);QFr=r(z5t,"pretrained_model_name_or_path"),z5t.forEach(t),HFr=r(uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EFe=n(uw,"CODE",{});var W5t=s(EFe);UFr=r(W5t,"pretrained_model_name_or_path"),W5t.forEach(t),JFr=r(uw,":"),uw.forEach(t),YFr=i(Ll),ln=n(Ll,"UL",{});var _w=s(ln);u9=n(_w,"LI",{});var cIe=s(u9);CFe=n(cIe,"STRONG",{});var Q5t=s(CFe);KFr=r(Q5t,"convnext"),Q5t.forEach(t),ZFr=r(cIe," \u2014 "),dU=n(cIe,"A",{href:!0});var H5t=s(dU);e6r=r(H5t,"TFConvNextForImageClassification"),H5t.forEach(t),o6r=r(cIe," (ConvNeXT model)"),cIe.forEach(t),r6r=i(_w),_9=n(_w,"LI",{});var fIe=s(_9);wFe=n(fIe,"STRONG",{});var U5t=s(wFe);t6r=r(U5t,"data2vec-vision"),U5t.forEach(t),a6r=r(fIe," \u2014 "),cU=n(fIe,"A",{href:!0});var J5t=s(cU);n6r=r(J5t,"TFData2VecVisionForImageClassification"),J5t.forEach(t),s6r=r(fIe," (Data2VecVision model)"),fIe.forEach(t),l6r=i(_w),b9=n(_w,"LI",{});var mIe=s(b9);AFe=n(mIe,"STRONG",{});var Y5t=s(AFe);i6r=r(Y5t,"swin"),Y5t.forEach(t),d6r=r(mIe," \u2014 "),fU=n(mIe,"A",{href:!0});var K5t=s(fU);c6r=r(K5t,"TFSwinForImageClassification"),K5t.forEach(t),f6r=r(mIe," (Swin Transformer model)"),mIe.forEach(t),m6r=i(_w),v9=n(_w,"LI",{});var gIe=s(v9);yFe=n(gIe,"STRONG",{});var Z5t=s(yFe);g6r=r(Z5t,"vit"),Z5t.forEach(t),h6r=r(gIe," \u2014 "),mU=n(gIe,"A",{href:!0});var e0t=s(mU);p6r=r(e0t,"TFViTForImageClassification"),e0t.forEach(t),u6r=r(gIe," (ViT model)"),gIe.forEach(t),_w.forEach(t),_6r=i(Ll),T(F9.$$.fragment,Ll),Ll.forEach(t),yl.forEach(t),qGe=i(f),cc=n(f,"H2",{class:!0});var WVe=s(cc);T9=n(WVe,"A",{id:!0,class:!0,href:!0});var o0t=s(T9);LFe=n(o0t,"SPAN",{});var r0t=s(LFe);T(b8.$$.fragment,r0t),r0t.forEach(t),o0t.forEach(t),b6r=i(WVe),xFe=n(WVe,"SPAN",{});var t0t=s(xFe);v6r=r(t0t,"TFAutoModelForMaskedLM"),t0t.forEach(t),WVe.forEach(t),jGe=i(f),tr=n(f,"DIV",{class:!0});var xl=s(tr);T(v8.$$.fragment,xl),F6r=i(xl),fc=n(xl,"P",{});var qoe=s(fc);T6r=r(qoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),gU=n(qoe,"A",{href:!0});var a0t=s(gU);M6r=r(a0t,"from_pretrained()"),a0t.forEach(t),E6r=r(qoe," class method or the "),hU=n(qoe,"A",{href:!0});var n0t=s(hU);C6r=r(n0t,"from_config()"),n0t.forEach(t),w6r=r(qoe,` class
method.`),qoe.forEach(t),A6r=i(xl),F8=n(xl,"P",{});var QVe=s(F8);y6r=r(QVe,"This class cannot be instantiated directly using "),$Fe=n(QVe,"CODE",{});var s0t=s($Fe);L6r=r(s0t,"__init__()"),s0t.forEach(t),x6r=r(QVe," (throws an error)."),QVe.forEach(t),$6r=i(xl),Pt=n(xl,"DIV",{class:!0});var bw=s(Pt);T(T8.$$.fragment,bw),k6r=i(bw),kFe=n(bw,"P",{});var l0t=s(kFe);S6r=r(l0t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),l0t.forEach(t),R6r=i(bw),mc=n(bw,"P",{});var joe=s(mc);P6r=r(joe,`Note:
Loading a model from its configuration file does `),SFe=n(joe,"STRONG",{});var i0t=s(SFe);B6r=r(i0t,"not"),i0t.forEach(t),I6r=r(joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),pU=n(joe,"A",{href:!0});var d0t=s(pU);N6r=r(d0t,"from_pretrained()"),d0t.forEach(t),q6r=r(joe," to load the model weights."),joe.forEach(t),j6r=i(bw),T(M9.$$.fragment,bw),bw.forEach(t),D6r=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(M8.$$.fragment,$l),G6r=i($l),RFe=n($l,"P",{});var c0t=s(RFe);O6r=r(c0t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),c0t.forEach(t),V6r=i($l),dn=n($l,"P",{});var vw=s(dn);X6r=r(vw,"The model class to instantiate is selected based on the "),PFe=n(vw,"CODE",{});var f0t=s(PFe);z6r=r(f0t,"model_type"),f0t.forEach(t),W6r=r(vw,` property of the config object (either
passed as an argument or loaded from `),BFe=n(vw,"CODE",{});var m0t=s(BFe);Q6r=r(m0t,"pretrained_model_name_or_path"),m0t.forEach(t),H6r=r(vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IFe=n(vw,"CODE",{});var g0t=s(IFe);U6r=r(g0t,"pretrained_model_name_or_path"),g0t.forEach(t),J6r=r(vw,":"),vw.forEach(t),Y6r=i($l),ie=n($l,"UL",{});var fe=s(ie);E9=n(fe,"LI",{});var hIe=s(E9);NFe=n(hIe,"STRONG",{});var h0t=s(NFe);K6r=r(h0t,"albert"),h0t.forEach(t),Z6r=r(hIe," \u2014 "),uU=n(hIe,"A",{href:!0});var p0t=s(uU);eTr=r(p0t,"TFAlbertForMaskedLM"),p0t.forEach(t),oTr=r(hIe," (ALBERT model)"),hIe.forEach(t),rTr=i(fe),C9=n(fe,"LI",{});var pIe=s(C9);qFe=n(pIe,"STRONG",{});var u0t=s(qFe);tTr=r(u0t,"bert"),u0t.forEach(t),aTr=r(pIe," \u2014 "),_U=n(pIe,"A",{href:!0});var _0t=s(_U);nTr=r(_0t,"TFBertForMaskedLM"),_0t.forEach(t),sTr=r(pIe," (BERT model)"),pIe.forEach(t),lTr=i(fe),w9=n(fe,"LI",{});var uIe=s(w9);jFe=n(uIe,"STRONG",{});var b0t=s(jFe);iTr=r(b0t,"camembert"),b0t.forEach(t),dTr=r(uIe," \u2014 "),bU=n(uIe,"A",{href:!0});var v0t=s(bU);cTr=r(v0t,"TFCamembertForMaskedLM"),v0t.forEach(t),fTr=r(uIe," (CamemBERT model)"),uIe.forEach(t),mTr=i(fe),A9=n(fe,"LI",{});var _Ie=s(A9);DFe=n(_Ie,"STRONG",{});var F0t=s(DFe);gTr=r(F0t,"convbert"),F0t.forEach(t),hTr=r(_Ie," \u2014 "),vU=n(_Ie,"A",{href:!0});var T0t=s(vU);pTr=r(T0t,"TFConvBertForMaskedLM"),T0t.forEach(t),uTr=r(_Ie," (ConvBERT model)"),_Ie.forEach(t),_Tr=i(fe),y9=n(fe,"LI",{});var bIe=s(y9);GFe=n(bIe,"STRONG",{});var M0t=s(GFe);bTr=r(M0t,"deberta"),M0t.forEach(t),vTr=r(bIe," \u2014 "),FU=n(bIe,"A",{href:!0});var E0t=s(FU);FTr=r(E0t,"TFDebertaForMaskedLM"),E0t.forEach(t),TTr=r(bIe," (DeBERTa model)"),bIe.forEach(t),MTr=i(fe),L9=n(fe,"LI",{});var vIe=s(L9);OFe=n(vIe,"STRONG",{});var C0t=s(OFe);ETr=r(C0t,"deberta-v2"),C0t.forEach(t),CTr=r(vIe," \u2014 "),TU=n(vIe,"A",{href:!0});var w0t=s(TU);wTr=r(w0t,"TFDebertaV2ForMaskedLM"),w0t.forEach(t),ATr=r(vIe," (DeBERTa-v2 model)"),vIe.forEach(t),yTr=i(fe),x9=n(fe,"LI",{});var FIe=s(x9);VFe=n(FIe,"STRONG",{});var A0t=s(VFe);LTr=r(A0t,"distilbert"),A0t.forEach(t),xTr=r(FIe," \u2014 "),MU=n(FIe,"A",{href:!0});var y0t=s(MU);$Tr=r(y0t,"TFDistilBertForMaskedLM"),y0t.forEach(t),kTr=r(FIe," (DistilBERT model)"),FIe.forEach(t),STr=i(fe),$9=n(fe,"LI",{});var TIe=s($9);XFe=n(TIe,"STRONG",{});var L0t=s(XFe);RTr=r(L0t,"electra"),L0t.forEach(t),PTr=r(TIe," \u2014 "),EU=n(TIe,"A",{href:!0});var x0t=s(EU);BTr=r(x0t,"TFElectraForMaskedLM"),x0t.forEach(t),ITr=r(TIe," (ELECTRA model)"),TIe.forEach(t),NTr=i(fe),k9=n(fe,"LI",{});var MIe=s(k9);zFe=n(MIe,"STRONG",{});var $0t=s(zFe);qTr=r($0t,"flaubert"),$0t.forEach(t),jTr=r(MIe," \u2014 "),CU=n(MIe,"A",{href:!0});var k0t=s(CU);DTr=r(k0t,"TFFlaubertWithLMHeadModel"),k0t.forEach(t),GTr=r(MIe," (FlauBERT model)"),MIe.forEach(t),OTr=i(fe),S9=n(fe,"LI",{});var EIe=s(S9);WFe=n(EIe,"STRONG",{});var S0t=s(WFe);VTr=r(S0t,"funnel"),S0t.forEach(t),XTr=r(EIe," \u2014 "),wU=n(EIe,"A",{href:!0});var R0t=s(wU);zTr=r(R0t,"TFFunnelForMaskedLM"),R0t.forEach(t),WTr=r(EIe," (Funnel Transformer model)"),EIe.forEach(t),QTr=i(fe),R9=n(fe,"LI",{});var CIe=s(R9);QFe=n(CIe,"STRONG",{});var P0t=s(QFe);HTr=r(P0t,"layoutlm"),P0t.forEach(t),UTr=r(CIe," \u2014 "),AU=n(CIe,"A",{href:!0});var B0t=s(AU);JTr=r(B0t,"TFLayoutLMForMaskedLM"),B0t.forEach(t),YTr=r(CIe," (LayoutLM model)"),CIe.forEach(t),KTr=i(fe),P9=n(fe,"LI",{});var wIe=s(P9);HFe=n(wIe,"STRONG",{});var I0t=s(HFe);ZTr=r(I0t,"longformer"),I0t.forEach(t),e7r=r(wIe," \u2014 "),yU=n(wIe,"A",{href:!0});var N0t=s(yU);o7r=r(N0t,"TFLongformerForMaskedLM"),N0t.forEach(t),r7r=r(wIe," (Longformer model)"),wIe.forEach(t),t7r=i(fe),B9=n(fe,"LI",{});var AIe=s(B9);UFe=n(AIe,"STRONG",{});var q0t=s(UFe);a7r=r(q0t,"mobilebert"),q0t.forEach(t),n7r=r(AIe," \u2014 "),LU=n(AIe,"A",{href:!0});var j0t=s(LU);s7r=r(j0t,"TFMobileBertForMaskedLM"),j0t.forEach(t),l7r=r(AIe," (MobileBERT model)"),AIe.forEach(t),i7r=i(fe),I9=n(fe,"LI",{});var yIe=s(I9);JFe=n(yIe,"STRONG",{});var D0t=s(JFe);d7r=r(D0t,"mpnet"),D0t.forEach(t),c7r=r(yIe," \u2014 "),xU=n(yIe,"A",{href:!0});var G0t=s(xU);f7r=r(G0t,"TFMPNetForMaskedLM"),G0t.forEach(t),m7r=r(yIe," (MPNet model)"),yIe.forEach(t),g7r=i(fe),N9=n(fe,"LI",{});var LIe=s(N9);YFe=n(LIe,"STRONG",{});var O0t=s(YFe);h7r=r(O0t,"rembert"),O0t.forEach(t),p7r=r(LIe," \u2014 "),$U=n(LIe,"A",{href:!0});var V0t=s($U);u7r=r(V0t,"TFRemBertForMaskedLM"),V0t.forEach(t),_7r=r(LIe," (RemBERT model)"),LIe.forEach(t),b7r=i(fe),q9=n(fe,"LI",{});var xIe=s(q9);KFe=n(xIe,"STRONG",{});var X0t=s(KFe);v7r=r(X0t,"roberta"),X0t.forEach(t),F7r=r(xIe," \u2014 "),kU=n(xIe,"A",{href:!0});var z0t=s(kU);T7r=r(z0t,"TFRobertaForMaskedLM"),z0t.forEach(t),M7r=r(xIe," (RoBERTa model)"),xIe.forEach(t),E7r=i(fe),j9=n(fe,"LI",{});var $Ie=s(j9);ZFe=n($Ie,"STRONG",{});var W0t=s(ZFe);C7r=r(W0t,"roformer"),W0t.forEach(t),w7r=r($Ie," \u2014 "),SU=n($Ie,"A",{href:!0});var Q0t=s(SU);A7r=r(Q0t,"TFRoFormerForMaskedLM"),Q0t.forEach(t),y7r=r($Ie," (RoFormer model)"),$Ie.forEach(t),L7r=i(fe),D9=n(fe,"LI",{});var kIe=s(D9);e6e=n(kIe,"STRONG",{});var H0t=s(e6e);x7r=r(H0t,"tapas"),H0t.forEach(t),$7r=r(kIe," \u2014 "),RU=n(kIe,"A",{href:!0});var U0t=s(RU);k7r=r(U0t,"TFTapasForMaskedLM"),U0t.forEach(t),S7r=r(kIe," (TAPAS model)"),kIe.forEach(t),R7r=i(fe),G9=n(fe,"LI",{});var SIe=s(G9);o6e=n(SIe,"STRONG",{});var J0t=s(o6e);P7r=r(J0t,"xlm"),J0t.forEach(t),B7r=r(SIe," \u2014 "),PU=n(SIe,"A",{href:!0});var Y0t=s(PU);I7r=r(Y0t,"TFXLMWithLMHeadModel"),Y0t.forEach(t),N7r=r(SIe," (XLM model)"),SIe.forEach(t),q7r=i(fe),O9=n(fe,"LI",{});var RIe=s(O9);r6e=n(RIe,"STRONG",{});var K0t=s(r6e);j7r=r(K0t,"xlm-roberta"),K0t.forEach(t),D7r=r(RIe," \u2014 "),BU=n(RIe,"A",{href:!0});var Z0t=s(BU);G7r=r(Z0t,"TFXLMRobertaForMaskedLM"),Z0t.forEach(t),O7r=r(RIe," (XLM-RoBERTa model)"),RIe.forEach(t),fe.forEach(t),V7r=i($l),T(V9.$$.fragment,$l),$l.forEach(t),xl.forEach(t),DGe=i(f),gc=n(f,"H2",{class:!0});var HVe=s(gc);X9=n(HVe,"A",{id:!0,class:!0,href:!0});var ewt=s(X9);t6e=n(ewt,"SPAN",{});var owt=s(t6e);T(E8.$$.fragment,owt),owt.forEach(t),ewt.forEach(t),X7r=i(HVe),a6e=n(HVe,"SPAN",{});var rwt=s(a6e);z7r=r(rwt,"TFAutoModelForSeq2SeqLM"),rwt.forEach(t),HVe.forEach(t),GGe=i(f),ar=n(f,"DIV",{class:!0});var kl=s(ar);T(C8.$$.fragment,kl),W7r=i(kl),hc=n(kl,"P",{});var Doe=s(hc);Q7r=r(Doe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),IU=n(Doe,"A",{href:!0});var twt=s(IU);H7r=r(twt,"from_pretrained()"),twt.forEach(t),U7r=r(Doe," class method or the "),NU=n(Doe,"A",{href:!0});var awt=s(NU);J7r=r(awt,"from_config()"),awt.forEach(t),Y7r=r(Doe,` class
method.`),Doe.forEach(t),K7r=i(kl),w8=n(kl,"P",{});var UVe=s(w8);Z7r=r(UVe,"This class cannot be instantiated directly using "),n6e=n(UVe,"CODE",{});var nwt=s(n6e);e9r=r(nwt,"__init__()"),nwt.forEach(t),o9r=r(UVe," (throws an error)."),UVe.forEach(t),r9r=i(kl),Bt=n(kl,"DIV",{class:!0});var Fw=s(Bt);T(A8.$$.fragment,Fw),t9r=i(Fw),s6e=n(Fw,"P",{});var swt=s(s6e);a9r=r(swt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),swt.forEach(t),n9r=i(Fw),pc=n(Fw,"P",{});var Goe=s(pc);s9r=r(Goe,`Note:
Loading a model from its configuration file does `),l6e=n(Goe,"STRONG",{});var lwt=s(l6e);l9r=r(lwt,"not"),lwt.forEach(t),i9r=r(Goe,` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=n(Goe,"A",{href:!0});var iwt=s(qU);d9r=r(iwt,"from_pretrained()"),iwt.forEach(t),c9r=r(Goe," to load the model weights."),Goe.forEach(t),f9r=i(Fw),T(z9.$$.fragment,Fw),Fw.forEach(t),m9r=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(y8.$$.fragment,Sl),g9r=i(Sl),i6e=n(Sl,"P",{});var dwt=s(i6e);h9r=r(dwt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dwt.forEach(t),p9r=i(Sl),cn=n(Sl,"P",{});var Tw=s(cn);u9r=r(Tw,"The model class to instantiate is selected based on the "),d6e=n(Tw,"CODE",{});var cwt=s(d6e);_9r=r(cwt,"model_type"),cwt.forEach(t),b9r=r(Tw,` property of the config object (either
passed as an argument or loaded from `),c6e=n(Tw,"CODE",{});var fwt=s(c6e);v9r=r(fwt,"pretrained_model_name_or_path"),fwt.forEach(t),F9r=r(Tw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f6e=n(Tw,"CODE",{});var mwt=s(f6e);T9r=r(mwt,"pretrained_model_name_or_path"),mwt.forEach(t),M9r=r(Tw,":"),Tw.forEach(t),E9r=i(Sl),Le=n(Sl,"UL",{});var Ie=s(Le);W9=n(Ie,"LI",{});var PIe=s(W9);m6e=n(PIe,"STRONG",{});var gwt=s(m6e);C9r=r(gwt,"bart"),gwt.forEach(t),w9r=r(PIe," \u2014 "),jU=n(PIe,"A",{href:!0});var hwt=s(jU);A9r=r(hwt,"TFBartForConditionalGeneration"),hwt.forEach(t),y9r=r(PIe," (BART model)"),PIe.forEach(t),L9r=i(Ie),Q9=n(Ie,"LI",{});var BIe=s(Q9);g6e=n(BIe,"STRONG",{});var pwt=s(g6e);x9r=r(pwt,"blenderbot"),pwt.forEach(t),$9r=r(BIe," \u2014 "),DU=n(BIe,"A",{href:!0});var uwt=s(DU);k9r=r(uwt,"TFBlenderbotForConditionalGeneration"),uwt.forEach(t),S9r=r(BIe," (Blenderbot model)"),BIe.forEach(t),R9r=i(Ie),H9=n(Ie,"LI",{});var IIe=s(H9);h6e=n(IIe,"STRONG",{});var _wt=s(h6e);P9r=r(_wt,"blenderbot-small"),_wt.forEach(t),B9r=r(IIe," \u2014 "),GU=n(IIe,"A",{href:!0});var bwt=s(GU);I9r=r(bwt,"TFBlenderbotSmallForConditionalGeneration"),bwt.forEach(t),N9r=r(IIe," (BlenderbotSmall model)"),IIe.forEach(t),q9r=i(Ie),U9=n(Ie,"LI",{});var NIe=s(U9);p6e=n(NIe,"STRONG",{});var vwt=s(p6e);j9r=r(vwt,"encoder-decoder"),vwt.forEach(t),D9r=r(NIe," \u2014 "),OU=n(NIe,"A",{href:!0});var Fwt=s(OU);G9r=r(Fwt,"TFEncoderDecoderModel"),Fwt.forEach(t),O9r=r(NIe," (Encoder decoder model)"),NIe.forEach(t),V9r=i(Ie),J9=n(Ie,"LI",{});var qIe=s(J9);u6e=n(qIe,"STRONG",{});var Twt=s(u6e);X9r=r(Twt,"led"),Twt.forEach(t),z9r=r(qIe," \u2014 "),VU=n(qIe,"A",{href:!0});var Mwt=s(VU);W9r=r(Mwt,"TFLEDForConditionalGeneration"),Mwt.forEach(t),Q9r=r(qIe," (LED model)"),qIe.forEach(t),H9r=i(Ie),Y9=n(Ie,"LI",{});var jIe=s(Y9);_6e=n(jIe,"STRONG",{});var Ewt=s(_6e);U9r=r(Ewt,"marian"),Ewt.forEach(t),J9r=r(jIe," \u2014 "),XU=n(jIe,"A",{href:!0});var Cwt=s(XU);Y9r=r(Cwt,"TFMarianMTModel"),Cwt.forEach(t),K9r=r(jIe," (Marian model)"),jIe.forEach(t),Z9r=i(Ie),K9=n(Ie,"LI",{});var DIe=s(K9);b6e=n(DIe,"STRONG",{});var wwt=s(b6e);eMr=r(wwt,"mbart"),wwt.forEach(t),oMr=r(DIe," \u2014 "),zU=n(DIe,"A",{href:!0});var Awt=s(zU);rMr=r(Awt,"TFMBartForConditionalGeneration"),Awt.forEach(t),tMr=r(DIe," (mBART model)"),DIe.forEach(t),aMr=i(Ie),Z9=n(Ie,"LI",{});var GIe=s(Z9);v6e=n(GIe,"STRONG",{});var ywt=s(v6e);nMr=r(ywt,"mt5"),ywt.forEach(t),sMr=r(GIe," \u2014 "),WU=n(GIe,"A",{href:!0});var Lwt=s(WU);lMr=r(Lwt,"TFMT5ForConditionalGeneration"),Lwt.forEach(t),iMr=r(GIe," (MT5 model)"),GIe.forEach(t),dMr=i(Ie),eM=n(Ie,"LI",{});var OIe=s(eM);F6e=n(OIe,"STRONG",{});var xwt=s(F6e);cMr=r(xwt,"pegasus"),xwt.forEach(t),fMr=r(OIe," \u2014 "),QU=n(OIe,"A",{href:!0});var $wt=s(QU);mMr=r($wt,"TFPegasusForConditionalGeneration"),$wt.forEach(t),gMr=r(OIe," (Pegasus model)"),OIe.forEach(t),hMr=i(Ie),oM=n(Ie,"LI",{});var VIe=s(oM);T6e=n(VIe,"STRONG",{});var kwt=s(T6e);pMr=r(kwt,"t5"),kwt.forEach(t),uMr=r(VIe," \u2014 "),HU=n(VIe,"A",{href:!0});var Swt=s(HU);_Mr=r(Swt,"TFT5ForConditionalGeneration"),Swt.forEach(t),bMr=r(VIe," (T5 model)"),VIe.forEach(t),Ie.forEach(t),vMr=i(Sl),T(rM.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),OGe=i(f),uc=n(f,"H2",{class:!0});var JVe=s(uc);tM=n(JVe,"A",{id:!0,class:!0,href:!0});var Rwt=s(tM);M6e=n(Rwt,"SPAN",{});var Pwt=s(M6e);T(L8.$$.fragment,Pwt),Pwt.forEach(t),Rwt.forEach(t),FMr=i(JVe),E6e=n(JVe,"SPAN",{});var Bwt=s(E6e);TMr=r(Bwt,"TFAutoModelForSequenceClassification"),Bwt.forEach(t),JVe.forEach(t),VGe=i(f),nr=n(f,"DIV",{class:!0});var Rl=s(nr);T(x8.$$.fragment,Rl),MMr=i(Rl),_c=n(Rl,"P",{});var Ooe=s(_c);EMr=r(Ooe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),UU=n(Ooe,"A",{href:!0});var Iwt=s(UU);CMr=r(Iwt,"from_pretrained()"),Iwt.forEach(t),wMr=r(Ooe," class method or the "),JU=n(Ooe,"A",{href:!0});var Nwt=s(JU);AMr=r(Nwt,"from_config()"),Nwt.forEach(t),yMr=r(Ooe,` class
method.`),Ooe.forEach(t),LMr=i(Rl),$8=n(Rl,"P",{});var YVe=s($8);xMr=r(YVe,"This class cannot be instantiated directly using "),C6e=n(YVe,"CODE",{});var qwt=s(C6e);$Mr=r(qwt,"__init__()"),qwt.forEach(t),kMr=r(YVe," (throws an error)."),YVe.forEach(t),SMr=i(Rl),It=n(Rl,"DIV",{class:!0});var Mw=s(It);T(k8.$$.fragment,Mw),RMr=i(Mw),w6e=n(Mw,"P",{});var jwt=s(w6e);PMr=r(jwt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),jwt.forEach(t),BMr=i(Mw),bc=n(Mw,"P",{});var Voe=s(bc);IMr=r(Voe,`Note:
Loading a model from its configuration file does `),A6e=n(Voe,"STRONG",{});var Dwt=s(A6e);NMr=r(Dwt,"not"),Dwt.forEach(t),qMr=r(Voe,` load the model weights. It only affects the
model\u2019s configuration. Use `),YU=n(Voe,"A",{href:!0});var Gwt=s(YU);jMr=r(Gwt,"from_pretrained()"),Gwt.forEach(t),DMr=r(Voe," to load the model weights."),Voe.forEach(t),GMr=i(Mw),T(aM.$$.fragment,Mw),Mw.forEach(t),OMr=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(S8.$$.fragment,Pl),VMr=i(Pl),y6e=n(Pl,"P",{});var Owt=s(y6e);XMr=r(Owt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Owt.forEach(t),zMr=i(Pl),fn=n(Pl,"P",{});var Ew=s(fn);WMr=r(Ew,"The model class to instantiate is selected based on the "),L6e=n(Ew,"CODE",{});var Vwt=s(L6e);QMr=r(Vwt,"model_type"),Vwt.forEach(t),HMr=r(Ew,` property of the config object (either
passed as an argument or loaded from `),x6e=n(Ew,"CODE",{});var Xwt=s(x6e);UMr=r(Xwt,"pretrained_model_name_or_path"),Xwt.forEach(t),JMr=r(Ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$6e=n(Ew,"CODE",{});var zwt=s($6e);YMr=r(zwt,"pretrained_model_name_or_path"),zwt.forEach(t),KMr=r(Ew,":"),Ew.forEach(t),ZMr=i(Pl),re=n(Pl,"UL",{});var ae=s(re);nM=n(ae,"LI",{});var XIe=s(nM);k6e=n(XIe,"STRONG",{});var Wwt=s(k6e);e4r=r(Wwt,"albert"),Wwt.forEach(t),o4r=r(XIe," \u2014 "),KU=n(XIe,"A",{href:!0});var Qwt=s(KU);r4r=r(Qwt,"TFAlbertForSequenceClassification"),Qwt.forEach(t),t4r=r(XIe," (ALBERT model)"),XIe.forEach(t),a4r=i(ae),sM=n(ae,"LI",{});var zIe=s(sM);S6e=n(zIe,"STRONG",{});var Hwt=s(S6e);n4r=r(Hwt,"bert"),Hwt.forEach(t),s4r=r(zIe," \u2014 "),ZU=n(zIe,"A",{href:!0});var Uwt=s(ZU);l4r=r(Uwt,"TFBertForSequenceClassification"),Uwt.forEach(t),i4r=r(zIe," (BERT model)"),zIe.forEach(t),d4r=i(ae),lM=n(ae,"LI",{});var WIe=s(lM);R6e=n(WIe,"STRONG",{});var Jwt=s(R6e);c4r=r(Jwt,"camembert"),Jwt.forEach(t),f4r=r(WIe," \u2014 "),eJ=n(WIe,"A",{href:!0});var Ywt=s(eJ);m4r=r(Ywt,"TFCamembertForSequenceClassification"),Ywt.forEach(t),g4r=r(WIe," (CamemBERT model)"),WIe.forEach(t),h4r=i(ae),iM=n(ae,"LI",{});var QIe=s(iM);P6e=n(QIe,"STRONG",{});var Kwt=s(P6e);p4r=r(Kwt,"convbert"),Kwt.forEach(t),u4r=r(QIe," \u2014 "),oJ=n(QIe,"A",{href:!0});var Zwt=s(oJ);_4r=r(Zwt,"TFConvBertForSequenceClassification"),Zwt.forEach(t),b4r=r(QIe," (ConvBERT model)"),QIe.forEach(t),v4r=i(ae),dM=n(ae,"LI",{});var HIe=s(dM);B6e=n(HIe,"STRONG",{});var eAt=s(B6e);F4r=r(eAt,"ctrl"),eAt.forEach(t),T4r=r(HIe," \u2014 "),rJ=n(HIe,"A",{href:!0});var oAt=s(rJ);M4r=r(oAt,"TFCTRLForSequenceClassification"),oAt.forEach(t),E4r=r(HIe," (CTRL model)"),HIe.forEach(t),C4r=i(ae),cM=n(ae,"LI",{});var UIe=s(cM);I6e=n(UIe,"STRONG",{});var rAt=s(I6e);w4r=r(rAt,"deberta"),rAt.forEach(t),A4r=r(UIe," \u2014 "),tJ=n(UIe,"A",{href:!0});var tAt=s(tJ);y4r=r(tAt,"TFDebertaForSequenceClassification"),tAt.forEach(t),L4r=r(UIe," (DeBERTa model)"),UIe.forEach(t),x4r=i(ae),fM=n(ae,"LI",{});var JIe=s(fM);N6e=n(JIe,"STRONG",{});var aAt=s(N6e);$4r=r(aAt,"deberta-v2"),aAt.forEach(t),k4r=r(JIe," \u2014 "),aJ=n(JIe,"A",{href:!0});var nAt=s(aJ);S4r=r(nAt,"TFDebertaV2ForSequenceClassification"),nAt.forEach(t),R4r=r(JIe," (DeBERTa-v2 model)"),JIe.forEach(t),P4r=i(ae),mM=n(ae,"LI",{});var YIe=s(mM);q6e=n(YIe,"STRONG",{});var sAt=s(q6e);B4r=r(sAt,"distilbert"),sAt.forEach(t),I4r=r(YIe," \u2014 "),nJ=n(YIe,"A",{href:!0});var lAt=s(nJ);N4r=r(lAt,"TFDistilBertForSequenceClassification"),lAt.forEach(t),q4r=r(YIe," (DistilBERT model)"),YIe.forEach(t),j4r=i(ae),gM=n(ae,"LI",{});var KIe=s(gM);j6e=n(KIe,"STRONG",{});var iAt=s(j6e);D4r=r(iAt,"electra"),iAt.forEach(t),G4r=r(KIe," \u2014 "),sJ=n(KIe,"A",{href:!0});var dAt=s(sJ);O4r=r(dAt,"TFElectraForSequenceClassification"),dAt.forEach(t),V4r=r(KIe," (ELECTRA model)"),KIe.forEach(t),X4r=i(ae),hM=n(ae,"LI",{});var ZIe=s(hM);D6e=n(ZIe,"STRONG",{});var cAt=s(D6e);z4r=r(cAt,"flaubert"),cAt.forEach(t),W4r=r(ZIe," \u2014 "),lJ=n(ZIe,"A",{href:!0});var fAt=s(lJ);Q4r=r(fAt,"TFFlaubertForSequenceClassification"),fAt.forEach(t),H4r=r(ZIe," (FlauBERT model)"),ZIe.forEach(t),U4r=i(ae),pM=n(ae,"LI",{});var eNe=s(pM);G6e=n(eNe,"STRONG",{});var mAt=s(G6e);J4r=r(mAt,"funnel"),mAt.forEach(t),Y4r=r(eNe," \u2014 "),iJ=n(eNe,"A",{href:!0});var gAt=s(iJ);K4r=r(gAt,"TFFunnelForSequenceClassification"),gAt.forEach(t),Z4r=r(eNe," (Funnel Transformer model)"),eNe.forEach(t),eEr=i(ae),uM=n(ae,"LI",{});var oNe=s(uM);O6e=n(oNe,"STRONG",{});var hAt=s(O6e);oEr=r(hAt,"gpt2"),hAt.forEach(t),rEr=r(oNe," \u2014 "),dJ=n(oNe,"A",{href:!0});var pAt=s(dJ);tEr=r(pAt,"TFGPT2ForSequenceClassification"),pAt.forEach(t),aEr=r(oNe," (OpenAI GPT-2 model)"),oNe.forEach(t),nEr=i(ae),_M=n(ae,"LI",{});var rNe=s(_M);V6e=n(rNe,"STRONG",{});var uAt=s(V6e);sEr=r(uAt,"gptj"),uAt.forEach(t),lEr=r(rNe," \u2014 "),cJ=n(rNe,"A",{href:!0});var _At=s(cJ);iEr=r(_At,"TFGPTJForSequenceClassification"),_At.forEach(t),dEr=r(rNe," (GPT-J model)"),rNe.forEach(t),cEr=i(ae),bM=n(ae,"LI",{});var tNe=s(bM);X6e=n(tNe,"STRONG",{});var bAt=s(X6e);fEr=r(bAt,"layoutlm"),bAt.forEach(t),mEr=r(tNe," \u2014 "),fJ=n(tNe,"A",{href:!0});var vAt=s(fJ);gEr=r(vAt,"TFLayoutLMForSequenceClassification"),vAt.forEach(t),hEr=r(tNe," (LayoutLM model)"),tNe.forEach(t),pEr=i(ae),vM=n(ae,"LI",{});var aNe=s(vM);z6e=n(aNe,"STRONG",{});var FAt=s(z6e);uEr=r(FAt,"longformer"),FAt.forEach(t),_Er=r(aNe," \u2014 "),mJ=n(aNe,"A",{href:!0});var TAt=s(mJ);bEr=r(TAt,"TFLongformerForSequenceClassification"),TAt.forEach(t),vEr=r(aNe," (Longformer model)"),aNe.forEach(t),FEr=i(ae),FM=n(ae,"LI",{});var nNe=s(FM);W6e=n(nNe,"STRONG",{});var MAt=s(W6e);TEr=r(MAt,"mobilebert"),MAt.forEach(t),MEr=r(nNe," \u2014 "),gJ=n(nNe,"A",{href:!0});var EAt=s(gJ);EEr=r(EAt,"TFMobileBertForSequenceClassification"),EAt.forEach(t),CEr=r(nNe," (MobileBERT model)"),nNe.forEach(t),wEr=i(ae),TM=n(ae,"LI",{});var sNe=s(TM);Q6e=n(sNe,"STRONG",{});var CAt=s(Q6e);AEr=r(CAt,"mpnet"),CAt.forEach(t),yEr=r(sNe," \u2014 "),hJ=n(sNe,"A",{href:!0});var wAt=s(hJ);LEr=r(wAt,"TFMPNetForSequenceClassification"),wAt.forEach(t),xEr=r(sNe," (MPNet model)"),sNe.forEach(t),$Er=i(ae),MM=n(ae,"LI",{});var lNe=s(MM);H6e=n(lNe,"STRONG",{});var AAt=s(H6e);kEr=r(AAt,"openai-gpt"),AAt.forEach(t),SEr=r(lNe," \u2014 "),pJ=n(lNe,"A",{href:!0});var yAt=s(pJ);REr=r(yAt,"TFOpenAIGPTForSequenceClassification"),yAt.forEach(t),PEr=r(lNe," (OpenAI GPT model)"),lNe.forEach(t),BEr=i(ae),EM=n(ae,"LI",{});var iNe=s(EM);U6e=n(iNe,"STRONG",{});var LAt=s(U6e);IEr=r(LAt,"rembert"),LAt.forEach(t),NEr=r(iNe," \u2014 "),uJ=n(iNe,"A",{href:!0});var xAt=s(uJ);qEr=r(xAt,"TFRemBertForSequenceClassification"),xAt.forEach(t),jEr=r(iNe," (RemBERT model)"),iNe.forEach(t),DEr=i(ae),CM=n(ae,"LI",{});var dNe=s(CM);J6e=n(dNe,"STRONG",{});var $At=s(J6e);GEr=r($At,"roberta"),$At.forEach(t),OEr=r(dNe," \u2014 "),_J=n(dNe,"A",{href:!0});var kAt=s(_J);VEr=r(kAt,"TFRobertaForSequenceClassification"),kAt.forEach(t),XEr=r(dNe," (RoBERTa model)"),dNe.forEach(t),zEr=i(ae),wM=n(ae,"LI",{});var cNe=s(wM);Y6e=n(cNe,"STRONG",{});var SAt=s(Y6e);WEr=r(SAt,"roformer"),SAt.forEach(t),QEr=r(cNe," \u2014 "),bJ=n(cNe,"A",{href:!0});var RAt=s(bJ);HEr=r(RAt,"TFRoFormerForSequenceClassification"),RAt.forEach(t),UEr=r(cNe," (RoFormer model)"),cNe.forEach(t),JEr=i(ae),AM=n(ae,"LI",{});var fNe=s(AM);K6e=n(fNe,"STRONG",{});var PAt=s(K6e);YEr=r(PAt,"tapas"),PAt.forEach(t),KEr=r(fNe," \u2014 "),vJ=n(fNe,"A",{href:!0});var BAt=s(vJ);ZEr=r(BAt,"TFTapasForSequenceClassification"),BAt.forEach(t),eCr=r(fNe," (TAPAS model)"),fNe.forEach(t),oCr=i(ae),yM=n(ae,"LI",{});var mNe=s(yM);Z6e=n(mNe,"STRONG",{});var IAt=s(Z6e);rCr=r(IAt,"transfo-xl"),IAt.forEach(t),tCr=r(mNe," \u2014 "),FJ=n(mNe,"A",{href:!0});var NAt=s(FJ);aCr=r(NAt,"TFTransfoXLForSequenceClassification"),NAt.forEach(t),nCr=r(mNe," (Transformer-XL model)"),mNe.forEach(t),sCr=i(ae),LM=n(ae,"LI",{});var gNe=s(LM);eTe=n(gNe,"STRONG",{});var qAt=s(eTe);lCr=r(qAt,"xlm"),qAt.forEach(t),iCr=r(gNe," \u2014 "),TJ=n(gNe,"A",{href:!0});var jAt=s(TJ);dCr=r(jAt,"TFXLMForSequenceClassification"),jAt.forEach(t),cCr=r(gNe," (XLM model)"),gNe.forEach(t),fCr=i(ae),xM=n(ae,"LI",{});var hNe=s(xM);oTe=n(hNe,"STRONG",{});var DAt=s(oTe);mCr=r(DAt,"xlm-roberta"),DAt.forEach(t),gCr=r(hNe," \u2014 "),MJ=n(hNe,"A",{href:!0});var GAt=s(MJ);hCr=r(GAt,"TFXLMRobertaForSequenceClassification"),GAt.forEach(t),pCr=r(hNe," (XLM-RoBERTa model)"),hNe.forEach(t),uCr=i(ae),$M=n(ae,"LI",{});var pNe=s($M);rTe=n(pNe,"STRONG",{});var OAt=s(rTe);_Cr=r(OAt,"xlnet"),OAt.forEach(t),bCr=r(pNe," \u2014 "),EJ=n(pNe,"A",{href:!0});var VAt=s(EJ);vCr=r(VAt,"TFXLNetForSequenceClassification"),VAt.forEach(t),FCr=r(pNe," (XLNet model)"),pNe.forEach(t),ae.forEach(t),TCr=i(Pl),T(kM.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),XGe=i(f),vc=n(f,"H2",{class:!0});var KVe=s(vc);SM=n(KVe,"A",{id:!0,class:!0,href:!0});var XAt=s(SM);tTe=n(XAt,"SPAN",{});var zAt=s(tTe);T(R8.$$.fragment,zAt),zAt.forEach(t),XAt.forEach(t),MCr=i(KVe),aTe=n(KVe,"SPAN",{});var WAt=s(aTe);ECr=r(WAt,"TFAutoModelForMultipleChoice"),WAt.forEach(t),KVe.forEach(t),zGe=i(f),sr=n(f,"DIV",{class:!0});var Bl=s(sr);T(P8.$$.fragment,Bl),CCr=i(Bl),Fc=n(Bl,"P",{});var Xoe=s(Fc);wCr=r(Xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),CJ=n(Xoe,"A",{href:!0});var QAt=s(CJ);ACr=r(QAt,"from_pretrained()"),QAt.forEach(t),yCr=r(Xoe," class method or the "),wJ=n(Xoe,"A",{href:!0});var HAt=s(wJ);LCr=r(HAt,"from_config()"),HAt.forEach(t),xCr=r(Xoe,` class
method.`),Xoe.forEach(t),$Cr=i(Bl),B8=n(Bl,"P",{});var ZVe=s(B8);kCr=r(ZVe,"This class cannot be instantiated directly using "),nTe=n(ZVe,"CODE",{});var UAt=s(nTe);SCr=r(UAt,"__init__()"),UAt.forEach(t),RCr=r(ZVe," (throws an error)."),ZVe.forEach(t),PCr=i(Bl),Nt=n(Bl,"DIV",{class:!0});var Cw=s(Nt);T(I8.$$.fragment,Cw),BCr=i(Cw),sTe=n(Cw,"P",{});var JAt=s(sTe);ICr=r(JAt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),JAt.forEach(t),NCr=i(Cw),Tc=n(Cw,"P",{});var zoe=s(Tc);qCr=r(zoe,`Note:
Loading a model from its configuration file does `),lTe=n(zoe,"STRONG",{});var YAt=s(lTe);jCr=r(YAt,"not"),YAt.forEach(t),DCr=r(zoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),AJ=n(zoe,"A",{href:!0});var KAt=s(AJ);GCr=r(KAt,"from_pretrained()"),KAt.forEach(t),OCr=r(zoe," to load the model weights."),zoe.forEach(t),VCr=i(Cw),T(RM.$$.fragment,Cw),Cw.forEach(t),XCr=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(N8.$$.fragment,Il),zCr=i(Il),iTe=n(Il,"P",{});var ZAt=s(iTe);WCr=r(ZAt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ZAt.forEach(t),QCr=i(Il),mn=n(Il,"P",{});var ww=s(mn);HCr=r(ww,"The model class to instantiate is selected based on the "),dTe=n(ww,"CODE",{});var eyt=s(dTe);UCr=r(eyt,"model_type"),eyt.forEach(t),JCr=r(ww,` property of the config object (either
passed as an argument or loaded from `),cTe=n(ww,"CODE",{});var oyt=s(cTe);YCr=r(oyt,"pretrained_model_name_or_path"),oyt.forEach(t),KCr=r(ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fTe=n(ww,"CODE",{});var ryt=s(fTe);ZCr=r(ryt,"pretrained_model_name_or_path"),ryt.forEach(t),e5r=r(ww,":"),ww.forEach(t),o5r=i(Il),pe=n(Il,"UL",{});var be=s(pe);PM=n(be,"LI",{});var uNe=s(PM);mTe=n(uNe,"STRONG",{});var tyt=s(mTe);r5r=r(tyt,"albert"),tyt.forEach(t),t5r=r(uNe," \u2014 "),yJ=n(uNe,"A",{href:!0});var ayt=s(yJ);a5r=r(ayt,"TFAlbertForMultipleChoice"),ayt.forEach(t),n5r=r(uNe," (ALBERT model)"),uNe.forEach(t),s5r=i(be),BM=n(be,"LI",{});var _Ne=s(BM);gTe=n(_Ne,"STRONG",{});var nyt=s(gTe);l5r=r(nyt,"bert"),nyt.forEach(t),i5r=r(_Ne," \u2014 "),LJ=n(_Ne,"A",{href:!0});var syt=s(LJ);d5r=r(syt,"TFBertForMultipleChoice"),syt.forEach(t),c5r=r(_Ne," (BERT model)"),_Ne.forEach(t),f5r=i(be),IM=n(be,"LI",{});var bNe=s(IM);hTe=n(bNe,"STRONG",{});var lyt=s(hTe);m5r=r(lyt,"camembert"),lyt.forEach(t),g5r=r(bNe," \u2014 "),xJ=n(bNe,"A",{href:!0});var iyt=s(xJ);h5r=r(iyt,"TFCamembertForMultipleChoice"),iyt.forEach(t),p5r=r(bNe," (CamemBERT model)"),bNe.forEach(t),u5r=i(be),NM=n(be,"LI",{});var vNe=s(NM);pTe=n(vNe,"STRONG",{});var dyt=s(pTe);_5r=r(dyt,"convbert"),dyt.forEach(t),b5r=r(vNe," \u2014 "),$J=n(vNe,"A",{href:!0});var cyt=s($J);v5r=r(cyt,"TFConvBertForMultipleChoice"),cyt.forEach(t),F5r=r(vNe," (ConvBERT model)"),vNe.forEach(t),T5r=i(be),qM=n(be,"LI",{});var FNe=s(qM);uTe=n(FNe,"STRONG",{});var fyt=s(uTe);M5r=r(fyt,"distilbert"),fyt.forEach(t),E5r=r(FNe," \u2014 "),kJ=n(FNe,"A",{href:!0});var myt=s(kJ);C5r=r(myt,"TFDistilBertForMultipleChoice"),myt.forEach(t),w5r=r(FNe," (DistilBERT model)"),FNe.forEach(t),A5r=i(be),jM=n(be,"LI",{});var TNe=s(jM);_Te=n(TNe,"STRONG",{});var gyt=s(_Te);y5r=r(gyt,"electra"),gyt.forEach(t),L5r=r(TNe," \u2014 "),SJ=n(TNe,"A",{href:!0});var hyt=s(SJ);x5r=r(hyt,"TFElectraForMultipleChoice"),hyt.forEach(t),$5r=r(TNe," (ELECTRA model)"),TNe.forEach(t),k5r=i(be),DM=n(be,"LI",{});var MNe=s(DM);bTe=n(MNe,"STRONG",{});var pyt=s(bTe);S5r=r(pyt,"flaubert"),pyt.forEach(t),R5r=r(MNe," \u2014 "),RJ=n(MNe,"A",{href:!0});var uyt=s(RJ);P5r=r(uyt,"TFFlaubertForMultipleChoice"),uyt.forEach(t),B5r=r(MNe," (FlauBERT model)"),MNe.forEach(t),I5r=i(be),GM=n(be,"LI",{});var ENe=s(GM);vTe=n(ENe,"STRONG",{});var _yt=s(vTe);N5r=r(_yt,"funnel"),_yt.forEach(t),q5r=r(ENe," \u2014 "),PJ=n(ENe,"A",{href:!0});var byt=s(PJ);j5r=r(byt,"TFFunnelForMultipleChoice"),byt.forEach(t),D5r=r(ENe," (Funnel Transformer model)"),ENe.forEach(t),G5r=i(be),OM=n(be,"LI",{});var CNe=s(OM);FTe=n(CNe,"STRONG",{});var vyt=s(FTe);O5r=r(vyt,"longformer"),vyt.forEach(t),V5r=r(CNe," \u2014 "),BJ=n(CNe,"A",{href:!0});var Fyt=s(BJ);X5r=r(Fyt,"TFLongformerForMultipleChoice"),Fyt.forEach(t),z5r=r(CNe," (Longformer model)"),CNe.forEach(t),W5r=i(be),VM=n(be,"LI",{});var wNe=s(VM);TTe=n(wNe,"STRONG",{});var Tyt=s(TTe);Q5r=r(Tyt,"mobilebert"),Tyt.forEach(t),H5r=r(wNe," \u2014 "),IJ=n(wNe,"A",{href:!0});var Myt=s(IJ);U5r=r(Myt,"TFMobileBertForMultipleChoice"),Myt.forEach(t),J5r=r(wNe," (MobileBERT model)"),wNe.forEach(t),Y5r=i(be),XM=n(be,"LI",{});var ANe=s(XM);MTe=n(ANe,"STRONG",{});var Eyt=s(MTe);K5r=r(Eyt,"mpnet"),Eyt.forEach(t),Z5r=r(ANe," \u2014 "),NJ=n(ANe,"A",{href:!0});var Cyt=s(NJ);e0r=r(Cyt,"TFMPNetForMultipleChoice"),Cyt.forEach(t),o0r=r(ANe," (MPNet model)"),ANe.forEach(t),r0r=i(be),zM=n(be,"LI",{});var yNe=s(zM);ETe=n(yNe,"STRONG",{});var wyt=s(ETe);t0r=r(wyt,"rembert"),wyt.forEach(t),a0r=r(yNe," \u2014 "),qJ=n(yNe,"A",{href:!0});var Ayt=s(qJ);n0r=r(Ayt,"TFRemBertForMultipleChoice"),Ayt.forEach(t),s0r=r(yNe," (RemBERT model)"),yNe.forEach(t),l0r=i(be),WM=n(be,"LI",{});var LNe=s(WM);CTe=n(LNe,"STRONG",{});var yyt=s(CTe);i0r=r(yyt,"roberta"),yyt.forEach(t),d0r=r(LNe," \u2014 "),jJ=n(LNe,"A",{href:!0});var Lyt=s(jJ);c0r=r(Lyt,"TFRobertaForMultipleChoice"),Lyt.forEach(t),f0r=r(LNe," (RoBERTa model)"),LNe.forEach(t),m0r=i(be),QM=n(be,"LI",{});var xNe=s(QM);wTe=n(xNe,"STRONG",{});var xyt=s(wTe);g0r=r(xyt,"roformer"),xyt.forEach(t),h0r=r(xNe," \u2014 "),DJ=n(xNe,"A",{href:!0});var $yt=s(DJ);p0r=r($yt,"TFRoFormerForMultipleChoice"),$yt.forEach(t),u0r=r(xNe," (RoFormer model)"),xNe.forEach(t),_0r=i(be),HM=n(be,"LI",{});var $Ne=s(HM);ATe=n($Ne,"STRONG",{});var kyt=s(ATe);b0r=r(kyt,"xlm"),kyt.forEach(t),v0r=r($Ne," \u2014 "),GJ=n($Ne,"A",{href:!0});var Syt=s(GJ);F0r=r(Syt,"TFXLMForMultipleChoice"),Syt.forEach(t),T0r=r($Ne," (XLM model)"),$Ne.forEach(t),M0r=i(be),UM=n(be,"LI",{});var kNe=s(UM);yTe=n(kNe,"STRONG",{});var Ryt=s(yTe);E0r=r(Ryt,"xlm-roberta"),Ryt.forEach(t),C0r=r(kNe," \u2014 "),OJ=n(kNe,"A",{href:!0});var Pyt=s(OJ);w0r=r(Pyt,"TFXLMRobertaForMultipleChoice"),Pyt.forEach(t),A0r=r(kNe," (XLM-RoBERTa model)"),kNe.forEach(t),y0r=i(be),JM=n(be,"LI",{});var SNe=s(JM);LTe=n(SNe,"STRONG",{});var Byt=s(LTe);L0r=r(Byt,"xlnet"),Byt.forEach(t),x0r=r(SNe," \u2014 "),VJ=n(SNe,"A",{href:!0});var Iyt=s(VJ);$0r=r(Iyt,"TFXLNetForMultipleChoice"),Iyt.forEach(t),k0r=r(SNe," (XLNet model)"),SNe.forEach(t),be.forEach(t),S0r=i(Il),T(YM.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),WGe=i(f),Mc=n(f,"H2",{class:!0});var eXe=s(Mc);KM=n(eXe,"A",{id:!0,class:!0,href:!0});var Nyt=s(KM);xTe=n(Nyt,"SPAN",{});var qyt=s(xTe);T(q8.$$.fragment,qyt),qyt.forEach(t),Nyt.forEach(t),R0r=i(eXe),$Te=n(eXe,"SPAN",{});var jyt=s($Te);P0r=r(jyt,"TFAutoModelForNextSentencePrediction"),jyt.forEach(t),eXe.forEach(t),QGe=i(f),lr=n(f,"DIV",{class:!0});var Nl=s(lr);T(j8.$$.fragment,Nl),B0r=i(Nl),Ec=n(Nl,"P",{});var Woe=s(Ec);I0r=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),XJ=n(Woe,"A",{href:!0});var Dyt=s(XJ);N0r=r(Dyt,"from_pretrained()"),Dyt.forEach(t),q0r=r(Woe," class method or the "),zJ=n(Woe,"A",{href:!0});var Gyt=s(zJ);j0r=r(Gyt,"from_config()"),Gyt.forEach(t),D0r=r(Woe,` class
method.`),Woe.forEach(t),G0r=i(Nl),D8=n(Nl,"P",{});var oXe=s(D8);O0r=r(oXe,"This class cannot be instantiated directly using "),kTe=n(oXe,"CODE",{});var Oyt=s(kTe);V0r=r(Oyt,"__init__()"),Oyt.forEach(t),X0r=r(oXe," (throws an error)."),oXe.forEach(t),z0r=i(Nl),qt=n(Nl,"DIV",{class:!0});var Aw=s(qt);T(G8.$$.fragment,Aw),W0r=i(Aw),STe=n(Aw,"P",{});var Vyt=s(STe);Q0r=r(Vyt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Vyt.forEach(t),H0r=i(Aw),Cc=n(Aw,"P",{});var Qoe=s(Cc);U0r=r(Qoe,`Note:
Loading a model from its configuration file does `),RTe=n(Qoe,"STRONG",{});var Xyt=s(RTe);J0r=r(Xyt,"not"),Xyt.forEach(t),Y0r=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),WJ=n(Qoe,"A",{href:!0});var zyt=s(WJ);K0r=r(zyt,"from_pretrained()"),zyt.forEach(t),Z0r=r(Qoe," to load the model weights."),Qoe.forEach(t),ewr=i(Aw),T(ZM.$$.fragment,Aw),Aw.forEach(t),owr=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(O8.$$.fragment,ql),rwr=i(ql),PTe=n(ql,"P",{});var Wyt=s(PTe);twr=r(Wyt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Wyt.forEach(t),awr=i(ql),gn=n(ql,"P",{});var yw=s(gn);nwr=r(yw,"The model class to instantiate is selected based on the "),BTe=n(yw,"CODE",{});var Qyt=s(BTe);swr=r(Qyt,"model_type"),Qyt.forEach(t),lwr=r(yw,` property of the config object (either
passed as an argument or loaded from `),ITe=n(yw,"CODE",{});var Hyt=s(ITe);iwr=r(Hyt,"pretrained_model_name_or_path"),Hyt.forEach(t),dwr=r(yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=n(yw,"CODE",{});var Uyt=s(NTe);cwr=r(Uyt,"pretrained_model_name_or_path"),Uyt.forEach(t),fwr=r(yw,":"),yw.forEach(t),mwr=i(ql),V8=n(ql,"UL",{});var rXe=s(V8);e4=n(rXe,"LI",{});var RNe=s(e4);qTe=n(RNe,"STRONG",{});var Jyt=s(qTe);gwr=r(Jyt,"bert"),Jyt.forEach(t),hwr=r(RNe," \u2014 "),QJ=n(RNe,"A",{href:!0});var Yyt=s(QJ);pwr=r(Yyt,"TFBertForNextSentencePrediction"),Yyt.forEach(t),uwr=r(RNe," (BERT model)"),RNe.forEach(t),_wr=i(rXe),o4=n(rXe,"LI",{});var PNe=s(o4);jTe=n(PNe,"STRONG",{});var Kyt=s(jTe);bwr=r(Kyt,"mobilebert"),Kyt.forEach(t),vwr=r(PNe," \u2014 "),HJ=n(PNe,"A",{href:!0});var Zyt=s(HJ);Fwr=r(Zyt,"TFMobileBertForNextSentencePrediction"),Zyt.forEach(t),Twr=r(PNe," (MobileBERT model)"),PNe.forEach(t),rXe.forEach(t),Mwr=i(ql),T(r4.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),HGe=i(f),wc=n(f,"H2",{class:!0});var tXe=s(wc);t4=n(tXe,"A",{id:!0,class:!0,href:!0});var eLt=s(t4);DTe=n(eLt,"SPAN",{});var oLt=s(DTe);T(X8.$$.fragment,oLt),oLt.forEach(t),eLt.forEach(t),Ewr=i(tXe),GTe=n(tXe,"SPAN",{});var rLt=s(GTe);Cwr=r(rLt,"TFAutoModelForTableQuestionAnswering"),rLt.forEach(t),tXe.forEach(t),UGe=i(f),ir=n(f,"DIV",{class:!0});var jl=s(ir);T(z8.$$.fragment,jl),wwr=i(jl),Ac=n(jl,"P",{});var Hoe=s(Ac);Awr=r(Hoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),UJ=n(Hoe,"A",{href:!0});var tLt=s(UJ);ywr=r(tLt,"from_pretrained()"),tLt.forEach(t),Lwr=r(Hoe," class method or the "),JJ=n(Hoe,"A",{href:!0});var aLt=s(JJ);xwr=r(aLt,"from_config()"),aLt.forEach(t),$wr=r(Hoe,` class
method.`),Hoe.forEach(t),kwr=i(jl),W8=n(jl,"P",{});var aXe=s(W8);Swr=r(aXe,"This class cannot be instantiated directly using "),OTe=n(aXe,"CODE",{});var nLt=s(OTe);Rwr=r(nLt,"__init__()"),nLt.forEach(t),Pwr=r(aXe," (throws an error)."),aXe.forEach(t),Bwr=i(jl),jt=n(jl,"DIV",{class:!0});var Lw=s(jt);T(Q8.$$.fragment,Lw),Iwr=i(Lw),VTe=n(Lw,"P",{});var sLt=s(VTe);Nwr=r(sLt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),sLt.forEach(t),qwr=i(Lw),yc=n(Lw,"P",{});var Uoe=s(yc);jwr=r(Uoe,`Note:
Loading a model from its configuration file does `),XTe=n(Uoe,"STRONG",{});var lLt=s(XTe);Dwr=r(lLt,"not"),lLt.forEach(t),Gwr=r(Uoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(Uoe,"A",{href:!0});var iLt=s(YJ);Owr=r(iLt,"from_pretrained()"),iLt.forEach(t),Vwr=r(Uoe," to load the model weights."),Uoe.forEach(t),Xwr=i(Lw),T(a4.$$.fragment,Lw),Lw.forEach(t),zwr=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(H8.$$.fragment,Dl),Wwr=i(Dl),zTe=n(Dl,"P",{});var dLt=s(zTe);Qwr=r(dLt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),dLt.forEach(t),Hwr=i(Dl),hn=n(Dl,"P",{});var xw=s(hn);Uwr=r(xw,"The model class to instantiate is selected based on the "),WTe=n(xw,"CODE",{});var cLt=s(WTe);Jwr=r(cLt,"model_type"),cLt.forEach(t),Ywr=r(xw,` property of the config object (either
passed as an argument or loaded from `),QTe=n(xw,"CODE",{});var fLt=s(QTe);Kwr=r(fLt,"pretrained_model_name_or_path"),fLt.forEach(t),Zwr=r(xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HTe=n(xw,"CODE",{});var mLt=s(HTe);eAr=r(mLt,"pretrained_model_name_or_path"),mLt.forEach(t),oAr=r(xw,":"),xw.forEach(t),rAr=i(Dl),UTe=n(Dl,"UL",{});var gLt=s(UTe);n4=n(gLt,"LI",{});var BNe=s(n4);JTe=n(BNe,"STRONG",{});var hLt=s(JTe);tAr=r(hLt,"tapas"),hLt.forEach(t),aAr=r(BNe," \u2014 "),KJ=n(BNe,"A",{href:!0});var pLt=s(KJ);nAr=r(pLt,"TFTapasForQuestionAnswering"),pLt.forEach(t),sAr=r(BNe," (TAPAS model)"),BNe.forEach(t),gLt.forEach(t),lAr=i(Dl),T(s4.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),JGe=i(f),Lc=n(f,"H2",{class:!0});var nXe=s(Lc);l4=n(nXe,"A",{id:!0,class:!0,href:!0});var uLt=s(l4);YTe=n(uLt,"SPAN",{});var _Lt=s(YTe);T(U8.$$.fragment,_Lt),_Lt.forEach(t),uLt.forEach(t),iAr=i(nXe),KTe=n(nXe,"SPAN",{});var bLt=s(KTe);dAr=r(bLt,"TFAutoModelForTokenClassification"),bLt.forEach(t),nXe.forEach(t),YGe=i(f),dr=n(f,"DIV",{class:!0});var Gl=s(dr);T(J8.$$.fragment,Gl),cAr=i(Gl),xc=n(Gl,"P",{});var Joe=s(xc);fAr=r(Joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ZJ=n(Joe,"A",{href:!0});var vLt=s(ZJ);mAr=r(vLt,"from_pretrained()"),vLt.forEach(t),gAr=r(Joe," class method or the "),eY=n(Joe,"A",{href:!0});var FLt=s(eY);hAr=r(FLt,"from_config()"),FLt.forEach(t),pAr=r(Joe,` class
method.`),Joe.forEach(t),uAr=i(Gl),Y8=n(Gl,"P",{});var sXe=s(Y8);_Ar=r(sXe,"This class cannot be instantiated directly using "),ZTe=n(sXe,"CODE",{});var TLt=s(ZTe);bAr=r(TLt,"__init__()"),TLt.forEach(t),vAr=r(sXe," (throws an error)."),sXe.forEach(t),FAr=i(Gl),Dt=n(Gl,"DIV",{class:!0});var $w=s(Dt);T(K8.$$.fragment,$w),TAr=i($w),e7e=n($w,"P",{});var MLt=s(e7e);MAr=r(MLt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),MLt.forEach(t),EAr=i($w),$c=n($w,"P",{});var Yoe=s($c);CAr=r(Yoe,`Note:
Loading a model from its configuration file does `),o7e=n(Yoe,"STRONG",{});var ELt=s(o7e);wAr=r(ELt,"not"),ELt.forEach(t),AAr=r(Yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),oY=n(Yoe,"A",{href:!0});var CLt=s(oY);yAr=r(CLt,"from_pretrained()"),CLt.forEach(t),LAr=r(Yoe," to load the model weights."),Yoe.forEach(t),xAr=i($w),T(i4.$$.fragment,$w),$w.forEach(t),$Ar=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(Z8.$$.fragment,Ol),kAr=i(Ol),r7e=n(Ol,"P",{});var wLt=s(r7e);SAr=r(wLt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wLt.forEach(t),RAr=i(Ol),pn=n(Ol,"P",{});var kw=s(pn);PAr=r(kw,"The model class to instantiate is selected based on the "),t7e=n(kw,"CODE",{});var ALt=s(t7e);BAr=r(ALt,"model_type"),ALt.forEach(t),IAr=r(kw,` property of the config object (either
passed as an argument or loaded from `),a7e=n(kw,"CODE",{});var yLt=s(a7e);NAr=r(yLt,"pretrained_model_name_or_path"),yLt.forEach(t),qAr=r(kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(kw,"CODE",{});var LLt=s(n7e);jAr=r(LLt,"pretrained_model_name_or_path"),LLt.forEach(t),DAr=r(kw,":"),kw.forEach(t),GAr=i(Ol),de=n(Ol,"UL",{});var me=s(de);d4=n(me,"LI",{});var INe=s(d4);s7e=n(INe,"STRONG",{});var xLt=s(s7e);OAr=r(xLt,"albert"),xLt.forEach(t),VAr=r(INe," \u2014 "),rY=n(INe,"A",{href:!0});var $Lt=s(rY);XAr=r($Lt,"TFAlbertForTokenClassification"),$Lt.forEach(t),zAr=r(INe," (ALBERT model)"),INe.forEach(t),WAr=i(me),c4=n(me,"LI",{});var NNe=s(c4);l7e=n(NNe,"STRONG",{});var kLt=s(l7e);QAr=r(kLt,"bert"),kLt.forEach(t),HAr=r(NNe," \u2014 "),tY=n(NNe,"A",{href:!0});var SLt=s(tY);UAr=r(SLt,"TFBertForTokenClassification"),SLt.forEach(t),JAr=r(NNe," (BERT model)"),NNe.forEach(t),YAr=i(me),f4=n(me,"LI",{});var qNe=s(f4);i7e=n(qNe,"STRONG",{});var RLt=s(i7e);KAr=r(RLt,"camembert"),RLt.forEach(t),ZAr=r(qNe," \u2014 "),aY=n(qNe,"A",{href:!0});var PLt=s(aY);eyr=r(PLt,"TFCamembertForTokenClassification"),PLt.forEach(t),oyr=r(qNe," (CamemBERT model)"),qNe.forEach(t),ryr=i(me),m4=n(me,"LI",{});var jNe=s(m4);d7e=n(jNe,"STRONG",{});var BLt=s(d7e);tyr=r(BLt,"convbert"),BLt.forEach(t),ayr=r(jNe," \u2014 "),nY=n(jNe,"A",{href:!0});var ILt=s(nY);nyr=r(ILt,"TFConvBertForTokenClassification"),ILt.forEach(t),syr=r(jNe," (ConvBERT model)"),jNe.forEach(t),lyr=i(me),g4=n(me,"LI",{});var DNe=s(g4);c7e=n(DNe,"STRONG",{});var NLt=s(c7e);iyr=r(NLt,"deberta"),NLt.forEach(t),dyr=r(DNe," \u2014 "),sY=n(DNe,"A",{href:!0});var qLt=s(sY);cyr=r(qLt,"TFDebertaForTokenClassification"),qLt.forEach(t),fyr=r(DNe," (DeBERTa model)"),DNe.forEach(t),myr=i(me),h4=n(me,"LI",{});var GNe=s(h4);f7e=n(GNe,"STRONG",{});var jLt=s(f7e);gyr=r(jLt,"deberta-v2"),jLt.forEach(t),hyr=r(GNe," \u2014 "),lY=n(GNe,"A",{href:!0});var DLt=s(lY);pyr=r(DLt,"TFDebertaV2ForTokenClassification"),DLt.forEach(t),uyr=r(GNe," (DeBERTa-v2 model)"),GNe.forEach(t),_yr=i(me),p4=n(me,"LI",{});var ONe=s(p4);m7e=n(ONe,"STRONG",{});var GLt=s(m7e);byr=r(GLt,"distilbert"),GLt.forEach(t),vyr=r(ONe," \u2014 "),iY=n(ONe,"A",{href:!0});var OLt=s(iY);Fyr=r(OLt,"TFDistilBertForTokenClassification"),OLt.forEach(t),Tyr=r(ONe," (DistilBERT model)"),ONe.forEach(t),Myr=i(me),u4=n(me,"LI",{});var VNe=s(u4);g7e=n(VNe,"STRONG",{});var VLt=s(g7e);Eyr=r(VLt,"electra"),VLt.forEach(t),Cyr=r(VNe," \u2014 "),dY=n(VNe,"A",{href:!0});var XLt=s(dY);wyr=r(XLt,"TFElectraForTokenClassification"),XLt.forEach(t),Ayr=r(VNe," (ELECTRA model)"),VNe.forEach(t),yyr=i(me),_4=n(me,"LI",{});var XNe=s(_4);h7e=n(XNe,"STRONG",{});var zLt=s(h7e);Lyr=r(zLt,"flaubert"),zLt.forEach(t),xyr=r(XNe," \u2014 "),cY=n(XNe,"A",{href:!0});var WLt=s(cY);$yr=r(WLt,"TFFlaubertForTokenClassification"),WLt.forEach(t),kyr=r(XNe," (FlauBERT model)"),XNe.forEach(t),Syr=i(me),b4=n(me,"LI",{});var zNe=s(b4);p7e=n(zNe,"STRONG",{});var QLt=s(p7e);Ryr=r(QLt,"funnel"),QLt.forEach(t),Pyr=r(zNe," \u2014 "),fY=n(zNe,"A",{href:!0});var HLt=s(fY);Byr=r(HLt,"TFFunnelForTokenClassification"),HLt.forEach(t),Iyr=r(zNe," (Funnel Transformer model)"),zNe.forEach(t),Nyr=i(me),v4=n(me,"LI",{});var WNe=s(v4);u7e=n(WNe,"STRONG",{});var ULt=s(u7e);qyr=r(ULt,"layoutlm"),ULt.forEach(t),jyr=r(WNe," \u2014 "),mY=n(WNe,"A",{href:!0});var JLt=s(mY);Dyr=r(JLt,"TFLayoutLMForTokenClassification"),JLt.forEach(t),Gyr=r(WNe," (LayoutLM model)"),WNe.forEach(t),Oyr=i(me),F4=n(me,"LI",{});var QNe=s(F4);_7e=n(QNe,"STRONG",{});var YLt=s(_7e);Vyr=r(YLt,"longformer"),YLt.forEach(t),Xyr=r(QNe," \u2014 "),gY=n(QNe,"A",{href:!0});var KLt=s(gY);zyr=r(KLt,"TFLongformerForTokenClassification"),KLt.forEach(t),Wyr=r(QNe," (Longformer model)"),QNe.forEach(t),Qyr=i(me),T4=n(me,"LI",{});var HNe=s(T4);b7e=n(HNe,"STRONG",{});var ZLt=s(b7e);Hyr=r(ZLt,"mobilebert"),ZLt.forEach(t),Uyr=r(HNe," \u2014 "),hY=n(HNe,"A",{href:!0});var e8t=s(hY);Jyr=r(e8t,"TFMobileBertForTokenClassification"),e8t.forEach(t),Yyr=r(HNe," (MobileBERT model)"),HNe.forEach(t),Kyr=i(me),M4=n(me,"LI",{});var UNe=s(M4);v7e=n(UNe,"STRONG",{});var o8t=s(v7e);Zyr=r(o8t,"mpnet"),o8t.forEach(t),eLr=r(UNe," \u2014 "),pY=n(UNe,"A",{href:!0});var r8t=s(pY);oLr=r(r8t,"TFMPNetForTokenClassification"),r8t.forEach(t),rLr=r(UNe," (MPNet model)"),UNe.forEach(t),tLr=i(me),E4=n(me,"LI",{});var JNe=s(E4);F7e=n(JNe,"STRONG",{});var t8t=s(F7e);aLr=r(t8t,"rembert"),t8t.forEach(t),nLr=r(JNe," \u2014 "),uY=n(JNe,"A",{href:!0});var a8t=s(uY);sLr=r(a8t,"TFRemBertForTokenClassification"),a8t.forEach(t),lLr=r(JNe," (RemBERT model)"),JNe.forEach(t),iLr=i(me),C4=n(me,"LI",{});var YNe=s(C4);T7e=n(YNe,"STRONG",{});var n8t=s(T7e);dLr=r(n8t,"roberta"),n8t.forEach(t),cLr=r(YNe," \u2014 "),_Y=n(YNe,"A",{href:!0});var s8t=s(_Y);fLr=r(s8t,"TFRobertaForTokenClassification"),s8t.forEach(t),mLr=r(YNe," (RoBERTa model)"),YNe.forEach(t),gLr=i(me),w4=n(me,"LI",{});var KNe=s(w4);M7e=n(KNe,"STRONG",{});var l8t=s(M7e);hLr=r(l8t,"roformer"),l8t.forEach(t),pLr=r(KNe," \u2014 "),bY=n(KNe,"A",{href:!0});var i8t=s(bY);uLr=r(i8t,"TFRoFormerForTokenClassification"),i8t.forEach(t),_Lr=r(KNe," (RoFormer model)"),KNe.forEach(t),bLr=i(me),A4=n(me,"LI",{});var ZNe=s(A4);E7e=n(ZNe,"STRONG",{});var d8t=s(E7e);vLr=r(d8t,"xlm"),d8t.forEach(t),FLr=r(ZNe," \u2014 "),vY=n(ZNe,"A",{href:!0});var c8t=s(vY);TLr=r(c8t,"TFXLMForTokenClassification"),c8t.forEach(t),MLr=r(ZNe," (XLM model)"),ZNe.forEach(t),ELr=i(me),y4=n(me,"LI",{});var eqe=s(y4);C7e=n(eqe,"STRONG",{});var f8t=s(C7e);CLr=r(f8t,"xlm-roberta"),f8t.forEach(t),wLr=r(eqe," \u2014 "),FY=n(eqe,"A",{href:!0});var m8t=s(FY);ALr=r(m8t,"TFXLMRobertaForTokenClassification"),m8t.forEach(t),yLr=r(eqe," (XLM-RoBERTa model)"),eqe.forEach(t),LLr=i(me),L4=n(me,"LI",{});var oqe=s(L4);w7e=n(oqe,"STRONG",{});var g8t=s(w7e);xLr=r(g8t,"xlnet"),g8t.forEach(t),$Lr=r(oqe," \u2014 "),TY=n(oqe,"A",{href:!0});var h8t=s(TY);kLr=r(h8t,"TFXLNetForTokenClassification"),h8t.forEach(t),SLr=r(oqe," (XLNet model)"),oqe.forEach(t),me.forEach(t),RLr=i(Ol),T(x4.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),KGe=i(f),kc=n(f,"H2",{class:!0});var lXe=s(kc);$4=n(lXe,"A",{id:!0,class:!0,href:!0});var p8t=s($4);A7e=n(p8t,"SPAN",{});var u8t=s(A7e);T(ex.$$.fragment,u8t),u8t.forEach(t),p8t.forEach(t),PLr=i(lXe),y7e=n(lXe,"SPAN",{});var _8t=s(y7e);BLr=r(_8t,"TFAutoModelForQuestionAnswering"),_8t.forEach(t),lXe.forEach(t),ZGe=i(f),cr=n(f,"DIV",{class:!0});var Vl=s(cr);T(ox.$$.fragment,Vl),ILr=i(Vl),Sc=n(Vl,"P",{});var Koe=s(Sc);NLr=r(Koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),MY=n(Koe,"A",{href:!0});var b8t=s(MY);qLr=r(b8t,"from_pretrained()"),b8t.forEach(t),jLr=r(Koe," class method or the "),EY=n(Koe,"A",{href:!0});var v8t=s(EY);DLr=r(v8t,"from_config()"),v8t.forEach(t),GLr=r(Koe,` class
method.`),Koe.forEach(t),OLr=i(Vl),rx=n(Vl,"P",{});var iXe=s(rx);VLr=r(iXe,"This class cannot be instantiated directly using "),L7e=n(iXe,"CODE",{});var F8t=s(L7e);XLr=r(F8t,"__init__()"),F8t.forEach(t),zLr=r(iXe," (throws an error)."),iXe.forEach(t),WLr=i(Vl),Gt=n(Vl,"DIV",{class:!0});var Sw=s(Gt);T(tx.$$.fragment,Sw),QLr=i(Sw),x7e=n(Sw,"P",{});var T8t=s(x7e);HLr=r(T8t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),T8t.forEach(t),ULr=i(Sw),Rc=n(Sw,"P",{});var Zoe=s(Rc);JLr=r(Zoe,`Note:
Loading a model from its configuration file does `),$7e=n(Zoe,"STRONG",{});var M8t=s($7e);YLr=r(M8t,"not"),M8t.forEach(t),KLr=r(Zoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),CY=n(Zoe,"A",{href:!0});var E8t=s(CY);ZLr=r(E8t,"from_pretrained()"),E8t.forEach(t),e8r=r(Zoe," to load the model weights."),Zoe.forEach(t),o8r=i(Sw),T(k4.$$.fragment,Sw),Sw.forEach(t),r8r=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(ax.$$.fragment,Xl),t8r=i(Xl),k7e=n(Xl,"P",{});var C8t=s(k7e);a8r=r(C8t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),C8t.forEach(t),n8r=i(Xl),un=n(Xl,"P",{});var Rw=s(un);s8r=r(Rw,"The model class to instantiate is selected based on the "),S7e=n(Rw,"CODE",{});var w8t=s(S7e);l8r=r(w8t,"model_type"),w8t.forEach(t),i8r=r(Rw,` property of the config object (either
passed as an argument or loaded from `),R7e=n(Rw,"CODE",{});var A8t=s(R7e);d8r=r(A8t,"pretrained_model_name_or_path"),A8t.forEach(t),c8r=r(Rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P7e=n(Rw,"CODE",{});var y8t=s(P7e);f8r=r(y8t,"pretrained_model_name_or_path"),y8t.forEach(t),m8r=r(Rw,":"),Rw.forEach(t),g8r=i(Xl),ce=n(Xl,"UL",{});var ge=s(ce);S4=n(ge,"LI",{});var rqe=s(S4);B7e=n(rqe,"STRONG",{});var L8t=s(B7e);h8r=r(L8t,"albert"),L8t.forEach(t),p8r=r(rqe," \u2014 "),wY=n(rqe,"A",{href:!0});var x8t=s(wY);u8r=r(x8t,"TFAlbertForQuestionAnswering"),x8t.forEach(t),_8r=r(rqe," (ALBERT model)"),rqe.forEach(t),b8r=i(ge),R4=n(ge,"LI",{});var tqe=s(R4);I7e=n(tqe,"STRONG",{});var $8t=s(I7e);v8r=r($8t,"bert"),$8t.forEach(t),F8r=r(tqe," \u2014 "),AY=n(tqe,"A",{href:!0});var k8t=s(AY);T8r=r(k8t,"TFBertForQuestionAnswering"),k8t.forEach(t),M8r=r(tqe," (BERT model)"),tqe.forEach(t),E8r=i(ge),P4=n(ge,"LI",{});var aqe=s(P4);N7e=n(aqe,"STRONG",{});var S8t=s(N7e);C8r=r(S8t,"camembert"),S8t.forEach(t),w8r=r(aqe," \u2014 "),yY=n(aqe,"A",{href:!0});var R8t=s(yY);A8r=r(R8t,"TFCamembertForQuestionAnswering"),R8t.forEach(t),y8r=r(aqe," (CamemBERT model)"),aqe.forEach(t),L8r=i(ge),B4=n(ge,"LI",{});var nqe=s(B4);q7e=n(nqe,"STRONG",{});var P8t=s(q7e);x8r=r(P8t,"convbert"),P8t.forEach(t),$8r=r(nqe," \u2014 "),LY=n(nqe,"A",{href:!0});var B8t=s(LY);k8r=r(B8t,"TFConvBertForQuestionAnswering"),B8t.forEach(t),S8r=r(nqe," (ConvBERT model)"),nqe.forEach(t),R8r=i(ge),I4=n(ge,"LI",{});var sqe=s(I4);j7e=n(sqe,"STRONG",{});var I8t=s(j7e);P8r=r(I8t,"deberta"),I8t.forEach(t),B8r=r(sqe," \u2014 "),xY=n(sqe,"A",{href:!0});var N8t=s(xY);I8r=r(N8t,"TFDebertaForQuestionAnswering"),N8t.forEach(t),N8r=r(sqe," (DeBERTa model)"),sqe.forEach(t),q8r=i(ge),N4=n(ge,"LI",{});var lqe=s(N4);D7e=n(lqe,"STRONG",{});var q8t=s(D7e);j8r=r(q8t,"deberta-v2"),q8t.forEach(t),D8r=r(lqe," \u2014 "),$Y=n(lqe,"A",{href:!0});var j8t=s($Y);G8r=r(j8t,"TFDebertaV2ForQuestionAnswering"),j8t.forEach(t),O8r=r(lqe," (DeBERTa-v2 model)"),lqe.forEach(t),V8r=i(ge),q4=n(ge,"LI",{});var iqe=s(q4);G7e=n(iqe,"STRONG",{});var D8t=s(G7e);X8r=r(D8t,"distilbert"),D8t.forEach(t),z8r=r(iqe," \u2014 "),kY=n(iqe,"A",{href:!0});var G8t=s(kY);W8r=r(G8t,"TFDistilBertForQuestionAnswering"),G8t.forEach(t),Q8r=r(iqe," (DistilBERT model)"),iqe.forEach(t),H8r=i(ge),j4=n(ge,"LI",{});var dqe=s(j4);O7e=n(dqe,"STRONG",{});var O8t=s(O7e);U8r=r(O8t,"electra"),O8t.forEach(t),J8r=r(dqe," \u2014 "),SY=n(dqe,"A",{href:!0});var V8t=s(SY);Y8r=r(V8t,"TFElectraForQuestionAnswering"),V8t.forEach(t),K8r=r(dqe," (ELECTRA model)"),dqe.forEach(t),Z8r=i(ge),D4=n(ge,"LI",{});var cqe=s(D4);V7e=n(cqe,"STRONG",{});var X8t=s(V7e);exr=r(X8t,"flaubert"),X8t.forEach(t),oxr=r(cqe," \u2014 "),RY=n(cqe,"A",{href:!0});var z8t=s(RY);rxr=r(z8t,"TFFlaubertForQuestionAnsweringSimple"),z8t.forEach(t),txr=r(cqe," (FlauBERT model)"),cqe.forEach(t),axr=i(ge),G4=n(ge,"LI",{});var fqe=s(G4);X7e=n(fqe,"STRONG",{});var W8t=s(X7e);nxr=r(W8t,"funnel"),W8t.forEach(t),sxr=r(fqe," \u2014 "),PY=n(fqe,"A",{href:!0});var Q8t=s(PY);lxr=r(Q8t,"TFFunnelForQuestionAnswering"),Q8t.forEach(t),ixr=r(fqe," (Funnel Transformer model)"),fqe.forEach(t),dxr=i(ge),O4=n(ge,"LI",{});var mqe=s(O4);z7e=n(mqe,"STRONG",{});var H8t=s(z7e);cxr=r(H8t,"gptj"),H8t.forEach(t),fxr=r(mqe," \u2014 "),BY=n(mqe,"A",{href:!0});var U8t=s(BY);mxr=r(U8t,"TFGPTJForQuestionAnswering"),U8t.forEach(t),gxr=r(mqe," (GPT-J model)"),mqe.forEach(t),hxr=i(ge),V4=n(ge,"LI",{});var gqe=s(V4);W7e=n(gqe,"STRONG",{});var J8t=s(W7e);pxr=r(J8t,"longformer"),J8t.forEach(t),uxr=r(gqe," \u2014 "),IY=n(gqe,"A",{href:!0});var Y8t=s(IY);_xr=r(Y8t,"TFLongformerForQuestionAnswering"),Y8t.forEach(t),bxr=r(gqe," (Longformer model)"),gqe.forEach(t),vxr=i(ge),X4=n(ge,"LI",{});var hqe=s(X4);Q7e=n(hqe,"STRONG",{});var K8t=s(Q7e);Fxr=r(K8t,"mobilebert"),K8t.forEach(t),Txr=r(hqe," \u2014 "),NY=n(hqe,"A",{href:!0});var Z8t=s(NY);Mxr=r(Z8t,"TFMobileBertForQuestionAnswering"),Z8t.forEach(t),Exr=r(hqe," (MobileBERT model)"),hqe.forEach(t),Cxr=i(ge),z4=n(ge,"LI",{});var pqe=s(z4);H7e=n(pqe,"STRONG",{});var ext=s(H7e);wxr=r(ext,"mpnet"),ext.forEach(t),Axr=r(pqe," \u2014 "),qY=n(pqe,"A",{href:!0});var oxt=s(qY);yxr=r(oxt,"TFMPNetForQuestionAnswering"),oxt.forEach(t),Lxr=r(pqe," (MPNet model)"),pqe.forEach(t),xxr=i(ge),W4=n(ge,"LI",{});var uqe=s(W4);U7e=n(uqe,"STRONG",{});var rxt=s(U7e);$xr=r(rxt,"rembert"),rxt.forEach(t),kxr=r(uqe," \u2014 "),jY=n(uqe,"A",{href:!0});var txt=s(jY);Sxr=r(txt,"TFRemBertForQuestionAnswering"),txt.forEach(t),Rxr=r(uqe," (RemBERT model)"),uqe.forEach(t),Pxr=i(ge),Q4=n(ge,"LI",{});var _qe=s(Q4);J7e=n(_qe,"STRONG",{});var axt=s(J7e);Bxr=r(axt,"roberta"),axt.forEach(t),Ixr=r(_qe," \u2014 "),DY=n(_qe,"A",{href:!0});var nxt=s(DY);Nxr=r(nxt,"TFRobertaForQuestionAnswering"),nxt.forEach(t),qxr=r(_qe," (RoBERTa model)"),_qe.forEach(t),jxr=i(ge),H4=n(ge,"LI",{});var bqe=s(H4);Y7e=n(bqe,"STRONG",{});var sxt=s(Y7e);Dxr=r(sxt,"roformer"),sxt.forEach(t),Gxr=r(bqe," \u2014 "),GY=n(bqe,"A",{href:!0});var lxt=s(GY);Oxr=r(lxt,"TFRoFormerForQuestionAnswering"),lxt.forEach(t),Vxr=r(bqe," (RoFormer model)"),bqe.forEach(t),Xxr=i(ge),U4=n(ge,"LI",{});var vqe=s(U4);K7e=n(vqe,"STRONG",{});var ixt=s(K7e);zxr=r(ixt,"xlm"),ixt.forEach(t),Wxr=r(vqe," \u2014 "),OY=n(vqe,"A",{href:!0});var dxt=s(OY);Qxr=r(dxt,"TFXLMForQuestionAnsweringSimple"),dxt.forEach(t),Hxr=r(vqe," (XLM model)"),vqe.forEach(t),Uxr=i(ge),J4=n(ge,"LI",{});var Fqe=s(J4);Z7e=n(Fqe,"STRONG",{});var cxt=s(Z7e);Jxr=r(cxt,"xlm-roberta"),cxt.forEach(t),Yxr=r(Fqe," \u2014 "),VY=n(Fqe,"A",{href:!0});var fxt=s(VY);Kxr=r(fxt,"TFXLMRobertaForQuestionAnswering"),fxt.forEach(t),Zxr=r(Fqe," (XLM-RoBERTa model)"),Fqe.forEach(t),e$r=i(ge),Y4=n(ge,"LI",{});var Tqe=s(Y4);e9e=n(Tqe,"STRONG",{});var mxt=s(e9e);o$r=r(mxt,"xlnet"),mxt.forEach(t),r$r=r(Tqe," \u2014 "),XY=n(Tqe,"A",{href:!0});var gxt=s(XY);t$r=r(gxt,"TFXLNetForQuestionAnsweringSimple"),gxt.forEach(t),a$r=r(Tqe," (XLNet model)"),Tqe.forEach(t),ge.forEach(t),n$r=i(Xl),T(K4.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),eOe=i(f),Pc=n(f,"H2",{class:!0});var dXe=s(Pc);Z4=n(dXe,"A",{id:!0,class:!0,href:!0});var hxt=s(Z4);o9e=n(hxt,"SPAN",{});var pxt=s(o9e);T(nx.$$.fragment,pxt),pxt.forEach(t),hxt.forEach(t),s$r=i(dXe),r9e=n(dXe,"SPAN",{});var uxt=s(r9e);l$r=r(uxt,"TFAutoModelForVision2Seq"),uxt.forEach(t),dXe.forEach(t),oOe=i(f),fr=n(f,"DIV",{class:!0});var zl=s(fr);T(sx.$$.fragment,zl),i$r=i(zl),Bc=n(zl,"P",{});var ere=s(Bc);d$r=r(ere,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),zY=n(ere,"A",{href:!0});var _xt=s(zY);c$r=r(_xt,"from_pretrained()"),_xt.forEach(t),f$r=r(ere," class method or the "),WY=n(ere,"A",{href:!0});var bxt=s(WY);m$r=r(bxt,"from_config()"),bxt.forEach(t),g$r=r(ere,` class
method.`),ere.forEach(t),h$r=i(zl),lx=n(zl,"P",{});var cXe=s(lx);p$r=r(cXe,"This class cannot be instantiated directly using "),t9e=n(cXe,"CODE",{});var vxt=s(t9e);u$r=r(vxt,"__init__()"),vxt.forEach(t),_$r=r(cXe," (throws an error)."),cXe.forEach(t),b$r=i(zl),Ot=n(zl,"DIV",{class:!0});var Pw=s(Ot);T(ix.$$.fragment,Pw),v$r=i(Pw),a9e=n(Pw,"P",{});var Fxt=s(a9e);F$r=r(Fxt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Fxt.forEach(t),T$r=i(Pw),Ic=n(Pw,"P",{});var ore=s(Ic);M$r=r(ore,`Note:
Loading a model from its configuration file does `),n9e=n(ore,"STRONG",{});var Txt=s(n9e);E$r=r(Txt,"not"),Txt.forEach(t),C$r=r(ore,` load the model weights. It only affects the
model\u2019s configuration. Use `),QY=n(ore,"A",{href:!0});var Mxt=s(QY);w$r=r(Mxt,"from_pretrained()"),Mxt.forEach(t),A$r=r(ore," to load the model weights."),ore.forEach(t),y$r=i(Pw),T(eE.$$.fragment,Pw),Pw.forEach(t),L$r=i(zl),jr=n(zl,"DIV",{class:!0});var Wl=s(jr);T(dx.$$.fragment,Wl),x$r=i(Wl),s9e=n(Wl,"P",{});var Ext=s(s9e);$$r=r(Ext,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ext.forEach(t),k$r=i(Wl),_n=n(Wl,"P",{});var Bw=s(_n);S$r=r(Bw,"The model class to instantiate is selected based on the "),l9e=n(Bw,"CODE",{});var Cxt=s(l9e);R$r=r(Cxt,"model_type"),Cxt.forEach(t),P$r=r(Bw,` property of the config object (either
passed as an argument or loaded from `),i9e=n(Bw,"CODE",{});var wxt=s(i9e);B$r=r(wxt,"pretrained_model_name_or_path"),wxt.forEach(t),I$r=r(Bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d9e=n(Bw,"CODE",{});var Axt=s(d9e);N$r=r(Axt,"pretrained_model_name_or_path"),Axt.forEach(t),q$r=r(Bw,":"),Bw.forEach(t),j$r=i(Wl),c9e=n(Wl,"UL",{});var yxt=s(c9e);oE=n(yxt,"LI",{});var Mqe=s(oE);f9e=n(Mqe,"STRONG",{});var Lxt=s(f9e);D$r=r(Lxt,"vision-encoder-decoder"),Lxt.forEach(t),G$r=r(Mqe," \u2014 "),HY=n(Mqe,"A",{href:!0});var xxt=s(HY);O$r=r(xxt,"TFVisionEncoderDecoderModel"),xxt.forEach(t),V$r=r(Mqe," (Vision Encoder decoder model)"),Mqe.forEach(t),yxt.forEach(t),X$r=i(Wl),T(rE.$$.fragment,Wl),Wl.forEach(t),zl.forEach(t),rOe=i(f),Nc=n(f,"H2",{class:!0});var fXe=s(Nc);tE=n(fXe,"A",{id:!0,class:!0,href:!0});var $xt=s(tE);m9e=n($xt,"SPAN",{});var kxt=s(m9e);T(cx.$$.fragment,kxt),kxt.forEach(t),$xt.forEach(t),z$r=i(fXe),g9e=n(fXe,"SPAN",{});var Sxt=s(g9e);W$r=r(Sxt,"TFAutoModelForSpeechSeq2Seq"),Sxt.forEach(t),fXe.forEach(t),tOe=i(f),mr=n(f,"DIV",{class:!0});var Ql=s(mr);T(fx.$$.fragment,Ql),Q$r=i(Ql),qc=n(Ql,"P",{});var rre=s(qc);H$r=r(rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),UY=n(rre,"A",{href:!0});var Rxt=s(UY);U$r=r(Rxt,"from_pretrained()"),Rxt.forEach(t),J$r=r(rre," class method or the "),JY=n(rre,"A",{href:!0});var Pxt=s(JY);Y$r=r(Pxt,"from_config()"),Pxt.forEach(t),K$r=r(rre,` class
method.`),rre.forEach(t),Z$r=i(Ql),mx=n(Ql,"P",{});var mXe=s(mx);ekr=r(mXe,"This class cannot be instantiated directly using "),h9e=n(mXe,"CODE",{});var Bxt=s(h9e);okr=r(Bxt,"__init__()"),Bxt.forEach(t),rkr=r(mXe," (throws an error)."),mXe.forEach(t),tkr=i(Ql),Vt=n(Ql,"DIV",{class:!0});var Iw=s(Vt);T(gx.$$.fragment,Iw),akr=i(Iw),p9e=n(Iw,"P",{});var Ixt=s(p9e);nkr=r(Ixt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ixt.forEach(t),skr=i(Iw),jc=n(Iw,"P",{});var tre=s(jc);lkr=r(tre,`Note:
Loading a model from its configuration file does `),u9e=n(tre,"STRONG",{});var Nxt=s(u9e);ikr=r(Nxt,"not"),Nxt.forEach(t),dkr=r(tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=n(tre,"A",{href:!0});var qxt=s(YY);ckr=r(qxt,"from_pretrained()"),qxt.forEach(t),fkr=r(tre," to load the model weights."),tre.forEach(t),mkr=i(Iw),T(aE.$$.fragment,Iw),Iw.forEach(t),gkr=i(Ql),Dr=n(Ql,"DIV",{class:!0});var Hl=s(Dr);T(hx.$$.fragment,Hl),hkr=i(Hl),_9e=n(Hl,"P",{});var jxt=s(_9e);pkr=r(jxt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),jxt.forEach(t),ukr=i(Hl),bn=n(Hl,"P",{});var Nw=s(bn);_kr=r(Nw,"The model class to instantiate is selected based on the "),b9e=n(Nw,"CODE",{});var Dxt=s(b9e);bkr=r(Dxt,"model_type"),Dxt.forEach(t),vkr=r(Nw,` property of the config object (either
passed as an argument or loaded from `),v9e=n(Nw,"CODE",{});var Gxt=s(v9e);Fkr=r(Gxt,"pretrained_model_name_or_path"),Gxt.forEach(t),Tkr=r(Nw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F9e=n(Nw,"CODE",{});var Oxt=s(F9e);Mkr=r(Oxt,"pretrained_model_name_or_path"),Oxt.forEach(t),Ekr=r(Nw,":"),Nw.forEach(t),Ckr=i(Hl),T9e=n(Hl,"UL",{});var Vxt=s(T9e);nE=n(Vxt,"LI",{});var Eqe=s(nE);M9e=n(Eqe,"STRONG",{});var Xxt=s(M9e);wkr=r(Xxt,"speech_to_text"),Xxt.forEach(t),Akr=r(Eqe," \u2014 "),KY=n(Eqe,"A",{href:!0});var zxt=s(KY);ykr=r(zxt,"TFSpeech2TextForConditionalGeneration"),zxt.forEach(t),Lkr=r(Eqe," (Speech2Text model)"),Eqe.forEach(t),Vxt.forEach(t),xkr=i(Hl),T(sE.$$.fragment,Hl),Hl.forEach(t),Ql.forEach(t),aOe=i(f),Dc=n(f,"H2",{class:!0});var gXe=s(Dc);lE=n(gXe,"A",{id:!0,class:!0,href:!0});var Wxt=s(lE);E9e=n(Wxt,"SPAN",{});var Qxt=s(E9e);T(px.$$.fragment,Qxt),Qxt.forEach(t),Wxt.forEach(t),$kr=i(gXe),C9e=n(gXe,"SPAN",{});var Hxt=s(C9e);kkr=r(Hxt,"FlaxAutoModel"),Hxt.forEach(t),gXe.forEach(t),nOe=i(f),gr=n(f,"DIV",{class:!0});var Ul=s(gr);T(ux.$$.fragment,Ul),Skr=i(Ul),Gc=n(Ul,"P",{});var are=s(Gc);Rkr=r(are,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ZY=n(are,"A",{href:!0});var Uxt=s(ZY);Pkr=r(Uxt,"from_pretrained()"),Uxt.forEach(t),Bkr=r(are," class method or the "),eK=n(are,"A",{href:!0});var Jxt=s(eK);Ikr=r(Jxt,"from_config()"),Jxt.forEach(t),Nkr=r(are,` class
method.`),are.forEach(t),qkr=i(Ul),_x=n(Ul,"P",{});var hXe=s(_x);jkr=r(hXe,"This class cannot be instantiated directly using "),w9e=n(hXe,"CODE",{});var Yxt=s(w9e);Dkr=r(Yxt,"__init__()"),Yxt.forEach(t),Gkr=r(hXe," (throws an error)."),hXe.forEach(t),Okr=i(Ul),Xt=n(Ul,"DIV",{class:!0});var qw=s(Xt);T(bx.$$.fragment,qw),Vkr=i(qw),A9e=n(qw,"P",{});var Kxt=s(A9e);Xkr=r(Kxt,"Instantiates one of the base model classes of the library from a configuration."),Kxt.forEach(t),zkr=i(qw),Oc=n(qw,"P",{});var nre=s(Oc);Wkr=r(nre,`Note:
Loading a model from its configuration file does `),y9e=n(nre,"STRONG",{});var Zxt=s(y9e);Qkr=r(Zxt,"not"),Zxt.forEach(t),Hkr=r(nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),oK=n(nre,"A",{href:!0});var e$t=s(oK);Ukr=r(e$t,"from_pretrained()"),e$t.forEach(t),Jkr=r(nre," to load the model weights."),nre.forEach(t),Ykr=i(qw),T(iE.$$.fragment,qw),qw.forEach(t),Kkr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(vx.$$.fragment,Jl),Zkr=i(Jl),L9e=n(Jl,"P",{});var o$t=s(L9e);eSr=r(o$t,"Instantiate one of the base model classes of the library from a pretrained model."),o$t.forEach(t),oSr=i(Jl),vn=n(Jl,"P",{});var jw=s(vn);rSr=r(jw,"The model class to instantiate is selected based on the "),x9e=n(jw,"CODE",{});var r$t=s(x9e);tSr=r(r$t,"model_type"),r$t.forEach(t),aSr=r(jw,` property of the config object (either
passed as an argument or loaded from `),$9e=n(jw,"CODE",{});var t$t=s($9e);nSr=r(t$t,"pretrained_model_name_or_path"),t$t.forEach(t),sSr=r(jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k9e=n(jw,"CODE",{});var a$t=s(k9e);lSr=r(a$t,"pretrained_model_name_or_path"),a$t.forEach(t),iSr=r(jw,":"),jw.forEach(t),dSr=i(Jl),te=n(Jl,"UL",{});var ne=s(te);dE=n(ne,"LI",{});var Cqe=s(dE);S9e=n(Cqe,"STRONG",{});var n$t=s(S9e);cSr=r(n$t,"albert"),n$t.forEach(t),fSr=r(Cqe," \u2014 "),rK=n(Cqe,"A",{href:!0});var s$t=s(rK);mSr=r(s$t,"FlaxAlbertModel"),s$t.forEach(t),gSr=r(Cqe," (ALBERT model)"),Cqe.forEach(t),hSr=i(ne),cE=n(ne,"LI",{});var wqe=s(cE);R9e=n(wqe,"STRONG",{});var l$t=s(R9e);pSr=r(l$t,"bart"),l$t.forEach(t),uSr=r(wqe," \u2014 "),tK=n(wqe,"A",{href:!0});var i$t=s(tK);_Sr=r(i$t,"FlaxBartModel"),i$t.forEach(t),bSr=r(wqe," (BART model)"),wqe.forEach(t),vSr=i(ne),fE=n(ne,"LI",{});var Aqe=s(fE);P9e=n(Aqe,"STRONG",{});var d$t=s(P9e);FSr=r(d$t,"beit"),d$t.forEach(t),TSr=r(Aqe," \u2014 "),aK=n(Aqe,"A",{href:!0});var c$t=s(aK);MSr=r(c$t,"FlaxBeitModel"),c$t.forEach(t),ESr=r(Aqe," (BEiT model)"),Aqe.forEach(t),CSr=i(ne),mE=n(ne,"LI",{});var yqe=s(mE);B9e=n(yqe,"STRONG",{});var f$t=s(B9e);wSr=r(f$t,"bert"),f$t.forEach(t),ASr=r(yqe," \u2014 "),nK=n(yqe,"A",{href:!0});var m$t=s(nK);ySr=r(m$t,"FlaxBertModel"),m$t.forEach(t),LSr=r(yqe," (BERT model)"),yqe.forEach(t),xSr=i(ne),gE=n(ne,"LI",{});var Lqe=s(gE);I9e=n(Lqe,"STRONG",{});var g$t=s(I9e);$Sr=r(g$t,"big_bird"),g$t.forEach(t),kSr=r(Lqe," \u2014 "),sK=n(Lqe,"A",{href:!0});var h$t=s(sK);SSr=r(h$t,"FlaxBigBirdModel"),h$t.forEach(t),RSr=r(Lqe," (BigBird model)"),Lqe.forEach(t),PSr=i(ne),hE=n(ne,"LI",{});var xqe=s(hE);N9e=n(xqe,"STRONG",{});var p$t=s(N9e);BSr=r(p$t,"blenderbot"),p$t.forEach(t),ISr=r(xqe," \u2014 "),lK=n(xqe,"A",{href:!0});var u$t=s(lK);NSr=r(u$t,"FlaxBlenderbotModel"),u$t.forEach(t),qSr=r(xqe," (Blenderbot model)"),xqe.forEach(t),jSr=i(ne),pE=n(ne,"LI",{});var $qe=s(pE);q9e=n($qe,"STRONG",{});var _$t=s(q9e);DSr=r(_$t,"blenderbot-small"),_$t.forEach(t),GSr=r($qe," \u2014 "),iK=n($qe,"A",{href:!0});var b$t=s(iK);OSr=r(b$t,"FlaxBlenderbotSmallModel"),b$t.forEach(t),VSr=r($qe," (BlenderbotSmall model)"),$qe.forEach(t),XSr=i(ne),uE=n(ne,"LI",{});var kqe=s(uE);j9e=n(kqe,"STRONG",{});var v$t=s(j9e);zSr=r(v$t,"clip"),v$t.forEach(t),WSr=r(kqe," \u2014 "),dK=n(kqe,"A",{href:!0});var F$t=s(dK);QSr=r(F$t,"FlaxCLIPModel"),F$t.forEach(t),HSr=r(kqe," (CLIP model)"),kqe.forEach(t),USr=i(ne),_E=n(ne,"LI",{});var Sqe=s(_E);D9e=n(Sqe,"STRONG",{});var T$t=s(D9e);JSr=r(T$t,"distilbert"),T$t.forEach(t),YSr=r(Sqe," \u2014 "),cK=n(Sqe,"A",{href:!0});var M$t=s(cK);KSr=r(M$t,"FlaxDistilBertModel"),M$t.forEach(t),ZSr=r(Sqe," (DistilBERT model)"),Sqe.forEach(t),eRr=i(ne),bE=n(ne,"LI",{});var Rqe=s(bE);G9e=n(Rqe,"STRONG",{});var E$t=s(G9e);oRr=r(E$t,"electra"),E$t.forEach(t),rRr=r(Rqe," \u2014 "),fK=n(Rqe,"A",{href:!0});var C$t=s(fK);tRr=r(C$t,"FlaxElectraModel"),C$t.forEach(t),aRr=r(Rqe," (ELECTRA model)"),Rqe.forEach(t),nRr=i(ne),vE=n(ne,"LI",{});var Pqe=s(vE);O9e=n(Pqe,"STRONG",{});var w$t=s(O9e);sRr=r(w$t,"gpt2"),w$t.forEach(t),lRr=r(Pqe," \u2014 "),mK=n(Pqe,"A",{href:!0});var A$t=s(mK);iRr=r(A$t,"FlaxGPT2Model"),A$t.forEach(t),dRr=r(Pqe," (OpenAI GPT-2 model)"),Pqe.forEach(t),cRr=i(ne),FE=n(ne,"LI",{});var Bqe=s(FE);V9e=n(Bqe,"STRONG",{});var y$t=s(V9e);fRr=r(y$t,"gpt_neo"),y$t.forEach(t),mRr=r(Bqe," \u2014 "),gK=n(Bqe,"A",{href:!0});var L$t=s(gK);gRr=r(L$t,"FlaxGPTNeoModel"),L$t.forEach(t),hRr=r(Bqe," (GPT Neo model)"),Bqe.forEach(t),pRr=i(ne),TE=n(ne,"LI",{});var Iqe=s(TE);X9e=n(Iqe,"STRONG",{});var x$t=s(X9e);uRr=r(x$t,"gptj"),x$t.forEach(t),_Rr=r(Iqe," \u2014 "),hK=n(Iqe,"A",{href:!0});var $$t=s(hK);bRr=r($$t,"FlaxGPTJModel"),$$t.forEach(t),vRr=r(Iqe," (GPT-J model)"),Iqe.forEach(t),FRr=i(ne),ME=n(ne,"LI",{});var Nqe=s(ME);z9e=n(Nqe,"STRONG",{});var k$t=s(z9e);TRr=r(k$t,"marian"),k$t.forEach(t),MRr=r(Nqe," \u2014 "),pK=n(Nqe,"A",{href:!0});var S$t=s(pK);ERr=r(S$t,"FlaxMarianModel"),S$t.forEach(t),CRr=r(Nqe," (Marian model)"),Nqe.forEach(t),wRr=i(ne),EE=n(ne,"LI",{});var qqe=s(EE);W9e=n(qqe,"STRONG",{});var R$t=s(W9e);ARr=r(R$t,"mbart"),R$t.forEach(t),yRr=r(qqe," \u2014 "),uK=n(qqe,"A",{href:!0});var P$t=s(uK);LRr=r(P$t,"FlaxMBartModel"),P$t.forEach(t),xRr=r(qqe," (mBART model)"),qqe.forEach(t),$Rr=i(ne),CE=n(ne,"LI",{});var jqe=s(CE);Q9e=n(jqe,"STRONG",{});var B$t=s(Q9e);kRr=r(B$t,"mt5"),B$t.forEach(t),SRr=r(jqe," \u2014 "),_K=n(jqe,"A",{href:!0});var I$t=s(_K);RRr=r(I$t,"FlaxMT5Model"),I$t.forEach(t),PRr=r(jqe," (MT5 model)"),jqe.forEach(t),BRr=i(ne),wE=n(ne,"LI",{});var Dqe=s(wE);H9e=n(Dqe,"STRONG",{});var N$t=s(H9e);IRr=r(N$t,"opt"),N$t.forEach(t),NRr=r(Dqe," \u2014 "),bK=n(Dqe,"A",{href:!0});var q$t=s(bK);qRr=r(q$t,"FlaxOPTModel"),q$t.forEach(t),jRr=r(Dqe," (OPT model)"),Dqe.forEach(t),DRr=i(ne),AE=n(ne,"LI",{});var Gqe=s(AE);U9e=n(Gqe,"STRONG",{});var j$t=s(U9e);GRr=r(j$t,"pegasus"),j$t.forEach(t),ORr=r(Gqe," \u2014 "),vK=n(Gqe,"A",{href:!0});var D$t=s(vK);VRr=r(D$t,"FlaxPegasusModel"),D$t.forEach(t),XRr=r(Gqe," (Pegasus model)"),Gqe.forEach(t),zRr=i(ne),yE=n(ne,"LI",{});var Oqe=s(yE);J9e=n(Oqe,"STRONG",{});var G$t=s(J9e);WRr=r(G$t,"roberta"),G$t.forEach(t),QRr=r(Oqe," \u2014 "),FK=n(Oqe,"A",{href:!0});var O$t=s(FK);HRr=r(O$t,"FlaxRobertaModel"),O$t.forEach(t),URr=r(Oqe," (RoBERTa model)"),Oqe.forEach(t),JRr=i(ne),LE=n(ne,"LI",{});var Vqe=s(LE);Y9e=n(Vqe,"STRONG",{});var V$t=s(Y9e);YRr=r(V$t,"roformer"),V$t.forEach(t),KRr=r(Vqe," \u2014 "),TK=n(Vqe,"A",{href:!0});var X$t=s(TK);ZRr=r(X$t,"FlaxRoFormerModel"),X$t.forEach(t),ePr=r(Vqe," (RoFormer model)"),Vqe.forEach(t),oPr=i(ne),xE=n(ne,"LI",{});var Xqe=s(xE);K9e=n(Xqe,"STRONG",{});var z$t=s(K9e);rPr=r(z$t,"t5"),z$t.forEach(t),tPr=r(Xqe," \u2014 "),MK=n(Xqe,"A",{href:!0});var W$t=s(MK);aPr=r(W$t,"FlaxT5Model"),W$t.forEach(t),nPr=r(Xqe," (T5 model)"),Xqe.forEach(t),sPr=i(ne),$E=n(ne,"LI",{});var zqe=s($E);Z9e=n(zqe,"STRONG",{});var Q$t=s(Z9e);lPr=r(Q$t,"vision-text-dual-encoder"),Q$t.forEach(t),iPr=r(zqe," \u2014 "),EK=n(zqe,"A",{href:!0});var H$t=s(EK);dPr=r(H$t,"FlaxVisionTextDualEncoderModel"),H$t.forEach(t),cPr=r(zqe," (VisionTextDualEncoder model)"),zqe.forEach(t),fPr=i(ne),kE=n(ne,"LI",{});var Wqe=s(kE);eMe=n(Wqe,"STRONG",{});var U$t=s(eMe);mPr=r(U$t,"vit"),U$t.forEach(t),gPr=r(Wqe," \u2014 "),CK=n(Wqe,"A",{href:!0});var J$t=s(CK);hPr=r(J$t,"FlaxViTModel"),J$t.forEach(t),pPr=r(Wqe," (ViT model)"),Wqe.forEach(t),uPr=i(ne),SE=n(ne,"LI",{});var Qqe=s(SE);oMe=n(Qqe,"STRONG",{});var Y$t=s(oMe);_Pr=r(Y$t,"wav2vec2"),Y$t.forEach(t),bPr=r(Qqe," \u2014 "),wK=n(Qqe,"A",{href:!0});var K$t=s(wK);vPr=r(K$t,"FlaxWav2Vec2Model"),K$t.forEach(t),FPr=r(Qqe," (Wav2Vec2 model)"),Qqe.forEach(t),TPr=i(ne),RE=n(ne,"LI",{});var Hqe=s(RE);rMe=n(Hqe,"STRONG",{});var Z$t=s(rMe);MPr=r(Z$t,"xglm"),Z$t.forEach(t),EPr=r(Hqe," \u2014 "),AK=n(Hqe,"A",{href:!0});var ekt=s(AK);CPr=r(ekt,"FlaxXGLMModel"),ekt.forEach(t),wPr=r(Hqe," (XGLM model)"),Hqe.forEach(t),APr=i(ne),PE=n(ne,"LI",{});var Uqe=s(PE);tMe=n(Uqe,"STRONG",{});var okt=s(tMe);yPr=r(okt,"xlm-roberta"),okt.forEach(t),LPr=r(Uqe," \u2014 "),yK=n(Uqe,"A",{href:!0});var rkt=s(yK);xPr=r(rkt,"FlaxXLMRobertaModel"),rkt.forEach(t),$Pr=r(Uqe," (XLM-RoBERTa model)"),Uqe.forEach(t),ne.forEach(t),kPr=i(Jl),T(BE.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),sOe=i(f),Vc=n(f,"H2",{class:!0});var pXe=s(Vc);IE=n(pXe,"A",{id:!0,class:!0,href:!0});var tkt=s(IE);aMe=n(tkt,"SPAN",{});var akt=s(aMe);T(Fx.$$.fragment,akt),akt.forEach(t),tkt.forEach(t),SPr=i(pXe),nMe=n(pXe,"SPAN",{});var nkt=s(nMe);RPr=r(nkt,"FlaxAutoModelForCausalLM"),nkt.forEach(t),pXe.forEach(t),lOe=i(f),hr=n(f,"DIV",{class:!0});var Yl=s(hr);T(Tx.$$.fragment,Yl),PPr=i(Yl),Xc=n(Yl,"P",{});var sre=s(Xc);BPr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),LK=n(sre,"A",{href:!0});var skt=s(LK);IPr=r(skt,"from_pretrained()"),skt.forEach(t),NPr=r(sre," class method or the "),xK=n(sre,"A",{href:!0});var lkt=s(xK);qPr=r(lkt,"from_config()"),lkt.forEach(t),jPr=r(sre,` class
method.`),sre.forEach(t),DPr=i(Yl),Mx=n(Yl,"P",{});var uXe=s(Mx);GPr=r(uXe,"This class cannot be instantiated directly using "),sMe=n(uXe,"CODE",{});var ikt=s(sMe);OPr=r(ikt,"__init__()"),ikt.forEach(t),VPr=r(uXe," (throws an error)."),uXe.forEach(t),XPr=i(Yl),zt=n(Yl,"DIV",{class:!0});var Dw=s(zt);T(Ex.$$.fragment,Dw),zPr=i(Dw),lMe=n(Dw,"P",{});var dkt=s(lMe);WPr=r(dkt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),dkt.forEach(t),QPr=i(Dw),zc=n(Dw,"P",{});var lre=s(zc);HPr=r(lre,`Note:
Loading a model from its configuration file does `),iMe=n(lre,"STRONG",{});var ckt=s(iMe);UPr=r(ckt,"not"),ckt.forEach(t),JPr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),$K=n(lre,"A",{href:!0});var fkt=s($K);YPr=r(fkt,"from_pretrained()"),fkt.forEach(t),KPr=r(lre," to load the model weights."),lre.forEach(t),ZPr=i(Dw),T(NE.$$.fragment,Dw),Dw.forEach(t),eBr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(Cx.$$.fragment,Kl),oBr=i(Kl),dMe=n(Kl,"P",{});var mkt=s(dMe);rBr=r(mkt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),mkt.forEach(t),tBr=i(Kl),Fn=n(Kl,"P",{});var Gw=s(Fn);aBr=r(Gw,"The model class to instantiate is selected based on the "),cMe=n(Gw,"CODE",{});var gkt=s(cMe);nBr=r(gkt,"model_type"),gkt.forEach(t),sBr=r(Gw,` property of the config object (either
passed as an argument or loaded from `),fMe=n(Gw,"CODE",{});var hkt=s(fMe);lBr=r(hkt,"pretrained_model_name_or_path"),hkt.forEach(t),iBr=r(Gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mMe=n(Gw,"CODE",{});var pkt=s(mMe);dBr=r(pkt,"pretrained_model_name_or_path"),pkt.forEach(t),cBr=r(Gw,":"),Gw.forEach(t),fBr=i(Kl),xe=n(Kl,"UL",{});var Ne=s(xe);qE=n(Ne,"LI",{});var Jqe=s(qE);gMe=n(Jqe,"STRONG",{});var ukt=s(gMe);mBr=r(ukt,"bart"),ukt.forEach(t),gBr=r(Jqe," \u2014 "),kK=n(Jqe,"A",{href:!0});var _kt=s(kK);hBr=r(_kt,"FlaxBartForCausalLM"),_kt.forEach(t),pBr=r(Jqe," (BART model)"),Jqe.forEach(t),uBr=i(Ne),jE=n(Ne,"LI",{});var Yqe=s(jE);hMe=n(Yqe,"STRONG",{});var bkt=s(hMe);_Br=r(bkt,"bert"),bkt.forEach(t),bBr=r(Yqe," \u2014 "),SK=n(Yqe,"A",{href:!0});var vkt=s(SK);vBr=r(vkt,"FlaxBertForCausalLM"),vkt.forEach(t),FBr=r(Yqe," (BERT model)"),Yqe.forEach(t),TBr=i(Ne),DE=n(Ne,"LI",{});var Kqe=s(DE);pMe=n(Kqe,"STRONG",{});var Fkt=s(pMe);MBr=r(Fkt,"big_bird"),Fkt.forEach(t),EBr=r(Kqe," \u2014 "),RK=n(Kqe,"A",{href:!0});var Tkt=s(RK);CBr=r(Tkt,"FlaxBigBirdForCausalLM"),Tkt.forEach(t),wBr=r(Kqe," (BigBird model)"),Kqe.forEach(t),ABr=i(Ne),GE=n(Ne,"LI",{});var Zqe=s(GE);uMe=n(Zqe,"STRONG",{});var Mkt=s(uMe);yBr=r(Mkt,"electra"),Mkt.forEach(t),LBr=r(Zqe," \u2014 "),PK=n(Zqe,"A",{href:!0});var Ekt=s(PK);xBr=r(Ekt,"FlaxElectraForCausalLM"),Ekt.forEach(t),$Br=r(Zqe," (ELECTRA model)"),Zqe.forEach(t),kBr=i(Ne),OE=n(Ne,"LI",{});var eje=s(OE);_Me=n(eje,"STRONG",{});var Ckt=s(_Me);SBr=r(Ckt,"gpt2"),Ckt.forEach(t),RBr=r(eje," \u2014 "),BK=n(eje,"A",{href:!0});var wkt=s(BK);PBr=r(wkt,"FlaxGPT2LMHeadModel"),wkt.forEach(t),BBr=r(eje," (OpenAI GPT-2 model)"),eje.forEach(t),IBr=i(Ne),VE=n(Ne,"LI",{});var oje=s(VE);bMe=n(oje,"STRONG",{});var Akt=s(bMe);NBr=r(Akt,"gpt_neo"),Akt.forEach(t),qBr=r(oje," \u2014 "),IK=n(oje,"A",{href:!0});var ykt=s(IK);jBr=r(ykt,"FlaxGPTNeoForCausalLM"),ykt.forEach(t),DBr=r(oje," (GPT Neo model)"),oje.forEach(t),GBr=i(Ne),XE=n(Ne,"LI",{});var rje=s(XE);vMe=n(rje,"STRONG",{});var Lkt=s(vMe);OBr=r(Lkt,"gptj"),Lkt.forEach(t),VBr=r(rje," \u2014 "),NK=n(rje,"A",{href:!0});var xkt=s(NK);XBr=r(xkt,"FlaxGPTJForCausalLM"),xkt.forEach(t),zBr=r(rje," (GPT-J model)"),rje.forEach(t),WBr=i(Ne),zE=n(Ne,"LI",{});var tje=s(zE);FMe=n(tje,"STRONG",{});var $kt=s(FMe);QBr=r($kt,"opt"),$kt.forEach(t),HBr=r(tje," \u2014 "),qK=n(tje,"A",{href:!0});var kkt=s(qK);UBr=r(kkt,"FlaxOPTForCausalLM"),kkt.forEach(t),JBr=r(tje," (OPT model)"),tje.forEach(t),YBr=i(Ne),WE=n(Ne,"LI",{});var aje=s(WE);TMe=n(aje,"STRONG",{});var Skt=s(TMe);KBr=r(Skt,"roberta"),Skt.forEach(t),ZBr=r(aje," \u2014 "),jK=n(aje,"A",{href:!0});var Rkt=s(jK);eIr=r(Rkt,"FlaxRobertaForCausalLM"),Rkt.forEach(t),oIr=r(aje," (RoBERTa model)"),aje.forEach(t),rIr=i(Ne),QE=n(Ne,"LI",{});var nje=s(QE);MMe=n(nje,"STRONG",{});var Pkt=s(MMe);tIr=r(Pkt,"xglm"),Pkt.forEach(t),aIr=r(nje," \u2014 "),DK=n(nje,"A",{href:!0});var Bkt=s(DK);nIr=r(Bkt,"FlaxXGLMForCausalLM"),Bkt.forEach(t),sIr=r(nje," (XGLM model)"),nje.forEach(t),Ne.forEach(t),lIr=i(Kl),T(HE.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),iOe=i(f),Wc=n(f,"H2",{class:!0});var _Xe=s(Wc);UE=n(_Xe,"A",{id:!0,class:!0,href:!0});var Ikt=s(UE);EMe=n(Ikt,"SPAN",{});var Nkt=s(EMe);T(wx.$$.fragment,Nkt),Nkt.forEach(t),Ikt.forEach(t),iIr=i(_Xe),CMe=n(_Xe,"SPAN",{});var qkt=s(CMe);dIr=r(qkt,"FlaxAutoModelForPreTraining"),qkt.forEach(t),_Xe.forEach(t),dOe=i(f),pr=n(f,"DIV",{class:!0});var Zl=s(pr);T(Ax.$$.fragment,Zl),cIr=i(Zl),Qc=n(Zl,"P",{});var ire=s(Qc);fIr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),GK=n(ire,"A",{href:!0});var jkt=s(GK);mIr=r(jkt,"from_pretrained()"),jkt.forEach(t),gIr=r(ire," class method or the "),OK=n(ire,"A",{href:!0});var Dkt=s(OK);hIr=r(Dkt,"from_config()"),Dkt.forEach(t),pIr=r(ire,` class
method.`),ire.forEach(t),uIr=i(Zl),yx=n(Zl,"P",{});var bXe=s(yx);_Ir=r(bXe,"This class cannot be instantiated directly using "),wMe=n(bXe,"CODE",{});var Gkt=s(wMe);bIr=r(Gkt,"__init__()"),Gkt.forEach(t),vIr=r(bXe," (throws an error)."),bXe.forEach(t),FIr=i(Zl),Wt=n(Zl,"DIV",{class:!0});var Ow=s(Wt);T(Lx.$$.fragment,Ow),TIr=i(Ow),AMe=n(Ow,"P",{});var Okt=s(AMe);MIr=r(Okt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Okt.forEach(t),EIr=i(Ow),Hc=n(Ow,"P",{});var dre=s(Hc);CIr=r(dre,`Note:
Loading a model from its configuration file does `),yMe=n(dre,"STRONG",{});var Vkt=s(yMe);wIr=r(Vkt,"not"),Vkt.forEach(t),AIr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=n(dre,"A",{href:!0});var Xkt=s(VK);yIr=r(Xkt,"from_pretrained()"),Xkt.forEach(t),LIr=r(dre," to load the model weights."),dre.forEach(t),xIr=i(Ow),T(JE.$$.fragment,Ow),Ow.forEach(t),$Ir=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(xx.$$.fragment,ei),kIr=i(ei),LMe=n(ei,"P",{});var zkt=s(LMe);SIr=r(zkt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),zkt.forEach(t),RIr=i(ei),Tn=n(ei,"P",{});var Vw=s(Tn);PIr=r(Vw,"The model class to instantiate is selected based on the "),xMe=n(Vw,"CODE",{});var Wkt=s(xMe);BIr=r(Wkt,"model_type"),Wkt.forEach(t),IIr=r(Vw,` property of the config object (either
passed as an argument or loaded from `),$Me=n(Vw,"CODE",{});var Qkt=s($Me);NIr=r(Qkt,"pretrained_model_name_or_path"),Qkt.forEach(t),qIr=r(Vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kMe=n(Vw,"CODE",{});var Hkt=s(kMe);jIr=r(Hkt,"pretrained_model_name_or_path"),Hkt.forEach(t),DIr=r(Vw,":"),Vw.forEach(t),GIr=i(ei),Ee=n(ei,"UL",{});var we=s(Ee);YE=n(we,"LI",{});var sje=s(YE);SMe=n(sje,"STRONG",{});var Ukt=s(SMe);OIr=r(Ukt,"albert"),Ukt.forEach(t),VIr=r(sje," \u2014 "),XK=n(sje,"A",{href:!0});var Jkt=s(XK);XIr=r(Jkt,"FlaxAlbertForPreTraining"),Jkt.forEach(t),zIr=r(sje," (ALBERT model)"),sje.forEach(t),WIr=i(we),KE=n(we,"LI",{});var lje=s(KE);RMe=n(lje,"STRONG",{});var Ykt=s(RMe);QIr=r(Ykt,"bart"),Ykt.forEach(t),HIr=r(lje," \u2014 "),zK=n(lje,"A",{href:!0});var Kkt=s(zK);UIr=r(Kkt,"FlaxBartForConditionalGeneration"),Kkt.forEach(t),JIr=r(lje," (BART model)"),lje.forEach(t),YIr=i(we),ZE=n(we,"LI",{});var ije=s(ZE);PMe=n(ije,"STRONG",{});var Zkt=s(PMe);KIr=r(Zkt,"bert"),Zkt.forEach(t),ZIr=r(ije," \u2014 "),WK=n(ije,"A",{href:!0});var eSt=s(WK);eNr=r(eSt,"FlaxBertForPreTraining"),eSt.forEach(t),oNr=r(ije," (BERT model)"),ije.forEach(t),rNr=i(we),eC=n(we,"LI",{});var dje=s(eC);BMe=n(dje,"STRONG",{});var oSt=s(BMe);tNr=r(oSt,"big_bird"),oSt.forEach(t),aNr=r(dje," \u2014 "),QK=n(dje,"A",{href:!0});var rSt=s(QK);nNr=r(rSt,"FlaxBigBirdForPreTraining"),rSt.forEach(t),sNr=r(dje," (BigBird model)"),dje.forEach(t),lNr=i(we),oC=n(we,"LI",{});var cje=s(oC);IMe=n(cje,"STRONG",{});var tSt=s(IMe);iNr=r(tSt,"electra"),tSt.forEach(t),dNr=r(cje," \u2014 "),HK=n(cje,"A",{href:!0});var aSt=s(HK);cNr=r(aSt,"FlaxElectraForPreTraining"),aSt.forEach(t),fNr=r(cje," (ELECTRA model)"),cje.forEach(t),mNr=i(we),rC=n(we,"LI",{});var fje=s(rC);NMe=n(fje,"STRONG",{});var nSt=s(NMe);gNr=r(nSt,"mbart"),nSt.forEach(t),hNr=r(fje," \u2014 "),UK=n(fje,"A",{href:!0});var sSt=s(UK);pNr=r(sSt,"FlaxMBartForConditionalGeneration"),sSt.forEach(t),uNr=r(fje," (mBART model)"),fje.forEach(t),_Nr=i(we),tC=n(we,"LI",{});var mje=s(tC);qMe=n(mje,"STRONG",{});var lSt=s(qMe);bNr=r(lSt,"mt5"),lSt.forEach(t),vNr=r(mje," \u2014 "),JK=n(mje,"A",{href:!0});var iSt=s(JK);FNr=r(iSt,"FlaxMT5ForConditionalGeneration"),iSt.forEach(t),TNr=r(mje," (MT5 model)"),mje.forEach(t),MNr=i(we),aC=n(we,"LI",{});var gje=s(aC);jMe=n(gje,"STRONG",{});var dSt=s(jMe);ENr=r(dSt,"roberta"),dSt.forEach(t),CNr=r(gje," \u2014 "),YK=n(gje,"A",{href:!0});var cSt=s(YK);wNr=r(cSt,"FlaxRobertaForMaskedLM"),cSt.forEach(t),ANr=r(gje," (RoBERTa model)"),gje.forEach(t),yNr=i(we),nC=n(we,"LI",{});var hje=s(nC);DMe=n(hje,"STRONG",{});var fSt=s(DMe);LNr=r(fSt,"roformer"),fSt.forEach(t),xNr=r(hje," \u2014 "),KK=n(hje,"A",{href:!0});var mSt=s(KK);$Nr=r(mSt,"FlaxRoFormerForMaskedLM"),mSt.forEach(t),kNr=r(hje," (RoFormer model)"),hje.forEach(t),SNr=i(we),sC=n(we,"LI",{});var pje=s(sC);GMe=n(pje,"STRONG",{});var gSt=s(GMe);RNr=r(gSt,"t5"),gSt.forEach(t),PNr=r(pje," \u2014 "),ZK=n(pje,"A",{href:!0});var hSt=s(ZK);BNr=r(hSt,"FlaxT5ForConditionalGeneration"),hSt.forEach(t),INr=r(pje," (T5 model)"),pje.forEach(t),NNr=i(we),lC=n(we,"LI",{});var uje=s(lC);OMe=n(uje,"STRONG",{});var pSt=s(OMe);qNr=r(pSt,"wav2vec2"),pSt.forEach(t),jNr=r(uje," \u2014 "),eZ=n(uje,"A",{href:!0});var uSt=s(eZ);DNr=r(uSt,"FlaxWav2Vec2ForPreTraining"),uSt.forEach(t),GNr=r(uje," (Wav2Vec2 model)"),uje.forEach(t),ONr=i(we),iC=n(we,"LI",{});var _je=s(iC);VMe=n(_je,"STRONG",{});var _St=s(VMe);VNr=r(_St,"xlm-roberta"),_St.forEach(t),XNr=r(_je," \u2014 "),oZ=n(_je,"A",{href:!0});var bSt=s(oZ);zNr=r(bSt,"FlaxXLMRobertaForMaskedLM"),bSt.forEach(t),WNr=r(_je," (XLM-RoBERTa model)"),_je.forEach(t),we.forEach(t),QNr=i(ei),T(dC.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),cOe=i(f),Uc=n(f,"H2",{class:!0});var vXe=s(Uc);cC=n(vXe,"A",{id:!0,class:!0,href:!0});var vSt=s(cC);XMe=n(vSt,"SPAN",{});var FSt=s(XMe);T($x.$$.fragment,FSt),FSt.forEach(t),vSt.forEach(t),HNr=i(vXe),zMe=n(vXe,"SPAN",{});var TSt=s(zMe);UNr=r(TSt,"FlaxAutoModelForMaskedLM"),TSt.forEach(t),vXe.forEach(t),fOe=i(f),ur=n(f,"DIV",{class:!0});var oi=s(ur);T(kx.$$.fragment,oi),JNr=i(oi),Jc=n(oi,"P",{});var cre=s(Jc);YNr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),rZ=n(cre,"A",{href:!0});var MSt=s(rZ);KNr=r(MSt,"from_pretrained()"),MSt.forEach(t),ZNr=r(cre," class method or the "),tZ=n(cre,"A",{href:!0});var ESt=s(tZ);eqr=r(ESt,"from_config()"),ESt.forEach(t),oqr=r(cre,` class
method.`),cre.forEach(t),rqr=i(oi),Sx=n(oi,"P",{});var FXe=s(Sx);tqr=r(FXe,"This class cannot be instantiated directly using "),WMe=n(FXe,"CODE",{});var CSt=s(WMe);aqr=r(CSt,"__init__()"),CSt.forEach(t),nqr=r(FXe," (throws an error)."),FXe.forEach(t),sqr=i(oi),Qt=n(oi,"DIV",{class:!0});var Xw=s(Qt);T(Rx.$$.fragment,Xw),lqr=i(Xw),QMe=n(Xw,"P",{});var wSt=s(QMe);iqr=r(wSt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wSt.forEach(t),dqr=i(Xw),Yc=n(Xw,"P",{});var fre=s(Yc);cqr=r(fre,`Note:
Loading a model from its configuration file does `),HMe=n(fre,"STRONG",{});var ASt=s(HMe);fqr=r(ASt,"not"),ASt.forEach(t),mqr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aZ=n(fre,"A",{href:!0});var ySt=s(aZ);gqr=r(ySt,"from_pretrained()"),ySt.forEach(t),hqr=r(fre," to load the model weights."),fre.forEach(t),pqr=i(Xw),T(fC.$$.fragment,Xw),Xw.forEach(t),uqr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Px.$$.fragment,ri),_qr=i(ri),UMe=n(ri,"P",{});var LSt=s(UMe);bqr=r(LSt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),LSt.forEach(t),vqr=i(ri),Mn=n(ri,"P",{});var zw=s(Mn);Fqr=r(zw,"The model class to instantiate is selected based on the "),JMe=n(zw,"CODE",{});var xSt=s(JMe);Tqr=r(xSt,"model_type"),xSt.forEach(t),Mqr=r(zw,` property of the config object (either
passed as an argument or loaded from `),YMe=n(zw,"CODE",{});var $St=s(YMe);Eqr=r($St,"pretrained_model_name_or_path"),$St.forEach(t),Cqr=r(zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=n(zw,"CODE",{});var kSt=s(KMe);wqr=r(kSt,"pretrained_model_name_or_path"),kSt.forEach(t),Aqr=r(zw,":"),zw.forEach(t),yqr=i(ri),$e=n(ri,"UL",{});var qe=s($e);mC=n(qe,"LI",{});var bje=s(mC);ZMe=n(bje,"STRONG",{});var SSt=s(ZMe);Lqr=r(SSt,"albert"),SSt.forEach(t),xqr=r(bje," \u2014 "),nZ=n(bje,"A",{href:!0});var RSt=s(nZ);$qr=r(RSt,"FlaxAlbertForMaskedLM"),RSt.forEach(t),kqr=r(bje," (ALBERT model)"),bje.forEach(t),Sqr=i(qe),gC=n(qe,"LI",{});var vje=s(gC);e4e=n(vje,"STRONG",{});var PSt=s(e4e);Rqr=r(PSt,"bart"),PSt.forEach(t),Pqr=r(vje," \u2014 "),sZ=n(vje,"A",{href:!0});var BSt=s(sZ);Bqr=r(BSt,"FlaxBartForConditionalGeneration"),BSt.forEach(t),Iqr=r(vje," (BART model)"),vje.forEach(t),Nqr=i(qe),hC=n(qe,"LI",{});var Fje=s(hC);o4e=n(Fje,"STRONG",{});var ISt=s(o4e);qqr=r(ISt,"bert"),ISt.forEach(t),jqr=r(Fje," \u2014 "),lZ=n(Fje,"A",{href:!0});var NSt=s(lZ);Dqr=r(NSt,"FlaxBertForMaskedLM"),NSt.forEach(t),Gqr=r(Fje," (BERT model)"),Fje.forEach(t),Oqr=i(qe),pC=n(qe,"LI",{});var Tje=s(pC);r4e=n(Tje,"STRONG",{});var qSt=s(r4e);Vqr=r(qSt,"big_bird"),qSt.forEach(t),Xqr=r(Tje," \u2014 "),iZ=n(Tje,"A",{href:!0});var jSt=s(iZ);zqr=r(jSt,"FlaxBigBirdForMaskedLM"),jSt.forEach(t),Wqr=r(Tje," (BigBird model)"),Tje.forEach(t),Qqr=i(qe),uC=n(qe,"LI",{});var Mje=s(uC);t4e=n(Mje,"STRONG",{});var DSt=s(t4e);Hqr=r(DSt,"distilbert"),DSt.forEach(t),Uqr=r(Mje," \u2014 "),dZ=n(Mje,"A",{href:!0});var GSt=s(dZ);Jqr=r(GSt,"FlaxDistilBertForMaskedLM"),GSt.forEach(t),Yqr=r(Mje," (DistilBERT model)"),Mje.forEach(t),Kqr=i(qe),_C=n(qe,"LI",{});var Eje=s(_C);a4e=n(Eje,"STRONG",{});var OSt=s(a4e);Zqr=r(OSt,"electra"),OSt.forEach(t),ejr=r(Eje," \u2014 "),cZ=n(Eje,"A",{href:!0});var VSt=s(cZ);ojr=r(VSt,"FlaxElectraForMaskedLM"),VSt.forEach(t),rjr=r(Eje," (ELECTRA model)"),Eje.forEach(t),tjr=i(qe),bC=n(qe,"LI",{});var Cje=s(bC);n4e=n(Cje,"STRONG",{});var XSt=s(n4e);ajr=r(XSt,"mbart"),XSt.forEach(t),njr=r(Cje," \u2014 "),fZ=n(Cje,"A",{href:!0});var zSt=s(fZ);sjr=r(zSt,"FlaxMBartForConditionalGeneration"),zSt.forEach(t),ljr=r(Cje," (mBART model)"),Cje.forEach(t),ijr=i(qe),vC=n(qe,"LI",{});var wje=s(vC);s4e=n(wje,"STRONG",{});var WSt=s(s4e);djr=r(WSt,"roberta"),WSt.forEach(t),cjr=r(wje," \u2014 "),mZ=n(wje,"A",{href:!0});var QSt=s(mZ);fjr=r(QSt,"FlaxRobertaForMaskedLM"),QSt.forEach(t),mjr=r(wje," (RoBERTa model)"),wje.forEach(t),gjr=i(qe),FC=n(qe,"LI",{});var Aje=s(FC);l4e=n(Aje,"STRONG",{});var HSt=s(l4e);hjr=r(HSt,"roformer"),HSt.forEach(t),pjr=r(Aje," \u2014 "),gZ=n(Aje,"A",{href:!0});var USt=s(gZ);ujr=r(USt,"FlaxRoFormerForMaskedLM"),USt.forEach(t),_jr=r(Aje," (RoFormer model)"),Aje.forEach(t),bjr=i(qe),TC=n(qe,"LI",{});var yje=s(TC);i4e=n(yje,"STRONG",{});var JSt=s(i4e);vjr=r(JSt,"xlm-roberta"),JSt.forEach(t),Fjr=r(yje," \u2014 "),hZ=n(yje,"A",{href:!0});var YSt=s(hZ);Tjr=r(YSt,"FlaxXLMRobertaForMaskedLM"),YSt.forEach(t),Mjr=r(yje," (XLM-RoBERTa model)"),yje.forEach(t),qe.forEach(t),Ejr=i(ri),T(MC.$$.fragment,ri),ri.forEach(t),oi.forEach(t),mOe=i(f),Kc=n(f,"H2",{class:!0});var TXe=s(Kc);EC=n(TXe,"A",{id:!0,class:!0,href:!0});var KSt=s(EC);d4e=n(KSt,"SPAN",{});var ZSt=s(d4e);T(Bx.$$.fragment,ZSt),ZSt.forEach(t),KSt.forEach(t),Cjr=i(TXe),c4e=n(TXe,"SPAN",{});var eRt=s(c4e);wjr=r(eRt,"FlaxAutoModelForSeq2SeqLM"),eRt.forEach(t),TXe.forEach(t),gOe=i(f),_r=n(f,"DIV",{class:!0});var ti=s(_r);T(Ix.$$.fragment,ti),Ajr=i(ti),Zc=n(ti,"P",{});var mre=s(Zc);yjr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),pZ=n(mre,"A",{href:!0});var oRt=s(pZ);Ljr=r(oRt,"from_pretrained()"),oRt.forEach(t),xjr=r(mre," class method or the "),uZ=n(mre,"A",{href:!0});var rRt=s(uZ);$jr=r(rRt,"from_config()"),rRt.forEach(t),kjr=r(mre,` class
method.`),mre.forEach(t),Sjr=i(ti),Nx=n(ti,"P",{});var MXe=s(Nx);Rjr=r(MXe,"This class cannot be instantiated directly using "),f4e=n(MXe,"CODE",{});var tRt=s(f4e);Pjr=r(tRt,"__init__()"),tRt.forEach(t),Bjr=r(MXe," (throws an error)."),MXe.forEach(t),Ijr=i(ti),Ht=n(ti,"DIV",{class:!0});var Ww=s(Ht);T(qx.$$.fragment,Ww),Njr=i(Ww),m4e=n(Ww,"P",{});var aRt=s(m4e);qjr=r(aRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),aRt.forEach(t),jjr=i(Ww),ef=n(Ww,"P",{});var gre=s(ef);Djr=r(gre,`Note:
Loading a model from its configuration file does `),g4e=n(gre,"STRONG",{});var nRt=s(g4e);Gjr=r(nRt,"not"),nRt.forEach(t),Ojr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=n(gre,"A",{href:!0});var sRt=s(_Z);Vjr=r(sRt,"from_pretrained()"),sRt.forEach(t),Xjr=r(gre," to load the model weights."),gre.forEach(t),zjr=i(Ww),T(CC.$$.fragment,Ww),Ww.forEach(t),Wjr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(jx.$$.fragment,ai),Qjr=i(ai),h4e=n(ai,"P",{});var lRt=s(h4e);Hjr=r(lRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),lRt.forEach(t),Ujr=i(ai),En=n(ai,"P",{});var Qw=s(En);Jjr=r(Qw,"The model class to instantiate is selected based on the "),p4e=n(Qw,"CODE",{});var iRt=s(p4e);Yjr=r(iRt,"model_type"),iRt.forEach(t),Kjr=r(Qw,` property of the config object (either
passed as an argument or loaded from `),u4e=n(Qw,"CODE",{});var dRt=s(u4e);Zjr=r(dRt,"pretrained_model_name_or_path"),dRt.forEach(t),eDr=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_4e=n(Qw,"CODE",{});var cRt=s(_4e);oDr=r(cRt,"pretrained_model_name_or_path"),cRt.forEach(t),rDr=r(Qw,":"),Qw.forEach(t),tDr=i(ai),Pe=n(ai,"UL",{});var ze=s(Pe);wC=n(ze,"LI",{});var Lje=s(wC);b4e=n(Lje,"STRONG",{});var fRt=s(b4e);aDr=r(fRt,"bart"),fRt.forEach(t),nDr=r(Lje," \u2014 "),bZ=n(Lje,"A",{href:!0});var mRt=s(bZ);sDr=r(mRt,"FlaxBartForConditionalGeneration"),mRt.forEach(t),lDr=r(Lje," (BART model)"),Lje.forEach(t),iDr=i(ze),AC=n(ze,"LI",{});var xje=s(AC);v4e=n(xje,"STRONG",{});var gRt=s(v4e);dDr=r(gRt,"blenderbot"),gRt.forEach(t),cDr=r(xje," \u2014 "),vZ=n(xje,"A",{href:!0});var hRt=s(vZ);fDr=r(hRt,"FlaxBlenderbotForConditionalGeneration"),hRt.forEach(t),mDr=r(xje," (Blenderbot model)"),xje.forEach(t),gDr=i(ze),yC=n(ze,"LI",{});var $je=s(yC);F4e=n($je,"STRONG",{});var pRt=s(F4e);hDr=r(pRt,"blenderbot-small"),pRt.forEach(t),pDr=r($je," \u2014 "),FZ=n($je,"A",{href:!0});var uRt=s(FZ);uDr=r(uRt,"FlaxBlenderbotSmallForConditionalGeneration"),uRt.forEach(t),_Dr=r($je," (BlenderbotSmall model)"),$je.forEach(t),bDr=i(ze),LC=n(ze,"LI",{});var kje=s(LC);T4e=n(kje,"STRONG",{});var _Rt=s(T4e);vDr=r(_Rt,"encoder-decoder"),_Rt.forEach(t),FDr=r(kje," \u2014 "),TZ=n(kje,"A",{href:!0});var bRt=s(TZ);TDr=r(bRt,"FlaxEncoderDecoderModel"),bRt.forEach(t),MDr=r(kje," (Encoder decoder model)"),kje.forEach(t),EDr=i(ze),xC=n(ze,"LI",{});var Sje=s(xC);M4e=n(Sje,"STRONG",{});var vRt=s(M4e);CDr=r(vRt,"marian"),vRt.forEach(t),wDr=r(Sje," \u2014 "),MZ=n(Sje,"A",{href:!0});var FRt=s(MZ);ADr=r(FRt,"FlaxMarianMTModel"),FRt.forEach(t),yDr=r(Sje," (Marian model)"),Sje.forEach(t),LDr=i(ze),$C=n(ze,"LI",{});var Rje=s($C);E4e=n(Rje,"STRONG",{});var TRt=s(E4e);xDr=r(TRt,"mbart"),TRt.forEach(t),$Dr=r(Rje," \u2014 "),EZ=n(Rje,"A",{href:!0});var MRt=s(EZ);kDr=r(MRt,"FlaxMBartForConditionalGeneration"),MRt.forEach(t),SDr=r(Rje," (mBART model)"),Rje.forEach(t),RDr=i(ze),kC=n(ze,"LI",{});var Pje=s(kC);C4e=n(Pje,"STRONG",{});var ERt=s(C4e);PDr=r(ERt,"mt5"),ERt.forEach(t),BDr=r(Pje," \u2014 "),CZ=n(Pje,"A",{href:!0});var CRt=s(CZ);IDr=r(CRt,"FlaxMT5ForConditionalGeneration"),CRt.forEach(t),NDr=r(Pje," (MT5 model)"),Pje.forEach(t),qDr=i(ze),SC=n(ze,"LI",{});var Bje=s(SC);w4e=n(Bje,"STRONG",{});var wRt=s(w4e);jDr=r(wRt,"pegasus"),wRt.forEach(t),DDr=r(Bje," \u2014 "),wZ=n(Bje,"A",{href:!0});var ARt=s(wZ);GDr=r(ARt,"FlaxPegasusForConditionalGeneration"),ARt.forEach(t),ODr=r(Bje," (Pegasus model)"),Bje.forEach(t),VDr=i(ze),RC=n(ze,"LI",{});var Ije=s(RC);A4e=n(Ije,"STRONG",{});var yRt=s(A4e);XDr=r(yRt,"t5"),yRt.forEach(t),zDr=r(Ije," \u2014 "),AZ=n(Ije,"A",{href:!0});var LRt=s(AZ);WDr=r(LRt,"FlaxT5ForConditionalGeneration"),LRt.forEach(t),QDr=r(Ije," (T5 model)"),Ije.forEach(t),ze.forEach(t),HDr=i(ai),T(PC.$$.fragment,ai),ai.forEach(t),ti.forEach(t),hOe=i(f),of=n(f,"H2",{class:!0});var EXe=s(of);BC=n(EXe,"A",{id:!0,class:!0,href:!0});var xRt=s(BC);y4e=n(xRt,"SPAN",{});var $Rt=s(y4e);T(Dx.$$.fragment,$Rt),$Rt.forEach(t),xRt.forEach(t),UDr=i(EXe),L4e=n(EXe,"SPAN",{});var kRt=s(L4e);JDr=r(kRt,"FlaxAutoModelForSequenceClassification"),kRt.forEach(t),EXe.forEach(t),pOe=i(f),br=n(f,"DIV",{class:!0});var ni=s(br);T(Gx.$$.fragment,ni),YDr=i(ni),rf=n(ni,"P",{});var hre=s(rf);KDr=r(hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),yZ=n(hre,"A",{href:!0});var SRt=s(yZ);ZDr=r(SRt,"from_pretrained()"),SRt.forEach(t),eGr=r(hre," class method or the "),LZ=n(hre,"A",{href:!0});var RRt=s(LZ);oGr=r(RRt,"from_config()"),RRt.forEach(t),rGr=r(hre,` class
method.`),hre.forEach(t),tGr=i(ni),Ox=n(ni,"P",{});var CXe=s(Ox);aGr=r(CXe,"This class cannot be instantiated directly using "),x4e=n(CXe,"CODE",{});var PRt=s(x4e);nGr=r(PRt,"__init__()"),PRt.forEach(t),sGr=r(CXe," (throws an error)."),CXe.forEach(t),lGr=i(ni),Ut=n(ni,"DIV",{class:!0});var Hw=s(Ut);T(Vx.$$.fragment,Hw),iGr=i(Hw),$4e=n(Hw,"P",{});var BRt=s($4e);dGr=r(BRt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),BRt.forEach(t),cGr=i(Hw),tf=n(Hw,"P",{});var pre=s(tf);fGr=r(pre,`Note:
Loading a model from its configuration file does `),k4e=n(pre,"STRONG",{});var IRt=s(k4e);mGr=r(IRt,"not"),IRt.forEach(t),gGr=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),xZ=n(pre,"A",{href:!0});var NRt=s(xZ);hGr=r(NRt,"from_pretrained()"),NRt.forEach(t),pGr=r(pre," to load the model weights."),pre.forEach(t),uGr=i(Hw),T(IC.$$.fragment,Hw),Hw.forEach(t),_Gr=i(ni),Wr=n(ni,"DIV",{class:!0});var si=s(Wr);T(Xx.$$.fragment,si),bGr=i(si),S4e=n(si,"P",{});var qRt=s(S4e);vGr=r(qRt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qRt.forEach(t),FGr=i(si),Cn=n(si,"P",{});var Uw=s(Cn);TGr=r(Uw,"The model class to instantiate is selected based on the "),R4e=n(Uw,"CODE",{});var jRt=s(R4e);MGr=r(jRt,"model_type"),jRt.forEach(t),EGr=r(Uw,` property of the config object (either
passed as an argument or loaded from `),P4e=n(Uw,"CODE",{});var DRt=s(P4e);CGr=r(DRt,"pretrained_model_name_or_path"),DRt.forEach(t),wGr=r(Uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B4e=n(Uw,"CODE",{});var GRt=s(B4e);AGr=r(GRt,"pretrained_model_name_or_path"),GRt.forEach(t),yGr=r(Uw,":"),Uw.forEach(t),LGr=i(si),ke=n(si,"UL",{});var je=s(ke);NC=n(je,"LI",{});var Nje=s(NC);I4e=n(Nje,"STRONG",{});var ORt=s(I4e);xGr=r(ORt,"albert"),ORt.forEach(t),$Gr=r(Nje," \u2014 "),$Z=n(Nje,"A",{href:!0});var VRt=s($Z);kGr=r(VRt,"FlaxAlbertForSequenceClassification"),VRt.forEach(t),SGr=r(Nje," (ALBERT model)"),Nje.forEach(t),RGr=i(je),qC=n(je,"LI",{});var qje=s(qC);N4e=n(qje,"STRONG",{});var XRt=s(N4e);PGr=r(XRt,"bart"),XRt.forEach(t),BGr=r(qje," \u2014 "),kZ=n(qje,"A",{href:!0});var zRt=s(kZ);IGr=r(zRt,"FlaxBartForSequenceClassification"),zRt.forEach(t),NGr=r(qje," (BART model)"),qje.forEach(t),qGr=i(je),jC=n(je,"LI",{});var jje=s(jC);q4e=n(jje,"STRONG",{});var WRt=s(q4e);jGr=r(WRt,"bert"),WRt.forEach(t),DGr=r(jje," \u2014 "),SZ=n(jje,"A",{href:!0});var QRt=s(SZ);GGr=r(QRt,"FlaxBertForSequenceClassification"),QRt.forEach(t),OGr=r(jje," (BERT model)"),jje.forEach(t),VGr=i(je),DC=n(je,"LI",{});var Dje=s(DC);j4e=n(Dje,"STRONG",{});var HRt=s(j4e);XGr=r(HRt,"big_bird"),HRt.forEach(t),zGr=r(Dje," \u2014 "),RZ=n(Dje,"A",{href:!0});var URt=s(RZ);WGr=r(URt,"FlaxBigBirdForSequenceClassification"),URt.forEach(t),QGr=r(Dje," (BigBird model)"),Dje.forEach(t),HGr=i(je),GC=n(je,"LI",{});var Gje=s(GC);D4e=n(Gje,"STRONG",{});var JRt=s(D4e);UGr=r(JRt,"distilbert"),JRt.forEach(t),JGr=r(Gje," \u2014 "),PZ=n(Gje,"A",{href:!0});var YRt=s(PZ);YGr=r(YRt,"FlaxDistilBertForSequenceClassification"),YRt.forEach(t),KGr=r(Gje," (DistilBERT model)"),Gje.forEach(t),ZGr=i(je),OC=n(je,"LI",{});var Oje=s(OC);G4e=n(Oje,"STRONG",{});var KRt=s(G4e);eOr=r(KRt,"electra"),KRt.forEach(t),oOr=r(Oje," \u2014 "),BZ=n(Oje,"A",{href:!0});var ZRt=s(BZ);rOr=r(ZRt,"FlaxElectraForSequenceClassification"),ZRt.forEach(t),tOr=r(Oje," (ELECTRA model)"),Oje.forEach(t),aOr=i(je),VC=n(je,"LI",{});var Vje=s(VC);O4e=n(Vje,"STRONG",{});var ePt=s(O4e);nOr=r(ePt,"mbart"),ePt.forEach(t),sOr=r(Vje," \u2014 "),IZ=n(Vje,"A",{href:!0});var oPt=s(IZ);lOr=r(oPt,"FlaxMBartForSequenceClassification"),oPt.forEach(t),iOr=r(Vje," (mBART model)"),Vje.forEach(t),dOr=i(je),XC=n(je,"LI",{});var Xje=s(XC);V4e=n(Xje,"STRONG",{});var rPt=s(V4e);cOr=r(rPt,"roberta"),rPt.forEach(t),fOr=r(Xje," \u2014 "),NZ=n(Xje,"A",{href:!0});var tPt=s(NZ);mOr=r(tPt,"FlaxRobertaForSequenceClassification"),tPt.forEach(t),gOr=r(Xje," (RoBERTa model)"),Xje.forEach(t),hOr=i(je),zC=n(je,"LI",{});var zje=s(zC);X4e=n(zje,"STRONG",{});var aPt=s(X4e);pOr=r(aPt,"roformer"),aPt.forEach(t),uOr=r(zje," \u2014 "),qZ=n(zje,"A",{href:!0});var nPt=s(qZ);_Or=r(nPt,"FlaxRoFormerForSequenceClassification"),nPt.forEach(t),bOr=r(zje," (RoFormer model)"),zje.forEach(t),vOr=i(je),WC=n(je,"LI",{});var Wje=s(WC);z4e=n(Wje,"STRONG",{});var sPt=s(z4e);FOr=r(sPt,"xlm-roberta"),sPt.forEach(t),TOr=r(Wje," \u2014 "),jZ=n(Wje,"A",{href:!0});var lPt=s(jZ);MOr=r(lPt,"FlaxXLMRobertaForSequenceClassification"),lPt.forEach(t),EOr=r(Wje," (XLM-RoBERTa model)"),Wje.forEach(t),je.forEach(t),COr=i(si),T(QC.$$.fragment,si),si.forEach(t),ni.forEach(t),uOe=i(f),af=n(f,"H2",{class:!0});var wXe=s(af);HC=n(wXe,"A",{id:!0,class:!0,href:!0});var iPt=s(HC);W4e=n(iPt,"SPAN",{});var dPt=s(W4e);T(zx.$$.fragment,dPt),dPt.forEach(t),iPt.forEach(t),wOr=i(wXe),Q4e=n(wXe,"SPAN",{});var cPt=s(Q4e);AOr=r(cPt,"FlaxAutoModelForQuestionAnswering"),cPt.forEach(t),wXe.forEach(t),_Oe=i(f),vr=n(f,"DIV",{class:!0});var li=s(vr);T(Wx.$$.fragment,li),yOr=i(li),nf=n(li,"P",{});var ure=s(nf);LOr=r(ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DZ=n(ure,"A",{href:!0});var fPt=s(DZ);xOr=r(fPt,"from_pretrained()"),fPt.forEach(t),$Or=r(ure," class method or the "),GZ=n(ure,"A",{href:!0});var mPt=s(GZ);kOr=r(mPt,"from_config()"),mPt.forEach(t),SOr=r(ure,` class
method.`),ure.forEach(t),ROr=i(li),Qx=n(li,"P",{});var AXe=s(Qx);POr=r(AXe,"This class cannot be instantiated directly using "),H4e=n(AXe,"CODE",{});var gPt=s(H4e);BOr=r(gPt,"__init__()"),gPt.forEach(t),IOr=r(AXe," (throws an error)."),AXe.forEach(t),NOr=i(li),Jt=n(li,"DIV",{class:!0});var Jw=s(Jt);T(Hx.$$.fragment,Jw),qOr=i(Jw),U4e=n(Jw,"P",{});var hPt=s(U4e);jOr=r(hPt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),hPt.forEach(t),DOr=i(Jw),sf=n(Jw,"P",{});var _re=s(sf);GOr=r(_re,`Note:
Loading a model from its configuration file does `),J4e=n(_re,"STRONG",{});var pPt=s(J4e);OOr=r(pPt,"not"),pPt.forEach(t),VOr=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),OZ=n(_re,"A",{href:!0});var uPt=s(OZ);XOr=r(uPt,"from_pretrained()"),uPt.forEach(t),zOr=r(_re," to load the model weights."),_re.forEach(t),WOr=i(Jw),T(UC.$$.fragment,Jw),Jw.forEach(t),QOr=i(li),Qr=n(li,"DIV",{class:!0});var ii=s(Qr);T(Ux.$$.fragment,ii),HOr=i(ii),Y4e=n(ii,"P",{});var _Pt=s(Y4e);UOr=r(_Pt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),_Pt.forEach(t),JOr=i(ii),wn=n(ii,"P",{});var Yw=s(wn);YOr=r(Yw,"The model class to instantiate is selected based on the "),K4e=n(Yw,"CODE",{});var bPt=s(K4e);KOr=r(bPt,"model_type"),bPt.forEach(t),ZOr=r(Yw,` property of the config object (either
passed as an argument or loaded from `),Z4e=n(Yw,"CODE",{});var vPt=s(Z4e);eVr=r(vPt,"pretrained_model_name_or_path"),vPt.forEach(t),oVr=r(Yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eEe=n(Yw,"CODE",{});var FPt=s(eEe);rVr=r(FPt,"pretrained_model_name_or_path"),FPt.forEach(t),tVr=r(Yw,":"),Yw.forEach(t),aVr=i(ii),Se=n(ii,"UL",{});var De=s(Se);JC=n(De,"LI",{});var Qje=s(JC);oEe=n(Qje,"STRONG",{});var TPt=s(oEe);nVr=r(TPt,"albert"),TPt.forEach(t),sVr=r(Qje," \u2014 "),VZ=n(Qje,"A",{href:!0});var MPt=s(VZ);lVr=r(MPt,"FlaxAlbertForQuestionAnswering"),MPt.forEach(t),iVr=r(Qje," (ALBERT model)"),Qje.forEach(t),dVr=i(De),YC=n(De,"LI",{});var Hje=s(YC);rEe=n(Hje,"STRONG",{});var EPt=s(rEe);cVr=r(EPt,"bart"),EPt.forEach(t),fVr=r(Hje," \u2014 "),XZ=n(Hje,"A",{href:!0});var CPt=s(XZ);mVr=r(CPt,"FlaxBartForQuestionAnswering"),CPt.forEach(t),gVr=r(Hje," (BART model)"),Hje.forEach(t),hVr=i(De),KC=n(De,"LI",{});var Uje=s(KC);tEe=n(Uje,"STRONG",{});var wPt=s(tEe);pVr=r(wPt,"bert"),wPt.forEach(t),uVr=r(Uje," \u2014 "),zZ=n(Uje,"A",{href:!0});var APt=s(zZ);_Vr=r(APt,"FlaxBertForQuestionAnswering"),APt.forEach(t),bVr=r(Uje," (BERT model)"),Uje.forEach(t),vVr=i(De),ZC=n(De,"LI",{});var Jje=s(ZC);aEe=n(Jje,"STRONG",{});var yPt=s(aEe);FVr=r(yPt,"big_bird"),yPt.forEach(t),TVr=r(Jje," \u2014 "),WZ=n(Jje,"A",{href:!0});var LPt=s(WZ);MVr=r(LPt,"FlaxBigBirdForQuestionAnswering"),LPt.forEach(t),EVr=r(Jje," (BigBird model)"),Jje.forEach(t),CVr=i(De),e5=n(De,"LI",{});var Yje=s(e5);nEe=n(Yje,"STRONG",{});var xPt=s(nEe);wVr=r(xPt,"distilbert"),xPt.forEach(t),AVr=r(Yje," \u2014 "),QZ=n(Yje,"A",{href:!0});var $Pt=s(QZ);yVr=r($Pt,"FlaxDistilBertForQuestionAnswering"),$Pt.forEach(t),LVr=r(Yje," (DistilBERT model)"),Yje.forEach(t),xVr=i(De),o5=n(De,"LI",{});var Kje=s(o5);sEe=n(Kje,"STRONG",{});var kPt=s(sEe);$Vr=r(kPt,"electra"),kPt.forEach(t),kVr=r(Kje," \u2014 "),HZ=n(Kje,"A",{href:!0});var SPt=s(HZ);SVr=r(SPt,"FlaxElectraForQuestionAnswering"),SPt.forEach(t),RVr=r(Kje," (ELECTRA model)"),Kje.forEach(t),PVr=i(De),r5=n(De,"LI",{});var Zje=s(r5);lEe=n(Zje,"STRONG",{});var RPt=s(lEe);BVr=r(RPt,"mbart"),RPt.forEach(t),IVr=r(Zje," \u2014 "),UZ=n(Zje,"A",{href:!0});var PPt=s(UZ);NVr=r(PPt,"FlaxMBartForQuestionAnswering"),PPt.forEach(t),qVr=r(Zje," (mBART model)"),Zje.forEach(t),jVr=i(De),t5=n(De,"LI",{});var eDe=s(t5);iEe=n(eDe,"STRONG",{});var BPt=s(iEe);DVr=r(BPt,"roberta"),BPt.forEach(t),GVr=r(eDe," \u2014 "),JZ=n(eDe,"A",{href:!0});var IPt=s(JZ);OVr=r(IPt,"FlaxRobertaForQuestionAnswering"),IPt.forEach(t),VVr=r(eDe," (RoBERTa model)"),eDe.forEach(t),XVr=i(De),a5=n(De,"LI",{});var oDe=s(a5);dEe=n(oDe,"STRONG",{});var NPt=s(dEe);zVr=r(NPt,"roformer"),NPt.forEach(t),WVr=r(oDe," \u2014 "),YZ=n(oDe,"A",{href:!0});var qPt=s(YZ);QVr=r(qPt,"FlaxRoFormerForQuestionAnswering"),qPt.forEach(t),HVr=r(oDe," (RoFormer model)"),oDe.forEach(t),UVr=i(De),n5=n(De,"LI",{});var rDe=s(n5);cEe=n(rDe,"STRONG",{});var jPt=s(cEe);JVr=r(jPt,"xlm-roberta"),jPt.forEach(t),YVr=r(rDe," \u2014 "),KZ=n(rDe,"A",{href:!0});var DPt=s(KZ);KVr=r(DPt,"FlaxXLMRobertaForQuestionAnswering"),DPt.forEach(t),ZVr=r(rDe," (XLM-RoBERTa model)"),rDe.forEach(t),De.forEach(t),eXr=i(ii),T(s5.$$.fragment,ii),ii.forEach(t),li.forEach(t),bOe=i(f),lf=n(f,"H2",{class:!0});var yXe=s(lf);l5=n(yXe,"A",{id:!0,class:!0,href:!0});var GPt=s(l5);fEe=n(GPt,"SPAN",{});var OPt=s(fEe);T(Jx.$$.fragment,OPt),OPt.forEach(t),GPt.forEach(t),oXr=i(yXe),mEe=n(yXe,"SPAN",{});var VPt=s(mEe);rXr=r(VPt,"FlaxAutoModelForTokenClassification"),VPt.forEach(t),yXe.forEach(t),vOe=i(f),Fr=n(f,"DIV",{class:!0});var di=s(Fr);T(Yx.$$.fragment,di),tXr=i(di),df=n(di,"P",{});var bre=s(df);aXr=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ZZ=n(bre,"A",{href:!0});var XPt=s(ZZ);nXr=r(XPt,"from_pretrained()"),XPt.forEach(t),sXr=r(bre," class method or the "),eee=n(bre,"A",{href:!0});var zPt=s(eee);lXr=r(zPt,"from_config()"),zPt.forEach(t),iXr=r(bre,` class
method.`),bre.forEach(t),dXr=i(di),Kx=n(di,"P",{});var LXe=s(Kx);cXr=r(LXe,"This class cannot be instantiated directly using "),gEe=n(LXe,"CODE",{});var WPt=s(gEe);fXr=r(WPt,"__init__()"),WPt.forEach(t),mXr=r(LXe," (throws an error)."),LXe.forEach(t),gXr=i(di),Yt=n(di,"DIV",{class:!0});var Kw=s(Yt);T(Zx.$$.fragment,Kw),hXr=i(Kw),hEe=n(Kw,"P",{});var QPt=s(hEe);pXr=r(QPt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),QPt.forEach(t),uXr=i(Kw),cf=n(Kw,"P",{});var vre=s(cf);_Xr=r(vre,`Note:
Loading a model from its configuration file does `),pEe=n(vre,"STRONG",{});var HPt=s(pEe);bXr=r(HPt,"not"),HPt.forEach(t),vXr=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),oee=n(vre,"A",{href:!0});var UPt=s(oee);FXr=r(UPt,"from_pretrained()"),UPt.forEach(t),TXr=r(vre," to load the model weights."),vre.forEach(t),MXr=i(Kw),T(i5.$$.fragment,Kw),Kw.forEach(t),EXr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(e$.$$.fragment,ci),CXr=i(ci),uEe=n(ci,"P",{});var JPt=s(uEe);wXr=r(JPt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),JPt.forEach(t),AXr=i(ci),An=n(ci,"P",{});var Zw=s(An);yXr=r(Zw,"The model class to instantiate is selected based on the "),_Ee=n(Zw,"CODE",{});var YPt=s(_Ee);LXr=r(YPt,"model_type"),YPt.forEach(t),xXr=r(Zw,` property of the config object (either
passed as an argument or loaded from `),bEe=n(Zw,"CODE",{});var KPt=s(bEe);$Xr=r(KPt,"pretrained_model_name_or_path"),KPt.forEach(t),kXr=r(Zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vEe=n(Zw,"CODE",{});var ZPt=s(vEe);SXr=r(ZPt,"pretrained_model_name_or_path"),ZPt.forEach(t),RXr=r(Zw,":"),Zw.forEach(t),PXr=i(ci),Oe=n(ci,"UL",{});var To=s(Oe);d5=n(To,"LI",{});var tDe=s(d5);FEe=n(tDe,"STRONG",{});var eBt=s(FEe);BXr=r(eBt,"albert"),eBt.forEach(t),IXr=r(tDe," \u2014 "),ree=n(tDe,"A",{href:!0});var oBt=s(ree);NXr=r(oBt,"FlaxAlbertForTokenClassification"),oBt.forEach(t),qXr=r(tDe," (ALBERT model)"),tDe.forEach(t),jXr=i(To),c5=n(To,"LI",{});var aDe=s(c5);TEe=n(aDe,"STRONG",{});var rBt=s(TEe);DXr=r(rBt,"bert"),rBt.forEach(t),GXr=r(aDe," \u2014 "),tee=n(aDe,"A",{href:!0});var tBt=s(tee);OXr=r(tBt,"FlaxBertForTokenClassification"),tBt.forEach(t),VXr=r(aDe," (BERT model)"),aDe.forEach(t),XXr=i(To),f5=n(To,"LI",{});var nDe=s(f5);MEe=n(nDe,"STRONG",{});var aBt=s(MEe);zXr=r(aBt,"big_bird"),aBt.forEach(t),WXr=r(nDe," \u2014 "),aee=n(nDe,"A",{href:!0});var nBt=s(aee);QXr=r(nBt,"FlaxBigBirdForTokenClassification"),nBt.forEach(t),HXr=r(nDe," (BigBird model)"),nDe.forEach(t),UXr=i(To),m5=n(To,"LI",{});var sDe=s(m5);EEe=n(sDe,"STRONG",{});var sBt=s(EEe);JXr=r(sBt,"distilbert"),sBt.forEach(t),YXr=r(sDe," \u2014 "),nee=n(sDe,"A",{href:!0});var lBt=s(nee);KXr=r(lBt,"FlaxDistilBertForTokenClassification"),lBt.forEach(t),ZXr=r(sDe," (DistilBERT model)"),sDe.forEach(t),ezr=i(To),g5=n(To,"LI",{});var lDe=s(g5);CEe=n(lDe,"STRONG",{});var iBt=s(CEe);ozr=r(iBt,"electra"),iBt.forEach(t),rzr=r(lDe," \u2014 "),see=n(lDe,"A",{href:!0});var dBt=s(see);tzr=r(dBt,"FlaxElectraForTokenClassification"),dBt.forEach(t),azr=r(lDe," (ELECTRA model)"),lDe.forEach(t),nzr=i(To),h5=n(To,"LI",{});var iDe=s(h5);wEe=n(iDe,"STRONG",{});var cBt=s(wEe);szr=r(cBt,"roberta"),cBt.forEach(t),lzr=r(iDe," \u2014 "),lee=n(iDe,"A",{href:!0});var fBt=s(lee);izr=r(fBt,"FlaxRobertaForTokenClassification"),fBt.forEach(t),dzr=r(iDe," (RoBERTa model)"),iDe.forEach(t),czr=i(To),p5=n(To,"LI",{});var dDe=s(p5);AEe=n(dDe,"STRONG",{});var mBt=s(AEe);fzr=r(mBt,"roformer"),mBt.forEach(t),mzr=r(dDe," \u2014 "),iee=n(dDe,"A",{href:!0});var gBt=s(iee);gzr=r(gBt,"FlaxRoFormerForTokenClassification"),gBt.forEach(t),hzr=r(dDe," (RoFormer model)"),dDe.forEach(t),pzr=i(To),u5=n(To,"LI",{});var cDe=s(u5);yEe=n(cDe,"STRONG",{});var hBt=s(yEe);uzr=r(hBt,"xlm-roberta"),hBt.forEach(t),_zr=r(cDe," \u2014 "),dee=n(cDe,"A",{href:!0});var pBt=s(dee);bzr=r(pBt,"FlaxXLMRobertaForTokenClassification"),pBt.forEach(t),vzr=r(cDe," (XLM-RoBERTa model)"),cDe.forEach(t),To.forEach(t),Fzr=i(ci),T(_5.$$.fragment,ci),ci.forEach(t),di.forEach(t),FOe=i(f),ff=n(f,"H2",{class:!0});var xXe=s(ff);b5=n(xXe,"A",{id:!0,class:!0,href:!0});var uBt=s(b5);LEe=n(uBt,"SPAN",{});var _Bt=s(LEe);T(o$.$$.fragment,_Bt),_Bt.forEach(t),uBt.forEach(t),Tzr=i(xXe),xEe=n(xXe,"SPAN",{});var bBt=s(xEe);Mzr=r(bBt,"FlaxAutoModelForMultipleChoice"),bBt.forEach(t),xXe.forEach(t),TOe=i(f),Tr=n(f,"DIV",{class:!0});var fi=s(Tr);T(r$.$$.fragment,fi),Ezr=i(fi),mf=n(fi,"P",{});var Fre=s(mf);Czr=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cee=n(Fre,"A",{href:!0});var vBt=s(cee);wzr=r(vBt,"from_pretrained()"),vBt.forEach(t),Azr=r(Fre," class method or the "),fee=n(Fre,"A",{href:!0});var FBt=s(fee);yzr=r(FBt,"from_config()"),FBt.forEach(t),Lzr=r(Fre,` class
method.`),Fre.forEach(t),xzr=i(fi),t$=n(fi,"P",{});var $Xe=s(t$);$zr=r($Xe,"This class cannot be instantiated directly using "),$Ee=n($Xe,"CODE",{});var TBt=s($Ee);kzr=r(TBt,"__init__()"),TBt.forEach(t),Szr=r($Xe," (throws an error)."),$Xe.forEach(t),Rzr=i(fi),Kt=n(fi,"DIV",{class:!0});var eA=s(Kt);T(a$.$$.fragment,eA),Pzr=i(eA),kEe=n(eA,"P",{});var MBt=s(kEe);Bzr=r(MBt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),MBt.forEach(t),Izr=i(eA),gf=n(eA,"P",{});var Tre=s(gf);Nzr=r(Tre,`Note:
Loading a model from its configuration file does `),SEe=n(Tre,"STRONG",{});var EBt=s(SEe);qzr=r(EBt,"not"),EBt.forEach(t),jzr=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mee=n(Tre,"A",{href:!0});var CBt=s(mee);Dzr=r(CBt,"from_pretrained()"),CBt.forEach(t),Gzr=r(Tre," to load the model weights."),Tre.forEach(t),Ozr=i(eA),T(v5.$$.fragment,eA),eA.forEach(t),Vzr=i(fi),Ur=n(fi,"DIV",{class:!0});var mi=s(Ur);T(n$.$$.fragment,mi),Xzr=i(mi),REe=n(mi,"P",{});var wBt=s(REe);zzr=r(wBt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),wBt.forEach(t),Wzr=i(mi),yn=n(mi,"P",{});var oA=s(yn);Qzr=r(oA,"The model class to instantiate is selected based on the "),PEe=n(oA,"CODE",{});var ABt=s(PEe);Hzr=r(ABt,"model_type"),ABt.forEach(t),Uzr=r(oA,` property of the config object (either
passed as an argument or loaded from `),BEe=n(oA,"CODE",{});var yBt=s(BEe);Jzr=r(yBt,"pretrained_model_name_or_path"),yBt.forEach(t),Yzr=r(oA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=n(oA,"CODE",{});var LBt=s(IEe);Kzr=r(LBt,"pretrained_model_name_or_path"),LBt.forEach(t),Zzr=r(oA,":"),oA.forEach(t),eWr=i(mi),Ve=n(mi,"UL",{});var Mo=s(Ve);F5=n(Mo,"LI",{});var fDe=s(F5);NEe=n(fDe,"STRONG",{});var xBt=s(NEe);oWr=r(xBt,"albert"),xBt.forEach(t),rWr=r(fDe," \u2014 "),gee=n(fDe,"A",{href:!0});var $Bt=s(gee);tWr=r($Bt,"FlaxAlbertForMultipleChoice"),$Bt.forEach(t),aWr=r(fDe," (ALBERT model)"),fDe.forEach(t),nWr=i(Mo),T5=n(Mo,"LI",{});var mDe=s(T5);qEe=n(mDe,"STRONG",{});var kBt=s(qEe);sWr=r(kBt,"bert"),kBt.forEach(t),lWr=r(mDe," \u2014 "),hee=n(mDe,"A",{href:!0});var SBt=s(hee);iWr=r(SBt,"FlaxBertForMultipleChoice"),SBt.forEach(t),dWr=r(mDe," (BERT model)"),mDe.forEach(t),cWr=i(Mo),M5=n(Mo,"LI",{});var gDe=s(M5);jEe=n(gDe,"STRONG",{});var RBt=s(jEe);fWr=r(RBt,"big_bird"),RBt.forEach(t),mWr=r(gDe," \u2014 "),pee=n(gDe,"A",{href:!0});var PBt=s(pee);gWr=r(PBt,"FlaxBigBirdForMultipleChoice"),PBt.forEach(t),hWr=r(gDe," (BigBird model)"),gDe.forEach(t),pWr=i(Mo),E5=n(Mo,"LI",{});var hDe=s(E5);DEe=n(hDe,"STRONG",{});var BBt=s(DEe);uWr=r(BBt,"distilbert"),BBt.forEach(t),_Wr=r(hDe," \u2014 "),uee=n(hDe,"A",{href:!0});var IBt=s(uee);bWr=r(IBt,"FlaxDistilBertForMultipleChoice"),IBt.forEach(t),vWr=r(hDe," (DistilBERT model)"),hDe.forEach(t),FWr=i(Mo),C5=n(Mo,"LI",{});var pDe=s(C5);GEe=n(pDe,"STRONG",{});var NBt=s(GEe);TWr=r(NBt,"electra"),NBt.forEach(t),MWr=r(pDe," \u2014 "),_ee=n(pDe,"A",{href:!0});var qBt=s(_ee);EWr=r(qBt,"FlaxElectraForMultipleChoice"),qBt.forEach(t),CWr=r(pDe," (ELECTRA model)"),pDe.forEach(t),wWr=i(Mo),w5=n(Mo,"LI",{});var uDe=s(w5);OEe=n(uDe,"STRONG",{});var jBt=s(OEe);AWr=r(jBt,"roberta"),jBt.forEach(t),yWr=r(uDe," \u2014 "),bee=n(uDe,"A",{href:!0});var DBt=s(bee);LWr=r(DBt,"FlaxRobertaForMultipleChoice"),DBt.forEach(t),xWr=r(uDe," (RoBERTa model)"),uDe.forEach(t),$Wr=i(Mo),A5=n(Mo,"LI",{});var _De=s(A5);VEe=n(_De,"STRONG",{});var GBt=s(VEe);kWr=r(GBt,"roformer"),GBt.forEach(t),SWr=r(_De," \u2014 "),vee=n(_De,"A",{href:!0});var OBt=s(vee);RWr=r(OBt,"FlaxRoFormerForMultipleChoice"),OBt.forEach(t),PWr=r(_De," (RoFormer model)"),_De.forEach(t),BWr=i(Mo),y5=n(Mo,"LI",{});var bDe=s(y5);XEe=n(bDe,"STRONG",{});var VBt=s(XEe);IWr=r(VBt,"xlm-roberta"),VBt.forEach(t),NWr=r(bDe," \u2014 "),Fee=n(bDe,"A",{href:!0});var XBt=s(Fee);qWr=r(XBt,"FlaxXLMRobertaForMultipleChoice"),XBt.forEach(t),jWr=r(bDe," (XLM-RoBERTa model)"),bDe.forEach(t),Mo.forEach(t),DWr=i(mi),T(L5.$$.fragment,mi),mi.forEach(t),fi.forEach(t),MOe=i(f),hf=n(f,"H2",{class:!0});var kXe=s(hf);x5=n(kXe,"A",{id:!0,class:!0,href:!0});var zBt=s(x5);zEe=n(zBt,"SPAN",{});var WBt=s(zEe);T(s$.$$.fragment,WBt),WBt.forEach(t),zBt.forEach(t),GWr=i(kXe),WEe=n(kXe,"SPAN",{});var QBt=s(WEe);OWr=r(QBt,"FlaxAutoModelForNextSentencePrediction"),QBt.forEach(t),kXe.forEach(t),EOe=i(f),Mr=n(f,"DIV",{class:!0});var gi=s(Mr);T(l$.$$.fragment,gi),VWr=i(gi),pf=n(gi,"P",{});var Mre=s(pf);XWr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Tee=n(Mre,"A",{href:!0});var HBt=s(Tee);zWr=r(HBt,"from_pretrained()"),HBt.forEach(t),WWr=r(Mre," class method or the "),Mee=n(Mre,"A",{href:!0});var UBt=s(Mee);QWr=r(UBt,"from_config()"),UBt.forEach(t),HWr=r(Mre,` class
method.`),Mre.forEach(t),UWr=i(gi),i$=n(gi,"P",{});var SXe=s(i$);JWr=r(SXe,"This class cannot be instantiated directly using "),QEe=n(SXe,"CODE",{});var JBt=s(QEe);YWr=r(JBt,"__init__()"),JBt.forEach(t),KWr=r(SXe," (throws an error)."),SXe.forEach(t),ZWr=i(gi),Zt=n(gi,"DIV",{class:!0});var rA=s(Zt);T(d$.$$.fragment,rA),eQr=i(rA),HEe=n(rA,"P",{});var YBt=s(HEe);oQr=r(YBt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),YBt.forEach(t),rQr=i(rA),uf=n(rA,"P",{});var Ere=s(uf);tQr=r(Ere,`Note:
Loading a model from its configuration file does `),UEe=n(Ere,"STRONG",{});var KBt=s(UEe);aQr=r(KBt,"not"),KBt.forEach(t),nQr=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=n(Ere,"A",{href:!0});var ZBt=s(Eee);sQr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),lQr=r(Ere," to load the model weights."),Ere.forEach(t),iQr=i(rA),T($5.$$.fragment,rA),rA.forEach(t),dQr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(c$.$$.fragment,hi),cQr=i(hi),JEe=n(hi,"P",{});var eIt=s(JEe);fQr=r(eIt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eIt.forEach(t),mQr=i(hi),Ln=n(hi,"P",{});var tA=s(Ln);gQr=r(tA,"The model class to instantiate is selected based on the "),YEe=n(tA,"CODE",{});var oIt=s(YEe);hQr=r(oIt,"model_type"),oIt.forEach(t),pQr=r(tA,` property of the config object (either
passed as an argument or loaded from `),KEe=n(tA,"CODE",{});var rIt=s(KEe);uQr=r(rIt,"pretrained_model_name_or_path"),rIt.forEach(t),_Qr=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZEe=n(tA,"CODE",{});var tIt=s(ZEe);bQr=r(tIt,"pretrained_model_name_or_path"),tIt.forEach(t),vQr=r(tA,":"),tA.forEach(t),FQr=i(hi),eCe=n(hi,"UL",{});var aIt=s(eCe);k5=n(aIt,"LI",{});var vDe=s(k5);oCe=n(vDe,"STRONG",{});var nIt=s(oCe);TQr=r(nIt,"bert"),nIt.forEach(t),MQr=r(vDe," \u2014 "),Cee=n(vDe,"A",{href:!0});var sIt=s(Cee);EQr=r(sIt,"FlaxBertForNextSentencePrediction"),sIt.forEach(t),CQr=r(vDe," (BERT model)"),vDe.forEach(t),aIt.forEach(t),wQr=i(hi),T(S5.$$.fragment,hi),hi.forEach(t),gi.forEach(t),COe=i(f),_f=n(f,"H2",{class:!0});var RXe=s(_f);R5=n(RXe,"A",{id:!0,class:!0,href:!0});var lIt=s(R5);rCe=n(lIt,"SPAN",{});var iIt=s(rCe);T(f$.$$.fragment,iIt),iIt.forEach(t),lIt.forEach(t),AQr=i(RXe),tCe=n(RXe,"SPAN",{});var dIt=s(tCe);yQr=r(dIt,"FlaxAutoModelForImageClassification"),dIt.forEach(t),RXe.forEach(t),wOe=i(f),Er=n(f,"DIV",{class:!0});var pi=s(Er);T(m$.$$.fragment,pi),LQr=i(pi),bf=n(pi,"P",{});var Cre=s(bf);xQr=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),wee=n(Cre,"A",{href:!0});var cIt=s(wee);$Qr=r(cIt,"from_pretrained()"),cIt.forEach(t),kQr=r(Cre," class method or the "),Aee=n(Cre,"A",{href:!0});var fIt=s(Aee);SQr=r(fIt,"from_config()"),fIt.forEach(t),RQr=r(Cre,` class
method.`),Cre.forEach(t),PQr=i(pi),g$=n(pi,"P",{});var PXe=s(g$);BQr=r(PXe,"This class cannot be instantiated directly using "),aCe=n(PXe,"CODE",{});var mIt=s(aCe);IQr=r(mIt,"__init__()"),mIt.forEach(t),NQr=r(PXe," (throws an error)."),PXe.forEach(t),qQr=i(pi),ea=n(pi,"DIV",{class:!0});var aA=s(ea);T(h$.$$.fragment,aA),jQr=i(aA),nCe=n(aA,"P",{});var gIt=s(nCe);DQr=r(gIt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),gIt.forEach(t),GQr=i(aA),vf=n(aA,"P",{});var wre=s(vf);OQr=r(wre,`Note:
Loading a model from its configuration file does `),sCe=n(wre,"STRONG",{});var hIt=s(sCe);VQr=r(hIt,"not"),hIt.forEach(t),XQr=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yee=n(wre,"A",{href:!0});var pIt=s(yee);zQr=r(pIt,"from_pretrained()"),pIt.forEach(t),WQr=r(wre," to load the model weights."),wre.forEach(t),QQr=i(aA),T(P5.$$.fragment,aA),aA.forEach(t),HQr=i(pi),Yr=n(pi,"DIV",{class:!0});var ui=s(Yr);T(p$.$$.fragment,ui),UQr=i(ui),lCe=n(ui,"P",{});var uIt=s(lCe);JQr=r(uIt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),uIt.forEach(t),YQr=i(ui),xn=n(ui,"P",{});var nA=s(xn);KQr=r(nA,"The model class to instantiate is selected based on the "),iCe=n(nA,"CODE",{});var _It=s(iCe);ZQr=r(_It,"model_type"),_It.forEach(t),eHr=r(nA,` property of the config object (either
passed as an argument or loaded from `),dCe=n(nA,"CODE",{});var bIt=s(dCe);oHr=r(bIt,"pretrained_model_name_or_path"),bIt.forEach(t),rHr=r(nA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=n(nA,"CODE",{});var vIt=s(cCe);tHr=r(vIt,"pretrained_model_name_or_path"),vIt.forEach(t),aHr=r(nA,":"),nA.forEach(t),nHr=i(ui),u$=n(ui,"UL",{});var BXe=s(u$);B5=n(BXe,"LI",{});var FDe=s(B5);fCe=n(FDe,"STRONG",{});var FIt=s(fCe);sHr=r(FIt,"beit"),FIt.forEach(t),lHr=r(FDe," \u2014 "),Lee=n(FDe,"A",{href:!0});var TIt=s(Lee);iHr=r(TIt,"FlaxBeitForImageClassification"),TIt.forEach(t),dHr=r(FDe," (BEiT model)"),FDe.forEach(t),cHr=i(BXe),I5=n(BXe,"LI",{});var TDe=s(I5);mCe=n(TDe,"STRONG",{});var MIt=s(mCe);fHr=r(MIt,"vit"),MIt.forEach(t),mHr=r(TDe," \u2014 "),xee=n(TDe,"A",{href:!0});var EIt=s(xee);gHr=r(EIt,"FlaxViTForImageClassification"),EIt.forEach(t),hHr=r(TDe," (ViT model)"),TDe.forEach(t),BXe.forEach(t),pHr=i(ui),T(N5.$$.fragment,ui),ui.forEach(t),pi.forEach(t),AOe=i(f),Ff=n(f,"H2",{class:!0});var IXe=s(Ff);q5=n(IXe,"A",{id:!0,class:!0,href:!0});var CIt=s(q5);gCe=n(CIt,"SPAN",{});var wIt=s(gCe);T(_$.$$.fragment,wIt),wIt.forEach(t),CIt.forEach(t),uHr=i(IXe),hCe=n(IXe,"SPAN",{});var AIt=s(hCe);_Hr=r(AIt,"FlaxAutoModelForVision2Seq"),AIt.forEach(t),IXe.forEach(t),yOe=i(f),Cr=n(f,"DIV",{class:!0});var _i=s(Cr);T(b$.$$.fragment,_i),bHr=i(_i),Tf=n(_i,"P",{});var Are=s(Tf);vHr=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$ee=n(Are,"A",{href:!0});var yIt=s($ee);FHr=r(yIt,"from_pretrained()"),yIt.forEach(t),THr=r(Are," class method or the "),kee=n(Are,"A",{href:!0});var LIt=s(kee);MHr=r(LIt,"from_config()"),LIt.forEach(t),EHr=r(Are,` class
method.`),Are.forEach(t),CHr=i(_i),v$=n(_i,"P",{});var NXe=s(v$);wHr=r(NXe,"This class cannot be instantiated directly using "),pCe=n(NXe,"CODE",{});var xIt=s(pCe);AHr=r(xIt,"__init__()"),xIt.forEach(t),yHr=r(NXe," (throws an error)."),NXe.forEach(t),LHr=i(_i),oa=n(_i,"DIV",{class:!0});var sA=s(oa);T(F$.$$.fragment,sA),xHr=i(sA),uCe=n(sA,"P",{});var $It=s(uCe);$Hr=r($It,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),$It.forEach(t),kHr=i(sA),Mf=n(sA,"P",{});var yre=s(Mf);SHr=r(yre,`Note:
Loading a model from its configuration file does `),_Ce=n(yre,"STRONG",{});var kIt=s(_Ce);RHr=r(kIt,"not"),kIt.forEach(t),PHr=r(yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),See=n(yre,"A",{href:!0});var SIt=s(See);BHr=r(SIt,"from_pretrained()"),SIt.forEach(t),IHr=r(yre," to load the model weights."),yre.forEach(t),NHr=i(sA),T(j5.$$.fragment,sA),sA.forEach(t),qHr=i(_i),Kr=n(_i,"DIV",{class:!0});var bi=s(Kr);T(T$.$$.fragment,bi),jHr=i(bi),bCe=n(bi,"P",{});var RIt=s(bCe);DHr=r(RIt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),RIt.forEach(t),GHr=i(bi),$n=n(bi,"P",{});var lA=s($n);OHr=r(lA,"The model class to instantiate is selected based on the "),vCe=n(lA,"CODE",{});var PIt=s(vCe);VHr=r(PIt,"model_type"),PIt.forEach(t),XHr=r(lA,` property of the config object (either
passed as an argument or loaded from `),FCe=n(lA,"CODE",{});var BIt=s(FCe);zHr=r(BIt,"pretrained_model_name_or_path"),BIt.forEach(t),WHr=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(lA,"CODE",{});var IIt=s(TCe);QHr=r(IIt,"pretrained_model_name_or_path"),IIt.forEach(t),HHr=r(lA,":"),lA.forEach(t),UHr=i(bi),MCe=n(bi,"UL",{});var NIt=s(MCe);D5=n(NIt,"LI",{});var MDe=s(D5);ECe=n(MDe,"STRONG",{});var qIt=s(ECe);JHr=r(qIt,"vision-encoder-decoder"),qIt.forEach(t),YHr=r(MDe," \u2014 "),Ree=n(MDe,"A",{href:!0});var jIt=s(Ree);KHr=r(jIt,"FlaxVisionEncoderDecoderModel"),jIt.forEach(t),ZHr=r(MDe," (Vision Encoder decoder model)"),MDe.forEach(t),NIt.forEach(t),eUr=i(bi),T(G5.$$.fragment,bi),bi.forEach(t),_i.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(zqt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Sn,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoConfig"),c(Pn,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoModel"),c(Bn,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoTokenizer"),c(wi,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertModel"),c($f,"id","extending-the-auto-classes"),c($f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($f,"href","#extending-the-auto-classes"),c(Ai,"class","relative group"),c(Sf,"id","transformers.AutoConfig"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#transformers.AutoConfig"),c(yi,"class","relative group"),c(Vk,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(Xk,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertConfig"),c(zk,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartConfig"),c(Wk,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitConfig"),c(Qk,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertConfig"),c(Hk,"href","/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(Uk,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdConfig"),c(Jk,"href","/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(Yk,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(Kk,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(Zk,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomConfig"),c(eS,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertConfig"),c(oS,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineConfig"),c(rS,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPConfig"),c(tS,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertConfig"),c(aS,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextConfig"),c(nS,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLConfig"),c(sS,"href","/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtConfig"),c(lS,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(iS,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(dS,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(cS,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaConfig"),c(fS,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(mS,"href","/docs/transformers/pr_17639/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(gS,"href","/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTConfig"),c(hS,"href","/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrConfig"),c(pS,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertConfig"),c(uS,"href","/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRConfig"),c(_S,"href","/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTConfig"),c(bS,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraConfig"),c(vS,"href","/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(FS,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertConfig"),c(TS,"href","/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaConfig"),c(MS,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetConfig"),c(ES,"href","/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTConfig"),c(CS,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelConfig"),c(wS,"href","/docs/transformers/pr_17639/en/model_doc/glpn#transformers.GLPNConfig"),c(AS,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Config"),c(yS,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(LS,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(xS,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJConfig"),c($S,"href","/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertConfig"),c(kS,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertConfig"),c(SS,"href","/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(RS,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(PS,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(BS,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(IS,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDConfig"),c(NS,"href","/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitConfig"),c(qS,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerConfig"),c(jS,"href","/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeConfig"),c(DS,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertConfig"),c(GS,"href","/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100Config"),c(OS,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianConfig"),c(VS,"href","/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(XS,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartConfig"),c(zS,"href","/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTConfig"),c(WS,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(QS,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(HS,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetConfig"),c(US,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Config"),c(JS,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(YS,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(KS,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTConfig"),c(ZS,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusConfig"),c(eR,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverConfig"),c(oR,"href","/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartConfig"),c(rR,"href","/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(tR,"href","/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(aR,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(nR,"href","/docs/transformers/pr_17639/en/model_doc/rag#transformers.RagConfig"),c(sR,"href","/docs/transformers/pr_17639/en/model_doc/realm#transformers.RealmConfig"),c(lR,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerConfig"),c(iR,"href","/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetConfig"),c(dR,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertConfig"),c(cR,"href","/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetConfig"),c(fR,"href","/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertConfig"),c(mR,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaConfig"),c(gR,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerConfig"),c(hR,"href","/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerConfig"),c(pR,"href","/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWConfig"),c(uR,"href","/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDConfig"),c(_R,"href","/docs/transformers/pr_17639/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(bR,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(vR,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(FR,"href","/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterConfig"),c(TR,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(MR,"href","/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinConfig"),c(ER,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Config"),c(CR,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasConfig"),c(wR,"href","/docs/transformers/pr_17639/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(AR,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(yR,"href","/docs/transformers/pr_17639/en/model_doc/trocr#transformers.TrOCRConfig"),c(LR,"href","/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(xR,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c($R,"href","/docs/transformers/pr_17639/en/model_doc/van#transformers.VanConfig"),c(kR,"href","/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltConfig"),c(SR,"href","/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(RR,"href","/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(PR,"href","/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(BR,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTConfig"),c(IR,"href","/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(NR,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(qR,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(jR,"href","/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMConfig"),c(DR,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMConfig"),c(GR,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMConfig"),c(OR,"href","/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(VR,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(XR,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(zR,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetConfig"),c(WR,"href","/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosConfig"),c(QR,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoConfig"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jg,"id","transformers.AutoTokenizer"),c(jg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jg,"href","#transformers.AutoTokenizer"),c(xi,"class","relative group"),c(HR,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(UR,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertTokenizer"),c(JR,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(YR,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartTokenizer"),c(KR,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartTokenizerFast"),c(ZR,"href","/docs/transformers/pr_17639/en/model_doc/barthez#transformers.BarthezTokenizer"),c(eP,"href","/docs/transformers/pr_17639/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(oP,"href","/docs/transformers/pr_17639/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(rP,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizer"),c(tP,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizerFast"),c(aP,"href","/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(nP,"href","/docs/transformers/pr_17639/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(sP,"href","/docs/transformers/pr_17639/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(lP,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(iP,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(dP,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(cP,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(fP,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(mP,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(gP,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(hP,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(pP,"href","/docs/transformers/pr_17639/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(uP,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertTokenizer"),c(_P,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(bP,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineTokenizer"),c(vP,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPTokenizer"),c(FP,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(TP,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(MP,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(EP,"href","/docs/transformers/pr_17639/en/model_doc/cpm#transformers.CpmTokenizer"),c(CP,"href","/docs/transformers/pr_17639/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(wP,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(AP,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizer"),c(yP,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LP,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaTokenizer"),c(xP,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c($P,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(kP,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(SP,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(RP,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(PP,"href","/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(BP,"href","/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(IP,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraTokenizer"),c(NP,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(qP,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(jP,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetTokenizer"),c(DP,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(GP,"href","/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(OP,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelTokenizer"),c(VP,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(XP,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(zP,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(WP,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(QP,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(HP,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(UP,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(JP,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(YP,"href","/docs/transformers/pr_17639/en/model_doc/herbert#transformers.HerbertTokenizer"),c(KP,"href","/docs/transformers/pr_17639/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(ZP,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(eB,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizer"),c(oB,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(rB,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(tB,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(aB,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(nB,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(sB,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(lB,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(iB,"href","/docs/transformers/pr_17639/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(dB,"href","/docs/transformers/pr_17639/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(cB,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDTokenizer"),c(fB,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDTokenizerFast"),c(mB,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerTokenizer"),c(gB,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(hB,"href","/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeTokenizer"),c(pB,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(uB,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(_B,"href","/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(bB,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianTokenizer"),c(vB,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartTokenizer"),c(FB,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(TB,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(MB,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(EB,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizer"),c(CB,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizerFast"),c(wB,"href","/docs/transformers/pr_17639/en/model_doc/mluke#transformers.MLukeTokenizer"),c(AB,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(yB,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(LB,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(xB,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c($B,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Tokenizer"),c(kB,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5TokenizerFast"),c(SB,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertTokenizer"),c(RB,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(PB,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(BB,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(IB,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(NB,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(qB,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(jB,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(DB,"href","/docs/transformers/pr_17639/en/model_doc/phobert#transformers.PhobertTokenizer"),c(GB,"href","/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartTokenizer"),c(OB,"href","/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(VB,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizer"),c(XB,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizerFast"),c(zB,"href","/docs/transformers/pr_17639/en/model_doc/rag#transformers.RagTokenizer"),c(WB,"href","/docs/transformers/pr_17639/en/model_doc/realm#transformers.RealmTokenizer"),c(QB,"href","/docs/transformers/pr_17639/en/model_doc/realm#transformers.RealmTokenizerFast"),c(HB,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerTokenizer"),c(UB,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(JB,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertTokenizer"),c(YB,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(KB,"href","/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(ZB,"href","/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(eI,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizer"),c(oI,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(rI,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(tI,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(aI,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(nI,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(sI,"href","/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterTokenizer"),c(lI,"href","/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(iI,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(dI,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(cI,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Tokenizer"),c(fI,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5TokenizerFast"),c(mI,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasTokenizer"),c(gI,"href","/docs/transformers/pr_17639/en/model_doc/tapex#transformers.TapexTokenizer"),c(hI,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(pI,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizer"),c(uI,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizerFast"),c(_I,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizer"),c(bI,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertTokenizerFast"),c(vI,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(FI,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TI,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(MI,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMTokenizer"),c(EI,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(CI,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMTokenizer"),c(wI,"href","/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(AI,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(yI,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(LI,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizer"),c(xI,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c($I,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(kI,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(SI,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertTokenizer"),c(RI,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Th,"id","transformers.AutoFeatureExtractor"),c(Th,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Th,"href","#transformers.AutoFeatureExtractor"),c($i,"class","relative group"),c(PI,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(BI,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(II,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(NI,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(qI,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(jI,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(DI,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(GI,"href","/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(OI,"href","/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(VI,"href","/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(XI,"href","/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(zI,"href","/docs/transformers/pr_17639/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(WI,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(QI,"href","/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(HI,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(UI,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(JI,"href","/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(YI,"href","/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(KI,"href","/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(ZI,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(eN,"href","/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(oN,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rN,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(tN,"href","/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(aN,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(nN,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(sN,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(dN,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(mN,"href","/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tp,"id","transformers.AutoProcessor"),c(tp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tp,"href","#transformers.AutoProcessor"),c(ki,"class","relative group"),c(gN,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(hN,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPProcessor"),c(pN,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(uN,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(_N,"href","/docs/transformers/pr_17639/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(bN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(vN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(FN,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(TN,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(MN,"href","/docs/transformers/pr_17639/en/model_doc/trocr#transformers.TrOCRProcessor"),c(EN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(CN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(wN,"href","/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltProcessor"),c(AN,"href","/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(yN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(LN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(xN,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ep,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cp,"id","transformers.AutoModel"),c(Cp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Cp,"href","#transformers.AutoModel"),c(Ri,"class","relative group"),c($N,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kN,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SN,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RN,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertModel"),c(PN,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartModel"),c(BN,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitModel"),c(IN,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertModel"),c(NN,"href","/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(qN,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdModel"),c(jN,"href","/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(DN,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(GN,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(ON,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomModel"),c(VN,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertModel"),c(XN,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineModel"),c(zN,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.CLIPModel"),c(WN,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertModel"),c(QN,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextModel"),c(HN,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLModel"),c(UN,"href","/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtModel"),c(JN,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(YN,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(KN,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(ZN,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaModel"),c(eq,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(oq,"href","/docs/transformers/pr_17639/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(rq,"href","/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTModel"),c(tq,"href","/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrModel"),c(aq,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertModel"),c(nq,"href","/docs/transformers/pr_17639/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(sq,"href","/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTModel"),c(lq,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraModel"),c(iq,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertModel"),c(dq,"href","/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaModel"),c(cq,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetModel"),c(fq,"href","/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTModel"),c(mq,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelModel"),c(gq,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelBaseModel"),c(hq,"href","/docs/transformers/pr_17639/en/model_doc/glpn#transformers.GLPNModel"),c(pq,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2Model"),c(uq,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(_q,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(bq,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJModel"),c(vq,"href","/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertModel"),c(Fq,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertModel"),c(Tq,"href","/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Mq,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Eq,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Cq,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(wq,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDModel"),c(Aq,"href","/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitModel"),c(yq,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerModel"),c(Lq,"href","/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeModel"),c(xq,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertModel"),c($q,"href","/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100Model"),c(kq,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianModel"),c(Sq,"href","/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Rq,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartModel"),c(Pq,"href","/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTModel"),c(Bq,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Iq,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertModel"),c(Nq,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetModel"),c(qq,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5Model"),c(jq,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerModel"),c(Dq,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(Gq,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTModel"),c(Oq,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusModel"),c(Vq,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverModel"),c(Xq,"href","/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartModel"),c(zq,"href","/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerModel"),c(Wq,"href","/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Qq,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Hq,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerModel"),c(Uq,"href","/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetModel"),c(Jq,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertModel"),c(Yq,"href","/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetModel"),c(Kq,"href","/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertModel"),c(Zq,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaModel"),c(ej,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerModel"),c(oj,"href","/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerModel"),c(rj,"href","/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWModel"),c(tj,"href","/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDModel"),c(aj,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(nj,"href","/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterModel"),c(sj,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(lj,"href","/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinModel"),c(ij,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5Model"),c(dj,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasModel"),c(cj,"href","/docs/transformers/pr_17639/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(fj,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(mj,"href","/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechModel"),c(gj,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(hj,"href","/docs/transformers/pr_17639/en/model_doc/van#transformers.VanModel"),c(pj,"href","/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltModel"),c(uj,"href","/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(_j,"href","/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertModel"),c(bj,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTModel"),c(vj,"href","/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Fj,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Tj,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Mj,"href","/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMModel"),c(Ej,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMModel"),c(Cj,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMModel"),c(wj,"href","/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Aj,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(yj,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Lj,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetModel"),c(xj,"href","/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosModel"),c($j,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C_,"id","transformers.AutoModelForPreTraining"),c(C_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C_,"href","#transformers.AutoModelForPreTraining"),c(Ii,"class","relative group"),c(kj,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Sj,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Rj,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Pj,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForPreTraining"),c(Bj,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Ij,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForPreTraining"),c(Nj,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(qj,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForCausalLM"),c(jj,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Dj,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Gj,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(Oj,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Vj,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(Xj,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(zj,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForPreTraining"),c(Wj,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Qj,"href","/docs/transformers/pr_17639/en/model_doc/flava#transformers.FlavaForPreTraining"),c(Hj,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForPreTraining"),c(Uj,"href","/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(Jj,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(Yj,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Kj,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(Zj,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(eD,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(oD,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(rD,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(tD,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(aD,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(nD,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(sD,"href","/docs/transformers/pr_17639/en/model_doc/retribert#transformers.RetriBertModel"),c(lD,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(iD,"href","/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(dD,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(cD,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(fD,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(mD,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(gD,"href","/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(hD,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(pD,"href","/docs/transformers/pr_17639/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(uD,"href","/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(_D,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(bD,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(vD,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FD,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TD,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MD,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_1,"id","transformers.AutoModelForCausalLM"),c(_1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_1,"href","#transformers.AutoModelForCausalLM"),c(ji,"class","relative group"),c(ED,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CD,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wD,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AD,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForCausalLM"),c(yD,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertLMHeadModel"),c(LD,"href","/docs/transformers/pr_17639/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(xD,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c($D,"href","/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(kD,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(SD,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(RD,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForCausalLM"),c(PD,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(BD,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(ID,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(ND,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForCausalLM"),c(qD,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(jD,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(DD,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(GD,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(OD,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianForCausalLM"),c(VD,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForCausalLM"),c(XD,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(zD,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(WD,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.OPTForCausalLM"),c(QD,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(HD,"href","/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(UD,"href","/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(JD,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(YD,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(KD,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(ZD,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(eG,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(oG,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(rG,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(tG,"href","/docs/transformers/pr_17639/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(aG,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(nG,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(sG,"href","/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(lG,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(iG,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(dG,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nb,"id","transformers.AutoModelForMaskedLM"),c(nb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nb,"href","#transformers.AutoModelForMaskedLM"),c(Oi,"class","relative group"),c(cG,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fG,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mG,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gG,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(hG,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(pG,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForMaskedLM"),c(uG,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(_G,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(bG,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(vG,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(FG,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(TG,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(MG,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(EG,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(CG,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(wG,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(AG,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(yG,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(LG,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(xG,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c($G,"href","/docs/transformers/pr_17639/en/model_doc/luke#transformers.LukeForMaskedLM"),c(kG,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(SG,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(RG,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(PG,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(BG,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(IG,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(NG,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(qG,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(jG,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(DG,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(GG,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(OG,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(VG,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(XG,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(zG,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(WG,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(QG,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zb,"id","transformers.AutoModelForSeq2SeqLM"),c(zb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zb,"href","#transformers.AutoModelForSeq2SeqLM"),c(zi,"class","relative group"),c(HG,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UG,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JG,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YG,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(KG,"href","/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(ZG,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(eO,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(oO,"href","/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(rO,"href","/docs/transformers/pr_17639/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(tO,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(aO,"href","/docs/transformers/pr_17639/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(nO,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.MarianMTModel"),c(sO,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(lO,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(iO,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(dO,"href","/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(cO,"href","/docs/transformers/pr_17639/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(fO,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(mO,"href","/docs/transformers/pr_17639/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f2,"id","transformers.AutoModelForSequenceClassification"),c(f2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f2,"href","#transformers.AutoModelForSequenceClassification"),c(Hi,"class","relative group"),c(gO,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hO,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pO,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uO,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(_O,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForSequenceClassification"),c(bO,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForSequenceClassification"),c(vO,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(FO,"href","/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(TO,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(MO,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(EO,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(CO,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(wO,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(AO,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(yO,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(LO,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(xO,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c($O,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(kO,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(SO,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(RO,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(PO,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(BO,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(IO,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(NO,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(qO,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(jO,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(DO,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(GO,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDForSequenceClassification"),c(OO,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(VO,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(XO,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(zO,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(QO,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17639/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dv,"id","transformers.AutoModelForMultipleChoice"),c(dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dv,"href","#transformers.AutoModelForMultipleChoice"),c(Yi,"class","relative group"),c(cV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gV,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(hV,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForMultipleChoice"),c(pV,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(uV,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(_V,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(bV,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(vV,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(FV,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(TV,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(MV,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(EV,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(CV,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(wV,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(AV,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(yV,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(LV,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(xV,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c($V,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(kV,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(SV,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(RV,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(PV,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(BV,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(IV,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(NV,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(qV,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(jV,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(DV,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(GV,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ov,"id","transformers.AutoModelForNextSentencePrediction"),c(Ov,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ov,"href","#transformers.AutoModelForNextSentencePrediction"),c(ed,"class","relative group"),c(OV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zV,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(WV,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(QV,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(HV,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(UV,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yv,"id","transformers.AutoModelForTokenClassification"),c(Yv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yv,"href","#transformers.AutoModelForTokenClassification"),c(td,"class","relative group"),c(JV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KV,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZV,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(eX,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForTokenClassification"),c(oX,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(rX,"href","/docs/transformers/pr_17639/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(tX,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(aX,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForTokenClassification"),c(nX,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(sX,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(lX,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(iX,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(dX,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(cX,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(fX,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(mX,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(gX,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(hX,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(pX,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(uX,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(_X,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(bX,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(vX,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(FX,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(TX,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(MX,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(EX,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(CX,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(wX,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(AX,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(yX,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(LX,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(xX,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForTokenClassification"),c($X,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(kX,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(SX,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(RX,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I3,"id","transformers.AutoModelForQuestionAnswering"),c(I3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I3,"href","#transformers.AutoModelForQuestionAnswering"),c(sd,"class","relative group"),c(PX,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BX,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IX,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NX,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(qX,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(jX,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(DX,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(GX,"href","/docs/transformers/pr_17639/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(OX,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(VX,"href","/docs/transformers/pr_17639/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(XX,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(zX,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(WX,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(QX,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(HX,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(UX,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(JX,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(YX,"href","/docs/transformers/pr_17639/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(KX,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(ZX,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(ez,"href","/docs/transformers/pr_17639/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(oz,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(rz,"href","/docs/transformers/pr_17639/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(tz,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(az,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(nz,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(sz,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(lz,"href","/docs/transformers/pr_17639/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(iz,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(dz,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(cz,"href","/docs/transformers/pr_17639/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(fz,"href","/docs/transformers/pr_17639/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(mz,"href","/docs/transformers/pr_17639/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(gz,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(hz,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(pz,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(uz,"href","/docs/transformers/pr_17639/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(_z,"href","/docs/transformers/pr_17639/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(vz,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(Mz,"href","/docs/transformers/pr_17639/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AF,"id","transformers.AutoModelForTableQuestionAnswering"),c(AF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(dd,"class","relative group"),c(Ez,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Az,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kF,"id","transformers.AutoModelForImageClassification"),c(kF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kF,"href","#transformers.AutoModelForImageClassification"),c(md,"class","relative group"),c(yz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($z,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitForImageClassification"),c(kz,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(Sz,"href","/docs/transformers/pr_17639/en/model_doc/cvt#transformers.CvtForImageClassification"),c(Rz,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(Pz,"href","/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTForImageClassification"),c(Bz,"href","/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(Iz,"href","/docs/transformers/pr_17639/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(Nz,"href","/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitForImageClassification"),c(qz,"href","/docs/transformers/pr_17639/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(jz,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(Dz,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(Gz,"href","/docs/transformers/pr_17639/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(Oz,"href","/docs/transformers/pr_17639/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(Vz,"href","/docs/transformers/pr_17639/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(Xz,"href","/docs/transformers/pr_17639/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(zz,"href","/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(Wz,"href","/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinForImageClassification"),c(Qz,"href","/docs/transformers/pr_17639/en/model_doc/van#transformers.VanForImageClassification"),c(Hz,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QF,"id","transformers.AutoModelForVision2Seq"),c(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QF,"href","#transformers.AutoModelForVision2Seq"),c(pd,"class","relative group"),c(Uz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kz,"href","/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KF,"id","transformers.AutoModelForVisualQuestionAnswering"),c(KF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KF,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(bd,"class","relative group"),c(Zz,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rW,"href","/docs/transformers/pr_17639/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t6,"id","transformers.AutoModelForAudioClassification"),c(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t6,"href","#transformers.AutoModelForAudioClassification"),c(Td,"class","relative group"),c(tW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sW,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(lW,"href","/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(iW,"href","/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(dW,"href","/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(cW,"href","/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(fW,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(mW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(gW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(hW,"href","/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u6,"id","transformers.AutoModelForAudioFrameClassification"),c(u6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u6,"href","#transformers.AutoModelForAudioFrameClassification"),c(Cd,"class","relative group"),c(pW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_W,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bW,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(vW,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(FW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(TW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(MW,"href","/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w6,"id","transformers.AutoModelForCTC"),c(w6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w6,"href","#transformers.AutoModelForCTC"),c(yd,"class","relative group"),c(EW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AW,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(yW,"href","/docs/transformers/pr_17639/en/model_doc/hubert#transformers.HubertForCTC"),c(LW,"href","/docs/transformers/pr_17639/en/model_doc/mctct#transformers.MCTCTForCTC"),c(xW,"href","/docs/transformers/pr_17639/en/model_doc/sew#transformers.SEWForCTC"),c($W,"href","/docs/transformers/pr_17639/en/model_doc/sew-d#transformers.SEWDForCTC"),c(kW,"href","/docs/transformers/pr_17639/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(SW,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(RW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(PW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(BW,"href","/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j6,"id","transformers.AutoModelForSpeechSeq2Seq"),c(j6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j6,"href","#transformers.AutoModelForSpeechSeq2Seq"),c($d,"class","relative group"),c(IW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/pr_17639/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(DW,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z6,"id","transformers.AutoModelForAudioXVector"),c(z6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z6,"href","#transformers.AutoModelForAudioXVector"),c(Rd,"class","relative group"),c(GW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(zW,"href","/docs/transformers/pr_17639/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(WW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(QW,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(HW,"href","/docs/transformers/pr_17639/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eT,"id","transformers.AutoModelForMaskedImageModeling"),c(eT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eT,"href","#transformers.AutoModelForMaskedImageModeling"),c(Id,"class","relative group"),c(UW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YW,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KW,"href","/docs/transformers/pr_17639/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(ZW,"href","/docs/transformers/pr_17639/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(eQ,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lT,"id","transformers.AutoModelForObjectDetection"),c(lT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lT,"href","#transformers.AutoModelForObjectDetection"),c(Dd,"class","relative group"),c(oQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aQ,"href","/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrForObjectDetection"),c(nQ,"href","/docs/transformers/pr_17639/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gT,"id","transformers.AutoModelForImageSegmentation"),c(gT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gT,"href","#transformers.AutoModelForImageSegmentation"),c(Vd,"class","relative group"),c(sQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dQ,"href","/docs/transformers/pr_17639/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bT,"id","transformers.AutoModelForSemanticSegmentation"),c(bT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bT,"href","#transformers.AutoModelForSemanticSegmentation"),c(Wd,"class","relative group"),c(cQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gQ,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(hQ,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(pQ,"href","/docs/transformers/pr_17639/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(uQ,"href","/docs/transformers/pr_17639/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AT,"id","transformers.AutoModelForInstanceSegmentation"),c(AT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AT,"href","#transformers.AutoModelForInstanceSegmentation"),c(Ud,"class","relative group"),c(_Q,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FQ,"href","/docs/transformers/pr_17639/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kT,"id","transformers.TFAutoModel"),c(kT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kT,"href","#transformers.TFAutoModel"),c(Kd,"class","relative group"),c(TQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EQ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CQ,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertModel"),c(wQ,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.TFBartModel"),c(AQ,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertModel"),c(yQ,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(LQ,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(xQ,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertModel"),c($Q,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.TFCLIPModel"),c(kQ,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertModel"),c(SQ,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.TFConvNextModel"),c(RQ,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLModel"),c(PQ,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(BQ,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaModel"),c(IQ,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(NQ,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(qQ,"href","/docs/transformers/pr_17639/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(jQ,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraModel"),c(DQ,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(GQ,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelModel"),c(OQ,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(VQ,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2Model"),c(XQ,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJModel"),c(zQ,"href","/docs/transformers/pr_17639/en/model_doc/hubert#transformers.TFHubertModel"),c(WQ,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(QQ,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.TFLEDModel"),c(HQ,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerModel"),c(UQ,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.TFLxmertModel"),c(JQ,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.TFMarianModel"),c(YQ,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.TFMBartModel"),c(KQ,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(ZQ,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetModel"),c(eH,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.TFMT5Model"),c(oH,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(rH,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.TFOPTModel"),c(tH,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.TFPegasusModel"),c(aH,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertModel"),c(nH,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaModel"),c(sH,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerModel"),c(lH,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(iH,"href","/docs/transformers/pr_17639/en/model_doc/swin#transformers.TFSwinModel"),c(dH,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.TFT5Model"),c(cH,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasModel"),c(fH,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(mH,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.TFViTModel"),c(gH,"href","/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(hH,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(pH,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMModel"),c(uH,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(_H,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A7,"id","transformers.TFAutoModelForPreTraining"),c(A7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A7,"href","#transformers.TFAutoModelForPreTraining"),c(oc,"class","relative group"),c(bH,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vH,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FH,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TH,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(MH,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(EH,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForPreTraining"),c(CH,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(wH,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(AH,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(yH,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(LH,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(xH,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c($H,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(kH,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(SH,"href","/docs/transformers/pr_17639/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(RH,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(PH,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(BH,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(IH,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(NH,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(qH,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(jH,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(DH,"href","/docs/transformers/pr_17639/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(GH,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(OH,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(VH,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K7,"id","transformers.TFAutoModelForCausalLM"),c(K7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K7,"href","#transformers.TFAutoModelForCausalLM"),c(ac,"class","relative group"),c(XH,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zH,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WH,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QH,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(HH,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(UH,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(JH,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(YH,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(KH,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(ZH,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(eU,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(oU,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(rU,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(tU,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(aU,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(nU,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h9,"id","transformers.TFAutoModelForImageClassification"),c(h9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h9,"href","#transformers.TFAutoModelForImageClassification"),c(lc,"class","relative group"),c(sU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dU,"href","/docs/transformers/pr_17639/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(cU,"href","/docs/transformers/pr_17639/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(fU,"href","/docs/transformers/pr_17639/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(mU,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.TFViTForImageClassification"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T9,"id","transformers.TFAutoModelForMaskedLM"),c(T9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T9,"href","#transformers.TFAutoModelForMaskedLM"),c(cc,"class","relative group"),c(gU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uU,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(_U,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(bU,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(vU,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(FU,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(TU,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(MU,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(EU,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(CU,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(wU,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(AU,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(yU,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(LU,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(xU,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c($U,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(kU,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(SU,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(RU,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(PU,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(BU,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X9,"id","transformers.TFAutoModelForSeq2SeqLM"),c(X9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X9,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(gc,"class","relative group"),c(IU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jU,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(DU,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(GU,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(OU,"href","/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(VU,"href","/docs/transformers/pr_17639/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(XU,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.TFMarianMTModel"),c(zU,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(WU,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(QU,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(HU,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tM,"id","transformers.TFAutoModelForSequenceClassification"),c(tM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tM,"href","#transformers.TFAutoModelForSequenceClassification"),c(uc,"class","relative group"),c(UU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YU,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KU,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(ZU,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(eJ,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(oJ,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(rJ,"href","/docs/transformers/pr_17639/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(tJ,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(aJ,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(nJ,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(sJ,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(lJ,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(iJ,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(dJ,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(cJ,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(fJ,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(mJ,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(gJ,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(hJ,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(pJ,"href","/docs/transformers/pr_17639/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(uJ,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(_J,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(bJ,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(vJ,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(FJ,"href","/docs/transformers/pr_17639/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(TJ,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(MJ,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(EJ,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SM,"id","transformers.TFAutoModelForMultipleChoice"),c(SM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SM,"href","#transformers.TFAutoModelForMultipleChoice"),c(vc,"class","relative group"),c(CJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(AJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yJ,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(LJ,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(xJ,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c($J,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(kJ,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(SJ,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(RJ,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(PJ,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(BJ,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(IJ,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(NJ,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(qJ,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(jJ,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(DJ,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(GJ,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(OJ,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(VJ,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KM,"id","transformers.TFAutoModelForNextSentencePrediction"),c(KM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KM,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Mc,"class","relative group"),c(XJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QJ,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(HJ,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t4,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(t4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t4,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(wc,"class","relative group"),c(UJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KJ,"href","/docs/transformers/pr_17639/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l4,"id","transformers.TFAutoModelForTokenClassification"),c(l4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l4,"href","#transformers.TFAutoModelForTokenClassification"),c(Lc,"class","relative group"),c(ZJ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rY,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(tY,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(aY,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(nY,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(sY,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(lY,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(iY,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(dY,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(cY,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(fY,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(mY,"href","/docs/transformers/pr_17639/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(gY,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(hY,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(pY,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(uY,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(_Y,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(bY,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(vY,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(FY,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(TY,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($4,"id","transformers.TFAutoModelForQuestionAnswering"),c($4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($4,"href","#transformers.TFAutoModelForQuestionAnswering"),c(kc,"class","relative group"),c(MY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wY,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(AY,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(yY,"href","/docs/transformers/pr_17639/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(LY,"href","/docs/transformers/pr_17639/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(xY,"href","/docs/transformers/pr_17639/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c($Y,"href","/docs/transformers/pr_17639/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(kY,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(SY,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(RY,"href","/docs/transformers/pr_17639/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(PY,"href","/docs/transformers/pr_17639/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(BY,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(IY,"href","/docs/transformers/pr_17639/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(NY,"href","/docs/transformers/pr_17639/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(qY,"href","/docs/transformers/pr_17639/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(jY,"href","/docs/transformers/pr_17639/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(DY,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(GY,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(OY,"href","/docs/transformers/pr_17639/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(VY,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(XY,"href","/docs/transformers/pr_17639/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z4,"id","transformers.TFAutoModelForVision2Seq"),c(Z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z4,"href","#transformers.TFAutoModelForVision2Seq"),c(Pc,"class","relative group"),c(zY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HY,"href","/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tE,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(tE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tE,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Nc,"class","relative group"),c(UY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KY,"href","/docs/transformers/pr_17639/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lE,"id","transformers.FlaxAutoModel"),c(lE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lE,"href","#transformers.FlaxAutoModel"),c(Dc,"class","relative group"),c(ZY,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rK,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertModel"),c(tK,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartModel"),c(aK,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.FlaxBeitModel"),c(nK,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertModel"),c(sK,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(lK,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(iK,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(dK,"href","/docs/transformers/pr_17639/en/model_doc/clip#transformers.FlaxCLIPModel"),c(cK,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(fK,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraModel"),c(mK,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(gK,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(hK,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(pK,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.FlaxMarianModel"),c(uK,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartModel"),c(_K,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.FlaxMT5Model"),c(bK,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.FlaxOPTModel"),c(vK,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(FK,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(TK,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(MK,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.FlaxT5Model"),c(EK,"href","/docs/transformers/pr_17639/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(CK,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.FlaxViTModel"),c(wK,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(AK,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(yK,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IE,"id","transformers.FlaxAutoModelForCausalLM"),c(IE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IE,"href","#transformers.FlaxAutoModelForCausalLM"),c(Vc,"class","relative group"),c(LK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($K,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kK,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(SK,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(RK,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(PK,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(BK,"href","/docs/transformers/pr_17639/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(IK,"href","/docs/transformers/pr_17639/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(NK,"href","/docs/transformers/pr_17639/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(qK,"href","/docs/transformers/pr_17639/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(jK,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(DK,"href","/docs/transformers/pr_17639/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UE,"id","transformers.FlaxAutoModelForPreTraining"),c(UE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UE,"href","#transformers.FlaxAutoModelForPreTraining"),c(Wc,"class","relative group"),c(GK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VK,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XK,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(zK,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(WK,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(QK,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(HK,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(UK,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(JK,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(YK,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(KK,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(ZK,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(eZ,"href","/docs/transformers/pr_17639/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(oZ,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cC,"id","transformers.FlaxAutoModelForMaskedLM"),c(cC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cC,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Uc,"class","relative group"),c(rZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nZ,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(sZ,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(lZ,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(iZ,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(dZ,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(cZ,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(fZ,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(mZ,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(gZ,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(hZ,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EC,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(EC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EC,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Kc,"class","relative group"),c(pZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_Z,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bZ,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(vZ,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(FZ,"href","/docs/transformers/pr_17639/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(TZ,"href","/docs/transformers/pr_17639/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(MZ,"href","/docs/transformers/pr_17639/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(EZ,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(CZ,"href","/docs/transformers/pr_17639/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(wZ,"href","/docs/transformers/pr_17639/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(AZ,"href","/docs/transformers/pr_17639/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BC,"id","transformers.FlaxAutoModelForSequenceClassification"),c(BC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BC,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(of,"class","relative group"),c(yZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($Z,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(kZ,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(SZ,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(RZ,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(PZ,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(BZ,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(IZ,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(NZ,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(qZ,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(jZ,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HC,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(HC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(HC,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(af,"class","relative group"),c(DZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VZ,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(XZ,"href","/docs/transformers/pr_17639/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(zZ,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(WZ,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(QZ,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(HZ,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(UZ,"href","/docs/transformers/pr_17639/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(JZ,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(YZ,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(KZ,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l5,"id","transformers.FlaxAutoModelForTokenClassification"),c(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l5,"href","#transformers.FlaxAutoModelForTokenClassification"),c(lf,"class","relative group"),c(ZZ,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ree,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(tee,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(aee,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(nee,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(see,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(lee,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(iee,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(dee,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b5,"id","transformers.FlaxAutoModelForMultipleChoice"),c(b5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b5,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(ff,"class","relative group"),c(cee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gee,"href","/docs/transformers/pr_17639/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(hee,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(pee,"href","/docs/transformers/pr_17639/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(uee,"href","/docs/transformers/pr_17639/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(_ee,"href","/docs/transformers/pr_17639/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(bee,"href","/docs/transformers/pr_17639/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(vee,"href","/docs/transformers/pr_17639/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Fee,"href","/docs/transformers/pr_17639/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x5,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(x5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x5,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(hf,"class","relative group"),c(Tee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Eee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cee,"href","/docs/transformers/pr_17639/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R5,"id","transformers.FlaxAutoModelForImageClassification"),c(R5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R5,"href","#transformers.FlaxAutoModelForImageClassification"),c(_f,"class","relative group"),c(wee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Aee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lee,"href","/docs/transformers/pr_17639/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(xee,"href","/docs/transformers/pr_17639/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q5,"id","transformers.FlaxAutoModelForVision2Seq"),c(q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q5,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Ff,"class","relative group"),c($ee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kee,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(See,"href","/docs/transformers/pr_17639/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ree,"href","/docs/transformers/pr_17639/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Eo),e(Eo,vi),b(f,Af,_),b(f,at,_),e(at,Fi),e(at,Ti),e(Ti,iA),e(at,yf),b(f,Ge,_),b(f,We,_),e(We,Mi),e(We,Sn),e(Sn,dA),e(We,Rn),e(We,Pn),e(Pn,cA),e(We,Ei),e(We,Bn),e(Bn,fA),e(We,Ci),b(f,Lf,_),M(La,f,_),b(f,Qe,_),b(f,Ae,_),e(Ae,Nk),e(Ae,wi),e(wi,qk),e(Ae,jk),b(f,Co,_),b(f,xa,_),e(xa,Dk),e(xa,xf),e(xf,Gk),e(xa,qXe),b(f,EDe,_),b(f,Ai,_),e(Ai,$f),e($f,Lre),M(mA,Lre,null),e(Ai,jXe),e(Ai,xre),e(xre,DXe),b(f,CDe,_),b(f,In,_),e(In,GXe),e(In,$re),e($re,OXe),e(In,VXe),e(In,kre),e(kre,XXe),e(In,zXe),b(f,wDe,_),M(gA,f,_),b(f,ADe,_),b(f,Ok,_),e(Ok,WXe),b(f,yDe,_),M(kf,f,_),b(f,LDe,_),b(f,yi,_),e(yi,Sf),e(Sf,Sre),M(hA,Sre,null),e(yi,QXe),e(yi,Rre),e(Rre,HXe),b(f,xDe,_),b(f,wo,_),M(pA,wo,null),e(wo,UXe),e(wo,uA),e(uA,JXe),e(uA,Vk),e(Vk,YXe),e(uA,KXe),e(wo,ZXe),e(wo,_A),e(_A,eze),e(_A,Pre),e(Pre,oze),e(_A,rze),e(wo,tze),e(wo,wr),M(bA,wr,null),e(wr,aze),e(wr,Bre),e(Bre,nze),e(wr,sze),e(wr,Li),e(Li,lze),e(Li,Ire),e(Ire,ize),e(Li,dze),e(Li,Nre),e(Nre,cze),e(Li,fze),e(wr,mze),e(wr,A),e(A,Rf),e(Rf,qre),e(qre,gze),e(Rf,hze),e(Rf,Xk),e(Xk,pze),e(Rf,uze),e(A,_ze),e(A,Pf),e(Pf,jre),e(jre,bze),e(Pf,vze),e(Pf,zk),e(zk,Fze),e(Pf,Tze),e(A,Mze),e(A,Bf),e(Bf,Dre),e(Dre,Eze),e(Bf,Cze),e(Bf,Wk),e(Wk,wze),e(Bf,Aze),e(A,yze),e(A,If),e(If,Gre),e(Gre,Lze),e(If,xze),e(If,Qk),e(Qk,$ze),e(If,kze),e(A,Sze),e(A,Nf),e(Nf,Ore),e(Ore,Rze),e(Nf,Pze),e(Nf,Hk),e(Hk,Bze),e(Nf,Ize),e(A,Nze),e(A,qf),e(qf,Vre),e(Vre,qze),e(qf,jze),e(qf,Uk),e(Uk,Dze),e(qf,Gze),e(A,Oze),e(A,jf),e(jf,Xre),e(Xre,Vze),e(jf,Xze),e(jf,Jk),e(Jk,zze),e(jf,Wze),e(A,Qze),e(A,Df),e(Df,zre),e(zre,Hze),e(Df,Uze),e(Df,Yk),e(Yk,Jze),e(Df,Yze),e(A,Kze),e(A,Gf),e(Gf,Wre),e(Wre,Zze),e(Gf,eWe),e(Gf,Kk),e(Kk,oWe),e(Gf,rWe),e(A,tWe),e(A,Of),e(Of,Qre),e(Qre,aWe),e(Of,nWe),e(Of,Zk),e(Zk,sWe),e(Of,lWe),e(A,iWe),e(A,Vf),e(Vf,Hre),e(Hre,dWe),e(Vf,cWe),e(Vf,eS),e(eS,fWe),e(Vf,mWe),e(A,gWe),e(A,Xf),e(Xf,Ure),e(Ure,hWe),e(Xf,pWe),e(Xf,oS),e(oS,uWe),e(Xf,_We),e(A,bWe),e(A,zf),e(zf,Jre),e(Jre,vWe),e(zf,FWe),e(zf,rS),e(rS,TWe),e(zf,MWe),e(A,EWe),e(A,Wf),e(Wf,Yre),e(Yre,CWe),e(Wf,wWe),e(Wf,tS),e(tS,AWe),e(Wf,yWe),e(A,LWe),e(A,Qf),e(Qf,Kre),e(Kre,xWe),e(Qf,$We),e(Qf,aS),e(aS,kWe),e(Qf,SWe),e(A,RWe),e(A,Hf),e(Hf,Zre),e(Zre,PWe),e(Hf,BWe),e(Hf,nS),e(nS,IWe),e(Hf,NWe),e(A,qWe),e(A,Uf),e(Uf,ete),e(ete,jWe),e(Uf,DWe),e(Uf,sS),e(sS,GWe),e(Uf,OWe),e(A,VWe),e(A,Jf),e(Jf,ote),e(ote,XWe),e(Jf,zWe),e(Jf,lS),e(lS,WWe),e(Jf,QWe),e(A,HWe),e(A,Yf),e(Yf,rte),e(rte,UWe),e(Yf,JWe),e(Yf,iS),e(iS,YWe),e(Yf,KWe),e(A,ZWe),e(A,Kf),e(Kf,tte),e(tte,eQe),e(Kf,oQe),e(Kf,dS),e(dS,rQe),e(Kf,tQe),e(A,aQe),e(A,Zf),e(Zf,ate),e(ate,nQe),e(Zf,sQe),e(Zf,cS),e(cS,lQe),e(Zf,iQe),e(A,dQe),e(A,em),e(em,nte),e(nte,cQe),e(em,fQe),e(em,fS),e(fS,mQe),e(em,gQe),e(A,hQe),e(A,om),e(om,ste),e(ste,pQe),e(om,uQe),e(om,mS),e(mS,_Qe),e(om,bQe),e(A,vQe),e(A,rm),e(rm,lte),e(lte,FQe),e(rm,TQe),e(rm,gS),e(gS,MQe),e(rm,EQe),e(A,CQe),e(A,tm),e(tm,ite),e(ite,wQe),e(tm,AQe),e(tm,hS),e(hS,yQe),e(tm,LQe),e(A,xQe),e(A,am),e(am,dte),e(dte,$Qe),e(am,kQe),e(am,pS),e(pS,SQe),e(am,RQe),e(A,PQe),e(A,nm),e(nm,cte),e(cte,BQe),e(nm,IQe),e(nm,uS),e(uS,NQe),e(nm,qQe),e(A,jQe),e(A,sm),e(sm,fte),e(fte,DQe),e(sm,GQe),e(sm,_S),e(_S,OQe),e(sm,VQe),e(A,XQe),e(A,lm),e(lm,mte),e(mte,zQe),e(lm,WQe),e(lm,bS),e(bS,QQe),e(lm,HQe),e(A,UQe),e(A,im),e(im,gte),e(gte,JQe),e(im,YQe),e(im,vS),e(vS,KQe),e(im,ZQe),e(A,eHe),e(A,dm),e(dm,hte),e(hte,oHe),e(dm,rHe),e(dm,FS),e(FS,tHe),e(dm,aHe),e(A,nHe),e(A,cm),e(cm,pte),e(pte,sHe),e(cm,lHe),e(cm,TS),e(TS,iHe),e(cm,dHe),e(A,cHe),e(A,fm),e(fm,ute),e(ute,fHe),e(fm,mHe),e(fm,MS),e(MS,gHe),e(fm,hHe),e(A,pHe),e(A,mm),e(mm,_te),e(_te,uHe),e(mm,_He),e(mm,ES),e(ES,bHe),e(mm,vHe),e(A,FHe),e(A,gm),e(gm,bte),e(bte,THe),e(gm,MHe),e(gm,CS),e(CS,EHe),e(gm,CHe),e(A,wHe),e(A,hm),e(hm,vte),e(vte,AHe),e(hm,yHe),e(hm,wS),e(wS,LHe),e(hm,xHe),e(A,$He),e(A,pm),e(pm,Fte),e(Fte,kHe),e(pm,SHe),e(pm,AS),e(AS,RHe),e(pm,PHe),e(A,BHe),e(A,um),e(um,Tte),e(Tte,IHe),e(um,NHe),e(um,yS),e(yS,qHe),e(um,jHe),e(A,DHe),e(A,_m),e(_m,Mte),e(Mte,GHe),e(_m,OHe),e(_m,LS),e(LS,VHe),e(_m,XHe),e(A,zHe),e(A,bm),e(bm,Ete),e(Ete,WHe),e(bm,QHe),e(bm,xS),e(xS,HHe),e(bm,UHe),e(A,JHe),e(A,vm),e(vm,Cte),e(Cte,YHe),e(vm,KHe),e(vm,$S),e($S,ZHe),e(vm,eUe),e(A,oUe),e(A,Fm),e(Fm,wte),e(wte,rUe),e(Fm,tUe),e(Fm,kS),e(kS,aUe),e(Fm,nUe),e(A,sUe),e(A,Tm),e(Tm,Ate),e(Ate,lUe),e(Tm,iUe),e(Tm,SS),e(SS,dUe),e(Tm,cUe),e(A,fUe),e(A,Mm),e(Mm,yte),e(yte,mUe),e(Mm,gUe),e(Mm,RS),e(RS,hUe),e(Mm,pUe),e(A,uUe),e(A,Em),e(Em,Lte),e(Lte,_Ue),e(Em,bUe),e(Em,PS),e(PS,vUe),e(Em,FUe),e(A,TUe),e(A,Cm),e(Cm,xte),e(xte,MUe),e(Cm,EUe),e(Cm,BS),e(BS,CUe),e(Cm,wUe),e(A,AUe),e(A,wm),e(wm,$te),e($te,yUe),e(wm,LUe),e(wm,IS),e(IS,xUe),e(wm,$Ue),e(A,kUe),e(A,Am),e(Am,kte),e(kte,SUe),e(Am,RUe),e(Am,NS),e(NS,PUe),e(Am,BUe),e(A,IUe),e(A,ym),e(ym,Ste),e(Ste,NUe),e(ym,qUe),e(ym,qS),e(qS,jUe),e(ym,DUe),e(A,GUe),e(A,Lm),e(Lm,Rte),e(Rte,OUe),e(Lm,VUe),e(Lm,jS),e(jS,XUe),e(Lm,zUe),e(A,WUe),e(A,xm),e(xm,Pte),e(Pte,QUe),e(xm,HUe),e(xm,DS),e(DS,UUe),e(xm,JUe),e(A,YUe),e(A,$m),e($m,Bte),e(Bte,KUe),e($m,ZUe),e($m,GS),e(GS,eJe),e($m,oJe),e(A,rJe),e(A,km),e(km,Ite),e(Ite,tJe),e(km,aJe),e(km,OS),e(OS,nJe),e(km,sJe),e(A,lJe),e(A,Sm),e(Sm,Nte),e(Nte,iJe),e(Sm,dJe),e(Sm,VS),e(VS,cJe),e(Sm,fJe),e(A,mJe),e(A,Rm),e(Rm,qte),e(qte,gJe),e(Rm,hJe),e(Rm,XS),e(XS,pJe),e(Rm,uJe),e(A,_Je),e(A,Pm),e(Pm,jte),e(jte,bJe),e(Pm,vJe),e(Pm,zS),e(zS,FJe),e(Pm,TJe),e(A,MJe),e(A,Bm),e(Bm,Dte),e(Dte,EJe),e(Bm,CJe),e(Bm,WS),e(WS,wJe),e(Bm,AJe),e(A,yJe),e(A,Im),e(Im,Gte),e(Gte,LJe),e(Im,xJe),e(Im,QS),e(QS,$Je),e(Im,kJe),e(A,SJe),e(A,Nm),e(Nm,Ote),e(Ote,RJe),e(Nm,PJe),e(Nm,HS),e(HS,BJe),e(Nm,IJe),e(A,NJe),e(A,qm),e(qm,Vte),e(Vte,qJe),e(qm,jJe),e(qm,US),e(US,DJe),e(qm,GJe),e(A,OJe),e(A,jm),e(jm,Xte),e(Xte,VJe),e(jm,XJe),e(jm,JS),e(JS,zJe),e(jm,WJe),e(A,QJe),e(A,Dm),e(Dm,zte),e(zte,HJe),e(Dm,UJe),e(Dm,YS),e(YS,JJe),e(Dm,YJe),e(A,KJe),e(A,Gm),e(Gm,Wte),e(Wte,ZJe),e(Gm,eYe),e(Gm,KS),e(KS,oYe),e(Gm,rYe),e(A,tYe),e(A,Om),e(Om,Qte),e(Qte,aYe),e(Om,nYe),e(Om,ZS),e(ZS,sYe),e(Om,lYe),e(A,iYe),e(A,Vm),e(Vm,Hte),e(Hte,dYe),e(Vm,cYe),e(Vm,eR),e(eR,fYe),e(Vm,mYe),e(A,gYe),e(A,Xm),e(Xm,Ute),e(Ute,hYe),e(Xm,pYe),e(Xm,oR),e(oR,uYe),e(Xm,_Ye),e(A,bYe),e(A,zm),e(zm,Jte),e(Jte,vYe),e(zm,FYe),e(zm,rR),e(rR,TYe),e(zm,MYe),e(A,EYe),e(A,Wm),e(Wm,Yte),e(Yte,CYe),e(Wm,wYe),e(Wm,tR),e(tR,AYe),e(Wm,yYe),e(A,LYe),e(A,Qm),e(Qm,Kte),e(Kte,xYe),e(Qm,$Ye),e(Qm,aR),e(aR,kYe),e(Qm,SYe),e(A,RYe),e(A,Hm),e(Hm,Zte),e(Zte,PYe),e(Hm,BYe),e(Hm,nR),e(nR,IYe),e(Hm,NYe),e(A,qYe),e(A,Um),e(Um,eae),e(eae,jYe),e(Um,DYe),e(Um,sR),e(sR,GYe),e(Um,OYe),e(A,VYe),e(A,Jm),e(Jm,oae),e(oae,XYe),e(Jm,zYe),e(Jm,lR),e(lR,WYe),e(Jm,QYe),e(A,HYe),e(A,Ym),e(Ym,rae),e(rae,UYe),e(Ym,JYe),e(Ym,iR),e(iR,YYe),e(Ym,KYe),e(A,ZYe),e(A,Km),e(Km,tae),e(tae,eKe),e(Km,oKe),e(Km,dR),e(dR,rKe),e(Km,tKe),e(A,aKe),e(A,Zm),e(Zm,aae),e(aae,nKe),e(Zm,sKe),e(Zm,cR),e(cR,lKe),e(Zm,iKe),e(A,dKe),e(A,eg),e(eg,nae),e(nae,cKe),e(eg,fKe),e(eg,fR),e(fR,mKe),e(eg,gKe),e(A,hKe),e(A,og),e(og,sae),e(sae,pKe),e(og,uKe),e(og,mR),e(mR,_Ke),e(og,bKe),e(A,vKe),e(A,rg),e(rg,lae),e(lae,FKe),e(rg,TKe),e(rg,gR),e(gR,MKe),e(rg,EKe),e(A,CKe),e(A,tg),e(tg,iae),e(iae,wKe),e(tg,AKe),e(tg,hR),e(hR,yKe),e(tg,LKe),e(A,xKe),e(A,ag),e(ag,dae),e(dae,$Ke),e(ag,kKe),e(ag,pR),e(pR,SKe),e(ag,RKe),e(A,PKe),e(A,ng),e(ng,cae),e(cae,BKe),e(ng,IKe),e(ng,uR),e(uR,NKe),e(ng,qKe),e(A,jKe),e(A,sg),e(sg,fae),e(fae,DKe),e(sg,GKe),e(sg,_R),e(_R,OKe),e(sg,VKe),e(A,XKe),e(A,lg),e(lg,mae),e(mae,zKe),e(lg,WKe),e(lg,bR),e(bR,QKe),e(lg,HKe),e(A,UKe),e(A,ig),e(ig,gae),e(gae,JKe),e(ig,YKe),e(ig,vR),e(vR,KKe),e(ig,ZKe),e(A,eZe),e(A,dg),e(dg,hae),e(hae,oZe),e(dg,rZe),e(dg,FR),e(FR,tZe),e(dg,aZe),e(A,nZe),e(A,cg),e(cg,pae),e(pae,sZe),e(cg,lZe),e(cg,TR),e(TR,iZe),e(cg,dZe),e(A,cZe),e(A,fg),e(fg,uae),e(uae,fZe),e(fg,mZe),e(fg,MR),e(MR,gZe),e(fg,hZe),e(A,pZe),e(A,mg),e(mg,_ae),e(_ae,uZe),e(mg,_Ze),e(mg,ER),e(ER,bZe),e(mg,vZe),e(A,FZe),e(A,gg),e(gg,bae),e(bae,TZe),e(gg,MZe),e(gg,CR),e(CR,EZe),e(gg,CZe),e(A,wZe),e(A,hg),e(hg,vae),e(vae,AZe),e(hg,yZe),e(hg,wR),e(wR,LZe),e(hg,xZe),e(A,$Ze),e(A,pg),e(pg,Fae),e(Fae,kZe),e(pg,SZe),e(pg,AR),e(AR,RZe),e(pg,PZe),e(A,BZe),e(A,ug),e(ug,Tae),e(Tae,IZe),e(ug,NZe),e(ug,yR),e(yR,qZe),e(ug,jZe),e(A,DZe),e(A,_g),e(_g,Mae),e(Mae,GZe),e(_g,OZe),e(_g,LR),e(LR,VZe),e(_g,XZe),e(A,zZe),e(A,bg),e(bg,Eae),e(Eae,WZe),e(bg,QZe),e(bg,xR),e(xR,HZe),e(bg,UZe),e(A,JZe),e(A,vg),e(vg,Cae),e(Cae,YZe),e(vg,KZe),e(vg,$R),e($R,ZZe),e(vg,eeo),e(A,oeo),e(A,Fg),e(Fg,wae),e(wae,reo),e(Fg,teo),e(Fg,kR),e(kR,aeo),e(Fg,neo),e(A,seo),e(A,Tg),e(Tg,Aae),e(Aae,leo),e(Tg,ieo),e(Tg,SR),e(SR,deo),e(Tg,ceo),e(A,feo),e(A,Mg),e(Mg,yae),e(yae,meo),e(Mg,geo),e(Mg,RR),e(RR,heo),e(Mg,peo),e(A,ueo),e(A,Eg),e(Eg,Lae),e(Lae,_eo),e(Eg,beo),e(Eg,PR),e(PR,veo),e(Eg,Feo),e(A,Teo),e(A,Cg),e(Cg,xae),e(xae,Meo),e(Cg,Eeo),e(Cg,BR),e(BR,Ceo),e(Cg,weo),e(A,Aeo),e(A,wg),e(wg,$ae),e($ae,yeo),e(wg,Leo),e(wg,IR),e(IR,xeo),e(wg,$eo),e(A,keo),e(A,Ag),e(Ag,kae),e(kae,Seo),e(Ag,Reo),e(Ag,NR),e(NR,Peo),e(Ag,Beo),e(A,Ieo),e(A,yg),e(yg,Sae),e(Sae,Neo),e(yg,qeo),e(yg,qR),e(qR,jeo),e(yg,Deo),e(A,Geo),e(A,Lg),e(Lg,Rae),e(Rae,Oeo),e(Lg,Veo),e(Lg,jR),e(jR,Xeo),e(Lg,zeo),e(A,Weo),e(A,xg),e(xg,Pae),e(Pae,Qeo),e(xg,Heo),e(xg,DR),e(DR,Ueo),e(xg,Jeo),e(A,Yeo),e(A,$g),e($g,Bae),e(Bae,Keo),e($g,Zeo),e($g,GR),e(GR,eoo),e($g,ooo),e(A,roo),e(A,kg),e(kg,Iae),e(Iae,too),e(kg,aoo),e(kg,OR),e(OR,noo),e(kg,soo),e(A,loo),e(A,Sg),e(Sg,Nae),e(Nae,ioo),e(Sg,doo),e(Sg,VR),e(VR,coo),e(Sg,foo),e(A,moo),e(A,Rg),e(Rg,qae),e(qae,goo),e(Rg,hoo),e(Rg,XR),e(XR,poo),e(Rg,uoo),e(A,_oo),e(A,Pg),e(Pg,jae),e(jae,boo),e(Pg,voo),e(Pg,zR),e(zR,Foo),e(Pg,Too),e(A,Moo),e(A,Bg),e(Bg,Dae),e(Dae,Eoo),e(Bg,Coo),e(Bg,WR),e(WR,woo),e(Bg,Aoo),e(A,yoo),e(A,Ig),e(Ig,Gae),e(Gae,Loo),e(Ig,xoo),e(Ig,QR),e(QR,$oo),e(Ig,koo),e(wr,Soo),M(Ng,wr,null),e(wo,Roo),e(wo,qg),M(vA,qg,null),e(qg,Poo),e(qg,Oae),e(Oae,Boo),b(f,$De,_),b(f,xi,_),e(xi,jg),e(jg,Vae),M(FA,Vae,null),e(xi,Ioo),e(xi,Xae),e(Xae,Noo),b(f,kDe,_),b(f,Ao,_),M(TA,Ao,null),e(Ao,qoo),e(Ao,MA),e(MA,joo),e(MA,HR),e(HR,Doo),e(MA,Goo),e(Ao,Ooo),e(Ao,EA),e(EA,Voo),e(EA,zae),e(zae,Xoo),e(EA,zoo),e(Ao,Woo),e(Ao,Ar),M(CA,Ar,null),e(Ar,Qoo),e(Ar,Wae),e(Wae,Hoo),e(Ar,Uoo),e(Ar,$a),e($a,Joo),e($a,Qae),e(Qae,Yoo),e($a,Koo),e($a,Hae),e(Hae,Zoo),e($a,ero),e($a,Uae),e(Uae,oro),e($a,rro),e(Ar,tro),e(Ar,k),e(k,Nn),e(Nn,Jae),e(Jae,aro),e(Nn,nro),e(Nn,UR),e(UR,sro),e(Nn,lro),e(Nn,JR),e(JR,iro),e(Nn,dro),e(k,cro),e(k,qn),e(qn,Yae),e(Yae,fro),e(qn,mro),e(qn,YR),e(YR,gro),e(qn,hro),e(qn,KR),e(KR,pro),e(qn,uro),e(k,_ro),e(k,jn),e(jn,Kae),e(Kae,bro),e(jn,vro),e(jn,ZR),e(ZR,Fro),e(jn,Tro),e(jn,eP),e(eP,Mro),e(jn,Ero),e(k,Cro),e(k,Dg),e(Dg,Zae),e(Zae,wro),e(Dg,Aro),e(Dg,oP),e(oP,yro),e(Dg,Lro),e(k,xro),e(k,Dn),e(Dn,ene),e(ene,$ro),e(Dn,kro),e(Dn,rP),e(rP,Sro),e(Dn,Rro),e(Dn,tP),e(tP,Pro),e(Dn,Bro),e(k,Iro),e(k,Gg),e(Gg,one),e(one,Nro),e(Gg,qro),e(Gg,aP),e(aP,jro),e(Gg,Dro),e(k,Gro),e(k,Og),e(Og,rne),e(rne,Oro),e(Og,Vro),e(Og,nP),e(nP,Xro),e(Og,zro),e(k,Wro),e(k,Vg),e(Vg,tne),e(tne,Qro),e(Vg,Hro),e(Vg,sP),e(sP,Uro),e(Vg,Jro),e(k,Yro),e(k,Gn),e(Gn,ane),e(ane,Kro),e(Gn,Zro),e(Gn,lP),e(lP,eto),e(Gn,oto),e(Gn,iP),e(iP,rto),e(Gn,tto),e(k,ato),e(k,On),e(On,nne),e(nne,nto),e(On,sto),e(On,dP),e(dP,lto),e(On,ito),e(On,cP),e(cP,dto),e(On,cto),e(k,fto),e(k,Vn),e(Vn,sne),e(sne,mto),e(Vn,gto),e(Vn,fP),e(fP,hto),e(Vn,pto),e(Vn,mP),e(mP,uto),e(Vn,_to),e(k,bto),e(k,Xg),e(Xg,lne),e(lne,vto),e(Xg,Fto),e(Xg,gP),e(gP,Tto),e(Xg,Mto),e(k,Eto),e(k,zg),e(zg,ine),e(ine,Cto),e(zg,wto),e(zg,hP),e(hP,Ato),e(zg,yto),e(k,Lto),e(k,Wg),e(Wg,dne),e(dne,xto),e(Wg,$to),e(Wg,pP),e(pP,kto),e(Wg,Sto),e(k,Rto),e(k,Xn),e(Xn,cne),e(cne,Pto),e(Xn,Bto),e(Xn,uP),e(uP,Ito),e(Xn,Nto),e(Xn,_P),e(_P,qto),e(Xn,jto),e(k,Dto),e(k,Qg),e(Qg,fne),e(fne,Gto),e(Qg,Oto),e(Qg,bP),e(bP,Vto),e(Qg,Xto),e(k,zto),e(k,zn),e(zn,mne),e(mne,Wto),e(zn,Qto),e(zn,vP),e(vP,Hto),e(zn,Uto),e(zn,FP),e(FP,Jto),e(zn,Yto),e(k,Kto),e(k,Wn),e(Wn,gne),e(gne,Zto),e(Wn,eao),e(Wn,TP),e(TP,oao),e(Wn,rao),e(Wn,MP),e(MP,tao),e(Wn,aao),e(k,nao),e(k,Qn),e(Qn,hne),e(hne,sao),e(Qn,lao),e(Qn,EP),e(EP,iao),e(Qn,dao),e(Qn,CP),e(CP,cao),e(Qn,fao),e(k,mao),e(k,Hg),e(Hg,pne),e(pne,gao),e(Hg,hao),e(Hg,wP),e(wP,pao),e(Hg,uao),e(k,_ao),e(k,Hn),e(Hn,une),e(une,bao),e(Hn,vao),e(Hn,AP),e(AP,Fao),e(Hn,Tao),e(Hn,yP),e(yP,Mao),e(Hn,Eao),e(k,Cao),e(k,Un),e(Un,_ne),e(_ne,wao),e(Un,Aao),e(Un,LP),e(LP,yao),e(Un,Lao),e(Un,xP),e(xP,xao),e(Un,$ao),e(k,kao),e(k,Jn),e(Jn,bne),e(bne,Sao),e(Jn,Rao),e(Jn,$P),e($P,Pao),e(Jn,Bao),e(Jn,kP),e(kP,Iao),e(Jn,Nao),e(k,qao),e(k,Yn),e(Yn,vne),e(vne,jao),e(Yn,Dao),e(Yn,SP),e(SP,Gao),e(Yn,Oao),e(Yn,RP),e(RP,Vao),e(Yn,Xao),e(k,zao),e(k,Kn),e(Kn,Fne),e(Fne,Wao),e(Kn,Qao),e(Kn,PP),e(PP,Hao),e(Kn,Uao),e(Kn,BP),e(BP,Jao),e(Kn,Yao),e(k,Kao),e(k,Zn),e(Zn,Tne),e(Tne,Zao),e(Zn,eno),e(Zn,IP),e(IP,ono),e(Zn,rno),e(Zn,NP),e(NP,tno),e(Zn,ano),e(k,nno),e(k,Ug),e(Ug,Mne),e(Mne,sno),e(Ug,lno),e(Ug,qP),e(qP,ino),e(Ug,dno),e(k,cno),e(k,es),e(es,Ene),e(Ene,fno),e(es,mno),e(es,jP),e(jP,gno),e(es,hno),e(es,DP),e(DP,pno),e(es,uno),e(k,_no),e(k,Jg),e(Jg,Cne),e(Cne,bno),e(Jg,vno),e(Jg,GP),e(GP,Fno),e(Jg,Tno),e(k,Mno),e(k,os),e(os,wne),e(wne,Eno),e(os,Cno),e(os,OP),e(OP,wno),e(os,Ano),e(os,VP),e(VP,yno),e(os,Lno),e(k,xno),e(k,rs),e(rs,Ane),e(Ane,$no),e(rs,kno),e(rs,XP),e(XP,Sno),e(rs,Rno),e(rs,zP),e(zP,Pno),e(rs,Bno),e(k,Ino),e(k,ts),e(ts,yne),e(yne,Nno),e(ts,qno),e(ts,WP),e(WP,jno),e(ts,Dno),e(ts,QP),e(QP,Gno),e(ts,Ono),e(k,Vno),e(k,Yg),e(Yg,Lne),e(Lne,Xno),e(Yg,zno),e(Yg,HP),e(HP,Wno),e(Yg,Qno),e(k,Hno),e(k,as),e(as,xne),e(xne,Uno),e(as,Jno),e(as,UP),e(UP,Yno),e(as,Kno),e(as,JP),e(JP,Zno),e(as,eso),e(k,oso),e(k,ns),e(ns,$ne),e($ne,rso),e(ns,tso),e(ns,YP),e(YP,aso),e(ns,nso),e(ns,KP),e(KP,sso),e(ns,lso),e(k,iso),e(k,Kg),e(Kg,kne),e(kne,dso),e(Kg,cso),e(Kg,ZP),e(ZP,fso),e(Kg,mso),e(k,gso),e(k,ss),e(ss,Sne),e(Sne,hso),e(ss,pso),e(ss,eB),e(eB,uso),e(ss,_so),e(ss,oB),e(oB,bso),e(ss,vso),e(k,Fso),e(k,ls),e(ls,Rne),e(Rne,Tso),e(ls,Mso),e(ls,rB),e(rB,Eso),e(ls,Cso),e(ls,tB),e(tB,wso),e(ls,Aso),e(k,yso),e(k,is),e(is,Pne),e(Pne,Lso),e(is,xso),e(is,aB),e(aB,$so),e(is,kso),e(is,nB),e(nB,Sso),e(is,Rso),e(k,Pso),e(k,ds),e(ds,Bne),e(Bne,Bso),e(ds,Iso),e(ds,sB),e(sB,Nso),e(ds,qso),e(ds,lB),e(lB,jso),e(ds,Dso),e(k,Gso),e(k,cs),e(cs,Ine),e(Ine,Oso),e(cs,Vso),e(cs,iB),e(iB,Xso),e(cs,zso),e(cs,dB),e(dB,Wso),e(cs,Qso),e(k,Hso),e(k,fs),e(fs,Nne),e(Nne,Uso),e(fs,Jso),e(fs,cB),e(cB,Yso),e(fs,Kso),e(fs,fB),e(fB,Zso),e(fs,elo),e(k,olo),e(k,ms),e(ms,qne),e(qne,rlo),e(ms,tlo),e(ms,mB),e(mB,alo),e(ms,nlo),e(ms,gB),e(gB,slo),e(ms,llo),e(k,ilo),e(k,Zg),e(Zg,jne),e(jne,dlo),e(Zg,clo),e(Zg,hB),e(hB,flo),e(Zg,mlo),e(k,glo),e(k,gs),e(gs,Dne),e(Dne,hlo),e(gs,plo),e(gs,pB),e(pB,ulo),e(gs,_lo),e(gs,uB),e(uB,blo),e(gs,vlo),e(k,Flo),e(k,eh),e(eh,Gne),e(Gne,Tlo),e(eh,Mlo),e(eh,_B),e(_B,Elo),e(eh,Clo),e(k,wlo),e(k,oh),e(oh,One),e(One,Alo),e(oh,ylo),e(oh,bB),e(bB,Llo),e(oh,xlo),e(k,$lo),e(k,hs),e(hs,Vne),e(Vne,klo),e(hs,Slo),e(hs,vB),e(vB,Rlo),e(hs,Plo),e(hs,FB),e(FB,Blo),e(hs,Ilo),e(k,Nlo),e(k,ps),e(ps,Xne),e(Xne,qlo),e(ps,jlo),e(ps,TB),e(TB,Dlo),e(ps,Glo),e(ps,MB),e(MB,Olo),e(ps,Vlo),e(k,Xlo),e(k,us),e(us,zne),e(zne,zlo),e(us,Wlo),e(us,EB),e(EB,Qlo),e(us,Hlo),e(us,CB),e(CB,Ulo),e(us,Jlo),e(k,Ylo),e(k,rh),e(rh,Wne),e(Wne,Klo),e(rh,Zlo),e(rh,wB),e(wB,eio),e(rh,oio),e(k,rio),e(k,_s),e(_s,Qne),e(Qne,tio),e(_s,aio),e(_s,AB),e(AB,nio),e(_s,sio),e(_s,yB),e(yB,lio),e(_s,iio),e(k,dio),e(k,bs),e(bs,Hne),e(Hne,cio),e(bs,fio),e(bs,LB),e(LB,mio),e(bs,gio),e(bs,xB),e(xB,hio),e(bs,pio),e(k,uio),e(k,vs),e(vs,Une),e(Une,_io),e(vs,bio),e(vs,$B),e($B,vio),e(vs,Fio),e(vs,kB),e(kB,Tio),e(vs,Mio),e(k,Eio),e(k,Fs),e(Fs,Jne),e(Jne,Cio),e(Fs,wio),e(Fs,SB),e(SB,Aio),e(Fs,yio),e(Fs,RB),e(RB,Lio),e(Fs,xio),e(k,$io),e(k,Ts),e(Ts,Yne),e(Yne,kio),e(Ts,Sio),e(Ts,PB),e(PB,Rio),e(Ts,Pio),e(Ts,BB),e(BB,Bio),e(Ts,Iio),e(k,Nio),e(k,th),e(th,Kne),e(Kne,qio),e(th,jio),e(th,IB),e(IB,Dio),e(th,Gio),e(k,Oio),e(k,Ms),e(Ms,Zne),e(Zne,Vio),e(Ms,Xio),e(Ms,NB),e(NB,zio),e(Ms,Wio),e(Ms,qB),e(qB,Qio),e(Ms,Hio),e(k,Uio),e(k,ah),e(ah,ese),e(ese,Jio),e(ah,Yio),e(ah,jB),e(jB,Kio),e(ah,Zio),e(k,edo),e(k,nh),e(nh,ose),e(ose,odo),e(nh,rdo),e(nh,DB),e(DB,tdo),e(nh,ado),e(k,ndo),e(k,sh),e(sh,rse),e(rse,sdo),e(sh,ldo),e(sh,GB),e(GB,ido),e(sh,ddo),e(k,cdo),e(k,lh),e(lh,tse),e(tse,fdo),e(lh,mdo),e(lh,OB),e(OB,gdo),e(lh,hdo),e(k,pdo),e(k,Es),e(Es,ase),e(ase,udo),e(Es,_do),e(Es,VB),e(VB,bdo),e(Es,vdo),e(Es,XB),e(XB,Fdo),e(Es,Tdo),e(k,Mdo),e(k,ih),e(ih,nse),e(nse,Edo),e(ih,Cdo),e(ih,zB),e(zB,wdo),e(ih,Ado),e(k,ydo),e(k,Cs),e(Cs,sse),e(sse,Ldo),e(Cs,xdo),e(Cs,WB),e(WB,$do),e(Cs,kdo),e(Cs,QB),e(QB,Sdo),e(Cs,Rdo),e(k,Pdo),e(k,ws),e(ws,lse),e(lse,Bdo),e(ws,Ido),e(ws,HB),e(HB,Ndo),e(ws,qdo),e(ws,UB),e(UB,jdo),e(ws,Ddo),e(k,Gdo),e(k,As),e(As,ise),e(ise,Odo),e(As,Vdo),e(As,JB),e(JB,Xdo),e(As,zdo),e(As,YB),e(YB,Wdo),e(As,Qdo),e(k,Hdo),e(k,ys),e(ys,dse),e(dse,Udo),e(ys,Jdo),e(ys,KB),e(KB,Ydo),e(ys,Kdo),e(ys,ZB),e(ZB,Zdo),e(ys,eco),e(k,oco),e(k,Ls),e(Ls,cse),e(cse,rco),e(Ls,tco),e(Ls,eI),e(eI,aco),e(Ls,nco),e(Ls,oI),e(oI,sco),e(Ls,lco),e(k,ico),e(k,xs),e(xs,fse),e(fse,dco),e(xs,cco),e(xs,rI),e(rI,fco),e(xs,mco),e(xs,tI),e(tI,gco),e(xs,hco),e(k,pco),e(k,dh),e(dh,mse),e(mse,uco),e(dh,_co),e(dh,aI),e(aI,bco),e(dh,vco),e(k,Fco),e(k,ch),e(ch,gse),e(gse,Tco),e(ch,Mco),e(ch,nI),e(nI,Eco),e(ch,Cco),e(k,wco),e(k,$s),e($s,hse),e(hse,Aco),e($s,yco),e($s,sI),e(sI,Lco),e($s,xco),e($s,lI),e(lI,$co),e($s,kco),e(k,Sco),e(k,ks),e(ks,pse),e(pse,Rco),e(ks,Pco),e(ks,iI),e(iI,Bco),e(ks,Ico),e(ks,dI),e(dI,Nco),e(ks,qco),e(k,jco),e(k,Ss),e(Ss,use),e(use,Dco),e(Ss,Gco),e(Ss,cI),e(cI,Oco),e(Ss,Vco),e(Ss,fI),e(fI,Xco),e(Ss,zco),e(k,Wco),e(k,fh),e(fh,_se),e(_se,Qco),e(fh,Hco),e(fh,mI),e(mI,Uco),e(fh,Jco),e(k,Yco),e(k,mh),e(mh,bse),e(bse,Kco),e(mh,Zco),e(mh,gI),e(gI,efo),e(mh,ofo),e(k,rfo),e(k,gh),e(gh,vse),e(vse,tfo),e(gh,afo),e(gh,hI),e(hI,nfo),e(gh,sfo),e(k,lfo),e(k,Rs),e(Rs,Fse),e(Fse,ifo),e(Rs,dfo),e(Rs,pI),e(pI,cfo),e(Rs,ffo),e(Rs,uI),e(uI,mfo),e(Rs,gfo),e(k,hfo),e(k,Ps),e(Ps,Tse),e(Tse,pfo),e(Ps,ufo),e(Ps,_I),e(_I,_fo),e(Ps,bfo),e(Ps,bI),e(bI,vfo),e(Ps,Ffo),e(k,Tfo),e(k,hh),e(hh,Mse),e(Mse,Mfo),e(hh,Efo),e(hh,vI),e(vI,Cfo),e(hh,wfo),e(k,Afo),e(k,ph),e(ph,Ese),e(Ese,yfo),e(ph,Lfo),e(ph,FI),e(FI,xfo),e(ph,$fo),e(k,kfo),e(k,uh),e(uh,Cse),e(Cse,Sfo),e(uh,Rfo),e(uh,TI),e(TI,Pfo),e(uh,Bfo),e(k,Ifo),e(k,Bs),e(Bs,wse),e(wse,Nfo),e(Bs,qfo),e(Bs,MI),e(MI,jfo),e(Bs,Dfo),e(Bs,EI),e(EI,Gfo),e(Bs,Ofo),e(k,Vfo),e(k,_h),e(_h,Ase),e(Ase,Xfo),e(_h,zfo),e(_h,CI),e(CI,Wfo),e(_h,Qfo),e(k,Hfo),e(k,bh),e(bh,yse),e(yse,Ufo),e(bh,Jfo),e(bh,wI),e(wI,Yfo),e(bh,Kfo),e(k,Zfo),e(k,Is),e(Is,Lse),e(Lse,emo),e(Is,omo),e(Is,AI),e(AI,rmo),e(Is,tmo),e(Is,yI),e(yI,amo),e(Is,nmo),e(k,smo),e(k,Ns),e(Ns,xse),e(xse,lmo),e(Ns,imo),e(Ns,LI),e(LI,dmo),e(Ns,cmo),e(Ns,xI),e(xI,fmo),e(Ns,mmo),e(k,gmo),e(k,qs),e(qs,$se),e($se,hmo),e(qs,pmo),e(qs,$I),e($I,umo),e(qs,_mo),e(qs,kI),e(kI,bmo),e(qs,vmo),e(k,Fmo),e(k,js),e(js,kse),e(kse,Tmo),e(js,Mmo),e(js,SI),e(SI,Emo),e(js,Cmo),e(js,RI),e(RI,wmo),e(js,Amo),e(Ar,ymo),M(vh,Ar,null),e(Ao,Lmo),e(Ao,Fh),M(wA,Fh,null),e(Fh,xmo),e(Fh,Sse),e(Sse,$mo),b(f,SDe,_),b(f,$i,_),e($i,Th),e(Th,Rse),M(AA,Rse,null),e($i,kmo),e($i,Pse),e(Pse,Smo),b(f,RDe,_),b(f,yo,_),M(yA,yo,null),e(yo,Rmo),e(yo,LA),e(LA,Pmo),e(LA,PI),e(PI,Bmo),e(LA,Imo),e(yo,Nmo),e(yo,xA),e(xA,qmo),e(xA,Bse),e(Bse,jmo),e(xA,Dmo),e(yo,Gmo),e(yo,He),M($A,He,null),e(He,Omo),e(He,Ise),e(Ise,Vmo),e(He,Xmo),e(He,ka),e(ka,zmo),e(ka,Nse),e(Nse,Wmo),e(ka,Qmo),e(ka,qse),e(qse,Hmo),e(ka,Umo),e(ka,jse),e(jse,Jmo),e(ka,Ymo),e(He,Kmo),e(He,Y),e(Y,Mh),e(Mh,Dse),e(Dse,Zmo),e(Mh,ego),e(Mh,BI),e(BI,ogo),e(Mh,rgo),e(Y,tgo),e(Y,Eh),e(Eh,Gse),e(Gse,ago),e(Eh,ngo),e(Eh,II),e(II,sgo),e(Eh,lgo),e(Y,igo),e(Y,Ch),e(Ch,Ose),e(Ose,dgo),e(Ch,cgo),e(Ch,NI),e(NI,fgo),e(Ch,mgo),e(Y,ggo),e(Y,wh),e(wh,Vse),e(Vse,hgo),e(wh,pgo),e(wh,qI),e(qI,ugo),e(wh,_go),e(Y,bgo),e(Y,Ah),e(Ah,Xse),e(Xse,vgo),e(Ah,Fgo),e(Ah,jI),e(jI,Tgo),e(Ah,Mgo),e(Y,Ego),e(Y,yh),e(yh,zse),e(zse,Cgo),e(yh,wgo),e(yh,DI),e(DI,Ago),e(yh,ygo),e(Y,Lgo),e(Y,Lh),e(Lh,Wse),e(Wse,xgo),e(Lh,$go),e(Lh,GI),e(GI,kgo),e(Lh,Sgo),e(Y,Rgo),e(Y,xh),e(xh,Qse),e(Qse,Pgo),e(xh,Bgo),e(xh,OI),e(OI,Igo),e(xh,Ngo),e(Y,qgo),e(Y,$h),e($h,Hse),e(Hse,jgo),e($h,Dgo),e($h,VI),e(VI,Ggo),e($h,Ogo),e(Y,Vgo),e(Y,kh),e(kh,Use),e(Use,Xgo),e(kh,zgo),e(kh,XI),e(XI,Wgo),e(kh,Qgo),e(Y,Hgo),e(Y,Sh),e(Sh,Jse),e(Jse,Ugo),e(Sh,Jgo),e(Sh,zI),e(zI,Ygo),e(Sh,Kgo),e(Y,Zgo),e(Y,Rh),e(Rh,Yse),e(Yse,eho),e(Rh,oho),e(Rh,WI),e(WI,rho),e(Rh,tho),e(Y,aho),e(Y,Ph),e(Ph,Kse),e(Kse,nho),e(Ph,sho),e(Ph,QI),e(QI,lho),e(Ph,iho),e(Y,dho),e(Y,Bh),e(Bh,Zse),e(Zse,cho),e(Bh,fho),e(Bh,HI),e(HI,mho),e(Bh,gho),e(Y,hho),e(Y,Ih),e(Ih,ele),e(ele,pho),e(Ih,uho),e(Ih,UI),e(UI,_ho),e(Ih,bho),e(Y,vho),e(Y,Nh),e(Nh,ole),e(ole,Fho),e(Nh,Tho),e(Nh,JI),e(JI,Mho),e(Nh,Eho),e(Y,Cho),e(Y,qh),e(qh,rle),e(rle,who),e(qh,Aho),e(qh,YI),e(YI,yho),e(qh,Lho),e(Y,xho),e(Y,jh),e(jh,tle),e(tle,$ho),e(jh,kho),e(jh,KI),e(KI,Sho),e(jh,Rho),e(Y,Pho),e(Y,Dh),e(Dh,ale),e(ale,Bho),e(Dh,Iho),e(Dh,ZI),e(ZI,Nho),e(Dh,qho),e(Y,jho),e(Y,Gh),e(Gh,nle),e(nle,Dho),e(Gh,Gho),e(Gh,eN),e(eN,Oho),e(Gh,Vho),e(Y,Xho),e(Y,Oh),e(Oh,sle),e(sle,zho),e(Oh,Who),e(Oh,oN),e(oN,Qho),e(Oh,Hho),e(Y,Uho),e(Y,Vh),e(Vh,lle),e(lle,Jho),e(Vh,Yho),e(Vh,rN),e(rN,Kho),e(Vh,Zho),e(Y,epo),e(Y,Xh),e(Xh,ile),e(ile,opo),e(Xh,rpo),e(Xh,tN),e(tN,tpo),e(Xh,apo),e(Y,npo),e(Y,zh),e(zh,dle),e(dle,spo),e(zh,lpo),e(zh,aN),e(aN,ipo),e(zh,dpo),e(Y,cpo),e(Y,Wh),e(Wh,cle),e(cle,fpo),e(Wh,mpo),e(Wh,nN),e(nN,gpo),e(Wh,hpo),e(Y,ppo),e(Y,Qh),e(Qh,fle),e(fle,upo),e(Qh,_po),e(Qh,sN),e(sN,bpo),e(Qh,vpo),e(Y,Fpo),e(Y,Hh),e(Hh,mle),e(mle,Tpo),e(Hh,Mpo),e(Hh,lN),e(lN,Epo),e(Hh,Cpo),e(Y,wpo),e(Y,Uh),e(Uh,gle),e(gle,Apo),e(Uh,ypo),e(Uh,iN),e(iN,Lpo),e(Uh,xpo),e(Y,$po),e(Y,Jh),e(Jh,hle),e(hle,kpo),e(Jh,Spo),e(Jh,dN),e(dN,Rpo),e(Jh,Ppo),e(Y,Bpo),e(Y,Yh),e(Yh,ple),e(ple,Ipo),e(Yh,Npo),e(Yh,cN),e(cN,qpo),e(Yh,jpo),e(Y,Dpo),e(Y,Kh),e(Kh,ule),e(ule,Gpo),e(Kh,Opo),e(Kh,fN),e(fN,Vpo),e(Kh,Xpo),e(Y,zpo),e(Y,Zh),e(Zh,_le),e(_le,Wpo),e(Zh,Qpo),e(Zh,mN),e(mN,Hpo),e(Zh,Upo),e(He,Jpo),M(ep,He,null),e(He,Ypo),M(op,He,null),e(yo,Kpo),e(yo,rp),M(kA,rp,null),e(rp,Zpo),e(rp,ble),e(ble,euo),b(f,PDe,_),b(f,ki,_),e(ki,tp),e(tp,vle),M(SA,vle,null),e(ki,ouo),e(ki,Fle),e(Fle,ruo),b(f,BDe,_),b(f,Lo,_),M(RA,Lo,null),e(Lo,tuo),e(Lo,PA),e(PA,auo),e(PA,gN),e(gN,nuo),e(PA,suo),e(Lo,luo),e(Lo,BA),e(BA,iuo),e(BA,Tle),e(Tle,duo),e(BA,cuo),e(Lo,fuo),e(Lo,Ue),M(IA,Ue,null),e(Ue,muo),e(Ue,Mle),e(Mle,guo),e(Ue,huo),e(Ue,Si),e(Si,puo),e(Si,Ele),e(Ele,uuo),e(Si,_uo),e(Si,Cle),e(Cle,buo),e(Si,vuo),e(Ue,Fuo),e(Ue,he),e(he,ap),e(ap,wle),e(wle,Tuo),e(ap,Muo),e(ap,hN),e(hN,Euo),e(ap,Cuo),e(he,wuo),e(he,np),e(np,Ale),e(Ale,Auo),e(np,yuo),e(np,yle),e(yle,Luo),e(np,xuo),e(he,$uo),e(he,sp),e(sp,Lle),e(Lle,kuo),e(sp,Suo),e(sp,pN),e(pN,Ruo),e(sp,Puo),e(he,Buo),e(he,lp),e(lp,xle),e(xle,Iuo),e(lp,Nuo),e(lp,uN),e(uN,quo),e(lp,juo),e(he,Duo),e(he,ip),e(ip,$le),e($le,Guo),e(ip,Ouo),e(ip,_N),e(_N,Vuo),e(ip,Xuo),e(he,zuo),e(he,dp),e(dp,kle),e(kle,Wuo),e(dp,Quo),e(dp,bN),e(bN,Huo),e(dp,Uuo),e(he,Juo),e(he,cp),e(cp,Sle),e(Sle,Yuo),e(cp,Kuo),e(cp,vN),e(vN,Zuo),e(cp,e_o),e(he,o_o),e(he,fp),e(fp,Rle),e(Rle,r_o),e(fp,t_o),e(fp,FN),e(FN,a_o),e(fp,n_o),e(he,s_o),e(he,mp),e(mp,Ple),e(Ple,l_o),e(mp,i_o),e(mp,TN),e(TN,d_o),e(mp,c_o),e(he,f_o),e(he,gp),e(gp,Ble),e(Ble,m_o),e(gp,g_o),e(gp,MN),e(MN,h_o),e(gp,p_o),e(he,u_o),e(he,hp),e(hp,Ile),e(Ile,__o),e(hp,b_o),e(hp,EN),e(EN,v_o),e(hp,F_o),e(he,T_o),e(he,pp),e(pp,Nle),e(Nle,M_o),e(pp,E_o),e(pp,CN),e(CN,C_o),e(pp,w_o),e(he,A_o),e(he,up),e(up,qle),e(qle,y_o),e(up,L_o),e(up,wN),e(wN,x_o),e(up,$_o),e(he,k_o),e(he,_p),e(_p,jle),e(jle,S_o),e(_p,R_o),e(_p,AN),e(AN,P_o),e(_p,B_o),e(he,I_o),e(he,bp),e(bp,Dle),e(Dle,N_o),e(bp,q_o),e(bp,yN),e(yN,j_o),e(bp,D_o),e(he,G_o),e(he,vp),e(vp,Gle),e(Gle,O_o),e(vp,V_o),e(vp,LN),e(LN,X_o),e(vp,z_o),e(he,W_o),e(he,Fp),e(Fp,Ole),e(Ole,Q_o),e(Fp,H_o),e(Fp,xN),e(xN,U_o),e(Fp,J_o),e(Ue,Y_o),M(Tp,Ue,null),e(Ue,K_o),M(Mp,Ue,null),e(Lo,Z_o),e(Lo,Ep),M(NA,Ep,null),e(Ep,e1o),e(Ep,Vle),e(Vle,o1o),b(f,IDe,_),b(f,Ri,_),e(Ri,Cp),e(Cp,Xle),M(qA,Xle,null),e(Ri,r1o),e(Ri,zle),e(zle,t1o),b(f,NDe,_),b(f,xo,_),M(jA,xo,null),e(xo,a1o),e(xo,Pi),e(Pi,n1o),e(Pi,$N),e($N,s1o),e(Pi,l1o),e(Pi,kN),e(kN,i1o),e(Pi,d1o),e(xo,c1o),e(xo,DA),e(DA,f1o),e(DA,Wle),e(Wle,m1o),e(DA,g1o),e(xo,h1o),e(xo,nt),M(GA,nt,null),e(nt,p1o),e(nt,Qle),e(Qle,u1o),e(nt,_1o),e(nt,Bi),e(Bi,b1o),e(Bi,Hle),e(Hle,v1o),e(Bi,F1o),e(Bi,SN),e(SN,T1o),e(Bi,M1o),e(nt,E1o),M(wp,nt,null),e(xo,C1o),e(xo,Je),M(OA,Je,null),e(Je,w1o),e(Je,Ule),e(Ule,A1o),e(Je,y1o),e(Je,Sa),e(Sa,L1o),e(Sa,Jle),e(Jle,x1o),e(Sa,$1o),e(Sa,Yle),e(Yle,k1o),e(Sa,S1o),e(Sa,Kle),e(Kle,R1o),e(Sa,P1o),e(Je,B1o),e(Je,x),e(x,Ap),e(Ap,Zle),e(Zle,I1o),e(Ap,N1o),e(Ap,RN),e(RN,q1o),e(Ap,j1o),e(x,D1o),e(x,yp),e(yp,eie),e(eie,G1o),e(yp,O1o),e(yp,PN),e(PN,V1o),e(yp,X1o),e(x,z1o),e(x,Lp),e(Lp,oie),e(oie,W1o),e(Lp,Q1o),e(Lp,BN),e(BN,H1o),e(Lp,U1o),e(x,J1o),e(x,xp),e(xp,rie),e(rie,Y1o),e(xp,K1o),e(xp,IN),e(IN,Z1o),e(xp,ebo),e(x,obo),e(x,$p),e($p,tie),e(tie,rbo),e($p,tbo),e($p,NN),e(NN,abo),e($p,nbo),e(x,sbo),e(x,kp),e(kp,aie),e(aie,lbo),e(kp,ibo),e(kp,qN),e(qN,dbo),e(kp,cbo),e(x,fbo),e(x,Sp),e(Sp,nie),e(nie,mbo),e(Sp,gbo),e(Sp,jN),e(jN,hbo),e(Sp,pbo),e(x,ubo),e(x,Rp),e(Rp,sie),e(sie,_bo),e(Rp,bbo),e(Rp,DN),e(DN,vbo),e(Rp,Fbo),e(x,Tbo),e(x,Pp),e(Pp,lie),e(lie,Mbo),e(Pp,Ebo),e(Pp,GN),e(GN,Cbo),e(Pp,wbo),e(x,Abo),e(x,Bp),e(Bp,iie),e(iie,ybo),e(Bp,Lbo),e(Bp,ON),e(ON,xbo),e(Bp,$bo),e(x,kbo),e(x,Ip),e(Ip,die),e(die,Sbo),e(Ip,Rbo),e(Ip,VN),e(VN,Pbo),e(Ip,Bbo),e(x,Ibo),e(x,Np),e(Np,cie),e(cie,Nbo),e(Np,qbo),e(Np,XN),e(XN,jbo),e(Np,Dbo),e(x,Gbo),e(x,qp),e(qp,fie),e(fie,Obo),e(qp,Vbo),e(qp,zN),e(zN,Xbo),e(qp,zbo),e(x,Wbo),e(x,jp),e(jp,mie),e(mie,Qbo),e(jp,Hbo),e(jp,WN),e(WN,Ubo),e(jp,Jbo),e(x,Ybo),e(x,Dp),e(Dp,gie),e(gie,Kbo),e(Dp,Zbo),e(Dp,QN),e(QN,e2o),e(Dp,o2o),e(x,r2o),e(x,Gp),e(Gp,hie),e(hie,t2o),e(Gp,a2o),e(Gp,HN),e(HN,n2o),e(Gp,s2o),e(x,l2o),e(x,Op),e(Op,pie),e(pie,i2o),e(Op,d2o),e(Op,UN),e(UN,c2o),e(Op,f2o),e(x,m2o),e(x,Vp),e(Vp,uie),e(uie,g2o),e(Vp,h2o),e(Vp,JN),e(JN,p2o),e(Vp,u2o),e(x,_2o),e(x,Xp),e(Xp,_ie),e(_ie,b2o),e(Xp,v2o),e(Xp,YN),e(YN,F2o),e(Xp,T2o),e(x,M2o),e(x,zp),e(zp,bie),e(bie,E2o),e(zp,C2o),e(zp,KN),e(KN,w2o),e(zp,A2o),e(x,y2o),e(x,Wp),e(Wp,vie),e(vie,L2o),e(Wp,x2o),e(Wp,ZN),e(ZN,$2o),e(Wp,k2o),e(x,S2o),e(x,Qp),e(Qp,Fie),e(Fie,R2o),e(Qp,P2o),e(Qp,eq),e(eq,B2o),e(Qp,I2o),e(x,N2o),e(x,Hp),e(Hp,Tie),e(Tie,q2o),e(Hp,j2o),e(Hp,oq),e(oq,D2o),e(Hp,G2o),e(x,O2o),e(x,Up),e(Up,Mie),e(Mie,V2o),e(Up,X2o),e(Up,rq),e(rq,z2o),e(Up,W2o),e(x,Q2o),e(x,Jp),e(Jp,Eie),e(Eie,H2o),e(Jp,U2o),e(Jp,tq),e(tq,J2o),e(Jp,Y2o),e(x,K2o),e(x,Yp),e(Yp,Cie),e(Cie,Z2o),e(Yp,evo),e(Yp,aq),e(aq,ovo),e(Yp,rvo),e(x,tvo),e(x,Kp),e(Kp,wie),e(wie,avo),e(Kp,nvo),e(Kp,nq),e(nq,svo),e(Kp,lvo),e(x,ivo),e(x,Zp),e(Zp,Aie),e(Aie,dvo),e(Zp,cvo),e(Zp,sq),e(sq,fvo),e(Zp,mvo),e(x,gvo),e(x,eu),e(eu,yie),e(yie,hvo),e(eu,pvo),e(eu,lq),e(lq,uvo),e(eu,_vo),e(x,bvo),e(x,ou),e(ou,Lie),e(Lie,vvo),e(ou,Fvo),e(ou,iq),e(iq,Tvo),e(ou,Mvo),e(x,Evo),e(x,ru),e(ru,xie),e(xie,Cvo),e(ru,wvo),e(ru,dq),e(dq,Avo),e(ru,yvo),e(x,Lvo),e(x,tu),e(tu,$ie),e($ie,xvo),e(tu,$vo),e(tu,cq),e(cq,kvo),e(tu,Svo),e(x,Rvo),e(x,au),e(au,kie),e(kie,Pvo),e(au,Bvo),e(au,fq),e(fq,Ivo),e(au,Nvo),e(x,qvo),e(x,Ds),e(Ds,Sie),e(Sie,jvo),e(Ds,Dvo),e(Ds,mq),e(mq,Gvo),e(Ds,Ovo),e(Ds,gq),e(gq,Vvo),e(Ds,Xvo),e(x,zvo),e(x,nu),e(nu,Rie),e(Rie,Wvo),e(nu,Qvo),e(nu,hq),e(hq,Hvo),e(nu,Uvo),e(x,Jvo),e(x,su),e(su,Pie),e(Pie,Yvo),e(su,Kvo),e(su,pq),e(pq,Zvo),e(su,e3o),e(x,o3o),e(x,lu),e(lu,Bie),e(Bie,r3o),e(lu,t3o),e(lu,uq),e(uq,a3o),e(lu,n3o),e(x,s3o),e(x,iu),e(iu,Iie),e(Iie,l3o),e(iu,i3o),e(iu,_q),e(_q,d3o),e(iu,c3o),e(x,f3o),e(x,du),e(du,Nie),e(Nie,m3o),e(du,g3o),e(du,bq),e(bq,h3o),e(du,p3o),e(x,u3o),e(x,cu),e(cu,qie),e(qie,_3o),e(cu,b3o),e(cu,vq),e(vq,v3o),e(cu,F3o),e(x,T3o),e(x,fu),e(fu,jie),e(jie,M3o),e(fu,E3o),e(fu,Fq),e(Fq,C3o),e(fu,w3o),e(x,A3o),e(x,mu),e(mu,Die),e(Die,y3o),e(mu,L3o),e(mu,Tq),e(Tq,x3o),e(mu,$3o),e(x,k3o),e(x,gu),e(gu,Gie),e(Gie,S3o),e(gu,R3o),e(gu,Mq),e(Mq,P3o),e(gu,B3o),e(x,I3o),e(x,hu),e(hu,Oie),e(Oie,N3o),e(hu,q3o),e(hu,Eq),e(Eq,j3o),e(hu,D3o),e(x,G3o),e(x,pu),e(pu,Vie),e(Vie,O3o),e(pu,V3o),e(pu,Cq),e(Cq,X3o),e(pu,z3o),e(x,W3o),e(x,uu),e(uu,Xie),e(Xie,Q3o),e(uu,H3o),e(uu,wq),e(wq,U3o),e(uu,J3o),e(x,Y3o),e(x,_u),e(_u,zie),e(zie,K3o),e(_u,Z3o),e(_u,Aq),e(Aq,eFo),e(_u,oFo),e(x,rFo),e(x,bu),e(bu,Wie),e(Wie,tFo),e(bu,aFo),e(bu,yq),e(yq,nFo),e(bu,sFo),e(x,lFo),e(x,vu),e(vu,Qie),e(Qie,iFo),e(vu,dFo),e(vu,Lq),e(Lq,cFo),e(vu,fFo),e(x,mFo),e(x,Fu),e(Fu,Hie),e(Hie,gFo),e(Fu,hFo),e(Fu,xq),e(xq,pFo),e(Fu,uFo),e(x,_Fo),e(x,Tu),e(Tu,Uie),e(Uie,bFo),e(Tu,vFo),e(Tu,$q),e($q,FFo),e(Tu,TFo),e(x,MFo),e(x,Mu),e(Mu,Jie),e(Jie,EFo),e(Mu,CFo),e(Mu,kq),e(kq,wFo),e(Mu,AFo),e(x,yFo),e(x,Eu),e(Eu,Yie),e(Yie,LFo),e(Eu,xFo),e(Eu,Sq),e(Sq,$Fo),e(Eu,kFo),e(x,SFo),e(x,Cu),e(Cu,Kie),e(Kie,RFo),e(Cu,PFo),e(Cu,Rq),e(Rq,BFo),e(Cu,IFo),e(x,NFo),e(x,wu),e(wu,Zie),e(Zie,qFo),e(wu,jFo),e(wu,Pq),e(Pq,DFo),e(wu,GFo),e(x,OFo),e(x,Au),e(Au,ede),e(ede,VFo),e(Au,XFo),e(Au,Bq),e(Bq,zFo),e(Au,WFo),e(x,QFo),e(x,yu),e(yu,ode),e(ode,HFo),e(yu,UFo),e(yu,Iq),e(Iq,JFo),e(yu,YFo),e(x,KFo),e(x,Lu),e(Lu,rde),e(rde,ZFo),e(Lu,e6o),e(Lu,Nq),e(Nq,o6o),e(Lu,r6o),e(x,t6o),e(x,xu),e(xu,tde),e(tde,a6o),e(xu,n6o),e(xu,qq),e(qq,s6o),e(xu,l6o),e(x,i6o),e(x,$u),e($u,ade),e(ade,d6o),e($u,c6o),e($u,jq),e(jq,f6o),e($u,m6o),e(x,g6o),e(x,ku),e(ku,nde),e(nde,h6o),e(ku,p6o),e(ku,Dq),e(Dq,u6o),e(ku,_6o),e(x,b6o),e(x,Su),e(Su,sde),e(sde,v6o),e(Su,F6o),e(Su,Gq),e(Gq,T6o),e(Su,M6o),e(x,E6o),e(x,Ru),e(Ru,lde),e(lde,C6o),e(Ru,w6o),e(Ru,Oq),e(Oq,A6o),e(Ru,y6o),e(x,L6o),e(x,Pu),e(Pu,ide),e(ide,x6o),e(Pu,$6o),e(Pu,Vq),e(Vq,k6o),e(Pu,S6o),e(x,R6o),e(x,Bu),e(Bu,dde),e(dde,P6o),e(Bu,B6o),e(Bu,Xq),e(Xq,I6o),e(Bu,N6o),e(x,q6o),e(x,Iu),e(Iu,cde),e(cde,j6o),e(Iu,D6o),e(Iu,zq),e(zq,G6o),e(Iu,O6o),e(x,V6o),e(x,Nu),e(Nu,fde),e(fde,X6o),e(Nu,z6o),e(Nu,Wq),e(Wq,W6o),e(Nu,Q6o),e(x,H6o),e(x,qu),e(qu,mde),e(mde,U6o),e(qu,J6o),e(qu,Qq),e(Qq,Y6o),e(qu,K6o),e(x,Z6o),e(x,ju),e(ju,gde),e(gde,eTo),e(ju,oTo),e(ju,Hq),e(Hq,rTo),e(ju,tTo),e(x,aTo),e(x,Du),e(Du,hde),e(hde,nTo),e(Du,sTo),e(Du,Uq),e(Uq,lTo),e(Du,iTo),e(x,dTo),e(x,Gu),e(Gu,pde),e(pde,cTo),e(Gu,fTo),e(Gu,Jq),e(Jq,mTo),e(Gu,gTo),e(x,hTo),e(x,Ou),e(Ou,ude),e(ude,pTo),e(Ou,uTo),e(Ou,Yq),e(Yq,_To),e(Ou,bTo),e(x,vTo),e(x,Vu),e(Vu,_de),e(_de,FTo),e(Vu,TTo),e(Vu,Kq),e(Kq,MTo),e(Vu,ETo),e(x,CTo),e(x,Xu),e(Xu,bde),e(bde,wTo),e(Xu,ATo),e(Xu,Zq),e(Zq,yTo),e(Xu,LTo),e(x,xTo),e(x,zu),e(zu,vde),e(vde,$To),e(zu,kTo),e(zu,ej),e(ej,STo),e(zu,RTo),e(x,PTo),e(x,Wu),e(Wu,Fde),e(Fde,BTo),e(Wu,ITo),e(Wu,oj),e(oj,NTo),e(Wu,qTo),e(x,jTo),e(x,Qu),e(Qu,Tde),e(Tde,DTo),e(Qu,GTo),e(Qu,rj),e(rj,OTo),e(Qu,VTo),e(x,XTo),e(x,Hu),e(Hu,Mde),e(Mde,zTo),e(Hu,WTo),e(Hu,tj),e(tj,QTo),e(Hu,HTo),e(x,UTo),e(x,Uu),e(Uu,Ede),e(Ede,JTo),e(Uu,YTo),e(Uu,aj),e(aj,KTo),e(Uu,ZTo),e(x,e7o),e(x,Ju),e(Ju,Cde),e(Cde,o7o),e(Ju,r7o),e(Ju,nj),e(nj,t7o),e(Ju,a7o),e(x,n7o),e(x,Yu),e(Yu,wde),e(wde,s7o),e(Yu,l7o),e(Yu,sj),e(sj,i7o),e(Yu,d7o),e(x,c7o),e(x,Ku),e(Ku,Ade),e(Ade,f7o),e(Ku,m7o),e(Ku,lj),e(lj,g7o),e(Ku,h7o),e(x,p7o),e(x,Zu),e(Zu,yde),e(yde,u7o),e(Zu,_7o),e(Zu,ij),e(ij,b7o),e(Zu,v7o),e(x,F7o),e(x,e_),e(e_,Lde),e(Lde,T7o),e(e_,M7o),e(e_,dj),e(dj,E7o),e(e_,C7o),e(x,w7o),e(x,o_),e(o_,xde),e(xde,A7o),e(o_,y7o),e(o_,cj),e(cj,L7o),e(o_,x7o),e(x,$7o),e(x,r_),e(r_,$de),e($de,k7o),e(r_,S7o),e(r_,fj),e(fj,R7o),e(r_,P7o),e(x,B7o),e(x,t_),e(t_,kde),e(kde,I7o),e(t_,N7o),e(t_,mj),e(mj,q7o),e(t_,j7o),e(x,D7o),e(x,a_),e(a_,Sde),e(Sde,G7o),e(a_,O7o),e(a_,gj),e(gj,V7o),e(a_,X7o),e(x,z7o),e(x,n_),e(n_,Rde),e(Rde,W7o),e(n_,Q7o),e(n_,hj),e(hj,H7o),e(n_,U7o),e(x,J7o),e(x,s_),e(s_,Pde),e(Pde,Y7o),e(s_,K7o),e(s_,pj),e(pj,Z7o),e(s_,e9o),e(x,o9o),e(x,l_),e(l_,Bde),e(Bde,r9o),e(l_,t9o),e(l_,uj),e(uj,a9o),e(l_,n9o),e(x,s9o),e(x,i_),e(i_,Ide),e(Ide,l9o),e(i_,i9o),e(i_,_j),e(_j,d9o),e(i_,c9o),e(x,f9o),e(x,d_),e(d_,Nde),e(Nde,m9o),e(d_,g9o),e(d_,bj),e(bj,h9o),e(d_,p9o),e(x,u9o),e(x,c_),e(c_,qde),e(qde,_9o),e(c_,b9o),e(c_,vj),e(vj,v9o),e(c_,F9o),e(x,T9o),e(x,f_),e(f_,jde),e(jde,M9o),e(f_,E9o),e(f_,Fj),e(Fj,C9o),e(f_,w9o),e(x,A9o),e(x,m_),e(m_,Dde),e(Dde,y9o),e(m_,L9o),e(m_,Tj),e(Tj,x9o),e(m_,$9o),e(x,k9o),e(x,g_),e(g_,Gde),e(Gde,S9o),e(g_,R9o),e(g_,Mj),e(Mj,P9o),e(g_,B9o),e(x,I9o),e(x,h_),e(h_,Ode),e(Ode,N9o),e(h_,q9o),e(h_,Ej),e(Ej,j9o),e(h_,D9o),e(x,G9o),e(x,p_),e(p_,Vde),e(Vde,O9o),e(p_,V9o),e(p_,Cj),e(Cj,X9o),e(p_,z9o),e(x,W9o),e(x,u_),e(u_,Xde),e(Xde,Q9o),e(u_,H9o),e(u_,wj),e(wj,U9o),e(u_,J9o),e(x,Y9o),e(x,__),e(__,zde),e(zde,K9o),e(__,Z9o),e(__,Aj),e(Aj,eMo),e(__,oMo),e(x,rMo),e(x,b_),e(b_,Wde),e(Wde,tMo),e(b_,aMo),e(b_,yj),e(yj,nMo),e(b_,sMo),e(x,lMo),e(x,v_),e(v_,Qde),e(Qde,iMo),e(v_,dMo),e(v_,Lj),e(Lj,cMo),e(v_,fMo),e(x,mMo),e(x,F_),e(F_,Hde),e(Hde,gMo),e(F_,hMo),e(F_,xj),e(xj,pMo),e(F_,uMo),e(x,_Mo),e(x,T_),e(T_,Ude),e(Ude,bMo),e(T_,vMo),e(T_,$j),e($j,FMo),e(T_,TMo),e(Je,MMo),e(Je,M_),e(M_,EMo),e(M_,Jde),e(Jde,CMo),e(M_,wMo),e(M_,Yde),e(Yde,AMo),e(Je,yMo),M(E_,Je,null),b(f,qDe,_),b(f,Ii,_),e(Ii,C_),e(C_,Kde),M(VA,Kde,null),e(Ii,LMo),e(Ii,Zde),e(Zde,xMo),b(f,jDe,_),b(f,$o,_),M(XA,$o,null),e($o,$Mo),e($o,Ni),e(Ni,kMo),e(Ni,kj),e(kj,SMo),e(Ni,RMo),e(Ni,Sj),e(Sj,PMo),e(Ni,BMo),e($o,IMo),e($o,zA),e(zA,NMo),e(zA,ece),e(ece,qMo),e(zA,jMo),e($o,DMo),e($o,st),M(WA,st,null),e(st,GMo),e(st,oce),e(oce,OMo),e(st,VMo),e(st,qi),e(qi,XMo),e(qi,rce),e(rce,zMo),e(qi,WMo),e(qi,Rj),e(Rj,QMo),e(qi,HMo),e(st,UMo),M(w_,st,null),e($o,JMo),e($o,Ye),M(QA,Ye,null),e(Ye,YMo),e(Ye,tce),e(tce,KMo),e(Ye,ZMo),e(Ye,Ra),e(Ra,e4o),e(Ra,ace),e(ace,o4o),e(Ra,r4o),e(Ra,nce),e(nce,t4o),e(Ra,a4o),e(Ra,sce),e(sce,n4o),e(Ra,s4o),e(Ye,l4o),e(Ye,G),e(G,A_),e(A_,lce),e(lce,i4o),e(A_,d4o),e(A_,Pj),e(Pj,c4o),e(A_,f4o),e(G,m4o),e(G,y_),e(y_,ice),e(ice,g4o),e(y_,h4o),e(y_,Bj),e(Bj,p4o),e(y_,u4o),e(G,_4o),e(G,L_),e(L_,dce),e(dce,b4o),e(L_,v4o),e(L_,Ij),e(Ij,F4o),e(L_,T4o),e(G,M4o),e(G,x_),e(x_,cce),e(cce,E4o),e(x_,C4o),e(x_,Nj),e(Nj,w4o),e(x_,A4o),e(G,y4o),e(G,$_),e($_,fce),e(fce,L4o),e($_,x4o),e($_,qj),e(qj,$4o),e($_,k4o),e(G,S4o),e(G,k_),e(k_,mce),e(mce,R4o),e(k_,P4o),e(k_,jj),e(jj,B4o),e(k_,I4o),e(G,N4o),e(G,S_),e(S_,gce),e(gce,q4o),e(S_,j4o),e(S_,Dj),e(Dj,D4o),e(S_,G4o),e(G,O4o),e(G,R_),e(R_,hce),e(hce,V4o),e(R_,X4o),e(R_,Gj),e(Gj,z4o),e(R_,W4o),e(G,Q4o),e(G,P_),e(P_,pce),e(pce,H4o),e(P_,U4o),e(P_,Oj),e(Oj,J4o),e(P_,Y4o),e(G,K4o),e(G,B_),e(B_,uce),e(uce,Z4o),e(B_,eEo),e(B_,Vj),e(Vj,oEo),e(B_,rEo),e(G,tEo),e(G,I_),e(I_,_ce),e(_ce,aEo),e(I_,nEo),e(I_,Xj),e(Xj,sEo),e(I_,lEo),e(G,iEo),e(G,N_),e(N_,bce),e(bce,dEo),e(N_,cEo),e(N_,zj),e(zj,fEo),e(N_,mEo),e(G,gEo),e(G,q_),e(q_,vce),e(vce,hEo),e(q_,pEo),e(q_,Wj),e(Wj,uEo),e(q_,_Eo),e(G,bEo),e(G,j_),e(j_,Fce),e(Fce,vEo),e(j_,FEo),e(j_,Qj),e(Qj,TEo),e(j_,MEo),e(G,EEo),e(G,D_),e(D_,Tce),e(Tce,CEo),e(D_,wEo),e(D_,Hj),e(Hj,AEo),e(D_,yEo),e(G,LEo),e(G,G_),e(G_,Mce),e(Mce,xEo),e(G_,$Eo),e(G_,Uj),e(Uj,kEo),e(G_,SEo),e(G,REo),e(G,O_),e(O_,Ece),e(Ece,PEo),e(O_,BEo),e(O_,Jj),e(Jj,IEo),e(O_,NEo),e(G,qEo),e(G,V_),e(V_,Cce),e(Cce,jEo),e(V_,DEo),e(V_,Yj),e(Yj,GEo),e(V_,OEo),e(G,VEo),e(G,X_),e(X_,wce),e(wce,XEo),e(X_,zEo),e(X_,Kj),e(Kj,WEo),e(X_,QEo),e(G,HEo),e(G,z_),e(z_,Ace),e(Ace,UEo),e(z_,JEo),e(z_,Zj),e(Zj,YEo),e(z_,KEo),e(G,ZEo),e(G,W_),e(W_,yce),e(yce,eCo),e(W_,oCo),e(W_,eD),e(eD,rCo),e(W_,tCo),e(G,aCo),e(G,Q_),e(Q_,Lce),e(Lce,nCo),e(Q_,sCo),e(Q_,oD),e(oD,lCo),e(Q_,iCo),e(G,dCo),e(G,H_),e(H_,xce),e(xce,cCo),e(H_,fCo),e(H_,rD),e(rD,mCo),e(H_,gCo),e(G,hCo),e(G,U_),e(U_,$ce),e($ce,pCo),e(U_,uCo),e(U_,tD),e(tD,_Co),e(U_,bCo),e(G,vCo),e(G,J_),e(J_,kce),e(kce,FCo),e(J_,TCo),e(J_,aD),e(aD,MCo),e(J_,ECo),e(G,CCo),e(G,Y_),e(Y_,Sce),e(Sce,wCo),e(Y_,ACo),e(Y_,nD),e(nD,yCo),e(Y_,LCo),e(G,xCo),e(G,K_),e(K_,Rce),e(Rce,$Co),e(K_,kCo),e(K_,sD),e(sD,SCo),e(K_,RCo),e(G,PCo),e(G,Z_),e(Z_,Pce),e(Pce,BCo),e(Z_,ICo),e(Z_,lD),e(lD,NCo),e(Z_,qCo),e(G,jCo),e(G,e1),e(e1,Bce),e(Bce,DCo),e(e1,GCo),e(e1,iD),e(iD,OCo),e(e1,VCo),e(G,XCo),e(G,o1),e(o1,Ice),e(Ice,zCo),e(o1,WCo),e(o1,dD),e(dD,QCo),e(o1,HCo),e(G,UCo),e(G,r1),e(r1,Nce),e(Nce,JCo),e(r1,YCo),e(r1,cD),e(cD,KCo),e(r1,ZCo),e(G,e5o),e(G,t1),e(t1,qce),e(qce,o5o),e(t1,r5o),e(t1,fD),e(fD,t5o),e(t1,a5o),e(G,n5o),e(G,a1),e(a1,jce),e(jce,s5o),e(a1,l5o),e(a1,mD),e(mD,i5o),e(a1,d5o),e(G,c5o),e(G,n1),e(n1,Dce),e(Dce,f5o),e(n1,m5o),e(n1,gD),e(gD,g5o),e(n1,h5o),e(G,p5o),e(G,s1),e(s1,Gce),e(Gce,u5o),e(s1,_5o),e(s1,hD),e(hD,b5o),e(s1,v5o),e(G,F5o),e(G,l1),e(l1,Oce),e(Oce,T5o),e(l1,M5o),e(l1,pD),e(pD,E5o),e(l1,C5o),e(G,w5o),e(G,i1),e(i1,Vce),e(Vce,A5o),e(i1,y5o),e(i1,uD),e(uD,L5o),e(i1,x5o),e(G,$5o),e(G,d1),e(d1,Xce),e(Xce,k5o),e(d1,S5o),e(d1,_D),e(_D,R5o),e(d1,P5o),e(G,B5o),e(G,c1),e(c1,zce),e(zce,I5o),e(c1,N5o),e(c1,bD),e(bD,q5o),e(c1,j5o),e(G,D5o),e(G,f1),e(f1,Wce),e(Wce,G5o),e(f1,O5o),e(f1,vD),e(vD,V5o),e(f1,X5o),e(G,z5o),e(G,m1),e(m1,Qce),e(Qce,W5o),e(m1,Q5o),e(m1,FD),e(FD,H5o),e(m1,U5o),e(G,J5o),e(G,g1),e(g1,Hce),e(Hce,Y5o),e(g1,K5o),e(g1,TD),e(TD,Z5o),e(g1,e0o),e(G,o0o),e(G,h1),e(h1,Uce),e(Uce,r0o),e(h1,t0o),e(h1,MD),e(MD,a0o),e(h1,n0o),e(Ye,s0o),e(Ye,p1),e(p1,l0o),e(p1,Jce),e(Jce,i0o),e(p1,d0o),e(p1,Yce),e(Yce,c0o),e(Ye,f0o),M(u1,Ye,null),b(f,DDe,_),b(f,ji,_),e(ji,_1),e(_1,Kce),M(HA,Kce,null),e(ji,m0o),e(ji,Zce),e(Zce,g0o),b(f,GDe,_),b(f,ko,_),M(UA,ko,null),e(ko,h0o),e(ko,Di),e(Di,p0o),e(Di,ED),e(ED,u0o),e(Di,_0o),e(Di,CD),e(CD,b0o),e(Di,v0o),e(ko,F0o),e(ko,JA),e(JA,T0o),e(JA,efe),e(efe,M0o),e(JA,E0o),e(ko,C0o),e(ko,lt),M(YA,lt,null),e(lt,w0o),e(lt,ofe),e(ofe,A0o),e(lt,y0o),e(lt,Gi),e(Gi,L0o),e(Gi,rfe),e(rfe,x0o),e(Gi,$0o),e(Gi,wD),e(wD,k0o),e(Gi,S0o),e(lt,R0o),M(b1,lt,null),e(ko,P0o),e(ko,Ke),M(KA,Ke,null),e(Ke,B0o),e(Ke,tfe),e(tfe,I0o),e(Ke,N0o),e(Ke,Pa),e(Pa,q0o),e(Pa,afe),e(afe,j0o),e(Pa,D0o),e(Pa,nfe),e(nfe,G0o),e(Pa,O0o),e(Pa,sfe),e(sfe,V0o),e(Pa,X0o),e(Ke,z0o),e(Ke,z),e(z,v1),e(v1,lfe),e(lfe,W0o),e(v1,Q0o),e(v1,AD),e(AD,H0o),e(v1,U0o),e(z,J0o),e(z,F1),e(F1,ife),e(ife,Y0o),e(F1,K0o),e(F1,yD),e(yD,Z0o),e(F1,ewo),e(z,owo),e(z,T1),e(T1,dfe),e(dfe,rwo),e(T1,two),e(T1,LD),e(LD,awo),e(T1,nwo),e(z,swo),e(z,M1),e(M1,cfe),e(cfe,lwo),e(M1,iwo),e(M1,xD),e(xD,dwo),e(M1,cwo),e(z,fwo),e(z,E1),e(E1,ffe),e(ffe,mwo),e(E1,gwo),e(E1,$D),e($D,hwo),e(E1,pwo),e(z,uwo),e(z,C1),e(C1,mfe),e(mfe,_wo),e(C1,bwo),e(C1,kD),e(kD,vwo),e(C1,Fwo),e(z,Two),e(z,w1),e(w1,gfe),e(gfe,Mwo),e(w1,Ewo),e(w1,SD),e(SD,Cwo),e(w1,wwo),e(z,Awo),e(z,A1),e(A1,hfe),e(hfe,ywo),e(A1,Lwo),e(A1,RD),e(RD,xwo),e(A1,$wo),e(z,kwo),e(z,y1),e(y1,pfe),e(pfe,Swo),e(y1,Rwo),e(y1,PD),e(PD,Pwo),e(y1,Bwo),e(z,Iwo),e(z,L1),e(L1,ufe),e(ufe,Nwo),e(L1,qwo),e(L1,BD),e(BD,jwo),e(L1,Dwo),e(z,Gwo),e(z,x1),e(x1,_fe),e(_fe,Owo),e(x1,Vwo),e(x1,ID),e(ID,Xwo),e(x1,zwo),e(z,Wwo),e(z,$1),e($1,bfe),e(bfe,Qwo),e($1,Hwo),e($1,ND),e(ND,Uwo),e($1,Jwo),e(z,Ywo),e(z,k1),e(k1,vfe),e(vfe,Kwo),e(k1,Zwo),e(k1,qD),e(qD,eAo),e(k1,oAo),e(z,rAo),e(z,S1),e(S1,Ffe),e(Ffe,tAo),e(S1,aAo),e(S1,jD),e(jD,nAo),e(S1,sAo),e(z,lAo),e(z,R1),e(R1,Tfe),e(Tfe,iAo),e(R1,dAo),e(R1,DD),e(DD,cAo),e(R1,fAo),e(z,mAo),e(z,P1),e(P1,Mfe),e(Mfe,gAo),e(P1,hAo),e(P1,GD),e(GD,pAo),e(P1,uAo),e(z,_Ao),e(z,B1),e(B1,Efe),e(Efe,bAo),e(B1,vAo),e(B1,OD),e(OD,FAo),e(B1,TAo),e(z,MAo),e(z,I1),e(I1,Cfe),e(Cfe,EAo),e(I1,CAo),e(I1,VD),e(VD,wAo),e(I1,AAo),e(z,yAo),e(z,N1),e(N1,wfe),e(wfe,LAo),e(N1,xAo),e(N1,XD),e(XD,$Ao),e(N1,kAo),e(z,SAo),e(z,q1),e(q1,Afe),e(Afe,RAo),e(q1,PAo),e(q1,zD),e(zD,BAo),e(q1,IAo),e(z,NAo),e(z,j1),e(j1,yfe),e(yfe,qAo),e(j1,jAo),e(j1,WD),e(WD,DAo),e(j1,GAo),e(z,OAo),e(z,D1),e(D1,Lfe),e(Lfe,VAo),e(D1,XAo),e(D1,QD),e(QD,zAo),e(D1,WAo),e(z,QAo),e(z,G1),e(G1,xfe),e(xfe,HAo),e(G1,UAo),e(G1,HD),e(HD,JAo),e(G1,YAo),e(z,KAo),e(z,O1),e(O1,$fe),e($fe,ZAo),e(O1,eyo),e(O1,UD),e(UD,oyo),e(O1,ryo),e(z,tyo),e(z,V1),e(V1,kfe),e(kfe,ayo),e(V1,nyo),e(V1,JD),e(JD,syo),e(V1,lyo),e(z,iyo),e(z,X1),e(X1,Sfe),e(Sfe,dyo),e(X1,cyo),e(X1,YD),e(YD,fyo),e(X1,myo),e(z,gyo),e(z,z1),e(z1,Rfe),e(Rfe,hyo),e(z1,pyo),e(z1,KD),e(KD,uyo),e(z1,_yo),e(z,byo),e(z,W1),e(W1,Pfe),e(Pfe,vyo),e(W1,Fyo),e(W1,ZD),e(ZD,Tyo),e(W1,Myo),e(z,Eyo),e(z,Q1),e(Q1,Bfe),e(Bfe,Cyo),e(Q1,wyo),e(Q1,eG),e(eG,Ayo),e(Q1,yyo),e(z,Lyo),e(z,H1),e(H1,Ife),e(Ife,xyo),e(H1,$yo),e(H1,oG),e(oG,kyo),e(H1,Syo),e(z,Ryo),e(z,U1),e(U1,Nfe),e(Nfe,Pyo),e(U1,Byo),e(U1,rG),e(rG,Iyo),e(U1,Nyo),e(z,qyo),e(z,J1),e(J1,qfe),e(qfe,jyo),e(J1,Dyo),e(J1,tG),e(tG,Gyo),e(J1,Oyo),e(z,Vyo),e(z,Y1),e(Y1,jfe),e(jfe,Xyo),e(Y1,zyo),e(Y1,aG),e(aG,Wyo),e(Y1,Qyo),e(z,Hyo),e(z,K1),e(K1,Dfe),e(Dfe,Uyo),e(K1,Jyo),e(K1,nG),e(nG,Yyo),e(K1,Kyo),e(z,Zyo),e(z,Z1),e(Z1,Gfe),e(Gfe,eLo),e(Z1,oLo),e(Z1,sG),e(sG,rLo),e(Z1,tLo),e(z,aLo),e(z,eb),e(eb,Ofe),e(Ofe,nLo),e(eb,sLo),e(eb,lG),e(lG,lLo),e(eb,iLo),e(z,dLo),e(z,ob),e(ob,Vfe),e(Vfe,cLo),e(ob,fLo),e(ob,iG),e(iG,mLo),e(ob,gLo),e(z,hLo),e(z,rb),e(rb,Xfe),e(Xfe,pLo),e(rb,uLo),e(rb,dG),e(dG,_Lo),e(rb,bLo),e(Ke,vLo),e(Ke,tb),e(tb,FLo),e(tb,zfe),e(zfe,TLo),e(tb,MLo),e(tb,Wfe),e(Wfe,ELo),e(Ke,CLo),M(ab,Ke,null),b(f,ODe,_),b(f,Oi,_),e(Oi,nb),e(nb,Qfe),M(ZA,Qfe,null),e(Oi,wLo),e(Oi,Hfe),e(Hfe,ALo),b(f,VDe,_),b(f,So,_),M(ey,So,null),e(So,yLo),e(So,Vi),e(Vi,LLo),e(Vi,cG),e(cG,xLo),e(Vi,$Lo),e(Vi,fG),e(fG,kLo),e(Vi,SLo),e(So,RLo),e(So,oy),e(oy,PLo),e(oy,Ufe),e(Ufe,BLo),e(oy,ILo),e(So,NLo),e(So,it),M(ry,it,null),e(it,qLo),e(it,Jfe),e(Jfe,jLo),e(it,DLo),e(it,Xi),e(Xi,GLo),e(Xi,Yfe),e(Yfe,OLo),e(Xi,VLo),e(Xi,mG),e(mG,XLo),e(Xi,zLo),e(it,WLo),M(sb,it,null),e(So,QLo),e(So,Ze),M(ty,Ze,null),e(Ze,HLo),e(Ze,Kfe),e(Kfe,ULo),e(Ze,JLo),e(Ze,Ba),e(Ba,YLo),e(Ba,Zfe),e(Zfe,KLo),e(Ba,ZLo),e(Ba,eme),e(eme,e8o),e(Ba,o8o),e(Ba,ome),e(ome,r8o),e(Ba,t8o),e(Ze,a8o),e(Ze,Q),e(Q,lb),e(lb,rme),e(rme,n8o),e(lb,s8o),e(lb,gG),e(gG,l8o),e(lb,i8o),e(Q,d8o),e(Q,ib),e(ib,tme),e(tme,c8o),e(ib,f8o),e(ib,hG),e(hG,m8o),e(ib,g8o),e(Q,h8o),e(Q,db),e(db,ame),e(ame,p8o),e(db,u8o),e(db,pG),e(pG,_8o),e(db,b8o),e(Q,v8o),e(Q,cb),e(cb,nme),e(nme,F8o),e(cb,T8o),e(cb,uG),e(uG,M8o),e(cb,E8o),e(Q,C8o),e(Q,fb),e(fb,sme),e(sme,w8o),e(fb,A8o),e(fb,_G),e(_G,y8o),e(fb,L8o),e(Q,x8o),e(Q,mb),e(mb,lme),e(lme,$8o),e(mb,k8o),e(mb,bG),e(bG,S8o),e(mb,R8o),e(Q,P8o),e(Q,gb),e(gb,ime),e(ime,B8o),e(gb,I8o),e(gb,vG),e(vG,N8o),e(gb,q8o),e(Q,j8o),e(Q,hb),e(hb,dme),e(dme,D8o),e(hb,G8o),e(hb,FG),e(FG,O8o),e(hb,V8o),e(Q,X8o),e(Q,pb),e(pb,cme),e(cme,z8o),e(pb,W8o),e(pb,TG),e(TG,Q8o),e(pb,H8o),e(Q,U8o),e(Q,ub),e(ub,fme),e(fme,J8o),e(ub,Y8o),e(ub,MG),e(MG,K8o),e(ub,Z8o),e(Q,exo),e(Q,_b),e(_b,mme),e(mme,oxo),e(_b,rxo),e(_b,EG),e(EG,txo),e(_b,axo),e(Q,nxo),e(Q,bb),e(bb,gme),e(gme,sxo),e(bb,lxo),e(bb,CG),e(CG,ixo),e(bb,dxo),e(Q,cxo),e(Q,vb),e(vb,hme),e(hme,fxo),e(vb,mxo),e(vb,wG),e(wG,gxo),e(vb,hxo),e(Q,pxo),e(Q,Fb),e(Fb,pme),e(pme,uxo),e(Fb,_xo),e(Fb,AG),e(AG,bxo),e(Fb,vxo),e(Q,Fxo),e(Q,Tb),e(Tb,ume),e(ume,Txo),e(Tb,Mxo),e(Tb,yG),e(yG,Exo),e(Tb,Cxo),e(Q,wxo),e(Q,Mb),e(Mb,_me),e(_me,Axo),e(Mb,yxo),e(Mb,LG),e(LG,Lxo),e(Mb,xxo),e(Q,$xo),e(Q,Eb),e(Eb,bme),e(bme,kxo),e(Eb,Sxo),e(Eb,xG),e(xG,Rxo),e(Eb,Pxo),e(Q,Bxo),e(Q,Cb),e(Cb,vme),e(vme,Ixo),e(Cb,Nxo),e(Cb,$G),e($G,qxo),e(Cb,jxo),e(Q,Dxo),e(Q,wb),e(wb,Fme),e(Fme,Gxo),e(wb,Oxo),e(wb,kG),e(kG,Vxo),e(wb,Xxo),e(Q,zxo),e(Q,Ab),e(Ab,Tme),e(Tme,Wxo),e(Ab,Qxo),e(Ab,SG),e(SG,Hxo),e(Ab,Uxo),e(Q,Jxo),e(Q,yb),e(yb,Mme),e(Mme,Yxo),e(yb,Kxo),e(yb,RG),e(RG,Zxo),e(yb,e$o),e(Q,o$o),e(Q,Lb),e(Lb,Eme),e(Eme,r$o),e(Lb,t$o),e(Lb,PG),e(PG,a$o),e(Lb,n$o),e(Q,s$o),e(Q,xb),e(xb,Cme),e(Cme,l$o),e(xb,i$o),e(xb,BG),e(BG,d$o),e(xb,c$o),e(Q,f$o),e(Q,$b),e($b,wme),e(wme,m$o),e($b,g$o),e($b,IG),e(IG,h$o),e($b,p$o),e(Q,u$o),e(Q,kb),e(kb,Ame),e(Ame,_$o),e(kb,b$o),e(kb,NG),e(NG,v$o),e(kb,F$o),e(Q,T$o),e(Q,Sb),e(Sb,yme),e(yme,M$o),e(Sb,E$o),e(Sb,qG),e(qG,C$o),e(Sb,w$o),e(Q,A$o),e(Q,Rb),e(Rb,Lme),e(Lme,y$o),e(Rb,L$o),e(Rb,jG),e(jG,x$o),e(Rb,$$o),e(Q,k$o),e(Q,Pb),e(Pb,xme),e(xme,S$o),e(Pb,R$o),e(Pb,DG),e(DG,P$o),e(Pb,B$o),e(Q,I$o),e(Q,Bb),e(Bb,$me),e($me,N$o),e(Bb,q$o),e(Bb,GG),e(GG,j$o),e(Bb,D$o),e(Q,G$o),e(Q,Ib),e(Ib,kme),e(kme,O$o),e(Ib,V$o),e(Ib,OG),e(OG,X$o),e(Ib,z$o),e(Q,W$o),e(Q,Nb),e(Nb,Sme),e(Sme,Q$o),e(Nb,H$o),e(Nb,VG),e(VG,U$o),e(Nb,J$o),e(Q,Y$o),e(Q,qb),e(qb,Rme),e(Rme,K$o),e(qb,Z$o),e(qb,Pme),e(Pme,eko),e(qb,oko),e(Q,rko),e(Q,jb),e(jb,Bme),e(Bme,tko),e(jb,ako),e(jb,XG),e(XG,nko),e(jb,sko),e(Q,lko),e(Q,Db),e(Db,Ime),e(Ime,iko),e(Db,dko),e(Db,zG),e(zG,cko),e(Db,fko),e(Q,mko),e(Q,Gb),e(Gb,Nme),e(Nme,gko),e(Gb,hko),e(Gb,WG),e(WG,pko),e(Gb,uko),e(Q,_ko),e(Q,Ob),e(Ob,qme),e(qme,bko),e(Ob,vko),e(Ob,QG),e(QG,Fko),e(Ob,Tko),e(Ze,Mko),e(Ze,Vb),e(Vb,Eko),e(Vb,jme),e(jme,Cko),e(Vb,wko),e(Vb,Dme),e(Dme,Ako),e(Ze,yko),M(Xb,Ze,null),b(f,XDe,_),b(f,zi,_),e(zi,zb),e(zb,Gme),M(ay,Gme,null),e(zi,Lko),e(zi,Ome),e(Ome,xko),b(f,zDe,_),b(f,Ro,_),M(ny,Ro,null),e(Ro,$ko),e(Ro,Wi),e(Wi,kko),e(Wi,HG),e(HG,Sko),e(Wi,Rko),e(Wi,UG),e(UG,Pko),e(Wi,Bko),e(Ro,Iko),e(Ro,sy),e(sy,Nko),e(sy,Vme),e(Vme,qko),e(sy,jko),e(Ro,Dko),e(Ro,dt),M(ly,dt,null),e(dt,Gko),e(dt,Xme),e(Xme,Oko),e(dt,Vko),e(dt,Qi),e(Qi,Xko),e(Qi,zme),e(zme,zko),e(Qi,Wko),e(Qi,JG),e(JG,Qko),e(Qi,Hko),e(dt,Uko),M(Wb,dt,null),e(Ro,Jko),e(Ro,eo),M(iy,eo,null),e(eo,Yko),e(eo,Wme),e(Wme,Kko),e(eo,Zko),e(eo,Ia),e(Ia,eSo),e(Ia,Qme),e(Qme,oSo),e(Ia,rSo),e(Ia,Hme),e(Hme,tSo),e(Ia,aSo),e(Ia,Ume),e(Ume,nSo),e(Ia,sSo),e(eo,lSo),e(eo,ue),e(ue,Qb),e(Qb,Jme),e(Jme,iSo),e(Qb,dSo),e(Qb,YG),e(YG,cSo),e(Qb,fSo),e(ue,mSo),e(ue,Hb),e(Hb,Yme),e(Yme,gSo),e(Hb,hSo),e(Hb,KG),e(KG,pSo),e(Hb,uSo),e(ue,_So),e(ue,Ub),e(Ub,Kme),e(Kme,bSo),e(Ub,vSo),e(Ub,ZG),e(ZG,FSo),e(Ub,TSo),e(ue,MSo),e(ue,Jb),e(Jb,Zme),e(Zme,ESo),e(Jb,CSo),e(Jb,eO),e(eO,wSo),e(Jb,ASo),e(ue,ySo),e(ue,Yb),e(Yb,ege),e(ege,LSo),e(Yb,xSo),e(Yb,oO),e(oO,$So),e(Yb,kSo),e(ue,SSo),e(ue,Kb),e(Kb,oge),e(oge,RSo),e(Kb,PSo),e(Kb,rO),e(rO,BSo),e(Kb,ISo),e(ue,NSo),e(ue,Zb),e(Zb,rge),e(rge,qSo),e(Zb,jSo),e(Zb,tO),e(tO,DSo),e(Zb,GSo),e(ue,OSo),e(ue,e2),e(e2,tge),e(tge,VSo),e(e2,XSo),e(e2,aO),e(aO,zSo),e(e2,WSo),e(ue,QSo),e(ue,o2),e(o2,age),e(age,HSo),e(o2,USo),e(o2,nO),e(nO,JSo),e(o2,YSo),e(ue,KSo),e(ue,r2),e(r2,nge),e(nge,ZSo),e(r2,eRo),e(r2,sO),e(sO,oRo),e(r2,rRo),e(ue,tRo),e(ue,t2),e(t2,sge),e(sge,aRo),e(t2,nRo),e(t2,lO),e(lO,sRo),e(t2,lRo),e(ue,iRo),e(ue,a2),e(a2,lge),e(lge,dRo),e(a2,cRo),e(a2,iO),e(iO,fRo),e(a2,mRo),e(ue,gRo),e(ue,n2),e(n2,ige),e(ige,hRo),e(n2,pRo),e(n2,dO),e(dO,uRo),e(n2,_Ro),e(ue,bRo),e(ue,s2),e(s2,dge),e(dge,vRo),e(s2,FRo),e(s2,cO),e(cO,TRo),e(s2,MRo),e(ue,ERo),e(ue,l2),e(l2,cge),e(cge,CRo),e(l2,wRo),e(l2,fO),e(fO,ARo),e(l2,yRo),e(ue,LRo),e(ue,i2),e(i2,fge),e(fge,xRo),e(i2,$Ro),e(i2,mO),e(mO,kRo),e(i2,SRo),e(eo,RRo),e(eo,d2),e(d2,PRo),e(d2,mge),e(mge,BRo),e(d2,IRo),e(d2,gge),e(gge,NRo),e(eo,qRo),M(c2,eo,null),b(f,WDe,_),b(f,Hi,_),e(Hi,f2),e(f2,hge),M(dy,hge,null),e(Hi,jRo),e(Hi,pge),e(pge,DRo),b(f,QDe,_),b(f,Po,_),M(cy,Po,null),e(Po,GRo),e(Po,Ui),e(Ui,ORo),e(Ui,gO),e(gO,VRo),e(Ui,XRo),e(Ui,hO),e(hO,zRo),e(Ui,WRo),e(Po,QRo),e(Po,fy),e(fy,HRo),e(fy,uge),e(uge,URo),e(fy,JRo),e(Po,YRo),e(Po,ct),M(my,ct,null),e(ct,KRo),e(ct,_ge),e(_ge,ZRo),e(ct,ePo),e(ct,Ji),e(Ji,oPo),e(Ji,bge),e(bge,rPo),e(Ji,tPo),e(Ji,pO),e(pO,aPo),e(Ji,nPo),e(ct,sPo),M(m2,ct,null),e(Po,lPo),e(Po,oo),M(gy,oo,null),e(oo,iPo),e(oo,vge),e(vge,dPo),e(oo,cPo),e(oo,Na),e(Na,fPo),e(Na,Fge),e(Fge,mPo),e(Na,gPo),e(Na,Tge),e(Tge,hPo),e(Na,pPo),e(Na,Mge),e(Mge,uPo),e(Na,_Po),e(oo,bPo),e(oo,N),e(N,g2),e(g2,Ege),e(Ege,vPo),e(g2,FPo),e(g2,uO),e(uO,TPo),e(g2,MPo),e(N,EPo),e(N,h2),e(h2,Cge),e(Cge,CPo),e(h2,wPo),e(h2,_O),e(_O,APo),e(h2,yPo),e(N,LPo),e(N,p2),e(p2,wge),e(wge,xPo),e(p2,$Po),e(p2,bO),e(bO,kPo),e(p2,SPo),e(N,RPo),e(N,u2),e(u2,Age),e(Age,PPo),e(u2,BPo),e(u2,vO),e(vO,IPo),e(u2,NPo),e(N,qPo),e(N,_2),e(_2,yge),e(yge,jPo),e(_2,DPo),e(_2,FO),e(FO,GPo),e(_2,OPo),e(N,VPo),e(N,b2),e(b2,Lge),e(Lge,XPo),e(b2,zPo),e(b2,TO),e(TO,WPo),e(b2,QPo),e(N,HPo),e(N,v2),e(v2,xge),e(xge,UPo),e(v2,JPo),e(v2,MO),e(MO,YPo),e(v2,KPo),e(N,ZPo),e(N,F2),e(F2,$ge),e($ge,eBo),e(F2,oBo),e(F2,EO),e(EO,rBo),e(F2,tBo),e(N,aBo),e(N,T2),e(T2,kge),e(kge,nBo),e(T2,sBo),e(T2,CO),e(CO,lBo),e(T2,iBo),e(N,dBo),e(N,M2),e(M2,Sge),e(Sge,cBo),e(M2,fBo),e(M2,wO),e(wO,mBo),e(M2,gBo),e(N,hBo),e(N,E2),e(E2,Rge),e(Rge,pBo),e(E2,uBo),e(E2,AO),e(AO,_Bo),e(E2,bBo),e(N,vBo),e(N,C2),e(C2,Pge),e(Pge,FBo),e(C2,TBo),e(C2,yO),e(yO,MBo),e(C2,EBo),e(N,CBo),e(N,w2),e(w2,Bge),e(Bge,wBo),e(w2,ABo),e(w2,LO),e(LO,yBo),e(w2,LBo),e(N,xBo),e(N,A2),e(A2,Ige),e(Ige,$Bo),e(A2,kBo),e(A2,xO),e(xO,SBo),e(A2,RBo),e(N,PBo),e(N,y2),e(y2,Nge),e(Nge,BBo),e(y2,IBo),e(y2,$O),e($O,NBo),e(y2,qBo),e(N,jBo),e(N,L2),e(L2,qge),e(qge,DBo),e(L2,GBo),e(L2,kO),e(kO,OBo),e(L2,VBo),e(N,XBo),e(N,x2),e(x2,jge),e(jge,zBo),e(x2,WBo),e(x2,SO),e(SO,QBo),e(x2,HBo),e(N,UBo),e(N,$2),e($2,Dge),e(Dge,JBo),e($2,YBo),e($2,RO),e(RO,KBo),e($2,ZBo),e(N,eIo),e(N,k2),e(k2,Gge),e(Gge,oIo),e(k2,rIo),e(k2,PO),e(PO,tIo),e(k2,aIo),e(N,nIo),e(N,S2),e(S2,Oge),e(Oge,sIo),e(S2,lIo),e(S2,BO),e(BO,iIo),e(S2,dIo),e(N,cIo),e(N,R2),e(R2,Vge),e(Vge,fIo),e(R2,mIo),e(R2,IO),e(IO,gIo),e(R2,hIo),e(N,pIo),e(N,P2),e(P2,Xge),e(Xge,uIo),e(P2,_Io),e(P2,NO),e(NO,bIo),e(P2,vIo),e(N,FIo),e(N,B2),e(B2,zge),e(zge,TIo),e(B2,MIo),e(B2,qO),e(qO,EIo),e(B2,CIo),e(N,wIo),e(N,I2),e(I2,Wge),e(Wge,AIo),e(I2,yIo),e(I2,jO),e(jO,LIo),e(I2,xIo),e(N,$Io),e(N,N2),e(N2,Qge),e(Qge,kIo),e(N2,SIo),e(N2,DO),e(DO,RIo),e(N2,PIo),e(N,BIo),e(N,q2),e(q2,Hge),e(Hge,IIo),e(q2,NIo),e(q2,GO),e(GO,qIo),e(q2,jIo),e(N,DIo),e(N,j2),e(j2,Uge),e(Uge,GIo),e(j2,OIo),e(j2,OO),e(OO,VIo),e(j2,XIo),e(N,zIo),e(N,D2),e(D2,Jge),e(Jge,WIo),e(D2,QIo),e(D2,VO),e(VO,HIo),e(D2,UIo),e(N,JIo),e(N,G2),e(G2,Yge),e(Yge,YIo),e(G2,KIo),e(G2,XO),e(XO,ZIo),e(G2,eNo),e(N,oNo),e(N,O2),e(O2,Kge),e(Kge,rNo),e(O2,tNo),e(O2,zO),e(zO,aNo),e(O2,nNo),e(N,sNo),e(N,V2),e(V2,Zge),e(Zge,lNo),e(V2,iNo),e(V2,WO),e(WO,dNo),e(V2,cNo),e(N,fNo),e(N,X2),e(X2,ehe),e(ehe,mNo),e(X2,gNo),e(X2,QO),e(QO,hNo),e(X2,pNo),e(N,uNo),e(N,z2),e(z2,ohe),e(ohe,_No),e(z2,bNo),e(z2,HO),e(HO,vNo),e(z2,FNo),e(N,TNo),e(N,W2),e(W2,rhe),e(rhe,MNo),e(W2,ENo),e(W2,UO),e(UO,CNo),e(W2,wNo),e(N,ANo),e(N,Q2),e(Q2,the),e(the,yNo),e(Q2,LNo),e(Q2,JO),e(JO,xNo),e(Q2,$No),e(N,kNo),e(N,H2),e(H2,ahe),e(ahe,SNo),e(H2,RNo),e(H2,YO),e(YO,PNo),e(H2,BNo),e(N,INo),e(N,U2),e(U2,nhe),e(nhe,NNo),e(U2,qNo),e(U2,KO),e(KO,jNo),e(U2,DNo),e(N,GNo),e(N,J2),e(J2,she),e(she,ONo),e(J2,VNo),e(J2,ZO),e(ZO,XNo),e(J2,zNo),e(N,WNo),e(N,Y2),e(Y2,lhe),e(lhe,QNo),e(Y2,HNo),e(Y2,eV),e(eV,UNo),e(Y2,JNo),e(N,YNo),e(N,K2),e(K2,ihe),e(ihe,KNo),e(K2,ZNo),e(K2,oV),e(oV,eqo),e(K2,oqo),e(N,rqo),e(N,Z2),e(Z2,dhe),e(dhe,tqo),e(Z2,aqo),e(Z2,rV),e(rV,nqo),e(Z2,sqo),e(N,lqo),e(N,ev),e(ev,che),e(che,iqo),e(ev,dqo),e(ev,tV),e(tV,cqo),e(ev,fqo),e(N,mqo),e(N,ov),e(ov,fhe),e(fhe,gqo),e(ov,hqo),e(ov,aV),e(aV,pqo),e(ov,uqo),e(N,_qo),e(N,rv),e(rv,mhe),e(mhe,bqo),e(rv,vqo),e(rv,nV),e(nV,Fqo),e(rv,Tqo),e(N,Mqo),e(N,tv),e(tv,ghe),e(ghe,Eqo),e(tv,Cqo),e(tv,sV),e(sV,wqo),e(tv,Aqo),e(N,yqo),e(N,av),e(av,hhe),e(hhe,Lqo),e(av,xqo),e(av,lV),e(lV,$qo),e(av,kqo),e(N,Sqo),e(N,nv),e(nv,phe),e(phe,Rqo),e(nv,Pqo),e(nv,iV),e(iV,Bqo),e(nv,Iqo),e(N,Nqo),e(N,sv),e(sv,uhe),e(uhe,qqo),e(sv,jqo),e(sv,dV),e(dV,Dqo),e(sv,Gqo),e(oo,Oqo),e(oo,lv),e(lv,Vqo),e(lv,_he),e(_he,Xqo),e(lv,zqo),e(lv,bhe),e(bhe,Wqo),e(oo,Qqo),M(iv,oo,null),b(f,HDe,_),b(f,Yi,_),e(Yi,dv),e(dv,vhe),M(hy,vhe,null),e(Yi,Hqo),e(Yi,Fhe),e(Fhe,Uqo),b(f,UDe,_),b(f,Bo,_),M(py,Bo,null),e(Bo,Jqo),e(Bo,Ki),e(Ki,Yqo),e(Ki,cV),e(cV,Kqo),e(Ki,Zqo),e(Ki,fV),e(fV,ejo),e(Ki,ojo),e(Bo,rjo),e(Bo,uy),e(uy,tjo),e(uy,The),e(The,ajo),e(uy,njo),e(Bo,sjo),e(Bo,ft),M(_y,ft,null),e(ft,ljo),e(ft,Mhe),e(Mhe,ijo),e(ft,djo),e(ft,Zi),e(Zi,cjo),e(Zi,Ehe),e(Ehe,fjo),e(Zi,mjo),e(Zi,mV),e(mV,gjo),e(Zi,hjo),e(ft,pjo),M(cv,ft,null),e(Bo,ujo),e(Bo,ro),M(by,ro,null),e(ro,_jo),e(ro,Che),e(Che,bjo),e(ro,vjo),e(ro,qa),e(qa,Fjo),e(qa,whe),e(whe,Tjo),e(qa,Mjo),e(qa,Ahe),e(Ahe,Ejo),e(qa,Cjo),e(qa,yhe),e(yhe,wjo),e(qa,Ajo),e(ro,yjo),e(ro,Z),e(Z,fv),e(fv,Lhe),e(Lhe,Ljo),e(fv,xjo),e(fv,gV),e(gV,$jo),e(fv,kjo),e(Z,Sjo),e(Z,mv),e(mv,xhe),e(xhe,Rjo),e(mv,Pjo),e(mv,hV),e(hV,Bjo),e(mv,Ijo),e(Z,Njo),e(Z,gv),e(gv,$he),e($he,qjo),e(gv,jjo),e(gv,pV),e(pV,Djo),e(gv,Gjo),e(Z,Ojo),e(Z,hv),e(hv,khe),e(khe,Vjo),e(hv,Xjo),e(hv,uV),e(uV,zjo),e(hv,Wjo),e(Z,Qjo),e(Z,pv),e(pv,She),e(She,Hjo),e(pv,Ujo),e(pv,_V),e(_V,Jjo),e(pv,Yjo),e(Z,Kjo),e(Z,uv),e(uv,Rhe),e(Rhe,Zjo),e(uv,eDo),e(uv,bV),e(bV,oDo),e(uv,rDo),e(Z,tDo),e(Z,_v),e(_v,Phe),e(Phe,aDo),e(_v,nDo),e(_v,vV),e(vV,sDo),e(_v,lDo),e(Z,iDo),e(Z,bv),e(bv,Bhe),e(Bhe,dDo),e(bv,cDo),e(bv,FV),e(FV,fDo),e(bv,mDo),e(Z,gDo),e(Z,vv),e(vv,Ihe),e(Ihe,hDo),e(vv,pDo),e(vv,TV),e(TV,uDo),e(vv,_Do),e(Z,bDo),e(Z,Fv),e(Fv,Nhe),e(Nhe,vDo),e(Fv,FDo),e(Fv,MV),e(MV,TDo),e(Fv,MDo),e(Z,EDo),e(Z,Tv),e(Tv,qhe),e(qhe,CDo),e(Tv,wDo),e(Tv,EV),e(EV,ADo),e(Tv,yDo),e(Z,LDo),e(Z,Mv),e(Mv,jhe),e(jhe,xDo),e(Mv,$Do),e(Mv,CV),e(CV,kDo),e(Mv,SDo),e(Z,RDo),e(Z,Ev),e(Ev,Dhe),e(Dhe,PDo),e(Ev,BDo),e(Ev,wV),e(wV,IDo),e(Ev,NDo),e(Z,qDo),e(Z,Cv),e(Cv,Ghe),e(Ghe,jDo),e(Cv,DDo),e(Cv,AV),e(AV,GDo),e(Cv,ODo),e(Z,VDo),e(Z,wv),e(wv,Ohe),e(Ohe,XDo),e(wv,zDo),e(wv,yV),e(yV,WDo),e(wv,QDo),e(Z,HDo),e(Z,Av),e(Av,Vhe),e(Vhe,UDo),e(Av,JDo),e(Av,LV),e(LV,YDo),e(Av,KDo),e(Z,ZDo),e(Z,yv),e(yv,Xhe),e(Xhe,eGo),e(yv,oGo),e(yv,xV),e(xV,rGo),e(yv,tGo),e(Z,aGo),e(Z,Lv),e(Lv,zhe),e(zhe,nGo),e(Lv,sGo),e(Lv,$V),e($V,lGo),e(Lv,iGo),e(Z,dGo),e(Z,xv),e(xv,Whe),e(Whe,cGo),e(xv,fGo),e(xv,kV),e(kV,mGo),e(xv,gGo),e(Z,hGo),e(Z,$v),e($v,Qhe),e(Qhe,pGo),e($v,uGo),e($v,SV),e(SV,_Go),e($v,bGo),e(Z,vGo),e(Z,kv),e(kv,Hhe),e(Hhe,FGo),e(kv,TGo),e(kv,RV),e(RV,MGo),e(kv,EGo),e(Z,CGo),e(Z,Sv),e(Sv,Uhe),e(Uhe,wGo),e(Sv,AGo),e(Sv,PV),e(PV,yGo),e(Sv,LGo),e(Z,xGo),e(Z,Rv),e(Rv,Jhe),e(Jhe,$Go),e(Rv,kGo),e(Rv,BV),e(BV,SGo),e(Rv,RGo),e(Z,PGo),e(Z,Pv),e(Pv,Yhe),e(Yhe,BGo),e(Pv,IGo),e(Pv,IV),e(IV,NGo),e(Pv,qGo),e(Z,jGo),e(Z,Bv),e(Bv,Khe),e(Khe,DGo),e(Bv,GGo),e(Bv,NV),e(NV,OGo),e(Bv,VGo),e(Z,XGo),e(Z,Iv),e(Iv,Zhe),e(Zhe,zGo),e(Iv,WGo),e(Iv,qV),e(qV,QGo),e(Iv,HGo),e(Z,UGo),e(Z,Nv),e(Nv,epe),e(epe,JGo),e(Nv,YGo),e(Nv,jV),e(jV,KGo),e(Nv,ZGo),e(Z,eOo),e(Z,qv),e(qv,ope),e(ope,oOo),e(qv,rOo),e(qv,DV),e(DV,tOo),e(qv,aOo),e(Z,nOo),e(Z,jv),e(jv,rpe),e(rpe,sOo),e(jv,lOo),e(jv,GV),e(GV,iOo),e(jv,dOo),e(ro,cOo),e(ro,Dv),e(Dv,fOo),e(Dv,tpe),e(tpe,mOo),e(Dv,gOo),e(Dv,ape),e(ape,hOo),e(ro,pOo),M(Gv,ro,null),b(f,JDe,_),b(f,ed,_),e(ed,Ov),e(Ov,npe),M(vy,npe,null),e(ed,uOo),e(ed,spe),e(spe,_Oo),b(f,YDe,_),b(f,Io,_),M(Fy,Io,null),e(Io,bOo),e(Io,od),e(od,vOo),e(od,OV),e(OV,FOo),e(od,TOo),e(od,VV),e(VV,MOo),e(od,EOo),e(Io,COo),e(Io,Ty),e(Ty,wOo),e(Ty,lpe),e(lpe,AOo),e(Ty,yOo),e(Io,LOo),e(Io,mt),M(My,mt,null),e(mt,xOo),e(mt,ipe),e(ipe,$Oo),e(mt,kOo),e(mt,rd),e(rd,SOo),e(rd,dpe),e(dpe,ROo),e(rd,POo),e(rd,XV),e(XV,BOo),e(rd,IOo),e(mt,NOo),M(Vv,mt,null),e(Io,qOo),e(Io,to),M(Ey,to,null),e(to,jOo),e(to,cpe),e(cpe,DOo),e(to,GOo),e(to,ja),e(ja,OOo),e(ja,fpe),e(fpe,VOo),e(ja,XOo),e(ja,mpe),e(mpe,zOo),e(ja,WOo),e(ja,gpe),e(gpe,QOo),e(ja,HOo),e(to,UOo),e(to,Zr),e(Zr,Xv),e(Xv,hpe),e(hpe,JOo),e(Xv,YOo),e(Xv,zV),e(zV,KOo),e(Xv,ZOo),e(Zr,eVo),e(Zr,zv),e(zv,ppe),e(ppe,oVo),e(zv,rVo),e(zv,WV),e(WV,tVo),e(zv,aVo),e(Zr,nVo),e(Zr,Wv),e(Wv,upe),e(upe,sVo),e(Wv,lVo),e(Wv,QV),e(QV,iVo),e(Wv,dVo),e(Zr,cVo),e(Zr,Qv),e(Qv,_pe),e(_pe,fVo),e(Qv,mVo),e(Qv,HV),e(HV,gVo),e(Qv,hVo),e(Zr,pVo),e(Zr,Hv),e(Hv,bpe),e(bpe,uVo),e(Hv,_Vo),e(Hv,UV),e(UV,bVo),e(Hv,vVo),e(to,FVo),e(to,Uv),e(Uv,TVo),e(Uv,vpe),e(vpe,MVo),e(Uv,EVo),e(Uv,Fpe),e(Fpe,CVo),e(to,wVo),M(Jv,to,null),b(f,KDe,_),b(f,td,_),e(td,Yv),e(Yv,Tpe),M(Cy,Tpe,null),e(td,AVo),e(td,Mpe),e(Mpe,yVo),b(f,ZDe,_),b(f,No,_),M(wy,No,null),e(No,LVo),e(No,ad),e(ad,xVo),e(ad,JV),e(JV,$Vo),e(ad,kVo),e(ad,YV),e(YV,SVo),e(ad,RVo),e(No,PVo),e(No,Ay),e(Ay,BVo),e(Ay,Epe),e(Epe,IVo),e(Ay,NVo),e(No,qVo),e(No,gt),M(yy,gt,null),e(gt,jVo),e(gt,Cpe),e(Cpe,DVo),e(gt,GVo),e(gt,nd),e(nd,OVo),e(nd,wpe),e(wpe,VVo),e(nd,XVo),e(nd,KV),e(KV,zVo),e(nd,WVo),e(gt,QVo),M(Kv,gt,null),e(No,HVo),e(No,ao),M(Ly,ao,null),e(ao,UVo),e(ao,Ape),e(Ape,JVo),e(ao,YVo),e(ao,Da),e(Da,KVo),e(Da,ype),e(ype,ZVo),e(Da,eXo),e(Da,Lpe),e(Lpe,oXo),e(Da,rXo),e(Da,xpe),e(xpe,tXo),e(Da,aXo),e(ao,nXo),e(ao,H),e(H,Zv),e(Zv,$pe),e($pe,sXo),e(Zv,lXo),e(Zv,ZV),e(ZV,iXo),e(Zv,dXo),e(H,cXo),e(H,e3),e(e3,kpe),e(kpe,fXo),e(e3,mXo),e(e3,eX),e(eX,gXo),e(e3,hXo),e(H,pXo),e(H,o3),e(o3,Spe),e(Spe,uXo),e(o3,_Xo),e(o3,oX),e(oX,bXo),e(o3,vXo),e(H,FXo),e(H,r3),e(r3,Rpe),e(Rpe,TXo),e(r3,MXo),e(r3,rX),e(rX,EXo),e(r3,CXo),e(H,wXo),e(H,t3),e(t3,Ppe),e(Ppe,AXo),e(t3,yXo),e(t3,tX),e(tX,LXo),e(t3,xXo),e(H,$Xo),e(H,a3),e(a3,Bpe),e(Bpe,kXo),e(a3,SXo),e(a3,aX),e(aX,RXo),e(a3,PXo),e(H,BXo),e(H,n3),e(n3,Ipe),e(Ipe,IXo),e(n3,NXo),e(n3,nX),e(nX,qXo),e(n3,jXo),e(H,DXo),e(H,s3),e(s3,Npe),e(Npe,GXo),e(s3,OXo),e(s3,sX),e(sX,VXo),e(s3,XXo),e(H,zXo),e(H,l3),e(l3,qpe),e(qpe,WXo),e(l3,QXo),e(l3,lX),e(lX,HXo),e(l3,UXo),e(H,JXo),e(H,i3),e(i3,jpe),e(jpe,YXo),e(i3,KXo),e(i3,iX),e(iX,ZXo),e(i3,ezo),e(H,ozo),e(H,d3),e(d3,Dpe),e(Dpe,rzo),e(d3,tzo),e(d3,dX),e(dX,azo),e(d3,nzo),e(H,szo),e(H,c3),e(c3,Gpe),e(Gpe,lzo),e(c3,izo),e(c3,cX),e(cX,dzo),e(c3,czo),e(H,fzo),e(H,f3),e(f3,Ope),e(Ope,mzo),e(f3,gzo),e(f3,fX),e(fX,hzo),e(f3,pzo),e(H,uzo),e(H,m3),e(m3,Vpe),e(Vpe,_zo),e(m3,bzo),e(m3,mX),e(mX,vzo),e(m3,Fzo),e(H,Tzo),e(H,g3),e(g3,Xpe),e(Xpe,Mzo),e(g3,Ezo),e(g3,gX),e(gX,Czo),e(g3,wzo),e(H,Azo),e(H,h3),e(h3,zpe),e(zpe,yzo),e(h3,Lzo),e(h3,hX),e(hX,xzo),e(h3,$zo),e(H,kzo),e(H,p3),e(p3,Wpe),e(Wpe,Szo),e(p3,Rzo),e(p3,pX),e(pX,Pzo),e(p3,Bzo),e(H,Izo),e(H,u3),e(u3,Qpe),e(Qpe,Nzo),e(u3,qzo),e(u3,uX),e(uX,jzo),e(u3,Dzo),e(H,Gzo),e(H,_3),e(_3,Hpe),e(Hpe,Ozo),e(_3,Vzo),e(_3,_X),e(_X,Xzo),e(_3,zzo),e(H,Wzo),e(H,b3),e(b3,Upe),e(Upe,Qzo),e(b3,Hzo),e(b3,bX),e(bX,Uzo),e(b3,Jzo),e(H,Yzo),e(H,v3),e(v3,Jpe),e(Jpe,Kzo),e(v3,Zzo),e(v3,vX),e(vX,eWo),e(v3,oWo),e(H,rWo),e(H,F3),e(F3,Ype),e(Ype,tWo),e(F3,aWo),e(F3,FX),e(FX,nWo),e(F3,sWo),e(H,lWo),e(H,T3),e(T3,Kpe),e(Kpe,iWo),e(T3,dWo),e(T3,TX),e(TX,cWo),e(T3,fWo),e(H,mWo),e(H,M3),e(M3,Zpe),e(Zpe,gWo),e(M3,hWo),e(M3,MX),e(MX,pWo),e(M3,uWo),e(H,_Wo),e(H,E3),e(E3,eue),e(eue,bWo),e(E3,vWo),e(E3,EX),e(EX,FWo),e(E3,TWo),e(H,MWo),e(H,C3),e(C3,oue),e(oue,EWo),e(C3,CWo),e(C3,CX),e(CX,wWo),e(C3,AWo),e(H,yWo),e(H,w3),e(w3,rue),e(rue,LWo),e(w3,xWo),e(w3,wX),e(wX,$Wo),e(w3,kWo),e(H,SWo),e(H,A3),e(A3,tue),e(tue,RWo),e(A3,PWo),e(A3,AX),e(AX,BWo),e(A3,IWo),e(H,NWo),e(H,y3),e(y3,aue),e(aue,qWo),e(y3,jWo),e(y3,yX),e(yX,DWo),e(y3,GWo),e(H,OWo),e(H,L3),e(L3,nue),e(nue,VWo),e(L3,XWo),e(L3,LX),e(LX,zWo),e(L3,WWo),e(H,QWo),e(H,x3),e(x3,sue),e(sue,HWo),e(x3,UWo),e(x3,xX),e(xX,JWo),e(x3,YWo),e(H,KWo),e(H,$3),e($3,lue),e(lue,ZWo),e($3,eQo),e($3,$X),e($X,oQo),e($3,rQo),e(H,tQo),e(H,k3),e(k3,iue),e(iue,aQo),e(k3,nQo),e(k3,kX),e(kX,sQo),e(k3,lQo),e(H,iQo),e(H,S3),e(S3,due),e(due,dQo),e(S3,cQo),e(S3,SX),e(SX,fQo),e(S3,mQo),e(H,gQo),e(H,R3),e(R3,cue),e(cue,hQo),e(R3,pQo),e(R3,RX),e(RX,uQo),e(R3,_Qo),e(ao,bQo),e(ao,P3),e(P3,vQo),e(P3,fue),e(fue,FQo),e(P3,TQo),e(P3,mue),e(mue,MQo),e(ao,EQo),M(B3,ao,null),b(f,eGe,_),b(f,sd,_),e(sd,I3),e(I3,gue),M(xy,gue,null),e(sd,CQo),e(sd,hue),e(hue,wQo),b(f,oGe,_),b(f,qo,_),M($y,qo,null),e(qo,AQo),e(qo,ld),e(ld,yQo),e(ld,PX),e(PX,LQo),e(ld,xQo),e(ld,BX),e(BX,$Qo),e(ld,kQo),e(qo,SQo),e(qo,ky),e(ky,RQo),e(ky,pue),e(pue,PQo),e(ky,BQo),e(qo,IQo),e(qo,ht),M(Sy,ht,null),e(ht,NQo),e(ht,uue),e(uue,qQo),e(ht,jQo),e(ht,id),e(id,DQo),e(id,_ue),e(_ue,GQo),e(id,OQo),e(id,IX),e(IX,VQo),e(id,XQo),e(ht,zQo),M(N3,ht,null),e(qo,WQo),e(qo,no),M(Ry,no,null),e(no,QQo),e(no,bue),e(bue,HQo),e(no,UQo),e(no,Ga),e(Ga,JQo),e(Ga,vue),e(vue,YQo),e(Ga,KQo),e(Ga,Fue),e(Fue,ZQo),e(Ga,eHo),e(Ga,Tue),e(Tue,oHo),e(Ga,rHo),e(no,tHo),e(no,V),e(V,q3),e(q3,Mue),e(Mue,aHo),e(q3,nHo),e(q3,NX),e(NX,sHo),e(q3,lHo),e(V,iHo),e(V,j3),e(j3,Eue),e(Eue,dHo),e(j3,cHo),e(j3,qX),e(qX,fHo),e(j3,mHo),e(V,gHo),e(V,D3),e(D3,Cue),e(Cue,hHo),e(D3,pHo),e(D3,jX),e(jX,uHo),e(D3,_Ho),e(V,bHo),e(V,G3),e(G3,wue),e(wue,vHo),e(G3,FHo),e(G3,DX),e(DX,THo),e(G3,MHo),e(V,EHo),e(V,O3),e(O3,Aue),e(Aue,CHo),e(O3,wHo),e(O3,GX),e(GX,AHo),e(O3,yHo),e(V,LHo),e(V,V3),e(V3,yue),e(yue,xHo),e(V3,$Ho),e(V3,OX),e(OX,kHo),e(V3,SHo),e(V,RHo),e(V,X3),e(X3,Lue),e(Lue,PHo),e(X3,BHo),e(X3,VX),e(VX,IHo),e(X3,NHo),e(V,qHo),e(V,z3),e(z3,xue),e(xue,jHo),e(z3,DHo),e(z3,XX),e(XX,GHo),e(z3,OHo),e(V,VHo),e(V,W3),e(W3,$ue),e($ue,XHo),e(W3,zHo),e(W3,zX),e(zX,WHo),e(W3,QHo),e(V,HHo),e(V,Q3),e(Q3,kue),e(kue,UHo),e(Q3,JHo),e(Q3,WX),e(WX,YHo),e(Q3,KHo),e(V,ZHo),e(V,H3),e(H3,Sue),e(Sue,eUo),e(H3,oUo),e(H3,QX),e(QX,rUo),e(H3,tUo),e(V,aUo),e(V,U3),e(U3,Rue),e(Rue,nUo),e(U3,sUo),e(U3,HX),e(HX,lUo),e(U3,iUo),e(V,dUo),e(V,J3),e(J3,Pue),e(Pue,cUo),e(J3,fUo),e(J3,UX),e(UX,mUo),e(J3,gUo),e(V,hUo),e(V,Y3),e(Y3,Bue),e(Bue,pUo),e(Y3,uUo),e(Y3,JX),e(JX,_Uo),e(Y3,bUo),e(V,vUo),e(V,K3),e(K3,Iue),e(Iue,FUo),e(K3,TUo),e(K3,YX),e(YX,MUo),e(K3,EUo),e(V,CUo),e(V,Z3),e(Z3,Nue),e(Nue,wUo),e(Z3,AUo),e(Z3,KX),e(KX,yUo),e(Z3,LUo),e(V,xUo),e(V,eF),e(eF,que),e(que,$Uo),e(eF,kUo),e(eF,ZX),e(ZX,SUo),e(eF,RUo),e(V,PUo),e(V,oF),e(oF,jue),e(jue,BUo),e(oF,IUo),e(oF,ez),e(ez,NUo),e(oF,qUo),e(V,jUo),e(V,rF),e(rF,Due),e(Due,DUo),e(rF,GUo),e(rF,oz),e(oz,OUo),e(rF,VUo),e(V,XUo),e(V,tF),e(tF,Gue),e(Gue,zUo),e(tF,WUo),e(tF,rz),e(rz,QUo),e(tF,HUo),e(V,UUo),e(V,aF),e(aF,Oue),e(Oue,JUo),e(aF,YUo),e(aF,tz),e(tz,KUo),e(aF,ZUo),e(V,eJo),e(V,nF),e(nF,Vue),e(Vue,oJo),e(nF,rJo),e(nF,az),e(az,tJo),e(nF,aJo),e(V,nJo),e(V,sF),e(sF,Xue),e(Xue,sJo),e(sF,lJo),e(sF,nz),e(nz,iJo),e(sF,dJo),e(V,cJo),e(V,lF),e(lF,zue),e(zue,fJo),e(lF,mJo),e(lF,sz),e(sz,gJo),e(lF,hJo),e(V,pJo),e(V,iF),e(iF,Wue),e(Wue,uJo),e(iF,_Jo),e(iF,lz),e(lz,bJo),e(iF,vJo),e(V,FJo),e(V,dF),e(dF,Que),e(Que,TJo),e(dF,MJo),e(dF,iz),e(iz,EJo),e(dF,CJo),e(V,wJo),e(V,cF),e(cF,Hue),e(Hue,AJo),e(cF,yJo),e(cF,dz),e(dz,LJo),e(cF,xJo),e(V,$Jo),e(V,fF),e(fF,Uue),e(Uue,kJo),e(fF,SJo),e(fF,cz),e(cz,RJo),e(fF,PJo),e(V,BJo),e(V,mF),e(mF,Jue),e(Jue,IJo),e(mF,NJo),e(mF,fz),e(fz,qJo),e(mF,jJo),e(V,DJo),e(V,gF),e(gF,Yue),e(Yue,GJo),e(gF,OJo),e(gF,mz),e(mz,VJo),e(gF,XJo),e(V,zJo),e(V,hF),e(hF,Kue),e(Kue,WJo),e(hF,QJo),e(hF,gz),e(gz,HJo),e(hF,UJo),e(V,JJo),e(V,pF),e(pF,Zue),e(Zue,YJo),e(pF,KJo),e(pF,hz),e(hz,ZJo),e(pF,eYo),e(V,oYo),e(V,uF),e(uF,e_e),e(e_e,rYo),e(uF,tYo),e(uF,pz),e(pz,aYo),e(uF,nYo),e(V,sYo),e(V,_F),e(_F,o_e),e(o_e,lYo),e(_F,iYo),e(_F,uz),e(uz,dYo),e(_F,cYo),e(V,fYo),e(V,bF),e(bF,r_e),e(r_e,mYo),e(bF,gYo),e(bF,_z),e(_z,hYo),e(bF,pYo),e(V,uYo),e(V,vF),e(vF,t_e),e(t_e,_Yo),e(vF,bYo),e(vF,bz),e(bz,vYo),e(vF,FYo),e(V,TYo),e(V,FF),e(FF,a_e),e(a_e,MYo),e(FF,EYo),e(FF,vz),e(vz,CYo),e(FF,wYo),e(V,AYo),e(V,TF),e(TF,n_e),e(n_e,yYo),e(TF,LYo),e(TF,Fz),e(Fz,xYo),e(TF,$Yo),e(V,kYo),e(V,MF),e(MF,s_e),e(s_e,SYo),e(MF,RYo),e(MF,Tz),e(Tz,PYo),e(MF,BYo),e(V,IYo),e(V,EF),e(EF,l_e),e(l_e,NYo),e(EF,qYo),e(EF,Mz),e(Mz,jYo),e(EF,DYo),e(no,GYo),e(no,CF),e(CF,OYo),e(CF,i_e),e(i_e,VYo),e(CF,XYo),e(CF,d_e),e(d_e,zYo),e(no,WYo),M(wF,no,null),b(f,rGe,_),b(f,dd,_),e(dd,AF),e(AF,c_e),M(Py,c_e,null),e(dd,QYo),e(dd,f_e),e(f_e,HYo),b(f,tGe,_),b(f,jo,_),M(By,jo,null),e(jo,UYo),e(jo,cd),e(cd,JYo),e(cd,Ez),e(Ez,YYo),e(cd,KYo),e(cd,Cz),e(Cz,ZYo),e(cd,eKo),e(jo,oKo),e(jo,Iy),e(Iy,rKo),e(Iy,m_e),e(m_e,tKo),e(Iy,aKo),e(jo,nKo),e(jo,pt),M(Ny,pt,null),e(pt,sKo),e(pt,g_e),e(g_e,lKo),e(pt,iKo),e(pt,fd),e(fd,dKo),e(fd,h_e),e(h_e,cKo),e(fd,fKo),e(fd,wz),e(wz,mKo),e(fd,gKo),e(pt,hKo),M(yF,pt,null),e(jo,pKo),e(jo,so),M(qy,so,null),e(so,uKo),e(so,p_e),e(p_e,_Ko),e(so,bKo),e(so,Oa),e(Oa,vKo),e(Oa,u_e),e(u_e,FKo),e(Oa,TKo),e(Oa,__e),e(__e,MKo),e(Oa,EKo),e(Oa,b_e),e(b_e,CKo),e(Oa,wKo),e(so,AKo),e(so,v_e),e(v_e,LF),e(LF,F_e),e(F_e,yKo),e(LF,LKo),e(LF,Az),e(Az,xKo),e(LF,$Ko),e(so,kKo),e(so,xF),e(xF,SKo),e(xF,T_e),e(T_e,RKo),e(xF,PKo),e(xF,M_e),e(M_e,BKo),e(so,IKo),M($F,so,null),b(f,aGe,_),b(f,md,_),e(md,kF),e(kF,E_e),M(jy,E_e,null),e(md,NKo),e(md,C_e),e(C_e,qKo),b(f,nGe,_),b(f,Do,_),M(Dy,Do,null),e(Do,jKo),e(Do,gd),e(gd,DKo),e(gd,yz),e(yz,GKo),e(gd,OKo),e(gd,Lz),e(Lz,VKo),e(gd,XKo),e(Do,zKo),e(Do,Gy),e(Gy,WKo),e(Gy,w_e),e(w_e,QKo),e(Gy,HKo),e(Do,UKo),e(Do,ut),M(Oy,ut,null),e(ut,JKo),e(ut,A_e),e(A_e,YKo),e(ut,KKo),e(ut,hd),e(hd,ZKo),e(hd,y_e),e(y_e,eZo),e(hd,oZo),e(hd,xz),e(xz,rZo),e(hd,tZo),e(ut,aZo),M(SF,ut,null),e(Do,nZo),e(Do,lo),M(Vy,lo,null),e(lo,sZo),e(lo,L_e),e(L_e,lZo),e(lo,iZo),e(lo,Va),e(Va,dZo),e(Va,x_e),e(x_e,cZo),e(Va,fZo),e(Va,$_e),e($_e,mZo),e(Va,gZo),e(Va,k_e),e(k_e,hZo),e(Va,pZo),e(lo,uZo),e(lo,ve),e(ve,RF),e(RF,S_e),e(S_e,_Zo),e(RF,bZo),e(RF,$z),e($z,vZo),e(RF,FZo),e(ve,TZo),e(ve,PF),e(PF,R_e),e(R_e,MZo),e(PF,EZo),e(PF,kz),e(kz,CZo),e(PF,wZo),e(ve,AZo),e(ve,BF),e(BF,P_e),e(P_e,yZo),e(BF,LZo),e(BF,Sz),e(Sz,xZo),e(BF,$Zo),e(ve,kZo),e(ve,IF),e(IF,B_e),e(B_e,SZo),e(IF,RZo),e(IF,Rz),e(Rz,PZo),e(IF,BZo),e(ve,IZo),e(ve,Gs),e(Gs,I_e),e(I_e,NZo),e(Gs,qZo),e(Gs,Pz),e(Pz,jZo),e(Gs,DZo),e(Gs,Bz),e(Bz,GZo),e(Gs,OZo),e(ve,VZo),e(ve,NF),e(NF,N_e),e(N_e,XZo),e(NF,zZo),e(NF,Iz),e(Iz,WZo),e(NF,QZo),e(ve,HZo),e(ve,Os),e(Os,q_e),e(q_e,UZo),e(Os,JZo),e(Os,Nz),e(Nz,YZo),e(Os,KZo),e(Os,qz),e(qz,ZZo),e(Os,eer),e(ve,oer),e(ve,_t),e(_t,j_e),e(j_e,rer),e(_t,ter),e(_t,jz),e(jz,aer),e(_t,ner),e(_t,Dz),e(Dz,ser),e(_t,ler),e(_t,Gz),e(Gz,ier),e(_t,der),e(ve,cer),e(ve,qF),e(qF,D_e),e(D_e,fer),e(qF,mer),e(qF,Oz),e(Oz,ger),e(qF,her),e(ve,per),e(ve,jF),e(jF,G_e),e(G_e,uer),e(jF,_er),e(jF,Vz),e(Vz,ber),e(jF,ver),e(ve,Fer),e(ve,DF),e(DF,O_e),e(O_e,Ter),e(DF,Mer),e(DF,Xz),e(Xz,Eer),e(DF,Cer),e(ve,wer),e(ve,GF),e(GF,V_e),e(V_e,Aer),e(GF,yer),e(GF,zz),e(zz,Ler),e(GF,xer),e(ve,$er),e(ve,OF),e(OF,X_e),e(X_e,ker),e(OF,Ser),e(OF,Wz),e(Wz,Rer),e(OF,Per),e(ve,Ber),e(ve,VF),e(VF,z_e),e(z_e,Ier),e(VF,Ner),e(VF,Qz),e(Qz,qer),e(VF,jer),e(ve,Der),e(ve,XF),e(XF,W_e),e(W_e,Ger),e(XF,Oer),e(XF,Hz),e(Hz,Ver),e(XF,Xer),e(lo,zer),e(lo,zF),e(zF,Wer),e(zF,Q_e),e(Q_e,Qer),e(zF,Her),e(zF,H_e),e(H_e,Uer),e(lo,Jer),M(WF,lo,null),b(f,sGe,_),b(f,pd,_),e(pd,QF),e(QF,U_e),M(Xy,U_e,null),e(pd,Yer),e(pd,J_e),e(J_e,Ker),b(f,lGe,_),b(f,Go,_),M(zy,Go,null),e(Go,Zer),e(Go,ud),e(ud,eor),e(ud,Uz),e(Uz,oor),e(ud,ror),e(ud,Jz),e(Jz,tor),e(ud,aor),e(Go,nor),e(Go,Wy),e(Wy,sor),e(Wy,Y_e),e(Y_e,lor),e(Wy,ior),e(Go,dor),e(Go,bt),M(Qy,bt,null),e(bt,cor),e(bt,K_e),e(K_e,mor),e(bt,gor),e(bt,_d),e(_d,hor),e(_d,Z_e),e(Z_e,por),e(_d,uor),e(_d,Yz),e(Yz,_or),e(_d,bor),e(bt,vor),M(HF,bt,null),e(Go,For),e(Go,io),M(Hy,io,null),e(io,Tor),e(io,e1e),e(e1e,Mor),e(io,Eor),e(io,Xa),e(Xa,Cor),e(Xa,o1e),e(o1e,wor),e(Xa,Aor),e(Xa,r1e),e(r1e,yor),e(Xa,Lor),e(Xa,t1e),e(t1e,xor),e(Xa,$or),e(io,kor),e(io,a1e),e(a1e,UF),e(UF,n1e),e(n1e,Sor),e(UF,Ror),e(UF,Kz),e(Kz,Por),e(UF,Bor),e(io,Ior),e(io,JF),e(JF,Nor),e(JF,s1e),e(s1e,qor),e(JF,jor),e(JF,l1e),e(l1e,Dor),e(io,Gor),M(YF,io,null),b(f,iGe,_),b(f,bd,_),e(bd,KF),e(KF,i1e),M(Uy,i1e,null),e(bd,Oor),e(bd,d1e),e(d1e,Vor),b(f,dGe,_),b(f,Oo,_),M(Jy,Oo,null),e(Oo,Xor),e(Oo,vd),e(vd,zor),e(vd,Zz),e(Zz,Wor),e(vd,Qor),e(vd,eW),e(eW,Hor),e(vd,Uor),e(Oo,Jor),e(Oo,Yy),e(Yy,Yor),e(Yy,c1e),e(c1e,Kor),e(Yy,Zor),e(Oo,err),e(Oo,vt),M(Ky,vt,null),e(vt,orr),e(vt,f1e),e(f1e,rrr),e(vt,trr),e(vt,Fd),e(Fd,arr),e(Fd,m1e),e(m1e,nrr),e(Fd,srr),e(Fd,oW),e(oW,lrr),e(Fd,irr),e(vt,drr),M(ZF,vt,null),e(Oo,crr),e(Oo,co),M(Zy,co,null),e(co,frr),e(co,g1e),e(g1e,mrr),e(co,grr),e(co,za),e(za,hrr),e(za,h1e),e(h1e,prr),e(za,urr),e(za,p1e),e(p1e,_rr),e(za,brr),e(za,u1e),e(u1e,vrr),e(za,Frr),e(co,Trr),e(co,_1e),e(_1e,e6),e(e6,b1e),e(b1e,Mrr),e(e6,Err),e(e6,rW),e(rW,Crr),e(e6,wrr),e(co,Arr),e(co,o6),e(o6,yrr),e(o6,v1e),e(v1e,Lrr),e(o6,xrr),e(o6,F1e),e(F1e,$rr),e(co,krr),M(r6,co,null),b(f,cGe,_),b(f,Td,_),e(Td,t6),e(t6,T1e),M(eL,T1e,null),e(Td,Srr),e(Td,M1e),e(M1e,Rrr),b(f,fGe,_),b(f,Vo,_),M(oL,Vo,null),e(Vo,Prr),e(Vo,Md),e(Md,Brr),e(Md,tW),e(tW,Irr),e(Md,Nrr),e(Md,aW),e(aW,qrr),e(Md,jrr),e(Vo,Drr),e(Vo,rL),e(rL,Grr),e(rL,E1e),e(E1e,Orr),e(rL,Vrr),e(Vo,Xrr),e(Vo,Ft),M(tL,Ft,null),e(Ft,zrr),e(Ft,C1e),e(C1e,Wrr),e(Ft,Qrr),e(Ft,Ed),e(Ed,Hrr),e(Ed,w1e),e(w1e,Urr),e(Ed,Jrr),e(Ed,nW),e(nW,Yrr),e(Ed,Krr),e(Ft,Zrr),M(a6,Ft,null),e(Vo,etr),e(Vo,fo),M(aL,fo,null),e(fo,otr),e(fo,A1e),e(A1e,rtr),e(fo,ttr),e(fo,Wa),e(Wa,atr),e(Wa,y1e),e(y1e,ntr),e(Wa,str),e(Wa,L1e),e(L1e,ltr),e(Wa,itr),e(Wa,x1e),e(x1e,dtr),e(Wa,ctr),e(fo,ftr),e(fo,Re),e(Re,n6),e(n6,$1e),e($1e,mtr),e(n6,gtr),e(n6,sW),e(sW,htr),e(n6,ptr),e(Re,utr),e(Re,s6),e(s6,k1e),e(k1e,_tr),e(s6,btr),e(s6,lW),e(lW,vtr),e(s6,Ftr),e(Re,Ttr),e(Re,l6),e(l6,S1e),e(S1e,Mtr),e(l6,Etr),e(l6,iW),e(iW,Ctr),e(l6,wtr),e(Re,Atr),e(Re,i6),e(i6,R1e),e(R1e,ytr),e(i6,Ltr),e(i6,dW),e(dW,xtr),e(i6,$tr),e(Re,ktr),e(Re,d6),e(d6,P1e),e(P1e,Str),e(d6,Rtr),e(d6,cW),e(cW,Ptr),e(d6,Btr),e(Re,Itr),e(Re,c6),e(c6,B1e),e(B1e,Ntr),e(c6,qtr),e(c6,fW),e(fW,jtr),e(c6,Dtr),e(Re,Gtr),e(Re,f6),e(f6,I1e),e(I1e,Otr),e(f6,Vtr),e(f6,mW),e(mW,Xtr),e(f6,ztr),e(Re,Wtr),e(Re,m6),e(m6,N1e),e(N1e,Qtr),e(m6,Htr),e(m6,gW),e(gW,Utr),e(m6,Jtr),e(Re,Ytr),e(Re,g6),e(g6,q1e),e(q1e,Ktr),e(g6,Ztr),e(g6,hW),e(hW,ear),e(g6,oar),e(fo,rar),e(fo,h6),e(h6,tar),e(h6,j1e),e(j1e,aar),e(h6,nar),e(h6,D1e),e(D1e,sar),e(fo,lar),M(p6,fo,null),b(f,mGe,_),b(f,Cd,_),e(Cd,u6),e(u6,G1e),M(nL,G1e,null),e(Cd,iar),e(Cd,O1e),e(O1e,dar),b(f,gGe,_),b(f,Xo,_),M(sL,Xo,null),e(Xo,car),e(Xo,wd),e(wd,far),e(wd,pW),e(pW,mar),e(wd,gar),e(wd,uW),e(uW,har),e(wd,par),e(Xo,uar),e(Xo,lL),e(lL,_ar),e(lL,V1e),e(V1e,bar),e(lL,Far),e(Xo,Tar),e(Xo,Tt),M(iL,Tt,null),e(Tt,Mar),e(Tt,X1e),e(X1e,Ear),e(Tt,Car),e(Tt,Ad),e(Ad,war),e(Ad,z1e),e(z1e,Aar),e(Ad,yar),e(Ad,_W),e(_W,Lar),e(Ad,xar),e(Tt,$ar),M(_6,Tt,null),e(Xo,kar),e(Xo,mo),M(dL,mo,null),e(mo,Sar),e(mo,W1e),e(W1e,Rar),e(mo,Par),e(mo,Qa),e(Qa,Bar),e(Qa,Q1e),e(Q1e,Iar),e(Qa,Nar),e(Qa,H1e),e(H1e,qar),e(Qa,jar),e(Qa,U1e),e(U1e,Dar),e(Qa,Gar),e(mo,Oar),e(mo,et),e(et,b6),e(b6,J1e),e(J1e,Var),e(b6,Xar),e(b6,bW),e(bW,zar),e(b6,War),e(et,Qar),e(et,v6),e(v6,Y1e),e(Y1e,Har),e(v6,Uar),e(v6,vW),e(vW,Jar),e(v6,Yar),e(et,Kar),e(et,F6),e(F6,K1e),e(K1e,Zar),e(F6,enr),e(F6,FW),e(FW,onr),e(F6,rnr),e(et,tnr),e(et,T6),e(T6,Z1e),e(Z1e,anr),e(T6,nnr),e(T6,TW),e(TW,snr),e(T6,lnr),e(et,inr),e(et,M6),e(M6,ebe),e(ebe,dnr),e(M6,cnr),e(M6,MW),e(MW,fnr),e(M6,mnr),e(mo,gnr),e(mo,E6),e(E6,hnr),e(E6,obe),e(obe,pnr),e(E6,unr),e(E6,rbe),e(rbe,_nr),e(mo,bnr),M(C6,mo,null),b(f,hGe,_),b(f,yd,_),e(yd,w6),e(w6,tbe),M(cL,tbe,null),e(yd,vnr),e(yd,abe),e(abe,Fnr),b(f,pGe,_),b(f,zo,_),M(fL,zo,null),e(zo,Tnr),e(zo,Ld),e(Ld,Mnr),e(Ld,EW),e(EW,Enr),e(Ld,Cnr),e(Ld,CW),e(CW,wnr),e(Ld,Anr),e(zo,ynr),e(zo,mL),e(mL,Lnr),e(mL,nbe),e(nbe,xnr),e(mL,$nr),e(zo,knr),e(zo,Mt),M(gL,Mt,null),e(Mt,Snr),e(Mt,sbe),e(sbe,Rnr),e(Mt,Pnr),e(Mt,xd),e(xd,Bnr),e(xd,lbe),e(lbe,Inr),e(xd,Nnr),e(xd,wW),e(wW,qnr),e(xd,jnr),e(Mt,Dnr),M(A6,Mt,null),e(zo,Gnr),e(zo,go),M(hL,go,null),e(go,Onr),e(go,ibe),e(ibe,Vnr),e(go,Xnr),e(go,Ha),e(Ha,znr),e(Ha,dbe),e(dbe,Wnr),e(Ha,Qnr),e(Ha,cbe),e(cbe,Hnr),e(Ha,Unr),e(Ha,fbe),e(fbe,Jnr),e(Ha,Ynr),e(go,Knr),e(go,ye),e(ye,y6),e(y6,mbe),e(mbe,Znr),e(y6,esr),e(y6,AW),e(AW,osr),e(y6,rsr),e(ye,tsr),e(ye,L6),e(L6,gbe),e(gbe,asr),e(L6,nsr),e(L6,yW),e(yW,ssr),e(L6,lsr),e(ye,isr),e(ye,x6),e(x6,hbe),e(hbe,dsr),e(x6,csr),e(x6,LW),e(LW,fsr),e(x6,msr),e(ye,gsr),e(ye,$6),e($6,pbe),e(pbe,hsr),e($6,psr),e($6,xW),e(xW,usr),e($6,_sr),e(ye,bsr),e(ye,k6),e(k6,ube),e(ube,vsr),e(k6,Fsr),e(k6,$W),e($W,Tsr),e(k6,Msr),e(ye,Esr),e(ye,S6),e(S6,_be),e(_be,Csr),e(S6,wsr),e(S6,kW),e(kW,Asr),e(S6,ysr),e(ye,Lsr),e(ye,R6),e(R6,bbe),e(bbe,xsr),e(R6,$sr),e(R6,SW),e(SW,ksr),e(R6,Ssr),e(ye,Rsr),e(ye,P6),e(P6,vbe),e(vbe,Psr),e(P6,Bsr),e(P6,RW),e(RW,Isr),e(P6,Nsr),e(ye,qsr),e(ye,B6),e(B6,Fbe),e(Fbe,jsr),e(B6,Dsr),e(B6,PW),e(PW,Gsr),e(B6,Osr),e(ye,Vsr),e(ye,I6),e(I6,Tbe),e(Tbe,Xsr),e(I6,zsr),e(I6,BW),e(BW,Wsr),e(I6,Qsr),e(go,Hsr),e(go,N6),e(N6,Usr),e(N6,Mbe),e(Mbe,Jsr),e(N6,Ysr),e(N6,Ebe),e(Ebe,Ksr),e(go,Zsr),M(q6,go,null),b(f,uGe,_),b(f,$d,_),e($d,j6),e(j6,Cbe),M(pL,Cbe,null),e($d,elr),e($d,wbe),e(wbe,olr),b(f,_Ge,_),b(f,Wo,_),M(uL,Wo,null),e(Wo,rlr),e(Wo,kd),e(kd,tlr),e(kd,IW),e(IW,alr),e(kd,nlr),e(kd,NW),e(NW,slr),e(kd,llr),e(Wo,ilr),e(Wo,_L),e(_L,dlr),e(_L,Abe),e(Abe,clr),e(_L,flr),e(Wo,mlr),e(Wo,Et),M(bL,Et,null),e(Et,glr),e(Et,ybe),e(ybe,hlr),e(Et,plr),e(Et,Sd),e(Sd,ulr),e(Sd,Lbe),e(Lbe,_lr),e(Sd,blr),e(Sd,qW),e(qW,vlr),e(Sd,Flr),e(Et,Tlr),M(D6,Et,null),e(Wo,Mlr),e(Wo,ho),M(vL,ho,null),e(ho,Elr),e(ho,xbe),e(xbe,Clr),e(ho,wlr),e(ho,Ua),e(Ua,Alr),e(Ua,$be),e($be,ylr),e(Ua,Llr),e(Ua,kbe),e(kbe,xlr),e(Ua,$lr),e(Ua,Sbe),e(Sbe,klr),e(Ua,Slr),e(ho,Rlr),e(ho,FL),e(FL,G6),e(G6,Rbe),e(Rbe,Plr),e(G6,Blr),e(G6,jW),e(jW,Ilr),e(G6,Nlr),e(FL,qlr),e(FL,O6),e(O6,Pbe),e(Pbe,jlr),e(O6,Dlr),e(O6,DW),e(DW,Glr),e(O6,Olr),e(ho,Vlr),e(ho,V6),e(V6,Xlr),e(V6,Bbe),e(Bbe,zlr),e(V6,Wlr),e(V6,Ibe),e(Ibe,Qlr),e(ho,Hlr),M(X6,ho,null),b(f,bGe,_),b(f,Rd,_),e(Rd,z6),e(z6,Nbe),M(TL,Nbe,null),e(Rd,Ulr),e(Rd,qbe),e(qbe,Jlr),b(f,vGe,_),b(f,Qo,_),M(ML,Qo,null),e(Qo,Ylr),e(Qo,Pd),e(Pd,Klr),e(Pd,GW),e(GW,Zlr),e(Pd,eir),e(Pd,OW),e(OW,oir),e(Pd,rir),e(Qo,tir),e(Qo,EL),e(EL,air),e(EL,jbe),e(jbe,nir),e(EL,sir),e(Qo,lir),e(Qo,Ct),M(CL,Ct,null),e(Ct,iir),e(Ct,Dbe),e(Dbe,dir),e(Ct,cir),e(Ct,Bd),e(Bd,fir),e(Bd,Gbe),e(Gbe,mir),e(Bd,gir),e(Bd,VW),e(VW,hir),e(Bd,pir),e(Ct,uir),M(W6,Ct,null),e(Qo,_ir),e(Qo,po),M(wL,po,null),e(po,bir),e(po,Obe),e(Obe,vir),e(po,Fir),e(po,Ja),e(Ja,Tir),e(Ja,Vbe),e(Vbe,Mir),e(Ja,Eir),e(Ja,Xbe),e(Xbe,Cir),e(Ja,wir),e(Ja,zbe),e(zbe,Air),e(Ja,yir),e(po,Lir),e(po,ot),e(ot,Q6),e(Q6,Wbe),e(Wbe,xir),e(Q6,$ir),e(Q6,XW),e(XW,kir),e(Q6,Sir),e(ot,Rir),e(ot,H6),e(H6,Qbe),e(Qbe,Pir),e(H6,Bir),e(H6,zW),e(zW,Iir),e(H6,Nir),e(ot,qir),e(ot,U6),e(U6,Hbe),e(Hbe,jir),e(U6,Dir),e(U6,WW),e(WW,Gir),e(U6,Oir),e(ot,Vir),e(ot,J6),e(J6,Ube),e(Ube,Xir),e(J6,zir),e(J6,QW),e(QW,Wir),e(J6,Qir),e(ot,Hir),e(ot,Y6),e(Y6,Jbe),e(Jbe,Uir),e(Y6,Jir),e(Y6,HW),e(HW,Yir),e(Y6,Kir),e(po,Zir),e(po,K6),e(K6,edr),e(K6,Ybe),e(Ybe,odr),e(K6,rdr),e(K6,Kbe),e(Kbe,tdr),e(po,adr),M(Z6,po,null),b(f,FGe,_),b(f,Id,_),e(Id,eT),e(eT,Zbe),M(AL,Zbe,null),e(Id,ndr),e(Id,e2e),e(e2e,sdr),b(f,TGe,_),b(f,Ho,_),M(yL,Ho,null),e(Ho,ldr),e(Ho,Nd),e(Nd,idr),e(Nd,UW),e(UW,ddr),e(Nd,cdr),e(Nd,JW),e(JW,fdr),e(Nd,mdr),e(Ho,gdr),e(Ho,LL),e(LL,hdr),e(LL,o2e),e(o2e,pdr),e(LL,udr),e(Ho,_dr),e(Ho,wt),M(xL,wt,null),e(wt,bdr),e(wt,r2e),e(r2e,vdr),e(wt,Fdr),e(wt,qd),e(qd,Tdr),e(qd,t2e),e(t2e,Mdr),e(qd,Edr),e(qd,YW),e(YW,Cdr),e(qd,wdr),e(wt,Adr),M(oT,wt,null),e(Ho,ydr),e(Ho,uo),M($L,uo,null),e(uo,Ldr),e(uo,a2e),e(a2e,xdr),e(uo,$dr),e(uo,Ya),e(Ya,kdr),e(Ya,n2e),e(n2e,Sdr),e(Ya,Rdr),e(Ya,s2e),e(s2e,Pdr),e(Ya,Bdr),e(Ya,l2e),e(l2e,Idr),e(Ya,Ndr),e(uo,qdr),e(uo,jd),e(jd,rT),e(rT,i2e),e(i2e,jdr),e(rT,Ddr),e(rT,KW),e(KW,Gdr),e(rT,Odr),e(jd,Vdr),e(jd,tT),e(tT,d2e),e(d2e,Xdr),e(tT,zdr),e(tT,ZW),e(ZW,Wdr),e(tT,Qdr),e(jd,Hdr),e(jd,aT),e(aT,c2e),e(c2e,Udr),e(aT,Jdr),e(aT,eQ),e(eQ,Ydr),e(aT,Kdr),e(uo,Zdr),e(uo,nT),e(nT,ecr),e(nT,f2e),e(f2e,ocr),e(nT,rcr),e(nT,m2e),e(m2e,tcr),e(uo,acr),M(sT,uo,null),b(f,MGe,_),b(f,Dd,_),e(Dd,lT),e(lT,g2e),M(kL,g2e,null),e(Dd,ncr),e(Dd,h2e),e(h2e,scr),b(f,EGe,_),b(f,Uo,_),M(SL,Uo,null),e(Uo,lcr),e(Uo,Gd),e(Gd,icr),e(Gd,oQ),e(oQ,dcr),e(Gd,ccr),e(Gd,rQ),e(rQ,fcr),e(Gd,mcr),e(Uo,gcr),e(Uo,RL),e(RL,hcr),e(RL,p2e),e(p2e,pcr),e(RL,ucr),e(Uo,_cr),e(Uo,At),M(PL,At,null),e(At,bcr),e(At,u2e),e(u2e,vcr),e(At,Fcr),e(At,Od),e(Od,Tcr),e(Od,_2e),e(_2e,Mcr),e(Od,Ecr),e(Od,tQ),e(tQ,Ccr),e(Od,wcr),e(At,Acr),M(iT,At,null),e(Uo,ycr),e(Uo,_o),M(BL,_o,null),e(_o,Lcr),e(_o,b2e),e(b2e,xcr),e(_o,$cr),e(_o,Ka),e(Ka,kcr),e(Ka,v2e),e(v2e,Scr),e(Ka,Rcr),e(Ka,F2e),e(F2e,Pcr),e(Ka,Bcr),e(Ka,T2e),e(T2e,Icr),e(Ka,Ncr),e(_o,qcr),e(_o,IL),e(IL,dT),e(dT,M2e),e(M2e,jcr),e(dT,Dcr),e(dT,aQ),e(aQ,Gcr),e(dT,Ocr),e(IL,Vcr),e(IL,cT),e(cT,E2e),e(E2e,Xcr),e(cT,zcr),e(cT,nQ),e(nQ,Wcr),e(cT,Qcr),e(_o,Hcr),e(_o,fT),e(fT,Ucr),e(fT,C2e),e(C2e,Jcr),e(fT,Ycr),e(fT,w2e),e(w2e,Kcr),e(_o,Zcr),M(mT,_o,null),b(f,CGe,_),b(f,Vd,_),e(Vd,gT),e(gT,A2e),M(NL,A2e,null),e(Vd,efr),e(Vd,y2e),e(y2e,ofr),b(f,wGe,_),b(f,Jo,_),M(qL,Jo,null),e(Jo,rfr),e(Jo,Xd),e(Xd,tfr),e(Xd,sQ),e(sQ,afr),e(Xd,nfr),e(Xd,lQ),e(lQ,sfr),e(Xd,lfr),e(Jo,ifr),e(Jo,jL),e(jL,dfr),e(jL,L2e),e(L2e,cfr),e(jL,ffr),e(Jo,mfr),e(Jo,yt),M(DL,yt,null),e(yt,gfr),e(yt,x2e),e(x2e,hfr),e(yt,pfr),e(yt,zd),e(zd,ufr),e(zd,$2e),e($2e,_fr),e(zd,bfr),e(zd,iQ),e(iQ,vfr),e(zd,Ffr),e(yt,Tfr),M(hT,yt,null),e(Jo,Mfr),e(Jo,bo),M(GL,bo,null),e(bo,Efr),e(bo,k2e),e(k2e,Cfr),e(bo,wfr),e(bo,Za),e(Za,Afr),e(Za,S2e),e(S2e,yfr),e(Za,Lfr),e(Za,R2e),e(R2e,xfr),e(Za,$fr),e(Za,P2e),e(P2e,kfr),e(Za,Sfr),e(bo,Rfr),e(bo,B2e),e(B2e,pT),e(pT,I2e),e(I2e,Pfr),e(pT,Bfr),e(pT,dQ),e(dQ,Ifr),e(pT,Nfr),e(bo,qfr),e(bo,uT),e(uT,jfr),e(uT,N2e),e(N2e,Dfr),e(uT,Gfr),e(uT,q2e),e(q2e,Ofr),e(bo,Vfr),M(_T,bo,null),b(f,AGe,_),b(f,Wd,_),e(Wd,bT),e(bT,j2e),M(OL,j2e,null),e(Wd,Xfr),e(Wd,D2e),e(D2e,zfr),b(f,yGe,_),b(f,Yo,_),M(VL,Yo,null),e(Yo,Wfr),e(Yo,Qd),e(Qd,Qfr),e(Qd,cQ),e(cQ,Hfr),e(Qd,Ufr),e(Qd,fQ),e(fQ,Jfr),e(Qd,Yfr),e(Yo,Kfr),e(Yo,XL),e(XL,Zfr),e(XL,G2e),e(G2e,emr),e(XL,omr),e(Yo,rmr),e(Yo,Lt),M(zL,Lt,null),e(Lt,tmr),e(Lt,O2e),e(O2e,amr),e(Lt,nmr),e(Lt,Hd),e(Hd,smr),e(Hd,V2e),e(V2e,lmr),e(Hd,imr),e(Hd,mQ),e(mQ,dmr),e(Hd,cmr),e(Lt,fmr),M(vT,Lt,null),e(Yo,mmr),e(Yo,vo),M(WL,vo,null),e(vo,gmr),e(vo,X2e),e(X2e,hmr),e(vo,pmr),e(vo,en),e(en,umr),e(en,z2e),e(z2e,_mr),e(en,bmr),e(en,W2e),e(W2e,vmr),e(en,Fmr),e(en,Q2e),e(Q2e,Tmr),e(en,Mmr),e(vo,Emr),e(vo,on),e(on,FT),e(FT,H2e),e(H2e,Cmr),e(FT,wmr),e(FT,gQ),e(gQ,Amr),e(FT,ymr),e(on,Lmr),e(on,TT),e(TT,U2e),e(U2e,xmr),e(TT,$mr),e(TT,hQ),e(hQ,kmr),e(TT,Smr),e(on,Rmr),e(on,MT),e(MT,J2e),e(J2e,Pmr),e(MT,Bmr),e(MT,pQ),e(pQ,Imr),e(MT,Nmr),e(on,qmr),e(on,ET),e(ET,Y2e),e(Y2e,jmr),e(ET,Dmr),e(ET,uQ),e(uQ,Gmr),e(ET,Omr),e(vo,Vmr),e(vo,CT),e(CT,Xmr),e(CT,K2e),e(K2e,zmr),e(CT,Wmr),e(CT,Z2e),e(Z2e,Qmr),e(vo,Hmr),M(wT,vo,null),b(f,LGe,_),b(f,Ud,_),e(Ud,AT),e(AT,eve),M(QL,eve,null),e(Ud,Umr),e(Ud,ove),e(ove,Jmr),b(f,xGe,_),b(f,Ko,_),M(HL,Ko,null),e(Ko,Ymr),e(Ko,Jd),e(Jd,Kmr),e(Jd,_Q),e(_Q,Zmr),e(Jd,egr),e(Jd,bQ),e(bQ,ogr),e(Jd,rgr),e(Ko,tgr),e(Ko,UL),e(UL,agr),e(UL,rve),e(rve,ngr),e(UL,sgr),e(Ko,lgr),e(Ko,xt),M(JL,xt,null),e(xt,igr),e(xt,tve),e(tve,dgr),e(xt,cgr),e(xt,Yd),e(Yd,fgr),e(Yd,ave),e(ave,mgr),e(Yd,ggr),e(Yd,vQ),e(vQ,hgr),e(Yd,pgr),e(xt,ugr),M(yT,xt,null),e(Ko,_gr),e(Ko,Fo),M(YL,Fo,null),e(Fo,bgr),e(Fo,nve),e(nve,vgr),e(Fo,Fgr),e(Fo,rn),e(rn,Tgr),e(rn,sve),e(sve,Mgr),e(rn,Egr),e(rn,lve),e(lve,Cgr),e(rn,wgr),e(rn,ive),e(ive,Agr),e(rn,ygr),e(Fo,Lgr),e(Fo,dve),e(dve,LT),e(LT,cve),e(cve,xgr),e(LT,$gr),e(LT,FQ),e(FQ,kgr),e(LT,Sgr),e(Fo,Rgr),e(Fo,xT),e(xT,Pgr),e(xT,fve),e(fve,Bgr),e(xT,Igr),e(xT,mve),e(mve,Ngr),e(Fo,qgr),M($T,Fo,null),b(f,$Ge,_),b(f,Kd,_),e(Kd,kT),e(kT,gve),M(KL,gve,null),e(Kd,jgr),e(Kd,hve),e(hve,Dgr),b(f,kGe,_),b(f,Zo,_),M(ZL,Zo,null),e(Zo,Ggr),e(Zo,Zd),e(Zd,Ogr),e(Zd,TQ),e(TQ,Vgr),e(Zd,Xgr),e(Zd,MQ),e(MQ,zgr),e(Zd,Wgr),e(Zo,Qgr),e(Zo,e8),e(e8,Hgr),e(e8,pve),e(pve,Ugr),e(e8,Jgr),e(Zo,Ygr),e(Zo,$t),M(o8,$t,null),e($t,Kgr),e($t,uve),e(uve,Zgr),e($t,ehr),e($t,ec),e(ec,ohr),e(ec,_ve),e(_ve,rhr),e(ec,thr),e(ec,EQ),e(EQ,ahr),e(ec,nhr),e($t,shr),M(ST,$t,null),e(Zo,lhr),e(Zo,yr),M(r8,yr,null),e(yr,ihr),e(yr,bve),e(bve,dhr),e(yr,chr),e(yr,tn),e(tn,fhr),e(tn,vve),e(vve,mhr),e(tn,ghr),e(tn,Fve),e(Fve,hhr),e(tn,phr),e(tn,Tve),e(Tve,uhr),e(tn,_hr),e(yr,bhr),e(yr,q),e(q,RT),e(RT,Mve),e(Mve,vhr),e(RT,Fhr),e(RT,CQ),e(CQ,Thr),e(RT,Mhr),e(q,Ehr),e(q,PT),e(PT,Eve),e(Eve,Chr),e(PT,whr),e(PT,wQ),e(wQ,Ahr),e(PT,yhr),e(q,Lhr),e(q,BT),e(BT,Cve),e(Cve,xhr),e(BT,$hr),e(BT,AQ),e(AQ,khr),e(BT,Shr),e(q,Rhr),e(q,IT),e(IT,wve),e(wve,Phr),e(IT,Bhr),e(IT,yQ),e(yQ,Ihr),e(IT,Nhr),e(q,qhr),e(q,NT),e(NT,Ave),e(Ave,jhr),e(NT,Dhr),e(NT,LQ),e(LQ,Ghr),e(NT,Ohr),e(q,Vhr),e(q,qT),e(qT,yve),e(yve,Xhr),e(qT,zhr),e(qT,xQ),e(xQ,Whr),e(qT,Qhr),e(q,Hhr),e(q,jT),e(jT,Lve),e(Lve,Uhr),e(jT,Jhr),e(jT,$Q),e($Q,Yhr),e(jT,Khr),e(q,Zhr),e(q,DT),e(DT,xve),e(xve,epr),e(DT,opr),e(DT,kQ),e(kQ,rpr),e(DT,tpr),e(q,apr),e(q,GT),e(GT,$ve),e($ve,npr),e(GT,spr),e(GT,SQ),e(SQ,lpr),e(GT,ipr),e(q,dpr),e(q,OT),e(OT,kve),e(kve,cpr),e(OT,fpr),e(OT,RQ),e(RQ,mpr),e(OT,gpr),e(q,hpr),e(q,VT),e(VT,Sve),e(Sve,ppr),e(VT,upr),e(VT,PQ),e(PQ,_pr),e(VT,bpr),e(q,vpr),e(q,XT),e(XT,Rve),e(Rve,Fpr),e(XT,Tpr),e(XT,BQ),e(BQ,Mpr),e(XT,Epr),e(q,Cpr),e(q,zT),e(zT,Pve),e(Pve,wpr),e(zT,Apr),e(zT,IQ),e(IQ,ypr),e(zT,Lpr),e(q,xpr),e(q,WT),e(WT,Bve),e(Bve,$pr),e(WT,kpr),e(WT,NQ),e(NQ,Spr),e(WT,Rpr),e(q,Ppr),e(q,QT),e(QT,Ive),e(Ive,Bpr),e(QT,Ipr),e(QT,qQ),e(qQ,Npr),e(QT,qpr),e(q,jpr),e(q,HT),e(HT,Nve),e(Nve,Dpr),e(HT,Gpr),e(HT,jQ),e(jQ,Opr),e(HT,Vpr),e(q,Xpr),e(q,UT),e(UT,qve),e(qve,zpr),e(UT,Wpr),e(UT,DQ),e(DQ,Qpr),e(UT,Hpr),e(q,Upr),e(q,Vs),e(Vs,jve),e(jve,Jpr),e(Vs,Ypr),e(Vs,GQ),e(GQ,Kpr),e(Vs,Zpr),e(Vs,OQ),e(OQ,eur),e(Vs,our),e(q,rur),e(q,JT),e(JT,Dve),e(Dve,tur),e(JT,aur),e(JT,VQ),e(VQ,nur),e(JT,sur),e(q,lur),e(q,YT),e(YT,Gve),e(Gve,iur),e(YT,dur),e(YT,XQ),e(XQ,cur),e(YT,fur),e(q,mur),e(q,KT),e(KT,Ove),e(Ove,gur),e(KT,hur),e(KT,zQ),e(zQ,pur),e(KT,uur),e(q,_ur),e(q,ZT),e(ZT,Vve),e(Vve,bur),e(ZT,vur),e(ZT,WQ),e(WQ,Fur),e(ZT,Tur),e(q,Mur),e(q,e7),e(e7,Xve),e(Xve,Eur),e(e7,Cur),e(e7,QQ),e(QQ,wur),e(e7,Aur),e(q,yur),e(q,o7),e(o7,zve),e(zve,Lur),e(o7,xur),e(o7,HQ),e(HQ,$ur),e(o7,kur),e(q,Sur),e(q,r7),e(r7,Wve),e(Wve,Rur),e(r7,Pur),e(r7,UQ),e(UQ,Bur),e(r7,Iur),e(q,Nur),e(q,t7),e(t7,Qve),e(Qve,qur),e(t7,jur),e(t7,JQ),e(JQ,Dur),e(t7,Gur),e(q,Our),e(q,a7),e(a7,Hve),e(Hve,Vur),e(a7,Xur),e(a7,YQ),e(YQ,zur),e(a7,Wur),e(q,Qur),e(q,n7),e(n7,Uve),e(Uve,Hur),e(n7,Uur),e(n7,KQ),e(KQ,Jur),e(n7,Yur),e(q,Kur),e(q,s7),e(s7,Jve),e(Jve,Zur),e(s7,e_r),e(s7,ZQ),e(ZQ,o_r),e(s7,r_r),e(q,t_r),e(q,l7),e(l7,Yve),e(Yve,a_r),e(l7,n_r),e(l7,eH),e(eH,s_r),e(l7,l_r),e(q,i_r),e(q,i7),e(i7,Kve),e(Kve,d_r),e(i7,c_r),e(i7,oH),e(oH,f_r),e(i7,m_r),e(q,g_r),e(q,d7),e(d7,Zve),e(Zve,h_r),e(d7,p_r),e(d7,rH),e(rH,u_r),e(d7,__r),e(q,b_r),e(q,c7),e(c7,e3e),e(e3e,v_r),e(c7,F_r),e(c7,tH),e(tH,T_r),e(c7,M_r),e(q,E_r),e(q,f7),e(f7,o3e),e(o3e,C_r),e(f7,w_r),e(f7,aH),e(aH,A_r),e(f7,y_r),e(q,L_r),e(q,m7),e(m7,r3e),e(r3e,x_r),e(m7,$_r),e(m7,nH),e(nH,k_r),e(m7,S_r),e(q,R_r),e(q,g7),e(g7,t3e),e(t3e,P_r),e(g7,B_r),e(g7,sH),e(sH,I_r),e(g7,N_r),e(q,q_r),e(q,h7),e(h7,a3e),e(a3e,j_r),e(h7,D_r),e(h7,lH),e(lH,G_r),e(h7,O_r),e(q,V_r),e(q,p7),e(p7,n3e),e(n3e,X_r),e(p7,z_r),e(p7,iH),e(iH,W_r),e(p7,Q_r),e(q,H_r),e(q,u7),e(u7,s3e),e(s3e,U_r),e(u7,J_r),e(u7,dH),e(dH,Y_r),e(u7,K_r),e(q,Z_r),e(q,_7),e(_7,l3e),e(l3e,e1r),e(_7,o1r),e(_7,cH),e(cH,r1r),e(_7,t1r),e(q,a1r),e(q,b7),e(b7,i3e),e(i3e,n1r),e(b7,s1r),e(b7,fH),e(fH,l1r),e(b7,i1r),e(q,d1r),e(q,v7),e(v7,d3e),e(d3e,c1r),e(v7,f1r),e(v7,mH),e(mH,m1r),e(v7,g1r),e(q,h1r),e(q,F7),e(F7,c3e),e(c3e,p1r),e(F7,u1r),e(F7,gH),e(gH,_1r),e(F7,b1r),e(q,v1r),e(q,T7),e(T7,f3e),e(f3e,F1r),e(T7,T1r),e(T7,hH),e(hH,M1r),e(T7,E1r),e(q,C1r),e(q,M7),e(M7,m3e),e(m3e,w1r),e(M7,A1r),e(M7,pH),e(pH,y1r),e(M7,L1r),e(q,x1r),e(q,E7),e(E7,g3e),e(g3e,$1r),e(E7,k1r),e(E7,uH),e(uH,S1r),e(E7,R1r),e(q,P1r),e(q,C7),e(C7,h3e),e(h3e,B1r),e(C7,I1r),e(C7,_H),e(_H,N1r),e(C7,q1r),e(yr,j1r),M(w7,yr,null),b(f,SGe,_),b(f,oc,_),e(oc,A7),e(A7,p3e),M(t8,p3e,null),e(oc,D1r),e(oc,u3e),e(u3e,G1r),b(f,RGe,_),b(f,er,_),M(a8,er,null),e(er,O1r),e(er,rc),e(rc,V1r),e(rc,bH),e(bH,X1r),e(rc,z1r),e(rc,vH),e(vH,W1r),e(rc,Q1r),e(er,H1r),e(er,n8),e(n8,U1r),e(n8,_3e),e(_3e,J1r),e(n8,Y1r),e(er,K1r),e(er,kt),M(s8,kt,null),e(kt,Z1r),e(kt,b3e),e(b3e,ebr),e(kt,obr),e(kt,tc),e(tc,rbr),e(tc,v3e),e(v3e,tbr),e(tc,abr),e(tc,FH),e(FH,nbr),e(tc,sbr),e(kt,lbr),M(y7,kt,null),e(er,ibr),e(er,Lr),M(l8,Lr,null),e(Lr,dbr),e(Lr,F3e),e(F3e,cbr),e(Lr,fbr),e(Lr,an),e(an,mbr),e(an,T3e),e(T3e,gbr),e(an,hbr),e(an,M3e),e(M3e,pbr),e(an,ubr),e(an,E3e),e(E3e,_br),e(an,bbr),e(Lr,vbr),e(Lr,se),e(se,L7),e(L7,C3e),e(C3e,Fbr),e(L7,Tbr),e(L7,TH),e(TH,Mbr),e(L7,Ebr),e(se,Cbr),e(se,x7),e(x7,w3e),e(w3e,wbr),e(x7,Abr),e(x7,MH),e(MH,ybr),e(x7,Lbr),e(se,xbr),e(se,$7),e($7,A3e),e(A3e,$br),e($7,kbr),e($7,EH),e(EH,Sbr),e($7,Rbr),e(se,Pbr),e(se,k7),e(k7,y3e),e(y3e,Bbr),e(k7,Ibr),e(k7,CH),e(CH,Nbr),e(k7,qbr),e(se,jbr),e(se,S7),e(S7,L3e),e(L3e,Dbr),e(S7,Gbr),e(S7,wH),e(wH,Obr),e(S7,Vbr),e(se,Xbr),e(se,R7),e(R7,x3e),e(x3e,zbr),e(R7,Wbr),e(R7,AH),e(AH,Qbr),e(R7,Hbr),e(se,Ubr),e(se,P7),e(P7,$3e),e($3e,Jbr),e(P7,Ybr),e(P7,yH),e(yH,Kbr),e(P7,Zbr),e(se,e2r),e(se,B7),e(B7,k3e),e(k3e,o2r),e(B7,r2r),e(B7,LH),e(LH,t2r),e(B7,a2r),e(se,n2r),e(se,I7),e(I7,S3e),e(S3e,s2r),e(I7,l2r),e(I7,xH),e(xH,i2r),e(I7,d2r),e(se,c2r),e(se,N7),e(N7,R3e),e(R3e,f2r),e(N7,m2r),e(N7,$H),e($H,g2r),e(N7,h2r),e(se,p2r),e(se,q7),e(q7,P3e),e(P3e,u2r),e(q7,_2r),e(q7,kH),e(kH,b2r),e(q7,v2r),e(se,F2r),e(se,j7),e(j7,B3e),e(B3e,T2r),e(j7,M2r),e(j7,SH),e(SH,E2r),e(j7,C2r),e(se,w2r),e(se,D7),e(D7,I3e),e(I3e,A2r),e(D7,y2r),e(D7,RH),e(RH,L2r),e(D7,x2r),e(se,$2r),e(se,G7),e(G7,N3e),e(N3e,k2r),e(G7,S2r),e(G7,PH),e(PH,R2r),e(G7,P2r),e(se,B2r),e(se,O7),e(O7,q3e),e(q3e,I2r),e(O7,N2r),e(O7,BH),e(BH,q2r),e(O7,j2r),e(se,D2r),e(se,V7),e(V7,j3e),e(j3e,G2r),e(V7,O2r),e(V7,IH),e(IH,V2r),e(V7,X2r),e(se,z2r),e(se,X7),e(X7,D3e),e(D3e,W2r),e(X7,Q2r),e(X7,NH),e(NH,H2r),e(X7,U2r),e(se,J2r),e(se,z7),e(z7,G3e),e(G3e,Y2r),e(z7,K2r),e(z7,qH),e(qH,Z2r),e(z7,evr),e(se,ovr),e(se,W7),e(W7,O3e),e(O3e,rvr),e(W7,tvr),e(W7,jH),e(jH,avr),e(W7,nvr),e(se,svr),e(se,Q7),e(Q7,V3e),e(V3e,lvr),e(Q7,ivr),e(Q7,DH),e(DH,dvr),e(Q7,cvr),e(se,fvr),e(se,H7),e(H7,X3e),e(X3e,mvr),e(H7,gvr),e(H7,GH),e(GH,hvr),e(H7,pvr),e(se,uvr),e(se,U7),e(U7,z3e),e(z3e,_vr),e(U7,bvr),e(U7,OH),e(OH,vvr),e(U7,Fvr),e(se,Tvr),e(se,J7),e(J7,W3e),e(W3e,Mvr),e(J7,Evr),e(J7,VH),e(VH,Cvr),e(J7,wvr),e(Lr,Avr),M(Y7,Lr,null),b(f,PGe,_),b(f,ac,_),e(ac,K7),e(K7,Q3e),M(i8,Q3e,null),e(ac,yvr),e(ac,H3e),e(H3e,Lvr),b(f,BGe,_),b(f,or,_),M(d8,or,null),e(or,xvr),e(or,nc),e(nc,$vr),e(nc,XH),e(XH,kvr),e(nc,Svr),e(nc,zH),e(zH,Rvr),e(nc,Pvr),e(or,Bvr),e(or,c8),e(c8,Ivr),e(c8,U3e),e(U3e,Nvr),e(c8,qvr),e(or,jvr),e(or,St),M(f8,St,null),e(St,Dvr),e(St,J3e),e(J3e,Gvr),e(St,Ovr),e(St,sc),e(sc,Vvr),e(sc,Y3e),e(Y3e,Xvr),e(sc,zvr),e(sc,WH),e(WH,Wvr),e(sc,Qvr),e(St,Hvr),M(Z7,St,null),e(or,Uvr),e(or,xr),M(m8,xr,null),e(xr,Jvr),e(xr,K3e),e(K3e,Yvr),e(xr,Kvr),e(xr,nn),e(nn,Zvr),e(nn,Z3e),e(Z3e,e3r),e(nn,o3r),e(nn,eFe),e(eFe,r3r),e(nn,t3r),e(nn,oFe),e(oFe,a3r),e(nn,n3r),e(xr,s3r),e(xr,Me),e(Me,e9),e(e9,rFe),e(rFe,l3r),e(e9,i3r),e(e9,QH),e(QH,d3r),e(e9,c3r),e(Me,f3r),e(Me,o9),e(o9,tFe),e(tFe,m3r),e(o9,g3r),e(o9,HH),e(HH,h3r),e(o9,p3r),e(Me,u3r),e(Me,r9),e(r9,aFe),e(aFe,_3r),e(r9,b3r),e(r9,UH),e(UH,v3r),e(r9,F3r),e(Me,T3r),e(Me,t9),e(t9,nFe),e(nFe,M3r),e(t9,E3r),e(t9,JH),e(JH,C3r),e(t9,w3r),e(Me,A3r),e(Me,a9),e(a9,sFe),e(sFe,y3r),e(a9,L3r),e(a9,YH),e(YH,x3r),e(a9,$3r),e(Me,k3r),e(Me,n9),e(n9,lFe),e(lFe,S3r),e(n9,R3r),e(n9,KH),e(KH,P3r),e(n9,B3r),e(Me,I3r),e(Me,s9),e(s9,iFe),e(iFe,N3r),e(s9,q3r),e(s9,ZH),e(ZH,j3r),e(s9,D3r),e(Me,G3r),e(Me,l9),e(l9,dFe),e(dFe,O3r),e(l9,V3r),e(l9,eU),e(eU,X3r),e(l9,z3r),e(Me,W3r),e(Me,i9),e(i9,cFe),e(cFe,Q3r),e(i9,H3r),e(i9,oU),e(oU,U3r),e(i9,J3r),e(Me,Y3r),e(Me,d9),e(d9,fFe),e(fFe,K3r),e(d9,Z3r),e(d9,rU),e(rU,eFr),e(d9,oFr),e(Me,rFr),e(Me,c9),e(c9,mFe),e(mFe,tFr),e(c9,aFr),e(c9,tU),e(tU,nFr),e(c9,sFr),e(Me,lFr),e(Me,f9),e(f9,gFe),e(gFe,iFr),e(f9,dFr),e(f9,aU),e(aU,cFr),e(f9,fFr),e(Me,mFr),e(Me,m9),e(m9,hFe),e(hFe,gFr),e(m9,hFr),e(m9,nU),e(nU,pFr),e(m9,uFr),e(xr,_Fr),M(g9,xr,null),b(f,IGe,_),b(f,lc,_),e(lc,h9),e(h9,pFe),M(g8,pFe,null),e(lc,bFr),e(lc,uFe),e(uFe,vFr),b(f,NGe,_),b(f,rr,_),M(h8,rr,null),e(rr,FFr),e(rr,ic),e(ic,TFr),e(ic,sU),e(sU,MFr),e(ic,EFr),e(ic,lU),e(lU,CFr),e(ic,wFr),e(rr,AFr),e(rr,p8),e(p8,yFr),e(p8,_Fe),e(_Fe,LFr),e(p8,xFr),e(rr,$Fr),e(rr,Rt),M(u8,Rt,null),e(Rt,kFr),e(Rt,bFe),e(bFe,SFr),e(Rt,RFr),e(Rt,dc),e(dc,PFr),e(dc,vFe),e(vFe,BFr),e(dc,IFr),e(dc,iU),e(iU,NFr),e(dc,qFr),e(Rt,jFr),M(p9,Rt,null),e(rr,DFr),e(rr,$r),M(_8,$r,null),e($r,GFr),e($r,FFe),e(FFe,OFr),e($r,VFr),e($r,sn),e(sn,XFr),e(sn,TFe),e(TFe,zFr),e(sn,WFr),e(sn,MFe),e(MFe,QFr),e(sn,HFr),e(sn,EFe),e(EFe,UFr),e(sn,JFr),e($r,YFr),e($r,ln),e(ln,u9),e(u9,CFe),e(CFe,KFr),e(u9,ZFr),e(u9,dU),e(dU,e6r),e(u9,o6r),e(ln,r6r),e(ln,_9),e(_9,wFe),e(wFe,t6r),e(_9,a6r),e(_9,cU),e(cU,n6r),e(_9,s6r),e(ln,l6r),e(ln,b9),e(b9,AFe),e(AFe,i6r),e(b9,d6r),e(b9,fU),e(fU,c6r),e(b9,f6r),e(ln,m6r),e(ln,v9),e(v9,yFe),e(yFe,g6r),e(v9,h6r),e(v9,mU),e(mU,p6r),e(v9,u6r),e($r,_6r),M(F9,$r,null),b(f,qGe,_),b(f,cc,_),e(cc,T9),e(T9,LFe),M(b8,LFe,null),e(cc,b6r),e(cc,xFe),e(xFe,v6r),b(f,jGe,_),b(f,tr,_),M(v8,tr,null),e(tr,F6r),e(tr,fc),e(fc,T6r),e(fc,gU),e(gU,M6r),e(fc,E6r),e(fc,hU),e(hU,C6r),e(fc,w6r),e(tr,A6r),e(tr,F8),e(F8,y6r),e(F8,$Fe),e($Fe,L6r),e(F8,x6r),e(tr,$6r),e(tr,Pt),M(T8,Pt,null),e(Pt,k6r),e(Pt,kFe),e(kFe,S6r),e(Pt,R6r),e(Pt,mc),e(mc,P6r),e(mc,SFe),e(SFe,B6r),e(mc,I6r),e(mc,pU),e(pU,N6r),e(mc,q6r),e(Pt,j6r),M(M9,Pt,null),e(tr,D6r),e(tr,kr),M(M8,kr,null),e(kr,G6r),e(kr,RFe),e(RFe,O6r),e(kr,V6r),e(kr,dn),e(dn,X6r),e(dn,PFe),e(PFe,z6r),e(dn,W6r),e(dn,BFe),e(BFe,Q6r),e(dn,H6r),e(dn,IFe),e(IFe,U6r),e(dn,J6r),e(kr,Y6r),e(kr,ie),e(ie,E9),e(E9,NFe),e(NFe,K6r),e(E9,Z6r),e(E9,uU),e(uU,eTr),e(E9,oTr),e(ie,rTr),e(ie,C9),e(C9,qFe),e(qFe,tTr),e(C9,aTr),e(C9,_U),e(_U,nTr),e(C9,sTr),e(ie,lTr),e(ie,w9),e(w9,jFe),e(jFe,iTr),e(w9,dTr),e(w9,bU),e(bU,cTr),e(w9,fTr),e(ie,mTr),e(ie,A9),e(A9,DFe),e(DFe,gTr),e(A9,hTr),e(A9,vU),e(vU,pTr),e(A9,uTr),e(ie,_Tr),e(ie,y9),e(y9,GFe),e(GFe,bTr),e(y9,vTr),e(y9,FU),e(FU,FTr),e(y9,TTr),e(ie,MTr),e(ie,L9),e(L9,OFe),e(OFe,ETr),e(L9,CTr),e(L9,TU),e(TU,wTr),e(L9,ATr),e(ie,yTr),e(ie,x9),e(x9,VFe),e(VFe,LTr),e(x9,xTr),e(x9,MU),e(MU,$Tr),e(x9,kTr),e(ie,STr),e(ie,$9),e($9,XFe),e(XFe,RTr),e($9,PTr),e($9,EU),e(EU,BTr),e($9,ITr),e(ie,NTr),e(ie,k9),e(k9,zFe),e(zFe,qTr),e(k9,jTr),e(k9,CU),e(CU,DTr),e(k9,GTr),e(ie,OTr),e(ie,S9),e(S9,WFe),e(WFe,VTr),e(S9,XTr),e(S9,wU),e(wU,zTr),e(S9,WTr),e(ie,QTr),e(ie,R9),e(R9,QFe),e(QFe,HTr),e(R9,UTr),e(R9,AU),e(AU,JTr),e(R9,YTr),e(ie,KTr),e(ie,P9),e(P9,HFe),e(HFe,ZTr),e(P9,e7r),e(P9,yU),e(yU,o7r),e(P9,r7r),e(ie,t7r),e(ie,B9),e(B9,UFe),e(UFe,a7r),e(B9,n7r),e(B9,LU),e(LU,s7r),e(B9,l7r),e(ie,i7r),e(ie,I9),e(I9,JFe),e(JFe,d7r),e(I9,c7r),e(I9,xU),e(xU,f7r),e(I9,m7r),e(ie,g7r),e(ie,N9),e(N9,YFe),e(YFe,h7r),e(N9,p7r),e(N9,$U),e($U,u7r),e(N9,_7r),e(ie,b7r),e(ie,q9),e(q9,KFe),e(KFe,v7r),e(q9,F7r),e(q9,kU),e(kU,T7r),e(q9,M7r),e(ie,E7r),e(ie,j9),e(j9,ZFe),e(ZFe,C7r),e(j9,w7r),e(j9,SU),e(SU,A7r),e(j9,y7r),e(ie,L7r),e(ie,D9),e(D9,e6e),e(e6e,x7r),e(D9,$7r),e(D9,RU),e(RU,k7r),e(D9,S7r),e(ie,R7r),e(ie,G9),e(G9,o6e),e(o6e,P7r),e(G9,B7r),e(G9,PU),e(PU,I7r),e(G9,N7r),e(ie,q7r),e(ie,O9),e(O9,r6e),e(r6e,j7r),e(O9,D7r),e(O9,BU),e(BU,G7r),e(O9,O7r),e(kr,V7r),M(V9,kr,null),b(f,DGe,_),b(f,gc,_),e(gc,X9),e(X9,t6e),M(E8,t6e,null),e(gc,X7r),e(gc,a6e),e(a6e,z7r),b(f,GGe,_),b(f,ar,_),M(C8,ar,null),e(ar,W7r),e(ar,hc),e(hc,Q7r),e(hc,IU),e(IU,H7r),e(hc,U7r),e(hc,NU),e(NU,J7r),e(hc,Y7r),e(ar,K7r),e(ar,w8),e(w8,Z7r),e(w8,n6e),e(n6e,e9r),e(w8,o9r),e(ar,r9r),e(ar,Bt),M(A8,Bt,null),e(Bt,t9r),e(Bt,s6e),e(s6e,a9r),e(Bt,n9r),e(Bt,pc),e(pc,s9r),e(pc,l6e),e(l6e,l9r),e(pc,i9r),e(pc,qU),e(qU,d9r),e(pc,c9r),e(Bt,f9r),M(z9,Bt,null),e(ar,m9r),e(ar,Sr),M(y8,Sr,null),e(Sr,g9r),e(Sr,i6e),e(i6e,h9r),e(Sr,p9r),e(Sr,cn),e(cn,u9r),e(cn,d6e),e(d6e,_9r),e(cn,b9r),e(cn,c6e),e(c6e,v9r),e(cn,F9r),e(cn,f6e),e(f6e,T9r),e(cn,M9r),e(Sr,E9r),e(Sr,Le),e(Le,W9),e(W9,m6e),e(m6e,C9r),e(W9,w9r),e(W9,jU),e(jU,A9r),e(W9,y9r),e(Le,L9r),e(Le,Q9),e(Q9,g6e),e(g6e,x9r),e(Q9,$9r),e(Q9,DU),e(DU,k9r),e(Q9,S9r),e(Le,R9r),e(Le,H9),e(H9,h6e),e(h6e,P9r),e(H9,B9r),e(H9,GU),e(GU,I9r),e(H9,N9r),e(Le,q9r),e(Le,U9),e(U9,p6e),e(p6e,j9r),e(U9,D9r),e(U9,OU),e(OU,G9r),e(U9,O9r),e(Le,V9r),e(Le,J9),e(J9,u6e),e(u6e,X9r),e(J9,z9r),e(J9,VU),e(VU,W9r),e(J9,Q9r),e(Le,H9r),e(Le,Y9),e(Y9,_6e),e(_6e,U9r),e(Y9,J9r),e(Y9,XU),e(XU,Y9r),e(Y9,K9r),e(Le,Z9r),e(Le,K9),e(K9,b6e),e(b6e,eMr),e(K9,oMr),e(K9,zU),e(zU,rMr),e(K9,tMr),e(Le,aMr),e(Le,Z9),e(Z9,v6e),e(v6e,nMr),e(Z9,sMr),e(Z9,WU),e(WU,lMr),e(Z9,iMr),e(Le,dMr),e(Le,eM),e(eM,F6e),e(F6e,cMr),e(eM,fMr),e(eM,QU),e(QU,mMr),e(eM,gMr),e(Le,hMr),e(Le,oM),e(oM,T6e),e(T6e,pMr),e(oM,uMr),e(oM,HU),e(HU,_Mr),e(oM,bMr),e(Sr,vMr),M(rM,Sr,null),b(f,OGe,_),b(f,uc,_),e(uc,tM),e(tM,M6e),M(L8,M6e,null),e(uc,FMr),e(uc,E6e),e(E6e,TMr),b(f,VGe,_),b(f,nr,_),M(x8,nr,null),e(nr,MMr),e(nr,_c),e(_c,EMr),e(_c,UU),e(UU,CMr),e(_c,wMr),e(_c,JU),e(JU,AMr),e(_c,yMr),e(nr,LMr),e(nr,$8),e($8,xMr),e($8,C6e),e(C6e,$Mr),e($8,kMr),e(nr,SMr),e(nr,It),M(k8,It,null),e(It,RMr),e(It,w6e),e(w6e,PMr),e(It,BMr),e(It,bc),e(bc,IMr),e(bc,A6e),e(A6e,NMr),e(bc,qMr),e(bc,YU),e(YU,jMr),e(bc,DMr),e(It,GMr),M(aM,It,null),e(nr,OMr),e(nr,Rr),M(S8,Rr,null),e(Rr,VMr),e(Rr,y6e),e(y6e,XMr),e(Rr,zMr),e(Rr,fn),e(fn,WMr),e(fn,L6e),e(L6e,QMr),e(fn,HMr),e(fn,x6e),e(x6e,UMr),e(fn,JMr),e(fn,$6e),e($6e,YMr),e(fn,KMr),e(Rr,ZMr),e(Rr,re),e(re,nM),e(nM,k6e),e(k6e,e4r),e(nM,o4r),e(nM,KU),e(KU,r4r),e(nM,t4r),e(re,a4r),e(re,sM),e(sM,S6e),e(S6e,n4r),e(sM,s4r),e(sM,ZU),e(ZU,l4r),e(sM,i4r),e(re,d4r),e(re,lM),e(lM,R6e),e(R6e,c4r),e(lM,f4r),e(lM,eJ),e(eJ,m4r),e(lM,g4r),e(re,h4r),e(re,iM),e(iM,P6e),e(P6e,p4r),e(iM,u4r),e(iM,oJ),e(oJ,_4r),e(iM,b4r),e(re,v4r),e(re,dM),e(dM,B6e),e(B6e,F4r),e(dM,T4r),e(dM,rJ),e(rJ,M4r),e(dM,E4r),e(re,C4r),e(re,cM),e(cM,I6e),e(I6e,w4r),e(cM,A4r),e(cM,tJ),e(tJ,y4r),e(cM,L4r),e(re,x4r),e(re,fM),e(fM,N6e),e(N6e,$4r),e(fM,k4r),e(fM,aJ),e(aJ,S4r),e(fM,R4r),e(re,P4r),e(re,mM),e(mM,q6e),e(q6e,B4r),e(mM,I4r),e(mM,nJ),e(nJ,N4r),e(mM,q4r),e(re,j4r),e(re,gM),e(gM,j6e),e(j6e,D4r),e(gM,G4r),e(gM,sJ),e(sJ,O4r),e(gM,V4r),e(re,X4r),e(re,hM),e(hM,D6e),e(D6e,z4r),e(hM,W4r),e(hM,lJ),e(lJ,Q4r),e(hM,H4r),e(re,U4r),e(re,pM),e(pM,G6e),e(G6e,J4r),e(pM,Y4r),e(pM,iJ),e(iJ,K4r),e(pM,Z4r),e(re,eEr),e(re,uM),e(uM,O6e),e(O6e,oEr),e(uM,rEr),e(uM,dJ),e(dJ,tEr),e(uM,aEr),e(re,nEr),e(re,_M),e(_M,V6e),e(V6e,sEr),e(_M,lEr),e(_M,cJ),e(cJ,iEr),e(_M,dEr),e(re,cEr),e(re,bM),e(bM,X6e),e(X6e,fEr),e(bM,mEr),e(bM,fJ),e(fJ,gEr),e(bM,hEr),e(re,pEr),e(re,vM),e(vM,z6e),e(z6e,uEr),e(vM,_Er),e(vM,mJ),e(mJ,bEr),e(vM,vEr),e(re,FEr),e(re,FM),e(FM,W6e),e(W6e,TEr),e(FM,MEr),e(FM,gJ),e(gJ,EEr),e(FM,CEr),e(re,wEr),e(re,TM),e(TM,Q6e),e(Q6e,AEr),e(TM,yEr),e(TM,hJ),e(hJ,LEr),e(TM,xEr),e(re,$Er),e(re,MM),e(MM,H6e),e(H6e,kEr),e(MM,SEr),e(MM,pJ),e(pJ,REr),e(MM,PEr),e(re,BEr),e(re,EM),e(EM,U6e),e(U6e,IEr),e(EM,NEr),e(EM,uJ),e(uJ,qEr),e(EM,jEr),e(re,DEr),e(re,CM),e(CM,J6e),e(J6e,GEr),e(CM,OEr),e(CM,_J),e(_J,VEr),e(CM,XEr),e(re,zEr),e(re,wM),e(wM,Y6e),e(Y6e,WEr),e(wM,QEr),e(wM,bJ),e(bJ,HEr),e(wM,UEr),e(re,JEr),e(re,AM),e(AM,K6e),e(K6e,YEr),e(AM,KEr),e(AM,vJ),e(vJ,ZEr),e(AM,eCr),e(re,oCr),e(re,yM),e(yM,Z6e),e(Z6e,rCr),e(yM,tCr),e(yM,FJ),e(FJ,aCr),e(yM,nCr),e(re,sCr),e(re,LM),e(LM,eTe),e(eTe,lCr),e(LM,iCr),e(LM,TJ),e(TJ,dCr),e(LM,cCr),e(re,fCr),e(re,xM),e(xM,oTe),e(oTe,mCr),e(xM,gCr),e(xM,MJ),e(MJ,hCr),e(xM,pCr),e(re,uCr),e(re,$M),e($M,rTe),e(rTe,_Cr),e($M,bCr),e($M,EJ),e(EJ,vCr),e($M,FCr),e(Rr,TCr),M(kM,Rr,null),b(f,XGe,_),b(f,vc,_),e(vc,SM),e(SM,tTe),M(R8,tTe,null),e(vc,MCr),e(vc,aTe),e(aTe,ECr),b(f,zGe,_),b(f,sr,_),M(P8,sr,null),e(sr,CCr),e(sr,Fc),e(Fc,wCr),e(Fc,CJ),e(CJ,ACr),e(Fc,yCr),e(Fc,wJ),e(wJ,LCr),e(Fc,xCr),e(sr,$Cr),e(sr,B8),e(B8,kCr),e(B8,nTe),e(nTe,SCr),e(B8,RCr),e(sr,PCr),e(sr,Nt),M(I8,Nt,null),e(Nt,BCr),e(Nt,sTe),e(sTe,ICr),e(Nt,NCr),e(Nt,Tc),e(Tc,qCr),e(Tc,lTe),e(lTe,jCr),e(Tc,DCr),e(Tc,AJ),e(AJ,GCr),e(Tc,OCr),e(Nt,VCr),M(RM,Nt,null),e(sr,XCr),e(sr,Pr),M(N8,Pr,null),e(Pr,zCr),e(Pr,iTe),e(iTe,WCr),e(Pr,QCr),e(Pr,mn),e(mn,HCr),e(mn,dTe),e(dTe,UCr),e(mn,JCr),e(mn,cTe),e(cTe,YCr),e(mn,KCr),e(mn,fTe),e(fTe,ZCr),e(mn,e5r),e(Pr,o5r),e(Pr,pe),e(pe,PM),e(PM,mTe),e(mTe,r5r),e(PM,t5r),e(PM,yJ),e(yJ,a5r),e(PM,n5r),e(pe,s5r),e(pe,BM),e(BM,gTe),e(gTe,l5r),e(BM,i5r),e(BM,LJ),e(LJ,d5r),e(BM,c5r),e(pe,f5r),e(pe,IM),e(IM,hTe),e(hTe,m5r),e(IM,g5r),e(IM,xJ),e(xJ,h5r),e(IM,p5r),e(pe,u5r),e(pe,NM),e(NM,pTe),e(pTe,_5r),e(NM,b5r),e(NM,$J),e($J,v5r),e(NM,F5r),e(pe,T5r),e(pe,qM),e(qM,uTe),e(uTe,M5r),e(qM,E5r),e(qM,kJ),e(kJ,C5r),e(qM,w5r),e(pe,A5r),e(pe,jM),e(jM,_Te),e(_Te,y5r),e(jM,L5r),e(jM,SJ),e(SJ,x5r),e(jM,$5r),e(pe,k5r),e(pe,DM),e(DM,bTe),e(bTe,S5r),e(DM,R5r),e(DM,RJ),e(RJ,P5r),e(DM,B5r),e(pe,I5r),e(pe,GM),e(GM,vTe),e(vTe,N5r),e(GM,q5r),e(GM,PJ),e(PJ,j5r),e(GM,D5r),e(pe,G5r),e(pe,OM),e(OM,FTe),e(FTe,O5r),e(OM,V5r),e(OM,BJ),e(BJ,X5r),e(OM,z5r),e(pe,W5r),e(pe,VM),e(VM,TTe),e(TTe,Q5r),e(VM,H5r),e(VM,IJ),e(IJ,U5r),e(VM,J5r),e(pe,Y5r),e(pe,XM),e(XM,MTe),e(MTe,K5r),e(XM,Z5r),e(XM,NJ),e(NJ,e0r),e(XM,o0r),e(pe,r0r),e(pe,zM),e(zM,ETe),e(ETe,t0r),e(zM,a0r),e(zM,qJ),e(qJ,n0r),e(zM,s0r),e(pe,l0r),e(pe,WM),e(WM,CTe),e(CTe,i0r),e(WM,d0r),e(WM,jJ),e(jJ,c0r),e(WM,f0r),e(pe,m0r),e(pe,QM),e(QM,wTe),e(wTe,g0r),e(QM,h0r),e(QM,DJ),e(DJ,p0r),e(QM,u0r),e(pe,_0r),e(pe,HM),e(HM,ATe),e(ATe,b0r),e(HM,v0r),e(HM,GJ),e(GJ,F0r),e(HM,T0r),e(pe,M0r),e(pe,UM),e(UM,yTe),e(yTe,E0r),e(UM,C0r),e(UM,OJ),e(OJ,w0r),e(UM,A0r),e(pe,y0r),e(pe,JM),e(JM,LTe),e(LTe,L0r),e(JM,x0r),e(JM,VJ),e(VJ,$0r),e(JM,k0r),e(Pr,S0r),M(YM,Pr,null),b(f,WGe,_),b(f,Mc,_),e(Mc,KM),e(KM,xTe),M(q8,xTe,null),e(Mc,R0r),e(Mc,$Te),e($Te,P0r),b(f,QGe,_),b(f,lr,_),M(j8,lr,null),e(lr,B0r),e(lr,Ec),e(Ec,I0r),e(Ec,XJ),e(XJ,N0r),e(Ec,q0r),e(Ec,zJ),e(zJ,j0r),e(Ec,D0r),e(lr,G0r),e(lr,D8),e(D8,O0r),e(D8,kTe),e(kTe,V0r),e(D8,X0r),e(lr,z0r),e(lr,qt),M(G8,qt,null),e(qt,W0r),e(qt,STe),e(STe,Q0r),e(qt,H0r),e(qt,Cc),e(Cc,U0r),e(Cc,RTe),e(RTe,J0r),e(Cc,Y0r),e(Cc,WJ),e(WJ,K0r),e(Cc,Z0r),e(qt,ewr),M(ZM,qt,null),e(lr,owr),e(lr,Br),M(O8,Br,null),e(Br,rwr),e(Br,PTe),e(PTe,twr),e(Br,awr),e(Br,gn),e(gn,nwr),e(gn,BTe),e(BTe,swr),e(gn,lwr),e(gn,ITe),e(ITe,iwr),e(gn,dwr),e(gn,NTe),e(NTe,cwr),e(gn,fwr),e(Br,mwr),e(Br,V8),e(V8,e4),e(e4,qTe),e(qTe,gwr),e(e4,hwr),e(e4,QJ),e(QJ,pwr),e(e4,uwr),e(V8,_wr),e(V8,o4),e(o4,jTe),e(jTe,bwr),e(o4,vwr),e(o4,HJ),e(HJ,Fwr),e(o4,Twr),e(Br,Mwr),M(r4,Br,null),b(f,HGe,_),b(f,wc,_),e(wc,t4),e(t4,DTe),M(X8,DTe,null),e(wc,Ewr),e(wc,GTe),e(GTe,Cwr),b(f,UGe,_),b(f,ir,_),M(z8,ir,null),e(ir,wwr),e(ir,Ac),e(Ac,Awr),e(Ac,UJ),e(UJ,ywr),e(Ac,Lwr),e(Ac,JJ),e(JJ,xwr),e(Ac,$wr),e(ir,kwr),e(ir,W8),e(W8,Swr),e(W8,OTe),e(OTe,Rwr),e(W8,Pwr),e(ir,Bwr),e(ir,jt),M(Q8,jt,null),e(jt,Iwr),e(jt,VTe),e(VTe,Nwr),e(jt,qwr),e(jt,yc),e(yc,jwr),e(yc,XTe),e(XTe,Dwr),e(yc,Gwr),e(yc,YJ),e(YJ,Owr),e(yc,Vwr),e(jt,Xwr),M(a4,jt,null),e(ir,zwr),e(ir,Ir),M(H8,Ir,null),e(Ir,Wwr),e(Ir,zTe),e(zTe,Qwr),e(Ir,Hwr),e(Ir,hn),e(hn,Uwr),e(hn,WTe),e(WTe,Jwr),e(hn,Ywr),e(hn,QTe),e(QTe,Kwr),e(hn,Zwr),e(hn,HTe),e(HTe,eAr),e(hn,oAr),e(Ir,rAr),e(Ir,UTe),e(UTe,n4),e(n4,JTe),e(JTe,tAr),e(n4,aAr),e(n4,KJ),e(KJ,nAr),e(n4,sAr),e(Ir,lAr),M(s4,Ir,null),b(f,JGe,_),b(f,Lc,_),e(Lc,l4),e(l4,YTe),M(U8,YTe,null),e(Lc,iAr),e(Lc,KTe),e(KTe,dAr),b(f,YGe,_),b(f,dr,_),M(J8,dr,null),e(dr,cAr),e(dr,xc),e(xc,fAr),e(xc,ZJ),e(ZJ,mAr),e(xc,gAr),e(xc,eY),e(eY,hAr),e(xc,pAr),e(dr,uAr),e(dr,Y8),e(Y8,_Ar),e(Y8,ZTe),e(ZTe,bAr),e(Y8,vAr),e(dr,FAr),e(dr,Dt),M(K8,Dt,null),e(Dt,TAr),e(Dt,e7e),e(e7e,MAr),e(Dt,EAr),e(Dt,$c),e($c,CAr),e($c,o7e),e(o7e,wAr),e($c,AAr),e($c,oY),e(oY,yAr),e($c,LAr),e(Dt,xAr),M(i4,Dt,null),e(dr,$Ar),e(dr,Nr),M(Z8,Nr,null),e(Nr,kAr),e(Nr,r7e),e(r7e,SAr),e(Nr,RAr),e(Nr,pn),e(pn,PAr),e(pn,t7e),e(t7e,BAr),e(pn,IAr),e(pn,a7e),e(a7e,NAr),e(pn,qAr),e(pn,n7e),e(n7e,jAr),e(pn,DAr),e(Nr,GAr),e(Nr,de),e(de,d4),e(d4,s7e),e(s7e,OAr),e(d4,VAr),e(d4,rY),e(rY,XAr),e(d4,zAr),e(de,WAr),e(de,c4),e(c4,l7e),e(l7e,QAr),e(c4,HAr),e(c4,tY),e(tY,UAr),e(c4,JAr),e(de,YAr),e(de,f4),e(f4,i7e),e(i7e,KAr),e(f4,ZAr),e(f4,aY),e(aY,eyr),e(f4,oyr),e(de,ryr),e(de,m4),e(m4,d7e),e(d7e,tyr),e(m4,ayr),e(m4,nY),e(nY,nyr),e(m4,syr),e(de,lyr),e(de,g4),e(g4,c7e),e(c7e,iyr),e(g4,dyr),e(g4,sY),e(sY,cyr),e(g4,fyr),e(de,myr),e(de,h4),e(h4,f7e),e(f7e,gyr),e(h4,hyr),e(h4,lY),e(lY,pyr),e(h4,uyr),e(de,_yr),e(de,p4),e(p4,m7e),e(m7e,byr),e(p4,vyr),e(p4,iY),e(iY,Fyr),e(p4,Tyr),e(de,Myr),e(de,u4),e(u4,g7e),e(g7e,Eyr),e(u4,Cyr),e(u4,dY),e(dY,wyr),e(u4,Ayr),e(de,yyr),e(de,_4),e(_4,h7e),e(h7e,Lyr),e(_4,xyr),e(_4,cY),e(cY,$yr),e(_4,kyr),e(de,Syr),e(de,b4),e(b4,p7e),e(p7e,Ryr),e(b4,Pyr),e(b4,fY),e(fY,Byr),e(b4,Iyr),e(de,Nyr),e(de,v4),e(v4,u7e),e(u7e,qyr),e(v4,jyr),e(v4,mY),e(mY,Dyr),e(v4,Gyr),e(de,Oyr),e(de,F4),e(F4,_7e),e(_7e,Vyr),e(F4,Xyr),e(F4,gY),e(gY,zyr),e(F4,Wyr),e(de,Qyr),e(de,T4),e(T4,b7e),e(b7e,Hyr),e(T4,Uyr),e(T4,hY),e(hY,Jyr),e(T4,Yyr),e(de,Kyr),e(de,M4),e(M4,v7e),e(v7e,Zyr),e(M4,eLr),e(M4,pY),e(pY,oLr),e(M4,rLr),e(de,tLr),e(de,E4),e(E4,F7e),e(F7e,aLr),e(E4,nLr),e(E4,uY),e(uY,sLr),e(E4,lLr),e(de,iLr),e(de,C4),e(C4,T7e),e(T7e,dLr),e(C4,cLr),e(C4,_Y),e(_Y,fLr),e(C4,mLr),e(de,gLr),e(de,w4),e(w4,M7e),e(M7e,hLr),e(w4,pLr),e(w4,bY),e(bY,uLr),e(w4,_Lr),e(de,bLr),e(de,A4),e(A4,E7e),e(E7e,vLr),e(A4,FLr),e(A4,vY),e(vY,TLr),e(A4,MLr),e(de,ELr),e(de,y4),e(y4,C7e),e(C7e,CLr),e(y4,wLr),e(y4,FY),e(FY,ALr),e(y4,yLr),e(de,LLr),e(de,L4),e(L4,w7e),e(w7e,xLr),e(L4,$Lr),e(L4,TY),e(TY,kLr),e(L4,SLr),e(Nr,RLr),M(x4,Nr,null),b(f,KGe,_),b(f,kc,_),e(kc,$4),e($4,A7e),M(ex,A7e,null),e(kc,PLr),e(kc,y7e),e(y7e,BLr),b(f,ZGe,_),b(f,cr,_),M(ox,cr,null),e(cr,ILr),e(cr,Sc),e(Sc,NLr),e(Sc,MY),e(MY,qLr),e(Sc,jLr),e(Sc,EY),e(EY,DLr),e(Sc,GLr),e(cr,OLr),e(cr,rx),e(rx,VLr),e(rx,L7e),e(L7e,XLr),e(rx,zLr),e(cr,WLr),e(cr,Gt),M(tx,Gt,null),e(Gt,QLr),e(Gt,x7e),e(x7e,HLr),e(Gt,ULr),e(Gt,Rc),e(Rc,JLr),e(Rc,$7e),e($7e,YLr),e(Rc,KLr),e(Rc,CY),e(CY,ZLr),e(Rc,e8r),e(Gt,o8r),M(k4,Gt,null),e(cr,r8r),e(cr,qr),M(ax,qr,null),e(qr,t8r),e(qr,k7e),e(k7e,a8r),e(qr,n8r),e(qr,un),e(un,s8r),e(un,S7e),e(S7e,l8r),e(un,i8r),e(un,R7e),e(R7e,d8r),e(un,c8r),e(un,P7e),e(P7e,f8r),e(un,m8r),e(qr,g8r),e(qr,ce),e(ce,S4),e(S4,B7e),e(B7e,h8r),e(S4,p8r),e(S4,wY),e(wY,u8r),e(S4,_8r),e(ce,b8r),e(ce,R4),e(R4,I7e),e(I7e,v8r),e(R4,F8r),e(R4,AY),e(AY,T8r),e(R4,M8r),e(ce,E8r),e(ce,P4),e(P4,N7e),e(N7e,C8r),e(P4,w8r),e(P4,yY),e(yY,A8r),e(P4,y8r),e(ce,L8r),e(ce,B4),e(B4,q7e),e(q7e,x8r),e(B4,$8r),e(B4,LY),e(LY,k8r),e(B4,S8r),e(ce,R8r),e(ce,I4),e(I4,j7e),e(j7e,P8r),e(I4,B8r),e(I4,xY),e(xY,I8r),e(I4,N8r),e(ce,q8r),e(ce,N4),e(N4,D7e),e(D7e,j8r),e(N4,D8r),e(N4,$Y),e($Y,G8r),e(N4,O8r),e(ce,V8r),e(ce,q4),e(q4,G7e),e(G7e,X8r),e(q4,z8r),e(q4,kY),e(kY,W8r),e(q4,Q8r),e(ce,H8r),e(ce,j4),e(j4,O7e),e(O7e,U8r),e(j4,J8r),e(j4,SY),e(SY,Y8r),e(j4,K8r),e(ce,Z8r),e(ce,D4),e(D4,V7e),e(V7e,exr),e(D4,oxr),e(D4,RY),e(RY,rxr),e(D4,txr),e(ce,axr),e(ce,G4),e(G4,X7e),e(X7e,nxr),e(G4,sxr),e(G4,PY),e(PY,lxr),e(G4,ixr),e(ce,dxr),e(ce,O4),e(O4,z7e),e(z7e,cxr),e(O4,fxr),e(O4,BY),e(BY,mxr),e(O4,gxr),e(ce,hxr),e(ce,V4),e(V4,W7e),e(W7e,pxr),e(V4,uxr),e(V4,IY),e(IY,_xr),e(V4,bxr),e(ce,vxr),e(ce,X4),e(X4,Q7e),e(Q7e,Fxr),e(X4,Txr),e(X4,NY),e(NY,Mxr),e(X4,Exr),e(ce,Cxr),e(ce,z4),e(z4,H7e),e(H7e,wxr),e(z4,Axr),e(z4,qY),e(qY,yxr),e(z4,Lxr),e(ce,xxr),e(ce,W4),e(W4,U7e),e(U7e,$xr),e(W4,kxr),e(W4,jY),e(jY,Sxr),e(W4,Rxr),e(ce,Pxr),e(ce,Q4),e(Q4,J7e),e(J7e,Bxr),e(Q4,Ixr),e(Q4,DY),e(DY,Nxr),e(Q4,qxr),e(ce,jxr),e(ce,H4),e(H4,Y7e),e(Y7e,Dxr),e(H4,Gxr),e(H4,GY),e(GY,Oxr),e(H4,Vxr),e(ce,Xxr),e(ce,U4),e(U4,K7e),e(K7e,zxr),e(U4,Wxr),e(U4,OY),e(OY,Qxr),e(U4,Hxr),e(ce,Uxr),e(ce,J4),e(J4,Z7e),e(Z7e,Jxr),e(J4,Yxr),e(J4,VY),e(VY,Kxr),e(J4,Zxr),e(ce,e$r),e(ce,Y4),e(Y4,e9e),e(e9e,o$r),e(Y4,r$r),e(Y4,XY),e(XY,t$r),e(Y4,a$r),e(qr,n$r),M(K4,qr,null),b(f,eOe,_),b(f,Pc,_),e(Pc,Z4),e(Z4,o9e),M(nx,o9e,null),e(Pc,s$r),e(Pc,r9e),e(r9e,l$r),b(f,oOe,_),b(f,fr,_),M(sx,fr,null),e(fr,i$r),e(fr,Bc),e(Bc,d$r),e(Bc,zY),e(zY,c$r),e(Bc,f$r),e(Bc,WY),e(WY,m$r),e(Bc,g$r),e(fr,h$r),e(fr,lx),e(lx,p$r),e(lx,t9e),e(t9e,u$r),e(lx,_$r),e(fr,b$r),e(fr,Ot),M(ix,Ot,null),e(Ot,v$r),e(Ot,a9e),e(a9e,F$r),e(Ot,T$r),e(Ot,Ic),e(Ic,M$r),e(Ic,n9e),e(n9e,E$r),e(Ic,C$r),e(Ic,QY),e(QY,w$r),e(Ic,A$r),e(Ot,y$r),M(eE,Ot,null),e(fr,L$r),e(fr,jr),M(dx,jr,null),e(jr,x$r),e(jr,s9e),e(s9e,$$r),e(jr,k$r),e(jr,_n),e(_n,S$r),e(_n,l9e),e(l9e,R$r),e(_n,P$r),e(_n,i9e),e(i9e,B$r),e(_n,I$r),e(_n,d9e),e(d9e,N$r),e(_n,q$r),e(jr,j$r),e(jr,c9e),e(c9e,oE),e(oE,f9e),e(f9e,D$r),e(oE,G$r),e(oE,HY),e(HY,O$r),e(oE,V$r),e(jr,X$r),M(rE,jr,null),b(f,rOe,_),b(f,Nc,_),e(Nc,tE),e(tE,m9e),M(cx,m9e,null),e(Nc,z$r),e(Nc,g9e),e(g9e,W$r),b(f,tOe,_),b(f,mr,_),M(fx,mr,null),e(mr,Q$r),e(mr,qc),e(qc,H$r),e(qc,UY),e(UY,U$r),e(qc,J$r),e(qc,JY),e(JY,Y$r),e(qc,K$r),e(mr,Z$r),e(mr,mx),e(mx,ekr),e(mx,h9e),e(h9e,okr),e(mx,rkr),e(mr,tkr),e(mr,Vt),M(gx,Vt,null),e(Vt,akr),e(Vt,p9e),e(p9e,nkr),e(Vt,skr),e(Vt,jc),e(jc,lkr),e(jc,u9e),e(u9e,ikr),e(jc,dkr),e(jc,YY),e(YY,ckr),e(jc,fkr),e(Vt,mkr),M(aE,Vt,null),e(mr,gkr),e(mr,Dr),M(hx,Dr,null),e(Dr,hkr),e(Dr,_9e),e(_9e,pkr),e(Dr,ukr),e(Dr,bn),e(bn,_kr),e(bn,b9e),e(b9e,bkr),e(bn,vkr),e(bn,v9e),e(v9e,Fkr),e(bn,Tkr),e(bn,F9e),e(F9e,Mkr),e(bn,Ekr),e(Dr,Ckr),e(Dr,T9e),e(T9e,nE),e(nE,M9e),e(M9e,wkr),e(nE,Akr),e(nE,KY),e(KY,ykr),e(nE,Lkr),e(Dr,xkr),M(sE,Dr,null),b(f,aOe,_),b(f,Dc,_),e(Dc,lE),e(lE,E9e),M(px,E9e,null),e(Dc,$kr),e(Dc,C9e),e(C9e,kkr),b(f,nOe,_),b(f,gr,_),M(ux,gr,null),e(gr,Skr),e(gr,Gc),e(Gc,Rkr),e(Gc,ZY),e(ZY,Pkr),e(Gc,Bkr),e(Gc,eK),e(eK,Ikr),e(Gc,Nkr),e(gr,qkr),e(gr,_x),e(_x,jkr),e(_x,w9e),e(w9e,Dkr),e(_x,Gkr),e(gr,Okr),e(gr,Xt),M(bx,Xt,null),e(Xt,Vkr),e(Xt,A9e),e(A9e,Xkr),e(Xt,zkr),e(Xt,Oc),e(Oc,Wkr),e(Oc,y9e),e(y9e,Qkr),e(Oc,Hkr),e(Oc,oK),e(oK,Ukr),e(Oc,Jkr),e(Xt,Ykr),M(iE,Xt,null),e(gr,Kkr),e(gr,Gr),M(vx,Gr,null),e(Gr,Zkr),e(Gr,L9e),e(L9e,eSr),e(Gr,oSr),e(Gr,vn),e(vn,rSr),e(vn,x9e),e(x9e,tSr),e(vn,aSr),e(vn,$9e),e($9e,nSr),e(vn,sSr),e(vn,k9e),e(k9e,lSr),e(vn,iSr),e(Gr,dSr),e(Gr,te),e(te,dE),e(dE,S9e),e(S9e,cSr),e(dE,fSr),e(dE,rK),e(rK,mSr),e(dE,gSr),e(te,hSr),e(te,cE),e(cE,R9e),e(R9e,pSr),e(cE,uSr),e(cE,tK),e(tK,_Sr),e(cE,bSr),e(te,vSr),e(te,fE),e(fE,P9e),e(P9e,FSr),e(fE,TSr),e(fE,aK),e(aK,MSr),e(fE,ESr),e(te,CSr),e(te,mE),e(mE,B9e),e(B9e,wSr),e(mE,ASr),e(mE,nK),e(nK,ySr),e(mE,LSr),e(te,xSr),e(te,gE),e(gE,I9e),e(I9e,$Sr),e(gE,kSr),e(gE,sK),e(sK,SSr),e(gE,RSr),e(te,PSr),e(te,hE),e(hE,N9e),e(N9e,BSr),e(hE,ISr),e(hE,lK),e(lK,NSr),e(hE,qSr),e(te,jSr),e(te,pE),e(pE,q9e),e(q9e,DSr),e(pE,GSr),e(pE,iK),e(iK,OSr),e(pE,VSr),e(te,XSr),e(te,uE),e(uE,j9e),e(j9e,zSr),e(uE,WSr),e(uE,dK),e(dK,QSr),e(uE,HSr),e(te,USr),e(te,_E),e(_E,D9e),e(D9e,JSr),e(_E,YSr),e(_E,cK),e(cK,KSr),e(_E,ZSr),e(te,eRr),e(te,bE),e(bE,G9e),e(G9e,oRr),e(bE,rRr),e(bE,fK),e(fK,tRr),e(bE,aRr),e(te,nRr),e(te,vE),e(vE,O9e),e(O9e,sRr),e(vE,lRr),e(vE,mK),e(mK,iRr),e(vE,dRr),e(te,cRr),e(te,FE),e(FE,V9e),e(V9e,fRr),e(FE,mRr),e(FE,gK),e(gK,gRr),e(FE,hRr),e(te,pRr),e(te,TE),e(TE,X9e),e(X9e,uRr),e(TE,_Rr),e(TE,hK),e(hK,bRr),e(TE,vRr),e(te,FRr),e(te,ME),e(ME,z9e),e(z9e,TRr),e(ME,MRr),e(ME,pK),e(pK,ERr),e(ME,CRr),e(te,wRr),e(te,EE),e(EE,W9e),e(W9e,ARr),e(EE,yRr),e(EE,uK),e(uK,LRr),e(EE,xRr),e(te,$Rr),e(te,CE),e(CE,Q9e),e(Q9e,kRr),e(CE,SRr),e(CE,_K),e(_K,RRr),e(CE,PRr),e(te,BRr),e(te,wE),e(wE,H9e),e(H9e,IRr),e(wE,NRr),e(wE,bK),e(bK,qRr),e(wE,jRr),e(te,DRr),e(te,AE),e(AE,U9e),e(U9e,GRr),e(AE,ORr),e(AE,vK),e(vK,VRr),e(AE,XRr),e(te,zRr),e(te,yE),e(yE,J9e),e(J9e,WRr),e(yE,QRr),e(yE,FK),e(FK,HRr),e(yE,URr),e(te,JRr),e(te,LE),e(LE,Y9e),e(Y9e,YRr),e(LE,KRr),e(LE,TK),e(TK,ZRr),e(LE,ePr),e(te,oPr),e(te,xE),e(xE,K9e),e(K9e,rPr),e(xE,tPr),e(xE,MK),e(MK,aPr),e(xE,nPr),e(te,sPr),e(te,$E),e($E,Z9e),e(Z9e,lPr),e($E,iPr),e($E,EK),e(EK,dPr),e($E,cPr),e(te,fPr),e(te,kE),e(kE,eMe),e(eMe,mPr),e(kE,gPr),e(kE,CK),e(CK,hPr),e(kE,pPr),e(te,uPr),e(te,SE),e(SE,oMe),e(oMe,_Pr),e(SE,bPr),e(SE,wK),e(wK,vPr),e(SE,FPr),e(te,TPr),e(te,RE),e(RE,rMe),e(rMe,MPr),e(RE,EPr),e(RE,AK),e(AK,CPr),e(RE,wPr),e(te,APr),e(te,PE),e(PE,tMe),e(tMe,yPr),e(PE,LPr),e(PE,yK),e(yK,xPr),e(PE,$Pr),e(Gr,kPr),M(BE,Gr,null),b(f,sOe,_),b(f,Vc,_),e(Vc,IE),e(IE,aMe),M(Fx,aMe,null),e(Vc,SPr),e(Vc,nMe),e(nMe,RPr),b(f,lOe,_),b(f,hr,_),M(Tx,hr,null),e(hr,PPr),e(hr,Xc),e(Xc,BPr),e(Xc,LK),e(LK,IPr),e(Xc,NPr),e(Xc,xK),e(xK,qPr),e(Xc,jPr),e(hr,DPr),e(hr,Mx),e(Mx,GPr),e(Mx,sMe),e(sMe,OPr),e(Mx,VPr),e(hr,XPr),e(hr,zt),M(Ex,zt,null),e(zt,zPr),e(zt,lMe),e(lMe,WPr),e(zt,QPr),e(zt,zc),e(zc,HPr),e(zc,iMe),e(iMe,UPr),e(zc,JPr),e(zc,$K),e($K,YPr),e(zc,KPr),e(zt,ZPr),M(NE,zt,null),e(hr,eBr),e(hr,Or),M(Cx,Or,null),e(Or,oBr),e(Or,dMe),e(dMe,rBr),e(Or,tBr),e(Or,Fn),e(Fn,aBr),e(Fn,cMe),e(cMe,nBr),e(Fn,sBr),e(Fn,fMe),e(fMe,lBr),e(Fn,iBr),e(Fn,mMe),e(mMe,dBr),e(Fn,cBr),e(Or,fBr),e(Or,xe),e(xe,qE),e(qE,gMe),e(gMe,mBr),e(qE,gBr),e(qE,kK),e(kK,hBr),e(qE,pBr),e(xe,uBr),e(xe,jE),e(jE,hMe),e(hMe,_Br),e(jE,bBr),e(jE,SK),e(SK,vBr),e(jE,FBr),e(xe,TBr),e(xe,DE),e(DE,pMe),e(pMe,MBr),e(DE,EBr),e(DE,RK),e(RK,CBr),e(DE,wBr),e(xe,ABr),e(xe,GE),e(GE,uMe),e(uMe,yBr),e(GE,LBr),e(GE,PK),e(PK,xBr),e(GE,$Br),e(xe,kBr),e(xe,OE),e(OE,_Me),e(_Me,SBr),e(OE,RBr),e(OE,BK),e(BK,PBr),e(OE,BBr),e(xe,IBr),e(xe,VE),e(VE,bMe),e(bMe,NBr),e(VE,qBr),e(VE,IK),e(IK,jBr),e(VE,DBr),e(xe,GBr),e(xe,XE),e(XE,vMe),e(vMe,OBr),e(XE,VBr),e(XE,NK),e(NK,XBr),e(XE,zBr),e(xe,WBr),e(xe,zE),e(zE,FMe),e(FMe,QBr),e(zE,HBr),e(zE,qK),e(qK,UBr),e(zE,JBr),e(xe,YBr),e(xe,WE),e(WE,TMe),e(TMe,KBr),e(WE,ZBr),e(WE,jK),e(jK,eIr),e(WE,oIr),e(xe,rIr),e(xe,QE),e(QE,MMe),e(MMe,tIr),e(QE,aIr),e(QE,DK),e(DK,nIr),e(QE,sIr),e(Or,lIr),M(HE,Or,null),b(f,iOe,_),b(f,Wc,_),e(Wc,UE),e(UE,EMe),M(wx,EMe,null),e(Wc,iIr),e(Wc,CMe),e(CMe,dIr),b(f,dOe,_),b(f,pr,_),M(Ax,pr,null),e(pr,cIr),e(pr,Qc),e(Qc,fIr),e(Qc,GK),e(GK,mIr),e(Qc,gIr),e(Qc,OK),e(OK,hIr),e(Qc,pIr),e(pr,uIr),e(pr,yx),e(yx,_Ir),e(yx,wMe),e(wMe,bIr),e(yx,vIr),e(pr,FIr),e(pr,Wt),M(Lx,Wt,null),e(Wt,TIr),e(Wt,AMe),e(AMe,MIr),e(Wt,EIr),e(Wt,Hc),e(Hc,CIr),e(Hc,yMe),e(yMe,wIr),e(Hc,AIr),e(Hc,VK),e(VK,yIr),e(Hc,LIr),e(Wt,xIr),M(JE,Wt,null),e(pr,$Ir),e(pr,Vr),M(xx,Vr,null),e(Vr,kIr),e(Vr,LMe),e(LMe,SIr),e(Vr,RIr),e(Vr,Tn),e(Tn,PIr),e(Tn,xMe),e(xMe,BIr),e(Tn,IIr),e(Tn,$Me),e($Me,NIr),e(Tn,qIr),e(Tn,kMe),e(kMe,jIr),e(Tn,DIr),e(Vr,GIr),e(Vr,Ee),e(Ee,YE),e(YE,SMe),e(SMe,OIr),e(YE,VIr),e(YE,XK),e(XK,XIr),e(YE,zIr),e(Ee,WIr),e(Ee,KE),e(KE,RMe),e(RMe,QIr),e(KE,HIr),e(KE,zK),e(zK,UIr),e(KE,JIr),e(Ee,YIr),e(Ee,ZE),e(ZE,PMe),e(PMe,KIr),e(ZE,ZIr),e(ZE,WK),e(WK,eNr),e(ZE,oNr),e(Ee,rNr),e(Ee,eC),e(eC,BMe),e(BMe,tNr),e(eC,aNr),e(eC,QK),e(QK,nNr),e(eC,sNr),e(Ee,lNr),e(Ee,oC),e(oC,IMe),e(IMe,iNr),e(oC,dNr),e(oC,HK),e(HK,cNr),e(oC,fNr),e(Ee,mNr),e(Ee,rC),e(rC,NMe),e(NMe,gNr),e(rC,hNr),e(rC,UK),e(UK,pNr),e(rC,uNr),e(Ee,_Nr),e(Ee,tC),e(tC,qMe),e(qMe,bNr),e(tC,vNr),e(tC,JK),e(JK,FNr),e(tC,TNr),e(Ee,MNr),e(Ee,aC),e(aC,jMe),e(jMe,ENr),e(aC,CNr),e(aC,YK),e(YK,wNr),e(aC,ANr),e(Ee,yNr),e(Ee,nC),e(nC,DMe),e(DMe,LNr),e(nC,xNr),e(nC,KK),e(KK,$Nr),e(nC,kNr),e(Ee,SNr),e(Ee,sC),e(sC,GMe),e(GMe,RNr),e(sC,PNr),e(sC,ZK),e(ZK,BNr),e(sC,INr),e(Ee,NNr),e(Ee,lC),e(lC,OMe),e(OMe,qNr),e(lC,jNr),e(lC,eZ),e(eZ,DNr),e(lC,GNr),e(Ee,ONr),e(Ee,iC),e(iC,VMe),e(VMe,VNr),e(iC,XNr),e(iC,oZ),e(oZ,zNr),e(iC,WNr),e(Vr,QNr),M(dC,Vr,null),b(f,cOe,_),b(f,Uc,_),e(Uc,cC),e(cC,XMe),M($x,XMe,null),e(Uc,HNr),e(Uc,zMe),e(zMe,UNr),b(f,fOe,_),b(f,ur,_),M(kx,ur,null),e(ur,JNr),e(ur,Jc),e(Jc,YNr),e(Jc,rZ),e(rZ,KNr),e(Jc,ZNr),e(Jc,tZ),e(tZ,eqr),e(Jc,oqr),e(ur,rqr),e(ur,Sx),e(Sx,tqr),e(Sx,WMe),e(WMe,aqr),e(Sx,nqr),e(ur,sqr),e(ur,Qt),M(Rx,Qt,null),e(Qt,lqr),e(Qt,QMe),e(QMe,iqr),e(Qt,dqr),e(Qt,Yc),e(Yc,cqr),e(Yc,HMe),e(HMe,fqr),e(Yc,mqr),e(Yc,aZ),e(aZ,gqr),e(Yc,hqr),e(Qt,pqr),M(fC,Qt,null),e(ur,uqr),e(ur,Xr),M(Px,Xr,null),e(Xr,_qr),e(Xr,UMe),e(UMe,bqr),e(Xr,vqr),e(Xr,Mn),e(Mn,Fqr),e(Mn,JMe),e(JMe,Tqr),e(Mn,Mqr),e(Mn,YMe),e(YMe,Eqr),e(Mn,Cqr),e(Mn,KMe),e(KMe,wqr),e(Mn,Aqr),e(Xr,yqr),e(Xr,$e),e($e,mC),e(mC,ZMe),e(ZMe,Lqr),e(mC,xqr),e(mC,nZ),e(nZ,$qr),e(mC,kqr),e($e,Sqr),e($e,gC),e(gC,e4e),e(e4e,Rqr),e(gC,Pqr),e(gC,sZ),e(sZ,Bqr),e(gC,Iqr),e($e,Nqr),e($e,hC),e(hC,o4e),e(o4e,qqr),e(hC,jqr),e(hC,lZ),e(lZ,Dqr),e(hC,Gqr),e($e,Oqr),e($e,pC),e(pC,r4e),e(r4e,Vqr),e(pC,Xqr),e(pC,iZ),e(iZ,zqr),e(pC,Wqr),e($e,Qqr),e($e,uC),e(uC,t4e),e(t4e,Hqr),e(uC,Uqr),e(uC,dZ),e(dZ,Jqr),e(uC,Yqr),e($e,Kqr),e($e,_C),e(_C,a4e),e(a4e,Zqr),e(_C,ejr),e(_C,cZ),e(cZ,ojr),e(_C,rjr),e($e,tjr),e($e,bC),e(bC,n4e),e(n4e,ajr),e(bC,njr),e(bC,fZ),e(fZ,sjr),e(bC,ljr),e($e,ijr),e($e,vC),e(vC,s4e),e(s4e,djr),e(vC,cjr),e(vC,mZ),e(mZ,fjr),e(vC,mjr),e($e,gjr),e($e,FC),e(FC,l4e),e(l4e,hjr),e(FC,pjr),e(FC,gZ),e(gZ,ujr),e(FC,_jr),e($e,bjr),e($e,TC),e(TC,i4e),e(i4e,vjr),e(TC,Fjr),e(TC,hZ),e(hZ,Tjr),e(TC,Mjr),e(Xr,Ejr),M(MC,Xr,null),b(f,mOe,_),b(f,Kc,_),e(Kc,EC),e(EC,d4e),M(Bx,d4e,null),e(Kc,Cjr),e(Kc,c4e),e(c4e,wjr),b(f,gOe,_),b(f,_r,_),M(Ix,_r,null),e(_r,Ajr),e(_r,Zc),e(Zc,yjr),e(Zc,pZ),e(pZ,Ljr),e(Zc,xjr),e(Zc,uZ),e(uZ,$jr),e(Zc,kjr),e(_r,Sjr),e(_r,Nx),e(Nx,Rjr),e(Nx,f4e),e(f4e,Pjr),e(Nx,Bjr),e(_r,Ijr),e(_r,Ht),M(qx,Ht,null),e(Ht,Njr),e(Ht,m4e),e(m4e,qjr),e(Ht,jjr),e(Ht,ef),e(ef,Djr),e(ef,g4e),e(g4e,Gjr),e(ef,Ojr),e(ef,_Z),e(_Z,Vjr),e(ef,Xjr),e(Ht,zjr),M(CC,Ht,null),e(_r,Wjr),e(_r,zr),M(jx,zr,null),e(zr,Qjr),e(zr,h4e),e(h4e,Hjr),e(zr,Ujr),e(zr,En),e(En,Jjr),e(En,p4e),e(p4e,Yjr),e(En,Kjr),e(En,u4e),e(u4e,Zjr),e(En,eDr),e(En,_4e),e(_4e,oDr),e(En,rDr),e(zr,tDr),e(zr,Pe),e(Pe,wC),e(wC,b4e),e(b4e,aDr),e(wC,nDr),e(wC,bZ),e(bZ,sDr),e(wC,lDr),e(Pe,iDr),e(Pe,AC),e(AC,v4e),e(v4e,dDr),e(AC,cDr),e(AC,vZ),e(vZ,fDr),e(AC,mDr),e(Pe,gDr),e(Pe,yC),e(yC,F4e),e(F4e,hDr),e(yC,pDr),e(yC,FZ),e(FZ,uDr),e(yC,_Dr),e(Pe,bDr),e(Pe,LC),e(LC,T4e),e(T4e,vDr),e(LC,FDr),e(LC,TZ),e(TZ,TDr),e(LC,MDr),e(Pe,EDr),e(Pe,xC),e(xC,M4e),e(M4e,CDr),e(xC,wDr),e(xC,MZ),e(MZ,ADr),e(xC,yDr),e(Pe,LDr),e(Pe,$C),e($C,E4e),e(E4e,xDr),e($C,$Dr),e($C,EZ),e(EZ,kDr),e($C,SDr),e(Pe,RDr),e(Pe,kC),e(kC,C4e),e(C4e,PDr),e(kC,BDr),e(kC,CZ),e(CZ,IDr),e(kC,NDr),e(Pe,qDr),e(Pe,SC),e(SC,w4e),e(w4e,jDr),e(SC,DDr),e(SC,wZ),e(wZ,GDr),e(SC,ODr),e(Pe,VDr),e(Pe,RC),e(RC,A4e),e(A4e,XDr),e(RC,zDr),e(RC,AZ),e(AZ,WDr),e(RC,QDr),e(zr,HDr),M(PC,zr,null),b(f,hOe,_),b(f,of,_),e(of,BC),e(BC,y4e),M(Dx,y4e,null),e(of,UDr),e(of,L4e),e(L4e,JDr),b(f,pOe,_),b(f,br,_),M(Gx,br,null),e(br,YDr),e(br,rf),e(rf,KDr),e(rf,yZ),e(yZ,ZDr),e(rf,eGr),e(rf,LZ),e(LZ,oGr),e(rf,rGr),e(br,tGr),e(br,Ox),e(Ox,aGr),e(Ox,x4e),e(x4e,nGr),e(Ox,sGr),e(br,lGr),e(br,Ut),M(Vx,Ut,null),e(Ut,iGr),e(Ut,$4e),e($4e,dGr),e(Ut,cGr),e(Ut,tf),e(tf,fGr),e(tf,k4e),e(k4e,mGr),e(tf,gGr),e(tf,xZ),e(xZ,hGr),e(tf,pGr),e(Ut,uGr),M(IC,Ut,null),e(br,_Gr),e(br,Wr),M(Xx,Wr,null),e(Wr,bGr),e(Wr,S4e),e(S4e,vGr),e(Wr,FGr),e(Wr,Cn),e(Cn,TGr),e(Cn,R4e),e(R4e,MGr),e(Cn,EGr),e(Cn,P4e),e(P4e,CGr),e(Cn,wGr),e(Cn,B4e),e(B4e,AGr),e(Cn,yGr),e(Wr,LGr),e(Wr,ke),e(ke,NC),e(NC,I4e),e(I4e,xGr),e(NC,$Gr),e(NC,$Z),e($Z,kGr),e(NC,SGr),e(ke,RGr),e(ke,qC),e(qC,N4e),e(N4e,PGr),e(qC,BGr),e(qC,kZ),e(kZ,IGr),e(qC,NGr),e(ke,qGr),e(ke,jC),e(jC,q4e),e(q4e,jGr),e(jC,DGr),e(jC,SZ),e(SZ,GGr),e(jC,OGr),e(ke,VGr),e(ke,DC),e(DC,j4e),e(j4e,XGr),e(DC,zGr),e(DC,RZ),e(RZ,WGr),e(DC,QGr),e(ke,HGr),e(ke,GC),e(GC,D4e),e(D4e,UGr),e(GC,JGr),e(GC,PZ),e(PZ,YGr),e(GC,KGr),e(ke,ZGr),e(ke,OC),e(OC,G4e),e(G4e,eOr),e(OC,oOr),e(OC,BZ),e(BZ,rOr),e(OC,tOr),e(ke,aOr),e(ke,VC),e(VC,O4e),e(O4e,nOr),e(VC,sOr),e(VC,IZ),e(IZ,lOr),e(VC,iOr),e(ke,dOr),e(ke,XC),e(XC,V4e),e(V4e,cOr),e(XC,fOr),e(XC,NZ),e(NZ,mOr),e(XC,gOr),e(ke,hOr),e(ke,zC),e(zC,X4e),e(X4e,pOr),e(zC,uOr),e(zC,qZ),e(qZ,_Or),e(zC,bOr),e(ke,vOr),e(ke,WC),e(WC,z4e),e(z4e,FOr),e(WC,TOr),e(WC,jZ),e(jZ,MOr),e(WC,EOr),e(Wr,COr),M(QC,Wr,null),b(f,uOe,_),b(f,af,_),e(af,HC),e(HC,W4e),M(zx,W4e,null),e(af,wOr),e(af,Q4e),e(Q4e,AOr),b(f,_Oe,_),b(f,vr,_),M(Wx,vr,null),e(vr,yOr),e(vr,nf),e(nf,LOr),e(nf,DZ),e(DZ,xOr),e(nf,$Or),e(nf,GZ),e(GZ,kOr),e(nf,SOr),e(vr,ROr),e(vr,Qx),e(Qx,POr),e(Qx,H4e),e(H4e,BOr),e(Qx,IOr),e(vr,NOr),e(vr,Jt),M(Hx,Jt,null),e(Jt,qOr),e(Jt,U4e),e(U4e,jOr),e(Jt,DOr),e(Jt,sf),e(sf,GOr),e(sf,J4e),e(J4e,OOr),e(sf,VOr),e(sf,OZ),e(OZ,XOr),e(sf,zOr),e(Jt,WOr),M(UC,Jt,null),e(vr,QOr),e(vr,Qr),M(Ux,Qr,null),e(Qr,HOr),e(Qr,Y4e),e(Y4e,UOr),e(Qr,JOr),e(Qr,wn),e(wn,YOr),e(wn,K4e),e(K4e,KOr),e(wn,ZOr),e(wn,Z4e),e(Z4e,eVr),e(wn,oVr),e(wn,eEe),e(eEe,rVr),e(wn,tVr),e(Qr,aVr),e(Qr,Se),e(Se,JC),e(JC,oEe),e(oEe,nVr),e(JC,sVr),e(JC,VZ),e(VZ,lVr),e(JC,iVr),e(Se,dVr),e(Se,YC),e(YC,rEe),e(rEe,cVr),e(YC,fVr),e(YC,XZ),e(XZ,mVr),e(YC,gVr),e(Se,hVr),e(Se,KC),e(KC,tEe),e(tEe,pVr),e(KC,uVr),e(KC,zZ),e(zZ,_Vr),e(KC,bVr),e(Se,vVr),e(Se,ZC),e(ZC,aEe),e(aEe,FVr),e(ZC,TVr),e(ZC,WZ),e(WZ,MVr),e(ZC,EVr),e(Se,CVr),e(Se,e5),e(e5,nEe),e(nEe,wVr),e(e5,AVr),e(e5,QZ),e(QZ,yVr),e(e5,LVr),e(Se,xVr),e(Se,o5),e(o5,sEe),e(sEe,$Vr),e(o5,kVr),e(o5,HZ),e(HZ,SVr),e(o5,RVr),e(Se,PVr),e(Se,r5),e(r5,lEe),e(lEe,BVr),e(r5,IVr),e(r5,UZ),e(UZ,NVr),e(r5,qVr),e(Se,jVr),e(Se,t5),e(t5,iEe),e(iEe,DVr),e(t5,GVr),e(t5,JZ),e(JZ,OVr),e(t5,VVr),e(Se,XVr),e(Se,a5),e(a5,dEe),e(dEe,zVr),e(a5,WVr),e(a5,YZ),e(YZ,QVr),e(a5,HVr),e(Se,UVr),e(Se,n5),e(n5,cEe),e(cEe,JVr),e(n5,YVr),e(n5,KZ),e(KZ,KVr),e(n5,ZVr),e(Qr,eXr),M(s5,Qr,null),b(f,bOe,_),b(f,lf,_),e(lf,l5),e(l5,fEe),M(Jx,fEe,null),e(lf,oXr),e(lf,mEe),e(mEe,rXr),b(f,vOe,_),b(f,Fr,_),M(Yx,Fr,null),e(Fr,tXr),e(Fr,df),e(df,aXr),e(df,ZZ),e(ZZ,nXr),e(df,sXr),e(df,eee),e(eee,lXr),e(df,iXr),e(Fr,dXr),e(Fr,Kx),e(Kx,cXr),e(Kx,gEe),e(gEe,fXr),e(Kx,mXr),e(Fr,gXr),e(Fr,Yt),M(Zx,Yt,null),e(Yt,hXr),e(Yt,hEe),e(hEe,pXr),e(Yt,uXr),e(Yt,cf),e(cf,_Xr),e(cf,pEe),e(pEe,bXr),e(cf,vXr),e(cf,oee),e(oee,FXr),e(cf,TXr),e(Yt,MXr),M(i5,Yt,null),e(Fr,EXr),e(Fr,Hr),M(e$,Hr,null),e(Hr,CXr),e(Hr,uEe),e(uEe,wXr),e(Hr,AXr),e(Hr,An),e(An,yXr),e(An,_Ee),e(_Ee,LXr),e(An,xXr),e(An,bEe),e(bEe,$Xr),e(An,kXr),e(An,vEe),e(vEe,SXr),e(An,RXr),e(Hr,PXr),e(Hr,Oe),e(Oe,d5),e(d5,FEe),e(FEe,BXr),e(d5,IXr),e(d5,ree),e(ree,NXr),e(d5,qXr),e(Oe,jXr),e(Oe,c5),e(c5,TEe),e(TEe,DXr),e(c5,GXr),e(c5,tee),e(tee,OXr),e(c5,VXr),e(Oe,XXr),e(Oe,f5),e(f5,MEe),e(MEe,zXr),e(f5,WXr),e(f5,aee),e(aee,QXr),e(f5,HXr),e(Oe,UXr),e(Oe,m5),e(m5,EEe),e(EEe,JXr),e(m5,YXr),e(m5,nee),e(nee,KXr),e(m5,ZXr),e(Oe,ezr),e(Oe,g5),e(g5,CEe),e(CEe,ozr),e(g5,rzr),e(g5,see),e(see,tzr),e(g5,azr),e(Oe,nzr),e(Oe,h5),e(h5,wEe),e(wEe,szr),e(h5,lzr),e(h5,lee),e(lee,izr),e(h5,dzr),e(Oe,czr),e(Oe,p5),e(p5,AEe),e(AEe,fzr),e(p5,mzr),e(p5,iee),e(iee,gzr),e(p5,hzr),e(Oe,pzr),e(Oe,u5),e(u5,yEe),e(yEe,uzr),e(u5,_zr),e(u5,dee),e(dee,bzr),e(u5,vzr),e(Hr,Fzr),M(_5,Hr,null),b(f,FOe,_),b(f,ff,_),e(ff,b5),e(b5,LEe),M(o$,LEe,null),e(ff,Tzr),e(ff,xEe),e(xEe,Mzr),b(f,TOe,_),b(f,Tr,_),M(r$,Tr,null),e(Tr,Ezr),e(Tr,mf),e(mf,Czr),e(mf,cee),e(cee,wzr),e(mf,Azr),e(mf,fee),e(fee,yzr),e(mf,Lzr),e(Tr,xzr),e(Tr,t$),e(t$,$zr),e(t$,$Ee),e($Ee,kzr),e(t$,Szr),e(Tr,Rzr),e(Tr,Kt),M(a$,Kt,null),e(Kt,Pzr),e(Kt,kEe),e(kEe,Bzr),e(Kt,Izr),e(Kt,gf),e(gf,Nzr),e(gf,SEe),e(SEe,qzr),e(gf,jzr),e(gf,mee),e(mee,Dzr),e(gf,Gzr),e(Kt,Ozr),M(v5,Kt,null),e(Tr,Vzr),e(Tr,Ur),M(n$,Ur,null),e(Ur,Xzr),e(Ur,REe),e(REe,zzr),e(Ur,Wzr),e(Ur,yn),e(yn,Qzr),e(yn,PEe),e(PEe,Hzr),e(yn,Uzr),e(yn,BEe),e(BEe,Jzr),e(yn,Yzr),e(yn,IEe),e(IEe,Kzr),e(yn,Zzr),e(Ur,eWr),e(Ur,Ve),e(Ve,F5),e(F5,NEe),e(NEe,oWr),e(F5,rWr),e(F5,gee),e(gee,tWr),e(F5,aWr),e(Ve,nWr),e(Ve,T5),e(T5,qEe),e(qEe,sWr),e(T5,lWr),e(T5,hee),e(hee,iWr),e(T5,dWr),e(Ve,cWr),e(Ve,M5),e(M5,jEe),e(jEe,fWr),e(M5,mWr),e(M5,pee),e(pee,gWr),e(M5,hWr),e(Ve,pWr),e(Ve,E5),e(E5,DEe),e(DEe,uWr),e(E5,_Wr),e(E5,uee),e(uee,bWr),e(E5,vWr),e(Ve,FWr),e(Ve,C5),e(C5,GEe),e(GEe,TWr),e(C5,MWr),e(C5,_ee),e(_ee,EWr),e(C5,CWr),e(Ve,wWr),e(Ve,w5),e(w5,OEe),e(OEe,AWr),e(w5,yWr),e(w5,bee),e(bee,LWr),e(w5,xWr),e(Ve,$Wr),e(Ve,A5),e(A5,VEe),e(VEe,kWr),e(A5,SWr),e(A5,vee),e(vee,RWr),e(A5,PWr),e(Ve,BWr),e(Ve,y5),e(y5,XEe),e(XEe,IWr),e(y5,NWr),e(y5,Fee),e(Fee,qWr),e(y5,jWr),e(Ur,DWr),M(L5,Ur,null),b(f,MOe,_),b(f,hf,_),e(hf,x5),e(x5,zEe),M(s$,zEe,null),e(hf,GWr),e(hf,WEe),e(WEe,OWr),b(f,EOe,_),b(f,Mr,_),M(l$,Mr,null),e(Mr,VWr),e(Mr,pf),e(pf,XWr),e(pf,Tee),e(Tee,zWr),e(pf,WWr),e(pf,Mee),e(Mee,QWr),e(pf,HWr),e(Mr,UWr),e(Mr,i$),e(i$,JWr),e(i$,QEe),e(QEe,YWr),e(i$,KWr),e(Mr,ZWr),e(Mr,Zt),M(d$,Zt,null),e(Zt,eQr),e(Zt,HEe),e(HEe,oQr),e(Zt,rQr),e(Zt,uf),e(uf,tQr),e(uf,UEe),e(UEe,aQr),e(uf,nQr),e(uf,Eee),e(Eee,sQr),e(uf,lQr),e(Zt,iQr),M($5,Zt,null),e(Mr,dQr),e(Mr,Jr),M(c$,Jr,null),e(Jr,cQr),e(Jr,JEe),e(JEe,fQr),e(Jr,mQr),e(Jr,Ln),e(Ln,gQr),e(Ln,YEe),e(YEe,hQr),e(Ln,pQr),e(Ln,KEe),e(KEe,uQr),e(Ln,_Qr),e(Ln,ZEe),e(ZEe,bQr),e(Ln,vQr),e(Jr,FQr),e(Jr,eCe),e(eCe,k5),e(k5,oCe),e(oCe,TQr),e(k5,MQr),e(k5,Cee),e(Cee,EQr),e(k5,CQr),e(Jr,wQr),M(S5,Jr,null),b(f,COe,_),b(f,_f,_),e(_f,R5),e(R5,rCe),M(f$,rCe,null),e(_f,AQr),e(_f,tCe),e(tCe,yQr),b(f,wOe,_),b(f,Er,_),M(m$,Er,null),e(Er,LQr),e(Er,bf),e(bf,xQr),e(bf,wee),e(wee,$Qr),e(bf,kQr),e(bf,Aee),e(Aee,SQr),e(bf,RQr),e(Er,PQr),e(Er,g$),e(g$,BQr),e(g$,aCe),e(aCe,IQr),e(g$,NQr),e(Er,qQr),e(Er,ea),M(h$,ea,null),e(ea,jQr),e(ea,nCe),e(nCe,DQr),e(ea,GQr),e(ea,vf),e(vf,OQr),e(vf,sCe),e(sCe,VQr),e(vf,XQr),e(vf,yee),e(yee,zQr),e(vf,WQr),e(ea,QQr),M(P5,ea,null),e(Er,HQr),e(Er,Yr),M(p$,Yr,null),e(Yr,UQr),e(Yr,lCe),e(lCe,JQr),e(Yr,YQr),e(Yr,xn),e(xn,KQr),e(xn,iCe),e(iCe,ZQr),e(xn,eHr),e(xn,dCe),e(dCe,oHr),e(xn,rHr),e(xn,cCe),e(cCe,tHr),e(xn,aHr),e(Yr,nHr),e(Yr,u$),e(u$,B5),e(B5,fCe),e(fCe,sHr),e(B5,lHr),e(B5,Lee),e(Lee,iHr),e(B5,dHr),e(u$,cHr),e(u$,I5),e(I5,mCe),e(mCe,fHr),e(I5,mHr),e(I5,xee),e(xee,gHr),e(I5,hHr),e(Yr,pHr),M(N5,Yr,null),b(f,AOe,_),b(f,Ff,_),e(Ff,q5),e(q5,gCe),M(_$,gCe,null),e(Ff,uHr),e(Ff,hCe),e(hCe,_Hr),b(f,yOe,_),b(f,Cr,_),M(b$,Cr,null),e(Cr,bHr),e(Cr,Tf),e(Tf,vHr),e(Tf,$ee),e($ee,FHr),e(Tf,THr),e(Tf,kee),e(kee,MHr),e(Tf,EHr),e(Cr,CHr),e(Cr,v$),e(v$,wHr),e(v$,pCe),e(pCe,AHr),e(v$,yHr),e(Cr,LHr),e(Cr,oa),M(F$,oa,null),e(oa,xHr),e(oa,uCe),e(uCe,$Hr),e(oa,kHr),e(oa,Mf),e(Mf,SHr),e(Mf,_Ce),e(_Ce,RHr),e(Mf,PHr),e(Mf,See),e(See,BHr),e(Mf,IHr),e(oa,NHr),M(j5,oa,null),e(Cr,qHr),e(Cr,Kr),M(T$,Kr,null),e(Kr,jHr),e(Kr,bCe),e(bCe,DHr),e(Kr,GHr),e(Kr,$n),e($n,OHr),e($n,vCe),e(vCe,VHr),e($n,XHr),e($n,FCe),e(FCe,zHr),e($n,WHr),e($n,TCe),e(TCe,QHr),e($n,HHr),e(Kr,UHr),e(Kr,MCe),e(MCe,D5),e(D5,ECe),e(ECe,JHr),e(D5,YHr),e(D5,Ree),e(Ree,KHr),e(D5,ZHr),e(Kr,eUr),M(G5,Kr,null),LOe=!0},p(f,[_]){const M$={};_&2&&(M$.$$scope={dirty:_,ctx:f}),kf.$set(M$);const CCe={};_&2&&(CCe.$$scope={dirty:_,ctx:f}),Ng.$set(CCe);const wCe={};_&2&&(wCe.$$scope={dirty:_,ctx:f}),vh.$set(wCe);const ACe={};_&2&&(ACe.$$scope={dirty:_,ctx:f}),ep.$set(ACe);const E$={};_&2&&(E$.$$scope={dirty:_,ctx:f}),op.$set(E$);const yCe={};_&2&&(yCe.$$scope={dirty:_,ctx:f}),Tp.$set(yCe);const kn={};_&2&&(kn.$$scope={dirty:_,ctx:f}),Mp.$set(kn);const LCe={};_&2&&(LCe.$$scope={dirty:_,ctx:f}),wp.$set(LCe);const xCe={};_&2&&(xCe.$$scope={dirty:_,ctx:f}),E_.$set(xCe);const $Ce={};_&2&&($Ce.$$scope={dirty:_,ctx:f}),w_.$set($Ce);const C$={};_&2&&(C$.$$scope={dirty:_,ctx:f}),u1.$set(C$);const kCe={};_&2&&(kCe.$$scope={dirty:_,ctx:f}),b1.$set(kCe);const w$={};_&2&&(w$.$$scope={dirty:_,ctx:f}),ab.$set(w$);const SCe={};_&2&&(SCe.$$scope={dirty:_,ctx:f}),sb.$set(SCe);const A$={};_&2&&(A$.$$scope={dirty:_,ctx:f}),Xb.$set(A$);const RCe={};_&2&&(RCe.$$scope={dirty:_,ctx:f}),Wb.$set(RCe);const PCe={};_&2&&(PCe.$$scope={dirty:_,ctx:f}),c2.$set(PCe);const BCe={};_&2&&(BCe.$$scope={dirty:_,ctx:f}),m2.$set(BCe);const Ef={};_&2&&(Ef.$$scope={dirty:_,ctx:f}),iv.$set(Ef);const ICe={};_&2&&(ICe.$$scope={dirty:_,ctx:f}),cv.$set(ICe);const NCe={};_&2&&(NCe.$$scope={dirty:_,ctx:f}),Gv.$set(NCe);const qCe={};_&2&&(qCe.$$scope={dirty:_,ctx:f}),Vv.$set(qCe);const y$={};_&2&&(y$.$$scope={dirty:_,ctx:f}),Jv.$set(y$);const jCe={};_&2&&(jCe.$$scope={dirty:_,ctx:f}),Kv.$set(jCe);const DCe={};_&2&&(DCe.$$scope={dirty:_,ctx:f}),B3.$set(DCe);const GCe={};_&2&&(GCe.$$scope={dirty:_,ctx:f}),N3.$set(GCe);const rt={};_&2&&(rt.$$scope={dirty:_,ctx:f}),wF.$set(rt);const L$={};_&2&&(L$.$$scope={dirty:_,ctx:f}),yF.$set(L$);const OCe={};_&2&&(OCe.$$scope={dirty:_,ctx:f}),$F.$set(OCe);const x$={};_&2&&(x$.$$scope={dirty:_,ctx:f}),SF.$set(x$);const VCe={};_&2&&(VCe.$$scope={dirty:_,ctx:f}),WF.$set(VCe);const tt={};_&2&&(tt.$$scope={dirty:_,ctx:f}),HF.$set(tt);const XCe={};_&2&&(XCe.$$scope={dirty:_,ctx:f}),YF.$set(XCe);const Cf={};_&2&&(Cf.$$scope={dirty:_,ctx:f}),ZF.$set(Cf);const zCe={};_&2&&(zCe.$$scope={dirty:_,ctx:f}),r6.$set(zCe);const WCe={};_&2&&(WCe.$$scope={dirty:_,ctx:f}),a6.$set(WCe);const y={};_&2&&(y.$$scope={dirty:_,ctx:f}),p6.$set(y);const O5={};_&2&&(O5.$$scope={dirty:_,ctx:f}),_6.$set(O5);const QCe={};_&2&&(QCe.$$scope={dirty:_,ctx:f}),C6.$set(QCe);const HCe={};_&2&&(HCe.$$scope={dirty:_,ctx:f}),A6.$set(HCe);const V5={};_&2&&(V5.$$scope={dirty:_,ctx:f}),q6.$set(V5);const UCe={};_&2&&(UCe.$$scope={dirty:_,ctx:f}),D6.$set(UCe);const JCe={};_&2&&(JCe.$$scope={dirty:_,ctx:f}),X6.$set(JCe);const X5={};_&2&&(X5.$$scope={dirty:_,ctx:f}),W6.$set(X5);const YCe={};_&2&&(YCe.$$scope={dirty:_,ctx:f}),Z6.$set(YCe);const KCe={};_&2&&(KCe.$$scope={dirty:_,ctx:f}),oT.$set(KCe);const z5={};_&2&&(z5.$$scope={dirty:_,ctx:f}),sT.$set(z5);const ZCe={};_&2&&(ZCe.$$scope={dirty:_,ctx:f}),iT.$set(ZCe);const e5e={};_&2&&(e5e.$$scope={dirty:_,ctx:f}),mT.$set(e5e);const W5={};_&2&&(W5.$$scope={dirty:_,ctx:f}),hT.$set(W5);const o5e={};_&2&&(o5e.$$scope={dirty:_,ctx:f}),_T.$set(o5e);const r5e={};_&2&&(r5e.$$scope={dirty:_,ctx:f}),vT.$set(r5e);const Q5={};_&2&&(Q5.$$scope={dirty:_,ctx:f}),wT.$set(Q5);const t5e={};_&2&&(t5e.$$scope={dirty:_,ctx:f}),yT.$set(t5e);const a5e={};_&2&&(a5e.$$scope={dirty:_,ctx:f}),$T.$set(a5e);const H5={};_&2&&(H5.$$scope={dirty:_,ctx:f}),ST.$set(H5);const n5e={};_&2&&(n5e.$$scope={dirty:_,ctx:f}),w7.$set(n5e);const s5e={};_&2&&(s5e.$$scope={dirty:_,ctx:f}),y7.$set(s5e);const U5={};_&2&&(U5.$$scope={dirty:_,ctx:f}),Y7.$set(U5);const l5e={};_&2&&(l5e.$$scope={dirty:_,ctx:f}),Z7.$set(l5e);const i5e={};_&2&&(i5e.$$scope={dirty:_,ctx:f}),g9.$set(i5e);const J5={};_&2&&(J5.$$scope={dirty:_,ctx:f}),p9.$set(J5);const d5e={};_&2&&(d5e.$$scope={dirty:_,ctx:f}),F9.$set(d5e);const c5e={};_&2&&(c5e.$$scope={dirty:_,ctx:f}),M9.$set(c5e);const Y5={};_&2&&(Y5.$$scope={dirty:_,ctx:f}),V9.$set(Y5);const f5e={};_&2&&(f5e.$$scope={dirty:_,ctx:f}),z9.$set(f5e);const m5e={};_&2&&(m5e.$$scope={dirty:_,ctx:f}),rM.$set(m5e);const K5={};_&2&&(K5.$$scope={dirty:_,ctx:f}),aM.$set(K5);const g5e={};_&2&&(g5e.$$scope={dirty:_,ctx:f}),kM.$set(g5e);const h5e={};_&2&&(h5e.$$scope={dirty:_,ctx:f}),RM.$set(h5e);const Z5={};_&2&&(Z5.$$scope={dirty:_,ctx:f}),YM.$set(Z5);const p5e={};_&2&&(p5e.$$scope={dirty:_,ctx:f}),ZM.$set(p5e);const u5e={};_&2&&(u5e.$$scope={dirty:_,ctx:f}),r4.$set(u5e);const e0={};_&2&&(e0.$$scope={dirty:_,ctx:f}),a4.$set(e0);const _5e={};_&2&&(_5e.$$scope={dirty:_,ctx:f}),s4.$set(_5e);const b5e={};_&2&&(b5e.$$scope={dirty:_,ctx:f}),i4.$set(b5e);const o0={};_&2&&(o0.$$scope={dirty:_,ctx:f}),x4.$set(o0);const v5e={};_&2&&(v5e.$$scope={dirty:_,ctx:f}),k4.$set(v5e);const F5e={};_&2&&(F5e.$$scope={dirty:_,ctx:f}),K4.$set(F5e);const r0={};_&2&&(r0.$$scope={dirty:_,ctx:f}),eE.$set(r0);const T5e={};_&2&&(T5e.$$scope={dirty:_,ctx:f}),rE.$set(T5e);const M5e={};_&2&&(M5e.$$scope={dirty:_,ctx:f}),aE.$set(M5e);const t0={};_&2&&(t0.$$scope={dirty:_,ctx:f}),sE.$set(t0);const E5e={};_&2&&(E5e.$$scope={dirty:_,ctx:f}),iE.$set(E5e);const C5e={};_&2&&(C5e.$$scope={dirty:_,ctx:f}),BE.$set(C5e);const a0={};_&2&&(a0.$$scope={dirty:_,ctx:f}),NE.$set(a0);const w5e={};_&2&&(w5e.$$scope={dirty:_,ctx:f}),HE.$set(w5e);const A5e={};_&2&&(A5e.$$scope={dirty:_,ctx:f}),JE.$set(A5e);const n0={};_&2&&(n0.$$scope={dirty:_,ctx:f}),dC.$set(n0);const y5e={};_&2&&(y5e.$$scope={dirty:_,ctx:f}),fC.$set(y5e);const L5e={};_&2&&(L5e.$$scope={dirty:_,ctx:f}),MC.$set(L5e);const s0={};_&2&&(s0.$$scope={dirty:_,ctx:f}),CC.$set(s0);const x5e={};_&2&&(x5e.$$scope={dirty:_,ctx:f}),PC.$set(x5e);const $5e={};_&2&&($5e.$$scope={dirty:_,ctx:f}),IC.$set($5e);const l0={};_&2&&(l0.$$scope={dirty:_,ctx:f}),QC.$set(l0);const k5e={};_&2&&(k5e.$$scope={dirty:_,ctx:f}),UC.$set(k5e);const S5e={};_&2&&(S5e.$$scope={dirty:_,ctx:f}),s5.$set(S5e);const i0={};_&2&&(i0.$$scope={dirty:_,ctx:f}),i5.$set(i0);const R5e={};_&2&&(R5e.$$scope={dirty:_,ctx:f}),_5.$set(R5e);const P5e={};_&2&&(P5e.$$scope={dirty:_,ctx:f}),v5.$set(P5e);const d0={};_&2&&(d0.$$scope={dirty:_,ctx:f}),L5.$set(d0);const B5e={};_&2&&(B5e.$$scope={dirty:_,ctx:f}),$5.$set(B5e);const I5e={};_&2&&(I5e.$$scope={dirty:_,ctx:f}),S5.$set(I5e);const c0={};_&2&&(c0.$$scope={dirty:_,ctx:f}),P5.$set(c0);const N5e={};_&2&&(N5e.$$scope={dirty:_,ctx:f}),N5.$set(N5e);const q5e={};_&2&&(q5e.$$scope={dirty:_,ctx:f}),j5.$set(q5e);const f0={};_&2&&(f0.$$scope={dirty:_,ctx:f}),G5.$set(f0)},i(f){LOe||(E(d.$$.fragment,f),E(La.$$.fragment,f),E(mA.$$.fragment,f),E(gA.$$.fragment,f),E(kf.$$.fragment,f),E(hA.$$.fragment,f),E(pA.$$.fragment,f),E(bA.$$.fragment,f),E(Ng.$$.fragment,f),E(vA.$$.fragment,f),E(FA.$$.fragment,f),E(TA.$$.fragment,f),E(CA.$$.fragment,f),E(vh.$$.fragment,f),E(wA.$$.fragment,f),E(AA.$$.fragment,f),E(yA.$$.fragment,f),E($A.$$.fragment,f),E(ep.$$.fragment,f),E(op.$$.fragment,f),E(kA.$$.fragment,f),E(SA.$$.fragment,f),E(RA.$$.fragment,f),E(IA.$$.fragment,f),E(Tp.$$.fragment,f),E(Mp.$$.fragment,f),E(NA.$$.fragment,f),E(qA.$$.fragment,f),E(jA.$$.fragment,f),E(GA.$$.fragment,f),E(wp.$$.fragment,f),E(OA.$$.fragment,f),E(E_.$$.fragment,f),E(VA.$$.fragment,f),E(XA.$$.fragment,f),E(WA.$$.fragment,f),E(w_.$$.fragment,f),E(QA.$$.fragment,f),E(u1.$$.fragment,f),E(HA.$$.fragment,f),E(UA.$$.fragment,f),E(YA.$$.fragment,f),E(b1.$$.fragment,f),E(KA.$$.fragment,f),E(ab.$$.fragment,f),E(ZA.$$.fragment,f),E(ey.$$.fragment,f),E(ry.$$.fragment,f),E(sb.$$.fragment,f),E(ty.$$.fragment,f),E(Xb.$$.fragment,f),E(ay.$$.fragment,f),E(ny.$$.fragment,f),E(ly.$$.fragment,f),E(Wb.$$.fragment,f),E(iy.$$.fragment,f),E(c2.$$.fragment,f),E(dy.$$.fragment,f),E(cy.$$.fragment,f),E(my.$$.fragment,f),E(m2.$$.fragment,f),E(gy.$$.fragment,f),E(iv.$$.fragment,f),E(hy.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(cv.$$.fragment,f),E(by.$$.fragment,f),E(Gv.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(My.$$.fragment,f),E(Vv.$$.fragment,f),E(Ey.$$.fragment,f),E(Jv.$$.fragment,f),E(Cy.$$.fragment,f),E(wy.$$.fragment,f),E(yy.$$.fragment,f),E(Kv.$$.fragment,f),E(Ly.$$.fragment,f),E(B3.$$.fragment,f),E(xy.$$.fragment,f),E($y.$$.fragment,f),E(Sy.$$.fragment,f),E(N3.$$.fragment,f),E(Ry.$$.fragment,f),E(wF.$$.fragment,f),E(Py.$$.fragment,f),E(By.$$.fragment,f),E(Ny.$$.fragment,f),E(yF.$$.fragment,f),E(qy.$$.fragment,f),E($F.$$.fragment,f),E(jy.$$.fragment,f),E(Dy.$$.fragment,f),E(Oy.$$.fragment,f),E(SF.$$.fragment,f),E(Vy.$$.fragment,f),E(WF.$$.fragment,f),E(Xy.$$.fragment,f),E(zy.$$.fragment,f),E(Qy.$$.fragment,f),E(HF.$$.fragment,f),E(Hy.$$.fragment,f),E(YF.$$.fragment,f),E(Uy.$$.fragment,f),E(Jy.$$.fragment,f),E(Ky.$$.fragment,f),E(ZF.$$.fragment,f),E(Zy.$$.fragment,f),E(r6.$$.fragment,f),E(eL.$$.fragment,f),E(oL.$$.fragment,f),E(tL.$$.fragment,f),E(a6.$$.fragment,f),E(aL.$$.fragment,f),E(p6.$$.fragment,f),E(nL.$$.fragment,f),E(sL.$$.fragment,f),E(iL.$$.fragment,f),E(_6.$$.fragment,f),E(dL.$$.fragment,f),E(C6.$$.fragment,f),E(cL.$$.fragment,f),E(fL.$$.fragment,f),E(gL.$$.fragment,f),E(A6.$$.fragment,f),E(hL.$$.fragment,f),E(q6.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(bL.$$.fragment,f),E(D6.$$.fragment,f),E(vL.$$.fragment,f),E(X6.$$.fragment,f),E(TL.$$.fragment,f),E(ML.$$.fragment,f),E(CL.$$.fragment,f),E(W6.$$.fragment,f),E(wL.$$.fragment,f),E(Z6.$$.fragment,f),E(AL.$$.fragment,f),E(yL.$$.fragment,f),E(xL.$$.fragment,f),E(oT.$$.fragment,f),E($L.$$.fragment,f),E(sT.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(PL.$$.fragment,f),E(iT.$$.fragment,f),E(BL.$$.fragment,f),E(mT.$$.fragment,f),E(NL.$$.fragment,f),E(qL.$$.fragment,f),E(DL.$$.fragment,f),E(hT.$$.fragment,f),E(GL.$$.fragment,f),E(_T.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(zL.$$.fragment,f),E(vT.$$.fragment,f),E(WL.$$.fragment,f),E(wT.$$.fragment,f),E(QL.$$.fragment,f),E(HL.$$.fragment,f),E(JL.$$.fragment,f),E(yT.$$.fragment,f),E(YL.$$.fragment,f),E($T.$$.fragment,f),E(KL.$$.fragment,f),E(ZL.$$.fragment,f),E(o8.$$.fragment,f),E(ST.$$.fragment,f),E(r8.$$.fragment,f),E(w7.$$.fragment,f),E(t8.$$.fragment,f),E(a8.$$.fragment,f),E(s8.$$.fragment,f),E(y7.$$.fragment,f),E(l8.$$.fragment,f),E(Y7.$$.fragment,f),E(i8.$$.fragment,f),E(d8.$$.fragment,f),E(f8.$$.fragment,f),E(Z7.$$.fragment,f),E(m8.$$.fragment,f),E(g9.$$.fragment,f),E(g8.$$.fragment,f),E(h8.$$.fragment,f),E(u8.$$.fragment,f),E(p9.$$.fragment,f),E(_8.$$.fragment,f),E(F9.$$.fragment,f),E(b8.$$.fragment,f),E(v8.$$.fragment,f),E(T8.$$.fragment,f),E(M9.$$.fragment,f),E(M8.$$.fragment,f),E(V9.$$.fragment,f),E(E8.$$.fragment,f),E(C8.$$.fragment,f),E(A8.$$.fragment,f),E(z9.$$.fragment,f),E(y8.$$.fragment,f),E(rM.$$.fragment,f),E(L8.$$.fragment,f),E(x8.$$.fragment,f),E(k8.$$.fragment,f),E(aM.$$.fragment,f),E(S8.$$.fragment,f),E(kM.$$.fragment,f),E(R8.$$.fragment,f),E(P8.$$.fragment,f),E(I8.$$.fragment,f),E(RM.$$.fragment,f),E(N8.$$.fragment,f),E(YM.$$.fragment,f),E(q8.$$.fragment,f),E(j8.$$.fragment,f),E(G8.$$.fragment,f),E(ZM.$$.fragment,f),E(O8.$$.fragment,f),E(r4.$$.fragment,f),E(X8.$$.fragment,f),E(z8.$$.fragment,f),E(Q8.$$.fragment,f),E(a4.$$.fragment,f),E(H8.$$.fragment,f),E(s4.$$.fragment,f),E(U8.$$.fragment,f),E(J8.$$.fragment,f),E(K8.$$.fragment,f),E(i4.$$.fragment,f),E(Z8.$$.fragment,f),E(x4.$$.fragment,f),E(ex.$$.fragment,f),E(ox.$$.fragment,f),E(tx.$$.fragment,f),E(k4.$$.fragment,f),E(ax.$$.fragment,f),E(K4.$$.fragment,f),E(nx.$$.fragment,f),E(sx.$$.fragment,f),E(ix.$$.fragment,f),E(eE.$$.fragment,f),E(dx.$$.fragment,f),E(rE.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E(aE.$$.fragment,f),E(hx.$$.fragment,f),E(sE.$$.fragment,f),E(px.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(iE.$$.fragment,f),E(vx.$$.fragment,f),E(BE.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(NE.$$.fragment,f),E(Cx.$$.fragment,f),E(HE.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(Lx.$$.fragment,f),E(JE.$$.fragment,f),E(xx.$$.fragment,f),E(dC.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(fC.$$.fragment,f),E(Px.$$.fragment,f),E(MC.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(qx.$$.fragment,f),E(CC.$$.fragment,f),E(jx.$$.fragment,f),E(PC.$$.fragment,f),E(Dx.$$.fragment,f),E(Gx.$$.fragment,f),E(Vx.$$.fragment,f),E(IC.$$.fragment,f),E(Xx.$$.fragment,f),E(QC.$$.fragment,f),E(zx.$$.fragment,f),E(Wx.$$.fragment,f),E(Hx.$$.fragment,f),E(UC.$$.fragment,f),E(Ux.$$.fragment,f),E(s5.$$.fragment,f),E(Jx.$$.fragment,f),E(Yx.$$.fragment,f),E(Zx.$$.fragment,f),E(i5.$$.fragment,f),E(e$.$$.fragment,f),E(_5.$$.fragment,f),E(o$.$$.fragment,f),E(r$.$$.fragment,f),E(a$.$$.fragment,f),E(v5.$$.fragment,f),E(n$.$$.fragment,f),E(L5.$$.fragment,f),E(s$.$$.fragment,f),E(l$.$$.fragment,f),E(d$.$$.fragment,f),E($5.$$.fragment,f),E(c$.$$.fragment,f),E(S5.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(h$.$$.fragment,f),E(P5.$$.fragment,f),E(p$.$$.fragment,f),E(N5.$$.fragment,f),E(_$.$$.fragment,f),E(b$.$$.fragment,f),E(F$.$$.fragment,f),E(j5.$$.fragment,f),E(T$.$$.fragment,f),E(G5.$$.fragment,f),LOe=!0)},o(f){C(d.$$.fragment,f),C(La.$$.fragment,f),C(mA.$$.fragment,f),C(gA.$$.fragment,f),C(kf.$$.fragment,f),C(hA.$$.fragment,f),C(pA.$$.fragment,f),C(bA.$$.fragment,f),C(Ng.$$.fragment,f),C(vA.$$.fragment,f),C(FA.$$.fragment,f),C(TA.$$.fragment,f),C(CA.$$.fragment,f),C(vh.$$.fragment,f),C(wA.$$.fragment,f),C(AA.$$.fragment,f),C(yA.$$.fragment,f),C($A.$$.fragment,f),C(ep.$$.fragment,f),C(op.$$.fragment,f),C(kA.$$.fragment,f),C(SA.$$.fragment,f),C(RA.$$.fragment,f),C(IA.$$.fragment,f),C(Tp.$$.fragment,f),C(Mp.$$.fragment,f),C(NA.$$.fragment,f),C(qA.$$.fragment,f),C(jA.$$.fragment,f),C(GA.$$.fragment,f),C(wp.$$.fragment,f),C(OA.$$.fragment,f),C(E_.$$.fragment,f),C(VA.$$.fragment,f),C(XA.$$.fragment,f),C(WA.$$.fragment,f),C(w_.$$.fragment,f),C(QA.$$.fragment,f),C(u1.$$.fragment,f),C(HA.$$.fragment,f),C(UA.$$.fragment,f),C(YA.$$.fragment,f),C(b1.$$.fragment,f),C(KA.$$.fragment,f),C(ab.$$.fragment,f),C(ZA.$$.fragment,f),C(ey.$$.fragment,f),C(ry.$$.fragment,f),C(sb.$$.fragment,f),C(ty.$$.fragment,f),C(Xb.$$.fragment,f),C(ay.$$.fragment,f),C(ny.$$.fragment,f),C(ly.$$.fragment,f),C(Wb.$$.fragment,f),C(iy.$$.fragment,f),C(c2.$$.fragment,f),C(dy.$$.fragment,f),C(cy.$$.fragment,f),C(my.$$.fragment,f),C(m2.$$.fragment,f),C(gy.$$.fragment,f),C(iv.$$.fragment,f),C(hy.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(cv.$$.fragment,f),C(by.$$.fragment,f),C(Gv.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(My.$$.fragment,f),C(Vv.$$.fragment,f),C(Ey.$$.fragment,f),C(Jv.$$.fragment,f),C(Cy.$$.fragment,f),C(wy.$$.fragment,f),C(yy.$$.fragment,f),C(Kv.$$.fragment,f),C(Ly.$$.fragment,f),C(B3.$$.fragment,f),C(xy.$$.fragment,f),C($y.$$.fragment,f),C(Sy.$$.fragment,f),C(N3.$$.fragment,f),C(Ry.$$.fragment,f),C(wF.$$.fragment,f),C(Py.$$.fragment,f),C(By.$$.fragment,f),C(Ny.$$.fragment,f),C(yF.$$.fragment,f),C(qy.$$.fragment,f),C($F.$$.fragment,f),C(jy.$$.fragment,f),C(Dy.$$.fragment,f),C(Oy.$$.fragment,f),C(SF.$$.fragment,f),C(Vy.$$.fragment,f),C(WF.$$.fragment,f),C(Xy.$$.fragment,f),C(zy.$$.fragment,f),C(Qy.$$.fragment,f),C(HF.$$.fragment,f),C(Hy.$$.fragment,f),C(YF.$$.fragment,f),C(Uy.$$.fragment,f),C(Jy.$$.fragment,f),C(Ky.$$.fragment,f),C(ZF.$$.fragment,f),C(Zy.$$.fragment,f),C(r6.$$.fragment,f),C(eL.$$.fragment,f),C(oL.$$.fragment,f),C(tL.$$.fragment,f),C(a6.$$.fragment,f),C(aL.$$.fragment,f),C(p6.$$.fragment,f),C(nL.$$.fragment,f),C(sL.$$.fragment,f),C(iL.$$.fragment,f),C(_6.$$.fragment,f),C(dL.$$.fragment,f),C(C6.$$.fragment,f),C(cL.$$.fragment,f),C(fL.$$.fragment,f),C(gL.$$.fragment,f),C(A6.$$.fragment,f),C(hL.$$.fragment,f),C(q6.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(bL.$$.fragment,f),C(D6.$$.fragment,f),C(vL.$$.fragment,f),C(X6.$$.fragment,f),C(TL.$$.fragment,f),C(ML.$$.fragment,f),C(CL.$$.fragment,f),C(W6.$$.fragment,f),C(wL.$$.fragment,f),C(Z6.$$.fragment,f),C(AL.$$.fragment,f),C(yL.$$.fragment,f),C(xL.$$.fragment,f),C(oT.$$.fragment,f),C($L.$$.fragment,f),C(sT.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(PL.$$.fragment,f),C(iT.$$.fragment,f),C(BL.$$.fragment,f),C(mT.$$.fragment,f),C(NL.$$.fragment,f),C(qL.$$.fragment,f),C(DL.$$.fragment,f),C(hT.$$.fragment,f),C(GL.$$.fragment,f),C(_T.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(zL.$$.fragment,f),C(vT.$$.fragment,f),C(WL.$$.fragment,f),C(wT.$$.fragment,f),C(QL.$$.fragment,f),C(HL.$$.fragment,f),C(JL.$$.fragment,f),C(yT.$$.fragment,f),C(YL.$$.fragment,f),C($T.$$.fragment,f),C(KL.$$.fragment,f),C(ZL.$$.fragment,f),C(o8.$$.fragment,f),C(ST.$$.fragment,f),C(r8.$$.fragment,f),C(w7.$$.fragment,f),C(t8.$$.fragment,f),C(a8.$$.fragment,f),C(s8.$$.fragment,f),C(y7.$$.fragment,f),C(l8.$$.fragment,f),C(Y7.$$.fragment,f),C(i8.$$.fragment,f),C(d8.$$.fragment,f),C(f8.$$.fragment,f),C(Z7.$$.fragment,f),C(m8.$$.fragment,f),C(g9.$$.fragment,f),C(g8.$$.fragment,f),C(h8.$$.fragment,f),C(u8.$$.fragment,f),C(p9.$$.fragment,f),C(_8.$$.fragment,f),C(F9.$$.fragment,f),C(b8.$$.fragment,f),C(v8.$$.fragment,f),C(T8.$$.fragment,f),C(M9.$$.fragment,f),C(M8.$$.fragment,f),C(V9.$$.fragment,f),C(E8.$$.fragment,f),C(C8.$$.fragment,f),C(A8.$$.fragment,f),C(z9.$$.fragment,f),C(y8.$$.fragment,f),C(rM.$$.fragment,f),C(L8.$$.fragment,f),C(x8.$$.fragment,f),C(k8.$$.fragment,f),C(aM.$$.fragment,f),C(S8.$$.fragment,f),C(kM.$$.fragment,f),C(R8.$$.fragment,f),C(P8.$$.fragment,f),C(I8.$$.fragment,f),C(RM.$$.fragment,f),C(N8.$$.fragment,f),C(YM.$$.fragment,f),C(q8.$$.fragment,f),C(j8.$$.fragment,f),C(G8.$$.fragment,f),C(ZM.$$.fragment,f),C(O8.$$.fragment,f),C(r4.$$.fragment,f),C(X8.$$.fragment,f),C(z8.$$.fragment,f),C(Q8.$$.fragment,f),C(a4.$$.fragment,f),C(H8.$$.fragment,f),C(s4.$$.fragment,f),C(U8.$$.fragment,f),C(J8.$$.fragment,f),C(K8.$$.fragment,f),C(i4.$$.fragment,f),C(Z8.$$.fragment,f),C(x4.$$.fragment,f),C(ex.$$.fragment,f),C(ox.$$.fragment,f),C(tx.$$.fragment,f),C(k4.$$.fragment,f),C(ax.$$.fragment,f),C(K4.$$.fragment,f),C(nx.$$.fragment,f),C(sx.$$.fragment,f),C(ix.$$.fragment,f),C(eE.$$.fragment,f),C(dx.$$.fragment,f),C(rE.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C(aE.$$.fragment,f),C(hx.$$.fragment,f),C(sE.$$.fragment,f),C(px.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(iE.$$.fragment,f),C(vx.$$.fragment,f),C(BE.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(NE.$$.fragment,f),C(Cx.$$.fragment,f),C(HE.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(Lx.$$.fragment,f),C(JE.$$.fragment,f),C(xx.$$.fragment,f),C(dC.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(fC.$$.fragment,f),C(Px.$$.fragment,f),C(MC.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(qx.$$.fragment,f),C(CC.$$.fragment,f),C(jx.$$.fragment,f),C(PC.$$.fragment,f),C(Dx.$$.fragment,f),C(Gx.$$.fragment,f),C(Vx.$$.fragment,f),C(IC.$$.fragment,f),C(Xx.$$.fragment,f),C(QC.$$.fragment,f),C(zx.$$.fragment,f),C(Wx.$$.fragment,f),C(Hx.$$.fragment,f),C(UC.$$.fragment,f),C(Ux.$$.fragment,f),C(s5.$$.fragment,f),C(Jx.$$.fragment,f),C(Yx.$$.fragment,f),C(Zx.$$.fragment,f),C(i5.$$.fragment,f),C(e$.$$.fragment,f),C(_5.$$.fragment,f),C(o$.$$.fragment,f),C(r$.$$.fragment,f),C(a$.$$.fragment,f),C(v5.$$.fragment,f),C(n$.$$.fragment,f),C(L5.$$.fragment,f),C(s$.$$.fragment,f),C(l$.$$.fragment,f),C(d$.$$.fragment,f),C($5.$$.fragment,f),C(c$.$$.fragment,f),C(S5.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(h$.$$.fragment,f),C(P5.$$.fragment,f),C(p$.$$.fragment,f),C(N5.$$.fragment,f),C(_$.$$.fragment,f),C(b$.$$.fragment,f),C(F$.$$.fragment,f),C(j5.$$.fragment,f),C(T$.$$.fragment,f),C(G5.$$.fragment,f),LOe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(Af),f&&t(at),f&&t(Ge),f&&t(We),f&&t(Lf),w(La,f),f&&t(Qe),f&&t(Ae),f&&t(Co),f&&t(xa),f&&t(EDe),f&&t(Ai),w(mA),f&&t(CDe),f&&t(In),f&&t(wDe),w(gA,f),f&&t(ADe),f&&t(Ok),f&&t(yDe),w(kf,f),f&&t(LDe),f&&t(yi),w(hA),f&&t(xDe),f&&t(wo),w(pA),w(bA),w(Ng),w(vA),f&&t($De),f&&t(xi),w(FA),f&&t(kDe),f&&t(Ao),w(TA),w(CA),w(vh),w(wA),f&&t(SDe),f&&t($i),w(AA),f&&t(RDe),f&&t(yo),w(yA),w($A),w(ep),w(op),w(kA),f&&t(PDe),f&&t(ki),w(SA),f&&t(BDe),f&&t(Lo),w(RA),w(IA),w(Tp),w(Mp),w(NA),f&&t(IDe),f&&t(Ri),w(qA),f&&t(NDe),f&&t(xo),w(jA),w(GA),w(wp),w(OA),w(E_),f&&t(qDe),f&&t(Ii),w(VA),f&&t(jDe),f&&t($o),w(XA),w(WA),w(w_),w(QA),w(u1),f&&t(DDe),f&&t(ji),w(HA),f&&t(GDe),f&&t(ko),w(UA),w(YA),w(b1),w(KA),w(ab),f&&t(ODe),f&&t(Oi),w(ZA),f&&t(VDe),f&&t(So),w(ey),w(ry),w(sb),w(ty),w(Xb),f&&t(XDe),f&&t(zi),w(ay),f&&t(zDe),f&&t(Ro),w(ny),w(ly),w(Wb),w(iy),w(c2),f&&t(WDe),f&&t(Hi),w(dy),f&&t(QDe),f&&t(Po),w(cy),w(my),w(m2),w(gy),w(iv),f&&t(HDe),f&&t(Yi),w(hy),f&&t(UDe),f&&t(Bo),w(py),w(_y),w(cv),w(by),w(Gv),f&&t(JDe),f&&t(ed),w(vy),f&&t(YDe),f&&t(Io),w(Fy),w(My),w(Vv),w(Ey),w(Jv),f&&t(KDe),f&&t(td),w(Cy),f&&t(ZDe),f&&t(No),w(wy),w(yy),w(Kv),w(Ly),w(B3),f&&t(eGe),f&&t(sd),w(xy),f&&t(oGe),f&&t(qo),w($y),w(Sy),w(N3),w(Ry),w(wF),f&&t(rGe),f&&t(dd),w(Py),f&&t(tGe),f&&t(jo),w(By),w(Ny),w(yF),w(qy),w($F),f&&t(aGe),f&&t(md),w(jy),f&&t(nGe),f&&t(Do),w(Dy),w(Oy),w(SF),w(Vy),w(WF),f&&t(sGe),f&&t(pd),w(Xy),f&&t(lGe),f&&t(Go),w(zy),w(Qy),w(HF),w(Hy),w(YF),f&&t(iGe),f&&t(bd),w(Uy),f&&t(dGe),f&&t(Oo),w(Jy),w(Ky),w(ZF),w(Zy),w(r6),f&&t(cGe),f&&t(Td),w(eL),f&&t(fGe),f&&t(Vo),w(oL),w(tL),w(a6),w(aL),w(p6),f&&t(mGe),f&&t(Cd),w(nL),f&&t(gGe),f&&t(Xo),w(sL),w(iL),w(_6),w(dL),w(C6),f&&t(hGe),f&&t(yd),w(cL),f&&t(pGe),f&&t(zo),w(fL),w(gL),w(A6),w(hL),w(q6),f&&t(uGe),f&&t($d),w(pL),f&&t(_Ge),f&&t(Wo),w(uL),w(bL),w(D6),w(vL),w(X6),f&&t(bGe),f&&t(Rd),w(TL),f&&t(vGe),f&&t(Qo),w(ML),w(CL),w(W6),w(wL),w(Z6),f&&t(FGe),f&&t(Id),w(AL),f&&t(TGe),f&&t(Ho),w(yL),w(xL),w(oT),w($L),w(sT),f&&t(MGe),f&&t(Dd),w(kL),f&&t(EGe),f&&t(Uo),w(SL),w(PL),w(iT),w(BL),w(mT),f&&t(CGe),f&&t(Vd),w(NL),f&&t(wGe),f&&t(Jo),w(qL),w(DL),w(hT),w(GL),w(_T),f&&t(AGe),f&&t(Wd),w(OL),f&&t(yGe),f&&t(Yo),w(VL),w(zL),w(vT),w(WL),w(wT),f&&t(LGe),f&&t(Ud),w(QL),f&&t(xGe),f&&t(Ko),w(HL),w(JL),w(yT),w(YL),w($T),f&&t($Ge),f&&t(Kd),w(KL),f&&t(kGe),f&&t(Zo),w(ZL),w(o8),w(ST),w(r8),w(w7),f&&t(SGe),f&&t(oc),w(t8),f&&t(RGe),f&&t(er),w(a8),w(s8),w(y7),w(l8),w(Y7),f&&t(PGe),f&&t(ac),w(i8),f&&t(BGe),f&&t(or),w(d8),w(f8),w(Z7),w(m8),w(g9),f&&t(IGe),f&&t(lc),w(g8),f&&t(NGe),f&&t(rr),w(h8),w(u8),w(p9),w(_8),w(F9),f&&t(qGe),f&&t(cc),w(b8),f&&t(jGe),f&&t(tr),w(v8),w(T8),w(M9),w(M8),w(V9),f&&t(DGe),f&&t(gc),w(E8),f&&t(GGe),f&&t(ar),w(C8),w(A8),w(z9),w(y8),w(rM),f&&t(OGe),f&&t(uc),w(L8),f&&t(VGe),f&&t(nr),w(x8),w(k8),w(aM),w(S8),w(kM),f&&t(XGe),f&&t(vc),w(R8),f&&t(zGe),f&&t(sr),w(P8),w(I8),w(RM),w(N8),w(YM),f&&t(WGe),f&&t(Mc),w(q8),f&&t(QGe),f&&t(lr),w(j8),w(G8),w(ZM),w(O8),w(r4),f&&t(HGe),f&&t(wc),w(X8),f&&t(UGe),f&&t(ir),w(z8),w(Q8),w(a4),w(H8),w(s4),f&&t(JGe),f&&t(Lc),w(U8),f&&t(YGe),f&&t(dr),w(J8),w(K8),w(i4),w(Z8),w(x4),f&&t(KGe),f&&t(kc),w(ex),f&&t(ZGe),f&&t(cr),w(ox),w(tx),w(k4),w(ax),w(K4),f&&t(eOe),f&&t(Pc),w(nx),f&&t(oOe),f&&t(fr),w(sx),w(ix),w(eE),w(dx),w(rE),f&&t(rOe),f&&t(Nc),w(cx),f&&t(tOe),f&&t(mr),w(fx),w(gx),w(aE),w(hx),w(sE),f&&t(aOe),f&&t(Dc),w(px),f&&t(nOe),f&&t(gr),w(ux),w(bx),w(iE),w(vx),w(BE),f&&t(sOe),f&&t(Vc),w(Fx),f&&t(lOe),f&&t(hr),w(Tx),w(Ex),w(NE),w(Cx),w(HE),f&&t(iOe),f&&t(Wc),w(wx),f&&t(dOe),f&&t(pr),w(Ax),w(Lx),w(JE),w(xx),w(dC),f&&t(cOe),f&&t(Uc),w($x),f&&t(fOe),f&&t(ur),w(kx),w(Rx),w(fC),w(Px),w(MC),f&&t(mOe),f&&t(Kc),w(Bx),f&&t(gOe),f&&t(_r),w(Ix),w(qx),w(CC),w(jx),w(PC),f&&t(hOe),f&&t(of),w(Dx),f&&t(pOe),f&&t(br),w(Gx),w(Vx),w(IC),w(Xx),w(QC),f&&t(uOe),f&&t(af),w(zx),f&&t(_Oe),f&&t(vr),w(Wx),w(Hx),w(UC),w(Ux),w(s5),f&&t(bOe),f&&t(lf),w(Jx),f&&t(vOe),f&&t(Fr),w(Yx),w(Zx),w(i5),w(e$),w(_5),f&&t(FOe),f&&t(ff),w(o$),f&&t(TOe),f&&t(Tr),w(r$),w(a$),w(v5),w(n$),w(L5),f&&t(MOe),f&&t(hf),w(s$),f&&t(EOe),f&&t(Mr),w(l$),w(d$),w($5),w(c$),w(S5),f&&t(COe),f&&t(_f),w(f$),f&&t(wOe),f&&t(Er),w(m$),w(h$),w(P5),w(p$),w(N5),f&&t(AOe),f&&t(Ff),w(_$),f&&t(yOe),f&&t(Cr),w(b$),w(F$),w(j5),w(T$),w(G5)}}}const zqt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Wqt(L){return XIt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Zqt extends DIt{constructor(g){super();GIt(this,g,Wqt,Xqt,OIt,{})}}export{Zqt as default,zqt as metadata};
